@ARTICLE{10741578,
  author={Chanakya, Patibandla and Harsha, Putla and Pratap Singh, Krishna},
  journal={IEEE Access}, 
  title={Robustness of Generative Adversarial CLIPs Against Single-Character Adversarial Attacks in Text-to-Image Generation}, 
  year={2024},
  volume={12},
  number={},
  pages={162551-162563},
  abstract={Generative Adversarial Networks (GANs) have emerged as a powerful type of generative model, particularly effective at creating images from textual descriptions. Similar to diffusion models, GANs rely on text encoders to extract embeddings from these descriptions. However, this reliance introduces specific vulnerabilities to adversarial attacks. A notable example is a single-character adversarial attack, where altering a single character in the text description can lead to significant performance degradation in the generated image quality and model’s performance. In this study, we systematically evaluate the susceptibility of GANs to such attacks using Generative Adversarial CLIP (GALIP), a single-stage architecture that leverages a pre-trained Contrastive Language-Image Pre-training (CLIP) text encoder for text embeddings. We meticulously selected captions with single-character modifications that exhibit maximum and median-distance embeddings for the attack. Experimental results show up to 310.5% degradation in Fréchet Inception Distance (FID) scores, underscoring the importance of developing improved defenses in text-to-image synthesis.},
  keywords={Text to image;Robustness;Perturbation methods;Degradation;Diffusion models;Image synthesis;Image quality;Training;Generators;Generative adversarial networks;Single-character attack;GALIP;GAN;CLIP text encoder;Text-to-image generation},
  doi={10.1109/ACCESS.2024.3491017},
  ISSN={2169-3536},
  month={},}@ARTICLE{10693469,
  author={Tang, Yi-Jun and Chi, Po-Wen},
  journal={IEEE Access}, 
  title={Theseus Data Synthesis Approach: A Privacy-Preserving Online Data Sharing Service}, 
  year={2024},
  volume={12},
  number={},
  pages={141130-141143},
  abstract={With the vigorously developed services of cloud computing, it is relatively easier and more convenient for organizations or enterprises to open data on clouds. However, as personal information in electronic data becomes more massive and detailed, how to balance data opening and personal privacy has become a critical issue. In this paper, we propose the Theseus Data Synthesis Approach (TDSA), which generates synthetic data by replacing partial records until no record from the original dataset remains. Unlike other data anonymization works such as k-anonymity and differential privacy, which encountered limitations and challenges when applying to real-world scenarios. In our work, Since there are no real data, personal privacy is definitely preserved. We also analyze the quality and utility of the synthetic dataset and make comparisons with related works. We conclude that with our scheme, opening useful data on clouds and preserving personal privacy can be simultaneously achieved.},
  keywords={Data privacy;Synthetic data;Generators;Generative adversarial networks;Differential privacy;Information integrity;Information filtering;Data integrity;Information sharing;Data anonymization;data synthesis;privacy-preserving data sharing},
  doi={10.1109/ACCESS.2024.3467373},
  ISSN={2169-3536},
  month={},}@ARTICLE{10154032,
  author={Pinto, Lyanh Vinicios Lopes and Alves, Andre Vinicius Neves and Medeiros, Alana Miranda and Costa, Saulo William da Silva and Pires, Yomara Pinheiro and Costa, Fernando Augusto Ribeiro and Seruffo, Marcos Cesar da Rocha},
  journal={IEEE Access}, 
  title={A Systematic Review of Facial Expression Detection Methods}, 
  year={2023},
  volume={11},
  number={},
  pages={61881-61891},
  abstract={Understanding emotions is one of the greatest capabilities of human beings, as it allows the understanding of facial expressions that facilitate the capture of important information about other individuals, which are used for the perception of mental or emotional states. Advances in Artificial Intelligence and Visual Computing, more specifically in Deep Learning with the advent of Artificial Neural Networks, have enhanced the ability of machines to infer human emotions through image analysis. This paper presents a Systematic Literature Review (SLR) with the purpose of researching, mapping and summarizing studies that address techniques or algorithms more efficiently. The convolutional neural network models analyzed in this review are based on deep learning with an emphasis on expression and microexpression recognition. The results suggest that database uses, with laboratory controlled images, combined with CNN’s such as VGG and ResNet, have excellent performances in their tests. For better understanding, we will detail and compare all the methods obtained in the review.},
  keywords={Databases;Deep learning;Systematics;Computational modeling;Codes;Search problems;Emotion recognition;Convolutional neural networks;Computer vision;Expressions recognition;convolutional neural networks;deep learning;databases;visual computing},
  doi={10.1109/ACCESS.2023.3287090},
  ISSN={2169-3536},
  month={},}@ARTICLE{10264089,
  author={Peppes, Nikolaos and Alexakis, Theodoros and Daskalakis, Emmanouil and Demestichas, Konstantinos and Adamopoulou, Evgenia},
  journal={IEEE Access}, 
  title={Malware Image Generation and Detection Method Using DCGANs and Transfer Learning}, 
  year={2023},
  volume={11},
  number={},
  pages={105872-105884},
  abstract={Cybersecurity in modern age is of utmost importance in almost every domain of economic activity. As digital activities make heavy use of multimedia a new type of cyber-threat gradually emerges: the possibility of producing and seamlessly embedding malware into digital images. Such type of malware can potentially avoid detection of typical scanners and infect the systems of either the service providers and the end-users. In this context, this study proposes and describes a complete methodology starting from the process of generation of malware-based yet realistic to the human eye images and concluding to the design of a suitable malware detector. This methodology designs and employs Deep Convolutional Generative Adversarial Networks (DCGANs) to synthetically generate two new large datasets of images: one with suspicious malware images (called Expanded Malware Images – EMI, in this study) and one with adversarial sample images of fashion products (called Fashion Adversarial Samples – FAS, in this study). The two new datasets are used for training two different Convolutional Neural Network (CNN) models using different training and configuration approaches. The first CNN (named c-CCN) follows a conventional approach for training, whereas the second one (named TL-CCN) leverages transfer learning to take advantage of the knowledge of ResNet50. Results show that the generation of malware images and adversarial samples stabilizes after 3000 iterations and produces very realistically looking images. Moreover, the TL-CNN model trained with part of the adversarial samples outperforms the other malware detector designs and produces results of high validation accuracy and minimal validation loss.},
  keywords={Malware;Generative adversarial networks;Europe;Convolutional neural networks;Training;Detectors;Generators;Transfer learning;Computer security;Malware generation;generative adversarial networks (GANs);transfer learning;convolutional neural network (CNN);cybersecurity},
  doi={10.1109/ACCESS.2023.3319436},
  ISSN={2169-3536},
  month={},}@ARTICLE{10339292,
  author={Naz, Isra and Shah, Jamal Hussain and Rehman, Muhammad Habib Ur and Rafiq, Muhammad and Choi, Gyu Sang},
  journal={IEEE Access}, 
  title={Quantum Mechanism-Based Convolution Model for the Classification of Pathogenic Bacteria}, 
  year={2023},
  volume={11},
  number={},
  pages={137747-137757},
  abstract={Water, especially drinking water, should be clean and free of disease-causing bacteria because of its critical role in life. However, it isn’t easy to identify and classify them rapidly at an early stage. Primarily, the examination of water is performed manually to check the contamination level. Some researchers have proposed techniques to detect and classify bacteria images, but this field still needs more attention. In this research work, a robust Quantum Convolutional Neural Network (QCNN) classification model is proposed to classify the six major categories of pathogenic bacteria. For the acquisition of pathogen images, different slides are created through the gram-staining process, and then images are captured from those slides. DIBaS is the publicly available dataset that provides these slides captured through gram-staining, which is used to evaluate the proposed methodology. So, in the first step, database preprocessing, small patches are extracted from slide images. However, the extracted patches were not clear and very useful, so the Enhanced Super-Resolution Generative Adversarial Network Model (ESRGAN) was applied to images to improve the image quality of extracted patches. The third step is to extract the deep features and classify bacterial images using the QCNN model, in which the Quantum Convolutional layer is added, and classical data is converted into quantum data to perform classification. Based on the results of classification experiments using the QCNN model, the accuracy is 96.54%.},
  keywords={Microorganisms;Pathogens;Clustering algorithms;Classification algorithms;Image processing;Image segmentation;Feature extraction;Generative adversarial networks;Convolutional neural networks;Quantum computing;Superresolution;Generative adversarial network (GAN);pathogens;quantum convolutional network (QCNN);super resolution},
  doi={10.1109/ACCESS.2023.3339127},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10615843,
  author={Dai, Philip and Yue, Kai and Jin, Richeng and Wu, Tianfu Matt and Xiong, Kaiqi},
  booktitle={2024 IEEE International Conference on Communications Workshops (ICC Workshops)}, 
  title={Enhancing Approximate Message Passing via Diffusion Models Towards On-Device Intelligence}, 
  year={2024},
  volume={},
  number={},
  pages={890-895},
  abstract={In this paper, we introduce a novel denoising-based approximate message passing framework augmented by a noise estimation module realized through a reverse diffusion process. This approach offers significant improvements in training simplicity, recovery quality, and inference efficiency, particularly suitable for deployment at mobile terminals in dynamic environments to facilitate edge computing. Extensive experiments verify the superiority of the proposed method over the state of the art, and demonstrate its potential towards sustainable edge computing and on-device intelligence at scale.},
  keywords={Training;Message passing;Conferences;Computational modeling;Noise;Estimation;Diffusion processes;compressed sensing;approximate message passing;diffusion models;edge computing},
  doi={10.1109/ICCWorkshops59551.2024.10615843},
  ISSN={2694-2941},
  month={June},}@INPROCEEDINGS{10778684,
  author={Huang, Jun and Ma, Hao and Zhang, Tengchao and Lin, Fei and Ma, Siji and Wang, Xiao and Wang, Fei-Yue},
  booktitle={2024 IEEE 4th International Conference on Digital Twins and Parallel Intelligence (DTPI)}, 
  title={DriveRP: RAG and Prompt Engineering Embodied Parallel Driving in Cyber-Physical-Social Spaces}, 
  year={2024},
  volume={},
  number={},
  pages={547-553},
  abstract={In recent years, numerous technological advancements in Artificial Generative Intelligences (AGIs) have demonstrated significant potential to transform the intelligence acquisition mechanisms in connected autonomous vehicles (CAVs). Integrating technologies like ChatGPT into CAVs can enhance human-machine interactions. However, the emergence of such new traffic entities may introduce unforeseen hallucinations and complex risks that surpass our current understanding. To address these challenges, Retrieval-Augmented Generation (RAG) and prompt engineering technologies are being explored to enhance the reliability and safety of autonomous driving systems. RAG retrieves relevant contextual information, such as driving experiences and real-time road network status, from external databases to ensure that foundation models have access to accurate and timely data for informed decision-making. Prompt engineering optimizes the performance of large language models in autonomous driving systems by designing and refining prompts that guide the models’ responses, thereby improving their relevance and accuracy in various driving scenarios. Together, these technologies enhance the robustness and trustworthiness of autonomous driving systems. This paper proposes DriveRP, a framework that integrates RAG and prompt engineering within the Descriptive-Predictive-Prescriptive Intelligence framework of Parallel Driving theory. DriveRP aims to enhance the safety and interpretability of autonomous vehicle trajectory planning, decision-making, and motion control, ultimately achieving the "6S" goals. Grounded in Digital Twins and Metaverse-embodied parallel driving theory, DriveRP provides the infrastructure and foundational intelligence for parallel driving with Multi-modal Large Lange Models(MLLMs). Additionally, the paper discusses future trends and potential research directions, focusing on the "6S" goals of parallel driving: Smart, Safe, Secure, Sensitive, Sustainable, and Serviceable.},
  keywords={Accuracy;Trajectory planning;Decision making;Transportation;Transforms;Safety;Digital twins;Prompt engineering;Motion control;Autonomous vehicles;Intelligent Transportation Systems;Autonomous Vehicles;Large Language Models;Metaverse;Digital Twin;Parallel Driving;Retrieval-Augmented Generation},
  doi={10.1109/DTPI61353.2024.10778684},
  ISSN={},
  month={Oct},}@ARTICLE{8865093,
  author={Park, Jihong and Samarakoon, Sumudu and Bennis, Mehdi and Debbah, Mérouane},
  journal={Proceedings of the IEEE}, 
  title={Wireless Network Intelligence at the Edge}, 
  year={2019},
  volume={107},
  number={11},
  pages={2204-2239},
  abstract={Fueled by the availability of more data and computing power, recent breakthroughs in cloud-based machine learning (ML) have transformed every aspect of our lives from face recognition and medical diagnosis to natural language processing. However, classical ML exerts severe demands in terms of energy, memory, and computing resources, limiting their adoption for resource-constrained edge devices. The new breed of intelligent devices and high-stake applications (drones, augmented/virtual reality, autonomous systems, and so on) requires a novel paradigm change calling for distributed, low-latency and reliable ML at the wireless network edge (referred to as edge ML). In edge ML, training data are unevenly distributed over a large number of edge nodes, which have access to a tiny fraction of the data. Moreover, training and inference are carried out collectively over wireless links, where edge devices communicate and exchange their learned models (not their private data). In a first of its kind, this article explores the key building blocks of edge ML, different neural network architectural splits and their inherent tradeoffs, as well as theoretical and technical enablers stemming from a wide range of mathematical disciplines. Finally, several case studies pertaining to various high-stake applications are presented to demonstrate the effectiveness of edge ML in unlocking the full potential of 5G and beyond.},
  keywords={Cloud computing;Artificial neural networks;5G mobile communication;Data models;Wireless networks;Training data;6G mobile communication;Machine learning;Scalability;6G;beyond 5G;distributed machine learning (ML);latency;on-device machine learningML;reliability;scalability;ultrareliable and low-latency communication (URLLC)},
  doi={10.1109/JPROC.2019.2941458},
  ISSN={1558-2256},
  month={Nov},}@ARTICLE{10849529,
  author={Wang, Lingling and Li, Xiang and Chen, Xiaoyan and Zhou, Bin},
  journal={IEEE Access}, 
  title={CenterNet-Elite: A Small Object Detection Model for Driving Scenario}, 
  year={2025},
  volume={13},
  number={},
  pages={17868-17877},
  abstract={With the rapid development of deep learning networks, the accuracy of generic object detection has consistently improved. Nonetheless, small object detection tasks still face a range of challenges. On one hand, the limited pixel size of small objects severely constrains their visual features in images, making them susceptible to distortion and difficult to distinguish from background noise. On the other hand, small objects often appear in complex scenarios with severe occlusion and dense arrangement, further increasing the complexity and difficulty of small object detection tasks. In this context, this study proposes a new model, CenterNet-Elite, to overcome these challenges. To address the issue of feature information loss resulting from multiple downsamplings during feature extraction for small objects, we introduce the spatial and channel reconstruction convolution (SCConv) into the bottleneck to reduce spatial and channel redundancy and enhance feature representation. In the meantime, we construct multiple short connections to integrate feature maps of the same scale during the downsampling and upsampling stages, thereby retaining critical shallow spatial information. We introduce a multi-scale pooling module, SPPCSPC, to address the challenge of significant variations in object scale. This module obtains receptive fields of different sizes through max-pooling layers of diverse sizes, adapting to changes in object scale on the feature maps. Furthermore, we introduce the content-aware reassembly of features (CARAFE) to replace deconvolution, refining the upsampling process to enhance the quality of feature maps. A series of comparative experiments and ablation studies demonstrate the effectiveness of our method in small object detection. The CenterNet-Elite achieves a 2.3% increase in the average precision on the large-scale small object detection dataset (SODA-D).},
  keywords={Feature extraction;Object detection;Image reconstruction;Generative adversarial networks;Convolution;Vectors;Convolutional neural networks;Computational modeling;Accuracy;YOLO;CARAFE;object detection;SCConv;SPPCSPC;SODA dataset},
  doi={10.1109/ACCESS.2025.3532786},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10526067,
  author={Rebekah, Repalle Deepthi Crestose and Laxmaiah, G and Raj, S Solomon and Singh, Samit Kumar and Hazela, Bramah and Verma, Manish Kumar},
  booktitle={2023 International Conference on New Frontiers in Communication, Automation, Management and Security (ICCAMS)}, 
  title={AI Based Data Augmentation Process Used to Find the Defect in Injection Molding}, 
  year={2023},
  volume={1},
  number={},
  pages={1-6},
  abstract={Automatic quality examination is now receiving attention as a vital element of the industry 4.o. However, because of the variety of products, challenges associated with creating uniformly high-quality product pictures, and short cycle durations, injection molding technologies have not gotten much attention in this field of study. In this work, we suggested an injection molding defect inspection method for edge intelligence. The data imbalance and scarcity issues faced by small and medium-sized businesses (SMEs) are addressed via data augmentation, implemented the unique technique of the injection process, and evaluated effectiveness of the created AI model. The suggested model’s accuracy was more than 90%, demonstrating the system’s viability for use in the real world.},
  keywords={Industries;Automation;Injection molding;Inspection;Data augmentation;Data models;Security;Automatic quality examination;Data augmentation;Injection molding;Artificial intelligence model;Defect inspection},
  doi={10.1109/ICCAMS60113.2023.10526067},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9162664,
  author={Luo, Zhengping and Hou, Tao and Nguyen, Tung Thanh and Zeng, Hui and Lu, Zhuo},
  booktitle={IEEE INFOCOM 2020 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, 
  title={Log Analytics in HPC: A Data-driven Reinforcement Learning Framework}, 
  year={2020},
  volume={},
  number={},
  pages={550-555},
  abstract={High Performance Computing (HPC) has been employed in many fields such as aerospace, weather forecast, numerical simulation, scientific research etc. Security of HPC, especially anomaly/intrusion detection, has attracted many attentions in recent years. Given the heavily instrumented property of HPC systems, logs become an effective and direct data source that can be utilized to evaluate the system status, further, to detect anomalies or malicious users. In this paper, we offer a novel perspective, treating the anomaly detection in HPC as a sequential decision process, and further applying reinforcement learning techniques to learn the state transition process, based on which we build a framework named as ReLog to detect anomalies or malicious users. Besides, a common challenge of employing machine learning techniques is lacking sufficient data, we provide a generative adversarial network (GAN)-based solution to generate sufficient training data in HPC. The experimental validations are conducted based on real-world collected MPI logs, and our results demonstrate a 93% of detection accuracy on the collected dataset.},
  keywords={Feature extraction;Learning (artificial intelligence);Security;Machine learning;Generative adversarial networks;Microsoft Windows;Data mining;High performance computing;security;reinforcement learning;defenses and attacks;log analytics},
  doi={10.1109/INFOCOMWKSHPS50562.2020.9162664},
  ISSN={},
  month={July},}@INPROCEEDINGS{11102713,
  author={Jyoti and Sharma, Akhilesh Kumar and Srivastava, Devesh Kumar},
  booktitle={2025 International Conference on Networks and Cryptology (NETCRYPT)}, 
  title={Review of Deep Learning Models Based on Hyperspectral Image Classification Techniques in Monitoring Crop Production}, 
  year={2025},
  volume={},
  number={},
  pages={506-511},
  abstract={the importance of evaluating and ensuring the quality of agricultural and horticultural products has increased in recent years. Conventional techniques that require Field measurements, research, as well as statistics analysis are expensive, and time taking labor-intensive. As a novel technology, HSI has been very popular, especially because of its potential uses in the field of remote sensing, particularly in agriculture. But, there are a number of difficulties in identifying HSI data, including the complex non-linear relationship between spectral bands and spatial coordinates, limited availability of training data and the massive duplication of spectral bands. Interestingly, Deep Learning (DL) techniques have demonstrated remarkable efficacy in a number of HSI analytic applications, including agricultural ones. There is an urgent need for a thorough survey that will help academics understand the significant progress made and the fascinating potential avenues for future research in this area, given the growing interest in using DL approaches to leverage HSI data for agricultural applications. This study of the literature carefully gathers, examines, and talks about recent attempts to use DL approaches. Autoencoders (AE), Recurrent Neural Networks (RNN), Deep Belief Networks (DBN), Generative Adversarial Networks (GAN), Convolutional Neural Networks (CNN) (in 1D, 2D, and 3D configurations), Transfer Learning (TL), Semi-Supervised Learning (SSL), Few-Shot Learning (FSL), and Active Learning (AL) are just a few of the techniques that fall under this broad category. These methods are designed to tackle the particular difficulties presented by HSI analysis in agriculture. The performance demonstrated by these various approaches is assessed and discussed in this review. In light of this, the effectiveness of these methods has been thoroughly examined and debated in light of the findings of cutting-edge research on well-known land cover datasets repository on Github. The viability, adaptability, and affordability of using hyperspectral imagery (HSI) for crop classification in agricultural regions have been extensively established.},
  keywords={Recurrent neural networks;Reviews;Transfer learning;Crops;Generative adversarial networks;Agriculture;Complexity theory;Convolutional neural networks;Artificial intelligence;Hyperspectral imaging;CNN;RNN;GAN;HSI;Deep learning;Hyperspectral imaging;Sustainable Agriculture},
  doi={10.1109/NETCRYPT65877.2025.11102713},
  ISSN={},
  month={May},}@INPROCEEDINGS{10984516,
  author={K, Praveen and Pandey, Atul and Rudra, Bhawana},
  booktitle={2025 IEEE International Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation (IATMSI)}, 
  title={An Effective Approach for Deepfake Video Detection using Binarized Neural Network}, 
  year={2025},
  volume={3},
  number={},
  pages={1-6},
  abstract={The rise of DeepFake technologies, especially in audio and video, poses significant threats to information integrity, security, and privacy. Artificially driven Artificial Intelligence (AI) methods and their advancement make it difficult to trace synthetic media through deepfakes that closely approximate real speech, facial expressions, and body movements. Consequently, traditional methods of detecting these are losing the race because they cannot compete with the newly invented methods that are more advanced in comparison. This paper proposes a lightweight and scalable approach to deepfake video detection using Binarized Neural Networks (BNNs). We integrate BNNs with Convolutional Neural Networks (CNNs) and Multi-task Cascaded Convolutional Networks (MTCNN) to boost feature extraction and analysis while making sure that this is done at a computational efficiency, especially to be deployed in resource-constrained systems such as mobile and embedded devices. The binarization of network weights and activations naturally deals with the trade-off regarding detection accuracy and computational cost. Our approach introduces a practical solution for real-time deepfake detection, thus advancing toward more secure and trusted digital environments. Our proposed model has achieved an accuracy of 80%.},
  keywords={Deepfakes;Technological innovation;Accuracy;Neural networks;Streaming media;Real-time systems;Computational efficiency;Convolutional neural networks;Security;Artificial intelligence;Deepfake Detection;Convolutional Neural Networks;Binarized Neural Networks;Video Processing;Multitask Cascaded Convolutional Networks},
  doi={10.1109/IATMSI64286.2025.10984516},
  ISSN={},
  month={March},}@ARTICLE{10873847,
  author={Yang, Yana and Yi, Haorui and Xi, Meng and Wen, Jiabao and Yang, Jiachen},
  journal={IEEE Consumer Electronics Magazine}, 
  title={GenAI-Driven Unsupervised Denoising for Consumer Device Imagery}, 
  year={2025},
  volume={14},
  number={5},
  pages={94-102},
  abstract={In the era of ubiquitous consumer electronics, image transmission across various communication channels has become an indispensable part of life. However, noise interference during transmission affects image quality, consumer satisfaction, and device functionality. To address this issue, we propose an unsupervised image denoising framework based on generative adversarial networks, which is applicable to consumer electronic devices under various communication channels and improves the quality of images received by users. We introduce a multilevel feature interaction model that utilizes a cross-attention mechanism to efficiently integrate multiscale feature information, preserve shallow details, and incorporate deep semantics. Extensive experiments show that our proposed framework exhibits excellent performance in a variety of realistic noisy scenarios, effectively removing a wide range of noise intensities while preserving image details and structural information, thus significantly improving the visual quality of content on consumer devices.},
  keywords={Transformers;Consumer electronics;Noise measurement;Feature extraction;Noise reduction;Image denoising;Training;Artificial intelligence;Data mining;Ubiquitous computing;Unsupervised learning;Generative AI},
  doi={10.1109/MCE.2025.3538904},
  ISSN={2162-2256},
  month={Sep.},}@INPROCEEDINGS{11080590,
  author={Di Caro, Edoardo and Brina, Matteo and Belletti, Nicolas and Poltronieri, Filippo and Tortonesi, Mauro and Stefanelli, Cesare},
  booktitle={2025 IEEE 11th International Conference on Network Softwarization (NetSoft)}, 
  title={TimeGraph: Synthetic Generation of Graph Sequences for Realistic Mobile Connectivity Models}, 
  year={2025},
  volume={},
  number={},
  pages={249-256},
  abstract={Softwarized networking solutions are a key enabler for effective and efficient communications in natural disaster recovery scenarios. However, the design development of reliable and robust softwarization solutions in this context is hampered by the scarcity of reference datasets which accurately capture the real-world behavior – and variability – of those environments. This paper presents a method for synthetic generation of sequences of graphs using state-of-the-art Graph Neural Networks (GNNs) and Time-series Generative Adversarial Networks (TimeGAN). By leveraging available real-world data, the proposed approach generates synthetic datasets that closely replicate the features and connectivity patterns found in actual scenarios. These synthetic datasets not only support the training of AI models but also enable testing and evaluation of solutions across different but similar scenarios. Preliminary results using the Anglova scenario show that our solution accurately captures spatio-temporal behaviour in disrupted networks, making it a powerful tool for developing and validating systems in fields where access to real-world data is limited, enhancing their generalizability and reliability.},
  keywords={Training;Disasters;Reliability engineering;Generative adversarial networks;Graph neural networks;Data models;Artificial intelligence;Synthetic data;Testing;Synthetic Data Generation;Graph Neural Networks;Mobile Networks},
  doi={10.1109/NetSoft64993.2025.11080590},
  ISSN={2693-9789},
  month={June},}@ARTICLE{10466747,
  author={Chen, Yuxuan and Li, Rongpeng and Zhao, Zhifeng and Peng, Chenghui and Wu, Jianjun and Hossain, Ekram and Zhang, Honggang},
  journal={IEEE Network}, 
  title={NetGPT: An AI-Native Network Architecture for Provisioning Beyond Personalized Generative Services}, 
  year={2024},
  volume={38},
  number={6},
  pages={404-413},
  abstract={Large language models (LLMs) have triggered tremendous success to empower our daily life by generative information. The personalization of LLMs could further contribute to their applications due to better alignment with human intents. Towards personalized generative services, a collaborative cloud-edge methodology is promising, as it facilitates the effective orchestration of heterogeneous distributed communication and computing resources. In this article, we put forward NetGPT to capably synergize appropriate LLMs at the edge and the cloud based on their computing capacity. In addition, edge LLMs could efficiently leverage location-based information for personalized prompt completion, thus benefiting the interaction with the cloud LLM. In particular, we present the feasibility of NetGPT by leveraging low-rank adaptation-based fine-tuning of open-source LLMs (i.e., GPT-2-base model and LLaMA model), and conduct comprehensive numerical comparisons with alternative cloudedge collaboration or cloud-only techniques, so as to demonstrate the superiority of NetGPT. Subsequently, we highlight the essential changes required for an artificial intelligence (AI)-native network architecture towards NetGPT, with emphasis on deeper integration of communications and computing resources and careful calibration of logical AI workflows. Furthermore, we demonstrate several benefits of NetGPT, which come as by-products, as the edge LLMs’ capability to predict trends and infer intents promises a unified solution for intelligent network management & orchestration. We argue that NetGPT is a promising Al-native network architecture for provisioning beyond personalized generative services.},
  keywords={Computational modeling;Collaboration;Servers;Artificial intelligence;Adaptation models;Training;Context modeling;Large language models},
  doi={10.1109/MNET.2024.3376419},
  ISSN={1558-156X},
  month={Nov},}@INPROCEEDINGS{10097255,
  author={Andreev, Pavel and Alanov, Aibek and Ivanov, Oleg and Vetrov, Dmitry},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={HIFI++: A Unified Framework for Bandwidth Extension and Speech Enhancement}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Generative adversarial networks have recently demonstrated outstanding performance in neural vocoding outperforming best autoregressive and flow-based models. In this paper, we show that this success can be extended to other tasks of conditional audio generation. In particular, building upon HiFi vocoders, we propose a novel HiFi++ general frame-work for bandwidth extension and speech enhancement. We show that with the improved generator architecture, HiFi++ performs better or comparably with the state-of-the-art in these tasks while spending significantly less computational resources. The effectiveness of our approach is validated through a series of extensive experiments.},
  keywords={Vocoders;Computational modeling;Buildings;Bandwidth;Computer architecture;Speech enhancement;Signal processing;speech enhancement;bandwidth extension},
  doi={10.1109/ICASSP49357.2023.10097255},
  ISSN={2379-190X},
  month={June},}@INPROCEEDINGS{10222152,
  author={She, Lei and Zhang, Chenghong and Man, Xin and Luo, Xuewei and Shao, Jie},
  booktitle={2023 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)}, 
  title={A Self-Attention Causal LSTM Model for Precipitation Nowcasting}, 
  year={2023},
  volume={},
  number={},
  pages={470-473},
  abstract={Precipitation nowcasting is a critical task that can facilitate multiple applications including urban warnings and traffic. Deep learning methods combining convolutional neural networks and recurrent neural networks have been investigated for this problem. However, they always capture local and ineffective spatial dependencies through convolutional layers, while long-range spatial dependencies are critical for spatial applications. To improve long-range representations, we propose a spatiotemporal prediction model called Self-Attention Causal LSTM (SAC-LSTM), which utilizes a self-attention mechanism to model channel correlations. SAC-LSTM aggregates sequence features by extracting spatial features with global and local dependencies so that the visual details of each frame can be significantly preserved. Furthermore, SAC-LSTM is trained by a generative adversarial network with a learned perceptual loss, which improves the perceptual quality of predictions. Experimental results show that the proposed SAC-LSTM outperforms other models. Code is available at https://github.com/LeiShel/SAC-LSTM-MindSpore.},
  keywords={Visualization;Extrapolation;Precipitation;Recurrent neural networks;Aggregates;Predictive models;Feature extraction;Precipitation nowcasting;image sequence prediction;radar echo extrapolation},
  doi={10.1109/ICMEW59549.2023.00088},
  ISSN={},
  month={July},}@INPROCEEDINGS{9630026,
  author={Zhang, Guanghao and Hui, Hui and Ning, Bin and Dong, Di and Tian, Jie and He, Wen},
  booktitle={2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)}, 
  title={Self-Attention Based Virtual Staining for Bright-field Images of Label-free Human Carotid Atherosclerotic Plaque Tissue Section}, 
  year={2021},
  volume={},
  number={},
  pages={3492-3495},
  abstract={Histological analysis of carotid atherosclerotic plaque tissue specimens is a widely used method for studying the diagnosis of ischemic heart disease and stroke. Understanding the physiological and pathological mechanisms of carotid atherosclerotic plaque is of great significance for the effective prevention and treatment of plaque formation and rupture. In this work, we adapted a self-attention generative adversarial model to virtually stain label-free human carotid atherosclerotic plaque tissue sections into corresponding H&E stained sections. The self-attention mechanism and multi-layer structure are introduced into the residual steps of the generator and in the discriminator. Our method achieved the best performance (SSIM, PSNR, and LPIPS of 0.53, 20.29, and 0.30, respectively) in comparison with other state-of-the-art methods.Clinical Relevance — The proposed approach allows for the virtual staining of unlabeled human carotid plaque tissue images. It identifies the histopathological features of atherosclerotic plaques in the same tissue sample which could facilitate the development of personalized prevention and other interventional treatments for carotid atherosclerosis.},
  keywords={Measurement;Heart;Adaptation models;Pathology;Atherosclerosis;Physiology;Generators},
  doi={10.1109/EMBC46164.2021.9630026},
  ISSN={2694-0604},
  month={Nov},}@ARTICLE{10976516,
  author={Liu, Feng and Chang, Xiaobin},
  journal={Computational Visual Media}, 
  title={IIDM: Image-to-Image Diffusion Model for Semantic Image Synthesis}, 
  year={2025},
  volume={11},
  number={2},
  pages={423-429},
  abstract={Semantic image synthesis aims to generate high-quality images given semantic conditions, i.e., segmentation masks and style reference images. Existing methods widely adopt generative adversarial networks (GANs). GANs take all conditional inputs and directly synthesize images in a single forward step. In this paper, semantic image synthesis is treated as an image denoising task and is handled with a novel image-to-image diffusion model (IIDM). Specifically, the style reference is first contaminated with random noise and then progressively denoised by IIDM, guided by segmentation masks. Moreover, three techniques, refinement, color-transfer, and model ensembles, are proposed to further boost the generation quality. They are plug-in inference modules and do not require additional training. Extensive experiments show that our IIDM outperforms existing state-of-the-art methods by clear margins. Further analysis is provided via detailed demonstrations. We have implemented IIDM based on the Jittor framework; code is available at https://github.com/ader47/jittor-jieke-semantic_images_synthesis.},
  keywords={Semantics;Image synthesis;Image segmentation;Noise reduction;Diffusion models;Training;Diffusion processes;Image quality;Accuracy;Testing},
  doi={10.26599/CVM.2025.9450419},
  ISSN={2096-0662},
  month={April},}@INPROCEEDINGS{10327361,
  author={Luo, Tao and Zhu, Songhao},
  booktitle={2023 35th Chinese Control and Decision Conference (CCDC)}, 
  title={Multi-Branch Convolutional Auto-Encoder Model For Cross-Domain Person Re-Recognition}, 
  year={2023},
  volume={},
  number={},
  pages={2378-2383},
  abstract={Cross-domain person re-recognition is very important for the applications of intelligent video surveillance. To further reduce the cross-domain differences, a new multi-branch convolutional auto-encoder based cross-domain person re-recognition network (MCAENet) is here proposed. Firstly, the reconstructed feature map is utilized as an input of the generative model module, and reconstruction loss and divergence loss are utilized to extract domain specific features and unknown domain features; then, the domain invariant feature guidance branch is introduced to enhance the robustness of domain invariant features; finally, identity loss is introduced and combined with the triple loss to constrain the distance between different pedestrians, so as to extract representative features to distinguish different pedestrians. Extensive experimental results demonstrate that the proposed cross-domain person re-recognition method based on convolutional -encoder achieves the best identification accuracy in various environments.},
  keywords={Technological innovation;Analytical models;Pedestrians;Feature extraction;Video surveillance;Robustness;Person Re-Recognition;Convolutional Auto-Encoder;Invariant Features;Specific Feature},
  doi={10.1109/CCDC58219.2023.10327361},
  ISSN={1948-9447},
  month={May},}@INPROCEEDINGS{10444449,
  author={Park, Jiwon and Jeong, Dasol and Lee, Hyebean and Han, Seunghee and Paik, Joonki},
  booktitle={2024 IEEE International Conference on Consumer Electronics (ICCE)}, 
  title={Dynamic Contextual Attention Networks for Improved Single Image Generation}, 
  year={2024},
  volume={},
  number={},
  pages={1-2},
  abstract={Recently, single generative models that generate various samples from a single image without training on large datasets are of great interest. However, training the model to generate realistic images from a single sample remains a challenging task. Previous research in the field of single-image generation has also exhibited sensitivity to fine-grained image features and encountered limitations in terms of the quality of the generated images. To overcome the limitations, we introduce an attention module and block architecture that leverages latent information within a single image. The proposed method aims to enhance the capabilities of a single image generation model to generate a diverse range of data samples based on a single input image. Our proposed model shows innovative results in a variety of tasks and performs particularly well in image generation and outpainting. Experimental results show that our proposed model provides better image quality compared to the traditional single image generation, which represents an important advance for future image processing applications.},
  keywords={Training;Image quality;Sensitivity;Image synthesis;Data models;Task analysis;Context modeling;Single image generation;Random sampling},
  doi={10.1109/ICCE59016.2024.10444449},
  ISSN={2158-4001},
  month={Jan},}@INPROCEEDINGS{8372100,
  author={Cherti, Mehdi and Kégl, Balázs and Kazakçı, Akin},
  booktitle={2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Out-of-Class Novelty Generation : An Experimental Foundation}, 
  year={2017},
  volume={},
  number={},
  pages={1312-1319},
  abstract={Recent advances in machine learning have brought the field closer to computational creativity research. From a creativity research point of view, this offers the potential to study creativity in relationship with knowledge acquisition. From a machine learning perspective, however, several aspects of creativity need to be better defined to allow the machine learning community to develop and test hypotheses in a systematic way. We propose an actionable definition of creativity as the generation of out-of-distribution novelty. We assess several metrics designed for evaluating the quality of generative models on this new task. We also propose a new experimental setup. Inspired by the usual held-out validation, we hold out entire classes for evaluating the generative potential of models. The goal of the novelty generator is then to use training classes to build a model that can generate objects from future (hold-out) classes, unknown at training time - and thus, are novel with respect to the knowledge the model incorporates. Through extensive experiments on various types of generative models, we are able to find architectures and hyperparameter combinations which lead to out-of-distribution novelty.},
  keywords={Machine learning;Creativity;Measurement;Generators;Training;Gallium nitride;Pipelines;generative model;knowledge driven creativity;deep neural nets;value of novelty;evaluation of generative models},
  doi={10.1109/ICTAI.2017.00197},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{11042624,
  author={Om Prakash, P.G. and Tadi, Yoga Sairam Srihari and Karumajji, Kyathisree},
  booktitle={2025 2nd International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)}, 
  title={AI-Powered Facial Analysis: Real or Fake Image Detection, Age Group Classification, Grooming Analysis and Emotion Recognition}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={The development of deepfake technology has made it extremely difficult to tell the difference between real and altered facial photos, which presents significant privacy and security risks. This project offers a multifaceted deep learning-driven solution that can classify age, identify emotions, and conduct grooming analysis in addition to detecting deepfake photos. The method achieves 93.91% success rate in deepfake identification using a model built on CNN that was trained on datasets of real and fake faces. Furthermore, an OpenCV-Caffe model categorizes people into various age groups, a Vision Transformer (ViT)-based beard recognition model achieves 99.9% accuracy, and an Xception-based emotion detection method reaches 98.65% accuracy. Users can input photographs, evaluate several faces, and generate a detailed report on age distribution, feelings beard presence and real/fake categorization using the system's real-time Streamlit user interface. This AI-powered solution addresses the growing worries about digital verification of identity and distorted media by offering a safe, effective and automated method of facial analysis.},
  keywords={Emotion recognition;Deepfakes;Computer vision;Accuracy;Streaming media;Transformers;Real-time systems;Security;Faces;Resilience;Age Classification;Deepfake Detection;Emotion Recognition;Facial Analysis;Grooming Detection and Vision Transformer},
  doi={10.1109/RMKMATE64874.2025.11042624},
  ISSN={},
  month={May},}@INPROCEEDINGS{11141312,
  author={Hoque, Mahmudul and Hasan, Md Rakibul and Emon, Md. Ismail Siddiqi and Oluwafemi, Ejiga Peter Ojonugwa and Rahman, Md Mahmudur and Khalifa, Fahmi},
  booktitle={2025 IEEE 4th International Conference on Computing and Machine Intelligence (ICMI)}, 
  title={Comparative Analysis of Fine-Tuned Multimodal Models in Radiology Image Captioning}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Multimodal artificial intelligence (AI) models offer a promising approach for automatically generating captions from radiology images, bridging visual and textual data to enhance medical image interpretation. This study compares a selectively fine-tuned Large Multimodal Model (LMM) with a fully fine-tuned multimodal encoder-decoder architecture on a subset of the Radiology Objects in Context version 2 (ROCOv2) dataset. Specifically, Vision Generative Pretrained Transformer 2 (VisionGPT-2) is evaluated against Large Language and Vision Assistant (LLaVA) version 1.6, a Mistral-7B-based LMM adapted using Low-Rank Adaptation (LoRA) on selected projection matrices. Experimental results show that LLaVA-1.6 outperforms VisionGPT-2 while significantly reducing the computational cost of full fine-tuning through selective adaptation with LoRA. Performance gains are observed across multiple metrics, including MedBERTScore (0.633), ClinicalBLEURT (0.456), ROUGE (0.251), BLEU-1 (0.209), BLEURT (0.317), METEOR (0.092), CIDEr (0.245), CLIPScore (0.816), RefCLIPScore (0.815), and BERTScore (0.628). These findings underscore the potential of selectively fine-tuned LMMs for efficient, semantically rich caption generation in medical imaging tasks, particularly in contexts constrained by sensitive data and limited computational resources.},
  keywords={Adaptation models;Analytical models;Visualization;Computational modeling;Radiology;Transformers;Data models;Computational efficiency;Artificial intelligence;Biomedical imaging;Large Multimodal Model;Transformer;Large Language and Vision Assistant;Mistral-7B;Medical Image Analysis;Low-Rank Adaptation;Muitlimodal Data;Radiology Image Captioning;Vision Generative Pre-Trained Transformer-2},
  doi={10.1109/ICMI65310.2025.11141312},
  ISSN={},
  month={April},}@ARTICLE{9760165,
  author={Pfau, Johannes and Liapis, Antonios and Yannakakis, Georgios N. and Malaka, Rainer},
  journal={IEEE Transactions on Games}, 
  title={Dungeons & Replicants II: Automated Game Balancing Across Multiple Difficulty Dimensions via Deep Player Behavior Modeling}, 
  year={2023},
  volume={15},
  number={2},
  pages={217-227},
  abstract={Video game testing has become a major investment of time, labor, and expense in the game industry. Particularly the balancing of in-game units, characters, and classes can cause long-lasting issues that persist years after a game's launch. While approaches incorporating artificial intelligence have already shown successes in reducing manual effort and enhancing game development processes, most of these draw on heuristic, generalized, or optimal behavior routines, while actual low-level decisions from individual players and their resulting playing styles are rarely considered. In this article, we apply deep player behavior modeling to turn atomic actions of 213 players from six months of single-player instances within the MMORPG Aion into generative models that capture and reproduce particular playing strategies. In a subsequent simulation, the resulting generative agents (“replicants”) were tested against common NPC opponent types of MMORPGs that iteratively increased in difficulty, respective to the primary factor that constitutes this enemy type (Melee, Ranged, Rogue, Buffer, Debuffer, Healer, Tank, or Group). As a result, imbalances between classes as well as strengths and weaknesses regarding particular combat challenges could be identified and regulated automatically.},
  keywords={Games;Industries;Computer bugs;Measurement;Computational modeling;Tuning;Reinforcement learning;Artificial intelligence;automatic playtesting;game balance;massive multiplayer online games;user modeling},
  doi={10.1109/TG.2022.3167728},
  ISSN={2475-1510},
  month={June},}@INPROCEEDINGS{9752445,
  author={Thanikkal, Jibi G and Dubey, Ashwani Kumar and Thomas, M.T},
  booktitle={2022 International Mobile and Embedded Technology Conference (MECON)}, 
  title={Importance of Image Morphological Features in Continues Learning}, 
  year={2022},
  volume={},
  number={},
  pages={372-376},
  abstract={A deep neural network is a fantastic and effective method for image processing. However, the pixel values are based on continuous learning leading to forgetting the previous information from the system. This forgetting problem also affects the result of deep learning. Morphology is structure-based image processing action that processes the input image based on its shape features. In a leaf identification system, leaf morphological features include shape, apex, base, edge and vein. Leaf morphological features are helping to study the structural information of a leaf image. The image morphological feature concentrates on the image structure so the image morphological feature based deep learning system that helps the artificial brain to focus on image features. So, in this article, a solution for the forgetting problem of continuous learning, using the image morphological feature is provided.},
  keywords={Deep learning;Shape;Veins;Image edge detection;Neural networks;Morphology;Feature extraction;Image processing;deep learning;continues learning;artificial intelligence;image features},
  doi={10.1109/MECON53876.2022.9752445},
  ISSN={},
  month={March},}@ARTICLE{9448268,
  author={Siddiqi, Umair F. and Sait, Sadiq M. and Al-Utaibi, Khaled Abdul-Aziz},
  journal={IEEE Access}, 
  title={A Machine Learning Method to Synthesize Channel State Information Data in Millimeter Wave Networks}, 
  year={2021},
  volume={9},
  number={},
  pages={83441-83452},
  abstract={In millimeter-wave (MMW) networks, the channel state information (CSI) carries essential information from the user to the base station (BS). The CSI values depend highly on the geometrical and physical features of the environment. Therefore, it is impossible to generate CSI data for computer simulations or analysis through mathematical models. The CSI in MMW networks can only be acquired through physical measurement(s) or with the help of expensive and complicated ray-tracing software. For many users, both these options are infeasible. This work aims to propose a simple and fast method that can generate artificial samples from the real data samples while ensuring that the artificial samples look similar to the real ones. The proposed method helps increase the size of existing CSI datasets and likely to benefit the evolution of deep learning models that need a large amount of training/testing data. The proposed method comprises two parts. (i) The first part applies data clustering and transformations such as principal component analysis (PCA)-based dimensionality reduction and probability integral transform (PIT) to convert the real data into a multivariate normal distribution of a smaller number of variables, and (ii) The second part synthesizes artificial data by learning from the multivariate normal distribution of the first part. The last step in the second part is to apply PIT and inverse PCA transformations to transform the artificial data into the same space as the input data. We compared the proposed method's performance with the well-known Kernel density estimation (KDE)-based methods that use Scott's rule and Silverman's rule to choose the bandwidth parameter value. The results show that the artificial samples generated by the proposed method exhibit very high similarity with the real ones as compared to the KDE-based methods.},
  keywords={Gaussian distribution;Data models;Bandwidth;MIMO communication;Interference;Estimation;Wireless communication;Millimeter wave networks;wireless communications;machine learning;principal component analysis;artificial data},
  doi={10.1109/ACCESS.2021.3087630},
  ISSN={2169-3536},
  month={},}@ARTICLE{10485267,
  author={Wu, Xiaokang and Xu, Wei and Xue, Feng},
  journal={Journal of Modern Power Systems and Clean Energy}, 
  title={Sample Generation for Security Region Boundary Identification Based on Topological Features of Historical Operation Data}, 
  year={2024},
  volume={12},
  number={4},
  pages={1087-1095},
  abstract={Since the scale and uncertainty of the power system have been rapidly increasing, the computation efficiency of constructing the security region boundary (SRB) has become a prominent problem. Based on the topological features of historical operation data, a sample generation method for SRB identification is proposed to generate evenly distributed samples, which cover dominant security modes. The boundary sample pair (BSP) composed of a secure sample and an unsecure sample is defined to describe the feature of SRB. The resolution, sampling, and span indices are designed to evaluate the coverage degree of existing BSPs on the SRB and generate samples closer to the SRB. Based on the feature of flat distribution of BSPs over the SRB, the principal component analysis (PCA) is adopted to calculate the tangent vectors and normal vectors of SRB. Then, the sample distribution can be expanded along the tangent vector and corrected along the normal vector to cover different security modes. Finally, a sample set is randomly generated based on the IEEE standard example and another new sample set is generated by the proposed method. The results indicate that the new sample set is closer to the SRB and covers different security modes with a small calculation time cost.},
  keywords={Security;Vectors;Power system stability;Principal component analysis;Mathematical models;Load flow;Indexes;Clustering analysis;principal component analysis (PCA);sample generation;security region boundary (SRB)},
  doi={10.35833/MPCE.2023.000321},
  ISSN={2196-5420},
  month={July},}@ARTICLE{11069291,
  author={Hossain, Md Junayed and Alam, Khorshed and Fahad Monir, Md and Mozammal Hoque, Md and Ahmed, Tarem},
  journal={IEEE Access}, 
  title={Explainable AI Meets Synthetic Data: A Deep Learning Framework for Detecting Network Intrusion in NextG Network Infrastructure}, 
  year={2025},
  volume={13},
  number={},
  pages={114979-115001},
  abstract={In today’s digitally driven world, network security has become a top accountability as cyberattacks become more sophisticated, especially within emerging NextG network infrastructures. Advanced threats, including as zero-day exploits, polymorphic malware, and large-scale distributed denial-of-service (DDoS) attacks, have surpassed traditional Network Intrusion Detection Systems (NIDS), which frequently use out-of-date signature-based methodologies. These conventional methods not only struggle to detect unknown attack patterns but are also hindered by the issue of imbalanced datasets, where minority attack classes are underrepresented and frequently overlooked. To address these challenges, we proposes an innovative NIDS framework tailored for NextG networks that combines Generative Adversarial Networks (GANs) with Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) models. The framework utilizes GANs to generate synthetic samples for minority classes, ensuring a balanced dataset and enhancing the detection of underrepresented attack types. The CNN and LSTM models, applied independently, leverage their respective strengths to extract spatial and temporal features from network traffic, achieving robust classification accuracy. Furthermore, we integrate Local Interpretable Model-Agnostic Explanations (LIME) to make model predictions transparent, increasing trust and usability for practical deployment. Our framework is evaluated on the NF-CSE-CIC-IDS2018 dataset and achieves outstanding results. The LSTM model attains a detection accuracy of 99.67%, while CNN achieves 97.45%. On this GitHub Repository: https://github.com/i-am-junayed/XAI-Intrusion-Detection-System, the entire data analysis and prediction method is available for use by anyone. Here, both models perform exceptionally well in detecting minority attack classes, with the LSTM showing superior consistency across all metrics. This framework’s high accuracy, explainability, and adaptability make it a critical tool for securing dynamic and high-speed NextG networks against evolving cyber threats.},
  keywords={Long short term memory;Convolutional neural networks;Generative adversarial networks;Feature extraction;Telecommunication traffic;Accuracy;Predictive models;Network security;Network intrusion detection;Deep learning;Intrusion detection;GANs imputation;LSTM;CNN;LIME;XAI;SDG 9;SDG 16},
  doi={10.1109/ACCESS.2025.3585783},
  ISSN={2169-3536},
  month={},}@ARTICLE{11080019,
  author={Zhu, Lin and Zhang, Wenjuan},
  journal={IEEE Access}, 
  title={Research on Polyphonic Music Generation Algorithm Based on GPT Large Model}, 
  year={2025},
  volume={13},
  number={},
  pages={129638-129647},
  abstract={Along with the rapid technological progress in the field of artificial intelligence, music generation algorithms based on large-scale pre-trained models have increasingly become the focus of academic attention. Existing polyphonic music generation techniques have limitations in terms of melodic complexity and harmonic diversity. To address the challenges of structural accuracy and long-range dependency modelling in polyphonic music generation, this paper proposes a targeted fine-tuning algorithm based on GPT macromodels, which improves the generation quality by incorporating domain-specific mechanisms. On the basis of GPT, the method embeds directional cross-track attention to enhance the modelling of vocal interactions, designs dynamic interval weight mask constraints and acoustic compliance, and introduces beat-phase embedding to enhance the temporal structure perception, forming a “GPT + domain-enhanced” generation framework. Experimental results show that the method demonstrates significant advantages in objective evaluation dimensions, such as note accuracy and harmonic consistency. The proposed method opens up an innovative path for polyphonic music composition and demonstrates the great potential of this technology in practical scenarios.},
  keywords={Music;Harmonic analysis;Transformers;Training;Multiple signal classification;Data models;Coherence;Accuracy;Deep learning;Complexity theory;GPT large language model;polyphonic music generation;transformer module;fine-tuning},
  doi={10.1109/ACCESS.2025.3588847},
  ISSN={2169-3536},
  month={},}@ARTICLE{10517591,
  author={Hun Yoo, Joo and Hyun An, Ji and Chung, Tai-Myoung},
  journal={IEEE Access}, 
  title={Feature Distribution-Based Medical Data Augmentation: Enhancing Mood Disorder Classification}, 
  year={2024},
  volume={12},
  number={},
  pages={127782-127791},
  abstract={Classification models using deep or machine learning algorithms require a sufficient and balanced training dataset to improve performance. Still, they suffer from data collection due to data privacy issues. In medical research, where most data variables are sensitive information, collecting enough training data for model performance improvement is more challenging. This study presents a new medical data augmentation algorithm consisting of four steps to solve the data shortage and class imbalance issues. The main idea of the proposed algorithm is to reflect the core characteristic of the original data’s class label. The algorithm receives an original dataset as an input value to extract the feature vector and trains the individual autoencoder model. Then it verifies the augmented feature vector through a distributional equality check, and each feature vector is concatenated into one feature vector. The deep learning model inference is applied on a concatenated vector for the second verification, to finalize the augmented training dataset. Our team performed mood disorder classification using patient data to prove the presented data augmentation algorithm. With the method, the classification performance improved by 0.059 in the severity classification of major depressive disorder, 0.041 in the severity classification of anxiety disorder, and 0.073 in the subtype classification of bipolar disorder. Through this study, we proved that our algorithm can be applied to minimize model bias and improve classification performance on the medical data that are unbalanced or insufficient in number by class.},
  keywords={Data models;Mood;Medical diagnostic imaging;Data augmentation;Classification algorithms;Vectors;Training;Artificial neural networks;Emotion recognition;Multimodal sensors;Data augmentation;data synthesis;deep neural networks;mood disorder classification;multimodal analysis},
  doi={10.1109/ACCESS.2024.3396138},
  ISSN={2169-3536},
  month={},}@ARTICLE{9348911,
  author={Shahidi, Faezehsadat},
  journal={IEEE Access}, 
  title={Breast Cancer Histopathology Image Super-Resolution Using Wide-Attention GAN With Improved Wasserstein Gradient Penalty and Perceptual Loss}, 
  year={2021},
  volume={9},
  number={},
  pages={32795-32809},
  abstract={In the realm of image processing, enhancing the quality of the images is known as a superresolution problem (SR). Among SR methods, a super-resolution generative adversarial network, or SRGAN, has been introduced to generate SR images from low-resolution images. As it is of the utmost importance to keep the size and the shape of the images, while enlarging the medical images, we propose a novel super-resolution model with a generative adversarial network to generate SR images with finer details and higher quality to encourage less blurring. By widening residual blocks and using a self-attention layer, our model becomes robust and generalizable as it is able to extract the most important part of the images before up-sampling. We named our proposed model as wide-attention SRGAN (WA-SRGAN). Moreover, we have applied improved Wasserstein with a Gradient penalty to stabilize the model while training. To train our model, we have applied images from Camylon 16 database and enlarged them by 2×, 4×, 8×, and 16× upscale factors with the ground truth of the size of 256 × 256 × 3. Furthermore, two normalization methods, including batch normalization, and weight normalization have been applied and we observed that weight normalization is an enabling factor to improve metric performance in terms of SSIM. Moreover, several evaluation metrics, such as PSNR, MSE, SSIM, MS-SSIM, and QILV have been applied for having a comprehensive objective comparison with other methods, including SRGAN, A-SRGAN, and bicubial. Also, we performed the job of classification by using a deep learning model called ResNeXt-101 (32 × 8d) for super-resolution, high-resolution, and low-resolution images and compared the outcomes in terms of accuracy score. Finally, the results on breast cancer histopathology images show the superiority of our model by using weight normalization and a batch size of one in terms of restoration of the color and the texture details.},
  keywords={Generative adversarial networks;Histopathology;Superresolution;Biomedical imaging;Measurement;Training;Generators;SRGAN;Wasserstein gradient penalty;weight and batch normalization;perceptual loss;breast cancer histopathology medical images;classification},
  doi={10.1109/ACCESS.2021.3057497},
  ISSN={2169-3536},
  month={},}@ARTICLE{8825805,
  author={Xiong, Feng and Wang, Qianqian and Gao, Quanxue},
  journal={IEEE Access}, 
  title={Consistent Embedded GAN for Image-to-Image Translation}, 
  year={2019},
  volume={7},
  number={},
  pages={126651-126661},
  abstract={Generative Adversarial Networks (GANs) have achieved remarkable progress in image-to-image translation tasks. However, these methods have the common problem that lacking the ability to generate both perceptually realistic and diverse images in the target domain. To tackle the problem, in this paper, we propose a novel model named Consistent Embedded Generative Adversarial Networks (CEGAN) for the image-to-image translation task. It aims to learn conditional generation models for generating perceptually realistic outputs and capture the full distribution of potential multiple modes of results by enforcing tight connections in both the real image space and latent space. To achieve realism, unlike existing GANs models that their discriminators attempt to differentiate between real images from the dataset and fake samples produced by the generator, the discriminator in our model distinguishes the real images and fake images in the latent space to alleviate the impact of the redundancy and noise in generated images. On the other hand, we learn a low-dimensional latent code that is distilled from the possible multiple distribution in the latent space to achieve diversity. By this way, our model avoids the problem of mode collapse and produces more diverse and realistic results. Extensive experimental results demonstrate the superiority of the proposed method.},
  keywords={Generative adversarial networks;Generators;Gallium nitride;Task analysis;Training;Redundancy;Image synthesis;Image-to-image translation;GAN;latent space},
  doi={10.1109/ACCESS.2019.2939654},
  ISSN={2169-3536},
  month={},}@ARTICLE{10658971,
  author={Yenew, Azmeraw Bekele and Assefa, Beakal Gizachew and Belay, Elefelious Getachew},
  journal={IEEE Access}, 
  title={HouseGanDi: A Hybrid Approach to Strike a Balance of Sampling Time and Diversity in Floorplan Generation}, 
  year={2024},
  volume={12},
  number={},
  pages={125235-125252},
  abstract={Floorplan synthesis is the process of generating new, realistic floor plans for buildings and homes using machine learning and generative models. In recent years, various generative methods, including GANs and diffusion models, have been utilized for the task of floorplan generation, demonstrating promising advancements in architectural design and planning. However, despite their potential, these methods face unique challenges like mode collapse, training instability, and sampling time, which require innovative solutions to overcome for further progress in this field. To address these issues, various techniques such as regualrization techniques, architectural modifications, and optimization algorithms, have been employed. However, existing techniques still struggle to balance both sampling time and diversity simultaneously. In response, HouseGanDi proposes a novel hybrid approach that amalgamates GANs and diffusion models to address the dual challenges of diversity and sampling time in floorplan generation. To the best of our knowledge, this work is the first to introduce a solution that not only balances sampling time and diversity but also enhances the realism of the generated floorplans. HouseGanDi is trained on the RPLAN dataset and combines the advantages of GANs and diffusion models in multimodal fashion while incorporating different techniques such as regularization methods and architectural modifications to optimize our objectives. The multimodality allows our model to jump a number of denoising steps while capturing data distributions. To evaluate the effect of the denoising step, we experimented with different time steps and found better diversity results at T = 20. Evaluation of diversity using FID demonstrates an average 15.5% improvement over the state-of-the-art houseDiffusion model, with a 41% reduction in generation time. However, challenges persist in generating non-orthogonal floorplans and accommodating intricate spatial layouts.},
  keywords={Generative adversarial networks;Adaptation models;Noise measurement;Diffusion processes;Data models;Computational modeling;Transformers;Diffusion model;diversity;floorplan;GAN;sampling time},
  doi={10.1109/ACCESS.2024.3451406},
  ISSN={2169-3536},
  month={},}@ARTICLE{10909618,
  author={Saffari, Mohsen and Khodayar, Mahdi and Khodayar, Mohammad E. and Fazlhashemi, Seyed Saeed},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Deep Graph Convolutional Autoencoder With Conditional Normalizing Flow for Power Distribution Systems Fault Classification and Location}, 
  year={2025},
  volume={6},
  number={9},
  pages={2448-2463},
  abstract={Accurate fault classification and location are critical to ensure the reliability and resilience of large-scale power distribution systems (PDSs). The existing data-driven works in this area struggle to capture essential space-time correlations of PDS measurements and often rely on deterministic and shallow neural architectures. Furthermore, they encounter challenges such as over-smoothing and the inability to capture deep correlations. To overcome these limitations, a novel deep space-time generative graph convolutional autoencoder (SGGCA) is proposed. First, the PDS is modeled as a space-time graph where the nodes and edges show the bus measurements and line impedance values, respectively. The proposed SGGCA's encoder captures deep correlations of the space-time graph using a new graph convolution with early connections and identity transformations to mitigate the over-smoothing. Our encoder encompasses a new recurrent method to adjust graph convolution parameters without relying on node embeddings on the temporal dimension. Additionally, it incorporates generative modeling by capturing the probability distribution function of the latent representation through a conditional normalizing flow model. The extracted generative space-time features are enhanced by a multi-head attention mechanism to better capture task-relevant characteristics of the PDS measurements. The extracted features are fed to sparse decoders to classify and locate the faults in the PDS. The feature sparsity of decoders ensures a high generalization capacity and avoids overfitting. The proposed method is evaluated on the IEEE 69-bus and 123-bus systems. It achieves substantial improvements in fault classification accuracy by 3.33% and 6.26% and enhances fault location accuracy by 6.33% and 5.73% for the respective PDSs compared with state-of-the-art models.},
  keywords={Fault location;Feature extraction;Decoding;Convolutional neural networks;Convolution;Artificial intelligence;Accuracy;Transmission line measurements;Logic gates;Current measurement;Conditional normalizing flow (CNF);deep convolution network;deep spars architectures;fault classification;fault location},
  doi={10.1109/TAI.2025.3547878},
  ISSN={2691-4581},
  month={Sep.},}@ARTICLE{10258361,
  author={Cao, Zhongping and Zhang, Jianxiong and Chen, Rihui and Guo, Xuemei and Wang, Guoli},
  journal={IEEE Transactions on Aerospace and Electronic Systems}, 
  title={Task-Specific Feature Purifying in Radar-Based Human Pose Estimation}, 
  year={2023},
  volume={59},
  number={6},
  pages={9285-9298},
  abstract={Recently, radar-based human pose estimation has attracted increasing attention, which aims to reconstruct the human skeleton from the radar signals with the advanced deep neural networks. However, one fundamental challenge is the interferences from task-irrelevant ingredients due to the propagation characteristics of radar signals during feature learning. In this article, we present a two-stage framework for task-specific feature purifying to distill the feature representation with high discriminability specific to the pose estimation task but less interpersonal discrepancy, which is essential to handle the difficulties arising from the task-irrelevant interferences in reconstructing the human skeleton. The logic behind the proposed two-stage feature purifying architecture is that the discrepancy among individual personal data is first eliminated with an adversarial auto-encoder module to distill the interpersonal-independent features, and then the pose-irrelevant components are removed through a feature disentanglement module to form task-specific features for human pose estimations. The two-stage architecture turns out to be considerably effective for feature purifying against the interferences due to the task-irrelevant ingredients involved in the feature learning process. The experimental study is presented to illustrate the effectiveness of the proposed approach.},
  keywords={Task analysis;Radar;Feature extraction;Skeleton;Pose estimation;Representation learning;Soft sensors;3-D human pose estimation;adversarial learning;disentanglement representation learning;feature purification;millimeter wave radar;task-specific},
  doi={10.1109/TAES.2023.3317816},
  ISSN={1557-9603},
  month={Dec},}@ARTICLE{9810813,
  author={Liu, Jun and Zhang, Lei and Li, Chunlin and Bai, Jingpan and Lv, Haibin and Lv, Zhihan},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Blockchain-Based Secure Communication of Intelligent Transportation Digital Twins System}, 
  year={2022},
  volume={23},
  number={11},
  pages={22630-22640},
  abstract={The present work aims to improve the communication security of Internet of Vehicles (IoV) nodes in intelligent transportation through studying the safety of IoV in smart transportation based on Blockchain (BC). An IoV DTs model is built by combining big data with Digital Twins (DTs). Then, regarding the current IoV communication security issues, a secure communication architecture for the IoV system is proposed based on the immutable and trackable BC data. Besides, Wasserstein Distance Based Generative Adversarial Network (WaGAN) model constructs the IoV node risk forecast model. Because the WaGAN model calculates the loss function through Wasserstein distance, the learning rate of the model accelerates remarkably. After ten iterations, the loss rate of the WaGAN model is close to zero. Massive in-vehicle devices in IoV are connected simultaneously to the base station, causing network channel congestion. Therefore, a Group Authentication and Privacy-preserving (GAP) scheme is put forward. As users increase during authentication, the GAP scheme performs better than other authentication access schemes. In summary, the Intelligent Transportation System driven by DTs can promote intelligent transportation management. Besides, introducing BC into IoV can improve access control’s accuracy and response efficiency. The research reported here has significant value for improving the security of the information sharing of the IoV.},
  keywords={Security;Encryption;Data models;Computational modeling;6G mobile communication;Vehicles;Real-time systems;Internet of Vehicles;digital twins;blockchain;secure communication;intelligent transportation},
  doi={10.1109/TITS.2022.3183379},
  ISSN={1558-0016},
  month={Nov},}@ARTICLE{9234639,
  author={Zeng, Shaoning and Zhang, Bob and Gou, Jianping and Xu, Yong},
  journal={IEEE Transactions on Cybernetics}, 
  title={Regularization on Augmented Data to Diversify Sparse Representation for Robust Image Classification}, 
  year={2022},
  volume={52},
  number={6},
  pages={4935-4948},
  abstract={Image classification is a fundamental component in modern computer vision systems, where sparse representation-based classification has drawn a lot of attention due to its robustness. However, on the optimization of sparse learning systems, regularization and data augmentation are both powerful, but currently isolated. We believe that regularization and data augmentation can cooperate to generate a breakthrough in robust image classification. In this article, we propose a novel framework, regularization on augmented data (READ), which creates diversification in the data using the generic augmentation techniques to implement robust sparse representation-based image classification. When the training data are augmented, READ applies a distinct regularizer,  $l_{1}$  or  $l_{2}$ , in particular, on the augmented training data apart from the original data, so that regularization and data augmentation are utilized and enhanced synchronously. We introduce an elaborate theoretical analysis on how to optimize the sparse representation by both  $l_{1}$ -norm and  $l_{2}$ -norm with the generic data augmentation and demonstrate its performance in extensive experiments. The results obtained on several facial and object datasets show that READ outperforms many state-of-the-art methods when using deep features.},
  keywords={Training;Robustness;Optimization;Face recognition;Data models;Training data;Computer science;Data augmentation;diversification;image classification;regularization;sparse representation},
  doi={10.1109/TCYB.2020.3025757},
  ISSN={2168-2275},
  month={June},}@INPROCEEDINGS{10377529,
  author={Jeong, Yujin and Ryoo, Wonjeong and Lee, Seunghyun and Seo, Dabin and Byeon, Wonmin and Kim, Sangpil and Kim, Jinkyu},
  booktitle={2023 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={The Power of Sound (TPoS): Audio Reactive Video Generation with Stable Diffusion}, 
  year={2023},
  volume={},
  number={},
  pages={7788-7798},
  abstract={In recent years, video generation has become a prominent generative tool and has drawn significant attention. However, there is little consideration in audio-to-video generation, though audio contains unique qualities like temporal semantics and magnitude. Hence, we propose The Power of Sound (TPoS) model to incorporate audio input that includes both changeable temporal semantics and magnitude. To generate video frames, TPoS utilizes a latent stable diffusion model with textual semantic information, which is then guided by the sequential audio embedding from our pretrained Audio Encoder. As a result, this method produces audio reactive video contents. We demonstrate the effectiveness of TPoS across various tasks and compare its results with current state-of-the-art techniques in the field of audio-to-video generation. More examples are available at https://ku-vai.github.io/TPoS/},
  keywords={Computer vision;Computational modeling;Semantics;Benchmark testing;Task analysis},
  doi={10.1109/ICCV51070.2023.00719},
  ISSN={2380-7504},
  month={Oct},}@ARTICLE{10385050,
  author={Liu, Xuan and Xie, Yaoqin and Diao, Songhui and Tan, Shan and Liang, Xiaokun},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Unsupervised CT Metal Artifact Reduction by Plugging Diffusion Priors in Dual Domains}, 
  year={2024},
  volume={43},
  number={10},
  pages={3533-3545},
  abstract={During the process of computed tomography (CT), metallic implants often cause disruptive artifacts in the reconstructed images, impeding accurate diagnosis. Many supervised deep learning-based approaches have been proposed for metal artifact reduction (MAR). However, these methods heavily rely on training with paired simulated data, which are challenging to acquire. This limitation can lead to decreased performance when applying these methods in clinical practice. Existing unsupervised MAR methods, whether based on learning or not, typically work within a single domain, either in the image domain or the sinogram domain. In this paper, we propose an unsupervised MAR method based on the diffusion model, a generative model with a high capacity to represent data distributions. Specifically, we first train a diffusion model using CT images without metal artifacts. Subsequently, we iteratively introduce the diffusion priors in both the sinogram domain and image domain to restore the degraded portions caused by metal artifacts. Besides, we design temporally dynamic weight masks for the image-domian fusion. The dual-domain processing empowers our approach to outperform existing unsupervised MAR methods, including another MAR method based on diffusion model. The effectiveness has been qualitatively and quantitatively validated on synthetic datasets. Moreover, our method demonstrates superior visual results among both supervised and unsupervised methods on clinical datasets. Codes are available in github.com/DeepXuan/DuDoDp-MAR.},
  keywords={Computed tomography;Metals;Image reconstruction;Data models;Training;Implants;Convolutional neural networks;Computed tomography;metal artifact reduction;diffusion model;unsupervised learning},
  doi={10.1109/TMI.2024.3351201},
  ISSN={1558-254X},
  month={Oct},}@INPROCEEDINGS{10350913,
  author={Castillo, Angela and Escobar, Maria and Jeanneret, Guillaume and Pumarola, Albert and Arbeláez, Pablo and Thabet, Ali and Sanakoyeu, Artsiom},
  booktitle={2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)}, 
  title={BoDiffusion: Diffusing Sparse Observations for Full-Body Human Motion Synthesis}, 
  year={2023},
  volume={},
  number={},
  pages={4223-4233},
  abstract={Mixed reality applications require tracking the user’s full-body motion to enable an immersive experience. However, typical head-mounted devices can only track head and hand movements, leading to a limited reconstruction of full-body motion due to variability in lower body configurations. We propose BoDiffusion – a generative diffusion model for motion synthesis to tackle this under-constrained reconstruction problem. We present a time and space conditioning scheme that allows BoDiffusion to leverage sparse tracking inputs while generating smooth and realistic full-body motion sequences. To the best of our knowledge, this is the first approach that uses the reverse diffusion process to model full-body tracking as a conditional sequence generation task. We conduct experiments on the large-scale motion-capture dataset AMASS and show that our approach outperforms the state-of-the-art approaches by a significant margin in terms of full-body motion realism and joint reconstruction error.},
  keywords={Measurement;Head;Tracking;Image synthesis;Stochastic processes;Mixed reality;Diffusion processes;Pose Estimation;Diffusion Models;Motion Synthesis},
  doi={10.1109/ICCVW60793.2023.00456},
  ISSN={2473-9944},
  month={Oct},}@INPROCEEDINGS{8851993,
  author={Wu, Di and Chen, Junjun and Sharma, Nabin and Pan, Shirui and Long, Guodong and Blumenstein, Michael},
  booktitle={2019 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Adversarial Action Data Augmentation for Similar Gesture Action Recognition}, 
  year={2019},
  volume={},
  number={},
  pages={1-8},
  abstract={Human gestures are unique for recognizing and describing human actions, and video-based human action recognition techniques are effective solutions to varies real-world applications, such as surveillance, video indexing, and human-computer interaction. Most existing video human action recognition approaches either using handcraft features from the frames or deep learning models such as convolutional neural networks (CNN) and recurrent neural networks (RNN); however, they have mostly overlooked the similar gestures between different actions when processing the frames into the models. The classifiers suffer from similar features extracted from similar gestures, which are unable to classify the actions in the video streams. In this paper, we propose a novel framework with generative adversarial networks (GAN) to generate the data augmentation for similar gesture action recognition. The contribution of our work is tri-fold: 1) we proposed a novel action data augmentation framework (ADAF) to enlarge the differences between the actions with very similar gestures; 2) the framework can boost the classification performance either on similar gesture action pairs or the whole dataset; 3) experiments conducted on both KTH and UCF101 datasets show that our data augmentation framework boost the performance on both similar gestures actions as well as the whole dataset compared with baseline methods such as 2DCNN and 3DCNN.},
  keywords={Feature extraction;Streaming media;Correlation;Kernel;Deep learning;Recurrent neural networks;Similar gestures;Action recognition;Neural Networks;Deep learning},
  doi={10.1109/IJCNN.2019.8851993},
  ISSN={2161-4407},
  month={July},}@ARTICLE{10418170,
  author={Li, Siyang and Xiong, Hui and Chen, Yize},
  journal={IEEE Transactions on Smart Grid}, 
  title={DiffCharge: Generating EV Charging Scenarios via a Denoising Diffusion Model}, 
  year={2024},
  volume={15},
  number={4},
  pages={3936-3949},
  abstract={Recent proliferation of electric vehicle (EV) charging load has imposed vital stress on power grid. The stochasticity and volatility of EV charging behaviors render it challenging to manipulate the uncertain charging demand for grid operations and charging management. Charging scenario generation can serve for future EV integration by modeling charging load uncertainties and simulating various realistic charging sessions. To this end, we propose a denoising Diffusion-based Charging scenario generation model coined DiffCharge, which is capable of yielding both battery-level and station-level EV charging time-series data with distinct temporal properties. In principle, the devised model can progressively convert the simply known Gaussian noise to genuine charging demand profiles by learning a parameterized reversal of the forward diffusion process. Besides, we leverage the multi-head self-attention mechanism and prior conditions to capture the unique temporal correlations associated with battery or charging station types in actual charging dynamics. Moreover, we validate the superior generative capacity of DiffCharge on a real-world dataset involving ample charging session records, and attest the efficacy of produced charging scenarios on a practical EV operation problem in the day-ahead electricity market.},
  keywords={Electric vehicle charging;Batteries;Load modeling;Scenario generation;Renewable energy sources;Uncertainty;Noise reduction;EV charging;scenario generation;diffusion model;machine learning},
  doi={10.1109/TSG.2024.3360874},
  ISSN={1949-3061},
  month={July},}@ARTICLE{9354038,
  author={Zhang, Rui and Zhang, Hongyuan and Li, Xuelong},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Maximum Joint Probability With Multiple Representations for Clustering}, 
  year={2022},
  volume={33},
  number={9},
  pages={4300-4310},
  abstract={Classical generative models in unsupervised learning intend to maximize  $p(X)$ . In practice, samples may have multiple representations caused by various transformations, measurements, and so on. Therefore, it is crucial to integrate information from different representations, and lots of models have been developed. However, most of them fail to incorporate the prior information about data distribution  $p(X)$  to distinguish representations. In this article, we propose a novel clustering framework that attempts to maximize the joint probability of data and parameters. Under this framework, the prior distribution can be employed to measure the rationality of diverse representations.  $K$ -means is a special case of the proposed framework. Meanwhile, a specific clustering model considering both multiple kernels and multiple views is derived to verify the validity of the designed framework and model.},
  keywords={Kernel;Unsupervised learning;Data models;Clustering algorithms;Task analysis;Feature extraction;Computational modeling;Clustering;maximum joint probability;multikernel learning;multiview learning;unsupervised learning},
  doi={10.1109/TNNLS.2021.3056420},
  ISSN={2162-2388},
  month={Sep.},}@INPROCEEDINGS{6907015,
  author={Rosen, David M. and Huang, Guoquan and Leonard, John J.},
  booktitle={2014 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Inference over heterogeneous finite-/infinite-dimensional systems using factor graphs and Gaussian processes}, 
  year={2014},
  volume={},
  number={},
  pages={1261-1268},
  abstract={The ability to reason over partially observable networks of interacting states is a fundamental competency in probabilistic robotics. While the well-known factor graph and Gaussian process models provide flexible and computationally efficient solutions for this inference problem in the special cases in which all of the hidden states are either finite-dimensional parameters or real-valued functions, respectively, in many cases we are interested in reasoning about heterogeneous networks whose hidden states are comprised of both finite-dimensional parameters and functions. To that end, in this paper we propose a novel probabilistic generative model that incorporates both factor graphs and Gaussian processes to model these heterogeneous systems. Our model improves upon prior approaches to inference within these networks by removing the assumption of any specific set of conditional independences amongst the modeled states, thereby significantly expanding the class of systems that can be represented. Furthermore, we show that inference within this model can always be performed by means of a two-stage procedure involving inference within a factor graph followed by inference over a Gaussian process; by exploiting fast inference methods for the individual factor graph and Gaussian process models to solve each of these subproblems in succession, we thus obtain a general framework for computationally efficient inference over heterogeneous finite-/infinite-dimensional systems.},
  keywords={Gaussian processes;Hidden Markov models;Kernel;Computational modeling;Joints;Mathematical model;Robots},
  doi={10.1109/ICRA.2014.6907015},
  ISSN={1050-4729},
  month={May},}@INPROCEEDINGS{10580553,
  author={Cheng, Yunkun and Zhang, Xiankun and Liu, Fufeng and Zhao, Danyang and Luo, Xin},
  booktitle={2024 27th International Conference on Computer Supported Cooperative Work in Design (CSCWD)}, 
  title={PromoterDiff: De Novo Design Approach for Escherichia coli Promoters Based on a Diffusion Model}, 
  year={2024},
  volume={},
  number={},
  pages={2381-2387},
  abstract={Promoter components play a critical role in the regulation of gene expression, directly determining the expression intensity of downstream target genes. Opting for high-quality promoters is essential for synthetic biology. In the existing literature, the method of designing high-quality promoters using Generative Adversarial Networks (GANs) is constrained by training difficulties, mode collapse, implicit generation, and information loss in deep networks after vector representation of promoters. Diffusion models are more easily trainable, possess elegant mathematical explanations, and can directly model the target distribution, potentially overcoming the issues faced by GANs mentioned above. In this paper, we propose a new method for promoter design, PromoterDiff, based on the diffusion model. Specifically, we adjusted the convolutional network structure of the diffusion model and introduced a bridging structure to adapt to the diffusion and reconstruction steps of the diffusion model when dealing with DNA sequence tensors containing a large number of zero elements. We used natural promoters of Escherichia coli as the training set to train the model, resulting in the successful design of 14,080 entirely new promoters. Through the analysis of the motifs, k-mer frequencies, and motif spacing constraints of these promoters, we confirmed that the diffusion model can capture the characteristics of natural promoters, and the quality of the generated promoters surpasses existing models. Through biological experiments, it has been confirmed that 83% of the promoter sequences designed by PromoterDiff surpass the activity of natural promoters, exceeding the current leading model by 13%. This underscores the immense potential of applying the diffusion model to de novo promoter design. This paper also provides a clear mathematical representation of the de novo promoter design task. According to our survey, this is the first time the diffusion model has been applied in the field of de novo promoter design.},
  keywords={Training;Biological system modeling;Design methodology;Computational modeling;DNA;Escherichia coli;Diffusion models;promoter;synthetic biology;diffusion model;de novo design},
  doi={10.1109/CSCWD61410.2024.10580553},
  ISSN={2768-1904},
  month={May},}@ARTICLE{11096051,
  author={Maddileti, Nakka Saampotth and Namburi, Rupesh and Raj, Rayappa David Amar and Yanamala, Rama Muni Reddy and Pallakonda, Archana},
  journal={IEEE Transactions on Device and Materials Reliability}, 
  title={DCGAN-Driven Minority Class Augmentation for Lightweight YOLO-Based Photovoltaic Defect Localization Suitable for Edge Deployment}, 
  year={2025},
  volume={25},
  number={3},
  pages={742-751},
  abstract={This study presents YOLOv11n-GhostLite, an innovative lightweight deep learning architecture optimized for real-time localization of photovoltaic (PV) faults in electroluminescence (EL) images, specifically designed for edge deployment. A Deep Convolutional Generative Adversarial Network (DCGAN)-based synthetic augmentation pipeline is presented to address the issues of class imbalance and limited resource availability, generating high-fidelity, class-conditional EL images that include realistic banding artifacts. This method enhances the representation of minority defect categories by more than 150%, elevating the mean Average Precision (mAP@50) by 4% and decreasing false negatives by 5%. The proposed model incorporates GhostConv for efficient early feature extraction, C3k2 residual blocks for deep representation learning, GhostSPPF for multi-scale context aggregation, C2PSA attention for adaptive feature refinement, and an anchor-free detection head, achieving high performance with only 2.34 million parameters and 6.2 GFLOPs. Detailed experiments on two benchmark datasets PVEL-AD and PV Multi-Defect exhibit the model’s efficacy, attaining 97.2% mAP@50 on PVEL-AD, and 96.4% mAP@50 on PV Multi-Defect, outperforming larger models in both accuracy and speed. The model is further deployed on a Google Coral Edge TPU, demonstrating its real-time functionality with minimal power consumption (~2W) and suitable latency for drone-based solar inspections. YOLOv11n-GhostLite’s integration of efficient architecture and data-driven augmentation renders it an effective solution for scalable, real-time photovoltaic fault detection in resource-limited settings.},
  keywords={Training;Accuracy;Real-time systems;Photovoltaic systems;Data models;Tuning;Image edge detection;Generators;Feature extraction;Computational modeling;Fault detection;YOLO;real-time object detection;DCGAN augmentation;lightweight deep learning},
  doi={10.1109/TDMR.2025.3592416},
  ISSN={1558-2574},
  month={Sep.},}@ARTICLE{11162525,
  author={Abd-hood, Samia F. and Omar, Nazlia and Tiun, Sabrina},
  journal={IEEE Access}, 
  title={A Novel Data Augmentation Framework for Arabic Multi-label Text Classification using AraBART, AraGPT2, and Borderline-SMOTE}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Data Augmentation (DA) techniques present solutions for Natural Language Processing (NLP) to address class imbalance and data scarcity. The current solutions for class imbalance, either random oversampling or random under-sampling techniques, suffer from several issues. For instance, oversampling leads to overfitting due to replication, whilst under-sampling leads to loss of information due to removals. Meanwhile, traditional DA techniques, including paraphrasing, rule-based, or noising approaches, require strong lexicons. These techniques are also either time-consuming or introduce noise, resulting in incorrect syntactical and semantic contexts. Hence, this paper aims to propose a novel DA framework for Arabic news articles to address the prevailing challenges in Arabic Multi-Label Text Classification (AMLTC). The proposed framework consists of three phases: abstractive summarization using the Arabic Bidirectional and Auto-Regressive Transformer (AraBART) model to introduce new features, data generation with Arabic Generative Pre-trained Transformer (AraGPT2) to create diverse and contextual texts, and data balancing using borderline Synthetic Minority Over-Sampling Technique (SMOTE) to achieve an optimal balance. Each phase was evaluated to ensure the quality of the augmented data. Furthermore, a Bidirectional Long Short-Term Memory (BiLSTM) model was conducted to assess the performance of the augmented dataset (augDS) on a multi-label Arabic RTN news dataset. The results demonstrated that the proposed framework effectively addressed the class imbalance problem by preserving data integrity and significantly improving Multi-Label Text Classification (MLTC) performance compared to the non-augDS. Specifically, the F1-score increased from 0.54% on the original dataset to 0.90% after augmentation. Overall, this study demonstrates that the proposed framework successfully addresses the issues in Arabic datasets by generating diverse, novel augmented data. Additionally, it enhanced MLTC performance, showcasing its effectiveness.},
  keywords={Text categorization;Semantics;Data augmentation;Vectors;Context modeling;Filtration;Diversity reception;Data collection;Bidirectional long short term memory;Translation;AraBART;AraGPT2;class imbalance;data augmentation;multi-label text classification;abstractive summarization},
  doi={10.1109/ACCESS.2025.3609462},
  ISSN={2169-3536},
  month={},}@ARTICLE{11152350,
  author={Xu, Chong-Xuan and Xiao, Jiang-Wen and Wang, Yan-Wu},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={A Nonparametric Balanced Diffusion Based Fault Diagnosis Scheme for Electric Vehicle DC Charging Piles Under Imbalanced Samples}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={The imbalance between faulty and healthy samples of electric vehicle (EV) charging piles makes it difficult for both algorithm-level and data-level diagnostic methods to identify fault categories with limited data. In this article, a fault diagnosis scheme for EV DC charging piles based on a nonparametric balanced diffusion (BalDiff) model under imbalanced samples is proposed by the data-level method. First, the nonparametric BalDiff model is proposed to augment the imbalanced samples. Unlike existing generative data augmentation methods, it does not require the assumption of a specific data distribution. In addition, BalDiff uses attenuated noise instead of the constant noise intensity during the reverse process of the diffusion model to enhance the ability to capture the sample distribution. Second, an online fault diagnosis strategy applicable to different data sources is designed, which guarantees the diagnosis time while ensuring the diagnosis accuracy. Case studies on different data sources show that the proposed scheme achieves at least 4.2% and 6.7% improvement in F1-score and accuracy compared to the comparison methods, and the single diagnosis time is only 0.021 s.},
  keywords={Fault diagnosis;Diffusion models;Noise;Attenuation;Training;Standards;Data models;Convergence;Soft sensors;Signal processing algorithms;Diffusion model;electric vehicle DC charging piles;fault diagnosis;imbalanced sample;sample augmentation},
  doi={10.1109/TII.2025.3598491},
  ISSN={1941-0050},
  month={},}@INPROCEEDINGS{10888772,
  author={Yun, Jun-Hak and Kim, Seung-Bin and Lee, Seong-Whan},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={FLowHigh: Towards Efficient and High-Quality Audio Super-Resolution with Single-Step Flow Matching}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Audio super-resolution is challenging owing to its ill-posed nature. Recently, the application of diffusion models in audio super-resolution has shown promising results in alleviating this challenge. However, diffusion-based models have limitations, primarily the necessity for numerous sampling steps, which causes significantly increased latency when synthesizing high-quality audio samples. In this paper, we propose FLowHigh, a novel approach that integrates flow matching, a highly efficient generative model, into audio super-resolution. We also explore probability paths specially tailored for audio super-resolution, which effectively capture high-resolution audio distributions, thereby enhancing reconstruction quality. The proposed method generates high-fidelity, high-resolution audio through a single-step sampling process across various input sampling rates. The experimental results on the VCTK benchmark dataset demonstrate that FLowHigh achieves state-of-the-art performance in audio super-resolution, as evaluated by log-spectral distance and ViSQOL while maintaining computational efficiency with only a single-step sampling process.},
  keywords={Computational modeling;Superresolution;Benchmark testing;Diffusion models;Data models;Acoustics;Computational efficiency;Speech processing;Signal resolution;audio super-resolution;bandwidth extension;conditional flow matching;diffusion models;single-step},
  doi={10.1109/ICASSP49660.2025.10888772},
  ISSN={2379-190X},
  month={April},}@ARTICLE{11048957,
  author={Jin, Cong and Lin, Meixiu and Wu, Fengjuan and Wu, Xiaoyu and Zhou, Yu and Wang, Jiacun},
  journal={IEEE Transactions on Systems, Man, and Cybernetics: Systems}, 
  title={TVMTrailer: A Text-Video-Music AIGC Framework for Film Trailer Generation}, 
  year={2025},
  volume={55},
  number={9},
  pages={6000-6010},
  abstract={In the ever-evolving landscape of media and entertainment, where trends like short-form video content and new media platforms reign supreme, the need for innovative approaches across various industries becomes increasingly apparent. One such industry deeply impacted by these shifts is the film industry, where the creation and dissemination of film trailers stand as pivotal promotional strategies. Making a film trailer by hand is time consuming. However, the emerging artificial intelligence generated content (AIGC) technique has shown significant potential to enhance the efficiency. This article presents a novel model named TVMTrailer, which consists of a text-video generation network (TVGNet) and a video-music generation network (VMGNet). TVGNet employs an encoder-decoder framework, utilizing movie footage and synopses to generate movie trailers. Besides, VMGNet is proposed to generate sound track of our trailer. It combines video and audio features, and uses a transformer model for associative learning to adaptively generate audio clips with features, such as emotion, rhythm and beat. The effectiveness of TVMTrailer is demonstrated through experiment conducted on the proposed dataset and a comprehensive collection of over two thousand video-audio pairs from classic movies.},
  keywords={Motion pictures;Visualization;Transformers;Diversity reception;Deep learning;Rhythm;Media;Hands;Feature extraction;Encoding;Artificial intelligence generated content (AIGC);film trailer;text-to-video generation;video-to-music generation},
  doi={10.1109/TSMC.2025.3576988},
  ISSN={2168-2232},
  month={Sep.},}@ARTICLE{11133680,
  author={Li, Zengyi and Gao, Junyu and Yuan, Yuan},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Dual-Stage Prior-Driven Diffusion Model for Remote Sensing Spectral Super-Resolution}, 
  year={2025},
  volume={63},
  number={},
  pages={1-14},
  abstract={Spectral super-resolution (SSR) is a key technology for generating high-spatial-resolution hyperspectral images (HSIs). However, deep learning approaches for SSR, especially generative models like diffusion, often rely heavily on large training datasets. Furthermore, their stochastic generation process can compromise the precise spectral fidelity required in remote sensing. To address this limitation, we propose a dual-stage prior-driven diffusion model (DPDM) for SSR tasks. The DPDM comprises two modules: the prior-driven diffusion module (PDM) and the spectral refinement module (SRM). The PDM replaces the conventional pure noise input with a structured prior, which we term the prior-informed noise (PIN). This PIN is deterministically generated by projecting the input multispectral image (MSI) onto a spectral basis, which is extracted from the spectral response function (SRF). By initializing the reverse process with this information-rich starting point, our model significantly reduces its dependence on large training datasets and inherently enforces spectral consistency. The SRM is subsequently introduced to specifically target and correct residual artifacts and coarse features from the initial stage. Employing a hierarchical multiscale architecture and a single-sample optimization framework, the SRM meticulously restores fine-grained details while suppressing noise in the PDM’s output. By integrating these two modules, the DPDM progressively enhances both spatial and spectral fidelity. Extensive experimental results demonstrate that the DPDM achieves competitive performance in SSR tasks.},
  keywords={Noise;Diffusion models;Superresolution;Training;Optimization;Image reconstruction;Dictionaries;Feature extraction;Spatial resolution;Diffusion processes;Data generation;diffusion model;dual-stage network;hyperspectral image;spectral super-resolution (SSR)},
  doi={10.1109/TGRS.2025.3601119},
  ISSN={1558-0644},
  month={},}@ARTICLE{10898075,
  author={Zhu, Shiyu and Wu, Zhan and Zhang, Zhizhou and Shu, Huazhong and Xie, Shipeng and Coatrieux, Jean-Louis and Chen, Yang},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Planning CT Guided Limited-Angle CBCT to CT Synthesis via Content-Style Decoupled Learning}, 
  year={2025},
  volume={74},
  number={},
  pages={1-14},
  abstract={Cone-beam computed tomography (CBCT) images are usually applied to clinical tasks such as image-guided radiation therapy due to the capability of providing accurate anatomical structures of patients. CBCT data obtained by full-angle scan takes a long scanning time and has a relatively high radiation dose, which may increase the health risks and discomfort of patients. Limited-angle CBCT (LA-CBCT) can effectively decrease scanning time and radiation dose by reducing the scanning angle range. On the other hand, it suffers from serious wedge artifacts, loss of image details, and low Hounsfield unit (HU) accuracy. Hence it is worthwhile to investigate the generation of high-quality CT-like images from LA-CBCT. However, due to neglect of the recovering of missing anatomical content caused by the limited-angle scan, traditional DL-based methods fail to generate high-quality synthetic CT from LA-CBCT directly. To solve this problem, we make full use of the bidirectional mapping between CBCT and CT domain and decouple LA-CBCT to CT synthesis into image style (context, HU) learning stage and image content (anatomical structure) learning stage. To accurately correct the image texture and intensity, an edge-enhanced generative adversarial network (EEGAN) is proposed to learn the bidirectional mapping relationship between CBCT and CT images. To recover the missing content caused by the limited-angle scan, a prior-guided content supplement network (PGCS-Net) is proposed to eliminate the limited-angle artifacts and supplement the missing anatomic structure. Results on real clinical chest and head datasets indicate that synthetic CT generated with our method can effectively improve image quality and registration quality of LA-CBCT, and has great potential in some image-guided radiotherapy tasks such as patient setup error obtaining.},
  keywords={Computed tomography;Training;Planning;Deep learning;Translation;Reconstruction algorithms;Radiation therapy;Image edge detection;Accuracy;Image quality;Content-style decouple;image-guided radiotherapy;limited-angle cone-beam computed tomography (LA-CBCT);synthetic CT;unsupervised deep learning},
  doi={10.1109/TIM.2025.3544370},
  ISSN={1557-9662},
  month={},}@ARTICLE{11018203,
  author={Wang, Shuai and Ding, Liang and Zhan, Yibing and Luo, Yong and Liu, Shuai and Ding, Weiping},
  journal={IEEE Transactions on Fuzzy Systems}, 
  title={Fuzzy-Assisted Contrastive Decoding Improving Code Generation of Large Language Models}, 
  year={2025},
  volume={33},
  number={8},
  pages={2689-2703},
  abstract={Large language models (LLMs) play a crucial role in intelligent code generation tasks. Most existing work focuses on pretraining or fine-tuning specialized code LLMs, e.g., CodeLlama. However, pretraining or fine-tuning a code LLM requires a vast corpus of data, significant computational resources, and considerable human effort. Compared to pretraining or fine-tuning LLMs, a simple and flexible method of contrastive decoding has garnered widespread attention to improve the text generation quality of LLMs. While contrastive decoding can indeed improve the text generation quality of LLMs, our research has found that directly using contrastive decoding: 1) introduces erroneous information into the logit distribution generated from normal prompts (i.e., user’s input), particularly in the code generation of LLMs; 2) significantly impedes the inference and decoding time of LLMs. In this work, the limitations of using contrastive decoding directly are systematically highlighted, and a novel real-time fuzzy-assisted contrastive decoding (FCD) mechanism is proposed to improve the code generation quality of LLMs. The proposed FCD mechanism initially categorizes prompts into high-quality and low-quality groups based on the results of the evaluator (i.e., unit test) before integrating the LLM. Next, feature values (e.g., standard deviation, peak value, etc.) related to the logit distribution of predicted tokens during the LLM’s inference process for both high-quality and low-quality prompts are extracted. Finally, the extracted feature values are used to train the fuzzy neural network (i.e, fuzzy min–max neural network) offline, allowing for the prejudgement of the reliability of the logit distribution for normal prompt outputs. This prevents the direct use of erroneous information from contrastive decoding and improves the code generation quality of LLMs. Through extensive experiments, it has been demonstrated that the proposed FCD mechanism can significantly improve the code generation quality of LLMs through FCD. Moreover, the FCD mechanism can also reduce the time required for inference and contrastive decoding.},
  keywords={Decoding;Codes;Computational modeling;Solid modeling;Training;Feature extraction;Software development management;Predictive models;Data models;Standards;Contrastive decoding;generative artificial intelligence;large language models (LLMs);normal prompts},
  doi={10.1109/TFUZZ.2025.3575060},
  ISSN={1941-0034},
  month={Aug},}@INPROCEEDINGS{11095150,
  author={Zhang, Lintong and Yin, Kang and Lee, Seong-Whan},
  booktitle={2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Towards Fine-Grained Interpretability: Counterfactual Explanations for Misclassification with Saliency Partition}, 
  year={2025},
  volume={},
  number={},
  pages={30053-30062},
  abstract={Attribution-based explanation techniques capture key patterns to enhance visual interpretability; however, these patterns often lack the granularity needed for insight in fine-grained tasks, particularly in cases of model misclassification, where explanations may be insufficiently detailed. To address this limitation, we propose a fine-grained counterfactual explanation framework that generates both object-level and part-level interpretability, addressing two fundamental questions: (1) which fine-grained features contribute to model misclassification, and (2) where dominant local features influence counterfactual adjustments. Our approach yields explainable counterfactuals in a non-generative manner by quantifying similarity and weighting component contributions within regions of interest between correctly classified and misclassified samples. Furthermore, we introduce a saliency partition module grounded in Shapley value contributions, isolating features with region-specific relevance. Extensive experiments demonstrate the superiority of our approach in capturing more granular, intuitively meaningful regions, surpassing fine-grained methods.},
  keywords={Visualization;Computer vision;Adaptation models;Computational modeling;Semantics;Computer architecture;Predictive models;Transformers;Pattern recognition;Iterative methods;model misclassification;attribution-based explanation;fine-grained feature;counterfactual explanation},
  doi={10.1109/CVPR52734.2025.02797},
  ISSN={2575-7075},
  month={June},}@ARTICLE{10172151,
  author={Du, Hongyang and Zhang, Ruichen and Niyato, Dusit and Kang, Jiawen and Xiong, Zehui and Kim, Dong In and Shen, Xuemin and Poor, H. Vincent},
  journal={IEEE Network}, 
  title={Exploring Collaborative Distributed Diffusion-Based AI-Generated Content (AIGC) in Wireless Networks}, 
  year={2024},
  volume={38},
  number={3},
  pages={178-186},
  abstract={Driven by advances in generative artificial intelligence (AI) techniques and algorithms, the widespread adoption of AI-generated content (AIGC) has emerged, allowing for the generation of diverse and high-quality content. Especially, the diffusion model-based AIGC technique has been widely used to generate content in a variety of modalities. However, the real-world implementation of AIGC models, particularly on resource-constrained devices such as mobile phones, introduces significant challenges related to energy consumption and privacy concerns. To further promote the realization of ubiquitous AIGC services, we propose a novel collaborative distributed diffusion-based AIGC framework. By capitalizing on collaboration among devices in wireless networks, the proposed framework facilitates the efficient execution of AIGC tasks, optimizing edge computation resource utilization. Furthermore, we examine the practical implementation of the denoising steps on mobile phones, the impact of the proposed approach on the wireless network-aided AIGC landscape, and the future opportunities associated with its real-world integration. The contributions of this paper not only offer a promising solution to the existing limitations of AIGC services but also pave the way for future research in device collaboration, resource optimization, and the seamless delivery of AIGC services across various devices. Our code is available at https://github.com/HongyangDu/DistributedDiffusion},
  keywords={Computational modeling;Collaboration;Noise reduction;Data models;Artificial intelligence;Tensors;Content management},
  doi={10.1109/MNET.006.2300223},
  ISSN={1558-156X},
  month={May},}@ARTICLE{10745245,
  author={Kalor, Anders E. and Durisi, Giuseppe and Coleri, Sinem and Parkvall, Stefan and Yu, Wei and Mueller, Andreas and Popovski, Petar},
  journal={Proceedings of the IEEE}, 
  title={Wireless 6G Connectivity for Massive Number of Devices and Critical Services}, 
  year={2024},
  volume={},
  number={},
  pages={1-23},
  abstract={Compared to the generations up to 4G, whose main focus was on broadband and coverage aspects, 5G has expanded the scope of wireless cellular systems toward embracing two new types of connectivity: massive machine-type communications (mMTCs) and ultrareliable low-latency communications (URLLCs). This article discusses the possible evolution of these two types of connectivity within the umbrella of 6G wireless systems. This article consists of three parts. The first part deals with the connectivity for a massive number of devices. While mMTC research in 5G predominantly focuses on the problem of uncoordinated access in the uplink for a large number of devices, the traffic patterns in 6G may become more symmetric, leading to closed-loop massive connectivity. One of the drivers for this type of traffic pattern is distributed/decentralized learning and inference. The second part of this article discusses the evolution of wireless connectivity for critical services. While latency and reliability are tightly coupled in 5G, 6G will support a variety of safety-critical control applications with different types of timing requirements, as evidenced by the emergence of metrics related to information freshness and information value. In addition, ensuring ultrahigh reliability for safety-critical control applications requires modeling and estimation of the tail statistics of the wireless channel, queue length, and delay. The fulfillment of these stringent requirements calls for the development of novel artificial intelligence (AI)-based techniques, incorporating optimization theory, explainable AI (XAI), generative AI, and digital twins (DTs). The third part analyzes the coexistence of massive connectivity and critical services. Specifically, we consider scenarios in which a massive number of devices need to support traffic patterns of mixed criticality. This is followed by a discussion about the management of wireless resources shared by services with different criticality.},
  keywords={6G mobile communication;5G mobile communication;Wireless communication;Internet of Things;Ultra reliable low latency communication;Reliability;Wireless sensor networks;Sensors;Artificial intelligence;Traffic control;6G;Internet of Things (IoT);machine-type communications (MTCs);massive access;massive connectivity;ultrareliable low-latency communications (URLLC);wireless networks},
  doi={10.1109/JPROC.2024.3484529},
  ISSN={1558-2256},
  month={},}@ARTICLE{10803939,
  author={Tzanakaki, Anna and Anastasopoulos, Markos and Alevizaki, Victoria-Maria},
  journal={Journal of Optical Communications and Networking}, 
  title={Intent-based control and management framework for optical transport networks supporting B5G services empowered by large language models [Invited]}, 
  year={2025},
  volume={17},
  number={1},
  pages={A112-A123},
  abstract={This study focuses on the development of an intent-based networking (IBN) control and management framework automating operations of beyond 5G (B5G) infrastructures supported by optical transport networks to interconnect radio access and core networks. Currently, these infrastructures operate in accordance with the software defined networking (SDN) and network function virtualization (NFV) paradigm, relying on complex northbound and southbound interfaces to expose their (network) capabilities and apply suitable configuration policies to B5G infrastructure. B5G infrastructures are expected to operate over complex heterogeneous transport network and compute domains, each having its own programming language and interfaces. To address the increased complexity of this approach, the present study relies on generative artificial intelligence (GenAI) and large language models (LLMs) to significantly simplify the interaction between different layers and domains through automated translation of configuration policies from one domain to another. More specifically, the developed GenAI models are used to support automated operations of B5G infrastructures by 1) translating high-level intents provided by network operators expressed in the form of natural language into autogenerated optimization code used by the orchestrator and 2) creating autoconfiguration policies for the optical transport network. The semantic accuracy and complexity of the proposed framework to generate appropriate configuration policies are experimentally tested over an optical transport network interconnecting the radio access and core networks of a B5G infrastructure.},
  keywords={Business;Optical fiber networks;Artificial intelligence;Complexity theory;Optimization;Transformers;Protocols;Optical interconnections;Integrated optics;Codes},
  doi={10.1364/JOCN.534909},
  ISSN={1943-0639},
  month={January},}@INPROCEEDINGS{10893146,
  author={Gopi, Sreekanth and Sreekanth, Devananda and Dehbozorgi, Nasrin},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Enhancing Engineering Education Through LLM-Driven Adaptive Quiz Generation: A RAG-Based Approach}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This research-to-practice study aims to develop an Artificial Intelligence (AI) MCQ generation system for engineering students, with a focus on adaptive learning, educational technology, and innovative assessment tools, to enhance personalized learning. Engineering education faces significant academic performance challenges, with first-year retention rates in STEM fields ranging between 27% to 46%, largely due to poor academic achievements. Multiple Choice Questions (MCQs) identify misconceptions, reinforce knowledge retention, and offer efficient assessment methods for engineering education. This interactive method improves attention and memory retention, reinforces knowledge, and improves comprehension. In this context, the emergence of Large Language Models (LLMs) such as GPT-4 has marked a significant advancement. Our literature review method employed a systematic approach, analyzing peer-reviewed articles, conference papers, and authoritative reports to uncover the trends and challenges in AI-driven quiz generation. The notable gap identified in our literature review is the lack of LLM-based adaptive quiz generation methods specifically for engineering education. Our methodology involved sourcing relevant structured datasets, data pre-processing, embedding generation, vector database storage, hybrid-search retrieval, LLM query results feed, prompt engineering, and context-based response. In this research, we adopted Vectara as a vector database tool for its automatic data ingestion capabilities and seamless integration with generative AI applications. Prompt engineering involves a dual-prompt approach, where the Contextual Question Prompt formulates questions based on user topics and chat history, while the Answer Question Prompt manages MCQ responses with explanations, ensuring relevant and contextually accurate interactions. Evaluation includes topic relevancy, answer relevancy, and a contextual relevancy score. Preliminary results indicate promising results for the generation of accurate and contextually appropriate questions with minimal hallucinations. The quiz generation system was deployed using Streamlit cloud-based architecture to showcase the functionality. Looking forward, we aim to expand the dataset to include more diverse engineering disciplines and to refine the retrieval algorithms to better handle complex diagrams and mathematical expressions commonly found in engineering texts.},
  keywords={Accuracy;Systematics;Databases;Learning (artificial intelligence);Market research;Vectors;Mathematical models;Prompt engineering;Systematic literature review;STEM;AI quiz generation;engineering education;personalized learning;Large Language Models;GPT-4;RAG;Vec-tara;prompt engineering;LLM evaluation},
  doi={10.1109/FIE61694.2024.10893146},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{9185658,
  author={Brown, Joseph Alexander and Aslam, Hamna and Miklashevskaya, Daria and Lozhnikov, Nikita},
  booktitle={2020 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Pedagogical Evolved Art: An Examination and Results of the Innopolis Al Art Contest}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={Evolutionary Algorithms (EA) capacitate a myriad of possibilities and creativity. Therefore, while teaching evolutionary programming to students of Computer Science, we decided to equip them with the technical details and then let them explore the creative aspects themselves. As part of the introductory course on Artificial Intelligence, an evolutionary generation of art is an assignment The teaching goals were to inform students of creative aspects of EA as well as invoke critical thinking and analysis in them. The students generated images via EA, and the only restriction was on the pixel size for input. The assignment was well-received, despite its complexity. Students engaged with the art generation and felt confident in expressing their perspectives of creativity and art The assignment evaluation as a contest allowed for judges from diverse domains such as Computer scientists and artists. The goals of the course are met as the students were trained not only in technical details but also realized the capacity and generative power of algorithms, as they practically simulated and expressed their creative thoughts via this contest Furthermore, the students engaged with the philosophical foundations of computational creativity effectively by the design process, and a report completed along with the work required them to develop their own artistic exegesis of the algorithm.},
  keywords={Art;Education;Evolutionary computation;Learning (artificial intelligence);Programming;Mathematics;Creativity;Art;Contest;Genetic Algorithms;Education},
  doi={10.1109/CEC48606.2020.9185658},
  ISSN={},
  month={July},}@INPROCEEDINGS{10798141,
  author={Rastogi, Ashish and Ashraf Ali Hassan Al Lawati, Al Ghadir},
  booktitle={2024 1st International Conference on Innovative Engineering Sciences and Technological Research (ICIESTR)}, 
  title={Understanding the acceptance of ChatGPT by HEI’s students for knowledge enhancement}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={The adoption of Artificial Intelligence (AI) in education has accelerated as a result of technological advancement. The use of conversational agents, like ChatGPT (Chat Generative Pre-Trained Transformer), to improve students' knowledge acquisition and learning experiences is one well-known use of AI. The purpose of this study is to comprehend how students of HEI’s see ChatGPT as a tool for improving their knowledge. We investigate the perspectives, attitudes, and experiences of students when utilizing ChatGPT in a learning environment through empirical research. We assess the use of ChatGPT by students, looking at elements including usability, satisfaction, and perceived utility. In addition, we identify and examine acceptability elements such social influence, trust, privacy worries, and perceived learning gains. The cognitive consequences of utilizing ChatGPT for knowledge development are also explored in this study, along with how students evaluate ChatGPT's efficiency in promoting learning, critical thinking, and information retrieval. The ethical issues around algorithmic bias, data privacy, and responsible AI application in education are also covered. The study's findings advance the field of educational technology by shedding light on how well-liked ChatGPT is among students for enhancing their knowledge. The development and use of educational technologies powered by AI can be guided by the pedagogical recommendations gained from the study findings. The paper also identifies areas for future research to better investigate ChatGPT's long-term impacts, cross-cultural variations, and customizability potential in education. For educators, researchers, and practitioners hoping to use AI technology effectively in educational contexts, understanding student acceptance of ChatGPT knowledge augmentation is essential. This research encourages informed decision-making and ethical application of AI technologies to improve students' learning results by bridging the gap between AI and education.},
  keywords={Privacy;Ethics;Knowledge acquisition;Decision making;Educational technology;Chatbots;Transformers;Information retrieval;Artificial intelligence;Usability;ChatGPT;AI;HEI’s;Data privacy},
  doi={10.1109/ICIESTR60916.2024.10798141},
  ISSN={},
  month={May},}@INBOOK{10982309,
  author={Pierson, Lillian},
  booktitle={Data & AI Imperative: Designing Strategies for Exponential Growth}, 
  title={Practical Tactics for Successful AI Deployments}, 
  year={2024},
  volume={},
  number={},
  pages={121-138},
  abstract={<p>&#x201c;Artificial intelligence (AI) deployment&#x201d; refers to bringing models into production. The fact is, the deployment of machine learning (ML) models and foundation models usually falls under the same large AI umbrella, but there are major differences between them. Despite their differences, many best practices for ML deployment will hold true for generative model deployment. Deployment is the final puzzle piece required to drive measurable growth from data and AI projects. This chapter looks at some key strategies for maintaining ML systems: monitoring model performance, managing resource utilization; and ensuring model maintenance. Object detection applications are heavyweight and need scaling with changing needs, so the preceding stack will support them more effectively than would traditional on&#x2010;premise solutions and monolithic architectures. Agile and DevOps principles are the cornerstone of software development, and it can be beneficial to adapt the same philosophy for AI deployments.</p>},
  keywords={Artificial intelligence;Buildings;Predictive models;Foundation models;Mathematical models;Training;Production;Generators;Tuning;Testing},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394251971},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10982309},}@INPROCEEDINGS{11081155,
  author={Jonathan, Andrew and Halim, Cornelius Karel and Wulandhari, Lili Ayu and Nabiilah, Ghinaa Zain},
  booktitle={2025 International Conference on Smart Computing, IoT and Machine Learning (SIML)}, 
  title={Exploring Sentiment Patterns in ChatGPT Interactions: A Machine and Deep Learning Approach to Sentiment Classification}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Artificial Intelligence (AI) chatbots are transforming human-computer interaction, yet their understanding and response to human emotions remain a critical frontier. This research presents a comprehensive sentiment classification analysis of 219,294 tweets about Chat Generative Pre-trained Transformer (ChatGPT) through a combination of classical machine learning approaches and state-of-the-art deep learning architectures. We benchmark a wide range of models, from conventional algorithms including Logistic Regression, Support Vector Machine (SVM), Naive Bayes, eXtreme Gradient Boosting (XGBoost) to neural architectures including Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), Bidirectional Encoder Representations from Transformers (BERT), Robustly Optimized BERT Approach (RoBERTa) on the curated dataset of Twitter interactions. Our framework uses text representation methods such as Term Frequency-Inverse Document Frequency (TF-IDF) and transformer tokenization that capture the complex emotional landscape of human-AI interactions. Model performance is evaluated using F1-score, accuracy, precision, and recall. Transformer-based models (BERT and RoBERTa) achieved the highest accuracy of 0.85, outperforming traditional methods such as CNN and Logistic Regression. Most notably, our discoveries reveal a systematic bias across all models in detecting neutral sentiment, which consistently resulted in lower classification performance compared to positive and negative classes. This reveals a limitation in sentiment analysis methodology when dealing with uncertain or ambiguous emotional expressions. By recognizing and characterizing this bias, our work provides a critical step toward enabling emotionally intelligent AI systems and enhancing the robustness of real-world chatbot applications.},
  keywords={Support vector machines;Sentiment analysis;Logistic regression;Accuracy;Computational modeling;Bidirectional control;Chatbots;Transformers;Encoding;Artificial intelligence;sentiment;ChatGPT;models;learning;analysis},
  doi={10.1109/SIML65326.2025.11081155},
  ISSN={},
  month={June},}@ARTICLE{11157742,
  author={Zhang, Yao and Song, Yuchen and Pang, Yue and Li, Shengnan and Jiang, Xiaotian and Wang, Yidi and Li, Jin and Zhang, Min and Wang, Danshi},
  journal={IEEE Open Journal of the Communications Society}, 
  title={Design and Evaluation of an LLM-Based Agent for QoT Estimation and Performance Optimization in Optical Networks}, 
  year={2025},
  volume={6},
  number={},
  pages={7470-7484},
  abstract={The rapid expansion of optical networks has catalyzed the growth of data capacity, creating a new era of high-speed network services. However, as the scale and complexity of nodes and connections increase, coupled with increasingly stringent demands for service efficiency, quality, and resistance to interference, intelligent solutions are needed to achieve efficient and autonomous network operation and maintenance. In this study, we proposed an advanced artificial intelligence (AI) Agent empowered by large language model (LLM), aimed at providing a practical solution for autonomous optical network management. We leverage the powerful language processing and reasoning capabilities of the Generative Pre-trained Transformer (GPT-4), and integrate domain-specific knowledge and optical network tools to simplify maintenance workflows, reduce manual intervention, and improve operational efficiency. Acting as an intelligent assistant for optical network operations, the AI Agent is capable of providing real-time insights and optimization recommendations. In particular, we focus on four typical tasks: quality of transmission (QoT) estimation, performance analysis, optimization, and parameter calibration for physical-layer modeling, which are essential for ensuring service reliability and resource efficiency. Through the design, implementation, and evaluation of these tasks, we demonstrate the feasibility and effectiveness of the proposed agent in addressing key challenges of optical network maintenance. Furthermore, we provide an assessment of accuracy and reliability based on a predetermined scoring standard. The proposed solution not only enhances automation in network monitoring and optimization, but also provides a scalable and generalizable framework for LLM-based support in evolving optical transport environments.},
  keywords={Optical fiber networks;Estimation;Artificial intelligence;Quality of transmission;Optimization;Maintenance;Knowledge engineering;Knowledge based systems;Resource management;Cognition;Large language model;LLM-enabled AI Agent;autonomous optical network;QoT estimation;network optimization},
  doi={10.1109/OJCOMS.2025.3608290},
  ISSN={2644-125X},
  month={},}@ARTICLE{9775188,
  author={Chen, Zhuo and Xiong, Gengang and Sun, Yao and Li, Yun and Li, Yan},
  journal={IEEE Internet of Things Journal}, 
  title={An Internet-of-Things-Enabled System for Road Icing Detection and Prediction}, 
  year={2022},
  volume={9},
  number={20},
  pages={20257-20269},
  abstract={Road icing has become one of the most critical factors threatening traffic safety. This article proposes an Internet of Things (IoT)-enabled road icing detection and prediction system. In the proposed system, we first design a low-power icing sensor equipped with IoT function to periodically collect current road status and transmit the sampled data to IoT gateway through Long Range Radio (LoRa). Then, we design a simple but effective algorithm deployed on IoT gateway to identify road icing in time. The algorithm is proposed based on the change trend of the sampled data of the road state, and can be adapted to the icing recognition on the road covered with various impurities. Furthermore, we put forward a newly designed deep neural network model called Trans-CGAN to achieve accurate road icing prediction even the positive and negative samples are imbalanced. Through a real system deployment and experiments, the results show that our proposed system can detect the formation of road icing effectively and timely, and shows better prediction performance of road icing than several representative models.},
  keywords={Roads;Ice;Optical surface waves;Predictive models;Capacitance measurement;Logic gates;Impurities;Deep neural network (DNN);Internet of Things (IoT);Long Range Radio (LoRa);road icing detection;road icing prediction},
  doi={10.1109/JIOT.2022.3175220},
  ISSN={2327-4662},
  month={Oct},}@INPROCEEDINGS{10285812,
  author={Yaman, Aris and Puspasari, Reny and Akbar, Zaenal and Indrawati, Ariani and Kartika, Yulia Aris and Manik, Lindung Parningotan and Triharyuni, Setiya and Albasri, Hatim and Wibowo, Sandi and Pardede, Hilman F.},
  booktitle={2023 International Conference on Computer, Control, Informatics and its Applications (IC3INA)}, 
  title={Harmful Algal Blooms Prediction Model: Dealing With Limited Datasets}, 
  year={2023},
  volume={},
  number={},
  pages={370-375},
  abstract={HABs pose serious threats to natural aquatic systems, such as mass mortality of aquatic organisms, degradation of water quality, and human poisoning from consuming aquatic organisms exposed to HABs. Monitoring water quality and weather data through buoy data loggers is very useful nowadays. Through these buoys, environmental data can be accessed in real time. Various technical constraints on these buoys will directly and indirectly result in missing values (limited data sets). It often happens that one has a good idea of a learning model, but due to its complexity and smaller number of data sets, the model performs far below expectations. Transfer learning approaches and data synthesis with the CT GAN algorithm have been applied to deal with modelling on limited datasets. The transfer learning model gives better results. It can be seen from the value of model evaluation parameters (AUC and MSE) that the transfer learning model provides better results than other models (model-based CTGAN and deep learning model without transfer learning). The process of adapting (fine-tuning) knowledge is an important process in improving the performance of the model in the transfer learning procedure.},
  keywords={Deep learning;Adaptation models;Computational modeling;Salinity (geophysical);Transfer learning;Water quality;Data models;HABs;deep learning;tabular data;transfer learning;insufficient dataset},
  doi={10.1109/IC3INA60834.2023.10285812},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11035392,
  author={Hana, Silabdi and Hassan, Raini and Faizabadi, Ahmed Rimaz and Gubbi, Abdullah and Bellary, Mohammed Zakir and M, Afsar Baig},
  booktitle={2025 4th International Conference on Distributed Computing and Electrical Circuits and Electronics (ICDCECE)}, 
  title={Leveraging EEG and Signal-to-Noise Ratio Augmentation for Advanced Stress Detection}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Student stress has emerged as a significant concern, requiring prompt identification to avoid serious repercussions. Unlike conventional EEG stress detection approaches that rely on feature extraction, our work introduces a novel combination of SNR-based augmentation with ShallowConvNet recognised for its simplicity and efficiency. Utilising the StressDB-UIA1 dataset, EEG data from 31 subjects were examined under stress and non-stress situations. The research tackles the issue of restricted EEG data availability by utilising Signal-to-Noise Ratio (SNR)-based augmentation, replicating noise levels of 10 dB, 15 dB, and 20 dB. This augmentation strategy improves model robustness and generalisability to real-world situations. The results shows that ShallowConvNet, when trained on SNR-augmented datasets, attains enhanced accuracy and Area Under Curve (AUC) metrics, with peak performance recorded at 20 dB SNR (83.69% accuracy, 0.921 AUC). SNR-based augmentation is apparent in enhancing EEG classification and emphasise ShallowConvNet's capability for real-time stress monitoring, facilitating prompt interventions and mental health support systems.},
  keywords={Accuracy;Mental health;Brain modeling;Feature extraction;Electroencephalography;Real-time systems;Robustness;Biomedical monitoring;Monitoring;Signal to noise ratio;raw EEG signal;electroencephalography;stress prediction;shallowconvnet;non-invasive stress monitoring;signal-to-noise ratio;augmentation;dataset stressDB-UIA1 I},
  doi={10.1109/ICDCECE65353.2025.11035392},
  ISSN={},
  month={April},}@INPROCEEDINGS{9534247,
  author={Saadallah, Amal and Morik, Katharina},
  booktitle={2021 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Meta-Adversarial Training of Neural Networks for Binary Classification}, 
  year={2021},
  volume={},
  number={},
  pages={1-7},
  abstract={We propose a novel framework for classification using neural networks via an adversarial training procedure, in which we simultaneously train a main classifier—a neural network that solves the original classification task, i.e classifying instances into two main categories—and two meta-classifiers which act as discriminators and aim to detect false positives and negatives predicted by the original classifier. Our framework operates in two stages: In a first stage, both main and meta classifiers are pre-trained using the cross-entropy loss. The second stage consists of an adversarial training stage in which both main and meta classifiers are placed in a min-max game. Therefore, we switch to our new loss function so that the goal for the main classifier becomes to maximize the probability of failure of the adversarial meta-classifiers. Our training procedure can be explained by the fact that the meta-classifiers are more accurate when the main classifier is weak i.e., instances misclassified by the main classifier are naturally easy to separate and assign to the correct class membership. Opposingly, if the main classifier is robust enough, then the meta-classifiers are supposed to distinguish between instances that are naturally hard to classify, making thus more mistakes. In this work, both main and meta-classifiers are defined by Multi-Layer Perceptrons (MLP) and the entire training system is performed using backpropagation with gradient descent optimization. Experiments demonstrate the potential of our framework in outperforming the traditional learning scheme in improving the classification accuracy.},
  keywords={Training;Backpropagation;Neural networks;Collaboration;Games;Switches;Machine learning;Adversarial Training;Supervised Learning;Classification;Min-max Game},
  doi={10.1109/IJCNN52387.2021.9534247},
  ISSN={2161-4407},
  month={July},}@ARTICLE{10770756,
  author={Li, Yansheng and Wang, Linlin and Wang, Tingzhu and Yang, Xue and Luo, Junwei and Wang, Qi and Deng, Youming and Wang, Wenbin and Sun, Xian and Li, Haifeng and Dang, Bo and Zhang, Yongjun and Yu, Yi and Yan, Junchi},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={STAR: A First-Ever Dataset and a Large-Scale Benchmark for Scene Graph Generation in Large-Size Satellite Imagery}, 
  year={2025},
  volume={47},
  number={3},
  pages={1832-1849},
  abstract={Scene graph generation (SGG) in satellite imagery (SAI) benefits promoting understanding of geospatial scenarios from perception to cognition. In SAI, objects exhibit great variations in scales and aspect ratios, and there exist rich relationships between objects (even between spatially disjoint objects), which makes it attractive to holistically conduct SGG in large-size very-high-resolution (VHR) SAI. However, there lack such SGG datasets. Due to the complexity of large-size SAI, mining triplets $< $<subject, relationship, object$> $> heavily relies on long-range contextual reasoning. Consequently, SGG models designed for small-size natural imagery are not directly applicable to large-size SAI. This paper constructs a large-scale dataset for SGG in large-size VHR SAI with image sizes ranging from 512 × 768 to 27 860 × 31 096 pixels, named STAR (Scene graph generaTion in lArge-size satellite imageRy), encompassing over 210K objects and over 400K triplets. To realize SGG in large-size SAI, we propose a context-aware cascade cognition (CAC) framework to understand SAI regarding object detection (OBD), pair pruning and relationship prediction for SGG. We also release a SAI-oriented SGG toolkit with about 30 OBD and 10 SGG methods which need further adaptation by our devised modules on our challenging STAR dataset.},
  keywords={Stars;Annotations;Marine vehicles;Satellite images;Visualization;Object detection;Cognition;Benchmark testing;Complexity theory;Bridges;Large-size satellite imagery;object detection;relationship prediction;scene graph generation benchmark},
  doi={10.1109/TPAMI.2024.3508072},
  ISSN={1939-3539},
  month={March},}@ARTICLE{10607932,
  author={Li, Tong and Feng, Hansen and Wang, Lizhi and Zhu, Lin and Xiong, Zhiwei and Huang, Hua},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Stimulating Diffusion Model for Image Denoising via Adaptive Embedding and Ensembling}, 
  year={2024},
  volume={46},
  number={12},
  pages={8240-8257},
  abstract={Image denoising is a fundamental problem in computational photography, where achieving high perception with low distortion is highly demanding. Current methods either struggle with perceptual quality or suffer from significant distortion. Recently, the emerging diffusion model has achieved state-of-the-art performance in various tasks and demonstrates great potential for image denoising. However, stimulating diffusion models for image denoising is not straightforward and requires solving several critical problems. For one thing, the input inconsistency hinders the connection between diffusion models and image denoising. For another, the content inconsistency between the generated image and the desired denoised image introduces distortion. To tackle these problems, we present a novel strategy called the Diffusion Model for Image Denoising (DMID) by understanding and rethinking the diffusion model from a denoising perspective. Our DMID strategy includes an adaptive embedding method that embeds the noisy image into a pre-trained unconditional diffusion model and an adaptive ensembling method that reduces distortion in the denoised image. Our DMID strategy achieves state-of-the-art performance on both distortion-based and perception-based metrics, for both Gaussian and real-world image denoising.},
  keywords={Diffusion models;Image denoising;Noise reduction;Distortion;Task analysis;Iterative methods;Image restoration;Computational photography;image denoising;diffusion model;self-supervised;distortion-perception},
  doi={10.1109/TPAMI.2024.3432812},
  ISSN={1939-3539},
  month={Dec},}@ARTICLE{9904872,
  author={Rao, Yuan and Ni, Jiangqun and Zhang, Weizhe and Huang, Jiwu},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Towards JPEG-Resistant Image Forgery Detection and Localization Via Self-Supervised Domain Adaptation}, 
  year={2025},
  volume={47},
  number={5},
  pages={3285-3297},
  abstract={With wide applications of image editing tools, forged images (splicing, copy-move, removal and etc.) have been becoming great public concerns. Although existing image forgery localization methods could achieve fairly good results on several public datasets, most of them perform poorly when the forged images are JPEG compressed as they are usually done in social networks. To tackle this issue, in this paper, a self-supervised domain adaptation network, which is composed of a backbone network with Siamese architecture and a compression approximation network (ComNet), is proposed for JPEG-resistant image forgery detection and localization. To improve the performance against JPEG compression, ComNet is customized to approximate the JPEG compression operation through self-supervised learning, generating JPEG-agent images with general JPEG compression characteristics. The backbone network is then trained with domain adaptation strategy to localize the tampering boundary and region, and alleviate the domain shift between uncompressed and JPEG-agent images. Extensive experimental results on several public datasets show that the proposed method outperforms or rivals to other state-of-the-art methods in image forgery detection and localization, especially for JPEG compression with unknown QFs.},
  keywords={Forgery;Transform coding;Image coding;Location awareness;Forensics;Splicing;Feature extraction;Data augmentation;domain adaptation;forgery detection and localization;image forensics;self-supervised learning},
  doi={10.1109/TPAMI.2022.3210379},
  ISSN={1939-3539},
  month={May},}@INPROCEEDINGS{9688171,
  author={Li, Jin and Yan, Nan and Wang, Lan},
  booktitle={2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)}, 
  title={Unsupervised Cross-Lingual Speech Emotion Recognition Using Pseudo Multilabel}, 
  year={2021},
  volume={},
  number={},
  pages={366-373},
  abstract={Speech Emotion Recognition (SER) in a single language has achieved remarkable results through deep learning approaches in the last decade. However, cross-lingual SER remains a challenge in real-world applications due to a great difference between the source and target domain distributions. To address this issue, we propose an unsupervised cross-lingual Neural Network with Pseudo Multilabel (NNPM) that is trained to learn the emotion similarities between source domain features inside an external memory adjusted to identify emotion in cross-lingual databases. NNPM introduces a novel approach that leverages external memory to store source domain features and generates pseudo multilabel for each target domain data by computing the similarities between the external memory and the target domain features. We evaluate our approach on multiple different languages of speech emotion databases. Experimental results show our proposed approach significantly improves the weighted accuracy (WA) across multiple low-resource languages on Urdu, Skropus, ShEMO, and EMO-DB corpus. To facilitate further research, code is available at https://github.com/happyjin/NNPM},
  keywords={Deep learning;Emotion recognition;Codes;Databases;Speech coding;Conferences;Artificial neural networks;speech emotion recognition;human-computer interaction;cross-domain adaptation;cross-lingual speech emotion recognition},
  doi={10.1109/ASRU51503.2021.9688171},
  ISSN={},
  month={Dec},}@ARTICLE{10143393,
  author={Yang, Xiaolong and Jia, Xiaohong and Gong, Dihong and Yan, Dong-Ming and Li, Zhifeng and Liu, Wei},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={LARNeXt: End-to-End Lie Algebra Residual Network for Face Recognition}, 
  year={2023},
  volume={45},
  number={10},
  pages={11961-11976},
  abstract={Face recognition has always been courted in computer vision and is especially amenable to situations with significant variations between frontal and profile faces. Traditional techniques make great strides either by synthesizing frontal faces from sizable datasets or by empirical pose invariant learning. In this paper, we propose a completely integrated embedded end-to-end Lie algebra residual architecture (LARNeXt) to achieve pose robust face recognition. First, we explore how the face rotation in the 3D space affects the deep feature generation process of convolutional neural networks (CNNs), and prove that face rotation in the image space is equivalent to an additive residual component in the feature space of CNNs, which is determined solely by the rotation. Second, on the basis of this theoretical finding, we further design three critical subnets to leverage a soft regression subnet with novel multi-fusion attention feature aggregation for efficient pose estimation, a residual subnet for decoding rotation information from input face images, and a gating subnet to learn rotation magnitude for controlling the strength of the residual component that contributes to the feature learning process. Finally, we conduct a large number of ablation experiments, and our quantitative and visualization results both corroborate the credibility of our theory and corresponding network designs. Our comprehensive experimental evaluations on frontal-profile face datasets, general unconstrained face recognition datasets, and industrial-grade tasks demonstrate that our method consistently outperforms the state-of-the-art ones.},
  keywords={Face recognition;Algebra;Three-dimensional displays;Task analysis;Pose estimation;Image reconstruction;Visualization;Face recognition;lie algebra;pose estimation;profile face},
  doi={10.1109/TPAMI.2023.3279378},
  ISSN={1939-3539},
  month={Oct},}@ARTICLE{9971748,
  author={Fu, Chaoyou and Zhou, Xiaoqiang and He, Weizan and He, Ran},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Towards Lightweight Pixel-Wise Hallucination for Heterogeneous Face Recognition}, 
  year={2023},
  volume={45},
  number={7},
  pages={9135-9148},
  abstract={Cross-spectral face hallucination is an intuitive way to mitigate the modality discrepancy in Heterogeneous Face Recognition (HFR). However, due to imaging differences, the hallucination inevitably suffers from a shape misalignment between paired heterogeneous images. Rather than building complicated architectures to circumvent the problem like previous works, we propose a simple yet effective method called Shape Alignment FacE (SAFE). Specifically, given an image, we align its shape to that of the paired one under the assistance of a 3D face model. The produced aligned pair enables us to train a lightweight generator that solely concentrates on spectrum translation with a pixel-wise supervision. However, since the 3D face model is powerless to attributes like the hair and glasses, there are still pixel discrepancies between the aligned pair. Given that, in the image space, we introduce a probabilistic pixel-wise loss that incorporates the discrepancies into a probabilistic distribution. Moreover, in order to alleviate the influence of the shape misalignment on spectrum translation, a spectrum optimal transport is performed in a shape-irrelevant latent space. Note that, in the final inference phase, except the lightweight generator, all other auxiliary modules are discarded. In addition to superior performance in qualitative synthesis and quantitative recognition, extensive experiments on 6 datasets demonstrate that our method also gains other two distinct advantages over existing state-of-the-art counterparts. The first is using a more lightweight generator. Compared with the state-of-the-art method, our method can achieve higher recognition results with 128x fewer parameters and 63x fewer FLOPs with only 4.58 ms latency on a single TITAN-XP. The second is training on low-shot datasets such as Oulu-CASIA NIR-VIS that just contains 1,920 images from 20 identities. To the best of our knowledge, we are the first that can perform well on such a small-scale dataset. These advantages make our method more practical in the real world and further push boundaries of heterogeneous face recognition.},
  keywords={Face recognition;Generators;Shape;Training;Probabilistic logic;Three-dimensional displays;Task analysis;Heterogeneous face recognition;cross-spectral face hallucination},
  doi={10.1109/TPAMI.2022.3227180},
  ISSN={1939-3539},
  month={July},}@INPROCEEDINGS{9736171,
  author={Yang, Shuqiang and Qin, Huafeng and El-Yacoubi, Mounim A. and Liu, Chongwen},
  booktitle={2021 International Conference on Cyber-Physical Social Intelligence (ICCSI)}, 
  title={Cross-Modality Domain Adaptation for hand-vein recognition}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Palm-vein recognition has attracted increasing attention over the last years. Although deep learning-based approaches, such as Convolutional Neural Networks (CNN), have been shown to be effective for feature representation, thereby achieving good performance in vein verification tasks, they typically are trained on large labeled datasets. In general, labeling vein images is expensive and time cost, and typical hand-tuned approaches for data augmentation can not collect the complex variations in such images. To address this problem, a novel unsupervised domain adaptation approach, named CycleGAN-based domain adaptation (CGAN-DA), is proposed to automatically extract discriminant from the palm-vein network, without the need of any image annotation. Our proposed CGAN-DA allows a learning scheme that ensures a synergistic fusion of adaptations image-wise and feature-wise. Concretely, we transform the image appearance across two domains (palm-vein image domain and retinal image domain), in order to enhance the domain-invariance of the extracted features for the palm-vein segmentation task. Without using any annotation from the target domain (palm-vein images), our model learning is guided by several adversarial losses, a cycle consistence loss and a segmentation loss. Our experimental on the public CASIA palm-vein dataset show that our approach is capable of achieving state-of-the art verification accuracy.},
  keywords={Image segmentation;Adaptation models;Annotations;Veins;Biological system modeling;Transforms;Feature extraction;Palm-vein Authentication;Domain Adaptation;GAN;CNN},
  doi={10.1109/ICCSI53130.2021.9736171},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11042133,
  author={Salunke, Priya and Katti, Jayashree},
  booktitle={2025 Third International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)}, 
  title={Tomato Leaf Disease Detection using Lightweight Deep Convolution Network}, 
  year={2025},
  volume={},
  number={},
  pages={1236-1243},
  abstract={Plant diseases are the most significant dangers to the nation's food supply and the decline in agricultural output; yet, the rapid identification of plant diseases continues to be difficult due to a lack of availability of the appropriate infrastructure. It is possible to see the symptoms of the crop disease in a variety of components of the crop; however, the leaves exhibit signs of the illnesses that are particularly relevant. Distinct computer visionbased approaches that are used successfully for the plant leaf disease detection (PLDD). In this study, a comprehensive assessment of PLDD methodologies that make use of a different of machine learning (ML) and deep learning (DL)-based techniques is presented. It is focused on the positive and negative aspects of the study. Additionally, we have assessed the results of PLDD system for deep convolution neural network. The DCNN based PLDD offers the accuracy of 95.50%, recall of 0.97, precision of 0.95 and F1-score of 0.96 for Plant Village dataset.},
  keywords={Deep learning;Surveys;Smart agriculture;Plant diseases;Image segmentation;Convolution;Plants (biology);Neural networks;Crops;Data augmentation;Plant leaf disease detection;Smart Agriculture;Machine Learning;Deep Learning},
  doi={10.1109/ICAISS61471.2025.11042133},
  ISSN={},
  month={May},}@ARTICLE{11059839,
  author={Zhang, Yifan and Hou, Junhui and Ren, Siyu and Wu, Jinjian and Yuan, Yixuan and Shi, Guangming},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Self-Supervised Learning of LiDAR 3D Point Clouds via 2D-3D Neural Calibration}, 
  year={2025},
  volume={47},
  number={10},
  pages={9201-9216},
  abstract={This paper introduces a novel self-supervised learning framework for enhancing 3D perception in autonomous driving scenes. Specifically, our approach, namely NCLR, focuses on 2D-3D neural calibration, a novel pretext task that estimates the rigid pose aligning camera and LiDAR coordinate systems. First, we propose the learnable transformation alignment to bridge the domain gap between image and point cloud data, converting features into a unified representation space for effective comparison and matching. Second, we identify the overlapping area between the image and point cloud with the fused features. Third, we establish dense 2D-3D correspondences to estimate the rigid pose. The framework not only learns fine-grained matching from points to pixels but also achieves alignment of the image and point cloud at a holistic level, understanding the LiDAR-to-camera extrinsic parameters. We demonstrate the efficacy of NCLR by applying the pre-trained backbone to downstream tasks, such as LiDAR-based 3D semantic segmentation, object detection, and panoptic segmentation. Comprehensive experiments on various datasets illustrate the superiority of NCLR over existing self-supervised methods. The results confirm that joint learning from different modalities significantly enhances the network’s understanding abilities and effectiveness of learned representation.},
  keywords={Three-dimensional displays;Point cloud compression;Self-supervised learning;Training;Laser radar;Image reconstruction;Semantic segmentation;Calibration;Autonomous vehicles;Cameras;Self-supervised learning;3D perception;cross-modal;autonomous driving;registration},
  doi={10.1109/TPAMI.2025.3584625},
  ISSN={1939-3539},
  month={Oct},}@ARTICLE{9279200,
  author={Habib, Habib Ur Rahman and Wang, Shaorong and Waqar, Asad and Farhan, Bashar Sakeen and Kotb, Kotb M. and Kim, Yun-Su},
  journal={IEEE Access}, 
  title={Combined Heat and Power Units Sizing and Energy Cost Optimization of a Residential Building by Using an Artificial Bee Colony Algorithm}, 
  year={2020},
  volume={8},
  number={},
  pages={218289-218303},
  abstract={Battery manufacturing and recycling are expensive; combined heat and power (CHP) units are optimal for residential premises. CHP units can enhance energy efficiency and reduce energy costs, but appropriately sized units must be chosen. Here, we optimize CHP unit sizing to minimize the energy costs of residential areas. Sizing is based on both the electricity and heat loads; it is possible to optimally rate the various types of CHP units. We compare an artificial bee colony (ABC) optimization method to a genetic algorithm (GA) when various strategies are adopted. Electricity and heat loads are considered together when sizing CHP units and optimizing costs using the ABC algorithm and the GA. The optimization outcomes are compared to a base case; the ABC method performs better than the GA. The average daily energy cost savings possible using the ABC method were higher for all three seasons (by 25.9, 4.4, and 10.8% respectively) compared to those possible when residential premises lacked CHP units.},
  keywords={Cogeneration;Optimization;Genetic algorithms;Artificial bee colony algorithm;Resistance heating;Linear programming;Buildings;Artificial bee colony;cost-benefit analysis;CHP unit size optimization;energy conversion;genetic algorithm;residential building automation},
  doi={10.1109/ACCESS.2020.3042173},
  ISSN={2169-3536},
  month={},}@ARTICLE{11165292,
  author={Silva, Waruna De and Fernando, Anil},
  journal={IEEE Access}, 
  title={Toward Intelligent Ad Breaks: A Survey and Taxonomy of AI-Driven Ad Placement in Streaming Media}, 
  year={2025},
  volume={13},
  number={},
  pages={163844-163868},
  abstract={Streaming media growth has increased demand for intelligent, non-intrusive placement of advertisements that balance monetization targets with viewer experience. Traditional rule-based heuristics such as scene change or silence discovery fail to capture contemporary video consumption diversity, complexity, and cognitive variability. Here, we present a comprehensive summary of artificial intelligence (AI) methods for optimizing ad break placement within streaming systems. We introduce a new three-phase taxonomy Data, Decision, and Delivery organizing state-of-the-art techniques within computer vision, natural language processing, affective computing, and reinforcement learning. AdBreakScore(t), a cognitively and emotionally guided model of appropriateness evaluation for advertisements, underpins this work with additions to model ethical and computational constraints. We analyze multimodal scene interpretation, viewer engagement prediction, and adaptable scheduling to illustrate prospects and trade-offs along technical, cognitive, and regulatory axes. We conclude with future directions neurophysiological engagement modeling, generative storyline alignment, and edge-compliant delivery aiming to advance development of viewer-centered, adaptive, and ethically principled systems for placing advertisements within an ever-changing digital media landscape.},
  keywords={Taxonomy;Ethics;Load modeling;Computational modeling;Videos;Artificial intelligence;Optimization;Cognitive load;Streaming media;Analytical models;Ad placement optimization;streaming media;artificial intelligence;multimodal analysis;viewer engagement prediction;reinforcement learning;cognitive load modeling;affective computing;context-aware advertising;ethical AI},
  doi={10.1109/ACCESS.2025.3610662},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8893115,
  author={Pondenkandath, Vinaychandran and Alberti, Michele and Diatta, Michaël and Ingold, Rolf and Liwicki, Marcus},
  booktitle={2019 International Conference on Document Analysis and Recognition Workshops (ICDARW)}, 
  title={Historical Document Synthesis with Generative Adversarial Networks}, 
  year={2019},
  volume={5},
  number={},
  pages={146-151},
  abstract={The following topics are dealt with: learning (artificial intelligence); document image processing; convolutional neural nets; text analysis; handwritten character recognition; feature extraction; neural nets; optical character recognition; image segmentation; image recognition.},
  keywords={Task analysis;Training;Software;Gallium nitride;Electronic publishing;Image synthesis;Generators;historical document;deep learning;document synthesis},
  doi={10.1109/ICDARW.2019.40096},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10046564,
  author={Revanth, Banala and Dwivedi, Sanjay K. and Kumar, Manoj},
  booktitle={2022 2nd International Conference on Innovative Sustainable Computational Technologies (CISCT)}, 
  title={A Framework For Single Image Dehazing Using DWT Based Cross Bilateral Filter Fusion of Generative and ASM Models}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Due to the latest advancements in technologies like artificial intelligence, machine learning, and deep learning in image processing, computer vision, and their uses in various applications, there has been a lot of interest in the restoration of murky images. This paper gives a novel single-image dehazing (SID) framework for the restoration of single hazy image (SHI). The framework has three parts. The first part of the framework comprises three networks. A white-balanced auto-encoder network in the front, followed by a pair of sequential auto-encoder networks at the end for image dehazing (ID). A white balance auto-encoder network is used for correcting the white balance error in the input hazy image (HI). Pair of sequential auto- encoder networks gives haze-reduced output by taking corrected white balanced error image as input. The second part comprises an ASM-based model Dark Channel Prior (DCP) for ID. DCP produce haze-free images (HFI) by taking HI as input. The third part presents the fusion model for integrating the first and second parts of the framework. DWT-based cross bilateral filter model is the fusion model (FM) to get the final HFI. The first part of the framework is trained by using a hybrid loss function (perceptual loss function combined with MSE loss function) on O- HAZE, I-HAZE, and MRFID data sets. The proposed framework got considerably good result in terms of Structural Similarity Index (SSIM), Peak signal-to-noise ratio (PSNR), compared with cutting-edge methods.},
  keywords={Training;Measurement;Learning systems;PSNR;Benchmark testing;Discrete wavelet transforms;Image restoration;Auto-encoder;Residual learning;rectified linear activation unit (ReLU)},
  doi={10.1109/CISCT55310.2022.10046564},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10759984,
  author={Xu, Qihui and Tang, Jiacheng and Kang, Qi and WU, Qinhao and Yao, Shuaiyu},
  booktitle={2024 International Conference on Networking, Sensing and Control (ICNSC)}, 
  title={FPRAN: A Hierarchical Generative Model for Few-Shot Pantograph Fault Diagnosis}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Pantograph is the crucial component of rail transit vehicles. Detecting and resolving faults swiftly is important in the pantograph. Existing fault diagnosis technologies with artificial intelligence have difficulties in dealing with some rare faults due to the scarcity of training samples. This paper proposes a new algorithm for few-shot fault diagnosis of pantograph. The proposed method constructs a reconstructive adversarial network with hierarchical structure to mine multi-scale feature from few-shot samples. A hierarchical data generation module is designed leveraging adversarial learning to generate scarce category samples. An initial classifier is employed to constrain the generated results, while the classifier is dynamically reconstructed to enhance overall performance. This paper designs detailed experiments to demonstrate that, compared with other existing methods, the proposed algorithm can better solve the problem of pantograph fault diagnosis.},
  keywords={Fault diagnosis;Training;Rails;Heuristic algorithms;Production;Data collection;Feature extraction;Classification algorithms;Sensors;Data mining;hierarchical model;few-shot learning;data generation},
  doi={10.1109/ICNSC62968.2024.10759984},
  ISSN={2766-8665},
  month={Oct},}@ARTICLE{11074270,
  author={Yuan, Tianguo and Xie, Jiyang and Li, Yang and Yang, Xiaozhen and Yang, Xiaolin and Wen, Erda},
  journal={IEEE Transactions on Antennas and Propagation}, 
  title={Flex-form Generative Neural Network for Multi-frequency Modes Antennas}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={This communication introduces a Flex-form Generative Neural Network (FGNN) that is capable of inverse designing the dimensions of a multi-frequency modes antenna, which is implemented with a metallic monopole patch containing variable numbers of slots, based on a target reflection coefficient across 0.3-3 GHz. The FGNN integrates three models: the Forward Prediction Model (FPM) for predicting the antenna’s reflection coefficient S11 based on geometric parameters, i.e., patch and slot dimensions, the Auxiliary Classification Model (ACM) for determining slots count, and finally the Inverse Design Model (IDM) for generating geometric parameters from the desired reflection coefficient. The proposed method enables flexible adjustment of antenna structure by allowing parameters output of indefinite-length. Antenna supporting up to three bands are achieved in this demonstration, with minimal amount of dataset required. The network potentially provides an efficient framework for various electromagnetic structures design with flexible forms of geometry parameters or targets.},
  keywords={Antennas;Training;Slot antennas;Neurons;Inverse design;Predictive models;Reflection coefficient;Resonant frequency;Microwave antenna arrays;Silicon;Recurrent Neural Network (RNN);inverse design;multi-frequency modes;antenna},
  doi={10.1109/TAP.2025.3584591},
  ISSN={1558-2221},
  month={},}@ARTICLE{9837952,
  author={Chen, Shengchao and Shu, Ting and Zhao, Huan and Wan, Qilin and Huang, Jincan and Li, Cailing},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Dynamic Multiscale Fusion Generative Adversarial Network for Radar Image Extrapolation}, 
  year={2022},
  volume={60},
  number={},
  pages={1-11},
  abstract={Typhoons, a kind of devastating natural disaster, have caused incalculable damages worldwide. The meteorological radar image is essential for weather forecasting, especially typhoons. The weather nowcasting (future 0–6 h) can be implemented via extrapolating radar images without using the primary weather forecasting method—the numerical weather prediction model. However, the existing related techniques based on statistics or artificial intelligence were not efficient enough. In this article, a novel radar image extrapolation algorithm named dynamic multiscale fusion-generative adversarial network (DMSF-GAN) was proposed. DMSF-GAN captures the future radar image distribution based on current radar images through modifying the GAN. In the generative module of GAN, an auto-encoder consisting of dynamic inception-3-D and feature connection blocks extracts significant features from current radar images. The feasibility of the proposed model was verified on a real radar image dataset, and the experimental results proved that the proposed algorithm could effectively capture the location and pattern of the future radar echo, especially for typhoon weather systems. Compared with the mainstream methods of radar image extrapolation such as optical-flow and recurrent neural network (RNN)-based models, DMSF-GAN has a more superior and robust performance, which is also suitable for running on low-configuration machines.},
  keywords={Radar;Radar imaging;Extrapolation;Meteorology;Feature extraction;Tropical cyclones;Meteorological radar;Convolutional neural network;deep learning;generative adversarial network;precipitation nowcasting;radar echo extrapolation;typhoon prediction},
  doi={10.1109/TGRS.2022.3193458},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{10578716,
  author={Kloos, Carlos Delgado and Alario-Hoyos, Carlos and Estévez-Ayres, Iria and Callejo-Pinardo, Patricia and Hombrados-Herrera, Miguel A. and Muñoz-Merino, Pedro J. and Moreno-Marcos, Pedro Manuel and Muñoz-Organero, Mario and Ibáñez, María Blanca},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={How can Generative AI Support Education?}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={The possible applications of GenAI (Generative AI) in education alone are so manyfold and overwhelming that it is useful to have an overview of the many possibilities that are opening up. In this paper, we try to organize some of the low-hanging fruits that can help instructors, learners, and educational managers use GenAI applications to improve educational performance. For instructors, GenAI can help in gaining a deeper understanding of the topics to be taught, preparing educational materials, and facilitating the enactment phase in class. Learners can be assisted in getting personalized content and feedback, having GenAI as a participant in forums, or for self-reflection and emotions detection. Managers and other stakeholders can profit from Academic Analytics, bias detection, course repurposing, and many other uses. In this paper, we also present a use case detailing some initial actions we are implementing for a Programming with Java course. One action is to explicitly identify, in each problem set, the competencies being developed. Another one is the development of a chatbot, fine-tuned with the course material, which can be used by students as a tutor. The third action is to use a GenAI tool to generate questions aimed at assessing whether students truly grasp the programming project they have supposedly developed. AI is here to stay, in spite of the issues it opens up, and therefore it is never too early to start experimenting with it in practice.},
  keywords={Java;Emotion recognition;Ecosystems;Companies;Chatbots;Internet;Stakeholders;Generative Artificial Intelligence;AI in education;programming course},
  doi={10.1109/EDUCON60312.2024.10578716},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10446942,
  author={Park, YeongHyeon and Kang, Sungho and Kim, Myung Jin and Jeong, Hyeonho and Park, Hyunkyu and Kim, Hyeong Seok and Yi, Juneho},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Neural Network Training Strategy To Enhance Anomaly Detection Performance: A Perspective On Reconstruction Loss Amplification}, 
  year={2024},
  volume={},
  number={},
  pages={5165-5169},
  abstract={Unsupervised anomaly detection (UAD) is a widely adopted approach in industry due to rare anomaly occurrences and data imbalance. A desirable characteristic of an UAD model is contained generalization ability which excels in the reconstruction of seen normal patterns but struggles with unseen anomalies. Recent studies have pursued to contain the generalization capability of their UAD models in reconstruction from different perspectives, such as design of neural network (NN) structure and training strategy. In contrast, we note that containing of generalization ability in reconstruction can also be obtained simply from steep-shaped loss landscape. Motivated by this, we propose a loss landscape sharpening method by amplifying the reconstruction loss, dubbed Loss AMPlification (LAMP). LAMP deforms the loss landscape into a steep shape so the reconstruction error on unseen anomalies becomes greater. Accordingly, the anomaly detection performance is improved without any change of the NN architecture. Our findings suggest that LAMP can be easily applied to any reconstruction error metrics in UAD settings where the reconstruction model is trained with anomaly-free samples only.},
  keywords={Training;Measurement;Industries;Shape;Artificial neural networks;Signal processing;Acoustics;Unsupervised anomaly detection;Loss amplification;Loss landscape;Training strategy},
  doi={10.1109/ICASSP48485.2024.10446942},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{9520693,
  author={Yilma, Getinet and Gedamu, Kumie and Assefa, Maregu and Oluwasanmi, Ariyo and Qin, Zhiguang},
  booktitle={2021 IEEE 2nd International Conference on Pattern Recognition and Machine Learning (PRML)}, 
  title={Generation and Transformation Invariant Learning for Tomato Disease Classification}, 
  year={2021},
  volume={},
  number={},
  pages={121-128},
  abstract={Deep learning-based plant disease management became a cost-effective way to improved agro-productivity. Advanced train sample generation and augmentation methods enlarge train sample size and improve feature distribution but generation and augmentation introduced sample feature discrepancy due to the generation learning process and augmentation artificial bias. We proposed a generation and geometric transformation invariant feature learning method using Siamese networks with maximum mean discrepancy loss to minimize the feature distribution discrepancies coming from the generated and augmented samples. Through variational GAN and geometric transformation, we created four dataset settings to train the proposed approach. The abundant evaluation results on the PlantVillage tomato dataset demonstrated the effectiveness of the proposed approach for the ResNet50 Siamese networks in learning generation and transformation invariant features for plant disease classification.},
  keywords={Training;Learning systems;Image synthesis;Learning (artificial intelligence);Generative adversarial networks;Pattern recognition;Task analysis;generation invariant learning;tomato disease classification;maximum mean discrepancy;variational GAN generation},
  doi={10.1109/PRML52754.2021.9520693},
  ISSN={},
  month={July},}@ARTICLE{11053810,
  author={Marquez-Carpintero, Luis and Viejo, Diego and Cazorla, Miguel},
  journal={IEEE Access}, 
  title={Enhancing Engineering and STEM Education With Vision and Multimodal Large Language Models to Predict Student Attention}, 
  year={2025},
  volume={13},
  number={},
  pages={114681-114695},
  abstract={Generative Artificial Intelligence (AI) and Large Language Models (LLMs), including Visual Language Models (VLMs) and Multimodal LLMs (MLLMs), have shown transformative potential in education. These technologies address persistent challenges in fostering classroom engagement and interaction. Our study highlights the efficacy of these models in detecting students’ attention levels and emotional states, equipping educators with actionable insights to optimize instructional delivery. However, widespread adoption is hindered by significant barriers such as high computational demands and the limited availability of high-quality datasets. To overcome these challenges, this research proposes the integration of MLLMs with Few-Shot Learning techniques, offering a resource-efficient framework to enable their practical implementation in educational contexts. This study focuses on the application of VLMs and MLLMs to predict student attention in science, technology, engineering and mathematics (STEM) education, evaluating the effectiveness of Few-Shot Training compared to traditional AI methodologies. The research is structured into two phases: the first phase optimizes image frequency and computational costs using MLLMs, while the second phase trains VLMs on classroom data to identify visual cues, including gaze direction and head movement. The results demonstrate that VLMs combined with Few-Shot Learning significantly outperform traditional models in capturing nuanced visual data, allowing for pedagogical adjustments comparable to those made through human labeling. These findings underline the transformative potential of VLMs and MLLMs in education, particularly in resource-constrained environments. Few-Shot Learning emerges as a practical and effective approach for leveraging small datasets to enhance student engagement and instructional quality.},
  keywords={Computational modeling;Visualization;Accuracy;Data models;Few shot learning;Computational efficiency;STEM;Real-time systems;Predictive models;Feature extraction;Attention prediction;engineering education;few-shot learning;large language models;student engagement},
  doi={10.1109/ACCESS.2025.3584025},
  ISSN={2169-3536},
  month={},}@ARTICLE{10886920,
  author={Tao, Songjing and Yuan, Meng and Wu, Qiang and Wang, Ran and Hao, Jie},
  journal={IEEE Internet of Things Journal}, 
  title={Generative AI-Aided Vertical Handover Decision in SAGIN for IoT With Integrated Sensing and Communication}, 
  year={2025},
  volume={12},
  number={10},
  pages={13297-13310},
  abstract={As an advanced form of IoT technology, integrated sensing and communication (ISAC) deeply integrates communication and perception, enhancing the performance and application range of IoT. At the same time, the space-air-ground integrated network (SAGIN) provides a wider and more efficient connection and information processing support for both. However, the highly dynamic and time-varying characteristics of SAGIN lead to more frequent vertical handovers among heterogeneous wireless networks, which seriously affects the continuity and reliability of services. This motivates us to explore an effective vertical handover method in SAGIN to guarantee the quality of network service. The issue is a typical complex and high-dimensional problem with its online and dynamic characteristics, which provides a particularly favorable scenario for the adaptability of the diffusion model (DM). Accordingly, we propose a novel vertical handover decision algorithm with the aid of DM. First, we innovate a novel vertical handover analytical model that describes handover jitter, load difference, and handover robustness. Then we formulate it as a multiobjective optimization problem. Next, inspired by Generative AI (GAI), we propose a DM-based GAI-empowered handover decision (DGHD) algorithm to capture the time-varying and high-dimensional environments and generate optimal vertical handover decisions. Subsequently, the policy network of multiagent proximal policy optimization (MAPPO) is replaced with the proposed DGHD for addressing environmental uncertainty and enhancing efficiency. Finally, the simulations exhibit that our proposed algorithm outperforms existing algorithms.},
  keywords={Handover;Space-air-ground integrated networks;Satellites;Heuristic algorithms;Optimization;Internet of Things;Heterogeneous networks;Vehicle dynamics;Robustness;Jitter;Diffusion model (DM);generative artificial intelligence (GAI);Internet of Things (IoT);space–air–ground integrated networks (SAGINs);vertical handover decision},
  doi={10.1109/JIOT.2025.3536640},
  ISSN={2327-4662},
  month={May},}@ARTICLE{11164900,
  author={Lin, Xixun and Yu, Qing and Cao, Yanan and Zou, Lixin and Zhou, Chuan and Wu, Jia and Li, Chenliang and Zhang, Peng and Pan, Shirui},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Generative Causality-driven Network for Graph Multi-task Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-16},
  abstract={Multi-task learning (MTL) is a standard learning paradigm in machine learning. The central idea of MTL is to capture the shared knowledge among multiple tasks for mitigating the problem of data sparsity where the annotated samples for each task are quite limited. Recent studies indicate that graph multi-task learning (GMTL) yields the promising improvement over previous MTL methods. GMTL represents tasks on a task relation graph, and further leverages graph neural networks (GNNs) to learn complex task relationships. Although GMTL achieves the better performance, the construction of task relation graph heavily depends on simple heuristic tricks, which results in the existence of spurious task correlations and the absence of true edges between tasks with strong connections. This problem largely limits the effectiveness of GMTL. To this end, we propose the Generative Causality-driven Network (GCNet), a novel framework that progressively learns the causal structure between tasks to discover which tasks are beneficial to be jointly trained for improving generalization ability and model robustness. To be specific, in the feature space, GCNet first introduces a feature-level generator to generate the structure prior for reducing learning difficulty. Afterwards, GCNet develops a output-level generator which is parameterized as a new causal energy-based model (EBM) to refine the learned structure prior in the output space driven by causality. Benefiting from our proposed causal framework, we theoretically derive an intervention contrastive estimation for training this causal EBM efficiently. Experiments are conducted on multiple synthetic and real-world datasets. Extensive empirical results and model analyses demonstrate the superior performance of GCNet over several competitive MTL baselines.},
  keywords={Multitasking;Training;Mathematical models;Graph neural networks;Data models;Generators;Predictive models;Optimization;Numerical analysis;Correlation;Graph neural networks;Graph machine learning;Graph multi-task learning},
  doi={10.1109/TPAMI.2025.3610096},
  ISSN={1939-3539},
  month={},}@INPROCEEDINGS{11038330,
  author={An, Hyunjun and Suh, Haeseok and Son, Keeyoung and Kim, Haeyeon and Kim, Keunwoo and Lee, Junghyun and Shin, Taein and Choi, Seonguk and Kim, Taesoo and Park, Junho and Choi, Inyoung and Kim, Joungho},
  booktitle={2025 IEEE 75th Electronic Components and Technology Conference (ECTC)}, 
  title={Generative Model Based Multi-Layer PDN Impedance Estimation with Multi-Power Domain}, 
  year={2025},
  volume={},
  number={},
  pages={927-932},
  abstract={In this paper, we propose a generative model based power distribution network (PDN) impedance estimator. For given input PDN configurations of each power domain, our model estimates Z-parameters in a fast and accurate manner. For practical applications, we specifically address multi-layer PDNs with multiple power domains. Our neural architecture combines convolutional neural network (CNN) and attention mechanism, which effectively capture both microscopic structural details and macroscopic interactions within power domains. For verification, we compared the estimated Z-parameters against results from full-wave 3D electromagnetic (EM) simulations. As a result, the proposed model achieved mean absolute error (MAE) of 2.93 $\text{dB}\Omega$ with inference time of only 2.35 $\mu\mathrm{s}$, while full-wave 3D EM simulation requires about 10,000 seconds, representing a substantial advancement in computation time.},
  keywords={Solid modeling;Accuracy;Three-dimensional displays;Computational modeling;Scalability;Estimation;Predictive models;Impedance;Convolutional neural networks;Optimization;Artificial intelligence;generative model;multi-power domain;power distribution network},
  doi={10.1109/ECTC51687.2025.00162},
  ISSN={2377-5726},
  month={May},}@ARTICLE{10981727,
  author={Jin, Zhenzhou and You, Li and Ng, Derrick Wing Kwan and Xia, Xiang-Gen and Gao, Xiqi},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Near-Field Channel Estimation for XL-MIMO: A Deep Generative Model Guided by Side Information}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={This paper investigates the near-field (NF) channel estimation (CE) for extremely large-scale multiple-input multiple-output (XL-MIMO) systems. Considering the pronounced NF effects in XL-MIMO communications, we first establish a joint angle-distance (AD) domain-based spherical-wavefront physical channel model that captures the inherent sparsity of XL-MIMO channels. Leveraging the channel’s sparsity in the joint AD domain, the CE is approached as a task of reconstructing sparse signals. Anchored in this framework, we first propose a compressed sensing algorithm to acquire a preliminary channel estimate. Harnessing the powerful implicit prior learning capability of generative artificial intelligence (GenAI), we further propose a GenAI-based approach to refine the estimated channel. Specifically, we introduce the preliminary estimated channel as side information, and derive the evidence lower bound (ELBO) of the log-marginal distribution of the target NF channel conditioned on the preliminary estimated channel, which serves as the optimization objective for the proposed generative diffusion model (GDM). Additionally, we introduce a more generalized version of the GDM, the non-Markovian GDM (NM-GDM), to accelerate the sampling process, achieving an approximately tenfold enhancement in sampling efficiency. Experimental results indicate that the proposed approach is capable of offering substantial performance gain in CE compared to existing benchmark schemes within NF XL-MIMO systems. Furthermore, our approach exhibits enhanced generalization capabilities in both the NF or far-field (FF) regions.},
  keywords={Noise measurement;Channel estimation;Antenna arrays;Training;Accuracy;OFDM;Noise reduction;Noise;Gaussian distribution;6G mobile communication;XL-MIMO;near-field;channel refinement;channel estimation;conditional generative model},
  doi={10.1109/TCCN.2025.3566047},
  ISSN={2332-7731},
  month={},}@ARTICLE{10384606,
  author={Shen, Yifei and Shao, Jiawei and Zhang, Xinjie and Lin, Zehong and Pan, Hao and Li, Dongsheng and Zhang, Jun and Letaief, Khaled B.},
  journal={IEEE Communications Magazine}, 
  title={Large Language Models Empowered Autonomous Edge AI for Connected Intelligence}, 
  year={2024},
  volume={62},
  number={10},
  pages={140-146},
  abstract={The evolution of wireless networks gravitates toward connected intelligence, a concept that envisions seamless interconnectivity among humans, objects, and intelligence in a hyper-connected cyber-physical world. Edge artificial intelligence (Edge AI) is a promising solution to achieve connected intelligence by delivering high-quality, low-latency, and privacy-preserving AI services at the network edge. This article presents a vision of autonomous edge AI systems that automatically organize, adapt, and optimize themselves to meet users' diverse requirements, leveraging the power of large language models (LLMs), that is, generative pretrained transformer (GPT). By exploiting the powerful abilities of GPT in language understanding, planning, and code generation, as well as incorporating classic wisdom such as task-oriented communication and edge federated learning, we present a versatile framework that efficiently coordinates edge AI models to cater to users' personal demands while automatically generating code to train new models in a privacy-preserving manner. Experimental results demonstrate the system's remarkable ability to accurately comprehend user demands, efficiently execute AI models with minimal cost, and effectively create high-performance AI models at edge servers.},
  keywords={Artificial intelligence;Codes;Sensors;Adaptation models;Task analysis;Servers;Computational modeling;Large language models},
  doi={10.1109/MCOM.001.2300550},
  ISSN={1558-1896},
  month={October},}@ARTICLE{8764602,
  author={Zhang, Mingjin and Wang, Nannan and Li, Yunsong and Gao, Xinbo},
  journal={IEEE Transactions on Cybernetics}, 
  title={Bionic Face Sketch Generator}, 
  year={2020},
  volume={50},
  number={6},
  pages={2701-2714},
  abstract={Face sketch synthesis is a crucial technique in digital entertainment. However, the existing face sketch synthesis approaches usually generate face sketches with coarse structures. The fine details on some facial components fail to be generated. In this paper, inspired by the artists during drawing face sketches, we propose a bionic face sketch generator. It includes three parts: 1) a coarse part; 2) a fine part; and 3) a finer part. The coarse part builds the facial structure of a sketch by a generative adversarial network in the U-Net. In the middle part, the noise produced by the coarse part is erased and the fine details on the important face components are generated via a probabilistic graphic model. To compensate for the fine sketch with distinctive edge and area of shadows and lights, we learn a mapping relationship at the high-frequency band by a convolutional neural network in the finer part. The experimental results show that the proposed bionic face sketch generator can synthesize the face sketch with more delicate and striking details, satisfy the requirement of users in the digital entertainment, and provide the students with the coarse, fine, and finer face sketch copies when learning sketches. Compared with the state-of-the-art methods, the proposed approach achieves better results in both visual effects and quantitative metrics.},
  keywords={Face;Generators;Learning systems;Entertainment industry;Probabilistic logic;Graphics;Biological system modeling;Bionic face sketch generator;convolutional neural network;facial entertainment;generative adversarial network (GAN);probabilistic graphic model},
  doi={10.1109/TCYB.2019.2924589},
  ISSN={2168-2275},
  month={June},}@INPROCEEDINGS{10422102,
  author={Samadi, Amir and Shirian, Amir and Koufos, Konstantinos and Debattista, Kurt and Dianati, Mehrdad},
  booktitle={2023 IEEE 26th International Conference on Intelligent Transportation Systems (ITSC)}, 
  title={SAFE: Saliency-Aware Counterfactual Explanations for DNN-based Automated Driving Systems}, 
  year={2023},
  volume={},
  number={},
  pages={5655-5662},
  abstract={The explainability of Deep Neural Networks (DNNs) has recently gained significant importance especially in safety-critical applications such as automated/autonomous vehicles, a.k.a. automated driving systems. CounterFactual (CF) explanations have emerged as a promising approach for interpreting the behaviour of black-box DNNs. A CF explainer identifies the minimum modifications in the input that would alter the model's output to its complement. In other words, it computes the minimum modifications required to cross the model's decision boundary. Current deep generative CF models often work with user-selected features rather than focusing on the discriminative features of the black-box model. Consequently, such CF examples may not necessarily lie near the decision boundary, thereby contradicting the definition of CFs. To address this issue, we propose in this paper a novel approach that leverages saliency maps to generate more informative CF explanations. Our approach guides a Generative Adversarial Network based on the most influential features of the input of the black-box model to produce CFs near the decision boundary. We evaluate the performance using a real-world dataset of driving scenes, BDD100k, and demonstrate its superiority over several baseline methods in terms of well-known CF metrics, including proximity, sparsity and validity. Our work contributes to the ongoing efforts to improve the interpretability of DNNs and provides a promising direction for generating more accurate and informative CF explanations. The source codes are available at: https://github.com/Amir-Samadi//Saliency_Aware_CF.},
  keywords={Measurement;Visualization;Computational modeling;Source coding;Closed box;Machine learning;Predictive models},
  doi={10.1109/ITSC57777.2023.10422102},
  ISSN={2153-0017},
  month={Sep.},}@INBOOK{10237054,
  author={Malof, Jordan M. and Ren, Simiao and Padilla, Willie J.},
  booktitle={Advances in Electromagnetics Empowered by Artificial Intelligence and Deep Learning}, 
  title={Forward and Inverse Design of Artificial Electromagnetic Materials}, 
  year={2023},
  volume={},
  number={},
  pages={345-370},
  abstract={Deep learning, and deep neural networks (DNNs) in particular, has recently demonstrated impressive results for the design of artificial electromagnetic materials (AEMs). In this context AEMs are materials whose properties derive primarily from their structure, and includes metamaterials, metasurfaces, plasmonics, and photonic crystals. We discuss two major paradigms that are commonly employed for AEM design: forward design and inverse design. In each case we formulate the design problem, describe major fundamental challenges of design within that paradigm, and how DNNs have recently been used to overcome these challenges. We also discuss the DNN models typically employed for forward and inverse design, respectively, and a comparison of their performance and limitations is discussed. We conclude by detailing some important outstanding issues of DNN design of AEMs and present an outlook of this exciting field.},
  keywords={Metasurfaces;Electromagnetic scattering;Numerical models;Magnetic materials;Plasmons;Media;Flyback transformers},
  doi={10.1002/9781119853923.ch11},
  ISSN={},
  publisher={IEEE},
  isbn={9781119853909},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10237054},}@ARTICLE{9765839,
  author={Huo, Jing and Liu, Xiangde and Li, Wenbin and Gao, Yang and Yin, Hujun and Luo, Jiebo},
  journal={IEEE Transactions on Image Processing}, 
  title={CAST: Learning Both Geometric and Texture Style Transfers for Effective Caricature Generation}, 
  year={2022},
  volume={31},
  number={},
  pages={3347-3358},
  abstract={Given a photo of a subject, ability to generate a caricature image that captures distinct characteristics of the subject but with certain exaggeration of their prominent features is of fundamental importance to image processing and facial recognition. There are two main challenges in this task: shape exaggeration and style transfer. The former morphs and exaggerates key facial features of the subject, while the latter generates caricature images in a certain artistic style. In this paper, we propose a CAricature Style Transfer (CAST) framework for caricature generation. There are two modules in the proposed framework. The first is a geometric warping module. Different from the existing style transfer methods, we incorporate the Whitening and Coloring Transformation (WCT) in the geometric style transfer. The WCT is learned on photo and caricature landmarks or the caricature landmark space of a specific artist and is capable of transforming input photo landmarks to caricature landmarks. The second module is a texture style rendering module. We propose a new style transfer method by considering a semantic region-aligned style transfer via affinity constraint. Given a reference caricature image as the style reference, this module is capable of transferring styles between the same or similar semantic regions in caricatures and photos. Furthermore, it can transfer visual attributes of the reference caricatures (such as mouth shape and expressions) to the output caricatures. Experiments have shown desirable effects of the proposed method in transferring both the geometric and artistic texture styles of caricatures. Both qualitative and quantitative results show that the CAST framework is more effective compared than the state-of-the-art caricature generation methods.},
  keywords={Shape;Semantics;Faces;Covariance matrices;Task analysis;Generative adversarial networks;Face recognition;Style transfer;caricature generation;semantic alignment},
  doi={10.1109/TIP.2022.3154238},
  ISSN={1941-0042},
  month={},}@ARTICLE{10804065,
  author={Sai, Siva and Prasad, Manish and Dashore, Garima and Chamola, Vinay and Sikdar, Biplab},
  journal={IEEE Consumer Electronics Magazine}, 
  title={On-Device Generative AI: The Need, Architectures, and Challenges}, 
  year={2025},
  volume={14},
  number={4},
  pages={21-32},
  abstract={The area of Generative Artificial Intelligence (GenAI) is rapidly expanding, as seen by the regular release of new models and applications every few months. While these GenAI models have impressive capabilities, their computational intensity has presented issues, especially in applications demanding low latency. Hence, substantial research is being conducted to develop ways to scale down these models so that they may be used for on-device computing on edge devices. Examining successful examples of GenAI models implemented on mobile devices with minimum latency becomes critical in understanding the practical consequences of these breakthroughs. Notable instances, such as the deployment of diffusion-based GenAI models on flagship smartphones like Samsung S23 Ultra and iPhone 14, demonstrate the possibility and promise of bringing GenAI applications to consumers’ fingertips. We further analyze and find out the approaches and strategies that make these on-device deployments successful.},
  keywords={Computational modeling;Data models;Adaptation models;Optimization;Training;Graphics processing units;Convolutional neural networks;Consumer electronics;Computational efficiency;Tensors;Generative AI},
  doi={10.1109/MCE.2024.3518761},
  ISSN={2162-2256},
  month={July},}@ARTICLE{10872872,
  author={He, Long and Sun, Geng and Niyato, Dusit and Du, Hongyang and Mei, Fang and Kang, Jiawen and Debbah, Mérouane and Han, Zhu},
  journal={IEEE Wireless Communications}, 
  title={Generative AI for Game Theory-Based Mobile Networking}, 
  year={2025},
  volume={32},
  number={1},
  pages={122-130},
  abstract={With the continuous advancement of network technology, various emerging complex networking optimization problems have created a wide range of applications utilizing game theory. However, since game theory is a mathematical framework, game theory-based solutions often rely heavily on the experience and knowledge of human experts. Recently, the remarkable advantages exhibited by generative artificial intelligence (GAI) have gained widespread attention. In this work, we propose a novel GAI-enabled game theory solution that combines the powerful reasoning and generation capabilities of GAI with the design and optimization of mobile networking. Specifically, we first outline the game theory and key technologies of GAI and explore the advantages of combining GAI with game theory. Then, we review the contributions and limitations of existing research and demonstrate the potential application values of GAI applied to game theory in mobile networking. Subsequently, we develop a large language model (LLM)-enabled game theory framework to realize this combination and demonstrate the effectiveness of the proposed framework through a case study in secured UAV networks. Finally, we provide several directions for future extensions.},
  keywords={Generative AI;Reviews;Large language models;Autonomous aerial vehicles;Cognition;Game theory;Optimization},
  doi={10.1109/MWC.007.2400133},
  ISSN={1558-0687},
  month={February},}
