@INPROCEEDINGS{10556223,
  author={Olson, Lauren},
  booktitle={2024 IEEE/ACM 3rd International Conference on AI Engineering – Software Engineering for AI (CAIN)}, 
  title={Custom Developer GPT for Ethical AI Solutions}, 
  year={2024},
  volume={},
  number={},
  pages={282-283},
  abstract={The main goal of this project is to create a new software artefact: a custom Generative Pre-trained Transformer (GPT) for developers to discuss and solve ethical issues through AI engineering. This conversational agent will provide developers with practical application on (1) how to comply with legal frameworks which regard AI systems (like the EU AI Act [8] and GDPR [11]) and (2) present alternate ethical perspectives to allow developers to understand and incorporate alternate moral positions. In this paper, we provide motivation for the need of such an agent, detail our idea and demonstrate a use case. The use of such a tool can allow practitioners to engineer AI solutions which meet legal requirements and satisfy diverse ethical perspectives.},
  keywords={Ethics;Law;Transformers;Software;Artificial intelligence;Software engineering;generative AI;GPT;ethics;software;development},
  doi={},
  ISSN={},
  month={April},}@ARTICLE{10967257,
  author={Ko, Kanghyeok and Kim, Sungyup and Lee, Minhyeok},
  journal={IEEE Access}, 
  title={Zero-Shot 3D Scene Representation With Invertible Generative Neural Radiance Fields}, 
  year={2025},
  volume={13},
  number={},
  pages={68561-68576},
  abstract={Generative Neural Radiance Fields (NeRFs) have recently enabled efficient synthesis of 3D scenes by training on unposed real image sets. However, existing methods for generating multi-view images of specific input images have limitations, such as requiring camera parameters or additional components for estimating them. In this paper, we propose ZIGNeRF, a novel learning-based approach for zero-shot 3D Generative Adversarial Network (GAN) inversion that generates multi-view images from a single input image without requiring camera parameters. Our method introduces a novel inverter that maps out-of-distribution images into the latent space of the 3D generator without needing additional training steps. We demonstrate the efficacy of ZIGNeRF on multiple real-world image datasets, including Cats, AFHQ, CelebA-HQ, CompCars, and CUB-200-2011. For example, ZIGNeRF achieves an FID of 14.77 for face image generation when trained on the CelebA-HQ dataset. Furthermore, ZIGNeRF is capable of performing 3D operations such as 360-degree rotation and spatial translations by disentangling objects from the background. It can also generate style-mixed images by combining characteristics from two distinct input images, which is a pioneering attempt in 3D-scene synthesis. Our approach opens up new possibilities for flexible and controllable 3D image generation from real-world data.},
  keywords={Three-dimensional displays;Neural radiance field;Cameras;Training;Solid modeling;Generative adversarial networks;Computational modeling;Inverters;Generators;Image reconstruction;Neural radiance fields;3D-scene generation;generative adversarial networks;neural rendering;generative artificial intelligence},
  doi={10.1109/ACCESS.2025.3561923},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11047944,
  author={Huang, Wenguo and Yi, Jin and Liu, Ziyao and Zhou, Wenjing},
  booktitle={2025 5th International Conference on Artificial Intelligence and Industrial Technology Applications (AIITA)}, 
  title={MLLMs for Versatile Scene Understanding: Towards Embodied Intelligent Surgical Robots}, 
  year={2025},
  volume={},
  number={},
  pages={1300-1303},
  abstract={In recent years, the integration of robotics and artificial intelligence has significantly advanced the field of surgical automation. However, existing surgical robotic systems often rely on fixed-resolution imaging and struggle to dynamically adapt to the complexities of surgical environments. To address these limitations, this research explores the application of Multimodal Large Language Models (MLLMs) in surgical scene understanding, enabling real-time adaptive resolution adjustment for robotic-assisted surgery. Our approach leverages a combination of Graph Neural Networks (GNNs) and Vision-Language Large Models (VLLMs) to enhance robotic perception and decision-making. By modeling surgical instruments, anatomical structures, and their interactions as a spatiotemporal scene graph, the system can anticipate critical surgical actions and adjust visual resolution accordingly. This dynamic framework ensures high-resolution visualization in areas requiring precision, such as tissue dissection, while optimizing computational resources in less critical regions. Additionally, our method integrates multimodal sensory inputs, including real-time visual, auditory, and biological signals, to improve situational awareness and risk assessment. By incorporating Video Question Answering (VideoQA) frameworks and Chain-of-Thought (CoT) reasoning, our proposed system enhances surgical robots' cognitive capabilities, allowing for context-aware decision-making. The adaptive resolution mechanism not only improves visualization and surgical accuracy but also contributes to reducing surgeon fatigue and improving overall procedural efficiency. This research represents a step toward embodied intelligent surgical robots capable of real-time multimodal reasoning, with potential applications across various surgical domains.},
  keywords={Visualization;Image resolution;Medical robotics;Large language models;Computational modeling;Decision making;Surgery;Real-time systems;Graph neural networks;Signal resolution;Multimodal Large Language Models;Embodied Intelligence;Real-time Local Adaptation;Robotic Surgery Automation},
  doi={10.1109/AIITA65135.2025.11047944},
  ISSN={},
  month={March},}@INPROCEEDINGS{10463397,
  author={Chemudupati, Sathvik},
  booktitle={2024 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={A Dynamic Machine Learning Model for Accelerated Oil Spill Remediation}, 
  year={2024},
  volume={},
  number={},
  pages={182-187},
  abstract={134 million gallons of oil were spilled into the Gulf of Mexico after the explosion of an offshore oil rig in 2010. Known as the Deepwater Horizon spill, this event crippled marine environments spanning thousands of miles and killed countless sea creatures already deemed at risk of extinction. Over 10 years and billions of dollars later, efforts to clean up this spill continue. Rapid mitigation is necessary to prevent future incidents from spiraling out of control. After an oil spill, various organizations must decide how to remediate it. To do so, there are close to a dozen methods employed today. Each approach has its pros and cons and must be carefully selected based on spill conditions. Some techniques (such as in-situ burning of the oil slick off the water) are highly effective but have environmentally degrading effects. Choosing a suboptimal remediation tactic can lead to billions of wasted dollars, and more importantly, leftover oil that continues to harm the environment. During this study, an artificial intelligence (AI) based system using a convolutional neural network (CNN) has been developed to prescribe the most effective oil spill countermeasure. Findings were used to develop a mobile application to further expedite oil spill cleanup and recovery in real time. After being tested at various configurations, the machine learning model achieved a maximum average accuracy of 93.1 % after 16.19 seconds of training time with 10 epochs and a batch-size of 16. This work significantly enhances our ability to quickly remediate oil spills, protecting the environment from this disastrous calamity.},
  keywords={Training;Adaptation models;Oils;Neural networks;Machine learning;Organizations;Predictive models;Oil Spill Remediation (OSR);Artificial Intelligence (AI);Machine Learning (ML);Deep Learning;Convolutional Neural Network (CNN);Generative Adversarial Network (GAN);Oil booms;In-situ burning;dispersants;bioremediation;sorbents},
  doi={10.1109/ICAIIC60209.2024.10463397},
  ISSN={2831-6983},
  month={Feb},}@INPROCEEDINGS{11070936,
  author={Choudhry, Anurag and Singh, Kumar Avishek},
  booktitle={2025 4th OPJU International Technology Conference (OTCON) on Smart Computing for Innovation and Advancement in Industry 5.0}, 
  title={Gen AI-Powered Applications Modernization}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Application modernization is the process of transforming legacy software systems to meet evolving business requirements, such as improving performance, scalability, and user experience. This often involves re-platforming, re-hosting, or rearchitecting applications to leverage the latest technological advancements such as artificial intelligence, cloud computing, and microservices.Generative AI (Gen AI), a subset of artificial intelligence that focuses on creating new content (such as text, images, and code), is revolutionizing numerous areas including the application modernization landscape. By automating tasks, enhancing creativity, and providing data-driven insights, generative AI offers unprecedented opportunities for businesses to modernize their applications faster and more efficiently. This paper explores the integration of generative AI in application modernization, examining its role and benefits, strategies, challenges, and future trends.},
  keywords={Cloud computing;Technological innovation;Generative AI;Scalability;Microservice architectures;Software systems;Market research;User experience;Security;Creativity;application modernization;generation ai;app mod;gen ai;cloud native services;modernization methodology;modernization strategies},
  doi={10.1109/OTCON65728.2025.11070936},
  ISSN={},
  month={April},}@INPROCEEDINGS{9680760,
  author={Bang, Junseong and Kim, Sineae and Nam, Jang Won and Yang, Dong-Geun},
  booktitle={2021 International Conference on Platform Technology and Service (PlatCon)}, 
  title={Ethical Chatbot Design for Reducing Negative Effects of Biased Data and Unethical Conversations}, 
  year={2021},
  volume={},
  number={},
  pages={1-5},
  abstract={AI technology is being introduced into various public and private service domains, transforming existing computing systems or creating new ones. While AI technologies can provide benefits to humans and society, the unexpected consequences (e.g., malfunctions) of AI systems can cause social losses. For this reason, research on ethical design for the development of AI-based systems is becoming important. In this paper, from existing studies on AI ethics, general guidelines such as transparency, explainability, predictability, accountability, fairness, privacy, and control for the ethical design of AI systems are reviewed. And, based on the ethical design guidelines, we discuss ethical design to reduce the negative effects of biased data and unethical dialogues in AI-based conversational chatbots.},
  keywords={Ethics;Privacy;Systematics;Chatbots;Social factors;Stakeholders;Artificial intelligence;conversational chatbot;ethical design;framework},
  doi={10.1109/PlatCon53246.2021.9680760},
  ISSN={},
  month={Aug},}@ARTICLE{9494720,
  author={Huang, Yixiang and Wu, Ming and Guo, Jun and Zhang, Chuang and Xu, Mengqiu},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={A Correlation Context-Driven Method for Sea Fog Detection in Meteorological Satellite Imagery}, 
  year={2022},
  volume={19},
  number={},
  pages={1-5},
  abstract={Sea fog detection is a challenging and essential issue in satellite remote sensing. Although conventional threshold methods and deep learning methods can achieve pixel-level classification, it is difficult to distinguish ambiguous boundaries and thin structures from the background. Considering the correlations between neighbor pixels and the affinities between superpixels, a correlation context-driven method for sea fog detection is proposed in this letter, which mainly consists of a two-stage superpixel-based fully convolutional network (SFCNet), named SFCNet. A fully connected Conditional Random Field (CRF) is utilized to model the dependencies between pixels. To alleviate the problem of high cloud occlusion, an attentive Generative Adversarial Network (GAN) is implemented for image enhancement by exploiting contextual information. Experimental results demonstrate that our proposed method achieves 91.65% mIoU and obtains more refined segmentation results, performing well in detecting fogs in small, broken bits and weak contrast thin structures, as well as detects more obscured parts.},
  keywords={Feature extraction;Image segmentation;Generative adversarial networks;Remote sensing;Correlation;Satellites;Semantics;Deep learning;satellite imagery;sea fog detection;superpixel},
  doi={10.1109/LGRS.2021.3095731},
  ISSN={1558-0571},
  month={},}@INBOOK{10964449,
  author={Bergeret, Olivier and Abbasi, Asif and Farvault, Joel},
  booktitle={GenAI on AWS: A Practical Approach to Building Generative AI Applications on AWS}, 
  title={GenAI on AWS&#xae;}, 
  year={2025},
  volume={},
  number={},
  pages={i-xxii},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394281305},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10964449},}@ARTICLE{10557693,
  author={Yang, Wanting and Xiong, Zehui and Quek, Tony Q. S. and Shen, Xuemin},
  journal={IEEE Network}, 
  title={Streamlined Transmission: A Semantic-Aware XR Deployment Framework Enhanced by Generative AI}, 
  year={2024},
  volume={38},
  number={6},
  pages={29-38},
  abstract={In the era of 6G, featuring compelling visions of digital twins and metaverses, Extended Reality (XR) has emerged as a vital conduit connecting the digital and physical realms, garnering widespread interest. Ensuring a fully immersive wireless XR experience stands as a paramount technical necessity, demanding the liberation of XR from the confines of wired connections. In this paper, we first introduce the technologies applied in the wireless XR domain, delve into their benefits and limitations, and highlight the ongoing challenges. We then propose a novel deployment framework for a broad XR pipeline, termed “GeSa-XRF”, inspired by the core philosophy of Semantic Communication (SemCom) which shifts the concern from “how” to transmit to “what” to transmit. Particularly, the framework comprises three stages: data collection, data analysis, and data delivery. In each stage, we integrate semantic awareness to achieve streamlined transmission and employ Generative Artificial Intelligence (GAI) to achieve collaborative refinements. For the data collection of multi-modal data with differentiated data volumes and heterogeneous latency requirements, we propose a novel SemCom paradigm based on multi-modal fusion and separation and a GAI-based robust superposition scheme. To perform a comprehensive data analysis, we employ multi-task learning to perform the prediction of field of view and personalized attention and discuss the possible preprocessing approaches assisted by GAI. Lastly, for the data delivery stage, we present a semantic-aware multicast-based delivery strategy aimed at reducing pixel level redundant transmissions and introduce the GAI collaborative refinement approach. The performance gain of the proposed GeSa-XRF is preliminarily demonstrated through a case study.},
  keywords={X reality;Semantic communication;Data collection;Data analysis;Transcoding;Artificial intelligence;Generative AI;Transcoding;Multicast communication;Wireless extended reality;generative artificial intelligence;semantic communication;transcoding;multicast},
  doi={10.1109/MNET.2024.3414398},
  ISSN={1558-156X},
  month={Nov},}@ARTICLE{11024158,
  author={Zhang, Chuan and You, You and Wang, Naigang and Park, Jongsun and Zhang, Li},
  journal={IEEE Journal on Emerging and Selected Topics in Circuits and Systems}, 
  title={Generative AI Through CAS Lens: An Integrated Overview of Algorithmic Optimizations, Architectural Advances, and Automated Designs}, 
  year={2025},
  volume={15},
  number={2},
  pages={149-185},
  abstract={Generative artificial intelligence (GenAI) has emerged as a pivotal focus in global innovation agendas, revealing transformative potential that extends beyond technological applications to reshape diverse societal domains. Given the fundamental dependency of GenAI deployment on circuits and systems (CAS), a co-evolutionary approach integrating both technological paradigms becomes imperative. This synergistic framework confronts three interrelated challenges: 1) developing deployment-ready GenAI algorithms, 2) engineering implementation-efficient CAS architectures, and 3) leveraging GenAI for autonomous CAS designs - each representing critical innovations vectors. Given the rapid advancement of GenAI-CAS technologies, a comprehensive synthesis has become an urgent priority across academia and industry. Consequently, this timely review systematically analyzes current advancements, provides integrative perspectives, and identifies emerging research trajectories. This review endeavors to serve both AI and CAS communities, thereby catalyzing an innovation feedback loop: GenAI-optimized CAS architectures in turn accelerate GenAI evolution through algorithm-hardware co-empowerment.},
  keywords={Computational modeling;Optimization;Circuits and systems;Artificial intelligence;Hardware;Biological system modeling;Computer architecture;Adaptation models;Integrated circuit modeling;Generative adversarial networks;Generative artificial intelligence (GenAI);circuits and systems (CAS);algorithms;architectures;autonomous design},
  doi={10.1109/JETCAS.2025.3575272},
  ISSN={2156-3365},
  month={June},}@INPROCEEDINGS{10913095,
  author={Kurniawan, Priscilla Anthonio and Veny and Chau, Michelle and Gui, Anderes},
  booktitle={2024 International Conference on Intelligent Cybernetics Technology & Applications (ICICyTA)}, 
  title={Unveiling Generative Adversarial Network Adoption in Design Processes}, 
  year={2024},
  volume={},
  number={},
  pages={666-671},
  abstract={With rapid advancements in artificial intelligence, Generative Adversarial Network (GAN) technology is increasingly embedded in designers' workflows, supporting a range of tasks from basic to complex. Despite its potential, the adoption of GAN technology in design processes faces challenges such as user acceptance and the understanding of its capabilities. In order to address this gap and challenge, this research analyzed responses from 376 valid participants (from an initial 439), using Partial Least Squares Structural Equation Modeling (PLS-SEM). Eight hypotheses were tested, which four were accepted and the rest rejected. Results indicated that perceived usefulness, ease of use, task-technology fit, and computer anxiety do not significantly impact behavioral intention toward GAN adoption. In contrast, social influence, perceived self-efficacy, and perceived enjoyment showed a positive impact on adoption intentions. Additionally, this study has found that Generation Z respondents are particularly influenced by social trends and enjoyment, which are factors that often outweigh traditional motivators like ease of use. These findings underscore the importance of community influence and enjoyment in driving technology adoption among younger designers. In the end, this study highlights important factors for integrating GAN technology into creative processes to provide insights, and foster innovation for technology developers, educators, and designers.},
  keywords={Industries;Productivity;Technological innovation;Anxiety disorders;Generative adversarial networks;Market research;Mathematical models;Stakeholders;Artificial intelligence;Faces;artificial intelligence;design processes;generative adversarial network;user acceptance},
  doi={10.1109/ICICYTA64807.2024.10913095},
  ISSN={},
  month={Dec},}@INBOOK{10951019,
  author={Reddy, C. Kishor Kumar and Reddy, Patlolla Sathvika and Pilly, Ashritha and Doss, Srinath},
  booktitle={Artificial Intelligence-Enabled Businesses: How to Develop Strategies for Innovation}, 
  title={Transformative Effects of Smarter Chatbots}, 
  year={2025},
  volume={},
  number={},
  pages={333-350},
  abstract={Summary <p>Conversational artificial intelligence (AI) systems have witnessed remarkable advancements in recent years with ChatGPT (chat generative pretrained transformer), an advanced language model developed by Open AI emerging as a prominent model for producing human&#x2010;like responses in natural language conversations. ChatGPT is built on the GPT&#x2010;3.5 architecture and has been trained on a vast corpus of diverse textual data. The core objective of this proposed chapter is to analyze the performance of ChatGPT and also to know about the effectiveness of ChatGPT in conversational contexts, highlighting its potential applications as well as the challenges it presents. Furthermore, this proposed chapter investigates the limitations and challenges faced by ChatGPT. This chapter also provides an in&#x2010;depth analysis of ChatGPT, highlighting its strengths, limitations, and broader societal implications. These include issues related to biased and unsafe responses, the model's sensitivity to input phrasing, and its susceptibility of generating incorrect information. Overall, this research chapter contributes to the understanding of ChatGPT's capabilities and limitations.</p>},
  keywords={Chatbots;Artificial intelligence;Ethics;Virtual assistants;Focusing;Accuracy;Medical diagnostic imaging;Training;Programming profession;Plagiarism},
  doi={10.1002/9781394234028.ch18},
  ISSN={},
  publisher={Wiley},
  isbn={9781394234004},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951019},}@ARTICLE{10707288,
  author={Smolin, Mikhail},
  journal={IEEE Access}, 
  title={GenCoder: A Generative AI-Based Adaptive Intra-Vehicle Intrusion Detection System}, 
  year={2024},
  volume={12},
  number={},
  pages={150651-150663},
  abstract={With the rapid expansion of the vehicular cybersecurity (VCS) market and the increasing sophistication of cyberthreats, developing an adaptive intra-vehicular intrusion detection system (IDS) is crucial. This paper introduces GenCoder, a generative artificial intelligence (GenAI)-based IDS that uniquely addresses the dynamic and evolving nature of vehicular cyberthreats. GenCoder combines a five-layer deep neural network (DNN) with a variational autoencoder (VAE), overseen by a novel communication layer known as the GenCoder layer. This system dynamically adapts to new intrusion patterns by generating and utilizing new training data when deviations from known patterns are detected. The generated samples have a Shannon entropy (SE) value of 1.65 bits for four classes, indicating standard variety among the synthetic data. GenCoder demonstrates exceptional adaptability, pushing the accuracy, precision, recall, and F1-score from 84.79%, 83.58%, 83.70%, and 83.64% to 92.19%, 90.12%, 90.44%, and 90.28%, respectively, after introducing 50% feature deformation to testing data. The novel concept of an adaptive intra-vehicular IDS, the innovative GenCoder layer that establishes seamless communication among the DNN, the VAE, and the dataset, as well as the unique assessment strategies of adaptability make this research exceptional with the potential to create a new dimension in automotive IDS research.},
  keywords={Computer crime;Automobiles;Principal component analysis;Intrusion detection;Adaptive systems;Protocols;NSL-KDD;Vehicle dynamics;Support vector machines;Artificial neural networks;Artificial intelligence;Generative AI;Encoding;Intrusion detection;Adaptive intrusion detection;automotive cybersecurity;deep neural network;GenCoder layer;generative artificial intelligence;variational autoencoder;vehicular intrusion detection system},
  doi={10.1109/ACCESS.2024.3476177},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10788265,
  author={Yong, Li and Dan, Xiong},
  booktitle={2024 International Conference on Computers, Information Processing and Advanced Education (CIPAE)}, 
  title={Research on Intelligent Generation Algorithm of AIGC in Digital Media Content Creation}, 
  year={2024},
  volume={},
  number={},
  pages={874-878},
  abstract={This paper aims to explore how AIGC (Generative Artificial Intelligence) drives innovation in digital media content creation and proposes a new content generation framework based on Generative Multiple Adversarial steganography (GMASS). By integrating advanced machine learning models, the framework enables efficient generation and editing of image, video and audio content, while ensuring content security and privacy. Firstly, this paper summarizes the basic principle of AIGC and its application in the field of digital media, and points out its potential in improving creative efficiency and reducing production cost. Then, aiming at the challenges of the existing content generation technology in privacy disclosure and copyright infringement, the GMASS algorithm is proposed. The algorithm makes use of the characteristics of adversarial network to generate content and embed an imperceptible information hiding layer to effectively prevent unauthorized copying and tampering. In order to verify the effectiveness of the proposed framework, detailed system modeling and simulation experiments are carried out in this paper. The experimental results show that the GMASS algorithm can significantly improve the content security while maintaining the quality of the generated content. In addition, by comparing with traditional steganography techniques, GMASS's superior performance in resisting various attack methods and media content generation frameworks is demonstrated.},
  keywords={Steganography;Privacy;Visualization;Technological innovation;Generative AI;Production;Media;Copyright protection;Systems modeling;Security;Generative artificial intelligence (AIGC);digital media content creation;generative multiple adversarial steganography;system modeling;simulation},
  doi={10.1109/CIPAE64326.2024.00166},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10733560,
  author={Samaras, Georgios and Mertiri, Marinela and Xezonaki, Maria-Evgenia and Theodorou, Vasileios and Chartsias, Panteleimon Konstantinos and Bozios, Theodoros},
  booktitle={2024 IEEE Symposium on Computers and Communications (ISCC)}, 
  title={Democratizing Predictive Analytics with Generative Artificial Intelligence towards AI-Native Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In the rapidly advancing era of Artificial Intelligence (AI), the transformative force of foundation models has streamlined the automated generation of multi-modal content, corresponding to user intents. At the same time, Machine Learning (ML), particularly Deep Learning (DL), has achieved state-of-the-art performance in optimization and inference tasks of various domains, including telecommunications. However, the segregation of technological domains poses challenges to the integration of powerful AI/ML capabilities towards realizing the vision of "AI-native" networks, such as future 6G networks that will provide ubiquitous intelligence across their infrastructure and service planes and will seamlessly adapt and evolve to support new classes of applications. This paper introduces Auto-TimeGPT, a handsfree Automated ML (AutoML) solution, extending the profound impact of Generative AI (GenAI) for Time Series Analysis, to networks and communications. The contribution includes an out-of-the-box zero-shot approach for anomaly detection and Time Series Forecasting (TSF) which is particularly useful for the Edge-Cloud orchestration framework CODECO, comprehensive in and out-of-domain evaluation, and a limitations analysis. Evaluation results across diverse real-world datasets demonstrate competitive performance with cutting-edge approaches based on Large Language Models (LLMs) and DL models, generalization and optimization ability and effective anomaly detection. The proposed framework democratizes AI analytics in communication and networking domains.},
  keywords={Generative AI;Large language models;Image edge detection;Time series analysis;Force;Telecommunications;Predictive analytics;Forecasting;Optimization;Anomaly detection;Automated Machine Learning;Generative AI;Zero-shot Inference;Internet of Things;Network Automation;TS;6G;AI-native},
  doi={10.1109/ISCC61673.2024.10733560},
  ISSN={2642-7389},
  month={June},}@INPROCEEDINGS{8490429,
  author={Canaan, Rodrigo and Menzel, Stefan and Togelius, Julian and Nealen, Andy},
  booktitle={2018 IEEE Conference on Computational Intelligence and Games (CIG)}, 
  title={Towards Game-based Metrics for Computational Co-Creativity}, 
  year={2018},
  volume={},
  number={},
  pages={1-8},
  abstract={We propose the following question: what game-like interactive system would provide a good environment for measuring the impact and success of a co-creative, cooperative agent? Creativity is often formulated in terms of novelty, value, surprise and interestingness. We review how these concepts are measured in current computational intelligence research and provide a mapping from modern electronic and tabletop games to open research problems in mixed-initiative systems and computational co-creativity. We propose application scenarios for future research, and a number of metrics under which the performance of cooperative agents in these environments will be evaluated.},
  keywords={Creativity;Predictive models;Games;Extraterrestrial measurements;Current measurement;Learning (artificial intelligence);artificial intelligence;cooperative systems;games},
  doi={10.1109/CIG.2018.8490429},
  ISSN={2325-4289},
  month={Aug},}@ARTICLE{10965478,
  author={Lee, In},
  journal={IT Professional}, 
  title={Generative Artificial Intelligence: Project Valuation}, 
  year={2025},
  volume={27},
  number={2},
  pages={42-47},
  abstract={The main purpose of this article is to provide a real options approach to cost–benefit project evaluation for generative artificial intelligence (GAI). Currently, managers are being challenged to justify GAI projects because of the potential but uncertain benefits and high investment costs, but there is a lack of a proper justification model for managers to measure every GAI-enabled opportunity and challenge. Hence, this article presents a typology of GAI projects and discusses cost–benefit perspectives on GAI. Then, this article discusses the real options approach to the valuation of GAI projects, highlighting its advantage over traditional valuation methods in highly fluid technological and regulatory environments.},
  keywords={Generative AI;Measurement uncertainty;Delays;Cost accounting;Contracts;Investment;Cost benefit analysis;Project management;Performance evaluation},
  doi={10.1109/MITP.2025.3534817},
  ISSN={1941-045X},
  month={March},}@INPROCEEDINGS{11081160,
  author={Widjaja, Sugiyanto Yoannatan and Yohannis, Alfa},
  booktitle={2025 International Conference on Smart Computing, IoT and Machine Learning (SIML)}, 
  title={AI-Powered Automatic Question Generation for Teachers}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Indonesia is facing a significant shortage of teachers, particularly in remote areas, due to various contributing factors. This shortage exacerbates disparities in teaching quality and underscores the need for innovative solutions. This study proposes the use of Artificial Intelligence (AI), specifically Generative AI, to automate the creation of diverse test items. The proposed AI-powered tool focuses on generating questions aligned with Indonesia's Minimum Competency Assessment (MCA) in reading literacy and mathematics. By leveraging large language models, natural language processing techniques, and image generation for visual stimuli, the tool aims to support teachers in developing engaging and customized assessments tailored to students' needs. The outcome is expected to be an AI-based tool that not only reduces teacher workload but also improves the quality and effectiveness of student assessments in Indonesia.},
  keywords={Visualization;Image synthesis;Generative AI;Large language models;Education;Machine learning;Question generation;Mathematics;artificial intelligence;question generation;image generation;teacher assistance;minimum competency assessment;indonesia;large language model},
  doi={10.1109/SIML65326.2025.11081160},
  ISSN={},
  month={June},}@ARTICLE{10965479,
  author={Lee, In},
  journal={IT Professional}, 
  title={Generative Artificial Intelligence for Enterprises: Ecosystem, Typology of Applications, and Challenges}, 
  year={2025},
  volume={27},
  number={2},
  pages={28-34},
  abstract={Generative artificial intelligence (GAI) is considered to be one of the most enabling technologies of the Fifth Industrial Revolution. GAI has been used to improve various customer services and internal operations at enterprises and the market for GAI is growing rapidly. In light of the great potential of GAI, this article introduces an ecosystem of the GAI industry and presents a typology of GAI applications used for enterprises. Then this article discusses four challenges to be overcome in adopting GAI.},
  keywords={Industries;Symbiosis;Technological innovation;Ethics;Data privacy;Ecosystems;Government;Fifth Industrial Revolution;Investment;Generative AI;Enterprise resource planning},
  doi={10.1109/MITP.2025.3544261},
  ISSN={1941-045X},
  month={March},}@ARTICLE{10857306,
  author={Tabassum, Aliya and Elmahjub, Ezieddin and Padela, Aasim I. and Zwitter, Andrej and Qadir, Junaid},
  journal={IEEE Open Journal of the Computer Society}, 
  title={Generative AI and the Metaverse: A Scoping Review of Ethical and Legal Challenges}, 
  year={2025},
  volume={6},
  number={},
  pages={348-359},
  abstract={The metaverse, a pioneering digital realm merging virtual and augmented realities with Artificial Intelligence (AI), represents a transformative environment where digital and physical realities converge seamlessly. Generative AI (GenAI) is indispensable in powering the metaverse's dynamic and immersive experiences, enabling the autonomous generation of diverse digital content. Large Language Models (LLMs), as a component of GenAI, play a critical role by facilitating real-time communication, multilingual translation, and personalized interactions, enhancing user engagement in shared virtual spaces. This scoping review explores the interdependence between GenAI and the metaverse and the unique ethical and legal challenges that emerge from their integration. It identifies key ethical and legal issues, such as bias in AI-generated content, misinformation, and data privacy concerns, related to the deployment of GenAI and LLMs, and offers strategic recommendations for addressing these challenges responsibly. Emphasizing the transformative potential of these technologies, this review highlights the necessity of developing tailored ethical and legal frameworks to manage their convergence responsibly, ensuring equitable and sustainable growth within the metaverse.},
  keywords={Metaverse;Ethics;Law;Reviews;Databases;Internet;Generative AI;Translation;Real-time systems;Three-dimensional displays;Ethics;extended reality;generative AI (GenAI);LLMs;metaverse;privacy;regulation;security},
  doi={10.1109/OJCS.2025.3536082},
  ISSN={2644-1268},
  month={},}@INPROCEEDINGS{10962002,
  author={Putjorn, Pruet and Putjorn, Jittasak and Sutumma, Janyawath and Putjorn, Tipsuda and Sangchoey, Thanakrit and Wachirasirodom, Rachakorn and Sangchatkaew, Supparat and Kaewuthai, Kanokwan and Sawasdee, Hathairat and Jitpakdee, Pit and Suksamran, Apalai and Dokchan, Thanawat},
  booktitle={2025 Joint International Conference on Digital Arts, Media and Technology with ECTI Northern Section Conference on Electrical, Electronics, Computer and Telecommunications Engineering (ECTI DAMT & NCON)}, 
  title={Exploring Generative AI for Dynamic Carrying Capacity Assessment in Mountainous and Cave Areas: A Framework Development Approach}, 
  year={2025},
  volume={},
  number={},
  pages={725-730},
  abstract={This study explores the potential of Generative Artificial Intelligence (GenAI) in developing a dynamic framework for assessing tourism carrying capacities in natural destinations, with a specific focus on mountainous and cave areas in Thailand. The proposed framework, termed SAFER (Sustainable Economic Development, Allocating Resources Optimally, Fostering Community Engagement, Enhancing Visitor Satisfaction, and Resource Conservation), integrates GenAI’s advanced capabilities in creating data-driven and adaptive solutions to address the complexities of sustainable tourism management. Unlike traditional AI applications, which emphasize pattern recognition and decision-making, GenAI uniquely enables the creation of predictive and prescriptive tools tailored to specific ecological and cultural contexts. The study employs a mixed-methods approach, involving data collection from 14 pilot sites, stakeholder feedback sessions, and collaborative workshops. These methodologies were critical in refining the SAFER framework and identifying its usability and scalability for diverse tourism settings. By leveraging GenAI’s ability to analyze and generate content dynamically, the framework offers innovative strategies to balance tourism growth with environmental conservation and community welfare. Results highlight the SAFER framework’s applicability in managing tourism’s carrying capacity in sensitive ecosystems, demonstrating how GenAI enhances decision-making processes and visitor management strategies. While the focus of this research is on mountainous and cave regions due to their ecological significance and pressing conservation challenges, the SAFER framework can be adapted to other natural and cultural settings.This study contributes to sustainable tourism research by introducing an adaptable framework that aligns technological innovation with conservation principles, promoting long-term ecological and social well-being. Policymakers, tourism managers, and conservationists can utilize these insights to implement GenAI-driven strategies, fostering resilience and sustainability in tourism management.},
  keywords={Technological innovation;Generative AI;Scalability;Decision making;Refining;Cultural differences;Stakeholders;Usability;Sustainable development;Resilience;HCI;Generative AI;Tourism Environmental Carrying Capacity;Natural Environment Area;Sustainable Tourism;Thailand},
  doi={10.1109/ECTIDAMTNCON64748.2025.10962002},
  ISSN={2768-4644},
  month={Jan},}@INPROCEEDINGS{9514052,
  author={Li, Wanwan},
  booktitle={2021 Fifth World Conference on Smart Trends in Systems Security and Sustainability (WorldS4)}, 
  title={Image Synthesis and Editing with Generative Adversarial Networks (GANs): A Review}, 
  year={2021},
  volume={},
  number={},
  pages={65-70},
  abstract={Recently, as many deep learning models are emerging, deep learning has achieved great success in the field of artificial intelligence(AI). Especially, the Generative adversarial networks (GANs) based on zero-sum game theory has become a new research hot spot in the field of deep learning. The significance of the GAN model is that it can generate realistic data through unsupervised learning. Based on the conceptual and theoretical framework of the generative adversarial network, GANs models and their application result in tremendous success among different areas, especially in image synthesis and editing. This paper visualizes the data structures of various kinds of GANs models in 3D and discusses the variational GAN models with respect to their improvements in the applications. As the GANs have superior learning ability, strong plasticity, great potential for improvement, and a wide application range, this paper prospects the possible applications of the GANs in the near future.},
  keywords={Deep learning;Solid modeling;Three-dimensional displays;Image synthesis;Generative adversarial networks;Data models;Security;Image Synthesis;Image Editing;Neural Networks;Deep Learning;Generative Adversarial Networks},
  doi={10.1109/WorldS451998.2021.9514052},
  ISSN={},
  month={July},}@INPROCEEDINGS{10475111,
  author={Omara, Ahmed and Kantarci, Burak},
  booktitle={2023 IEEE Virtual Conference on Communications (VCC)}, 
  title={Generative Adversarial Networks to Secure Vehicle-to-Microgrid Services}, 
  year={2023},
  volume={},
  number={},
  pages={151-156},
  abstract={As the use of Artificial Intelligence (AI) becomes more prevalent in the cyber-physical systems, there has been a rise in the number of adversarial attacks targeting Machine Learning (ML) models. Therefore, it has become imperative to safeguard ML models against such attacks. Our analysis under a vehicle-to-microgrid service setting shows that adversaries aim to deceive the victim's ML classifier at the network edge to misclassify the incoming energy requests from microgrid users. In this paper, we introduce an AI-powered framework to detect new instances of Adversarial attacks against Vehicle-to-Microgrid (V2M) systems. The proposed detection technique uses a Generative Adversarial Network (GAN) model and ML classifiers to accurately detect adversarial attacks. We test the proposed detection technique under three strategies of adversarial sample generation. Adversaries perform a two-stage adversarial attack beginning with an inference attack followed by an evasion attack against the victim's ML model. In addition, we investigate how the adversaries' knowledge of the victim's ML training dataset impacts the Adversarial Detection Rate (ADR). We assess five access cases to the victim's ML training dataset varying from a white-box to various levels of a gray-box attack. Moreover, we implement an unsupervised ML algorithm (i.e., DBSCAN) as a baseline method. Through simulations, we show that DBSCAN results in an ADR up to 69% and 17% for gray-box and white-box attacks, respectively. On the other hand, our proposed generative approach (i.e., GAN-based) outperforms DBSCAN resulting in an ADR up to 94.6% for the gray-box attack and 30.2% for the white-box attack.},
  keywords={Training;Image edge detection;Training data;Microgrids;Machine learning;Cyber-physical systems;Generative adversarial networks;vehicle-to-microgrid (V2M);machine learning;smart microgrids;cybersecurity;generative adversarial network (GAN);evasion attack;inference attack;vehicle-to-home (V2H)},
  doi={10.1109/VCC60689.2023.10475111},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8900903,
  author={Wakefield, Graham and Ji, Haru Hyunkyung},
  booktitle={2019 IEEE VIS Arts Program (VISAP)}, 
  title={Infranet: A Geospatial Data-Driven Neuro-Evolutionary Artwork}, 
  year={2019},
  volume={},
  number={},
  pages={1-7},
  abstract={“Infranet” is a generative artwork interweaving data visualization and sonification, artificial intelligence, and evolutionary algorithms in a population of artificial life creatures, thriving upon geospatial data of the infrastructure of a city as its sustenance and canvas. Each exhibit of Infranet utilizes public data available on the host city; including Gwangju, South Korea (2018), New York, USA (2019), and Vancouver, Canada (2019). This paper documents the motivations behind the work, its design and subsequent implementation in details. At its heart is the speculative proposition of the data of a city as a habitat for new forms of life. Our design in response utilizes neural networks at individual, as well as population-wide scales, along with horizontal gene transfer and contagion/entrainment as means for the living beings to open-endedly discover the variety in the data habitat.},
  keywords={Urban areas;Art;Geospatial analysis;Data visualization;Neural networks;Artificial intelligence;Ecosystems;Data art;geospatial;generative art;artificial life;artificial intelligence;neural network;neuro-evolution;sonification},
  doi={10.1109/VISAP.2019.8900903},
  ISSN={},
  month={Oct},}@INBOOK{10952401,
  author={Minevich, Mark},
  booktitle={Our Planet Powered by AI: How We Use Artificial Intelligence to Create a Sustainable Future for Humanity}, 
  title={The Future of Work}, 
  year={2024},
  volume={},
  number={},
  pages={33-56},
  abstract={Summary <p>The future of work is merely a prediction of how the work being done, the workplace, and the labor force will progress and evolve in the years to come. This chapter shares important skill sets and jobs we can expect to see develop in the next 10 years. It discusses how these changes will affect the future customer experience and how artificial intelligence (AI) will alter human creativity and experiences. According to Goldman Sachs, ChatGPT is poised to disrupt every major industry and potentially replace over 300 million jobs. Over the next 10 years, 1.2 billion employees worldwide will be affected by the adaptation of automation technologies and AI. Predictive intelligence uses machine learning algorithms and statistical models to analyze past data and make predictions about future outcomes. By leveraging data and analytics, predictive intelligence can help users make informed decisions and forecast the impact of various choices.</p>},
  keywords={Artificial intelligence;Automation;Productivity;Generative AI;Industries;Employment;Companies;Codes;Chatbots;Market research},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394180745},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952401},}@INBOOK{11049702,
  author={},
  booktitle={New Horizons in Artificial Intelligence in Libraries}, 
  title={Generative Artificial Intelligence for Library and Information Professionals}, 
  year={2025},
  volume={},
  number={},
  pages={364-371},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9783111336817},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11049702},}@INPROCEEDINGS{10500172,
  author={Pande, Aarush Kaunteya and Brantley, Preston and Tanveer, Muhammad Hassan and Voicu, Razvan Cristian},
  booktitle={SoutheastCon 2024}, 
  title={From AI to AGI - The Evolution of Real-Time Systems with GPT Integration}, 
  year={2024},
  volume={},
  number={},
  pages={699-707},
  abstract={Generative artificial intelligence (AI), particularly ChatGPT, is revolutionizing various sectors, from exercise applications to accounting software, politics, and pharmaceuticals. As versatile aerial vehicles, drones have broad applications in videography, military operations, and surveying. However, their programming and optimal utilization often require extensive training. This research tackles these challenges by utilizing ChatGPT's sophisticated logic and prompt training features to enable drones to operate autonomously in various settings, ranging from everyday tasks to emergencies like search and rescue missions. Enhancing Microsoft Research's PromptCraft robotics, the project integrates innovative algorithms and GPT-4-Vision, improving command efficiency, speed, and accuracy. This integration also leverages additional sensor data feedback, allowing the drones to process user prompts with enhanced contextual understanding. Initial results show a significant improvement in command response times and accuracy, enabling the drones to interpret and execute complex voice commands in various environments. This paper presents a multimodal framework that enriches the capabilities of voice-controlled robotic systems and broadens the scope of AI applications in real-time systems, laying the groundwork for customized AI-driven systems, including robots tailored for diverse applications and the shift towards AGI.},
  keywords={Training;Chatbots;Robot sensing systems;Real-time systems;Software;Safety;Time factors;Real-Time Systems;Voice Control;Artificial Intelligence;Computer Vision;GPT;Drones;AGI},
  doi={10.1109/SoutheastCon52093.2024.10500172},
  ISSN={1558-058X},
  month={March},}@INPROCEEDINGS{10468754,
  author={Bharath Suhas, K. B. and Sri Krishna, A. P. and B., Karishram and Roopesh, Maddina Sai and Jothi S., Sachithanantha and Teja, Kondepati and Kumar, Anu G. and Nandanan, Krishna},
  booktitle={2024 Fourth International Conference on Advances in Electrical, Computing, Communication and Sustainable Technologies (ICAECT)}, 
  title={Generative AI for Community Empowerment: Transforming Livelihood Opportunities in a Rural Indian Village}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Artificial Intelligence (AI) and Machine Learning (ML) are rapidly emerging technologies that augur revolutionary changes in developing nations. AI and ML can help address challenges in critical areas such as agriculture, healthcare, education, and employment. The challenges and barriers to the widespread adoption of AI and ML technologies in Indian villages were analyzed through participatory approaches from a livelihood perspective. AI implementations were proposed for a real-world case study conducted as part of the Live-in-Labs® program in Malkhanpur, a rural village in the Indian state of Uttar Pradesh, addressing the community challenge of low income. The challenges were evaluated at different dimensions - community level, household level, and individual level, using Participatory Rural Appraisal (PRA) and Human-centered Design (HCD) approach. This paper explored the application of AI to drive employment to achieve income generation and overall well-being. A generative AI-based platform, ’JobConnect: AI-based Rural Job Seeker-Provider App with ChatGPT Assistance’ is proposed with AI-based virtual assist with NLP, location-based Job listing, and matching algorithms. The platform is designed to be user-friendly and accessible to rural community with varying levels of digital literacy and connectivity.},
  keywords={Couplings;Machine learning algorithms;Virtual assistants;Jobs listings;Government;Machine learning;Medical services;Participatory Rural Appraisal;Human-Centered Design;Generative AI;Rural Empowerment;Technology;SDG 8},
  doi={10.1109/ICAECT60202.2024.10468754},
  ISSN={},
  month={Jan},}@ARTICLE{11090063,
  author={Tchaleu, Boriane Y. and Ndjiongue, Alain R. and Leke, Collins A.},
  journal={SAIEE Africa Research Journal}, 
  title={Generative adversarial networks: A comprehensive review and the way forward}, 
  year={2025},
  volume={116},
  number={3},
  pages={101-124},
  abstract={The deep learning ability to recognize patterns in data has recently become popular within education. Created in 2014, generative adversarial networks (GANs) are innovative classes of deep learning generative models based on game theory and consist of two players. GANs generate data from scratch using two neural networks: the generator and the discriminator. Since their creation, GANs have been utilized in many applications and have advantages and disadvantages. In light of such a long journey, evaluating the technology is essential as it provides readers with the way forward. To this end, this paper reviews GANs and explores some fundamental challenges that develop during evaluation and training. We also discuss GANs' challenges and elaborate subsequent solutions. Through a single context, we explain the reasoning behind the GAN technology and examine its direction and motivation. We discuss different variants of GANs and real-world application examples, including performance evaluation metrics across various sectors. We consider results obtained recently and highlight ideas for further investigation. This detailed retrospect will give the reader a better understanding of the possible uses of GANs. It will also show how they can help address current issues in a variety of disciplines. Before that, the paper reviews GANs' architectures and network approaches and elaborates on challenges and solutions. The reader is then guided through the literature on the various applications of GANs and the importance of the research interest associated with GANs. As a final step, we suggest the way forward and conclude the review.},
  keywords={Generative adversarial networks;Generators;Training;Reviews;Noise;Computational modeling;Probability distribution;Linear programming;Optimization;Computer architecture;Generative adversarial network (GAN);artificial intelligence;generator;discriminator;deep fake;mode collapse;neural network},
  doi={10.23919/SAIEE.2025.11090063},
  ISSN={1991-1696},
  month={Sep.},}@ARTICLE{9927312,
  author={Xie, Guo-Sen and Zhang, Xu-Yao and Xiang, Tian-Zhu and Zhao, Fang and Zhang, Zheng and Shao, Ling and Li, Xuelong},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Leveraging Balanced Semantic Embedding for Generative Zero-Shot Learning}, 
  year={2023},
  volume={34},
  number={11},
  pages={9575-9582},
  abstract={Generative (generalized) zero-shot learning [(G)ZSL] models aim to synthesize unseen class features by using only seen class feature and attribute pairs as training data. However, the generated fake unseen features tend to be dominated by the seen class features and thus classified as seen classes, which can lead to inferior performances under zero-shot learning (ZSL), and unbalanced results under generalized ZSL (GZSL). To address this challenge, we tailor a novel balanced semantic embedding generative network (BSeGN), which incorporates balanced semantic embedding learning into generative learning scenarios in the pursuit of unbiased GZSL. Specifically, we first design a feature-to-semantic embedding module (FEM) to distinguish real seen and fake unseen features collaboratively with the generator in an online manner. We introduce the bidirectional contrastive and balance losses for the FEM learning, which can guarantee a balanced prediction for the interdomain features. In turn, the updated FEM can boost the learning of the generator. Next, we propose a multilevel feature integration module (mFIM) from the cycle-consistency branch of BSeGN, which can mitigate the domain bias through feature enhancement. To the best of our knowledge, this is the first work to explore embedding and generative learning jointly within the field of ZSL. Extensive evaluations on four benchmarks demonstrate the superiority of BSeGN over its state-of-the-art counterparts.},
  keywords={Finite element analysis;Semantics;Generators;Generative adversarial networks;Task analysis;Training data;Training;Feature generation;generative adversarial network (GAN);variational autoencoders;zero-shot learning (ZSL)},
  doi={10.1109/TNNLS.2022.3208525},
  ISSN={2162-2388},
  month={Nov},}@INPROCEEDINGS{9483563,
  author={Sebdani, Abbas Mazrouei and Mostafavi, Amir},
  booktitle={2021 5th International Conference on Pattern Recognition and Image Analysis (IPRIA)}, 
  title={Medical Image Processing and Deep Learning to Diagnose COVID-19 with CT Images}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={In this article two classification algorithms of computed tomography images with the purpose of detection of COVID-19 based on the local binary pattern, the GLCM features and the other extraction of statistical has been proposed to classify the chest images into two classes, COVID-19 patient or non-COVID-19 person. For this purpose, 746 images from the lung of healthy people and with the positive symptoms of COVID-19 disorder from the public data were collected and the collection of the features that was extracted in gray level was the input for artificial neural network (ANN) and support vector machine classifier (SVM), and the result of models shows that the highest accuracy is for SVM 98.5% and 97.2% accuracy by using the ANN.},
  keywords={COVID-19;Support vector machines;Image analysis;Computed tomography;Lung;Artificial neural networks;Feature extraction;COVID-19;artificial intelligence;image processing;deep learning;detection;CT scan image},
  doi={10.1109/IPRIA53572.2021.9483563},
  ISSN={2049-3630},
  month={April},}@INPROCEEDINGS{10930103,
  author={Lee, Sanghyuck and Khairulov, Timur and Lee, Jaesung},
  booktitle={2025 IEEE International Conference on Consumer Electronics (ICCE)}, 
  title={Diffusion Model-Based Generative Pipeline for Children Song Video}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Children songs have been essential in early childhood education, supporting cognitive development, language acquisition, and emotional expression. With the rise of digital media, the traditional children songs have evolved into multimedia experiences, including music videos. However, the creation of these videos is a resource-intensive process that requires a blend of artistic and technical expertise. Meanwhile, recent advancements in generative models, especially diffusion models, have shown impressive text-to-image capabilities, though they still face limitations in generating temporally coherent video content. This paper explores an innovative approach to generating music videos for children songs, that convert children song lyrics into visually appealing and contextually relevant video content. Our approach integrates natural language processing to interpret lyrics and computer vision techniques to generate corresponding animations and visuals. Our experiments on 20 prompts demonstrate that the Cascade SD model outperforms the other four models across three evaluation measures. The qualitative analysis on 10 prompts demonstrates the superiority of the Cascade SD model and highlights the effectiveness of negative prompting and secondary prompting techniques. The demo is available in https://github.com/tkdgur658/Children_Song_Video.},
  keywords={Visualization;Generative AI;Computational modeling;Pipelines;Text to image;Streaming media;Media;Natural language processing;Text to video;Videos;text-to-video generation;music video generation;generative AI},
  doi={10.1109/ICCE63647.2025.10930103},
  ISSN={2158-4001},
  month={Jan},}@INBOOK{10955020,
  author={Marr, Bernard},
  booktitle={Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society}, 
  title={RETAIL REIMAGINED: THE RISE OF VIRTUAL TRY&#x2010;ONS, AI SHOPPING ASSISTANTS, AND MORE}, 
  year={2024},
  volume={},
  number={},
  pages={121-132},
  abstract={Summary <p>Incredible GenAI tools like ChatGPT will clearly have an effect on every industry, and the retail sector is no different. This chapter explores some of the main ways GenAI can be used in retail &#x2013; and how it might transform the shopping experience for both customers and retailers. Fashion will crop up a lot in this chapter but make no mistake, GenAI will impact all kinds of retailers. The chapter talks about immersive virtual stores and websites optimized for GenAI technologies. It discusses interactive displays in physical stores, hyper&#x2010;personalization on a mass scale, and optimized behind&#x2010;the&#x2010;scenes processes. Thanks to augmented reality technology, virtual try&#x2010;ons are getting better. eBay has introduced ShopBot, an AI personal shopping assistant available in Facebook Messenger. One area in which GenAI excels is in writing descriptions, including bespoke descriptions that tell a story about a product.</p>},
  keywords={Mirrors;Metaverse;Reviews;Generative AI;Games;Shape;Internet;Image color analysis;Glass;Electronic commerce},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394254255},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10955020},}@INBOOK{10951356,
  author={Marr, Bernard},
  booktitle={Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society}, 
  title={ADVERTISING AND MARKETING: BRIDGING CREATIVITY WITH AI}, 
  year={2024},
  volume={},
  number={},
  pages={97-107},
  abstract={Summary <p>GenAI can be used to create professional&#x2010;looking content that is not just engaging for audiences, but also tailored to their specific needs. Another major benefit comes down to time and money, since GenAI can automate many of the processes involved in creating marketing and advertising materials. Plus, GenAI allows even smaller teams to increase innovation and generate inspirational ads and marketing materials. Personalization is a recurring theme throughout this book, and it's especially relevant in the field of marketing and advertising. GenAI can be used to help brands generate text, visuals, video, and music for high&#x2010;quality advertising and marketing campaigns &#x2013; far cheaper and quicker than through traditional methods. GenAI can help businesses come up with ideas, and automate aspects of the creative process &#x2013; for example, by creating images through natural text prompts. Several high&#x2010;profile brands have already embraced GenAI for ads.</p>},
  keywords={Social networking (online);Advertising;Generative AI;Creativity;TV;Real-time systems;Natural languages;Ethics;Electronic mail;Companies},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394254255},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951356},}@INBOOK{10950624,
  author={Marr, Bernard},
  booktitle={Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society}, 
  title={REINVENTING CUSTOMER ENGAGEMENT THROUGH INTELLIGENT SYSTEMS}, 
  year={2024},
  volume={},
  number={},
  pages={109-120},
  abstract={Summary <p>The customer service function stands to be revolutionized by GenAI, particularly by text&#x2010;and&#x2010;speech models. But customer service isn't the only aspect of customer engagement that can benefit from GenAI; through new personalized offerings, preventive interventions, and intelligent products and services, GenAI will transform how brands interact with their customers. Personalization is a huge theme in GenAI, and we can expect all organizations to unearth new opportunities to provide personalized solutions for customers. GenAI can assist with this by understanding the customer's history and preferences, and generating thoughtful suggestions and recommendations. Personalization also enables a new level of proactive responsiveness for organizations. From identifying potential issues and malfunctions before they occur, to delivering proactive advice that helps customers achieve their goals, GenAI can help businesses better anticipate their customers' needs. Customer engagement is a topic that applies to any organization across any industry.</p>},
  keywords={Customer services;Chatbots;Generative AI;Companies;Intelligent systems;Training;Social networking (online);History;Fans;Electronics packaging},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394254255},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10950624},}@INBOOK{10952707,
  author={Marr, Bernard},
  booktitle={Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society}, 
  title={BANKING AND FINANCIAL SERVICES: AI AS A DISRUPTIVE FORCE}, 
  year={2024},
  volume={},
  number={},
  pages={189-199},
  abstract={Summary <p>Banks and other financial institutions are already starting to implement GenAI. GenAI can create sophisticated financial models that simulate various economic and market conditions to predict their effects on investment portfolios, asset values, or institutional risk exposure. Know Your Customer (KYC) and Anti&#x2013;Money Laundering processes are critical for banks to mitigate financial crime and maintain regulatory compliance. GenAI can assist in automating these processes by analyzing large amounts of customer data, including personal data and transaction history, and identifying potential compliance issues. Another example comes from insurance and financial services company, Nationwide, which has been using GenAI to improve pet insurance provision by helping pet owners take better care of their pets' health. Morgan Stanley has been experimenting with OpenAI's GPT&#x2010;4 model, using the language model as a sort of encyclopedia for financial advisors.</p>},
  keywords={Banking;Financial services;Generative AI;Predictive models;Biological system modeling;Risk management;Portfolios;Fraud;Force;Investment},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394254255},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952707},}@INPROCEEDINGS{10985115,
  author={Suresh, Yeresime and Joshi, Shreeharsh and C, Shreyas and Poojary, Sinchana and Reddy, Sreevalli},
  booktitle={2025 International Conference on Intelligent Computing and Control Systems (ICICCS)}, 
  title={Smart Travel Assistance using Machine Learning and Generative Artificial Intelligence}, 
  year={2025},
  volume={},
  number={},
  pages={757-762},
  abstract={Travel planning is tedious and perplexing due to the plethora of options and the lack of a unified, consistent solution. The Smart Travel Assistance System, developed using Machine Learning and Generative Artificial Intelligence, simplifies travel planning by offering real-time data and personalized guidance. The key features are weather, AI-driven itinerary suggestions, destination and attraction recommendations, crowd density predictions, geo-location services, and an interactive chatbot for immediate assistance. These features ensure a smooth, efficient, and hassle-free travel experience. Future enhancements, including the integration of user-generated content and enhanced prediction algorithms, will further enhance the system, and it will become an essential travel companion.},
  keywords={Generative AI;Scalability;User-generated content;Neural networks;Weather forecasting;Machine learning;Prediction algorithms;Real-time systems;Planning;Reliability;Crowd prediction;Geo-location;Itinerary;Neural network;Sustainable travel},
  doi={10.1109/ICICCS65191.2025.10985115},
  ISSN={},
  month={March},}@INPROCEEDINGS{10311876,
  author={Chen, Mingying and Liu, Ye and Shu, Lei and Li, Kailiang and Yang, Xing and Yang, Fan},
  booktitle={IECON 2023- 49th Annual Conference of the IEEE Industrial Electronics Society}, 
  title={SILGAN: Generative Adversarial Networks for Multimedia Data Compression in Solar Insecticidal Lamps Internet of Things}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents a low overhead multimedia data compression method for Solar Insecticidal Lamps Internet of Things (SIL-IoTs), achieving efficient audio data transmission. First, the audio and video data generated by working solar insecticidal lamps are collected to form an original dataset in the solar insecticidal lamps applications. Then, we propose SILGAN, a generative adversarial network to compress multimedia audio data in the SIL-IoTs. Specifically, a depth-wise separable convolution is adopted to reduce the computational resources for training networks and running programs. Moreover, the network parameters are optimized so that obtaining a better neural network model with stable operation on the nodes of the SIL-IoTs. Finally, experimental evaluation is conducted, showing the effectiveness of the proposed SILGAN approach.},
  keywords={Training;Industrial electronics;Convolution;Computational modeling;Neural networks;Data compression;Streaming media;Generative Adversarial Networks;data compression;Solar Insecticidal Lamps Internet of Things},
  doi={10.1109/IECON51785.2023.10311876},
  ISSN={2577-1647},
  month={Oct},}@INBOOK{10790432,
  author={},
  booktitle={Toward Artificial General Intelligence: Deep Learning, Neural Networks, Generative AI}, 
  title={Index}, 
  year={2024},
  volume={},
  number={},
  pages={401-410},
  abstract={},
  keywords={Heuristic algorithms;Medical diagnostic imaging;Indexes;Fraud;Feature extraction;Object recognition;Manipulator dynamics;Libraries;Learning (artificial intelligence);Industries},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9783111324166},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10790432},}@INPROCEEDINGS{10834380,
  author={Ito, Yosuke and Watanabe, Takuto and Sasaki, Yuta},
  booktitle={2024 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}, 
  title={Technology Education of Artificial Intelligence with Web Map Content in Secondary Schools}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={The purpose of this study is to develop and evaluate technology education in which students learn about various types of artificial intelligence (AI) experientially through creating web map content to solve problems in life and society in secondary schools. A teaching guidance plan was developed for practice in Japanese secondary schools. Two types of AI were employed as teaching materials: data classification AI and image generation AI. Based on the results of tentative teaching practice, the feasibility of the learning content, except for the image generation AI, was confirmed. The proposed AI technology education will be conducted in secondary schools to evaluate its usefulness.},
  keywords={Image synthesis;Generative AI;Education;Production;technology education;artificial intelligence;neural network;map content},
  doi={10.1109/TALE62452.2024.10834380},
  ISSN={},
  month={Dec},}@ARTICLE{11028129,
  author={Sikder, Md Nazmul Kabir and Wang, Yingjie and Batarseh, Feras A.},
  journal={IEEE Access}, 
  title={Assessing the Fidelity and Utility of Water Systems Data Using Generative Adversarial Networks: A Technical Review}, 
  year={2025},
  volume={13},
  number={},
  pages={106443-106464},
  abstract={Limited data access to Water Distribution Systems (WDSs) is a longstanding barrier to data-driven research and development. This limited access is further exacerbated by the reluctance of WDSs operators to share data. Driven by the absence of standard mandates, resource constraints, privacy and security concerns, and legal challenges, access to big data has been a challenge in the water scientific community. This review paper addresses this limitation by utilizing Generative Adversarial Networks (GANs) to generate realistic synthetic datasets, overcoming data scarcity and privacy concerns in WDSs. We review, train, and evaluate seven state-of-the-art GAN models using three multivariate time-series datasets. The core contribution of this work lies in its comprehensive technical review of the GANs, comparing and evaluating their ability to replicate temporal dynamics and maintain spatio-temporal dependencies within WDSs. For evaluation, we use techniques like t-distributed Stochastic Neighbor Embedding (t-SNE) and Principal Component Analysis (PCA) to quantify the diversity of the generated synthetic data. Key findings indicate that specific GAN models, such as Cramer GAN and CTGAN, are effective in generating data for predictive modeling, replacing the need for original WDSs datasets. Additionally, DoppelGANger and TimeGAN exhibit strong capabilities in preserving essential spatio-temporal relationships, which are critical for applications like environmental impact estimation. The results also highlight the practical utility of GAN-generated synthetic data in supporting the secure and effective management of WDSs, particularly in scenarios where data are scarce or sensitive. This research contributes to the application of Artificial Intelligence (AI) in water resource management and guides the selection of appropriate GAN models for specific tasks and contexts, demonstrating their practical implications in real-world scenarios. Experimental results are recorded, evaluated, and discussed.},
  keywords={Synthetic data;Water resources;Artificial intelligence;Data privacy;Reviews;Generative adversarial networks;Data models;Accuracy;Principal component analysis;Costs;Cyberbiosecurity;deep learning;generative adversarial networks (GANs);synthetic data generation;water data;water policy},
  doi={10.1109/ACCESS.2025.3577969},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8785739,
  author={XU, Yang and WANG, Weijia and YANG, Jiaxin and LI, Jiahong},
  booktitle={2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={Research on online user comments in artificial intelligence times}, 
  year={2019},
  volume={},
  number={},
  pages={507-511},
  abstract={In this era of artificial intelligence, the online user comment in the e-commerce platform contains a lot of valuable information. Mining and analyzing these online comments can help enterprises and organizations better understand the clients' needs, attitudes and concerns. Based on studies on word of mouth, automatic tag generation, and deep learning technologies, this paper uses Long Short-Term Memory (LSTM) as a hidden layer neuron, introduces the attention mechanism, captures information in text sequences, understands user comment text, and builds a model of automatic tags generation. The model can be used to help consumers make smarter shopping decisions and help merchants make better business decisions.},
  keywords={Feature extraction;Task analysis;Deep learning;Data models;Semantics;Data mining;Classification algorithms;Online User Comment;Word Of Mouth;Deep Learning;E-Commerce},
  doi={10.1109/ITAIC.2019.8785739},
  ISSN={},
  month={May},}@INPROCEEDINGS{10581108,
  author={Bisherwal, Pragya and Srivastava, Pranjal and Kumar, Rahul and Jindal, Rajni},
  booktitle={2024 International Conference on Intelligent Systems for Cybersecurity (ISCS)}, 
  title={A Novel Approach to Image Synthesis: Using Stack GAN to Enhance Cybersecurity Application of Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Text-to-image synthesis, a transformative application of artificial intelligence, converts textual descriptions into vivid images, with implications ranging from artistic expression to cybersecurity. This paper explores Stack Generative Adversarial Networks (Stack GAN) as an architectural innovation, enhancing image quality in two stages: Stage I and Stage II, each employing generators and discriminators to produce high-resolution images. With a focus on data integrity and system security, encryption algorithms safeguard sensitive input data. The Stack GAN model, coupled with conditional augmentation, improves resource efficiency, and content linkage, and mitigates over-fitting. Results demonstrate the model's robustness, offering utility in information and network security through enhanced fraud detection, user authentication, and visualization of security policies. This research underscores the fusion of AI's creative capabilities with traditional and innovative security measures.},
  keywords={Training;Visualization;Technological innovation;Refining;Text to image;Generative adversarial networks;Generators;Artificial Intelligence in Cybersecurity;Machine Learning;Text-to-visual representation;Stacked GAN;Fraud Detection;User Authentication;GANs for Visual Security},
  doi={10.1109/ISCS61804.2024.10581108},
  ISSN={},
  month={May},}@INBOOK{10785702,
  author={Tardy, Jean},
  booktitle={The Creation of a Conscious Machine: The Quest for Artificial Intelligence}, 
  title={Chapter 17: Specifications of Synthetic Consciousness}, 
  year={2023},
  volume={},
  number={},
  pages={167-176},
  abstract={},
  keywords={Behavioral sciences;Artificial intelligence;Problem-solving;Autonomous agents;Software;Psychology;Prototypes;Natural languages;Hybrid power systems;Generative AI},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9781501518331},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10785702},}@INPROCEEDINGS{10740140,
  author={Ding, Pengyong and Liu, Jiarong and Sun, Min and Li, Li and Liu, Hong},
  booktitle={2024 IEEE International Conference on Metaverse Computing, Networking, and Applications (MetaCom)}, 
  title={Enhancing Computational Processing Performance for Generative AI Large Models with Autonomous Decision-Making in Metaverse Applications}, 
  year={2024},
  volume={},
  number={},
  pages={253-258},
  abstract={We explore how to enhance the computational processing performance for generative AI large models with autonomous decision-making in metaverse applications. We first introduce the relationship between AI large models and the Metaverse. We elaborate on the application scenarios of generative AI large models in Metaverse, including real-time weather simulation, embodied intelligence of agents, dynamic environment interaction, and user emotion recognition. We then propose the method of Multi-Dimensional Optimization Generation Framework (MDOGF) to improve computational processing performance. The experiment results show great improvement in computational processing performance.},
  keywords={Emotion recognition;Metaverse;Generative AI;Computational modeling;Decision making;Artificial general intelligence;Data models;Real-time systems;Optimization;Meteorology;Generative AI Large Models;Metaverse;Autonomous Decision-Making;Reinforcement Learning;Multi-Agent Systems;Model Compression;Model Acceleration;Multi-Modal Data Integration;Digital Twin Technology;AGI (Artificial General Intelligence)},
  doi={10.1109/MetaCom62920.2024.00048},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10556084,
  author={Burégio, Vanilson and Pereira, Iverson and Cabral, Henrique},
  booktitle={2024 IEEE/ACM 3rd International Conference on AI Engineering – Software Engineering for AI (CAIN)}, 
  title={Innovating Translation: Lessons Learned from BWX Generative Language Engine}, 
  year={2024},
  volume={},
  number={},
  pages={98-99},
  abstract={The integration of Translation Management Systems (TMS) and Large Language Models (LLMs) has revolutionized the translation landscape, offering nuanced and culturally sensitive translations. This paper explores the lessons learned from developing the BWX Generative Language Engine, an award-winning Generative AI tool for translation, which exemplifies the application of generative AI in translation management. Lessons include the transformative impact of AI, the accelerated delivery of beta features with LLMs, and the strategic integration of enabling technologies. Additionally, insights are drawn from strategic testing for optimal model routing, caching mechanisms, fallbacks, and the importance of security and data policy awareness.CCS CONCEPTS• Information systems • Information systems applications • Computing platforms},
  keywords={Technological innovation;Generative AI;Computational modeling;Routing;Software reliability;Security;Engines;Generative AI;Translation Management Systems;Large Language Models;Software Engineering},
  doi={},
  ISSN={},
  month={April},}@ARTICLE{10416760,
  author={Yang, Jing and Wang, Yutong and Wang, Xingxia and Wang, Xiaoxing and Wang, Xiao and Wang, Fei-Yue},
  journal={IEEE Transactions on Systems, Man, and Cybernetics: Systems}, 
  title={Generative AI Empowering Parallel Manufacturing: Building a “6S” Collaborative Production Ecology for Manufacturing 5.0}, 
  year={2024},
  volume={54},
  number={11},
  pages={6522-6536},
  abstract={Since Manufacturing 4.0 faces various challenges, including the risks of data leakage and privacy violation, the struggle to meet the growing demand for personalization, and the limitations in harnessing human creativity, it has become crucial to embark on a transformation toward Manufacturing 5.0. To this end, we propose a DeFACT framework for parallel manufacturing and Manufacturing 5.0, which focuses on safe, efficient and personalized collaborative production. In DeFACT, different enterprises and parallel workers (i.e., digital, robotic and biological workers) are organized, coordinated and scheduled based on decentralized autonomous organizations and operations to promote mutual benefits among members, even in the context of low or zero trust. This contributes to providing customers with higher-quality personalized products and services while ensuring the confidentiality and safeguarding of data. Additionally, various advanced technologies, such as generative artificial intelligence, scenarios engineering, and blockchain, are leveraged to achieve trustworthy and adaptable decision making, user-friendly human–machine interaction, and the federated control and management of parallel workers. Finally, the effectiveness and efficiency of DeFACT are experimentally validated through the design and implementation of three case studies.},
  keywords={Manufacturing;Collaboration;Production;Biological system modeling;Computational modeling;Fifth Industrial Revolution;Decision making;Blockchain;collaborative manufacturing;DAO;foundation models;industry 5.0;manufacturing 5.0;parallel intelligence;parallel manufacturing;privacy-preserving},
  doi={10.1109/TSMC.2024.3349555},
  ISSN={2168-2232},
  month={Nov},}@INBOOK{10834031,
  author={Sharma, Ravindra and Kumar, Narendra and Sharma, Vinod},
  booktitle={AI in Disease Detection: Advancements and Applications}, 
  title={Computer Vision for Disease Detection &#x2014; An Overview of How Computer Vision Techniques Can Be Used to Detect Diseases in Medical Images, Such as X&#x2010;Rays and MRIs}, 
  year={2025},
  volume={},
  number={},
  pages={77-98},
  abstract={Summary <p>The utility of computer imaginative and predictive strategies to medical imaging for disease detection represents a big advancement in healthcare diagnostics. This explores a complete methodology that integrates progressive approaches in deep learning, data augmentation, explainable artificial intelligence (AI), real&#x2010;time processing, and multimodal records fusion. The primary goal is to enhance the accuracy, efficiency, and transparency of diagnostic strategies throughout various clinical situations consisting of Alzheimer's disease, cardiovascular disorders, and pores and skin conditions.</p> <p>The approach begins with the compilation and preprocessing of diverse scientific datasets, including X&#x2010;rays, MRIs, CT scans, ECGs, and fundus images. This phase involves close collaboration with medical experts for accurate annotation and the application of advanced preprocessing techniques to ensure high&#x2010;quality input data. In the final phase, a hybrid deep learning architecture is employed, combining Convolutional Neural Networks (CNNs) for spatial feature extraction and transformers for better capturing long&#x2010;range dependencies and enhancing the model's predictive performance.This architecture is in addition reinforced through transfer getting to know, leveraging pre&#x2010;educated models and best&#x2010;tuning them on precise medical datasets to enhance performance.</p> <p>Information augmentation strategies and generative hostile networks (GANs) are applied to mitigate records scarcity by creating synthetic scientific pictures, thereby enhancing the version's robustness. The education section consists of both supervised and semi&#x2010;supervised studying strategies, with cross&#x2010;validation to make certain model generalizability. Explainable AI strategies, consisting of Grad&#x2010;CAM, are included to offer visible insights into the model's decision&#x2010;making process, fostering consider and interpretability.</p> <p>Actual&#x2010;time processing talents are finished through model optimization techniques like pruning and quantization, and deployment on aspect devices to ensure on the spot diagnostic comments. Seamless integration with clinical workflows is prioritized, with the improvement of consumer&#x2010;friendly interfaces and dashboards that gift diagnostic effects and recommendations comprehensively.</p> <p>A key innovation is the multimodal data integration, combining clinical pictures with EHRs and genetic data. This holistic technique permits for a more comprehensive evaluation and personalized diagnostic insights. Continuous learning frameworks also are carried out, enabling the models to conform and improve with new information and feedback, ensuring they remain current with today's clinical advancements.</p> <p>The results demonstrate extensive enhancements in diagnostic accuracy and performance, with real&#x2010;time systems imparting instant and dependable comments. The mixing of explainable AI strategies guarantees transparency and fosters greater acceptance amongst healthcare experts. The future scope of this studies consists of further enhancements in multimodal data integration, using federated learning to ensure records privacy, and the incorporation of augmented and virtual reality for interactive diagnostics. Continuous development and real&#x2010;world validation via clinical trials might be essential in solidifying the role of AI&#x2010;pushed diagnostics in healthcare.</p> <p>Thus, this looks at providing a robust and innovative framework for disease detection the use of computer imaginative and predictive, highlighting its potential to transform healthcare diagnostics by means of supplying precise, green, and transparent solutions. As the sphere progresses, those AI&#x2010;driven equipment are poised to come to be integral in clinical exercise, riding ahead the competencies of precision remedy and personalized care.</p>},
  keywords={Diseases;Computer vision;Computational modeling;Accuracy;Artificial intelligence;Medical diagnostic imaging;Medical services;Adaptation models;Transfer learning;Technological innovation},
  doi={10.1002/9781394278695.ch4},
  ISSN={},
  publisher={IEEE},
  isbn={9781394278688},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10834031},}@INPROCEEDINGS{10547727,
  author={N, Saranya and C, Jowin Alfred and RR, Rishikesh and I, Gilbert Idayan},
  booktitle={2024 International Conference on Recent Advances in Electrical, Electronics, Ubiquitous Communication, and Computational Intelligence (RAEEUCCI)}, 
  title={Analysis of GAN for Melanoma Skin CancerClassification with Dermatologist Recommendation}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Melanoma is a type of skin cancer that poses a significant health threat globally, necessitating effective early detection methods. Melanoma arises from the pigment-producing cells(melanocytes) and is known for its higher metastatic potential. Designing a reliable Computer-Aided Diagnosis (CAD) system for accurate melanoma detection is challenging due to the appearance of the nevus. This study investigates the application of a GAN for classification of melanoma. The GAN architecture is employed to learn and generate synthetic melanoma images, enhancing the diversity and richness of the training dataset. We mainly focus on evaluating performance of GAN-enhanced model through comprehensive metrics like specificity, accuracy, the receiver operating characteristic curve (ROC) and area under the curve (AUC). This study sheds light on utility of synthetic data in clinical image analysis and provides insights into the strengths and limitations of utilizing GANs for melanoma skin cancer classification. We also added a dermatologist recommendation feature to our model. It uses computer programs to understand what youneed and then matches you with the best doctor available nearby. This system helps you get the care you need faster and easier, making sure you see a doctor who's a good fit for you and your health needs. This system matches patients with suitable doctors. This matching involves considering factors like doctor specialty and location.},
  keywords={Training;Solid modeling;Neural networks;Melanoma;Medical services;Receivers;Generative adversarial networks;Deep Learning;Melanoma skin cancer;GANConvolutional Neural Network Dermatology},
  doi={10.1109/RAEEUCCI61380.2024.10547727},
  ISSN={},
  month={April},}@INPROCEEDINGS{11030955,
  author={Amarasinghe, H M Sudith and Arachchi, S P Kasthuri},
  booktitle={2025 International Research Conference on Smart Computing and Systems Engineering (SCSE)}, 
  title={Deepfake Detection Using a Hybrid Deep Learning Approach with Swin Transformers and ConvNeXt}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={The rapid advancement of artificial intelligence has led to the proliferation of deep-fake technology, which poses significant challenges to digital security and trust. As deepfakes become increasingly sophisticated, there is an urgent need for effective detection methods that can accurately identify manipulated media across various platforms and contexts. Deepfakes are outcomes of advanced Artificial Intelligence algorithms such as Generative Adversarial Networks, and have become a danger to digital integrity, personal privacy, and public trust. With continuous advancements in the techniques for generating deepfakes, conventional methods of detection based on the artifact analysis of visuals and inconsistencies in physiological signals have started to wear out. This paper presents a hybrid deep learning model that works between Swin Transformers and ConvNeXt architectures for better detection. The proposed model achieves better detection accuracy and robustness by leveraging Swin Transformers' hierarchical feature extraction capabilities and the efficient processing strengths of ConvNeXt. Obtained results on the "Deepfake and Real Images" dataset demonstrated performance of 95.6% accuracy, 97.4% precision, 93.7% recall, and a 95.2% F1 score. The hybrid model is more effective than existing ones, demonstrating their potential for concrete application in social media platforms, news agencies, and digital forensics to help fight misinformation and preserve digital trust.},
  keywords={Deep learning;Deepfakes;Visualization;Accuracy;Social networking (online);Transformers;Generative adversarial networks;Robustness;Security;Artificial intelligence;ConvNeXt;deepfakes;generative adversarial networks;swin transformers},
  doi={10.1109/SCSE65633.2025.11030955},
  ISSN={2997-7363},
  month={April},}@ARTICLE{9950553,
  author={Meng, Yapeng and Li, Wenyuan and Lei, Sen and Zou, Zhengxia and Shi, Zhenwei},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Large-Factor Super-Resolution of Remote Sensing Images With Spectra-Guided Generative Adversarial Networks}, 
  year={2022},
  volume={60},
  number={},
  pages={1-11},
  abstract={Large-factor image super-resolution (SR) is a challenging task due to the high uncertainty and incompleteness of the missing details to be recovered. In remote sensing images, the subpixel spectral mixing and semantic ambiguity of ground objects make this task even more challenging. In this article, we propose a novel method for large-factor SR of remote sensing images named spectra-guided generative adversarial networks (SpecGANs). In response to the above problems, we explore whether introducing additional hyperspectral images (HSIs) to GAN as conditional input can be the key to solving the problems. Different from previous approaches that mainly focus on improving the feature representation of a single source input, we propose a dual-branch network architecture to effectively fuse low-resolution (LR) red, green, blue (RGB) images and corresponding HSIs, which fully exploit the rich hyperspectral information as conditional semantic guidance. Due to the spectral specificity of ground objects, the semantic accuracy of the generated images is guaranteed. To further improve the visual fidelity of the generated output, we also introduce the Latent Code Bank with rich visual priors under a generative adversarial training framework so that high-resolution, detailed, and realistic images can be progressively generated. Extensive experiments show the superiority of our method over the state-of-art image SR methods in terms of both quantitative evaluation metrics and visual quality. Ablation experiments also suggest the necessity of adding spectral information and the effectiveness of our designed fusion module. To our best knowledge, we are the first to achieve up to 32x SR of remote sensing images with high visual fidelity under the premise of accurate ground object semantics. Our code can be publicly available at https://github.com/YapengMeng/SpecGAN.},
  keywords={Superresolution;Hyperspectral imaging;Semantics;Task analysis;Visualization;Generative adversarial networks;Image reconstruction;Deep convolutional neural networks (CNNs);generative adversarial networks (GANs);hyperspectral image (HSI);remote sensing image;super-resolution (SR)},
  doi={10.1109/TGRS.2022.3222360},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{9625310,
  author={Zhou, Danyang and Wang, Huxiao and Li, Wei and Zhou, Yi and Cheng, Nan and Lu, Ning},
  booktitle={2021 IEEE 94th Vehicular Technology Conference (VTC2021-Fall)}, 
  title={SA-SGAN: A Vehicle Trajectory Prediction Model Based on Generative Adversarial Networks}, 
  year={2021},
  volume={},
  number={},
  pages={1-5},
  abstract={Vehicle trajectory prediction technology is of great significance in autonomous driving and intelligent transportation systems. Ego-vehicles can judge the future motion state considering nearby vehicles by predicting their trajectories, which facilitates safe and effective decisions to avoid collisions. It is a challenging task to accurately predict the future trajectories of surrounding vehicles. To solve this problem, we propose a Self-Attention Social Generative Adversarial Networks (SA-SGAN) model to predict trajectories of surrounding vehicles. We use the Self-Attention mechanism to capture the correlation between the features in the vehicle trajectory sequence to effectively solve the problem of missing important information due to a long input sequence, and use training characteristic of Generative Adversarial Networks (GAN) to effectively learn the distribution of real trajectory data and improve prediction accuracy. We evaluate the proposed model through NGSIM dataset, use the trained model to investigate the vehicle trajectory in the next 5s in a three-segment scenario of the US-101 highway, and use the Average Displacement Error (ADE) and Final Displacement Error (FDE) as the evaluation indicators. Compared with baseline methods, the proposed model reduces the evaluation indicators to 4.97 and 8.92 respectively.},
  keywords={Road transportation;Training;Vehicular and wireless technologies;Data visualization;Games;Predictive models;Generative adversarial networks;Vehicle trajectory prediction;Autonomous driving vehicles;Generative adversarial network;Attention mechanism},
  doi={10.1109/VTC2021-Fall52928.2021.9625310},
  ISSN={2577-2465},
  month={Sep.},}@INPROCEEDINGS{10456709,
  author={Cai, Qiang and Xiong, Shaohua and Wang, Chen and Li, Ziyao},
  booktitle={2023 3rd International Conference on Electronic Information Engineering and Computer Communication (EIECC)}, 
  title={Staged Progressive Single Image Generative Adversarial Network}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper focuses on exploring unconditional generative model training methods for single image learning and proposes a new staged progressive single image generative adversarial network (SPSI-GAN). By conducting staged multiscale training on a single image, we gradually learn the feature block information of different areas within the image and pay more systematic attention to the overall structure of the image, the basic outline of the scene, and the details of the content. Experiments verified the application effect of this method in multiple image tasks and compared it with other mainstream methods. This method shows excellence in generated image quality and feature distribution and could improve training efficiency and performance metrics while maintaining high quality generated images.},
  keywords={Training;Measurement;Image quality;Systematics;Image synthesis;Superresolution;Generative adversarial networks;Image processing;Generative Adversarial Network;Single-image learning},
  doi={10.1109/EIECC60864.2023.10456709},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8691394,
  author={Xu, Wendi and Zhang, Ming},
  booktitle={2018 5th IEEE International Conference on Cloud Computing and Intelligence Systems (CCIS)}, 
  title={Theory of Generative Deep Learning II:Probe Landscape of Empirical Error via Norm Based Capacity Control}, 
  year={2018},
  volume={},
  number={},
  pages={470-474},
  abstract={Despite its remarkable empirical success as a highly competitive branch of artificial intelligence, deep learning is often blamed for its widely known low interpretation and lack of firm and rigorous mathematical foundation. However, most theoretical endeavor is devoted in discriminative deep learning case, whose complementary part is generative deep learning. To the best of our knowledge, we firstly highlight landscape of empirical error in generative case to complete the full picture through exquisite design of image super resolution under norm based capacity control. Our theoretical advance in interpretation of the training dynamic is achieved from both mathematical and biological sides.},
  keywords={Deep learning;Training;Cloud computing;Superresolution;Statistical learning;Biology;Artificial intelligence;Deep learning;Statistical learning theory;Image super resolution;Capacity control;Regularization techniques;Brain-inspired intelligence},
  doi={10.1109/CCIS.2018.8691394},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11036144,
  author={Vavikar, Soumil and Ostrowski, David Alfred},
  booktitle={2025 19th International Conference on Semantic Computing (ICSC)}, 
  title={A Generative AI-Based Framework for Decentralized Finance and Cryptocurrency Fraud Prevention}, 
  year={2025},
  volume={},
  number={},
  pages={302-305},
  abstract={Although aligned with security-based principles, Blockchain networks have maintained some exposure to fraudulent transactions. This paper introduces a novel methodology and framework for effectively characterizing fraud within blockchain networks and a method for prevention. To leverage the transparency of the blockchain, suitable starting data can be acquired to characterize potentially nefarious transactions. The framework presented applies generative AI at two levels: to support the characterization of synthetic training data for scenarios that may yet be deployed and to generate suitable testing scenarios for constructing effective techniques to safeguard transactions.},
  keywords={Accuracy;Generative AI;Scalability;Prevention and mitigation;Smart contracts;Finance;Bitcoin;Decentralized applications;Fraud;Blockchains;blockchain;cryptocurrency},
  doi={10.1109/ICSC64641.2025.00052},
  ISSN={2472-9671},
  month={Feb},}@INPROCEEDINGS{11077170,
  author={Teke, Aditya and Pise, Nitin},
  booktitle={2025 6th International Conference on Control, Communication and Computing (ICCC)}, 
  title={Generative Models Reimagined: Review into Resource-Efficient Training}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={In the era of rapid improvements to generative artificial intelligence, resource-effective training methods are important for optimising models like BERT, ChatGPT, and Gemini. These large-scale models require tremendous processing capacity, which might be a barrier to scalability and sustainability. This review paper dives into novel strategies that improve computing economy while maintaining model performance. Architectural optimisation, quantisation, models pruning, and effective ways for discovering high-quality datasets while maintaining accuracy are among the key topics explored. The research emphasises sustainable AI approaches by demonstrating methods for reducing resource use while maintaining the resilience for generative models across several datasets. Furthermore, this paper identifies additional areas for study, such as refining model structures to reduce energy usage, improving data selection approaches, and creating hybrid models that incorporate different resource-saving techniques. Finally, the paper seeks to contribute to current efforts to balance AI developments with the requirement for long-term, scalable, and efficient model training methods.},
  keywords={Training;Adaptation models;Accuracy;Reviews;Biological system modeling;Computational modeling;Chatbots;Data models;Optimization;Context modeling;Generative Models;ResourceEfficiency;Gemini;BERT;TrainingTechniques;ChatGPT},
  doi={10.1109/ICCC64910.2025.11077170},
  ISSN={},
  month={May},}@INPROCEEDINGS{10652856,
  author={Liu, Yue and Xu, Na and Li, Min and Jin, Jianhai},
  booktitle={2024 13th International Conference on Communications, Circuits and Systems (ICCCAS)}, 
  title={Intelligent Prediction Model for Ship Roll Damping Based on CTGAN-XGBoost}, 
  year={2024},
  volume={},
  number={},
  pages={154-158},
  abstract={In order to prevent the substantial rolling of ships in intricate and harsh marine environments, ensuring the safety of personnel and cargo during maritime transportation, this paper proposes an intelligent prediction model for ship roll damping based on CTGAN-XGBoost. Firstly, a dataset for roll damping is constructed using ship geometry model data and ship motion data to improve data quality. Then, a Conditional Table Generative Adversarial Network is used to balance and generate more roll damping data, thereby augmenting the quantity of available data. Finally, taking advantage of XGBoost's strong generalization ability and low overfitting degree, an intelligent prediction model for roll damping is established. Experimental results demonstrate that the CTGAN-XGBoost model achieves the highest accuracy with MSE and MAE values of only 0.325 and 0.451 respectively, along with an R2 value of 0.975. It significantly outperforms other comparative models in terms of predictive accuracy.},
  keywords={Damping;Geometry;Accuracy;Transportation;Predictive models;Generative adversarial networks;Safety;ship roll damping;intelligent prediction;generative adversarial network;XGBoost},
  doi={10.1109/ICCCAS62034.2024.10652856},
  ISSN={},
  month={May},}@ARTICLE{11033416,
  author={Bühler, Katja and Höllt, Thomas and Schultz, Thomas and Vázquez, Pere-Pau},
  journal={IEEE Computer Graphics and Applications}, 
  title={AI-in-The-Loop: The Future of Biomedical Visual Analytics Applications in the Era of AI}, 
  year={2025},
  volume={45},
  number={2},
  pages={90-99},
  abstract={AI is the workhorse of modern data analytics and omnipresent across many sectors. Large language models and multimodal foundation models are today capable of generating code, charts, visualizations, etc. How will these massive developments of AI in data analytics shape future data visualizations and visual analytics workflows? What is the potential of AI to reshape methodology and design of future visual analytics applications? What will be our role as visualization researchers in the future? What are opportunities, open challenges, and threats in the context of an increasingly powerful AI? This Visualization Viewpoints discusses these questions in the special context of biomedical data analytics as an example of a domain in which critical decisions are taken based on complex and sensitive data, with high requirements on transparency, efficiency, and reliability. We map recent trends and developments in AI on the elements of interactive visualization and visual analytics workflows and highlight the potential of AI to transform biomedical visualization as a research field. Given that agency and responsibility have to remain with human experts, we argue that it is helpful to keep the focus on human-centered workflows, and to use visual analytics as a tool for integrating “AI-in-the-loop.” This is in contrast to the more traditional term “human-in-the-loop.” which focuses on incorporating human expertise into AI-based systems.},
  keywords={Data analysis;Shape measurement;Visual analytics;Large language models;Data visualization;Transforms;Market research;Human in the loop;Reliability;Artificial intelligence;Generative AI;Biomedical image processing},
  doi={10.1109/MCG.2024.3517293},
  ISSN={1558-1756},
  month={March},}@ARTICLE{9369834,
  author={Liu, Wei and You, Jie and Lee, Joonwhoan},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={HSIGAN: A Conditional Hyperspectral Image Synthesis Method With Auxiliary Classifier}, 
  year={2021},
  volume={14},
  number={},
  pages={3330-3344},
  abstract={In this article, we explore a conditional hyperspectral image (HSI) synthesis method with generative adversarial networks (GAN). A new multistage and multipole generative adversarial network, which is suitable for conditional HSI generation and classification (HSIGAN), is proposed. For HSIs synthesis, it is crucial to learn a great deal of spatial-spectral distribution features from source data. The multistage progressive training makes the generator effectively imitate the real data by fully exploiting the high-dimension learning capability of GAN models. The coarse-to-fine information extraction method helps the discriminator to understand the semantic feature better while the multiscale classification prediction presents a positive impact on results. A spectral classifier joins the adversarial network, which offers a helping hand to stabilize and optimize the model. Moreover, we apply the 3-D DropBlock layer in the generator to remove semantic information in a contiguous spatial-spectral region and avoid model collapse. Experimental results of the quantitative and qualitative evaluation show that HSIGAN could generate high-fidelity, diverse hyperspectral cubes while achieving top-ranking accuracy for supervised classification. This result is encouraging for using GANs as a data augmentation strategy in the HSI vision task.},
  keywords={Gallium nitride;Generative adversarial networks;Generators;Hyperspectral imaging;Deep learning;Training;Task analysis;Classification;generative adversarial network (GAN);hyperspectral image (HSI);synthesis},
  doi={10.1109/JSTARS.2021.3063911},
  ISSN={2151-1535},
  month={},}@INPROCEEDINGS{8718245,
  author={Zhang, Pengcheng and Dai, Qiyin and Ji, Shunhui},
  booktitle={2019 IEEE International Conference On Artificial Intelligence Testing (AITest)}, 
  title={Condition-Guided Adversarial Generative Testing for Deep Learning Systems}, 
  year={2019},
  volume={},
  number={},
  pages={71-72},
  abstract={Over the past decade, Deep Neural Networks (DNNs) have achieved remarkable progress. However, the quality of such kind of systems is far from perfect. Software test is one of the most effective techniques for finding bugs in DNNs. Test case generation is the key factors of the success of software test. Existing test case generation approaches for DNNs always generate a large number of test cases, most of which do not meet the test requirements or the actual situation. In this paper, we propose CAGTest, a condition-guided adversarial generative testing tool for other DNNs to generate their test inputs to find potential defects. In general, CAGTest can generate test cases conditionally, which is not only efficient, but also does not produce a large number of invalid test cases and reduces the scale of test cases.},
  keywords={Fuzzing;Neural networks;Deep learning;Software;Generators;Sun;DNNs;Test Case Generation;Coverage Criteria;Conditional Adversarial Generative Network},
  doi={10.1109/AITest.2019.000-5},
  ISSN={},
  month={April},}@ARTICLE{10970745,
  author={Fung, Clement and Qiu, Chen and Li, Aodong and Rudolph, Maja},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Model Selection of Anomaly Detectors in the Absence of Labeled Validation Data}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={Anomaly detection is the task of identifying abnormal samples in large unlabeled datasets. Although the advent of foundation models has produced powerful zero-shot anomaly detection methods, their deployment in practice is often hindered by the absence of labeled validation data—without it, detection performance cannot be evaluated reliably. In this work, we propose SWSA (Selection With Synthetic Anomalies): a general-purpose framework to select image-based anomaly detectors without labeled validation data. Instead of collecting labeled validation data, we generate synthetic anomalies from a small support set of normal images without using any training or fine-tuning. Our synthetic anomalies are then used to create detection tasks that compose a validation framework for model selection. In an empirical study, we evaluate SWSA with three types of synthetic anomalies and on two selection tasks: model selection of image-based anomaly detectors and prompt selection for CLIP-based anomaly detection. SWSA often selects models and prompts that match selections made with a ground-truth validation set, outperforming baseline selection strategies.},
  keywords={Anomaly detection;Data models;Training;Detectors;Diffusion models;Foundation models;Training data;Flowering plants;Computational modeling;Semantics;Artificial intelligence algorithmic design and analysis;Testing machine learning;Unsupervised learning},
  doi={10.1109/TAI.2025.3562505},
  ISSN={2691-4581},
  month={},}@INPROCEEDINGS{10206258,
  author={Yu, Zhuojun and Choi, Ka-Cheng},
  booktitle={2023 6th International Conference on Artificial Intelligence and Big Data (ICAIBD)}, 
  title={Augmenting RetinaFace Model with Conditional Generative Adversarial Networks for Hair Segmentation}, 
  year={2023},
  volume={},
  number={},
  pages={890-894},
  abstract={In this paper, an augmentation of the RetinaFace model for hair segmentation is proposed by incorporating a Conditional Generative Adversarial Network (cGAN). The proposed model is trained to generate high-quality hair segmentation masks by considering various hair textures, colors, and styles. Our approach is based on the idea that hair segmentation can benefit from the use of cGANs, because they can learn to generate realistic hair images and help improve the performance of RetinaFace. Experimental results show that our model outperforms the RetinaFace model on several benchmarks, achieving state-of-the-art performance.},
  keywords={Hair;Training;Image segmentation;Solid modeling;Image color analysis;Neural networks;Virtual environments;deep learning models;RetinaFace model;conditional generative adversarial network (cGAN);convolutional neural networks (CNNs);hair segmentation;face detection},
  doi={10.1109/ICAIBD57115.2023.10206258},
  ISSN={2769-3554},
  month={May},}@INPROCEEDINGS{8785447,
  author={Zhenye, Gan and Guangying, Zhao and Hongwu, Yang and Xiaotian, Xing and Yi, Jiao},
  booktitle={2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={Voice Conversion from Tibetan Amdo Dialect to Tibetan U-tsang Dialect Based on Generative Adversarial Networks}, 
  year={2019},
  volume={},
  number={},
  pages={325-329},
  abstract={This paper proposes a Voice Conversion (VC) method from Tibetan Amdo dialect to Tibetan U-tsang dialect based on Generative Adversarial Networks (GANs). An inevitable problem with the traditional VC framework is that the acoustic feature vector output from the conversion model is over-smoothing, which leads to a drop in the quality of the converted speech. This is because in the training phase of acoustic model, a specific probability model is used to model the distribution of data, so that the output of a relatively average parameter of the model is considered to be optimal. Acoustic parameter over-smoothing occurs as long as the analytical form of the model distribution is artificially designed. In order to overcome this problem, the VC framework proposed in this paper uses GANs as the modeling network of the acoustic model, directly uses a generator model to learn the distribution of data, and guides the generator through a discriminator model. The training of the model makes the sample distribution of the model close to the distribution of the target speaker data samples, thus alleviating the problem of over-smoothing of the converted speech spectrum. The experimental results show that the proposed method is superior to VC based on Deep Neural Networks (DNNs) in the sound quality and similarity of the converted speech.},
  keywords={Data models;Training;Acoustics;Generators;Gallium nitride;Analytical models;Feature extraction;Generative Adversarial Networks;Voice Conversion;over-smoothing;Deep Neural Networks},
  doi={10.1109/ITAIC.2019.8785447},
  ISSN={},
  month={May},}@INPROCEEDINGS{10972659,
  author={Sousa, Rafael T. and Oliveira, Elisa A. M. and Cintra, Luiza M. F. and Filho, Arlindo R. Galvão},
  booktitle={2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, 
  title={Transformative Technologies for Rehabilitation: Leveraging Immersive and AI-Driven Solutions to Reduce Recidivism and Promote Decent Work}, 
  year={2025},
  volume={},
  number={},
  pages={168-171},
  abstract={The reintegration of incarcerated individuals into society presents significant challenges, particularly in addressing barriers related to vocational training, social skill development, and emotional rehabilitation. Immersive technologies, such as Virtual Reality and Augmented Reality, combined with generative Artificial Intelligence (AI) and Large Language Models, offer innovative opportunities to enhance these areas. These technologies create practical, controlled environments for skill acquisition and behavioral training, while generative AI enables dynamic, personalized, and adaptive experiences. This paper explores the broader potential of these integrated technologies in supporting rehabilitation, reducing recidivism, and fostering sustainable employment opportunities and these initiatives align with the overarching equity objective of ensuring Decent Work for All, reinforcing the commitment to inclusive and equitable progress across diverse communities, through the transformative potential of immersive and AI-driven systems in correctional systems.},
  keywords={Technological innovation;Three-dimensional displays;Generative AI;Large language models;Employment;Psychology;User interfaces;Vocational training;Real-time systems;Sustainable development;Social Reintegration;Generative AI;Immersive Technology;Large Language Models;AI- Driven Rehabilitation—;—},
  doi={10.1109/VRW66409.2025.00042},
  ISSN={},
  month={March},}@INPROCEEDINGS{10590292,
  author={Hadj Azzem, Yousra Chahinez and Moussaoui, Abdelouahab and Berrimi, Mohamed},
  booktitle={2023 2nd International Engineering Conference on Electrical, Energy, and Artificial Intelligence (EICEEAI)}, 
  title={Arabic Calligraphy Generation Through Image-to-Image Translation Using Generative Adversarial Networks (GANs)}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Arabic calligraphy is a revered art form in the Arab world that has seen limited exploration in automated generation due to its complex nature and aesthetic principles and rules. However, recent advancements in deep learning provide promising avenues to address this challenge. In this work, we investigate the automatic generation of Arabic Calligraphy through image-to-image translation. Our approach utilizes Generative Adversarial Networks (GANs), a highly effective class of deep learning models recognized for their exceptional data generation abilities, to convert source font images (such as Arial) into desired calligraphy styles. Additionally, we propose a dataset comprising aligned images of conventional font and corresponding calligraphy styles. We evaluate the quality of the generated images on the proposed dataset. Our experiments yield promising results, demonstrating significant progress in the automatic generation of Arabic calligraphy images.},
  keywords={Deep learning;Visualization;Image recognition;Art;Shape;Deformation;Noise;Arabic Calligraphy;Generative AI;Image-to-Image translation;Pix2Pix;CycleGAN},
  doi={10.1109/EICEEAI60672.2023.10590292},
  ISSN={},
  month={Dec},}@ARTICLE{9972903,
  author={Wen, Yu-Wei and Ting, Chuan-Kang},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, 
  title={Recent Advances of Computational Intelligence Techniques for Composing Music}, 
  year={2023},
  volume={7},
  number={2},
  pages={578-597},
  abstract={Music exerts a ubiquitous influence on human cultures and daily lives. Composing music is deemed rather complicated because it involves various factors (e.g., instruments, melodies, percussions, and chords) needed to be well coordinated for creating harmony, tension, and emotions. Computational intelligence (CI) has shown its effectiveness in solving complex problems, such as optimization, data modeling, and reasoning. In light of the advantages of CI, a considerable amount of research has been proposed to incorporate CI techniques into music composition applications. The literature shows that evolutionary computation and neural network are very popular in this research area. The present survey reviews the recent studies on music composition using CI techniques, to reflect the methodological advances in the past decade. Particularly, this survey stresses two trends: 1) an increasing interest in deep learning for music composition and 2) the deepened engagement of synergizing domain knowledge, music data, and human interaction. In addition, we provide a taxonomy to classify these studies and discuss the research challenges and future directions.},
  keywords={Music;Artificial neural networks;Task analysis;Spectrogram;Genetics;Genetic algorithms;Fatigue;Computational intelligence;music composition;neural network;deep learning;evolutionary computation;genetic algorithm},
  doi={10.1109/TETCI.2022.3221126},
  ISSN={2471-285X},
  month={April},}@INPROCEEDINGS{10896435,
  author={Garbaruk, Julia and Ray, Jiban Kumar and Logofătu, Doina},
  booktitle={2024 26th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)}, 
  title={Level Generation Using ChatGPT: A Case Study on the Science Bird Game}, 
  year={2024},
  volume={},
  number={},
  pages={318-325},
  abstract={The increasing complexity of video games and development costs have necessitated innovative approaches to content creation. Procedural Content Generation (PCG) and AI tools like ChatGPT offer promising solutions. This paper explores the application of ChatGPT in Procedural Level Generation (PLG) for the game “Science Birds”. Through a combination of theoretical exploration and practical experiments, we demonstrate how ChatGPT can be leveraged to automate level design, enhancing both efficiency and creativity in game development.},
  keywords={Video games;Procedural generation;Costs;Scientific computing;Chatbots;Birds;Complexity theory;Artificial intelligence;Creativity;ChatGPT;Procedural Content Generation;Level Design;Artificial Intelligence;Video Games},
  doi={10.1109/SYNASC65383.2024.00060},
  ISSN={2470-881X},
  month={Sep.},}@INPROCEEDINGS{10837046,
  author={Bire, Pranav and Ambalkar, Om and Bagade, Ritesh and Mehta, Pradnya and Yenkikar, Anuradha},
  booktitle={2024 IEEE International Conference on Blockchain and Distributed Systems Security (ICBDS)}, 
  title={Preserving the Veracity of Digital Media using Neural Network Based Detection of Deepfake Videos}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Free deep learning applications have made it easier to create similar to humans synthesized videos in the past couple of years, a trend known as "deep fakes." Over many years, it has been possible to manipulate digital videos through the skilful use of visual effects. However, the simplicity with which fake content can be created and its realism have both increased dramatically due to recent advancements in deep learning. It is easy to imagine scenarios in which people are blackmailed, political unrest is caused, or events involving terrorism are fabricated using these realistic face-swapping deepfakes. This project proposal describes an exciting deep learning-based method that effectively recognizes real videos from ones produced by artificial intelligence. The use of artificial intelligence (AI) to combat AI is mentioned in the proposed model. The proposed method extracts frame-level features utilizing a Res-Next Convolution neural network. These attributes are then used to train an LSTM-based Recurrent Neural Network (RNN) to identify videos based on whether they have been altered or not, i.e., whether they are deepfake or real. The Deepfake Detection Challenge and Celeb-DF are two examples of the many available datasets that are combined to create a big, balanced, and mixed dataset that the model's performance on real-time data and apply it to real-world scenarios.},
  keywords={Deep learning;Deepfakes;Recurrent neural networks;Terrorism;Feature extraction;Visual effects;Market research;Real-time systems;Proposals;Long short term memory;Deepfake Video Detection;Res-Next;Convolution neural network;Recurrent Neural Network (RNN);Long Short-Term Memory (LSTM)},
  doi={10.1109/ICBDS61829.2024.10837046},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10989928,
  author={Faraji, Nastaran and Ansari, Sam and Alnajjar, Khawla A. and Albreem, Mahmoud A. and Mahmoud, Soliman and Hussain, Abir},
  booktitle={2025 IEEE 22nd International Multi-Conference on Systems, Signals & Devices (SSD)}, 
  title={Leveraging Generative Artificial Intelligence for Enhanced Detection and Classification of Diabetic Retinopathy}, 
  year={2025},
  volume={},
  number={},
  pages={1236-1241},
  abstract={Diabetic retinopathy (DR) is a severe microvascular complication of diabetes mellitus, causing progressive retinal damage and, if left untreated, leading to permanent blindness. Early detection is critical for effective treatment; however, the current manual diagnostic process performed by ophthalmologists is both time-intensive and reliant on highly trained professionals. This approach faces numerous challenges, including its inefficiency in detecting early-stage DR and the growing global prevalence of the disease. To address these limitations, the adoption of automated, efficient, and accurate detection methods is imperative. Recent advancements in deep learning (DL) algorithms have significantly improved the performance of commercial DR detection systems, enabling more precise diagnoses. This study examines the challenges associated with traditional DR detection and classification, particularly in the early stages, and explores the transformative potential of generative artificial intelligence (GAI). By leveraging technologies like chat generative pre-trained transformers (e.g., ChatGPT), GAI can enhance clinical workflows by generating detailed medical reports, educating patients, and analyzing extensive datasets to uncover actionable insights. This research highlights the integration of GAI as a promising avenue for revolutionizing DR detection and management.},
  keywords={Deep learning;Diabetic retinopathy;Generative AI;Manuals;Chatbots;Transformers;Retina;Classification algorithms;Medical diagnostic imaging;Image classification;chatgpt;deep learning algorithms;diabetic retinopathy detection;generative artificial intelligence;medical image classification},
  doi={10.1109/SSD64182.2025.10989928},
  ISSN={2474-0446},
  month={Feb},}@INPROCEEDINGS{11165999,
  author={Yang, Qianyu and Xie, Zewen and Niu, Gengfeng},
  booktitle={2025 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)}, 
  title={Personalized Mental Health Interventions Using Generative AI and Multimodal Data}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Artificial Intelligence (AI) systems could provide customized mental health interventions based on multiple types of data. The study introduces dynamic graph convolutional neural network (DGCNN) which identifies emotions simultaneously from text signals, as well as voice and face data as a real-time recognition model. The research addresses the gap in effective multimodal integration by introducing a weighted decision-level fusion technique that compensates for modality-specific data degradation. This research implements one-frame-per-second constant video processing of IEMOCAP and MELD video clips through majority voting which serves as a reliable classification technique. By minimizing the differences between various input signals, the weighted decision-level fusion technique optimizes its accuracy performance. The assessment system combines dependable psychological measures which act as infrastructure to support AI-based customized therapeutic services. Key findings reveal that the proposed model achieves improved classification accuracy and supports early detection of emotional distress with minimal computational load. Such emotional evaluation immediately supports clinicians during early detection of psychological stress indicators. Advanced mental health care access is achieved through better patient reach and enhanced health achievement according to the implemented strategy.},
  keywords={Emotion recognition;Accuracy;Generative AI;Text recognition;Face recognition;Computational modeling;Mental health;Real-time systems;Convolutional neural networks;Videos;Dynamic graph convolutional neural network;emotion recognition;multimodal data fusion;generative AI and mental health assessment},
  doi={10.1109/ACDSA65407.2025.11165999},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10421556,
  author={Cui, Di and Zhan, Xiaotiao and Sun, Guoqing},
  booktitle={2023 International Conference on Integrated Intelligence and Communication Systems (ICIICS)}, 
  title={Dangerous Behavior Image Recognition Algorithm of Smart Port Based on Deep Neural Network}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={In this paper, a new deep learning-based image recognition method is proposed to address the problems of existing image recognition methods. Through the depth neural network, the Generative adversarial network model is improved, so that the generated images can be classified, and the image recognition algorithm is optimized. And to verify the effectiveness of DNN in the application of image discrimination algorithm for dangerous behaviors in smart ports, this paper compares it with the traditional image recognition algorithm. The research results show that when the number of dangerous behavior images of Smart port is 500, it has been experimentally verified that its recognition accuracy can reach 94.40%, and the time required for image recognition is 0.29 seconds. This shows that the algorithm in this paper has high recognition accuracy, fast recognition speed, and can effectively identify dangerous behaviors in the port, which plays an important role in ensuring the safety of life and property of Smart port staff.},
  keywords={Image recognition;Communication systems;Artificial neural networks;Generative adversarial networks;Hazards;Behavioral sciences;Classification algorithms;image recognition algorithm;deep neural network;dangerous behavior;smart port},
  doi={10.1109/ICIICS59993.2023.10421556},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8932868,
  author={Arslan, Abdullah Taha and Seke, Erol},
  booktitle={2019 3rd International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT)}, 
  title={Training Wasserstein GANs for Estimating Depth Maps}, 
  year={2019},
  volume={},
  number={},
  pages={1-4},
  abstract={Depth maps depict pixel-wise depth association with a 2D digital image. Point clouds generation and 3D surface reconstruction can be conducted by processing a depth map. Estimating a corresponding depth map from a given input image is an important and difficult task in the computer vision field. Fortunately, with the advent of artificial intelligence, and especially deep learning based techniques new approaches for difficult tasks have been developed. One of the attractive structures is named as Generative Adversarial Network (GAN). However, training a GAN has been reported to be problematic in terms of optimization leading to some convergence issues. Vanishing or exploding gradients and mode collapses are some examples of these issues. Lately, several alternative optimization functions and distance measures have been investigated in order to handle these difficulties. Among these approaches, Wasserstein-1 distance and Wasserstein GAN (WGAN) offers a promising alternative. In this study, Wasserstein functions and its variants are investigated for the depth map estimation task from a given 2D face image. Different network structures are trained and compared in order to assess the effectiveness and stability. Quantitative analysis is conducted by calculating two separate error metrics between the network outputs and ground-truth values.},
  keywords={Generative adversarial networks;Training;Optimization;Face recognition;Three-dimensional displays;Task analysis;Estimation;depth estimation;3d reconstruction;generative adversarial networks;Wasserstein metric;artificial intelligence},
  doi={10.1109/ISMSIT.2019.8932868},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10578789,
  author={Balart, Trini and Shryock, Kristi J.},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Work in Progress: Empowering Engineering Education With ChatGPT: A Dive into the Potential and Challenges of Using AI for Tutoring}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={This research explores the integration of ChatGPT, an advanced AI language model, in engineering and computer science education. It investigates ChatGPT's effectiveness in enhancing learning outcomes, engagement, and skill development among first-year engineering students. Utilizing a mixed-method approach in an introductory programming course, the study compares the impact of ChatGPT, traditional teaching assistant support, and a combined method on student performance and perceptions. Anticipated findings aim to illuminate the benefits and challenges of AI tutoring, focusing on personalized learning experiences and ethical considerations in AI integration. This research contributes to the discourse on AI in education, highlighting its potential to transform educational practices and outcomes in engineering and computer science fields.},
  keywords={Ethics;Generative AI;Computational modeling;Scalability;Focusing;Transforms;Chatbots;Engineering education;Artificial intelligence;Computer science education;Educational technology;Intelligent tutoring system;Educational programs;Curriculum development},
  doi={10.1109/EDUCON60312.2024.10578789},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{11158957,
  author={Singh, Jogendra and Srivastava, Karunesh and Agrahari, Rajan},
  booktitle={2025 IEEE Wireless Antenna and Microwave Symposium (WAMS)}, 
  title={A Data-Driven Approach for Metasurface Design Using Conditional Genertaive Adversarial Network (cGAN)}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={Deep learning has become the very fascinating and popular tool to solve complex and non-linear databased problems in artificial intelligence. The inverse design of the metasurface is a very challenging task due to the non-linear relationship between spectrum and unit cell design. Conventional design of metasurface for target spectrum mainly is done using a trial and test basis which is very time-consuming and requires a lot of effort. In this paper, a Conditional Generative Adversarial Network (cGAN) has been used for the inverse design of a metasurface unit cell. Training of cGAN framework is done to generate metasurface designs for targeted sparameters with the rapid synthesis of structures to meet desired electromagnetic criteria. Mapping of sparameters and random noise to metasurface designs are done by the Generator while the discriminator ensures that the fabricated designs closely match the real structures by evaluating their authenticity. Results of the work reveal that the cGAN successfully models the relationship between spectrum data and metasurface configurations, achieving high design accuracy and diversity of structure. The proposed approach effectively increases the design process and provides an ascendable solution for engineering applications in photonics, antennas, and wavefront manipulation.},
  keywords={Training;Microwave antennas;Deep learning;Accuracy;Computational modeling;Metasurfaces;Generative adversarial networks;Generators;Scattering parameters;Inverse design;unit cell;metasurface;s-parameter;spectrum;deep learning;artificial intelligence;conditional Generative Adversarial Network (cGAN)},
  doi={10.1109/WAMS64402.2025.11158957},
  ISSN={},
  month={June},}@INPROCEEDINGS{9207466,
  author={Zhou, Qiongyi and Du, Changde and Li, Dan and Wang, Haibao and Liu, Jian K. and He, Huiguang},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Simultaneous Neural Spike Encoding and Decoding Based on Cross-modal Dual Deep Generative Model}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={Neural encoding and decoding of retinal ganglion cells (RGCs) have been attached great importance in the research work of brain-machine interfaces. Much effort has been invested to mimic RGC and get insight into RGC signals to reconstruct stimuli. However, there remain two challenges. On the one hand, complex nonlinear processes in retinal neural circuits hinder encoding models from enhancing their ability to fit the natural stimuli and modelling RGCs accurately. On the other hand, current research of the decoding process is separate from that of the encoding process, in which the liaison of mutual promotion between them is neglected. In order to alleviate the above problems, we propose a cross-modal dual deep generative model (CDDG) in this paper. CDDG treats the RGC spike signals and the stimuli as two modalities, which learns a shared latent representation for the concatenated modality and two modal-specific latent representations. Then, it imposes distribution consistency restriction on different latent space, cross-consistency and cycle-consistency constraints on the generated variables. Thus, our model ensures cross-modal generation from RGC spike signals to stimuli and vice versa. In our framework, the generation from stimuli to RGC spike signals is equivalent to neural encoding while the inverse process is equivalent to neural decoding. Hence, the proposed method integrates neural encoding and decoding and exploits the reciprocity between them. The experimental results demonstrate that our proposed method can achieve excellent encoding and decoding performance compared with the state-of-the-art methods on three salamander RGC spike datasets with natural stimuli.},
  keywords={Decoding;Encoding;Retina;Visualization;Brain modeling;Image reconstruction;Bidirectional control;dual learning;cross-modal generation;retinal ganglion cells;neural encoding;neural decoding},
  doi={10.1109/IJCNN48605.2020.9207466},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{9643241,
  author={Demke, Jonathan and Morain, Robert and Wilhelm, Connor and Ventura, Dan},
  booktitle={2021 IEEE 33rd International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Multi-agent Story-based Settlement Generation}, 
  year={2021},
  volume={},
  number={},
  pages={1149-1153},
  abstract={Video game content creation is a creative task that has typically been performed by 3D artists. While procedurally generated worlds provide the opportunity to create arbitrarily large cohesive environments, if the generated content lacks an integrated narrative, the environment may begin to feel generic and auto-generated; human artists can use story narratives to help them create 3D worlds which feel more "alive". This paper describes the StoryViz system which uses a short story as inspiration for generating a 3D settlement in Minecraft, leveraging swarm intelligence to optimize a set of rule-based interest functions. A user survey evaluating the system’s generated settlements provides a baseline for further development of the story visualization task.},
  keywords={Visualization;Three-dimensional displays;Conferences;Games;Task analysis;Particle swarm optimization;Artificial intelligence;computational creativity;narrative visualization;settlement generation;Minecraft;generative design},
  doi={10.1109/ICTAI52525.2021.00182},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{9731030,
  author={Chang, Dan and Xie, Wentao and Yu, Zhiqi},
  booktitle={2021 3rd International Conference on Machine Learning, Big Data and Business Intelligence (MLBDBI)}, 
  title={Handwriting Image Generation by Adversarial Training}, 
  year={2021},
  volume={},
  number={},
  pages={658-661},
  abstract={The generative adversarial network (GAN) has become a popular research direction in the field of artificial intelligence, which has been applied to the image and visual computing, speech and language processing, information security, chess games, etc. In this paper, using GAN to generate handwriting numerals, we propose a new framework to generate handwriting images through the confrontation process. To be specific, we train the generation model G and the discrimination model D iteratively. The generation model G aims to estimate the empirical data distribution. In contrast, the discrimination model D judges whether the input is a real data instance or a fake sample generated by G. The training process is an adversarial game. The generator learns to realistic synthetic data to fool the discriminator. In contrast, the discriminator tries to distinguish the fake data from the real data. In this way, G will gradually approach the empirical data distribution, thus deceiving the discriminator. As a result, the generator can generate plausible handwriting images. The experiment proved the potential of the framework by qualitatively and quantitatively evaluating the generated samples.},
  keywords={Training;Visualization;Computational modeling;Games;Machine learning;Generative adversarial networks;Generators;GAN;Digital Image Generation;Generation Model;Discrimination Model},
  doi={10.1109/MLBDBI54094.2021.00130},
  ISSN={},
  month={Dec},}@INBOOK{10952192,
  author={},
  booktitle={Mathematical Models Using Artificial Intelligence for Surveillance Systems}, 
  title={Front Matter}, 
  year={2024},
  volume={},
  number={},
  pages={i-xviii},
  abstract={<p>The prelims comprise: <ul> <li>Half&#x2010;Title Page</li> <li>Publisher Page</li> <li>Title Page</li> <li>Copyright Page</li> <li>Table of Contents</li> <li>Preface</li> </ul> </p>},
  keywords={},
  doi={10.1002/9781394200733.fmatter},
  ISSN={},
  publisher={Wiley},
  isbn={9781394200726},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952192},}@ARTICLE{10538272,
  author={Dubey, Shiv Ram and Singh, Satish Kumar},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Transformer-Based Generative Adversarial Networks in Computer Vision: A Comprehensive Survey}, 
  year={2024},
  volume={5},
  number={10},
  pages={4851-4867},
  abstract={Generative adversarial networks (GANs) have been very successful for synthesizing the images in a given dataset. The artificially generated images by GANs are very realistic. The GANs have shown potential usability in several computer vision applications, including image generation, image-to-image translation, and video synthesis. Conventionally, the generator network is the backbone of GANs, which generates the samples, and the discriminator network is used to facilitate the training of the generator network. The generator and discriminator networks are usually a convolutional neural network (CNN). The convolution-based networks exploit the local relationship in a layer, which requires the deep networks to extract the abstract features. However, recently developed transformer networks are able to exploit the global relationship with tremendous performance improvement for several problems in computer vision. Motivated from the success of transformer networks and GANs, recent works have tried to exploit the transformers in GAN framework for the image/video synthesis. This article presents a comprehensive survey on the developments and advancements in GANs utilizing the transformer networks for computer vision applications. The performance comparison for several applications on benchmark datasets is also performed and analyzed. The conducted survey will be very useful to understand the research trends and gaps related with transformer-based GANs and to develop the advanced GAN architectures by exploiting the global and local relationships for different applications.},
  keywords={Transformers;Generative adversarial networks;Generators;Computer vision;Computational modeling;Image synthesis;Surveys;Deep learning;generative adversarial networks (GANs);image and video synthesis;survey;transformer network},
  doi={10.1109/TAI.2024.3404910},
  ISSN={2691-4581},
  month={Oct},}@INPROCEEDINGS{10356537,
  author={Alexiou, Michail S. and Mertoguno, J. Sukarno},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={A Survey on Recent Advancements in Lightweight Generative Adversarial Networks, their Applications and Datasets}, 
  year={2023},
  volume={},
  number={},
  pages={269-278},
  abstract={Generative Adversarial Networks (GANs) have garnered significant research attention owing to their revolutionary generator-vs-discriminator architecture, making them versatile for various domains, including medical, military, and computer vision applications. Nevertheless, their computationally demanding nature during training and inference restricts their widespread adoption on mobile and edge devices. In this study, the latest advancements are explored in lightweight GAN implementations, considering their unique characteristics and diverse applications. The objective is to identify modifications that can enhance the efficiency of GAN-based models without compromising their robustness and accuracy, both for specific use-cases and in a more general context. Additionally, a discussion is presented on the availability of datasets suitable for lightweight GAN training and evaluation, as well as potential research directions for the future.},
  keywords={Surveys;Training;Military computing;Computational modeling;Neural networks;Generative adversarial networks;Feature extraction;Lightweight Neural Networks;Generative Adversarial Networks;Towards TinyML},
  doi={10.1109/ICTAI59109.2023.00047},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{9887491,
  author={Sankalpa, Donthi and Ramesh, Jayroop and Zualkernan, Imran},
  booktitle={2022 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT)}, 
  title={Using Generative Adversarial Networks for Conditional Creation of Anime Posters}, 
  year={2022},
  volume={},
  number={},
  pages={197-203},
  abstract={Japanese animation, known as anime, has become one of the most accessible forms of entertainment across globe. Recent advances in generative adversarial networks (GAN) and deep learning have contributed greatly to multiple interesting applications in the domain of anime, particularly in face generation, style transfer, and colorization. However, there are no existing implementations for generating composite anime posters with a genre accompaniment prompt. This work proposes a novel application of genre to anime poster generation conditioned on BERT-tokenized binary genre-tags of light-hearted or heavy-hearted categorized based on the thematic subject content of the medium. A dataset of 9,840 image with genre tags and synopses was constructed by scraping MyAnimeList. The conditional Deep Convolution GAN with Spectral Normalization produced the best posters, achieving the quantitative scores of FID: 90.17, average IS: 3.505, 1KNN with PSNR: 0.445 across inter-label discernability, and FID: 166.4, across genuine versus generated poster distinguishability. The primary contribution of this work is to present results outlining the feasibility of various GAN architectures in synthesizing controllable and complex composite anime posters. The larger implication of this project is to provide an introductory approach showing the promise of a creativity assistant for authors, artists, and animators, where they can simply enter a key phrase representing a concept they have in mind, to generate a baseline idea as an initial phase.},
  keywords={Training;Image quality;Deep learning;Image segmentation;Entertainment industry;Generative adversarial networks;Generators;Anime;Computer Generated Art;Deep Learning;Generative Adversarial Networks;Image Generation},
  doi={10.1109/IAICT55358.2022.9887491},
  ISSN={},
  month={July},}@INPROCEEDINGS{10833963,
  author={Liu, Yixuan and Wang, Lisha and Chen, Zhen and Lin, Weiran and Zhang, Lie and Hu, Yaodong and Xie, Xin},
  booktitle={2024 Artificial Intelligence x Humanities, Education, and Art (AIxHEART)}, 
  title={3D Designer Toy Design Methods Based on Generative AI and AI Agent}, 
  year={2024},
  volume={},
  number={},
  pages={18-22},
  abstract={As the market for designer toys expands, consumers are increasingly seeking toys that reflect their unique personalities. Generative AI technology presents a viable solution to cater to this demand. This article proposing innovative solutions that leverage multimodal models and agent technology, we summarizes two generative design methodologies and compares their respective merits, conducts a thorough analysis of the design and production processes of designer toys. The main idea objective is to explore the innovative applications of generative AI in the contemporary designer toy design.},
  keywords={Fans;Analytical models;Three-dimensional displays;Art;Generative AI;Design methodology;Toy manufacturing industry;Production;Designer Toy;Design;Multimodal Models;AI Agent;Generative AI;Comparative Study},
  doi={10.1109/AIxHeart62327.2024.00010},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11007904,
  author={Rizvi, Syeda Warisha Fatima and Ahmed, Fatimaelzahraa Ali and Qassmi, Noof and Al-Ali, Abdulla},
  booktitle={2025 International Conference on Unmanned Aircraft Systems (ICUAS)}, 
  title={Silent Drones: A Deep Learning Approach to Suppress Drone Propeller Noise}, 
  year={2025},
  volume={},
  number={},
  pages={1117-1123},
  abstract={Unmanned Aerial Vehicles (UAVs) provide many benefits and opportunities across a range of sectors, including surveillance, humanitarian work, disaster management, research, and transportation. Due to their accessibility and affordability, they are now used more than ever, which also poses some challenges. This is the noise pollution produced by the motors and propellers that has been highlighted as a significant issue to the people's health and the environment. To address this issue, this paper proposes to use Generative Adversarial Networks (GAN) to produce an inverse sound signal based on the drone's acoustic signals and use that to cancel the noise produced by the drone. We synthesize training data spanning the acoustic diversity of drone noise: steady-state propeller tones, rapid throttle transitions (simulating ascent/descent), and superimposed broadband turbulence. The GAN model is capable of adapting to dynamic settings, learning from data, and adjusting to testing conditions accordingly. We compared our proposed solution with other techniques that can also be used for drone signal interference in order to suppress the drone noise. This research idea paves the way for the need to address the issue created due to drone noise and a solution in managing this problem for modern drone applications.},
  keywords={Training;Adaptation models;Propellers;Transportation;Training data;Generative adversarial networks;Noise cancellation;Acoustics;Vehicle dynamics;Drones;Unmanned Vehicle Systems;Drones;Generative Adversarial Networks;Artificial Intelligence;Noise},
  doi={10.1109/ICUAS65942.2025.11007904},
  ISSN={2575-7296},
  month={May},}@ARTICLE{9491039,
  author={Huang, Shuo and Sun, Liang and Yousefnezhad, Muhammad and Wang, Meiling and Zhang, Daoqiang},
  journal={IEEE Transactions on Cognitive and Developmental Systems}, 
  title={Temporal Information-Guided Generative Adversarial Networks for Stimuli Image Reconstruction From Human Brain Activities}, 
  year={2022},
  volume={14},
  number={3},
  pages={1104-1118},
  abstract={Understanding how the human brain works has attracted increasing attention in both fields of neuroscience and machine learning. Previous studies use autoencoder and generative adversarial networks (GANs) to improve the quality of stimuli image reconstruction from functional magnetic resonance imaging (fMRI) data. However, these methods mainly focus on acquiring relevant features between two different modalities of data, i.e., stimuli images and fMRI, while ignoring the temporal information of fMRI data, thus leading to suboptimal performance. To address this issue, in this article, we propose a temporal information-guided GAN (TIGAN) to reconstruct visual stimuli from human brain activities. Specifically, the proposed method consists of three key components, including: 1) an image encoder for mapping the stimuli images into latent space; 2) a long short-term memory (LSTM) generator for fMRI feature mapping, which is used to capture temporal information in fMRI data; and 3) a discriminator for image reconstruction, which is used to make the reconstructed image more similar to the original image. In addition, to better measure the relationship of two different modalities of data (i.e., fMRI and natural images), we leverage a pairwise ranking loss to rank the stimuli images and fMRI to ensure strongly associated pairs at the top and weakly related ones at the bottom. The experimental results on real-world data sets suggest that the proposed TIGAN achieves better performance in comparison with several state-of-the-art image reconstruction approaches.},
  keywords={Visualization;Neuroscience;Functional magnetic resonance imaging;Reconstruction algorithms;Generative adversarial networks;Brain modeling;Loss measurement;Functional magnetic resonance imaging (fMRI);generative adversarial networks (GANs);long-short term memory;stimuli image reconstruction},
  doi={10.1109/TCDS.2021.3098743},
  ISSN={2379-8939},
  month={Sep.},}@INPROCEEDINGS{10670966,
  author={Fatima, Tehreem and Yang, Wenbiao and Xia, Kewen and Zia, Syed Muhammad Khalid Bin},
  booktitle={2024 3rd International Conference on Robotics, Artificial Intelligence and Intelligent Control (RAIIC)}, 
  title={Deep Learning Approach Combining GAN and BiGRU for Diabetes Prediction}, 
  year={2024},
  volume={},
  number={},
  pages={346-349},
  abstract={The increasing prevalence of diabetes in contemporary society underscores the pressing need for reliable and early diagnosis methods. However, accurately diagnosing diabetes poses significant challenges due to limitations in available datasets, often characterized by restrictions and imbalances. To address these constraints, an upgraded diabetes prediction model is proposed in this study, which combines a Bidirectional Gated Recurrent Unit (BiGRU) architecture with Generative Adversarial Network (GAN)-based data augmentation. By leveraging GAN, synthetic yet realistic samples are generated, thereby enriching the dataset and facilitating a more robust training procedure. The enhanced BiGRU model is subsequently employed for binary diabetes classification, exhibiting a noteworthy improvement in predictive accuracy. Remarkably, an astounding validation accuracy of $96.74 \%$ and test accuracy of $97.62 \%$ are achieved by our model, underscoring the efficacy of integrating GAN-based data augmentation with BiGRU for diabetes prediction. This study not only introduces a novel approach to medical data augmentation but also establishes a new standard for diabetes classification accuracy, thereby advancing the field of diabetes diagnosis.},
  keywords={Training;Accuracy;Predictive models;Generative adversarial networks;Data augmentation;Data models;Diabetes;Diabetes Prediction;Deep Learning;GAN;BiGRU},
  doi={10.1109/RAIIC61787.2024.10670966},
  ISSN={},
  month={July},}@INPROCEEDINGS{11135255,
  author={Manimegalai, R. and Sugumaran, S. and Lakshmi, S. and Lakshmibai, T and Kumar, T. Dinesh and Archana, M.A.},
  booktitle={2025 6th International Conference on Data Intelligence and Cognitive Informatics (ICDICI)}, 
  title={Harnessing GANs for Innovative Voice Generation in AI Applications}, 
  year={2025},
  volume={},
  number={},
  pages={497-502},
  abstract={Generative Adversarial Networks (GANs) have revolutionized artificial intelligence by enabling high-fidelity data generation across multiple domains. In speech processing, GANbased voice generation techniques have demonstrated remarkable improvements in realism, expressiveness, and adaptability. This paper explores the advancements in GAN-based voice synthesis, focusing on architectures such as WaveGAN, VoiceGAN, and MelGAN. We investigate their applications in text-to-speech (TTS) systems, voice cloning, and speech enhancement while addressing challenges related to training stability, mode collapse, and dataset biases. Additionally, we propose an optimized GAN framework for high-quality voice generation, validated through objective and subjective evaluations. Experimental results show that our method outperforms traditional models in naturalness, intelligibility, and diversity. This work contributes to the growing field of voice-based generative AI by providing insights into future trends and applications in human-computer interaction, assistive technologies, and digital content creation.},
  keywords={Training;Vocoders;Cloning;Computer architecture;Speech enhancement;Generative adversarial networks;Transformers;Stability analysis;Real-time systems;Text to speech;Generative Adversarial Networks;Voice Generation;Speech Synthesis;Text-to-Speech;AI in Audio Processing;Deep Learning;WaveGAN;MelGAN;Voice Cloning},
  doi={10.1109/ICDICI66477.2025.11135255},
  ISSN={},
  month={July},}@INPROCEEDINGS{9102895,
  author={Ma, Jupo and Wu, Jinjian and Li, Leida and Dong, Weisheng and Xie, Xuemei},
  booktitle={2020 IEEE International Conference on Multimedia and Expo (ICME)}, 
  title={Active Inference of GAN for No-Reference Image Quality Assessment}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={No-reference image quality assessment (NR-IQA) is a challenging task. It is a promising idea to design NR-IQA algorithms by mimicking how human visual system (HVS) works. The internal generative mechanism (IGM) indicates that HVS actively infers the primary content of an image for better understanding. Inspired by that, a novel NR-IQA method with active inference is proposed in this paper. First, a generative adversarial network (GAN) is proposed to predict the primary content of a distorted image, in which two IGM-inspired constraints are considered during the optimization. Next, based on the correlation between the distorted image and its primary content, different degradations (i.e., the content/distortion-/structure-dependency degradation) are measured simultaneously with a multi-stream convolutional neural network (CNN) for NR-IQA. Benefit from the primary content obtained from GAN and the multiple degradations measurement of CNN, our method achieves the state-of-the-art on five public IQA databases.},
  keywords={Degradation;Gallium nitride;Distortion measurement;Image quality;Databases;Distortion;Semantics;Blind Image Quality Assessment;Internal Generative Mechanism;Generative Adversarial Network;Convolutional Neural Network},
  doi={10.1109/ICME46284.2020.9102895},
  ISSN={1945-788X},
  month={July},}@INPROCEEDINGS{11069449,
  author={Mathur, Arpit and Shah, Kartik},
  booktitle={2025 3rd International Conference on Inventive Computing and Informatics (ICICI)}, 
  title={TSDCG: Tabular Synthetic Data with Code Generation LLMs}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={In the past years, there has been significant research on generating synthetic data, especially using Generative AI. Data engineering and analysis play crucial roles for any business in the study of past trends and forecasting future trends. However, real-world data often contains biases, missing values, and duplications, which limits its effectiveness in variety of tasks. Such issues can lead to model overfitting, underfitting, and poor generalization while training. To address these challenges, there has been extensive research on various GAN and LLM architectures and their ability to generate high quality synthetic data. This paper introduces and investigates a novel approach of using code-generating LLMs and advanced data profiling, in generating high quality synthetic data to enhance the speed and quality of the data generated.},
  keywords={Training;Codes;Generative AI;Large language models;Machine learning;Market research;Generative adversarial networks;Informatics;Synthetic data;Overfitting;Synthetic Data Generation;Generative Artificial Intelligence (AI);LLM (Large Language Model);Code Generation;Machine Learning},
  doi={10.1109/ICICI65870.2025.11069449},
  ISSN={},
  month={June},}@ARTICLE{11123609,
  author={Demir, Kaan and Nguyen, Bach Hoai and Xue, Bing and Zhang, Mengjie},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Multi-Label Black-Box Attacks via Evolutionary Structured Many-Objective Adversarial Perturbations}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Multi-label learning poses significant challenges due to the complexities of co-occurring labels. Adversarial examples are critical in safety-sensitive domains, where malicious tampered data can compromise models. Yet, their application to tabular multi-label learning remains under-explored, presenting a potential security risk. This paper introduces an adversarial training framework leveraging Evolutionary Computation, specifically the Covariance Matrix Adaptation Evolution Strategy (CMA-ES), to craft structured and concealable adversarial examples for tabular multi-label classifiers. Our contributions centre on an effective adversarial method tailored for tabulated multi-label learning, and a many-objective framework to balance the conflict between multi-label attack success, attack robustness, and attack concealability. We extend multi-label adversarial training to cope with tabulated data necessitating novel methods for generating structured adversarial examples and assessing attack concealability compared to image-based approaches—pioneering future research in tabulated multi-label adversarial training.Our framework also simulates real-world black-box attack scenarios where true model information is unknown. Our approach trains adversarial examples without prior knowledge of the target model by competing with a proxy model, progressively training more robust adversarial examples. Experiments show a high attack success rate (81.3–100%) across large datasets, significantly reducing multi-label classification performance post-perturbation and confirming the concealability of the attacks. Our results highlight the robustness of our approach, advancing adversarial training for multi-label, tabulated data.},
  keywords={Training;Perturbation methods;Multi label classification;Robustness;Closed box;Evolutionary computation;Data models;Computational modeling;Noise;Contracts;Adversarial perturbations;black-box attacks;evolutionary many-objective;multi-label;classification},
  doi={10.1109/TEVC.2025.3597966},
  ISSN={1941-0026},
  month={},}@INPROCEEDINGS{10473391,
  author={Hao, Jingbo},
  booktitle={2023 9th Annual International Conference on Network and Information Systems for Computers (ICNISC)}, 
  title={Medical Image Segmentation with Explainable Diffusion Models}, 
  year={2023},
  volume={},
  number={},
  pages={54-57},
  abstract={Diffusion models have made great success in image generation and own much potential in other vision tasks like image segmentation. With respect to medical image segmentation (MIS), model interpretability is indeed as important as model accuracy. This paper introduces the fundamental situation of MIS and typical diffusion model-related frameworks for MIS. Interpretability issues are also discussed in earnest.},
  keywords={Surveys;Computers;Image segmentation;Image synthesis;Computational modeling;Task analysis;Artificial intelligence;medical image segmentation;deep learning;model interpretability;diffusion model;explainable artificial intelligence},
  doi={10.1109/ICNISC60562.2023.00093},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10536148,
  author={Chen, Jiangong and Lan, Tian and Li, Bin},
  booktitle={2024 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, 
  title={GPT-VR Nexus: ChatGPT-Powered Immersive Virtual Reality Experience*}, 
  year={2024},
  volume={},
  number={},
  pages={01-02},
  abstract={The fusion of generative Artificial Intelligence (AI) like ChatGPT and Virtual Reality (VR) can unlock new interaction capabilities through natural language. We introduce GPT-VR Nexus, a novel framework creating a truly immersive VR experience driven by an underlying generative AI engine. It employs a two-step prompt strategy and robust post-processing procedures, without fine-tuning the complex AI model. Our experimental results show quick responses to various user audio requests/inputs.},
  keywords={Solid modeling;Three-dimensional displays;Generative AI;Conferences;Natural languages;Virtual reality;User interfaces;Human-centered computing—Human computer interaction (HCI)—Interaction paradigms—Virtual reality;Computing methodologies—Artificial intelligence—Distributed artificial intelligence—Intelligent agents;Computing methodologies—Artificial intelligence—Natural language processing—Natural language generation;Computing methodologies—Artificial intelligence—Naturallanguage processing—Speech recognition},
  doi={10.1109/VRW62533.2024.00383},
  ISSN={},
  month={March},}@ARTICLE{9773984,
  author={Hu, Li and Li, Jin and Lin, Guanbiao and Peng, Shiyu and Zhang, Zhenxin and Zhang, Yingying and Dong, Changyu},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={Defending Against Membership Inference Attacks With High Utility by GAN}, 
  year={2023},
  volume={20},
  number={3},
  pages={2144-2157},
  abstract={The success of machine learning (ML) depends on the availability of large-scale datasets. However, recent studies have shown that models trained on such datasets are vulnerable to privacy attacks, among which membership inference attack (MIA) brings serious privacy risk. MIA allows an adversary to infer whether a sample belongs to the training dataset of the target model or not. Though a variety of defenses against MIA have been proposed such as differential privacy and adversarial regularization, they also result in lower model accuracy and thus make the models less unusable. In this article, aiming at maintaining the accuracy while protecting the privacy against MIA, we propose a new defense against membership inference attacks by generative adversarial network (GAN). Specifically, sensitive data is used to train a GAN, then the GAN generate the data for training the actual model. To ensure that the model trained with GAN on small datasets can has high utility, two different GAN structures with special training techniques are utilized to deal with the image data and table data, respectively. Experiment results show that the defense is more effective on different data sets against the existing attack schemes, and is more efficient compared with most advanced MIA defenses.},
  keywords={Data models;Training;Generative adversarial networks;Privacy;Machine learning;Computational modeling;Training data;Membership inference attack;generative adversarial network;machine learning;privacy},
  doi={10.1109/TDSC.2022.3174569},
  ISSN={1941-0018},
  month={May},}@ARTICLE{10439020,
  author={Chen, Zuohui and Chen, Cheng and Shao, Chongyang and Cai, Chang and Song, Xujie and Chen, Cheng and Xiang, Yun and Liu, Ruigang and Xuan, Qi},
  journal={IEEE Sensors Journal}, 
  title={MITNet: GAN Enhanced Magnetic Induction Tomography Based on Complex CNN}, 
  year={2024},
  volume={24},
  number={20},
  pages={33573-33584},
  abstract={Magnetic induction tomography (MIT) is an efficient solution for long-term brain disease monitoring. It focuses on reconstructing the brain’s bio-impedance distribution through nonintrusive electromagnetic fields. However, high-quality reconstruction of brain images remains a significant challenge, as reconstructing images from weak and noisy signals is a highly nonlinear and ill-conditioned problem. In this work, we propose a generative adversarial network (GAN) enhanced MIT technique, named MITNet, based on a complex convolutional neural network (CNN). MITNet takes complex-valued signals as input and outputs a discretized conductivity distribution map. Our approach leverages the power of GANs to eliminate artifacts and enhance the reconstruction of object shapes. The experimental results on the real-world dataset validate the performance of our technique. The F1 score of MITNet surpasses the state-of-the-art stacked auto-encoder (SAE) method by 5.33% on the agar data.},
  keywords={Image reconstruction;Generative adversarial networks;Magnetic resonance imaging;Conductivity;Tomography;Mathematical models;Diseases;Deep neural network (DNN);electromagnetic inversion;electromagnetic tomography;generative adversarial networks (GANs);magnetic induction tomography (MIT)},
  doi={10.1109/JSEN.2024.3350742},
  ISSN={1558-1748},
  month={Oct},}@ARTICLE{10794750,
  author={Yang, Jiajun and Wang, Wenjing and Chen, Keyan and Liu, Liqin and Zou, Zhengxia and Shi, Zhenwei},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={Structural Representation-Guided GAN for Remote Sensing Image Cloud Removal}, 
  year={2025},
  volume={22},
  number={},
  pages={1-5},
  abstract={Optical remote sensing imagery is often compromised by cloud cover, making effective cloud-removal techniques essential for enhancing the usability of such data. We designed a novel structural representation-guided generative adversarial network (GAN) framework for cloud removal, in which structure and gradient branches are integrated into the network, helping the model focus on the structural representations of ground objects during image reconstruction. Different from previous methods that concentrate on recovering pixel information, we emphasize learning the structural information of remote sensing images. We then utilize error feedback to fuse features from the structural auxiliary branch, guiding the image reconstruction process. During the training phase, synthetic cloud images are used to supervise the optimization of the cloud-removal network, while real cloud images are employed in an adversarial training manner for unsupervised learning to improve the generalization ability of the network. Additionally, multitemporal revisit images from remote sensing satellites are employed as auxiliary inputs, aiding the network to remove thick clouds reliably. We evaluated our framework on a dataset derived from SEN12MS-CR, and the proposed method outperformed classical cloud-removal methods in both objective performance and subjective visual quality. Furthermore, compared to other methods, our approach achieved superior cloud-removal results on real images.},
  keywords={Remote sensing;Cloud computing;Training;Clouds;Image reconstruction;Generative adversarial networks;Decoding;Semantics;Synthetic data;Feature extraction;Cloud removal;generative adversarial network (GAN);optical remote sensing},
  doi={10.1109/LGRS.2024.3516078},
  ISSN={1558-0571},
  month={},}@INPROCEEDINGS{9792759,
  author={Shah, Bickey Kumar and Yadav, Anshul and Dixit, Ashutosh Kumar},
  booktitle={2022 International Conference on Applied Artificial Intelligence and Computing (ICAAIC)}, 
  title={License Plate Image Super Resolution Using Generative Adversarial Network(GAN)}, 
  year={2022},
  volume={},
  number={},
  pages={1139-1143},
  abstract={Super resolution of images in the field of Computer Vision is a widely used for the conversion of images into high resolution without the loss of pixel data into the images. Due to fast movement of vehicles and low quality of camera the image cannot be verified easily so, the techniques of Generative Adversarial network have been applied for the Super resolution of license plate Images which works to recover the loss data of license plate images without loss of pixel data. Earlier, mean square error (MS E) and peak signal to noise ratio (PSNR) was used as content loss to minimize the error but at optimal minimization the images get over smoothen and pixel data were lost. This paper has proposed and applied VGG-19 as pretrained neural network along with MSE and PSNR to minimize the content loss which overall optimizes the perpetual loss, and over smoothness of the images gets controlled which saves pixel data. Later, the pre-trained neural network is integrated with Generative Adversarial Network [GAN] of discriminator and generator to produce high resolution images. Taking the PSNR as an evaluation metrices for the images, it increases from 26.184 to 28.696 and accuracy from 58% to 84%.},
  keywords={Computer vision;Image resolution;PSNR;Neural networks;Mean square error methods;Generative adversarial networks;Super Resolution;Generator;Discriminator;Peak signal to noise ratio;VGG-19},
  doi={10.1109/ICAAIC53929.2022.9792759},
  ISSN={},
  month={May},}@INPROCEEDINGS{10092345,
  author={Allam, Sammar},
  booktitle={2023 20th Learning and Technology Conference (L&T)}, 
  title={AI-Based Use-Pattern Generative Hybrid Spaces for Indoor and Outdoor Activities}, 
  year={2023},
  volume={},
  number={},
  pages={54-58},
  abstract={This research explores machine learnt use-patter of human activities in outdoor and indoor spaces. It proposes scenarios to be used through Generative Adversarial Network for AI-Based use-pattern generative spaces. The study investigates futuristic AI-based life styles and its impact on the architectural spaces and clusters agglomeration. Clusters algorithmic design includes cellular automata and fractals in regards of stable null space as green nodes. Machine learnt use-pattern from daily activities incorporates a dynamic-responsive pixelation of spaces. The research manifest machine learnt algorithmic design and demonstrates IOT generative responsive spaces. A hybrid space of extended spatial reality that complies as well architectural boundaries has resulted using cellular responsive units/cells to include an extended reality (XR) part that supply the space with extended multiple activities. This hybrid space acts as a virtual and a real space that accommodates various functionalities with flexibilities relying on IOT, AI-based and XR technologies.},
  keywords={Legged locomotion;Image quality;Machine learning algorithms;Heuristic algorithms;Learning automata;Clustering algorithms;Null space;Keywords—Artificial Intelligence & Machine learning;Generative Space;Generative Adversarial Network;Internet of things (IOT);Green Nodes},
  doi={10.1109/LT58159.2023.10092345},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{8959865,
  author={Bai, Jing and Cao, Rui and Ma, Wen and Shinnou, Hiroyuki},
  booktitle={2019 International Conference on Technologies and Applications of Artiﬁcial Intelligence (TAAI)}, 
  title={Combination of Feature-based and Instance-based methods for Domain Adaptation in Sentiment Classification}, 
  year={2019},
  volume={},
  number={},
  pages={1-4},
  abstract={Methods of domain adaptation can be roughly divided into two categories: feature-based and instance-based. In summary, both methods are a kind of weighted-learning, but feature-based gives weight to features and instance-based gives weight to instance. Generally, feature-based is more effective than instance-based. However, these two methods can be combined to improve the accuracy of only the feature-based method. In this paper, we do it using the neural network model, where we use the feature-based method as SVD and instance-based method proposed in our previous work. In the experiment for the Amazon dataset, we confirmed the effectiveness of the proposed method.},
  keywords={Artificial neural networks;Adaptation models;Generative adversarial networks;Frequency measurement;Task analysis;Motion pictures;domain adaptation;feature-based;instance-based;neural network model},
  doi={10.1109/TAAI48200.2019.8959865},
  ISSN={2376-6824},
  month={Nov},}@INPROCEEDINGS{11005149,
  author={Sai, Sighakolli Dheeraj Venkata and Sathwik, Simma and Dhiraj, Solleti Venkata and Deekshith, Peddi and Lekshmi, C. R},
  booktitle={2025 International Conference on Inventive Computation Technologies (ICICT)}, 
  title={Ai-Powered Pencil Strokes: Face Sketch Synthesis Using Cyclegan and Style Transfer}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper introduces an AI-driven framework for face sketch synthesis using Cycle Generative Adversarial Networks (CycleGAN), enhanced with a style transfer module to improve the perceptual quality of generated sketches. Unlike conventional edge-detection or handcrafted filter-based techniques, our method leverages adversarial learning to capture intricate details, shading, and texture while maintaining structural coherence. By incorporating perceptual and edgeaware constraints into the objective function, the model enhances sketch quality. Qualitative analysis reveals progressive refinement over training epochs, while quantitative evaluation using the Structural Similarity Index (SSIM) confirms improved structural and perceptual similarity. The stable convergence of training loss further validates the model's effectiveness. Experimental results demonstrate that our approach generates highly realistic and visually appealing sketches, surpassing traditional methods in both fidelity and perceptual quality. Future work will focus on enhancing fine details and improving generalization across diverse datasets.},
  keywords={Training;Computational modeling;Computer architecture;Generative adversarial networks;Linear programming;Adversarial machine learning;Robustness;Indexes;Faces;Convergence;face-to-sketch;generative adversarial networks;CycleGAN;adversarial learning;SSIM},
  doi={10.1109/ICICT64420.2025.11005149},
  ISSN={2767-7788},
  month={April},}@INPROCEEDINGS{11016469,
  author={Haider, Sami Ahmed and Ahmad, Khwaja Mutahir and Akbar, Jehan and Soni, Mukesh and Keshta, Ismail and AlGhamdi, Azzah and Shahzadi, Hafiza Mahrukh},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Generative AI as a Catalyst for Transforming Transnational Engineering Education: Opportunities, Challenges, and Future Directions}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Generative Artificial Intelligence (GAI) is emerging as a transformative force that empowers transnational education (TNE) in engineering. Recent trends indicate a significant shift in the application of generative AI in engineering policies, academic research, business practices, and educational settings throughout TNE. Governments and organizations are transitioning from restrictive stances to developing guiding frameworks for its application, enabling cross-border collaboration in TNE. Numerous universities have permitted and even promoted the utilization of GAI. Furthermore, academic research around the world is looking into the pros and cons of GAI in engineering education, focusing on how it can help teachers and keep students interested. Industrial applications are diversifying, extending across disciplines, and TNE is occurring in engineering contexts, including cross-border programs. GAI possesses the capacity to transform TNE by revolutionizing talent development, reformulating engineering models, and facilitating scientific assessment across multinational frameworks. However, problems like the generative illusion, ethical and ideological risks, lack of trust between teachers and students, and new threats to TNE in engineering equity in global settings require substantial focus. This study examines these concerns and outlines potential strategies to leverage GAI for transnational education in engineering, offering stakeholders the opportunity to prioritize AI literacy among educators and learners. This work emphasizes that cross-disciplinary and collaborative R&D, following national and international standards, should tackle application hurdles while guaranteeing safety and inclusion. This study also addresses several future directions that can contribute to creating a unified framework and cost-effective solutions. These solutions, integrated with platforms like the National Smart Education Platform, can bridge digital divides, ensuring equitable access and enabling global TNE stakeholders to capitalize on the GAI revolution. We also provide several statistics and case studies to show the effectiveness of GAI over TNE in engineering and provide practical solutions for the incorporation of GAI into TNE within engineering frameworks, guaranteeing inclusivity and equity.},
  keywords={Ethics;Generative AI;Catalysts;Collaboration;Transforms;Market research;Safety;Stakeholders;Engineering education;Research and development;Transnational Education;Generative AI;ChatGPT;Technological Factors;Intelligent Computing;Artificial Intelligence},
  doi={10.1109/EDUCON62633.2025.11016469},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{9195680,
  author={Liu, Yongmin},
  booktitle={2020 IEEE Research and Applications of Photonics in Defense Conference (RAPID)}, 
  title={Accelerating the Design of Photonic Metamaterials by Artificial Intelligence}, 
  year={2020},
  volume={},
  number={},
  pages={1-2},
  abstract={In this talk, I will discuss how to accelerate the design of novel metamaterials by deep learning, a subset of artificial intelligence (AI) that learns multilevel abstraction of data using hierarchically structured layers. Different from the conventional approaches, deep learning can produce fast and accurate designs without the need of case-by-case and time-consuming numerical calculations or optimizations. The results show many exciting opportunities in the areas of optical design, integration and measurements when interfacing photonics with deep learning.},
  keywords={Metamaterials;Machine learning;Numerical models;Optical design;Photonics;Predictive models;Optical ring resonators},
  doi={10.1109/RAPID49481.2020.9195680},
  ISSN={},
  month={Aug},}
