@INPROCEEDINGS{10823294,
  author={Karunakaran, V and Akshaya, N and Harismita, B and Atchaya, S},
  booktitle={2024 International Conference on IoT Based Control Networks and Intelligent Systems (ICICNIS)}, 
  title={Lung Cancer Classification Using CNN with Data Augmentation}, 
  year={2024},
  volume={},
  number={},
  pages={1152-1157},
  abstract={Lung cancer remains a leading cause of cancer-related deaths globally. This study investigates the application of Convolutional Neural Networks (CNNs) for the classification of lung cancer using the IQ-OTH/NCCD lung cancer dataset. The study compares the performance of CNN models with and without data augmentation techniques. Experimental results demonstrate that CNN models with data augmentation exhibit superior performance, achieving higher accuracy, precision, F1-score, and recall compared to models trained without data augmentation. These findings highlight the importance of data augmentation in improving the accuracy and robustness of deep learning models for lung cancer classification, ultimately contributing to early detection and improved patient outcomes.},
  keywords={Measurement;Accuracy;Lung cancer;Data augmentation;Data models;Robustness;Convolutional neural networks;Intelligent systems;Standards;Medical diagnostic imaging;Convolutional Neural Networks;Data Augmentation;Classification and Lung Cancer},
  doi={10.1109/ICICNIS64247.2024.10823294},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10888884,
  author={Li, Jinye and Men, Aidong and Liu, Yang and Han, Pengda and Chen, Qingchao},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Radar2ECG: Multi-Scale Bottleneck Fusion and Cross-modal Semantic Distillation for Conditional Electrocardiogram Generation from Radar Heart Sound}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={The field of conditional Electrocardiogram(ECG) generation focuses on generating specified ECGs under given conditions for medical purposes. Existing methods are typically based on conditions of simple inputs like text or lead types. However, they struggle to handle the complexity of radar heart sound signals due to the lack of effective feature extraction, which hinders capturing the intricate waveform correlations between radar heart sounds and ECGs. Considering that radar-detected heart sound signals are contactless, the application is of essential value in a real-world deployment like sleep scenarios. Moreover, no prior approaches have addressed this specific task. To tackle this challenge, we propose a novel multi-scale feature fusion network framework, Radar2ECG. This model leverages pre-trained autoencoders for heart sound and ECG signals, aligning and integrating multi-layer features through a bottleneck structure to enhance receptive fields and reduce redundant features, thereby capturing the correlations between heart sounds and ECGs. Finally, we employ knowledge distillation to transfer knowledge from the ECG decoder to the heart sound decoder. We present three anomaly type datasets and extensive experiments conducted on both normal and abnormal datasets demonstrate that our method outperforms existing models in both accuracy and robustness. The multi-scale feature fusion significantly improves performance, showcasing strong potential in ECG generation and heart sound anomaly detection tasks.},
  keywords={Heart;Correlation;Semantics;Autoencoders;Radar;Electrocardiography;Feature extraction;Decoding;Speech processing;Anomaly detection;Radar-to-ECG;ECG synthesis;knowledge distillation},
  doi={10.1109/ICASSP49660.2025.10888884},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10984591,
  author={Wang, Yi and Shang, Xinping and Dong, A'ni and Zhang, Chulan},
  booktitle={2025 5th International Conference on Consumer Electronics and Computer Engineering (ICCECE)}, 
  title={Predicting Stroke Through Health Data Analysis and Stacking Integration Algorithm}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Stroke is the second leading cause of death worldwide and a significant contributor to the global burden of disability. This study aims to analyze health data from community residents using ensemble learning algorithms to screen for early stroke symptoms, enhancing the reliability and accuracy of predictions and reducing healthcare costs. We propose a Stacking Integration method, SIXCL, which combines three gradient boosting decision tree algorithms-XGBoost, CatBoost, and LightGBM-and integrates them with logistic regression with L2 regularization through stacking techniques. To address the extreme data imbalance, oversampling techniques were employed to balance the dataset. Experimental results demonstrate that the SIXCL method achieved a prediction accuracy of 96.4%, significantly outperforming single models. Furthermore, the study identified key factors influencing stroke prediction. This research provides a cost-effective approach to early stroke prevention and screening and offers recommendations for future stroke prevention strategies.},
  keywords={Accuracy;Machine learning algorithms;Prevention and mitigation;Stacking;Predictive models;Stroke (medical condition);Prediction algorithms;Boosting;Decision trees;Reliability;stroke prediction;boosting decision tree;integration method;stacking techniques},
  doi={10.1109/ICCECE65250.2025.10984591},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10402681,
  author={Wei, Hao and Ge, Chenyang and Qiao, Xin and Deng, Pengchao},
  booktitle={2023 IEEE International Conference on Visual Communications and Image Processing (VCIP)}, 
  title={Non-uniform Deblurring by Deep Sharpness Edge Guided Model}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={In this paper, we propose a two-branch deblurring framework. Given a blurred image, we first extract the edge map and employ an edge refinement network to recover the structure. Then the refined edge map is utilized to guide the subsequent deblurring process for correct structure recovery. Specifically, we develop a lightweight omni-dimensional attention module for long-range dependencies modeling and plug it into the edge refinement network, which effectively handles blur patterns with high variation. Furthermore, we propose a dynamic feature upsample module, which integrates dynamic convolution with upsampling and adaptively deals with the non-uniform blur. Extensive experiments show that our method outperforms state-of-the-art methods.},
  keywords={Adaptation models;Convolution;Visual communication;Image edge detection;Benchmark testing;Image restoration;Plugs;Image deblurring;edge guidance;long-range dependencies;dynamic convolution},
  doi={10.1109/VCIP59821.2023.10402681},
  ISSN={2642-9357},
  month={Dec},}@INPROCEEDINGS{10865505,
  author={Jiang, Haobin and Wang, Tianlei and Hu, Dinghan and Cao, Jiuwen},
  booktitle={2024 China Automation Congress (CAC)}, 
  title={Dual-Branch Speech Enhancement Network for Noise-Robust Automatic Speech Recognition}, 
  year={2024},
  volume={},
  number={},
  pages={5421-5426},
  abstract={Automatic speech recognition (ASR) has achieved remarkable successes thanks to the end-to-end deep neural networks, but it is still challenging in the noisy and reverberation environments. The joint training of front-end speech enhancement (SE) and speech recognition system becomes a popular solution to the noise-robust ASR. However, the speech distortion problem arisen due to excessive information suppression by the SE module. To address this issue, in this paper, a novel dual-branch SE (DBSE) module is proposed as the front-end of the ASR system for joint training. Particularly, the two branches extract the clean speeches using different ways: one branch directly extracts clean speeches and the other branch utilizes spectral subtraction method. The final denoising speech signals are obtained by combining the outputs from both branches. In this way, the oversuppressed information can be compensated from each other. The two-stage joint training strategy is adopted for the noise-robust ASR model where the proposed DBSE is first pretrained by multitask reconstruction loss, and then the DBSE and ASR model is jointly trained using the speech recognition based loss function. Comparisons with several state-of-the-art ASR algorithms on benchmark dataset are conducted, and the results demonstrate the superior performance of our proposed algorithm.},
  keywords={Training;Automation;Noise;Speech enhancement;Benchmark testing;Distortion;Noise robustness;Reverberation;Noise measurement;Automatic speech recognition;Automatic speech recognition;speech enhancement;dual-branch network;speech denoising},
  doi={10.1109/CAC63892.2024.10865505},
  ISSN={2688-0938},
  month={Nov},}@INPROCEEDINGS{10868922,
  author={Wu, Kaiyi and Ding, Jiaoyang and Li, Jingsen and Yang, Yuke and Zhang, Chen and Cao, Jiaxin},
  booktitle={2024 4th International Conference on Educational Technology (ICET)}, 
  title={LLM-Empowered Image Generation in the Neko Painter App: A Preliminary Application for Producing Teaching Materials}, 
  year={2024},
  volume={},
  number={},
  pages={110-114},
  abstract={This paper introduces the Neko Painter app and its key features, demonstrates the Large Language Models (LLMs)-empowered image generation with diffusion models and ContorlNet to be smarter and more automatic to control and optimise the image generation process, and shares some cases of using it to produce teaching materials. A preliminary application for producing teaching materials on General Studies using the Neko Painter app was conducted with 36 pre-service teachers from Hong Kong. The results showed that using LLM-empowered features positively impacts pre-service teachers’ motivation in producing teaching materials by using image generation. Future work will further explore the potential of LLM-empowered image generation in more educational subjects and scenarios.},
  keywords={Image synthesis;Large language models;Education;Process control;Educational technology;Diffusion models;Large Language Model (LLM);Image Generation;Neko Painter;Diffusion Models;Teaching Materials},
  doi={10.1109/ICET62460.2024.10868922},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9959483,
  author={Saffi, Houda and Hmamouche, Youssef and Elharrouss, Omar and El Fallah Seghrouchni, Amal},
  booktitle={2022 18th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)}, 
  title={Inception-based Deep Learning Architecture for 3D Point Cloud Completion}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={3D point clouds are a simple and compact data format that represents the surface geometry of 3D objects. The output of the data acquisition process often yields incomplete shapes. Hence, it is crucial to infer the missing regions of 3D objects from incomplete ones for many real-world applications. By leveraging a framework of 3D point cloud completion architectures, the proposed inception module is an intermediate layer that aims to extract the hierarchical features, recognize the fine-grained details of point clouds and avoid overfitting. We conduct comprehensive experiments on three state-of-the-art datasets: ShapeNet-55, ShapeNet-34, and PCN. The experimental results demonstrate that the enhanced architectures outperform the state-of-the-art point cloud completion methods.},
  keywords={Point cloud compression;Geometry;Three-dimensional displays;Shape;Surveillance;Streaming media;Feature extraction},
  doi={10.1109/AVSS56176.2022.9959483},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10507390,
  author={Li, Mei and Ai, Xinbo and Gu, Yanjun and Chen, Zhanghui},
  booktitle={2023 9th International Conference on Computer and Communications (ICCC)}, 
  title={A Hybrid Approach for Event Extraction in Safety Production}, 
  year={2023},
  volume={},
  number={},
  pages={2378-2382},
  abstract={Event extraction aims to identify events of interest from unstructured text and represent them in a structured format. However, due to the diversity and complexity of events, the current accuracy of event extraction remains low, particularly for sentences containing multiple events. Furthermore, existing event extraction studies have primarily focused on domains such as news, finance, and biomedicine, with limited application in the field of safety production. To address these challenges, this paper divides the event extraction task into two phases tailored to the characteristics of the safety production domain: event triple extraction and event classification. This approach achieves the extraction of essential event information and the categorization of event types through a phase-based extraction method. By extracting event triples based on dependent syntactic analysis and semantic role annotation, we can successfully match 84.64% of events according to the template and structure the event representations. Subsequently, the event classification task is performed on the event triples using the ELECTRA_TextRCNN model. In comparison to the TextRCNN model, our proposed ELECTRA_TextRCNN model demonstrates a 9% improvement in accuracy and a 7% increase in F1 value. Ultimately, we have significantly enhanced the accuracy of event extraction in the safety domain through a two-stage approach.},
  keywords={Semantics;Finance;Production;Organizations;Syntactics;Safety;Data mining;Event extraction;Information extraction;Text classification;safety production;HFACS},
  doi={10.1109/ICCC59590.2023.10507390},
  ISSN={2837-7109},
  month={Dec},}@ARTICLE{11115047,
  author={Jiang, Guangqi and Zhang, Ao and Liu, Yi and Wang, Huibing and Xu, Shoukun},
  journal={IEEE Signal Processing Letters}, 
  title={MVG-FD: Multi-Modal Visual Guidance and Feature Decomposition for Underwater Image Restoration}, 
  year={2025},
  volume={32},
  number={},
  pages={3305-3309},
  abstract={Underwater images are frequently affected by light absorption and scattering, which lead to color distortion, reduced contrast, and blurred details, significantly degrading overall image quality. Most underwater image restoration methods are confined to the pixel space of the raw modality, overlooking the important role of other modalities and different frequency-domain features. As a result, the representational capacity of deep learning models is not fully realized, affecting the generation of high-quality images. To address the above issues, we propose Multi-modal Visual Guidance and Feature Decomposition (MVG-FD) method for underwater image restoration. Specifically, we introduce Modality Visual Guidance (MVG) module, which integrates the complementary information provided by depth modality features into the raw features to guide the model in restoring the color of underwater images. Meanwhile, we design Feature Decomposition (FD) module, which utilizes Learnable Wavelet Decomposition (LWD) to decompose and extract the high-frequency bands of the raw features to help restore the texture details of the image. MVG-FD significantly improves PSNR and SSIM on existing datasets. The code is available at: https://github.com/zhangao668/MVG-FD.},
  keywords={Feature extraction;Image restoration;Convolution;Visualization;Image color analysis;Training;Data mining;Transformers;Foundation models;Testing;Underwater image restoration;multi-modal;feature decomposition},
  doi={10.1109/LSP.2025.3596447},
  ISSN={1558-2361},
  month={},}@INPROCEEDINGS{11168496,
  author={S, Mohammed Yaseen and Mohamed, Yaqub Moosa and Jacob, Chinnu},
  booktitle={2025 Advanced Computing and Communication Technologies for High Performance Applications (ACCTHPA)}, 
  title={Detecting AI-Generated Social Media Comments Using BERT-Extracted Semantic Style Features}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The rapid rise of artificial intelligence (AI) in generating synthetic content has raised significant concerns regarding the spread of fake news and political propaganda, especially in the context of India's 2024 elections. Identifying human-written comments and tweets amidst AI-generated ones is critical for mitigating such challenges. This paper proposes a method for detecting AI-generated comment by fine-tuning a BERT (Bidirectional Encoder Representations from Transformers) model for classification tasks. The BERT model is fine-tuned on a custom AI text classification dataset, incorporating a neural network classification head to distinguish between machine-generated text (MGT) and human-written text (HWT). A custom dataset of YouTube comments, consisting of both human-written and AI-generated comments, is constructed to evaluate the model's performance in real-world social media scenarios. The model is fine-tuned on this dataset to detect AI-generated comments in social media discussions. To further analyze the discriminative capabilities of the model, Principal Component Analysis (PCA) is applied to visualize the embeddings. The results indicate that the fine-tuned BERT model effectively captures semantic patterns and separates AI comments and human comments into distinct regions in the embedding space, with a clear decision boundary between the two classes. This approach demonstrates the potential of fine-tuned transformer-based models for detecting AI-generated text and offers a robust solution to countering AI-driven misinformation on social media platforms.},
  keywords={Visualization;Social networking (online);Semantics;Text categorization;Bidirectional control;Transformers;Encoding;Natural language processing;Fake news;Principal component analysis;AI-generated text;BERT;Text classification;Transformer models;Natural Language Processing (NLP);Semantic analysis;Text embeddings},
  doi={10.1109/ACCTHPA65749.2025.11168496},
  ISSN={},
  month={July},}@INPROCEEDINGS{10657743,
  author={Kim, S. Y. and Chung, H. B. and Lee, J. S. and Kang, M. J.},
  booktitle={2024 IEEE Nuclear Science Symposium (NSS), Medical Imaging Conference (MIC) and Room Temperature Semiconductor Detector Conference (RTSD)}, 
  title={EDM: Enhancing Quality Diversity of Medical Image Augmentation Under the User-specified Complex and Various Conditions}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={In the medical domain, the scarcity of data leads to class imbalances and fairness issues, significantly impairing deep learning performance and leading to the underrepresentation of minority patient groups. To address these challenges, data augmentation techniques employing Generative Adversarial Networks (GANs) and diffusion models have been extensively explored, with diffusion models particularly noted for their ability to enhance data diversity and quality. Despite their achievements, it remains a challenging task to generate a diverse range of samples from limited datasets and to achieve precise generation of images that align with user intentions.To overcome these limitations, we propose a framework, EDM (Enhancing Quality Diversity of Medical image augmentation under the user-specified complex and various conditions), designed to generate diverse high-quality medical images under the various and complex multimodal conditions, representing age, sex, and diseases. Our framework comprises four steps. First, we propose a metric to quantize the necessity of data augmentation. Second, we prepare data augmentation. We generate medical sketch-image-text triplets using DiffSketcher from the real patients’ dataset. Then we employ these triplets to train ControlNet, enabling the generation of synthetic medical images from sketch data. Third, we generate synthetic medical images. We obtain multiple sketches for each image from a diversity-enhanced DiffSketcher, incorporating similarity loss. Using these sketches, we augment data from the fine-tuned ControlNet from the second step. Lastly, we introduce a metric to measure the diversity of the generated images, ensuring the effectiveness of our augmentation process.Our preliminary experimental results imply EDM can be the promising solution. Future experiments are planned to construct synthetic datasets of various modalities such as PET and CT for underrepresented patient groups.},
  keywords={Semiconductor device measurement;Microwave integrated circuits;Semiconductor detectors;Data augmentation;Diffusion models;Generative adversarial networks;Image augmentation},
  doi={10.1109/NSS/MIC/RTSD57108.2024.10657743},
  ISSN={2577-0829},
  month={Oct},}@ARTICLE{10552157,
  author={Du, Chenghu and Xiong, Shengwu},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={MuSAnet: Monocular-to-3-D Human Modeling via Multi-Scale Spatial Awareness}, 
  year={2024},
  volume={70},
  number={3},
  pages={5115-5127},
  abstract={Monocular-to-3D human modeling involves creating colored three-dimensional models of humans from monocular try-on images. This technology offers personalized services to consumers and has garnered considerable attention for its potential business value. However, current methods are unable to deform clothing images to align with the human body naturally. Additionally, the generation of low-quality monocular try-on images severely hinders the creation of high-precision human models. This paper presents a novel monocular-to-3D human modeling network capable of accurately generating 3D models from monocular try-on images. To improve the accuracy of clothing deformation, an enhanced non-rigid deformation constraint strategy is introduced. This strategy helps reduce excessive deformation by strengthening penalties for outliers. Additionally, occlusion is addressed by implementing strict boundary constraints, resulting in more realistic and natural deformation outcomes. Furthermore, a stepped spatial-aware block is proposed to fuse latent multi-scale shape features in person images during depth estimation. This approach allows for creating high-precision person models in a single stage, enhancing the overall quality of the generated 3D models. Experiments conducted on the MPV-3D dataset demonstrate the superiority of the method. Regarding human modeling, Abs. decreased from 7.88 to 7.38, Sq. from 0.39 to 0.34, and RMSE from 11.27 to 10.66.},
  keywords={Clothing;Deformation;Three-dimensional displays;Deformable models;Computational modeling;Generative adversarial networks;Monocular-to-3D human modeling;virtual try-on;generative adversarial network;consumer technology},
  doi={10.1109/TCE.2024.3410989},
  ISSN={1558-4127},
  month={Aug},}@INPROCEEDINGS{10047554,
  author={Srinu, Nidamanuri and Bindu, Bejawada Hima},
  booktitle={2022 International Conference on Power, Energy, Control and Transmission Systems (ICPECTS)}, 
  title={A Review on Machine Learning and Deep Learning based Rainfall Prediction Methods}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  abstract={Water for farming and storage capacity in dams are both affected by the quantity of precipitation that falls. Predicting when and how much rain will fall is challenging because of global warming and other variables. Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) may use factors like the amount of rainfall in previous years, climatic change, climatic conditions, and so on to forecast rainfall in a given area. Potential flooding and damage to man-made structures might result from unexpected rainfall. Comprehensive data categorization and investigation, evaluation, inquiry, and interpretations are needed to uncover rainfall that will help governments avert human deaths, agricultural failures, and animal fatalities. The development of ML and DL systems is ongoing to assess and manage crucial rainfall data. Therefore, the purpose of this research is to investigate the potential of using ML and DL approaches to forecast precipitation for future planning of human settlements and related activities. Prediction methods in ML are investigated, including regression, Convolutional Neural Networks (CNNs), and Long-Short Term Memory (LSTM). The benefits and drawbacks of using neural network algorithms and ML algorithms are also discussed in this paper, with each approach taking into account the data and features at hand. New developments in the field of precipitation forecasting are also covered, including studies that use a wide range of feature extraction and prediction methods. In this study, we discuss many ML methods and algorithms for predicting rainfall based on historical data and other criteria.},
  keywords={Deep learning;Rain;Biological system modeling;Weather forecasting;Predictive models;Prediction algorithms;Generative adversarial networks;Climate change;Farming;Rainfall;Review;Deep Learning;Machine Learning},
  doi={10.1109/ICPECTS56089.2022.10047554},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10986870,
  author={Hebbar, Aniketh and Rasheed, Shahil and Kl, Spoorthi and Mustafa, Sarah and Santhosh, Soumya},
  booktitle={2025 International Conference on Artificial Intelligence and Data Engineering (AIDE)}, 
  title={Text-to-Voice Conversion for Indic Languages}, 
  year={2025},
  volume={},
  number={},
  pages={346-352},
  abstract={The demand for sophisticated Text-to-Speech (TTS) systems is rising due to linguistic diversity, with Indic languages posing particular difficulties. Conventional text-to-speech (TTS) synthesis algorithms frequently fall short in capturing the rich expressiveness and subtle cultural nuances of Indic languages, resulting in an artificial voice output devoid of authentic prosody. By integrating the HiFi-GAN for high-fidelity voice cloning and the Tortoise TTS framework into a hybrid TTS architecture, this solution suggests a novel way to get beyond these restrictions. Allowing the system to pick up on and replicate the complex patterns and nuanced subtleties of Indic speech. High-fidelity waveforms are effectively synthesized from mel-spectrograms by the HiFi-GAN vocoder, while extremely expressive and natural-sounding speech waveforms are produced by the Tortoise TTS model, which is based on Denoising Diffusion Restoration Models. High-quality training data is ensured via a complex data processing pipeline that includes silence reduction, audio segmentation, and transcription filtering. The suggested system performs much better than current TTS systems on both Mean Opinion Score (MOS) and Comparative Mean Opinion Score (CMOS) according to extensive subjective evaluations.},
  keywords={Semiconductor device modeling;Filtering;Vocoders;Pipelines;Noise reduction;Training data;Linguistics;Generative adversarial networks;Hybrid power systems;Text to speech;Text-to-Speech;Indic languages;Deep learning;Hybrid architectures;Tortoise TTS;High-Fidelity Generative Adversarial Network (HiFi-GAN)},
  doi={10.1109/AIDE64228.2025.10986870},
  ISSN={},
  month={Feb},}@ARTICLE{9703109,
  author={Chen, Yutong and Schönlieb, Carola-Bibiane and Liò, Pietro and Leiner, Tim and Dragotti, Pier Luigi and Wang, Ge and Rueckert, Daniel and Firmin, David and Yang, Guang},
  journal={Proceedings of the IEEE}, 
  title={AI-Based Reconstruction for Fast MRI—A Systematic Review and Meta-Analysis}, 
  year={2022},
  volume={110},
  number={2},
  pages={224-245},
  abstract={Compressed sensing (CS) has been playing a key role in accelerating the magnetic resonance imaging (MRI) acquisition process. With the resurgence of artificial intelligence, deep neural networks and CS algorithms are being integrated to redefine the state of the art of fast MRI. The past several years have witnessed substantial growth in the complexity, diversity, and performance of deep-learning-based CS techniques that are dedicated to fast MRI. In this meta-analysis, we systematically review the deep-learning-based CS techniques for fast MRI, describe key model designs, highlight breakthroughs, and discuss promising directions. We have also introduced a comprehensive analysis framework and a classification system to assess the pivotal role of deep learning in CS-based acceleration for MRI.},
  keywords={Deep learning;Systematics;Magnetic resonance imaging;Neural networks;Complexity theory;Artificial intelligence;Compressed sensing;Compressed sensing (CS);deep learning;magnetic resonance imaging (MRI);neural network},
  doi={10.1109/JPROC.2022.3141367},
  ISSN={1558-2256},
  month={Feb},}@INPROCEEDINGS{4587722,
  author={Xiaogang Wang and Kinh Tieu and Grimson, W. Eric L.},
  booktitle={2008 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Correspondence-free multi-camera activity analysis and scene modeling}, 
  year={2008},
  volume={},
  number={},
  pages={1-8},
  abstract={We propose a novel approach for activity analysis in multiple synchronized but uncalibrated static camera views. We assume that the topology of camera views is unknown and quite arbitrary, the fields of views covered by these cameras may have no overlap or any amount of overlap, and objects may move on different ground planes. Using low-level cues, objects are tracked in each of the camera views independently, and the positions and velocities of objects along trajectories are computed as features. Under a generative model, our approach jointly learns the distribution of an activity in the feature spaces of different camera views. It accomplishes two tasks: (1) grouping trajectories in different camera views belonging to the same activity into one cluster; (2) modeling paths commonly taken by objects across camera views. To our knowledge, no prior result of co-clustering trajectories in multiple camera views has been published. Advantages of this approach are that it does not require first solving the challenging correspondence problem, and the learning is unsupervised. Our approach is evaluated on two very large data sets with 22, 951 and 14, 985 trajectories.},
  keywords={Layout;Surveillance;Monitoring;Computer science;Artificial intelligence;Smart cameras;Trajectory;Streaming media;Network topology;History},
  doi={10.1109/CVPR.2008.4587722},
  ISSN={1063-6919},
  month={June},}@INPROCEEDINGS{1467429,
  author={Taycher, L. and Fisher, J.W. and Darrell, T.},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)}, 
  title={Combining object and feature dynamics in probabilistic tracking}, 
  year={2005},
  volume={2},
  number={},
  pages={106-113 vol. 2},
  abstract={Objects can exhibit different dynamics at different scales, and this is often exploited by visual tracking algorithms. A local dynamic model is typically used to extract image features that are then used as input to a system for tracking the entire object using a global dynamic model. Approximate local dynamics may be brittle - point trackers drift due to image noise and adaptive background models adapt to foreground objects that become stationary - but constraints from the global model can make them more robust. We propose a probabilistic framework for incorporating global dynamics knowledge into the local feature extraction processes. A global tracking algorithm can be formulated as a generative model and used to predict feature values that are incorporated into an observation process of the feature extractor. We combine such models in a multichain graphical model framework. We show the utility of our framework for improving feature tracking and thus shape and motion estimates in a batch factorization algorithm. We also propose an approximate filtering algorithm appropriate for online applications, and demonstrate its application to background subtraction.},
  keywords={Feature extraction;Hidden Markov models;Computer science;Artificial intelligence;Laboratories;Background noise;Noise robustness;Predictive models;Graphical models;Tracking},
  doi={10.1109/CVPR.2005.102},
  ISSN={1063-6919},
  month={June},}@INPROCEEDINGS{5543434,
  author={Lashkari, Danial and Sridharan, Ramesh and Vul, Edward and Hsieh, Po-Jang and Kanwisher, Nancy and Golland, Polina},
  booktitle={2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops}, 
  title={Nonparametric hierarchical Bayesian model for functional brain parcellation}, 
  year={2010},
  volume={},
  number={},
  pages={15-22},
  abstract={We develop a method for unsupervised analysis of functional brain images that learns group-level patterns of functional response. Our algorithm is based on a generative model that comprises two main layers. At the lower level, we express the functional brain response to each stimulus as a binary activation variable. At the next level, we define a prior over the sets of activation variables in all subjects. We use a Hierarchical Dirichlet Process as the prior in order to simultaneously learn the patterns of response that are shared across the group, and to estimate the number of these patterns supported by data. Inference based on this model enables automatic discovery and characterization of salient and consistent patterns in functional signals. We apply our method to data from a study that explores the response of the visual cortex to a collection of images. The discovered profiles of activation correspond to selectivity to a number of image categories such as faces, bodies, and scenes. More generally, our results appear superior to the results of alternative data-driven methods in capturing the category structure in the space of stimuli.},
  keywords={Bayesian methods;Brain modeling;Independent component analysis;Layout;Testing;Computer science;Artificial intelligence;Laboratories;Image analysis;Pattern analysis},
  doi={10.1109/CVPRW.2010.5543434},
  ISSN={2160-7516},
  month={June},}@INPROCEEDINGS{9668602,
  author={Aneja, Sandhya and En, Melanie Ang Xuan and Aneja, Nagender},
  booktitle={2022 14th International Conference on COMmunication Systems & NETworkS (COMSNETS)}, 
  title={Collaborative adversary nodes learning on the logs of IoT devices in an IoT network}, 
  year={2022},
  volume={},
  number={},
  pages={231-235},
  abstract={Artificial Intelligence (AI) development has encouraged many new research areas, including AI-enabled Internet of Things (IoT) network. AI analytics and intelligent paradigms greatly improve learning efficiency and accuracy. Applying these learning paradigms to network scenarios provide technical advantages of new networking solutions. In this paper, we propose an improved approach for IoT security from data perspective. The network traffic of IoT devices can be analyzed using AI techniques. The Adversary Learning (AdLIoTLog) model is proposed using Recurrent Neural Network (RNN) with attention mechanism on sequences of network events in the network traffic. We define network events as a sequence of the time series packets of protocols captured in the log. We have considered different packets TCP packets, UDP packets, and HTTP packets in the network log to make the algorithm robust. The distributed IoT devices can collaborate to cripple our world which is extending to Internet of Intelligence. The time series packets are converted into structured data by removing noise and adding timestamps. The resulting data set is trained by RNN and can detect the node pairs collaborating with each other. We used the BLEU score to evaluate the model performance. Our results show that the predicting performance of the AdLIoTLog model trained by our method degrades by 3-4% in the presence of attack in comparison to the scenario when the network is not under attack. AdLIoTLog can detect adversaries because when adversaries are present the model gets duped by the collaborative events and therefore predicts the next event with a biased event rather than a benign event. We conclude that AI can provision ubiquitous learning for the new generation of Internet of Things.},
  keywords={Performance evaluation;Recurrent neural networks;Protocols;Time series analysis;Collaboration;Telecommunication traffic;Predictive models;Deep learning;recurrent neural network;gated recurrent unit;internet of things;adversary},
  doi={10.1109/COMSNETS53615.2022.9668602},
  ISSN={2155-2509},
  month={Jan},}@INPROCEEDINGS{5074650,
  author={Golland, Polina and Lashkari, Danial and Venkataraman, Archana},
  booktitle={2008 42nd Asilomar Conference on Signals, Systems and Computers}, 
  title={Spatial patterns and functional profiles for discovering structure in fMRI data}, 
  year={2008},
  volume={},
  number={},
  pages={1402-1409},
  abstract={We explore unsupervised, hypothesis-free methods for fMRI analysis in two different types of experiments. First, we employ clustering to identify large-scale functionally homogeneous systems. We formulate a generative mixture model, derive the EM algorithm and apply it to delineate functional systems. We also investigate spectral clustering in application to this problem and demonstrate that both methods give rise to similar partitions of the brain based on resting state fMRI data. Second, we demonstrate how to extend this approach to include information about the experimental protocol. Specifically, we formulate a mixture model in the space of possible profiles of brain response to stimuli. In both applications, our methods confirm previously known results in brain mapping and point to new research directions for exploratory analysis of fMRI data.},
  keywords={Independent component analysis;Pattern analysis;Protocols;Image analysis;Principal component analysis;Brain modeling;Computer science;Artificial intelligence;Laboratories;Paper technology},
  doi={10.1109/ACSSC.2008.5074650},
  ISSN={1058-6393},
  month={Oct},}@ARTICLE{10985830,
  author={Xu, Wei and Zhou, Tianfei and Zhang, Taoyuan and Li, Jie and Chen, Peiyin and Pan, Jia and Liu, Xiaofeng},
  journal={IEEE Transactions on Cognitive and Developmental Systems}, 
  title={Exploring Grounding Abilities in Vision-Language Models through Contextual Perception}, 
  year={2025},
  volume={},
  number={},
  pages={1-14},
  abstract={Vision language models (VLMs) have demonstrated strong general capabilities and achieved great success in areas such as image understanding and reasoning. Visual prompts enhance the focus of VLMs on designated areas, but their fine-grained grounding has not been fully developed. Recent research has used Set-of-Mark (SoM) approach to unleash the grounding capabilities of Generative Pre-trained Transformer-4 with Vision (GPT-4V), achieving significant benchmark performance. However, SoM still has problems with label offset and hallucination of vision language models, and the grounding ability of VLMs remains limited, making it challenging to handle complex scenarios in human-robot interaction. To address these limitations and provide more accurate and less hallucinatory results, we propose Contextual Set-of-Mark (ConSoM), a new SoM-based prompting mechanism that leverages dual-image inputs and contextual semantic information of images. Experiments demonstrate that ConSoM has distinct advantages in visual grounding, improving by 11% compared to the baseline on the dataset Refcocog. Furthermore, we evaluated ConSoM’s grounding abilities in five indoor scenarios, where it exhibited strong robustness in complex environments and under occlusion conditions. We also introduced a scalable annotation method for pixel-level question-answering dataset. The accuracy, scalability, and depth of world knowledge make ConSoM a highly effective approach for future human-robot interactions.},
  keywords={Robots;Visualization;Grounding;Large language models;Artificial intelligence;Human-robot interaction;Accuracy;Semantics;Robot kinematics;Prompt engineering;Large language model;prompt engineering;visual grounding;human-robot interaction},
  doi={10.1109/TCDS.2025.3566649},
  ISSN={2379-8939},
  month={},}@INPROCEEDINGS{11079082,
  author={Olowe, Emmanuel A. and Chitnis, Danial},
  booktitle={2025 IEEE International Instrumentation and Measurement Technology Conference (I2MTC)}, 
  title={TMIQ: Quantifying Test and Measurement Domain Intelligence in Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The Test and Measurement domain, known for its strict requirements for accuracy and efficiency, is increasingly adopting Generative AI technologies to enhance the performance of data analysis, automation, and decision-making processes. Among these, Large Language Models (LLMs) show significant promise for advancing automation and precision in testing. However, the evaluation of LLMs in this specialized area remains insufficiently explored. To address this gap, we introduce the Test and Measurement Intelligence Quotient (TMIQ), a benchmark designed to quantitatively assess LLMs across a wide range of electronic engineering tasks. TMIQ offers a comprehensive set of scenarios and metrics for detailed evaluation, including SCPI command matching accuracy, ranked response evaluation, Chain-of-Thought Reasoning (CoT), and the impact of output formatting variations required by LLMs on performance. In testing various LLMs, our findings indicate varying levels of proficiency, with exact SCPI command match accuracy ranging from around 56% to 73%, and ranked matching first-position scores achieving around 33% for the best-performing model. We also assess token usage, cost-efficiency, and response times, identifying trade-offs between accuracy and operational efficiency. Additionally, we present a command-line interface (CLI) tool that enables users to generate datasets using the same methodology, allowing for tailored assessments of LLMs. TMIQ and the CLI tool provide a rigorous, reproducible means of evaluating LLMs for production environments, facilitating continuous monitoring and identifying strengths and areas for improvement, and driving innovation in their selections for applications within the Test and Measurement industry.},
  keywords={Industries;Technological innovation;Accuracy;Automation;Large language models;Production;Benchmark testing;Cognition;Time factors;Standards;Artificial intelligence;Large language models;Synthetic LLM Benchmark;Test and measurement;Electronic engineering;Automation},
  doi={10.1109/I2MTC62753.2025.11079082},
  ISSN={2642-2077},
  month={May},}@INPROCEEDINGS{9679936,
  author={Liu, Shuo and Xu, Liwen},
  booktitle={2021 International Conference on Data Mining Workshops (ICDMW)}, 
  title={Anomaly Detection with Dual Adversarial Training}, 
  year={2021},
  volume={},
  number={},
  pages={466-473},
  abstract={Anomaly detection is of paramount importance in data mining and artificial intelligence. Deep generative models have been widely used in anomaly detection as a dominant paradigm to model complex and high-dimensional data distribution. However, developing effective and robust anomaly detection systems for complex and high-dimensional data using generative models remains a challenge. In this paper, we propose a novel Dual Adversarial Training method for Anomaly Detection (DAT-AD), which uses the adversarial training idea in Generative Adversarial Network (GAN) and the Virtual Adversarial Training (VAT) idea to improve the effectiveness and robustness of anomaly detector, respectively. In addition, we have also carefully designed the network architecture and the loss function of our method to ensure that the trained network can be utilized to the greatest extent. We demonstrate the superiority of our method by conducting various experiments on tabular and image data.},
  keywords={Training;Conferences;Detectors;Network architecture;Benchmark testing;Generative adversarial networks;Data models;data mining;anomaly detection;deep generative model;virtual adversarial training},
  doi={10.1109/ICDMW53433.2021.00063},
  ISSN={2375-9259},
  month={Dec},}@ARTICLE{8930532,
  author={Cai, Yali and Wang, Xiaoru and Yu, Zhihong and Li, Fu and Xu, Peirong and Li, Yueli and Li, Lixian},
  journal={IEEE Access}, 
  title={Dualattn-GAN: Text to Image Synthesis With Dual Attentional Generative Adversarial Network}, 
  year={2019},
  volume={7},
  number={},
  pages={183706-183716},
  abstract={Recent generative adversarial network based methods have shown promising results for the charming but challenging task of synthesizing images from text descriptions. These approaches can generate images with general shape and color but often produce distorted global structures with unnatural local semantic details. It is due to ineffectiveness of convolutional neural networks in capturing the high-level semantic information for pixel-level image synthesis. In this paper, we propose a Dual Attentional Generative Adversarial Network (DualAttn-GAN) in which the dual attention modules are introduced to enhance local details and global structures by attending to related features from relevant words and different visual regions. As one of the dual modules, the textual attention module is designed to explore the fine-grained interaction between vision and language. On the other hand, visual attention module models internal representations of vision from channel and spatial axes, which can better capture the global structures. Meanwhile, we apply an attention embedding module to merge multi-path features. Furthermore, we present an inverted residual structure to boost representation power of CNNs and apply spectral normalization to stabilize GAN training. With extensive experimental validation on two benchmark datasets, our method significantly improves state-of-the-art models over the evaluation metrics of inception score and Fréchet inception distance.},
  keywords={Visualization;Generative adversarial networks;Gallium nitride;Semantics;Training;Image synthesis;Task analysis;Generative adversarial network;textual attention;visual attention;inverted residual structure;spectral normalization},
  doi={10.1109/ACCESS.2019.2958864},
  ISSN={2169-3536},
  month={},}@ARTICLE{8645630,
  author={Li, Zhi and Zhang, Juan and Fang, Zhijun and Huang, Bo and Jiang, Xiaoyan and Gao, Yongbin and Hwang, Jenq-Neng},
  journal={IEEE Access}, 
  title={Single Image Snow Removal via Composition Generative Adversarial Networks}, 
  year={2019},
  volume={7},
  number={},
  pages={25016-25025},
  abstract={Snowflakes attached to the camera lens can severely affect the visibility of the background scene and compromise the image quality. In this paper, we solve this problem by visually removing snowflakes to convert the snowy image into a clean one. The problem is troublesome; the information about the background of the occluded regions is completely lost for the most part. For removing snowflakes from a single image, we proposed a composition generative adversarial network. Different from the previous generative adversarial networks, our generator network comprises clean background module and a snow mask estimate module. The clean background module aims to generate a clear image from an input snowy image, and snow mask estimate module is used to produce the snow mask in an input image. During the training step, we put forward a composition loss between the input snowy image and composition of the generated clean image and estimated snow mask. We use a dataset named Snow100K2 including indoor and outdoor scenes to train and test the proposed method. The extensive experiments on both synthetic and real-world images show that our network has a good effect and it is superior to the other state-of-the-art methods.},
  keywords={Snow;Rain;Generators;Gallium nitride;Generative adversarial networks;Image enhancement;Remove snowflakes;composition generative adversarial network;dataset},
  doi={10.1109/ACCESS.2019.2900323},
  ISSN={2169-3536},
  month={},}@ARTICLE{10210017,
  author={Ding, Yuanming and Kang, Wei and Feng, Jianxin and Peng, Bo and Yang, Anna},
  journal={IEEE Access}, 
  title={Credit Card Fraud Detection Based on Improved Variational Autoencoder Generative Adversarial Network}, 
  year={2023},
  volume={11},
  number={},
  pages={83680-83691},
  abstract={The rapid spread of mobile banking and e-commerce has coincided with a dramatic increase in fraudulent online payments in recent years. Although machine learning and deep learning are widely used in credit card fraud detection, the typical credit card transaction data set is unbalanced, and the fraud data is much less than the normal transaction data, limiting the effectiveness of traditional binary classification algorithms. To overcome this issue, researchers oversample minority class data and utilize ensemble learning classification algorithms. However, oversampling still has disadvantages. Hence, we improve the generator part of the Variational Autoencoder Generative Adversarial Network (VAEGAN) and propose a new oversampling method that generates convincing and diverse minority class data. The training set is enhanced by generating minority class fraud data to train the ensemble learning classification model. The method is tested on an open credit card dataset, with the experimental results demonstrating that the oversampling method utilizing the improved VAEGAN is superior to the oversampling method of Generative Adversarial Network (GAN), Variational Autoencoder (VAE), and Synthetic Minority Oversampling Technique (SMOTE) in terms of Precision, F1_score, and other indicators. The oversampling method based on the improved VAEGAN effectively deals with the classification problem of imbalanced data.},
  keywords={Fraud;Credit cards;Generative adversarial networks;Data models;Machine learning algorithms;Ensemble learning;Encoding;Electronic commerce;Banking;Credit card fraud;ensemble learning;variational autoencoder generative adversarial network;oversampling},
  doi={10.1109/ACCESS.2023.3302339},
  ISSN={2169-3536},
  month={},}@ARTICLE{8911320,
  author={Yang, Zhiguang and Chen, Youping and Le, Zhuliang and Fan, Fan and Pan, Erting},
  journal={IEEE Access}, 
  title={Multi-Source Medical Image Fusion Based on Wasserstein Generative Adversarial Networks}, 
  year={2019},
  volume={7},
  number={},
  pages={175947-175958},
  abstract={In this paper, we propose the medical Wasserstein generative adversarial networks (MWGAN), an end-to-end model, for fusing magnetic resonance imaging (MRI) and positron emission tomography (PET) medical images. Our method establishes two adversarial games between a generator and two discriminators to generate a fused image with the details of soft tissue structures in organs from MRI images and the functional and metabolic information from PET images. Different information from source images can be effectively adjusted with a specifically designed loss function. In addition, we use WGAN instead of the traditional generative adversarial networks to make the training process more stable and allow our architecture to deal with source images of different resolutions. Qualitative and quantitative comparisons on publicly available datasets demonstrate the superiority of MWGAN over the state-of-the-art networks. Furthermore, our MWGAN is applied to the fusion of MRI and computed tomography images of different resolutions, achieving a satisfactory performance.},
  keywords={Magnetic resonance imaging;Image fusion;Generative adversarial networks;Biomedical imaging;Deep learning;Training;Image resolution;Medical image fusion;Wasserstein generative adversarial networks;end-to-end;different resolutions},
  doi={10.1109/ACCESS.2019.2955382},
  ISSN={2169-3536},
  month={},}@ARTICLE{8793240,
  author={Lee, Donghyeon and Lee, Sangheon and Lee, Hoseong and Lee, Kyujoong and Lee, Hyuk-Jae},
  journal={IEEE Access}, 
  title={Resolution-Preserving Generative Adversarial Networks for Image Enhancement}, 
  year={2019},
  volume={7},
  number={},
  pages={110344-110357},
  abstract={Generative adversarial networks (GANs) are used for image enhancement such as single image super-resolution (SISR) and deblurring. The conventional GANs-based image enhancement suffers from two drawbacks that cause a quality degradation due to a loss of detailed information. First, the conventional discriminator network adopts strided convolution layers which cause a reduction in the resolution of the feature map, and thereby resulting in a loss of detailed information. Second, the previous GANs for image enhancement use the feature map of the visual geometry group (VGG) network for generating a content loss, which also causes visual artifacts because the maxpooling layers in the VGG network result in a loss of detailed information. To overcome these two drawbacks, this paper presents a proposal of a new resolution-preserving discriminator network architecture which removes the strided convolution layers, and a new content loss generated from the VGG network without maxpooling layers. The proposed discriminator network is applied to the super-resolution generative adversarial network (SRGAN), which is called a resolution-preserving SRGAN (RPSRGAN). Experimental results show that RPSRGAN generates more realistic super-resolution images than SRGAN does, and consequently, RPSRGAN with the new content loss improves the average peak signal-to-noise ratio (PSNR) by 0.75 dB and 0.32 dB for super-resolution images with the scale factors of 2 and 4, respectively. For deblurring, the visual appearance is also significantly improved, and the average PSNR is increased by 1.54 dB when the proposed discriminator and content loss are applied to the deblurring adversarial network.},
  keywords={Generative adversarial networks;Three-dimensional displays;Convolution;Image enhancement;Iron;Gallium nitride;Single image super-resolution;deblurring;generative adversarial networks;image enhancement},
  doi={10.1109/ACCESS.2019.2934320},
  ISSN={2169-3536},
  month={},}@ARTICLE{9530576,
  author={Zhang, Weichao and Wang, Guanjun and Huang, Mengxing and Wang, Hongyu and Wen, Shaoping},
  journal={IEEE Access}, 
  title={Generative Adversarial Networks for Abnormal Event Detection in Videos Based on Self-Attention Mechanism}, 
  year={2021},
  volume={9},
  number={},
  pages={124847-124860},
  abstract={Unsupervised anomaly detection defines an abnormal event as an event that does not conform to expected behavior. In the field of unsupervised anomaly detection, it is a pioneering work that leverages the difference between a future frame predicted by a generative adversarial network and its ground truth to detect an abnormal event. Based on the work, we improve the ability of video prediction framework to detect abnormal events by enhancing the difference between prediction results for normal and abnormal events. We incorporate super-resolution and self-attention mechanism to design a generative adversarial network. We propose an auto-encoder as a generator, which incorporates dense residual networks and self-attention. Moreover, we propose a new discriminator, which introduces self-attention on the basis of a relativistic discriminator. To predict a future frame with higher quality for normal events, we impose a constraint on the motion in video prediction by fusing optical flow and gradient difference between frames. We also introduce a perception constraint in video prediction to enrich the texture details of a frame. The AUC of our method on CUHK Avenue and Shanghai Tech datasets reaches 89.2% and 75.7% respectively, which is better than most existing methods. In addition, we propose a processing flow that can realize real-time anomaly detection in videos. The average running time of our video prediction framework is 37 frames per second. Among all real-time methods for abnormal event detection in videos, our method is competitive with the state-of-the-art methods.},
  keywords={Streaming media;Event detection;Anomaly detection;Feature extraction;Generative adversarial networks;Generators;Training;Abnormal event detection;generative adversarial networks (GANs);self-attention;video understanding},
  doi={10.1109/ACCESS.2021.3110798},
  ISSN={2169-3536},
  month={},}@ARTICLE{9212411,
  author={Zeng, Huimin and Zhang, Xinliang and Yu, Zhibin and Wang, Yubo},
  journal={IEEE Access}, 
  title={SR-ITM-GAN: Learning 4K UHD HDR With a Generative Adversarial Network}, 
  year={2020},
  volume={8},
  number={},
  pages={182815-182827},
  abstract={Currently, high dynamic range (HDR) videos with high resolution (HR) have become popular due to the display and the rendered technological advancements. However, making ultra-high definition (UHD) with HDR videos is expensive. The legacy low-resolution (LR) standard dynamic range (SDR) format is still largely used in practice. It is necessary to search for a solution to transform LR SDR videos into UHD HDR format. In this paper, we consider joint super resolution and learning inverse tone mapping an issue of high-frequency reconstruction and local contrast enhancement, and we propose an architecture based on a generative adversarial network to apply joint SR-ITM learning. Specifically, we include the residual ResNeXt block (RRXB) as a basic module to better capture high-frequency textures and adopt YUV interpolation to achieve local contrast enhancement. By adopting a generative adversarial network as a pivotal training mechanism, our designs show advantages in both integration and performance. Our code is now available on GitHub: SR-ITM-GAN.},
  keywords={Generative adversarial networks;Videos;Task analysis;UHDTV;Image reconstruction;Image resolution;Computer architecture;Super resolution;inverse tone mapping;generative adversarial network;high dynamic range},
  doi={10.1109/ACCESS.2020.3028584},
  ISSN={2169-3536},
  month={},}@ARTICLE{10226181,
  author={Lin, Jiahao and Miao, Qi and Surawech, Chuthaporn and Raman, Steven S. and Zhao, Kai and Wu, Holden H. and Sung, Kyunghyun},
  journal={IEEE Access}, 
  title={High-Resolution 3D MRI With Deep Generative Networks via Novel Slice-Profile Transformation Super-Resolution}, 
  year={2023},
  volume={11},
  number={},
  pages={95022-95036},
  abstract={High-resolution magnetic resonance imaging (MRI) sequences, such as 3D turbo or fast spin-echo (TSE/FSE) imaging, are clinically desirable but suffer from long scanning time-related blurring when reformatted into preferred orientations. Instead, multi-slice two-dimensional (2D) TSE imaging is commonly used because of its high in-plane resolution but is limited clinically by poor through-plane resolution due to elongated voxels and the inability to generate multi-planar reformations due to staircase artifacts. Therefore, multiple 2D TSE scans are acquired in various orthogonal imaging planes, increasing the overall MRI scan time. In this study, we propose a novel slice-profile transformation super-resolution (SPTSR) framework with deep generative learning for through-plane super-resolution (SR) of multi-slice 2D TSE imaging. The deep generative networks were trained by synthesized low-resolution training input via slice-profile downsampling (SP-DS), and the trained networks inferred on the slice profile convolved (SP-conv) testing input for 5.5x through-plane SR. The network output was further slice-profile deconvolved (SP-deconv) to achieve an isotropic super-resolution. Compared to SMORE SR method and the networks trained by conventional downsampling, our SPTSR framework demonstrated the best overall image quality from 50 testing cases, evaluated by two abdominal radiologists. The quantitative analysis cross-validated the expert reader study results. 3D simulation experiments confirmed the quantitative improvement of the proposed SPTSR and the effectiveness of the SP-deconv step, compared to 3D ground-truths. Ablation studies were conducted on the individual contributions of SP-DS and SP-conv, networks structure, training dataset size, and different slice profiles.},
  keywords={Magnetic resonance imaging;Image resolution;Three-dimensional displays;Superresolution;Training;Image reconstruction;Generative adversarial networks;Deep learning;Generative adversarial networks;magnetic resonance imaging;turbo spin echo;slice profile;super-resolution},
  doi={10.1109/ACCESS.2023.3307577},
  ISSN={2169-3536},
  month={},}@ARTICLE{9803044,
  author={Zhang, Xin-Yu and Xie, Kai and Li, Mei-Ran and Wen, Chang and He, Jian-Biao},
  journal={IEEE Access}, 
  title={Generative Facial Prior and Semantic Guidance for Iterative Face Inpainting}, 
  year={2022},
  volume={10},
  number={},
  pages={66757-66769},
  abstract={Image inpainting techniques have been greatly improved by relying on structure and texture priors. However, damaged original images or rough predictions cannot provide sufficient texture information and accurate structural priors, leading to a drop in image quality. Moreover, from the perspective of human visual perception, it is important to pay attention to facial symmetry and facial attribute consistency. In this paper, we present a face inpainting system with iteration structure, guided by generative facial priors contained in pretrained GANs and predicted semantic information. Specifically, generative facial priors generated by the GAN inversion techniques introduce sufficient textures and features to assist inpainting; semantic maps are able to provide facial structural information and semantic categories of different pixels for face reconstruction. In particular, we iteratively refine images multiple times, updating semantic maps at each iteration. The Weighted Prior-Guidance Modulation layer (WPGM) is devised for incorporating priors into networks through spatial modulation. We also propose facial feature self-symmetry loss to constrain the symmetry of faces in feature space. Experiments on CelebA-HQ and LaPa datasets demonstrate the superiority of our model for facial detail and attribute consistency. Meanwhile, under the background of COVID-19, it is worth trying recognition via inpainting to deal with recognition challenges brought by mask occlusion. Relevant experiments show that our inpainting model does help to recognition tasks to a certain degree, with higher accuracy.},
  keywords={Face recognition;Semantics;Faces;Iterative methods;Generative adversarial networks;Facial features;Shape;Face inpainting;semantic prior;generative facial prior;iterative structure;face symmetry;recognition via inpainting},
  doi={10.1109/ACCESS.2022.3185210},
  ISSN={2169-3536},
  month={},}@ARTICLE{10662895,
  author={Xia, Siqi and Rajasegarar, Sutharshan and Pan, Lei and Leckie, Christopher and Erfani, Sarah M. and Chan, Jeffrey},
  journal={IEEE Access}, 
  title={LabelGen: An Anomaly Label Generative Framework for Enhanced Graph Anomaly Detection}, 
  year={2024},
  volume={12},
  number={},
  pages={121971-121982},
  abstract={Anomaly detection in graphs is increasingly used to reveal fraud, fakes, security attacks and unusual behaviours in networks, such as social networks, financial transaction networks and the Internet of Things. Accurately detecting such graph anomalies using deep learning approaches faces challenges in terms of obtaining sufficient labelled data, as well as an imbalance between normal and anomalous instances. These contribute to model bias or over-fitting problems and inferior anomaly detection outcomes. In order to address these challenges in graphs, we propose a novel generative framework, called LabelGen, that can generate additional anomalous labels, in terms of graph objects, such as nodes, through augmentation and provide updated deep embedding for the graph concurrently. In particular, we propose the use of a k-hop neighborhood sampling strategy, an anomaly scoring mechanism and an adversarial learning framework with a generator and discriminator pair in order to generate sufficient and informative anomalous nodes that closely resemble the characteristics of existing anomalies in the graph. Evaluation on benchmark network datasets, as well as ablation and comparison studies with random label generation processes and other existing works reveal that the proposed generative framework is superior in improving the anomaly detection accuracy in graphs, while achieving a balanced trade-off between accuracy and computational efficiency.},
  keywords={Anomaly detection;Generators;Training;Detectors;Data models;Data augmentation;Generative adversarial networks;Deep learning;Fraud;Network security;Graphical models;Anomalies in graphs;generative adversarial networks;k-hop neighborhood sampling;deep learning},
  doi={10.1109/ACCESS.2024.3453178},
  ISSN={2169-3536},
  month={},}@ARTICLE{10623426,
  author={Zhou, Chunlei and Xiao, Wang and Wang, Qingfeng and Feng, Zhipeng},
  journal={IEEE Access}, 
  title={Research on an Improved Wasserstein Generative Adversarial Network Early Fault Warning Method for Rotating Machinery}, 
  year={2024},
  volume={12},
  number={},
  pages={109109-109127},
  abstract={Early fault warning for large-scale high-speed rotating machinery can effectively reduce unplanned downtime and avoid major safety accidents. Aiming at the problems of difficult screening of multi-source common sensitive features, the challenging training of neural networks with a small number of sensitive features, and the difficulty of directly using generative adversarial networks for early fault warning, this paper constructs an early fault warning model based on multi-source common sensitive features and an improved Wasserstein generative adversarial network, proposing an early fault warning method for rotating machinery. The model was verified by using the open XJTU-SY bearing laboratory data, the P3409A centrifugal pump bearing fault engineering case data of a petrochemical company and the rotor system engineering case data of a circulating hydrogen centrifugal compressor of a petrochemical company. The early fault warning method of rotating machinery proposed in this paper warns the bearing fault of centrifugal pump 160 hours in advance and the rotor system fault of centrifugal compressor 1330 minutes in advance. Compared with the two published methods, the proposed method has better early fault warning effect, better normal and abnormal health index discrimination and less false warning.},
  keywords={Generative adversarial networks;Feature extraction;Machinery;Training;Time-frequency analysis;Noise;Rolling bearings;Rotating machines;deep learning;generative adversarial networks;early fault warning},
  doi={10.1109/ACCESS.2024.3438753},
  ISSN={2169-3536},
  month={},}@ARTICLE{9469035,
  author={Xing, Siyuan and Dong, Qiulei and Hu, Zhanyi},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={Gated Feature Aggregation for Height Estimation From Single Aerial Images}, 
  year={2022},
  volume={19},
  number={},
  pages={1-5},
  abstract={Height estimation from single images, strictly speaking, is an ill-posed problem. However, recently, it is shown that it is both possible and feasible to learn a mapping from image statistics to height information. In spite of recent efforts in this field, how to learn fine-shape preserving features, such as object boundaries and contours, is still an open issue. In this work, we propose a progressive learning network to estimate height information from single aerial images in a coarse-to-fine manner. In particular, a gated feature aggregation module is introduced to effectively combine low-level and high-level features. The proposed method is validated on three public datasets, including the Vaihingen dataset, the Potsdam dataset, and the DFC2019 dataset. Both quantitative and qualitative experimental results demonstrate that the proposed method can achieve more accurate height estimation from single aerial images, especially with better object boundary and contour preserving capability, than four related height estimation methods.},
  keywords={Estimation;Decoding;Logic gates;Training;Feature extraction;Testing;Encoding;Convolutional neural networks (CNNs);gate mechanism;height estimation;progressive refinement},
  doi={10.1109/LGRS.2021.3090470},
  ISSN={1558-0571},
  month={},}@ARTICLE{10856197,
  author={Zeng, Weizhe and Zheng, Jie and Gao, Ling and Niu, Jinping and Ren, Jie and Wang, Hai and Cao, Rui and Ji, Shuo},
  journal={IEEE Internet of Things Journal}, 
  title={Generative AI-Aided Multimodal Parallel Offloading for AIGC Metaverse Service in IoT Networks}, 
  year={2025},
  volume={12},
  number={10},
  pages={13273-13285},
  abstract={Mobile edge computing (MEC) enabled artificial intelligence-generated content (AIGC) has garnered considerable attention. To support AIGC metaverse applications within MEC in Internet of Things (IoT) networks, it is effective to offload computation tasks, particularly those involving neural networks generative in AIGC, from mobile devices to edge clouds. Existing solutions typically assume the availability of a dedicated and powerful edge server for each user with single modal data, which can handle the entire AIGC service offloading. However, the practical availability of such dedicated and powerful servers may be limited, necessitating the utilization of less capable alternatives. Thus, we propose the multimodal parallel offloading AIGC framework which partitions multimodal content and offloads partial diffusion tasks to multiple servers. Our proposed scheme accelerates mobile deep vision multimodal metaverse applications through parallel offloading provided by multiple servers. We further utilize the generative AI scheme to solve offloading problems to adapt the dynamic and available communication and computing resource in wireless IoT network. Our framework proposed a multimodal parallel diffusion offloading scheme with integrating the recurrent region proposal prediction algorithm to optimize communication and computing resources while minimizing delay. Simulation results show that our approach can significantly reduce delay compared to conventional algorithms.},
  keywords={Servers;Metaverse;Resource management;Edge computing;Proposals;Heuristic algorithms;Generative AI;Wireless communication;Dynamic scheduling;Prediction algorithms;Artificial intelligence-generated content (AIGC);multimodal parallel offloading;region proposal prediction},
  doi={10.1109/JIOT.2025.3535623},
  ISSN={2327-4662},
  month={May},}@INPROCEEDINGS{8372083,
  author={Jin, Di and Wang, Xiaobao and He, Dongxiao and Lu, Wenhuan and Fogelman-Soulié, Francoise and Dang, Jianwu},
  booktitle={2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Identification of Generalized Communities with Semantics in Networks with Content}, 
  year={2017},
  volume={},
  number={},
  pages={1182-1189},
  abstract={Discovery of communities in networks is a fundamental data analysis task. Recently, researchers have tried to improve its performance by exploiting node contents, and further interpret the communities using the derived semantics. However, the existing methods typically assume that the communities are assortative (i.e. members of each group are mostly connected to other members of the same group), and are unable to find the generalized community structure, e.g. structures with either assortative or disassortative communities (i.e. vertices of the same group have most of their connections outside their group), or a combination. In addition, these methods often assume that the network topology and node contents share the same group memberships, and thus cannot perform well when the contents mismatch with network structure. Also, they are limited to using only one topic to interpret each community. To address these two issues, we propose a new generative probabilistic model which is learned by using a nested expectation-maximization algorithm. It describes the generalized communities (based on network) and the content clusters (based on contents) separately, and further explores and models their correlation to improve as much as possible each of the communities and clusters based on the other. By depicting and utilizing this correlation, our model is not only robust with respect to the above problems, but is also able to interpret each community using more than one topic, which provides richer explanations. We validate the robustness of this proposed new approach on an artificial benchmark, and test its interpretability using a case study analysis. We finally show its definite superiority for community detection by comparing with seven state-of-the-art algorithms on eight real networks.},
  keywords={Conferences;Tools;Artificial intelligence;Social networks;attributed network;community detection;generalized communities;probabilistic model;EM algorithm;semantics},
  doi={10.1109/ICTAI.2017.00180},
  ISSN={2375-0197},
  month={Nov},}@INBOOK{10880605,
  author={Abdalla, Mohammed},
  booktitle={Generative Artificial Intelligence for Biomedical and Smart Health Informatics}, 
  title={Inclusive Role of Internet of (Healthcare) Things in Digital Health: Challenges, Methods, and Future Directions}, 
  year={2025},
  volume={},
  number={},
  pages={239-258},
  abstract={Summary <p>Healthcare systems could undergo a change with the incorporation of Internet of Things (IoT) technology, which would allow for enhanced analytics, real&#x2010;time data monitoring, and seamless communication. This chapter offers a thorough analysis of IoT applications in healthcare systems, emphasizing their influence on several facets of healthcare delivery, such as patient care, digital health, preventative medicine, remote monitoring, and future directions of IoT&#x2010;enabled healthcare systems. The first section of the chapter covers the basic elements of the IoT in the healthcare industry, including data networks, sensors, linked devices, and cloud&#x2010;based platforms. It looks at how wearable technology, smart healthcare devices that allow for continuous health tracking and real&#x2010;time data processing, and remote patient monitoring can all improve patient care. In the context of preventative healthcare, the potential of IoT to support personalized treatment and early diagnosis and intervention is explored. In addition, the chapter investigates how IoT integration affects healthcare systems, including smart medical devices, electronic health records, and hospital management systems. It looks at how IoT and digital health could help healthcare organizations make better decisions, use their resources more effectively, and run their operations more efficiently. There is also a discussion of the difficulties and factors involved in implementing IoT, such as privacy, interoperability, data security, and regulatory compliance. This chapter also emphasizes how IoT&#x2010;enabled healthcare systems have the potential to revolutionize the way that global healthcare issues, including managing chronic diseases, aging populations, and restricted access to healthcare services in remote places, are addressed. It highlights that to remove obstacles and promote the widespread use of IoT in healthcare, stakeholders, including technology developers, policymakers, researchers, and healthcare providers, must work together. Finally, the application of IoT technology to healthcare systems presents a plethora of chances to boost patient care, increase operational effectiveness, and spur innovation in the provision of healthcare services. The difficulties with data security, privacy, and interoperability, however, need to be carefully considered. The healthcare system may adopt a patient&#x2010;centered, data&#x2010;driven strategy and enhance health outcomes by utilizing the potential of the IoT. This will change the way healthcare is delivered in the digital age.</p>},
  keywords={Medical services;Medical diagnostic imaging;Pediatrics;Monitoring;Software;Medical devices;Heart;Electronic healthcare;Diabetes;Costs},
  doi={10.1002/9781394280735.ch12},
  ISSN={},
  publisher={IEEE},
  isbn={9781394280728},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10880605},}@INBOOK{10237060,
  author={Zhu, Dayu and Liu, Zhaocheng and Cai, Wenshan},
  booktitle={Advances in Electromagnetics Empowered by Artificial Intelligence and Deep Learning}, 
  title={Generative Machine Learning for Photonic Design}, 
  year={2023},
  volume={},
  number={},
  pages={197-224},
  abstract={Machine learning, as a study of algorithms that automate prediction and decision&#x2010;making based on complex data, has become one of the most effective tools in the exploitation of artificial intelligence. In recent years, scientific communities have been gradually merging data&#x2010;driven approaches with research endeavors, enabling dramatic progress in revealing underlying mechanisms, predicting essential properties, and discovering unconventional phenomena. Very recently, generative machine learning models have attracted growing attention in the design and optimization of complex photonic structures. In this chapter, we overview the advantages of the generative design strategy for photonic components and devices over traditional optimization schemes with both theoretical analysis and practical design examples.},
  keywords={Optimization;Probabilistic logic;Mathematical models;Generators;Stochastic processes;Predictive models;Photonics},
  doi={10.1002/9781119853923.ch6},
  ISSN={},
  publisher={IEEE},
  isbn={9781119853909},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10237060},}@ARTICLE{9186017,
  author={Cai, Zhini},
  journal={IEEE Access}, 
  title={Usage of Deep Learning and Blockchain in Compilation and Copyright Protection of Digital Music}, 
  year={2020},
  volume={8},
  number={},
  pages={164144-164154},
  abstract={In order to explore the application of deep learning algorithms in arrangement and composition, and the role of blockchain in the protection of digital music copyright, a monophonic melody composition model based on the deep generative adversarial networks (DCGANs) is constructed firstly, and the composition performance of the model is analyzed using hymn as input sample in this study. Later, the multi-instrument co-arrangement (MICA) model based on the multi-task learning is proposed, and the composition performance is analyzed by taking the actual music as an input sample. Finally, the improved practical byzantine fault tolerance (IPBFT) algorithm is proposed, and a digital music copyright protection system is designed based on the blockchain in this study. The results indicate that the accuracies constructed DCGANs model in predicting the Soprano and Alto voice melody are higher than those of the DeepBatch model by 2.29% and 3.32%, respectively. The performance on the harmony score, note accuracy, Levenshtein similarity (LS), notes distribution mean square error, and empty as well as the convergence speed of the constructed MICA model are better than those of other models. The average transaction per second (TPS) value of the proposed IPBFT algorithm in the real digital music copyright protection system is 3469, which is superior to other blockchain technologies. Finally, the digital music copyright protection system is achieved, the error rate of completing the request is 0% in the state of many users operating concurrently, and a high TPS value can be guaranteed. In short, the DCGANs and MICA models pointed out in this study can be used in the composition of monophonic melodies and complex melodies, and the digital music copyright protection system based on the blockchain has excellent performance in practical applications.},
  keywords={Copyright protection;Blockchain;Deep learning;Data models;Music;Generative adversarial networks;Mathematical model;Deep generative adversarial networks;multi-instrument co-arrangement;practical byzantine fault tolerance;blockchain;digital music copyright protection system},
  doi={10.1109/ACCESS.2020.3021523},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10192759,
  author={Chowdary, Nama Deepak and Inturu, Siddhartha and Katta, Jithendra and Yashwanth, Chiluka and Kanaparthi, Naga Sri Harsha Vardhan and Voore, Srinivas},
  booktitle={2023 8th International Conference on Communication and Electronics Systems (ICCES)}, 
  title={Skin Disease Detection and Recommendation System using Deep Learning and Cloud Computing}, 
  year={2023},
  volume={},
  number={},
  pages={1064-1068},
  abstract={The main objective of this research is to develop an application based on Deep learning, Computer vision and cloud computing that detects the different kinds of skin diseases caused by different types of viruses, Bacteria, Fungus and Environment. This study has also developed and integrated a recommendation system, which recommends the medicines and care taking process for a particular disease. The application also suggests preventive methods for different kinds of skin infections. This study used an ensemble of convolution neural networks (CNN) with generative adversarial network (GAN) and Computer vision for construction of the model. Further, Amazon Personalize is used to build recommendation system in the proposed web application. The proposed application detects the disease based on symptoms, pictures, and videos of infected skin area. The application will be helpful for dermatologists and common people to perform early detection and prevention of skin diseases in India. This study also compared the accuracy of ensemble of convolution neural networks (CNN) with GAN and other algorithms like CNN. In comparison of accuracy, this study found that the Ensembles of CNN with GAN give best results for the proposed dataset.},
  keywords={Deep learning;Visualization;Computer vision;Computational modeling;Neural networks;Generative adversarial networks;Prediction algorithms;Convolutional neural network;Generative Adversarial Networks;Cloud Computing;Amazon web services personalize;Deep learning;Computer Vision},
  doi={10.1109/ICCES57224.2023.10192759},
  ISSN={},
  month={June},}@ARTICLE{11014501,
  author={Ullah, Zabeeh and Arif, Fahim and Khan, Nauman Ali and Khan, Mudassar Ali and Din, Ikram Ud and Almogren, Ahmad and Altameem, Ayman},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Interpretable and Adaptive GAN-BiLSTM Approach for Cyber Threat Detection in IoMT-based Healthcare 5.0}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Healthcare 5.0, driven by the Internet of Medical Things (IoMT), introduces transformative changes in the medical field but also exposes systems to growing cybersecurity threats. While Deep Learning (DL) offers high accuracy in attack detection, its effectiveness is often limited by data imbalance and difficulty in identifying key features dynamically. Additionally, DL models are often criticized for their lack of interpretability, as their internal decisionmaking remains obscure. To overcome these limitations, this paper presents an explainable and adaptive DL-based security framework. It integrates a Generative Adversarial Network (GAN) to balance the dataset by generating realistic samples for underrepresented attack classes, and employs Bidirectional Long Short-Term Memory (BiLSTM) to identify temporal patterns and critical features. To enhance transparency, SHapley Additive exPlanations (SHAP) and Permutation Feature Importance (PFI) are used for interpreting the model's decisions. Experiments conducted on the NSL-KDD dataset demonstrate the effectiveness of the proposed method, achieving 93.81% accuracy and an F1-score of 82.95%.},
  keywords={Medical services;Explainable AI;Threat assessment;Bidirectional long short term memory;Security;NSL-KDD;Training;Feature extraction;Adaptation models;Generative adversarial networks;Healthcare 5.0;IoMT;Deep Learning;Explainable AI;Generative Adversarial Network},
  doi={10.1109/JBHI.2025.3573097},
  ISSN={2168-2208},
  month={},}@ARTICLE{9585370,
  author={Li, Mei and Xiang, Lu and Kang, Xiaomian and Zhao, Yang and Zhou, Yu and Zong, Chengqing},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Medical Term and Status Generation From Chinese Clinical Dialogue With Multi-Granularity Transformer}, 
  year={2021},
  volume={29},
  number={},
  pages={3362-3374},
  abstract={This paper describes a generative model for extracting medical terms and their status from Chinese medical dialogues. Notably, the extracted semantic information is particularly important to downstream tasks like automatic medical scribe and automatic diagnosis systems. However, how to effectively leverage dialogue context to generate medical terms and their corresponding status accurately remains less explored. Existing generative approaches treat dialogue text as a single continuous text, ignoring conversational characteristics like colloquialism, redundancy and interactions. Between the doctor and the patient, a variety of colloquial medical information is frequently discussed. Each speaker (doctor and patient) plays a specific role in the interaction's goals. As a result, the importance of role information and interactions between utterances cannot be overstated. Furthermore, existing generative approaches only use character-level tokens, disregarding word-level tokens, which are the shortest meaningful utterances in Chinese. In this paper, we propose a Multi-granularity Transformer (MGT) model to enhance the dialogue context understanding from multi-granularity features. We incorporate word-level information by adapting a Lattice-based encoder with our proposed relative position encoding method. We further propose a Role Access Controlled Attention (RaCa) mechanism for introducing utterance-level interaction information. Experimental results on two benchmark datasets illustrate our model's validity and effectiveness, achieving state-of-the-art performance on both datasets.},
  keywords={Transformers;Medical services;Encoding;Semantics;Hierarchical systems;Medical dialogue;multi-granularity;attention mechanism;natural language understanding;sequence to sequence learning},
  doi={10.1109/TASLP.2021.3122301},
  ISSN={2329-9304},
  month={},}@ARTICLE{9097251,
  author={Cheng, Kuanhong and Song, Jiangluqi and Du, Juan and Rong, Shenghui and Zhou, Huixin},
  journal={IEEE Access}, 
  title={Single Image Reflection Removal via Attention Model and SN-GAN}, 
  year={2020},
  volume={8},
  number={},
  pages={96046-96054},
  abstract={Single image reflection removal is of great practical importance for various computer vision tasks. Most non-learning methods try to solve this problem through the model-optimization scheme, which fails to produce promising results due to the shortage of suitable priors to model the difference between the reflection layer and the transmission layer. This paper presents an improved generative adversarial network to resolve this problem. First, we suggest that reflection removal is not only a channel-wise separation problem, but also a spatial variational occlusion removal task, which is sensitive to both spatial and channel-wise features. To this end, we integrate the CBAM module into the generator to enhance both spatial and channel-wise feature representation. Second, we consider the reflection layer as a spatial mask with space-relevant reflection intensity information, which can be used to elevate the performance of the discriminator. We then design a novel SNGAN structure with utilize the predicted reflection as a guidance to achieve better adversarial supervision. Specifically, our new generative network has an encoder-decoder structure with skip-connections, where the attention enhancement block is integrated into each skip-connection of the encoder-decoder subnet, and followed by an eight-layer fully convolutional subnet. Furthermore, the SNGAN loss is combined with L2 pixel loss and L1 VGG19 perceptual loss for training. The experimental results with benchmark datasets indicate that our method outperforms several state-of-the-art networks.},
  keywords={Reflection;Task analysis;Convolution;Generators;Generative adversarial networks;Computer vision;Computational modeling;Inverse problems;artificial neural networks;image processing;image restoration;computer vision;artificial intelligence;supervised learning;multi-layer neural network;knowledge-based systems},
  doi={10.1109/ACCESS.2020.2995871},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10717316,
  author={Iyer, Aditya A and Vojjala, Saipranav and J, Andrew},
  booktitle={2024 10th International Conference on Advanced Computing and Communication Systems (ICACCS)}, 
  title={Augmenting Sentiments into Chat-GPT Using FacialEmotion Recognition}, 
  year={2024},
  volume={1},
  number={},
  pages={69-74},
  abstract={This research initiative addresses the task of enhancing Chat Generative Pre-trained Transformer's (ChatGPT's) conversational capabilities by integrating the comprehension and response to user emotions conveyed through facial expressions. The central challenge lies in refining the AI system's proficiency to tailor responses according to users' detected emotional states. In this pursuit, our study adopts a comprehensive approach, aiming to seamlessly incorporate emotional intelligence into AI-driven interactions. To achieve this objective, the methodology involves integrating real-time sentiment analysis based on facial expressions into the ChatGPT framework. This is carried out through the utilization of a deep convolutional neural network (DCNN) architecture, designed to recognize and interpret various emotions exhibited in facial expressions. The primary goal is to enable ChatGPT to dynamically adjust its responses, fostering a more empathetic and contextually relevant interaction with users. In terms of evaluation metrics for facial expression recog- nition, our assessment employs a confusion matrix to quantify the model's performance across different emotional categories. Additionally, a heuristic approach is implemented, wherein the sum total probability of each detected emotion is calculated over the duration the user enters the prompt. These evaluation methodologies aim to provide a comprehensive understanding of the model's accuracy and effectiveness in discerning and responding to user emotions. Overall, this research contributes to the ongoing endeavor of imbuing AI systems with emotional intelligence, paving the way for more nuanced and human-like interactions.},
  keywords={Emotion recognition;Sentiment analysis;Face recognition;Computer architecture;Chatbots;Transformers;Real-time systems;User experience;Convolutional neural networks;Artificial intelligence;Fine-tuning;Natural Language Processing;Sentiment Analysis;Machine Learning;GPT;Facial Expression Recognition;Interaction adaptation;Emotional intelligence in AI;Conversational Agents},
  doi={10.1109/ICACCS60874.2024.10717316},
  ISSN={2575-7288},
  month={March},}@ARTICLE{10042407,
  author={Roy, Kyamelia and Chaudhuri, Sheli Sinha and Frnda, Jaroslav and Bandopadhyay, Srijita and Ray, Ishan Jyoti and Banerjee, Soumen and Nedoma, Jan},
  journal={IEEE Access}, 
  title={Detection of Tomato Leaf Diseases for Agro-Based Industries Using Novel PCA DeepNet}, 
  year={2023},
  volume={11},
  number={},
  pages={14983-15001},
  abstract={The advancement of Deep Learning and Computer Vision in the field of agriculture has been found to be an effective tool in detecting harmful plant diseases. Classification and detection of healthy and diseased crops play a very crucial role in determining the rate and quality of production. Thus the present work highlights a well-proposed novel method of detecting Tomato leaf diseases using Deep Neural Networks to strengthen agro-based industries. The present novel framework is utilized with a combination of classical Machine Learning model Principal Component Analysis (PCA) and a customized Deep Neural Network which has been named as PCA DeepNet. The hybridized framework also consists of Generative Adversarial Network (GAN) for obtaining a good mixture of datasets. The detection is carried out using the Faster Region-Based Convolutional Neural Network (F-RCNN). The overall work generated a classification accuracy of 99.60% with an average precision of 98.55%; giving a promising Intersection over Union (IOU) score of 0.95 in detection. Thus the presented work outperforms any other reported state-of-the-art.},
  keywords={Diseases;Deep learning;Feature extraction;Principal component analysis;Convolutional neural networks;Generative adversarial networks;Computer architecture;Crops;Tomato leaf diseases;artificial intelligence;deep learning;computer vision;generative adversarial networks;convolutional neural network;faster region-based convolutional neural network},
  doi={10.1109/ACCESS.2023.3244499},
  ISSN={2169-3536},
  month={},}@ARTICLE{9919840,
  author={Fornás, Javier Granado and Jaraba, Elías Herrero and Estopiñan, Andrés Llombart and Saldana, Jose},
  journal={IEEE Access}, 
  title={Detection and Classification of Fault Types in Distribution Lines by Applying Contrastive Learning to GAN Encoded Time-Series of Pulse Reflectometry Signals}, 
  year={2022},
  volume={10},
  number={},
  pages={110521-110536},
  abstract={This study proposes a new method for detecting and classifying faults in distribution lines. The physical principle of classification is based on time-domain pulse reflectometry (TDR). These high-frequency pulses are injected into the line, propagate through all of its bifurcations, and are reflected back to the injection point. According to the impedances encountered along the way, these signals carry information regarding the state of the line. In the present work, an initial signal database was obtained using the TDR technique, simulating a real distribution line using (PSCAD™). By transforming these signals into images and reducing their dimensionality, these signals are processed using convolutional neural networks (CNN). In particular, in this study, contrastive learning in Siamese networks was used for the classification of different types of faults (ToF). In addition, to avoid the problem of overfitting owing to the scarcity of examples, generative adversarial neural networks (GAN) have been used to synthesise new examples, enlarging the initial database. The combination of Siamese neural networks and GAN allows the classification of this type of signal using only synthesised examples to train and validate and only the original examples to test the network. This solves the problem of the lack of original examples in this type of signal of natural phenomena which are difficult to obtain and simulate.},
  keywords={Circuit faults;Databases;Generative adversarial networks;Task analysis;Generators;Reflectometry;Mathematical models;Artificial Neural Networks (ANNs);deep learning;siamese networks;generative adversarial neural networks (GAN’s);fault classification;fault detection;transmission lines},
  doi={10.1109/ACCESS.2022.3214994},
  ISSN={2169-3536},
  month={},}@ARTICLE{10537072,
  author={Salcedo, William and Achour, Sara and McBeth, Courtney},
  journal={IEEE Design & Test}, 
  title={Leveraging Generative AI for Rapid Design and Verification of a Vector Processor SoC}, 
  year={2024},
  volume={41},
  number={6},
  pages={8-18},
  abstract={This article presents a novel approach to using generative artificial intelligence (AI), specifically GPT-4, to accelerate the design and verification of a vector processor SoC, demonstrating the potential of AI to streamline chip development processes and reduce time to market. —Matthew Guthaus, University of California at Santa Cruz, USA},
  keywords={Registers;Hardware design languages;Vector processors;Computer architecture;Codes;Generative AI;Artificial intelligence;Vector processors},
  doi={10.1109/MDAT.2024.3404117},
  ISSN={2168-2364},
  month={Dec},}@ARTICLE{11020592,
  author={Zhou, Xiaomao and Hu, Yujiao and Jia, Qingmin and Xie, Renchao},
  journal={IEEE Communications Magazine}, 
  title={LLM-Enabled Multi-Modal Data Synthesis via Cross-Domain Collaboration}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Data is pivotal to the advancement of intelligent communication and network systems. However, the availability of relevant data is hampered by different challenges, including scarcity, privacy issues, and the high cost of acquisition. Furthermore, existing data generation models are of low quality, uncontrollable, and lack generalizability. In this article, we propose a large language models (LLMs) driven framework that leverages the power of LLMs in concert with various domain-specific generative models (DGMs) to realize general multi-modal data synthesis. Specifically, our method employs LLMs as the core to interpret user requests, decompose a complex task into a manageable set of sub-tasks, and delegate each sub-task to the most suitable DGM, thereby automatically constructing customized data generation pipelines. Meanwhile, DGMs contribute their expertise to generate high-fidelity, domain-relevant data, whose specialized knowledge can be further enhanced by the LLM's broad linguistic knowledge via knowledge transfer. In addition, the integration of reinforcement learning (RL) is promising to enhance the framework's ability to optimally utilize DGMs, resulting in data generation with superior quality and control flexibility. Experimental results demonstrate the effectiveness of LLMs in augmenting domain-specific generative models via knowledge transfer and in facilitating multi-modal data synthesis through collaborative interactions with diverse DGMs.},
  keywords={Data models;Data collection;Knowledge transfer;Pipelines;Artificial intelligence;Analytical models;Training data;Integrated circuit modeling;Linguistics;Context modeling},
  doi={10.1109/MCOM.002.2400435},
  ISSN={1558-1896},
  month={},}@ARTICLE{10559829,
  author={Poluan, Sevendi Eldrige Rifki and Chen, Yan-Ann},
  journal={IEEE Access}, 
  title={Generating Social-Aware Locations for a Robot in a Human Group by Image Generation Using Adversarial Learning}, 
  year={2024},
  volume={12},
  number={},
  pages={85681-85693},
  abstract={With the advance of deep learning techniques, social robots can have more powerful perception and interaction capabilities. However, the problem of finding a socially aware standing location for the robot to join a conversation group is not well addressed. Thus, we propose a generative-based and image-based approach to generate a social-aware group formation to obtain the possible locations for the robot. Furthermore, to overcome the problem of formulating human comforts, we try to leverage human behaviors with the concerns of human comforts when joining the conversation group. We utilize a self-supervised technique to generate this kind of human experience from the real-world dataset. Through extensive experiments, we show that the proposed method outperforms the social force method by 62% with respect to data from human experiences. In addition, our approach also provides controllable parameters to generate the location with the required features using the GAN noise vector.},
  keywords={Robots;Social robots;Robot kinematics;Navigation;Image synthesis;Oral communication;Trajectory planning;Adversarial machine learning;Generative AI;Adversarial learning;conversation group;edge artificial intelligence;generative AI;Internet of Things;robot standing position;social robot},
  doi={10.1109/ACCESS.2024.3415708},
  ISSN={2169-3536},
  month={},}@ARTICLE{10758932,
  author={Wu, Yanyi},
  journal={IEEE Potentials}, 
  title={Mitigating manipulation in generative AI}, 
  year={2024},
  volume={43},
  number={6},
  pages={39-45},
  abstract={In an era where generative artificial intelligence (GAI) can compose symphonies and generate news articles with equal facility, the boundary between creation and manipulation becomes increasingly nebulous. This article discusses the fascinating and risky field of GAI and explores its potential to manipulate through deepfake videos and AI-generated text. Rather than presenting a fatalistic outlook, it is a call to action to ethicists, engineers, and policy makers. It delineates strategies to harness GAI’s potential while implementing safeguards against misuse, proposing solutions from “trust by design” principles to adaptive regulatory frameworks.},
  keywords={Psychology;Ethics;Artificial intelligence;Transforms;Media;Watersheds;Social networking (online);Shape;Labeling;Generative AI},
  doi={10.1109/MPOT.2024.3491338},
  ISSN={1558-1772},
  month={Nov},}@ARTICLE{9773982,
  author={Li, Longyuan and Yan, Junchi and Wen, Qingsong and Jin, Yaohui and Yang, Xiaokang},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Learning Robust Deep State Space for Unsupervised Anomaly Detection in Contaminated Time-Series}, 
  year={2023},
  volume={35},
  number={6},
  pages={6058-6072},
  abstract={Anomalies are ubiquitous in real-world time-series data which call for effective and timely detection, especially in an unsupervised setting for labeling cost saving. In this paper, we develop an unsupervised density reconstruction model for multi-dimensional time-series anomaly detection. In particular, it directly handles an important realistic setting that the detection is achieved towards raw time-series contaminated with noise for training, in contrast to most existing anomaly detection works that assume the training data is in general clean i.e., not contaminated with anomaly. It extends recent advancements in deep generative models and state space models to achieve robust anomaly detection. Our approach comprises of a novel state space based generative model, a filtering based inference model, together with a carefully-designated emission model based on robust statistics theory. Extensive experimental results are conducted to show that our approach can adapt to complex patterns even given severely contaminated training data. We also develop visualization techniques to help better understand the behavior of the anomaly detection models. Empirical results show that our method outperforms state-of-the-arts on both synthetic and real-world datasets.},
  keywords={Data models;Anomaly detection;Training data;Hidden Markov models;Training;Adaptation models;Estimation;Anomaly detection;density estimation;time-series;variational auto-encoder;deep state space model},
  doi={10.1109/TKDE.2022.3171562},
  ISSN={1558-2191},
  month={June},}@ARTICLE{9662066,
  author={Huang, Bo and Xu, Tingfa and Li, Jianan and Luo, Fei and Qin, Qingwang and Chen, Junjie},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Learning Context Restrained Correlation Tracking Filters via Adversarial Negative Instance Generation}, 
  year={2023},
  volume={34},
  number={9},
  pages={6132-6145},
  abstract={The tracking performance of discriminative correlation filters (DCFs) is often subject to unwanted boundary effects. Many attempts have already been made to address the above issue by enlarging searching regions over the last years. However, introducing excessive background information makes the discriminative filter prone to learn from the surrounding context rather than the target. In this article, we propose a novel context restrained correlation tracking filter (CRCTF) that can effectively suppress background interference via incorporating high-quality adversarial generative negative instances. Concretely, we first construct an adversarial context generation network to simulate the central target area with surrounding background information at the initial frame. Then, we suggest a coarse background estimation network to accelerate the background generation in subsequent frames. By introducing a suppression convolution term, we utilize generative background patches to reformulate the original ridge regression objective through circulant property of correlation and a cropping operator. Finally, our tracking filter is efficiently solved by the alternating direction method of multipliers (ADMM). CRCTF demonstrates the accuracy performance on par with several well-established and highly optimized baselines on multiple challenging tracking datasets, verifying the effectiveness of our proposed approach.},
  keywords={Target tracking;Correlation;Training;Background noise;Interference;Adversarial machine learning;Feature extraction;Adversarial context generation;background interference;correlation filters;object tracking},
  doi={10.1109/TNNLS.2021.3133441},
  ISSN={2162-2388},
  month={Sep.},}@INPROCEEDINGS{10184689,
  author={Gao, Yuanning and Huang, Xiuqi and Zhou, Xuanhe and Gao, Xiaofeng and Li, Guoliang and Chen, Guihai},
  booktitle={2023 IEEE 39th International Conference on Data Engineering (ICDE)}, 
  title={DBAugur: An Adversarial-based Trend Forecasting System for Diversified Workloads}, 
  year={2023},
  volume={},
  number={},
  pages={27-39},
  abstract={Trend forecasting is vital to optimize the workload performance. It becomes even more urgent with an increasing number of applications and database configurations. However, DBAs mainly target at historical workloads and may give suboptimal configuration advice when the workload trends have changed. Although there are some studies on trend forecasting, they have several limitations. First, they mainly predict the changes of query numbers, which do not combine other critical factors (e.g., disk utilization) and cannot fully reflect the future workload trends. Besides, there are numerous queries in the workloads and exact clustering algorithms like K-means cannot effectively merge similar queries which contain noises like time shifts. Second, basic machine learning models like RNN may have relatively low prediction accuracy on complex workloads (e.g., no cycles but random bursts). Third, real-world workloads may have diverse patterns, while previous models cannot efficiently and reliably predict for all the different workload patterns.To address these challenges, we propose a trend forecasting system (DBAugur) that utilizes adversarial neural networks to predict the trends of different workloads. First, DBAugur collects the important features (e.g., queries, resource metrics) to characterize workloads, and reduces the number of involved queries by separately merging similar queries based on the SQL semantics and trend patterns. Second, DBAugur utilizes Generative Adversarial Networks (GANs) to capture the latent patterns, correlations between different metrics, and occasional bursts within the complicated and time-varying workloads. Moreover, we further propose a time-sensitive ensemble algorithm that takes advantage of various machine learning models (e.g., generative models, convolutional models, feed-forward models) to accommodate the various workload patterns. The experimental results show that DBAugur outperformed state-of-the-art methods on various real-world workloads.},
  keywords={Measurement;Machine learning algorithms;Databases;Clustering algorithms;Machine learning;Predictive models;Market research;Workload Forecasting;GAN;DBMS},
  doi={10.1109/ICDE55515.2023.00385},
  ISSN={2375-026X},
  month={April},}@INPROCEEDINGS{10229440,
  author={Luo, Xi and Deng, Yuhui and Liu, Junjie and Wu, Sirong and Sun, Gengchen},
  booktitle={2023 IEEE International Conference On Artificial Intelligence Testing (AITest)}, 
  title={Debunk online rumors via generative-contrastive learning based on tree-transformer}, 
  year={2023},
  volume={},
  number={},
  pages={152-159},
  abstract={Rumors have been treated as the online pandemic on social media, impeding the truth. Existing claim-guided approaches tend to capture the structural, temporal, or relational indicative features among responsive posts to enhance representation learning, but few of them can integrate these features properly to comprehensively explore them. Additionally, large pre-trained language models are widely used for rumor debunking, such as Transformer-based models, which can result in collapsed issues and achieve poor performance on semantic textual similarity. Given these circumstances, we treat the rumor thread propagation as a conversation tree and propose a hybrid model, TRANS-CVAE, to learn a thread embedding encoded with Bidirectional Encoder Representations from Transformers (BERT). We then adopt a temporal-based Variational Auto-Encoder (VAE) on this thread embedding to extract a compressed and latent representation from its latent semantic space. This latent embedding is revised by label-anchored contrastive loss. Using labels, this loss could pull together or push apart different threads to obtain better thread representations, and it could also alleviate the collapsed issue caused by BERT. Extensive experiments on the PHEME dataset show that our proposed approach outperforms many state-of-the-art rumor debunking models, and the ablation study also reflects the necessity of all three components to upgrade post-representation learning.},
  keywords={Representation learning;Social networking (online);Pandemics;Semantics;Learning (artificial intelligence);Bidirectional control;Transformers;Rumor Debunking;Transformer;Variational Auto-Encoder;Contrastive Learning},
  doi={10.1109/AITest58265.2023.00032},
  ISSN={2835-3560},
  month={July},}@ARTICLE{10839466,
  author={Tan, Qinzhong and Li, Ao and Dong, Le and Dong, Weisheng and Li, Xin and Shi, Guangming},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={CDS-Net: Contextual Difference Sensitivity Network for Pixel-Wise Road Crack Detection}, 
  year={2025},
  volume={35},
  number={6},
  pages={5223-5235},
  abstract={Road crack detection is a key computer vision task that identifies and locates cracks in road surface images, which usually have an irregular shape and contain only a few pixels in width. Generative and unsupervised methods are popular these years, but generative methods require a lot of training data and computational power while unsupervised methods are not so satisfactory in pixel-level segmentation. The process is challenged by the irregularity of crack shapes and complex road image backgrounds. To alleviate these problems, we propose a novel method in this paper, CDS-Net, that significantly improves road crack detection performance through multiple practical modules, including the Multi-Directional Hierarchical Attention (MDHA) module and the Difference Sensitivity Reconstruction Block (DSRB). Specifically, the MDHA module employs a multi-directional feature extraction strategy to capture detailed information of cracks, thereby enhancing the discriminative power of the features. The DSRB module, designed to address the inefficiency of traditional skip-connections, utilizes masked convolution and graph convolution attention to reconstruct and refine feature representations. Additionally, we propose an improved weighted cross-entropy loss function to address the inherent class imbalance problem in road crack detection. Extensive experiments on five public datasets demonstrate that CDS-Net achieves superior performance compared to other state-of-the-art methods, showcasing its effectiveness and robustness in road crack detection. It also has a stronger generalization ability compared with other methods. Code is available at https://github.com/ttttqz/CDS-Net/tree/master.},
  keywords={Roads;Image segmentation;Feature extraction;Accuracy;Transformers;Surface cracks;Shape;Sensitivity;Convolution;Computational modeling;Crack detection;hierarchical attention;sensitivity reconstruction;cross-entropy loss},
  doi={10.1109/TCSVT.2025.3529039},
  ISSN={1558-2205},
  month={June},}@INPROCEEDINGS{8665362,
  author={Chen, Ke and Zhang, Weilin and Dubnov, Shlomo and Xia, Gus and Li, Wei},
  booktitle={2019 International Workshop on Multilayer Music Representation and Processing (MMRP)}, 
  title={The Effect of Explicit Structure Encoding of Deep Neural Networks for Symbolic Music Generation}, 
  year={2019},
  volume={},
  number={},
  pages={77-84},
  abstract={With recent breakthroughs in artificial neural networks, deep generative models have become one of the leading techniques for computational creativity. Despite very promising progress on image and short sequence generation, symbolic music generation remains a challenging problem since the structure of compositions are usually complicated. In this study, we attempt to solve the melody generation problem constrained by the given chord progression. In particular, we explore the effect of explicit architectural encoding of musical structure via comparing two sequential generative models: LSTM (a type of RNN) and WaveNet (dilated temporal-CNN). As far as we know, this is the first study of applying WaveNet to symbolic music generation, as well as the first systematic comparison between temporal-CNN and RNN for music generation. We conduct a survey for evaluation in our generations and implemented Variable Markov Oracle in music pattern discovery. Experimental results show that to encode structure more explicitly using a stack of dilated convolution layers improved the performance significantly, and a global encoding of underlying chord progression into the generation procedure gains even more.},
  keywords={Music;Autoregressive processes;Encoding;Neural networks;Computational modeling;Convolution;Data models;symbolic music generation;artificial intelligence;deep generative model;machine learning and understanding of music;Variable Markov Oracle;analysis of variance;music structure analysis},
  doi={10.1109/MMRP.2019.00022},
  ISSN={},
  month={Jan},}@ARTICLE{10128698,
  author={Li, Keqiuyin and Lu, Jie and Zuo, Hua and Zhang, Guangquan},
  journal={IEEE Transactions on Fuzzy Systems}, 
  title={Source-Free Multidomain Adaptation With Fuzzy Rule-Based Deep Neural Networks}, 
  year={2023},
  volume={31},
  number={12},
  pages={4180-4194},
  abstract={Unsupervised domain adaptation deals with a task from an unlabeled target domain by leveraging the knowledge gained from labeled source domain(s). The fuzzy system is adopted in domain adaptation to better tackle the uncertainty caused by information scarcity in the transfer. Most existing fuzzy and nonfuzzy domain adaptation methods depend on data-level distribution matching to eliminate the domain shift. However, data sharing can trigger privacy concerns. This situation results in the unavailability of source data, wherein most domain adaptation methods cannot be applied. Source-free domain adaptation is then proposed to handle this problem. But the existing source-free domain adaptation methods rarely deal with any soft information component due to data imprecision. Besides, fewer methods handle multiple source domains that provide richer transfer information. Thus, in this article, we propose source-free multidomain adaptation with fuzzy rule-based deep neural networks, which takes advantage of a fuzzy system to handle data uncertainty in domain adaptation without source data. To learn source private models with high generality, which is important to collect low-noise pseudotarget labels, auxiliary tasks are designed by jointly training source models from multiple domains, which share source parameters and fuzzy rules while protecting source data. To transfer fuzzy rules and fit source private parameters to the target domain, self-supervised learning and anchor-based alignment are built to force target data into source feature spaces. Experiments on real-world datasets under both homogeneous and heterogeneous label space scenarios are carried out to validate the proposed method. The results indicate the superiority of the proposed fuzzy rule-based source-free multidomain adaptation method.},
  keywords={Adaptation models;Feature extraction;Data models;Neural networks;Deep learning;Transfer learning;Machine learning;Classification;domain adaptation;fuzzy rules;machine learning;transfer learning},
  doi={10.1109/TFUZZ.2023.3276978},
  ISSN={1941-0034},
  month={Dec},}@INPROCEEDINGS{9786028,
  author={Djouima, Hossena and Zitouni, Athmane and Megherbi, Ahmed Chaouki and Sbaa, Salim},
  booktitle={2022 7th International Conference on Image and Signal Processing and their Applications (ISPA)}, 
  title={Classification of Breast Cancer Histopathological Images using DensNet201}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Diagnosing and classifying breast cancer tumors is a rather complex activity for pathologists due to the heterogeneous nature of the tumor cells. The wide use of artificial intelligence (AI) and the rise of Deep Learning (DL) have led to promising results in terms of breast histopathology images classification. The outcomes depend largely on two main factors, namely, the number and quality of images. BreaKhis dataset shows an imbalance in the image classes distribution, thus generating the performance degradation of the classifier model due to a biased classification towards the majority class. In this paper, a Deep Convolution Generative Adversial Network (DCGAN) is applied to give the number of images consistence in the minority (benign) class with that of the majority (malignant) class. Data augmentation is a technique used later to create more data from the limited ones. The DenseNet201 pre-trained model is chosen and used with the concatenation of features from various DensNet blocks. Instead of considering all the layers of the pre-trained network, the features are extracted from the lower layers of DensNet201, via a global average pooling (GAP). These features are passed to the softmax classifier to classify breast cancer. The model is evaluated using a two-class BreaKhis, provided at four magnification levels 40x, 100x, 200x, and 400x. The proposed method yielded test accuracies of 96%, 95%, 88%, and 92% respectively for each magnification factor. As indicated in the results, the proposed method based on data augmentation by DCGAN and feature concatenation using DenseNet201 pre-trained models could produce an efficient prediction for breast cancer image classification.},
  keywords={Deep learning;Degradation;Histopathology;Predictive models;Feature extraction;Breast cancer;Data models;deep learning;breast cancer;classification;DCGAN;transfer learning},
  doi={10.1109/ISPA54004.2022.9786028},
  ISSN={},
  month={May},}@INPROCEEDINGS{11010595,
  author={Duan, Yifei and Yang, Liuqingqing and Zhang, Tong and Song, Zhijun and Shao, Fenghua},
  booktitle={2025 4th International Symposium on Computer Applications and Information Technology (ISCAIT)}, 
  title={Automated UI Interface Generation via Diffusion Models: Enhancing Personalization and Efficiency}, 
  year={2025},
  volume={},
  number={},
  pages={780-783},
  abstract={This study proposes a UI interface generation method based on a diffusion model, aiming to achieve high-quality, diversified, and personalized interface design through generative artificial intelligence technology. The diffusion model is based on its step-by-step denoising generation process. By combining the conditional generation mechanism, design optimization module, and user feedback mechanism, the model can generate a UI interface that meets the requirements based on multimodal inputs such as text descriptions and sketches provided by users. In the study, a complete experimental evaluation framework was designed, and mainstream generation models (such as GAN, VAE, DALL·E, etc.) were selected for comparative experiments. The generation results were quantitatively analyzed from indicators such as PSNR, SSIM, and FID. The results show that the model proposed in this study is superior to other models in terms of generation quality and user satisfaction, especially in terms of logical clarity of information transmission and visual aesthetics. The ablation experiment further verifies the key role of conditional generation and design optimization modules in improving interface quality. This study provides a new technical path for UI design automation and lays the foundation for the intelligent and personalized development of human-computer interaction interfaces. In the future, the application potential of the model in virtual reality, game design, and other fields will be further explored.},
  keywords={Human computer interaction;Solid modeling;Adaptation models;Visualization;Design automation;Virtual reality;Games;Diffusion models;Optimization;Design optimization;Diffusion model;UI interface generation;User experience;Human-computer interaction},
  doi={10.1109/ISCAIT64916.2025.11010595},
  ISSN={},
  month={March},}@INPROCEEDINGS{8836978,
  author={Lin, Xiaoyu and Yuan, Tommy and Lei, Gang},
  booktitle={2019 2nd International Conference on Artificial Intelligence and Big Data (ICAIBD)}, 
  title={History and Development Tendency of Human - Computer Dialogue System}, 
  year={2019},
  volume={},
  number={},
  pages={154-160},
  abstract={As the core technology in the field of artificial intelligence, human-computer dialogue system is developing rapidly, and it is more widely used in various fields. The development of science and technology is increasing people and computer communications. In order to clarify the direction, the development process and complex nature of human-computer dialogue system are classified and analysed. The development of human-computer dialogue system can be considered as three stages: embryonic, development and breakthrough according to chronological order and technical characteristics. We comprehensively combine and summarize the representative results and shortcomings of each stage, and analyze the opportunities and challenges faced by human-computer dialogue systems in terms of capabilities and technical means to adapt to human needs. It is anticipated that the work will help to understand the direction of this line of research and contribute to the development of human-computer dialogue.},
  keywords={Task analysis;Information retrieval;Robots;History;Pipelines;Personal digital assistants;human-computer dialogue system;task-oriented;non-task-oriented;Intelligent Personal Assistant;social chatbot},
  doi={10.1109/ICAIBD.2019.8836978},
  ISSN={},
  month={May},}@INPROCEEDINGS{10365001,
  author={Gao, B. and Kong, X.},
  booktitle={Tianjin University-IET Electrical & Information Engineering Doctoral Forum (TJU IET 2023)}, 
  title={Intelligent electricity theft detection system in low-voltage stations considering data with low-quality and imbalance}, 
  year={2023},
  volume={2023},
  number={},
  pages={16-21},
  abstract={Accurate locating and timely processing of electricity theft targets are of great significance to guarantee the stability of the grid operation. With the development of the electric internet of things and artificial intelligence technologies, various efficient and intelligent electricity theft detection methods have been researched. However, the problems of the data imbalance, missing and exception are often encountered in actual conditions, which have led to the inferior performance for detection model. In this paper, the DLMVI-VAE-rACGANs-RD model, as a potential solution, is proposed to solve the dilemmas existing in the actual situation of electricity theft detection. Firstly, deep learning-based missing value imputation (DLMVI) method was used to solve the problem of data missing and exception. After that, the variational autoencoder (VAE) combined with label-noise robust auxiliary classifier generative adversarial networks (rACGANs) was developed to generate electricity theft data to eliminate the impact of data imbalance. Finally, the retrained discriminator (RD) of rACGANs is used to complete the mission of electricity theft detection. The comprehensive experimental results indicate that the DLMVI-VAE-rACGANs-RD model has a better detection performance.},
  keywords={},
  doi={10.1049/icp.2023.2822},
  ISSN={},
  month={Sep.},}@ARTICLE{10695083,
  author={Mudassar Yamin, Muhammad and Hashmi, Ehtesham and Ullah, Mohib and Katt, Basel},
  journal={IEEE Access}, 
  title={Applications of LLMs for Generating Cyber Security Exercise Scenarios}, 
  year={2024},
  volume={12},
  number={},
  pages={143806-143822},
  abstract={This study proposes a novel approach leveraging Large Language Models (LLMs) to generate dynamic and complex adaptable cybersecurity exercise scenarios. Motivated by Turing’s seminal exploration into machine cognition, which questions the ability of machines to mimic human thought and intelligence. By exploiting the generative potential of LLMs, our methodology simulates a wide range of cyber threats, both known and novel, thereby enhancing cybersecurity training and awareness. This approach transforms the potential for ‘hallucination’ inherent in LLMs into a potential advantage, enabling the creation of complex exercise scenarios that push the boundaries of traditional cybersecurity training. The innovation lies in the sophisticated application of AI, aiming to advance the preparedness of security professionals against diverse cyber threats. The scenarios generated through this method were subject to meticulous testing and a rigorous evaluation process involving (Generated Pre-Trained Transformer) GPT models and expert review to ensure their realism and applicability. In this paper, we introduce ‘CyExec,’ a novel approach leveraging GPT to dynamically generate cybersecurity training scenarios. Furthermore, the prompts provided to the LLMs were meticulously designed to adopt a Retrieval-Augmented Generation (RAG) approach, enriching the complexity and relevance of the scenarios. This incorporation of RAG, alongside the inspiration drawn from Turing’s exploration of machine intelligence, showcases an advanced application of AI in cybersecurity training, reflecting a deep understanding of how machines can augment our capabilities to anticipate and mitigate cyber threats.},
  keywords={Training;Computer security;Computer crime;Security;Manuals;Transformers;Testing;Organizations;Ethics;Data models;Cyber security exercise scenarios;large language models;bounded rationality;generative configurations;Halluciation in LLMs},
  doi={10.1109/ACCESS.2024.3468914},
  ISSN={2169-3536},
  month={},}@ARTICLE{10896802,
  author={Golfe, Alejandro and Colomer, Adrián and Prades, José and Naranjo, Valery},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Enhancing Image Retrieval Performance With Generative Models in Siamese Networks}, 
  year={2025},
  volume={29},
  number={7},
  pages={4956-4968},
  abstract={Prostate cancer is a critical healthcare challenge globally and is one of the most prevalent types of cancer in men. Early and accurate diagnosis is essential for effective treatment and improved patient outcomes. In the existing literature, computer-aided diagnosis (CAD) solutions have been developed to assist pathologists in various tasks, including classification, diagnosis, and prostate cancer grading. Content-based image retrieval (CBIR) techniques provide valuable approaches to enhance these computer-aided solutions. This study evaluates how generative deep learning models can improve the quality of retrievals within a CBIR system. Specifically, we propose applying a Siamese Network approach, which enables us to learn how to encode image patches into latent representations for retrieval purposes. We used the ProGleason-GAN framework trained on the SiCAPv2 dataset to create similar pairs of input patches. Our observations indicate that introducing synthetic patches leads to notable improvements in the evaluated metrics, underscoring the utility of generative models within CBIR tasks. Furthermore, this work is the first in the literature where latent representations optimized for CBIR are used to train an attention mechanism for performing Gleason Scoring of a WSI.},
  keywords={Feature extraction;Biological system modeling;Deep learning;Solid modeling;Image retrieval;Histopathology;Vectors;Prostate cancer;Biopsy;Bioinformatics;Generative deep learning;prostate cancer;image retrieval;siamese network;histology},
  doi={10.1109/JBHI.2025.3543907},
  ISSN={2168-2208},
  month={July},}@INPROCEEDINGS{10860622,
  author={Rumondor, Abraham David and Abimanyu, Aditya and Abiyyu’Ammaar, Muhammad and Achmad, Said and Sutoyo, Rhio},
  booktitle={2024 10th International HCI and UX Conference in Indonesia (CHIuXiD)}, 
  title={Improving Programmer Work Quality with ChatGPT Assistance}, 
  year={2024},
  volume={},
  number={},
  pages={42-47},
  abstract={The potential of artificial intelligence as a tool that can be an assistant for humans is very close. This is reinforced by the breakthrough of a generative model that is considered to be able to help many tasks that are usually done by humans, namely ChatGPT. ChatGPT successfully demonstrated its potential by providing complete and intact code generation. ChatGPT, with GPT-3, is one of many language models currently available for people. In previous research, ChatGPT was tested to see if it could provide appropriate programming code results and perform large-scale data analysis on a specific dataset described in sentence form. The limitations of ChatGPT include understanding and generating code, which requires further training data. This opportunity positions ChatGPT as a provider of programming materials and a place to seek solutions to problems faced by programmers. This paper investigates the capabilities and also limitations of ChatGPT to help with the works of programmer’s daily tasks by examining overall ChatGPT capabilities within the assigned environment as a Programmer Assistant and examining the overall probability of ChatGPT limitations and failures to generate the results from specified prompts from the programmer. This study formulated the research question and performed the PRISMA step to answer the question. This study found significant potential for ChatGPT as a programmer’s assistant, catering to requests related to programming and design, and also functions as a tool for designing programming code to be implemented in software development.},
  keywords={Codes;Training data;Programming;Chatbots;Artificial intelligence;Software development management;Programmer;Programming;AI Assistant;and ChatGPT},
  doi={10.1109/CHIuXiD64022.2024.10860622},
  ISSN={},
  month={Nov},}@ARTICLE{9761928,
  author={Wang, Kunxi and Hu, Tianyue and Wang, Shangxu},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Unsupervised Learning for Seismic Internal Multiple Suppression Based on Adaptive Virtual Events}, 
  year={2022},
  volume={60},
  number={},
  pages={1-13},
  abstract={Seismic internal multiples are the key factors affecting the accuracy and reliability of velocity analysis and migration. The removal of internal multiples is a challenging direction. To effectively remove the internal multiples from the seismic data, we propose the unsupervised deep neural network (DNN) combined with the adaptive virtual events (AVEs) method. First, we use the AVE method to get the predicted internal multiples, which can calibrate the true internal multiples in the original data, also called the full wavefield data. Second, the unsupervised learning with the DNN is used as a nonlinear operator to minimize the difference between the estimated internal multiples and original data. The trained DNN can obtain the estimated internal multiples through the predicted internal multiples, thereby completing the suppression of the internal multiples. Since our proposed unsupervised learning is essentially an optimization process, it does not require true primaries as the label data to participate in the training process for the DNN. Therefore, our proposed method can deal with the problem of lack of training set and would have some good practical application value with low computational cost. The effectiveness and efficiency of our proposed method are verified through two sets of synthetic data and one land field data examples.},
  keywords={Deep learning;Scattering;Convolutional neural networks;Surface waves;Unsupervised learning;Training;Three-dimensional displays;Adaptive virtual events (AVE);deep neural network (DNN);internal multiple;unsupervised learning},
  doi={10.1109/TGRS.2022.3169481},
  ISSN={1558-0644},
  month={},}@INBOOK{10614265,
  author={Ojanperä, Tero},
  booktitle={AI Revolution: Mastering AI for Personal and Organizational Growth}, 
  title={5 AI Changes Society}, 
  year={2024},
  volume={},
  number={},
  pages={91-100},
  abstract={"The AI Revolution" is a practical guide to using new AI tools, such as ChatGPT, DALLE and Midjourney. Learn how to multiply your productivity by guiding or prompting AI in various ways. The book also introduces Microsoft Copilot, Google Bard, and Adobe Photoshop Generative Fill, among other new applications. ChatGPT reached a hundred million users in just two months after its release, faster than any other application before. This marked the advent of the generative AI era. Generative AI models generate text, images, music, videos, and even 3D models in ways previously thought impossible for machines. The book explains in an understandable manner how these AI models work. The book provides examples of how AI increases productivity, which professions are changing or disappearing, and how job markets will evolve in the coming years. With this book, you'll learn to recognize the opportunities and risks AI offers. Understand what this change demands from individuals and companies and what strategic skills are required. The book also covers legal questions caused by generative AI, like copyrights, data protection, and AI regulation. It also ponders societal impacts. AI produces content, thus influencing language, culture, and even worldviews. Therefore, it's crucial to understand by whom and how AI is trained. The AI revolution started by ChatGPT is just the beginning. This handbook is for you if you want to keep up with the rapid development of AI.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770042314},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10614265},}@INPROCEEDINGS{10834365,
  author={Alario-Hoyos, Carlos and Kemcha, Rebiha and Kloos, Carlos Delgado and Callejo, Patricia and Estévez-Ayres, Iria and Santín-Cristóbal, David and Cruz-Argudo, Francisco and López-Sánchez, José Luis},
  booktitle={2024 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}, 
  title={Tailoring Your Code Companion: Leveraging LLMs and RAG to Develop a Chatbot to Support Students in a Programming Course}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Students frequently rely on chatbots powered by generative Artificial Intelligence (GenAI), such as ChatGPT, Copilot, Gemini, and Claude, to assist with a wide range of academic tasks. However, these chatbots are not specifically designed for the context of particular courses, which can lead to responses that are sometimes inaccurate or insufficiently relevant. This paper introduces a chatbot specifically designed to support first-year engineering students in a Java programming course. Developed using the Retrieval-Augmented Generation (RAG) technique, the chatbot draws on course-specific resources such as videos, quizzes, programming exercises, and other materials, while using OpenAI’s Large Language Models (LLMs) GPT-4 and GPT-3.5 for information analysis and response generation. The data collected, consisting of logs from 1,059 messages sent by students to the chatbot and 30 responses to a survey, indicate that students primarily used the chatbot to clarify concepts and explain code snippets. Moreover, most of the students reported that the responses provided by the chatbot were well suited to the Java programming course.},
  keywords={Surveys;Java;Codes;Large language models;Retrieval augmented generation;Learning (artificial intelligence);Programming;Chatbots;Videos;Information analysis;Large Language Models (LLMs);Retrieval-Augmented Generation (RAG);Generative Artificial Intelligence (GenAI);Chatbots;and Programming Course},
  doi={10.1109/TALE62452.2024.10834365},
  ISSN={},
  month={Dec},}@ARTICLE{10634792,
  author={Xie, Gaochang and Xiong, Zehui and Zhang, Xinyuan and Xie, Renchao and Liu, Yunjie and Shen, Xuemin},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={Towards the Vehicular Metaverse: Exploring Distributed Inference With Transformer-Based Diffusion Model}, 
  year={2024},
  volume={73},
  number={12},
  pages={19931-19936},
  abstract={Generative artificial intelligence (GAI) is emerging as a promising solution for the vehicular metaverse due to its adaptable, high-quality, and multi-modal content generation capabilities. Particularly noteworthy is the recent introduction of the Sora model, a Transformer-based diffusion model, which exhibits exceptional performance in visual scenarios. However, diffusion vision transformer (DViT) models face limitations in terms of device resources, inference latency, and personalized requirements at the edge, despite their practical effectiveness in clouds. In response, we propose a DViT-enabled system to enhance vehicular metaverse services. Our approach involves a distributed DViT inference mechanism where road-side units (RSUs) and vehicles collaborate to execute the diffusion process and generate personalized content within vehicles using local prompts. Additionally, we address users' latency-sensitive service demands by formulating a distributed latency optimization problem that considers bandwidth, computation power, and dynamic positioning of heterogeneous devices. We then propose a value iteration-based distributed inference algorithm capable of adaptively determining optimal inference strategies within resource-constrained vehicular networks. Numerical simulations demonstrate that our approach achieves superior performance in reducing latency and enhancing success rates for inference tasks.},
  keywords={Metaverse;Diffusion models;Transformers;Vehicle dynamics;Optimization;Computational modeling;Artificial intelligence;Distributed inference;generative artificial intelligence (GAI);latency optimization;vehicular metaverse},
  doi={10.1109/TVT.2024.3442292},
  ISSN={1939-9359},
  month={Dec},}@INBOOK{10614277,
  author={Ojanperä, Tero},
  booktitle={AI Revolution: Mastering AI for Personal and Organizational Growth}, 
  title={8 Will AI Define our Culture, Language, and Worldview?}, 
  year={2024},
  volume={},
  number={},
  pages={125-134},
  abstract={"The AI Revolution" is a practical guide to using new AI tools, such as ChatGPT, DALLE and Midjourney. Learn how to multiply your productivity by guiding or prompting AI in various ways. The book also introduces Microsoft Copilot, Google Bard, and Adobe Photoshop Generative Fill, among other new applications. ChatGPT reached a hundred million users in just two months after its release, faster than any other application before. This marked the advent of the generative AI era. Generative AI models generate text, images, music, videos, and even 3D models in ways previously thought impossible for machines. The book explains in an understandable manner how these AI models work. The book provides examples of how AI increases productivity, which professions are changing or disappearing, and how job markets will evolve in the coming years. With this book, you'll learn to recognize the opportunities and risks AI offers. Understand what this change demands from individuals and companies and what strategic skills are required. The book also covers legal questions caused by generative AI, like copyrights, data protection, and AI regulation. It also ponders societal impacts. AI produces content, thus influencing language, culture, and even worldviews. Therefore, it's crucial to understand by whom and how AI is trained. The AI revolution started by ChatGPT is just the beginning. This handbook is for you if you want to keep up with the rapid development of AI.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770042314},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10614277},}@ARTICLE{11152548,
  author={Luo, Jiutong and Zhu, Chunying and Hu, Lixin and Sun, Meng},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Empowering Preservice Teachers Through Textbook Design Activities With GAI-Based Chatbot}, 
  year={2025},
  volume={18},
  number={},
  pages={822-832},
  abstract={Generative artificial intelligence (GAI) has become an epoch-making technology in the educational context. With a quasi-experimental repeated measure design and mixed-method data collection, this study examined the effects of the GAI-based chatbot in assisting preservice teachers in implementing the new national curriculum standards in Mainland China and their perceptions accordingly. A sample of 26 preservice teachers (divided into 13 teams) was included in this two-phrase study. Results showed that textbook design activities with the chatbot effectively promoted participants’ acquisition of content knowledge and improved self-efficacy, although it did not reduce teaching anxiety. Evidence was also extracted from participants’ open-ended responses with an extended COSTEM (i.e., content, others, self, tasks, ethics, and model) framework. Meanwhile, preservice teachers perceived both advantages and disadvantages regarding the utility of the GAI-based chatbot in learning. Implications of this study were also discussed.},
  keywords={Education;Standards;Chatbots;Anxiety disorders;Artificial intelligence;Training;Engineering profession;Electronic mail;Technological innovation;Hands;Advantages;disadvantages;generative artificial intelligence (GAI);preservice teachers;textbook design},
  doi={10.1109/TLT.2025.3606757},
  ISSN={1939-1382},
  month={},}@ARTICLE{8389206,
  author={Zheng, Ziqiang and Wang, Chao and Yu, Zhibin and Zheng, Haiyong and Zheng, Bing},
  journal={IEEE Access}, 
  title={Instance Map Based Image Synthesis With a Denoising Generative Adversarial Network}, 
  year={2018},
  volume={6},
  number={},
  pages={33654-33665},
  abstract={Semantic layout-based image synthesizing, which has benefited from the success of generative adversarial networks (GANs), has received a substantial amount of attention recently. How to enhance the synthesis image equality while maintaining the stochasticity of the GAN remains a challenge. We propose a novel denoising framework to handle this problem. The generation of overlapping objects is another challenging task when synthesizing images from a semantic layout to a realistic RGB photograph. To overcome this deficiency, we include a one-hot semantic label map to force the generator to pay more attention to the generation of overlapping objects. Furthermore, we improve the loss function of the discriminator by considering the perturbed loss and cascade layer loss to guide the generation process. We applied our methods to the Cityscapes, photo-sketch, day-night, facades, and NYU datasets to demonstrate the image generation ability of our model.},
  keywords={Gallium nitride;Semantics;Generators;Task analysis;Convolution;Layout;Neural networks;Underwater technology;artificial neural networks;image processing},
  doi={10.1109/ACCESS.2018.2849108},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10849478,
  author={Benamara, Issam and Viennet, Emmanuel},
  booktitle={2024 IEEE 36th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Power of Suggestion: Strategic Feature Manipulation in Transformer-Based Models}, 
  year={2024},
  volume={},
  number={},
  pages={174-180},
  abstract={This paper presents ASGARD, a novel generative framework for personalized advertising strategy design. ASGARD integrates user-preferences while maintaining the ability to autonomously generate high-quality outputs. The core challenge is balancing user preferences with the model's knowledge, enabling it to align with user inputs or propose optimal alternatives. Our novel approach uses a token-driven method for strategy generation, adapts a token masking strategy for training, and refines the loss function to prevent issues like mode collapse. We evaluate ASGARD to demonstrate its effectiveness, identify limitations, and suggest future enhancements. To our knowledge, this is the first approach that meets all constraints of advertising strategy design while allowing user-preference integration, showing potential for generalization across transformer-based generative models.},
  keywords={Training;Degradation;Adaptation models;Transformers;User preference;Advertising;Artificial intelligence;Generative Model;Transformers;Preference Injection;Adaptive Control Mechanism;AI Assistant;Digital Advertising},
  doi={10.1109/ICTAI62512.2024.00033},
  ISSN={2375-0197},
  month={Oct},}@ARTICLE{10438453,
  author={Chen, Jiayuan and Yi, Changyan and Du, Hongyang and Niyato, Dusit and Kang, Jiawen and Cai, Jun and Shen, Xuemin},
  journal={IEEE Network}, 
  title={A Revolution of Personalized Healthcare: Enabling Human Digital Twin With Mobile AIGC}, 
  year={2024},
  volume={38},
  number={6},
  pages={234-242},
  abstract={Mobile artificial intelligence-generated content (AIGC) refers to the adoption of generative artificial intelligence (GAI) algorithms deployed at mobile edge networks to automate the information creation process while fulfilling the requirements of end users. Mobile AIGC has recently attracted phenomenal attentions and can be a key enabling technology for an emerging application, called human digital twin (HDT). HDT empowered by the mobile AIGC is expected to revolutionize the personalized healthcare by generating rare disease data, modeling highfidelity digital twin, building versatile testbeds, and providing 24/7 customized medical services. To promote the development of this new breed of paradigm, in this article, we propose a system architecture of mobile AIGC-driven HDT and highlight the corresponding design requirements and challenges. Moreover, we illustrate two use cases, i.e., mobile AIGC-driven HDT in customized surgery planning and personalized medication. In addition, we conduct an experimental study to prove the effectiveness of the proposed mobile AIGC-driven HDT solution, which shows a particular application in a virtual physical therapy teaching platform. Finally, we conclude this article by briefly discussing several open issues and future directions.},
  keywords={Medical services;Data models;Solid modeling;Digital twins;Data collection;Distributed databases;Mobile communication;Artificial intelligence;Generative AI;Content management;Multi-access edge computing},
  doi={10.1109/MNET.2024.3366560},
  ISSN={1558-156X},
  month={Nov},}@ARTICLE{9684443,
  author={Cao, Xingdong and Lai, Kenneth and Hsu, Gee-Sern Jison and Smith, Michael and Yanushkevich, Svetlana N.},
  journal={IEEE Access}, 
  title={Cross-Spectrum Thermal Face Pattern Generator}, 
  year={2022},
  volume={10},
  number={},
  pages={9576-9586},
  abstract={Conversion of a visible face image into a thermal face image (V2T), or one thermal face image into another one given a different target temperature (T2T), is required in applications such as thermography, human body thermal pattern analysis, and surveillance using cross-spectral imaging. In this work, we propose to use conditional generative adversarial networks (cGAN) with cGAN loss, perceptual loss, and temperature loss to solve the conversion tasks. In our experiment, we used Carl and SpeakingFaces Databases. Frèchet Inception Distance (FID) is used to evaluate the generated images. As well, face recognition was applied to assess the performance of our models. For the V2T task, the FID of the generated thermal images reached a low value of 57.3. For the T2T task, we achieved a rank-1 face recognition rate of 91.0% which indicates that the generated thermal images preserve the majority of the identity information.},
  keywords={Face recognition;Task analysis;Databases;Generators;Training;Temperature measurement;Generative adversarial networks;Generative adversarial networks;image-to-image translation;thermal pattern generation;face recognition;biometrics},
  doi={10.1109/ACCESS.2022.3144308},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11084045,
  author={Deng, Xiaofei},
  booktitle={2025 IEEE 5th International Conference on Electronic Technology, Communication and Information (ICETCI)}, 
  title={Multi-Scale Attentional Networks with Adaptive Normalization for Real-to-Cartoon Facial Image Translation}, 
  year={2025},
  volume={},
  number={},
  pages={389-393},
  abstract={Facial cartoonization, crucial for applications in virtual reality, multimedia entertainment, and online communication, faces challenges in maintaining semantic coherence and high-fidelity outputs under hardware constraints. Traditional Cycle-GAN-based methods often suffer from mode collapse and discriminators’ overemphasis on local features, leading to artifacts and semantic fragmentation. This paper proposes an enhanced framework, U-GAT-IT (Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization), integrating multi-scale attention mechanisms and adaptive normalization (AdaLIN) to address these limitations. The attention module dynamically prioritizes critical facial features across hierarchical levels, balancing local details and global structures. AdaLIN adaptively fuses Instance and Layer Normalization, enabling content-aware stylization intensity adjustment. Experiments on a dataset of 10,000 Asian faces and 10,000 anime images demonstrate U-GAT-IT’s superiority: it achieves a 25% improvement in eye transformation accuracy (SSIM) and 30% faster convergence compared to Cycle-GAN. Results show realistic cartoon avatars with preserved geometric consistency, complete background removal, and reduced noise artifacts. Additionally, U-GAT-IT exhibits robustness in cross-domain tasks, such as medical imaging. Future directions include 3D expression synchronization, lightweight deployment, and multi-task collaboration with speech-driven modules. This work establishes a novel paradigm for GANs in complex cross-domain image translation, offering theoretical and practical advancements.},
  keywords={Adaptive systems;Attention mechanisms;Translation;Image color analysis;Shape;Semantics;Robustness;Generators;Facial features;Biomedical imaging;Generative Adversarial Network;Cycle-GAN;image transformation;Attention mechanism},
  doi={10.1109/ICETCI64844.2025.11084045},
  ISSN={},
  month={May},}@INPROCEEDINGS{10768582,
  author={Chu, Jieping and Wu, Junjing and Yuan, Nana and Lu, Tingyi and Gu, Lejun and He, Xing},
  booktitle={2024 The 9th International Conference on Power and Renewable Energy (ICPRE)}, 
  title={Fault Diagnosis of Wind Turbines Based on TimeGAN-Stacking}, 
  year={2024},
  volume={},
  number={},
  pages={735-739},
  abstract={The lack of sufficient fault samples to support the training of fault diagnosis models in wind turbines often leads to monitoring systems missing or misreporting faults. In response to the above issues, this article proposes a fault diagnosis method for wind turbine pitch system based on TimeGAN-Stacking. At the data level, due to the imbalance of the original sample categories, a Time Generative Adversarial Network (TimeGAN) is used to track the dynamic changes in the probability distribution of wind turbine operation data step by step, while optimizing the global and local distribution of the generated samples, effectively balancing and expanding the comprehensive sample set of wind turbine faults; At the model level, establish a Stacking integrated model that integrates the advantages of multiple fault diagnosis devices to further improve fault diagnosis capabilities. Finally, the proposed method was tested based on actual wind field data, and the results showed that the TimeGAN-Stacking fault recognition method can effectively diagnose wind turbine faults and has good recognition performance.},
  keywords={Fault diagnosis;Training;Performance evaluation;Renewable energy sources;Stacking;Wind farms;Feature extraction;Data models;Probability distribution;Wind turbines;timeseries generative adversarial network;sample enhancement;data driven},
  doi={10.1109/ICPRE62586.2024.10768582},
  ISSN={2768-0525},
  month={Sep.},}@INPROCEEDINGS{10688255,
  author={Guo, Liyan and Song, Kaiyu and Xu, Mengying and Lai, Hanjiang},
  booktitle={2024 IEEE International Conference on Multimedia and Expo (ICME)}, 
  title={DNAF: Diffusion with Noise-Aware Feature for Pose-Guided Person Image Synthesis}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Pose-guided person image synthesis aims at generating images based on the related pose skeleton and the appearance of a source image. As a popular generative model, the diffusion model shows its potential. However, there are two gaps to hinder the fusion between pose information and appearance: 1) Directly injecting pixel-level pose information into semantic features leads to the representation gap. 2) The timestep-dependent nature of the diffusion model introduces the noise-induced gap. To alleviate these, we propose Diffusion with Noise-Aware Feature(DNAF). Concretely, we leverage the T2I-Adapter-based pose adapter to achieve the mapping from the pixel level to the feature level. Then, we propose a lightweight trainable layer to infuse the multi-scale constant feature adaptively. In the end, we construct noise-aware features to more effectively guide the diffusion process. Experimental results show that DNAF achieves competitive results on DeepFashion and Market-1501 datasets.},
  keywords={Image synthesis;Semantics;Diffusion processes;Diffusion models;Skeleton;pose transfer;diffusion model;person image synthesis;conditional image generation;generative model},
  doi={10.1109/ICME57554.2024.10688255},
  ISSN={1945-788X},
  month={July},}@ARTICLE{10444916,
  author={Xiao, Feng and Liu, Ruyu and Zhu, Yunrui and Zhang, Haoyu and Zhang, Jianhua and Chen, Shengyong},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={A Dense Multicross Self-Attention and Adaptive Gated Perceptual Unit Method for Few-Shot Semantic Segmentation}, 
  year={2024},
  volume={5},
  number={6},
  pages={2493-2504},
  abstract={Few-shot semantic segmentation (FSSS) is a pivotal and prevalent research task for advancing the field of artificial intelligence. The task entails learning to differentiate between various classes in a support set and leveraging this knowledge on samples within a query set. However, traditional deep learning methods tend to underperform in this context due to limited training samples and subtle correlations between query and support images that are inadequately utilized. Existing methods for FSSS often compress support information into prototype categories or utilize only partial pixel-level support information, resulting in a significant impact. In this article, we propose a novel auto FSSS method that employs dense multicross self-attention and adaptive gate perception units to tackle this challenge. Specifically, our proposed method treats each query pixel as a label and predicts its segmentation label as the sum of labels of all support pixels. The method fully utilizes foreground and background support information through multilevel pixel correlations between paired query and support features to achieve state-of-the-art performance with only 1–5 annotated images. Moreover, our proposed adaptive gating perception unit filters and weighs each support image information by adaptively learning the gating values. This ensures the model selects only the most relevant support image information to the current query image. The proposed method is evaluated on several popular FSSS datasets and compared with state-of-the-art methods. Additionally, a visual analysis of our method is conducted to demonstrate its ability to distinguish different semantic categories and exhibit robustness at segmentation boundaries.},
  keywords={Semantic segmentation;Transformers;Task analysis;Semantics;Visualization;Artificial intelligence;Adaptation models;Auto machine learning;computer vision;few-shot semantic segmentation (FSSS);vision transformer},
  doi={10.1109/TAI.2024.3369553},
  ISSN={2691-4581},
  month={June},}@INPROCEEDINGS{10645262,
  author={Dasgupta, Subhram and Mason, Janelle and Yuan, Xiaohong and Odeyomi, Olusola and Roy, Kaushik},
  booktitle={2024 International Conference on Artificial Intelligence, Big Data, Computing and Data Communication Systems (icABCD)}, 
  title={Enhancing Deepfake Detection using SE Block Attention with CNN}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In the digital age, Deepfake present a formidable challenge by using advanced artificial intelligence to create highly convincing manipulated content, undermining information authenticity and security. These sophisticated fabrications surpass traditional detection methods in complexity and realism. To address this issue, we aim to harness cutting-edge deep learning methodologies to engineer an innovative deepfake detection model. However, most of the models designed for deepfake detection are large, causing heavy storage and mem-ory consumption. In this research, we propose a lightweight convolution neural network (CNN) with squeeze and excitation block attention (SE) for Deepfake detection. The SE block module is designed to perform dynamic channel-wise feature recalibration. The SE block allows the network to emphasize informative features and suppress less useful ones, which leads to a more efficient and effective learning module. This module is integrated with a simple sequential model to perform Deepfake detection. The model is smaller in size and it achieves competing accuracy with the existing models for deepfake detection tasks. The model achieved an overall classification accuracy of 94.14% and AVC-ROC score of 0.985 on the Style GAN dataset from the Diverse Fake Face Dataset. Our proposed approach presents a promising avenue for combating the Deepfake challenge with minimal computational resources, developing efficient and scalable solutions for digital content verification.},
  keywords={Deep learning;Deepfakes;Accuracy;Convolution;Computational modeling;Predictive models;Artificial intelligence;SE Block;CNN;Deepfake Detection;Entire Face Synthesis},
  doi={10.1109/icABCD62167.2024.10645262},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10271595,
  author={Marques, Stella Azevedo and Rodriguez, Demostenes Zegarra and Rosa, Renata Lopes},
  booktitle={2023 International Conference on Software, Telecommunications and Computer Networks (SoftCOM)}, 
  title={Use of ChatGPT as Configuration Support Tool and Network Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This article presents the configuration of development environments intended for the analysis of computer networks, ranging from the configuration of virtual machines to the analysis of packet traffic on the network using the Generative Pre-Trained Transformer (GPT). This article investigates the application of the ChatGPT tool, a variant based on the GPT-3.5 architecture developed by OpenAI, which employs a natural language model. The tool is employed as a facilitator in the configuration of network simulation scenarios. The study shows ChatGPT as an intelligent automatic assistant, being a great ally mainly in studies, and as a configuration assistant in the area of Computer Networks. In addition, it is also useful for beginners in this field, as it thoroughly describes the procedures needed to set up a development and network analysis environment. The work also presents the existing limitations inherent to this technology, such as the need for internet access and the possibility of inaccurate or incomplete answers. Making it clear that the use of artificial intelligence is a great ally, but until the present study there is no remote chance of replacing human expertise.},
  keywords={Analytical models;Computational modeling;Natural languages;Network analyzers;Chatbots;Transformers;Computer networks;Generative Pre-Trained Transformer;intelligent automatic assistant;ChatGPT;computer networks},
  doi={10.23919/SoftCOM58365.2023.10271595},
  ISSN={1847-358X},
  month={Sep.},}@INPROCEEDINGS{10098084,
  author={Menéndez, Héctor D.},
  booktitle={2022 IEEE 34th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Measuring Machine Learning Robustness in front of Static and Dynamic Adversaries*}, 
  year={2022},
  volume={},
  number={},
  pages={174-181},
  abstract={Adversarial machine learning brought a new way of understanding the reliability of different learning systems. Knowing that the learning confidence depends significantly on small changes, such as noise, created a mind change in the artificial intelligence community, who started to consider the boundaries and limitations of machine learning methods. However, if we can measure these limitations, we can improve the strength of our machine learning models and their robustness. Following this motivation, this work introduces different measures of robustness for machine learning models based on false negatives. These measures can be evaluated for either static or dynamic scenarios, where an adversary performs intelligent actions to evade the system. To evaluate the metrics I have applied 11 classifiers to different benchmark datasets and created an adversary that performs an evolutionary search process aiming to reduce the classification accuracy. The results show that the most robust models are related to K-Nearest Neighbours, Logistic regression, and neural networks, although none of the systems is robust enough when the target is to reach a single misclassification.},
  keywords={Measurement;Learning systems;Neural networks;Learning (artificial intelligence);Benchmark testing;Robustness;Adversarial machine learning;Machine Learning Testing;Adversarial Machine Learning;Robustness;Blindspots},
  doi={10.1109/ICTAI56018.2022.00033},
  ISSN={2375-0197},
  month={Oct},}@ARTICLE{10848485,
  author={Shaham, Sina and Hajisafi, Arash and Quan, Minh K. and Nguyen, Dinh C. and Krishnamachari, Bhaskar and Peris, Charith and Ghinita, Gabriel and Shahabi, Cyrus and Pathirana, Pubudu N.},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Privacy and Fairness in Machine Learning: A Survey}, 
  year={2025},
  volume={6},
  number={7},
  pages={1706-1726},
  abstract={Privacy and fairness are two crucial pillars of responsible artificial intelligence (AI) and trustworthy machine learning (ML). Each objective has been independently studied in the literature with the aim of reducing utility loss in achieving them. Despite the significant interest attracted from both academia and industry, there remains an immediate demand for more in-depth research to unravel how these two objectives can be simultaneously integrated into ML models. As opposed to well-accepted trade-offs, i.e., privacy-utility and fairness-utility, the interrelation between privacy and fairness is not well-understood. While some works suggest a trade-off between the two objective functions, there are others that demonstrate the alignment of these functions in certain scenarios. To fill this research gap, we provide a thorough review of privacy and fairness in ML, including supervised, unsupervised, semisupervised, and reinforcement learning. After examining and consolidating the literature on both objectives, we present a holistic survey on the impact of privacy on fairness, the impact of fairness on privacy, existing architectures, their interaction in application domains, and algorithms that aim to achieve both objectives while minimizing the utility sacrificed. Finally, we identify research challenges in achieving concurrently privacy and fairness in ML, particularly focusing on large language models.},
  keywords={Privacy;Data privacy;Surveys;Artificial intelligence;Reviews;Mathematical models;Decision making;Biological system modeling;Terminology;Social networking (online);Fairness;machine learning;privacy;supervised learning;unsupervised learning},
  doi={10.1109/TAI.2025.3531326},
  ISSN={2691-4581},
  month={July},}@ARTICLE{11072501,
  author={Lloret Abrisqueta, Francisco Antonio and Guerrero González, Antonio and Zapata Martinez, Roberto},
  journal={IEEE Latin America Transactions}, 
  title={Redefining Human-Machine Collaboration: Industry 5.0 to Improve Safety and Efficiency}, 
  year={2025},
  volume={23},
  number={8},
  pages={729-735},
  abstract={This study presents an innovative implementation of Industry 5.0 principles in a window production line, integrating advanced robotics and artificial intelligence technologies to improve operational efficiency and worker well-being. A robotic cell was designed to automate the handling of heavy components in the final production stage, resulting in a 35% reduction in cycle times and a significant decrease in ergonomic risks. Additionally, an interactive voice assistant based on generative AI was implemented, allowing operators to access system data and technical information in real-time through cognitive interaction. The results show a substantial improvement in job satisfaction, with a 278% increase in the perception of occupational health. This approach not only optimizes productivity but also redefines workers' roles, aligning with the human-centered vision of Industry 5.0. The study demonstrates how the integration of advanced technologies can create safer, more efficient, and adaptable work environments in modern manufacturing.},
  keywords={Production;Robots;Fifth Industrial Revolution;Real-time systems;Service robots;Personal voice assistants;Manufacturing;Collaboration;Accuracy;Unified modeling language;generative AI;advanced robotics;industry 5.0;occupational health},
  doi={10.1109/TLA.2025.11072501},
  ISSN={1548-0992},
  month={Aug},}@INPROCEEDINGS{10730450,
  author={Si, Jongwook and Yang, Seongeun and Song, Jeyong and Son, Seungjae and Lee, Sangjin and Kim, Daemin and Kim, Sungyoung},
  booktitle={2024 IEEE International Conference on Artificial Intelligence in Engineering and Technology (IICAIET)}, 
  title={Generating and Integrating Diffusion Model-Based Panoramic Views for Virtual Interview Platform}, 
  year={2024},
  volume={},
  number={},
  pages={343-348},
  abstract={This paper presents a new approach to improve virtual interview platforms in education, which are gaining significant attention. This study aims to simplify the complex manual process of equipment setup to enhance the realism and reliability of virtual interviews. To this end, this study proposes a method for automatically constructing 3D virtual interview environments using diffusion technology in generative AI. In this research, we exploit a diffusion model capable of generating high-quality panoramic images. We generate images of interview rooms capable of delivering immersive interview experiences via refined text prompts. The resulting imagery is then reconstituted 3D VR content utilizing the Unity engine, facilitating enhanced interaction and engagement within virtual environments. This research compares and analyzes various methods presented in related research and proposes a new process for efficiently constructing 360-degree virtual environments. When wearing Oculus Quest 2 and experiencing the virtual environment created using the proposed method, a high sense of immersion was experienced, similar to the actual interview environment.},
  keywords={Three-dimensional displays;Generative AI;Education;Virtual environments;Manuals;Learning (artificial intelligence);Diffusion models;Reliability;Interviews;Engines;Virtual Interview;Diffusion;AI;Panorama;Deep Learning},
  doi={10.1109/IICAIET62352.2024.10730450},
  ISSN={},
  month={Aug},}@INBOOK{10951654,
  author={Malviya, Rishabha and Rajput, Shivam and Vaidya, Makarand},
  booktitle={Artificial Intelligence for Bone Disorder: Diagnosis and Treatment}, 
  title={Deep Supervised Learning on Radiological Images to Classify Bone Fractures}, 
  year={2024},
  volume={},
  number={},
  pages={59-77},
  abstract={Summary <p>Several researchers in recent years have proposed several ways to classify bone fractures. Despite this, there is no well&#x2010;defined system for categorizing the many fractures that might occur in a human body. The use of X&#x2010;rays to identify bone fractures is just one such application, yet this can also occur with smaller fissures. This highlights the need to quickly diagnose a patient with a fracture and start treatment. Because of this, it is crucial to design efficient and intelligent systems. Still it is a regular emergency when a fracture is not properly diagnosed. Patients&#x2019; access to care and treatment is limited and often delayed as a result. The potential use of deep learning (DL) and other forms of artificial intelligence to aid radiologists in the identification of bone fractures is now receiving a great deal of attention. The analysis of medical images is a promising area for the use of DL. In this chapter, we investigate how deep supervised learning can be used to analyze X&#x2010;ray pictures and categorize the many types of bone fractures.</p>},
  keywords={Bones;Deep learning;Artificial intelligence;X-rays;Radiology;Medical diagnostic imaging;Supervised learning;Labeling;Computed tomography;Magnetic resonance imaging},
  doi={10.1002/9781394230914.ch3},
  ISSN={},
  publisher={Wiley},
  isbn={9781394230907},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951654},}@INPROCEEDINGS{10622943,
  author={Rustam, Furqan and Ranaweera, Pasika and Jurcut, Anca Delia},
  booktitle={ICC 2024 - IEEE International Conference on Communications}, 
  title={AI on the Defensive and Offensive: Securing Multi-Environment Networks from AI Agents}, 
  year={2024},
  volume={},
  number={},
  pages={4287-4292},
  abstract={The role of artificial intelligence (AI) in cybersecu-rity has grown due to increasing threats from malicious actors. It aids in threat detection, behavioral analysis, malware detection, phishing identification, and enhancing security measures. However, AI can also be weaponized for cyberattacks, as malicious actors use AI-based tools for sophisticated and adaptable assaults on security systems. This study contributes to cybersecurity by defending against AI-based threats. Machine learning models were trained on diverse, complex datasets to counter sophisticated AI-based attacks in multi-environments (M-En). We have utilized auto-encoders to generate our M-En dataset by combining two benchmark datasets: UNSW-NB15 and IoTID-20, that represent traditional IP-based and IoT-based traffic, respectively. Three generative models (CTGAN, CopulaGAN, and TVAE) produced AI-based traffic, leading to a dataset comprising traditional and AI-generated traffic. Machine learning and deep learning models were deployed on this M-En dataset. The ensemble Extra Trees classifier achieved the highest accuracy score of 0.983 for binary classification and 0.968 for multiclass problems. Our proposed approach demonstrates its effectiveness in countering AI-based traffic as well as traditional network traffic within the M-En networks.},
  keywords={Training;Accuracy;Weapons;Phishing;Diversity reception;Telecommunication traffic;Threat assessment;Cyber Security;Machine Learning;AI-based Attacks;Complex Networks;Generative Models},
  doi={10.1109/ICC51166.2024.10622943},
  ISSN={1938-1883},
  month={June},}@INPROCEEDINGS{10813439,
  author={Truong, Phi-Ho and Nguyen, Tien-Dung and Truong, Xuan-Hung and Nguyen, Nhat-Hai and Pham, Duy-Trung},
  booktitle={2024 1st International Conference On Cryptography And Information Security (VCRIS)}, 
  title={Employing a CNN Detector to Identify AI-Generated Images and Against Attacks on AI Systems}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The advancement of artificial intelligence (AI) technology has made Generative AI a significant concern for many. This technology generates fake images through highly complex algorithms. It involves a detailed analysis of the original image, extracting features like color, context, and feature, which are then used to build a neural network. This network is combined with computer graphics to produce an image that resembles the original. Attackers often use these fake images to attack AI systems, making the detection and prevention of such images a pressing issue. In this study, we propose a method to detect fake images using a detector built on CNN models. Our experimental results demonstrate that the proposed detectors achieve over 95% average accuracy on the test datasets, indicating their potential applicability to real-world problems.},
  keywords={Training;Accuracy;Image color analysis;Prevention and mitigation;Transfer learning;Neural networks;Information security;Detectors;Pressing;Feature extraction;Generative AI;Detect fake images;Convolutional Neural Networks;Pre-Training model},
  doi={10.1109/VCRIS63677.2024.10813439},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11042380,
  author={M, Nithish and P, Thiyagarajan and S, Rajalakshmi},
  booktitle={2025 2nd International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)}, 
  title={Detecting Deception: A Comparative Study of CNN Approaches for Deepfake Image Detection}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={The exponential growth of Artificial Intelligence (AI) has given rise to deepfake images, which present a major impact on digital safety, mistaken identity, and the spread of fake information. Due to their highly realistic nature, detecting deepfakes has become a major challenge, highlighting the critical need for robust detection systems. This research investigates the performance of nine advanced Convolutional Neural Network (CNN) architectures, namely: Custom CNN, ResNet50, VGG16, InceptionV3, DenseNet, MobileNetV2, XceptionNet, MesoNet, and InceptionResNetV2 which were used to detect deepfakes. To evaluate the effectiveness of the above CNN architectures, two large-scale image datasets were used: the Real & Deepfake Dataset and the 140K Real and Fake Faces Dataset. These datasets include more than 2,00,000 real and fake images. The training was done using a GPU to increase the speed and accuracy of the models. Among all the models, the Custom CNN provided the best results, reaching 99% accuracy on the Real & Deepfake Dataset and 98% on the 140K dataset. ResNet50, DenseNet, and InceptionV3 also performed very well, each scoring above 90% accuracy in both datasets. Other models like VGG16, MobileNetV2, XceptionNet, and InceptionResNetV2 also showed strong results, proving they are useful for deepfake detection. This analysis study aims to identify the most efficient and accurate CNN architecture for image-based deepfake detection, ensuring digital content safety, and identifying the fastest model for real-time deepfake detection in future applications.},
  keywords={Training;Deepfakes;Accuracy;Graphics processing units;Real-time systems;Knowledge management;Safety;Convolutional neural networks;Artificial intelligence;Residual neural networks;CNN Models;Deep fake;Images;Deep Learning,Comparison},
  doi={10.1109/RMKMATE64874.2025.11042380},
  ISSN={},
  month={May},}@INPROCEEDINGS{10800948,
  author={Sriman, B and Annie Silviya, S H and Mouleesh, Y and Vinod, S and Nishanthini, S and Nikitha, Polimera},
  booktitle={2024 8th International Conference on Electronics, Communication and Aerospace Technology (ICECA)}, 
  title={Intelligent Document Interaction with Advanced Vector Embeddings and FAISS-CPU Indexing}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Our research project aims to introduce an artificial intelligence (AI) conversational model that can be used to efficiently communicate with multiple PDF documents. Our solution uses natural language processing algorithms to enable users to have lively conversations with PDFs that have been uploaded. We have built a comprehensive platform that can interpret user queries and provide pertinent responses based on the content of uploaded documents by integrating Python with Streamlit for interface development, FAISSCPU for storage and similarity search, PyPDF2 for text extraction, ChromaDB, Langchain, and Google Gemini Generative AI for enhanced functionality. Our goals include developing a UI that is easy to use, processing documents correctly, and having strong conversational capabilities.},
  keywords={Navigation;Oral communication;Portable document format;Information retrieval;Vectors;Natural language processing;Libraries;Internet;Reliability;Indexing;Google Gemini Generative AI;Conversational Model;Natural Language Processing},
  doi={10.1109/ICECA63461.2024.10800948},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10405735,
  author={Di Domenico, Nicolò and Borghi, Guido and Franco, Annalisa and Ferrara, Matteo and Maltoni, Davide},
  booktitle={2023 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)}, 
  title={A Framework to Improve the Comparability and Reproducibility of Morphing Attack Detectors}, 
  year={2023},
  volume={},
  number={},
  pages={525-530},
  abstract={Morphing Attack, i.e. the deception of Face Recognition Systems (FRS) through a face morphing process between the identity of two subjects with criminal intent, has recently emerged as a serious security threat. Due to its significance, recently several Morphing Attack Detection (MAD) systems, i.e. methods based on Artificial Intelligence able to automatically detect the presence of morphing, have been proposed in the literature. Unfortunately, developing, comparing, and reproducing these MAD algorithms is challenging, particularly for deep learning-based solutions, since they are usually evaluated on private datasets and the source code is not publicly released. Therefore, we observe the need for an open-source framework that aims to simplify the development of new MAD systems, in combination with their evaluation. Thus, in this paper, after a discussion about the current limits of existing studies on the MAD task, we examine the desired properties and features of this framework, with a particular focus on its modularity, usability, and effectiveness.},
  keywords={Face recognition;Source coding;Reproducibility of results;Security;Artificial intelligence;Usability;Task analysis;Morphing Attack;Morphing Attack Detection (MAD);Single-image MAD (S-MAD);Differential MAD (D-MAD);Automated Border Control (ABC);Face Recognition Systems (FRS)},
  doi={10.1109/MetroXRAINE58569.2023.10405735},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10857545,
  author={Yadagiri, Annepaka and Pakray, Partha},
  booktitle={2025 19th International Conference on Ubiquitous Information Management and Communication (IMCOM)}, 
  title={Deep Learning Strategies for Identifying Machine-Generated Text}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Generative AIs like LLMs are now accessible to the general public. For example, students can utilize these tools to create essays or complete theses. However, how is a teacher supposed to determine if a text was composed by the student or an AI? Using deep learning techniques, we investigate novel and classic approaches for detecting text created by artificial intelligence. We also study the more complex instance when the AI is asked to write the text in a way that a human would not recognize as AI-generated, as we discovered that categorization is more challenging in this scenario. For our studies, we used llm-detect-ai-generated text from the Kaggle competition dataset, which included texts written by students and texts produced using different LLMs. Our top systems achieve an accuracy of 0.98% and F1 scores of more than 0.98% in classifying simple and complex texts produced by humans and AI-Genereted. The systems combine features such as TF-IDF vectorization, word2Vec, and word embedding properties. Our findings demonstrate that these additional characteristics significantly enhance the performance of several classifiers. Compared to deep learning models, our best-performing model for detecting AI-generated text outperforms even the fine-tuned ROBERTA-Open-AI classifier, achieving an accuracy of 0.98%. This underscores the efficacy of our proposed approach in distinguishing between human and AI-generated content.},
  keywords={Deep learning;Training;Adaptation models;Accuracy;Text recognition;Text categorization;Text detection;Detectors;Transformers;Information management;Large Language Models;Natural Language Processing;Neural Networks;Generative AI},
  doi={10.1109/IMCOM64595.2025.10857545},
  ISSN={},
  month={Jan},}@INBOOK{10950904,
  author={Shah, Priten},
  booktitle={AI and the Future of Education: Teaching in the Age of Artificial Intelligence}, 
  title={Using AI in Curriculum Development}, 
  year={2023},
  volume={},
  number={},
  pages={90-135},
  abstract={Summary <p>Generative AI tools have the potential to dramatically reduce the amount of time teachers spend creating and revising materials for their classrooms. The content generated by AI can be customized quickly, adapted to current events, personalized based on classroom needs and preferences, and match formats and guidelines from administrators. AI tools can also be used to help plan out a curriculum or unit while helping us think about time allocation, standards, and the unique needs that their classroom might have. Thinking about AI&#x2010;partnered lesson and curriculum planning as an iterative process will allow us to make the most of it by offloading as much work as possible to the AI. Everything from presentations and worksheets to posters and custom classroom resources can be enhanced with AI&#x2010;generated art. ChatGPT came up with a fun, interactive, problem&#x2010;based assessment to replace the essay prompt.</p>},
  keywords={Artificial intelligence;Standards;Education;Chatbots;Generative AI;Curriculum development;Videos;Refining;Planning;Particle swarm optimization},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394219261},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10950904},}@INPROCEEDINGS{11022294,
  author={Xie, Xin and Guan, Enguang and Wang, Yao},
  booktitle={2024 8th Asian Conference on Artificial Intelligence Technology (ACAIT)}, 
  title={Identification of Benign and Malignant Using GA and ResNet-50 for Pulmonary Nodules}, 
  year={2024},
  volume={},
  number={},
  pages={954-963},
  abstract={Artificial intelligence (AI) algorithms have been proven to be an effective and feasible technique for early diagnosing of medical images, such as lung or pulmonary, thyroid and other nodules diseases. Although numerous studies have been presented to improve diagnostic performance, there is still no absolutely reliable method for screening and identifying benign and malignant nodules, which significantly affects the predictions and universalities. In this study, a pulmonary nodule image identification framework which is based on deep-learning networks of ResNet-50 and genetic algorithm (GA) is developed, i.e. GA+ResNet-50, aiming at the classification problem of Computed Tomography (CT) images from LIDC-IDRI public data set. Six different algorithms have been used for comparative analysis in terms of the accuracy, the sensitivity, the precision and the F1 score. The results show that GA+ResNet-50 has a good performance on the identification of benign and malignant lung nodules, and the diagnostic capability is significantly improved. In addition, the method also performs well on three other datasets, further validating its broad applicability and reliability. This work can provide effective suggestions to doctors’ diagnosis for pulmonary nodule diseases.},
  keywords={Accuracy;Sensitivity;Lungs;Computed tomography;Transformers;Classification algorithms;Reliability;Artificial intelligence;Cancer;Genetic algorithms;lung or pulmonary nodule;benign and malignant;diagnostic imaging;deep learning;GA+ResNet-50},
  doi={10.1109/ACAIT63902.2024.11022294},
  ISSN={},
  month={Nov},}@ARTICLE{10765144,
  author={Liao, Wenxing and Liu, Zhuxian and Shen, Minghuang and Chen, Riqing and Liu, Xiaolong},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={APR-Net: Defense Against Adversarial Examples Based on Universal Adversarial Perturbation Removal Network}, 
  year={2025},
  volume={6},
  number={4},
  pages={945-954},
  abstract={Adversarial attack, a bleeding-edge technique that attempts to fool deep learning classification model by generating adversarial examples with imperceptible perturbations, is becoming a growing threat in artificial intelligence fields. Preprocessing models that remove perturbations are an effective approach for enhancing the robustness of classification models. However, most existing methods overlook a critical issue: although powerful preprocessing operations can remove adversarial perturbations, they may also weaken the representation of key features in the image, leading to decreased defense performance. To address this, we propose a novel universal defense model, APR-Net, which aims to remove adversarial perturbations while effectively preserving high-quality images. The key innovation of APR-Net lies in its dual-module design, which consists of a denoising module and an image restoration module. This design not only effectively eliminates imperceptible adversarial perturbations but also ensures the restoration of high-quality images. Unlike existing methods, APR-Net does not require modifications to the classifier architecture or specialized adversarial training, making it highly versatile. Extensive experiments on the ImageNet dataset demonstrate that APR-Net provides strong defense against various adversarial attack algorithms, significantly improves image quality, and outperforms other state-of-the-art defense methods in terms of overall performance.},
  keywords={Perturbation methods;Training;Robustness;Iterative methods;Computational modeling;Artificial intelligence;Image restoration;Deep learning;Technological innovation;Optimization;Adversarial defense;adversarial examples;deep neural networks (DNNs);image denoising;image restoration.},
  doi={10.1109/TAI.2024.3504478},
  ISSN={2691-4581},
  month={April},}@INPROCEEDINGS{9054438,
  author={Chung, Yu-An and Glass, James},
  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Generative Pre-Training for Speech with Autoregressive Predictive Coding}, 
  year={2020},
  volume={},
  number={},
  pages={3497-3501},
  abstract={Learning meaningful and general representations from unannotated speech that are applicable to a wide range of tasks remains challenging. In this paper we propose to use autoregressive predictive coding (APC), a recently proposed self-supervised objective, as a generative pre-training approach for learning meaningful, non-specific, and transferable speech representations. We pre-train APC on large-scale unlabeled data and conduct transfer learning experiments on three speech applications that require different information about speech characteristics to perform well: speech recognition, speech translation, and speaker identification. Extensive experiments show that APC not only outperforms surface features (e.g., log Mel spectrograms) and other popular representation learning methods on all three tasks, but is also effective at reducing downstream labeled data size and model parameters. We also investigate the use of Transformers for modeling APC and find it superior to RNNs.},
  keywords={Training;Speech coding;Transfer learning;Speech recognition;Predictive coding;Data models;Task analysis;representation learning;self-supervised learning;pre-training;transfer learning;autoregressive modeling},
  doi={10.1109/ICASSP40776.2020.9054438},
  ISSN={2379-190X},
  month={May},}@INPROCEEDINGS{9274911,
  author={Qiao, Jiahuan and Fang, Jianwu and Yan, Dingxin and Xue, Jianru},
  booktitle={2020 3rd International Conference on Unmanned Systems (ICUS)}, 
  title={Driving Accident Detection by Self-Supervised Adversarial Appearance-Motion Prediction in First-Person Videos}, 
  year={2020},
  volume={},
  number={},
  pages={1083-1088},
  abstract={Driving accident is the event that occur unexpectedly and should be detected effectively for autonomous driving systems. In this paper, we propose a method based on adversarial appearance-motion prediction for driving accident detection in dashcam videos. The novelty of this method is to consider the predictability of the frame-level and object-level motion and appearance from the current to the future. Through a self-supervised adversarial learning between the real observation in next frame and the predicted motion and appearance, the objects that may occur accident are detected. In order to evaluate the accuracy of the detection results of our method, we evaluate the performance on A3D dataset, and the effectiveness of the method is validated.},
  keywords={Accidents;Videos;Optical network units;Generative adversarial networks;Gallium nitride;Feature extraction;Control engineering;Driving accident detection;motion and appearance consistency;adversarial learning},
  doi={10.1109/ICUS50048.2020.9274911},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10497435,
  author={Song, Wenbo and Jiang, Yan and Fang, Yin and Cao, Xinyu and Wu, Peiyan and Xing, Hanshuo and Wu, Xinglong},
  booktitle={2023 International Conference on Artificial Intelligence Innovation (ICAII)}, 
  title={Medical Image Generation based on Latent Diffusion Models}, 
  year={2023},
  volume={},
  number={},
  pages={89-93},
  abstract={The application of deep learning networks in med-ical image analysis has become increasingly mature. However, the availability of a large amount of medical image data for training deep learning networks is hindered by various factors such as workload of doctors, different devices, and ethical privacy policies. These factors can limit the full potential of deep learning network models. In recent years, generative models, particularly diffusion models, have made significant progress in synthesizing realistic images in various domains. Nevertheless, there is currently limited research on the application of Latent Diffusion Models (LDMs) in medical image generation, especially when generating different types of medical images using a unified process. In our research, we explore the use of LDMs to generate synthetic images from various medical image datasets. We train the LDMs on the BreastMRI, Hand, HeadCT, and CXR images extracted from the MedNIST dataset. By employing a consistent LDMs architecture, we aim to generate images from different medical device sources. Additionally, we assess the similarity between the generated images and the real images to evaluate the performance of our approach.},
  keywords={Deep learning;Training;Performance evaluation;Image segmentation;Technological innovation;Privacy;Image synthesis;Medical Image;Latent Diffusion Models;Image Generation},
  doi={10.1109/ICAII59460.2023.10497435},
  ISSN={},
  month={Sep.},}@ARTICLE{10378949,
  author={Chen, Liuyin and Lu, Di and Zhai, Jianxue and Cai, Kaican and Wang, Long and Zhang, Zijun},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Vision Intelligence Assisted Lung Function Estimation Based on Transformer Encoder–Decoder Network With Invertible Modeling}, 
  year={2024},
  volume={5},
  number={7},
  pages={3336-3349},
  abstract={Lung function evaluation is important to many medical applications, but conducting pulmonary function tests is constrained by different conditions. This article presents a pioneer study of an integrated invertible deep learning method for lung function estimation via using computed tomography (CT) images. First, the projection method is proposed to flatten the three-dimensional (3-D) image onto a two-dimensional (2-D) plane, with preserving location information in 3-D. Next, the MBConv transformer-based encoder–decoder structure is developed to extract latent features. Finally, we develop an invertible normalizing flow (NF) model to infer lung function based on the extracted features and design two loss functions for two directions. The method enables both estimating the lung function based on CT images and metadata as well as generating the corresponding simulated CT image according to the lung function. Computational studies show that the proposed regression model outperforms all state-of-the-art image regression models. A comprehensive comparative analysis also demonstrates the effectiveness of using generated images and confirms the superiority of the proposed method. To the best of our knowledge, this work is the first of its kind in combining encoder–decoder network with NFs to ensure the effectiveness of the fully invertible framework, especially in lung CT image analysis.},
  keywords={Lung;Computed tomography;Computational modeling;Estimation;Metadata;Three-dimensional displays;Transformers;Generative model;image regression;lung function;normalizing flows (NFs);ViT},
  doi={10.1109/TAI.2023.3348428},
  ISSN={2691-4581},
  month={July},}@INPROCEEDINGS{10003937,
  author={Honda, Naoya and Kamiya, Tohru and Kido, Shoji},
  booktitle={2022 22nd International Conference on Control, Automation and Systems (ICCAS)}, 
  title={Identification of abnormal tissue from CT images using improved ResNet34}, 
  year={2022},
  volume={},
  number={},
  pages={532-536},
  abstract={In recent years, CT examinations have been widely used as a screening method to detect lung cancer. However, reading enormous CT images become a heavy burden to the physician. To avoid this problem, computer-aided diagnosis systems have been introduced on CT screening. In general, physicians consider patient information in addition to image information when they make a diagnosis, new efforts are being made to improve the accuracy of diagnosis by mimicking this information with a machine. In this paper, we propose a method for identifying pulmonary nodules by adding medical record information to images to improve the accuracy of diagnosis. We classify nodules from unknown data by assigning branching information of vascular opacities, straight vascular shadows, and nodular shadows as labeled image, which are a cause of misrecognition based on image features in machine learning. In the experiment, the classification accuracy of the nodule class was improved by adding clinical information to 644 images including 161 nodal images.},
  keywords={Computed tomography;Lung cancer;Lung;Machine learning;Generative adversarial networks;Control systems;Computer aided diagnosis;CT;computer-aided diagnosis;clinical information;multimodal;deep learning},
  doi={10.23919/ICCAS55662.2022.10003937},
  ISSN={2642-3901},
  month={Nov},}
