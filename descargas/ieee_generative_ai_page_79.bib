@INPROCEEDINGS{10435781,
  author={Yamsani, Nagendar and S, Pradeep Kumar and AL-Attabi, Kassem and Alassedi, Zainab and Hussein, Abbas Hameed Abdul},
  booktitle={2023 3rd International Conference on Mobile Networks and Wireless Communications (ICMNWC)}, 
  title={Multi-Path Attention Block-Loss Function for Non-Uniform Blind Image Deblurring}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Blind image deblurring is a significant and difficult task in the computer vision field. It is mainly focused on decreasing the blur caused by motion or camera shake. However, image deblurring has made great progress, but there is a need for enhancement in the visual effect and image information to enhance the overall image quality. In this research, the Multi-Path Attention Block-Loss Function (MPAB-LF) is proposed for non-uniform blind image deblurring to enhance image quality. The MPAB approach is employed to provide the foundation for blind image deblurring. To combine numerous MPABs instead of employing associated feature aggregation, the Improved One-Shot Aggregation (IOSA) is utilized. Finally, the loss functions are employed to enhance the generator and discriminator of the framework. Existing approaches like Generative Adversarial Network (GAN), MPAB, Two Convolutional Neural Networks (CNN), and Dense Dilated Block and Improved Attention Module (DDBIAM) are used to compare with the proposed MPAB-FL approach. The proposed MPAB-FL achieves a better Peak-to-Signal Noise Ratio (PSNR) of 35.65 dB and Structural Similarity Index (SSIM) of 0.9957 compared to the existing approaches like GNN, MPAB, Two-stage CNN, and DDBIAM respectively.},
  keywords={Image quality;Wireless communication;Generative adversarial networks;Visual effects;Generators;Image restoration;Convolutional neural networks;Blind image deblurring;Generative Adversarial Network;Improved One-Shot Aggregation;Loss Function;Multi-Path Attention Network},
  doi={10.1109/ICMNWC60182.2023.10435781},
  ISSN={},
  month={Dec},}@ARTICLE{11151183,
  author={Li, Tong and Ma, Zhuangzhuang and Shao, Jinliang and Zhao, Yuan and Zhang, Xilin and Cheng, Yuhua},
  journal={Chinese Journal of Electronics}, 
  title={Path Planning for Unmanned Aerial Vehicle Swarm Based on Electromagnetic Environment Sensing}, 
  year={2025},
  volume={34},
  number={4},
  pages={1156-1171},
  abstract={Unmanned aerial vehicle (UAV) swarm is widely used in tasks such as post-disaster rescue and battle-field monitoring. These tasks are often executed in unknown or complex environments, necessitating the programming of safe and efficient paths for UAV swarm to ensure the completion of missions. To address the path planning problem for UAV swarm in unknown electromagnetic environment, we propose a multi-agent deep deterministic policy gradient algorithm based on environment sensing where a safe learning mechanism is designed by using control barrier function. Additionally, a weakly supervised learning-based generative adversarial network algorithm is employed to construct an electromagnetic environment sensing module. By using the algrothim we propose, UAV swarm can avoid zones with strong electromagnetic interference and guarantee inter-UAV collisions avoidance during task execution. Compared to reinforcement learning algorithm without environment sensing module and safe learning mechanism, the algorithm we propose reduces convergence time by approximately 2.5 times. Simultaneously, it prevents individual trial-and-error learning process from violating safety constraints, ensuring the safety of UAV swarm in unknown environment. Finally, we verified the effectiveness of our algorithm on the experimental platform which is constructed by using universal software radio peripherals and quadcopter UAVs.},
  keywords={Software algorithms;Autonomous aerial vehicles;Generative adversarial networks;Approximation algorithms;Path planning;Sensors;Electromagnetics;Jamming;Protection;Quadrotors;Unmanned aerial vehicle swarm;Electromagnetic environment sensing;Path planning;Deep reinforcement learning;Generative adversarial network (GAN);Weakly supervised learning},
  doi={10.23919/cje.2024.00.088},
  ISSN={2075-5597},
  month={July},}@INPROCEEDINGS{10829128,
  author={Gejji, Sujay and Supreeth, B. R. and Khan, Pathan Firoze and Venkat, S. and Pradeepa, K and Kaliappan, S.},
  booktitle={2024 7th International Conference on Contemporary Computing and Informatics (IC3I)}, 
  title={Deep Learning Approaches for Solving Challenges in Computer Vision Applications and Exploring Evolving Patterns}, 
  year={2024},
  volume={7},
  number={},
  pages={1008-1013},
  abstract={Deep learning has brought substantial advancements to computer vision in recent years by providing answers to challenging visual interpretation problems. It investigates several DL methodologies, such as self-supervised learning strategies, hybrid CNN-RNN models, enhanced CNNs, generative adversarial networks (GANs), and vision transformers (ViTs). Novel CNN architectures are designed, GANs are used for image synthesis, hybrid models are used to integrate spatial and temporal information, self-attention is used in ViTs, and self-supervised learning is used for feature extraction. The results of the study show significant improvements: the accuracy of Enhanced CNNs was $81.6 \%$, the accuracy of GANs was $14.8 \%$, the accuracy of Hybrid CNN-RNN models was $86.2 \%$, the accuracy of ViTs was $79.2 \%$, and the accuracy of transfer for self-supervised learning techniques was $76.8 \%$. These findings demonstrate the improved effectiveness and performance of the suggested techniques, highlighting their potential to resolve challenging problems in feature extraction, video analysis, object recognition, picture enhancement, and image classification. It concludes that advances in computer vision will be facilitated by the ongoing development of DL methods. These advancements will lead to more precise and adaptable applications in a range of fields, including autonomous driving, medical imaging, surveillance, and augmented reality.},
  keywords={Computer vision;Visualization;Accuracy;Computational modeling;Surveillance;Self-supervised learning;Transformers;Generative adversarial networks;Object recognition;Image classification;Generative Adversarial Networks;Long Short-Term Memory;Vision Transformers;Momentum Contrast;Swapping Assignments},
  doi={10.1109/IC3I61595.2024.10829128},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10865865,
  author={Li, Baofeng and Xu, Bin and Hao, Yu and Qin, Yu and Xu, Meng and Gao, Xin},
  booktitle={2024 5th International Conference on Smart Grid and Energy Engineering (SGEE)}, 
  title={Smart Meter Fault Classification Method with Overlapping Samples Weight Optimization and Dual-Model Decision Under Imbalanced Datasets}, 
  year={2024},
  volume={},
  number={},
  pages={44-49},
  abstract={Accurate classification of smart meter faults helps reduce maintenance costs and improve grid stability and safety. Existing methods in the field of imbalanced classification often fail to fully utilize the differences between overlapping and safe zones, thus impacting classification performance. The paper proposes a dual-model decision classification method, consisting of a multi-label confidence comparisons model that focuses on overlapping regions and a GAN-based data balancing model. (OMLCC-GAN). It designs a weight calculation strategy to describe the degree to which samples approach the data overlapping area. Based on constructing sample-neighbors pairs, it adjusts the sampling frequency of neighboring samples to deeply explore adequate sample neighborhood relationship information in the overlapping area for inferring the labels of test samples. Simultaneously, after balancing the dataset using a generative adversarial network, a neural network classifier is employed to predict sample categories, focusing on sample features and typical samples in the safe zone. Finally, the predicted sample labels from the two methods are integrated proportionally, significantly enhancing model robustness. Experimental results on 11 public datasets and the smart meter fault dataset show that the proposed method outperforms typical methods in terms of F-measure and G-mean metrics.},
  keywords={Measurement;Adaptation models;Accuracy;Neural networks;Predictive models;Generative adversarial networks;Smart meters;Robustness;Data models;Stability analysis;Imbalanced Classification;Class Overlaps;Contrastive Learning;Generative Adversarial Network;Dual-Model Decision},
  doi={10.1109/SGEE64306.2024.10865865},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10915118,
  author={Raavi, Hemalatha and Korukonda, Keerthi Sujana},
  booktitle={2025 3rd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)}, 
  title={Predictive Modeling of Dysmenorrhea Onset and Severity in Adolescent Girls}, 
  year={2025},
  volume={},
  number={},
  pages={1697-1704},
  abstract={Dysmenorrhea, commonly known as period pain, significantly affects the quality of life for adolescent girls and post-marriage women, yet there are limited tools available for accurately predicting its onset and severity. The issue addressed by this research is the lack of effective prediction methods for dysmenorrhea. The outcome of the study is the development of a machine learning-based predictive model that utilizes predictive analytics and Generative Adversarial Networks (GANs) for period pain prediction. The model was trained using neural networks and enhanced with data augmentation to improve dataset diversity and robustness. By analyzing comprehensive data that includes physiological, psychological, and lifestyle factors, the model achieved superior accuracy in predicting the onset and severity of dysmenorrhea, compared to traditional methods. This research demonstrates the potential of machine learning to offer personalized healthcare interventions and early detection for dysmenorrhea. It also highlights the challenges faced by post-marriage women with dysmenorrhea, advocating for targeted healthcare solutions across life stages. The study showcases the power of advanced predictive analytics to transform the management of menstrual health and improve adolescent health outcomes.},
  keywords={Analytical models;Pain;Medical services;Transforms;Predictive models;Generative adversarial networks;Data augmentation;Data models;Robustness;Predictive analytics;Adolescent Health;Data Augmentation;Dysmenorrhea;Generative Adversarial Networks;Period Pain Prediction;Predictive Analytics},
  doi={10.1109/IDCIOT64235.2025.10915118},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10431294,
  author={S, Gowri Ganesh N. and D, Venkata Vara Prasad},
  booktitle={2023 4th International Conference on Communication, Computing and Industry 6.0 (C216)}, 
  title={Generating Creative Classical Music by Learning and Combining Existing Styles}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={The existing music creation system(s) only prioritise accuracy, that is, producing a sound that closely resembles actual music. Their primary concern is a criterion of legitimacy; creativity and the calibre of the music produced are not given much thought. A system should be able to produce music of a particular calibre, style, or even combinations of the two if it can intelligently model both composers and existing composition styles. As a result, this gives an AI agent some degree of combinational inventiveness. A framework is presented wherein music can be generated by encapsulating the structural styles of diverse composers through the utilisation of a sequence model comprising a Generative Adversarial Network (GAN) and Long Short-Term Memory Recurrent Neural Network (LSTM RNN). Western classical music is our main priority, but we also plan to include other genres. We use the Python module music21 to interpret the MIDI audio files in the dataset. A stream of signals or messages is extracted from the MIDI file and processed sequentially. The generator network and the discriminator network, which help with style-training the generator, are trained with these sequences. The generator network creates musical samples according to the stylistic contributions of different composers after undergoing training to understand the structural patterns of musical notations. The Audio Fingerprinting method is employed to further validate the generated samples.},
  keywords={Training;Recurrent neural networks;Music;Fingerprint recognition;Generative adversarial networks;Generators;Telecommunication computing;Neural Network;Long short-term memory RNN;Generative Adversarial Network;audio fingerprinting;music},
  doi={10.1109/C2I659362.2023.10431294},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8944347,
  author={Wu, Hongchang and Guan, Ziyu and Zhi, Tao and Zhao, Wei and Xu, Cai and Han, Hong and Yang, Yaming},
  booktitle={2019 IEEE International Conference on Big Knowledge (ICBK)}, 
  title={Adversarial Graph Attention Network for Multi-modal Cross-Modal Retrieval}, 
  year={2019},
  volume={},
  number={},
  pages={265-272},
  abstract={Existing cross-modal retrieval methods are mainly constrained to the bimodal case. When applied to the multi-modal case, we need to train O(K^2) (K: number of modalities) separate models, which is inefficient and unable to exploit common information among multiple modalities. Though some studies focused on learning a common space of multiple modalities for retrieval, they assumed data to be i.i.d. and failed to learn the underlying semantic structure which could be important for retrieval. To tackle this issue, we propose an extensive Adversarial Graph Attention Network for Multi-modal Cross-modal Retrieval (AGAT). AGAT synthesizes a self-attention network (SAT), a graph attention network (GAT) and a multi-modal generative adversarial network (MGAN). The SAT generates high-level embeddings for data items from different modalities, with self-attention capturing feature-level correlations in each modality. The GAT then uses attention to aggregate embeddings of matched items from different modalities to build a common embedding space. The MGAN aims to "cluster" matched embeddings of different modalities in the common space by forcing them to be similar to the aggregation. Finally, we train the common space so that it captures the semantic structure by constraining within-class/between-class distances. Experiments on three datasets show the effectiveness of AGAT.},
  keywords={Semantics;Generative adversarial networks;Correlation;Aggregates;Training;Complexity theory;Gallium nitride;Cross-modal retrieval;graph attention;self attention;generative adversarial network},
  doi={10.1109/ICBK.2019.00043},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11035670,
  author={Swapna, N. S. and Muralidhar, Appalaraju and Latha, Kambala Madhu and M, Archana and V, Thirupathi and M, Bhavsingh and D, Vidya Sagar S. and Addepalli, Lavanya and Lloret, Jaime},
  booktitle={2025 4th International Conference on Distributed Computing and Electrical Circuits and Electronics (ICDCECE)}, 
  title={Unified Framework for Enhancing Federated Learning Security and Robustness using GANs, Blockchain, and Differential Privacy}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Neural Network design by a group of clients (each is a person who owns the data) where the data remains private. FL is vulnerable to adversarial attacks, data poisoning, and Byzantine faults, which are threats destroying the integrity as well as the security of the trained model. In order to deal with the challenges above, we propose a new framework, namely FL-GAN-TrustDP, for security enhanced FL using Generative Adversarial Networks (GANs) for adversarial defence, blockchain based hierarchical trust evaluation and adaptive differential privacy. Optimizing the privacy-utility tradeoff based on client trust scores, the adaptive privacy mechanism is a mechanism. GAN based adversarial filtering helps in detecting adversarial updates and thus preventing it, and the trust mechanism backed by blockchain dynamically penalizes the malicious clients. Experimental results show that FL-GAN-TrustDP significantly outperforms baseline FL models (in terms of higher model accuracy, lower adversarial success rates, lower false alarms and faster convergence speed) compared to FedAvg, FedSGD, FedDP, FedBlockchain. In particular, the adversarial success rate on adversarial data seems to decrease significantly from 60% to below 30%, and the notice is more precise, recall, and F1 score than previous work for safeguarding FL. This proposed framework promotes security, privacy, and robustness for FL applications and thus can be a secure federated learning solution in IoT and edge computing environments.},
  keywords={Adaptation models;Differential privacy;Federated learning;Filtering;Generative adversarial networks;Robustness;Data models;Blockchains;Security;Edge computing;federated learning (FL);adversarial attacks;generative adversarial networks (GANs);blockchain-based trust mechanism;differential privacy;IoT security},
  doi={10.1109/ICDCECE65353.2025.11035670},
  ISSN={},
  month={April},}@ARTICLE{10820509,
  author={Xu, Peilong and Lan, Dan and Yang, Haolin and Zhang, Shengtian and Kim, Hyeonseok and Shin, Incheol},
  journal={IEEE Access}, 
  title={Ship Formation and Route Optimization Design Based on Improved PSO and D-P Algorithm}, 
  year={2025},
  volume={13},
  number={},
  pages={15529-15546},
  abstract={The rapid development of the global shipping industry and the changes in complex marine environments have put forward higher requirements for ship formation and route optimization. The purpose of the research is to improve the efficiency and accuracy of ship formation and route planning through improved algorithms. Based on this, a ship formation model combining improved particle swarm optimization algorithm and a generative route optimization method based on improved Douglas-Peucker algorithm are proposed. The particle swarm algorithm introduces dynamic adaptive parameter adjustment and the cross mutation strategy of genetic algorithm, while the Douglas-Peucker algorithm integrates density-based noise application spatial clustering algorithm to improve model performance. The test results show that the total navigation distance of the allocation path generated by the ship formation model is 605.3 meters, the calculation time is 31.8 seconds, and all ships can be accurately allocated to the target point. When the number of iterations is 1000, the route optimization model has a route coverage rate of 95.9% on the training set, an average error of 30.5 meters, and a computation time of 45.9 seconds, achieving zero collisions. The experimental results show that the improved algorithm outperforms traditional methods in accuracy and stability of formation target allocation and route planning, especially under complex sea conditions, and can significantly reduce computation time and errors. The research provides a new technological means for optimizing ship formations and routes, which has certain application potential and practical value.},
  keywords={Marine vehicles;Optimization;Heuristic algorithms;Resource management;Accuracy;Clustering algorithms;Mathematical models;Planning;Navigation;Sea surface;PSO;D-P algorithm;ship formation;route optimization;spatial clustering algorithm},
  doi={10.1109/ACCESS.2025.3525591},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10386092,
  author={Dickerson, Madelynn and Yun, Audra Eagle},
  booktitle={2023 IEEE International Conference on Big Data (BigData)}, 
  title={Critical Community-Centeredness: Ethical Considerations for Computational Archival Studies}, 
  year={2023},
  volume={},
  number={},
  pages={2032-2035},
  abstract={In this paper, we call for computational archival studies to prioritize social justice and community-centeredness. Our initial research findings, as well as the work of community archives, provide evidence of the need to elevate and truly center the voices of those depicted (or underrepresented) in large-scale digital archives, leveraging the power of computational thinking with the transformative experience of seeing oneself represented (or representing oneself) in digital collections.},
  keywords={Humanities;Ethics;Generative AI;Resists;Learning (artificial intelligence);Big Data;community archives;digitization;digital archives},
  doi={10.1109/BigData59044.2023.10386092},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10852477,
  author={Mowzoon, Shahin and Faustini, Mishkin},
  booktitle={2024 2nd International Conference on Foundation and Large Language Models (FLLM)}, 
  title={Introducing LLMScript: A Turing Complete Prompt Based Scripting Language for LLMs with No External Coding Required}, 
  year={2024},
  volume={},
  number={},
  pages={116-124},
  abstract={LLMScript is a Turing complete scripting language that runs entirely inside the LLM with no external coding required. It can orchestrate AI calls with control structures (loops, recursion, variables, functions, and decision-making), you can create workflows that leverage AI in dynamic, and interactive ways by capturing the results of AI calls and user inputs then make decisions using iterative workflows to create custom AI solutions. It enables a systematic way of integrating Chain of Thought (CoT), Tree of Thought (ToT), and Graph of Thought (GoT) reasoning and others into your workflow; this means you can build AI-driven solutions that integrate multi-step reasoning, iterative exploration, and even decision trees that dynamically shift based on intermediate results. It empowers users to systematically interact with an LLM to create innovative AI solutions.},
  keywords={Codes;Systematics;Large language models;Decision making;Programming;Encoding;Cognition;Iterative methods;Decision trees;Artificial intelligence;LLMScript;Chain-of-Thought;Tree-of-Thought;Function-of-Though;prompts;algorithms;emergent;generative-AI;Large-Language-Models;LLM;programming languages;GPT;no code solution;workflow;development environments},
  doi={10.1109/FLLM63129.2024.10852477},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10770982,
  author={Shaw, Peter and Barr, Joseph R. and Lean, Stephen and Abu-Khzam, Faisal N.},
  booktitle={2024 Conference on AI, Science, Engineering, and Technology (AIxSET)}, 
  title={Integrating Clustering with Overlaps into Intelligent Agent Systems}, 
  year={2024},
  volume={},
  number={},
  pages={53-60},
  abstract={Advances in Large Language Modeling (LLM) have allowed LLMs to be integrated into multi-agent problem-solving systems. We present a novel approach to enhance this technique and incorporate it, and some of its practical variants, into an intelligent agent system. Our approach is based on clustering with overlaps via an algorithm for Cluster Editing with Vertex Splitting (CEVS) to create a Network Hypothesis Search Agent. As a case study, we use a practical example of a panel discussion on possible mRNA treatments for Head and Neck cancer.},
  keywords={Heuristic algorithms;Biological system modeling;Computational modeling;Clustering algorithms;Oral communication;Writing;Intelligent agents;Problem-solving;Bioinformatics;Artificial intelligence;Large Language Models;Multi-Agent;User-Agent;Cluster-Editing;Model Complexity;Graph Theory;Classification;Generative AI},
  doi={10.1109/AIxSET62544.2024.00013},
  ISSN={},
  month={Sep.},}@INBOOK{10951402,
  author={Orange, Erica},
  booktitle={AI + The New Human Frontier: Reimagining the Future of Time, Trust + Truth}, 
  title={Assessing + Achieving Trustworthiness}, 
  year={2024},
  volume={},
  number={},
  pages={154-161},
  abstract={Summary <p>Trust in technology can vary greatly depending on various factors such as personal experiences, cultural backgrounds, and individual perceptions. While some people may readily embrace and trust new technologies, others may approach them with skepticism or even fear. The trustworthiness of technology is influenced by factors such as reliability, security, privacy protection, and ethical considerations. One of the critical questions we have to ask ourselves is how &#x201c;techno&#x2010;vaccinations&#x201d; can be created to help build a defensive immune system to combat deepfakes. &#x201c;Digital watermarking&#x201d; has been touted as a solution to address and detect deepfakes. As opposed to watermarking, which has many inherent flaws, the concept of &#x201c;digital vellum&#x201d; may offer a promising answer to enhance trust. Blockchain, the ledger technology behind cryptocurrencies, could be used to prevent bias or misinformation in the data that AI models are being trained on.</p>},
  keywords={Artificial intelligence;Fake news;Standards organizations;Stakeholders;Ethics;Privacy;Reliability;Generative AI;Assembly;Vaccines},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394276998},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951402},}@INBOOK{10785772,
  author={Haque, Enamul},
  booktitle={AI Horizons: Shaping a Better Future Through Responsible Innovation and Human Collaboration}, 
  title={Appendix}, 
  year={2024},
  volume={},
  number={},
  pages={201-204},
  abstract={},
  keywords={Artificial intelligence;Malware;Ethics;Presses;Generative adversarial networks;Europe;Engineering education;Deepfakes;Virtual assistants;Standards},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9781501518485},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10785772},}@INBOOK{10952981,
  author={Orange, Erica},
  booktitle={AI + The New Human Frontier: Reimagining the Future of Time, Trust + Truth}, 
  title={The Trust Imperative}, 
  year={2024},
  volume={},
  number={},
  pages={113-117},
  abstract={Summary <p>Trust, like time, is shifting, and it is pressing us to redefine what it means in today's operating environment. Businesses today are at the intersection of two trends that will define work and life for years to come. One is the widespread decline in trust. The other is the rise of AI. Trust in technologies like AI can be double&#x2010;sided: AI can help contribute to the erosion of trust, but it also can be leveraged as a tool for building trust. While younger generations may be more aware of the potential for deepfakes and other AI&#x2010;generated content to be used for financial and political scams, many of the oldest people in our society may simply not understand the full magnitude of these emerging threat. In today's ever&#x2010;evolving trust landscape, it may feel as though we're continually circling a Penrose Staircase.</p>},
  keywords={Artificial intelligence;Generative AI;Older adults;Stairs;Reliability;Navigation;Government;Aging;Surveys;Social networking (online)},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394276998},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952981},}@INBOOK{10954409,
  author={Jay, Rabi},
  booktitle={Enterprise AI in the Cloud: A Practical Guide to Deploying End-to-End Machine Learning and ChatGPT Solutions}, 
  title={Enterprise Transformation with AI in the Cloud}, 
  year={2024},
  volume={},
  number={},
  pages={2-18},
  abstract={Summary <p>This chapter describes the power and potential of AI in business landscape. Enterprise transformation with AI in the cloud is about more than just adopting the latest technology; it's a holistic approach that redefines how the business operates, competes, and delivers value in the modern world. Companies need a systematic methodology to leverage several foundational capabilities across business and technology to implement AI and machine learning technologies across the enterprise. The chapter discusses several crucial factors to consider for enterprise AI transformation, what it implies to be an AI&#x2010;first company, and why cloud computing is a game&#x2010;changer in implementing robust, scalable, and ethical AI. Different industries are at different stages of adoption of AI depending upon the availability of the data, the complexity of the industry, and the compliance requirements. In the retail industry, AI is used for customer service chatbots, personalized marketing, inventory control, and forecasting demand.</p>},
  keywords={Artificial intelligence;Cloud computing;Companies;Machine learning;Technological innovation;Generative AI;Data models;Computational modeling;Ethics;Buildings},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394213078},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10954409},}@ARTICLE{11114753,
  author={Andrews, Cris},
  journal={Engineering & Technology}, 
  title={Distorting democracy}, 
  year={2024},
  volume={19},
  number={2},
  pages={22-25},
  abstract={In January, research was published revealing that over 100 deepfake video ads impersonating Prime Minister Rishi Sunak had reached 400,000 people on Facebook as part of a concerted smear campaign.},
  keywords={Fake news;Voting;Social networking (online);Artificial intelligence;Government;Deepfakes;Companies;Generative AI;Advertising;Economics},
  doi={10.1049/et.2024.0207},
  ISSN={1750-9637},
  month={March},}@INPROCEEDINGS{8243952,
  author={Wu, Qing and Liu, Yungang and Li, Qiang and Jin, Shaoli and Li, Fengzhong},
  booktitle={2017 Chinese Automation Congress (CAC)}, 
  title={The application of deep learning in computer vision}, 
  year={2017},
  volume={},
  number={},
  pages={6522-6527},
  abstract={As the deep learning exhibits strong advantages in the feature extraction, it has been widely used in the field of computer vision and among others, and gradually replaced traditional machine learning algorithms. This paper first reviews the main ideas of deep learning, and displays several related frequently-used algorithms for computer vision. Afterwards, the current research status of computer vision field is demonstrated in this paper, particularly the main applications of deep learning in the research field.},
  keywords={Machine learning;Computer vision;Training;Gallium nitride;Feature extraction;Algorithm design and analysis},
  doi={10.1109/CAC.2017.8243952},
  ISSN={},
  month={Oct},}@ARTICLE{8931652,
  author={Yang, Fengxiang and Zhong, Zhun and Luo, Zhiming and Lian, Sheng and Li, Shaozi},
  journal={IEEE Transactions on Multimedia}, 
  title={Leveraging Virtual and Real Person for Unsupervised Person Re-Identification}, 
  year={2020},
  volume={22},
  number={9},
  pages={2444-2453},
  abstract={Person re-identification (re-ID) is a challenging instance retrieval problem, especially when identity annotations are not available for training. Although modern deep re-ID approaches have achieved great improvement, it is still difficult to optimize the deep re-ID model and learn discriminative person representation without annotations in training data. To address this challenge, this study considers the problem of unsupervised person re-ID and introduces a novel approach to solve this problem by leveraging virtual and real data. Our approach includes two components: virtual person generation and training of the deep re-ID model. For virtual person generation, we learn a person generation model and a camera style transfer model using unlabeled real data to generate virtual persons with different poses and camera styles. The virtual data is formed as labeled training data, enabling subsequent training deep re-ID model in supervision. For training of the deep re-ID model, we divide it into three steps: 1) pre-training a coarse re-ID model by using virtual data; 2) collaborative filtering based positive pair mining from the real data; and 3) fine-tuning of the coarse re-ID model by leveraging the mined positive pairs and virtual data. The final re-ID model is achieved by iterating between step 2 and step 3 until convergence. Extensive experiments demonstrate the effectiveness of our method. Experimental results on two large-scale datasets, Market-1501 and DukeMTMC-reID, show the advantages of our method over state-of-the-art approaches in unsupervised person re-ID. Our code is now available online1.},
  keywords={Training;Cameras;Data mining;Training data;Feature extraction;Annotations;Person re-identification;generative adversarial network;collaborative filtering},
  doi={10.1109/TMM.2019.2957928},
  ISSN={1941-0077},
  month={Sep.},}@INPROCEEDINGS{9641066,
  author={Reza, Md Tanzim and Ahmed, Farzad and Sharar, Shihab and Rasel, Annajiat Alim},
  booktitle={2021 International Conference on Electronics, Communications and Information Technology (ICECIT)}, 
  title={Interpretable Retinal Disease Classification from OCT Images Using Deep Neural Network and Explainable AI}, 
  year={2021},
  volume={},
  number={},
  pages={1-4},
  abstract={Deep Learning Models (DNN) are being used extensively for medical image classification such as MRI, OCT, x-ray in recent years. The proposed model revolves around the analysis of macular Optical Coherence Tomography (OCT) images to distinguish three eye-related anomalies: Choroidal Neovascularization (CNV), Diabetic Macular Edema (DME), and accumulation of Drusen from OCT images of patients. At first, the dataset was acquired and various pre-processing steps were performed on it. Then we performed a split on the dataset into train-test-validation sets with different numbers of images in each of them. Afterward, we applied pre-trained Resnet, Inception V3, and EfficientNet models in order to classify the images. From our experiment, we achieved the best accuracy of 96.9% from ResNet. Finally, we applied Explainable AI (XAI) framework though the LIME framework in an attempt to explain the reasons for misclassifications. Alongside achieving slightly better accuracy compared to the base model, the purpose of our research is to explain the reasons behind classification errors which can be utilized in the future to develop better models.},
  keywords={Deep learning;Integrated optics;Optical coherence tomography;Magnetic resonance imaging;Optical computing;Optical fiber networks;Retina;Optical Coherence Tomography;Retina;Explainable AI;Deep Learning},
  doi={10.1109/ICECIT54077.2021.9641066},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10511970,
  author={Patil, Sneha Arun and Bhosale, Akshay and Patil, Arun},
  booktitle={2024 3rd International Conference for Innovation in Technology (INOCON)}, 
  title={Advancements in Plant Leaf Disease Detection: A Comprehensive Review of Latest Trends and Technologies}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In the face of increasing global challenges in agriculture, the accurate and timely detection of plant diseases has become imperative for ensuring food security and sustainable crop production. Different machine-learning approaches to detecting plant leaf diseases are reviewed in this paper. This study focuses on the evolution of methodologies, challenges encountered, and the current state-of-the-art in this field. Leveraging the power of machine learning for plant disease detection holds promise for early diagnosis and effective disease management. The review synthesizes research findings, highlights critical advancements, and identifies potential areas for future research to contribute to the ongoing efforts in precision agriculture and smart farming.},
  keywords={Smart agriculture;Plant diseases;Technological innovation;Reviews;Transfer learning;Superresolution;Crops;agriculture;deep learning;farming;machine learning;plant leaf},
  doi={10.1109/INOCON60754.2024.10511970},
  ISSN={},
  month={March},}@INPROCEEDINGS{10206394,
  author={Elsayd, Rowayda A. and Rashad, Metwally and El-Attar, Noha E. and Elsawy, Ahmed},
  booktitle={2023 International Telecommunications Conference (ITC-Egypt)}, 
  title={Towards Content-Based Image Retrieval for Encrypted Images over Cloud Computing: Review of Recent Trends}, 
  year={2023},
  volume={},
  number={},
  pages={678-685},
  abstract={Recent advances in imaging and computing technology generate tremendous image data daily. Searching image collections has been made easier with the introduction of some content-based image retrieval (CBIR) approaches. The research area of CBIR is currently an active topic. It is becoming increasingly important to process and store big data in a parallel and distributed manner using CBIR, especially cloud computing platforms. Cloud computing provides high amounts of computation power that can be accessed at low costs. However, cloud servers are not entirely secure, and data owners raise privacy concerns; thus, the encrypted image and encrypted feature are uploaded to the cloud server to ensure privacy. This paper presents the essential techniques of secure content-based image retrieval over cloud computing. We will compare and contrast several approaches for CBIR, especially with cloud computing.},
  keywords={Cloud computing;Data privacy;Scalability;Image retrieval;Neural networks;Market research;Encryption;Content-based Image Retrieval;Generative Adversarial Network;Convolutional Neural Network;Hadoop},
  doi={10.1109/ITC-Egypt58155.2023.10206394},
  ISSN={},
  month={July},}@INPROCEEDINGS{10218399,
  author={Sun, Yubo and Cheng, Yuanyuan and Zhu, Zhizhong and Liu, Jinrui and Guo, Zhenhui and Yu, Ningbo},
  booktitle={2023 International Conference on Advanced Robotics and Mechatronics (ICARM)}, 
  title={A Novel Signals and Features Fusion Method Based on Fisher Vector for Severity Assessment in Parkinson's Disease}, 
  year={2023},
  volume={},
  number={},
  pages={877-882},
  abstract={Parkinson's disease (PD) is a progressive neurode-generative disorder that requires accurate severity assessment to facilitate proper medication and interventions. This study proposes a novel method for PD severity assessment by fusing bilateral surface electromyography (sEMG) signals and features using Fisher vector. The sEMG signals were measured from the tibialis anterior (TA) and lateral gastrocnemius (GL) muscles in 28 PD patients. Preprocessing was performed to remove industrial frequency noise and low-frequency trend, followed by feature extraction using a customized feature generator that included time-domain and frequency-domain features. The extracted features and preprocessed sEMG signals were then vectorized using the Fisher vector and fused as input to the classifier. Our results demonstrated that considering bilateral features is more favorable than unilateral features for the PD severity assessment. Moreover, the proposed method significantly enhanced the classification accuracy, with a remarkable classification accuracy of 96.00% achieved through the combination of our proposed method with a decision tree classifier.},
  keywords={Time-frequency analysis;Mechatronics;Parkinson's disease;Data preprocessing;Muscles;Feature extraction;Market research},
  doi={10.1109/ICARM58088.2023.10218399},
  ISSN={},
  month={July},}@INBOOK{10951545,
  author={Brooks, Chuck},
  booktitle={Inside Cyber: How AI, 5G, IoT, and Quantum Computing Will Transform Privacy and Our Security}, 
  title={Index}, 
  year={2025},
  volume={},
  number={},
  pages={221-227},
  abstract={},
  keywords={},
  doi={10.1002/9781394310562.index},
  ISSN={},
  publisher={Wiley},
  isbn={9781394254965},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951545},}@INPROCEEDINGS{10569385,
  author={Katović, D. and Bronzin, T. and Horvat, M. and Prole, B. and Stipić, A. and Jelača, N. and Pavlović, I. and Pap, K.},
  booktitle={2024 47th MIPRO ICT and Electronics Convention (MIPRO)}, 
  title={The use of AI in Human Pose Estimation Applications in Kinesiology: Taxonomy of Algorithms, Models, and Evaluation Methods}, 
  year={2024},
  volume={},
  number={},
  pages={1163-1166},
  abstract={Kinesiology and its related disciplines (kinanthropometry, biomechanics, kinesiological rehabilitation, sports games) symbiotically attract new computer technologies, implementing them in the form of effective tools for analysis, diagnosis, and assessment of the state of the subject or team.The use of neural networks and computer vision integrated into pose estimation technology can be used by kinesiology as an applicable integration of knowledge from the domain of movement analysis, analysis of sports games, rehabilitation, and education into an environment of computer-transformed visual information and patterns into a form suitable for further analytical processes.The paper represents a structured review of algorithms, models, and evaluation methods for recognizing and monitoring human movement, single or multi-person, in real-time using human pose estimation.},
  keywords={Symbiosis;Visualization;Tracking;Reviews;Pose estimation;Taxonomy;Games;action recognition;single person pose estimation;multi-person pose estimation;computer vision;neural networks;motion tracking;motion estimation},
  doi={10.1109/MIPRO60963.2024.10569385},
  ISSN={2623-8764},
  month={May},}@INPROCEEDINGS{11004082,
  author={Ozalas, Matthew and Pandey, Anil Kumar and DeMuer, Tom},
  booktitle={2025 IEEE Wireless and Microwave Technology Conference (WAMICON)}, 
  title={Utilizing Information Assets in RF and Microwave Engineering Workflows}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={To meet the demands of next generation wireless communication systems, engineering teams must build flexible, reconfigurable design processes, or workflows, which are able to incorporate and leverage existing information in new ways. The challenge: over the past few decades, Electronic Design Automation (EDA) software platforms have focused on building elaborate user interfaces which obscure the lower-level mechanisms now required to build such workflows. Recently, several vendors have provided access to their EDA toolsets through Application Programming Interfaces (APIs), and in doing so have enabled new possibilities for leveraging information in the engineering design process through automation. This paper studies specific areas in high frequency simulation and measurement where automation can dramatically increase productivity and enable novel solutions to difficult problems by allowing engineering teams to use existing data which was previously inaccessible. Four examples are highlighted: netlist data mining, image-based physical modeling, simulation model extraction from measured data, and improved simulation and measurement speed using AI image completion. Theme: utilizing existing data and streamlining design through automation},
  keywords={Microwave measurement;Wireless communication;Productivity;Semiconductor device measurement;Automation;Data models;Time measurement;Microwave transistors;Data mining;Microwave imaging;Data;Automation;Python;AI;Power Amplifier},
  doi={10.1109/WAMICON64429.2025.11004082},
  ISSN={},
  month={April},}@INPROCEEDINGS{10409697,
  author={Pasarelski, Rosen and Petrov, Georgi and Pasarelska, Teodora and Angelov, Krasen},
  booktitle={2023 31st National Conference with International Participation (TELECOM)}, 
  title={Neural Network Architecture to Predict Radio Wave Attenuation in a 5G Network}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={The purpose of this study is to use neural networks to predict radio wave attenuation in 5G networks, addressing the challenges of complex wave propagation and optimizing network performance. The research developed and trained a neural network model that effectively predicts radio wave attenuation in the dynamic and complex context of 5G networks. The model combines spatial data obtained using convolutional neural networks (CNN) with sequential data analyzed using long short-term memory (LSTM) networks. This research contributes to the field of 5G network optimization by introducing an innovative approach for radio wave attenuation prediction. The key contributions of this study can be summarized as follows:–Improved prediction accuracy - The neural network model demonstrates particular accuracy in predicting the attenuation of radio waves. Its performance metrics, including MAE and RMSE, consistently outperform conventional models, making it a valuable tool for optimizing 5G network design;–Improved network performance - Accurate radio attenuation predictions allow network operators to optimize coverage and capacity, resulting in improved signal quality and reduced interference. This in turn improves the overall performance and quality of service in 5G networks.–Incorporation of spatial and sequence data - The combined use of CNN for spatial data and LSTM for sequence data enables a comprehensive analysis of the complex factors affecting radio wave attenuation in 5G networks. This new approach significantly improves the prediction accuracy.},
  keywords={5G mobile communication;Neural networks;Predictive models;Attenuation;Spatial databases;Data models;Convolutional neural networks;5G;Radio wave;Attenuation;Neural networks;CNN;LSTM;Machine Learning},
  doi={10.1109/TELECOM59629.2023.10409697},
  ISSN={2837-5246},
  month={Nov},}@INPROCEEDINGS{10850835,
  author={Krupáš, Maroš and Antonets, Liudmyla and Vaščák, Ján and Zolotová, Iveta},
  booktitle={2024 International Conference on Emerging eLearning Technologies and Applications (ICETA)}, 
  title={AI-Based Assistant: LLMs for Effective Robotics Education and Research}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Large language models (LLMs) offer new educational and research opportunities by enabling personalized learning, providing tutoring and assistance and enhancing accessibility. This paper examines the current application solutions of LLMs in education and their usability, benefits, and challenges. Through our use case and experimental data on Turtlebot3 education robots, we discuss the potential of different transformer-based LLMs and their limitations to improve educational and research outcomes for students working with robotic systems in laboratory conditions. We also evaluated selected models based on quantitative and qualitative metrics to choose one which was best suited for our AI-based education and research assistant use case.},
  keywords={Measurement;Technological innovation;Systematics;Education;Transformers;Data models;Usability;Robots;Tuning;Testing;AI-based education and research assistant;Large Language Models (LLM);generative pre-trained transformers;robotics education;Turtlebot3},
  doi={10.1109/ICETA63795.2024.10850835},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10986532,
  author={Kumar, Sachin and Dewan, Ayushi and Solanki, Surabhi and Dave, Janhvi D. and Patidar, Praveen Kumar and Lilhare, Shivkumar},
  booktitle={2025 3rd International Conference on Disruptive Technologies (ICDT)}, 
  title={Automated Brain Tumor Identification in MRI Scans Using State-of-the-Art Deep Learning Models}, 
  year={2025},
  volume={},
  number={},
  pages={655-659},
  abstract={A lump or development of aberrant cells in your brain that grows unhindered is called a brain tumour. Cancer or tumours may begin in the brain or spread there from other parts of the body. Early brain cancer detection is an extremely difficult task for radiologists. Brain tumours grow quickly; they often double in size in 25 days. Patients who receive inadequate treatment typically have a survival rate of no more than six months. It can quickly result in death. Because of this, an automated approach is necessary to detect brain tumours at an early stage. This idea suggests an automated technique for quickly distinguishing between a cancer and a healthy brain using the brain's magnetic resonance imaging (MRI). Convolutional Neural Networks (CNN), two deep learning principles, are used in this research. Two models-one with two convolutional layers and the other with two fully linked layers-are displayed in this research. And the second model, which has three fully, linked layers and four convolutional layers. When testing these models, satisfactory accuracy was attained; hence, radiologists can use this method in real life to promptly identify cancers and take action that could potentially save lives.},
  keywords={Deep learning;Accuracy;Magnetic resonance imaging;Predictive models;Brain modeling;Data models;Planning;Convolutional neural networks;Tumors;Testing;Deep learning;image segmentation;Magneticresonace imaging;medical treatment;Tumours},
  doi={10.1109/ICDT63985.2025.10986532},
  ISSN={},
  month={March},}@ARTICLE{10938135,
  author={Sajja, Ramteja and Sermet, Yusuf and Demir, Ibrahim},
  journal={IEEE Access}, 
  title={End-to-End Deployment of the Educational AI Hub for Personalized Learning and Engagement: A Case Study on Environmental Science Education}, 
  year={2025},
  volume={13},
  number={},
  pages={55169-55186},
  abstract={This study introduces an end-to-end framework for deploying conversational AI-enabled educational assistants, focusing on personalized support for students across diverse subject areas, including Business, Culture, Environmental Sciences, History, Politics, and Science, as outlined in our evaluation framework. The system leverages advanced conversational AI technologies to provide targeted, course-specific learning experiences by facilitating access to complex data and integrating seamlessly with Learning Management Systems (LMS) like Canvas. Key metrics—information retrieval accuracy, question-answering accuracy, and hallucination accuracy—were selected to rigorously evaluate the system’s ability to retrieve relevant contexts, generate accurate responses, and identify unanswerable questions. Additionally, the Educational AI Hub agents utilize innovative document parsing methods, such as the Nougat technique, to interpret content accurately, enabling adaptable academic support tailored to individual learning needs and extending to quantitative fields through code execution capabilities. This study also emphasizes the importance of accessibility, inclusivity, and user privacy. The results showcase the potential for enhanced engagement and improved understanding of environmental concepts and software tools, demonstrating the significant impact of conversational AI in educational settings, especially in disciplines involving complex data interactions. A case study, presented at the 12th International Congress on Environmental Modelling and Software, illustrates the Educational AI Hub’s effectiveness in enhancing student engagement and delivering personalized learning experiences in environmental sciences education.},
  keywords={Education;Artificial intelligence;Adaptive learning;Virtual assistants;Accuracy;Electronic learning;Water quality;Learning management systems;Large language models;Decision making;Artificial intelligence (AI);document parsing techniques;generative pre-training transformer (GPT);large language models (LLM);natural language processing (NLP);personalized learning},
  doi={10.1109/ACCESS.2025.3554222},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10835546,
  author={Priyadarshini, Amisha and Gago-Masague, Sergio},
  booktitle={2024 IEEE 6th International Conference on Cognitive Machine Intelligence (CogMI)}, 
  title={Fair Evaluator: An Adversarial Debiasing-based Deep Learning Framework in Student Admissions}, 
  year={2024},
  volume={},
  number={},
  pages={152-161},
  abstract={This work considers the problem of enhancing the authenticity and fairness of undergraduate student admission decision-making process by employing state-of-the-art Deep Learning (DL) models with advanced bias-mitigation techniques. Traditional admission processes often introduce biases that can disadvantage underrepresented or marginalized groups, highlighting the need for more equitable and efficient methods. Although the DL models have emerged as a promising alternative offering superior performance and higher scalability than the classical Machine Learning approaches, fairness concerns remain a significant issue.We propose an adversarial debiasing-based DL framework that integrates the Optimistic Adam (OAdam) optimizer, ensuring consistent and stable model training crucial for achieving reliable and unbiased outcomes. Our framework leverages data from applicants to the Computer Science Department at the University of California, Irvine. To ensure holistic evaluation of applicants’ profile we utilize a dataset that encompasses a wide range of features showcasing demographics, academic records, high school information, and essay responses. By prioritizing the recall score alongside the fairness metrics, our approach effectively handles the fairness-accuracy trade-off, considerably minimizing the false negatives and ensuring equitable consideration for marginalized groups in admission decisions. Through rigorous experimentation and analysis, our comprehensive study demonstrates that the proposed fairness-aware Input Convex Neural Network model using OAdam optimizer, achieves high fairness metrics while ensuring a balanced predictive performance. The proposed model improves the p-% rule scores by an average of 39.989% across sensitive attributes and achieves recall scores 0.97% higher than those of unfair baseline models.},
  keywords={Measurement;Deep learning;Training;Computer science;Scalability;Neural networks;Decision making;Predictive models;Reliability;Machine intelligence;fairness;deep learning;adversarial debiasing;undergraduate student admissions;holistic evaluation},
  doi={10.1109/CogMI62246.2024.00029},
  ISSN={},
  month={Oct},}@ARTICLE{10734402,
  author={Khan, Wasiq and Topham, Luke K. and Khayam, Umar and Ortega-Martorell, Sandra and Panter, Heather and Ansell, Darren and Al-Jumeily, Dhiya and Hussain, Abir J.},
  journal={IEEE Transactions on Biometrics, Behavior, and Identity Science}, 
  title={Person De-Identification: A Comprehensive Review of Methods, Datasets, Applications, and Ethical Aspects Along With New Dimensions}, 
  year={2025},
  volume={7},
  number={3},
  pages={293-312},
  abstract={Person de-identification has become a challenging problem that is receiving substantial attention because of the growing demand for privacy protection and related regulations. In this context, computer vision and Deep Learning (DL) algorithms offer automated solutions for Face de-identification (FDeID), commonly used to conceal personal identities in visual data. The existing survey studies addressing the FDeID topic lack comprehensive coverage of modern generative DL-based FDeID methods, limitations of data resources, proposing new applications, and potential technical and ethical research directions, which are covered for the first time in this survey. Throughout the manuscript, we offer critical analysis from various perspectives with a recurring theme of the growing impact that generative deep learning techniques are beginning to have on FDeID and related areas such as gait de-identification. In addition, we suggest 17 novel research dimensions and corresponding research questions in both technical and dataset perspectives, which will advance the research frontiers in this domain. The insights presented in this survey can benefit the research community and diverse stakeholders such as law enforcement, healthcare, industry, etc. It offers valuable insights into the performance analysis of existing methodologies, identifies research gaps, highlights application domains, and suggests precise possible avenues for future contributions.},
  keywords={Face recognition;Privacy;Reviews;Artificial intelligence;Ethics;Security;Law enforcement;Image quality;Biometrics;Gesture recognition;Biometrics;face and gesture recognition;security and privacy protection;posture},
  doi={10.1109/TBIOM.2024.3485990},
  ISSN={2637-6407},
  month={July},}@ARTICLE{11164611,
  author={Oprea, Simona-Vasilica and Bâra, Adela},
  journal={IEEE Access}, 
  title={Smart Grids, Super Smart Grids, and Microgrids: A Triple Challenge for the Future of Energy Landscape}, 
  year={2025},
  volume={13},
  number={},
  pages={162422-162435},
  abstract={This paper explores the evolving landscape of smart grids and super smart grids (SSG) through a review of recent academic publications (2019-2024). An SSG expands the traditional smart grid concept by interconnecting power grids across vast regions, facilitating the efficient transfer of renewable energy sources (RES) across borders. While the potential of SSG lies in enhancing global energy security and reducing carbon emissions, significant challenges remain, including high infrastructure costs, geopolitical risks and cybersecurity concerns. Additionally, controversies surrounding energy control and the environmental impact of large-scale infrastructure development add complexity to the SSG debate. Our paper focuses on emerging research trends and key topics related to SSG, aiming to address several concerns: 1) SSG viability given the current global energy landscape and conflicts; 2) the prevailing academic sentiment towards SSG in recent publications; 3) the most prominent research topics and emergent themes in the field. By analyzing recent publications from the past five years, we aim to shed light on the future of SSG and their interactions with local energy systems such as microgrids. The first topic revolves around data-driven approaches within network contexts, highlighting load management, distribution systems and optimization techniques. The second topic explores performance analysis and comparative studies. The third topic concentrates on control methods in distributed networks. The fourth topic centers on voltage, current and control methods in direct current (DC) systems. Our research identifies seven new research directions for SSG development.},
  keywords={Microgrids;Smart grids;Economics;Bibliometrics;Costs;Artificial intelligence;Investment;HVDC transmission;Resilience;Buildings;Academic sentiment;artificial intelligence (AI);bibliometric analysis;data analytics;energy management;generative AI;latent topics;microgrid;smart grid;super smart grid},
  doi={10.1109/ACCESS.2025.3609793},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10657766,
  author={Lavronenko, K. and Paiva, L. Lopes de and Mueller, F. and Schulz, V. and Naunheim, S.},
  booktitle={2024 IEEE Nuclear Science Symposium (NSS), Medical Imaging Conference (MIC) and Room Temperature Semiconductor Detector Conference (RTSD)}, 
  title={Towards artificial data generation for accelerated PET detector ML-based timing calibration using GANs}, 
  year={2024},
  volume={},
  number={},
  pages={1-2},
  abstract={In PET systems, TOF scanners require dedicated time skew calibration of the individual detectors, which is commonly performed by analytical approaches. In previous research, we demon-strated that performing timing calibration of detectors with a machine learning (ML) approach yields superior results. However, this method demands an extensive data acquisition due to its reliance on supervised learning. Our current research introduces initial advancements in the data gathering approach by augmenting measurement data obtained from detectors using generative artificial intelligence (GenAI). GenAI excels at learning the data distribution of complete multidimensional samples, thereby preserving correlations between features and ensuring high-quality representation of individual feature distributions. We compare our approach with an analytical baseline, where we linearly interpolate the data between different measured positions. In our study, we leverage an adapted version of the conventional Fre’ chet inception distance (FID) score, a dissimilarity measure, to evaluate the quality of the generated data. Utilizing generative adversarial network (GAN) as our GenAI model, we benefit from its well-documented efficiency in tabular data setups. The adjusted FID score demonstrates a notable enhancement, with interpolated data scoring 12.05 and generated data scoring 1.56, while the comparison of subsets of measurement data results in 0.02. The cumulative Kullback-Leibler divergence (KLD) of generated data with GAN shows slightly worse performance with a value of 7.68 in comparison to linearly interpolated data of 3.75, with measurement data scoring 0.04. However, the influence of FID score improvement significantly overcomes the decrease in the KLD performance, as we show strikingly similar correlations between the features of GAN-generated data and measurement data, in contrast to predominantly zero correlations observed in linearly interpolated data.},
  keywords={Temperature measurement;Semiconductor device measurement;Temperature distribution;Correlation;Semiconductor detectors;Supervised learning;Position measurement},
  doi={10.1109/NSS/MIC/RTSD57108.2024.10657766},
  ISSN={2577-0829},
  month={Oct},}@INPROCEEDINGS{10776734,
  author={Sara, Ghorab and Lila, Meziani and Stuart, Rubin Harvey},
  booktitle={2024 IEEE International Conference on Artificial Intelligence & Green Energy (ICAIGE)}, 
  title={Exploring Deep Neural Network Compression: An Overview}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The rapid growth of deep learning has led to intricate and resource-intensive deep neural networks widely used in computer vision tasks. However, their complexity results in high computational demands and memory usage, hindering real-time application. To address this, research focuses on model compression techniques. The paper provides an overview of recent advancements in compressing neural networks and categorizes the various methods into four main approaches: network pruning, quantization, network decomposition, and knowledge distillation. This paper aims to provide a comprehensive outline of both the advantages and limitations of each method.},
  keywords={Knowledge engineering;Green energy;Deep learning;Computer vision;Quantization (signal);Computational modeling;Artificial neural networks;Real-time systems;Complexity theory;Model compression;Deep neural network;pruning;knowledge distillation;quantization;low-rank decomposition},
  doi={10.1109/ICAIGE62696.2024.10776734},
  ISSN={},
  month={Oct},}@ARTICLE{11162639,
  author={Zhang, Ruixue and Ji, Ping and Wang, Jinxia and Zhang, Bin},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={Creative Design and Visual Effect Simulation of IoT Dynamic Interfaces by Fractal Algorithms and Artificial Intelligence}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Contemporary dynamic interface designs for consumer IoT devices are constrained by several pressing issues, including excessive homogenization, insufficient real-time adaptability, and low generative efficiency. These constraints limit the ability to meet growing user expectations for personalized interactions and high-fidelity virtual experiences. To address these issues, this study proposes Puff-Net, an intelligent generation framework that overcomes such limitations through the synergistic integration of fractal algorithms and neural style transfer. First, multi-scale artistic textures are created by exploiting fractal self-similarity, while an end-to-end aesthetic control is achieved using a dynamic optimization module that incorporates gradient constraints and fractal dimension regularization. Second, a dual-branch feature architecture is designed to separately extract device state information and user preference style features, which are adaptively recombined to enable the dynamic visual expression of a holographic avatar. Finally, the framework ensures privacy and security while meeting the stringent requirements for multi-resolution display and real-time interaction in Internet of Things scenarios. Experimental results indicate that the proposed framework effectively enables dynamic interface generation across applications such as smart home systems and wearable devices. Through the coordinated use of fractal generation and style transfer, Puff-Net surpasses the limitations of traditional template-based design approaches, offering a lightweight solution that harmonizes artistic expression with functional responsiveness. Overall, this study presents a novel theoretical and technical foundation for integrating holographic representations within the IoT ecosystem, paving the way for the next generation of intelligent and personalized user interfaces in consumer electronics.},
  keywords={Fractals;Visualization;Internet of Things;Feature extraction;Art;Training;Real-time systems;Optimization;Motion pictures;Heuristic algorithms;Fractal Algorithm;Movie Poster;Internet of Things;Style Transfer;Creative Visual Design},
  doi={10.1109/TCE.2025.3609538},
  ISSN={1558-4127},
  month={},}@INPROCEEDINGS{10074420,
  author={R, Rishi and S, Abhishek and N, Anudeep and Vivek, V},
  booktitle={2022 4th International Conference on Advances in Computing, Communication Control and Networking (ICAC3N)}, 
  title={A Survey on Advanced Text Recognition and Projection in Augmented Reality}, 
  year={2022},
  volume={},
  number={},
  pages={1085-1089},
  abstract={Augmented Reality (AR) is a technology that overlays a computer-generated image on a user’s view of the real world, thus providing a combined view. Artificial Intelligence (AI) has been used in various sectors such as gaming, manufacturing, military, and law enforcement systems. With the rapid growth of augmented reality development tools and the expansion of their functionality over the years, developers have started believing that with the application of augmented reality for AI developers can create an artificial intelligence-based app that can perform all basic tasks such as adapting to different environments. The survey focuses on studying and comparing different methods and approaches of Augmented Reality and text/image identification and mapping techniques to further combine both the approaches to achieve the end goal of obtaining AR Projections from the recognized text. The process will involve the following steps which are Handwritten text Recognition and extraction using multi model CTC. Emotion and Sentiment Analysis for text mapping and recognition using BiLSTM and SENN, Image Generation using XMC-GAN and then finally converting 2D images to 3D using COLF making it ready for the final Augmented Reality projection.},
  keywords={Visualization;Sentiment analysis;Three-dimensional displays;Text recognition;Neural networks;Data mining;Artificial intelligence;Handwritten Text Recognition (HTR);Generative Adversarial Networks (GAN);Connectionist Temporal Classification (CTC);Bidirectional Long Short-Term Memory (BiL-STM);Semantic-Emotion Neural Network (SENN);Cross(X)-Modal Contrastive Generative Adversarial Network (XMC-GAN);Chain-of-lines Feature (COLF)},
  doi={10.1109/ICAC3N56670.2022.10074420},
  ISSN={},
  month={Dec},}@ARTICLE{9103527,
  author={Wang, Zhiyong and Chen, Longxi and Wang, Lifeng and Diao, Guangqiang},
  journal={IEEE Access}, 
  title={Recognition of Audio Depression Based on Convolutional Neural Network and Generative Antagonism Network Model}, 
  year={2020},
  volume={8},
  number={},
  pages={101181-101191},
  abstract={This paper proposes an audio depression recognition method based on convolution neural network and generative antagonism network model. First of all, preprocess the data set, remove the long-term mute segments in the data set, and splice the rest into a new audio file. Then, the features of speech signal, such as Mel-scale Frequency Cepstral Coefficients (MFCCs), short-term energy and spectral entropy, are extracted based on audio difference normalization algorithm. The extracted matrix vector feature data, which represents the unique attributes of the subjects' own voice, is the data base for model training. Then, based on the combination of CNN and GAN, DR AudioNet is used to build the model of depression recognition research. With the help of DR AudioNet, the former model is optimized and the recognition classification is completed through the normalization characteristics of the two adjacent segments before and after the current audio segment. The experimental results on AViD-Corpus and DAIC-WOZ datasets show that the proposed method effectively reduces the depression recognition error compared with other existing methods, and the RMSE and MAE values obtained on the two datasets are better than the comparison algorithm by more than 5%.},
  keywords={Feature extraction;Speech recognition;Hidden Markov models;Data models;Entropy;Machine learning;Filter banks;Recognition of audio depression;generative antagonism network;convolutional neural network;Mel-scale frequency cepstral coefficients;entropy feature of spectrogram},
  doi={10.1109/ACCESS.2020.2998532},
  ISSN={2169-3536},
  month={},}@ARTICLE{10480584,
  author={Gao, Yue and Lu, Jiaxuan and Li, Siqi and Li, Yipeng and Du, Shaoyi},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Hypergraph-Based Multi-View Action Recognition Using Event Cameras}, 
  year={2024},
  volume={46},
  number={10},
  pages={6610-6622},
  abstract={Action recognition from video data forms a cornerstone with wide-ranging applications. Single-view action recognition faces limitations due to its reliance on a single viewpoint. In contrast, multi-view approaches capture complementary information from various viewpoints for improved accuracy. Recently, event cameras have emerged as innovative bio-inspired sensors, leading to advancements in event-based action recognition. However, existing works predominantly focus on single-view scenarios, leaving a gap in multi-view event data exploitation, particularly in challenges like information deficit and semantic misalignment. To bridge this gap, we introduce HyperMV, a multi-view event-based action recognition framework. HyperMV converts discrete event data into frame-like representations and extracts view-related features using a shared convolutional network. By treating segments as vertices and constructing hyperedges using rule-based and KNN-based strategies, a multi-view hypergraph neural network that captures relationships across viewpoint and temporal features is established. The vertex attention hypergraph propagation is also introduced for enhanced feature fusion. To prompt research in this area, we present the largest multi-view event-based action dataset $\mathbf{THU}^{\mathbf{MV-EACT}}\mathbf{-50}$THUMV-EACT-50, comprising 50 actions from 6 viewpoints, which surpasses existing datasets by over tenfold. Experimental results show that HyperMV significantly outperforms baselines in both cross-subject and cross-view scenarios, and also exceeds the state-of-the-arts in frame-based multi-view action recognition.},
  keywords={Cameras;Feature extraction;Neural networks;Vision sensors;Task analysis;Semantics;Robot vision systems;Multi-view action recognition;event camera;dynamic vision sensor;hypergraph neural network},
  doi={10.1109/TPAMI.2024.3382117},
  ISSN={1939-3539},
  month={Oct},}@ARTICLE{10930695,
  author={Liang, Yuzhu and Yin, Mujun and Wang, Wenhua and Liu, Qin and Wang, Liang and Zheng, Xi and Wang, Tian},
  journal={IEEE Transactions on Services Computing}, 
  title={Collaborative Edge Server Placement for Maximizing QoS With Distributed Data Cleaning}, 
  year={2025},
  volume={18},
  number={3},
  pages={1321-1335},
  abstract={The proliferation of contaminated data on Internet of Things (IoT) devices has the potential to undermine the accuracy of data-driven decision-making by altering the distribution of original data. Existing data cleaning methods primarily depend on cloud center or cloud-edge cooperation, leading to prolonged data transmission delays and reduced cleaning accuracy. In this study, we identify edge server placement as a crucial step aligned with data cleaning and view the collaborative edge server placement with distributed data cleaning (SPDC) as a holistic problem. We comprehensively quantify the complexity of our issue through the analysis of numerous scenarios. To address this problem, we introduce a novel distributed collaborative edge framework comprising two key stages: server placement and data cleaning. We propose an optimized clustering algorithm for the former, considering the data distribution on the IoT layer and the constraints of the edge layer. For the latter, we introduce a gossip-based data cleaning algorithm that fully utilizes edge collaboration to enhance data cleaning accuracy. The algorithm exhibits an approximate performance complexity of O($\ln m$lnm), where $m$m represents the number of users’ tasks. Both theoretical analysis and experimental results reveal that our algorithm an average improvement in data cleaning accuracy of 9.02% and a reduction in delay of 36.61%, surpassing the performance of state-of-the-art works in various scenarios.},
  keywords={Cleaning;Servers;Collaboration;Accuracy;Distributed databases;Approximation algorithms;Delays;Internet of Things;Clustering algorithms;Complexity theory;Server placement;data cleaning;collaborative edge computing},
  doi={10.1109/TSC.2025.3552337},
  ISSN={1939-1374},
  month={May},}@ARTICLE{10380789,
  author={Peng, Xiting and Zhao, Huaxuan and Zhang, Xiaoyu and Zhang, Chaofeng and Chen, Caijuan},
  journal={IEEE Open Journal of the Communications Society}, 
  title={MetaGON: A Lightweight Pedestrian Re-Identification Domain Generalization Model Adapted to Edge Devices}, 
  year={2024},
  volume={5},
  number={},
  pages={690-699},
  abstract={Pedestrian re-identification (Re-ID) leverages cross-camera data acquired by the Internet of Things (IoT) devices and sensors to identify, monitor, and analyze pedestrians, allowing IoT applications to provide more intelligent, secure, and tailored services. Current pedestrian Re-ID research faces many challenges, such as low image resolution, perspective changes, posture changes, light changes, and occlusions, resulting in models trained on other datasets being unable to be directly applied and showing poor generalization capabilities. In addition, IoT edge devices are often limited by processing power and memory capacity and cannot withstand complex and large deep learning models. Therefore, designing a lightweight and generalizable pedestrian Re-ID model is better suited for implementation on edge devices. Considering these issues, this study presents MetaGON, a lightweight model with cross-domain generalization capabilities, which combines the lightweight omni-scale network (OSNet) with the meta-learning method and Cycle Generative Adversarial Network (CycleGAN) to perform domain generalization. The model’s generalization is enhanced through the simulation of the two stages of domain generalization in the meta-learning pipeline, where the obtained losses from meta-training and meta-testing are utilized for model optimization. Moreover, CycleGAN is employed to enhance and introduce style variations to the source data. The proposed MetaGON model is tested on a railway station re-identification dataset, and the model is deployed to edge devices for evaluation, which verifies the effectiveness of the algorithm.},
  keywords={Pedestrians;Training;Internet of Things;Metalearning;Monitoring;Cameras;Generative adversarial networks;meta-learning;pedestrian re-identification;Internet of Things},
  doi={10.1109/OJCOMS.2024.3349597},
  ISSN={2644-125X},
  month={},}@INPROCEEDINGS{7995721,
  author={Kuefler, Alex and Morton, Jeremy and Wheeler, Tim and Kochenderfer, Mykel},
  booktitle={2017 IEEE Intelligent Vehicles Symposium (IV)}, 
  title={Imitating driver behavior with generative adversarial networks}, 
  year={2017},
  volume={},
  number={},
  pages={204-211},
  abstract={The ability to accurately predict and simulate human driving behavior is critical for the development of intelligent transportation systems. Traditional modeling methods have employed simple parametric models and behavioral cloning. This paper adopts a method for overcoming the problem of cascading errors inherent in prior approaches, resulting in realistic behavior that is robust to trajectory perturbations. We extend Generative Adversarial Imitation Learning to the training of recurrent policies, and we demonstrate that our model rivals rule-based controllers and maximum likelihood models in realistic highway simulations. Our model both reproduces emergent behavior of human drivers, such as lane change rate, while maintaining realistic control over long time horizons.},
  keywords={Vehicles;Roads;Learning (artificial intelligence);Feedforward neural networks;Optimization;Cloning},
  doi={10.1109/IVS.2017.7995721},
  ISSN={},
  month={June},}@INPROCEEDINGS{9197497,
  author={Tsai, Chieh-En and Oh, Jean},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={A Generative Approach for Socially Compliant Navigation}, 
  year={2020},
  volume={},
  number={},
  pages={2160-2166},
  abstract={Robots navigating in human crowds need to optimize their paths not only for their task performance but also for their compliance to social norms. One of the key challenges in this context is the lack of standard metrics for evaluating and optimizing a socially compliant behavior. Existing works in social navigation can be grouped according to the differences in their optimization objectives. For instance, the reinforcement learning approaches tend to optimize on the comfort aspect of the socially compliant navigation, whereas the inverse reinforcement learning approaches are designed to achieve natural behavior. In this paper, we propose NaviGAN, a generative navigation algorithm that jointly optimizes both of the comfort and naturalness aspects. Our approach is designed as an adversarial training framework that can learn to generate a navigation path that is both optimized for achieving a goal and for complying with latent social rules. A set of experiments has been carried out on multiple datasets to demonstrate the strengths of the proposed approach quantitatively. We also perform extensive experiments using a physical robot in a realworld environment to qualitatively evaluate the trained social navigation behavior. The video recordings of the robot experiments can be found in the link: https://youtu.be/61blDymjCpw.},
  keywords={Navigation;Robots;Force;Generators;Trajectory;Learning (artificial intelligence);Collision avoidance},
  doi={10.1109/ICRA40945.2020.9197497},
  ISSN={2577-087X},
  month={May},}@ARTICLE{10909641,
  author={Çiloğlu, Berk and Koç, Görkem Berkay and Shamsabadi, Afsoon Alidadi and Ozturk, Metin and Yanikomeroglu, Halim},
  journal={IEEE Communications Magazine}, 
  title={Strategic Demand-Planning in Wireless Networks: Can Generative-AI Save Spectrum and Energy?}, 
  year={2025},
  volume={63},
  number={5},
  pages={134-141},
  abstract={Generative-AI (GenAI), a novel technology capable of producing various types of outputs, including text, images, and videos, offers significant potential for wireless communications. This article introduces the concept of strategic demand-planning through demand-labeling, demand-shaping, and demand-rescheduling. Accordingly, GenAI is proposed as a powerful tool to facilitate demand-shaping in wireless networks. More specifically, GenAI is used to compress and convert the content of various types (e.g., from a higher bandwidth mode to a lower one, such as from a video to text), which subsequently enhanc-es performance of wireless networks in various usage scenarios, such as cell-switching, user association and load balancing, interference management, as well as disasters and unusual gatherings. Therefore, GenAI can serve a function in saving energy and spectrum in wireless networks. With recent advancements in AI, including sophisti-cated algorithms like large language models and the development of more powerful hardware built exclusively for AI tasks, such as AI accelerators, the concept of demand-planning, particularly demand-shaping through GenAI, becomes increasingly relevant. Furthermore, recent efforts to make GenAI accessible on devices, such as user terminals, make the implementation of this concept even more straightforward and feasible.},
  keywords={Wireless networks;Artificial intelligence;Data models;Videos;Resource management;Optimization;Transformers;Telecommunication traffic;Noise measurement;Energy consumption},
  doi={10.1109/MCOM.001.2400381},
  ISSN={1558-1896},
  month={May},}@INPROCEEDINGS{9289277,
  author={Win, Yuzana and Lwin, Htoo Pyae and Masada, Tomonari},
  booktitle={2020 International Conference on Information and Communication Technology Convergence (ICTC)}, 
  title={Myanmar Text-to-Speech System based on Tacotron (End-to-End Generative Model)}, 
  year={2020},
  volume={},
  number={},
  pages={572-577},
  abstract={The main motivation of this paper is to improve the naturalness of Myanmar text-to-speech system using an end-to-end generative model called Tacotron. We introduce the open-source implementation for Myanmar text-to-speech system with very high natural-sounding. In this paper, there are four main parts: speech corpus creation, data pre-processing, applying end-to-end generative model, and speech synthesis. Firstly, we develop a speech corpus of 8k sentences from a large set of news articles, novel books, daily usages and travel-related expressions for corpus creation. Secondly, we use a syllable segmenter and text normalizer for data pre-processing. Thirdly, we apply end-to-end generative model called Tacotron that synthesizes speech directly from the sequence of text characters. Finally, we use Griffin-Lim algorithm to convert the corresponding text into the output speech. For the subjective evaluation, we compare our synthesized speech output with the original recording speech in both intelligibility and naturalness by using mean opinion score (MOS). The experimental results show that we can obtain the synthesized speech comparable to the similar state-of-the-art synthsizers for other languages.},
  keywords={Data models;Information and communication technology;Speech synthesis;Open source software;Spectrogram;Convergence;Tacotron;RNN;LSTM;Griffin-Lim;MOS},
  doi={10.1109/ICTC49870.2020.9289277},
  ISSN={2162-1233},
  month={Oct},}@ARTICLE{9676570,
  author={Shafqat, Wafa and Byun, Yung-Cheol},
  journal={IEEE Access}, 
  title={A Hybrid GAN-Based Approach to Solve Imbalanced Data Problem in Recommendation Systems}, 
  year={2022},
  volume={10},
  number={},
  pages={11036-11047},
  abstract={With the advent of information technology, the amount of online data generation has been massive. Recommendation systems have become an effective tool in filtering information and solving the problem of information overload. Machine learning algorithms to build these recommendation systems require well-balanced data in terms of class distribution, but real-world datasets are mostly imbalanced in nature. Imbalanced data imposes a classifier to focus more on the majority class, neglecting other classes of interests and thus hindering the predictive performance of any classification model. There exist many traditional techniques for oversampling minority classes. Still, generative adversarial networks (GAN) have been showing excellent results in generating realistic synthetic tabular data that keeps the probability distribution of the original data intact. In this paper, we propose a hybrid GAN approach to solve the data imbalance problem to enhance recommendation systems’ performance. We implemented conditional Wasserstein GAN with gradient penalty to generate tabular data containing both numerical and categorical values. We also augmented auxiliary classifier loss to enforce the model to explicitly generate data belonging to the minority class. We designed the discriminator architecture with the concept of PacGAN to receive m-packed samples as input instead of a single input. This inclusion of the PacGAN architecture eliminated the mode collapse problem in our proposed model. We did a two-fold evaluation of our model. Firstly based on the quality of the generated data and secondly on how different recommendation models perform using the generated data compared to original data.},
  keywords={Generative adversarial networks;Data models;Training;Data mining;IP networks;Generators;Numerical models;GAN;imbalanced data;oversampling;synthetic data;recommendation systems;condition GAN;WGAN-GP;PacGAN},
  doi={10.1109/ACCESS.2022.3141776},
  ISSN={2169-3536},
  month={},}@ARTICLE{10171607,
  author={Strelcenia, Emilija and Prakoonwit, Simant},
  journal={IEEE Access}, 
  title={Improving Cancer Detection Classification Performance Using GANs in Breast Cancer Data}, 
  year={2023},
  volume={11},
  number={},
  pages={71594-71615},
  abstract={Breast cancer is one of the most prevalent cancers in women. In recent years, many studies have been conducted in the breast cancer domain. Previous studies have confirmed that timely and accurate breast cancer detection allows patients to undergo early treatment. Recently, Generative Adversarial Networks have been applied in the medical domain to synthetically generate image and non-image data for diagnosis. However, the development of an effective classification model in healthcare is difficult owing to the limited datasets. To address this challenge, we propose a novel K-CGAN method trained in different settings to generate synthetic data. This study applied five classification methods and feature selection to non-image Wisconsin Breast Cancer data of 357 malignant and 212 benign cases for evaluation. Moreover, we used recall, precision, accuracy, and F1 Score on the synthetic data generated by the K-CGAN model to verify the classification performance of our proposed K-CGAN. The empirical study shows that K-CGAN performed well with the highest stability compared to the other GAN variants. Hence, our findings indicate that the synthetic data generated by K-CGAN accurately represent the original data.},
  keywords={Breast cancer;Cancer;Generative adversarial networks;Deep learning;Data augmentation;Medical diagnostic imaging;Generators;Data augmentation;diagnosis;breast cancer;GANs},
  doi={10.1109/ACCESS.2023.3291336},
  ISSN={2169-3536},
  month={},}@ARTICLE{9143104,
  author={Farooqui, Faiq Faizan and Hassan, Muhammad and Younis, Muhammad Shahzad and Siddhu, Muhammad Kashif},
  journal={IEEE Access}, 
  title={Offline Hand Written Urdu Word Spotting Using Random Data Generation}, 
  year={2020},
  volume={8},
  number={},
  pages={131119-131136},
  abstract={Urdu word spotting is among the most challenging tasks in image processing and word spotting of hand written Urdu text is even more so. When it comes to handwritten Urdu documents, variation among the same words of various writers is significant. The orientation and style of the handwriting makes it really challenging for a word spotting system to correctly recognize the instances of the keyword. In this research, we tend to overcome this hurdle. We propose a system that takes a database of hand written Urdu text and generates random, yet, similar images to improve the classifier’s ability to recognize variations caused by difference in handwriting. For image generation, we used geometric transformations and variants of Generative Adversarial Network (GAN). For the word spotting process, Histogram of Oriented Gradients (HOG) features are extracted from ligature images and then used to train a Long Short-Term Memory (LSTM) network for the classification task. This is the first study that focuses on improving word spotting by generating arbitrary samples using GANs and its variants. The system achieved a promising recognition rate of 98.96% due to the sample generation using Cycle-GANs.},
  keywords={Gallium nitride;Feature extraction;Generative adversarial networks;Hidden Markov models;Task analysis;Training;Image recognition;Word spotting;HOG features;hand written text;LSTM;GANs},
  doi={10.1109/ACCESS.2020.3010166},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10533993,
  author={Pagadala, Arnold Anand and Silas, Salaja and Joy, Emmanuel},
  booktitle={2024 International Conference on Cognitive Robotics and Intelligent Systems (ICC - ROBINS)}, 
  title={Ensemble of Vision Transformers and CNNs for Accurate Diabetic Foot Ulcer Classification}, 
  year={2024},
  volume={},
  number={},
  pages={300-304},
  abstract={Diabetic Foot Ulcers (DFU) are a significant diabetes complication that can lead to lower limb amputation. Currently, 537 million suffer from diabetes worldwide and it is anticipated to rise to 783 million by 2045. Given the speed at which DFU is developing, prompt action is necessary to avoid the serious consequences of amputation and associated various medical conditions. With the evolution of image-based ML algorithms, automated methods for identifying and assessing DFUs are becoming more common. Existing research works on visual computing techniques concerns tissue classification and detects the DFU's visual appearance. This research study combines ResNet50 with Vision Transformers (ViT) and MobileNet with Vision Transformers (ViT) to develop an ensemble model to classify the existence or absence of a Diabetic Foot Ulcer (DFU). Experimental results of the proposed model when tested on challenging datasets achieved a validation accuracy of 98.6%.},
  keywords={Visualization;Computational modeling;Neural networks;Transformers;Diabetes;Classification algorithms;Cognitive robotics;Deep Learning;Diabetic Foot Ulcers;Vision Transformers;Ensemble Models;Artificial Neural Networks},
  doi={10.1109/ICC-ROBINS60238.2024.10533993},
  ISSN={},
  month={April},}@ARTICLE{10068504,
  author={Gul, Omer Melih and Kulhandjian, Michel and Kantarci, Burak and Touazi, Azzedine and Ellement, Cliff and D’amours, Claude},
  journal={IEEE Access}, 
  title={Secure Industrial IoT Systems via RF Fingerprinting Under Impaired Channels With Interference and Noise}, 
  year={2023},
  volume={11},
  number={},
  pages={26289-26307},
  abstract={Industrial IoT-enabled critical infrastructures are susceptible to cyber attacks due to their mission-critical deployment. To ensure security by design, radio frequency (RF)-based security is considered an effective way for wirelessly monitored or actuated critical infrastructures. For this purpose, this paper presents a novel augmentation-driven deep learning approach to analyze unique transmitter fingerprints and determine the legitimacy of a user device or transmitter. An RF fingerprinting model is susceptible to various channel and environmental conditions that impact the learning performance of a machine/deep learning model. As data gathering cannot always be considered a feasible alternative, efficient solutions that can tackle the impact of varying propagation channels on learning performance are emergent. This work aims to shed light on the RF fingerprinting problem from a different angle when 4G, 5G, and WiFi data samples are collected from different transmitters by proposing a fine-grained augmentation approach to improve the learning performance of a deep learning model. This work also proposes an enhanced classifier structure following the fine-grained augmentation approach. Results of experiments, conducted on the POWDER dataset, demonstrate promising RF fingerprinting performance when training data are augmented in a waveform-specific fine-grained manner. Thus, the RF identification accuracy can be boosted to 97.84% on unseen RF data instances from our previously published work where we had achieved an accuracy of 87.94% using tapped delay line (TDL)/clustered delay line (CDL)-based augmentation approach. The paper also presents a sensitivity analysis of the fine-grained approach concerning different signal-to-noise-ratio (SNR), signal-to-interference-ratio (SIR) levels (20 dB and 30 dB), and signal-to-interference-plus-noise-ratio (SINR) levels (15 dB, 25 dB). The sensitivity analysis exhibits that it achieves 85.78% accuracy at 20 dB SIR on both Day 1 (train) and Day 2 (test) data. In addition, it achieves 92.37% accuracy even at 20 dB SNR on Day 2 data from POWDER dataset. Furthermore, it achieves 84.95% accuracy at 15 dB SINR on Day 2 data. Hence, these results exhibit the resiliency of the fine-grained augmentation approach against interference and noise.},
  keywords={Fingerprint recognition;Radio frequency;Mathematical models;Signal to noise ratio;Wireless communication;Deep learning;Interference;Autonomous aerial vehicles;Internet of Things;Deep learning;data augmentation;radio frequency fingerprinting;secure design;unmanned aerial vehicles;Internet of Things (IoT)},
  doi={10.1109/ACCESS.2023.3257266},
  ISSN={2169-3536},
  month={},}@ARTICLE{10360101,
  author={Pang, Shiyan and Lan, Jingjing and Zuo, Zhiqi and Chen, Jia},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={SFGT-CD: Semantic Feature-Guided Building Change Detection From Bitemporal Remote-Sensing Images With Transformers}, 
  year={2024},
  volume={21},
  number={},
  pages={1-5},
  abstract={High-resolution remote-sensing-image change detection is widely used in urban dynamic monitoring, geographic information updating, natural disaster monitoring, illegal building investigation, and land resource surveys. Common change-detection algorithms are mainly implemented in a fully supervised manner that relies on a large number of high-quality samples. Compared with a building change-detection dataset, a building semantic-segmentation dataset is easier to accumulate and obtain. Making full use of this semantic information in the design of a building change-detection network can effectively reduce the sample size required to train a change-detection model. In view of this, a semantic feature-guided Siamese change-detection framework is devised in this letter. The framework effectively exploits the prior information of building semantic features and uses the popular transformer structure to improve the change analysis module. The results of extensive experiments on two public datasets show that the framework is more accurate than the other state-of-the-art change detection algorithms and can effectively reduce the dependence of data on change detection samples in the model training process.},
  keywords={Feature extraction;Semantics;Transformers;Convolutional neural networks;Training;Remote sensing;Decoding;Change detection;high-resolution optical remote-sensing images;prior semantic information;transformers},
  doi={10.1109/LGRS.2023.3341045},
  ISSN={1558-0571},
  month={},}@INPROCEEDINGS{10094654,
  author={Tian, Cheng and Luo, Zhiming and Shi, Guimin and Li, Shaozi},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Frequency-Aware Attentional Feature Fusion for Deepfake Detection}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Various face manipulation techniques develop rapidly and can easily generate high-quality fake images or videos, posing significant ethical concerns when used for malicious purposes. Although recent works achieve significant performance in deepfake detection, they still suffer from overfitting issues. To deal with this problem, we propose a novel framework to aggregate diverse information for deepfake detection from both RGB and frequency. Specially, we first introduce a channel attention module to assemble local and global contexts to overcome the potential semantic inconsistency on local artifacts and global features. Then we design a spatial-frequency feature fusion module to fuse the RGB-frequency information comprehensively. Moreover, a variant attention module is further proposed to improve feature discrimination. Extensive experiments demonstrate that our method maintains comparable performance in intra-dataset and cross-dataset evaluation.},
  keywords={Deepfakes;Ethics;Fuses;Aggregates;Semantics;Signal processing;Feature extraction;DeepFake Detection;Feature Fusion},
  doi={10.1109/ICASSP49357.2023.10094654},
  ISSN={2379-190X},
  month={June},}@INPROCEEDINGS{8451010,
  author={Yan, Liang and Fan, Bin and Xiang, Shiming and Pan, Chunhong},
  booktitle={2018 25th IEEE International Conference on Image Processing (ICIP)}, 
  title={Adversarial Domain Adaptation with a Domain Similarity Discriminator for Semantic Segmentation of Urban Areas}, 
  year={2018},
  volume={},
  number={},
  pages={1583-1587},
  abstract={Existing semantic segmentation models of urban areas have shown to perform well in a supervised setting. However, collecting lots of annotated images from each city to train such models is time-consuming or difficult. In addition, when transferring the segmentation model from the trained city (source domain) to an unseen city (target domain), the performance will largely degrade due to the domain shift. For this reason, we propose a domain adaptation method with a domain similarity discriminator to eliminate such domain shift in the framework of adversarial learning. Contrary to the single-input adversarial network, our domain similarity discriminator, which consists of a Siamese network, is able to measure the similarity of the pairwise-input data. In this way, we can use more information about the pairwise-input to measure the similarity between different distributions so as to address the problem of domain shift. Experimental results demonstrate that our approach outperforms the competing methods on three different cities.},
  keywords={Urban areas;Semantics;Feature extraction;Image segmentation;Task analysis;Training;Labeling;domain adaptation;domain shift;semantic segmentation;Siamese network;urban areas},
  doi={10.1109/ICIP.2018.8451010},
  ISSN={2381-8549},
  month={Oct},}@ARTICLE{10752984,
  author={Cruzes, Sergio},
  journal={IEEE Access}, 
  title={Failure Management Overview in Optical Networks}, 
  year={2024},
  volume={12},
  number={},
  pages={169170-169193},
  abstract={Conventional optical networks are limited by static operational methods that hinder their scalability and effectiveness. As networks operate with reduced margins to maximize resource utilization, the risk of hard failures increases, necessitating efficient failure prediction systems and accurate quality of transmission (QoT) estimation. Effective management requires the detection of soft failures, accurate bit error rate (BER) predictions, and dynamic network operations to maintain minimal margins. Machine learning (ML) offers promising solutions for automating these tasks, significantly enhancing failure management and network reliability. This article provides an extensive overview of ML techniques applied to optical networks, specifically focusing on failure management. The key ML techniques discussed include network kriging (NK) for performance estimation and failure localization, support vector machine (SVM) for classification tasks, convolutional neural networks (CNNs) for signal analysis and soft failure identification, and generative adversarial networks (GANs) for synthetic data generation and soft failure detection. It also explores the application of artificial neural networks (ANNs), autoencoders (AEs), Gaussian process (GP), long short-term memory (LSTM), and gated recurrent units (GRUs) in optical networks. This study surveys ML techniques for early-warning and failure prediction, failure detection, identification, localization, magnitude estimation, and soft failure detection and prediction. Emphasizing automation, it discusses how ML algorithms can streamline failure management processes, reducing manual intervention and service disruptions. The potential of large language models (LLMs) and digital twins (DTs) for further advancements in automating failure management, optimizing performance, and network optimization in optical networks is also examined. LLMs significantly advance network management by improving network design, diagnosis, security, and autonomous optimization through the integration of comprehensive domain resources and intelligent agents. These advancements are paving the way towards achieving artificial general intelligence and fully automated optical network management.},
  keywords={Location awareness;Support vector machines;Maximum likelihood estimation;Accuracy;Failure analysis;Optical fiber networks;Optical imaging;Optical fiber filters;Optimization;Long short term memory;Optical networks;failure management;quality of transmission;machine learning},
  doi={10.1109/ACCESS.2024.3498704},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9414550,
  author={Huang, Houjun and Xiang, Xu and Zhao, Fei and Wang, Shuai and Qian, Yanmin},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Unit Selection Synthesis Based Data Augmentation for Fixed Phrase Speaker Verification}, 
  year={2021},
  volume={},
  number={},
  pages={5849-5853},
  abstract={Data augmentation is commonly used to help build a robust speaker verification system, especially in limited-resource case. However, conventional data augmentation methods usually focus on the diversity of acoustic environment, leaving the lexicon variation neglected. For text dependent speaker verification tasks, it’s well-known that preparing training data with the target transcript is the most effectual approach to build a well-performing system, however collecting such data is time-consuming and expensive. In this work, we propose a unit selection synthesis based data augmentation method to leverage the abundant text-independent data resources. In this approach text-independent speeches of each speaker are firstly broke up to speech segments each contains one phone unit. Then segments that contain phonetics in the target transcript are selected to produce a speech with the target transcript by concatenating them in turn. Experiments are carried out on the AISHELL Speaker Verification Challenge 2019 database, the results and analysis shows that our proposed method can boost the system performance significantly.},
  keywords={Databases;System performance;Conferences;Training data;Signal processing;Phonetics;Acoustics;speaker verification;data augmentation;unit selection synthesis;x-vector},
  doi={10.1109/ICASSP39728.2021.9414550},
  ISSN={2379-190X},
  month={June},}@INPROCEEDINGS{10452439,
  author={Devi, V. Anjana and Bhuvaneswari, E. and Tummala, Rama Krishna},
  booktitle={2023 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI)}, 
  title={Decentralized Hybrid Intrusion Detection System for Cyber Attack Identification using Machine Learning}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={This research proposes a hybrid intrusion detection system that uses machine learning, file integrity monitoring, anomaly-based and signature-based rootkit detection, and signature-and anomaly-based detection. A distributed architecture is also used in my research to share real-time threat intelligence among numerous nodes. The system offers proactive response methods for automatic incident response, endpoint quarantine, and improved detection capabilities.This hybrid intrusion detection system combines rule-based and machine-learning algorithms to detect and prevent cyberattacks better. The system utilizes decentralized storage and distribution of alerts, improving scalability and availability. The main objective of this project is to develop highly effective and efficient IDS that can detect and prevent cyber attacks in real time. The proposed hybrid approach combines rule-based and machine-learning algorithms to achieve better detection rates and reduce false positives. The system architecture consists of a central server and multiple agents deployed across the network to collect data from various sources. The collected data is analyzed using rule-based and machine-learning techniques to identify potential threats. Alerts are then sent to the central server, which distributes them to the relevant agents for further analysis and response.The machine learning models are trained using a large dataset of normal and attack traffic, and the system continuously learns and adapts to new attack techniques. Using decentralized storage ensures that alerts are always available, even during network disruptions or server failures. The effectiveness of the proposed system was evaluated using various performance metrics, including detection rate, false positive rate, and response time.The results indicate the system achieves high detection rates while minimizing false positives and response times. Overall, the proposed system provides a comprehensive solution for intrusion detection and prevention, combining the strengths of rule-based and machine-learning techniques while also offering high scalability and availability through decentralized storage and distribution of alerts.},
  keywords={Scalability;Intrusion detection;Machine learning;Real-time systems;Servers;Time factors;Cyberattack;IDS;Hybrid IDS;Machine learning;Signature and Anomaly detection},
  doi={10.1109/ICDSAAI59313.2023.10452439},
  ISSN={},
  month={Dec},}@ARTICLE{9775801,
  author={Zhang, Yu and Zhou, Huaping and Wang, Pengyan and Yang, Gaoming},
  journal={IEEE Access}, 
  title={Black-Box Based Limited Query Membership Inference Attack}, 
  year={2022},
  volume={10},
  number={},
  pages={55459-55468},
  abstract={Conventional membership inference attacks usually require a large number of queries of the target model when training shadow models, and this task becomes extremely difficult when the number of queries is limited. Aiming at the problem of insufficient training data for shadow models due to the limited number of queries, we propose a membership inference attack method based on generative adversarial networks (GAN). First, we use generative adversarial networks to augment the samples obtained by a small number of queries to expand the training data of the model; Secondly, we use the improved CNN to obtain shadow models that have a higher degree of fitting on different target model structures; Finally, we evaluate the accuracy of the proposed algorithm on XgBoost, Logistic, and neural network models using public datasets MNIST and CIFAR10 in a black-box setting, and the results show that our model has an average attack accuracy of 62% and 83%, respectively. It can be seen that, compared with the existing research methods, our model can obtain better attack effects under the condition of significantly reducing the number of queries, which shows the feasibility of our proposed method in membership inference attacks.},
  keywords={Data models;Training;Adaptation models;Training data;Predictive models;Generative adversarial networks;Machine learning;Membership inference attack;generative adversarial network;black-box attack;information leak},
  doi={10.1109/ACCESS.2022.3175824},
  ISSN={2169-3536},
  month={},}@ARTICLE{8970471,
  author={Xu, Xiaofeng and Tsang, Ivor W. and Liu, Chuancai},
  journal={Neural Computation}, 
  title={Improving Generalization via Attribute Selection on Out-of-the-Box Data}, 
  year={2020},
  volume={32},
  number={2},
  pages={485-514},
  abstract={Zero-shot learning (ZSL) aims to recognize unseen objects (test classes) given some other seen objects (training classes) by sharing information of attributes between different objects. Attributes are artificially annotated for objects and treated equally in recent ZSL tasks. However, some inferior attributes with poor predictability or poor discriminability may have negative impacts on the ZSL system performance. This letter first derives a generalization error bound for ZSL tasks. Our theoretical analysis verifies that selecting the subset of key attributes can improve the generalization performance of the original ZSL model, which uses all the attributes. Unfortunately, previous attribute selection methods have been conducted based on the seen data, and their selected attributes have poor generalization capability to the unseen data, which is unavailable in the training stage of ZSL tasks. Inspired by learning from pseudo-relevance feedback, this letter introduces out-of-the-box data—pseudo-data generated by an attribute-guided generative model—to mimic the unseen data. We then present an iterative attribute selection (IAS) strategy that iteratively selects key attributes based on the out-of-the-box data. Since the distribution of the generated out-of-the-box data is similar to that of the test data, the key attributes selected by IAS can be effectively generalized to test data. Extensive experiments demonstrate that IAS can significantly improve existing attribute-based ZSL methods and achieve state-of-the-art performance.},
  keywords={},
  doi={10.1162/neco_a_01256},
  ISSN={0899-7667},
  month={Feb},}@ARTICLE{9295378,
  author={Yuan, Yuan and Ma, Hanwen and Liu, Ganchao},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={A New Multiscale Residual Learning Network for HSI Inconsistent Noise Removal}, 
  year={2022},
  volume={19},
  number={},
  pages={1-5},
  abstract={Hyperspectral image (HSI) often suffers from various noise disturbances which makes the interpretation difficult. To solve this problem, a lot of HSI denoising algorithms have been proposed and widely used. Although many convolution neural network (CNN) based denoising methods have achieved successful performance in independently and identically distributed (i.i.d) Gaussian denoising, they are still limited to remove inconsistent noise, and even worse than traditional representative algorithms like total variation regularized low-rank matrix factorization (LRTV) and low-rank matrix recovery (LRMR). In this letter, a new multiscale residual learning network (MSRHSID) is proposed for HSIs denoising. In this network, a noise estimation network is used in our proposed method to obtain the image noise prior to achieve the reduction of inconsistent noise. At the same time, an efficient multiscale residual module (MRM) is employed to further improve the denoising effect. Both of the denoising experiments on synthetic and real-data HSIs show that this proposed MSRHSID outperforms the state-of-the-art methods.},
  keywords={Noise reduction;Feature extraction;Convolution;Image restoration;Noise measurement;Solid modeling;Estimation;Convolution network;denoising;hyperspectral image (HSI);mutiscale},
  doi={10.1109/LGRS.2020.3037104},
  ISSN={1558-0571},
  month={},}@INPROCEEDINGS{9506191,
  author={Zhang, Qindong and Zhou, Sanping and Wang, Jinjun},
  booktitle={2021 IEEE International Conference on Image Processing (ICIP)}, 
  title={Learning Generic Feature Representations with Adversarial Regularization for Person Re-Identification}, 
  year={2021},
  volume={},
  number={},
  pages={2358-2362},
  abstract={Many existing person re-identification (Re-ID) methods can achieve human-level accuracy on a single dataset, while most of them can be poorly generalized to other datasets. This is mainly caused by different data distributions between different domains. In this paper, we propose a novel adversarial regularization method to address this issue. Specifically, the features extracted from different datasets will be constrained and focused to follow a more similar distribution during the training process. As a result, our method can learn a feature representation with better inter-domain invariance, which will improve the generalization ability of the resulting model. Besides, our method is flexible and can be combined with any feature learning network. Extensive experiments on both Market1501 and DukeMTMC-reID datasets have demonstrated the effectiveness of our method.},
  keywords={Training;Conferences;Feature extraction;Person Re-identification;Adversarial Learning;Deep Learning},
  doi={10.1109/ICIP42928.2021.9506191},
  ISSN={2381-8549},
  month={Sep.},}@INPROCEEDINGS{10056481,
  author={Ge, Yangchen and Li, Jian and Tian, Yuan},
  booktitle={2022 4th International Conference on Applied Machine Learning (ICAML)}, 
  title={Internet of Things Intrusion Detection System Based on D-GRU}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Aiming at the shortcomings of slow training speed and insufficient accuracy of algorithms in IoT intrusion detection, an IoT intrusion detection system based on D-GRU neural network is proposed. The system uses window functions and D-GRU modules to extract the timing features in the network traffic and classify potential intrusions. The experiment was simulated on the intrusion detection dataset UNSW-NB15. In the binary-class and multi-class classification, the accuracy rates were 97.23% and 94.21%, respectively, and the parameters, training time, and prediction time were optimized in our scheme. The experimental results show that the IoT intrusion detection system based on the D-GRU algorithm maintains high accuracy while reducing the parameters, improving the performance of the system, and is more conducive to being deployed in resource-constrained edge nodes of the IoT.},
  keywords={Training;Machine learning algorithms;Neural networks;Intrusion detection;Telecommunication traffic;Feature extraction;Prediction algorithms;IoTs;intrusion detection system;GRU;deep learning;IoT security},
  doi={10.1109/ICAML57167.2022.00066},
  ISSN={},
  month={July},}@INPROCEEDINGS{9902414,
  author={Zhao, Yunbin and Zhu, Songhao and Liang, Zhiwei},
  booktitle={2022 41st Chinese Control Conference (CCC)}, 
  title={Open-Set Domain Adaptation Classification Via Adversarial Learning}, 
  year={2022},
  volume={},
  number={},
  pages={7059-7063},
  abstract={Domain adaptation has achieved great success in using labeled source domain samples to identify unlabeled target domain samples. Here, we aimed to solve the open-set domain adaptation, which is different from the closed-set domain adaptation in that it contains categories in target domain that do not appear in source domain. A new method based on open-set domain adaptation by back propagation (OSBP) is proposed. Known category samples in target domain are gradually selected, and domain invariant features are extracted through adversarial training. Singular value balance is utilized to preserve the discriminability of the network. In addition, a channel attention module is added to the feature generator. We conduct experiments on two benchmark datasets of domain adaptation datasets. Experimental results demonstrate that the proposed method has a significant improvement over some previous methods.},
  keywords={Training;Backpropagation;Benchmark testing;Feature extraction;Generators;Adversarial machine learning;Data mining;Open Set Domain Adaptation;Adversarial Learning;Image Classification;Channel attention},
  doi={10.23919/CCC55666.2022.9902414},
  ISSN={1934-1768},
  month={July},}@INPROCEEDINGS{10890756,
  author={Lu, Xikun and Wang, Yilei and Sang, Jinqiu and Zheng, Chengshi},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={BiCG: Binaural Cue Generation from Unified HRTF Datasets}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Head-related transfer functions (HRTFs) are important for spatial audio reproduction in immersive systems. Most existing data-driven methods focus on personalized HRTF estimation of monaural spectral factors. These methods ignore the importance of binaural cues, which are essential for binaural reproduction and perception. Moreover, the significant differences among various HRTF datasets in aspects such as measurement setup limit the potential of data-driven methods. This paper proposes a binaural cue generation method (BiCG), which utilizes an implicit neural network (INN) to estimate interaural level differences (ILDs) and interaural time differences (ITDs). Experimental results show that our method outperforms existing neural field methods in terms of binaural cue generation quality across datasets. We also evaluate various data preprocessing methods, and experimental results show that extreme smoothing improves binaural cue generation performance across datasets. The work provides new insights into enhancing HRTF modeling.},
  keywords={Smoothing methods;Spatial audio;Neural networks;Data preprocessing;Transfer functions;Estimation;Signal processing;Acoustics;Copper;Speech processing;head-related transfer function;binaural cue;implicit neural network;data preprocessing;spatial audio},
  doi={10.1109/ICASSP49660.2025.10890756},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10446540,
  author={Niu, Yunfang and Yi, Dong and Wu, Lingxiang and Liu, Zhiwei and Cai, Pengxiang and Wang, Jinqiao},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={PFDM: Parser-Free Virtual Try-On via Diffusion Model}, 
  year={2024},
  volume={},
  number={},
  pages={3780-3784},
  abstract={Virtual try-on can significantly improve the garment shopping experiences in both online and in-store scenarios, attracting broad interest in computer vision. However, to achieve high-fidelity try-on performance, most state-of-the-art methods still rely on accurate segmentation masks, which are often produced by near-perfect parsers or manual labeling. To overcome the bottleneck, we propose a parser-free virtual try-on method based on the diffusion model (PFDM). Given two images, PFDM can "wear" garments on the target person seamlessly by implicitly warping without any other information. To learn the model effectively, we synthesize many pseudo-images and construct sample pairs by wearing various garments on persons. Supervised by the large-scale expanded dataset, we fuse the person and garment features using a proposed Garment Fusion Attention (GFA) mechanism. Experiments demonstrate that our proposed PFDM can successfully handle complex cases, synthesize high-fidelity images, and outperform both state-of-the-art parser-free and parser-based models.},
  keywords={Image segmentation;Computer vision;Statistical analysis;Image synthesis;Fuses;Clothing;Manuals;Diffusion models;Labeling;Electronic commerce;Virtual try-on;diffusion models;implicit warping;high-resolution image synthesis},
  doi={10.1109/ICASSP48485.2024.10446540},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{9629833,
  author={Shi, Peiwen and Xin, Jingmin and Zheng, Nanning},
  booktitle={2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)}, 
  title={Correcting Pseudo Labels with Label Distribution for Unsupervised Domain Adaptive Vulnerable Plaque Detection}, 
  year={2021},
  volume={},
  number={},
  pages={3225-3228},
  abstract={Pseudo-label-based unsupervised domain adaptation (UDA) has increasingly gained interest in medical image analysis, aiming to solve the problem of performance degradation of deep neural networks when dealing with unseen data. Although it has achieved great success, it still faced two significant challenges: improving pseudo labels’ precision and mitigating the effects caused by noisy pseudo labels. To solve these problems, we propose a novel UDA framework based on label distribution learning, where the problem is formulated as noise label correcting and can be solved by converting a fixed categorical value (pseudo labels on target data) to a distribution and iteratively update both network parameters and label distribution to correct noisy pseudo labels, and then these labels are used to re-train the model. We have extensively evaluated our framework with vulnerable plaques detection between two IVOCT datasets. Experimental results show that our UDA framework is effective in improving the detection performance of unlabeled target images.},
  keywords={Degradation;Deep learning;Decision support systems;Adaptation models;Image analysis;Biological system modeling;Stability analysis;Unsupervised domain adaption;pseudo label;label distribution;plaque detection;IVOCT},
  doi={10.1109/EMBC46164.2021.9629833},
  ISSN={2694-0604},
  month={Nov},}@INPROCEEDINGS{9277499,
  author={Shiling, Zhang},
  booktitle={2020 IEEE International Conference on Information Technology,Big Data and Artificial Intelligence (ICIBA)}, 
  title={Optimization Design Method of Impulse Current Generation Using MATLAB/SIMULINK}, 
  year={2020},
  volume={1},
  number={},
  pages={1507-1512},
  abstract={The impulse current generator is widely used in the electrical power system, and the design method of the impulse current generator is mainly based on the classical theory. In view of this, this paper proposes new method of optimum design for the impulse current generator based on the MATLAB/SIMULINK simulation technology and the PSO intelligence optimization algorithm. This method can quickly and accurately determine the impulse current generator capacitance value C, the resistance value R, inductance RL and the initial DC voltage U0 according to the front time Tf, wave tail time Tt, peak current Im and the time of current reaches maximum time. PSO-Simulink optimization design method is fit to the design of the linear and the nonlinear impulse current generator, however, the solution of the traditional analytical method is complicated and does not apply to limitation of nonlinear resistance. The research results of this paper have the certain reference value for the design and operation of the impulse current generator.},
  keywords={Generators;Matlab;Capacitors;Capacitance;Optimization;Heuristic algorithms;Current measurement;Impulse current generator;PSO-Simulink;Nonlinear resistance},
  doi={10.1109/ICIBA50161.2020.9277499},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10094574,
  author={Tian, Mingjie and Giunchiglia, Fausto and Song, Rui and Chen, Xing and Xu, Hao},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Enhancing Ontology Translation Through Cross-Lingual Agreement}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Ontology serves as the foundation for the underlying representation of knowledge. In order to achieve the sharing of knowledge across languages, ontologies that are typically only represented in English must be translated into different languages. Building a domain-specific translation system is necessary for ontology due to the extremely specialized vocabulary and absence of contextual information. In this paper, we introduce cross-lingual agreement to alleviate the aforementioned issues. We propose a method for representing ontology labels that constructs agreement constraint objects by minimizing the distances between source and target sides. We also integrate with adversarial learning to reduce the difference between the ontology label and the hypothesis generated by the translation model during the fine-tuning. Finally, the agreement modeling strategy is incorporated into the decoding phase to guide the generation of translation candidates. Experiments on the four domains English-to-German ontology show that the proposed method achieves significant improvements over the baselines.},
  keywords={Training;Vocabulary;Buildings;Ontologies;Signal processing;Feature extraction;Adversarial machine learning;ontology translation;cross-lingual agreement;adversarial learning;fusion decoding;cross-lingual alignment},
  doi={10.1109/ICASSP49357.2023.10094574},
  ISSN={2379-190X},
  month={June},}@ARTICLE{10856767,
  author={Wang, Xuesong and Li, Yiran and Cheng, Yuhu},
  journal={Chinese Journal of Electronics}, 
  title={Hyperspectral Image Classification Based on Unsupervised Heterogeneous Domain Adaptation CycleGan}, 
  year={2020},
  volume={29},
  number={4},
  pages={608-614},
  abstract={Aiming at the difficulty of obtaining sufficient labeled Hyperspectral image (HSI) data and the inconsistent feature distribution of different HSIs, a novel Unsupervised heterogeneous domain adaptation CycleGan (UHDAC) is proposed by using CycleGan to capture the transferable features in the absence of similar data. On the one hand, the two-way mapping is used to find the internal relationship between the source and target domain data, while the two-way adversary is used to constrain the source and target domain features, realizing the alignment of feature distributions. On the other hand, the CORAL loss function is introduced to minimize the distance between the second-order statistical difference between the source and target domain features, so as to solve the insufficient constraint of mapping relationship caused by the low consistency of HSI data structure in different domains. Experiments on three real HSI datasets show that UHDAC can effectively realize the unsupervised classification of target domain HSI with high classification accuracy by using the labeled HSI data in the source domain.},
  keywords={Hands;Accuracy;Data structures;Hyperspectral imaging;Image classification;Unsupervised;Heterogeneous;Domain adaptation;CycleGan;Hyperspectral image;Classification},
  doi={10.1049/cje.2020.05.003},
  ISSN={2075-5597},
  month={July},}@INPROCEEDINGS{9859519,
  author={Chen, Yiru and Wang, Yumei and Liu, Yu},
  booktitle={2022 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)}, 
  title={MOFN: Multi-Offset-Flow-Based Network for Video Restoration and Enhancement}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Video restoration and enhancement tasks, including video super-resolution(VSR), are designed to convert low-quality videos into high-quality videos to improve the audience’s visual experience. In recent years, many deep learning methods using optical flow estimation or deformable convolution have been applied to video super-resolution. However, we find that motion estimation based on a single optical flow is difficult to capture enough inter-frame information, and the method using deformable convolution lacks clear motion constraints, which affects its ability to process fast motion. Therefore, we propose a multi-offset-flow-based network (MOFN) to make more effective use of inter-frame information by using optical flow with offset diversity. We proposed an alignment and compensation module that can estimate the optical flow with multiple offsets for neighbouring frames and perform frame alignment. The aligned video frames will be fed into the fusion module, and high-quality video frames will be obtained after fusion and reconstruction. Extensive results show that our proposed model has a good ability to process motion. On several benchmark datasets, our method has achieved favorable performance compared with the most advanced methods.},
  keywords={Deep learning;Visualization;Convolution;Motion estimation;Conferences;Superresolution;Estimation;Video Super-resolution;Deep Learning;Offset Diversity;Inter-frame Information},
  doi={10.1109/ICMEW56448.2022.9859519},
  ISSN={},
  month={July},}@INPROCEEDINGS{10082699,
  author={Sun, LongXiang and Yuan, ChenHui and Li, Kun and Zhu, JianBing and Li, ZeRui},
  booktitle={2023 IEEE 6th Information Technology,Networking,Electronic and Automation Control Conference (ITNEC)}, 
  title={Cross-well Lithology Identification based on Dynamic Adversarial Adaptation}, 
  year={2023},
  volume={6},
  number={},
  pages={120-124},
  abstract={Lithology identification is a fundamental task in geo-logical work such as stratigraphic correlation, reservoir zonation, and sedimentation simulation. Traditional lithology identification methods require too much manual labor and are inefficient. The shifts in data distribution between differ wells make it difficult to apply the same logging lithology identification method from well to well. In this paper, we study cross-well lithology identification by unsupervised domain adaptation. The features of the logging curve in the depth domain are extracted by semantic segmentation to achieve intensive lithology prediction for each depth point. An adversarial learning strategy is introduced to the cross-well lithology classification task to reduce the difference in distribution between two well features. The proposed method outperforms the baseline in four cross-well lithology identification tasks, demonstrating the efficiency of our method for cross-well lithology identification.},
  keywords={Correlation;Automation;Semantic segmentation;Geology;Manuals;Feature extraction;Reservoirs;Cross-well Lithology Identification;Unsupervised Domain Adaptation;Adversarial Learning;Semantic Segmentation;Fully Convolutional Network},
  doi={10.1109/ITNEC56291.2023.10082699},
  ISSN={2693-3128},
  month={Feb},}@INPROCEEDINGS{9678652,
  author={Wu, Xiaohui and Meng, Jie and Liu, Leyuan},
  booktitle={2021 IEEE International Conference on Engineering, Technology & Education (TALE)}, 
  title={An Emotional Intervention System for Children with ASD Based on the First Order Motion Model}, 
  year={2021},
  volume={},
  number={},
  pages={01-06},
  abstract={Most children with Autism Spectrum Disorder (ASD) have facial expression recognition difficulties. They are unable to communicate emotionally with others, which impacts the social interaction skills of children with ASD and even leads to other social interaction problems. In this paper, an emotional intervention system based on the First Order Motion Model technology is designed for children with ASD to improve their emotional expression and then promote their social communication skills through the intervention. The system provides a series of intervention sessions for children with ASD, and users simply upload a photo of the child with ASD and the person close to them. A video of facial expressions generated through First Order Motion Model technology is loaded into the system along with an animated cartoon video. It is hoped that the system will help children with ASD overcome abnormalities in the mirror neuron system and then improve the generalisation skills of children with ASD.},
  keywords={Autism;Face recognition;Neurons;Education;Mirrors;Load modeling;Autism spectrum disorder;Emotional Intervention;First Order Motion Model;Social communication skills;System},
  doi={10.1109/TALE52509.2021.9678652},
  ISSN={2470-6698},
  month={Dec},}@INPROCEEDINGS{10273909,
  author={Chandra, Sanskriti and Saxena, Shivam and Kumar, Santosh and Chaube, Mithilesh Kumar and K G, Srinivas and Alsamhi, Saeed Hamood and Curry, Edward and Saif, Abdu},
  booktitle={2023 3rd International Conference on Computing and Information Technology (ICCIT)}, 
  title={A Novel Framework for Detection of Digital Face Video Manipulation using Deep Learning}, 
  year={2023},
  volume={},
  number={},
  pages={348-352},
  abstract={Digital face manipulation and classification have recently attracted the attention of academia and industry worldwide. Researchers have developed deep learning and computer vision techniques for detecting face manipulations, and it has become a challenging task to differentiate between authentic and manipulated face images manually. The challenge results in the decline of authenticity in digital media content. In this paper, we propose a framework for the classification of manipulating face images using the EfficientNet learning model. The proposed framework takes four digital facial forgeries: Face-Swap, Face-2-Face, DeepFakes, and neural textures. Multiple manipulation techniques are used to process manipulated faces, such as the Blaze-face tracking method, to determine the locations of the face images and pixel coordinates. The proposed framework is used first to identify the type of face manipulation and then to perform detection of the tampered regions in the face images. The proposed framework provided an automated benchmark that considers all four modification techniques in a realistic situation. The results show that the proposed framework outperforms existing approaches regarding accuracy and efficiency. Furthermore, the proposed framework is suitable for detecting digital face video manipulation in various applications, including forensics and security.},
  keywords={Deep learning;Industries;Deepfakes;Computer vision;Forensics;Media;Security;Machine learning;deep learning;Face-Swap;neural textures;Face-2-Face},
  doi={10.1109/ICCIT58132.2023.10273909},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10444483,
  author={Li, Zhiyuan and Ge, Chenyang and Li, Shun},
  booktitle={2024 IEEE International Conference on Consumer Electronics (ICCE)}, 
  title={Traditional Transformation Theory Guided Model for Learned Image Compression}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Recently, many deep image compression methods have been proposed and achieved remarkable performance. However, these methods are dedicated to optimizing the compression performance and speed at medium and high bitrates, while research on ultra low bitrates is limited. In this work, we propose a ultra low bitrates enhanced invertible encoding network guided by traditional transformation theory, experiments show that our codec outperforms existing methods in both compression and reconstruction performance. Specifically, we introduce the Block Discrete Cosine Transformation to model the sparsity of features and employ traditional Haar transformation to improve the reconstruction performance of the model without increasing the bitstream cost.},
  keywords={Image coding;Costs;Bit rate;Termination of employment;Rate-distortion;Image reconstruction;Consumer electronics;Deep image compression;ultra low bitrates;invertible codec;traditional transformation theory},
  doi={10.1109/ICCE59016.2024.10444483},
  ISSN={2158-4001},
  month={Jan},}@INPROCEEDINGS{10773697,
  author={Le, Nhat-Trinh and Thai, Nhat Tan and Bui, Cao Vu},
  booktitle={2024 IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia)}, 
  title={GeOPipe: A Pipeline for Optimized Retrieval and Storage of Multispectral Satellite Imagery}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Efficient management of large-scale geospatial datasets is crucial for timely and effective environmental monitoring. GeOPipe integrates advanced spatial indexing using hashing with selective compression techniques to optimize the retrieval and storage of Sentinel-2 satellite imagery within specific geographic areas. This research demonstrates how hashing enables constant-time (O(1)) data retrieval, significantly outperforming traditional spatial indexing methods like R-trees. By compressing data only within designated geographic boundaries, GeOPipe enhances data access speed and reduces storage requirements without compromising image quality. Experimental results show that GeOPipe improves retrieval times by achieving a retrieval complexity of O(1) and decreases storage needs by 45-50% compared to conventional systems. Additionally, GeOPipe's optimized data handling provides a streamlined input pipeline for deep learning frameworks, improving the performance of tasks like semantic segmentation and land cover classification. This capability is essential for applications requiring rapid and accurate environmental assessments. GeOPipe represents a significant advancement in satellite imagery analysis, offering an efficient and scalable solution for managing environmental data and enhancing the integration of geospatial datasets in machine learning workflows.},
  keywords={Image coding;Accuracy;Satellites;Semantic segmentation;Pipelines;Streaming media;Satellite images;Geospatial analysis;Environmental monitoring;Spatial indexes;Spatial Indexing;Hashing Algorithms;Selective Compression;Multi Spectral Image;Data Retrieval},
  doi={10.1109/ICCE-Asia63397.2024.10773697},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10774858,
  author={S, Vasavi and Praneeth Polu, Venkata Sai and Manikya Venkata Saketh Nandula, Bala},
  booktitle={2024 IEEE North Karnataka Subsection Flagship International Conference (NKCon)}, 
  title={Detecting Suspicious Military Tents from Optical Images using Deep Learning Model}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Locating suspicious military tents or encampments is crucial for national security. Recently, deep learning methods have become increasingly popular for detecting military objects at country borders. Traditional methods, which rely on manual checks and morphological algorithms, are often inaccurate and slow at detecting such unauthorized activities. To overcome this issue, a solution that automatically detects suspicious tents from satellite images using deep learning techniques is crucial. An enhanced YOLOv8x-obb model is proposed and trained with a satellite image dataset that is well-prepared with various preprocessing and augmentation techniques. This model was validated and produced an accuracy of 91.9% and false alarm rate of 6.08%, specifying that the model works well in different terrains and situations, and it has the advantage of better border surveillance.},
  keywords={Deep learning;Accuracy;Surveillance;Manuals;Optical imaging;Satellite images;Military satellites;National security;Satellite Images;Suspicious military tents;YOLO;Preprocessing;Data Augmentation},
  doi={10.1109/NKCon62728.2024.10774858},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10003883,
  author={Cho, Sunyoung and Yoon, Soosung and Song, Hyunseung},
  booktitle={2022 22nd International Conference on Control, Automation and Systems (ICCAS)}, 
  title={Adversarial Domain Adaptation for Noisy Speech Emotion Recognition}, 
  year={2022},
  volume={},
  number={},
  pages={1966-1970},
  abstract={Speech Emotion Recognition (SER) has achieved many great results with deep learning techniques. However, noise discrepancy is still a challenging task due to the distribution shift between training and test data. In this paper, we present a novel approach based on unsupervised domain adaptation method to alleviate the distribution shift problem for noisy SER. Specifically, we apply an adversarial domain adaptation with bridge mechanism to model an intermediate domain for knowledge transfer. We construct a bridge layer by exploiting speech denoising approach to extract the domain-specific noise representation. Experimental results show that our method provides average improvements of 2.29% and 3.88% in weighted and unweighted accuracies over the baseline for SER with various noise settings.},
  keywords={Bridges;Training;Deep learning;Emotion recognition;Noise reduction;Speech recognition;Control systems;Speech emotion recognition;unsupervised domain adaptation;adversarial domain adaptation;noise},
  doi={10.23919/ICCAS55662.2022.10003883},
  ISSN={2642-3901},
  month={Nov},}@INPROCEEDINGS{10239882,
  author={Lei, Fei and Wang, Zhuorui and Ding, Yibo},
  booktitle={2023 42nd Chinese Control Conference (CCC)}, 
  title={Combining Multi-scale and Self-Supervised Features for Speech Emotion Recognition}, 
  year={2023},
  volume={},
  number={},
  pages={8701-8706},
  abstract={Speech emotion recognition (SER) plays a crucial role in classifying emotional information conveyed through audio signals, providing more accurate and convenient solutions for human-computer interaction, emotional analysis and other fields. The recent research has focused on training Transformer-based models on human-annotated emotional datasets to capture long-range dependencies by modeling fixed-scale feature representations, and processing time-varying spectral features as images. However, extracting efficient and robust common speech features from small-scale datasets is challenging, and dealing with scale variance is difficult due to the lack of inherent inductive bias (IB). To address these challenges, this paper proposes a noval architecture that extracts Multi-Scale features from raw signals and embeds them into a Self-supervised Features, i.e., MSSF. Technically, this paper first designs a spatial pyramid reduction cell that combines rich multi-scale speech features by utilizing multiple convolutions of different kernel sizes. Next, these features are embedded into a pre-trained self-supervised model to obtain multi-scale, discriminative, and common features for SER tasks. The predicted labels are then output through the final classification head. Additionally, this paper designs a convolution block in parallel, and its features are fused and fed into the multi-scale features. Finally, MSSF is fine-tuned on the benchmark corpus IEMOCAP for four emotions. Compared to previous methods, our proposed model demonstrates improvements on four common metrics, indicating its superiority.},
  keywords={Training;Emotion recognition;Convolution;Microprocessors;Speech recognition;Computer architecture;Benchmark testing;Speech Emotion Recognition;Multi-Scale Features;Self-Surperviesed Features;Inductive Bias},
  doi={10.23919/CCC58697.2023.10239882},
  ISSN={1934-1768},
  month={July},}@INPROCEEDINGS{9118551,
  author={Li, Dongyang and Tang, Guiying and Zhao, Li and Zhang, Xiaoqin and Ye, Xiuzi},
  booktitle={2020 5th International Conference on Computer and Communication Systems (ICCCS)}, 
  title={Single I mage Haze Removal Based on Concentration Scale Prior}, 
  year={2020},
  volume={},
  number={},
  pages={309-313},
  abstract={Haze is a major degradation factor in outdoor images. Removing haze from a single image is an ill-posed problem and the performance of existing prior-based image dehazing methods is limited by the effectiveness of hand-designed features. In this paper, new dehazing method is introduced which is refined using gamma transformation and does not utilize the traditional atmospheric scattering model. The proposed method restores haze-free images without reference to corresponding clear image or estimating a depth-dependent transmission map. A novel, simple and powerful Concentration Scale Prior (CSP) is then utilized for haze removal in a single haze image to enhance gamma transformation, and its performance is verified. Experimental results show that the proposed approach achieves superior dehazing performance compared to current state-of-the-art methods.},
  keywords={Atmospheric modeling;Scattering;Image restoration;Image color analysis;Task analysis;Estimation;Deep learning;dehaze;gamma transformation;prior;concentration},
  doi={10.1109/ICCCS49078.2020.9118551},
  ISSN={},
  month={May},}@INPROCEEDINGS{10065952,
  author={Liang, Xianchen and Bie, Zhisong and Ma, Shiwei},
  booktitle={2022 IEEE 8th International Conference on Computer and Communications (ICCC)}, 
  title={Pyramid Attention CycleGAN for Non-Parallel Voice Conversion}, 
  year={2022},
  volume={},
  number={},
  pages={139-143},
  abstract={Non-parallel voice conversion (VC) is a voice mapping technology that uses non-parallel corpus to convert source speeches into target speeches while maintaining semantic information unchanged. Cycle-consistent adversarial network-based VC with Filling in Frames (MaskCycleGAN-VC) is proposed and generally accepted as a current benchmark method. While it solves the problem of time-frequency structures consistency, the performance of voice conversion is not satisfactory enough. There is still a large gap between target and converted voice in terms of naturalness and similarity. In addition, the performance of MaskCycleGAN-VC seriously deteriorates because of a limited amount of training data. In order to solve above problems, we propose Pyramid Attention CycleGAN (PACycleGAN) for voice conversion which integrates pyramid structure and attention mechanism. We use a method named differentiable augmentation to improve the data efficiency of GANs and make training more stable. We evaluate the performance of PACycleGAN on inter-gender and intra-gender non-parallel VC. Subjective and objective evaluations in naturalness and speaker similarity show that PACycleGAN-VC outperforms MaskCycleGAN-VC for every VC pair.11https://chenpaopao.github.io/chenpaopao/Cyclegan/index.html},
  keywords={Training;Time-frequency analysis;Fuses;Convolution;Semantics;Training data;Logic gates;voice conversion;differentiable augmentation;pyramid;attention mechanism},
  doi={10.1109/ICCC56324.2022.10065952},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10033902,
  author={Li, Li and Chen, Junchao and Cao, Wenjie and Zhang, Bengong},
  booktitle={2022 34th Chinese Control and Decision Conference (CCDC)}, 
  title={New Framework for Highlights Removal Based on CycleGAN}, 
  year={2022},
  volume={},
  number={},
  pages={5082-5086},
  abstract={Highlights detection and removal is hot topic in computer vision. It exists in high-gloss leather, glass, plastic, metal parts, and other mirror-reflective objects. Deep convolutional neural network-based highlight removal techniques can learn material rendering parameters supervised by a large number of paired datasets to automatically remove highlights from object surfaces. However, in reality, the datasets are usually unpaired. It is difficult to obtain a large number of paired images. To deal with the unpaired data, dual learning (CycleGAN) can make full use of unlabeled data. Therefore, based on S2D-NET, a new framework is proposed to address the above problem. The main contribution is that: a confidence map with independent averages is proposed to guide the network to quickly search for the initial value, which can solve the problem of slow network convergence due to the lack of a very strict mathematical definition to distinguish specular reflection components from diffuse reflection components. The experiments are compared with the latest three methods. It is found that the SSIM and PSNR values of our proposed algorithm are improved.},
  keywords={Training;Reflectivity;Neural networks;Metals;Glass;Rendering (computer graphics);Search problems;Highlight removal;Convolutional neural networks;S2D-NET;Confidence map},
  doi={10.1109/CCDC55256.2022.10033902},
  ISSN={1948-9447},
  month={Aug},}@INPROCEEDINGS{11117721,
  author={Liu, Jingxiang and Chen, Xianqiao and Li, Boshi and Lu, Yao},
  booktitle={2024 6th International Academic Exchange Conference on Science and Technology Innovation (IAECST)}, 
  title={Object Detection and Tracking Algorithm Based on Yolov7 and Deepsort}, 
  year={2024},
  volume={},
  number={},
  pages={526-529},
  abstract={To address the issues of distant ship misdetection and occlusion-caused miss detections in port images, as well as the low real-time detection accuracy of video information, this paper proposes an inland vessel supervision algorithm based on the fusion of image and video information, aimed at improving supervision efficiency and accuracy. First, an improved YOLOv7 ship detection algorithm is proposed, which significantly improves detection accuracy by introducing the DecIoU and Push-IoU loss functions. Next, an improved DeepSort-based ship multi-object tracking algorithm is developed, replacing Faster R-CNN with the improved YOLOv7, and combining HS-ResNet with BYTE and OCR technologies to enhance tracking performance in complex scenarios. Experimental results show that this algorithm performs excellently on the SeaShips and SMD datasets, validating the effectiveness of the improvements.},
  keywords={Technological innovation;Accuracy;Target tracking;Optical character recognition;Transportation;Object detection;Real-time systems;Trajectory;Marine vehicles;Videos;Object detection;Multi-target tracking;YOLOv7;DeepSort},
  doi={10.1109/IAECST64597.2024.11117721},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11033810,
  author={Zhou, Shilong and Hu, Shuman and Qin, Siyuan and Wu, Yuzhu},
  booktitle={2025 6th International Conference on Electrical, Electronic Information and Communication Engineering (EEICE)}, 
  title={Low-Illumination Images Enhancement Using an Optimized Retinex Model with Improved Bilateral Filtering}, 
  year={2025},
  volume={},
  number={},
  pages={1166-1170},
  abstract={Images taken in low light conditions suffer from poor quality, which prevents visual systems from fully fulfilling their purposes. To improve the quality of these images, this paper proposes a correctional method based on improved bilateral filtering and optimized gamma transform. Firstly, the original image is converted from RGB to the HSV space, and a modified bilateral filter function is used as the center surround function of Multi-Scale Retinex algorithm. After which, the image brightness component is decomposed to obtain the illuminated component and the reflected component. An optimized Gamma transform function is proposed to enhance the radiation component of the image. For the reflected components, the high-frequency noise is filtered by non-local mean filtering, and the details are enhanced by edge enhancement algorithms such as the Laplace operator. Finally, the adaptive correction formula adjusts the saturation component to ensure that the color of the image is uniform. Experimental results on several challenging low illumination image datasets show that the proposed algorithm is effective in terms of computation time, gray mean, information entropy, average gradient and peak signal-to-noise ratio.},
  keywords={Radiation effects;Filtering;Image color analysis;Brightness;Transforms;Filtering algorithms;Visual systems;Filtering theory;Usability;Image enhancement;retinex theory;low-light image enhancement;bilateral filtering;gamma transformation},
  doi={10.1109/EEICE65049.2025.11033810},
  ISSN={},
  month={April},}@INPROCEEDINGS{10451413,
  author={Sun, Bin and Zhu, Qing and Ni, Shuang},
  booktitle={2023 China Automation Congress (CAC)}, 
  title={A Double-Neighborhood Local Ratio-Difference Contrast Method for Infrared Small Target Detection}, 
  year={2023},
  volume={},
  number={},
  pages={1983-1988},
  abstract={Detecting infrared small targets swiftly and reliably has posed a significant challenge in recent times. Existing algorithms are often plagued by problems such as noise residuals and insufficient background suppression capabilities due to the complexity of the imaging environment. A double-neighborhood local ratio-difference contrast method (DNLRDC) is proposed in this paper. First, a tri-layer sliding window is designed to move through the input infrared image. Second, the salience map can be obtained by calculating the DNLRDC to achieving the target enhancement and background suppression. Finally, the real target is segmented from the salience map by employing a simple threshold segmentation method. Experiments shows that the proposed method is more robust than methods used as controls in the experimental stage.},
  keywords={Image segmentation;Automation;Imaging;Interference;Object detection;Complexity theory;Reliability;Infrared(IR) small target;double-neighborhood local ratio-difference contrast(DNLRDC);tri-layer local contrast sliding window},
  doi={10.1109/CAC59555.2023.10451413},
  ISSN={2688-0938},
  month={Nov},}@INPROCEEDINGS{11159833,
  author={Lu, Gongzheng and Jiang, Siyuan and Lian, Zheng},
  booktitle={2025 IEEE 6th International Conference on Pattern Recognition and Machine Learning (PRML)}, 
  title={Video super-resolution improvement based on Super-Resolution 3 Model}, 
  year={2025},
  volume={},
  number={},
  pages={234-238},
  abstract={Resolution is one of the most critical technical indicators in video, which affects the clarity and detail of the video. However, due to the limitations of sensors and acquisition equipment, compression algorithms in network transmission, etc., the video will be blurred, resulting in a lower recognition rate. Therefore, it is necessary to develop a video super-resolution (SR) reconstruction system. Based on the iterative refinement super -resolution (SR3) model, this paper combines the continuous image time series information to expand the single image super-resolution task to the super-resolution reconstruction of the video, and develop a system using Spring Boot and Vue. We compare the SR3 model used in our system horizontally with the current mainstream super-resolution models DeblurGAN, STFAN and LESRCNN in terms of SSIM, PNSR and processing time. Experimental results show that for videos with a resolution of no more than 720P, our system has achieved an average peak signal-to-noise ratio of 25.41dB and a structural similarity of 0.743dB in multiple application scenarios, which is better than DeblurGAN and STFAN, and has a shorter processing time. Compared with LESRCNN, SR3 achieves a higher SSIM value, while LESRCNN shows a slightly higher PSNR and the shortest processing time.},
  keywords={Deblurring;Training;Superresolution;Time series analysis;Sensors;Springs;Image reconstruction;Signal resolution;Videos;Testing;deep learning;video super-resolution;SR3;Spring Boot;Vue},
  doi={10.1109/PRML66062.2025.11159833},
  ISSN={},
  month={June},}@INPROCEEDINGS{10234029,
  author={Su, Yu-Sheng and Chen, Jen-Jee and Tseng, Yu-Chee},
  booktitle={2023 VTS Asia Pacific Wireless Communications Symposium (APWCS)}, 
  title={Realistic Pedestrian Shadow Generation by 2D-to-3D Object-Lifting}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper studies the shadow generation problem in an outdoor street scene. Previous methods only rely on GAN-based model with the sun position to reconstruct the street view. Lacking in related dataset, we propose an evaluation method to make sure of the effectiveness. Our model applies a 2D-to-3D lifting method, casts the 3D object with sun estimation, and finally merges the shadow with a predicted sun brightness. Limited with lifting objects, our model casts more precise shadows than GAN-based model. Tuning with the brightness, the cast shadow will be in consistence with the whole street view. Then in our evaluation, we demonstrate better performance over the state-of-the-art models by 0.009 in LPIPS. Therefore, casting with a 3D human object is a feasible solution for shadow generation in the future.},
  keywords={Wireless communication;Solid modeling;Three-dimensional displays;Pedestrians;Shape;Brightness;Estimation;Outdoor Scene Synthesis;Human Synthesis;Object Lifting;Shadow Generation},
  doi={10.1109/APWCS60142.2023.10234029},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10635513,
  author={Seibel, Marc S. and Uzunova, Hristina and Kepp, Timo and Handels, Heinz},
  booktitle={2024 IEEE International Symposium on Biomedical Imaging (ISBI)}, 
  title={Anatomical Conditioning for Contrastive Unpaired Image-to-Image Translation of Optical Coherence Tomography Images}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={For a unified analysis of medical images from different modalities, data harmonization using image-to-image (I2I) translation is desired. We study this problem employing an optical coherence tomography (OCT) data set of SpectralisOCT and Home-OCT images. I2I translation is challenging because the images are unpaired, and a bijective mapping does not exist due to the information discrepancy between both domains. This problem has been addressed by the Contrastive Learning for Unpaired I2I Translation (CUT) approach, but it reduces semantic consistency. To restore the semantic consistency, we support the style decoder using an additional segmentation decoder. Our approach increases the similarity between the style-translated images and the target distribution. Importantly, we improve the segmentation of biomarkers in Home-OCT images in an unsupervised domain adaptation scenario. Our data harmonization approach provides potential for the monitoring of diseases, e.g., age related macular disease, using different OCT devices.},
  keywords={Training;Image segmentation;Optical coherence tomography;Semantics;Biomarkers;Decoding;Image restoration;style transfer;semantic segmentation;domain adaptation;OCT},
  doi={10.1109/ISBI56570.2024.10635513},
  ISSN={1945-8452},
  month={May},}@INPROCEEDINGS{10608377,
  author={Zheng, Qiuhong and Wang, Jinghan and Shen, Yun},
  booktitle={2024 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)}, 
  title={Driveable 3D Human Reconstruction Focusing on Facial Precision Enhancement}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Three-dimensional (3D) digital human reconstruction and driving technologies are increasingly used. The most commonly used method in the field of 3D digital human body reconstruction and driving is based on parameterized models, such as SMPL, which uses parameters to represent the shape of the human body and bone posture, and uses skin algorithms to calculate the skin. However, these algorithms typically do not specifically design and optimize the face region, so reconstruction and driving can cause the loss of facial identity information. This paper proposes a method that combines 3D human body reconstruction and driving methods with 3D facial precision enhancement reconstruction methods. It first reconstructs the human body and face separately from single-view RGB images or videos, and then fuses the human body and face models into a 3D digital human with facial precision enhancement, enabling it to be driven by the actions and expressions of characters in external videos, while maintaining facial identity information unchanged.},
  keywords={Solid modeling;Three-dimensional displays;Shape;Reconstruction algorithms;Skin;Digital humans;Parametric statistics;digital human;body;face;intelligent driven;Skinned Multi-Person Linear (SMPL);3D reconstruction;3D Morphable Model (3DMM)},
  doi={10.1109/BMSB62888.2024.10608377},
  ISSN={2155-5052},
  month={June},}@INPROCEEDINGS{11047769,
  author={Xie, Hongyang and Qiao, Mengyu},
  booktitle={2025 5th International Conference on Artificial Intelligence and Industrial Technology Applications (AIITA)}, 
  title={METCN: A Hybrid TCN-Transformer Architecture for Multimodal Emotion Recognition}, 
  year={2025},
  volume={},
  number={},
  pages={666-669},
  abstract={Emotion recognition is a crucial assessment measure for understanding social skills, emotional intelligence, and mental well-being. Recent advancements in deep learning drive the evolvement of emotion recognition from single-modal analysis to multimodal integration. The paradigm shift brings new challenges: representation unification, cross-modal alignment, and dynamic emotional patterns. This work introduces METCN, a fusion framework employing Temporal Convolutional Networks with multi-scale dilated convolutions to hierarchically capture transient neural spikes and sustained behavioral cues. Furthermore, the proposed framework mitigates cross-modal heterogeneity through dynamic channel-wise adaptation and integrates Transformer-based cross-attention mechanisms to model global dependencies across modalities. By synergizing temporal locality with contextual awareness, the framework achieves superior cross-subject generalization, demonstrating the efficacy of TCN-Transformer architecture for multimodal time series classification and offering promising applications for affective computing in clinical and human-computer interaction systems.},
  keywords={Emotion recognition;Adaptation models;Computational modeling;Time series analysis;Computer architecture;Network architecture;Brain modeling;Transformers;Electroencephalography;Transient analysis;multi-modal fusion;EEG;emotion classification;TCN;transformer;time series},
  doi={10.1109/AIITA65135.2025.11047769},
  ISSN={},
  month={March},}@INPROCEEDINGS{11101420,
  author={Sehgal, Tarun and Kumar, Prashant},
  booktitle={2025 International Conference on Electronics, AI and Computing (EAIC)}, 
  title={Deepfake Dilemma: A Review of GAN-Based Detection for Facial Manipulations}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Deepfakes, or the synthetic media generated by artificial intelligence, pose a serious threat to the authenticity of the information. The fake visual data available on social media poses a significant threat to the users associated with it. In this review, we look into the usage of GANs for the detection of generated content known as deepfakes. Further, we will understand the mathematical functioning of GANs along with the different architectures like cGANs, DCGANs, StarGANs, and StyleGANs. The detection of these deepfakes has been around for a while, so some detection methods are available; we will explore those as well. Also we will look into the deepfake datasets, which are updated over time with growing quantity and quality of samples. To check how well a method works in detecting the deepfake, we have some evaluation metrics, broadly categorised as quantitative and qualitative measures. This review provides a complete overview of the GAN technologies used for deepfake detection of the visual content.},
  keywords={Deepfakes;Visualization;Translation;Reviews;Social networking (online);Computational modeling;Surveillance;Computer architecture;Generative adversarial networks;Real-time systems;Image Synthesis;Anomaly Detection;Generative Adversarial Networks (GANs);Deep Convolutional GANs (DCGANs);Image-to-Image Translation},
  doi={10.1109/EAIC66483.2025.11101420},
  ISSN={},
  month={June},}@INPROCEEDINGS{8395212,
  author={Mohan, Srie Raam and Bukhari, Syed Saqib and Dengel, Andreas},
  booktitle={2018 13th IAPR International Workshop on Document Analysis Systems (DAS)}, 
  title={Layout Error Correction Using Deep Neural Networks}, 
  year={2018},
  volume={},
  number={},
  pages={299-304},
  abstract={Layout analysis, mainly including binarization and text-line extraction, is one of the most important performance determining steps of an OCR system for complex medieval historical document images, which contain noise, distortions and irregular layouts. In this paper, we present a novel text-line error correction technique which include a VGG Net to classify non-text-line and adversarial network approach to obtain the layout bounding mask. The presented text-line error correction technique are applied to a collection of 15th century Latin documents, which achieved more than 75% accuracy for segmentation techniques.},
  keywords={Layout;Training;Generators;Neural networks;Media;Image segmentation;Convolution;Automatic Correction of Layout Analysis Errors;Text Line Segmentation;Deep Neural Network;VGG Net;Historical Document Images},
  doi={10.1109/DAS.2018.61},
  ISSN={},
  month={April},}@INPROCEEDINGS{10848562,
  author={Vo, Chuong Hoang and Thanh Nhat Mai, Truong and Lee, Chul},
  booktitle={2024 Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)}, 
  title={Cloud Removal in Hyperspectral Satellite Images Using Low-rank Tensor Completion}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={We propose an unfolding-based low-rank tensor completion (LRTC) algorithm for cloud removal in hyperspectral satellite images. We first formulate cloud removal as an LRTC-based joint optimization problem, incorporating handcrafted priors for hyperspectral image acquisition and implicit regularization functions to compensate for modeling inaccuracies. We then solve the optimization problem iteratively and develop a multistage deep unfolded network. In this network, each stage corresponds to an iteration of the iterative algorithm in which the optimization variables and regularizers are updated using closed-form solutions and learned deep networks, respectively. Experimental results demonstrate that the proposed algorithm achieves better restoration performance than state-of-the-art algorithms in both quantitative and qualitative comparisons.},
  keywords={Tensors;Closed-form solutions;Information processing;Satellite images;Image restoration;Iterative methods;Optimization;Image reconstruction;Hyperspectral imaging;Synthetic data},
  doi={10.1109/APSIPAASC63619.2025.10848562},
  ISSN={2640-0103},
  month={Dec},}@INPROCEEDINGS{10873123,
  author={Lin, Xue and Ren, Xuejiao},
  booktitle={2024 International Conference on Artificial Intelligence, Deep Learning and Neural Networks (AIDLNN)}, 
  title={Deep Learning Based Content Recognition for News Images and Videos}, 
  year={2024},
  volume={},
  number={},
  pages={83-87},
  abstract={The popularization of mobile Internet represented by 5G has led to the increasing diversification of news content dissemination, and news images and videos have become one of the main carriers of information dissemination. However, the explosive growth in the number of news images and videos makes how to efficiently and accurately recognize their contents a major challenge for the news industry. To this end, this paper delves into deep learning-based content recognition techniques for news images and videos, aiming to ameliorate the intelligence of news content processing. This paper first explores the utilization of deep learning in news image recognition, and realizes the automatic extraction and classification of key information in news images by constructing CNN and other models, which effectively ameliorates the accuracy and efficiency of image recognition. In addition, this paper also studies the design and optimization process of the deep learning model, and finally verifies the effectiveness and superiority of the proposed method. The validation results show that the deep learning-based news image and video content recognition technology can significantly ameliorate the recognition accuracy and provide strong support for the automated processing of news content. In summary, the deep learning-based news image and video content recognition technology proposed in this paper has important theoretical and practical utilization value.},
  keywords={Deep learning;Image recognition;Accuracy;Text recognition;Neural networks;Feature extraction;Robustness;Data mining;Optimization;Videos;Deep Learning;Content Recognition;Images and Videos;News},
  doi={10.1109/AIDLNN65358.2024.00021},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10239995,
  author={Liu, Kun and Yang, Ying and Mao, Jingkun and Liu, Weipeng},
  booktitle={2023 42nd Chinese Control Conference (CCC)}, 
  title={Domain Generalized Solar Cell Defect Segmentation Based on Shape-Aware and Multi-View Meta-Learning}, 
  year={2023},
  volume={},
  number={},
  pages={7861-7865},
  abstract={Various defects are inevitably generated in the manufacturing process of solar cells. Deep learning-based methods for defect segmentation under closed situation have achieved remarkable progress. Due to the difference of imaging condition and camera parameter under different production line, there are large differences in brightness distribution of solar cell images. The model trained under closed situation cannot achieve good performance in opened situation such as multi-production lines. In this paper, a new shape-aware and multi-view meta-learning scheme is proposed to improve the model generalization performance for single-domain solar cell defect segmentation. The scheme roots in gradient-based meta-learning. Multi-brightness view information is yielded from the generated augmented images, and explicitly simulating domain shift with virtual meta-train and meta-test during training to mitigate overfitting in single-source domain train and unstable prediction. Importantly, considering tiny and faint solar cell defects are not easily identified under different image brightness conditions, shape edge constraint loss is proposed to encourage shape compactness and shape smoothness of segmentations. Experimental results show that the proposed method has high segmentation accuracy, which outperforms the state-of-the-art methods.},
  keywords={Metalearning;Training;Image segmentation;Smoothing methods;Shape;Photovoltaic cells;Image edge detection;Solar cell;Domain generalization;Semantic segmentation;Meta-learning},
  doi={10.23919/CCC58697.2023.10239995},
  ISSN={1934-1768},
  month={July},}@INPROCEEDINGS{10864714,
  author={Ye, Zhenghao and Yang, Min and Yang, Lunjin},
  booktitle={2024 China Automation Congress (CAC)}, 
  title={Transformer-based Diffusion Model for Single Image Deblurring}, 
  year={2024},
  volume={},
  number={},
  pages={4444-4448},
  abstract={A Transformer-based diffusion model for single image deblurring is proposed in this paper, which combines diffusion model and transformer block. Specifically, the blurred image is first used as a condition to guide the diffusion model to reverse restore and generate deblurred clean background image. Secondly, a U-shape Spatially Gate Transformer Net for Noise Estimation(USGTN-NE) is proposed, which utilizes blurred image and noisy states to estimate the distribution of noise. Introducing Spatially Adaptive Feature Modulation(SAFM) into the network to capture multi-scale and global information, combined with gate mechanisms to enhance the network's noise prediction capability. The experimental results show that the PSNR index and SSIM index of our proposal are higher than those of other competitors. The subjective quality has also been improved, and the restored images are visually closer to the real situation.},
  keywords={Visualization;Accuracy;Noise;Estimation;Logic gates;Diffusion models;Transformers;Proposals;Noise measurement;Indexes;diffusion model;Transformer;deblur},
  doi={10.1109/CAC63892.2024.10864714},
  ISSN={2688-0938},
  month={Nov},}@INPROCEEDINGS{10511495,
  author={Sharma, Vaishali and Singh, Neetu and Prasad, Rahul and Kalra, Shruti},
  booktitle={2024 11th International Conference on Signal Processing and Integrated Networks (SPIN)}, 
  title={Decoding Image Integrity: A Comprehensive Analysis of YOLOv8’s Performance for Detecting Copy-Move Forgery}, 
  year={2024},
  volume={},
  number={},
  pages={93-98},
  abstract={Copy-move forgery represents a prevalent type of image manipulation wherein a segment of an image is duplicated and inserted into another area within the same image. Its primary intent is to deceive viewers or alter the image’s content. Detecting such alterations is pivotal in upholding the integrity and authenticity of digital images. In this research, we undertook the task of training the YOLOv8 image classification model using our extensive image forensics dataset. Additionally, we leveraged Gradio to develop a user-friendly graphical interface, streamlining the detection process. The proposed methodology unfolds in two distinct phases: the training of the YOLOv8 model and the creation of a user-friendly interface using Gradio. To validate our model’s performance, we conducted training and validation on a combined dataset created from MICC-F220, MICC-F600, and MICC-F2000 datasets. Furthermore, we assessed the model’s generalization capability by subjecting it to the CoMoFoD v2 dataset. The experimental results substantiate the model’s efficacy, revealing an impressive accuracy of 97% with a mere 0.030 error rate, achieved within a concise span of 10 training epochs. These outcomes underscore the practical utility and robustness of our proposed framework.},
  keywords={Training;Analytical models;Image segmentation;Image forensics;Error analysis;Streaming media;Signal processing;Copy-move forgery;forensic analysis;gradio;image forensics;Transfer Learning;YOLO},
  doi={10.1109/SPIN60856.2024.10511495},
  ISSN={2688-769X},
  month={March},}@INPROCEEDINGS{10292120,
  author={Xu, Tao and Duan, Ziyang and Cai, Lei and Chai, Haojie and Zhao, Weishuo},
  booktitle={2022 International Conference on Intelligent Manufacturing and Industrial Big Data (ICIMIBD)}, 
  title={A Pig Carcass Segmentation Line Recognition Algorithm Based on Multi-source Information Fusion}, 
  year={2022},
  volume={},
  number={},
  pages={36-41},
  abstract={The similarity of structural and textural features of various parts of pig carcasses is large. And it is difficult for the existing object detection algorithms to distinguish them effectively. It leads to its difficulty to be applied to pig carcass segmentation robot. In order to solve the problems just mentioned, this paper comes up with a pig carcass segmentation line recognition algorithm based on multi-source information fusion. First, an improved dynamic memory network algorithm is used to fuse image-related off-field features. to obtain richer multiscale feature information. Subsequently, the image salient feature extraction module is constructed by contrast learning. So that the model can better distinguish the feature differences between the object and the background. Finally, the segmentation line is calculated by combining the multi-source sensing information with the pig carcass recognition results. Experimental results on a homemade pig carcass dataset show that. The above algorithm is more productive in the precision of recognition on different parts of pig carcasses compared with the best-in-class object detection algorithm. mAP index is up to 0.734, which is 4.5% higher than the comparison algorithm.},
  keywords={Image segmentation;Fuses;Heuristic algorithms;Object detection;Big Data;Robot sensing systems;Feature extraction;object detection;segmentation line recognition;multi-source information fusion;contrast learning},
  doi={10.1109/ICIMIBD58123.2022.00018},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10588493,
  author={Zhao, Haonan and Wang, Yiting and Bashford-Rogers, Thomas and Donzella, Valentina and Debattista, Kurt},
  booktitle={2024 IEEE Intelligent Vehicles Symposium (IV)}, 
  title={Exploring Generative AI for Sim2Real in Driving Data Synthesis}, 
  year={2024},
  volume={},
  number={},
  pages={3071-3077},
  abstract={Datasets are essential for training and testing vehicle perception algorithms. However, the collection and annotation of real-world images is time-consuming and expensive. Driving simulators offer a solution by automatically generating various driving scenarios with corresponding annotations, but the simulation-to-reality (Sim2Real) domain gap remains a challenge. While most of the Generative Artificial Intelligence (AI) follows the de facto Generative Adversarial Nets (GANs)-based methods, the recent emerging diffusion probabilistic models have not been fully explored in mitigating Sim2Real challenges for driving data synthesis. To explore the performance, this paper applied three different generative AI methods to leverage semantic label maps from a driving simulator as a bridge for the creation of realistic datasets. A comparative analysis of these methods is presented from the perspective of image quality and perception. New synthetic datasets, which include driving images and auto-generated high-quality annotations, are produced with low costs and high scene variability. The experimental results show that although GAN-based methods are adept at generating high-quality images when provided with manually annotated labels, ControlNet produces synthetic datasets with fewer artefacts and more structural fidelity when using simulator-generated labels. This suggests that the diffusion-based approach may provide improved stability and an alternative method for addressing Sim2Real challenges. These insights contribute to the intelligent vehicle community’s understanding of the potential for diffusion models to mitigate the Sim2Real gap.},
  keywords={Image quality;Training;Generative AI;Annotations;Intelligent vehicles;Semantics;Diffusion models;image synthesis;Sim2Real;generative AI;diffusion model},
  doi={10.1109/IV55156.2024.10588493},
  ISSN={2642-7214},
  month={June},}@ARTICLE{10930691,
  author={Zhou, Xingyu and Liang, Le and Zhang, Jing and Jiang, Peiwen and Li, Yong and Jin, Shi},
  journal={IEEE Transactions on Wireless Communications}, 
  title={Generative Diffusion Models for High Dimensional Channel Estimation}, 
  year={2025},
  volume={24},
  number={7},
  pages={5840-5854},
  abstract={Along with the prosperity of generative artificial intelligence (AI), its potential for solving conventional challenges in wireless communications has also surfaced. Inspired by this trend, we investigate the application of the advanced diffusion models (DMs), a representative class of generative AI models, to high dimensional wireless channel estimation. By capturing the structure of multiple-input multiple-output (MIMO) wireless channels via a deep generative prior encoded by DMs, we develop a novel posterior inference method for channel reconstruction. We further adapt the proposed method to recover channel information from low-resolution quantized measurements. Additionally, to enhance the over-the-air viability, we integrate the DM with the unsupervised Stein’s unbiased risk estimator to enable learning from noisy observations and circumvent the requirements for ground truth channel data that is hardly available in practice. Results reveal that the proposed estimator achieves high-fidelity channel recovery while reducing estimation latency by a factor of 10 compared to state-of-the-art schemes, facilitating real-time implementation. Moreover, our method outperforms existing estimators while reducing the pilot overhead by half, showcasing its scalability to ultra-massive antenna arrays.},
  keywords={Channel estimation;Training;Estimation;MIMO;Symbols;Generative AI;Antenna measurements;Antenna arrays;Transmitting antennas;Noise measurement;MIMO channel estimation;deep learning;diffusion models;generative AI},
  doi={10.1109/TWC.2025.3549592},
  ISSN={1558-2248},
  month={July},}@INPROCEEDINGS{11016518,
  author={Dewan, Umama and Hingle, Ashish and McDonald, Nora and Johri, Aditya},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Engineering Educators' Perspectives on the Impact of Generative AI in Higher Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={The introduction of generative artificial intelligence (GenAI) has been met with a mix of reactions by higher education institutions, ranging from consternation and resistance to whole-hearted acceptance. Previous work has looked at the discourse and policies adopted by universities across the U.S. as well as educators, along with the inclusion of GenAI-related content and topics in higher education. Building on previous research, this study reports findings from a survey of engineering educators on their use of and perspectives toward generative AI. Specifically, we surveyed 98 educators from engineering, computer science, and education who participated in a workshop on GenAI in Engineering Education to learn about their perspectives on using these tools for teaching and research. We asked them about their use of and comfort with GenAI, their overall perspectives on GenAI, the challenges and potential harms of using it for teaching, learning, and research, and examined whether their approach to using and integrating GenAI in their classroom influenced their experiences with GenAI and perceptions of it. Consistent with other research in GenAI education, we found that while the majority of participants were somewhat familiar with GenAI, reported use varied considerably. We found that educators harbored mostly hopeful and positive views about the potential of GenAI. We also found that those who engaged more with their students on the topic of GenAI, both as communi-cators (those who spoke directly with their students) and as incorporators (those who included it in their syllabus), tend to be more positive about its contribution to learning, while also being more attuned to its potential abuses. These findings suggest that integrating and engaging with generative AI is essential to foster productive interactions between instructors and students around this technology. Our work ultimately contributes to the evolving discourse on GenAI use, integration, and avoidance within educational settings. Through exploratory quantitative research, we have identified specific areas for further investigation.},
  keywords={Surveys;Resistance;Computer science;Ethics;Generative AI;Shape;Conferences;Distance measurement;Engineering education;Lenses;Generative AI;teaching and research;higher education;engineering education},
  doi={10.1109/EDUCON62633.2025.11016518},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11135215,
  author={Thang, Ha Viet and Vi, Truong Loi},
  booktitle={2025 International Conference on Circuit, Systems and Communication (ICCSC)}, 
  title={AI in the Age of Scientific Saturation: A Survey of How LLMs Rediscover the Obvious}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The accelerating growth of scientific literature has led to a state of scientific saturation in which potentially important connections lie hidden in plain sight. Large Language Models (LLMs) are emerging as powerful tools to rediscover such “obvious” knowledge by mining vast corpora of publications. This paper provides a literature review on the use of LLMs in uncovering overlooked links across disciplines. We first revisit historical efforts in literature-based discovery (LBD). We then examine how modern LLMs have been applied to scientific texts to bridge disconnected research in biomedicine, materials science, education, chemistry, and other domains. Through case studies, we highlight examples where LLMs and related AI methods synthesize established findings into new hypotheses or solutions, effectively re-discovering known information and making it accessible across fields. We discuss the limitations of these models, including their tendency to reproduce existing knowledge without human context or validation. Finally, we outline future directions for integrating LLMs with domain expertise, knowledge graphs, and retrieval systems to enhance scientific innovation.},
  keywords={Surveys;Technological innovation;Materials science and technology;Generative AI;Large language models;Knowledge graphs;Scientific publishing;Integrated circuit modeling;Context modeling;Systematic literature review;Large language models;literature-based discovery;interdisciplinary knowledge;knowledge synthesis;generative AI},
  doi={10.1109/ICCSC66714.2025.11135215},
  ISSN={},
  month={June},}
