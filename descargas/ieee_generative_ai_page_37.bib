@INPROCEEDINGS{10851547,
  author={Stoykova, Stela and Shakev, Nikola},
  booktitle={2024 International Conference Automatics and Informatics (ICAI)}, 
  title={Generative AI-Driven Personnel Training in Industrial Robotics through Intelligent HXM}, 
  year={2024},
  volume={},
  number={},
  pages={228-232},
  abstract={The aim of this paper is to present a developed solution for integrating an AI digital assistant as a service on one of the most widely used ERP platforms – SAP. The digital assistant is based on a popular large language model GPT-2 and has been trained locally on manuals and technical documentation for a Mitsubishi industrial robot as well as a command database for the programming language MELFA Basic V. The main task of the digital assistant is to contribute to the workforce on-boarding and training processes as a human experience management tool. The developed digital assistant service is made freely available via web-browser access to students in its testing stage.},
  keywords={Training;Service robots;Databases;Large language models;Manuals;Documentation;Industrial robots;Personnel;Informatics;Testing;artificial intelligence;ERP;SAP;HXM;GPT;LLM},
  doi={10.1109/ICAI63388.2024.10851547},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10056455,
  author={Hsiao, Ching-Shiuan and Tsai, Jiun-An and Liou, Jung-Shiuan and Chen, Yi-Shin},
  booktitle={2022 International Conference on Technologies and Applications of Artificial Intelligence (TAAI)}, 
  title={Generate Multi-Perspective Summarization with Pairwise Alignment Mechanism}, 
  year={2022},
  volume={},
  number={},
  pages={83-88},
  abstract={Cyberterrorism is often defined as attack using communication networks to cause destruction or generate fear in society to achieve political or ideological goals. Nowadays, due to the accessibility and anonymity, social media has become the breeding grounds for spreading cyberterrorism. To counter cyberterrorism efficiently and effectively, it is critical for the legal enforcement to summarize information on the internet. Particularly, to analyze intelligence comprehensively and make decision without bias, there are multiple perspectives to be considered. However, it remains two challenges to be solved for multi-perspective summarization, which are lacking of annotations and various perspectives with conflicts. To address the challenges, we propose Pairwise Alignment Mechanism and Perspective Consensus Strategy to incorporate different perspectives into the summary. The experiment results show that our methodology can significantly leverage the coverage of multiple perspectives and maintain the consistency of the generated summary.},
  keywords={Social networking (online);Law;Annotations;Cyber terrorism;Communication networks;Artificial intelligence;multi-perspective;generative;summarization},
  doi={10.1109/TAAI57707.2022.00024},
  ISSN={2376-6824},
  month={Dec},}@ARTICLE{10242366,
  author={Hu, Xuemin and Li, Shen and Huang, Tingyu and Tang, Bo and Huai, Rouxing and Chen, Long},
  journal={IEEE Transactions on Intelligent Vehicles}, 
  title={How Simulation Helps Autonomous Driving: A Survey of Sim2real, Digital Twins, and Parallel Intelligence}, 
  year={2024},
  volume={9},
  number={1},
  pages={593-612},
  abstract={Developing autonomous driving technologies necessitates addressing safety and cost concerns. Both academic research and commercial applications of autonomous driving vehicles require extensive simulation and real-world testing. The challenge lies in effectively transferring driving knowledge from the virtual simulation world to the reality world, known as the reality gap (RG). This gap arises due to differences in lighting, textures, vehicle dynamics, and agents' behaviors between the two environments. To address this issue, researchers have explored three main approaches: sim2real, digital twins (DTs), and parallel intelligence (PI) technologies. This article reviews these solutions and examines their applications and innovations in autonomous driving. Furthermore, we delve into the state-of-the-art algorithms, models, and involved simulators, and discuss the developmental process from sim2real to DTs and PI. The presentation also sheds light on the challenges and future perspectives in the development of sim2real, DTs, and PI in the field of autonomous driving.},
  keywords={Autonomous vehicles;Digital twins;Metalearning;Virtual reality;Vehicle dynamics;Autonomous driving;Autonomous driving;sim2real;digital twins;parallel intelligence;reality gap},
  doi={10.1109/TIV.2023.3312777},
  ISSN={2379-8904},
  month={Jan},}@ARTICLE{10772309,
  author={Qian, Zhongsheng and Zhu, Hui and Liu, Jinping and Wan, Zilong},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Harnessing Generative Large Language Models for Dynamic Intention Understanding in Recommender Systems: Insights From a Client–Designer Interaction Case Study}, 
  year={2025},
  volume={12},
  number={2},
  pages={807-817},
  abstract={Generative large language models (GLLMs) have achieved extreme success in the academic community of recommender systems. However, the application of such a powerful tool in the industrial world is still nascent. In Chinese home renovation industry, advisory consultants engage in offline conversations to fully understand the intentions of potential clients before subsequently recommending designers to them. Although conventional recommender systems can somewhat substitute for the consultants, they fall short in addressing two significant challenges. First, clients frequently revise their intentions during conversations, complicating the accurate capture of key intentions. Second, the process of recommending designers, which relies heavily on consultants’ manual efforts, is not only time-consuming but also prone to inaccuracies. To address the challenges, we present a recommendation agent, named DCICDRec, which leverages the robust conversational understanding and generation capabilities of the large language model MOSS. The creation of this agent involves two key steps. The first step is to prepare the corpus from the renovation domain by organizing it into conversational graphs, to which balanced sampling and profile normalization mechanisms are applied. This preparation ensures that the corpus is well-structured and unbiased before proceeding to fine-tune MOSS. The second step is to utilize the fine-tuned MOSS as a recommendation agent. In this capacity, the agent engages in conversations with potential clients and recommends designers, providing detailed reasons for each recommendation. Furthermore, if the client is dissatisfied with the recommended designers, the agent will delve deeper into understanding the client's true intentions and continually update the recommendations until the client is satisfied. We evaluate the agent's effectiveness on a real dialog dataset CRM between clients and consultants, as well as two publicly available datasets, INSPIRED and ReDIAL. Through comprehensive experiments with six baseline models, the DCICDRec agent demonstrate superior performances on the three datasets. Such experimental achievements indicate that the DCICDRec agent holds significant potential for generalization and commercial value. Moreover, the results of case study with 11 offline tests illustrate the scalability and efficiency of the agent in real-time scenarios.},
  keywords={Recommender systems;Oral communication;Business;Industries;Pipelines;Large language models;Biological system modeling;Accuracy;Motion pictures;Knowledge graphs;Client intention;conversational recommender system;designer expertise;generative large language model;MOSS;recommendation agent},
  doi={10.1109/TCSS.2024.3494265},
  ISSN={2329-924X},
  month={April},}@INPROCEEDINGS{10800337,
  author={Hu, Weiyang and Wang, Ge and Sun, Zikai and Cai, Menghuan},
  booktitle={2024 4th International Conference on Electronic Information Engineering and Computer Science (EIECS)}, 
  title={EfficientNetB4-ES: An Enhanced EfficientNetB4 Model for Deepfake Detection}, 
  year={2024},
  volume={},
  number={},
  pages={203-206},
  abstract={Deepfake technology employs deep learning and artificial intelligence to synthesize, modify, or replace image, audio, and video content, thereby creating realistic yet fabricated scenes. As artificial intelligence has progressed, tools like VAE (Variational Autoencoder) and GAN (Generative Adversarial Network) have facilitated the generation of fake images and videos, rendering the detection of such forgeries increasingly challenging due to their growing complexity. Should these technologies be utilized for malicious activities, including identity theft, online fraud, or political manipulation, they could pose a significant threat to societal security. Existing mainstream methods for detecting deep fakes struggle with effectively learning the nuanced features of faces and may yield redundant features during the extraction process. To tackle these challenges, we have introduced a novel EfficientNetB4-ES network model tailored for face detection. The model has yielded superior outcomes in terms of accuracy (ACC) and Area Under the Curve (AUC), resulting in enhanced classification accuracy and more effective detection. Extensive comparative experiments were conducted on the FaceForensics++ datasets, and the results demonstrated that our method surpasses baseline models in the evaluation of real versus fake face detection, affirming the superior performance of our approach in the domain of deepfake face detection.},
  keywords={Deepfakes;Visualization;Accuracy;Termination of employment;Feature extraction;Generative adversarial networks;Rendering (computer graphics);Face detection;Security;Artificial intelligence;Deepfake;EfficientNet;Deep Learning},
  doi={10.1109/EIECS63941.2024.10800337},
  ISSN={},
  month={Sep.},}@ARTICLE{10500411,
  author={Yenduri, Gokul and Ramalingam, M. and Selvi, G. Chemmalar and Supriya, Y. and Srivastava, Gautam and Maddikunta, Praveen Kumar Reddy and Raj, G. Deepti and Jhaveri, Rutvij H. and Prabadevi, B. and Wang, Weizheng and Vasilakos, Athanasios V. and Gadekallu, Thippa Reddy},
  journal={IEEE Access}, 
  title={GPT (Generative Pre-Trained Transformer)— A Comprehensive Review on Enabling Technologies, Potential Applications, Emerging Challenges, and Future Directions}, 
  year={2024},
  volume={12},
  number={},
  pages={54608-54649},
  abstract={The Generative Pre-trained Transformer (GPT) represents a notable breakthrough in the domain of natural language processing, which is propelling us toward the development of machines that can understand and communicate using language in a manner that closely resembles that of humans. GPT is based on the transformer architecture, a deep neural network designed for natural language processing tasks. Due to their impressive performance on natural language processing tasks and ability to effectively converse, GPT have gained significant popularity among researchers and industrial communities, making them one of the most widely used and effective models in natural language processing and related fields, which motivated to conduct this review. This review provides a detailed overview of the GPT, including its architecture, working process, training procedures, enabling technologies, and its impact on various applications. In this review, we also explored the potential challenges and limitations of a GPT. Furthermore, we discuss potential solutions and future directions. Overall, this paper aims to provide a comprehensive understanding of GPT, its enabling technologies, their impact on various applications, emerging challenges, and potential solutions.},
  keywords={Natural language processing;Solid modeling;Artificial intelligence;Surveys;Task analysis;Reviews;Transformers;Generative pre-trained transformer;natural language processing;artificial intelligence},
  doi={10.1109/ACCESS.2024.3389497},
  ISSN={2169-3536},
  month={},}@ARTICLE{10122524,
  author={Eigenschink, Peter and Reutterer, Thomas and Vamosi, Stefan and Vamosi, Ralf and Sun, Chang and Kalcher, Klaudius},
  journal={IEEE Access}, 
  title={Deep Generative Models for Synthetic Data: A Survey}, 
  year={2023},
  volume={11},
  number={},
  pages={47304-47320},
  abstract={A growing interest in synthetic data has stimulated the development and advancement of a large variety of deep generative models for a wide range of applications. However, as this research has progressed, its streams have become more specialized and disconnected from one another. This is why models for synthesizing text data for natural language processing cannot readily be compared to models for synthesizing health records anymore. To mitigate this isolation, we propose a data-driven evaluation framework for generative models for synthetic sequential data, an important and challenging sub-category of synthetic data, based on five high-level criteria: representativeness, novelty, realism, diversity and coherence of a synthetic data-set relative to the original data-set regardless of the models’ internal structures. The criteria reflect requirements different domains impose on synthetic data and allow model users to assess the quality of synthetic data across models. In a critical review of generative models for sequential data, we examine and compare the importance of each performance criterion in numerous domains. We find that realism and coherence are more important for synthetic data natural language, speech and audio processing tasks. At the same time, novelty and representativeness are more important for healthcare and mobility data. We also find that measurement of representativeness is often accomplished using statistical metrics, realism by using human judgement, and novelty using privacy tests.},
  keywords={Data models;Synthetic data;Measurement;Biological system modeling;Analytical models;Training data;Medical services;Artificial intelligence;big data;deep learning;generative models;neural networks;synthetic data;privacy},
  doi={10.1109/ACCESS.2023.3275134},
  ISSN={2169-3536},
  month={},}@ARTICLE{10506809,
  author={Wang, Mini Han and Xing, Lumin and Pan, Yi and Gu, Feng and Fang, Junbin and Yu, Xiangrong and Pang, Chi Pui and Chong, Kelvin Kam-Lung and Cheung, Carol Yim-Lui and Liao, Xulin and Fang, Xiaoxiao and Yang, Jie and Zhou, Ruoyu and Zhou, Xiaoshu and Wang, Fengling and Liu, Wenjian},
  journal={Big Data Mining and Analytics}, 
  title={AI-Based Advanced Approaches and Dry Eye Disease Detection Based on Multi-Source Evidence: Cases, Applications, Issues, and Future Directions}, 
  year={2024},
  volume={7},
  number={2},
  pages={445-484},
  abstract={This study explores the potential of Artificial Intelligence (AI) in early screening and prognosis of Dry Eye Disease (DED), aiming to enhance the accuracy of therapeutic approaches for eye-care practitioners. Despite the promising opportunities, challenges such as diverse diagnostic evidence, complex etiology, and interdisciplinary knowledge integration impede the interpretability, reliability, and applicability of AI-based DED detection methods. The research conducts a comprehensive review of datasets, diagnostic evidence, and standards, as well as advanced algorithms in AI-based DED detection over the past five years. The DED diagnostic methods are categorized into three groups based on their relationship with AI techniques: (1) those with ground truth and/or comparable standards, (2) potential AI-based methods with significant advantages, and (3) supplementary methods for AI-based DED detection. The study proposes suggested DED detection standards, the combination of multiple diagnostic evidence, and future research directions to guide further investigations. Ultimately, the research contributes to the advancement of ophthalmic disease detection by providing insights into knowledge foundations, advanced methods, challenges, and potential future perspectives, emphasizing the significant role of AI in both academic and practical aspects of ophthalmology.},
  keywords={Ethics;Biomarkers;Predictive models;Eye diseases;Prediction algorithms;Data models;Ophthalmology;Artificial Intelligence (AI);Dry Eye Disease (DED) detection;ophthalmology;multi-source evidence},
  doi={10.26599/BDMA.2023.9020024},
  ISSN={2097-406X},
  month={June},}@ARTICLE{9650851,
  author={Makhmudkhujaev, Farkhod and Park, In Kyu},
  journal={IEEE Access}, 
  title={Generative Adversarial Networks With Attention Mechanisms at Every Scale}, 
  year={2021},
  volume={9},
  number={},
  pages={168404-168414},
  abstract={Existing works in image synthesis have shown the efficiency of applying attention mechanisms in generating natural-looking images. Despite the great informativeness, current works utilize such mechanisms at a certain scale of generative and discriminative networks. Intuitively, the increased use of attention should lead to better performance. However, due to memory constraints, even moving a single attention mechanism to a higher scale of the network is infeasible. Motivated by the importance of attention in image generation, we tackle this limitation by proposing a generative adversarial network-based framework that readily incorporates attention mechanisms at every scale of its networks. A straightforward structure of attention mechanism enables direct plugging in a scale-wise manner and trains jointly with adversarial networks. As a result, networks are forced to focus on relevant regions of feature maps learned at every scale, thus improving their own image representation power. In addition, we exploit and show the usage of multiscale attention features as a complementary feature set in discriminator training. We demonstrate qualitatively and quantitatively that the introduction of scale-wise attention mechanisms benefits competitive networks, thus improving the performance compared with those of current works.},
  keywords={Generators;Generative adversarial networks;Image synthesis;Training;Task analysis;Games;Reliability;Image synthesis;generative adversarial networks;attention;multiscale},
  doi={10.1109/ACCESS.2021.3135637},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10771198,
  author={Dasgupta, Dipankar and Roy, Arunava},
  booktitle={2024 Artificial Intelligence for Business (AIxB)}, 
  title={Issues with Generic Large Language Models (GLLMs)}, 
  year={2024},
  volume={},
  number={},
  pages={47-50},
  abstract={Generic Large Language Models (GLLMs) are continuously being released with enhanced size and capabilities, promoting the abilities of these tools for different use. GLLMs excel in text, image, and video generation (assembling, summarizing, translating) with proper queries and prompts. However, the reliability of GLLMs’ responses is questionable in critical applications due to factual inaccuracies, and inappropriate or unrelated responses. Also there remain many open questions on the data collection-privacy, legal and ethical issues. This short report emphasizes the reliability and security aspects of GLLMs while recognizing significant benefits in a wide variety of applications.},
  keywords={Ethics;Law;Large language models;Data models;Reliability;Security;Business;Generative AI;Large Language Models (LLMs);Generative Pre-Trained Models (GPTs);Small Parameterized Data Models (SPDM)},
  doi={10.1109/AIxB62249.2024.00015},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11058829,
  author={Bertgren, Amanda and Öhberg, Fredrik and Soda, Paolo and Näslund, Ulf and Wennberg, Patrik and Grönlund, Christer},
  booktitle={2025 IEEE 38th International Symposium on Computer-Based Medical Systems (CBMS)}, 
  title={Generative Adversarial Networks for Synthetic Longitudinal Electronic Health Records Enabling Cardiovascular Digital Twins}, 
  year={2025},
  volume={},
  number={},
  pages={25-28},
  abstract={The silent progression of cardiovascular disease (CVD) is a major problem particularly in CVD prevention. New techniques enabled by the rise of electronic health records may facilitate CVD prevention. Both public health research and big data applications, such as digital twins, are dependent on access to longitudinal and sensitive data; a challenge which may be facilitated by access to longitudinal synthetic data. In this study, we establish a fidelity benchmark for longitudinal synthetic data by extending a well-known method for cross-sectional synthetic data to a longitudinal application within CVD. We find that the univariate distributional difference between the real and the synthetic data is kept low and that pairwise relations are preserved in the synthetic data. Further, we see that the variablewise temporal trends are preserved, yet may be more extensively studied and have some room for improvement. The results of this study is important to enable future studies within public health prevention and cardiovascular digital twins.},
  keywords={Prevention and mitigation;Benchmark testing;Data collection;Market research;Generative adversarial networks;Digital twins;Cardiovascular diseases;Public healthcare;Electronic medical records;Synthetic data;Synthetic data;digital twins;cardiovascular disease prevention},
  doi={10.1109/CBMS65348.2025.00015},
  ISSN={2372-9198},
  month={June},}@INPROCEEDINGS{10604128,
  author={Long, Min and Zhao, Fang and Zhang, Le-Bing and Duan, Qiangqiang},
  booktitle={2024 5th International Conference on Computer Engineering and Application (ICCEA)}, 
  title={Frequency-spatial Interaction Generative Adversarial Network for Face De-morphing}, 
  year={2024},
  volume={},
  number={},
  pages={67-71},
  abstract={The currently used face recognition systems have been proven to be seriously threatened by face morphing attacks. To counter this challenge, several detection methods have been proposed, with some focusing on restoring the accomplice's facial image. However, these methods are not yet mature enough to achieve high-quality restoration results. In this paper, we propose FSIFD-GAN, a face de-morphing method based on frequency-spatial dual-feature attention separation mechanism. In this method, frequency information is introduced into the face de-morphing research for the first time, and the task of separating accomplice's identity features from morphed images is transferred to frequency domain and spatial domain. FSIFD-GAN uses the attention mechanism to realize the separation operation of frequency and spatial features in two domains respectively, and then uses the frequency-spatial cross-attention operation to realize the interaction of frequency and spatial information, so as to obtain comprehensive accomplice's identity information. Our experiments demonstrate that FSIFD-GAN can effectively restore the accomplice's facial image. This can help to identify the accomplice's identity in criminal investigations and judicial evidence.},
  keywords={Time-frequency analysis;Attention mechanisms;Face recognition;Focusing;Generative adversarial networks;Image restoration;Task analysis;face de-morphing;face morphing attacks;frequency-spatial cross-attention},
  doi={10.1109/ICCEA62105.2024.10604128},
  ISSN={2159-1288},
  month={April},}@ARTICLE{9347460,
  author={Ruff, Lukas and Kauffmann, Jacob R. and Vandermeulen, Robert A. and Montavon, Grégoire and Samek, Wojciech and Kloft, Marius and Dietterich, Thomas G. and Müller, Klaus-Robert},
  journal={Proceedings of the IEEE}, 
  title={A Unifying Review of Deep and Shallow Anomaly Detection}, 
  year={2021},
  volume={109},
  number={5},
  pages={756-795},
  abstract={Deep learning approaches to anomaly detection (AD) have recently improved the state of the art in detection performance on complex data sets, such as large collections of images or text. These results have sparked a renewed interest in the AD problem and led to the introduction of a great variety of new methods. With the emergence of numerous such methods, including approaches based on generative models, one-class classification, and reconstruction, there is a growing need to bring methods of this field into a systematic and unified perspective. In this review, we aim to identify the common underlying principles and the assumptions that are often made implicitly by various methods. In particular, we draw connections between classic “shallow” and novel deep approaches and show how this relation might cross-fertilize or extend both directions. We further provide an empirical assessment of major existing methods that are enriched by the use of recent explainability techniques and present specific worked-through examples together with practical advice. Finally, we outline critical open challenges and identify specific paths for future research in AD.},
  keywords={Deep learning;Principal component analysis;Neural networks;Machine learning;Anomaly detection;Data models;Image reconstruction;Unsupervised learning;Classification;Artificial intelligence;Kernel;Anomaly detection (AD);deep learning;explainable artificial intelligence;interpretability;kernel methods;neural networks;novelty detection;one-class classification;outlier detection;out-of-distribution (OOD) detection;unsupervised learning.},
  doi={10.1109/JPROC.2021.3052449},
  ISSN={1558-2256},
  month={May},}@ARTICLE{9434401,
  author={Sharif, Adnan and Zhai, Guangtao and Min, Xiongkuo and Jia, Jun and Munir, Kashif},
  journal={IEEE Internet of Things Journal}, 
  title={Enhancing Decoding Rate of Barcode Decoders in Complex Scenes for IoT Systems}, 
  year={2021},
  volume={8},
  number={24},
  pages={17495-17507},
  abstract={Camera-based multiclass (1-D and 2-D) barcode detectors that can help in decoding barcodes in different complex scenes have huge potential applications in situations where Internet of Things (IoT) is combined with artificial intelligence (AI) and augmented reality (AR). The decoding rate in such applications under real-life complex scenes is greatly affected by two major factors: first, we cannot accurately localize the barcodes, and second, we cannot decode the blur samples. In this article, we first propose a barcode localization algorithm that is capable of regressing four vertices of barcodes accurately. Our localization method comprises an anchor-free approach that outputs multiscale output prediction maps. These segmentation-like maps of each scale are then further divided into three types of maps (classification, centerness, and 8-D regression). Eight-dimensional localization result of barcodes along with classification result is then obtained after postprocessing. Second, we propose a conditional generative adversarial network-based model for deblurring blur QR codes. Extensive decoding experiments on a challenging complex scene data set show that our localization and deblurring methods can contribute to improving the decoding rate of existing barcode decoders.},
  keywords={Location awareness;Internet of Things;Decoding;Detectors;Feature extraction;Cameras;Object detection;Barcode deblurring;conditional generative adversarial networks (GANs);multiclass barcode detection},
  doi={10.1109/JIOT.2021.3081555},
  ISSN={2327-4662},
  month={Dec},}@ARTICLE{10330097,
  author={Ji, Junzhong and Han, Lu and Wang, Feipeng and Liu, Jinduo},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Dynamic Effective Connectivity Learning Based on Nonparametric State Estimation and GAN}, 
  year={2024},
  volume={73},
  number={},
  pages={1-12},
  abstract={Dynamic effective connectivity (DEC) contains abundant temporal and spatial dynamic information, which can characterize the formation and dissolution of distributed directional functional patterns over time. Recently, learning DEC from functional magnetic resonance imaging (fMRI) time-series data has become a new hot spot in the field of neuroinformatics. However, current DEC learning methods are hard to effectively estimate the transition of brain states and accurately learn the network structure of DEC. In this article, we propose a novel DEC learning method based on nonparametric state estimation and generative adversarial network, named nPSE-GAN. The nPSE-GAN first employs nonparametric state estimation (nPSE) to automatically infer the number of brain states and transition time. In detail, the nPSE uses dual extended Kalman filtering (dEKF) to obtain state features and employs hierarchical clustering to estimate the transition of brain states. Then, the proposed method uses generative adversarial network (GAN) to learn the network structure of DEC. Specifically, GAN takes the transition information and original fMRI time-series data as input, which trains the generator and discriminator simultaneously. The experimental results on simulated datasets show that nPSE-GAN can effectively estimate the transition of brain states and is superior to other state-of-art methods in learning the network structure of DEC. The experimental results on real datasets show that nPSE-GAN can better reveal abnormal patterns of brain activity and has a good application potential in brain network analysis.},
  keywords={Functional magnetic resonance imaging;Generative adversarial networks;State estimation;Brain modeling;Time series analysis;Learning systems;Generators;Dynamic effective connectivity (DEC);functional magnetic resonance imaging (fMRI) time-series data;generative adversarial networks (GANs);state estimation},
  doi={10.1109/TIM.2023.3336748},
  ISSN={1557-9662},
  month={},}@INPROCEEDINGS{10335489,
  author={Mannone, Maria and Turchet, Luca},
  booktitle={2023 4th International Symposium on the Internet of Sounds}, 
  title={Theoretical Quantum Modeling of Improvisation in Networked Music Performances to Regulate the Behaviour of Artificial Musicians}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={During collective musical performances over the network that are characterized by improvisation, a performer may face the problem of what connected musician to follow most in order to direct his/her own improvisation. This choice may be taken on the basis of different factors related to the state of the network and of the kind of the received musical signal. In this paper we investigate the possibility to adopt the mathematical formalism of Quantum Mechanics to describe some interaction phenomena occurring during improvised networked music performances. We propose a decision-making system, having a quantum circuit in its core, where the approximated decision by performers is modeled with state superposition and probability amplitudes used in quantum computing. The model considers the levels of signal clarity (i.e., audio quality related to packet losses), latency, and musical novelty (e.g., melodic or harmonic variation with respect to a previous musical sequence) as the factors that affect the decision of a performer to select another connected performer to follow. This model may be exploited to regulate the behaviour of an artificial intelligent agent playing the role of a virtual musician in the networked ensemble (via generative music techniques). This allows to create mixed human-artificial ensembles and even fully artificial ensembles in networked contexts.},
  keywords={Computational modeling;Music;Quantum mechanics;Packet loss;Harmonic analysis;Mathematical models;Internet;Quantum computing;networked music performances;generative music;artificial agents;Internet of Musical Things},
  doi={10.1109/IEEECONF59510.2023.10335489},
  ISSN={},
  month={Oct},}@INBOOK{10880614,
  author={Sharma, Riya and Singh, Balraj and Khamparia, Aditya},
  booktitle={Generative Artificial Intelligence for Biomedical and Smart Health Informatics}, 
  title={Machine Learning and Generative AI Techniques for Sentiment Analysis with Applications}, 
  year={2025},
  volume={},
  number={},
  pages={183-208},
  abstract={Summary <p>This chapter presents a thorough investigation and examination of machine learning and generative artificial intelligence (AI)&#x2010;based sentiment analysis approaches in the context of social media. As more and more companies use social media platforms for customer involvement and service delivery, it is critical to comprehend the feelings and viewpoints that people are expressing. Although sentiment analysis is a machine learning technique that is skilled in identifying positive and negative sentiment polarities within textual data, due to technological advancements and an increase in the number of data, AI models are becoming popular nowadays. This chapter explores the different approaches used in sentiment analysis, using publications, journals, and scientific research articles. Sentiment analysis can turn an enormous amount of raw data from social media&#x2014;a rich supply of user&#x2010;generated content in a variety of formats, including text, photos, videos, and audio&#x2014;into insightful understandings. To better understand machine learning and generative AI, the study classifies popular research methods and applications from a range of domains.</p>},
  keywords={Sentiment analysis;Social networking (online);Classification algorithms;Unsupervised learning;Lexicon;Training data;Support vector machines;Supervised learning;Probabilistic logic;Principal component analysis},
  doi={10.1002/9781394280735.ch10},
  ISSN={},
  publisher={IEEE},
  isbn={9781394280728},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10880614},}@ARTICLE{10758837,
  author={Li, Wei and Zhang, Mingjun and Li, Wenhao and Wang, Yinghui and Zhang, Xiaowu and Chen, Bin and Ding, Hongwei},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={ASM-GAN: Arbitrary Object Shape Styles Manipulation in Synthesized Images for GANs}, 
  year={2025},
  volume={74},
  number={},
  pages={1-15},
  abstract={Utilizing deep learning-based algorithms to perform vision-based measurement (VBM) tasks is in the ascendant, especially for detecting defectives (i.e., objects in our study) in the industrial product inspection domain. The deep learning algorithms heavily rely on sufficiently labeled defective samples with different shape styles. However, insufficient samples with limited defective shape styles are often the case in many real-world industrial applications. Although existing studies utilize generative models to attempt to manipulate new, arbitrary shape styles, which are never observed in the training samples, of synthesized objects, they have limitations: 1) models that control the representations to manipulate shape styles can cause representation learning failure and 2) approaches discretize representations of objects for manipulating arbitrary object shape styles might bring low generation quality. In this article, we propose a new generation approach, named arbitrary shape manipulation generative adversarial net (ASM-GAN), to address the issues. We utilize the vector quantization (VQ) method to discretely learn the representations extracted by an encoder–decoder, which forms the generator. It helps the model learn the representations of contents (e.g., surroundings, context, and color) of the target objects in original images, then the model makes the synthesized object rendered by those contents after manipulating its shape styles with segmentation. Besides, we innovatively present the Hausdorff metric to make the discrete learning in VQ for improving the generation quality, given that the Kullback–Leibler (KL) divergence adopted by the traditional VQ could be  $\infty $  or 0, which certainly hurts the generation quality. We demonstrate the significant improvement performance of ASM-GAN in synthesizing high-fidelity images with new shape styles for objects over SOTA baseline models from both theoretical and empirical aspects.},
  keywords={Shape;Training;Vectors;Generative adversarial networks;Measurement;Codes;Generators;Vector quantization;Shape measurement;Defect detection;Conditional generative adversarial net (GAN);defect detection;Hausdorff metric;synthesized object shape manipulation;unknown defect generation},
  doi={10.1109/TIM.2024.3502835},
  ISSN={1557-9662},
  month={},}@INPROCEEDINGS{10761175,
  author={Miranda, John Paul and Bansil, Joseph Alexander and Fernando, Emerson and Gamboa, Almer and Hernandez, Hilene and Cruz, Myka and Dianelo, Roque Francis and Gonzales, Dina and Penecilla, Elmer},
  booktitle={2024 2nd International Conference on Technology Innovation and Its Applications (ICTIIA)}, 
  title={Prevalence, Devices Used, Reasons for Use, Trust, Barriers, and Challenges in Utilizing Generative AI among Tertiary Students}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This study examined generative AI usage among Philippine college students particularly on frequency, devices, reasons, knowledge, trust, perceptions, and challenges. Most students used free AI tools on smartphones due to financial constraints. They used it primarily for homework, idea generation, and research. Less than half felt confident with AI and expressed mixed feelings about its accuracy. Barriers included limited access, lack of teacher support, difficulty understanding outputs, and financial constraints. The study highlighted the need for better access, support, training, and ethical guidelines. Broader concerns included impacts on learning, academic standards, job loss, and privacy. Students viewed AI positively due to peer support. Recommendations are discussed.},
  keywords={Training;Technological innovation;Privacy;Ethics;Accuracy;Generative AI;Standards;Smart phones;Guidelines;AI usage;AI tools;AI for learning;accessibility;ChatGPT;higher education;Philippines},
  doi={10.1109/ICTIIA61827.2024.10761175},
  ISSN={},
  month={Sep.},}@ARTICLE{10628027,
  author={Zhang, Ye and Zhang, Jinrui and Yue, Sheng and Lu, Wei and Ren, Ju and Shen, Xuemin},
  journal={IEEE Wireless Communications}, 
  title={Mobile Generative AI: Opportunities and Challenges}, 
  year={2024},
  volume={31},
  number={4},
  pages={58-64},
  abstract={Recently, generative artificial intelligence (GenAI) has gained significant interest on a global scale, particularly with the explosion of some killer GenAl applications, like ChatGPT. However, due to the excessively large sizes of generative models, most current GenAl applications are deployed in the cloud, easily causing high cost, long delay, and potential risk of privacy leakage, thereby greatly impeding GenAl's further expansion and development. In this article, we explore mobile GenAl - deploying large generative models on mobile devices, aiming to bring the GenAl capability to the physical proximity to users. First, we analyze the benefits and opportunities of mobile GenAl in terms of cost, delay, privacy, personalization, and application. Then, we test various large generative models on the mobile testbed, and reveal mobile GenAl's key bottlenecks in inference latency and memory consumption. Accordingly, we propose a weight occupancy strategy for model compression during inference, and discuss the pros and cons thereof. Finally future directions are pointed out to foster continued research efforts.},
  keywords={Privacy;Costs;Generative AI;Memory management;Chatbots;Mobile handsets},
  doi={10.1109/MWC.006.2300576},
  ISSN={1558-0687},
  month={August},}@INPROCEEDINGS{10642512,
  author={Hu, Xuran and Zhu, Mingzhe and Liu, Yuanjing and Feng, Zhenpeng and Stanković, Ljubiša},
  booktitle={IGARSS 2024 - 2024 IEEE International Geoscience and Remote Sensing Symposium}, 
  title={Manifold-Based Shapley for SAR Recognization Network Explanation}, 
  year={2024},
  volume={},
  number={},
  pages={6920-6924},
  abstract={Explainable artificial intelligence (XAI) holds immense significance in enhancing the deep neural network’s transparency and credibility, particularly in some risky and high-cost scenarios, like synthetic aperture radar (SAR). Shapley is a game-based explanation technique with robust mathematical foundations. However, Shapley assumes that model’s features are independent, rendering Shapley explanation invalid for high dimensional models. This study introduces a manifold-based Shapley method by projecting high-dimensional features into low-dimensional manifold features and subsequently obtaining Fusion-Shap, which aims at (1) addressing the issue of erroneous explanations encountered by traditional Shap; (2) resolving the challenge of interpretability that traditional Shap faces in SAR recognization tasks.},
  keywords={Manifolds;Visualization;Sensitivity;Face recognition;Geoscience and remote sensing;Rendering (computer graphics);Mathematical models;synthetic aperture radar;explainable artificial intelligence;shapley explanation},
  doi={10.1109/IGARSS53475.2024.10642512},
  ISSN={2153-7003},
  month={July},}@INPROCEEDINGS{10317774,
  author={Sasiaowapak, Thanyathep and Boonsang, Siridech and Chuwongin, Santhad and Tongloy, Teerawat and Lalitrojwong, Pattarachai},
  booktitle={2023 15th International Conference on Information Technology and Electrical Engineering (ICITEE)}, 
  title={Generative AI for Industrial Applications: Synthetic Dataset}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The research and development of artificial intelligence (AI) techniques to enhance quality control in industrial equipment might face challenges due to the scarcity and limited privacy of actual industrial datasets. One approach to address this involves utilizing generative AI models that create synthetic data, simulating the characteristics and diversity found in crucial datasets. We present a methodology for generating synthetic datasets for industrial products such as bolts and screws by employing a segment-anything model and a stable diffusion technique for creating accurate representations. Furthermore, we propose the developed model by using a scaled-down version of DinoV2 algorithm's vision transformer (ViT-small). The self-supervised learning approach was studied to fine-tune the model to classify between normal- and defective industrial products, as well as those contaminated with dirt. By additional training dataset created through synthesis, we achieve an improvement in performance. The synthetic data leads to nearly perfect true positive results while completely eliminating false negatives. This indicates a significant advantage in terms of accuracy, recall, precision, specificity, and F1 score, all of which exceed 98%. Similarly, the model's predictions align perfectly with the area under the curve (AUC) metric. Although there is a slight performance reduction when dealing with up to six different class labels, the model retains strong capability in identifying normal products. Notably, the ViT-Small-based self-supervised learning model demonstrates superior accuracy compared to using ViT-Base, with considerations for dataset compatibility and model suitability. In conclusion, this study's contribution lies in enabling the deployment of the Dino V2 model for implementing quality control measures in industrial domains. It emphasizes the challenges that limited real-industrial data by leveraging synthetic data and innovative fine-tuning approaches, ultimately enhancing AI-powered for quality control processes.},
  keywords={Training;Visualization;Quality control;Self-supervised learning;Fasteners;Transformers;Robustness;industrial equipment;segment-anything model;stable diffusion;artificial intelligence;self-supervised learning;synthetic dataset},
  doi={10.1109/ICITEE59582.2023.10317774},
  ISSN={2766-0419},
  month={Oct},}@INPROCEEDINGS{10960794,
  author={Sathya, R. and Suganthi, M. and Trisha, M. and Janani, E. and Dhivya, S. and Viswanathan, R.V.},
  booktitle={2025 International Conference on Visual Analytics and Data Visualization (ICVADV)}, 
  title={AI Powered Ayurvedic Leaf Prediction and Disease Classification: A Comprehensive Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={1364-1370},
  abstract={Ayurvedic medicine, a fundamental component of India's traditional healthcare framework, is heavily dependent on the quality and efficacy of medicinal plants. Nevertheless, the medicinal properties of these plants can be adversely affected by diseases stemming from pathogens and environmental factors. This research explores the utilization of artificial intelligence (AI) methodologies, such as deep learning (DL), machine learning (ML), and technologies, for the prompt identification and diagnosis of plant diseases. The review emphasizes recent developments in this field, evaluates their success in disease detection, and pinpoints areas where further research is needed. By merging AI technologies with traditional practices, the integrity of medicinal plants can be preserved, promoting sustainable agricultural practices and improved disease management},
  keywords={Medicinal plants;Deep learning;Plant diseases;Explainable AI;Visual analytics;Environmental factors;Data models;Robustness;Sustainable development;Medical diagnostic imaging;Ayurvedic medicine;ArtificiaL intelligence;plant disease detection;deep learning;sustainability},
  doi={10.1109/ICVADV63329.2025.10960794},
  ISSN={},
  month={March},}@ARTICLE{11083758,
  author={Wang, Xiucheng and Zhang, Qiming and Cheng, Nan and Chen, Junting and Zhang, Zezhong and Li, Zan and Cui, Shuguang and Shen, Xuemin},
  journal={IEEE Transactions on Network Science and Engineering}, 
  title={RadioDiff-3D: A 3D× 3D Radio Map Dataset and Generative Diffusion Based Benchmark for 6G Environment-Aware Communication}, 
  year={2025},
  volume={},
  number={},
  pages={1-18},
  abstract={Radio maps (RMs) serve as a critical foundation for enabling environment-aware wireless communication, as they provide the spatial distribution of wireless channel characteristics. Despite recent progress in RM construction using data-driven approaches, most existing methods focus solely on pathloss prediction in a fixed 2D plane, neglecting key parameters such as direction of arrival (DoA), time of arrival (ToA), and vertical spatial variations. Such a limitation is primarily due to the reliance on static learning paradigms, which hinder generalization beyond the training data distribution. To address these challenges, we propose UrbanRadio3D, a large-scale, high-resolution 3D RM dataset constructed via ray tracing in realistic urban environments. UrbanRadio3D is over 37× larger than previous datasets across a 3D space with 3 metrics as pathloss, DoA, and ToA, forming a novel 3D×3D dataset with 7× more height layers than prior state-of-the-art (SOTA) dataset. To benchmark 3D RM construction, a UNet with 3D convolutional operators is proposed. Moreover, we further introduce RadioDiff-3D, a diffusion-model-based generative framework utilizing the 3D convolutional architecture. RadioDiff-3D supports both radiation-aware scenarios with known transmitter locations and radiation-unaware settings based on sparse spatial observations. Extensive evaluations on UrbanRadio3D validate that RadioDiff-3D achieves superior performance in constructing rich, high-dimensional radio maps under diverse environmental dynamics. This work provides a foundational dataset and benchmark for future research in 3D environment-aware communication. The dataset is available at https://github.com/UNIC-Lab/UrbanRadio3D.},
  keywords={Three-dimensional displays;Solid modeling;Buildings;Benchmark testing;6G mobile communication;Electromagnetics;Real-time systems;Ray tracing;Interpolation;Urban areas;radio map;pathloss;direction of arrival;time of arrival;diffusion model;generative artificial intelligence},
  doi={10.1109/TNSE.2025.3590545},
  ISSN={2327-4697},
  month={},}@INPROCEEDINGS{10381561,
  author={Yang, Hyelim and Wanaskar, Kapil and Shrivastava, Harshika and Mansahia, Shahbaz and Richhariya, Shakshi and Eirinaki, Magdalini},
  booktitle={2023 IEEE Sixth International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)}, 
  title={Prompt Recommendations for AI Art}, 
  year={2023},
  volume={},
  number={},
  pages={62-65},
  abstract={One of the main areas where generative AI models thrive is image synthesis or generation. This work highlights the importance of quality prompts in generating compelling artworks and delves into four principal methodologies for generating prompt recommendations: text embeddings, ensemble models, text with image embeddings and object detection for feature extraction. Multiple traditional and neural network-based models are explored for feature vector representation. Furthermore, the study explores the incorporation of image embeddings, the user’s preferred art styles for tailored recommendations, and the inherent challenges in evaluating these systems. We also propose a novel methodology for evaluating such systems, in the absence of ratings or preference scores, using graph analysis and community detection algorithms. This work distinctly contributes to the prompt recommendation domain and complements previous works in the AI art generation landscape.},
  keywords={Measurement;Knowledge engineering;Art;Image synthesis;Object detection;Feature extraction;Complexity theory;AI Art Generation;Prompt Recommendation System;Text Embeddings;Text-Image Embeddings;Prompt Engineering;Community detection},
  doi={10.1109/AIKE59827.2023.00017},
  ISSN={2831-7203},
  month={Sep.},}@ARTICLE{10813003,
  author={Hao, Guozhi and Pan, Qianqian and Wu, Jun},
  journal={IEEE Internet of Things Journal}, 
  title={Incentive Distributed Knowledge Graph Market for Generative Artificial Intelligence in IoT}, 
  year={2025},
  volume={12},
  number={10},
  pages={13367-13383},
  abstract={Generative artificial intelligence (GAI) models are pretrained using extensive public data. However, in the Internet of Things (IoT) domain, distributed and heterogeneous data from end devices lacks contextual relations, which impairs IoT domain GAI training efficiency and leads to inaccurate applications. Nowadays, knowledge graph (KG) offers an effective solution for enhanced performance and interpretability of GAI. Nevertheless, specific data collection and KG creation in IoT scenarios still pose quality and cost challenges for GAI developers. Therefore, designing an effective IoT KG collection and trading strategy is needed to provide reliable knowledge support for IoT GAI from professional data providers. Currently, establishing fair KG pricing, the effective construction of knowledge relations in edge IoT scenarios and preventing data providers from accessing private information remain significant open issues for IoT KG trading. To address these issues, we propose an incentive distributed IoT knowledge market framework to facilitate effective and secure KG trading for IoT GAI. Specifically, first, we design a utility incentive and GAI demand-driven KG pricing strategy, which establishes a three-layer game with trading participants and KG embedding utility function to obtain fair pricing. Second, we devise a smart contract based distributed knowledge aggregation method, which provides collaborative IoT KG relation creation. Third, we propose a privacy-preserving KG construction scheme via homomorphic encryption that achieves consensus of encrypted KG to prevent knowledge providers from accessing IoT privacy. Finally, experimental results of real KG verify the KG-enhanced GAI and proposed market availability.},
  keywords={Internet of Things;Pricing;Blockchains;Training;Data models;Knowledge graphs;Data collection;Servers;Smart contracts;Privacy;Blockchain;data market;generative artificial intelligence (GAI);Internet of Things (IoT);knowledge graph (KG)},
  doi={10.1109/JIOT.2024.3522191},
  ISSN={2327-4662},
  month={May},}@INPROCEEDINGS{11136300,
  author={Guo, Donghui},
  booktitle={2025 International Conference on Intelligent Computing and Knowledge Extraction (ICICKE)}, 
  title={An Enhanced Evaluation of English Teaching Quality based on Explainable Artificial Intelligence Techniques}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Preserving the quality of English instruction remains a foundation for fostering good language learning and pedagogical superiority in contemporary schools. Nonetheless, current assessment systems tend to be plagued with severe shortcomings, including overdependence on personal judgment, delayed written feedback, low scalability, and low responsiveness to changing teaching environments. These traditional methods are not able to provide real-time feedback, comprehensive assessment, or evidence-based assistance for instructors and administrators, resulting in inconsistent evaluation of teaching and diminished academic achievements. To resolve these issues, this research suggests an innovative Deep Neural Network (DNN)-based smart evaluation system that can automatically handle intricate, high-dimensional educational data to generate precise and comprehensible evaluations of instructional performance. The system architecture suggested includes structured data pre-processing, feature extraction of feedback metrics, academic grades, instructor engagement levels, and behavioral interactions, and then a DNN classifier for prediction. In addition, Explainable AI (XAI) modules such as SHAP (Shaply Additive Explanations) are integrated to visualize and interpret the effect of the important features on the final quality scores, facilitating transparent and actionable feedback. Experimental validation was performed on actual educational datasets, and the model revealed notable improvement in predictability, precision, and stability over conventional evaluation models. The suggested system recorded 98.5% accuracy, 98.3% precision, 98.3% recall, and 98.5% F1-score, indicating its high generalizability and applicability in institutions. This intelligent system provides a robust, data-driven solution to transform English teaching assessment and sets the stage for continued optimization through generative and adaptive models of learning.},
  keywords={Explainable AI;Scalability;Education;Systems architecture;Artificial neural networks;Transforms;Predictive models;Stability analysis;Real-time systems;Optimization;english teaching assessment;deep neural networks;assessment of teacher performance;quality of education;explainable AI;SHAP},
  doi={10.1109/ICICKE65317.2025.11136300},
  ISSN={},
  month={June},}@ARTICLE{11082656,
  author={Hou, Yan and Yang, Shuili and Li, Lixu and Chen, Lujie},
  journal={IEEE Transactions on Engineering Management}, 
  title={Unlocking Environmental Sustainability With Generative Artificial Intelligence: Insights From Resource Orchestration Theory}, 
  year={2025},
  volume={72},
  number={},
  pages={3080-3093},
  abstract={Despite the potential of generative artificial intelligence (GenAI) to unlock environmental sustainability, many firms still struggle to translate this potential into actionable practices. It is imperative to gain a deeper insight into the mechanisms by which GenAI unlocks environmental performance (EP). To tackle this issue, we propose a novel research framework grounded in resource orchestration theory (ROT). Drawing on survey responses from 260 high-tech manufacturing firms in China, we find that resource orchestration capabilities do not independently mediate the GenAI usage–EP relationship but instead require the support of decarbonization capabilities (DCs) to jointly serve as serial mediators. Moreover, environmental dynamism enhances the mediating effect of DCs in the GenAI usage–EP relationship. Our research elucidates the underlying mechanisms and boundary conditions associated with the use of GenAI to achieve environmental sustainability from the perspective of ROT, contributing to the field of technology-enabled management research. Our findings also provide valuable insights to guide firms in their transition towards carbon neutrality.},
  keywords={Green products;Low carbon economy;Discrete cosine transforms;Carbon neutral;Boundary conditions;Training;Technological innovation;Systematics;Surveys;Manufacturing;Decarbonization capabilities;environmental performance (EP);generative artificial intelligence (GenAI) usage;high-tech manufacturing firms;resource orchestration capabilities},
  doi={10.1109/TEM.2025.3586454},
  ISSN={1558-0040},
  month={},}@INPROCEEDINGS{10679470,
  author={Gregory, Jonathan and Liao, Qi},
  booktitle={2024 IEEE International Conference on Cyber Security and Resilience (CSR)}, 
  title={Autonomous Cyberattack with Security-Augmented Generative Artificial Intelligence}, 
  year={2024},
  volume={},
  number={},
  pages={270-275},
  abstract={Ethical hacking and penetration testing is a vital task by cybersecurity professionals to find and exploit possible vulnerabilities in a system before malicious actors do. However, system hacking has a high barrier to entry that necessitates years of experiential learning and formal education. The rapid development of generative artificial intelligence (AI) may potentially lower the barrier to entry. This research experiments with automatic penetration testing via large language models (LLMs) augmented with security information. This research uses a locally hosted Mistral 7B model with Low-Rank Adaptation (LoRA) fine-tuning and Retrieval-Augmented Generation (RAG) to improve penetration testing. When the LLMs are fine tuned with limited and unstructured security data such as privilege escalation articles from a few public web sites, the system succeeds in achieving privilege escalation on Linux hosts. The results of this research suggest that no-cost LLM-assisted penetration testing is possible even on ordinary PCs using locally hosted models. Future research is needed to achieve more diversified attacks and discover zero-day vulnerabilities, perhaps with better prompt engineering, models, and security data.},
  keywords={Adaptation models;Large language models;Linux;Data models;Software;Web sites;Prompt engineering;Cybersecurity;Generative Artificial Intelligence;Machine Learning;Large Language Models;Low-Rank Adaptation;Retrieval-Augmented Generation;Penetration Testing;Hacking;Attacks and Defense;Vulnerability},
  doi={10.1109/CSR61664.2024.10679470},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10568629,
  author={Niranjana, S. and N, Gomathi and Srimathy, G. and Charulatha, G. and Diwakaran, S.},
  booktitle={2024 Ninth International Conference on Science Technology Engineering and Mathematics (ICONSTEM)}, 
  title={Smart Artificial Intelligence Based Face Aging Recognition System Using Modified Hybrid Learning Strategy}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper presents a pioneering approach to face aging recognition, harnessing the synergy of Generative Adversarial Networks (GANs) and Convolutional Neural Networks (CNN) within a Modified Hybrid Learning Strategy (MHLS). Accurate face aging recognition is pivotal across various domains, including law enforcement, entertainment, and healthcare. Traditional methods often struggle with accurately predicting facial changes over time due to challenges such as varying lighting conditions, expressions, and occlusions. The proposed system addresses these challenges by amalgamating GANs to generate lifelike aging progression images and CNNs to extract discriminative features for age classification. The Modified Hybrid Learning Strategy amalgamates supervised and unsupervised learning approaches, enabling the model to glean insights from both labeled and unlabeled data. The GANs module comprises a generator network trained to produce realistic aged face images from input face images and a discriminator network trained to differentiate between real aged images and generated ones. This adversarial training encourages the generator to produce high-fidelity aged face images that closely resemble real ones. The MHLS framework facilitates the concurrent training of the GANs and CNN components, fostering mutual reinforcement and enhancing overall performance. Furthermore, the integration of unsupervised learning via GANs enables the model to learn from extensive amounts of unlabeled data, bolstering its ability to generalize to unseen faces and aging patterns. Experimental results on benchmark datasets showcase the efficacy of the proposed approach, boasting an impressive accuracy rate of 98%.},
  keywords={Training;Accuracy;Face recognition;Aging;Feature extraction;Generators;Data models;Smart Artificial Intelligence;Face Aging Recognition;Modified Hybrid Learning Strategy;MHLS;GANs-CNN Integration},
  doi={10.1109/ICONSTEM60960.2024.10568629},
  ISSN={},
  month={April},}@INPROCEEDINGS{1565717,
  author={Yakhnenko, O. and Silvescu, A. and Honavar, V.},
  booktitle={Fifth IEEE International Conference on Data Mining (ICDM'05)}, 
  title={Discriminatively trained Markov model for sequence classification}, 
  year={2005},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={In this paper, we propose a discriminative counterpart of the directed Markov Models of order k - 1, or MM(k - 1) for sequence classification. MM(k - 1) models capture dependencies among neighboring elements of a sequence. The parameters of the classifiers are initialized to based on the maximum likelihood estimates for their generative counterparts. We derive gradient based update equations for the parameters of the sequence classifiers in order to maximize the conditional likelihood function. Results of our experiments with data sets drawn from biological sequence classification (specifically protein function and subcellular localization) and text classification applications show that the discriminatively trained sequence classifiers outperform their generative counterparts, confirming the benefits of discriminative training when the primary objective is classification. Our experiments also show that the discriminatively trained MM(k - 1) sequence classifiers are competitive with the computationally much more expensive Support Vector Machines trained using k-gram representations of sequences.},
  keywords={Text categorization;Proteins;Artificial intelligence;Laboratories;Computational intelligence;Learning;Computer science;Maximum likelihood detection;Maximum likelihood estimation;Equations},
  doi={10.1109/ICDM.2005.52},
  ISSN={2374-8486},
  month={Nov},}@ARTICLE{10417097,
  author={Bariah, Lina and Debbah, Mérouane},
  journal={IEEE Wireless Communications}, 
  title={The Interplay of AI and Digital Twin: Bridging the Gap between Data-Driven and Model-Driven Approaches}, 
  year={2024},
  volume={31},
  number={3},
  pages={219-225},
  abstract={The evolution of network virtualization and native artificial intelligence (AI) paradigms have conceptualized the vision of future wireless networks as a comprehensive entity operating in whole over a digital platform with smart interaction with the physical domain, paving the way for the blooming of the Digital Twin (DT) concept. The recent interest in the DT networks is fueled by the emergence of novel wireless technologies and use-cases that exacerbate the level of complexity to orchestrate the network and to manage its resources. Driven by AI, the key principle of the DT is to create a virtual twin for the physical entities and network dynamics where the virtual twin will be leveraged to generate synthetic data and offer an on-demand platform for AI model training. Despite the common understanding that AI is the seed for DT, we anticipate that the DT and AI will be enablers for each other in a way that overcomes their limitations and complements each others' benefits. In this article, we dig into the fundamentals of DT, where we reveal the role of DT in unifying model- and data-driven approaches, and explore the opportunities offered by DT in order to achieve the optimistic vision of 6G networks. We further unfold the essential role of the theoretical underpinnings in unlocking further opportunities by AI, and hence, we unveil their pivotal impact on the realization of reliable, efficient, and low-latency DT.},
  keywords={Artificial intelligence;Data models;Training;Wireless networks;Reliability;Computed tomography;Distributed databases;Network function virtualization},
  doi={10.1109/MWC.133.2200447},
  ISSN={1558-0687},
  month={June},}@INPROCEEDINGS{10465380,
  author={Mahajan, Kirti and Madhavidevi, B. and Supreeth, B. R. and SreeRathna Lakshmi, N. V. S. and Joshi, Kireet and Bavankumar, S.},
  booktitle={2023 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES)}, 
  title={Detecting and Responding to Cloud Security Incidents based on AI and Forensic Approach}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={With the use of AI and digital forensics, this paper outlines a complete strategy for handling security incidents in the cloud. The research is meant to improve cloud-based security issue detection and response. The results indicate the promise of this integrated strategy, with AI models improving the accuracy of issue detection and digital forensics speeding incident triage. Improved cloud security, proactive threat detection, optimized resource allocation, and conformity with legal and regulatory standards are only some of the practical consequences discussed in the paper. Advanced AI models, automated incident response, human-machine cooperation, threat intelligence integration, adversarial machine learning, compliance and legal issues, and cross-cloud security are all areas the report suggests further investigation into. In sum, this study aids in developing a more proactive and resilient strategy for handling cloud security incidents in a dynamic digital environment},
  keywords={Cloud computing security;Human-machine systems;Digital forensics;Threat assessment;Adversarial machine learning;Security;Resource management;Incident management;Digital forensics;Cloud security;Artificial Intelligence (AI);Cross-cloud security;Compliance;Adversarial machine learning;Security incident detection;Threat identification;Threat intelligence},
  doi={10.1109/ICSES60034.2023.10465380},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10578588,
  author={Alomar, Ban and Trabelsi, Zouheir and Qayyum, Tariq and Ambali Parambil, Medha Mohan},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={AI and Network Security Curricula: Minding the Gap}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={The ongoing expansion of the digital landscape has led to a growing convergence between the fields of artificial intelligence (AI) and network security. This has necessitated the need for universities to incorporate AI into their network security curriculum. Although traditional network security courses are considered crucial, they lack the agility to address constantly evolving threats. AI offers a transformative solution to such difficulties with its predictive analytics, real-time intrusion detection, and adaptive learning capabilities. This study highlights the importance of incorporating AI into network security curricula at the undergraduate level. A modification to the curriculum is proposed, wherein AI themes are integrated into network security courses and labs. The proposed curricula include understanding theoretical AI concepts and designing AI -augmented hands-on laboratories. The pedagogy emphasizes the tools, and frame-works that facilitate the construction of AI models for intrusion detection, mal ware analysis, and network analytics. This plays a significant importance in providing a simulated environment for students to engage with AI tools and methods to address authentic cyber threats.},
  keywords={Laboratories;Intrusion detection;Network security;Threat assessment;Real-time systems;Artificial intelligence;Task analysis;AI pedagogy;Experiential Learning;Network Security},
  doi={10.1109/EDUCON60312.2024.10578588},
  ISSN={2165-9567},
  month={May},}@ARTICLE{10851279,
  author={Yamaoka, Kanta and Watanabe, Ko and Kise, Koichi and Dengel, Andreas and Ishimaru, Shoya},
  journal={IEEE Access}, 
  title={Img2Vocab: Explore Words Tied to Your Life With LLMs and Social Media Images}, 
  year={2025},
  volume={13},
  number={},
  pages={20456-20471},
  abstract={Psychological studies highlight the importance of combining new knowledge with one’s prior experience. Hence personalization for a learner plays a key role for vocabulary acquisition. However, this faces two challenges: probing a learner’s experiences in their lives and crafting tailored material for every different individual. With the prevalence of visual social media, such as Instagram, people share their photos from favorite moments, providing rich contexts, and emerging generative AI would create learning material in an effortless fashion. We prototyped an online vocabulary exploration system, which displays a learner’s selected photos from their Instagram along with a generated sentence using image recognition and a language model, GPT-3. The system lets a learner find new words that are strongly tied to their daily life with the approximated context. We carried out our within-subject design evaluation of the system with 23 participants with three conditions: contexts grounded with learner’s Instagram photos, contexts grounded from general images, and text-only modality. From learners’ recall task accuracy, we found that having a context grounded with a learner’s social image allowed them to find difficult words to quickly learn than having context generated by someone’s image, or text only modality—although this finding is statistically insignificant. The Zipf frequency comparisons revealed that generally having image-based context allowed learners to extract difficult vocabulary than having text-only context. We also discuss quantitative and qualitative results regarding participants’ acceptance of the personalization system using their personal photos from social media. Generally, they reported positive impressions for our system such as high engagement. While our system prioritizes user privacy with opt-in data control and secure design, we explore additional ethical considerations. This paves the way for a future where personalized language learning, grounded in real-world experiences and generative AI, benefits learners.},
  keywords={Vocabulary;Web sites;Multimedia communication;Social networking (online);Reviews;Translation;Sports;Visualization;Sensors;Generative AI;Context-aware language learning;HCI;large language models;generative AI},
  doi={10.1109/ACCESS.2025.3533076},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10888607,
  author={Guo, Yuzhe and Yang, Zhongliang and Wang, Zhuang and Zhou, Zhili and Zhou, Linna},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={SECC-Stega: Generative Linguistic Steganographic Framework Based on Error Correcting Codes}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={With the rise and maturation of neural network technology, generative text steganography based on language models is gradually becoming the mainstream technique in text steganography. However, homomorphic extraction attacks and text modification attacks from third parties pose serious threats to the usability of generative text steganography. To address this issue, this paper proposes a generative text steganography algorithm framework based on error correction codes. This framework enhances the robustness and security of steganography by encoding the secret information. Experimental results verify that the proposed framework achieves the expected outcomes and exhibits a certain degree of generality.},
  keywords={Steganography;Uncertainty;Speech coding;Signal processing algorithms;Linguistics;Robustness;Error correction codes;Security;Usability;Speech processing;Generative linguistic steganography;Error correcting code;Language model;Robustness},
  doi={10.1109/ICASSP49660.2025.10888607},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10417200,
  author={Wu, Hongyu and He, Yuanfei and Yang, Miaomiao and Zhang, Lixin and Ling, Tong and Wang, Yifei},
  booktitle={2023 2nd International Conference on Artificial Intelligence and Intelligent Information Processing (AIIIP)}, 
  title={Research on Generative Pre-Trained Model Evaluation Based on Causality Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={268-271},
  abstract={At present, generative models have developed to produce creative sentences and widely used in existing applications. Specifically, large language pre-trained models may produce various generative results from different inputs, which can assist users to finish their targets. However, these generative results may obtain unacceptable information caused by illegal and uncontrolled sentences inputs. Inspired by the explainable mechanism for machine learnings, we utilize the causality analysis to investigate the relationships between the generative results and corresponding inputs. Initially, we utilize a sentiment text dataset to pre-trained model and obtain the generative analysis results. Subsequently, we utilize the explainable model to select the words in the dataset, which means these words can significantly influence the generative results of the pre-trained model. Finally, we test the selected words and corresponding sentiment analysis results with traditional classification models and non-selected texts. From our experimental simulations, we can observe that the generative model is sensitive to some certain words, which can significantly improve the sentiment analysis accuracy when only process these sensitive words.},
  keywords={Measurement;Analytical models;Sentiment analysis;Simulation;Cause effect analysis;Machine learning;Probes;Generative Pre-trained Model;Sentiment Analysis;Causality Effects;Explainable Mechanism},
  doi={10.1109/AIIIP61647.2023.00057},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10560079,
  author={Padmaja, T Srinivasa and Basha, Shaik Mahaboob},
  booktitle={2023 IEEE Fifth International Conference on Advances in Electronics, Computers and Communications (ICAECC)}, 
  title={A Comprehensive Review on Steganography Techniques for Text, Images, and Audio}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={In audio steganography, artificial intelligence (AI) can boost system security by improving the accuracy and efficiency of encoding and decoding activities. AI techniques like Convnets, GANs, or generative adversarial networks (CNNs), which may also be taught to optimize the embedding approach to have the least detrimental effect on audio quality, can be used to find the best locations to conceal sensitive information inside an audio recording. Using AI-based sound steganography can provide a greater level of security compared to traditional approaches since it makes the procedure more reliable and unlikely to be discovered. However, difficulties like the need for a significant quantity of training data and the possibility of overfitting must be addressed in order to guarantee reliability and accuracy. Through the creation of an audio steganography technique based on artificial intelligence (AI), this research seeks to increase system security. Reviewing current steganography techniques for text, pictures, and audio and determining their advantages and disadvantages are among the goals of this work. The next step is to build and deploy a new AI-based steganography methodology that can successfully conceal hidden messages in audio signals using machine learning techniques in conjunction with currently used audio steganography techniques. The device will also use an encryption design method to further boost security. We'll evaluate a proposed system's effectiveness and resilience to various assaults, contrasting it with current audio steganography techniques and pointing out any shortcomings. Through the application of sophisticated AI-based steganography techniques, the results of this research will help in the creation of even more secure systems.},
  keywords={Resistance;Steganography;Accuracy;Reviews;System performance;Training data;Robustness;Steganography techniques;Audio steganography;Artificial intelligence (AI);Machine learning;System security},
  doi={10.1109/ICAECC59324.2023.10560079},
  ISSN={2642-6595},
  month={Sep.},}@INPROCEEDINGS{10912427,
  author={Bharamnaikar, Anjana and Gani, Pooja and Kinagi, Somashekhar M. and Sooji, Saarthak and Muttagi, Vijaykumar and Kulkarni, Prathit},
  booktitle={2024 IEEE Conference on Engineering Informatics (ICEI)}, 
  title={Text-to-Image Synthesis for Heritage Monuments Using Generative Adversarial Networks: A Survey}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={India’s architectural heritage, including iconic structures like the temples of the Vijayanagara Empire, faces significant preservation challenges from factors such as wars, neglect, and environmental degradation. Artificial Intelligence (AI) offers innovative solutions for heritage conservation, providing advanced tools for documenting, analyzing, and digitally restoring these cultural assets. Among AI technologies, Generative Adversarial Networks (GANs) stand out for their ability to reconstruct and visualize heritage sites from textual descriptions, enabling digital restoration and preservation. GANs can realistically recreate lost or damaged elements, offering a virtual glimpse into the past that supports both education and awareness. By providing immersive experiences through virtual tours and digital reconstructions, GANs can help raise global awareness about India’s rich architectural legacy, while also engaging local communities in the importance of preservation. This technology allows for interactive exploration, empowering conservationists to make informed decisions that balance historical accuracy with modern conservation needs. Ultimately, GANs play a crucial role in safeguarding India’s architectural heritage for future generations, fostering deeper public understanding and appreciation both locally and globally.},
  keywords={Surveys;Visualization;Accuracy;Layout;Text to image;Generative adversarial networks;Image restoration;Environmental management;Informatics;Image reconstruction;Generative Adversarial Networks (GANs);Heritage Conservation;Indian Digital Heritage Space (IHDS);Text-to-Image Synthesis},
  doi={10.1109/ICEI64305.2024.10912427},
  ISSN={},
  month={Nov},}@ARTICLE{10975024,
  author={Fu, Yang and Qin, Peng and Wang, Yifei and Chen, Liming and Li, Mengyao and Zhao, Xiongwen},
  journal={IEEE Transactions on Communications}, 
  title={Over-the-Air Edge Inference for Low-Altitude Airspace: Generative AI-Aided Multi-Task Batching and Beamforming Design}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={The exploitation of low-altitude (LA) airspace is advancing globally, boosting the sensing demands for heterogenous flying aircraft. To fulfill an accurate and intelligent sensing, the future 6G base station (BS) requires to aggregate features of multiple sensors’ views, then perform edge inference via loading the artificial intelligence (AI) model. However, this process confronts communication and computation bottlenecks owing to high-dimensional feature uploading as well as frequent memory access. To overcome these bottlenecks, we propose a multi-task over-the-air edge inference system for LA airspace, where feature aggregation is efficiently achieved employing over-the-air computation, and multiple inference tasks arriving at the BS are processed in batches to reduce memory access. Under this arrangement, we formulate a joint batching and beamforming design problem to maximize the number of completed tasks, constrained by completion latency and inference accuracy requirements. To address this intractable problem, we first examine the case with synchronous task arrivals and single batch. A spatial correlation-aware beamforming design approach is proposed to effectively suppress feature aggregation error and ensure inference accuracy. Next, we delve into the general asynchronous task arrival case. An AI-generated online policy is developed, which innovatively utilizes diffusion model to output batching decisions, thereby adapting to the dynamic and uncertain nature of task arrivals. Simulation results obtained on real-world dataset corroborate the importance of capturing the spatial correlation among sensors. In addition, the proposed approach realizes outstanding performance compared to benchmark batching, beamforming, and learning methods, and the completed task amount is close to offline optimization with prior task information.},
  keywords={Sensors;Artificial intelligence;Array signal processing;Accuracy;Diffusion models;Sensor phenomena and characterization;Feature extraction;Wireless networks;Resource management;Multitasking;Low-altitude airspace;edge inference;batching;over-the-air computation;multi-antenna beamforming;diffusion model},
  doi={10.1109/TCOMM.2025.3563657},
  ISSN={1558-0857},
  month={},}@ARTICLE{10988607,
  author={Wang, Jianing and Hua, Zheng and Zhang, Wan and Hao, Shengjia and Yao, Yuqiong and Gong, Maoguo},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={CL-BioGAN: Biologically Inspired Cross-Domain Continual Learning for Hyperspectral Anomaly Detection}, 
  year={2025},
  volume={63},
  number={},
  pages={1-15},
  abstract={The memory stability and learning flexibility in continual learning (CL) is a core challenge for cross-scene hyperspectral anomaly detection (HAD) task. Biological neural networks can actively forget history knowledge that conflicts with the learning of new experiences by regulating learning-triggered synaptic expansion and synaptic convergence. Inspired by this phenomenon, we propose a novel biologically inspired CL generative adversarial network (CL-BioGAN) for augmenting continuous distribution fitting ability for cross-domain HAD task, where CL bioinspired loss (CL-Bio Loss) and self-attention generative adversarial network (BioGAN) are incorporated to realize forgetting history knowledge as well as involving replay strategy in the proposed BioGAN. Specifically, a novel bioinspired loss composed with an active forgetting loss (AF Loss) and a CL loss is designed to realize parameters releasing and enhancing between new task and history tasks from a Bayesian perspective. Meanwhile, BioGAN loss with  $L_{2}$ -norm enhances self-attention (SA) to further balance the stability and flexibility for better fitting background distribution for open-scenario HAD (OHAD) tasks. Experimental results underscore that the proposed CL-BioGAN can achieve more robust and satisfying accuracy for cross-domain HAD with fewer parameters and computational cost. This dual contribution not only elevates CL performance but also offers new insights into neural adaptation mechanisms in OHAD task.},
  keywords={Training;Continuing education;History;Biology;Knowledge engineering;Generative adversarial networks;Bayes methods;Hyperspectral imaging;Fitting;Biological system modeling;Active forgetting;continual learning (CL);generative adversarial network (GAN);hyperspectral anomaly detection (HAD)},
  doi={10.1109/TGRS.2025.3561174},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{10137828,
  author={Ma, Zhiqiang and Li, Jinyi and Zhang, Junpeng},
  booktitle={2022 6th Asian Conference on Artificial Intelligence Technology (ACAIT)}, 
  title={Speech Augmentation Using Conditional Generative Adversarial Nets in Mongolian Speech Recognition}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={Aiming at the problem of uneven regional distribution of speech caused by the lack of labeled data in the Mongolian speech data set, this paper proposes a Mongolian speech data augmentation model based on a conditional generation confrontation network. The model uses conditional speech generators and multiple fusion discriminators for adversarial learning, and uses Mongolian text and specified regional features to generate Mongolian speech with specified regional features. The original data set was augmented by using the methods of speech rate perturbation and spectrogram enhancement, and compared with the end-to-end Mongolian speech recognition model trained on different augment data sets and the original data sets, it was found that the word error rate in the end-to-end Mongolian speech recognition model trained on the augment data set of the specified regional characteristics is 3.1%; Compared with the end-to-end Mongolian speech recognition model trained on the original data set, the speech rate disturbance data set, and the spectrogram enhancement data set, the word error rate dropped by 2%, 0.5%, and 0.8%.},
  keywords={Error analysis;Perturbation methods;Speech recognition;Speech enhancement;Data models;Generators;Adversarial machine learning;Data Augmentation;Special Regional;Generative Adversarial Network;Mongolian;Speech Data Set},
  doi={10.1109/ACAIT56212.2022.10137828},
  ISSN={},
  month={Dec},}@INBOOK{10811681,
  author={Zhao, Qiyang and Zou, Hang and Bennis, Mehdi and Debbah, Merouane},
  booktitle={Artificial Intelligence for Future Networks}, 
  title={Semantic Communications}, 
  year={2025},
  volume={},
  number={},
  pages={131-149},
  abstract={Abstract <p>Semantic communication transforms the transmitter and receiver pairs into teacher and student agents, which interact with each other through a semantic representation of the underlying information structure. Such representation must satisfy key properties of minimalism (least sufficient bits), generalizability (across different domains) and efficiency (high fidelity generation). Machine learning plays a key role in semantic communication, where generative artificial intelligence (AI) shows strong capabilities in semantic understanding and reasoning. In this chapter, we provide a holistic view on the role of semantic communication as a powerhouse of native AI networks in 6G and beyond, followed by technical insights into the mathematical theories and technologies of semantic communications leveraging machine learning and generative AI.</p>},
  keywords={Semantic communication;Decoding;Symbols;Receivers;Transmitters;Cognition;Wireless sensor networks;Wireless communication;Reviews;Random variables},
  doi={10.1002/9781394227952.ch4},
  ISSN={},
  publisher={IEEE},
  isbn={9781394227945},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10811681},}@INPROCEEDINGS{10229448,
  author={Zhao, Huanhuan and Chen, Haihua and Yoon, Hong-Jun},
  booktitle={2023 IEEE International Conference On Artificial Intelligence Testing (AITest)}, 
  title={Enhancing Text Classification Models with Generative AI-aided Data Augmentation}, 
  year={2023},
  volume={},
  number={},
  pages={138-145},
  abstract={This study investigated the potential of enhancing the performance of text classification by augmenting the training dataset with external knowledge samples generated by a generative AI, specifically ChatGPT. The study conducted experiments on three models - CNN, HiSAN, and BERT - using the Reuters dataset. First, the study evaluated the effectiveness of incorporating ChatGPT-generated samples and then analyzed the impact of various factors such as sample size, sample variability, and sample length on the models’ performance by varying the number, variety, and length of the generated samples. The models were assessed using macro and micro-averaged scores, and the results revealed that the macro-averaged scores improved significantly across all three models, with the BERT model showing the greatest improvement (from 49.87% to 65.73% in macro F1 score). The study further found that adding 30 distinct samples produced better results than adding 6 duplicates of 5 samples, and samples with 150 and 256 words had similar performance, while those with 50 words performed slightly worse. These findings suggest that incorporating external knowledge samples generated by a generative AI is an effective approach to enhance text classification models’ performance. The study also highlights that the variability of articles generated by ChatGPT positively impacted the models’ accuracy, and longer synthesized texts convey more comprehensive information on the subjects, leading to higher classification accuracy scores. Additionally, we conducted a comparison between our results and those obtained from EDA, a widely used data augmentation generator. The findings clearly demonstrate that our method surpasses EDA and offers additional advantages by reducing computational costs and solving zero-shot problem. Our code is available on GitHub.1},
  keywords={Training;Computational modeling;Text categorization;Machine learning;Data augmentation;Chatbots;Generators;text classification;data augmentation;ChatGPT;imbalanced data;natural language processing;machine learning;artificial intelligence},
  doi={10.1109/AITest58265.2023.00030},
  ISSN={2835-3560},
  month={July},}@INPROCEEDINGS{8987602,
  author={Liu, Qianjun and Ma, Guijun and Cheng, Cheng},
  booktitle={2019 4th International Conference on System Reliability and Safety (ICSRS)}, 
  title={Generative Adversarial Network Based Multi-class Imbalanced Fault Diagnosis of Rolling Bearing}, 
  year={2019},
  volume={},
  number={},
  pages={318-324},
  abstract={Fault diagnosis of rolling bearing plays an important role for the assessment of system reliability. Meanwhile, the number of fault data tend to be much less than the normal data in the real application. This imbalanced problem will greatly reduce the accuracy of most traditional fault diagnosis methods. Especially for the multi-classification problem, some conventional methods can not have good performance on dealing with unbalanced data. In this paper, a method based on generative adversarial network network which generates data for data unbalanced compensation is proposed. This method use designed generator to generate the virtual data which has significant useful features to puzzle the discriminator. Moreover, the virtual data that out-trick the discriminator can be added into the minor dataset. Finally, the classifier based on Convolutional Neurtal Network will dispose the new dataset. In order to verify the effect of this method, experiments based on major methods and proposed method are executed on the CWRU bearing dataset under different loads, which will reduce the correlation of data over time continuity in order to achieve a more realistic fit. Moreover, the proposed method has been compared with several widely applied methods for imbalanced data in fault diagnosis in terms of accuracy. Finally, the comparative results demonstrate that the proposed method has better performance on dealing with the imbalanced problem in fault diagnosis of the rolling bearing than major methods.},
  keywords={Fault diagnosis;Accuracy;Rolling bearings;Generative adversarial networks;Feature extraction;Generators;Safety;Convolutional neural networks;Load modeling;Synthetic data;Generative adversarial network;imbalanced falut diagnosis;data continuity;Convolutional neural network},
  doi={10.1109/ICSRS48664.2019.8987602},
  ISSN={},
  month={Nov},}@ARTICLE{10474191,
  author={Xu, Mengling and Wang, Jie and Tao, Ming and Bao, Bing-Kun and Xu, Changsheng},
  journal={IEEE Transactions on Multimedia}, 
  title={CookGALIP: Recipe Controllable Generative Adversarial CLIPs With Sequential Ingredient Prompts for Food Image Generation}, 
  year={2025},
  volume={27},
  number={},
  pages={2772-2782},
  abstract={Generating food images from recipes is a challenging task in food analysis, as recipes contain lengthy texts far beyond the semantic information in food images, making it difficult to align the features of two modalities. Existing studies usually concatenate the representations of ingredients and cooking instructions directly, and use the concatenated representations to generate food images through generative adversarial networks (GANs). However, previous models generally ignore the sequential information contained in complicated procedural instructions, which leads to semantic inconsistency between recipes and generated food images. Furthermore, it is still difficult for current models to distinguish and control fine-grained features, causing the entangled ingredient features in food images. To this end, we propose CookGALIP, which strengthens semantic consistency and controllability for food image generation. Based on the recently proposed text-to-image framework GALIP, two modules are specially designed. 1) To incorporate the sequential relationships into the food image generation process, we propose a Recipe Fusion Module (RFM) to fuse the semantics of cooking instructions, so as to balance the semantic complexity between modalities and improve the semantic consistency of recipes and generated food images. 2) To distinguish and control the fine-grained ingredient features, we introduce the Ingredient Control Module (ICM) to generate sequential ingredient prompts, which enables more refined control over the recipe-to-food synthesis process. Experimental results on Recipe1M and Vireo Food-172 datasets show that the proposed model outperforms the state-of-the-art methods.},
  keywords={Semantics;Image synthesis;Generative adversarial networks;Generators;Task analysis;Feature extraction;Rails;Recipe-to-food image generation;prompt learning;generative adversarial network},
  doi={10.1109/TMM.2024.3377540},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{10516492,
  author={Qi, Xiaosha and Hu, Zesheng and Ji, Genlin},
  booktitle={2023 Eleventh International Conference on Advanced Cloud and Big Data (CBD)}, 
  title={Retraining Generative Adversarial Autoencoder for Video Anomaly Detection}, 
  year={2023},
  volume={},
  number={},
  pages={63-68},
  abstract={Video anomaly detection is a challenging task that has received increasing attention in the computer vision community. However, most existing methods train the model only once, leading to misclassification of normal frames during testing and a high equal error rate. To address this problem, a novel retraining generative adversarial autoencoder (RGaAE) method is proposed in this paper. Concretely, during testing, misclassified normal frames are retrained by adding them to the training set, and the model is retrained several times to reduce the probability of normal frames being misclassified. Additionly, a regularization function is added to prevent overfitting during training. Experimental results on three publicly available datasets show that our method effectively reduces the probability of normal frames being misclassified during testing, thereby improving the detection accuracy. Compared to state-of-the-art video anomaly detection methods, our approach has shown obvious superiority in equal error rate.},
  keywords={Training;Computer vision;Error analysis;Computational modeling;Big Data;Generative adversarial networks;Generators;video anomaly detection;generative adversarial network;retraining learning},
  doi={10.1109/CBD63341.2023.00020},
  ISSN={},
  month={Dec},}@ARTICLE{11152552,
  author={Ding, Da and Wang, Youquan and Tao, Haicheng and Wu, Jia and Cao, Jie},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={A Dual-Discriminator Generative Adversarial Network for Anomaly Detection}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={Multivariate time series anomaly detection has shown potential in various fields, such as finance, aerospace, and security. The fuzzy definition of data anomalies, the complexity of data patterns, and the scarcity of abnormal data samples pose significant challenges to anomaly detection. Researchers have extensively employed autoencoders (AEs) and generative adversarial networks (GANs) in studying time series anomaly detection methods. However, relying on reconstruction error, the AE-based anomaly detection algorithm needs more effective regularization methods, rendering it susceptible to the problem of overfitting. Meanwhile, GAN-based anomaly detection algorithms require high-quality training data, significantly impacting their practical deployment. We propose a novel GAN based on a dual-discriminator structure to address these issues. The model first processes the data with the generator to obtain the reconstruction error and then calculates pseudo-labels to divide the data into two categories. One data category is input into the first discriminator, where a minor loss between the data and its reconstructed counterpart is better. The other data category is input into the second discriminator, where a larger loss between the data and its reconstructed counterpart is better. Through this process, the model can effectively constrain the generator, retaining information on normal data during data reconstruction while discarding information on abnormal data. After conducting experiments on multiple benchmark datasets, the proposed GAN based on a dual-discriminator structure achieved good results in anomaly detection, outperforming several advanced methods. Additionally, the model also performed well in practical transformer data.},
  keywords={Anomaly detection;Time series analysis;Generative adversarial networks;Training;Image reconstruction;Generators;Classification algorithms;Correlation;Overfitting;Object recognition;Anomaly detection;dual-discriminator structure;generative adversarial networks (GANs);industrial applications;pseudo-labels},
  doi={10.1109/TNNLS.2025.3585978},
  ISSN={2162-2388},
  month={},}@INPROCEEDINGS{10482062,
  author={Yang, Chen and Juanatas, Roben A.},
  booktitle={2023 5th International Conference on Machine Learning, Big Data and Business Intelligence (MLBDBI)}, 
  title={Unidirectional Generative Summary Model with Bidirectional Coding}, 
  year={2023},
  volume={},
  number={},
  pages={131-136},
  abstract={Due to the rapid growth of big data and artificial intelligence technology, the conventional automatic summarizing study has been shifting from abstracted summarization to generated summarization with the goal of offering higher quality, natural, and fluent text summary. The study of generative summaries has made extensive use of deep learning technology in recent years. One of the most popular models in this field is the seq2seq model, which is based on the attention mechanism and has produced impressive results in the summary generation job. Unfortunately, the majority of neural network-based generative abstract models now in use are one-way language models that lack abstract fluency, ambiguity processing, and context awareness. This research suggests a unidirectional generative summary model with bidirectional coding in light of this. The model mixes the two by having the input section have bidirectional language model coding capabilities and the output part retain unidirectional structure. The usefulness and development of the suggested strategy are demonstrated by experiments conducted on the CNewSum Chinese data set.},
  keywords={Deep learning;Context awareness;Big Data;Encoding;Data models;Business intelligence;Context modeling;generative summary;seq2seq One-way language model;Bidirectional language model},
  doi={10.1109/MLBDBI60823.2023.10482062},
  ISSN={2994-2977},
  month={Dec},}@ARTICLE{10301488,
  author={Lan, Guipeng and Xiao, Shuai and Yang, Jiachen and Wen, Jiabao and Xi, Meng},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Generative AI-Based Data Completeness Augmentation Algorithm for Data-Driven Smart Healthcare}, 
  year={2025},
  volume={29},
  number={6},
  pages={4001-4008},
  abstract={In the decade, artificial intelligence has achieved great popularity and applications in medicine and healthcare. Various AI-based algorithms have shown astonishing performance. However, in various data-driven smart healthcare algorithms, the problem of incomplete dataset remains a huge challenge. In this paper, we propose a data completeness enhancement algorithm based on generative AI (i.e., GenAI-DAA) to solve the problems of the in-sufficient data for model training, the data imbalance, and the biases of the training samples. We first construct the cognitive field of the generative models and effectively understand the state of incomplete cognition in generative models. Secondly, on this basis, we propose a quest algorithm for abnormal samples in the cognitive field based on local outlier factor. By fine-grained value evaluation, abnormal samples are given more refined attention. Finally, integrating the above process through multiple cognitive adjustments, GenAI-DAA gradually improves the cognitive ability. GenAI-DAA can be summarized as “Quest $ \longrightarrow$ Estimate$ \longrightarrow$Tune-up”. We have conducted extensive experiments to demonstrate the effectiveness of our proposed algorithm, and shown widely applications to some typical data-driven smart healthcare algorithms.},
  keywords={Data models;Medical services;Image enhancement;Bioinformatics;Training;Cognition;Training data;Generative AI;Data completeness;data-driven;smart healthcare},
  doi={10.1109/JBHI.2023.3327485},
  ISSN={2168-2208},
  month={June},}@INPROCEEDINGS{11035087,
  author={G, Elizabeth Rani and M, Ranjithkumar and Mohamad, Samsath and S, Shabeer Munna},
  booktitle={2025 5th International Conference on Pervasive Computing and Social Networking (ICPCSN)}, 
  title={Harnessing Deepfake Image Detection with Artificial Intelligence Techniques}, 
  year={2025},
  volume={},
  number={},
  pages={1377-1383},
  abstract={Deepfake technology poses significant risks to digital security and misinformation. This study presents a deepfake detection system using advanced deep learning models, including CNNs, ResNet50V2, and Vision Transformers, enhanced with ensemble learning for improved accuracy. The proposed model achieves high precision and generalizability across multiple datasets. All datasets were obtained from Kaggle, adhering to ethical guidelines, with no personally identifiable information collected. The system ensures data security and compliance with licensing terms. Experimental results show improved detection accuracy while maintaining computational efficiency. This research contributes to AI-driven media forensics by providing a scalable solution for deepfake identification.},
  keywords={Deep learning;Deepfakes;Ethics;Accuracy;Computational modeling;Forensics;Data security;Transformers;Real-time systems;Artificial intelligence;Deepfake;Deep Learning;Convolutional Neural Networks (CNNs);ResNet50;Vision Transformers;Image Manipulation},
  doi={10.1109/ICPCSN65854.2025.11035087},
  ISSN={},
  month={May},}@INPROCEEDINGS{10933073,
  author={Dioses, Isaac Angelo M. and Castillo, Wendell and Santiago, Patrick Neil and Geronimo, Marites P. and Macaso, Joel A. and Domingo, Suzette DC.},
  booktitle={2025 21st IEEE International Colloquium on Signal Processing & Its Applications (CSPA)}, 
  title={Performance of ResNet50 in Classifying Artificial Intelligence Generated Arts}, 
  year={2025},
  volume={},
  number={},
  pages={361-366},
  abstract={The increasing prevalence of AI-generated art has sparked debates regarding its authenticity and impact on traditional art. This study evaluates the performance of the ResNet50 deep learning model in classifying images as either AI-generated or non-AI-generated (traditional art). A dataset collected from Kaggle was divided into two categories, and training was conducted using a learning rate of 0.001, a minibatch size of 32, and 20 epochs, with validation occurring every 50 iterations. The model achieved an overall accuracy of 95.45%, with class wise accuracies of 95.82% for Algenerated images and 95.03% for non-AI-generated images. Precision, recall, and F1 scores further confirmed the model's robust performance, with balanced metrics across both classes. The results highlight the effectiveness of ResNet50 in distinguishing between these two forms of art, demonstrating its potential as a tool for addressing controversies related to AI -generated content in art competitions and creative domains. Future research could focus on refining the model's performance by exploring more diverse datasets and advanced architectures. This study contributes to the growing body of research at the intersection of deep learning and creative industries, offering a reliable solution for classifying AI-generated and traditional art.},
  keywords={Deep learning;Training;Art;Accuracy;Subspace constraints;Refining;Predictive models;Reliability;Artificial intelligence;Residual neural networks;ARTS;RESNET50;DEEP LEARNING;CONFUSION MATRIX;CNN},
  doi={10.1109/CSPA64953.2025.10933073},
  ISSN={2836-4090},
  month={Feb},}@ARTICLE{10508482,
  author={Sun, Yeali S. and Chen, Zhi-Kang and Huang, Yi-Ting and Chen, Meng Chang},
  journal={IEEE Security & Privacy}, 
  title={Unleashing Malware Analysis and Understanding With Generative AI}, 
  year={2024},
  volume={22},
  number={3},
  pages={12-23},
  abstract={Dissecting low-level malware behaviors into human-readable reports, such as cyber threat intelligence, is time-consuming and requires expertise in systems and cybersecurity. This work combines dynamic analysis and artificial intelligence-generative transformation for malware report generation, providing detailed technical insights and articulating malware intentions.},
  keywords={Malware;Linux;Object recognition;IP networks;Cyber threat intelligence;Termination of employment;Performance analysis;Generative AI;Content management;Artificial intelligence},
  doi={10.1109/MSEC.2024.3384415},
  ISSN={1558-4046},
  month={May},}@ARTICLE{9729822,
  author={Pranoto, Hady and Heryadi, Yaya and Warnars, Harco Leslie Hendric Spits and Budiharto, Widodo},
  journal={IEEE Access}, 
  title={Recent Generative Adversarial Approach in Face Aging and Dataset Review}, 
  year={2022},
  volume={10},
  number={},
  pages={28693-28716},
  abstract={Many studies have been conducted in the field of face aging, from approaches that use pure image-processing algorithms, to those that use generative adversarial networks. In this study, we review a classic approach that uses a generative adversarial network. The structure, formulation, learning algorithm, challenges, advantages, and disadvantages of the algorithms contained in each proposed algorithm are discussed systematically. Generative Adversarial Networks are an approach that obtains the status of the art in the field of face aging by adding an aging module, paying special attention to the face part, and using an identity-preserving module to preserve identity. In this paper, we also discuss the database used for facial aging, along with its characteristics. The dataset used in the face aging process must have the following criteria: (1) a sufficiently large age group in the dataset, each age group must have a small range, (2) a balanced distribution of each age group, and (3) has enough number of face images.},
  keywords={Aging;Face recognition;Generative adversarial networks;Active appearance model;Deep learning;Data models;Image processing;Face recognition;image generation;image database;face aging dataset;deep generative approach;generative adversarial network},
  doi={10.1109/ACCESS.2022.3157617},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10399148,
  author={Tadi, Mojtaba Jafari and Teuho, Jarmo and Klén, Riku and Lehtonen, Eero and Saraste, Antti and Levin, Craig S.},
  booktitle={2022 IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC)}, 
  title={Synthetic Full Dose Cardiac PET Images from Low Dose Scans Using Conditional GANs}, 
  year={2022},
  volume={},
  number={},
  pages={1-2},
  abstract={Positron emission tomography (PET) is often used to characterize diagnosing cancer, heart diseases, and neurological disorders. Radiation exposure to patients results from the injection of radioactive tracers. Researchers have proposed deploying various artificial intelligence (AI) methods to enhance image quality while reducing radiation dose. Lowering the dose, however, will result in low signal-to-noise-ratio (SNR) and loss of information, thus leading to difficulties with clinical decision making. To address this problem, we evaluated the performance and generalizability of a deep-learning algorithm for improving the quality and accuracy of low dose cardiac PET image quality. Our model structure is based on a conditional generative adversarial neural network (cGAN) including a U-net generator with skip connections and a discriminator. Model training and validations were performed on a low dose PET dataset simulated from a full dose dataset acquired from 40 patient. Low dose cardiac 18F-fluorodeoxyglucose (18F-FDG) PET scans were reconstructed using reduced PET raw data by randomly selecting 5 to 14% of the total events in the PET list mode data. We demonstrate through quantification that the cGAN framework successfully creates synthetic full dose images from low dose scans while preserving the original image resolution with significant noise correction.},
  keywords={Image quality;Training;Neurological diseases;Positron emission tomography;Artificial intelligence;Radiotracer;Signal to noise ratio;Generative Adversarial Networks;Positron Emission Tomography;Noise Correction;Synthetic Full Dose},
  doi={10.1109/NSS/MIC44845.2022.10399148},
  ISSN={2577-0829},
  month={Nov},}@INPROCEEDINGS{11098292,
  author={Chung, Chee Hae},
  booktitle={2025 IEEE International Symposium on Ethics in Engineering, Science, and Technology (ETHICS)}, 
  title={AI and the Rule and Role of Law: Reshaping Legal Regulatory Frameworks to Address Emerging Challenges}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={The rapid proliferation of artificial intelligence (AI) technologies-especially Generative AI and autonomous systems-has fundamentally challenged the foundations of legal governance, raising critical questions about the rule of law and the capacity of regulatory frameworks to ensure legal certainty, accountability, and enforceability. While existing legal scholarship has primarily focused on sector-specific AI regulations and compliance mechanisms, it has largely overlooked the broader implications of AI on legal authority, governance structures, and institutional legitimacy. This study addresses this gap by critically examining how AI disrupts traditional legal paradigms, weakens enforcement mechanisms, and reshapes regulatory authority. It argues that AI's autonomy, algorithmic opacity, transnational reach, and unprecedented scale and speed erode state control over rule-making, overwhelm regulatory institutions, and shift governance power to private AI actors-thereby diminishing democratic accountability. Given these transformations, the study advocates for a reconfiguration of legal regulatory frameworks toward adaptive, participatory, and ethically grounded governance models capable of responding to AI's evolving nature. By bridging legal theory and political science perspectives, this study contributes to the growing discourse on AI governance, offering a theoretical and policy-oriented framework for reasserting the role of law in regulating AI-driven, high-impact decision-making.},
  keywords={Ethics;Adaptation models;Law;Generative AI;Scholarships;Decision making;Regulation;Artificial intelligence;rule of law;AI governance;legal certainty;accountability;enforceability;regulatory challenges},
  doi={10.1109/ETHICS65148.2025.11098292},
  ISSN={2996-3648},
  month={June},}@ARTICLE{10716657,
  author={Hydara, Ebrima and Kikuchi, Masato and Ozono, Tadachika},
  journal={IEEE Access}, 
  title={Empirical Assessment of Deepfake Detection: Advancing Judicial Evidence Verification Through Artificial Intelligence}, 
  year={2024},
  volume={12},
  number={},
  pages={151188-151203},
  abstract={Deepfake technology poses a profound challenge to the integrity of facial evidence in criminal justice, threatening the authenticity and admissibility of such evidence in the courtroom. In this research, a specialized deepfake detection system tailored for facial evidence verification was developed, aiming to counteract the influence of deepfake technology. The proposed system integrates a unique combination of video-frame selection, confidence thresholds, prediction timestamps, and heat maps for individual frames of suspect videos. This methodological fusion is designed to support forensic analysts by enhancing the reliability and trustworthiness of video evidence used in judicial settings. Our comprehensive evaluation involved diverse user groups participating in experimental scenarios to assess the effectiveness of the system. The results indicated that the combined features of the system significantly enhanced the detection of fabricated evidence, fostering high levels of confidence and trust among users. Moreover, this study delves into the legal and ethical considerations surrounding the deployment of deep fake-detection technologies, underscoring the necessity for legal frameworks to evolve in response to emerging digital threats. By addressing both the technical and jurisprudential challenges, this research contributes to safeguarding the evidential value of facial recognition in the judicial process against the disruptive potential of deepfake technologies.},
  keywords={Deepfakes;Forensics;Artificial intelligence;Media;Feature extraction;Face recognition;Law enforcement;Ethics;Termination of employment;Artificial intelligence;criminal justice;deepfake detection;evidence verification;facial evidence},
  doi={10.1109/ACCESS.2024.3480320},
  ISSN={2169-3536},
  month={},}@ARTICLE{11098780,
  author={Boni, Mauro Henrique Lima de and Gervasio Sene Junior, Iwens and Martins da Costa, Ronaldo},
  journal={IEEE Access}, 
  title={Tabular Data Augmentation Using Artificial Intelligence: A Systematic Review and Taxonomic Framework}, 
  year={2025},
  volume={13},
  number={},
  pages={138950-138969},
  abstract={Context: Tabular data predominate in machine learning applications; however, data scarcity, class imbalance, and privacy-related constraints often impair the model performance. Therefore, AI-centric data-synthesis techniques have been adopted to mitigate these challenges. Objective: To systematically map the state of the art in AI-driven tabular-data augmentation, identifying trends, methodological gaps, and best practices. Method: The review followed Kitchenham’s guidelines and covered the ACM Digital Library, Compendex, IEEE Xplore, ScienceDirect, and Scopus for the period 2020–2024. After deduplication and application of the inclusion and exclusion criteria, 55 primary studies were selected and analyzed with respect to the eight research questions. Results: Of the 55 studies, 210 quantitative results were extracted: 70.95% employed utility metrics, and only 7.14% assessed privacy. To organize this heterogeneous landscape, we propose a taxonomic framework: solution type  $\times $  evaluation  $\times $  metric, highlighting gaps and redundancies. Conclusions: Although research has progressed from conventional synthesizers to hybrid and novel architectures, metric standardization and systematic privacy assessments remain limited. Future work should address these gaps and apply fidelity and privacy metrics to underrepresented tasks such as regression problems and ultra-rare-class datasets.},
  keywords={Measurement;Artificial intelligence;Systematic literature review;Synthetic data;Data models;Data privacy;Privacy;Surveys;Libraries;Market research;Artificial intelligence;data-centric AI;data augmentation;tabular data;systematic review},
  doi={10.1109/ACCESS.2025.3593449},
  ISSN={2169-3536},
  month={},}@INBOOK{10951346,
  author={Marr, Bernard},
  booktitle={Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society}, 
  title={A NEW DAWN IN MEDIA AND ENTERTAINMENT}, 
  year={2024},
  volume={},
  number={},
  pages={79-95},
  abstract={Summary <p>Lots of media organizations are thinking about how to leverage GenAI and what the technology means for journalism in the future. As we'll see, GenAI has a lot of potential in journalism, as it can be used to automate the creation of content (particularly for data&#x2010;driven stories and reports), and for other tasks. GenAI has lots of potential to revolutionize sports broadcasting by creating more engaging and personalized content for viewers. GenAI can also foster more collaborative and interactive storytelling &#x2013; meaning writers can create interactive narratives where the storyline progresses based on the reader's choices. A wave of AI&#x2010;powered music generation tools have been released that can create or assist in the creation of music. GenAI music tools could even be used to finalize tracks by dead artists. But even real&#x2010;life stars are experimenting with AI voice generation.</p>},
  keywords={Sports;Fans;Generative AI;Games;Journalism;Companies;Chatbots;Wearable sensors;Vehicles;Data models},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394254255},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951346},}@INBOOK{10950770,
  author={Marr, Bernard},
  booktitle={Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society}, 
  title={REVOLUTIONIZING SOCIETIES AND BUSINESS ECOSYSTEMS}, 
  year={2024},
  volume={},
  number={},
  pages={29-44},
  abstract={Summary <p>GenAI will transform the way we do business. It's no exaggeration to say that every organization must consider what GenAI might mean for its products and services, business processes, and even business model. The subscription model is all about moving from a traditional business model, where the customer buys a product or service as and when they need it, to one where they sign up to receive that product or service on a regular basis. According to Accenture stats, 98% of execs believe GenAI will be essential to their business going forward. Facebook parent company, Meta, is using GenAI to streamline a number of processes. One is Facebook ads, creating tools that allow businesses to automatically make multiple versions of the same ad, featuring different text and images aimed at different audiences. Microsoft Bing was the first to integrate ChatGPT into search capabilities.</p>},
  keywords={Business;Chatbots;Companies;Telecommunications;Generative AI;Translation;Medical services;Ecosystems;Virtual assistants;Software},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394254255},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10950770},}@ARTICLE{9107481,
  author={Chen, Xinyuan and Xu, Chang and Yang, Xiaokang and Tao, Dacheng},
  journal={IEEE Transactions on Image Processing}, 
  title={Long-Term Video Prediction via Criticization and Retrospection}, 
  year={2020},
  volume={29},
  number={},
  pages={7090-7103},
  abstract={Video prediction refers to predicting and generating future video frames given a set of consecutive frames. Conventional video prediction methods usually criticize the discrepancy between the ground-truth and predictions frame by frame. As the prediction error accumulates recursively, these methods would easily become out of control and are often confined to the short-term horizon. In this paper, we introduce a retrospection process to rectify the prediction errors beyond criticizing the future prediction. The introduced retrospection process is designed to look back what have been learned from the past and rectify the prediction deficiencies. To this end, we build a retrospection network to reconstruct the past frames given the currently predicted frames. A retrospection loss is introduced to push the retrospection frames being consistent with the observed frames, so that the prediction error is alleviated. On the other hand, an auxiliary route is built by reversing the flow of time and executing a similar retrospection. These two routes interact with each other to boost the performance of retrospection network and enhance the understanding of dynamics across frames, especially for the long-term horizon. An adversarial loss is employed to generate more realistic results in both prediction and retrospection process. In addition, the proposed method can be used to extend many state-of-the-art video prediction methods. Extensive experiments on the natural video dataset demonstrate the advantage of introducing the retrospection process for long-term video prediction.},
  keywords={Predictive models;Feature extraction;Training;Adaptive optics;Optical imaging;Image reconstruction;Video prediction;generative adversarial networks},
  doi={10.1109/TIP.2020.2998297},
  ISSN={1941-0042},
  month={},}@INPROCEEDINGS{10920845,
  author={Lystbæk, Michael Sahl},
  booktitle={2025 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Text-to-Image Conditional GAN-Based Floor Plan Generator}, 
  year={2025},
  volume={},
  number={},
  pages={0302-0307},
  abstract={To succeed with autonomous design processes within the architectural building design industry, conditional generative models are essential. One significant challenge with large language-image (LLI) models - such as Stable Diffusion, Adobe Firefly, Dall-E, and Midjourney - is their limited contextual understanding within specific design domains. However, precise conditional generation of floor plan designs is needed to unlock the full potential of custom-trained generative models. A custom-trained StyleGAN3 model, combined with a custom-trained captioning model and a translation model, merges the text embedding space with the GAN's latent space to enable text-to-image generation for highly contextual floor plan designs. This generative machine learning application is highly relevant for the early design stage of the architectural design process, enriching conceptual design development with faster, more efficient, and contextually meaningful design suggestions. The proposed framework contributes with a custom-trained text-to-floor plan generator utilizing a fine-tuned bootstrapped language-image pre-training (BLIP) model. Additionally, a comparison with a baseline model using a pre-trained BLIP model demonstrates that the fine-tuned text-to-image generator significantly outperforms the baseline model in accuracy of floor plan generation.},
  keywords={Industries;Translation;Buildings;Pipelines;Layout;Text to image;Machine learning;Generators;Floors;Context modeling;conditional GAN;generative machine learning;architecture;artificial intelligence;real-world data;industrial AI application},
  doi={10.1109/ICAIIC64266.2025.10920845},
  ISSN={2831-6983},
  month={Feb},}@INBOOK{10953267,
  author={Aminzadeh, Fred and Temizel, Cenk and Hajizadeh, Yasin},
  booktitle={Artificial Intelligence and Data Analytics for Energy Exploration and Production}, 
  title={Applications of Machine Learning in Exploration}, 
  year={2022},
  volume={},
  number={},
  pages={213-237},
  abstract={Summary <p>This chapter focuses on machine learning in exploration, focusing on where artificial intelligence (AI) and related methods have been used to better understand the petroleum system. Data from different sources are collected to carry out necessary investigation into the perspectivity of an area for exploration. Several steps such as data processing, data integration and data interpretation/analysis in this phase can benefit from various aspects of AI, machine learning and data analytic (DA). The chapter discusses AI applications in determining exploration risk factors, geophysical data acquisition, processing, and interpretation, exploration and appraisal drilling, geological risk assessment using level of knowledge and experience, as well as use of AI for exploration data integration. Issues include auto&#x2010;picking of first arrivals for micro&#x2010;seismic data, facies analysis, generating gas chimney cube reservoir geostatistical estimation of imprecise information, and fracture zone identification. All these applications discuss one or more AI and DA method and demonstrate how AI&#x2010;DA help improve results.</p>},
  keywords={Rocks;Reservoirs;Oils;Hydrocarbons;Machine learning;Drilling;Three-dimensional displays;Seals;Data analysis;Appraisal},
  doi={10.1002/9781119879893.ch8},
  ISSN={},
  publisher={Wiley},
  isbn={9781119879886},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10953267},}@ARTICLE{10980222,
  author={Zhang, Zherui and Xu, Rongtao and Wang, Changwei and Xu, Wenhao and Chen, Shunpeng and Xu, Shibiao and Xu, Guangyuan and Guo, Li},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={DFMC:Feature-Driven Data-Free Knowledge Distillation}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Data-Free Knowledge Distillation (DFKD) enables knowledge transfer from teacher networks without access to the real dataset. However, generator-based DFKD methods often suffer from insufficient diversity or low-confidence in synthetic images, negatively impacting student network performance. This paper introduces DFMC, a generative feature-driven framework to mitigate the inherent limitations of DFKD. We propose exploiting semantic description between generative feature domains to guide augmentation strategies, avoiding random abstract inputs caused by inconsistent semantic quality. Then, by applying noise to the generative features, we produce contrastive learning pairs indirectly, limiting the sampling range of the feature domain to encourage the student network to learn domain-invariant features. Finally, we guide the student network to deeply mimic the teacher’s layer-wise implicit classification behavior for the augmented synthetic images. Extensive experiments across various datasets and downstream tasks demonstrate the effectiveness of DFMC, achieving significant improvements while preventing student networks from overfitting to semantic ambiguous images.},
  keywords={Semantics;Knowledge engineering;Generators;Contrastive learning;Training;Synthetic data;Noise;Knowledge transfer;Circuits and systems;Diversity methods;Data-Free Knowledge Distillation;Feature Augmentation;Contrastive Learning},
  doi={10.1109/TCSVT.2025.3565616},
  ISSN={1558-2205},
  month={},}@ARTICLE{8957359,
  author={Gao, Rui and Hou, Xingsong and Qin, Jie and Chen, Jiaxin and Liu, Li and Zhu, Fan and Zhang, Zhao and Shao, Ling},
  journal={IEEE Transactions on Image Processing}, 
  title={Zero-VAE-GAN: Generating Unseen Features for Generalized and Transductive Zero-Shot Learning}, 
  year={2020},
  volume={29},
  number={},
  pages={3665-3680},
  abstract={Zero-shot learning (ZSL) is a challenging task due to the lack of unseen class data during training. Existing works attempt to establish a mapping between the visual and class spaces through a common intermediate semantic space. The main limitation of existing methods is the strong bias towards seen class, known as the domain shift problem, which leads to unsatisfactory performance in both conventional and generalized ZSL tasks. To tackle this challenge, we propose to convert ZSL to the conventional supervised learning by generating features for unseen classes. To this end, a joint generative model that couples variational autoencoder (VAE) and generative adversarial network (GAN), called Zero-VAE-GAN, is proposed to generate high-quality unseen features. To enhance the class-level discriminability, an adversarial categorization network is incorporated into the joint framework. Besides, we propose two self-training strategies to augment unlabeled unseen features for the transductive extension of our model, addressing the domain shift problem to a large extent. Experimental results on five standard benchmarks and a large-scale dataset demonstrate the superiority of our generative model over the state-of-the-art methods for conventional, especially generalized ZSL tasks. Moreover, the further improvement of the transductive setting demonstrates the effectiveness of the proposed self-training strategies.},
  keywords={Semantics;Task analysis;Training;Gallium nitride;Visualization;Image reconstruction;Data models;Zero-shot learning;generative model;self-training},
  doi={10.1109/TIP.2020.2964429},
  ISSN={1941-0042},
  month={},}@INPROCEEDINGS{10078574,
  author={Lee, Young-Eun and Kim, Sang-Ho and Lee, Seo-Hyun and Lee, Jung-Sun and Kim, Soowon and Lee, Seong-Whan},
  booktitle={2023 11th International Winter Conference on Brain-Computer Interface (BCI)}, 
  title={Speech Synthesis from Brain Signals Based on Generative Model}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Brain imaging studies of human speech are an active and intriguing research topic that is generating novel ways of communication through human brain signals. Efforts to generate voice from human neural activity have demonstrated the potential based on invasive measurements of speech, but have encountered difficulties in recreating data from imagined speech. Here, we propose NeuroTalk, which non-invasively converts brain signals from spoken and imagined speech to voice. The proposed framework is well-suited for decoding imagined speech, as it was trained on speech EEG data that was generalized to the domain of imagined speech. This means that the voice you hear when you imagine speaking is likely corresponding to the true voice of someone else, as the model has been specifically designed to adjust to this type of speech. Our findings suggest that speech synthesis of human EEG signals is a viable possibility, not just for spoken speech but also for imagined speech. This paper has extensively covered the contents of the paper, Lee et al. at AAAI 2023. Clearly, a high overlap with the above-mentioned contributions is inevitable and deliberate.},
  keywords={Deep learning;Vocoders;Neural networks;Speech recognition;Brain modeling;Speech;Electroencephalography;computer interface;speech synthesis;generative model},
  doi={10.1109/BCI57258.2023.10078574},
  ISSN={2572-7672},
  month={Feb},}@ARTICLE{9399843,
  author={Li, Ziqiang and Tao, Rentuo and Wang, Jie and Li, Fu and Niu, Hongjing and Yue, Mingdao and Li, Bin},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Interpreting the Latent Space of GANs via Measuring Decoupling}, 
  year={2021},
  volume={2},
  number={1},
  pages={58-70},
  abstract={With the success of generative adversarial networks (GANs) on various real-world applications, the controllability and security of GANs have raised more and more concerns from the community. Specifically, understanding the latent space of GANs, i.e., obtaining the completely decoupled latent space, is essential for applications in some secure scenarios. At present, there is no quantitative method to measure the decoupling of latent space, which is not conducive to the development of the community. In this article, we propose two methods to measure the sensitivity of latent dimensions: one is a sequential intervention method, and the other is an optimization-based method that measures the sensitivity in both the value and the direction. With these two methods, the decoupling of latent space can be measured by the sparsity of the sensitivity vector obtained. The effectiveness of the proposed methods has been verified by experiments on the representative GANs. Code will be available at https://github.com/iceli1007/latent-analysis-of.},
  keywords={Gallium nitride;Aerospace electronics;Sensitivity;Extraterrestrial measurements;Artificial intelligence;Interpolation;Generative adversarial networks;Correlation analysis;generative adversarial nets (GANs);interpreting networks;latent space},
  doi={10.1109/TAI.2021.3071642},
  ISSN={2691-4581},
  month={Feb},}@ARTICLE{10681115,
  author={Sun, Yuhang and Dong, Hongli and Chen, Gui and Shang, Yamin and Zhang, Liyan and Liu, Yang},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Seismic PP-Wave AVO Inversion Method for VTI Media Based on Double Discriminator Conditional Generative Adversarial Networks}, 
  year={2024},
  volume={62},
  number={},
  pages={1-21},
  abstract={Elastic parameters play pivotal roles in geophysics, with seismic amplitude variation with offset (AVO) inversion being a common method for obtaining the parameters. In contrast to isotropic media, vertical transversely isotropic (VTI) media, which introduce anisotropic parameters to describe geological characteristics, align more closely with field strata. Conducting AVO inversion based on VTI media enhances the accuracy of inverted parameters. Conventional AVO inversion methods typically rely on low-frequency parameters or training samples, which are often generated from well-log data. However, well-log data are usually insufficient, and obtaining accurate anisotropic parameters from well-log data is challenging. These hinder the generation of low-frequency anisotropic parameters or the creation of training samples with anisotropic parameters as labels, thus impacting the accuracy of inverted parameters for VTI media. Addressing these challenges, we construct a double discriminator conditional generative adversarial network (DDCGAN) models under the constraints of the convolution model theory. Building upon the foundation, we propose a seismic AVO inversion method tailored for VTI media. The DDCGANs combine the conditional generative adversarial networks (CGANs), which have superior feature extraction ability, with the well-established convolution model theory, making it suitable for addressing AVO inversion challenges in VTI media. Iterative optimization of the constructed DDCGANs is achieved by building combined loss functions, including errors of elastic parameters and seismic data. Trial calculations using model and field data demonstrate that the proposed method can improve the accuracy of inverted parameters compared to conventional AVO inversion methods, showcasing its feasibility, advancement, and practicality.},
  keywords={Mathematical models;Media;Anisotropic;Accuracy;Training;Generators;Geoscience and remote sensing;Anisotropic parameters;neural networks;seismic amplitude variation with offset (AVO) inversion;vertical transversely isotropic (VTI) media},
  doi={10.1109/TGRS.2024.3462098},
  ISSN={1558-0644},
  month={},}@INBOOK{11062537,
  author={Kumar, Rishi},
  booktitle={Winning the AI Arms Race: Defeating China and Russia, Re-establishing American Superpower for Global Prosperity and the Greater Good with Artificial Intelligence}, 
  title={3 The Arrival of Generative AI}, 
  year={2025},
  volume={},
  number={},
  pages={13-24},
  abstract={Rishi Kumar offers an insightful and compelling exploration of how artificial intelligence is set to shape America&#x2019;s future and its standing on the global stage with "Winning the AI Arms Race &#x2013; Defeating China and Russia, Re-establishing American Superpower for Global Prosperity and the Greater Good with Artificial Intelligence." With his extensive experience as an award-winning Silicon Valley C-suite executive, a former congressional candidate, an executive board member of the state party, and an elected leader in his city, Kumar brings a visionary yet grounded perspective on leveraging AI&#x2019;s transformative potential. His unique expertise in technology, public policy, and public service allows him to present strategies that could significantly influence national and global advancements in AI. The book is structured around three pivotal themes: strengthening and safeguarding America&#x2019;s superpower status, countering the threats posed by malicious actors, and harnessing AI for the greater global good. This book is essential reading for policy makers navigating the complexities of AI&#x2019;s future and business leaders aiming to position themselves for success in the AI-driven world. It&#x2019;s an indispensable resource for anyone looking to understand and influence the future of AI.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788743800880},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11062537},}@ARTICLE{9751719,
  author={Chaudhuri, Arjun and Talukdar, Jonti and Su, Fei and Chakrabarty, Krishnendu},
  journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems}, 
  title={Functional Criticality Analysis of Structural Faults in AI Accelerators}, 
  year={2022},
  volume={41},
  number={12},
  pages={5657-5670},
  abstract={The ubiquitous application of deep neural networks (DNNs) has led to a rise in demand for artificial intelligence (AI) accelerators. For example, the tensor processing unit from Google–based on a systolic array–and its variants are of considerable interest for DNN inferencing using AI accelerators. This article studies the problem of classifying structural faults in such an accelerator based on their functional criticality. We first analyze pin-level faults in the processing elements (PEs) of a systolic array. Simulation results for the LeNet network with 8-bit fixed-point, 16-bit floating-point (FP), and 32-bit FP data paths applied to the MNIST dataset show that over 93% of the pin-level structural faults in a PE are functionally benign. We present a greedy iterative framework for determining the criticality of stuck-at faults in a PE netlist and analyze the limitations of criticality analysis methods based on repeated fault simulations. We next present a scalable two-tier machine-learning (ML)-based method to assess the functional criticality of stuck-at faults in a computationally efficient manner. We address the problem of minimizing misclassification by utilizing generative adversarial networks (GANs). Two-tier ML/GAN-based criticality assessment leads to less than 1% test escapes during functional criticality evaluation of structural faults.},
  keywords={Circuit faults;Systolic arrays;AI accelerators;Generative adversarial networks;Deep learning;Artificial intelligence (AI) accelerator;binary classification;catastrophic faults;deep learning;defect screening;functional criticality;generative adversarial network (GAN);greedy fault-dropping;stuck-at faults;systolic array;test escape;two-tier framework},
  doi={10.1109/TCAD.2022.3166108},
  ISSN={1937-4151},
  month={Dec},}@ARTICLE{10720129,
  author={Wang, Ziqi and Yang, Chao and Mao, Shiwen},
  journal={IEEE Internet of Things Journal}, 
  title={AIGC for RF-Based Human Activity Sensing}, 
  year={2025},
  volume={12},
  number={4},
  pages={3991-4005},
  abstract={Radio frequency (RF) sensing has been considered as an effective approach to human perception of nonintrusive and high-privacy scenarios. However, the existing wireless sensing techniques mostly rely on extensive labeled RF sensing data for offline training, while wireless sensory data collection is highly time consuming and costly. To ridge this gap, we investigate the problem of generalized dataset augmentation with an artificial intelligence (AI) generated content (AIGC) approach, termed RF-AIGC, for wireless sensing, which can not only purposefully generate new RF sensing data but reduce the data collection cost by augmenting a limited training dataset with synthesized RF data. We propose a conditional recurrent generative adversarial network (termed RF-CRGAN) to generate labeled synthetic RF data for specified human activities for multiple wireless sensing platforms, such as WiFi, radio-frequency identification (RFID), and millimeter wave (mmWave) radar. We also propose a holistic quantitative method to help evaluate and explain the effects of the synthesized data. The experimental results demonstrate that the proposed approach can effectively enhance the diversity of training data and achieve similar performance as real data.},
  keywords={Radio frequency;Sensors;Human activity recognition;Millimeter wave communication;Wireless communication;Three-dimensional displays;Training;Radiofrequency identification;RF signals;Generative adversarial networks;3-D human pose estimation;artificial intelligence generated content (AIGC);data augmentation;generative adversarial network (GAN);radio frequency (RF) sensing},
  doi={10.1109/JIOT.2024.3482256},
  ISSN={2327-4662},
  month={Feb},}@INPROCEEDINGS{10544998,
  author={Kose, Utku and Deperlioglu, Omer and Kucuksille, Ecir Ugur and Turan, Gokhan},
  booktitle={2024 International Conference on Inventive Computation Technologies (ICICT)}, 
  title={Combining Deep Learning Models for Improved Drug Repurposing: Advancements and an Extended Solution Methodology}, 
  year={2024},
  volume={},
  number={},
  pages={238-244},
  abstract={Nowadays, major advancements through Artificial Intelligence (AI) were led by Deep Learning-based solutions. Considering their robust and extensive data processing mechanisms, Deep Learning (DL) models ensure great role in advancing solutions for real-world problems. Especially medical applications have been significantly improved by research studies as a result of intensive DL synergy. At this point, drug discovery has been one of the most remarkable fields where DL has been used in especially last few years. In the context of drug discovery studies, drug repurposing has a unique place to enable known drugs to be used for different diseases. As this is a remarkable way of optimizing discovery and treatment phases, use of DL for drug repurposing applications has still open areas to go. Objective of this paper is to examine the potential of combined DL models for improving drug repurposing and introduce a solution methodology, which includes use of multiple DL models to build a decision support system. It has been also aimed to support the system with computational models and Generative AI route to extend the capabilities towards a Digital Twin related approach.},
  keywords={Drugs;Deep learning;Generative AI;Computational modeling;Precision medicine;Medical services;Data models;Deep Learning;Drug Repurposing;Generative Artificial Intelligence;Computational Models},
  doi={10.1109/ICICT60155.2024.10544998},
  ISSN={2767-7788},
  month={April},}@INPROCEEDINGS{10850853,
  author={Balara, V. and Machová, K.},
  booktitle={2024 International Conference on Emerging eLearning Technologies and Applications (ICETA)}, 
  title={Detection of Artificially Created Faces with Convolutional Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The automatic detection of artificially generated content presents one of the most current topics in the field of artificial intelligence. It may help disguise deceitful users, spread misinformation or help in the dissemination of false accusations and therefore it is may prove vital in terms of teaching and improving the information literacy at schools,public institutions or general public. The automatic recognition of various forms of toxicity and artificially created faces in online space can help teachers to teach an information literacy and a critical thinking.This paper focuses on the detection of artificially generated faces depicted on still images with the utilization various types of convolutional neural networks.The paper presents an experiment aimed at multitude of methods which share the same convolutional basis. The focus is the creation of a efficient tool for image classification, which for our purposes was conducted with the use of ResNet, DenseNet and VGG architectures.},
  keywords={Image recognition;Toxicology;Social networking (online);Computational modeling;Large language models;Computer architecture;Convolutional neural networks;Security;Faces;Image classification;convolutional neural networks;deepfake detection;deep learning},
  doi={10.1109/ICETA63795.2024.10850853},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10774526,
  author={Jin, Tianmei and Zhang, Jiayi},
  booktitle={2024 IEEE 22nd International Conference on Industrial Informatics (INDIN)}, 
  title={Generating Adaptive Robotic Behaviours via Enhanced Diffusion Policy}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={While manual robot programming has been effective for many applications, fixed coding poses several challenges. Robot programming requested sophisticated and dynamic behaviours while increasing the complexity of the robot's tasks. Generative artificial intelligence models have revolutionised robot behaviour generation in dynamic environments to complete different tasks. This paper explores different approaches to robot behaviour generation evaluating their effectiveness, challenges, and potential implications for real-world robotic scenarios. An enhanced diffusion policy is proposed to mitigate anomalous behaviours in the original model. The results demonstrate the importance of training dataset quality and model adaptation to specific working environments in achieving successful robotic behaviours. The Resilient Diffusion solved unusual behaviour problems, improved the resilience capability of diffusion policy, and achieved a higher success rate.},
  keywords={Training;Adaptation models;Service robots;Generative AI;Manuals;Encoding;Dynamic programming;Informatics;Robot programming;Resilience;Generative Artificial Intelligence;Enhanced Diffusion Policy;Vision-based Control Introduction},
  doi={10.1109/INDIN58382.2024.10774526},
  ISSN={2378-363X},
  month={Aug},}@INPROCEEDINGS{10800670,
  author={Zhou, Tingxiao and Zhang, Leying and Qian, Yanmin},
  booktitle={2024 IEEE 14th International Symposium on Chinese Spoken Language Processing (ISCSLP)}, 
  title={Knowledge Distillation from Discriminative Model to Generative Model with Parallel Architecture for Speech Enhancement}, 
  year={2024},
  volume={},
  number={},
  pages={179-183},
  abstract={Generative speech enhancement methods, especially diffusion methods, have recently gained attention. However, current generative methods face several unresolved issues, such as lagging performance compared to discriminative methods on conventional enhancement metrics and slower inference speeds. In order to address these challenges, we propose a knowledge distillation approach from discriminative to generative models, and we design a parallel architecture with a latent vector fusion module to leverage their respective strengths. We conduct experiments and ablation studies on the LibriMix dataset to validate its effectiveness. The results demonstrate that our approach substantially improves performance over baseline systems in terms of speech quality and inference speed.},
  keywords={Measurement;Speech enhancement;Vectors;Parallel architectures;Faces;speech enhancement;generative model;knowledge distillation},
  doi={10.1109/ISCSLP63861.2024.10800670},
  ISSN={},
  month={Nov},}@ARTICLE{11168460,
  author={Wang, Yaodong and Zuo, Yiping and Chen, Dan and Zomaya, Albert Y. and Ranjan, Rajiv and Chen, Jingying and Gao, Tengfei},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Counterfactual Causal Inference of Biomedical Signals: Unveiling Causal EEG Patterns for ASD Evaluation}, 
  year={2025},
  volume={},
  number={},
  pages={1-15},
  abstract={The examination of complex diseases has greatly benefited from machine-learning techniques for interpreting biomedical signals. However, for diseases with multifactorial etiologies, such as Autism Spectrum Disorders (ASD), the inability of associative methods to distinguish between causal relationships and mere correlations often leads to unreliable outcomes. In contrast, causal models require well-defined causal structures, demanding a thorough understanding of their contributing factors. This study proposes a Generative Adversarial Network framework for Counterfactual Causal Inference (C2I-GAN) to uncover causal patterns from biomedical signals without a predefined causal structure. The framework leverages graph attention network to identify key features for directing counterfactual generation, applies generative adversarial learning to produce task-oriented counterfactuals, and supports inference by evaluating how modifications to specific features affect diagnostic outcomes. A case study of ASD evaluation is conducted on a resting-state EEG dataset (74 ASD and 143 TD children) using C2I-GAN against state-of-the-art methods (Associative: GAT; Counterfactual: CounteRGAN, Omnixai, and CXGAN). The findings show that C2I-GAN identified T3, T4, O1, and O2 channels as causal patterns while recognizing C3 and C4 as merely associative, aligning with the latest neuroscience evidence where counterpart methods failed. In terms of performance, the model improved actionability by 30E and accuracy by 10E compared to other counterfactual methods, and increased accuracy by 5E while reducing training loss by 20E against associative method, demonstrating enhanced precision and efficiency.},
  keywords={Electroencephalography;Diseases;Variable speed drives;Brain modeling;Accuracy;Generative adversarial networks;Medical diagnostic imaging;Correlation;Autism;Training;Counterfactual inference;Causal Electroen-cephalogram pattern;Autism spectrum disorders;Residual generative adversarial network;Graph attention network},
  doi={10.1109/TAI.2025.3610394},
  ISSN={2691-4581},
  month={},}@ARTICLE{10740484,
  author={Fu, Meijun and Wang, Xiaomin and Wang, Jun and Yi, Zhang},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, 
  title={Generative Probabilistic Meta-Learning for Few-Shot Image Classification}, 
  year={2025},
  volume={9},
  number={2},
  pages={1947-1960},
  abstract={Meta-learning, a rapidly advancing area in computational intelligence, leverages prior knowledge from related tasks to facilitate the swift adaptation to new tasks with limited data. A critical challenge in meta-learning is the quantification of model uncertainty. In this paper, we propose a novel meta-learning method, Generative Probabilistic Meta-Learning (GPML), designed for few-shot image classification. GPML extends the Probably Approximately Correct-Bayes (PAC-Bayes) framework, initially formulated for single-task scenarios, to meta-learning across multiple tasks. This extension not only provides theoretical generalization guarantees for meta-learning but also effectively captures model uncertainty through variational parameters. To enhance the expressiveness of approximated posteriors in Bayesian inference, GPML incorporates implicit modeling, which defines probability distributions over task-specific parameters in a data-driven manner. This is achieved by designing a generative model structure that integrates task-dependent prior knowledge into the model inference process. We conduct extensive multidimensional performance evaluations on few-shot image classification tasks across various benchmarks, demonstrating that GPML outperforms existing state-of-the-art meta-learning methods. Additionally, ablation studies focusing on model components, the PAC-Bayes framework, and implicit modeling validate the performance improvements attributed to the proposed generative model structure, learning framework, and modeling approach.},
  keywords={Metalearning;Data models;Adaptation models;Bayes methods;Uncertainty;Probabilistic logic;Optimization;Complexity theory;Training data;Mathematical models;Implicit modeling;meta-learning;model uncertainty;probably approximately correct-Bayes (PAC-Bayes);task-dependent prior},
  doi={10.1109/TETCI.2024.3483255},
  ISSN={2471-285X},
  month={April},}@ARTICLE{10850707,
  author={Luo, Dingsheng and Nie, Mengxi and Wu, Xihong},
  journal={Chinese Journal of Electronics}, 
  title={Generating Basic Unit Movements with Conditional Generative Adversarial Networks}, 
  year={2019},
  volume={28},
  number={6},
  pages={1099-1107},
  abstract={Arm motion control is fundamental for robot accomplishing complicated manipulation tasks. Different movements can be organized by configuring a series of motion units. Our work aims at equipping the robot with the ability to carry out Basic unit movements (BUMs), which are used to constitute various motion sequences so that the robot can drive its hand to a desired position. With the definition of BUMs, we explore a learning approach for the robot to develop such an ability by leveraging deep learning technique. In order to generate the BUM regarding to the current arm state, an internal inverse model is developed. We propose to use Conditional generative adversarial networks (CGANs) to establish the inverse model to generate the BUMs. The experimental results on a humanoid robot PKU-HR6.0II illustrate that CGANs could successfully generate multiple solutions given a BUM, and these BUMs can be used to constitute further reaching movement effectively.},
  keywords={Hands;Deep learning;Analytical models;Accuracy;Humanoid robots;Manipulators;Generative adversarial networks;Batteries;Motion control;Robots;Arm motion control;Basic unit movements;Deep learning;CGANs;Inverse model;Humanoids},
  doi={10.1049/cje.2019.07.013},
  ISSN={2075-5597},
  month={November},}@ARTICLE{9123388,
  author={Yu, Wentao and Bai, Jing and Jiao, Licheng},
  journal={IEEE Access}, 
  title={Background Subtraction Based on GAN and Domain Adaptation for VHR Optical Remote Sensing Videos}, 
  year={2020},
  volume={8},
  number={},
  pages={119144-119157},
  abstract={The application of deep learning techniques in background subtraction for VHR optical remote sensing videos holds the potential to facilitate multiple intelligent remote sensing processing tasks. However, existing methods on background subtraction for VHR optical remote sensing videos are still facing technical challenges. First, conventional CNN and other networks are limited by performance constraints. Second, existing background subtraction methods are mostly trained by natural videos due to the lack of VHR optical remote sensing video datasets. Third, VHR optical remote sensing videos have large scene sizes. In our article, we design a novel deep learning network via fully utilizing GAN and domain adaptation, which has the ability to measure and minimize the discrepancy between feature distributions of natural videos and VHR optical remote sensing videos so that the background subtraction performance for VHR optical remote sensing videos is improved significantly. Numerous experiments are conducted on the CDnet 2014 dataset and VHR optical remote sensing video dataset. Tremendous experiments demonstrate that our proposed method achieves an average FM of 0.8533, which reveals excellent performance on background subtraction.},
  keywords={Videos;Remote sensing;Optical sensors;Optical imaging;Integrated optics;Nonlinear optics;Generative adversarial networks;Background subtraction;generative adversarial networks (GAN);domain adaptation;very high resolution (VHR) optical remote sensing videos},
  doi={10.1109/ACCESS.2020.3004495},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10905875,
  author={K. J, Sanjay Kumar and Amritha Nandini, K.L and Dharshan, S.P Saran and V, Sowmya and Bandaragoda, Tharindu},
  booktitle={IECON 2024 - 50th Annual Conference of the IEEE Industrial Electronics Society}, 
  title={Automated Crack Analysis and Reporting in Civil Infrastructure using Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Maintaining and inspecting infrastructure is crucial due to the safety hazards and economic costs of structural failures. Traditional methods are labor-intensive, time-consuming, and reactive. We propose an automated inspection system leveraging generative AI to enhance efficiency, predictive maintenance capabilities, and comprehensive data analysis. Our framework uses drone-based data acquisition with high-definition cameras and depth sensors, and a custom deep learning model, EyeNet, for precise crack detection. Generative AI techniques, including a Visual Question-Answering (VQA) model and an image-to-image model, are employed for detailed crack analysis and future crack pattern visualization, enabling proactive maintenance. The VQA model achieves an average Root Mean Square Error (RMSE) of 0.394 and an average Symmetric Mean Absolute Percentage Error (SMAPE) of 31.22%. A Large Language Model generates comprehensive reports with visualizations, accessible via a dedicated website. Our system significantly improves the inspection process compared to traditional methods, setting a new benchmark by combining generative AI for detailed crack analysis and predictive maintenance capabilities, creating a comprehensive inspection system for civil infrastructure.},
  keywords={Solid modeling;Analytical models;Visualization;Generative AI;Large language models;Inspection;Streaming media;Predictive models;Maintenance;Predictive maintenance;Deep Learning;Visual Question Answering model;Large Language Model;Generative AI;Predictive Maintenance},
  doi={10.1109/IECON55916.2024.10905875},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9268710,
  author={Berrahal, Mohammed and Azizi, Mostafa},
  booktitle={2020 Fourth International Conference On Intelligent Computing in Data Sciences (ICDS)}, 
  title={Review of DL-Based Generation Techniques of Augmented Images using Portraits Specification}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={Artificial Intelligence (AI) reached various domains in our daily problems, among them is aiding law enforcement in identifying suspects by generating face images or retrieving their images from existing databases, based on the description of witnesses. The existing methods like hand-drawn sketches take time and absorb human resources; in addition to that rendering images from the software fails most of the time to sketch a real image and does not get the ideal scenario. In this paper, we present a survey of the recent progress concerning generating images from description and sketch face recognition, we analyze the difference between several algorithms on the problem based on evaluation metrics like accuracy and correlation similarity. We also give an overview of datasets used for generations or recognition.},
  keywords={Face recognition;Generative adversarial networks;Generators;Distributed databases;Artificial intelligence;Training;Deep learning;Generative Adversarial Networks;Composite Face;Sketch Face;Deep Learning;Image Generation},
  doi={10.1109/ICDS50568.2020.9268710},
  ISSN={},
  month={Oct},}@ARTICLE{9423593,
  author={Zhu, Yuxiang and Yang, Laurence T. and Feng, Jun and Xie, Xia},
  journal={IEEE Transactions on Network Science and Engineering}, 
  title={Tensor-Based GAN to Defense Adversarial Attacks for Cyber-Physical-Social System}, 
  year={2021},
  volume={},
  number={},
  pages={1-1},
  abstract={In recent years, considerable achievements made by scientists in artificial intelligence have provided strong support for the development of Cyber-Physical-Social-Systems. Meanwhile, deep computation to realize AI is widely used in various applications, such as object classification. However, in classification application, the nice perturbations carefully designed added to the input data will make the classification label wrong, and the difference between the adversarial sample and the original one is hard to detect for humans. Hence, this paper proposed a defense mechanism which was tensor-based deep convolution generation adversarial network model to resist the possible attacks of classifiers in CPSSs. The method could play a good defense effect of the application, because of the reconstruction method using a complete Tensor-DCGAN model. The decoder with the same structure as the discriminator was used to decode the classified data, and the generator was used to generate a data which was the most similar to the data to be classified. The experimental results shown that our improved method not only preserved the advantages of the original model, but also reduced the parameters required by the original methods, and be more importantly, it made up the shortcomings of the original of color images and network data.},
  keywords={Data models;Computational modeling;Tensors;Training;Generative adversarial networks;Image reconstruction;Perturbation methods},
  doi={10.1109/TNSE.2021.3077305},
  ISSN={2327-4697},
  month={},}@INPROCEEDINGS{10986449,
  author={Phogat, Rupesh and Arora, Dheeraj and Mehra, Pawan Singh and Sharma, Jatin and Chawla, Diksha},
  booktitle={2025 3rd International Conference on Device Intelligence, Computing and Communication Technologies (DICCT)}, 
  title={A Comparative Study of Large Language Models: ChatGPT, DeepSeek, Claude and Qwen}, 
  year={2025},
  volume={},
  number={},
  pages={609-613},
  abstract={In recent times, Artificial Intelligence sector has been booming. Its applications are stunning and outperform the previous generation models as advancements happen. Machine Learning is one of the best methods to achieve Artificial Intelligence, and one of the most famous examples of this is the LLMs (Large Language Models). Recently, there have been breakthroughs in the LLM industry with the entrance of many models, such as OpenAI's ChatGPT, DeepSeek, Claude, and Qwen. In this article, we have conducted a detailed analysis of different LLMs. The priority is on the comparison of ChatGPT, Qwen, DeepSeek, and Claude. This paper informs reader about the various model's performance and the architecture of famous LLM's like ChatGPT, Qwen, DeepSeek, and Claude, along with their comparisons. In the course of this article, we have provided plenty of knowledge about LLMs, which can provide a framework for researchers and may clear paths for them.},
  keywords={Industries;Generative AI;Large language models;Machine learning;Computer architecture;Chatbots;Communications technology;ChatGPT;DeepSeek;Claude;Qwen;Generative AI;Artificial Intelligence;Large Language Models},
  doi={10.1109/DICCT64131.2025.10986449},
  ISSN={},
  month={March},}@ARTICLE{10711187,
  author={Edwards, Peter and Nebel, Jean-Christophe and Greenhill, Darrel and Liang, Xing},
  journal={IEEE Access}, 
  title={A Review of Deepfake Techniques: Architecture, Detection, and Datasets}, 
  year={2024},
  volume={12},
  number={},
  pages={154718-154742},
  abstract={Driven by continuous advancements in artificial intelligence, especially deep learning, the level of realism associated with deepfake technology continues to improve year after year, which poses unprecedented challenges to the field of deepfake detection. The boundary between what we as humans can detect as real or fake becomes evermore blurred as new generations of algorithms such as Dall-E 3 and Stable Diffusion are released. This paper provides a comprehensive study into the landscape of deepfake detection, exploring in-depth the key challenges, recognising recent successes, and suggesting promising avenues for future research. A meta-literature review is conducted to identify the current challenges and future directions, which form the foundation of this work. They are investigated by analysing state-of-the-art research with a focus on the key components that are crucial to the design of a deepfake detector, i.e., the architecture, detection methods and datasets. A major challenge identified by this study is the lack of dataset diversity leading to unfair attribute representation. This must be addressed by improving standardisation on dataset ethics and privacy. This is one of the main reasons for the insufficient generalisation capability of current deepfake detectors as demonstrated by their unsatisfactory performance when faced with unseen data or data in the wild. This literature review provides deepfake detection researchers and practitioners with the latest information that will serve as a vital resource for their continued and important activity, now and in the future.},
  keywords={Deepfakes;Reviews;Bibliographies;Computer architecture;Scalability;Deep learning;Data models;Object recognition;Lighting;Feature extraction;Generative AI;Artificial intelligence;Machine learning;Deepfakes;deepfake detection;generative AI;deep learning;machine learning;artificial intelligence;datasets;survey},
  doi={10.1109/ACCESS.2024.3477257},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8243968,
  author={Zhao, Danchen and Weng, Jingkun and Liu, Yuehu},
  booktitle={2017 Chinese Automation Congress (CAC)}, 
  title={Generating traffic scene with deep convolutional generative adversarial networks}, 
  year={2017},
  volume={},
  number={},
  pages={6612-6617},
  abstract={Training and testing unmanned vehicles need various real data. However, data of some special or dangerous testing environment may not be accessible, or may only be accessible at certain times. So, using generative adversarial networks to learn the real traffic scene and generate a new scene is an effective way of solving the problem. In this paper, a framework of deep convolutional generative adversarial networks (DCGAN) was used to generate new traffic scene images and videos. Firstly, 300 sets of videos and images of overtaking scenes were selected as training data. A generator with convolutional neural network was used to generate samples. Then the training data and the generated samples were trained in a two-class discriminator that provides the probabilities of the samples that come from the generated sample and the training data respectively. Then the generator was updated by back propagation algorithm. Afterward, a new sample was generated and trained in the discriminator again. Repeated several times, a serial of generated samples were generated, the probability distribution of which is basically the same as the training data. The experiments show that this method can effectively generate realistic traffic scene images and videos.},
  keywords={Generators;Gallium nitride;Training data;Videos;Training;Convolution;Unmanned vehicles;traffic scene;generated image;unmanned vehicle},
  doi={10.1109/CAC.2017.8243968},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11050708,
  author={Somvanshi, Shriyank and Liu, Jinli and Das, Subasish},
  booktitle={2025 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={A Survey on Generative AI in Transportation Systems Management and Operation}, 
  year={2025},
  volume={},
  number={},
  pages={829-832},
  abstract={The integration of Generative AI (Gen-AI) into Transportation Systems Management and Operations (TSMO) offers transformative potential to address persistent knowledge management challenges. This survey study explores how Gen-AI can revolutionize TSMO through enhanced data integration, automated knowledge extraction, and predictive modeling. By synthesizing diverse datasets, Gen-AI facilitates the creation of unified knowledge repositories, improves real-time decision-making, and supports proactive scenario planning. The study introduces a comprehensive framework for embedding Gen-AI into TSMO workflows, enabling streamlined operational efficiency, cross-agency collaboration, and scalable data-driven strategies. Key applications of Gen-AI in TSMO include adaptive traffic control, crash response planning, and predictive modeling for future traffic scenarios. The study highlights innovative Gen-AI models and techniques, such as generative adversarial networks (GANs), large language models (LLMs), and hybrid augmented intelligence frameworks, which collectively enhance TSMO's capacity for resilience and responsiveness. Despite its transformative potential, Gen-AI adoption faces critical challenges, including ethical considerations, computational constraints, and the need for stakeholder trust. The paper emphasizes the importance of responsible AI development, fairness, and explainability to ensure sustainable adoption. By addressing these barriers, the proposed framework sets the stage for a new era of intelligent, adaptive, and community-centered transportation system management,},
  keywords={Surveys;Adaptation models;Computational modeling;Decision making;Transportation;Data integration;Predictive models;Traffic control;Planning;Stakeholders;Gen-AI;TSMO;Transportation Engineering;AI;Survey},
  doi={10.1109/CAI64502.2025.00148},
  ISSN={},
  month={May},}@ARTICLE{8576508,
  author={Cao, Yang-Jie and Jia, Li-Li and Chen, Yong-Xia and Lin, Nan and Yang, Cong and Zhang, Bo and Liu, Zhi and Li, Xue-Xiang and Dai, Hong-Hua},
  journal={IEEE Access}, 
  title={Recent Advances of Generative Adversarial Networks in Computer Vision}, 
  year={2019},
  volume={7},
  number={},
  pages={14985-15006},
  abstract={The appearance of generative adversarial networks (GAN) provides a new approach and framework for computer vision. Compared with traditional machine learning algorithms, GAN works via adversarial training concept and is more powerful in both feature learning and representation. GAN also exhibits some problems, such as non-convergence, model collapse, and uncontrollability due to high degree of freedom. How to improve the theory of GAN and apply it to computer-vision-related tasks have now attracted much research efforts. In this paper, recently proposed GAN models and their applications in computer vision are systematically reviewed. In particular, we firstly survey the history and development of generative algorithms, the mechanism of GAN, its fundamental network structures, and theoretical analysis of the original GAN. Classical GAN algorithms are then compared comprehensively in terms of the mechanism, visual results of generated samples, and Frechet Inception Distance. These networks are further evaluated from network construction, performance, and applicability aspects by extensive experiments conducted over public datasets. After that, several typical applications of GAN in computer vision, including high-quality samples generation, style transfer, and image translation, are examined. Finally, some existing problems of GAN are summarized and discussed and potential future research topics are forecasted.},
  keywords={Gallium nitride;Generative adversarial networks;Generators;Hidden Markov models;Computer vision;Training;Feature extraction;Deep learning;generative adversarial networks (GAN);computer vision (CV);image generation;style transfer;image inpainting},
  doi={10.1109/ACCESS.2018.2886814},
  ISSN={2169-3536},
  month={},}@ARTICLE{9625961,
  author={Brophy, Eoin and De Vos, Maarten and Boylan, Geraldine and Ward, Tomás},
  journal={IEEE Access}, 
  title={Multivariate Generative Adversarial Networks and Their Loss Functions for Synthesis of Multichannel ECGs}, 
  year={2021},
  volume={9},
  number={},
  pages={158936-158945},
  abstract={Access to medical data is highly regulated due to its sensitive nature, which can constrain communities’ ability to utilize these data for research or clinical purposes. Common de-identification techniques to enable the sharing of data may not provide adequate privacy in every circumstance. We investigate the ability of Generative Adversarial Networks (GANs) to generate synthetic, and more significantly, multichannel electrocardiogram signals that are representative of waveforms observed in patients to address these privacy concerns. Successful generation of high-quality synthetic time series data has the potential to act as an effective substitute for actual patient data. For the first time, we demonstrate a range of novel loss functions using our multivariate GAN architecture and analyse their effect on data quality and privacy. We also present the application of multivariate dynamic time warping as a means of evaluating generated time series. Quantitative evidence demonstrates that the inclusion of a penalisation coefficient (Dynamic Time Warping) in the loss function enables our GAN to outperform the other generative models and loss functions explored by 4.9% according to our metrics. This allows for the generation of data that is more representative of the training set and diverse across generated samples, all whilst ensuring sufficient privacy.},
  keywords={Time series analysis;Generative adversarial networks;Generators;Electrocardiography;Data privacy;Training;Data models;Generative adversarial networks;ECG;time series},
  doi={10.1109/ACCESS.2021.3130421},
  ISSN={2169-3536},
  month={},}@ARTICLE{10223211,
  author={Jin, Yeongbong and Chang, Woojin and Ko, Bonggyun},
  journal={IEEE Access}, 
  title={Generating Chest X-Ray Progression of Pneumonia Using Conditional Cycle Generative Adversarial Networks}, 
  year={2023},
  volume={11},
  number={},
  pages={88152-88160},
  abstract={Pneumonia is an inflammation of the lungs caused by pathogens or autoimmune diseases, with about 450 million patients worldwide each year. Chest X–ray analysis is the most common radiographic method used to diagnose pneumonia, and advances in deep learning have led to the availability of high-dimensional image, audio, and video data. Deep learning is being applied in many fields, including the medical field, where numerous researchers have attempted to use it for computer-aided diagnosis. Recently, with the appearance of generative adversarial networks, it is possible to generate plausible and realistic images. In this paper, we combined cycle Generative Adversarial Networks (GANs) and conditional GANs, which are extensions of GANs, to convert the domains between images and generate images of the intermediate domains. We conducted the domain change between pneumonia images and normal images by applying our framework to a Chest X–ray image dataset. We evaluated the domain change by redefining the ResNet152-based classifier, and we generated the pneumonia progression images by inputting a value between two domains in the conditional vector of the generator. We then evaluated the ability of the trained GANs by comparing the original dataset with the generated dataset, and generated plausible progression images of pneumonia.},
  keywords={Pulmonary diseases;Generators;Training;Generative adversarial networks;Deep learning;Medical diagnostic imaging;Convolutional neural networks;X-ray imaging;Pneumonia;Transfer learning;Chest X–ray;generative adversarial networks;pneumonia;transfer learning},
  doi={10.1109/ACCESS.2023.3305994},
  ISSN={2169-3536},
  month={},}@ARTICLE{8936350,
  author={Ma, Xiaohan and Jin, Rize and Sohn, Kyung-Ah and Paik, Joon-Young and Chung, Tae-Sun},
  journal={IEEE Access}, 
  title={An Adaptive Control Algorithm for Stable Training of Generative Adversarial Networks}, 
  year={2019},
  volume={7},
  number={},
  pages={184103-184114},
  abstract={Generative adversarial networks (GANs) have shown significant progress in generating highquality visual samples, however they are still well known both for being unstable to train and for the problem of mode collapse, particularly when trained on data collections containing a diverse set of visual objects. In this paper, we propose an Adaptive k-step Generative Adversarial Network (Ak-GAN), which is designed to mitigate the impact of instability and saturation in the original by dynamically adjusting the ratio of the training steps of both the generator and discriminator. To accomplish this, we track and analyze stable training curves of relatively narrow datasets and use them as the target fitting lines when training more diverse data collections. Furthermore, we conduct experiments on the proposed procedure using several optimization techniques (e.g., supervised guiding from previous stable learning curves with and without momentum) and compare their performance with that of state-of-the-art models on the task of image synthesis from datasets consisting of diverse images. Empirical results demonstrate that Ak-GAN works well in practice and exhibits more stable behavior than regular GANs during training. A quantitative evaluation has been conducted on the Inception Score (IS) and the relative inverse Inception Score (RIS); compared with regular GANs, the former has been improved by 61% and 83%, and the latter by 21% and 60%, on the CelebA and the Anime datasets, respectively.},
  keywords={Training;Gallium nitride;Generators;Generative adversarial networks;Adaptation models;Adaptive control;Convergence;Generative adversarial networks;image generation;adaptive algorithm;mode collapse},
  doi={10.1109/ACCESS.2019.2960461},
  ISSN={2169-3536},
  month={},}@ARTICLE{10410850,
  author={Alshantti, Abdallah and Varagnolo, Damiano and Rasheed, Adil and Rahmati, Aria and Westad, Frank},
  journal={IEEE Access}, 
  title={CasTGAN: Cascaded Generative Adversarial Network for Realistic Tabular Data Synthesis}, 
  year={2024},
  volume={12},
  number={},
  pages={13213-13232},
  abstract={Generative adversarial networks (GANs) have drawn considerable attention in recent years for their proven capability in generating synthetic data which can be utilised for multiple purposes. While GANs have demonstrated tremendous successes in producing synthetic data samples that replicate the dynamics of the original datasets, the validity of the synthetic data and the underlying privacy concerns represent major challenges which are not sufficiently addressed. In this work, we design a cascaded tabular GAN framework (CasTGAN) for generating realistic tabular data with a specific focus on the validity of the output. In this context, validity refers to the the dependency between features that can be found in the real data, but is typically misrepresented by traditional generative models. Our key idea entails that employing a cascaded architecture in which a dedicated generator samples each feature, the synthetic output becomes more representative of the real data. Our experimental results demonstrate that our model is capable of generating synthetic tabular data that can be used for fitting machine learning models, as CasTGAN’s classification performance only falls under the real training data’s PR-AUC score by 4.88% on average for classification datasets, and exhibits an average reduction of the real training data’s  $R^{2}$  score by 0.139 for regression datasets. In addition, our model captures well the constraints and the correlations between the features of the real data, especially the high dimensional datasets. Assessing the generation of invalid records demonstrates that CasTGAN reduces the number of invalid data observations by up to 622% in comparison to the second best performing baseline tabular GAN model. Furthermore, we evaluate the risk of white-box privacy attacks on our model and subsequently show that applying some perturbations to the auxiliary learners in CasTGAN increases the overall robustness of our model against targeted attacks.},
  keywords={Generators;Generative adversarial networks;Data models;Synthetic data;Privacy;Training;Data privacy;Generative adversarial networks;output validity;privacy attacks;tabular data},
  doi={10.1109/ACCESS.2024.3356913},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10780818,
  author={Gunawan, Marvella and Maia, Marcaelle and Klein, Steven and Meyliana and Surjandy},
  booktitle={2024 International Conference on Information Management and Technology (ICIMTech)}, 
  title={ChatGPT and VARK Model in Education: A Systematic Literature Review}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In the ever-growing digital era, the use of artificial intelligence (AI) such as ChatGPT is increasingly widespread, especially in education. ChatGPT is a generative AI that could produce human-quality text, write creative content, translate languages, and answer questions informatively. A Systematic Literature Review (SLR) methodology is conducted to explore the role of ChatGPT in supporting a learning process that considers individual learning styles based on the VARK Model (Visual, Auditory, Read/Write, and Kinesthetic). This research aims to identify factors in ChatGPT that could improve the learning process. The findings from this study provide valuable insights for education development, identifying 55 essential factors in ChatGPT for education and the implications for AI.},
  keywords={Visualization;Generative AI;Education;Focusing;Chatbots;Information management;ChatGPT;Generative AI;education;learning;learning style;VARK Model},
  doi={10.1109/ICIMTech63123.2024.10780818},
  ISSN={2837-2778},
  month={Aug},}@INPROCEEDINGS{10934554,
  author={Jameel, Faisal and Ahmad, Waqas and Heydari, Mohammad and Shahpasand, Maryam and Tafreshi, Vahid Heydari Fami},
  booktitle={Global Congress on Emerging Technologies (GCET-2024)}, 
  title={Evaluating Large Language Models Versus Traditional Tools in SQL Injection Exploit Generation}, 
  year={2024},
  volume={},
  number={},
  pages={322-329},
  abstract={SQL injection (SQLi) remains a critical threat to database security, as it exploits vulnerabilities that allow unauthorized access to or manipulation of database systems. Traditional tools like SQLmap are commonly used for vulnerability testing but often lack adaptability and efficiency in complex database environments. This research examines the potential of generative artificial intelligence to improve SQLi payload generation, specifically through a fine-tuned models of ChatGPT 3.5 Turbo by OpenAI and Command R by Cohere.The study began by using SQLmap to generate 1,136 SQLi payloads, which achieved a success rate of 6.51% in bypassing authentication and extracting data from a MySQL database. These payloads were then used to fine-tune Command R and ChatGPT 3.5 Turbo models, which subsequently generated 1,007 and 1,004 new payloads, respectively. The effectiveness of these payloads was tested using Burp Suite, a proxy software, targeting the OWASP Mutillidae II testbed. This involved setting parameters for username and password fields in the Burp Suite Intruder to launch attacks, resulting in ChatGPT 3.5 Turbo proved to be around 60% more effective than Command R and nearly 75% better than SQLmap. Furthermore, Command R was about 130% more effective than SQLmap.},
  keywords={Generative AI;Large language models;Passwords;SQL injection;Chatbots;Software;Database systems;Data models;Payloads;Testing;SQL Injection;Generative AI;Large Language Models;ChatGPT;Command R},
  doi={10.1109/GCET64327.2024.10934554},
  ISSN={},
  month={Dec},}@ARTICLE{10098869,
  author={Luo, Wenjian and Zhang, Licai and Wu, Yulin and Liu, Chuanyi and Han, Peiyi and Zhuang, Rongfei},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Capacity Abuse Attack of Deep Learning Models Without Need of Label Encodings}, 
  year={2024},
  volume={5},
  number={2},
  pages={814-826},
  abstract={In recent years, machine learning (ML) models, especially deep learning models, have become commodities. In this context, data centers which hold a lot of data often buy ML models from ML model providers, train them on their data locally and use the trained models to provide intelligent services. Existing work has shown that there is a risk of data leakage, which could cause incalculable consequences. Even under the black-box condition, there are still some attacks that can steal the private data held by data centers, and the capacity abuse attack (CAA) is the state-of-the-art attack method. CAA attackers steal the training data by labeling malicious samples with the data to be stolen. However, the label encodings are usually mapped into other output forms, such as categories, and it is impossible for the adversary to know the mapping relationship between the form output by the trained model and the label encodings. Without the mapping relationship, CAA becomes invalid. Aiming at the limitation of CAA, this study proposes a novel practical attack method, i.e., capacity abuse attack II (CAAII), which can find the mapping relationship between the output in the arbitrary form returned by the trained model and the values of the stolen data. Experiments are conducted on MNIST, Fashion-MNIST, and CIFAR10 datasets, and experimental results show that no matter what forms are returned by the model, our attack method can always find the mapping relationship and successfully steals the training data.},
  keywords={Data models;Training;Encoding;Closed box;Data centers;Deep learning;Training data;Backdoor attack;black-box attack;data privacy;machine learning (ML)},
  doi={10.1109/TAI.2023.3266419},
  ISSN={2691-4581},
  month={Feb},}@ARTICLE{10526446,
  author={Liu, Shuangrong and Oh, Sung-Kwun and Pedrycz, Witold and Yang, Bo and Wang, Lin and Peng, Zhen},
  journal={IEEE Transactions on Fuzzy Systems}, 
  title={SCINN: Semantic Concept-Based Inference Neural Networks With Explainable and Deep Fuzzy Structure}, 
  year={2024},
  volume={32},
  number={7},
  pages={4133-4147},
  abstract={In this study, a novel semantic concept-based inference neural network (SCINN) is proposed to develop a design methodology for the explainable deep neuro-fuzzy models and improve their generalization performance in high-dimensional problems. Traditional neuro-fuzzy models exhibit outstanding interpretability in the problems of lower dimensionality. However, when faced with high-dimensional scenarios, the long rule and rule explosion problems damage their interpretability and result in poor generalization performance, even making them unusable. Although deep neuro-fuzzy models show enhanced performance in handling high-dimensional problems compared to traditional counterparts, they often come at the expense of interpretability. To establish a neuro-fuzzy model that can address high-dimensional problems while preserving the interpretability, the SCINN is proposed with the aid of the concept-based measure generation paradigm (CMGP) and the multi-view information augmentation strategy (MIAS). The CMGP is designed to adaptively define the membership functions (MFs) that correspond to the human-understandable concepts based on the given data; the defined MFs contribute to the construction of the explainable fuzzy rule that can directly process high-dimensional data. The MIAS is structured to develop a unified paradigm for implementing consequence functions in the fuzzy rules, which enhances the approximation ability of the SCINN. The performance of SCINN is evaluated on various image datasets against different competitors, including neuro-fuzzy-based approaches and deep structure-based neural networks. A real-world application is adopted to evaluate its effectiveness. The experimental results show that SCINN outperforms the compared neuro-fuzzy models and is comparable to the deep structure-based neural networks.},
  keywords={Fuzzy logic;Data models;Computational modeling;Explosions;Semantics;Linguistics;Explainable AI;Fuzzy inference framework;generative adversarial network (GAN);interpretability;multiview information augmentation;semantic concept-based inference},
  doi={10.1109/TFUZZ.2024.3398719},
  ISSN={1941-0034},
  month={July},}@INPROCEEDINGS{10211027,
  author={Dharmalingam, Balakrishnan and Odat, Ibrahim and Mukherjee, Rajdeep and Piggott, Brett and Liu, Anyi},
  booktitle={2023 IEEE International Conference on Mobility, Operations, Services and Technologies (MOST)}, 
  title={Heterogeneous Generative Dataset for UASes}, 
  year={2023},
  volume={},
  number={},
  pages={229-230},
  abstract={In this poster, we present the construction of HGDAVE (Heterogeneous Generative Dataset for Unmanned Autonomous Systems), a new dataset for Connected and Autonomous Vehicles (CAVs) and Unmanned Aerial Vehicles (UAVs), namely Unmanned Autonomous Systems (UASes). The dataset will be used to train artificial intelligence (AI) models to detect cybersecurity and safety-related risks, malfunctions, and crashes. The dataset was collected from three sources: 1) script-generated flying or driving missions, 2) software fuzzer-generated crashes instances, and 3) cybersecurity exploits generated by ethical hackers. To collect the data, we utilized the Digital Twin (DT) to replicate the behavior of UASes, which provides data that can be used to analyze, develop, and detect new anomaly detection algorithms.},
  keywords={Ethics;Connected vehicles;Computer hacking;Software algorithms;Autonomous aerial vehicles;Software;Digital twins;UAS;Digital Twin;Unmanned Aerial Vehicles;Hardware in the loop;Software in the loop;Generative AI},
  doi={10.1109/MOST57249.2023.00034},
  ISSN={},
  month={May},}@INPROCEEDINGS{11152803,
  author={Basaran, Osman Tugay and Villa, Davide and Johari, Pedram and Polese, Michele and Fiandrino, Claudio and Dressler, Falko and Melodia, Tommaso},
  booktitle={IEEE INFOCOM 2025 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, 
  title={Gen-TWIN: Generative-AI-Enabled Digital Twin for Open Radio Access Networks}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={The realization of efficient Artificial Intelligence (AI) solutions for the optimization of next-generation Radio Access Network (RAN) relies on the availability of expansive, high-quality datasets that accurately capture nuanced, site-specific conditions. However, obtaining such abundant, domain-specific measurements poses a significant challenge, especially as network complexity and energy efficiency demand surge toward 6G. In response, we introduce GenerativeAI-enabled Digital Twin (Gen-TWIN), a synthetic data generation framework underpinned by a soft-attention LSTM-based generative adversarial network (soft-GAN). Our model augments realistic transmitter and receiver-focused RF datasets by supplementing scarce empirical samples and providing the synthetic data volumes essential for training advanced AI models on RAN. Accuracy results show that soft-GAN provided 19% performance improvement compared to baseline models.},
  keywords={Training;Accuracy;Computational modeling;Open RAN;Generative adversarial networks;Data models;Robustness;Digital twins;Next generation networking;Synthetic data;Digital Twin;Generative AI;O-RAN;Generative Adversarial Network;5G/6G},
  doi={10.1109/INFOCOMWKSHPS65812.2025.11152803},
  ISSN={2833-0587},
  month={May},}@INPROCEEDINGS{10156926,
  author={B, Kumaran and A, Shaikh Firaas and V, Rahul Chiranjeevi},
  booktitle={2023 2nd International Conference on Vision Towards Emerging Trends in Communication and Networking Technologies (ViTECoN)}, 
  title={A Novel Method for Image Inpainting Using CGAN}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Image Inpainting can be defined as the task of filling out blank spaces or holes that may appear on images. It has been mostly used for restoring old and damaged photos. Traditionally methods like image segmentation and auto encoders were used to obtain results for this problem. Also, the old traditional methods had to have datasets where the developer would manually pick which areas for the model to train so that it can paint those missing regions correctly. Newer deep learning-based techniques, which may also be carried out unsupervised, have demonstrated remarkable performance in producing visually realistic and refined contents for the missing regions in free-form image inpainting challenges. Although several existing solutions concentrate on including more inputs to address this issue, it is difficult to directly apply cutting-edge inpainting techniques to image extension since they frequently produce blurry or repeating pixels with erratic semantics. The discriminator of a generative adversarial network (GAN) is subjected to semantic conditioning, and the findings on image extension with coherent semantics and aesthetically pleasant colors and textures are strong. We also present encouraging findings for long extensions.},
  keywords={Image segmentation;Image color analysis;Computational modeling;Semantics;Generative adversarial networks;Market research;Image restoration;GAN - Generative Adversarial Networks;DL - Deep Learning;VAE - Variational AutoEncoder;SSIM - Structural Similarity Index;DFNet - Deep Fusion Network},
  doi={10.1109/ViTECoN58111.2023.10156926},
  ISSN={},
  month={May},}@INPROCEEDINGS{10883632,
  author={Parmanand, Satish L. and Chandankhede, Pankaj H. and Deshmukh, Atul R.},
  booktitle={2025 6th International Conference on Mobile Computing and Sustainable Informatics (ICMCSI)}, 
  title={Use of Generative AI for Audio Speech Recognition: Methods and Selection Criteria}, 
  year={2025},
  volume={},
  number={},
  pages={1113-1120},
  abstract={The generative AI has transformed human speech recognition systems audio-wise it was impossible prior. In this paper, various generative AI methods for speech recognition like End-to-end deep learning models, such as Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) and Transformer Models are described. A comprehensive evaluation framework is introduced in it to aid in the selection of appropriate generative AI models with respect to their performance and computational efficiency as well as language/dialect neutrality. Results indicate that, though generative AI substantially improves the performance of speech recognition in relation to accuracy and robustness, some guidelines need to be defined for an effective selection procedure aimed at maximizing system efficiency. Furthermore, the study highlights a call for further work to improve integration of these powerful AI models in practice-oriented solutions and establish their effectiveness and scalability for practical deployment. Improving these guidelines will allow for more accurate and trustworthy speech recognition systems going forward.},
  keywords={Adaptation models;Accuracy;Generative AI;Computational modeling;Scalability;Speech recognition;Transformers;Robustness;Computational efficiency;Guidelines;Generative AI in Speech Recognition;Speech Recognition Models (GANs;VAEs;Transformer Models);Performance and Computational Efficiency in AI models},
  doi={10.1109/ICMCSI64620.2025.10883632},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{11064515,
  author={Sharma, Kshitij and Singh, Swikriti and Shrivastava, Khushi and Shukla, Pallavi and Dwivedi, Vijay Kumar},
  booktitle={2025 3rd International Conference on Communication, Security, and Artificial Intelligence (ICCSAI)}, 
  title={Ai-Driven Dermatological Diagnosis and Treatment System}, 
  year={2025},
  volume={3},
  number={},
  pages={1752-1757},
  abstract={A sophisticated artificial intelligence-based system for the automated diagnosis, treatment suggestion, and detection of skin and hair problems is presented in this study. The system analyzes input photographs through VGG19 model to identify anomalies, categorize illnesses, and LLaMA-3 model to offer individualized, scientifically supported therapy recommendations by combining state-of-the-art image analysis and deep learning algorithms. The model guarantees great robustness and diagnostic accuracy across a range of dermatological disorders because it is based on a vast and diverse dataset. Thorough testing highlights its dependability, and the addition of real-time processing and user-friendly interfaces improves usefulness. This approach exemplifies how artificial intelligence (AI) can revolutionize dermatology by closing accessibility barriers and providing people with accurate and useful health insights.},
  keywords={Deep learning;Hair;Analytical models;Accuracy;Image analysis;Medical services;Skin;Convolutional neural networks;Diseases;Context modeling;Convolutional Neural Network (CNN);Deep Learning;Dermatological Diagnostics;Image Analysis},
  doi={10.1109/ICCSAI64074.2025.11064515},
  ISSN={},
  month={April},}
