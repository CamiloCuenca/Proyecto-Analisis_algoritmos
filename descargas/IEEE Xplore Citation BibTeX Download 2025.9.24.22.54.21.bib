@INPROCEEDINGS{10315744,
  author={Torres, Nicol√°s},
  booktitle={2023 42nd IEEE International Conference of the Chilean Computer Science Society (SCCC)}, 
  title={Do Robots Dream of Passing a Programming Course?}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Programming typically involves humans formulating instructions for a computer to execute computations. If we adhere to this definition, a machine would seemingly lack the capability to autonomously design algorithms. However, recent generative Artificial Intelligence models, such as GPT, have demonstrated an impressive ability to perform complex human tasks with remarkable precision. In this paper, we initially showcase how an AI model can successfully complete an entire college-level programming course, akin to one of the top-performing students in the class. We then put forward strategies for crafting programming exercises that enable educators to effectively integrate these innovative technologies into their teaching methods. Lastly, we illustrate how these models can transition from being perceived as a potential threat to educators to becoming a valuable opportunity when employed judiciously.},
  keywords={Training;Computational modeling;Instruments;Natural languages;Learning (artificial intelligence);Syntactics;Task analysis;Artificial Intelligence;Neural Networks;Programming;Learning Analysis;Technology-Enhanced Learning},
  doi={10.1109/SCCC59417.2023.10315744},
  ISSN={2691-0632},
  month={Oct},}@INPROCEEDINGS{10405724,
  author={Dimitri, Giovanna Maria and Parri, Lorenzo and Pozzebon, Alessandro and Vitanza, Eleonora and Fort, Ada and Mocenni, Chiara},
  booktitle={2023 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)}, 
  title={WeAIR: Wearable Swarm Sensors for Air Quality Monitoring to Foster Citizens' Awareness of Climate Change}, 
  year={2023},
  volume={},
  number={},
  pages={98-103},
  abstract={The present study proposes the implementation of an air quality measurement tool through the use of a swarm of wearable devices, named WeAIR, consisting of wearable sensors for measuring NOx, CO2, CO, temperature, humidity, and barometric pressure. Data will be stored and processed in a secure cloud environment. Artificial Intelligence algorithms will be used to visualize and make available real-time predictions of future states of air quality, by reconstructing spatio-temporal dynamical maps collected through the habitual movement of citizens in space and time. Then a pre-processing phase will allow us to appropriately homogenize the collected data, by means of the application of innovative artificial intelligence methods. All the data collected will be embedded into an integrated system with multiple functions. Among them, an important goal will also be to raise citizens' awareness of climate change.},
  keywords={Temperature measurement;Climate change;Cloud computing;Pollution measurement;Reliability;Artificial intelligence;Wearable sensors;climate change;air quality;monitoring devices;health;citizens' science},
  doi={10.1109/MetroXRAINE58569.2023.10405724},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11037909,
  author={Li, Duanjiao and Chen, Yun and Zhang, Ying and Sun, Wenxing and He, Xing and Tong, Haoran and Ding, Ning and Xia, Xuan},
  booktitle={2024 7th Asia Conference on Cognitive Engineering and Intelligent lnteraction (CEII)}, 
  title={Discriminative-Generative Representation Learning for One-Class Anomaly Detection}, 
  year={2024},
  volume={},
  number={},
  pages={227-232},
  abstract={Generative Adversarial Networks (GANs), as a form of generative self-supervised learning, have garnered significant attention in anomaly detection. However, the generator's capacity for representation learning is constrained due to its excessive focus on pixel-level details, which hinders its ability to effectively learn abstract semantic representations from label prediction pretext tasks compared to the discriminator. To enhance the generator's representation learning capabilities, we introduce a self-supervised learning framework that integrates generative and discriminative approaches. Our proposed discriminative-generative representation learning method not only rivals the performance of discriminative methods but also offers a significant speed advantage. When applied to one-class anomaly detection tasks, our method surpasses several state-of-the-art models on various benchmark datasets, improving upon the top-performing GAN-based baseline by 6% on CIFAR-10 and 2% on MVTAD. Furthermore, ablation studies reveal that absolute positional information negatively impacts the representational learning ability of generative methods in geometric transformation tasks, offering a valuable guideline for the utilization of positional information.},
  keywords={Representation learning;Semantics;Asia;Self-supervised learning;Benchmark testing;Generative adversarial networks;Generators;Anomaly detection;Guidelines;self-supervised learning;anomaly detection;discriminative;generative;one-class},
  doi={10.1109/CEII65291.2024.00052},
  ISSN={},
  month={Dec},}@INBOOK{11164582,
  author={Arun, C. and Karthick, S. and Selvakumara Samy, S. and Hariharan, B. and Lee, Po-Ming},
  booktitle={Generative AI and LLMs: Natural Language Processing and Generative Adversarial Networks}, 
  title={3 Generative AI Models and LLM: Training Techniques and Evaluation Metrics}, 
  year={2024},
  volume={},
  number={},
  pages={43-68},
  abstract={Generative artificial intelligence (AI) has been a prominent technique across data-driven applications, which uses deep learning architecture to learn the underlying characteristic of the sample to build the knowledge base in generating synthetic samples that mimic the real distribution. Generative AI models are ideal solutions where models suffer due to scarcity of data sample that hinders the training process be it text, video, audio, and image. Training the model plays a pivotal role, where it discovers the hidden pattern and understands the intrinsic behavior of samples that aid in generating realistic samples. The volume of data that is available for training and the computing power required pose threat on the performance of the intelligent systems, where large language models (LLM) has been an ideal solution. LLMs are generative AI systems that understand human language and provide intelligent, creative solutions to questions. Complex architecture of LLM allows them to capture the intricacies of language more precise, enabling to generate coherent and contextually relevant outputs. This chapter delves into comprehensive analysis on the well-known generative AI models such as generative adversarial networks, transformers, and LangChain. Generative AI employs different training techniques such as reinforcement learning, adversarial training, variational inference, transfer learning, and progressive training on diverse application domains. Furthermore, the study examines the crucial aspect of evaluating the effectiveness of generative models, using a variety of metrics ranging from BLUE, inception score, perplexity, Frechet inception distance, precision, ROUGE, recall, METEOR, BERT, MoverScore, and many more. A comparative analysis of these metrics offers insights into their respective advantages and disadvantages, aiding practitioners and researchers in selecting benchmarks that align with their specific use cases.},
  keywords={},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9783111425511},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11164582},}@ARTICLE{10305172,
  author={Cui, Lipeng and Liu, Jiarui},
  journal={IEEE Access}, 
  title={Virtual Human: A Comprehensive Survey on Academic and Applications}, 
  year={2023},
  volume={11},
  number={},
  pages={123830-123845},
  abstract={As a creative method for virtual human individuals based on multiple fusion technologies such as artificial intelligence, computer graphics, and speech synthesis, virtual human technology has developed rapidly since its birth, and continuous discussions and studies have been conducted in both academia and industry. Starting from the film and television industries, the cross-disciplinary application of virtual human has been continuously recognized and applied in fields such as media, games, and finance. Although virtual human has achieved sufficient development and innovation, it faces many challenges such as emotion recognition, privacy, and security, as well as the uncanny valley effect. This article starts with the development history of virtual human and analyzes the current academic research status and application scenarios in combination with the characteristics, technical architecture, and application of virtual human technology. At the same time, this article sorts out seven mainstream application scenarios of virtual human and analyzes their main advantages and possible future challenges. This article provides a valuable reference for subsequent related research by exploring development trends, application fields, and future research trends in virtual human.},
  keywords={Digital humans;Motion capture;Face recognition;Three-dimensional displays;Speech recognition;Solid modeling;Rendering (computer graphics);Artificial intelligence;Deep learning;Machine learning;Human computer interaction;Metaverse;Artificial intelligence;deep learning;machine learning;human-computer interaction;virtual reality;virtual human;metaverse},
  doi={10.1109/ACCESS.2023.3329573},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9339015,
  author={Zhang, Xu and Wang, Haipeng and Li, Yunqi and Cui, Qihui and Lyn, Juntao},
  booktitle={2020 IEEE 9th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={Research of Low-light Image Enhancement Method for Enclosed Tank}, 
  year={2020},
  volume={9},
  number={},
  pages={991-994},
  abstract={Due to closed environment of gas insulated switchgear (GIS) chamber, low-light images are easily produced when taking pictures under weak lighting conditions. The lost details and low contrast not only cause unpleasant subjective feelings, but also hurt the performance of many computer vision systems which are designed for normal-light images. Thus, a low-light image enhancement algorithm based on improved conditional generative adversarial network (GAN) is proposed here to solve this poor visual perception problem. Decom-Net referenced to RetinexNet used here decompose image into reflection map and illumination map. This study proposed an encode-decode convolutional neural network model as the generative model and a lightweight convolutional neural network(CNN) as the discriminative model. After joint training of generative model and discriminative model, the network outputs the final enhanced images. The experimental results demonstrate that the proposed method is more effective than existing methods in perception.},
  keywords={Training;Lighting;Generative adversarial networks;Reflection;Gas insulation;Convolutional neural networks;Image enhancement;low-light image;convolutional neural network;image enhancement;generative adversarial network},
  doi={10.1109/ITAIC49862.2020.9339015},
  ISSN={2693-2865},
  month={Dec},}@INPROCEEDINGS{9414429,
  author={Jeon, Seogkyu and Lee, Pilhyeon and Hong, Kibeom and Byun, Hyeran},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Continuous Face Aging Generative Adversarial Networks}, 
  year={2021},
  volume={},
  number={},
  pages={1995-1999},
  abstract={Face aging is the task aiming to translate the faces in input images to designated ages. To simplify the problem, previous methods have limited themselves only able to produce discrete age groups, each of which consists of ten years. Consequently, the exact ages of the translated results are unknown and it is unable to obtain the faces of different ages within groups. To this end, we propose the continuous face aging generative adversarial networks (CFA-GAN). Specifically, to make the continuous aging feasible, we propose to decompose image features into two orthogonal features: the identity and the age basis features. Moreover, we introduce the novel loss function for identity preservation which maximizes the cosine similarity between the original and the generated identity basis features. With the qualitative and quantitative evaluations on MORPH, we demonstrate the realistic and continuous aging ability of our model, validating its superiority against existing models. To the best of our knowledge, this work is the first attempt to handle continuous target ages.},
  keywords={Conferences;Aging;Signal processing;Generative adversarial networks;Acoustics;Task analysis;Speech processing;Face aging;Image-to-Image translation;Unsupervised Learning;Generative adversarial networks},
  doi={10.1109/ICASSP39728.2021.9414429},
  ISSN={2379-190X},
  month={June},}@INPROCEEDINGS{9377424,
  author={Shin, Yeji and Bum, Junghyun and Son, Chang-Hwan and Choo, Hyunseung},
  booktitle={2021 15th International Conference on Ubiquitous Information Management and Communication (IMCOM)}, 
  title={BCGAN: Facial Expression Synthesis by Bottleneck-Layered Conditional Generative Adversarial Networks}, 
  year={2021},
  volume={},
  number={},
  pages={1-4},
  abstract={Facial expression synthesis is widely applied to emotion prediction and face recognition for human-computer interaction. This task is challenging because it is difficult to reconstruct realistic and accurate facial expressions. Early deep learning methods focus only on pixel-level manipulation and are not suitable for generating realistic facial expressions. In this paper, we propose a bottleneck-layered conditional generative adversarial networks (BCGAN) for more realistic and accurate facial expression synthesis. BCGAN adopts a bottleneck layer that uses channel-wise concatenation in the generator to train with meaningful features only. In addition, a dense connection that links all bottleneck layers is added to generate an image which preserves the facial details of the original image. Both quantitative and qualitative evaluations were performed using the Radboud Faces Database (RaFD). Experimental results showed that BCGAN had 2% higher classification accuracy (98.7%) on the generated images as well as faster training speed compared to state-of-the-art approach.},
  keywords={Training;Human computer interaction;Face recognition;Generative adversarial networks;Information management;Task analysis;Image reconstruction;Facial expression synthesis;generative adversarial networks;densely connected convolutional networks},
  doi={10.1109/IMCOM51814.2021.9377424},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10435654,
  author={Hameed Abdul Hussein, Abbas and Ravindran, Gobinath and Latef naser, Zamen and Almusawi, Muntather and K, Santhiya},
  booktitle={2023 3rd International Conference on Mobile Networks and Wireless Communications (ICMNWC)}, 
  title={Identification of Fingerprint Orientation Using Improved Generative Adversarial Network with Support Vector Machine}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Fingerprint authentication is one of the methods used to prevent the loss of personal data, but the minutiae and angle variance of finger patterns make the process difficult. To overcome the issue, an authentication system for fingerprint orientation using an improved Generative Adversarial Network (GAN) with Support Vector Machine (SVM) is being developed. The process begins with image enhancement using Contrastive Limited Adaptive Histogram Equalization (CLAHE) techniques to increase image contrast. Next, GAN with SVM is employed to generate synthetic data through data augmentation, and decision-making is carried out using SVM. Both real and synthetic samples are binarized using the global thresholding technique, and edge-based thinning methods are applied to enhance the fingerprint patterns. Finally, features such as minutiae points of fingerprints are extracted using the Scale Invariant Feature Transform (SIFT) algorithm, serving as input for the SVM classifier. The implemented GAN-SVM model demonstrates superior performance, achieving a False Acceptance Rate (FAR) of 0.12%, a False Rejection Rate (FRR) of 1.3%, an Equal Error Rate (EER) of 0.29%, and an accuracy of 95.87%. When compared to previous models like Multi-layer Perceptron Neural Network (MLP), Fuzzy Commitment (FC), and Genetic Encryption Algorithm (GEA).},
  keywords={Support vector machines;Image edge detection;Authentication;Fingerprint recognition;Feature extraction;Generative adversarial networks;Synthetic data;Contrastive Limited Adaptive Histogram Equalization;Generative Adversarial Network;Global Thresholding;Scale Invariant Feature Transform;Support Vector Machine},
  doi={10.1109/ICMNWC60182.2023.10435654},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11065002,
  author={Li, Zhichao and Shen, Mingxue and Qin, Lei and Tian, Li},
  booktitle={2025 IEEE 14th Data Driven Control and Learning Systems (DDCLS)}, 
  title={Generative Adversarial Network based Data Augmentation Method for Bearing Fault diagnosis}, 
  year={2025},
  volume={},
  number={},
  pages={1095-1101},
  abstract={As a critical component of rotating machinery, the fault diagnosis of bearings holds significant importance. The deep learning-based approach to bearing fault diagnosis necessitates a substantial amount of fault data, which is often challenging to obtain in practical engineering scenarios. This data imbalance issue severely impacts the accuracy of fault diagnosis. To address this challenge, we propose a data augmentation method based on Multi-Source Generative Adversarial Network with Quality Assessment and Screening Module (MGAN-QASM). Firstly, the generator and discriminator are restructured using three loss functions, enhancing the stability of training and diversifying the generated data. Secondly, QASM screens for both similar and diverse samples to balance the training dataset. Finally, Deep Convolutional Neural Networks with Wide first-layer kernels (WDCNN) are employed for fault diagnosis. The results show that the proposed method has higher fault diagnosis accuracy than other methods under different imbalance ratio conditions.},
  keywords={Fault diagnosis;Training;Learning systems;Accuracy;Process control;Generative adversarial networks;Data augmentation;Quality assessment;Machinery;Kernel;Generative adversarial networks;Data augmentation;Imbalance;Quality assessment and screening;Fault diagnosis},
  doi={10.1109/DDCLS66240.2025.11065002},
  ISSN={2767-9861},
  month={May},}@INPROCEEDINGS{10097009,
  author={Chen, Po-Wei and Soo, Von-Wun},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={A Few Shot Learning of Singing Technique Conversion Based on Cycle Consistency Generative Adversarial Networks}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={We adopt the recent cycle consistent generative adversarial network (MaskCycleGAN-VC) that allows converting a specific singing technique using only a few articulations of singing voice as examples. Since it is often prone to fail to preserve the content information of the singing voice due to distortion and noise during the conversion, a self-supervised learning module is proposed as the basic framework to enforce content consistency without additional annotations. We evaluate the proposed methods on three datasets that were commonly used in pop songs which involve singing techniques in terms of breathy voice, vibrato, and vocal fry. Experiments showed that our proposed methods outperform the baseline in terms of audio quality and content preservation, including melody and singer‚Äôs timbral identity, without affecting the perception of singing techniques. 1},
  keywords={Acoustic distortion;Annotations;Self-supervised learning;Generative adversarial networks;Acoustics;Timbre;Task analysis;singing technique conversion;generative adversarial networks;few shot learning;cycle consistency;triplet learning},
  doi={10.1109/ICASSP49357.2023.10097009},
  ISSN={2379-190X},
  month={June},}@INPROCEEDINGS{10928135,
  author={Keser, Mert and Shoeb, Youssef and Knoll, Alois},
  booktitle={2024 IEEE International Conference on Vehicular Electronics and Safety (ICVES)}, 
  title={How Could Generative AI Support Compliance with the EU AI Act? A Review for Safe Automated Driving Perception}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Deep Neural Networks (DNNs) have become central for the perception functions of autonomous vehicles, substantially enhancing their ability to understand and interpret the environment. However, these systems exhibit inherent limitations such as brittleness, opacity, and unpredictable behavior in out-of-distribution scenarios. The European Union (EU) Artificial Intelligence (AI) Act, as a pioneering legislative framework, aims to address these challenges by establishing stringent norms and standards for AI systems, including those used in autonomous driving (AD), which are categorized as high-risk AI. In this work, we explore how the newly available generative AI models can potentially support addressing upcoming regulatory requirements in AD perception, particularly with respect to safety. This short review paper summarizes the requirements arising from the EU AI Act regarding DNN-based perception systems and systematically categorizes existing generative AI applications in AD. While generative AI models show promise in addressing some of the EU AI Act's requirements, such as transparency and robustness, this review examines their potential benefits and discusses how developers could leverage these methods to enhance compliance with the Act. The paper also highlights areas where further research is needed to ensure reliable and safe integration of these technologies.},
  keywords={Surveys;Vehicular and wireless technologies;Generative AI;Reviews;Europe;Robustness;Safety;Standards;Autonomous vehicles;Monitoring},
  doi={10.1109/ICVES61986.2024.10928135},
  ISSN={},
  month={Dec},}@ARTICLE{10988785,
  author={Glaws, Andrew and King, Ryan N. and Emami, Patrick and Buster, Grant and Benton, Brandon N. and Zhang, Xiangyu and Zamzam, Ahmed and Venkataramanan, Venkatesh and Macwan, Richard},
  journal={Computing in Science & Engineering}, 
  title={Designing Future Energy Systems with Generative AI}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={Energy systems are experiencing various changes that impact the distribution, use, and reliability of energy. Local utilities and municipalities must respond and adapt to these changes, moving towards a future energy system with modernized infrastructure and other targeted investments and policy decisions. However, planning for and enacting these advancements requires significant effort from experts and engineers to develop strategies that ensure a reliable and secure energy future. This includes characterizing the current energy infrastructure, identifying areas for development, and engaging with local community members. Emerging generative artificial intelligence techniques can alleviate pain points and help support the development of the next generation of energy systems. In this article, we highlight on-going generative AI work in the areas of atmospheric modeling, building energy management, and distribution network design, and we propose a vision for the role of generative AI that considers opportunities and identifies challenges inherent to this technology.},
  keywords={Generative AI;Data models;Reliability;Training;Next generation networking;Costs;Computational modeling;Urban areas;Superresolution;Investment},
  doi={10.1109/MCSE.2025.3567208},
  ISSN={1558-366X},
  month={},}@INPROCEEDINGS{11082753,
  author={Abudawood, T and Ahmed, Hamzah H. and Alrasheed, Mohammed and Alzeer, Abdullah},
  booktitle={2025 International Conference on Innovation in Artificial Intelligence and Internet of Things (AIIT)}, 
  title={The use of Generative AI, Optimization Algorithms, and IoT Technologies in Enhancing Pilgrims‚Äô Journey}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={This paper presents an innovative solution to enhance the transportation experience of pilgrims during Hajj, focusing on the journey from Jeddah to the holy cities of Makkah and Madinah. Managing the transportation of millions of pilgrims within a constrained timeframe poses significant logistical challenges, often addressed using inefficient manual methods. Our approach integrates Generative AI for data extraction and retrieval, Mixed-Integer Linear Programming (MILP) for algorithmic optimization, and Internet of Things (IoT) technologies for real-time tracking. The system automates the allocation of pilgrims to buses, optimizing travel distances, reducing the number of buses required, and maximizing capacity utilization. Furthermore, a voice-enabled chat interface powered by Retrieval-Augmented Generation (RAG) provides real-time information access for both staff and pilgrims. Comparative evaluations reveal that our approach outperforms traditional methods, achieving over 40 times faster bus allocations and a 13% reduction in the number of buses required, leading to enhanced efficiency, resource utilization, and cost savings of an approximately 16 million Saudi Riyals in two months. This system ultimately delivers a seamless, efficient, and comfortable transportation experience for pilgrims.},
  keywords={Technological innovation;Generative AI;Urban areas;Retrieval augmented generation;Transportation;Real-time systems;Mixed integer linear programming;Internet of Things;Resource management;Optimization;Artificial Intelligence;Generative AI;Optimization;Internet of Things;Hajj Pilgrims;Logistics},
  doi={10.1109/AIIT63112.2025.11082753},
  ISSN={},
  month={May},}@ARTICLE{9475883,
  author={Munir, Arslan and Blasch, Erik and Kwon, Jisu and Kong, Joonho and Aved, Alexander},
  journal={IEEE Aerospace and Electronic Systems Magazine}, 
  title={Artificial Intelligence and Data Fusion at the Edge}, 
  year={2021},
  volume={36},
  number={7},
  pages={62-78},
  abstract={Artificial intelligence (AI), owing to recent breakthroughs in deep learning, has revolutionized applications and services in almost all technology domains including aerospace. AI and deep learning rely on huge amounts of training data that are mostly generated at the network edge by Internet of Things (IoT) devices and sensors. Bringing the sensed data from the edge of a distributed network to a centralized cloud is often infeasible because of the massive data volume, limited network bandwidth, and real-time application constraints. Consequently, there is a desire to push AI frontiers to the network edge toward utilizing the enormous amount of data generated by IoT devices near the data source. The merger of edge computing and AI has engendered a new discipline, that is, AI at the edge or edge intelligence. To help AI make sense of gigantic data at the network edge, data fusion is of paramount significance and goes hand in hand with AI. This article focuses on data fusion and AI at the edge. In this article, we propose a framework for data fusion and AI processing at the edge. We then provide a comparative discussion of different data fusion and AI models and architectures. We discuss multiple levels of fusion and different types of AI, and how different types of AI align with different levels of fusion. We then highlight the benefits of combining data fusion with AI at the edge. The methods of AI and data fusion at the edge detailed in this article are applicable to many application domains including aerospace systems. We evaluate the effectiveness of combined data fusion and AI at the edge using convolutional neural network models and multiple hardware platforms suitable for edge computing. Experimental results reveal that combining AI with data fusion can impart a speedup of 9.8√ó while reducing energy consumption up to 88.5% over AI without data fusion. Furthermore, results demonstrate that data fusion either maintains or improves the accuracy of AI in most cases. For our experiments, data fusion imparts a maximum improvement of 15.8% in accuracy to AI.},
  keywords={Deep learning;Data integration;Distributed databases;Training data;Computer architecture;Data models},
  doi={10.1109/MAES.2020.3043072},
  ISSN={1557-959X},
  month={July},}@INPROCEEDINGS{10489036,
  author={Kumar, Manoj and Rai, Praveen Kumar and Kumar, Pankaj},
  booktitle={2024 2nd International Conference on Disruptive Technologies (ICDT)}, 
  title={A Novel Approach for Detecting Deepfake Face Using Machine Learning Algorithms}, 
  year={2024},
  volume={},
  number={},
  pages={1588-1592},
  abstract={In today's digital age, the ability to identify, differentiate, and authenticate manipulated online content is essential. Being ability to discriminate between the real and the fake is crucial. Recent advances in technologies such as artificial intelligence, machine learning, and deep learning are playing a major role in the generation of deepfake media (images and videos). Very realistic deep fake images and videos can be produced by utilizing sophisticated deep learning models such as generative adversarial neural networks (GAN s) and autoencoders, in conjunction with a sizable image collection pertaining to the subject matter. Deepfakes (DF) refer to artificially synthesized images or videos created using features such as face swapping and facial expression recombination. These face manipulation techniques have become extremely sophisticated. Deepfakes can be used to create child pornography, pornographic images of celebrities, revenge porn, fake news and harassment, spreading disinformation on social media platforms, financial fraud, election manipulation, and more. Therefore, there is a need to design and develop a robust framework to identify these deepfake images and videos. The purpose of this paper is to identify deepfakes from visual deepfake datasets and perform a comparative analysis of deep fake detection through machine learning algorithms.},
  keywords={Deep learning;Deepfakes;Visualization;Machine learning algorithms;Social networking (online);Face recognition;Voting;Deepfake;Artificial Intelligence (AI);Machine Learning (ML);Deep Learning;Generative Adversarial Neural Networks (GANs);Face Swapping},
  doi={10.1109/ICDT61202.2024.10489036},
  ISSN={},
  month={March},}@ARTICLE{9335504,
  author={Xie, Guo-Sen and Zhang, Zheng and Liu, Guoshuai and Zhu, Fan and Liu, Li and Shao, Ling and Li, Xuelong},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Generalized Zero-Shot Learning With Multiple Graph Adaptive Generative Networks}, 
  year={2022},
  volume={33},
  number={7},
  pages={2903-2915},
  abstract={Generative adversarial networks (GANs) for (generalized) zero-shot learning (ZSL) aim to generate unseen image features when conditioned on unseen class embeddings, each of which corresponds to one unique category. Most existing works on GANs for ZSL generate features by merely feeding the seen image feature/class embedding (combined with random Gaussian noise) pairs into the generator/discriminator for a two-player minimax game. However, the structure consistency of the distributions among the real/fake image features, which may shift the generated features away from their real distribution to some extent, is seldom considered. In this paper, to align the weights of the generator for better structure consistency between real/fake features, we propose a novel multigraph adaptive GAN (MGA-GAN). Specifically, a Wasserstein GAN equipped with a classification loss is trained to generate discriminative features with structure consistency. MGA-GAN leverages the multigraph similarity structures between sliced seen real/fake feature samples to assist in updating the generator weights in the local feature manifold. Moreover, correlation graphs for the whole real/fake features are adopted to guarantee structure correlation in the global feature manifold. Extensive evaluations on four benchmarks demonstrate well the superiority of MGA-GAN over its state-of-the-art counterparts.},
  keywords={Semantics;Generative adversarial networks;Training;Gallium nitride;Generators;Correlation;Task analysis;Feature generation;graph constraint;Wasserstein GAN;zero-shot learning (ZSL)},
  doi={10.1109/TNNLS.2020.3046924},
  ISSN={2162-2388},
  month={July},}@ARTICLE{10400892,
  author={Zhou, Zhili and Bao, Zhipeng and Jiang, Weiwei and Huang, Yuan and Peng, Yun and Shankar, Achyut and Maple, Carsten and Selvarajan, Shitharth},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={Latent Vector Optimization-Based Generative Image Steganography for Consumer Electronic Applications}, 
  year={2024},
  volume={70},
  number={1},
  pages={4357-4366},
  abstract={In consumer electronic applications, to transmit secret images securely, it is required to explore the advanced covert communication technology, i.e., Generative Image Steganography (GIS). However, the existing GIS schemes suffer from the issues of poor stego-image quality and limited hiding capacity. Consequently, these GIS schemes cannot meet the requirements of consumer electronic applications, in which massive secret information needs to be transmitted securely. To address the above issues, we propose a Latent Vector Optimization (LVO)-based GIS scheme, in which the information hiding is implemented by the flow-based generative model during the image generation. Specifically, the LVO algorithm is introduced to compute the hiding probability of each element of latent vector according to its impact on the quality of the stego-image generated from the latent vector. Then, it hides more information in elements with higher hiding probability. The extensive experiments demonstrate that, compared to current GIS schemes, the proposed LVO-based GIS scheme generates higher-quality images, while maintaining hiding capacity (up to  $5.0 \, bpp$ ) and accurate information extraction (almost 100% accuracy rate).},
  keywords={Steganography;Consumer electronics;Generative adversarial networks;Servers;Pareto optimization;Data models;Receivers;Generative model;generative steganography;AI-generated content;consumer electronics},
  doi={10.1109/TCE.2024.3354824},
  ISSN={1558-4127},
  month={Feb},}@INPROCEEDINGS{9261734,
  author={Zhang, Zhen and Zhang, Liuyang and Chen, Xuefeng and Xu, Yafei},
  booktitle={2020 International Conference on Sensing, Measurement & Data Analytics in the era of Artificial Intelligence (ICSMD)}, 
  title={Modified Generative Adversarial Network for Super-Resolution of Terahertz Image}, 
  year={2020},
  volume={},
  number={},
  pages={602-605},
  abstract={Terahertz (THz) images have low spatial resolution, blurring contour features and high background noise owing to the limitation of terahertz (THz) wavelengths and the THz imaging systems. We have proposed a modified Generative Adversarial Network (GAN) for super-resolution (SR) purpose. To fit the THz images, we design a kind of image degradation model to generate low-resolution images with Gaussian blur and white Gaussian noise. We establish a dataset of damage images in the field of non-destructive testing (NDT) for training and testing. The experimental results on THz images demonstrate that the improved GAN model can improve the quality of THz images effectively. Our method can be beneficial to improve the accuracy of THz NDT with low resolution.},
  keywords={Training;Image resolution;Imaging;Gallium nitride;Testing;Generators;Generative adversarial networks;THz image;super-resolution;degradation model;deep learning},
  doi={10.1109/ICSMD50554.2020.9261734},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10070223,
  author={Ding, Yuhang and Jiang, Wenrong},
  booktitle={2022 International Conference on Artificial Intelligence, Information Processing and Cloud Computing (AIIPCC)}, 
  title={Intrusion Detection Method Based On Improved Conditional Generative Adversarial Network}, 
  year={2022},
  volume={},
  number={},
  pages={37-40},
  abstract={At present, the intrusion detection model mainly uses anomalous behavior to establish a library of intrusion behavior patterns, and determines whether the intrusion behavior conforms to the intrusion behavior specification by comparing the library of intrusion behavior patterns. Once there is a change in intrusion behavior or a new type of network attack, the existing intrusion detection model cannot make corresponding changes according to the actual changes. Therefore, making intrusion detection models have the ability to learn autonomously and be able to adapt to changes in the network environment to detect new types of unknown attacks has received increasing attention from many security researchers. In this paper, we propose an intrusion detection model (CGAN-RF) based on conditional generative adversarial network (CGAN) and random forest (RF). The CGAN-RF model improves the class imbalance problem of the dataset by generating samples to enhance the detection efficiency of minority and unknown classes.},
  keywords={Radio frequency;Adaptation models;Intrusion detection;Information processing;Forestry;Generative adversarial networks;Libraries;component;intrusion detection;convolutional neural networks;conditional generation adversarial networks;class balancing technology;random forest},
  doi={10.1109/AIIPCC57291.2022.00016},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9065225,
  author={Lin, Jhe-Wei and Tseng, Jo-Han and Chang, Rong-Guey},
  booktitle={2020 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Chinese Story Generation Using Conditional Generative Adversarial Network}, 
  year={2020},
  volume={},
  number={},
  pages={457-462},
  abstract={Natural language processing has become popular considerably in a wide range of applications, but it still has been rarely applied to automatic text generation. In this paper, we focus on allowing the user to determine which content the machine is to narrate and the user can just give a summary to generate a complete paragraph. Based on the attention mechanism, we propose a Syntax-Guided Machine Reading Comprehension (SG-Net) to accept Chinese word vectors, learn from Chinese data sets, and semi-supervised self-growing generative adversarial network (SG-GAN) generate sequences with more realistic sequences. In order to reasonably evaluate the quality of the text produced by the machine, we also design a set of experiments by manipulating the content of the input sequence semantic information. It can be seen from the experimental results that both SG-Net and SG-GAN can understand the basic semantics and grammar and write a readable article. In summary, SG-Net may only recite the statements that have been read and SG-GAN can understand more semantic and grammar than SG-Net.},
  keywords={Vocabulary;Mathematical model;Generative adversarial networks;Gallium nitride;Semantics;Neural networks;Computational modeling;Deep Learning;Neural Chinese Story Generation;Nature language processing;Attention mechanisms},
  doi={10.1109/ICAIIC48513.2020.9065225},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10206191,
  author={Mendis, G. L. M. M. and Deshan, W. M. Y and Bandara, H. M. G. M. and Gunethilake, K. C. and Wijendra, Dinuka and Krishara, Jenny},
  booktitle={2023 6th International Conference on Artificial Intelligence and Big Data (ICAIBD)}, 
  title={Look AI ‚Äì An Intelligent System for Socialization of Visually Impaired}, 
  year={2023},
  volume={},
  number={},
  pages={351-356},
  abstract={It has found that 30% of the people among the visually impaired people are having a significant number of depressive symptoms whereas, the prevalence of depression in blind people was reported to be 33%, or nearly double the rate of the general population. Therefore, social activities among visually impaired people should increase. This research paper provides a unique system for assisting visually impaired individuals in navigating indoor environments heavily relies on the use of artificial intelligence, particularly deep learning and computer vision techniques. By leveraging these advanced technologies, the system can analyze and process large amounts of visual data in real-time, accurately identifying and locating various objects in the environment, including faces, doors, stairs, cross walks, traffic lights, potholes and other obstacles. The system then provides real-time feedback to the user via an audio interface, enabling them to navigate indoor and outdoor environments safely and independently. The use of artificial intelligence in this system is particularly significant, as it enables the system to adapt and improve over time based on user feedback and additional data. That means, the system can continuously improve its performance and accuracy, ultimately resulting in a more effective and reliable tool for visually impaired individuals. The authors have also evaluated the system in a real-world setting, demonstrating its effectiveness in assisting visually impaired individuals with indoor navigation. Overall, the proposed system has the potential to significantly enhance the quality of life for visually impaired individuals, showcasing the transformative power of artificial intelligence in addressing real-world challenges.},
  keywords={Visualization;Machine learning algorithms;Local government;Smart homes;Organizations;Stairs;User experience;artificial intelligence;machine learning;convolutional neural networks;recurrent neural network},
  doi={10.1109/ICAIBD57115.2023.10206191},
  ISSN={2769-3554},
  month={May},}@INPROCEEDINGS{10489393,
  author={Mimani, Sushant and Ramakrishnan, Rakesh and Rohella, Piyush and Jiwani, Nasmin and Logeshwaran, J.},
  booktitle={2024 2nd International Conference on Disruptive Technologies (ICDT)}, 
  title={The Utilization of AI Extends Beyond Payment Systems to E-Commerce Store Development}, 
  year={2024},
  volume={},
  number={},
  pages={555-560},
  abstract={In the age of advancing technology, Artificial Intelligence (AI) has become a fundamental force in almost every industry, including electronic commerce (e-commerce). AI can be used to power e-commerce store development in multiple ways, such as enhancing customer experience, improving search, optimizing product recommendations and inventory management, and improving payment systems. Through algorithms and machine learning, AI allows e-commerce storeowners to create and deploy intelligent bots, with predetermined parameters, to chat with customers, answer queries and suggest products or services. AI also enables customers to access automated search functions, product recommendations based on their previous purchases, and automated customer experiences. Improved payment systems can also be facilitated by AI to streamline transactions, reduce security risks, and enhance user experience. All of these features allow e-commerce stores to remain competitive in today's market. Ultimately, AI empowers e-commerce stores to stand out and drive sales.},
  keywords={Industries;Machine learning algorithms;Force;Machine learning;Inventory management;User experience;Electronic commerce;Artificial Intelligence;Payment Systems;Commerce;Store Development;Utilization},
  doi={10.1109/ICDT61202.2024.10489393},
  ISSN={},
  month={March},}@INPROCEEDINGS{10533091,
  author={Al-Remawi, Mayyas and Aburub, Faisal},
  booktitle={2024 2nd International Conference on Cyber Resilience (ICCR)}, 
  title={Clinical Applications of AI in Post-Cancer Rehabilitation}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The article examines the potential of Artificial Intelligence (AI) and machine learning in oncology rehabilitation. Traditional rehabilitation models have limitations in delivering personalized care in real-time. AI technologies close these gaps by utilizing advanced predictive capabilities and optimizing treatment strategies. Convolutional Neural Networks (CNNs) in radiomics provide a proactive approach to managing conditions such as lymphedema. In the field of physical rehabilitation, the integration of robotic systems with AI algorithms allows for real-time adaptive control mechanisms. This integration results in optimized muscle fiber recruitment and improves functional outcomes. Moreover, AI-powered platforms provide individualized psychological and nutritional assistance, enhancing the comprehensive care of individuals who have survived cancer. Despite the promising advancements, ethical considerations, including data privacy and algorithmic bias, necessitate a multidisciplinary approach for responsible implementation. Computational limitations, such as the requirement for extensive labeled datasets, present additional challenges. The analysis highlights the necessity of additional research to validate these emerging technologies, overcome their limitations, and establish ethical frameworks for their responsible clinical implementation.},
  keywords={Ethics;Psychology;Optical fiber networks;Muscles;Oncology;Prediction algorithms;Real-time systems;Post-Cancer Rehabilitation;Artificial Intelligence in Healthcare;Ethical Considerations in AI Implementation;Convolutional Neural Networks;Predictive Modeling in Oncology},
  doi={10.1109/ICCR61006.2024.10533091},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10550305,
  author={Dhanasekar, R. and Vijayaraja, L. and Rithika, C and Avanthika, S and Thalapathiraj, S. and Premkumar, R},
  booktitle={2024 International Conference on Communication, Computing and Internet of Things (IC3IoT)}, 
  title={Navigating Emerging Technologies: A Comprehensive Review of 5G and the Evolving Landscape of 6G Communication}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The purpose of this review is to investigate the application of artificial intelligence (AI), machine learning (ML), and the internet of things (IoT) within the context of 5G and 6G. The abstract provides an overview of this investigation. It sheds light on the growing demand for these technologies as well as the ways in which they could encourage innovation across a variety of business sectors. The most recent work in these disciplines will be examined, and insights into the potential and difficulties of implementing it in 5G and 6G networks will be provided by the study. The focus of the review is discussed briefly in the abstract; however, additional information on specific research and development fields would be valuable. It is also important to explore the potential repercussions that these technologies may have in the context of 5G and 6G, including the implications that they may have on businesses and on society.},
  keywords={6G mobile communication;Technological innovation;5G mobile communication;Reviews;Navigation;Machine learning;Telecommunication computing;Artificial Intelligence;Machine learning;Internet of Things},
  doi={10.1109/IC3IoT60841.2024.10550305},
  ISSN={},
  month={April},}@INPROCEEDINGS{10709187,
  author={Liang, Congxiao and Wang, Mini Han and Liu, Haoyang and Chong, Kelvin KL},
  booktitle={2024 IEEE 2nd International Conference on Image Processing and Computer Applications (ICIPCA)}, 
  title={Exploring Meibomian Gland Dysfunction Grading: A Comparison of Machine Learning and XAI Approaches}, 
  year={2024},
  volume={},
  number={},
  pages={2021-2024},
  abstract={This research investigates the effectiveness of employing a machine learning methodology and an Explainable Artificial Intelligence (XAI) tool for the assessment of Meibomian Gland Dysfunction (MGD). Utilizing ResNet34, a convolutional neural network (CNN), trained on a diverse dataset comprising images depicting varying degrees of MGD severity, the machine learning approach endeavors to classify MGD severity into four distinct grades (0, 1, 2, 3) by leveraging extracted characteristic features. Findings reveal comparable accuracy between ResNet34 and the XAI tool, with ResNet34 achieving a slightly lower accuracy of 99.1% in contrast to the XAI tool's 99.4%. However, ResNet34 demonstrates marginally higher precision and F1-score at 98.2% and 98.45%, respectively, suggesting a nuanced advantage in precision-recall equilibrium. Conversely, the XAI tool maintains a commendable precision of 97.2% and an Fl-score of 97.94%, alongside a recall of 98.7%, underscoring its effectiveness in discerning positive instances. Noteworthy is that ResNet34 operates as a black-box model, providing limited interpretability, while the XAI tool emphasizes transparency by furnishing clinicians with understandable MGD grading elucidations derived from meibomian gland segmentation and atrophy analysis. This transparency enhances trust and comprehension, which are integral for clinical acceptance and decision-making. Furthermore, the utilization of XAI heatmap generation facilitates data quality enhancement, as evidenced by instances of erroneous artifact identification, emphasizing the imperative nature of artifact elimination for the refinement of MGD grading procedures.},
  keywords={Heating systems;Accuracy;Explainable AI;Data integrity;Decision making;Glands;Closed box;Computer applications;Feature extraction;Convolutional neural networks;Meibomian Gland Dysfunction;Machine Learning;Explainable Artificial Intelligence;ResNet34;Interpretability},
  doi={10.1109/ICIPCA61593.2024.10709187},
  ISSN={},
  month={June},}@ARTICLE{11119538,
  author={Tinago, Ngonidzashe and Verkijika, Silas Formunyuy and Eva Mamabolo, Kelibone},
  journal={IEEE Access}, 
  title={Deepfakes in Visual Art: Differentiating AI-Generated Art From Human Art Using Convolutional Neural Networks (CNN)}, 
  year={2025},
  volume={13},
  number={},
  pages={141484-141495},
  abstract={As AI technology evolves, seeing is not believing. The boundary between human and machine creativity is increasingly blurred, presenting challenges for the art industry. This is more pronounced nowadays as advancements in AI technology make it increasingly easy to create highly realistic synthetic art. This study explores the use of Convolutional Neural Networks (CNNs) to differentiate AI-generated art from human-created art. By employing Error Level Analysis (ELA), an image forensic technique for detecting fake and real images, this study develops a robust CNN classifier. Using the AI-ArtBench dataset, the optimal model achieves a 99% classification accuracy, even when tested on art from a different generative model. While AI-image detection remains a ‚Äúcat and mouse‚Äù pursuit due to advancements in generative AI, the findings of this study highlight that there are clear, discriminable differences between AI-generated and human-created art. The implications of this research extend beyond academic inquiry. They offer support for artists, collectors, curators, and policymakers as they navigate the complexities of AI‚Äôs expanding availability and address the evolving role of AI in the art world. It sets the groundwork for application within fields faced with the same or similar challenges.},
  keywords={Art;Deepfakes;Convolutional neural networks;Artificial intelligence;Feature extraction;Accuracy;Generative adversarial networks;Data models;Standards;Diffusion models;Artificial intelligence (AI);convolutional neural network (CNN);deep learning;diffusion model;error level analysis (ELA);generative adversarial network (GAN)},
  doi={10.1109/ACCESS.2025.3596882},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10303076,
  author={Stave, Daniel √Örrestad and Korneliussen, Hanne and Hjellup, H. N√∏kleby and Shrestha, Raju},
  booktitle={2023 4th International Conference on Artificial Intelligence, Robotics and Control (AIRC)}, 
  title={SoMeMax - A Novel AI-driven Approach to Generate Artificial Social Media Content That Maximises User Engagement}, 
  year={2023},
  volume={},
  number={},
  pages={94-100},
  abstract={Today, many artificial or virtual influencers roam social media platforms to maximise followers and offer commercial options for companies. This work focuses on developing artificial influencers using state-of-the-art techniques within deep learning. Specifically, an autonomous theoretical framework for generating social media content that maximises user engagement is proposed. Deep learning models for generating realistic images and hashtags are trained on a dataset from a social media platform, and content is optimised for user engagement using an evolutionary algorithm. The generated images were evaluated by participants from existing social media users through two separate surveys. The complete framework is built, trained, and tested, and functionality is confirmed. The framework, which appears to be the first of its kind, produces content that matches the users‚Äô preferences well.},
  keywords={Deep learning;Surveys;Social networking (online);Sociology;Evolutionary computation;Companies;Artificial intelligence;AI;Deep learning;CNN;GAN;EA;Social Media;Artificial Influencer;User engagement},
  doi={10.1109/AIRC57904.2023.10303076},
  ISSN={},
  month={May},}@INPROCEEDINGS{10823621,
  author={Liu, Yonggang and Awang, Hapini and Mansor, Nur Suhaili},
  booktitle={2024 7th International Conference on Internet Applications, Protocols, and Services (NETAPPS)}, 
  title={Exploring Potential Applications of Generative Artificial Intelligence in Future Healthcare: The Case of Sora}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={In February 2024, OpenAI unveiled Sora, which built on the foundation of ChatGPT and was able to generate videos based on text, representing one of the most advanced Generative Artificial Intelligences (GAIs) in the current world. As a diffusion model, Sora has the ability to generate long and imaginative videos with multiple characters, genre-specific movements, and sophisticated scenarios based only on textual descriptions, as well as excellent scalability. The research objectives are formulated as follows: to explore Sora's potential applications in future healthcare; to identify Sora's potential influence on visualizations of the healthcare industry; and to investigate Sora's potential impact on diagnostic methods. This study adopts the documentary research method. This study finds that Sora has great potential applications in future healthcare in the following aspects: healthcare robots, virtual doctors, simulating surgical procedures, visualizations of medical academic achievements, visualizing medical records, private assistant-type and companion-type robotic doctors, humanmachine interaction in healthcare, reducing burnout among doctors and nurses and so on. This study is one of the earliest to research Sora's potential applications in future healthcare in above mentioned aspects. The current study will not only enrich theoretical research on the integration of GAI (especially Sora) and healthcare, but also contribute to healthcare practice.},
  keywords={Industries;Visualization;Technological innovation;Protocols;Service robots;Scalability;Medical services;Chatbots;Text to video;Medical diagnostic imaging;Sora;Generative Artificial Intelligence (GAI);Healthcare},
  doi={10.1109/NETAPPS63333.2024.10823621},
  ISSN={},
  month={Nov},}@ARTICLE{10932698,
  author={Song, Shijun and Fan, Min},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Emergency Routing Protocol for Intelligent Transportation Systems Using IoT and Generative Artificial Intelligence}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={Urban populations are always on the increase, increasing the number of vehicles, leading to severe congestion, longer travel times, and substantial emergency vehicle response time delays. This paper presents a routing protocol for Intelligent Transportation Systems (ITS), incorporating a Belief-Desire-Intention (BDI) model and generative Artificial Intelligence (AI) techniques. The proposed system utilizes BDI-based generative AI models, which rely on predefined logic and rules rather than machine learning to make real-time routing decisions. These decisions are based on data from vehicle-to-vehicle (V2V) communications, roadside units (RSUs) and IoT sensors, which integrate traffic density, congestion levels, collision avoidance and hazard detection. The system aims to optimize the accuracy of route selection, energy consumption, and communication latency. The simulation results, implemented using NS3 for real-world traffic scenarios, show improvements in route selection accuracy, collision avoidance, and energy efficiency compared to traditional routing methods. Specifically, the proposed system achieved a route selection accuracy of 95%, a collision avoidance rate of 95%, and reduced the communication latency to 105 ms, outperforming the other two methods. Furthermore, energy consumption was minimized and reduced to 85 J per route. These results highlight the potential of BDI-based routing with generative AI to improve ITS performance, particularly in real-time traffic management.},
  keywords={Real-time systems;Routing protocols;Routing;Generative AI;Sensors;Artificial intelligence;Decision making;Intelligent sensors;Transportation;Sensor systems;BDI-based decision making;real-time routing;intelligent transportation systems;generative AI;NS3 simulation},
  doi={10.1109/TITS.2025.3546340},
  ISSN={1558-0016},
  month={},}@INPROCEEDINGS{10408888,
  author={Fu, Cong and Tao, Hongzhu and Shang, Jingan and Huang, Yunhao and Wang, Jiaqi and Xu, Kai and Xin Ma, Xin and Sheng, XinXin},
  booktitle={2023 IEEE 11th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={Anomaly Detection Method Based on Gaussian Mixture Model and Orthogonal Generative Adversarial Network}, 
  year={2023},
  volume={11},
  number={},
  pages={1909-1915},
  abstract={In the analysis of power grid data, a critical task is to identify samples that significantly deviate from others, which constitutes anomaly detection. Presently, anomaly detection methods based on deep generative models face challenges related to complex network structures and difficult training processes. Addressing these issues, this paper proposes a lightweight anomaly detection method for power grid data based on Gaussian Mixture Model and Orthogonal Generative Adversarial Network. This approach combines traditional statistical techniques with advanced deep learning methods. In comparison to anomaly detection methods relying solely on deep generative models, this method features a more concise network structure, reducing both the model's complexity and training time, while retaining a certain level of expressive power.},
  keywords={Training;Deep learning;Feature extraction;Generative adversarial networks;Encoding;Anomaly detection;Gaussian mixture model;Anomaly Detection;Gaussian Mixture Model;Generative Adversarial Network},
  doi={10.1109/ITAIC58329.2023.10408888},
  ISSN={2693-2865},
  month={Dec},}@INPROCEEDINGS{11158710,
  author={Wang, Yunning},
  booktitle={2025 5th International Conference on Artificial Intelligence and Education (ICAIE)}, 
  title={Prospects of Generative Video Technology in the Field of Chinese Classical Literature: Exploring Female Education Through the Reimagining of Chinese Poetic Imagery Using Runway ML Gen-3 Alpha}, 
  year={2025},
  volume={},
  number={},
  pages={407-411},
  abstract={With the rapid advancement of artificial intelligence, generative video technology offers new possibilities in the field of education, particularly in enhancing women's literary skills and driving educational innovation. Chinese classical poetry, as a cultural treasure, often poses challenges for students due to its abstract imagery and complex content. These challenges are especially pronounced in women's education, where traditional teaching methods often lack intuitiveness and interactivity. This study, based on the generative video capabilities of the Runway ML Gen-3 Alpha model, explores how video generation technology can enhance female students' interest in learning and improve their memory retention by enabling them to perceive the imagery of classical poetry more intuitively. The research analyzes the applicability of generative video technology in women's education from a theoretical perspective and proposes specific methods and pathways for integrating it into classical literature teaching. By emphasizing women's cognitive strengths in visual perception and emotional resonance, the study further investigates how technology-driven teaching models can optimize educational outcomes and achieve a deep integration of traditional literature with modern technology. The findings indicate that generative video technology not only enhances the vividness of learning but also promotes the innovation of educational methods, offering new directions and approaches for cultural heritage and educational reform in the future.},
  keywords={Surveys;Technological innovation;Visualization;Atmospheric modeling;Education;Resonance;Cultural differences;Artificial intelligence;Videos;Visual perception;Women's Education;Multimedia Teaching;Educational Innovation;Runway ML;Gen-3 Alpha},
  doi={10.1109/ICAIE64856.2025.11158710},
  ISSN={},
  month={May},}@INPROCEEDINGS{10593404,
  author={Pooja and Krishna, Somanchi Hari and Kumar, G.M. Prem and Reddy, Y Manohar and Ayarekar, Sachin and Lourens, Melanie},
  booktitle={2024 International Conference on Communication, Computer Sciences and Engineering (IC3SE)}, 
  title={Generative AI in Business Analytics by Digital Transformation of Artificial Intelligence Techniques}, 
  year={2024},
  volume={},
  number={},
  pages={1532-1536},
  abstract={The advent of Digital Transformation introduces numerous challenges, opportunities, and changes for both the economy and society. Companies are confronted with rapidly evolving dynamics and must enhance their agility to effectively leverage these advancements. However, a significant aspect of Digital Transformation is the increasing prominence of Artificial Intelligence (AI). This document proposes a pragmatic approach to change management for organizations, encompassing both top-down and bottom-up elements. The aim is to facilitate a structured, organization-wide transformation process for the integration of AI technology into daily business operations. This approach endeavours to address the organization comprehensively and seeks to seamlessly integrate AI within existing strategic frameworks. In today's swiftly evolving business landscape, ongoing employee learning stands as a crucial element for organizational success. Businesses must prioritize transforming their capabilities and prioritize learning as a strategic imperative. To ensure the sustainability of their operations, organizational leadership should concentrate on enhancing employees' skills and promoting mental well-being. This involves gradually integrating new techniques that facilitate transformative change and fostering an environment conducive to disrupting prevailing patterns and nurturing the emergence of new ones. An example of such transformation is the rapid acceleration of digitalization.},
  keywords={Technological innovation;Leadership;Generative AI;Digital transformation;Bibliographies;Key performance indicator;Companies;SMEs;Digital transformation;Business Analytics;Artificial Intelligence},
  doi={10.1109/IC3SE62002.2024.10593404},
  ISSN={},
  month={May},}@INPROCEEDINGS{10392083,
  author={Ghadekar, Premanand and Gundawar, Ayush and Kamnapure, Somesh and Manjramkar, Devang and Gujarathi, Ishan and Deore, Dhananjay},
  booktitle={2023 7th International Conference On Computing, Communication, Control And Automation (ICCUBEA)}, 
  title={Improving Image Quality of Noisy Images Through Denoising and Style GAN Technique}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This research proposes an approach to enhance the denoising and upscaling performance of noisy images using Generative Adversarial Networks (GANs), particularly Style GAN architecture. Denoising and upscaling noisy images are crucial in many computer vision applications, and GANs have shown remarkable effectiveness in creating high-quality images. However, training Style GAN requires huge amount of data and is computationally expensive. To address this issue, this study proposes using various filters such as mean, median, and weighted median to pre-process the noisy images before feeding them to Style GAN. The proposed approach achieves superior denoising and up scaling compared with other system in terms of FID and inception score, and further exploration of hyperparameters and variations of the Style GAN architecture can lead to even better results.},
  keywords={Image quality;Training;Filtering;Noise reduction;Superresolution;Computer architecture;Generative adversarial networks;Diffusion Modelling;Style Gan;Deep learning;Super resolution;Image Processing;median filtering},
  doi={10.1109/ICCUBEA58933.2023.10392083},
  ISSN={2771-1358},
  month={Aug},}@ARTICLE{10770591,
  author={Akpinar, Muhammed Halil and Sengur, Abdulkadir and Salvi, Massimo and Seoni, Silvia and Faust, Oliver and Mir, Hasan and Molinari, Filippo and Acharya, U. Rajendra},
  journal={IEEE Open Journal of Engineering in Medicine and Biology}, 
  title={Synthetic Data Generation via Generative Adversarial Networks in Healthcare: A Systematic Review of Image- and Signal-Based Studies}, 
  year={2025},
  volume={6},
  number={},
  pages={183-192},
  abstract={Generative Adversarial Networks (GANs) have emerged as a powerful tool in artificial intelligence, particularly for unsupervised learning. This systematic review analyzes GAN applications in healthcare, focusing on image and signal-based studies across various clinical domains. Following Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) guidelines, we reviewed 72 relevant journal articles. Our findings reveal that magnetic resonance imaging (MRI) and electrocardiogram (ECG) signal acquisition techniques were most utilized, with brain studies (22%), cardiology (18%), cancer (15%), ophthalmology (12%), and lung studies (10%) being the most researched areas. We discuss key GAN architectures, including cGAN (31%) and CycleGAN (18%), along with datasets, evaluation metrics, and performance outcomes. The review highlights promising data augmentation, anonymization, and multi-task learning results. We identify current limitations, such as the lack of standardized metrics and direct comparisons, and propose future directions, including the development of no-reference metrics, immersive simulation scenarios, and enhanced interpretability.},
  keywords={Generative adversarial networks;Biomedical imaging;Measurement;Magnetic resonance imaging;Medical diagnostic imaging;Imaging;Generators;Synthetic data;Computed tomography;Training;Generative adversarial networks (GANs);medical imaging;data generation;signal simulation;deep learning},
  doi={10.1109/OJEMB.2024.3508472},
  ISSN={2644-1276},
  month={},}@INPROCEEDINGS{10143123,
  author={De Silva, Daswin and Mills, Nishan and El-Ayoubi, Mona and Manic, Milos and Alahakoon, Damminda},
  booktitle={2023 IEEE International Conference on Industrial Technology (ICIT)}, 
  title={ChatGPT and Generative AI Guidelines for Addressing Academic Integrity and Augmenting Pre-Existing Chatbots}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Chat Generative Pretrained Transformer (Chat-GPT) and related Generative AI models are leading a paradigm shift in the acceptance and application of Artificial Intelligence (AI) across all disciplines and industry sectors. Despite the criticisms of an ‚Äòintelligence without knowledge or reasoning or the notions of truth‚Äô, ChatGPT is highly effective at human-like conversation with seemingly sophisticated and useful responses to questions, summarization, classification, extraction and generation tasks. Unlike similar large AI models in the modalities of image, audio and video, text-based conversation is straightforward and familiar to a large audience of regular users of the Internet and smartphone applications. This is further accentuated by the large-scale adoption of ‚Äòstandard‚Äô chatbot technologies for trivial conversations in task-specific automation, across every industry sector. This rare combination of highly effective human-like conversation, familiarity of foundational technology and versatility of intelligent application, has led to several challenges and opportunities in leveraging generative AI. A primary challenge is its impact on the academic integrity of scholarly work, where AI-generated content can be useful and detrimental in both teaching and research. On the other hand, ChatGPT presents a unique opportunity in augmenting preexisting (‚Äòstandard‚Äô) chatbots with human-like conversation for advanced intelligent automation, across all application domains. Although diametrically opposed, the challenge of addressing academic integrity and the opportunity of augmenting pre-existing chatbots are grounded in the conversational AI capabilities of ChatGPT and similar generative AI models. In this paper, we investigate these formative capabilities and present guidelines for leveraging ChatGPT and similar generative AI models.},
  keywords={Industries;Intelligent automation;Education;Oral communication;Chatbots;Transformers;Internet;ChatGPT;Academic Integrity;Generative AI;Intelligent Automation;Chatbot;Artificial Intelligence;Pretrained Language Models;GPT3},
  doi={10.1109/ICIT58465.2023.10143123},
  ISSN={2643-2978},
  month={April},}@INPROCEEDINGS{11163176,
  author={Yan, Jie and Yang, Tao and Zhou, Zhinan and Yuan, Haijing and Liu, Shan},
  booktitle={2025 IEEE 12th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={Wavelet-Based Dual-Flow Feature Collaborativing GAN for Image Inpainting}, 
  year={2025},
  volume={12},
  number={},
  pages={412-418},
  abstract={Image inpainting is an important field in artificial intelligence, that aims to generate exquisite images from incomplete input images. At present, most methods utilize unilateral structural information to assist in the repair process, but when there is extensive distortion in the image, this method cannot generate beautiful results. Based on this, a wavelet-based dual-flow feature collaborativing GAN (WDFC-GAN) is proposed, which consists of two encoding and decoding subnetworks, namely the wavelet stream and Transformer stream. The wavelet stream is devised to adopt the wavelet transform for better capturing frequency domain features. The Transformer stream is presented to use stacked fast Fourier Transformers (FFTr) to expand the receptive fields effectively. Besides, a wavelet-based self-attention (WSA) is presented for constructing long-range correlated prominent structural information in multidimensional frequency information, thereby generating better results. A large number of qualitative and quantitative experiments have shown that the proposed method outperforms the state-of-the-art methods on Paris StreetView and CelebA-HQ.},
  keywords={Wavelet transforms;Wavelet domain;Frequency-domain analysis;Semantics;Streaming media;Maintenance engineering;Transformers;Generative adversarial networks;Feature extraction;Artificial intelligence;Image inpainting;fast Fourier Transformer;self-attention;generative adversarial network},
  doi={10.1109/ITAIC64559.2025.11163176},
  ISSN={2693-2865},
  month={May},}@INPROCEEDINGS{10723573,
  author={Sun, Wan and Wang, Tong and Liang, Guolong and Wang, Jinjin},
  booktitle={2024 OES China Ocean Acoustics (COA)}, 
  title={Improving Directional Resolution of Ocean Sound Sources Based on Oceanic Boundary Generative Adversarial Network}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The rapid development of artificial intelligence has brought new possibilities to signal processing. In the field of ocean moving target monitoring, traditional array signal processing faces significant challenges due to strong ocean background noise and observation equipment limitations. This paper presents a novel approach for enhancing the directional resolution of ocean sound sources using an oceanic boundary generative adversarial network (OB-GAN). Traditional methods used to analyze underwater sound signals often face challenges in accurately determining the direction of sound sources due to complex environmental conditions. The proposed OB-GAN framework leverages generative adversarial networks (GANs) to learn and enhance the spatial features of underwater sound signals, enabling more precise localization of sound sources. Experimental results demonstrate significant improvements in the directional resolution of ocean sound sources compared to existing methods, showcasing the potential of OB-GAN for advancing underwater acoustic signal processing.},
  keywords={Location awareness;Oceans;Parallel processing;Generative adversarial networks;Background noise;Spatial resolution;Underwater acoustics;Signal resolution;Faces;Monitoring;resolution enhance;sound source improvement;artificial intelligence;OB-GAN},
  doi={10.1109/COA58979.2024.10723573},
  ISSN={},
  month={May},}@INPROCEEDINGS{8947758,
  author={Yook, Dongsuk and Yoo, In-Chul and Yoo, Seungho},
  booktitle={2018 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Voice Conversion Using Conditional CycleGAN}, 
  year={2018},
  volume={},
  number={},
  pages={1460-1461},
  abstract={Voice conversion (VC) modifies characteristics of speech, such as gender and speaker identities. The VC can be applied to various tasks including speaking assistance and speaker anonymization. Generally, such VC techniques require parallel speech data for training, which is very expensive. Recently, voice conversion has been accomplished using CycleGAN, which does not require parallel speech data. In this paper, we further extend the idea of using CycleGAN to convert multiple speakers' voices by conditioning the CycleGAN using speaker identity information.},
  keywords={Generative adversarial networks;Generators;Gallium nitride;Task analysis;Logic gates;Training;Linguistics;voice conversion;generative adversarial networks (GAN);CycleGAN;Conditional CycleGAN (CC-GAN)},
  doi={10.1109/CSCI46756.2018.00290},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9792975,
  author={Mittal, Harsh and Rai, Vaibhav and Sonawane, Swaraj and Mhatre, Sneha},
  booktitle={2022 International Conference on Applied Artificial Intelligence and Computing (ICAAIC)}, 
  title={Image Resolution Enhancer using Deep Learning}, 
  year={2022},
  volume={},
  number={},
  pages={578-586},
  abstract={Image Super-Resolution is a technique that is used to obtain high-resolution, realistic images from low-resolution input images. Deep learning algorithms such as SRCNN, ESRGAN, RDN, etc. have shown significant results in this field. But these algorithms at times vary in results. To solve this problem, this research study has proposed an image super-resolution by using Patch Extraction on Deep Learning Algorithm, in which the LR image is first divided into patches and then the algorithms like RDN and ESRGAN are applied. Comparing each patch from each algorithm based on PSNR values, the patch with the highest PSNR value will be selected. After picking up all the patches for that image, it will be reconstructed and hence the super-resolution image will be obtained as the output.},
  keywords={Deep learning;Superresolution;Estimation;Computer architecture;Observers;Artificial intelligence;Image reconstruction;Computer Vision;Deep Learning;Convolutional Neural Networks;Image Super-Resolution;Residual Dense Networks;Generative Adversarial Networks;Patch Extraction},
  doi={10.1109/ICAAIC53929.2022.9792975},
  ISSN={},
  month={May},}@INPROCEEDINGS{9750760,
  author={Dong, Xun and Hua, Ruijia},
  booktitle={2022 3rd International Conference on Electronic Communication and Artificial Intelligence (IWECAI)}, 
  title={GAN Based Image Inpainting Methods: A Taxonomy}, 
  year={2022},
  volume={},
  number={},
  pages={145-150},
  abstract={Image inpainting is the technique that's able to ‚Äúrepair‚Äù or ‚Äúcorrect‚Äù the image by reconstructing missing regions of an image using AI algorithms. As the techniques of images inpainting become mature in recent years, the demand for image inpainting algorithms rises in the market. It can be used to fill out missing areas in a picture, denoise images, or even remove a specific object from an image. To this end, it is important to propose a survey for image inpainting method, which can provide a comprehensive introduction of this area. The reason for creating this paper is due to the lack of resources that conclude all the methods that are being used in image inpainting. As the field of image inpainting soars, researchers may need documents which explain all the methods that can be used to train their image inpainting models. In the paper, we gathered some most successful methods that are used by many researchers. We explained their model, methods they used, the results of the training, and the advantages of the approaches they used in their research.},
  keywords={Training;Iris;Image color analysis;Taxonomy;Artificial intelligence;Image reconstruction;Image inpainting;GAN;Image generation;generative model},
  doi={10.1109/IWECAI55315.2022.00037},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10137971,
  author={Ma, Hui and Hu, Zhuhua and Zheng, Yan},
  booktitle={2022 6th Asian Conference on Artificial Intelligence Technology (ACAIT)}, 
  title={A Virtual Try-on Model with Enhanced Feature Representation Capability}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={When consumers choose to buy clothing online, virtual try-on technology can provide them with a better shopping experience. The optimization of virtual try-on technology not only helps consumers to evaluate the selected clothing, but also can improve the profit for merchants. However, the traditional virtual try-on technology has problems such as high cost, image distortion, and deviation of clothing style. In order to solve the above problems, this paper proposes a virtual try-on model with enhanced feature representation capability. Through the improved residual block of Squeeze-and-Excitation Networks (SENet) and the style encoding module introduced by the Pyramid Squeeze Attention (PSA) module, our model enriches the content and style information, strengthens the representation ability of features, and the reconstructed image preserves the more details. Compared with related work, we improve the structural similarity measure by 1.1% and the Inception Score by 10.1%. It is demonstrated that our model can reconstruct more accurate and realistic images.},
  keywords={Image coding;Costs;Clothing;Distortion;Artificial intelligence;Image reconstruction;Optimization;Attention;Generative Adversarial Network (GAN);style transfer;image synthesis;Virtual try-on},
  doi={10.1109/ACAIT56212.2022.10137971},
  ISSN={},
  month={Dec},}@ARTICLE{10115412,
  author={Bilgram, Volker and Laarmann, Felix},
  journal={IEEE Engineering Management Review}, 
  title={Accelerating Innovation With Generative AI: AI-Augmented Digital Prototyping and Innovation Methods}, 
  year={2023},
  volume={51},
  number={2},
  pages={18-25},
  abstract={Easy-to-use generative artificial intelligence (AI) is democratizing the use of AI in innovation management and may significantly change the way how we work and innovate. In this article, we show how large language models (LLMs), such as generative pretrained transformer (GPT), can augment the early phases of innovation, in particular, exploration, ideation, and digital prototyping. Drawing on six months of experimenting with LLMs in internal and client innovation projects, we share first-hand experiences and concrete examples of AI-assisted approaches. The article highlights a large variety of use cases for generative AI ranging from user journey mapping to idea generation and prototyping and foreshadows the promising role LLMs may play in future knowledge management systems. Moreover, we argue that generative AI may become a game changer in early prototyping as the delegation of tasks to an artificial agent can result in faster iterations and reduced costs. Our experiences also provide insights into how human innovation teams purposively and effectively interact with AIs and integrate them into their workflows.},
  keywords={Artificial intelligence;Technological innovation;Chatbots;Codes;Prototypes;Task analysis;Companies;AI-augmented innovation management;artificial intelligence (AI);digital prototyping;generative AI;idea generation;innovation;large language model (LLM);need identification;no-code prototyping;UX/UI},
  doi={10.1109/EMR.2023.3272799},
  ISSN={1937-4178},
  month={Secondquarter},}@ARTICLE{10620174,
  author={Cao, Hui},
  journal={IEEE Access}, 
  title={The Detection of Abnormal Behavior by Artificial Intelligence Algorithms Under Network Security}, 
  year={2024},
  volume={12},
  number={},
  pages={118605-118617},
  abstract={With the continuous evolution of network attack methods, traditional rule-based and signature-based security strategies are becoming increasingly hard to deal with increasingly complex network threats. The research focuses on the problem of network traffic anomaly detection in network security, and proposes an improved Transformer and Generative Adversarial Networks network traffic anomaly detection model. The innovation lies in utilizing the Patch segmentation in the Transformer module to reduce information loss, while introducing random masked data blocks to enhance the anti-interference ability of Generative Adversarial Networks, and proposing a class balance model. Therefore, a Transformer Multi Receive Field Fusion (Trans-M) model for network traffic anomaly detection is constructed. The performance test results showed that after category balancing, the accuracy, recall, and F1-score of each model were been significantly improved. The accuracy of the Trans-M model on the balanced dataset arrived 98.12%, an improvement of 8.59% compared to before balancing. The recall rate of the Trans-M model was improved by 8.62% to 97.86%. On Balanced F Score (F1-score), the highest score of the Trans-M model was 98.46%, which was 8.18% higher than before balancing. The experiment outcomes demonstrate that the raised network traffic anomaly detection system is superior to common anomaly traffic detection models and can meet the actual network security protection needs.},
  keywords={Transformers;Security;Computational modeling;Telecommunication traffic;Feature extraction;Adaptation models;Network security;Artificial intelligence;Traffic control;Generative adversarial networks;AI;network security;traffic detection;GAN;Transformer},
  doi={10.1109/ACCESS.2024.3436541},
  ISSN={2169-3536},
  month={},}@INBOOK{10953304,
  author={Marr, Bernard},
  booktitle={Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society}, 
  title={RISKS AND CHALLENGES TO MANAGE}, 
  year={2024},
  volume={},
  number={},
  pages={45-61},
  abstract={Summary <p>Among the many ethical and societal concerns are the propagation of false information and the potential for malicious uses, as well as the risk of us becoming overly dependent on the technology (and thereby losing vital human skills). GenAI gives people and organizations the ability to produce masses of content, making it very easy to spread misinformation or disinformation. Another concern is that we'll become overly dependent on GenAI, which could lead to the withering of key human skills. Many of the big AI companies are of course working to mitigate the ethical challenges surrounding GenAI. Meta, for instance, says it is working with governments, AI experts, and privacy experts to establish &#x201c;responsible guardrails&#x201d; for its AI features. And there's the environmental impact of GenAI in terms of the massive energy usage, and the rare earth materials used in the production of AI hardware.</p>},
  keywords={Deepfakes;Generative AI;Web sites;Watermarking;Video on demand;Regulation;Medical services;Ethics;Degradation;Companies},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394254255},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10953304},}@ARTICLE{11048670,
  author={Cui, Yuxin and Wang, Chen and Shen, Jian and Vijayakumar, Pandi and Alfarraj, Osama and Tolba, Amr},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Keyword Searchable Provable Data Possession in Generative AI Enabled Intelligent Transportation Systems}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={In generative artificial intelligence (AI) enabled intelligent transportation systems (ITS), real-time interaction and analysis of massive multi-source data are the core drivers for system optimization. However, large scale outsourcing storage of data, while enhancing computational efficiency, also poses security threats such as data integrity compromise, sensitive information leakage, and malicious tampering. These issues severely impact the quality of generative AI model training and the reliability of system services. Although existing cloud provable data possession (PDP) schemes can verify data integrity, they incur high computational overhead in ITS scenarios and lack support for fine-grained data retrieval. To address the need for specific data auditing by data users in generative AI enabled ITS, we propose a keyword searchable provable data possession scheme, which integrates data integrity verification with efficient data retrieval. First, a lightweight indexing approach is integrated to optimize the keyword search process, allowing different data users to initiate keyword based targeted queries based on their specific business needs, with integrity verification performed only on matching data blocks. Second, an efficient integrity auditing scheme is designed to ensure the integrity of outsourced intelligent vehicle data. Finally, security analysis and experimental results demonstrate that the proposed scheme achieves acceptable efficiency in computation overhead compared to existing works, while improving the auditability and searchability of outsourced ITS data.},
  keywords={Generative AI;Data integrity;Cloud computing;Security;Data privacy;Real-time systems;Encryption;Training;Driver behavior;Data models;Intelligent transportation systems;provable data possession;generative artificial intelligence;keyword},
  doi={10.1109/TITS.2025.3579407},
  ISSN={1558-0016},
  month={},}@INPROCEEDINGS{10605237,
  author={Kothari, Dhruval Kenal and Noel Newton Fernando, Owen},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Enhancing Human-Computer Interaction through AI: A Study on ChatGPT in Educational Environments}, 
  year={2024},
  volume={},
  number={},
  pages={500-503},
  abstract={This research investigates the potential of Chat Generative Pre-Trained Transformer (ChatGPT) in Human-Computer Interaction (HCI) within educational contexts. Examining the intersection of Artificial Intelligence (AI) and HCI, the study emphasizes ChatGPT's ability to provide personalized and immediate responses, enhancing student engagement and understanding. A literature review reveals ChatGPT's applications in higher education, while highlighting challenges related to critical thinking in the field of HCI. This paper then outlines our objectives, focusing on answering student queries and generating Multiple-Choice Questions (MCQs) for revision. Experimental results demonstrate the superiority of Custom GPTs, emphasizing the importance of context-specific tailoring. The discussion addresses limitations, proposing future work on model fine-tuning, optimization, and human testing. In conclusion, this research contributes insights into leveraging ChatGPT in HCI education, highlighting its potential for personalized and effective learning experiences.},
  keywords={Bibliographies;Education;Focusing;Chatbots;Transformers;Artificial intelligence;Optimization;ChatGPT;human computer interaction (HCI);Custom GPT;education;artificial intelligence (AI)},
  doi={10.1109/CAI59869.2024.00100},
  ISSN={},
  month={June},}@ARTICLE{11037821,
  author={Zeng, Mingfei and Xie, Ming and Meng, Liang and Zhang, Huacheng and Wu, Tong and Wang, Jianquan},
  journal={IEEE Network}, 
  title={Generative AI Enabled Secure Communication in Smart Grid: Challenges and Solutions}, 
  year={2025},
  volume={39},
  number={5},
  pages={81-87},
  abstract={Generative AI has recently emerged as a promising solution to address critical challenges in smart grid communication, including security, privacy, and efficiency. In this paper, we first introduce some concepts of smart grid and generative AI, outline their current state, and discuss the potential applications of integrating generative AI into smart grid. Then, we examine traditional and non-generative AI solutions, highlighting their limitations. Subsequently, we propose a promising solution by integrating generative AI into the smart grid to develop a generative AI-based agent, aiming to enhance the security and efficiency of smart grid communication while addressing privacy concerns. Additionally, we provide an experimental evaluation to demonstrate how the proposed solution can be applied to optimize smart grid holistically. Experimental results clearly show that the proposed generative AI agent approach can protect user privacy and significantly improve the overall efficiency and security of smart grid communication. Furthermore, we highlight future research directions for generative AI in smart grid applications, including the synergistic role of generative AI in smart grids, cross-domain applications and extensions, and quantum security of smart grids.},
  keywords={Smart grids;Generative AI;Security;Artificial intelligence;Privacy;Firewalls (computing);Data privacy;Data models;Synthetic data;Training;Generative AI;smart grid;security;privacy;generative AI agent},
  doi={10.1109/MNET.2025.3580477},
  ISSN={1558-156X},
  month={Sep.},}@INPROCEEDINGS{10917080,
  author={Mingyue, Sun and Fan, Wu and Xin, Ji and Yanhong, Jian},
  booktitle={2024 IEEE International Conference on Energy Internet (ICEI)}, 
  title={Systematic GAN Parameter Selection for Fault Data Generation using Particle Swarm Optimization}, 
  year={2024},
  volume={},
  number={},
  pages={580-585},
  abstract={In real-world applications of artificial intelligence, fault data are often insufficient, making data training challenging. Generative adversarial networks (GAN) are widely recognized for addressing data generation issues. This study introduces swarm intelligence algorithms, specifically particle swarm optimization (PSO) and genetic algorithm (GA), to enhance GAN performance. The single-channel vibration signal data from a faulty motor serves as the case study. Fault vibration signals can rapidly, accurately, and comprehensively reflect the nature and extent of mechanical faults. The study compares and analyzes the results of PSO, GA, and random number (RN) optimization of GAN parameters. The findings demonstrate that PSO outperforms GA in terms of time efficiency and reducing generation errors. Swarm intelligence algorithms eliminate the need for manual experience or repetitive trials when selecting parameters. Compared to GA and RN, PSO improves performance by 80.92% and 90.44%, respectively, while also reducing optimization time by 46.55% compared to GA.},
  keywords={Vibrations;Training;Accuracy;Data collection;Generative adversarial networks;Motors;Particle swarm optimization;Optimization;Genetic algorithms;Convergence;genetic algorithm (GA);generative adversarial networks (GAN);parameter determination;vibration signal;particle swarm optimization (PSO)},
  doi={10.1109/ICEI63732.2024.10917080},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10772906,
  author={Vivek, Yelleti and Ravi, Vadlamani and Mane, Abhay and Naidu, Laveti Ramesh},
  booktitle={2024 IEEE Symposium on Computational Intelligence for Financial Engineering and Economics (CIFEr)}, 
  title={Explainable Artificial Intelligence and Causal Inference Based ATM Fraud Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Gaining the empathy and trust of customers is paramount in the financial domain. However, the recurring occurrence of fraudulent activities undermines both of these factors. ATM fraud is a prevalent issue faced in today's banking landscape. The critical challenges in fraud datasets are highly imbalanced datasets, evolving fraud patterns, and lack of explainability. In this study, we handled these techniques on an ATM transaction dataset collected from India. In binary classification, we investigated the effectiveness of various over-sampling techniques, such as the Synthetic Minority Oversampling Technique (SMOTE) and its variants, Generative Adversarial Networks (GAN), to achieve oversampling. Gradient Boosting Tree (GBT), outperformed the rest of the techniques by achieving an AUC of 0.963, and Decision Tree (DT) stands second with an AUC of 0.958. In terms of complexity and interpretability, DT is the winner. Among the oversampling approaches, SMOTE and its variants performed better. We incorporated explainable artificial intelligence (XAI) and Causal Inference (CI) in the fraud detection framework and studied them via various analyses. Further, we provided managerial impact.},
  keywords={Economics;Explainable AI;Banking;Generative adversarial networks;Boosting;Fraud;Complexity theory;Decision trees;Computational intelligence;Fraud detection;XAI;Causal Inference;SMOTE;GAN},
  doi={10.1109/CIFEr62890.2024.10772906},
  ISSN={2640-7701},
  month={Oct},}@INPROCEEDINGS{10596771,
  author={WANG, Haiyang and Mainardi, Luca},
  booktitle={2024 IEEE International Symposium on Medical Measurements and Applications (MeMeA)}, 
  title={CTGAN in Augmentation of Radiomics Features Classification from Narrow Band Imaging for Laryngeal Cancer}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Artificial intelligence (AI) holds immense promise in revolutionizing biomedical research, particularly in the field of early medical assistance analysis. This paper explores the application of AI in the context of laryngeal cancer, a disease where early screening, accurate diagnosis, effective management, and favorable prognosis are crucial for patient outcomes. The implementation of AI in biomedical field practice always faces challenges due to data scarcity. The limited availability of data leads to less satisfactory testing results. Even if the methods like geometric transformation and photometric transformation have been applied, it does not still enlarge the diversity in nature of data. Here, we investigated CTGAN on tabular radiomics features in a public laryngeal cancer dataset to check how various amount of data augmentation affects classifier's performance. The results were assessed by the synthetic data reports which captures the similarity with the columns shapes score (median value 71.23 %) and the trend and correction across columns with a column pair score median value 90.30%. The synthetic data respect the original data structure(100%) and overall synthetic data validity is above 81 %. It enhances the diversity and increase the amount of training data for laryngeal cancer detection. After assessing the synthetic report, a comparison of performances across different classifiers was followed. Result shows an increases in accuracy from 5 % to 10%. This proves the positive performance of the classifying improvement on an independent testing dataset (real data) and provides clues how much data should be synthesized. Our paper provides a positive and meaningful reference on tabular radiomics data augmentation for medical intelligent diagnosis design in the future.},
  keywords={Accuracy;Data augmentation;Market research;Data models;Artificial intelligence;Medical diagnostic imaging;Synthetic data;CTGAN;radiomics;data augmentation;laryngeal cancer;medical image},
  doi={10.1109/MeMeA60663.2024.10596771},
  ISSN={2837-5882},
  month={June},}@INPROCEEDINGS{9148327,
  author={Xia, Boming and Ye, Xiaozhen and Abuassba, Adnan O.M},
  booktitle={2020 International Wireless Communications and Mobile Computing (IWCMC)}, 
  title={Recent Research on AI in Games}, 
  year={2020},
  volume={},
  number={},
  pages={505-510},
  abstract={Games tend to have the properties of vast state space and high complexity, making them excellent benchmarks for evaluating various techniques, including AI ones. Techniques utilized in games capable of making them more attractive, immersive, smarter etc. can all be considered to be certain forms of game AI. Considering there are few reviews on the more recent work in the game AI field from the perspective of essential applications, in this paper, we make a systematic review of typical research from 2018 on three application fields of game AI: believable agents in non-player characters research, game level generation in procedural content generation, and player profiling in player modeling. We also provide a timeline of game AI history to give the readers a clearer picture of the game AI field. Moreover, general game AI and hybrid intelligence for games are discussed.},
  keywords={Games;Artificial intelligence;Solid modeling;Natural language processing;Benchmark testing;History;Augmented reality;Game;Artificial Intelligence (AI);Game AI},
  doi={10.1109/IWCMC48107.2020.9148327},
  ISSN={2376-6506},
  month={June},}@INPROCEEDINGS{10739229,
  author={Pendalwar, Rishab and Verma, Aditya and Patil, Ratna},
  booktitle={2024 International Conference on Electrical Electronics and Computing Technologies (ICEECT)}, 
  title={Machine Learning in Action: Supervised Learning Models for Classifying Credit Card Fraud}, 
  year={2024},
  volume={1},
  number={},
  pages={1-5},
  abstract={Financial institutions face a relentless battle against fraudulent credit card transactions. Machine learning (ML) offers a promising approach for tackling this challenge. This paper explores six supervised machine learning models (Support Vector Machine (SVM), Random Forest, Naive Bayes, K-Nearest Neighbours (KNN), XGBoost, and LIGHT GBM) for detecting credit card fraud using a benchmark dataset. We explore the impact of dimensionality reduction with Principal Component Analysis (PCA) and data balancing with Generative Adversarial Networks (GANs) on imbalanced class distributions. The assessment relies on metrics such as accuracy, precision, recall, and F1-score. The results indicate that Random Forest demonstrates the best overall performance, especially when paired with GAN-based data balancing techniques. This study highlights the importance of addressing class imbalance and exploring dimensionality reduction techniques for enhancing credit card fraud detection capabilities.},
  keywords={Dimensionality reduction;Support vector machines;Accuracy;Nearest neighbor methods;Credit cards;Data models;Fraud;Bayes methods;Random forests;Principal component analysis;imbalanced learning;principal component analysis (pca);generative adversarial networks (gans);random forest;credit card fraud detection;light gbm},
  doi={10.1109/ICEECT61758.2024.10739229},
  ISSN={},
  month={Aug},}@ARTICLE{10265048,
  author={Ferdowsi, Aidin and Saad, Walid},
  journal={IEEE Internet of Things Journal}, 
  title={Brainstorming Generative Adversarial Network (BGAN): Toward Multiagent Generative Models With Distributed Data Sets}, 
  year={2024},
  volume={11},
  number={5},
  pages={7828-7840},
  abstract={To achieve a high-learning accuracy, generative adversarial networks (GANs) must be fed by large data sets that adequately represent the data space. However, in many scenarios, the available data sets may be limited and distributed across multiple agents, each of which is seeking to learn the distribution of the data on its own. In such scenarios, the agents often do not wish to share their local data as it can cause communication overhead for large data sets. In this article, to address this multiagent GAN problem, a novel brainstorming GAN (BGAN) architecture is proposed using which multiple agents can generate real-like data samples while operating in a fully distributed manner. BGAN allows the agents to gain information from other agents without sharing their real data sets but by ‚Äúbrainstorming‚Äù via the sharing of their generated data samples. In contrast to existing distributed GAN solutions, the proposed BGAN architecture is designed to be fully distributed, and it does not need any centralized controller. Moreover, BGANs are shown to be scalable and not dependent on the hyperparameters of the agents‚Äô deep neural networks (DNNs) thus enabling the agents to have different DNN architectures. Theoretically, the interactions between BGAN agents are analyzed as a game whose unique Nash equilibrium is derived. Experimental results show that BGAN can generate real-like data samples with higher quality and lower Jensen-Shannon divergence (JSD) and Fr√®chet inception distance (FID) compared to other distributed GAN architectures.},
  keywords={Computer architecture;Generators;Distributed databases;Generative adversarial networks;Particle swarm optimization;Heuristic algorithms;Training;Communication efficiency;distributed learning;generative adversarial networks (GANs)},
  doi={10.1109/JIOT.2023.3319630},
  ISSN={2327-4662},
  month={March},}@ARTICLE{9617735,
  author={Kim, Kyung-Su and Lee, Jung Hyun and Yang, Eunho},
  journal={IEEE Access}, 
  title={Compressed Sensing via Measurement-Conditional Generative Models}, 
  year={2021},
  volume={9},
  number={},
  pages={155335-155352},
  abstract={Pre-trained generators have been frequently adopted in compressed sensing (CS) owing to their ability to effectively estimate signals with the prior of NNs. To further refine the NN-based prior, we propose a framework that allows the generator to utilize additional information from given measurements of training samples for prior learning, thereby yielding more accurate reconstruction for signals. As our framework has a simple form, it can be easily applied to existing CS methods using pre-trained generators. Through extensive experiments, we demonstrate that our framework consistently outperforms these works by a large margin and can reduce the reconstruction error up to an order of magnitude for the presented target applications. We also explain the experimental success theoretically by showing that our framework can slightly relax the stringent signal presence condition, which is required to guarantee the success of signal recovery.},
  keywords={Generators;Training;Image reconstruction;Generative adversarial networks;Magnetic resonance imaging;Phase measurement;Artificial neural networks;Compressed sensing;artificial neural networks;image reconstruction;image enhancement;signal reconstruction and prediction;measurement-conditional generative models;mitigation of signal presence condition;magnetic resonance imaging},
  doi={10.1109/ACCESS.2021.3128721},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9698877,
  author={Yang, Huifang and Li, Gang},
  booktitle={2021 IEEE International Conference on Medical Imaging Physics and Engineering (ICMIPE)}, 
  title={Automatic cone-beam computed tomography segmentation with small samples based on generative adversarial networks and semantic segmentation}, 
  year={2021},
  volume={},
  number={},
  pages={1-4},
  abstract={This paper establishes a method to realize semiautomatic or automatic labeling of multidimensional data based on small samples and weak labeling. This method could effectively assist dentists in the segmentation of different tissues. Based on U-Net combined with the generative adversarial network method, segmentation can be realized on multidimensional data. It also includes three-dimensional mesh reconstruction of the segmented tissue, smoothing the boundary, and the resulting data can be used to aid clinical diagnosis and printing. The segmentation results can reflect the structural distribution of different tissues and effectively build a mechanical model based on cone-beam computed tomography system (CBCT) datasets.},
  keywords={Printing;Image segmentation;Smoothing methods;Computed tomography;Magnetic resonance imaging;Semantics;Magnetic resonance;segmentation;generative adversarial networks;CBCT;annotation},
  doi={10.1109/ICMIPE53131.2021.9698877},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11129384,
  author={Tirumala, Sreenivas Sremath and Khwakhali, Ushik Shrestha},
  booktitle={2025 10th International STEM Education Conference (iSTEM-Ed)}, 
  title={Unethical Academic Practices through Ethical Tools}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Generative Artificial Intelligence (Gen-AI) tools have changed the course of academic teaching and learning practices, particularly, the way of writing assessment and scholarly reports. Although the use of Artificial Intelligence based tools or similar systems is not new to academia, advanced Gen-AI tools such as Chat-GPT has opened a new path for academic misconduct. The use of Gen-AI tools forced academic institutions to adapt new policies around the use of AI generated content in assessments and research. Reputed plagiarism checking tools like Turnitin has provided AI detection mechanisms with little success, due to inconsistency in the results attributed to the quality of detection algorithms. Tools like ZeroGPT, Originality.ai, GPTZero, etc., are exclusively developed for detecting AI generated content. However, at present, some Gen-AI based companies like StealthAI, AIHumanizer etc., are offering services that can be used to evade detection tools for plagiarism. These services use advanced algorithms and techniques to identify patterns and rewrite the content to mimic human styled text. This posed serious challenges in identifying academic misconduct. This research explores various tools that learners use or can be used in assessments and research that can evade AI and plagiarism detection. A list of 6 reputed tools like StealthAI, AIHumanizer, ByPassGPT are reviewed to identify how these tools evade AI detection. The problem of academic misconduct is critically evaluated using literature, and the practical implications of misconduct are presented. As this ongoing research is closely aligned with learner abilities, the impact of Gen-AI is presented through the lenses of learners.},
  keywords={Ethics;Generative AI;Plagiarism;Education;Learning (artificial intelligence);Companies;Writing;Detection algorithms;Lenses;education;academic misconduct;ethical practices;Gen-AI tools;AI writing},
  doi={10.1109/iSTEM-Ed65612.2025.11129384},
  ISSN={},
  month={July},}@BOOK{10745288,
  author={Bahree, Amit},
  booktitle={Generative AI in Action},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Generative AI can transform your business by streamlining the process of creating text, images, and code. This book will show you how to get in on the action! Generative AI in Action is the comprehensive and concrete guide to generative AI you‚Äôve been searching for. It introduces both AI‚Äôs fundamental principles and its practical applications in an enterprise context‚Äîfrom generating text and images for product catalogs and marketing campaigns, to technical reporting, and even writing software. Inside, author Amit Bahree shares his experience leading Generative AI projects at Microsoft for nearly a decade, starting well before the current GPT revolution. Inside Generative AI in Action you will find:  A practical overview of of generative AI applications Architectural patterns, integration guidance, and best practices for generative AI The latest techniques like RAG, prompt engineering, and multi-modality The challenges and risks of generative AI like hallucinations and jailbreaks How to integrate generative AI into your business and IT strategy  Generative AI in Action is full of real-world use cases for generative AI, showing you where and how to start integrating this powerful technology into your products and workflows. You‚Äôll benefit from tried-and-tested implementation advice, as well as application architectures to deploy GenAI in production at enterprise scale.},
  keywords={prompt engineering;model fine tuning;enterprise;safety;ethics;integration;RAG;multi-modality;LLMs;hallucinations;jailbreaks;architectural patterns;ChatGPT;Bard;Copilot},
  doi={},
  ISSN={},
  publisher={Manning},
  isbn={9781633436947},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10745288},}@INBOOK{10955601,
  author={Anand, M. and Sheeba, T. M. and Fancy, C.},
  booktitle={Artificial Intelligence-Enabled Digital Twin for Smart Manufacturing}, 
  title={Role of AI and Digital Twin in Smart Manufacturing}, 
  year={2024},
  volume={},
  number={},
  pages={233-248},
  abstract={Summary <p>Recent years we have seen the emergence of several technologies that are critical to the development of the Industrial IoT and smart manufacturing. These include next&#x2010;generation material science, advanced robotics, cyber&#x2010;physical systems, big data, advanced analytics, artificial intelligence (AI) and machine learning (ML), operational intelligence and generative design for additive manufacturing. Manufacturers are thinking about new business models based on real&#x2010;world implementations, in which they offer services instead of products and use the digital twin to optimize the product's performance and availability. In addition to full maintenance and operational optimization established on the digital twin's predictive and prescriptive capabilities, customers are provided the usage of the product or equipment. As a more profitable and manageable business model, the manufacturer retains ownership of the equipment while offering the maintenance service established on a digital twin.</p>},
  keywords={Digital twins;Smart manufacturing;Optimization;Business;Real-time systems;Maintenance;Robot sensing systems;Machine learning;Assembly;Service robots},
  doi={10.1002/9781394303601.ch11},
  ISSN={},
  publisher={Wiley},
  isbn={9781394303595},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10955601},}@INPROCEEDINGS{10776431,
  author={Lin, Shaolin and Yin, Senlin and Zhang, Yaowei and Liu, Juanxia and Tao, Chao},
  booktitle={2024 International Conference on New Trends in Computational Intelligence (NTCI)}, 
  title={Reservoir Facies Modeling Based on Generative Adversarial Network}, 
  year={2024},
  volume={},
  number={},
  pages={483-487},
  abstract={Three-dimensional geological modeling of reservoirs is of great significance for developing oil and gas resources, groundwater resources, and carbon dioxide geological storage. Geological facies models are the basis for accurately predicting underground oil reservoirs, geological carbon dioxide storage potential, and groundwater resources. Traditional geostatistical modeling methods can be consistent with geological models to some extent, but there are obvious shortcomings when the characteristics of geological models become complex. Therefore, this paper takes the braided river deltaic diversion channel and estuarine dam phase of the Hanjiang Formation in the Epping Depression of the Pearl River Estuary Basin as the research objective. Based on the geological background of the workings, 3D seismic data and seven logging wells, a conditionally bounded phase simulation based on an improved GAN model is proposed. The research results show that the phase model generated by modeling well facies data matches the input well facies data. The generated phase model has good diversity, and the trained generator can generate high-quality phase models with 100%. accuracy in reproducing well facies.},
  keywords={Geology;Computational modeling;Stochastic processes;Predictive models;Generative adversarial networks;Reservoirs;Data models;Generators;Vectors;Synthetic data;conditional phase modeling;generate adversarial networks;deep learning;geological model;reservoir prediction},
  doi={10.1109/NTCI64025.2024.10776431},
  ISSN={},
  month={Oct},}@INBOOK{10948951,
  author={Banafa, Ahmed},
  booktitle={Artificial Intelligence in Action: Real-World Applications and Innovations}, 
  title={Artificial Intelligence in Action: Real-World Applications and Innovations}, 
  year={2025},
  volume={},
  number={},
  pages={i-xxx},
  abstract={This comprehensive book dives deep into the current landscape of AI, exploring its fundamental principles, development challenges, potential risks, and the cutting-edge breakthroughs that are propelling it forward. Artificial intelligence (AI) is rapidly transforming industries and societies worldwide through groundbreaking innovations and real-world applications. Starting with the core concepts, the book examines the various types of AI systems, generative AI models, and the complexities of machine learning. It delves into the programming languages driving AI development, data pipelines, model creation and deployment processes, while shedding light on issues like AI hallucinations and the intricate path of machine unlearning. The book then showcases the remarkable real-world applications of AI across diverse domains. From preventing job displacement and promoting environmental sustainability, to enhancing disaster response, drone technology, and even nuclear energy innovation, it highlights how AI is tackling complex challenges and driving positive change. The book also explores the double-edged nature of AI, recognizing its tremendous potential while cautioning about the risks of misuse, unintended consequences, and the urgent need for responsible development practices. It examines the intersection of AI and fields like operating system design, warfare, and semiconductor technology, underscoring the wide-ranging implications of this transformative force. As the quest for artificial general intelligence (AGI) and superintelligent AI systems intensifies, the book delves into cutting-edge research, emerging trends, and the pursuit of multimodal, explainable, and causally aware AI systems. It explores the symbiotic relationship between AI and human creativity, the rise of user-friendly "casual AI," and the potential of AI to tackle open-ended tasks. This is an essential guide for understanding the profound impact of AI on our world today and its potential to shape our future. From the frontiers of innovation to the challenges of responsible development, this book offers a comprehensive and insightful exploration of the remarkable real-world applications and innovations driving the AI revolution.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770046190},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10948951},}@INPROCEEDINGS{11046234,
  author={Rafael Morano-Okuno, Hector and Enrique Chong-Quero, J. and Esqueda-Merino, Donovan M. and Sandoval-Benitez, Guillermo and Jaramillo-Godinez, Ricardo and Alfredo Murano-Labastida, Daishi},
  booktitle={2025 13th International Conference on Information and Education Technology (ICIET)}, 
  title={Software Application Experiences: Cloud Technology and Collaborative Work in a University Course}, 
  year={2025},
  volume={},
  number={},
  pages={257-261},
  abstract={Nowadays, many software applications based on artificial intelligence (AI) algorithms create generative designs, which can be used as didactic tools in university courses. Thanks to AI, almost all of them are user-friendly and allow collaborative work in cloud environments. However, it is necessary to explore them to understand their aims. This work was focused on studying a software application that allows collaborative work and cloud technology interaction; it also permits the creation of Generative Designs of products. It was employed in a course on Cyber-physical systems for engineering majors. Different activities were developed to identify their objectives. The results show that the cloud technology used by the software application allows students to work in multidisciplinary teams, from a distance, and in an adequate collaborative way. Finally, the experiences gained from working with this computational tool are shared, and some recommendations on creating generative designs are also defined.},
  keywords={Technological innovation;Federated learning;Education;Software algorithms;Collaboration;Cyber-physical systems;Software;Object recognition;Artificial intelligence;cloud technology;collaborative work;generative design;Fusion 360;educational innovation;higher education;professional education;tec21 model},
  doi={10.1109/ICIET66371.2025.11046234},
  ISSN={},
  month={April},}@INBOOK{9562726,
  author={Reznik, Leon},
  booktitle={Intelligent Security Systems: How Artificial Intelligence, Machine Learning and Data Science Work For and Against Computer Security}, 
  title={Front Matter}, 
  year={2022},
  volume={},
  number={},
  pages={i-xxvi},
  abstract={The prelims comprise:  Half‚ÄêTitle Page Series Page Title Page Copyright Page Dedication Page Table of Contents Acknowledgments Introduction },
  keywords={},
  doi={10.1002/9781119771579.fmatter},
  ISSN={},
  publisher={IEEE},
  isbn={9781119771555},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/9562726},}@INPROCEEDINGS{10424147,
  author={Zhong, Jinping and Zheng, Yunxiang},
  booktitle={2023 3rd International Conference on Educational Technology (ICET)}, 
  title={Identifying the impact of Human-AI co-creation on students' creativity development: a conceptual framework}, 
  year={2023},
  volume={},
  number={},
  pages={66-70},
  abstract={The amazing progress in conversational AI such as ChatGPT seems to be driving people into an era where human-AI co-creation is prevalent. Efforts need to focus on the new context of creativity development, as AI is more to creativity than simplifying creative tasks. The current study aims to explore the possible impact of AI on creativity and how students co-create with it in a way that optimizes its benefits. Whereas AI may challenge the position of humans in certain creative tasks, we argue that it provides multiple supports to the creative process. Accordingly, we proposed a conceptual framework of the impact of human-AI co-creation on creativity based on creativity theories and the SAMR model. Then we concluded with four principles of student-AI co-creation.},
  keywords={Ethics;Cognitive processes;Educational technology;Chatbots;Artificial intelligence;Task analysis;Creativity;creativity;artificial intelligence;human-AI co-creation;impact},
  doi={10.1109/ICET59358.2023.10424147},
  ISSN={},
  month={Sep.},}@ARTICLE{10382492,
  author={Deng, Lingfei and Zhao, Changming and Du, Zhenbang and Xia, Kun and Wu, Dongrui},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Semisupervised Transfer Boosting (SS-TrBoosting)}, 
  year={2024},
  volume={5},
  number={7},
  pages={3431-3444},
  abstract={Semisupervised domain adaptation (SSDA) aims at training a high-performance model for a target domain using few labeled target data, many unlabeled target data, and plenty of auxiliary data from a source domain. Previous works in SSDA mainly focused on learning transferable representations across domains. However, it is difficult to find a feature space where the source and target domains share the same conditional probability distribution. Additionally, there is no flexible and effective strategy extending existing unsupervised domain adaptation (UDA) approaches to SSDA settings. In order to solve the above two challenges, we propose a novel fine-tuning framework, semisupervised transfer boosting (SS-TrBoosting). Given a well-trained deep learning-based UDA or SSDA model, we use it as the initial model, generate additional base learners by boosting, and then use all of them as an ensemble. More specifically, half of the base learners are generated by supervised domain adaptation, and half by semisupervised learning. Furthermore, for more efficient data transmission and better data privacy protection, we propose a source data generation approach to extend SS-TrBoosting to semisupervised source-free domain adaptation (SS-SFDA). Extensive experiments showed that SS-TrBoosting can be applied to a variety of existing UDA, SSDA, and SFDA approaches to further improve their performance.},
  keywords={Feature extraction;Boosting;Adaptation models;Data models;Prototypes;Artificial intelligence;Ensemble learning;Boosting;ensemble learning;fine-tuning;semisupervised domain adaptation (SSDA);source-free domain adaptation (SFDA)},
  doi={10.1109/TAI.2024.3350543},
  ISSN={2691-4581},
  month={July},}@INPROCEEDINGS{10539708,
  author={Wen, Hao and Sun, Zhongya},
  booktitle={2024 International Conference on Electrical Drives, Power Electronics & Engineering (EDPEE)}, 
  title={The Application of Neural Networks in the Field of Architecture in Machine Learning}, 
  year={2024},
  volume={},
  number={},
  pages={386-390},
  abstract={The field of architectural design is known for its unique traditions and complexity. It is a multidisciplinary field that involves various disciplines, but machine learning has never been involved in this field before. However, with the emergence of Big Data and the 5G era, this barrier has been broken. Currently, the machine learning and artificial intelligence industries are gradually penetrating various aspects of the construction industry. This article explores the application of deep learning in architectural design through machine learning research and examines whether artificial intelligence has its own creativity today. The article first introduces the concepts of artificial intelligence, machine learning, and deep learning, and discusses their differences and connections to help readers understand the content. It then delves into deep learning, focusing on the use of neural networks in architectural design. Finally, it summarizes how neural networks are applied to architectural design in machine learning.},
  keywords={Training;Deep learning;Recurrent neural networks;Neurons;Focusing;Iterative methods;Object recognition;Artificial Intelligence;Deep Learning;Neural Networks;Architectural Applications},
  doi={10.1109/EDPEE61724.2024.00079},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10971683,
  author={Ramachandran, Renjith},
  booktitle={SoutheastCon 2025}, 
  title={Transforming Software Architecture Design With Intelligent Assistants-A Comparative Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={1446-1454},
  abstract={As artificial intelligence tools such as GitHub Copilot, Chat Generative Pre-Trained Transformer (ChatGPT), or Black Box Artificial Intelligence (BlackBoxAI) become more embedded in software development workflows, they are reshaping how architects approach modern software design. While enterprises are increasingly leveraging Generative Artificial Intelligence (GenAI) tools to enhance developer productivity, limited research has been conducted on their impact on software architects. Traditionally, architects utilize various tools to create architectural blueprints, including Unified Modelling Language (UML) diagrams, class diagrams, sequence diagrams, use case diagrams, and state diagrams. Many of these diagrams follow repetitive structures that can be automated with well-defined contexts. This paper examines the role of three AI tools in assisting architects during the design phase, assessing how closely the generated outputs adhere to established architectural principles. By analyzing deviations, the study explores how refined prompts and additional context can improve accuracy. Research also includes cross tool comparison. Ultimately, this research aims to evaluate the potential of AI assistant tools to enhance productivity, ensure design consistency, and support architectural decision-making, while providing best practices for integrating AI into modern software architecture.},
  keywords={Productivity;Software design;Software architecture;Generative AI;Unified modeling language;Chatbots;Transformers;Security;Artificial intelligence;Software development management;BlackboxAI;ChatGPT;Gen AI;Github Copilot;Software Architecture},
  doi={10.1109/SoutheastCon56624.2025.10971683},
  ISSN={1558-058X},
  month={March},}@ARTICLE{10258299,
  author={Avil√©s-Cruz, Carlos and Celis-Escudero, Gabriel J.},
  journal={IEEE Access}, 
  title={3G-AN: Triple-Generative Adversarial Network Under Corse-Medium-Fine Generator Architecture}, 
  year={2023},
  volume={11},
  number={},
  pages={105344-105354},
  abstract={In recent years, Generative Adversarial Networks (GANs) have gained worldwide interest and have marked a breakthrough in deep learning, encouraging detailed studies in generating artificial images. A new Generative Adversarial Networks (GAN) is proposed to unveil how Human visual perception takes place, focusing on how human beings perceive images, firstly, coarse structures and then their details. The network called 3G-AN consists of three generation stages and a single Discriminator. In this paper, a novel three-branch generator is proposed, which takes into account Coarse, Medium, and Fine structure of a given image. Coarse RGB decomposition image provides the general structure, while Medium RGB stage provides general-fine structure. Finally, Fine RGB decomposition provides fine details of the image. The proposal is tested on MNIST, CIFAR10, and Celebrity faces databases, generating realistic images with almost no anomalies. The RGB decomposition into coarse, medium, and fine, allows to understand the composition of an image from a structural point of view. The qualitative analysis carried out in this research paper outperforms the six most competitive models existing in the literature.},
  keywords={Generators;Generative adversarial networks;Task analysis;Faces;Training;Proposals;Deep learning;Artificial intelligence;Fake news;Image analysis;GAN;artificial intelligence;deep learning;fake images},
  doi={10.1109/ACCESS.2023.3317897},
  ISSN={2169-3536},
  month={},}@ARTICLE{10654499,
  author={Huang, Junjian and Zheng, Mao and Li, Zhizhang and He, Xing and Wen, Shiping},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, 
  title={ISRnet: Compressed Image Inpainting Based on Generative Adversarial Network}, 
  year={2025},
  volume={9},
  number={4},
  pages={2743-2753},
  abstract={In recent years, significant advancements have been made in the domain of image restoration, particularly in the context of repairing damaged images and super-resolution reconstruction, primarily owing to the emergence of deep learning techniques. However, during the course of transmission across various media devices, the original image quality may deteriorate due to factors such as the network environment, hardware constraints, and related conditions. Moreover, the restoration process becomes increasingly challenging when the original image quality is low or compromised. Presently, prevailing methods involve repairing the image prior to performing super-resolution reconstruction. However, this methodology typically relies on the utilization of multiple autonomous models, where the efficacy and time efficiency are not optimal. In light of this, we propose a novel neural network model based on GAN, termed ISRnet, designed to repair damaged compressed images. Our method is the first to leverage GAN networks specifically for compressed image restoration. ISRnet integrates the principles of image inpainting and super-resolution reconstruction, enabling the transformation of low-resolution images into high-resolution counterparts during the restoration process, thereby achieving superior restoration outcomes. Despite the partial increase in bias, this approach counteracts the variability inherent in a singularly trained neural network model. Compared to a single neural network model trained on the same dataset, our model demonstrates reduced variance and diminished sensitivity to data, thereby achieving optimal restoration quality and expedited repair speeds for damaged compressed images. Consequently, our proposed methodology presents a promising avenue for the utilization of neural networks in repairing damaged compressed images.},
  keywords={Image restoration;Superresolution;Image resolution;Generative adversarial networks;Image reconstruction;Generators;Training;Generative adversarial networks;super resolution;image inpainting},
  doi={10.1109/TETCI.2024.3446690},
  ISSN={2471-285X},
  month={Aug},}@INPROCEEDINGS{10940581,
  author={Upadhyay, Deepak and Upadhyay, Abhay and Sharma, Kuj Bihari and Dhondiyal, Shiv Ashish and Venu, Nookala},
  booktitle={2025 International Conference on Pervasive Computational Technologies (ICPCT)}, 
  title={Exploring the Impact of Conditional Deep Convolutional Generative Adversarial Networks in Brain Tumor Image Classification: A Novel Approach}, 
  year={2025},
  volume={},
  number={},
  pages={12-16},
  abstract={In this paper, we explore the impact of conditional Deep Convolutional Generative Adversarial Networks (cDCGANs) with brain tumor image classification and introduce a new way to improve diagnosis accuracy. Shortage of Data/Data Imbalance: In Medical Imaging datasets, it helps in surging the data scarcity and class imbalance with mimicking generation images using cDCGAN. The detailed investigation demonstrates that synthetic data effectively improves classifier performance by acting as a form of augmentation, providing additional training examples for classifiers and serving as ground truth. From the computational efficiency analysis, we see that there is also scalability in training time with respect to dataset size. Consequently, this study presents cDCGANs as an important asset with which to improve diagnostic accuracy through brain tumor categorization in clinical contexts.},
  keywords={Training;Accuracy;Scalability;Brain tumors;Medical services;Sensitivity and specificity;Generative adversarial networks;Robustness;Image classification;Synthetic data;cDCGANs;CNNs;ANNs;AI;ML},
  doi={10.1109/ICPCT64145.2025.10940581},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10823604,
  author={Choi, Min Sung and Lee, Hae Won and Bae, Seong Geon},
  booktitle={2024 International Conference on Electrical, Communication and Computer Engineering (ICECCE)}, 
  title={A Study on CartoonGAN Using High-Resolution Generative Networks Through Feature Emphasis}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={GAN is a model that generates completely new data and can create various media contents. CartoonGAN is a GAN model that converts real images into cartoon style, and can apply various cartoon styles. In this study, we propose ESRGAN (Enhanced Super-Resolution Generative Adversarial Networks) technology as a preprocessing method to improve the performance of CartoonGAN. ESRGAN is a model that improves resolution using GAN. This method showed better performance than other SR techniques in the evaluation indices MSE, PSNR, and SSIM results. This suggests that ESRGAN is effective in high-resolution restoration ability and visual quality improvement in cartoon style image conversion. The method proposed in this study can be used as a useful tool for high-resolution cartoon image generation. Since the learning data of the model is limited to a specific domain, there may be limitations in generalizability. Due to the characteristics of ESRGAN, which is computationally complex and consumes a lot of resources, there may be limitations in applying it to real-time processing or large datasets. In future studies, it is necessary to build an extended dataset for various images to overcome these limitations. It is important to reduce computational costs by making models lightweight and optimizing them, and to develop algorithms suitable for real-time processing. It is expected that these additional studies and improvements will be utilized to produce high-quality images.},
  keywords={Visualization;Image synthesis;Computational modeling;Noise;Media;Generative adversarial networks;Real-time systems;Data models;Image restoration;Computational efficiency;GAN;CartoonGAN;Image Processing;ESRGAN;Computer Vision},
  doi={10.1109/ICECCE63537.2024.10823604},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10645866,
  author={Xu, Mingming and Ye, Chen and Zeng, Zheng and Chang, Chenyang and Qi, Shijie and Wu, Yujia and Yang, Huifang and Chen, Yifan and Huang, Haifeng and Liu, Lin and Cao, Zhanqiang and Deng, Xuliang},
  booktitle={2024 IEEE International Conference on Digital Health (ICDH)}, 
  title={Adopting Generative AI with Precaution in Dentistry: A Review and Reflection}, 
  year={2024},
  volume={},
  number={},
  pages={244-256},
  abstract={The progress in large language models (LLMs) brings much excitement and efforts in medical artificial intelligence, which could transform patient-doctor conversation while making joint medical decisions. LLMs, exemplified by ChatGPT, are proficient in grasping and generating text, and can perform tasks such as question answering, document summarising, and paraphrasing with a level of proficiency comparable to that of a human. Their potential applications span across various tasks in medicine, notably improving clinical patient care experience, advancing scientific medical research, and revolutionizing medical education. This survey critically examines the evolving landscape of medical large language models (Med LLMs), with a special focus on their application in stomatology. While Med LLMs are inevitably becoming an integral part to medical text processing and image processing, their use in enhancing clinical care requires extra precaution and assurance due to the stringent requirements on ethics and patient safety. The design, deployment and use of LLMs and services requires thorough risks analysis of technology misuse and potential harms. This survey looks into the current status, different prospects and challenges in LLMs development in medical use cases and ways to control and mitigates risks of generative artificial intelligence.},
  keywords={Surveys;Ethics;Uncertainty;Generative AI;Large language models;Data security;Transforms;large language model;medicine;stomatology;ethics;risk analysis},
  doi={10.1109/ICDH62654.2024.00047},
  ISSN={},
  month={July},}@INPROCEEDINGS{10536541,
  author={Gatti, Elia and Giunchi, Daniele and Numan, Nels and Steed, Anthony},
  booktitle={2024 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, 
  title={AIsop: Exploring Immersive VR Storytelling Leveraging Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={865-866},
  abstract={We introduce Alsop, a system that autonomously generates VR sto-rytelling experiences using generative artificial intelligence (AI). Alsop crafts unique stories by leveraging state-of-the-art Large Lan-guage Models (LLMs) and employs Text-To-Speech (TTS) technology for narration. Further enriching the experience, a visual representation of the narrative is produced through a pipeline that pairs LLM-generated prompts with diffusion models, rendering visuals for clusters of sentences in the story. Our evaluation encompasses two distinct use cases: the narration of pre-existing content and the generation of entirely new narratives. Alsop highlights the myriad research prospects spanning its technical architecture and user engagement.},
  keywords={Visualization;Solid modeling;Three-dimensional displays;Generative AI;Conferences;Pipelines;Virtual reality;large language model;VR;storytelling;generative AI;Human-centered computing‚ÄîVirtual reality Human‚Äîcentered computing-Naturallanguage interfaces},
  doi={10.1109/VRW62533.2024.00229},
  ISSN={},
  month={March},}@INPROCEEDINGS{10707920,
  author={Li, Cheng-Tai and Lee, Liang-Hsuan and Hou, Huei-Tse},
  booktitle={2024 16th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)}, 
  title={An Educational Simulation Game Integrated with Generative AI as Conversational Contextual Scaffolding for Business English: A Preliminary Analysis of Learning Achievement, Self-Efficacy and Cognitive Load}, 
  year={2024},
  volume={},
  number={},
  pages={726-727},
  abstract={The rise of generative artificial intelligence (GAI) has had a significant impact on the English as foreign language (EFL) teaching field. How EFL teachers can make good use of GAI to enhance their teaching and students' learning is an important issue. The research developed an educational simulation game integrated with GAI to provide conversational contextual scaffolding and immersive language context to help EFL students learn tourism English. Evaluation of the proposed game-based learning approach was conducted through action research. The results indicated that this approach significantly promoted learning achievement and self-efficacy, and did not add too much to the workload of students' learning.},
  keywords={Generative AI;Education;Games;Cognitive load;Informatics;Business;Generative AI;EFL;conversational contextual scaffolding;immersive context;tourism English},
  doi={10.1109/IIAI-AAI63651.2024.00155},
  ISSN={2472-0070},
  month={July},}@INPROCEEDINGS{10972906,
  author={Lopes, Marilia K. S. and Falk, Tiago H.},
  booktitle={2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, 
  title={Generative AI for Personalized Multisensory Immersive Experiences: Challenges and Opportunities for Stress Reduction}, 
  year={2025},
  volume={},
  number={},
  pages={143-146},
  abstract={Stress management and relaxation are critical areas of interest in mental health and well-being. Forest bathing is a practice that has been shown to have a positive effect on reducing stress by stimulating all the senses in an immersive nature experience. Since access to nature is not universally available to everyone, virtual reality has emerged as a promising tool to simulate this type of experience. Furthermore, generative artificial intelligence (GenAI) tools offer new opportunities to create highly personalized and immersive experiences that can enhance relaxation and reduce stress. This study explores the potential of personalized multisensory VR environments, designed using GenAI tools, to optimize relaxation and stress relief via two experiments that are currently underway. The first evaluates the effectiveness of non-personalized versus personalized VR scenes generated using AI tools to promote increased relaxation. The second explores the potential benefits of providing the user with additional personalization tools, from adding new virtual elements to the AI-generated scene, to adding AI-generated sounds and scent/haptics customization. Ultimately, this research aims to identify which customizable elements may lead to improved therapeutic benefits for multisensory VR experiences.},
  keywords={Three-dimensional displays;Generative AI;Conferences;Virtual reality;Forestry;Mental health;User interfaces;Generative AI;environment personalization;multi-sensory virtual reality;forest bathing;relaxation},
  doi={10.1109/VRW66409.2025.00036},
  ISSN={},
  month={March},}@INPROCEEDINGS{11092216,
  author={Zhang, Yongfang and Gong, Xin and Wang, Xuan and Wang, Ziming and Zhou, Jiayu and Wang, Yuewen},
  booktitle={2025 7th International Conference on Computer Science and Technologies in Education (CSTE)}, 
  title={Research on the Application and Impact of Generative AI (AIGC) on College Students' Self-directed Learning}, 
  year={2025},
  volume={},
  number={},
  pages={557-560},
  abstract={With the rapid development of artificial intelligence technology, the application of Generative AI (AIGC) in the field of education has become increasingly widespread. This study, through interviews, delves into the current status, attitudes, impacts, and existing problems of college students' use of AIGC tools in their self-directed learning. The findings indicate that AIGC tools have played a positive role in improving learning efficiency, stimulating learning inspiration, and assisting academic writing. However, there are also issues such as insufficient accuracy of information, limited content innovation, and the potential for increased dependency. This paper proposes corresponding solutions and offers prospects for the future application of AIGC in the field of education.},
  keywords={Computer science;Technological innovation;Data privacy;Accuracy;Generative AI;Data security;Education;Interviews;Protection;Creativity;Generative AI(AIGC);college students;self-directed learning;information accuracy},
  doi={10.1109/CSTE64638.2025.11092216},
  ISSN={},
  month={April},}@ARTICLE{10811956,
  author={Li, Borui and Liu, Tianen and Wang, Weilong and Zhao, Chengqing and Wang, Shuai},
  journal={IEEE Network}, 
  title={Agent-as-a-Service: An AI-Native Edge Computing Framework for 6G Networks}, 
  year={2025},
  volume={39},
  number={2},
  pages={44-51},
  abstract={It has become a consensus that the integration of computing, sensing, and communication with ubiquitous intelligence will be the cornerstone of the sixth-generation (6G) network. The concept of edge computing and intelligence, which push the frontier of computation closer to the data source, is a suitable paradigm that aligns with these visions of 6G. In this article, we introduce Agent-as-a-Service (AaaS), an AI-native edge computing framework that leverages AI agents for both the control-plane operations and user-plane services of the 6G network. In the AaaS framework, agents can perform computing, sensing, and communicating tasks automatically by harnessing of the pervasive intelligence offered by 6G infrastructures. By AI-native, we refer to redesigning the whole lifecycle of an edge computing task to align with the prominent reasoning and planning ability of the generative AI. The lifecycle includes plan generation, execution orchestration, resource management, and long-term evolvement. The AaaS framework is built upon emerging techniques such as deviceless computing and WebAssembly to cope with the heterogeneous and geo-distributed 6G edge deployments. Based on the AaaS framework, we conduct a case study on autonomous driving in 6G edge computing to showcase the benefits in terms of overall latency reduction. Finally, we outline potential research directions to form a more efficient and integrated 6G edge computing with artificial intelligence.},
  keywords={6G mobile communication;Artificial intelligence;Edge computing;Planning;Robot sensing systems;Cognition;Autonomous vehicles;Generative AI;Computational modeling;Smart cities;Integrated sensing and communication;6G network;edge intelligence;AI agents;large language model},
  doi={10.1109/MNET.2024.3520987},
  ISSN={1558-156X},
  month={March},}@INPROCEEDINGS{9261711,
  author={Wang, Yinjun and Zeng, Liling and Ding, Xiaoxi and Wang, Liming and Shao, Yimin},
  booktitle={2020 International Conference on Sensing, Measurement & Data Analytics in the era of Artificial Intelligence (ICSMD)}, 
  title={Incremental Learning of Bearing Fault Diagnosis Via Style-Based Generative Adversarial Network}, 
  year={2020},
  volume={},
  number={},
  pages={512-517},
  abstract={At present, transfer learning of machine fault is a relatively popular research, its main problem is the imbalance of training data caused by the lack of actual fault data. The existing incremental learning model cannot solve the entanglement problem of sample features, and the ability to obtain new samples by combining features is limited. In this paper, Style-based Generative Adversarial Networks (StyleGAN) is used to map the data features to intermediate latent space, and then generate data by recombining features. StyleGAN realizes the complete separation of signal features. Therefore, StyleGAN can be used as a tool of data incremental learning to enrich the original data, solve the problem of imbalance between training data and test data, and achieve the goal of improving the accuracy of fault classification in the later stage. In the process of training, the category label is used as the auxiliary information to help the training model. The data of training set is enhanced, and the accuracy of fault diagnosis and classification is improved, the accuracy of fault classification network model is increased from 81.4% to more than 90%, so the validity of this method is proved.},
  keywords={Training;Wavelet transforms;Generators;Wavelet coefficients;Gray-scale;Data models;Convolution;Data imbalance;incremental learning;StyleGAN;transfer learning;bearing fault diagnosis},
  doi={10.1109/ICSMD50554.2020.9261711},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10762540,
  author={Hartato, Frandi and Yahya, Jovan and Enrico Christiano Hartono, Liem and Sudiana},
  booktitle={2024 International Seminar on Application for Technology of Information and Communication (iSemantic)}, 
  title={Art in the Era of Algorithms: Is Generative AI a Friend or Foe for 2D Artists?}, 
  year={2024},
  volume={},
  number={},
  pages={190-195},
  abstract={This research investigates the transformative impact of AI technologies such as DALL-E, ChatGPT, and other generative AI tools on the arts, particularly focusing on their implications for 2D artwork. These advancements have democratized the creation of 2D art, making it more accessible, but they have also raised concerns about the value of original talent and the potential impact on careers in the arts. The study employs the Technology Acceptance Model (TAM) to evaluate the acceptance and impact of generative AI among individuals in creative fields, including students, lecturers, and professionals. Data collected from 127 respondents through structured surveys indicate high levels of engagement with generative AI, reflecting significant curiosity and usage rates. Analysis using SmartPLS 4.0 Tools validated the initial research model, demonstrating that generative AI significantly influences perceived usefulness, perceived ease of use, and behavioral intention in 2D art creation. These findings underscore the critical need to consider AI's evolving role in the arts, its impact on perceptions of creativity and talent, and its broader implications for the creative industry. The study tested seven hypotheses, with six accepted and one rejected. This indicates that while factors like user computer self-efficacy and quality information significantly influence the perceived usefulness and ease of use of generative AI, ease of use alone does not necessarily lead to a positive attitude towards its use. However, perceived usefulness significantly contributes to a positive attitude towards using generative AI. Additionally, a positive attitude towards generative AI influences the behavioral intention to use it, thereby enhancing skills and providing inspiration for creating artwork.},
  keywords={Surveys;Seminars;Productivity;Industries;Java;Art;Technology acceptance model;Generative AI;Focusing;Chatbots;Artificial Intelligence;Generative AI;2D Artist;TAM Model;SEM-PLS},
  doi={10.1109/iSemantic63362.2024.10762540},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10761527,
  author={Zhang, Dajun and Shi, Wei},
  booktitle={2024 IEEE 12th International Conference on Information, Communication and Networks (ICICN)}, 
  title={Blockchain-based Edge Intelligence Enabled by AI Large Models for Future Internet of Things}, 
  year={2024},
  volume={},
  number={},
  pages={368-374},
  abstract={In recent years, the integration of Internet of Things (IoT) and Artificial Intelligence (AI) technologies has become a key factor in the development of modern communication systems. Through the deep integration of AI and IoT, the intelligence level of the network has been greatly improved, achieving higher data transmission speed, lower latency, and higher reliability to meet the growing communication needs. Especially in the context of intelligence networking and edge computing, large-scale language models (LLM) such as the Generative Pretrained Transformer (GPT) series have extended the capabilities to handle complex tasks and predict user intentions, programming, and planning. These capabilities provide new possibilities for optimizing communication systems, reducing semantic communication costs, and customizing services according to user preferences. This article explores the application of blockchain and AI large models in the edge intelligence of the Internet of Things, and proposes a distributed, non-tamperable knowledge and learning achievement recording system based on blockchain technology and AI large models. The system is designed to automatically generate code to train new models in a privacy-preserving manner. Experimental results show that the system can accurately understand user needs, efficiently execute, and create high-performance artificial intelligence models at minimal cost on edge servers.},
  keywords={Costs;Computational modeling;Data models;Blockchains;Recording;Internet of Things;Servers;Security;Artificial intelligence;Edge computing;Internet of Things;edge intelligence;AI large models;blockchain},
  doi={10.1109/ICICN62625.2024.10761527},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9018815,
  author={Chen, Baotong and Wan, Jiafu},
  booktitle={2019 Computing, Communications and IoT Applications (ComComAp)}, 
  title={Emerging Trends of ML-based Intelligent Services for Industrial Internet of Things (IIoT)}, 
  year={2019},
  volume={},
  number={},
  pages={135-139},
  abstract={Intelligent information technology is a notable feature in the context of industry 4.0. A key factor in obtaining intelligent industrial Internet of things (IIoT) services is to integrate machine learning (ML) into IIoT. With the increasing scale of deployed terminals, IIoT becomes heterogeneous, diverse, and dynamically changeable. Traditional optimization methods are difficult to deal with the emerging network problems. This paper first proposes a ML-based IIoT architecture for intelligent IIoT services and expounds two ML methods for IIoT analysis, namely, deep learning (DL) and reinforcement learning (RL). Secondly, advanced applications and development trends of ML in industrial field are summarized. Opportunities and challenges of ML for IIoT analysis are discussed finally. The purpose of this paper is to point out the role of artificial intelligence (AI) technology in IIoT from the macroscopic view.},
  keywords={Machine learning;Internet of Things;Learning (artificial intelligence);Routing;Adaptation models;Computer architecture;Industry 4.0;Industrial Internet of things;Machine Learning;Deep Learning;Reinforcement Learning},
  doi={10.1109/ComComAp46287.2019.9018815},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10820388,
  author={Mudabbirudin, Mohammed and Takacs, Judit and Mosavi, Amir and Imre, Felde and Nabipour, Narjes},
  booktitle={2024 IEEE 6th International Symposium on Logistics and Industrial Informatics (LINDI)}, 
  title={Deep Learning and Machine Learning for Materials Design}, 
  year={2024},
  volume={},
  number={},
  pages={73-82},
  abstract={The current materials design methodologies depend on AI-driven approaches to accelerate the development of materials. Deep learning (DL) and Machine Learning (ML) play essential roles in advancing materials design by automating analysis tasks and uncovering complex relationships within large datasets. These computational methods offer essential tools for materials innovation. This article investigates the impact of DL and ML on materials design innovation through proposing two taxonomies, i.e., one which focuses on the methods and the other on applications. The method-based taxonomy categorizes the different approaches used in DL and ML for materials design, while the application-based taxonomy presents the real-world scenarios.},
  keywords={Deep learning;Materials science and technology;Technological innovation;Reviews;Taxonomy;Learning (artificial intelligence);Mathematical models;Reliability;Informatics;Logistics;material science;materials design;artificial intelligence;ML;DL;applied mathematics;applied informatics;XAI;big data;data science;soft computing;computer science;applied ML;review;survey;generative AI;mathematics;mechatronics;model;information systems;data mining;generative artificial intelligence;sustainable development;SDGs;information fusion;data fusion;deep learning;machine learning},
  doi={10.1109/LINDI63813.2024.10820388},
  ISSN={2156-8804},
  month={Oct},}@INPROCEEDINGS{10664756,
  author={Marimekala, Daniel and Lamb, John},
  booktitle={2024 IEEE Integrated STEM Education Conference (ISEC)}, 
  title={Impact of Generative AI Adoption in Academia and How it Influences Ethics, Cognitive Thinking and AI Singularity}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Our Gen Alpha, born between year 2010 and 2024 see and experience more of AI and they adapt quickly to AI and will have less impact on advancements in Technology when compared to Generation X (19651980); Generation Y (Millennials) born from 1980 to 1994; Generation Z from 1995 to 2009. The reason is that Gen Alpha constantly uses electronic gadgets either in gaming, learning or for social media. They are susceptible quickly to Generative AI when compared to Gen X, Gen Y or Gen Z. Especially in Academia, where Gen Alpha is more encouraged to Generative AI such as ChatGPT in homework, assignments, and in research. Well, this is a good approach for those who are struggling to complete their work or for those who do not have a clue on how to complete their homework, assignment, or research. On other hand, the Generative AI tools such as ChatGPT are slowly becoming a part of the eco system that students lean on the Generative AI tools instead of doing research or thinking critically. As a result, there will be some behavioral changes that will be developed over a period. These behavioral changes are, impatient for answers to the problems, express panic while solving a problem, shows anxiety, low self-esteem in solving a problem, and low confidence factor. There is always a positive side of Generative AI, if we look at it from a different angle. Some of them are, it helps an individual and guides them with possible answers, all individuals can ask questions using prompt engineering and get responses. But the fact of the matter is how authentic the response from Generative AI is a question? Can the author quote the responses he/she received from ChatGPT and How can we avoid plagiarism? How can we reduce bias? How can we avoid AI singularity?},
  keywords={Technological innovation;Generative AI;Social networking (online);Shape;Plagiarism;Writing;Chatbots;Generative AI;ChatGPT;Guardrails;Singularity;AI Models;Large Language Models;ML},
  doi={10.1109/ISEC61299.2024.10664756},
  ISSN={2473-7623},
  month={March},}@INBOOK{10880522,
  author={Thakur, Raj and Patel, Shreyansh and Singh, Neelesh and Barde, Aaryan and Barde, Snehlata},
  booktitle={Generative Artificial Intelligence for Biomedical and Smart Health Informatics}, 
  title={Tackling the Complexities of Federated Learning}, 
  year={2025},
  volume={},
  number={},
  pages={343-353},
  abstract={Summary <p>Federated learning is an innovative machine learning approach enabling multiple devices to collaboratively train a model without sharing sensitive data, overseen by a central server. This chapter explores the strengths and vulnerabilities of federated learning, emphasizing its secure nature while acknowledging potential risks. It discusses key challenges like communication overhead and data heterogeneity, along with techniques to address them. The chapter also provides an overview of current federated learning methods, highlighting their efficacy and areas for improvement. Future directions are outlined, including enhancing robustness against attacks and scaling for larger systems, making this chapter a valuable resource for researchers and practitioners in the field of privacy&#x2010;preserving machine learning.</p>},
  keywords={Training;Data models;Servers;Brain modeling;Atmospheric modeling;Security;Predictive models;Monitoring;Inspection;Distributed databases},
  doi={10.1002/9781394280735.ch17},
  ISSN={},
  publisher={IEEE},
  isbn={9781394280728},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10880522},}@INPROCEEDINGS{11159054,
  author={Boljam, Ajay Mysore and Ul Hassan Mohammed, Hameed and Alluri, Venkat Rama Raju and Saini, Vipin and Bojja, Sai Ganesh Reddy},
  booktitle={2025 International Conference on Computing Technologies & Data Communication (ICCTDC)}, 
  title={Impact Analysis of Generative AI on the Accuracy and Scalability of Machine Learning Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Generative AI has become a fundamental tool in machine learning which address the issues of data scarcity, model generalization, providing additional model efficacy and allowing them to scale horizontally in nature. In this paper, presents the effect of generative AI on the performance of machine learning models with respect to improved accuracy and enhanced scalability. Advanced generative AI methods including GANs and VAEs are examined for data augmentation, model training, and other robustness improvements. The research shows that integrating generative AI with machine learning pipelines can dramatically boost the performance of machine learning models, especially in data-scarce settings. This enhances the scalability of the models, allowing them to perform better on larger and more complex datasets. These results indicate the potential significance of generative AI in paving the way for better application of machine learning, enabling a streamlined model while being generalizable to a wider scope of real-world systems.},
  keywords={Training;Analytical models;Accuracy;Generative AI;Scalability;Pipelines;Machine learning;Data augmentation;Data models;Robustness;Generative AI;Machine Learning Models;Accuracy;Scalability;Neural Networks;Model Efficiency;Data Augmentation;Deep Learning;Model Robustness},
  doi={10.1109/ICCTDC64446.2025.11159054},
  ISSN={},
  month={July},}@INPROCEEDINGS{10500778,
  author={Ramful, Raviduth and Shoaib Casseem, Mohammad},
  booktitle={2023 International Conference on Sustainable Technology and Engineering (i-COSTE)}, 
  title={Improving the Flexural Behaviour of Small Clear 3D-Printed PLA Specimens Through Generative Design}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={The interest to look into alternative engineered materials, which would maximize the efficiency and performance attributes in numerous modern engineering application as well as to push the boundary imposed by present-day material science in the field engineering, is ever so high. One commonly searched feature in engineered materials is their high strength-to-weight ratio. The new AI (Artificial Intelligence) -driven technique of generative design has revolutionized the method of design refinement in Computer-Aided Design (CAD) by enabling advanced optimization techniques which was formerly-unavailable. This study seeks to apply the technique of generative design to improve the flexural behaviour of small clear Polylactic acid (PLA) specimens produced through the additive manufacturing process. The results obtained have shown that despite the optimized material geometry and weight, the refined model was still able to bear significantly high bending loads. Further analysis via the Finite Element Method (FEM) was conducted to substantiate the experimental investigation. Findings of this study illustrates the benefits of generative design which can seamlessly provide advanced design refinements all while preserving or enhancing mechanical performance of the material.},
  keywords={Geometry;Solid modeling;Design automation;Programmable logic arrays;Bending;Three-dimensional printing;Finite element analysis;Generative design;3D-Printing;flexural behaviour;additive manufacturing;design optimization;Finite Element Method (FEM)},
  doi={10.1109/i-COSTE60462.2023.10500778},
  ISSN={},
  month={Dec},}@ARTICLE{10973296,
  author={Liu, Yinqiu and Du, Hongyang and Niyato, Dusit and Kang, Jiawen and Xiong, Zehui and Wen, Yonggang and Kim, Dong In},
  journal={IEEE Network}, 
  title={Generative AI in Data Center Networking: Fundamentals, Perspectives, and Case Study}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Generative AI (GenAI), exemplified by Large Language Models (LLMs), such as OpenAI‚Äôs ChatGPT, is revolutionizing various fields. Central to this transformation is Data Center Networking (DCN), which not only provides the infrastructure support for GenAI operation, but also provisions GenAI services to users. Hence, this article explores the interplay between GenAI and DCNs, analyzing their symbiotic relationship and mutual advances. We begin by reviewing the current challenges of DCNs and GenAI-based solutions, such as data augmentation, process automation, and domain transfer. We then discuss the distinctive characteristics of GenAI workloads on DCNs, gaining insights that catalyze the evolution of DCNs to more effectively support GenAI. Moreover, to illustrate the seamless integration of GenAI with DCNs, we present a case study on GenAI-empowered DCN digital twins. Specifically, we employ an LLM equipped with retrieval augmented generation to formulate optimization problems for DCNs (e.g., resource allocation and routing) and adopt diffusion-deep reinforcement learning to solve optimization. The experimental results on a representative DCN optimization problem, i.e., knowledge placement, demonstrate the validity and efficiency of our proposals. We anticipate that this article can promote further research to enhance the virtuous interaction between GenAI and DCNs.},
  keywords={Artificial intelligence;Training;Servers;Data centers;Optimization;Reviews;Load management;Data models;Topology;Routing;Generative artificial intelligence;large language model;data center networking;sustainability},
  doi={10.1109/MNET.2025.3563262},
  ISSN={1558-156X},
  month={},}@INPROCEEDINGS{10915950,
  author={Hsu, Chia-fang and Kuo, Liang-Yin},
  booktitle={International Conference on Innovation, Communication and Engineering 2024 (ICICE 2024)}, 
  title={The application of generative AI in the creation of picture books for young children in early childhood education undergraduate course}, 
  year={2024},
  volume={2024},
  number={},
  pages={128-131},
  abstract={Artificial Intelligence (AI) technologies are emerging as a critical technological capability of the 21st century and have been spreading their influence in various fields of education, including early childhood education (ECE) in recent years. When properly used and thoughtfully integrated into teaching, AI can be a powerful and effective tool in the classroom, not only to provide inspiration, generate ideas and encourage creativity for both children and teachers, but most importantly to prepare them for a future where technology plays an increasingly important role in schooling. For early childhood educators, AI can also be a tremendous assistant as an administrative helper, idea generator or data organizer, helping teachers to think outside the box and prepare for teaching more creatively and effectively. It appears that there is a growing need for early childhood educators to have not only pedagogical expertise but also a strong foundation in AI literacy, and that pre-service teachers need to be equipped with the ability to use AI appropriately in their formative or undergraduate stages. Therefore, this study aims to explore the ability of early childhood education students to use AI in the creation of picture books for young children, and seeks to provide insights into the potential strengths, weaknesses and ethical issues of integrating AI into early childhood education undergraduate course.},
  keywords={},
  doi={10.1049/icp.2025.0213},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10575055,
  author={Tejaswi, Majeti and Tapan, Kandikonda and Sathvik, Kunapareddi and Valiveti, Hima Bindu},
  booktitle={2024 3rd International Conference on Applied Artificial Intelligence and Computing (ICAAIC)}, 
  title={Implementation of Cycle Consistent GANs for Map to Image Translation using Deep Learning Techniques}, 
  year={2024},
  volume={},
  number={},
  pages={393-398},
  abstract={With the rapid urbanization and population growth, locating suitable geographical areas to accommodate these drastic changes is paramount. This study explores the use of Generative Adversarial Networks (GANs), specifically Cycle- Consistent Generative Adversarial Networks (Cycle GAN) and Conditional GAN(C-GAN), to generate a map image from a satellite image, that is easy to read and understand. By conditioning the generator and discriminator networks on the input satellite images and target map domain, the model picks up on certain distinguishable features from the satellite image and the map image to generate a map image. A Cycle-GAN doesn‚Äôt require the use of paired datasets, unlike C-GAN. This research study also briefly discusses about the various features that the Cycle-GAN applies to generate an accurate image. Various loss functions such as GAN loss, identity loss, and Cycle consistency loss that the GAN employs to improve the resolution of the image are also discussed in the study.},
  keywords={Accuracy;Image resolution;Navigation;Urban areas;Sociology;Generative adversarial networks;Satellite images;Generative Adversarial Network;Cycle-Consistent Adversarial Network;GAN loss;Identity Loss;Cycle Consistency Loss},
  doi={10.1109/ICAAIC60222.2024.10575055},
  ISSN={},
  month={June},}@INPROCEEDINGS{9996040,
  author={Lamjid, Ali and Ariffin, Khairul Akram Zainol and Aziz, Mohd Juzaiddin AB and Sani, Nor Samsiah},
  booktitle={2022 International Conference on Cyber Resilience (ICCR)}, 
  title={Determine the optimal Hidden Layers and Neurons in the Generative Adversarial Networks topology for the Intrusion Detection Systems}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={Neural Networks (NNs) are a vast field of research, particularly in terms of adjusting hyper-parameters such as hidden layers (HLs) and hidden neurons (HNs). On the other hand, (NN)s presents the main component of GAN's two elements: (1) Generator (G) and (2) Discriminator (D). It improves GAN as NN optimizes its parts. The number of Hidden Layers (HLs) and Hidden Neurons (HNs) inside the neural networks remains an important research topic despite numerous rules trying to predict the values by some directives and calculations. However, the study of the deepness and wideness of both (G) and (D) is still under-explored, and exploring this topic in GAN was neglected. Hence, this research focuses on the (NN)s contained in the original architecture of GAN and targets to clarify the relation between the number of (HL)s and (HN)s in the Generator (G) and the Discriminator (D) inside GAN. Furthermore, the goal is to determine which (NN) should have the most significant number of (HL) and (HN) in order to improve the performance of the created samples. Therefore, experiments were carried out by (1) increasing the number of (HL)s equally or differently in the G and the D and (2) increasing the number of (HN)s in each (HL) either on G or D. Deep Neural Network (DNN) is chosen as an intrusion detection system (IDS) model and the benchmark dataset KDD99 was used for application. It has been observed that a large number of (HL)s and (HN)s in the (G) improved GAN training and convergence. It means that the (G) should have more critical (HL)s and (HN)s than the (D) to generate better samples. Thus, this study provides the researchers with a vital resource to optimize the GAN's (NN)s and to process the experiments in this field by standardizing the number of (HL)s and (HN)s. The experiments carried out revealed that better training and convergence are seen when the number of (HL)s is 10 and the number of (HN)s is 1024 in the (G). The highest accuracy completed is 0.9991 which is 10 (HL)s and 1024 (HN)s in the Generator, and 2 (HL)s and 64 (HN)s in the Discriminator.},
  keywords={Training;Neurons;Intrusion detection;Artificial neural networks;Generative adversarial networks;Generators;Biological neural networks;Hidden Layers;Hidden neurons;Generative Adversarial Networks;Intrusion Detection System},
  doi={10.1109/ICCR56254.2022.9996040},
  ISSN={},
  month={Oct},}@ARTICLE{9236637,
  author={Deng, Qiyao and Li, Qi and Cao, Jie and Liu, Yunfan and Sun, Zhenan},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Controllable Multi-Attribute Editing of High-Resolution Face Images}, 
  year={2021},
  volume={16},
  number={},
  pages={1410-1423},
  abstract={In recent years, significant progress has been achieved in face image editing due to the success of Generative Adversarial Network (GAN). However, state-of-the-art face editing methods mainly suffer from the following two limitations: 1) they are only applicable to face images with relative low-resolutions and 2) multi-attribute face editing may generate uncontrollable changes in non-target face attribute categories. To solve these problems, we propose a novel High-Quality Generative Adversarial Network (HQ-GAN) for controllable editing of multiple face attributes in high-resolution images. HQ-GAN has two novel ideas to break the limitations of resolution and controllability correspondingly: 1) fine-grained textures and realistic details of high-resolution face images are better preserved with the aid of textural features extracted by the wavelet transform module and 2) desired multi-attribute targets of face editing are emphasized using a weighted binary cross-entropy (BCE) loss so that the influence on non-target attributes is greatly reduced. To the best of our knowledge, HQ-GAN is the first attempt to achieve continuous editing of multiple face attributes on high-resolution images of the CelebA-HQ using only 28 000 training samples. Extensive qualitative results demonstrate the superiority of the proposed method in rendering realistic high-resolution face images with accurate attribute modification, and comprehensive quantitative results show that the proposed method significantly outperforms state-of-the-art face editing methods.},
  keywords={Faces;Image resolution;Face recognition;Wavelet transforms;Generative adversarial networks;Gallium nitride;Computational modeling;Face attribute editing;face synthesis;generative adversarial network},
  doi={10.1109/TIFS.2020.3033184},
  ISSN={1556-6021},
  month={},}@INPROCEEDINGS{10792726,
  author={Jiang, Meichen and Fang, Xi},
  booktitle={2024 9th International Conference on Intelligent Informatics and Biomedical Sciences (ICIIBMS)}, 
  title={The Significance of Cultivating High-Value Patents in the Development of AI}, 
  year={2024},
  volume={9},
  number={},
  pages={648-651},
  abstract={With the rapid development of generative artificial intelligence (AI) technology, high-value patents play an increasingly important role in protecting innovation, promoting technological progress, and enhancing market competitiveness. This paper aims to explore how to effectively cultivate high-value patents in the field of generative AI and analyze their significance for technological innovation and industrial development. First, we review the basic concepts and current technological status of generative AI, conduct an in-depth analysis of high-value patents, and propose various strategies and methods for cultivating such patents. Through detailed case studies of Transformer architectures, this paper demonstrates the cultivation process and key success factors of these high-value patents. The study shows that high-value patents not only protect innovation outcomes but also promote the widespread application and commercialization of generative AI technology, providing strong support for sustainable technological development.},
  keywords={Industries;Patents;Technological innovation;Generative AI;Reviews;Technology transfer;Companies;Transformers;Faces;Commercialization;Generative AI;High-Value Patents;Patent Cultivation},
  doi={10.1109/ICIIBMS62405.2024.10792726},
  ISSN={2189-8723},
  month={Nov},}@INPROCEEDINGS{10930297,
  author={Yilmazer, Merve and Karakose, Mehmet},
  booktitle={2025 29th International Conference on Information Technology (IT)}, 
  title={LLM-Based Video Analytics Test Scenario Generation in Smart Cities}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={Rapid advances in the field of artificial intelligence have made significant contributions to the automation of software development and testing stages. Software created for use in various fields is tested with test scenarios created manually by software test experts or using test automation. Testing large-scale software with these methods complicates the testing phases because it requires increased human intervention and includes complex applications. In this study, an LLM-based scenario generation framework enhanced with prompt engineering is proposed for testing software to be used for video analysis in smart cities and smart campus areas. Thus, software test scenarios are created by strengthening large language models that are fast, flexible and have high learning ability using prompt engineering techniques. Test scenarios produced through LLM reinforced with prompt engineering techniques were evaluated with rarity and reality metrics and it was determined that more robust scenarios were produced compared to randomly generated test scenarios in the relevant field.},
  keywords={Software testing;Measurement;Automation;Smart cities;Large language models;Visual analytics;Software;Prompt engineering;Scenario generation;Software development management;prompt engineering;large language model;software testing;generative artificial intelligence;smart cities},
  doi={10.1109/IT64745.2025.10930297},
  ISSN={2836-3744},
  month={Feb},}@INPROCEEDINGS{9845345,
  author={Wang, Shuangbao Paul and Arafin, Md Tanvir and Osuagwu, Onyema and Wandji, Ketchiozo},
  booktitle={2022 6th International Conference on Cryptography, Security and Privacy (CSP)}, 
  title={Cyber Threat Analysis and Trustworthy Artificial Intelligence}, 
  year={2022},
  volume={},
  number={},
  pages={86-90},
  abstract={Cyber threats can cause severe damage to computing infrastructure and systems as well as data breaches that make sensitive data vulnerable to attackers and adversaries. It is therefore imperative to discover those threats and stop them before bad actors penetrating into the information systems.Threats hunting algorithms based on machine learning have shown great advantage over classical methods. Reinforcement learning models are getting more accurate for identifying not only signature-based but also behavior-based threats. Quantum mechanics brings a new dimension in improving classification speed with exponential advantage. The accuracy of the AI/ML algorithms could be affected by many factors, from algorithm, data, to prejudicial, or even intentional. As a result, AI/ML applications need to be non-biased and trustworthy.In this research, we developed a machine learning-based cyber threat detection and assessment tool. It uses two-stage (both unsupervised and supervised learning) analyzing method on 822,226 log data recorded from a web server on AWS cloud. The results show the algorithm has the ability to identify the threats with high confidence.},
  keywords={Privacy;Machine learning algorithms;Supervised learning;Quantum mechanics;Reinforcement learning;Data breach;Web servers;Machine Learning;Threat detection;Trustworthy AI;Data Analytics;quantum computing},
  doi={10.1109/CSP55486.2022.00024},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{11101561,
  author={Wang, Tianjun and Wang, Kai and Guo, Jiangtao and Xiao, Jingfeng and Cao, Shu and Lan, Songyan and Niu, Zhewen},
  booktitle={2025 IEEE International Symposium on the Application of Artificial Intelligence in Electrical Engineering (AAIEE)}, 
  title={Wind Power Scenario Generation Based on Temporal Conditional Generative Adversarial Network}, 
  year={2025},
  volume={},
  number={},
  pages={544-549},
  abstract={The uncertainty of wind power output poses significant challenges to the stable operation of power systems. Artificial intelligence-based scenario generation approach offers a new way to frame uncertainty in wind power. However, generative adversarial networks (GANs) face challenges, including limited ability to effectively capture temporal information, instability during the training process, and susceptibility to mode collapse. To this end, this paper proposes a Temporal Conditional Generative Adversarial Network (TC-GAN) for renewable energy output generation. Temporal convolutional networks are embedded in both the generator and discriminator of conditional generative adversarial networks (CGAN), with the Wasserstein distance serving as the loss function for the discriminator. This design enables adversarial training to effectively capture the mapping relationships between noise and scenarios in day-ahead forecasting conditions. Furthermore, a comprehensive evaluation metric system for generated scenarios was developed, employing statistical analysis methods to assess scenario quality. Case studies demonstrate that the proposed model effectively captures temporal dependencies and enhances the accuracy of wind power scenario generation.},
  keywords={Training;Renewable energy sources;Uncertainty;Statistical analysis;Wind power generation;Power system stability;Generative adversarial networks;Spatiotemporal phenomena;Scenario generation;Optimization;renewable energy;uncertainty modeling;scenario generation;generative model},
  doi={10.1109/AAIEE64965.2025.11101561},
  ISSN={},
  month={April},}@ARTICLE{10529221,
  author={Du, Hongyang and Zhang, Ruichen and Liu, Yinqiu and Wang, Jiacheng and Lin, Yijing and Li, Zonghang and Niyato, Dusit and Kang, Jiawen and Xiong, Zehui and Cui, Shuguang and Ai, Bo and Zhou, Haibo and Kim, Dong In},
  journal={IEEE Communications Surveys & Tutorials}, 
  title={Enhancing Deep Reinforcement Learning: A Tutorial on Generative Diffusion Models in Network Optimization}, 
  year={2024},
  volume={26},
  number={4},
  pages={2611-2646},
  abstract={Generative Diffusion Models (GDMs) have emerged as a transformative force in the realm of Generative Artificial Intelligence (GenAI), demonstrating their versatility and efficacy across various applications. The ability to model complex data distributions and generate high-quality samples has made GDMs particularly effective in tasks such as image generation and reinforcement learning. Furthermore, their iterative nature, which involves a series of noise addition and denoising steps, is a powerful and unique approach to learning and generating data. This paper serves as a comprehensive tutorial on applying GDMs in network optimization tasks. We delve into the strengths of GDMs, emphasizing their wide applicability across various domains, such as vision, text, and audio generation. We detail how GDMs can be effectively harnessed to solve complex optimization problems inherent in networks. The paper first provides a basic background of GDMs and their applications in network optimization. This is followed by a series of case studies, showcasing the integration of GDMs with Deep Reinforcement Learning (DRL), incentive mechanism design, Semantic Communications (SemCom), Internet of Vehicles (IoV) networks, etc. These case studies underscore the practicality and efficacy of GDMs in real-world scenarios, offering insights into network design. We conclude with a discussion on potential future directions for GDM research and applications, providing major insights into how they can continue to shape the future of network optimization.},
  keywords={Optimization;Tutorials;Computational modeling;Electronic mail;Task analysis;Data models;Artificial intelligence;Diffusion model;deep reinforcement learning;generative AI;AI-generated content;network optimization},
  doi={10.1109/COMST.2024.3400011},
  ISSN={1553-877X},
  month={Fourthquarter},}@INBOOK{10952212,
  author={Musiol, Martin},
  booktitle={Generative AI: Navigating the Course to the Artificial General Intelligence Future}, 
  title={Generative AI's Exponential Growth}, 
  year={2024},
  volume={},
  number={},
  pages={219-283},
  abstract={Summary <p>This chapter peels back the layers and explores the underlying factors that played a pivotal role in the rise of generative AI. The rise of generative AI is being significantly propelled by its convergence with other fields&#x2014;a phenomenon known as technological convergence. Technological convergence is often directional, with one field exerting a greater influence on other. Cloud computing, in its essence, is the great equalizer. It has ushered in an era where computing power, once the exclusive domain of tech behemoths, is now within arm's reach of the many. Quantum computing holds the potential to transform the computational world. Big Data is the main source for modern AI systems, providing the information for machine learning (ML) to get better. The evolution in AI is driven by advanced ML algorithms, an open source culture, and a suite of tools and libraries that streamline AI development.</p>},
  keywords={Artificial intelligence;Generative AI;Technological innovation;Business;Investment;Games;Deep learning;Cloud computing;Vehicle dynamics;Transistors},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394205950},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952212},}@INPROCEEDINGS{11076064,
  author={Shibli, Ali and Nascetti, Andrea and Ban, Yifang},
  booktitle={2025 Joint Urban Remote Sensing Event (JURSE)}, 
  title={Very High- to High- Resolution Imagery Transferability for Building Damage Detection Using Generative AI}, 
  year={2025},
  volume={CFP25RSD-ART},
  number={},
  pages={1-4},
  abstract={Wildfires are a growing global concern, causing significant damage to urban infrastructure each year. This study presents a novel approach for building damage assessment using generative artificial intelligence, focusing on the transferability of high-resolution satellite imagery models to lower-resolution datasets. Our diffusion-based model is trained on the xView2 Wildfire Building Damage Benchmark, a dataset specifically designed for wildfire-induced building damage detection. The model is further evaluated on real-world wildfire incidents in Lahaina, Hawaii, and Athens, Greece, demonstrating its effectiveness in damage localization across varying spatial resolutions. With competitive performance on benchmark datasets and practical utility in real-world scenarios, this work highlights the potential of generative AI for geospatial disaster assessment and urban resilience.},
  keywords={Deep learning;Wildfires;Generative AI;Disasters;Buildings;Benchmark testing;Diffusion models;Satellite images;Geospatial analysis;Spatial resolution;Natural disasters;wildfire;machine learning;diffusion models;deep learning;generative artificial intelligence;satellite imagery;geospatial data},
  doi={10.1109/JURSE60372.2025.11076064},
  ISSN={2642-9535},
  month={May},}@INPROCEEDINGS{10981398,
  author={Montoya Montoya, Jos√© Fabi√°n and Lopez-Vargas, Jorge},
  booktitle={2025 IEEE Engineering Education World Conference (EDUNINE)}, 
  title={DS Generative AI for Supporting Teaching Activities}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={Generative Artificial Intelligence (GAI) has become significant in education, particularly for creating content, resources, and automating repetitive and timeconsuming tasks. This project explores GAI‚Äôs potential to support teachers in analyzing low-to-medium complexity programs of student‚Äôs tasks, supporting the activities of teachers. The proposed solution includes an API and web application built based on the GPT-4o Large Language Model (LLM), specifically designed for teachers. The methodology begins with a review of relevant literature review to identify scenarios where GAI have shown their potential in the educational field. Subsequently, the performance of the GPT-4o model is evaluated in the context of review and analysis of student‚Äôs source code, using the Teaching Plans which the task proposals are extracted along with their respective evaluation rubrics, determining the quality and effectiveness of generative AI within this real application.},
  keywords={Generative AI;Source coding;Large language models;Refining;Prototypes;Reliability engineering;Proposals;Iterative methods;Programming profession;Systematic literature review;generative artificial intelligence;education;programming;source code analysis;gpt-4o;api;web application},
  doi={10.1109/EDUNINE62377.2025.10981398},
  ISSN={},
  month={March},}@INPROCEEDINGS{8396171,
  author={Chen, Yuwen and Zhong, Kunhua and Wang, Fei and Wang, Hongqian and Zhao, Xueliang},
  booktitle={2018 International Conference on Artificial Intelligence and Big Data (ICAIBD)}, 
  title={Surgical workflow image generation based on generative adversarial networks}, 
  year={2018},
  volume={},
  number={},
  pages={82-86},
  abstract={In the medical field, the labeling of surgical video data requires Expert knowledge, collecting enough numbers of marked surgical video data is difficult and time-consuming. The insufficient video data (labeled data) leads to the low generalization ability of the training model and the low accuracy of recognition. It has been recently shown that Generative Adversarial Networks (GANs) can produce synthetic images of exceptional visual fidelity. In this work, the authors propose the GAN-based method for automatic Surgical Workflow images. The theory and methodology of this paper are validated on real three surgery video datasets. It can generative effective surgical workflow images. The technology studied in this paper has broad application prospects in computer-aided surgical systems and is a core component of the artificial intelligence medical operating room in the future.},
  keywords={Surgery;Generators;Gallium nitride;Training;Hospitals;Biomedical imaging;Laparoscopes;surgical workflow;generative adversarial networks;CNN},
  doi={10.1109/ICAIBD.2018.8396171},
  ISSN={},
  month={May},}
