@INPROCEEDINGS{10368911,
  author={Prabha, R Sakthi and Vadivel, M.},
  booktitle={2023 International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)}, 
  title={SEFCL-DNN Based Multi-Grade Brain Tumor Prediction Model with Survival Time Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Among adults and children, one of the most dangerous and deadly cancers is Brain Tumor (BT). For treating the tumor effectively, BTs’ early identification along with classification into their specific grade is very important. For minute feature extraction as well as precise classification, prevailing techniques suffer from inherent challenges. Thus, this paper proposes a novel Squared Exponential Function activated Charbonnier Loss employed Deep Neural Network (SEFCL-DNN) and Fuzzy Inference System (FIS)-based survival time analysis of detected BT grades. Primarily, pre-processing is conducted, where bias correction, noise removal, along with edge detection and enhancement are executed. Thereafter, by utilizing Reniy’s Entropy-based Morphological Operation (REMO), the morphological operation is performed. Afterward, by employing the Cauchy Distributed-Ai-Biruni Earth radius Optimization Algorithm (CD-AiEBOA), the tumors are segmented. Next, grounded on the abnormalities of tumors and necrosis, the segmented images are clustered using Sorensen Dice Based Gaussian mixture model clustering (SDB-GMMC). Following this clustering, the features of tumors are extracted. Then, by utilizing the Symmetrical Uncertainty Principal Component Analysis (SU-PCA), the important features are selected. For classifying the grades of tumors, the selected features are fed into SEFCL-DNN. Grounded on the risk score, the survival time is analyzed for the classified grades. As per the experimental outcomes, the proposed technique withstands maximum accuracy as compared to prevailing methodologies.},
  keywords={Earth;Image segmentation;Analytical models;Uncertainty;Clustering algorithms;Feature extraction;Optimization;Cauchy Distributed-Ai-Biruni Earth radius Optimization Algorithm (CD-AiBEOA);Sorensen Dice Based Gaussian mixture model clustering (SDB-GMMC)},
  doi={10.1109/RMKMATE59243.2023.10368911},
  ISSN={},
  month={Nov},}@ARTICLE{10970392,
  author={Wang, Rui and Song, Chunyue and Li, Chaojie and Wang, Yi and Dong, Zhao Yang},
  journal={IEEE Systems, Man, and Cybernetics Magazine}, 
  title={The Go-to-Market Game Changer in the Low-Carbon Energy Industry: Generative Pre-Transformer and Its Potential for Improving Efficiency and Sustainability}, 
  year={2025},
  volume={11},
  number={2},
  pages={92-106},
  abstract={Conventional decision-making problem in the energy Industry requires complying with codes which requires programming ability and expert domain knowledge. The new AI technology Generative Pretrained Transformer 4 (GPT4) has exhibited human-like performance in professional activities through generated prompts instead of coding, demonstrating its potential to change the energy industry in terms of efficiency and sustainability. In this paper, how the generative AI technology of GPT could revolutionize the low-carbon energy sector is considered, particularly how it could provide unparalleled support in power system operation, smart home management, and electrical engineering education. Firstly, GPT holds promise to be an efficiency optimizer and sustainability promoter because it can be leveraged to deliver the best value for analyzing huge amounts of data from multiple sources, i.e., weather information and load demand, to provide real-time decision-making and insightful interpretations for power grid operation. Secondly, with its powerful self-learning ability, GPT could be utilized to help the household electronics systems of smart homes adapt to various human activities and environmental conditions. Thirdly, GPT could be used for communication innovations to boost meaningful conversation and avoid misunderstanding in learning complicated engineering mathematics and physical concepts, which would play a critical role in cultivating the next generation of electrical engineers. To demonstrate the potential of GPT in the Low-carbon energy industry, ChatGPT is applied to interpret the OPF solution with MATLAB for real-time decision, to forecast the solar energy with an explanation for decision support and assessment, and to boost meaningful conversation for electrical education of the electric circuit expression. Finally, future directions and limitations of GPT in the energy industry are discussed.},
  keywords={Industries;Electric potential;Decision making;Smart homes;Solar energy;Real-time systems;Power grids;Sustainable development;Next generation networking;Low carbon economy;Market research;Chatbots},
  doi={10.1109/MSMC.2024.3440569},
  ISSN={2333-942X},
  month={April},}@INPROCEEDINGS{11101397,
  author={Azzahra, Naufalia and Maziati, Devi and Fauzi, Hilman},
  booktitle={2025 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT)}, 
  title={Indonesian Herbal Plant Identification System Based on Deep Learning}, 
  year={2025},
  volume={},
  number={},
  pages={599-606},
  abstract={Indonesia possesses a rich diversity of herbal plants, with more than 3,000 species used in traditional medicine. However, the limited public ability to identify these plants impedes their optimal utilization. This paper presents an automated herbal plant identification system using leaf image processing and the YOLOv5s deep learning algorithm. A total 15,042 leaf images representing 20 herbal plant classes were collected and annotated using the Roboflow platform. The YOLOv5s model was trained and evaluated using accuracy, precision, recall, F1-score, and mean average precision (mAP50 and mAP50-95) metrics. Experimental results indicate that the model achieves an accuracy of 0.99, a precision and recall of 0.98, an F1-score of 0.98, an mAP50 of 0.98, and an mAP50-95 of 0.85 on the test set. Additionally, comparisons show that the YOLOv5s method works better than other top models like Faster RCNN and EfficientDet for identifying herbal plants. We evaluated the system under varying lighting and distance conditions, demonstrating reliable results across diverse environments.},
  keywords={YOLO;Deep learning;Measurement;Accuracy;Plants (biology);Lighting;Robustness;Real-time systems;Classification algorithms;Biomedical imaging;herbal plants;leaf identification;YOLOv5s;deep learning;image processing},
  doi={10.1109/IAICT65714.2025.11101397},
  ISSN={2834-8249},
  month={July},}@INPROCEEDINGS{10960027,
  author={Mohammad, Manzoor and Rout, Saroja Kumar and Praveen Kumar, Kanna and Jabbar, M.A. and Babu, Burra. Vijaya and Swapna, B.},
  booktitle={2024 2nd International Conference on Artificial Intelligence Trends and Pattern Recognition (ICAITPR)}, 
  title={A Survey on Machine Learning and Deep Learning Techniques for Alzheimer’s Disease Prediction}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Alzheimer’s disease (AD) is a brain condition that cannot be cured that gradually impairs cognitive function, symptoms can be greatly reduced with early identification. Nearly 20 years before AD is diagnosed, brain cell deterioration, synaptic dysfunction, and pathological alterations begin to manifest. A thorough examination of particular brain disorders’ tissues is necessary in order to precisely identify the condition using segmented magnetic resonance imaging (MRI). The literature review study investigates the use of MRI scans and deep learning algorithms for the identification of Alzheimer’s disease. Eight distinct research papers were examines, each employing various classification algorithms including pre-trained Convolutional Neural Networks. These research concentrated on categorising Alzheimer’s disease into several phases. The commonly utilized datasets in these investigations were ADNI and OASIS. The report provides an overview of the methodologies employed, emphasizing the diverse approaches taken in utilizing classification algorithms and CNN’s for Alzheimers disease stage classification based on MRI images.},
  keywords={Deep learning;Surveys;Pathology;Magnetic resonance imaging;Market research;Classification algorithms;Pattern recognition;Convolutional neural networks;Alzheimer's disease;Systematic literature review;Alzheimer’s Disease;Dementia;Magnetic Resonance Imaging;Classification;Deep Learning;Convolutional Neural Networks},
  doi={10.1109/ICAITPR63242.2024.10960027},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10369329,
  author={Dinesh Krishnan, S and G, Arun Prasath and Gatla, Rahul and Kommula, Bindhusri and Kalali, Vishnu Vardhan and Kaparthi, Bharath},
  booktitle={2023 International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)}, 
  title={Improving Action Recognition through Pose Estimation and Directed Graph Neural Networks}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={To improve the accurate performance and robustness of action recognition systems, this study attempts to merge the posture estimation and skeleton-based action recognition. While pose estimation provides a spatial representation of important places on the human body, skeleton-based action identification focuses on examining the time dynamics of human motions. By combining these two methods, we increase the performance of action recognition by utilizing the complementary data from both the spatial and temporal domains. Through empirical evaluation on benchmark dataset, this study shows the efficiency of alternative approaches for fusing posture estimation with action recognition. The outcomes show that this integrated method has the potential to attain cutting-edge performance in identifying human actions.},
  keywords={Pose estimation;Neural networks;Dynamics;Directed graphs;Benchmark testing;Robustness;Skeleton;Directed graph network block;Two-stream framework;Spatial information;Temporal convolutional block},
  doi={10.1109/RMKMATE59243.2023.10369329},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11063977,
  author={Kumar, P and Pandi S, Senthil and Kumar L, Bharath and R, Karthick},
  booktitle={2025 3rd International Conference on Communication, Security, and Artificial Intelligence (ICCSAI)}, 
  title={Enhanced Security with Deep Learning-Based Intrusion Detection}, 
  year={2025},
  volume={3},
  number={},
  pages={1484-1488},
  abstract={The Internet of Things (IoT) is widely used in modern culture, particularly in intelligent transportation systems and smart homes. According to IHS Markit, there will be 125 billion linked devices by 2030, up from 27 billion in 2017. That equates to an average annual growth rate of 12%. The design of the current Internet of Things, the vast number of linked devices, the variety of connection types (mainly wireless), and the massive volumes of data transferred over the network raise serious security issues. Numerous new technical security risks are emerging as a result of the Internet of Things. Although there are several approaches available for protecting IoT networks, more is still required. We suggest using deep learning to improve it. Denial-of-service (DOS), distributed denial-of-service (DDOS), probing, man-in-the-middle (spoofing), and remote-to-local attacks are among the potential attacks that the current approach should be able to detect. The proposed DL-IDS (Deep Learning-Intrusion Detection System) performs better than its predecessors in terms of recall, accuracy, and precision, according to research.},
  keywords={Training;Deep learning;Wireless communication;Knowledge engineering;Accuracy;Intrusion detection;Smart homes;Security;Internet of Things;Intelligent transportation systems;DDoS Attacks;Man-in-the-Middle Attacks;Deep Learning Intrusion Detection Systems (DL-IDS)},
  doi={10.1109/ICCSAI64074.2025.11063977},
  ISSN={},
  month={April},}@INPROCEEDINGS{10513333,
  author={Subeno, Muhammad Rizqi and Ataka, Ahmad and Ardiyanto, Igi and Cahyadi, Adha Imam},
  booktitle={2024 IEEE International Conference on Artificial Intelligence and Mechatronics Systems (AIMS)}, 
  title={Off-Policy Adversarial Inverse Reinforcement Learning in Mobile Robot Navigation Task}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Navigation tasks on mobile robots are getting more important to assist human tasks. However, navigation on mobile robots generally has several challenges, such as performing the task of navigating an unknown environment and being able to avoid obstacles. Conventional methods generally rely only on obstacle maps and cannot learn autonomously. Mapless navigation methods based on Reinforcement Learning (RL) are widely used to learn autonomous mobile robot navigation systems. However, the RL method requires a suitable reward function setting technique, and a simple reward function may not be easy to determine for the robot to perform navigation tasks. Therefore, this research proposed Off-Policy Adversarial Inverse Reinforcement Learning (AIRL) on mobile robot navigation tasks. We choose Off-Policy AIRL because it has strong advantages against dynamic changes so that mobile robots can perform navigation tasks efficiently. We compared the cumulative reward value, success rate, and trajectory length to reach the destination point with a reward designed via the reward shaping method and the reward estimated by Off-Policy AIRL. By applying RL using reward estimation from Off-Policy AIRL, the success rate of the robot reaching the destination point is 14 out of 15 scenarios and the proposed algorithm can outperform the reward produced by manually-reward shaping in 12 out of 15 scenarios.},
  keywords={Training;Mechatronics;Navigation;Estimation;Reinforcement learning;Manuals;Trajectory;Autonomous Navigation;Mobile Robot;Adversarial Inverse Reinforcement Learning},
  doi={10.1109/AIMS61812.2024.10513333},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{11100968,
  author={Ni, Kai and Li, Junkai and Shi, Enhao and Jiang, Zhaoxuan and Huang, Wenliang},
  booktitle={2025 IEEE International Symposium on the Application of Artificial Intelligence in Electrical Engineering (AAIEE)}, 
  title={Locational Marginal Price Prediction in Electricity Markets Based on CNN-LSTM-Attention}, 
  year={2025},
  volume={},
  number={},
  pages={867-872},
  abstract={Accurate pricing is essential for effective trading and grid optimization in electricity markets. The Locational Marginal Price (LMP) plays a key role, and its precise forecasting is crucial for optimal decision-making. This paper presents a combined model of Convolutional Neural Network - Long ShortTerm Memory (CNN-LSTM) and several attention mechanisms, including Squeeze-and-Excitation (SE), Efficient Channel Attention (ECA), Convolutional Block Attention Module (CBAM), and Hard-Weighted Attention (HWA), to achieve highly accurate forecasting of LMPs. First, the CNN is employed to extract local features and capture interactions among the three key influencing factors. The LSTM captures long-term dependencies, while the attention mechanisms improve the model’s focus on critical features and key time points. Experimental results demonstrate that the proposed approach significantly outperforms traditional statistical models and standalone neural networks, highlighting its potential for LMP forecasting in electricity markets. This study offers a robust and efficient solution to the complex problem of electricity price prediction.},
  keywords={Attention mechanisms;Accuracy;Predictive models;Electricity supply industry;Feature extraction;Transformers;Convolutional neural networks;Forecasting;Long short term memory;Optimization;Electricity Market;Locational Marginal Price;Convolutional Neural Network;Long Short-Term Memory;Attention Mechanism},
  doi={10.1109/AAIEE64965.2025.11100968},
  ISSN={},
  month={April},}@ARTICLE{10623189,
  author={Feng, Yuan and Lai, Yingxu and Chen, Ye and Zhang, Zhaoyi and Wei, Jingwen},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={LSTM-Based Model Compression for CAN Security in Intelligent Vehicles}, 
  year={2024},
  volume={5},
  number={12},
  pages={6457-6471},
  abstract={The rapid deployment and low-cost inference of controller area network (CAN) bus anomaly detection models on intelligent vehicles can drive the development of the Green Internet of Vehicles. Anomaly detection on intelligent vehicles often utilizes recurrent neural network models, but computational resources for these models are limited on small platforms. Model compression is essential to ensure CAN bus security with restricted computing resources while improving model computation efficiency. However, the existence of shared cyclic units significantly constrains the compression of recurrent neural networks. In this study, we propose a structured pruning method for long short-term memory (LSTM) based on the contribution values of shared vectors. By analyzing the contribution value of each dimension of shared vectors, the weight matrix of the model is structurally pruned, and the output value of the LSTM layer is supplemented to maintain the information integrity between adjacent network layers. We further propose an approximate matrix multiplication calculation module that runs in the whole process of model calculation and is deployed in parallel with the pruning module. Evaluated on a realistic public CAN bus dataset, our method effectively achieves highly structured pruning, improves model computing efficiency, and maintains performance stability compared to other compression methods.},
  keywords={Computational modeling;Long short term memory;Load modeling;Sparse matrices;Data models;Computational efficiency;Anomaly detection;Controller area network (CAN) bus;intrusion detection;long short-term memory (LSTM) model;model compression},
  doi={10.1109/TAI.2024.3438110},
  ISSN={2691-4581},
  month={Dec},}@INPROCEEDINGS{11022070,
  author={Meng, Lingpeng and Liu, Huixiang and Wang, Jiacheng and Li, Wei and Chen, Wenbai},
  booktitle={2024 8th Asian Conference on Artificial Intelligence Technology (ACAIT)}, 
  title={Gas Concentration Prediction for Sensor Drift Scenarios Based on Convolutional Autoencoder}, 
  year={2024},
  volume={},
  number={},
  pages={901-906},
  abstract={Gas sensor arrays are extensively utilized in various domains, but sensor aging results in signal drift, compromising concentration detection. To address the adverse effects of sensor drift on concentration detection accuracy, this paper presents a domain-adaptive network drift suppression method. This approach integrates domain adaptation principles with convolutional autoencoders, employing the Maximum Mean Discrepancy to diminish the distance between the source and target domains. Consequently, the model trained on data without drift can be effectively transferred to data that has undergone drift. Additionally, by incorporating data augmentation techniques, the method reduces the inaccuracies in concentration prediction caused by signal drift in gas sensor arrays. The experimental results show that the proposed model outperforms traditional methods in concentration prediction. And the model improves accuracy by 10 points compared to the baseline model.},
  keywords={Accuracy;Convolution;Autoencoders;Transfer learning;Gaussian distribution;Predictive models;Prediction algorithms;Data models;Gas detectors;Sensor arrays;transfer learning;multivariate normal distribution;sensor array;concentration regression},
  doi={10.1109/ACAIT63902.2024.11022070},
  ISSN={},
  month={Nov},}@INBOOK{10710591,
  author={Martinez, David R. and Kifle, Bruke M.},
  booktitle={Artificial Intelligence: A Systems Approach from Architecture Principles to Deployment}, 
  title={4 Machine Learning}, 
  year={2024},
  volume={},
  number={},
  pages={89-129},
  abstract={Recent years have witnessed remarkable progress in machine learning (ML) due to the convergence of big data, advanced algorithms, and modern computing technologies. The proliferation of large volumes of data, known as &#x201C;big data,&#x201D; is largely attributed to the prevalence of smart phones, Internet of Things (IoT), and social media, which have collectively contributed to over 2.5 million terabytes of data being generated daily and to over 90 percent of the world&#x0027;s data that has been generated over the last two years [1]. Along with big data, advancements in modern computing technologies such as graphics processing units (GPUs) and tensor processing units (TPUs) have made it possible to efficiently process data and large-scale computations, which is crucial for the computationally intensive task of model training in ML, as will be discussed in chapter 5. Finally, breakthroughs in new algorithms and ML techniques have been key to efficiently and effectively extracting actionable insights from massive volumes and varieties of data in ways that were previously unimaginable.},
  keywords={},
  doi={},
  ISSN={},
  publisher={MIT Press},
  isbn={9780262378703},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10710591},}@ARTICLE{11115108,
  author={Shi, Yu-Zhe and Xu, Qiao and Li, Yanjia and Liu, Mingchen and Qu, Huamin and Ruan, Lecheng and Wang, Qining},
  journal={IEEE Transactions on Automation Science and Engineering}, 
  title={Automated Constraint Specification for Job Scheduling by Regulating Generative Model with Domain-Specific Representation}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Advanced Planning and Scheduling (APS) systems have become indispensable for modern manufacturing operations, enabling optimized resource allocation and production efficiency in increasingly complex and dynamic environments. While algorithms for solving abstracted scheduling problems have been extensively investigated, the critical prerequisite of specifying manufacturing requirements into formal constraints remains manual and labor-intensive. Although recent advances of generative models, particularly Large Language Models (LLMs), show promise in automating constraint specification from heterogeneous raw manufacturing data, their direct application faces challenges due to natural language ambiguity, non-deterministic outputs, and limited domain-specific knowledge. This paper presents a constraint-centric architecture that regulates LLMs to perform reliable automated constraint specification for production scheduling. The architecture defines a hierarchical structural space organized across three levels, implemented through domain-specific representation to ensure precision and reliability while maintaining flexibility. Furthermore, an automated production scenario adaptation algorithm is designed and deployed to efficiently customize the architecture for specific manufacturing configurations. Experimental results demonstrate that the proposed approach successfully balances the generative capabilities of LLMs with the reliability requirements of manufacturing systems, significantly outperforming pure LLM-based approaches in constraint specification tasks.},
  keywords={Manufacturing;Production;Drilling;Reliability;Job shop scheduling;DSL;Automation;Schedules;Production facilities;Milling;Smart Manufacturing;Constraint Specification;Domain-Specific Representation},
  doi={10.1109/TASE.2025.3596540},
  ISSN={1558-3783},
  month={},}@INPROCEEDINGS{10801923,
  author={Pushp, Durgakant and Xu, Junhong and Chen, Zheng and Liu, Lantao},
  booktitle={2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Context-Generative Default Policy for Bounded Rational Agent}, 
  year={2024},
  volume={},
  number={},
  pages={7703-7709},
  abstract={Bounded rational agents often make decisions by evaluating a finite selection of choices, typically derived from a reference point termed the ‘default policy,’ based on previous experience. However, the inherent rigidity of the static default policy presents significant challenges for agents when operating in unknown environment, that are not included in agent’s prior knowledge. In this work, we introduce a context-generative default policy that leverages the region observed by the robot to predict unobserved part of the environment, thereby enabling the robot to adaptively adjust its default policy based on both the actual observed map and the imagined unobserved map. Furthermore, the adaptive nature of the bounded rationality framework enables the robot to manage unreliable or incorrect imaginations by selectively sampling a few trajectories in the vicinity of the default policy. Our approach utilizes a diffusion model for map prediction and a sampling-based planning with B-spline trajectory optimization to generate the default policy. Extensive evaluations reveal that the context-generative policy outperforms the baseline methods in identifying and avoiding unseen obstacles. Additionally, real-world experiments conducted with the Crazyflie drones demonstrate the adaptability of our proposed method, even when acting in environments outside the domain of the training distribution.},
  keywords={Training;Visualization;Systematics;Diffusion models;Planning;Rigidity;Splines (mathematics);Trajectory optimization;Intelligent robots;Drones},
  doi={10.1109/IROS58592.2024.10801923},
  ISSN={2153-0866},
  month={Oct},}@INPROCEEDINGS{10760875,
  author={Suganthi, N. Mohana and Arun, M.},
  booktitle={2024 2nd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS)}, 
  title={Skill Adam Optimization based Deep Spiking Neural Network for Retinal Multi Disease Classification in Fundus Images}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={The aim of fundus imaging is to inspect the irregularities corresponding to diseases that affect eye. The fundus image has a crucial role in detection and observation of diverse ophthalmic diseases. Existing researches have engaged on detection of single disease from the fundus image. However, simultaneous recognition of multi-disease (MD) from the fundus images is still confronting a major challenge. Therefore, this challenge can be addressed by devising a model to detect MD from the fundus imaging with an enhanced accuracy. Here, Skill Adam Optimization based Deep Spiking neural network (SAO_Deep SNN) is introduced for retinal MD classification using fundus images. Initially, considered fundus image is pre-processed to eliminate noises utilizing Median filter (MF). Thereafter, optic disc (OD) is segmented by DeepJoint segmentation and next, artery and vein (A/V) classification is accomplished using sparking process. Then, features are extracted from OD segmented image and A/V classified image in feature extraction (FE) phase. Finally, retinal MD classification is done by Deep Spiking Neural Network (Deep SNN). However, Deep SNN is trained utilizing Skill Adam Optimization (SAO) that is introduced by integrating Skill Optimization Algorithm (SOA) with Adam algorithm. Additionally, SAO_Deep SNN achieved accuracy of 90.81%, sensitivity of 91.69% and specificity of 90.49%.},
  keywords={Optical filters;Image segmentation;Accuracy;Sensitivity;Spiking neural networks;Retina;Feature extraction;Classification algorithms;Optimization;Diseases;Retinal multi-disease (MD);Fundus image;DeepJoint segmentation;Deep Spiking Neural Network;Skill Adam Optimization (SAO)},
  doi={10.1109/ICSSAS64001.2024.10760875},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9967638,
  author={Yamawaki, Kazuki and Watanabe, Hiroki and Naruse, Yasushi},
  booktitle={2022 IEEE International Conference on Metrology for Extended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)}, 
  title={Prediction of Scalp EEG Waveforms from Forehead Electrodes Using Convolutional Neural Networks to Improve Signal-to-Noise Ratio}, 
  year={2022},
  volume={},
  number={},
  pages={382-387},
  abstract={The electroencephalogram (EEG) is a non-invasive method for measuring brain activity, and event-related potentials (ERPs)—EEG responses observed to be time-locked to events—have been used for brain-computer interfaces (BCI) in real-world environments. An EEG is generally measured from electrodes placed on the scalp. However, it is not suitable for daily use because the preparation time is relatively long, and the electrodes are likely to cause discomfort to the user. EEG measurements from disposable electrodes placed on the forehead (forehead EEG) have been used to mitigate this disadvantage. However, because many ERP components used in BCI show the maximal voltage on the scalp, the signal-to-noise ratio (SNR) of ERPs obtained from a forehead EEG is low, which may affect the reliability of a BCI system. To address this shortcoming, we propose convolutional neural networks that predict the EEG signal measured from electrodes placed on the scalp (scalp EEG) from forehead EEG. In the study, we focused on predicting the mismatch negativity (MMN) responses, and single-trial scalp EEG at Fz was predicted from three forehead EEG measures (Fpz, horizontal, and vertical electrooculograms). Data were measured while nine subjects performed a passive auditory oddball task. To evaluate the proposed model, the mean squared error (MSE) between the observed single-trial EEG at Fz and the predicted single-trial EEG from three forehead EEG measures was calculated, as well as the MSE between the observed ERP difference wave (deviant – standard) at Fz and the difference wave predicted from three forehead EEG measures within the time window in which MMN was observed. The result showed that within the time window in which MMN was observed, the MSE between the ERP difference wave at Fz and the ERP difference wave predicted from three forehead EEG measures was significantly smaller than the MSE between the ERP difference wave at Fz and the ERP difference wave at the forehead (Fpz). This indicates that the proposed neural network improved the SNR of the forehead EEG for predicting ERP responses at the scalp and could lead to enhancing the usefulness of forehead EEG for BCI use in daily life.},
  keywords={Electrodes;Electric potential;Forehead;Scalp;Measurement uncertainty;Electroencephalography;Time measurement;electroencephalogram (EEG);convolutional neural networks;forehead EEG;mismatch negativity (MMN);event-related potential (ERP)},
  doi={10.1109/MetroXRAINE54828.2022.9967638},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10689997,
  author={K, Rajagopal and Kumari, V. Sheeja and S, Saraswathy and Kumar, V. Suresh and Ponmaniraj, S. and Deepa, A.},
  booktitle={2024 5th International Conference on Electronics and Sustainable Communication Systems (ICESC)}, 
  title={Hybrid Deep Learning Models with Genetic Algorithm Optimization for Enhanced Kidney Tumor Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1525-1530},
  abstract={Accurate and timely segmentation of kidney tumors from medical images is crucial for effective treatment and prognosis. This research study proposes a novel hybrid deep learning framework incorporating Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) for enhanced kidney tumor segmentation. To optimize model performance, Genetic Algorithms (GA) are employed to fine-tune hyperparameters and network architecture. The proposed method effectively captures both local and global image features, leading to improved segmentation accuracy compared to existing techniques. Experimental results on a publicly available dataset demonstrate the superiority of our approach in terms of recall, F1-score, and precision. This research contributes to the advancement of computer-aided diagnosis for kidney cancer.},
  keywords={Deep learning;Image segmentation;Recurrent neural networks;Accuracy;Network architecture;Convolutional neural networks;Kidney;Optimization;Tumors;Genetic algorithms;Kidney tumor detection;CNN;Genetic algorithm;feature extraction;feature selection},
  doi={10.1109/ICESC60852.2024.10689997},
  ISSN={2996-5357},
  month={Aug},}@INPROCEEDINGS{10624771,
  author={Cooke, Corey D.},
  booktitle={2024 IEEE International Conference on Machine Learning for Communication and Networking (ICMLCN)}, 
  title={A Self-Supervised Method for Accelerated Training of Neural Communication Receivers}, 
  year={2024},
  volume={},
  number={},
  pages={151-157},
  abstract={Self-supervised learning (SSL), which is a branch of unsupervised learning, is a new machine learning paradigm for learning from large unlabeled datasets. In this paper we apply principles of SSL to the channel autoencoder problem from communications theory. We demonstrated this by first performing an SSL pre-training step using a contrastive loss, the training time of a neural receiver can be significantly reduced, even when the extra pre-training time has been accounted for. This approach could be used to improve the performance of neural receivers in a wide variety of channel conditions.},
  keywords={Training;AWGN channels;Wireless networks;Receivers;Machine learning;Self-supervised learning;Channel models},
  doi={10.1109/ICMLCN59089.2024.10624771},
  ISSN={},
  month={May},}@INPROCEEDINGS{11154195,
  author={Roy, Upasana and Seth, Vani and Rayhan, Mahady Hasan and Pandey, Ashish and Alarcon, Mauro Lemus and Maschmann, Matthew and Calyam, Prasad},
  booktitle={2025 IEEE 5th International Conference on Human-Machine Systems (ICHMS)}, 
  title={Closed-Loop CNT Growth Using Retrieval Augmented Generation and Human Feedback}, 
  year={2025},
  volume={},
  number={},
  pages={128-133},
  abstract={Carbon Nanotube (CNT) synthesis is a complex process requiring precise control of input parameters in scanning electron microscopy (SEM) experiments by humans to achieve desired material properties. Use of artificial intelligence (AI) in such a human-machine system can foster a closedloop design to accelerate material discovery via integration of theory, computation, and experimentation. In this paper, we adopt emerging generative AI advances i.e., Large Language Models (LLMs) to guide human-machine interactions in CNT growth experiments and investigate an intelligent architecture viz., “ARES-Vidura” featuring ML models and human feedback to analyze CNT domain-specific datasets. ARESVidura features a knowledge base and Retrieval-Augmented Generation (RAG) to enhance user queries and responses with LLMs, simulation tools for CNT synthesis, and regression models for guiding novice/experienced researchers in predicting synthesis parameters using synthetic and real data training that alleviate data scarcity by mimicking experimental conditions. Our experimental results show that our approach delivers over 89% better performance in terms of response relevance for a novice user, as measured by the cosine similarity, outperforming public LLMs (e.g., GPT), with the Llama-2-7B model showing the best results, while the regression component achieves less than 2% mean square error in predicting CNT growth rate.},
  keywords={Training;Scanning electron microscopy;Human-machine systems;Retrieval augmented generation;Knowledge based systems;Systems architecture;Process control;Predictive models;Portals;Material properties;Closed-Loop Systems;CNT Synthesis;Retrieval-Augmented Generation;Human Feedback},
  doi={10.1109/ICHMS65439.2025.11154195},
  ISSN={},
  month={May},}@ARTICLE{10479166,
  author={Liu, Chao and Chen, Boxi and Shao, Wei and Zhang, Chris and Wong, Kelvin K. L. and Zhang, Yi},
  journal={IEEE Internet of Things Journal}, 
  title={Unraveling Attacks to Machine-Learning-Based IoT Systems: A Survey and the Open Libraries Behind Them}, 
  year={2024},
  volume={11},
  number={11},
  pages={19232-19255},
  abstract={The advent of the Internet of Things (IoT) has brought forth an era of unprecedented connectivity, with an estimated 80 billion smart devices expected to be in operation by the end of 2025. These devices facilitate a multitude of smart applications, enhancing the quality of life and efficiency across various domains. Machine learning (ML) serves as a crucial technology, not only for analyzing IoT-generated data but also for diverse applications within the IoT ecosystem. For instance, ML finds utility in IoT device recognition, anomaly detection, and even in uncovering malicious activities. This article embarks on a comprehensive exploration of the security threats arising from ML’s integration into various facets of IoT, spanning various attack types, including membership inference, adversarial evasion, reconstruction, property inference, model extraction, and poisoning attacks. Unlike previous studies, our work offers a holistic perspective, categorizing threats based on criteria, such as adversary models, attack targets, and key security attributes (confidentiality, integrity, and availability). We delve into the underlying techniques of ML attacks in IoT environment, providing a critical evaluation of their mechanisms and impacts. Furthermore, our research thoroughly assesses 65 libraries, both author-contributed and third-party, evaluating their role in safeguarding model and data privacy. We emphasize the availability and usability of these libraries, aiming to arm the community with the necessary tools to bolster their defenses against the evolving threat landscape. Through our comprehensive review and analysis, this article seeks to contribute to the ongoing discourse on ML-based IoT security, offering valuable insights and practical solutions to secure ML models and data in the rapidly expanding field of artificial intelligence in IoT.},
  keywords={Internet of Things;Security;Data models;Machine learning;Feature extraction;Training;Data privacy;Artificial intelligence;attack;Internet of Things (IoT);machine learning (ML);open library;security},
  doi={10.1109/JIOT.2024.3377730},
  ISSN={2327-4662},
  month={June},}@INPROCEEDINGS{10781986,
  author={Sherwin Akshay, J G and Vinusha, T and Sharon Bianca, R and Sarath Krishna, C K and Radhika, G},
  booktitle={2024 IEEE International Conference on Computer Vision and Machine Intelligence (CVMI)}, 
  title={Enhancing Credit Card Fraud Detection: A Comparative Analysis of Anomaly Detection Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Financial fraud poses a major threat to financial service institutions and clients, necessitating advanced anomaly detection capabilities. This paper delves into related deep learning models which can be be used to differentiate and detect fraudulent transactions from normal transactions and flag anomalies. Challenges include evolving attack strategies, class imbalance, and model interpret-ability. The proposed methods utilize of a synergistic combination of ensemble learning techniques and unsupervised deep neural networks, like autoencoders and recurrent neural networks. The outcomes exhibit reliable results on credit card transaction datasets. A comprehensive comparative analysis follows to compare the proposed approach to traditional fraud detection methods, demonstrating its superiority in accurately identifying fraudulent transactions, adapting to emerging threats, handling high-dimensional data, and mitigating class imbalances with respect to data privacy and security.},
  keywords={Recurrent neural networks;Finance;Credit cards;Fraud;Security;Reliability;Ensemble learning;Anomaly detection;Machine intelligence;Financial services;Deep learning;Unsupervised learning;Autoencoders;RNN;XGBoost},
  doi={10.1109/CVMI61877.2024.10781986},
  ISSN={},
  month={Oct},}@ARTICLE{9541089,
  author={Li, Bing and Zhu, Yuanlue and Wang, Yitong and Lin, Chia-Wen and Ghanem, Bernard and Shen, Linlin},
  journal={IEEE Transactions on Multimedia}, 
  title={AniGAN: Style-Guided Generative Adversarial Networks for Unsupervised Anime Face Generation}, 
  year={2022},
  volume={24},
  number={},
  pages={4077-4091},
  abstract={In this paper, we propose a novel framework to translate a portrait photo-face into an anime appearance. Different from existing translation methods which do not designate specific styles, we aim to synthesize anime-faces which are style-consistent with a given reference anime-face. However, unlike typical translation tasks, such anime-face translation is particularly challenging due to the large and complex variations of appearances among anime-faces. Existing methods often fail to transfer the styles of reference anime-faces to the generated anime-faces, or introduce noticeable artifacts/distortions in the local shapes of their generated anime-faces. We propose a novel GAN-based anime-face translator, called AniGAN, to synthesize high-quality anime-faces. Specifically, a new generator architecture is proposed to simultaneously transfer color/texture styles and transform local facial shapes into anime-like counterparts based on the style of a reference anime-face, while preserving the global structure of the source photo-face. New normalization functions are designed for the generator to further improve local shape transformation and color/texture style transfer. Besides, we propose a double-branch discriminator to learn domain-specific distributions through individual branches and learn cross-domain shared distributions via shared layers, helping generate visually pleasing anime-faces and effectively mitigate artifacts/distortions. Extensive experiments on benchmark datasets qualitatively and quantitatively demonstrate the superiority of our method over state-of-the-art methods.},
  keywords={Shape;Generators;Faces;Transforms;Task analysis;Decoding;Visualization;GAN;Image translation;non-photorealistic rendering;style transfer},
  doi={10.1109/TMM.2021.3113786},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{8843204,
  author={Niu, Shuanlong and Lin, Hui and Niu, Tongzhi and Li, Bin and Wang, Xinggang},
  booktitle={2019 IEEE 15th International Conference on Automation Science and Engineering (CASE)}, 
  title={DefectGAN: Weakly-Supervised Defect Detection using Generative Adversarial Network}, 
  year={2019},
  volume={},
  number={},
  pages={127-132},
  abstract={Traditional methods for defect detection applied in industry are complex, time-consuming, not robust and demanding for professional experience due to hand-crafted features extraction and pipeline design. Besides, current deep learning based methods for general object segmentation demand for a large number of region-level human annotations.Instead, we present DefectGAN for defect detection in a weakly-supervised learning, which requires very a few human annotations. In practical application, images in training dataset are merely labeled with two categories: negative and positive. Despite being trained on image-level rather than region-level labels, DefectGAN has remarkable ability of localizing defect regions.DefectGAN can have comparable and visually even better performance than SegNet, a supervised learning method on dataset CCSD-NL and DAGM 2007. The detected regions are more similar to the original defect regions visually and it has the potential of detecting unseen defects.},
  keywords={Training;Generators;Deep learning;Loss measurement;Feature extraction;Pipelines;Image segmentation},
  doi={10.1109/COASE.2019.8843204},
  ISSN={2161-8089},
  month={Aug},}@INPROCEEDINGS{10453752,
  author={Mohamed Firdhous, Mohamed Fazil and Elbreiki, Walid and Abdullahi, Ibrahim and Sudantha, B.H. and Budiarto, Rahmat},
  booktitle={2023 24th International Arab Conference on Information Technology (ACIT)}, 
  title={WormGPT: A Large Language Model Chatbot for Criminals}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={In recent years, AI has made many advances in multiple fronts. One such recent advance is the development of Large Language Models(LLMs), a deep learning model trained with a large set of data on billions of parameters. Many Generative Pretrained Transformer (GPT) models have been developed on these LLMs. ChatGPT has become the most popular GPT used by many people. Recently, a blackhat GPT named WormGPT has been launched for cybercriminals. WormGPT is capable of launching many types of attacks resulting in irreparable damage. Hence, Users are required to be familiar with these tools, if they are to protect themselves. This article is possibly the very first attempt to initiate a discussion on this topic within the formal research circles. This article starts with an introduction to LLMs and GPTs and then presents the details of WormGPT, its capabilities and the damage it can cause. Finally, a set of safeguards has been presented that can help to protect users from possible attacks.},
  keywords={Deep learning;Blogs;Organizations;Chatbots;Transformers;Data models;Information technology;Artificial Intelligence;Large Language Models;LLM;GPT;ChatGPT;WormGPT},
  doi={10.1109/ACIT58888.2023.10453752},
  ISSN={2831-4948},
  month={Dec},}@INPROCEEDINGS{10968764,
  author={S, Sujanthi and R, Priya and S, Ranga Shree and S, Suruthika and S, Sushmitha},
  booktitle={2025 International Conference on Machine Learning and Autonomous Systems (ICMLAS)}, 
  title={Comparison Analysis of Transfer Learning Models for Deep Fake Image Detection}, 
  year={2025},
  volume={},
  number={},
  pages={316-322},
  abstract={Deepfake identifies fake videos and photographs. To create deepfakes, machine learning algorithms change video or reputation features like faces. Deepfake identifies fake videos and photographs. New deep learning generative algorithms may make fake films and photos seem real, worrying many. Personal and social safety are jeopardized. We urgently need computational methods to detect fake material and alert consumers of picture and video changes. We evaluate deep learning-based deepfake detection. We want to automate field development fake content detection. Assessing the work's strengths and faults, we find deepfakes. AI, NLP, and computer vision use deep machine learning for efficiency and usability. Deepfakes create realistic images and videos using deep learning. We test multiple deep learning-based deepfake detection and generation approaches. Several deepfake detection techniques are examined. Researchers benefit from our paper's social media deepfake detection. Compare current and previous industrial practices and datasets.},
  keywords={Deep learning;Deepfakes;Visualization;Machine learning algorithms;Social networking (online);Films;Transfer learning;Motion pictures;Safety;Usability;Deep Fake Images;Deep Learning;Artificial Intelligence;Machine Learning techniques;Video Datasets},
  doi={10.1109/ICMLAS64557.2025.10968764},
  ISSN={},
  month={March},}@INPROCEEDINGS{10874136,
  author={A, Govind and Anzar, Ahad and Nair, Aiswarya Anil and Syam, Rohith},
  booktitle={2024 IEEE International Conference on Future Machine Learning and Data Science (FMLDS)}, 
  title={GenAI Empowered Script to Storyboard Generator}, 
  year={2024},
  volume={},
  number={},
  pages={451-456},
  abstract={The research presents an innovative solution for automating the generation of storyboards from screenplays through the integration of advanced AI technologies. By taking a screenplay as input, the system utilizes cutting-edge neural networks to recognize characters and objects, enhancing scene comprehension. A refined Bi LSTM model is employed to extract the nuanced emotional tones embedded within in dialogues in each scene, providing valuable insights into character dynamics and narrative depth. Through the application of regular expressions, key scene attributes such as time, place, and location are extracted to establish contextual relevance. A Facebook BART-large-CNN model is then employed to generate concise summaries of each scene, enhancing comprehension efficiency. Through script summarization and tag extraction from the Movie Plot Synopses with Tags dataset, a smooth transition between scenes is enabled. These extracted features are structured into a prompt using a rule based approach, facilitating seamless integration into the subsequent creative phase. Finally, a stable diffusion model is employed to generate scene-by-scene coherent storyboard, incorporating all extracted elements to streamline the visual storytelling process where coherency is achieved with the help of cosine similarity between prompts. This comprehensive approach not only automates tedious tasks but also enhances creativity and efficiency in storyboard creation.},
  keywords={Visualization;Social networking (online);Neural networks;Coherence;Streaming media;Feature extraction;Aerodynamics;Transformers;Motion pictures;Creativity;Generative AI;storyboard generation;prompt generation;scene summarising;script summarising;Generative Coherence},
  doi={10.1109/FMLDS63805.2024.00085},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10893388,
  author={Mackay, Sean and Eiselt, Kurt and Decker, Adrienne},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Two Sides of the Same Coin: Differing Approaches to Generative AI in Two Computer Science Classrooms}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This innovative practice paper explores two differing approaches to the use of artificial intelligence tools in computer science classrooms. Artificial Intelligence (AI), while not a new technology, has seen a rise in popularity over the past two years, with companies such as OpenAI, Google, and Microsoft making readily available generative AI tools for anyone to use. This surge in AI popularity has led to a rise in its use in educational settings, in some cases allowed and in others discouraged or disallowed. A debate has risen among academics, particularly in higher education, about what AI's place in education is, with some educators actively encouraging its use while others view the use of AI as a form of academic dishonesty. Given AI is only advancing and is becoming more prevalent, it will only continue to become a more dominant force throughout education and the world at large. This paper presents two educators' distinct viewpoints and experiences on how AI should be handled in computer science courses (absolutely forbidden vs. decriminalized). The goal of this paper is to present different perspectives as well as concrete experiences we have had with AI in our own classrooms to encourage others to consider their own positions on its use and its implications for their own learning environments. While the debate on the place of AI in education is a long way from being settled, educators need to think about making choices, clearly articulating policies, and evaluating the positives and negatives of positions about AI in their classrooms.},
  keywords={Codes;Generative AI;Affordances;Education;Force;Companies;Internet;Computer science education;Surges;Programming profession;academic integrity;LLM's;course policies;AI in education},
  doi={10.1109/FIE61694.2024.10893388},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10465798,
  author={Tiwari, Anamika and Kumar, Sandeep and Rengarajan, A},
  booktitle={2023 International Conference on Advances in Computation, Communication and Information Technology (ICAICCIT)}, 
  title={Incorporation of Deep Learning (DL) Techniques to make Intelligent and Adaptable Wireless Communication Systems}, 
  year={2023},
  volume={},
  number={},
  pages={1209-1213},
  abstract={The emergence of Deep Learning (DL) was a response to the widespread availability of mobile data and the growing complexity of wireless networks. It is a subfield of Machine learning that has been proposed in academic literature. This technology is regarded as a breakthrough in the management of mobile data traffic. Wireless systems generate a significant amount of varied data, which presents computational issues. In order to tackle this problem, a variety of optimization methodologies are being investigated. DL increases wireless communication by enhancing its intelligence and adaptability. This paper offers an overview of the DL platform and several methodologies employed to enable deep learning in wireless communications. Wireless networking involves various disciplines, including networking, routing, and scheduling, all of which incorporate DL. This text encompasses a comprehensive range of topics. The topic encompassed several optimization methodologies and the latest breakthroughs in this domain.},
  keywords={Deep learning;Wireless networks;Computational modeling;Transforms;Routing;Robustness;Information and communication technology;Deep learning;Fog computing;Mobile network;Wireless network;Reinforcement learning},
  doi={10.1109/ICAICCIT60255.2023.10465798},
  ISSN={},
  month={Nov},}@ARTICLE{9662987,
  author={Li, Ao and Chen, Shitao and Sun, Liting and Zheng, Nanning and Tomizuka, Masayoshi and Zhan, Wei},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={SceGene: Bio-Inspired Traffic Scenario Generation for Autonomous Driving Testing}, 
  year={2022},
  volume={23},
  number={9},
  pages={14859-14874},
  abstract={The core value of simulation-based autonomy tests is to create densely extreme traffic scenarios to test the performance and robustness of the algorithms and systems. Test scenarios are usually designed or extracted manually from the real-world data, which is inefficient with a remarkable domain gap compared with testing in real scenarios. Therefore, it is crucial to automatically generate realistic and diverse dynamic traffic scenarios making autonomy tests efficient. Moreover, scenario generation is expected to be interpretable, controllable, and diversified, which can be hard to achieve simultaneously by methods based on rules or deep networks. In this paper, we propose a dynamic traffic scenario generation method called SceGene, inspired by genetic inheritance and mutation processes in biological intelligence. SceGene applies biological processes, such as crossover and mutation, to exchange and mutate the content of scenarios, and involves the natural selection process to control generation direction. SceGene has three main parts: 1) a new representation method for describing the traffic scenarios’ feature; 2) a new scenario generation algorithm based on crossover, mutation, and selection; and 3) an abnormal scenario information repair method based on the microscopic driving model. Evaluation on the public traffic scenario dataset shows that SceGene can ensure highly realistic and diversified scenario generation in an interpretable and controllable way, significantly improving the efficiency of the simulation-based autonomy tests.},
  keywords={Mathematical models;Biological information theory;Testing;Microscopy;Evolution (biology);Biological system modeling;Vehicle dynamics;Autonomous driving;simulation-based test;scenario generation},
  doi={10.1109/TITS.2021.3134661},
  ISSN={1558-0016},
  month={Sep.},}@INPROCEEDINGS{9225395,
  author={Vamsi, G Krishna and Rasool, Akhtar and Hajela, Gaurav},
  booktitle={2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT)}, 
  title={Chatbot: A Deep Neural Network Based Human to Machine Conversation Model}, 
  year={2020},
  volume={},
  number={},
  pages={1-7},
  abstract={A conversational agent (chatbot) is computer software capable of communicating with humans using natural language processing. The crucial part of building any chatbot is the development of conversation. Despite many developments in Natural Language Processing (NLP) and Artificial Intelligence (AI), creating a good chatbot model remains a significant challenge in this field even today. A conversational bot can be used for countless errands. In general, they need to understand the user's intent and deliver appropriate replies. This is a software program of a conversational interface that allows a user to converse in the same manner one would address a human. Hence, these are used in almost every customer communication platform, like social networks. At present, there are two basic models used in developing a chatbot. Generative based models and Retrieval based models. The recent advancements in deep learning and artificial intelligence, such as the end-to-end trainable neural networks have rapidly replaced earlier methods based on hand-written instructions and patterns or statistical methods. This paper proposes a new method of creating a chatbot using a deep neural learning method. In this method, a neural network with multiple layers is built to learn and process the data.},
  keywords={Chatbot;Deep learning;Software;Medical services;Training;Task analysis;Feature extraction;machine learning;conversational agent;chatbot;machine learning classification technique;Neural Networks;Deep Learning;Natural Language Processing},
  doi={10.1109/ICCCNT49239.2020.9225395},
  ISSN={},
  month={July},}@ARTICLE{9725240,
  author={Zhan, Fangneng and Yu, Yingchen and Zhang, Changgong and Wu, Rongliang and Hu, Wenbo and Lu, Shijian and Ma, Feiying and Xie, Xuansong and Shao, Ling},
  journal={IEEE Transactions on Image Processing}, 
  title={GMLight: Lighting Estimation via Geometric Distribution Approximation}, 
  year={2022},
  volume={31},
  number={},
  pages={2268-2278},
  abstract={Inferring the scene illumination from a single image is an essential yet challenging task in computer vision and computer graphics. Existing works estimate lighting by regressing representative illumination parameters or generating illumination maps directly. However, these methods often suffer from poor accuracy and generalization. This paper presents Geometric Mover’s Light (GMLight), a lighting estimation framework that employs a regression network and a generative projector for effective illumination estimation. We parameterize illumination scenes in terms of the geometric light distribution, light intensity, ambient term, and auxiliary depth, which can be estimated by a regression network. Inspired by the earth mover’s distance, we design a novel geometric mover’s loss to guide the accurate regression of light distribution parameters. With the estimated light parameters, the generative projector synthesizes panoramic illumination maps with realistic appearance and high-frequency details. Extensive experiments show that GMLight achieves accurate illumination estimation and superior fidelity in relighting for 3D object insertion. The codes are available at https://github.com/fnzhan/Illumination-Estimation},
  keywords={Lighting;Geometry;Estimation;Light sources;Three-dimensional displays;Costs;Harmonic analysis;Lighting estimation;image synthesis;generative adversarial networks},
  doi={10.1109/TIP.2022.3151997},
  ISSN={1941-0042},
  month={},}@INPROCEEDINGS{9680013,
  author={Song, Geonhak and Nguyen, Tien-Dung and Bum, Junghyun and Yi, Hwijong and Son, Chang-Hwan and Choo, Hyunseung},
  booktitle={2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA)}, 
  title={Super Resolution with Sparse Gradient-Guided Attention for Suppressing Structural Distortion}, 
  year={2021},
  volume={},
  number={},
  pages={885-890},
  abstract={Generative adversarial network (GAN)-based methods recover perceptually pleasant details in super resolution (SR), but they pertain to structural distortions. Recent study alleviates such structural distortions by attaching a gradient branch to the generator. However, this method compromises the perceptual details. In this paper, we propose a sparse gradient-guided attention generative adversarial network (SGAGAN), which incorporates a modified residual-in-residual sparse block (MRRSB) in the gradient branch and gradient-guided self-attention (GSA) to suppress structural distortions. Compared to the most frequently used block in GAN-based SR methods, i.e., residual-in-residual dense block (RRDB), MRRSB reduces computational cost and avoids gradient redundancy. In addition, GSA emphasizes the highly correlated features in the generator by guiding sparse gradient. It captures the semantic information by connecting the global interdependencies of the sparse gradient features in the gradient branch and the features in the SR branch. Experimental results show that SGAGAN relieves the structural distortions and generates more realistic images compared to state-of-the-art SR methods. Qualitative and quantitative evaluations in the ablation study show that combining GSA and MRRSB together has a better perceptual quality than combining self-attention alone.},
  keywords={Measurement;Image resolution;Conferences;Redundancy;Semantics;Machine learning;Distortion;Super Resolution;Generative Adversarial Network;Self-Attention;Gradient Branch},
  doi={10.1109/ICMLA52953.2021.00146},
  ISSN={},
  month={Dec},}@ARTICLE{10159577,
  author={Liu, Xiaofeng and Wang, Ziyang and Li, Jie and Cangelosi, Angelo and Yang, Chenguang},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Demonstration Learning and Generalization of Robotic Motor Skills Based on Wearable Motion Tracking Sensors}, 
  year={2023},
  volume={72},
  number={},
  pages={1-15},
  abstract={Learning from demonstration (LfD) is an important way for robots to learn new skills. Its principle is to obtain an optimized trajectory through an instructor’s action teaching or action coding regression. By learning the teaching trajectory, the robot can master the movement skills. However, adapting the learned motor skills to meet additional constraints that arise during the task can be challenging. This article proposed a noise exploration method policy improvement through black-box optimization with an adaptive covariance matrix (PIBB-CMA), which improves the PIBB algorithm by using an adaptive covariance matrix. In our method, the teaching trajectory is collected with our designed inertial motion capture system. After that, a more reasonable trajectory is synthesized as the input to dynamic movement primitives (DMPs) using the Gaussian mixture model (GMM) and Gaussian mixture regression (GMR). Finally, the improved algorithm PIBB-CMA is used to perform noise exploration to ensure that the robot arm can pass the designated points in the path planning. Furthermore, three baseline methods are chosen for comparison to validate the robustness of our proposed method. The experimental results demonstrated that our proposed method outperforms the baseline algorithms and is feasible for improving robot intelligence. We believe that our method has a certain potential in the aspect of skill learning for robots.},
  keywords={Robots;Trajectory;Task analysis;Motion capture;Robot sensing systems;Optimization;Heuristic algorithms;Adaptive covariance matrix;dynamic movement primitives (DMPs);learning from demonstration (LfD);path planning;policy improvement through black-box optimization (PIBB)},
  doi={10.1109/TIM.2023.3288240},
  ISSN={1557-9662},
  month={},}@ARTICLE{8662628,
  author={Diaz-Pinto, Andres and Colomer, Adrián and Naranjo, Valery and Morales, Sandra and Xu, Yanwu and Frangi, Alejandro F.},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Retinal Image Synthesis and Semi-Supervised Learning for Glaucoma Assessment}, 
  year={2019},
  volume={38},
  number={9},
  pages={2211-2218},
  abstract={Recent works show that generative adversarial networks (GANs) can be successfully applied to image synthesis and semi-supervised learning, where, given a small labeled database and a large unlabeled database, the goal is to train a powerful classifier. In this paper, we trained a retinal image synthesizer and a semi-supervised learning method for automatic glaucoma assessment using an adversarial model on a small glaucoma-labeled database and a large unlabeled database. Various studies have shown that glaucoma can be monitored by analyzing the optic disc and its surroundings, and for that reason, the images used in this paper were automatically cropped around the optic disc. The novelty of this paper is to propose a new retinal image synthesizer and a semi-supervised learning method for glaucoma assessment based on the deep convolutional GANs. In addition, and to the best of our knowledge, this system is trained on an unprecedented number of publicly available images (86926 images). This system, hence, is not only able to generate images synthetically but to provide labels automatically. Synthetic images were qualitatively evaluated using t-SNE plots of features associated with the images and their anatomical consistency was estimated by measuring the proportion of pixels corresponding to the anatomical structures around the optic disc. The resulting image synthesizer is able to generate realistic (cropped) retinal images, and subsequently, the glaucoma classifier is able to classify them into glaucomatous and normal with high accuracy (AUC = 0.9017). The obtained retinal image synthesizer and the glaucoma classifier could then be used to generate an unlimited number of cropped retinal images with glaucoma labels.},
  keywords={Optical imaging;Biomedical optical imaging;Retina;Databases;Semisupervised learning;Synthesizers;Generative adversarial networks;Glaucoma assessment;retinal image synthesis;fundus images;DCGAN;medical imaging},
  doi={10.1109/TMI.2019.2903434},
  ISSN={1558-254X},
  month={Sep.},}@ARTICLE{9052492,
  author={Zheng, Yinhe and Chen, Guanyi and Huang, Minlie},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Out-of-Domain Detection for Natural Language Understanding in Dialog Systems}, 
  year={2020},
  volume={28},
  number={},
  pages={1198-1209},
  abstract={Natural Language Understanding (NLU) is a vital component of dialogue systems, and its ability to detect Out-of-Domain (OOD) inputs is critical in practical applications, since the acceptance of the OOD input that is unsupported by the current system may lead to catastrophic failure. However, most existing OOD detection methods rely heavily on manually labeled OOD samples and cannot take full advantage of unlabeled data. This limits the feasibility of these models in practical applications. In this paper, we propose a novel model to generate high-quality pseudo OOD samples that are akin to IN-Domain (IND) input utterances and thereby improves the performance of OOD detection. To this end, an autoencoder is trained to map an input utterance into a latent code. Moreover, the codes of IND and OOD samples are trained to be indistinguishable by utilizing a generative adversarial network. To provide more supervision signals, an auxiliary classifier is introduced to regularize the generated OOD samples to have indistinguishable intent labels. Experiments show that these pseudo OOD samples generated by our model can be used to effectively improve OOD detection in NLU. Besides, we also demonstrate that the effectiveness of these pseudo OOD data can be further improved by efficiently utilizing unlabeled data.},
  keywords={Training;Data models;Computational modeling;Erbium;Task analysis;Natural languages;Generative adversarial networks;Natural language understanding;out-of-domain detection;dialogue system;text classification},
  doi={10.1109/TASLP.2020.2983593},
  ISSN={2329-9304},
  month={},}@ARTICLE{9467283,
  author={Hu, Yanting and Li, Jie and Huang, Yuanfei and Gao, Xinbo},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Image Super-Resolution With Self-Similarity Prior Guided Network and Sample-Discriminating Learning}, 
  year={2022},
  volume={32},
  number={4},
  pages={1966-1985},
  abstract={The nonlocal self-similarity in natural image provides an effective prior for single image super-resolution (SISR), which is beneficial to contextual information capture and performance improvement, as demonstrated by conventional SISR methods. However, it is little explored to utilize this property in deep neural networks. In this paper, we propose a self-similarity prior guided (SSPG) network to incorporate self-similarity-based nonlocal operation into deep neural network for SISR. Specifically, we design a cross-scale nearest-neighbor residual (CSNNR) block via introducing cross-scale  $k$ -nearest neighbors (KNN) matching into a residual block, which can be flexibly integrated into deep networks to capture long-range correlations among multi-scale and multi-level features. Meanwhile, by stacking a CSNNR block and a sequence of wide-activated residual blocks with a local skip-connection, a multi-level residual self-similarity (MRSS) module is developed to effectively employ local and nonlocal information for detail recovery. Thus, through cascading multiple MRSS modules, the proposed SSPG network performs both self-similarity-based nonlocal operation and convolution-based local operation on multi-level features to reconstruct informative features for accurate SISR. In addition, for pursuing visually pleasing results, we apply our SSPG network to the perception-oriented SISR field by following the framework of generative adversarial networks. In particular, we explore a sample-discriminating learning mechanism based on the statistical descriptions of training samples, and include it in optimization procedure to automatically tune the contributions of different samples according to their characteristics and then focus the network on creating realistic results. Extensive quantitative and qualitative evaluations on benchmark datasets illustrate the superiority of our proposed models over the state-of-the-art methods for both distortion-oriented and perception-oriented image super-resolution tasks.},
  keywords={Feature extraction;Superresolution;Image reconstruction;Training;Optimization;Generative adversarial networks;Spatial resolution;Nonlocal self-similarity prior;sample-discriminating learning;k-nearest neighbors;single image super-resolution},
  doi={10.1109/TCSVT.2021.3093483},
  ISSN={1558-2205},
  month={April},}@ARTICLE{9186643,
  author={Cai, Lei and Zeng, Huanqiang and Zhu, Jianqing and Cao, Jiuwen and Wang, Yongtao and Ma, Kai-Kuang},
  journal={IEEE Internet of Things Journal}, 
  title={Cascading Scene and Viewpoint Feature Learning for Pedestrian Gender Recognition}, 
  year={2021},
  volume={8},
  number={4},
  pages={3014-3026},
  abstract={Pedestrian gender recognition plays an important role in smart city. To effectively improve the pedestrian gender recognition performance, a new method, called cascading scene and viewpoint feature learning (CSVFL), is proposed in this article. The novelty of the proposed CSVFL lies on the joint consideration of two crucial challenges in pedestrian gender recognition, namely, scene and viewpoint variation. For that, the proposed CSVFL starts with the scene transfer (ST) scheme, followed by the viewpoint adaptation (VA) scheme in a cascading manner. Specifically, the ST scheme exploits the key pedestrian segmentation network to extract the key pedestrian masks for the subsequent key pedestrian transfer generative adversarial network, with the goal of encouraging the input pedestrian image to have the similar style to the target scene while preserving the image details of the key pedestrian as much as possible. Afterward, the obtained scene-transferred pedestrian images are fed to train the deep feature learning network with the VA scheme, in which each neuron will be enabled/disabled for different viewpoints depending on whether it has contribution on the corresponding viewpoint. Extensive experiments conducted on the commonly used pedestrian attribute data sets have demonstrated that the proposed CSVFL approach outperforms multiple recently reported pedestrian gender recognition methods.},
  keywords={Feature extraction;Internet of Things;Task analysis;Generative adversarial networks;Cameras;Smart cities;Electronic mail;Cascading feature learning;pedestrian gender recognition;scene variation;viewpoint variation},
  doi={10.1109/JIOT.2020.3021763},
  ISSN={2327-4662},
  month={Feb},}@ARTICLE{10820354,
  author={Saeed, Adnan and Shehzad, Khurram and Bhatti, Shahzad Sarwar and Ahmed, Saim and Azar, Ahmad Taher},
  journal={IEEE Access}, 
  title={GGLA-NeXtE2NET: A Dual-Branch Ensemble Network With Gated Global-Local Attention for Enhanced Brain Tumor Recognition}, 
  year={2025},
  volume={13},
  number={},
  pages={7234-7257},
  abstract={Due to the limited availability of training data, the diverse shapes of brain tumors among different patients, inter-class similarity, and intra-class variation, achieving high recognition accuracy and speed in deep learning-based brain tumor recognition remains challenging. To address these issues, we propose a Dual-Branch Ensemble and Gated Global-Local Attention network based on EfficientNetV2S and ConvNeXt (GGLA-NeXtE2NET) to improve identification accuracy and model interpretability. For inter-class and intra-class problems, we designed a Gated Global-Local Attention (GGLA) mechanism that captures dependency information of query points in both horizontal and vertical directions, thereby obtaining global information indirectly. Simultaneously, local information is captured through multiple convolutions with a gating layer. The gating mechanism within the GGLA dynamically balances the contributions of global and local information, enabling the model to adaptively focus on the most relevant features for accurate classification. Furthermore, we introduce a dual-branch ensemble network to address the issue of image variety. This network uses two branches to extract image features at different resolutions for fusion, thereby expanding the network receptive field. Additionally, we utilized an Enhanced Super-Resolution Generative Adversarial Network (ESRGAN) to generate images that balance MRI data and implemented multiple preprocessing techniques to tackle inherent noise in MRI images. These techniques enhance the clarity of MRI images while preserving essential details. This results in a clear improvement in the identification of tumor boundaries, crucial for accurate surgical planning and treatment strategies. We evaluated GGLA-NeXtE2NET on 3-class and 4-class brain tumor datasets and achieved 99.06%, and 99.62% overall accuracy on both datasets respectively.},
  keywords={Magnetic resonance imaging;Tumors;Brain tumors;Brain modeling;Accuracy;Convolutional neural networks;Attention mechanisms;Feature extraction;Medical diagnostic imaging;Generative adversarial networks;MRI brain tumor;deep learning;image processing;medical image analysis;attention mechanism},
  doi={10.1109/ACCESS.2025.3525518},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8978165,
  author={Cu, Vinh Loc and Burie, Jean-Christophe and Ogier, Jean-Marc and Liu, Cheng-Lin},
  booktitle={2019 International Conference on Document Analysis and Recognition (ICDAR)}, 
  title={A Robust Data Hiding Scheme Using Generated Content for Securing Genuine Documents}, 
  year={2019},
  volume={},
  number={},
  pages={787-792},
  abstract={Data hiding is an effective technique, compared to pervasive black-and-white code patterns such as barcode and quick response code, which can be used to secure document images against forgery or unauthorized intervention. In this work, we propose a robust digital watermarking scheme for securing genuine documents by leveraging generative adversarial networks (GAN). To begin with, the input document is adjusted to its right form by geometric correction. Next, the generated document is obtained from the input document by using the mentioned networks, and it is regarded as a reference for data hiding and detection. We then introduce an algorithm that hides a secret information into the document and produces a watermarked document whose content is minimally distorted in terms of normal observation. Furthermore, we also present a method that detects the hidden data from the watermarked document by measuring the distance of pixel values between the generated and watermarked document. For improving the security feature, we encode the secret information prior to hiding it by using pseudo random numbers. Lastly, we demonstrate that our approach gives high precision of data detection, and competitive performance compared to state-of-the-art approaches.},
  keywords={Watermarking;Generators;Distortion;Feature extraction;Generative adversarial networks;Transforms;Data hiding;document security;watermarking;generated content},
  doi={10.1109/ICDAR.2019.00131},
  ISSN={2379-2140},
  month={Sep.},}@INPROCEEDINGS{10550799,
  author={Khaleel, Taif Ayad},
  booktitle={2024 International Congress on Human-Computer Interaction, Optimization and Robotic Applications (HORA)}, 
  title={Developing robust machine learning models to defend against adversarial attacks in the field of cybersecurity}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Due to their vulnerability to malicious attacks, machine learning models utilized in cybersecurity applications necessitate robust safeguards. Despite previous research, there is still a lack of effective and practical protections for real-world circumstances. In order to tackle this issue, our work extensively investigates methods to enhance the robustness of machine learning models against malicious assaults. Our cutting-edge cybersecurity defensive tactics are derived on the extensive Edge-IIoTset cybersecurity dataset, specifically designed for Internet of Things (IoT) and Industrial Internet of Things (IIoT) applications. Our methodology integrates sophisticated techniques like adversarial training, input preprocessing, and evaluating the robustness of models. The proposed defensive measures have shown to be highly successful in mitigating the impact of hostile attacks, as evidenced by substantial empirical research. Specifically, as compared to the baseline models, our defensive model exhibits a notable 15% enhancement in accuracy. Our research demonstrates that safeguarding machine learning systems in real-world cybersecurity scenarios necessitates taking proactive actions. This will enable further advancements in the development of unique defense measures. Training methods could be enhanced by including adversarial assaults employing generative adversarial networks (GANs), random forest ensembles, and a variety of scenario-specific hybrid approaches. Assess their effectiveness in dealing with the issue of models being vulnerable to complex manual attacks.},
  keywords={Training;Manuals;Generative adversarial networks;Robustness;Hybrid power systems;Computer crime;Random forests;Adversarial attack;Cybersecurity;Machine Learning;IoT},
  doi={10.1109/HORA61326.2024.10550799},
  ISSN={},
  month={May},}@ARTICLE{10613820,
  author={Dong, Yongsheng and Zhang, Yu and Li, Xuelong},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Dual-Encoding Matching Adversarial Learning for Image Cartoonlization}, 
  year={2024},
  volume={34},
  number={12},
  pages={12301-12315},
  abstract={Generative Adversarial Network (GAN)-based image cartoonization has made great progress. They usually use a “single-encoding adversarial feedback architecture” to generate cartoon image in a similar cartoon-style domain. However, this architecture cannot generate a satisfactory cartoonized image with both high style similarity and visual fidelity. In this work, to relieve this problem, we propose a novel dual-encoding matching adversarial learning dubbed DEMAL for image cartoonlization. Particularly, we first design a dual-encoding matching (DEM) by using a pair of dual encoders and a statistical matching module (SM) to match the content-style feature encodings extracted separately in the statistical space. We then construct double-structure style discriminators to adversarially learn global and local feature representations of cartoon-style via the improved loss function. Furthermore, we also propose a pre-training strategy for the DEMAL to achieve the best FID and ArtFID distance. Extensive experiments have demonstrated that our proposed DEMAL achieves high visual fidelity and style similarity compared to the previous representative baseline cartoonization methods. Code is available at https://github.com/ZYDeeplearning/DEMAL-Model.},
  keywords={Visualization;Feature extraction;Computer architecture;Task analysis;Image color analysis;Generative adversarial networks;Training;Cartoonization;dual-encoding matching;style similarity;high visual fidelity},
  doi={10.1109/TCSVT.2024.3416315},
  ISSN={1558-2205},
  month={Dec},}@ARTICLE{10398490,
  author={Li, Gaojie and Li, Yaochen and Liu, Jingle and Guo, Wei and Tang, Wenneng and Liu, Yuehu},
  journal={IEEE Transactions on Multimedia}, 
  title={ESE-GAN: Zero-Shot Food Image Classification Based on Low Dimensional Embedding of Visual Features}, 
  year={2025},
  volume={27},
  number={},
  pages={2713-2723},
  abstract={Existing zero-shot learning based image classification methods transform the zero-shot learning problem into supervised learning by applying generative adversarial network (GAN) to synthesize visual features of unseen classes. However, the visual features generated by the generator tend to be biased towards seen classes, and the discriminator is too weak to generate high-quality image features. To solve these problems, we propose a novel zero-shot food image classification method based on low dimensional embedding of visual features. Our method applies reinforced semantic guidance to increase the discriminative ability of the model by enhancing the strong distribution of input features. Moreover, the visual space is utilized as the embedding space to reduce the bias towards seen classes by reducing the distance between semantic information and visual features in the embedding space. Finally, the feature distribution of unseen classes is further specified by improving the prototype similarity function. Extensive experiments on three food datasets and four general benchmark datasets demonstrate the effectiveness of the proposed method.},
  keywords={Visualization;Semantics;Zero-shot learning;Generative adversarial networks;Training;Task analysis;Image classification;Zero-shot learning;food classification;semantic feature;latent attributes},
  doi={10.1109/TMM.2024.3353457},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{10797008,
  author={Al-Jawahry, Hassan M. and Challaraj Emmanuel, E. S and Rajasekhar, Boddu and Padmavathy, R. and Sasirekha, N.},
  booktitle={2024 First International Conference on Software, Systems and Information Technology (SSITCON)}, 
  title={Gastrointestinal Disease Classification using Mayfly Optimization Algorithm based Deep Belief Network}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Recently, the detection and classification of gastrointestinal disease tract and disorders based on utilizing endoscopic image classification have increased from the biomedical sector. However, the existing classification methods utilized for gastrointestinal classification has limitations where the models face difficulties in distinguishing between certain classes that results in misclassification. To overcome this limitation, a Mayfly Optimization Algorithm based Deep Belief Network (MOA-DBN) for hyper parameter tuning to classify the gastrointestinal disorder accurately. The proposed MOADBN classifies the gastrointestinal diseases effectively with the help of categorical cross entropy for multi-class classification. The mayfly optimization algorithm addresses the limitations of DBN such as sensitive to initialization and complex hyper parameter tuning that enhanced the classification performance. The endoscopy images are acquired and preprocessed to remove noise to improve classification performance. Features with most appropriate information about the gastrointestinal disease are extracted using pre-trained Visual Geometry Group (VGG) model and classified by the proposed MOA-DBN method. Experimental results of the proposed MOA-DBN method achieved accuracy of ${9 8. 8 3 \%}$ which is higher than the existing classification approaches namely Generative Adversarial Network (GAN) and Spatial attention Convmixer.},
  keywords={Geometry;Visualization;Generative adversarial networks;Feature extraction;Gastrointestinal tract;Entropy;Classification algorithms;Optimization;Tuning;Diseases;gastrointestinal disease;categorical cross entropy loss function;deep belief network;mayfly optimization algorithm and visual geometry group},
  doi={10.1109/SSITCON62437.2024.10797008},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10725305,
  author={Gadilohar, Pragat and Tomar, Deepak Singh and Dehalwar, Vasudev and Sharma, Yogesh Kumar},
  booktitle={2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Integrating CNN and XGBoost with Synthetic Samples for Advanced Android Malware Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The ubiquitous presence of Android smartphones exposes users to an ever-expanding arsenal of malware threats. Existing detection methods often struggle with false positives and limited adaptability to emerging threats. This paper presents a novel hybrid deep learning approach for Android malware detection, achieving a remarkable 98.66% accuracy while minimizing false positives. By combining Convolutional Neural Networks (CNNs) with XGBoost and leveraging Generative Adversarial Networks (GANs) for data augmentation, this method demonstrates scalability and robustness across varying dataset sizes. This approach significantly enhances user privacy, device security, and app integrity, contributing to the ongoing battle against evolving Android malware threats. Utilizing a balanced dataset of 3,000 benign and malicious APK files, our method employs feature importance techniques to ensure model interpretability and relevance. The proposed approach showcases consistent performance with 1000, 2000, and 3000 APK files, highlighting its efficacy in safeguarding Android users against an ever-expanding array of malware threats.},
  keywords={Deep learning;Privacy;Accuracy;Surge protection;Generative adversarial networks;Feature extraction;Malware;Security;Convolutional neural networks;Surges;Android malware;Dalvik opcode;CNN;XGBoost;GANs;F-classification;Permutation Importance},
  doi={10.1109/ICCCNT61001.2024.10725305},
  ISSN={2473-7674},
  month={June},}@INPROCEEDINGS{10260539,
  author={Song, Bing and Xiong, Gang and Shen, Zhen and Zhu, Fenghua and Lv, Yisheng and Ye, Peijun},
  booktitle={2023 IEEE 19th International Conference on Automation Science and Engineering (CASE)}, 
  title={Geometry Problem Solving Based on Counter-Factual Evolutionary Reasoning}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={As a representative topic in natural language processing and automated theorem proving, geometry problem solving requires an abstract problem understanding and symbolic reasoning. A major challenge here is to find a feasible reasoning sequence that is consistent with given axioms and the theorems already proved. Most recent methods have exploited neural network-based techniques to automatically discover eligible solving steps. Such a kind of methods, however, is greatly impacted by the expert solutions for training. To improve the accuracy, this paper proposes a new method called counterfactual evolutionary reasoning, which uses a generative adversarial network to generate initial reasoning sequences and then introduces counterfactual reasoning to explore potential solutions. By directly exploring theorem candidates rather than the neural network selection, the new method can sufficiently extend the searching space to get a more appropriate reasoning step. Through comparative experiments on the recent proposed Geometry3k, the largest geometry problem solving dataset, our method generally achieves a higher accuracy than most previous methods, bringing an overall improvement about 4.4% compared with the transformer models.},
  keywords={Geometry;Training;Technological innovation;Computer aided software engineering;Neural networks;Transformers;Generative adversarial networks},
  doi={10.1109/CASE56687.2023.10260539},
  ISSN={2161-8089},
  month={Aug},}@INPROCEEDINGS{10929816,
  author={Park, Seunghyeon and Bae, Youngho and Han, Gunhui and Olson, Alexander W},
  booktitle={2025 IEEE International Conference on Consumer Electronics (ICCE)}, 
  title={FLODA: Harnessing Vision-Language Models for Deepfake Assessment}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={The proliferation of advanced generative AI models has ushered in a new era of image creation, where the distinction between real and synthetic content has become increasingly blurred. This phenomenon poses significant challenges to the integrity and trustworthiness of digital content and AI systems. Recently, Vision-Language Models (VLMs) have shown great potential in addressing these challenges due to their superior performance in vision-language tasks. In this paper, we propose FLODA (FLorence-2 Optimized for Deepfake Assessment), an advanced method designed to surpass existing deepfake detection models. FLODA leverages the VLM model, Florence-2, and extends it by integrating image captioning and authenticity assessment into a single end-to-end architecture. By utilizing caption information, FLODA enhances visual analysis with contextual details, streamlining both caption generation and deepfake detection. To ensure FLODA's efficacy, we performed an ablation study to identify the optimal model configuration and demonstrated its contributions to performance improvements. We also compared our best FLODA model against existing benchmarks through rigorous evaluation. Notably, FLODA demonstrates strong generalization, showcasing its robustness across diverse scenarios with an average accuracy of 97.14%. This research advances digital content integrity and AI trustworthiness, providing a promising direction for future VLM applications. Code and models can be found at https://github.com/byh711/FLODA.},
  keywords={Training;Deepfakes;Visualization;Accuracy;Generative AI;Streaming media;Robustness;Faces;Resilience;Context modeling;Deepfake Detection;AI-generated Images Detection;AI Integrity;Vision-Language Models (VLMs)},
  doi={10.1109/ICCE63647.2025.10929816},
  ISSN={2158-4001},
  month={Jan},}@INPROCEEDINGS{10775717,
  author={Widodo, Agung Mulyo and Baghban, Hojjat and Rahaman, Mosiur and Baharudin, Erwan and Ulum, Muhamad Bahrul and Aryani, Diah},
  booktitle={2024 4th International Conference on Electronic and Electrical Engineering and Intelligent System (ICE3IS)}, 
  title={Integrating GAN to MFCC-Assisted RNN-LSTM Algorithms for Identifying Types of Tribes Based on English Pronunciation}, 
  year={2024},
  volume={},
  number={},
  pages={385-390},
  abstract={Many studies based on Natural Language Processing (NLP) that have been carried out focus on the results of speech recognition on devices, but do not discuss the speech recognition process that is applied until the device works according to voice commands from the user. One of the factors for success in the classification process is the amount of unbalanced data. Imbalances in the data can impact the performance of the Deep Learning architecture used to create classifier models. Therefore, it is proposed to integrate the Generative Adversarial Network (GAN) algorithm and the Mel Frequency Cepstral Coefficient (MFCC) algorithm assisted by RNN-LSTM which is used in Speech Recognition in English Pronunciation by Non-Native Speakers. The proposed model is able to produce ethnic recognition based on the pronunciation made by a speaker. The study was conducted using 2,722 voice samples from 4 indigenous tribes in Indonesia, namely, the Ambonese, Sundanese, Javanese and Betawi. By using the proposed method and after testing, a classifier model was obtained with an accuracy of 78.12%.},
  keywords={Performance evaluation;Accuracy;Speech recognition;Generative adversarial networks;Data models;Natural language processing;Classification algorithms;Mel frequency cepstral coefficient;Optimization;Testing;GAN;LSTM;MFCC;pronunciation;recognition;speech},
  doi={10.1109/ICE3IS62977.2024.10775717},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10822063,
  author={Gao, Peipei and Du, Ling and Qiao, Sibo and Yin, Nan},
  booktitle={2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Uncertainty-induced Incomplete Multi-Omics Integration Network for Cancer Diagnosis}, 
  year={2024},
  volume={},
  number={},
  pages={4415-4422},
  abstract={Cancer diagnosis with incomplete multi-omics data is inevitable since there are widely missing arbitrary omics in real-world applications. Currently, although much progress has been made in handling missing data, existing methods for cancer diagnosis still struggle to obtain credible predictions due to the relatively high uncertainty of missing omics data. In this paper, we propose a trusted and attention-based multi-omics integrated framework for cancer diagnosis using incomplete multi-omics data (TAIMONET). For the raw omics data, the framework first builds an attention-based shared encoder to pick out important features and align different omics data. Next, it utilizes generative adversarial learning to impute the missing omics features based on the extracted available omics features. Meanwhile, different reconstructed complete omics data are weighted and fused according to the attention mechanism. Moreover, it uses true-class-probability to calibrate the classification results and improve the reliability of the results. Extensive experiments on four real-world multimodal medical datasets are conducted. Compared to state-of-the-art methods, the superior performance and trustworthiness of our proposed model are clearly validated.},
  keywords={Uncertainty;Attention mechanisms;Fuses;Biological system modeling;Feature extraction;Generative adversarial networks;Reliability;Bioinformatics;Medical diagnostic imaging;Cancer;Cancer diagnosis;Incomplete multi-omics data;Uncertainty;Attention mechanism},
  doi={10.1109/BIBM62325.2024.10822063},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{11049114,
  author={Maity, Gouranga and Pramanik, Souvik and Mandal, Diptarka and Kaplun, Dmitrii and Gulvanskii, Vyacheslav and Sarkar, Ram},
  booktitle={2025 14th Mediterranean Conference on Embedded Computing (MECO)}, 
  title={VEGAN: A Vision-language and Edge-enhanced GAN-based Microscopic Medical Image Segmentation Model}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={In this paper, we introduce VEGAN: a vision-language and edge-enhanced GAN-based Microscopic Medical Image segmentation model, a novel framework that combines Attention U-Net with a Pix2Pix Generative Adversarial Network (GAN), incorporating a vision-language model (VLM), called CLIP, within skip connections of the U-Net model. In our approach, the Attention U-Net takes both the input image and an edge map to enhance spatial feature extraction. Additionally, the encoder part of the generator integrates Convolutional Block Attention Modules (CBAM) to refine feature representations by emphasizing informative spatial and channel-wise features. The Pix2Pix GAN framework further refines segmentation results, with the generator utilizing the modified Attention U-Net and the discriminator employing PatchGAN to improve structural accuracy. The inclusion of CLIP-based skip connections enhances semantic understanding, aiding in feature retention, and better generalization. The model is evaluated on a publicly available dataset, called MoNuSeg and CNS for nuclei segmentation. Additionally, to ensure the robustness, it has been evaluated on the PH2 dataset for skin lesion segmentation. Experimental results demonstrate that our model achieves a Dice scores of 79.24%, 99.56% and 92.54% on MoNuSeg, CNS and PH2 datasets, respectively, which are better than many recently proposed models found in the literature. The improved results underscore the effectiveness of VEGAN architecture in handling the complexity of microscopic medical images, making it a valuable tool for advancing automated cellular analysis in biomedical research. Code and additional results will be found at GitHub .},
  keywords={Training;Image segmentation;Accuracy;Image edge detection;Microscopy;Computational modeling;Biological system modeling;Generative adversarial networks;Generators;Biomedical imaging;Medical Image;Nuclei Segmentation;GAN model;Attention U-Net;Edge Map;Vision Language Model},
  doi={10.1109/MECO66322.2025.11049114},
  ISSN={2637-9511},
  month={June},}@ARTICLE{11089989,
  author={Dang, Zhangxuan and Zheng, Yu and Lian, Xinglin and Peng, Chunlei and Chen, Qiuyu and Gao, Xinbo},
  journal={IEEE Transactions on Network and Service Management}, 
  title={Semi-Supervised Learning for Anomaly Traffic Detection via Bidirectional Normalizing Flows}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={With the rapid development of the Internet, various types of anomaly traffic are threatening network security. However, the difficulty of collecting and labelling anomalous traffic is a significant challenge, so this paper proposes a semi-supervised anomaly detection framework. Considering normal and abnormal traffic have different data distributions, our framework can generate pseudo anomaly samples without prior knowledge of anomalies to achieve the detection of anomaly data. The framework comprises three principal components. Firstly, a pre-trained feature extractor is employed to extract a feature representation of the network traffic. Secondly, a bidirectional normalizing flow module establishes a reversible transformation between the latent data distribution and a Gaussian space. Through this bidirectional mapping, samples first undergo transformation manipulation within the Gaussian distribution space, and are then transported through the generative direction of normalizing flows, translating mathematical transformations into semantic feature evolutions in the latent data space. Finally, a simple classifier explicitly learns the potential differences between anomaly and normal samples to facilitate better anomaly detection. During inference, our framework requires only two modules to detect anomalous samples, leading to a considerable reduction in model size. According to the experiments, our method achieves the state-of-the-art results on the common benchmarking datasets of anomaly network traffic detection. Furthermore, it exhibits good generalisation performance across datasets.},
  keywords={Telecommunication traffic;Feature extraction;Anomaly detection;Training;Noise;Knowledge engineering;Image reconstruction;Generative adversarial networks;Accuracy;Semantics;network traffic detection;semi-supervised learning;anomaly detection},
  doi={10.1109/TNSM.2025.3591533},
  ISSN={1932-4537},
  month={},}@ARTICLE{10835146,
  author={Zhang, Chuan and Zheng, Xixi and Tao, Xiaolong and Hu, Chenfei and Zhang, Weiting and Zhu, Liehuang},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Distributed Collaborative Inference System in Next-Generation Networks and Communication}, 
  year={2025},
  volume={11},
  number={2},
  pages={923-932},
  abstract={With the rapid advancement of artificial intelligence, generative artificial intelligence (GAI) has taken a leading role in transforming data processing methods. However, the high computational demands of GAI present challenges for devices with limited resources. As we move towards the sixth generation of mobile networks (6G), the higher data rates of 6G create a need for more efficient data processing in GAI. Traditional GAI, however, shows its limitations in meeting these demands. To address these challenges, we introduce a multi-level collaborative inference system designed for next-generation networks and communication. Our proposed system features a deployment strategy that assigns models of varying sizes to devices at different network layers. Then, we design a task offloading strategy to optimise both efficiency and latency. Furthermore, a modified early exit mechanism is implemented to enhance the inference process for single models. Experimental results demonstrate that our system effectively reduces inference latency while maintaining high-quality output. Specifically, compared to existing work, our system can reduce inference time by up to 17% without sacrificing the inference accuracy.},
  keywords={Computational modeling;Accuracy;Transformers;Inference algorithms;Collaboration;Next generation networking;Adaptation models;6G mobile communication;Servers;Probabilistic logic;Generative artificial intelligence;early exit;collaborative inference;next-generation networks and communication},
  doi={10.1109/TCCN.2025.3527679},
  ISSN={2332-7731},
  month={April},}@INPROCEEDINGS{10555960,
  author={Du, Hongyang and Zhang, Ruichen and Niyato, Dusit and Kang, Jiawen and Xiong, Zehui and Kim, Dong In},
  booktitle={2024 International Conference on Computing, Networking and Communications (ICNC)}, 
  title={Reinforcement Learning with Large Language Models (LLMs) Interaction for Network Services}, 
  year={2024},
  volume={},
  number={},
  pages={799-803},
  abstract={Artificial Intelligence-Generated Content (AIGC)-related network services, especially image generation-based services, have garnered notable attention due to their ability to cater to diverse user preferences, which significantly impacts the subjective Quality of Experience (QoE). Specifically, different users can perceive the same semantically informed image quite differently, leading to varying levels of satisfaction. To address this challenge and maximize network users' subjective QoE, we introduce a novel interactive artificial intelligence (IAI) approach using Reinforcement Learning With Large Language Models Interaction (RLLI). RLLI leverages Large Language Model (LLM)-empowered generative agents to simulate user interactions, thereby providing real-time feedback on QoE that encapsulates a range of user personalities. This feedback is instrumental in facilitating the selection of the most suitable AIGC network service provider for each user, ensuring an optimized, personalized experience.},
  keywords={Image synthesis;Computational modeling;Instruments;Focusing;Reinforcement learning;Real-time systems;Quality of experience;Reinforcement learning;generative artificial intelligence;large language models},
  doi={10.1109/ICNC59896.2024.10555960},
  ISSN={2473-7585},
  month={Feb},}@ARTICLE{10829829,
  author={Zhuo, Biting and Duan, Wei and Gu, Juping and Cheng, Tianyu and Zhao, Fengshen},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={Integrating of GAI-Based Consumer IoV and Multiple Access: A Novel Bundled Approach}, 
  year={2025},
  volume={71},
  number={2},
  pages={3767-3778},
  abstract={Generative artificial intelligence (GAI) has attracted widespread attention since its creative artificial intelligence-generated content (AIGC) can be produced to meet the requirements of consumer electronics. In particular, bridging GAI and consumer Internet of Vehicles (IoV) is promising to serve mobile vehicles with complicated data processing, environmental perception, decision-making, and autonomous navigation. On the other hand, multiple access is one of the key approach to deal with ever-increasing data, benefited from its superior spectrum efficiency. However, the integrating of multiple access with GAI-based consumer IoV networks is still difficult to achieve, since the terrible interferences between vehicle devices. To solve this dilemma, taking uplink GAI-based consumer IoV as an example, we investigate a novel bundled scheme to improve received signal-to-noise ratio (SNR) and prevent outage events effectively, developing bundled non-orthogonal multiple access (B-NOMA), bundled rate-splitting multiple access (B-RSMA), and enhanced B-RSMA (EB-RSMA). Meanwhile, our proposed bundled schemes also solve the problem that the interference power exceeds the desired signal resulting in a significant performance loss, regarding both NOMA and RSMA decoding principles. In addition, since that our proposed schemes firmly depend on accurate channel state information (CSI), a GAI-based deep neural network (DNN) technique is further proposed for channel estimation. Closed-form expressions of our proposed schemes are respectively derived and confirmed by means of simulation results, which verify the superiority of B-NOMA, B-RSMA and EB-RSMA compared to the benchmark.},
  keywords={NOMA;Consumer electronics;Signal to noise ratio;Resource management;Streams;Decoding;Uplink;Power system reliability;Interference cancellation;Channel estimation;Generative artificial intelligence (GAI);consumer Internet of Vehicle (IoV);multiple access decoding principle;successive interference cancellation (SIC)},
  doi={10.1109/TCE.2025.3526826},
  ISSN={1558-4127},
  month={May},}@INPROCEEDINGS{10777194,
  author={Shakil, Mohammad and Mekuria, Fisseha},
  booktitle={2024 International Conference on Information and Communication Technology for Development for Africa (ICT4DA)}, 
  title={Balancing the Risks and Rewards of Deepfake and Synthetic Media Technology: A Regulatory Framework for Emerging Economies}, 
  year={2024},
  volume={},
  number={},
  pages={114-119},
  abstract={Deepfake and synthetic media technologies hold substantial promise for innovation in sectors such as entertainment, education, and healthcare. However, they also present significant risks, particularly in emerging economies with underdeveloped regulatory frameworks. This study proposes a comprehensive regulatory approach to balance the potential and risks of these technologies. The framework encompasses legal measures for consent and privacy, technical solutions for advanced detection tools and secure data management, and educational initiatives to enhance public awareness and digital literacy. By emphasizing collaboration with international bodies, technology companies, and community organizations, this framework aims to harness the benefits of deepfake technology while mitigating its risks, thereby fostering a safer and more ethical digital landscape in emerging economies.},
  keywords={Deepfakes;Ethics;Technological innovation;Data privacy;Law;Standards organizations;Companies;Media;Digital intelligence;Testing;Artificial intelligence;deepfakes;synthetic media;emerging economies;regulatory framework;ai ethics},
  doi={10.1109/ICT4DA62874.2024.10777194},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9532698,
  author={Muñoz-Ccuro, Felipa Elvira and Alvarado Mamani, Mercy Jeaninna and Hijar Hernandez, Victor Daniel and del carmen Emilia Ancaya-Martinez, María},
  booktitle={2021 IEEE XXVIII International Conference on Electronics, Electrical Engineering and Computing (INTERCON)}, 
  title={Solar panel analysis with adversary neural networks}, 
  year={2021},
  volume={},
  number={},
  pages={1-4},
  abstract={When solar panels received the irradiance from the sun, early detection is important to prevent fault or fast degradation. This research article provides a new method using “Generative Adversary Neural Networks” [1] (GANN), with a deep learning techniques, for evaluation of the degradation in solar panels (SP). The methodology required root cause analysis for SP degradation, it considered four stages for the deep learning: ”preprocessing, segmentation, extraction, and classification” [11]. In this paper, we are determined artificial intelligence methodology and new neural network proposal for panel degradation detection based on root cause analysis [2]. The effectiveness of the results were 97.5%; with minimum information. However, the training process produces 0.105 % false positives.},
  keywords={Degradation;Training;Deep learning;Root cause analysis;Neural networks;Inspection;Solar panels;Deep Learning;generative adversary;neural network;root cause analysis},
  doi={10.1109/INTERCON52678.2021.9532698},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10605325,
  author={Liu, Zhengyuan and Yin, Stella Xin and Lee, Carolyn and Chen, Nancy F.},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Scaffolding Language Learning via Multi-modal Tutoring Systems with Pedagogical Instructions}, 
  year={2024},
  volume={},
  number={},
  pages={1258-1265},
  abstract={Intelligent tutoring systems (ITSs) that imitate human tutors and aim to provide immediate and customized instructions or feedback to learners have shown their effectiveness in education. With the emergence of generative artificial intelligence, large language models (LLMs) further entitle the systems to complex and coherent conversational interactions. These systems would be of great help in language education as it involves developing skills in communication, which, however, drew relatively less attention. Additionally, due to the complicated cognitive development at younger ages, more endeavors are needed for practical uses. Scaffolding refers to a teaching technique where teachers provide support and guidance to students for learning and developing new concepts or skills. It is an effective way to support diverse learning needs, goals, processes, and outcomes. In this work, we investigate how pedagogical instructions facilitate the scaffolding in ITSs, by conducting a case study on guiding children to describe images for language learning. We construct different types of scaffolding tutoring systems grounded in four fundamental learning theories: knowledge construction, inquiry-based learning, dialogic teaching, and zone of proximal development. For qualitative and quantitative analyses, we build and refine a seven-dimension rubric to evaluate the scaffolding process. In our experiment on GPT-4V, we observe that LLMs demonstrate strong potential to follow pedagogical instructions and achieve self-paced learning in different student groups. Moreover, we extend our evaluation framework from a manual to an automated approach, paving the way to benchmark various conversational tutoring systems.},
  keywords={Statistical analysis;Generative AI;Large language models;Education;Manuals;Benchmark testing;Intelligent Tutoring Systems;Scaffolding;Multimodal Language Models},
  doi={10.1109/CAI59869.2024.00223},
  ISSN={},
  month={June},}@INBOOK{9536285,
  author={Boutaba, Raouf and Shahriar, Nashid and Salahuddin, Mohammad A. and Limam, Noura},
  booktitle={Communication Networks and Service Management in the Era of Artificial Intelligence and Machine Learning}, 
  title={Managing Virtualized Networks and Services with Machine Learning}, 
  year={2021},
  volume={},
  number={},
  pages={33-68},
  abstract={Virtualization is instigating a paradigm shift in the networking industry, to keep up with emerging application's quality of service requirements, massive growth in traffic volume, and to reduce capital and operational expenditures. Network virtualization coupled with function virtualization enables network providers to offer on&#x2010;demand virtualized networks and services. Network slicing goes a step further by facilitating a new business model, namely Network&#x2010;as&#x2010;a&#x2010;Service, to offer dedicated and customized network slices (i.e. partitions of physical infrastructure) to multiple tenants, while ensuring proper isolation. However, this shift introduces new challenges for network providers and calls for intelligent and automated management. Artificial intelligence and machine learning are considered as enablers for the automated deployment and management of virtualized networks and services. This chapter exposes the state&#x2010;of&#x2010;the&#x2010;art research that leverages artificial intelligence and machine learning to address complex problems in deploying and managing virtualized networks and services. It also delineates open, prominent research challenges and opportunities to realize automated management of virtualized networks and services.},
  keywords={Servers;Hardware;Virtualization;Virtual private networks;Network slicing;Network function virtualization;Computer industry},
  doi={10.1002/9781119675525.ch3},
  ISSN={},
  publisher={IEEE},
  isbn={9781119675440},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/9536285},}@INPROCEEDINGS{11141940,
  author={Qin, Yanghong and Yu, Miao},
  booktitle={2025 5th Asia-Pacific Conference on Communications Technology and Computer Science (ACCTCS)}, 
  title={Research on Pig Breed Identification Algorithm Based on Image Segmentation and Pattern Recognition Technology}, 
  year={2025},
  volume={},
  number={},
  pages={859-864},
  abstract={This paper discusses the application of image segmentation and pattern recognition technology in pig breed identification, and proposes a new framework combining NAM-YOLO algorithm and case segmentation network YOLACT. We first adopted the target detection network YOLOv5 for target positioning. The experimental results show that the preliminary application of YOLOv5 in the identification of pig breeds has achieved remarkable results. However, in practice, there are still some challenges, such as missing detection (not detecting all pigs) and false detection (incorrectly identifying non-pig objects as pigs). These problems are usually caused by a change in the size of the target and a shift in the position of the detection box. To solve these problems, this paper proposes a NAM-YOLO algorithm based on the improved normalized attention mechanism. By introducing the normalized attention mechanism to enhance the adaptability of the model to different scale targets, the false detection rate and missing detection rate are effectively reduced. In addition, the position error of the detection frame is corrected by boundary extension technique to ensure that each individual can be correctly identified. After the initial inspection, we divided the entire image into several small images and processed these small images using the YOLACT instance segmentation network to achieve accurate segmentation of individual pigs. The ability of YOLACT to generate instance masks directly from images without relying on additional segmentation modules or complex training processes makes it ideal for the individual pig segmentation task in this study. By applying YOLACT to the small images obtained above, it is possible to achieve fine segmentation of each individual pig, so as to obtain more accurate morphological characteristics information. To sum up, the framework based on NAM-YOLO and YOLACT proposed in this paper shows good potential in solving complex problems in pig breed identification, the recognition accuracy is significantly higher than that of traditional methods based on artificial features, and it can maintain high stability under different lighting conditions and shooting angles.},
  keywords={YOLO;Instance segmentation;Training;Accuracy;Attention mechanisms;Lighting;Stability analysis;Robustness;Pattern recognition;Object recognition;Image segmentation;YOLOv5;YOLACT;Object detection},
  doi={10.1109/ACCTCS66275.2025.00153},
  ISSN={},
  month={April},}@INPROCEEDINGS{10240132,
  author={Liu, Ziyi and Fang, Yongchun},
  booktitle={2023 42nd Chinese Control Conference (CCC)}, 
  title={Learning Diverse Control Strategies for Simulated Humanoid Combat via Motion Imitation and Multi-Agent Self-Play}, 
  year={2023},
  volume={},
  number={},
  pages={5595-5600},
  abstract={Human athletes can coordinate their bodies to achieve exquisite strategies with agile and diverse motions in multiplayer competitions, which is a long-standing challenge for robotics and physically embodied artificial agents. In this paper, we propose a hierarchical learning framework that generates diverse control strategies and agile motion for physically simulated humanoids, which can be divided into two stages: learning basic motion skills and learning high-level competitive strategies. The framework decouples low-level control and high-level strategy learning, where the low-level policy is trained via motion imitation and skill discovery objectives to generate agile motion skills, and the high-level policy is trained via prioritized fictitious self-play to generate diverse competitive strategies. Furthermore, we develop and release the world's first physically simulated humanoid combat environment. We evaluate our learning framework in this environment, and experimental results demonstrate that policies learned by our framework can generate both agile motion skills and diverse long-term competitive strategies.},
  keywords={Deep learning;Robot kinematics;Humanoid robots;Reinforcement learning;Aerospace electronics;Control systems;Behavioral sciences;Multi-Agent System;Motion Control;Hierarchical Reinforcement Learning},
  doi={10.23919/CCC58697.2023.10240132},
  ISSN={1934-1768},
  month={July},}@ARTICLE{10750819,
  author={Wang, Xuran and Zhang, Xinguang and Hoo, Vanessa and Shao, Zhouhang and Zhang, Xuguang},
  journal={IEEE Access}, 
  title={LegalReasoner: A Multi-Stage Framework for Legal Judgment Prediction via Large Language Models and Knowledge Integration}, 
  year={2024},
  volume={12},
  number={},
  pages={166843-166854},
  abstract={Legal judgment prediction (LJP) presents a formidable challenge in artificial intelligence, demanding intricate comprehension of legal texts, nuanced interpretation of statutes, and complex reasoning over multifaceted case elements. While recent advancements in natural language processing have shown promise, existing approaches often struggle to capture the sophisticated interplay between facts, legal principles, and precedents that characterize legal decision-making. This paper introduces LegalReasoner, a novel multi-stage framework that leverages large language models (LLMs) and integrates domain-specific knowledge for enhanced legal judgment prediction. Our approach encompasses four key stages: 1) legal knowledge infusion, where we pre-train an LLM on a vast corpus of legal literature using contrastive learning techniques; 2) case-law retrieval, employing a graph neural network to identify relevant precedents and statutes; 3) multi-hop reasoning, utilizing a transformer-based architecture with a hierarchical attention mechanism to navigate complex legal arguments; and 4) judgment synthesis, where we employ a generative adversarial network to produce coherent and legally sound judgments. We evaluate LegalReasoner on two diverse datasets: the European Court of Human Rights (ECHR) cases and the Chinese AI and Law Challenge (CAIL2018). Our framework demonstrates substantial improvements over state-of-the-art baselines, achieving an average accuracy increase of 7.8% across all datasets. Furthermore, we conduct extensive ablation studies and interpretability analyses to elucidate the contributions of each component and provide insights into the model’s decision-making process. Our work not only advances the field of automated legal reasoning but also offers a transparent and explainable system that could serve as a valuable tool for legal professionals. By bridging the gap between AI and legal expertise, LegalReasoner paves the way for more efficient, consistent, and fair legal decision-making processes.},
  keywords={Law;Cognition;Artificial intelligence;Predictive models;Natural language processing;Decision making;Large language models;Transformers;Contrastive learning;Knowledge based systems;Legal judgment prediction;large language models;knowledge integration;multi-hop reasoning},
  doi={10.1109/ACCESS.2024.3496666},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9457563,
  author={Sooksatra, Korn and Rivas, Pablo},
  booktitle={2020 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={A Review of Machine Learning and Cryptography Applications}, 
  year={2020},
  volume={},
  number={},
  pages={591-597},
  abstract={Adversarially robust neural cryptography deals with the training of a neural-based model using an adversary to leverage the learning process in favor of reliability and trustworthiness. The adversary can be a neural network or a strategy guided by a neural network. These mechanisms are proving successful in finding secure means of data protection. Similarly, machine learning benefits significantly from the cryptography area by protecting models from being accessible to malicious users. This paper is a literature review on the symbiotic relationship between machine learning and cryptography. We explain cryptographic algorithms that have been successfully applied in machine learning problems and, also, deep learning algorithms that have been used in cryptography. We pay special attention to the exciting and relatively new area of adversarial robustness.},
  keywords={Deep learning;Training;Symbiosis;Machine learning algorithms;Scientific computing;Neural networks;Robustness;neural cryptography;deep learning;block ciphers;generative adversarial networks;adversarial robustness},
  doi={10.1109/CSCI51800.2020.00105},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10545108,
  author={Pushparani, S. and Rekha, K. Sashi and Sivagami, V. M. and Usharani, R. and Jothi, M.},
  booktitle={2024 International Conference on Trends in Quantum Computing and Emerging Business Technologies}, 
  title={Exploring the Effectiveness of Deep Learning in Audio Compression and Restoration}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Modern audio processing requires compression and restoration for streaming services and data storage and transmission. This study examines how deep learning can address these difficulties and includes an architecture flow diagram. The suggested complex design has numerous integral stages optimized for audio compression and restoration. The input layer contains raw audio data. The pre-processing module normalizes and extracts features from raw data, frequently using Mel-frequency cepstral coefficients (MFCC) to capture audio characteristics. This module improves data quality by reducing noise and filtering. The architecture's heart is the compression module, where deep learning is used. This module compresses audio data using neural networks, maybe CNNs or RNNs. This compression is quantified by compression ratio and bitrate, with hypothetical values representing audio quality trade-offs. The compression module compacts audio data for storage or transmission. To minimize data size, quantization and encoding are common here. To accurately decompress audio, the decompression module mimics the compression module's architecture. Depending on needs, error correction or quality enhancement layers may be added. Filtering, equalization, and dynamic range compression may be used in the post-processing module to improve audio quality. If needed, a restoration module uses deep learning models to minimize noise and artifacts. This study presents four hypothetical scenarios to demonstrate different results. The scenarios emphasize high compression, balanced approaches, quality prioritization, and low resource utilization. Deep learning approaches can adapt to varied audio processing needs by balancing compression ratio, bitrate, audio quality (measured by PSNR), and restoration accuracy in each case.},
  keywords={Deep learning;Training;Filtering;Bit rate;Noise;Computer architecture;Feature extraction;Audio Compression;Audio Restoration;Deep learning;CNN},
  doi={10.1109/TQCEBT59414.2024.10545108},
  ISSN={},
  month={March},}@ARTICLE{10696938,
  author={Ahmad Fattah Saskoro, R. and Yudistira, Novanto and Noor Fatyanosa, Tirana},
  journal={IEEE Access}, 
  title={Detection of AI-Generated Images From Various Generators Using Gated Expert Convolutional Neural Network}, 
  year={2024},
  volume={12},
  number={},
  pages={147772-147783},
  abstract={The rapid advancement of artificial intelligence (AI), particularly in text-to-image generative models, has led to a proliferation of synthetic images. This progress, while remarkable, raises concerns about misuse in fraudulent activities. To address this issue, we propose a Convolutional Neural Network (CNN)-based approach for classifying AI-generated images from multiple generators. We introduce a gated CNN model that leverages mixed datasets for improved training efficiency and performance. This approach eliminates the need for extensive tuning with each new dataset and mitigates the risk of catastrophic forgetting. Our experiments demonstrate that the gated CNN model slightly outperforms traditional single CNN models, providing a more robust solution for identifying AI-generated images. This paper presents a comprehensive comparison of methods and offers insights into enhancing the classification of AI-generated images.},
  keywords={Accuracy;Generators;Logic gates;Convolutional neural networks;Transfer learning;Image classification;Artificial intelligence;AI-generated images;CNN;gated network;image classification},
  doi={10.1109/ACCESS.2024.3466614},
  ISSN={2169-3536},
  month={},}@ARTICLE{8960384,
  author={Chen, Shiyao and Zhang, Yan and He, Zunwen and Nie, Jinbo and Zhang, Wancheng},
  journal={IEEE Access}, 
  title={A Novel Attention Cooperative Framework for Automatic Modulation Recognition}, 
  year={2020},
  volume={8},
  number={},
  pages={15673-15686},
  abstract={Modulation recognition plays an indispensable role in the field of wireless communications. In this paper, a novel attention cooperative framework based on deep learning is proposed to improve the accuracy of the automatic modulation recognition (AMR). Within this framework, a convolutional neural network (CNN), a recurrent neural network (RNN), and a generative adversarial network (GAN) are constructed to cooperate in AMR. A cyclic connected CNN (CCNN) is designed to extract spatial features of the received signal, and a bidirectional RNN (BRNN) is constructed for obtaining temporal features. To take full advantage of the complementarity and relevance between the spatial and temporal features, a fusion strategy based on global average and max pooling (GAMP) is proposed. To deal with different influence levels of the signal feature maps, we present the attention mechanism in this framework to realize recalibration. Besides, modulation recognition based on deep learning requires numerous data for training purposes, which is difficult to achieve in practical AMR applications. Therefore, an auxiliary classification GAN (ACGAN) is developed as a generator to expand the training set, and we modify the loss function of ACGAN to accommodate the processing of the actual in-phase and quadrature (I/Q) signal data. Considering the difference in distribution between generated data and real data, we propose a novel auxiliary weighing loss function to achieve higher recognition accuracy. Experimental results on the dataset RML2016.10a show that the proposed framework outperforms existing deep learning-based approaches and achieves 94% accuracy at high signal to noise ratio (SNR).},
  keywords={Feature extraction;Modulation;Gallium nitride;Generative adversarial networks;Generators;Deep learning;Recurrent neural networks;Automatic modulation recognition (AMR);attention mechanism;convolutional neural network (CNN);generative adversarial network (GAN);recurrent neural network (RNN)},
  doi={10.1109/ACCESS.2020.2966777},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9711139,
  author={Naseer, Muzammal and Khan, Salman and Hayat, Munawar and Khan, Fahad Shahbaz and Porikli, Fatih},
  booktitle={2021 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={On Generating Transferable Targeted Perturbations}, 
  year={2021},
  volume={},
  number={},
  pages={7688-7697},
  abstract={While the untargeted black-box transferability of adversarial perturbations has been extensively studied before, changing an unseen model’s decisions to a specific ‘targeted’ class remains a challenging feat. In this paper, we propose a new generative approach for highly transferable targeted perturbations (TTP). We note that the existing methods are less suitable for this task due to their reliance on class-boundary information that changes from one model to another, thus reducing transferability. In contrast, our approach matches the perturbed image ‘distribution’ with that of the target class, leading to high targeted transferability rates. To this end, we propose a new objective function that not only aligns the global distributions of source and target images, but also matches the local neighbourhood structure between the two domains. Based on the proposed objective, we train a generator function that can adaptively synthesize perturbations specific to a given input. Our generative approach is in-dependent of the source or target domain labels, while consistently performs well against state-of-the-art methods on a wide range of attack settings. As an example, we achieve 32.63% target transferability from (an adversarially weak) VGG19BN to (a strong) WideResNet on ImageNet val. set, which is 4× higher than the previous best generative attack and 16× better than instance-specific iterative attack. Code is available at: https://github.com/Muzammal-Naseer/TTP.},
  keywords={Computer vision;Codes;Perturbation methods;Computational modeling;Transformers;Linear programming;Generators;Adversarial learning;Recognition and classification},
  doi={10.1109/ICCV48922.2021.00761},
  ISSN={2380-7504},
  month={Oct},}@ARTICLE{10367775,
  author={Xie, Bingyi and Xu, Honghui and Joe, YongJoon and Seo, Daehee and Cai, Zhipeng},
  journal={Tsinghua Science and Technology}, 
  title={Lightweight Super-Resolution Model for Complete Model Copyright Protection}, 
  year={2024},
  volume={29},
  number={4},
  pages={1194-1205},
  abstract={Deep learning based techniques are broadly used in various applications, which exhibit superior performance compared to traditional methods. One of the mainstream topics in computer vision is the image super-resolution task. In recent deep learning neural networks, the number of parameters in each convolution layer has increased along with more layers and feature maps, resulting in better image super-resolution performance. In today's era, numerous service providers offer super-resolution services to users, providing them with remarkable convenience. However, the availability of open-source super-resolution services exposes service providers to the risk of copyright infringement, as the complete model could be vulnerable to leakage. Therefore, safeguarding the copyright of the complete model is a non-trivial concern. To tackle this issue, this paper presents a lightweight model as a substitute for the original complete model in image super-resolution. This research has identified smaller networks that can deliver impressive performance, while protecting the original model's copyright. Finally, comprehensive experiments are conducted on multiple datasets to demonstrate the superiority of the proposed approach in generating super-resolution images even using lightweight neural networks.},
  keywords={Convolution;Superresolution;Computational modeling;Neural networks;Task analysis;Kernel;Generative adversarial networks;lightweight;copyright protection;adversarial learning;image super-resolution},
  doi={10.26599/TST.2023.9010082},
  ISSN={1007-0214},
  month={August},}@ARTICLE{8371286,
  author={Hohman, Fred and Kahng, Minsuk and Pienta, Robert and Chau, Duen Horng},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers}, 
  year={2019},
  volume={25},
  number={8},
  pages={2674-2693},
  abstract={Deep learning has recently seen rapid development and received significant attention due to its state-of-the-art performance on previously-thought hard problems. However, because of the internal complexity and nonlinear structure of deep neural networks, the underlying decision making processes for why these models are achieving such performance are challenging and sometimes mystifying to interpret. As deep learning spreads across domains, it is of paramount importance that we equip users of deep learning with tools for understanding when a model works correctly, when it fails, and ultimately how to improve its performance. Standardized toolkits for building neural networks have helped democratize deep learning; visual analytics systems have now been developed to support model explanation, interpretation, debugging, and improvement. We present a survey of the role of visual analytics in deep learning research, which highlights its short yet impactful history and thoroughly summarizes the state-of-the-art using a human-centered interrogative framework, focusing on the Five W's and How (Why, Who, What, How, When, and Where). We conclude by highlighting research directions and open research problems. This survey helps researchers and practitioners in both visual analytics and deep learning to quickly learn key aspects of this young and rapidly growing body of research, whose impact spans a diverse range of domains.},
  keywords={Machine learning;Conferences;Visual analytics;Data visualization;Neural networks;Computational modeling;Deep learning;visual analytics;information visualization;neural networks},
  doi={10.1109/TVCG.2018.2843369},
  ISSN={1941-0506},
  month={Aug},}@INPROCEEDINGS{8591773,
  author={Wickramasinghe, Chathurika S. and Marino, Daniel L. and Amarasinghe, Kasun and Manic, Milos},
  booktitle={IECON 2018 - 44th Annual Conference of the IEEE Industrial Electronics Society}, 
  title={Generalization of Deep Learning for Cyber-Physical System Security: A Survey}, 
  year={2018},
  volume={},
  number={},
  pages={745-751},
  abstract={Cyber-Physical Systems (CPSs)have become ubiquitous in recent years and has become the core of modern critical infrastructure and industrial applications. Therefore, ensuring security is a prime concern. Due to the success of Deep Learning (DL)in a multitude of domains, development of DL based CPS security applications have received increased interest in the past few years. Developing generalized models is critical since the models have to perform well under threats that they havent trained on. However, despite the broad body of work on using DL for ensuring the security of CPSs, to our best knowledge very little work exists where the focus is on the generalization capabilities of these DL applications. In this paper, we intend to provide a concise survey of the regularization methods for DL algorithms used in security-related applications in CPSs and thus could be used to improve the generalization capability of DL based cyber-physical system based security applications. Further, we provide a brief insight into the current challenges and future directions as well.},
  keywords={Neural networks;Malware;Cyber-physical systems;Data models;Generalization;Deep Neural networks;Regularization;Cyber- Physical Systems;Cyber Security},
  doi={10.1109/IECON.2018.8591773},
  ISSN={2577-1647},
  month={Oct},}@ARTICLE{8889699,
  author={Lungu, Iulia Alexandra and Liu, Shih-Chii and Delbruck, Tobi},
  journal={IEEE Journal on Emerging and Selected Topics in Circuits and Systems}, 
  title={Incremental Learning of Hand Symbols Using Event-Based Cameras}, 
  year={2019},
  volume={9},
  number={4},
  pages={690-696},
  abstract={Conventional cameras create redundant output especially when the frame rate is high. Dynamic vision sensors (DVSs), on the other hand, generate asynchronous and sparse brightness change events only when an object in the field of view is in motion. Such event-based output can be processed as a 1D time sequence, or it can be converted to 2D frames that resemble conventional camera frames. Frames created, e.g., by accumulating a fixed number of events, can be used as input for conventional deep learning algorithms, thus upgrading existing computer vision pipelines through low-power, low-redundancy sensors. This paper describes a hand symbol recognition system that can quickly be trained to incrementally learn new symbols recorded with an event-based camera, without forgetting previously learned classes. By using the iCaRL incremental learning algorithm, we show that we can learn up to 16 new symbols using only 4000 samples for each symbol and achieving a final symbol accuracy of over 80%. The system achieves latency of under 0.5s and training requires 3 minutes for 5 epochs on an NVIDIA 1080TI GPU.},
  keywords={Training;Cameras;Deep learning;Convolutional neural networks;Neuromorphics;Neuromorphic;event camera;deep networks;data-driven;incremental learning;robotics;convolutional networks},
  doi={10.1109/JETCAS.2019.2951062},
  ISSN={2156-3365},
  month={Dec},}@INPROCEEDINGS{9774113,
  author={Saleh, Mohammad AlShaikh and Refaat, Shady S. and Khatri, Sunil P. and Ghrayeb, Ali},
  booktitle={2022 3rd International Conference on Smart Grid and Renewable Energy (SGRE)}, 
  title={Detection and Classification of Defects in XLPE Power Cable Insulation via Machine Learning Algorithms}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Due to high electric stresses in power equipment, insulation degradation has been prevalent as a result of increased PD exposure. In this paper, we study different machine learning (ML) methods for the detection and classification of partial discharges (PDs) for assessing the reliability of insulation systems. We introduce and examine a set of features using selected machine learning-based algorithms. The aim is to detect and classify PDs transpiring within insulation systems. Therefore, this paper presents tools to detect defects using suitable PD sensors and Machine Learning algorithms to facilitate diagnostics and enhance isolation system design. Experiments are being conducted on several voids in the insulator with varying shapes and sizes. A PD sensor is used for detecting the PDs taking place. Due to the presence of noise and other external interferences, appropriate filters and denoising methods are implemented. After that, the relevant PD features, such as the PD magnitude, PD repetition rate, statistical features, wavelet features, etc., are extracted. This study attempts to emphasize the importance of classifying the type of defect, as this will allow engineers to determine the severity of the fault taking place, and take the proper countermeasures.},
  keywords={Partial discharges;Support vector machines;Machine learning algorithms;Machine learning;Feature extraction;Sensors;Classification algorithms;Ensemble methods;electromagnetic emissions;feature engineering;Machine Learning;Partial Discharge;Support Vector Machine;Wavelet Decomposition},
  doi={10.1109/SGRE53517.2022.9774113},
  ISSN={},
  month={March},}@INPROCEEDINGS{10633630,
  author={Plesner, Andreas and Vontobel, Tobias and Wattenhofer, Roger},
  booktitle={2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Breaking reCAPTCHAv2}, 
  year={2024},
  volume={},
  number={},
  pages={1047-1056},
  abstract={Our work examines the efficacy of employing advanced machine learning methods to solve captchas from Google's reCAPTCHAv2 system. We evaluate the effectiveness of automated systems in solving captchas by utilizing advanced YOLO models for image segmentation and classification. Our main result is that we can solve 100% of the captchas, while previous work only solved 68–71 %. Furthermore, our findings suggest that there is no significant difference in the number of challenges humans and bots must solve to pass the captchas in reCAPTCHAv2. This implies that current AI technologies can exploit advanced image-based captchas. We also look under the hood of reCAPTCHAv2, and find evidence that reCAPTCHAv2 is heavily based on cookie and browser history data when evaluating whether a user is human or not. The code is provided alongside this paper.11https://github.com/aplesner/Breaking-reCAPTCHAv2},
  keywords={YOLO;Image segmentation;Systematics;Machine learning;Internet;Browsers;History;reCAPTCHAv2;Proof-of-personhood;Machine Learning;Image Classification;Image Segmentation;YOLO;Machine Intelligence},
  doi={10.1109/COMPSAC61105.2024.00142},
  ISSN={2836-3795},
  month={July},}@INPROCEEDINGS{9781144,
  author={Jiang, Jianguo and Li, Boquan and Yu, Shuai and Liu, Chao and An, Shaohua and Liu, Mingqi and Yu, Min},
  booktitle={2021 IEEE 23rd Int Conf on High Performance Computing & Communications; 7th Int Conf on Data Science & Systems; 19th Int Conf on Smart City; 7th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)}, 
  title={A Residual Fingerprint-Based Defense Against Adversarial Deepfakes}, 
  year={2021},
  volume={},
  number={},
  pages={797-804},
  abstract={The authenticity and integrity of digital visual media have always been a crucial branch in the domain of multimedia forensics and information security. Currently, the emerging Deepfakes destroy the authenticity and integrity as well as trump up a person's behaviors that do not exist in reality, which pose potential threats to individual, social and even national security. Although multiple well-designed deep neural networks have achieved satisfactory performance on Deepfake detection, by adding imperceptible but purposeful adversarial perturbations to fake images or videos, the crafted adversarial Deepfakes are demonstrated to cause the malfunction of detectors. In response to such threats, little recent research attempts to take defensive measures but shows scarce applicability, and the effective conventional defenses are insufficient to protect the particular Deepfake detectors. Therefore, to defend against adversarial Deepfakes, we propose a residual fingerprint-based defense customized for Deepfake detectors. By analyzing the impacts of adversarial perturbations on detectors, we construct a reconstruction network, and propose novel strategies to degrade the adversarial efficacy as well as extract discriminative residual fingerprints. Ultimately, we transform the extracted residual fingerprints for Deepfake detection. The evaluation results indicate the performance of compromised detectors is regained by our proposed defense, which is qualified for enhancing the security and reliability of multiple Deepfake detectors.},
  keywords={Visualization;Smart cities;Perturbation methods;Forensics;Neural networks;Detectors;Transforms;multimedia forensics and information security;Deepfake detection;adversarial Deepfakes;residual fingerprints},
  doi={10.1109/HPCC-DSS-SmartCity-DependSys53884.2021.00129},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9986597,
  author={Tan, Wei and Zhao, Jiajia and Liang, Xinkai and Lu, Hanchen and Song, Baogang and Guan, Hao},
  booktitle={2022 IEEE International Conference on Unmanned Systems (ICUS)}, 
  title={Adversarial Example Attack and Defence of Object Recognition: A Survey}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Deep learning-based intelligent object recognition algorithm has been widely applied in object detection, auto driving, ect. However, deep neural network is very vulnerable because of its high-dimensional linearization. The object recognition results can be easily mis-leaded through a tiny disturbance in the original image. This kind of sample that adds tiny disturbance to the original image is called adversarial example. The adversarial example attack is a factor that must be considered in the design of robust object recognition algorithm, that is, the need for adversarial defence. An in-depth understanding of adversarial attack can help the model defend successfully. In this survey, an introduction of adversarial attack and defense aiming to object recognition algorithm at the present stage is summarized, and the challenges to be faced and the development trend in the future are pointed out.},
  keywords={Deep learning;Neural networks;Object detection;Prediction algorithms;Market research;Object recognition;object recognition;deep learning;adversarial attack;adversarial defence},
  doi={10.1109/ICUS55513.2022.9986597},
  ISSN={2771-7372},
  month={Oct},}@INPROCEEDINGS{10575173,
  author={Zilli, Cristian and Sacco, Alessio and Monaco, Doriana and Okafor, Okwudilichukwu and Esposito, Flavio and Marchetto, Guido},
  booktitle={NOMS 2024-2024 IEEE Network Operations and Management Symposium}, 
  title={Inferring Visibility of Internet Traffic Matrices Using eXplainable AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={A large fraction of recent network management tasks rely on Internet traffic matrices, ranging from planning and troubleshooting to routing and anomaly detection. Despite extensive research efforts over the years, acquiring a comprehensive overview of network traffic remains a difficult and error-prone task. While the literature has mostly proposed increasingly accurate and complex Machine Learning (ML) models to reconstruct missing information, in this paper we propose an alternative approach to further enhance this process: combining the ML model with eXplainable AI (XAI) to analyze the model behavior, detect most significant features, and limit the reconstruction process to such reduced input. With this methodology, not only we simplify the problem, but the entire solution finds greater deployability as the data acquisition phase is also simplified. Numerical results demonstrate that, with our solution on a Convolution Neural Network model, the error during completion can be lowered by 80% for a network telemetry traffic reduction of 75%.},
  keywords={Analytical models;Accuracy;Explainable AI;Telecommunication traffic;Routing;Numerical models;Internet},
  doi={10.1109/NOMS59830.2024.10575173},
  ISSN={2374-9709},
  month={May},}@ARTICLE{10807738,
  author={Pohren, Daniel Henrique and dos Santos Roque, Alexandre and de Freitas, Edison Pignaton and Pereira, Carlos Eduardo},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={A HIL Test Approach for Data Generation on CAN Communication Under Disturbance Injections}, 
  year={2025},
  volume={21},
  number={3},
  pages={2729-2737},
  abstract={This article presents a method for generating a dataset from CAN protocol communication using a test bench based on the IEC 62228-2019 standard. Modern automotive embedded systems feature many electronic control units for engine control, ABS, traction control, and power steering. Ensuring reliability and effectiveness, consistent testing, and data analysis are essential. This article proposes a testing approach to verify and record CAN communication under disturbances, using a redundant channel and a fault injection method with specially developed hardware. Different injected noise values were defined based on prior work. A sequence of tests applying the hardware-in-the-loop approach generates valuable preprocessed datasets. The results show that the proposed method records all CAN communication data, producing around 15 million records. This dataset enables detailed analysis of EFT fault propagation in the CAN network from various vehicle noise sources, providing a foundation for future data-driven diagnostic systems development.},
  keywords={Circuit faults;Protocols;Testing;Hardware;Safety;Reliability;Data collection;Automotive engineering;Transient analysis;Interference;Automotive EMC;dataset;data-driven tests;electrical fast transients (EFT);noise modeling and analysis},
  doi={10.1109/TII.2024.3514189},
  ISSN={1941-0050},
  month={March},}@INPROCEEDINGS{10182850,
  author={Raman, Ramakrishnan and Buddhi, Dharam and Gor, Mehul and Ratnavalli, B and Saini, Dimple and Luis Arias Gonzáles, José},
  booktitle={2023 3rd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)}, 
  title={Deep Learning Solution to Various Issues of Finance, A Productive Research Approach}, 
  year={2023},
  volume={},
  number={},
  pages={1020-1025},
  abstract={Natural language processing, audio-visual recognition and computer vision all make extensive use of deep learning. Research is becoming increasingly interested as a result of deep learning's resounding success as a computational tool. Deep learning is being used in financial and banking services as a result of Fintech's recent growth. The extant literature does not, however, provide a comprehensive overview of deep learning's uses in banking and finance. The goal of this study is to give a thorough review of the model preparation, input variables, and model evaluation by reviewing and analyzing the work on the use of deep models in the major financial and banking domains. Last but not least, we go through three factors that could influence how financial deep learning models perform. Insight and recommendations on the state-of-the-art of deep learning models' use in banking and finance are given to academics and practitioners by this study.},
  keywords={Deep learning;Analytical models;Computer vision;Databases;Computational modeling;Input variables;Finance;Natural Language Processing (NLP);Deep Learning;Data Mining;Fintech;k-nearest neighbours (k-NN)},
  doi={10.1109/ICACITE57410.2023.10182850},
  ISSN={},
  month={May},}@INPROCEEDINGS{10698870,
  author={Prayogo, Rizal Dwi and Alfisyahrin, Alvin Rizqi and Gambetta, Windy and Karimah, Siti Amatullah and Nambo, Hidetaka},
  booktitle={2024 International Conference on Information Technology Research and Innovation (ICITRI)}, 
  title={An Explainable Machine Learning-Based Phishing Website Detection using Gradient Boosting}, 
  year={2024},
  volume={},
  number={},
  pages={76-81},
  abstract={As the need for achieving optimal performance in prediction models, several recent and complex models have been developed. However, many of these models operate as black boxes, providing little insight into their predictive results. In recent years, three gradient-boosting methods based on Decision Trees have been recommended, i.e., XGBoost, CatBoost, and LightGBM. These methods have proven to deliver competitive performance with fast training times. Nevertheless, in critical domains like security, there is a growing need for increased transparency among stakeholders. One pressing concern in the security field is the proliferation of phishing websites. To address this issue, we propose an explainable machine learning-based approach using gradient-boosting methods with hyperparameter optimization on three phishing website datasets. Our best methods surpass the state-of-the-art phishing website detection methods, achieving accuracy rates of 97.45%, 99.16%, and $\mathbf{9 7. 8 5 \%}$ for the UCI (2015), Mendeley (2018), and Mendeley (2020) datasets, respectively. Subsequently, we implement posthoc explainability using SHAP and LIME for the selected dataset. The experimental results indicate that three features, i.e., length_url, directory_length, and time_domain_activation, are consistently identified as the most influential features in the dataset. Moreover, our proposed approach demonstrates promising results for detecting phishing websites with both high accuracy and explainability.},
  keywords={Training;Technological innovation;Accuracy;Machine learning algorithms;Phishing;Closed box;Predictive models;Classification algorithms;Security;Tuning;Black-box models;explainable machine learning;gradient-boosting methods;hyperparameter optimization;phishing website detection},
  doi={10.1109/ICITRI62858.2024.10698870},
  ISSN={},
  month={Sep.},}@ARTICLE{10807293,
  author={Shafiq, Muhammad and Ren, Lijing and Srivastava, Gautam and Zhang, Denghui and Bourouis, Sami and Reddy Gadekallu, Thippa},
  journal={IEEE Internet of Things Journal}, 
  title={Building Privacy-Preserving Medical Text Models With a Pretrained Transformer}, 
  year={2025},
  volume={12},
  number={9},
  pages={11529-11538},
  abstract={The rapid advancement of big data and artificial intelligence (AI) in healthcare heightens the urgency for accurate medical text sentiment analysis. The privacy protection of medical data has been a crucial concern due to its sensitivity. The Internet of Medical Things (IoMT) facilitates large-scale data collection at lower cost, enabling precision medicine. However, decentralized IoMT poses novel challenges to centralized standard encryption schemes. In this article, we propose a novel approach to building privacy-preserving sentiment models with a generative pretrained transformer (GPT). We first convert sensitive medical text data into noise-like and distributed one-hot images. Then, we introduce visual cryptography (VC) for lightweight and secure transmission of medical text across public networks in resource-limited IoMT devices. We adopt a cross-domain sentiment analysis framework that finetunes transformer-based language models for accurate sentiment analysis instead of training GPT in sentiment analysis from scratch. Experimental results show that the proposed approach improves the accuracy and effectiveness of sentiment analysis while maintaining privacy, thereby addressing a significant gap in biomedical text analysis.},
  keywords={Biomedical imaging;Sentiment analysis;Encryption;Data privacy;Analytical models;Training;Privacy;Protection;Internet of Things;Data models;GPT;Internet of Medical Things (IoMT);lightweight encryption;medical text;sentiment analysis},
  doi={10.1109/JIOT.2024.3520426},
  ISSN={2327-4662},
  month={May},}@ARTICLE{11017758,
  author={Li, Xinxin and Wang, Zichi and Zhang, Xinpeng},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Black-box Steganography for Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={In recent years, the rapid development of deep learning has brought new opportunities for steganography. However, the current advanced white-box model steganography methods are not suitable for large language models. Since the parameter scale and complexity of large language models are far beyond that of ordinary models, retraining them to hide secret data is extremely challenging. Moreover, the cover parameters or structures of the embedded data are vulnerable to detection by attackers. To enhance practicality, we propose a black-box steganographic scheme for large language models, which embeds secret data into the third-party pre-trained large language models using backdoor techniques without knowing the internal complex structure and parameters of the large language models. Specifically, the sender first encodes the secret data into trigger labels and then uses a certain proportion of trigger samples and clean samples to fine-tune the third-party large language model to embed the secret data without significantly reducing the model performance. The receiver uses trigger samples to extract the secret data by interacting with the large language model, thereby achieving covert communication of the secret data. Experiments demonstrate the effectiveness of the proposed scheme in terms of embedding capacity, robustness, and security.},
  keywords={Steganography;Data models;Watermarking;Data mining;Large language models;Glass box;Transformers;Neural networks;Closed box;Training;Large Language Models;Steganography;Backdoor},
  doi={10.1109/TCSVT.2025.3574808},
  ISSN={1558-2205},
  month={},}@BOOK{10163504,
  author={Palczewski, Tomasz and Lee, Jaejun (Brandon) and Mookiah, Lenin},
  booktitle={Production-Ready Applied Deep Learning: Learn how to construct and deploy complex models in PyTorch and TensorFlow deep learning frameworks},
  year={2022},
  volume={},
  number={},
  pages={},
  abstract={Supercharge your skills for developing powerful deep learning models and distributing them at scale efficiently using cloud servicesKey FeaturesUnderstand how to execute a deep learning project effectively using various tools availableLearn how to develop PyTorch and TensorFlow models at scale using Amazon Web ServicesExplore effective solutions to various difficulties that arise from model deploymentBook DescriptionMachine learning engineers, deep learning specialists, and data engineers encounter various problems when moving deep learning models to a production environment. The main objective of this book is to close the gap between theory and applications by providing a thorough explanation of how to transform various models for deployment and efficiently distribute them with a full understanding of the alternatives. First, you will learn how to construct complex deep learning models in PyTorch and TensorFlow. Next, you will acquire the knowledge you need to transform your models from one framework to the other and learn how to tailor them for specific requirements that deployment environments introduce. The book also provides concrete implementations and associated methodologies that will help you apply the knowledge you gain right away. You will get hands-on experience with commonly used deep learning frameworks and popular cloud services designed for data analytics at scale. Additionally, you will get to grips with the authors’ collective knowledge of deploying hundreds of AI-based services at a large scale. By the end of this book, you will have understood how to convert a model developed for proof of concept into a production-ready application optimized for a particular production setting.What you will learnUnderstand how to develop a deep learning model using PyTorch and TensorFlowConvert a proof-of-concept model into a production-ready applicationDiscover how to set up a deep learning pipeline in an efficient way using AWSExplore different ways to compress a model for various deployment requirementsDevelop Android and iOS applications that run deep learning on mobile devicesMonitor a system with a deep learning model in productionChoose the right system architecture for developing and deploying a modelWho this book is forMachine learning engineers, deep learning specialists, and data scientists will find this book helpful in closing the gap between the theory and application with detailed examples. Beginner-level knowledge in machine learning or software engineering will help you grasp the concepts covered in this book easily.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781803238050},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10163504},}@INBOOK{10528211,
  author={},
  booktitle={Predictive Data Modelling for Biomedical Data and Imaging}, 
  title={7 High-performance Intelligent Systems for Real-time Medical Imaging}, 
  year={2024},
  volume={},
  number={},
  pages={161-188},
  abstract={In this book, we embark on a journey into the realm of predictive data modeling for biomedical data and imaging in healthcare. It explores the potential of predictive analytics in the field of medical science through utilizing various tools and techniques to unravel insights and enhance patient care. This volume creates a medium for an interchange of knowledge from expertise and concerns in the field of predictive data modeling. In detail, the research work on this will include the effective use of predictive data modeling algorithms to run image analysis tasks for understanding. Predictive Data Modelling for Biomedical Data and Imaging is divided into three sections, namely Section I &#x2013; Beginning of Predictive Data Modeling for Biomedical Data and Imaging/Healthcare, Section II &#x2013; Data Design and Analysis for Biomedical Data and Imaging/Healthcare, and Section III &#x2013; Case Studies of Predictive Analytics for Biomedical Data and Imaging/Healthcare. We hope this book will inspire further research and innovation in the field of predictive data modeling for biomedical data and imaging in healthcare. By exploring diverse case studies and methodologies, this book contributes to the advancement of healthcare practices, ultimately improving patient outcomes and well-being.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770040761},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10528211},}@ARTICLE{10887127,
  author={Lippmann, Richard},
  journal={Neural Computation}, 
  title={Understanding and Applying Deep Learning}, 
  year={2023},
  volume={35},
  number={3},
  pages={287-308},
  abstract={The past 10 years have witnessed an explosion in deep learning neural network model development. The most common perceptual models with vision, speech, and text inputs are not general-purpose AI systems but tools. They automatically extract clues from inputs and compute probabilities of class labels. Successful applications require representative training data, an understanding of the limitations and capabilities of deep learning, and careful attention to a complex development process. The goal of this view is to foster an intuitive understanding of convolutional network deep learning models and how to use them with the goal of engaging a wider creative community. A focus is to make it possible for experts in areas such as health, education, poverty, and agriculture to understand the process of deep learning model development so they can help transition effective solutions to practice.},
  keywords={},
  doi={10.1162/neco_a_01518},
  ISSN={0899-7667},
  month={Feb},}@INPROCEEDINGS{11116268,
  author={Hamza, Muhammad and Zaman, Muhammad and Kehkashan, Tanzila and Akbar, Faheem and Munir, Khuzaima and Shehzad, Ahmad},
  booktitle={2024 5th International Conference on Innovative Computing (ICIC)}, 
  title={Enhanced and Interpretable Brain Stroke Detection with High Accuracy using ViT B-16 Model}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Brain stroke is a type of medical emergency that requires prompt and appropriate diagnosis to prevent more brain damage and improve patient outcomes. Standard diagnostic approaches are generally CNN-based but lack interpretability, and still struggle to capture long-range dependencies in medical images, which has limited their application at the clinic. In this study, this challenge was addressed by using the B-16 ViT model for automated stroke detection in the brain. On the other hand, rare details of the subtle spatial relationships are captured very well in scans of the brain and later become useful in looking for faint abnormalities in the spread of strokes across regions. For more confident predictions, CAMs1 are used, thereby visually explaining to the reader which regions of the image influence model decisions on classification. It was found that rigorous evaluation reported over 96% accuracy along with high precision, recall, and F1-score compared with the state-of-the-art CNNbased models. Besides this, transparency is another aspect for which this model is closer to clinical applications, using CAMs. The architecture of this very strong performing and, at the same time, interpretable ViT B-16 model is extremely promising to promote advancement in stroke diagnosis and better patient care in real-world settings.1CAMs are visual explanations that highlight the regions of an image that the model focuses on when making a prediction, helping to improve interpretability.},
  keywords={Computer vision;Accuracy;Computed tomography;Computer architecture;Predictive models;Stroke (medical condition);Brain modeling;Transformers;Cams;Medical diagnostic imaging;Brain Stroke Detection;CAM;Vision Transformer;Medical Image Analysis;Heatmap Visualization},
  doi={10.1109/ICIC63915.2024.11116268},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10913385,
  author={Nugroho, Wahyu Adi and Supriyanto, Catur and Shidik, Guruh Fajar and Pujiono},
  booktitle={2024 International Conference on Intelligent Cybernetics Technology & Applications (ICICyTA)}, 
  title={Modified ReLU in Deep Learning Models and Explainable AI Techniques for Accurate and Interpretable Breast Cancer Subtype Classification}, 
  year={2024},
  volume={},
  number={},
  pages={772-777},
  abstract={Breast cancer is a serious condition that presents a considerable risk to life if not identified in its initial stages. Numerous approaches for identifying breast cancer remain to be performed conventionally through medical examination, which entails limits in accuracy and reliability. Recent technological ad-vancements have led several researchers to create diverse deep-learning methodologies for automated breast cancer diagnosis, particularly convolutional neural network (CNN) models. The main objective of this study is to make the CNN model work better by modifying the rectified linear units (ReLU) activation function to distinguish eight subtypes of breast cancer. Based on the experiment results, the DenseNet201 model with Less-N egativeReLU modified activation function obtained the best performance with accuracy, precision, recall, and F1-score of 96.04 % $(\alpha=0.091)$, “ 96.45 % $(\alpha=0.03)$, 96.04 % $(\alpha=0.09)$, and 96.14% $(\alpha=0.03)$, respectively. The findings demonstrate that the proposed method effectively enhances and optimizes the CNN model performance. This study also employed explainable AI (XAI) techniques to improve the understanding of model prediction results, consequently enhancing clinician's confidence in its implementation. By improving the interpretability of AI-driven predictions, this study aims to support the practical adoption of these models in clinical settings, ultimately contributing to better diagnostic processes and outcomes in breast cancer care.},
  keywords={Deep learning;Measurement;Accuracy;Explainable AI;Neurons;Predictive models;Breast cancer;Convolutional neural networks;Reliability;Medical diagnostic imaging;breast cancer;convolutional neural network;deep learning;explainable AI;modified ReLU},
  doi={10.1109/ICICYTA64807.2024.10913385},
  ISSN={},
  month={Dec},}@ARTICLE{10444954,
  author={Wang, Liyuan and Zhang, Xingxing and Su, Hang and Zhu, Jun},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={A Comprehensive Survey of Continual Learning: Theory, Method and Application}, 
  year={2024},
  volume={46},
  number={8},
  pages={5362-5383},
  abstract={To cope with real-world dynamics, an intelligent system needs to incrementally acquire, update, accumulate, and exploit knowledge throughout its lifetime. This ability, known as continual learning, provides a foundation for AI systems to develop themselves adaptively. In a general sense, continual learning is explicitly limited by catastrophic forgetting, where learning a new task usually results in a dramatic performance drop of the old tasks. Beyond this, increasingly numerous advances have emerged in recent years that largely extend the understanding and application of continual learning. The growing and widespread interest in this direction demonstrates its realistic significance as well as complexity. In this work, we present a comprehensive survey of continual learning, seeking to bridge the basic settings, theoretical foundations, representative methods, and practical applications. Based on existing theoretical and empirical results, we summarize the general objectives of continual learning as ensuring a proper stability-plasticity trade-off and an adequate intra/inter-task generalizability in the context of resource efficiency. Then we provide a state-of-the-art and elaborated taxonomy, extensively analyzing how representative strategies address continual learning, and how they are adapted to particular challenges in various applications. Through an in-depth discussion of promising directions, we believe that such a holistic perspective can greatly facilitate subsequent exploration in this field and beyond.},
  keywords={Task analysis;Training;Surveys;Testing;Complexity theory;Stability analysis;Visualization;Continual learning;incremental learning;lifelong learning;catastrophic forgetting},
  doi={10.1109/TPAMI.2024.3367329},
  ISSN={1939-3539},
  month={Aug},}@ARTICLE{9531456,
  author={Niu, Yuhao and Gu, Lin and Zhao, Yitian and Lu, Feng},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Explainable Diabetic Retinopathy Detection and Retinal Image Generation}, 
  year={2022},
  volume={26},
  number={1},
  pages={44-55},
  abstract={Though deep learning has shown successful performance in classifying the label and severity stage of certain diseases, most of them give few explanations on how to make predictions. Inspired by Koch's Postulates, the foundation in evidence-based medicine (EBM) to identify the pathogen, we propose to exploit the interpretability of deep learning application in medical diagnosis. By isolating neuron activation patterns from a diabetic retinopathy (DR) detector and visualizing them, we can determine the symptoms that the DR detector identifies as evidence to make prediction. To be specific, we first define novel pathological descriptors using activated neurons of the DR detector to encode both spatial and appearance information of lesions. Then, to visualize the symptom encoded in the descriptor, we propose Patho-GAN, a new network to synthesize medically plausible retinal images. By manipulating these descriptors, we could even arbitrarily control the position, quantity, and categories of generated lesions. We also show that our synthesized images carry the symptoms directly related to diabetic retinopathy diagnosis. Our generated images are both qualitatively and quantitatively superior to the ones by previous methods. Besides, compared to existing methods that take hours to generate an image, our second level speed endows the potential to be an effective solution for data augmentation.},
  keywords={Lesions;Neurons;Diabetes;Pathology;Pathogens;Retinopathy;Medical diagnostic imaging;Interpretable deep learning;explainable artificial intelligence;medical image analysis;medical image generation;generative adversarial network},
  doi={10.1109/JBHI.2021.3110593},
  ISSN={2168-2208},
  month={Jan},}@ARTICLE{9661397,
  author={Mameli, Marco and Paolanti, Marina and Pietrini, Rocco and Pazzaglia, Giulia and Frontoni, Emanuele and Zingaretti, Primo},
  journal={IEEE Access}, 
  title={Deep Learning Approaches for Fashion Knowledge Extraction From Social Media: A Review}, 
  year={2022},
  volume={10},
  number={},
  pages={1545-1576},
  abstract={Fashion knowledge encourages people to properly dress and faces not only physiological necessity of users, but also the requirement of social practices and activities. It usually includes three jointly related aspects of: occasion, person and clothing. Nowadays, social media platforms allow users to interact with each other online to share opinions and information. The use of social media sites such as Instagram has already spread to almost every fashion brand and been evaluated as business take-off tools. With the heightened use of social media as a means of marketing communication for fashion brands, it has become necessary to empirically analyse and extract fashion knowledge from them. Thus, social brands are investing on them. In this way, they can understand the consumer’s preferences. This change is also having a significant impact on social media data analysis. To solve this issue, the Deep learning (DL) methods are proven to be effective solutions due to their automatic learning capability. However, little systematic work currently exists on how researchers have applied DL for analysing fashion knowledge from social media data. Hence, this contribution outlines DL-based techniques for social media data related to fashion domain. In this study, a review of the dataset within the fashion world and the DL methods applied on, it is presented to help out new researchers interested in this subject. In particular, five different tasks will be considered: Object Detection, that includes Clothes Landmark Detection, Clothes Parsing and Product Retrieval, Fashion Classification, Clothes Generation, Automatic Fashion Knowledge Extraction and Clothes Recommendation. Therefore, the purpose of this paper is to underline the multiple applications within the fashion world using deep learning techniques. However, this review does not cover all the methods used: in fact, only Deep Learning methods have been analyzed. This choice was made since, given the huge amount of fashion social media data that has been collected, Deep Learning methods achieve the best performance both in terms of accuracy and time. Limitations point towards unexplored areas for future investigations, serving as useful guidelines for future research directions.},
  keywords={Social networking (online);Deep learning;Multimedia Web sites;Task analysis;Object detection;Electronic commerce;Systematics;Artificial intelligence;machine learning;deep learning;fashion;neural networks;object detection;object parsing;product retrieval;clothes classification;fashion recommendation;fashion datasets;generative adversarial networks;social media},
  doi={10.1109/ACCESS.2021.3137893},
  ISSN={2169-3536},
  month={},}@ARTICLE{10313059,
  author={Peck, Jonathan and Goossens, Bart and Saeys, Yvan},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={An Introduction to Adversarially Robust Deep Learning}, 
  year={2024},
  volume={46},
  number={4},
  pages={2071-2090},
  abstract={The widespread success of deep learning in solving machine learning problems has fueled its adoption in many fields, from speech recognition to drug discovery and medical imaging. However, deep learning systems are extremely fragile: imperceptibly small modifications to their input data can cause the models to produce erroneous output. It is very easy to generate such adversarial perturbations even for state-of-the-art models, yet immunization against them has proven exceptionally challenging. Despite over a decade of research on this problem, our solutions are still far from satisfactory and many open problems remain. In this work, we survey some of the most important contributions in the field of adversarial robustness. We pay particular attention to the reasons why past attempts at improving robustness have been insufficient, and we identify several promising areas for future research.},
  keywords={Perturbation methods;Deep learning;Surveys;Robustness;Mathematical models;Image recognition;Predictive models;Adversarial machine learning;computer vision;deep learning},
  doi={10.1109/TPAMI.2023.3331087},
  ISSN={1939-3539},
  month={April},}@ARTICLE{10122886,
  author={Song, Di and Shen, Junxian and Ma, Tianchi and Xu, Feiyun},
  journal={IEEE Sensors Journal}, 
  title={Acoustic Sensor Placement Optimization for Compressor Based on Adversarial Transfer Learning and Vibro-Acoustic Simulation}, 
  year={2023},
  volume={23},
  number={12},
  pages={13539-13547},
  abstract={Generally, the success of the optimal sensor placement (OSP) method based on artificial intelligence (AI) highly depends on signals at all feasible placements, which may be unavailable or expensive. Therefore, the acoustic sensor placement optimization method is proposed based on adversarial transfer learning (ATL) and vibro-acoustic simulation. First, the vibro-acoustic simulation is applied to provide sufficient simulation signals for all feasible placements. To bridge the deviation of simulation and measured signals, the ATL-based conditional generative adversarial network (CGAN) is presented, which can transfer signals from limited measured placements to unmeasured placements. In addition, a multi-objective optimization model is proposed to obtain the OSP from three aspects, and it is useful for structural health monitoring (SHM). The acoustic signals obtained from the experimental platform are utilized to explore the feasibility and effectiveness of the proposed method. It can accurately detect the fault with an average accuracy of 98.35% under four working conditions. The comparison investigations demonstrate that the proposed method can obtain high-quality signals at all feasible placements, which can realize SHM with the OSPs and the least sensor cost.},
  keywords={Acoustic sensors;Data models;Acoustics;Acoustic measurements;Sensors;Load modeling;Blades;Adversarial transfer learning (ATL);conditional generative adversarial network (CGAN);optimal sensor placement (OSP);structural health monitoring (SHM);vibro-acoustic simulation},
  doi={10.1109/JSEN.2023.3273464},
  ISSN={1558-1748},
  month={June},}@ARTICLE{11091495,
  author={Cao, Zi-Han and Liang, Yu-Jie and Deng, Liang-Jian and Vivone, Gemine},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={An Efficient Image Fusion Network Exploiting Unifying Language and Mask Guidance}, 
  year={2025},
  volume={},
  number={},
  pages={1-18},
  abstract={Image fusion aims to merge image pairs collected by different sensors over the same scene, preserving their distinct features. Recent works have often focused on designing various image fusion losses, developing different network architectures, and leveraging downstream tasks (e.g., object detection) for image fusion. However, a few studies have explored how language and semantic masks can serve as guidance to aid image fusion. In this paper, we investigate how the combination of language and masks can guide image fusion tasks, discarding the previously complex frameworks, which rely on downstream tasks, GAN-based cycle training, diffusion models, or deep image priors. Additionally, we exploit a recurrent neural network-like architecture to build a lightweight network that avoids the quadratic-cost of traditional attention mechanisms. To adapt the receptance weighted key value (RWKV) model to an image modality, we modify it into a bidirectional version using an efficient scanning strategy (ESS). To guide image fusion by language and mask features, we introduce a multi-modal fusion module (MFM) to facilitate information exchange. Comprehensive experiments show that the proposed framework achieved state-of-the-art results in various image fusion tasks (i.e., visible-infrared image fusion, multi-focus image fusion, multi-exposure image fusion, medical image fusion, hyperspectral and multispectral image fusion, and pansharpening). Code will be available at https://github.com/294coder/RWKVFusion.},
  keywords={Image fusion;Training;Semantics;Windows;Flowering plants;Diffusion models;Pansharpening;Image sensors;Object detection;Magnetic resonance imaging;Multi-modal guided image fusion;efficient network;attention;image fusion;pansharpening;remote sensing;deep learning},
  doi={10.1109/TPAMI.2025.3591930},
  ISSN={1939-3539},
  month={},}@INPROCEEDINGS{9927944,
  author={Wang, Xiansheng and Yan, Ke},
  booktitle={2022 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)}, 
  title={Fault Detection and Diagnosis of HVAC System Based on Federated Learning}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Automation and accurate fault detection and diagnosis of heating, ventilation, and air conditioning (HVAC) systems are among the most important technologies for reducing time, energy, and financial costs in the field of intelligent industrial facility maintenance. Convolutional neural networks have been widely used in various fields for prediction and classification problems because of their excellent feature extraction ability and potent portability. In this study, we develop a Federated Learning-based CNN model (Fed_CNN), which utilizes multiparty data for multi-scale joint modeling to deal with the fault detection and diagnosis of HVAC systems. Our proposed Fed_CNN model can simultaneously detect and diagnose multilevel faults of chillers, and the fault detection and diagnosis effect of each level exceed 0.9. The Fed_CNN model can also perform cross-domain fault detection and diagnosis for chiller and AHU. A series of comparative experimental results show that the proposed custom federated learning framework outperforms most existing fault detection and diagnosis methods for HVAC systems.},
  keywords={HVAC;Federated learning;Fault detection;Ventilation;Data models;Solar system;Internet of Things;Deep Learning;Federated Learning;HVAC Systems;Fault Detection and Diagnosis},
  doi={10.1109/DASC/PiCom/CBDCom/Cy55231.2022.9927944},
  ISSN={},
  month={Sep.},}@ARTICLE{10520832,
  author={Yuan, Bo and Zhao, Danpei and Shi, Zhenwei},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Learning at a Glance: Towards Interpretable Data-Limited Continual Semantic Segmentation via Semantic-Invariance Modelling}, 
  year={2024},
  volume={46},
  number={12},
  pages={7909-7923},
  abstract={Continual semantic segmentation (CSS) based on incremental learning (IL) is a great endeavour in developing human-like segmentation models. However, current CSS approaches encounter challenges in the trade-off between preserving old knowledge and learning new ones, where they still need large-scale annotated data for incremental training and lack interpretability. In this paper, we present Learning at a Glance (LAG), an efficient, robust, human-like and interpretable approach for CSS. Specifically, LAG is a simple and model-agnostic architecture, yet it achieves competitive CSS efficiency with limited incremental data. Inspired by human-like recognition patterns, we propose a semantic-invariance modelling approach via semantic features decoupling that simultaneously reconciles solid knowledge inheritance and new-term learning. Concretely, the proposed decoupling manner includes two ways, i.e., channel-wise decoupling and spatial-level neuron-relevant semantic consistency. Our approach preserves semantic-invariant knowledge as solid prototypes to alleviate catastrophic forgetting, while also constraining sample-specific contents through an asymmetric contrastive learning method to enhance model robustness during IL steps. Experimental results in multiple datasets validate the effectiveness of the proposed method. Furthermore, we introduce a novel CSS protocol that better reflects realistic data-limited CSS settings, and LAG achieves superior performance under multiple data-limited conditions.},
  keywords={Semantics;Data models;Task analysis;Training;Semantic segmentation;Computational modeling;Solids;Continual semantic segmentation;incremental learning;limited data;interpretability;disentangled distillation},
  doi={10.1109/TPAMI.2024.3396809},
  ISSN={1939-3539},
  month={Dec},}@ARTICLE{10623292,
  author={Skocaj, Marco and Amorosa, Lorenzo Mario and Lombardi, Michele and Verdone, Roberto},
  journal={IEEE Transactions on Mobile Computing}, 
  title={GUMBLE: Uncertainty-Aware Conditional Mobile Data Generation Using Bayesian Learning}, 
  year={2024},
  volume={23},
  number={12},
  pages={13158-13171},
  abstract={In the context of mobile and Internet of Things (IoT) networks, data naturally originates at the edge, making crowdsourcing a convenient and inherent approach to data collection. However, crowdsourcing presents challenges related to privacy, sampling bias, statistical sufficiency, and the need for time-consuming post-processing. To this end, generating synthetic data using deep learning techniques emerges as a promising solution to overcome such limitations. In this study, we propose an innovative framework that transcends applications and data types, enabling the conditional generation of crowdsourced datasets with location information in mobile and IoT networks. A crucial aspect of our methodology lies in the ability to assess uncertainty in newly generated samples and produce calibrated predictions through approximate Bayesian methods. Without loss of generality, we ascertain the validity of our method on the task of minimization of drive test (MDT) data generation, presenting for the first time a comparison of synthetically generated data with an original large-scale MDT set collected from a mobile network operator's network infrastructure. By offering a versatile solution to data generation, our framework contributes to overcoming challenges associated with crowdsourced data, opening up possibilities for advanced analytics and experimentation in mobile and IoT networks.},
  keywords={Crowdsourcing;Task analysis;Bayes methods;Mobile computing;Data collection;Uncertainty;Synthetic data;Generative artificial intelligence;Bayesian learning;minimization of drive test data;crowdsourcing;mobile networks;Internet of Things},
  doi={10.1109/TMC.2024.3438208},
  ISSN={1558-0660},
  month={Dec},}@INPROCEEDINGS{10746985,
  author={Bdair, Tariq and Saadeh, Hiba and Qaqish, Ban and Sulaq, Aya and Rawashdeh, Majdi},
  booktitle={2024 Fifth International Conference on Intelligent Data Science Technologies and Applications (IDSTA)}, 
  title={Medical Image-to-Image Translation with Spatial Self-Attention for Radiotherapy in Federated Learning}, 
  year={2024},
  volume={},
  number={},
  pages={103-110},
  abstract={Globally, cancer remains a leading cause of death, affecting millions of people each year. Accurate medical imaging is crucial for the effective planning of radiotherapy. However, repeated exposure to radiation from Computed Tomography (CT) scans during treatment planning can put patients at more risk. Fortunately, the recent improvement in automated image-to-image translation using deep learning methods has reached a superior performance. However, this might be challenged by data limitation of requiring a large amount of annotated data assembled in one location, privacy, and motion artifacts in medical imaging. Yet, finding such conditions usually is not feasible. To address this, we propose RadiaSync. RadiaSync is a federated learning framework proposed to train decentralized models in a privacy-preserved fashion. In our method, we use CycleGAN architecture for image translation within an FL environment, ensuring patient privacy and collaborative learning across different clients. Further, we propose a spatial attention mechanism that enhances the translated image quality with more than 55% improvement over the baseline.},
  keywords={Image quality;Deep learning;Privacy;Federated learning;Computed tomography;Data science;Radiation therapy;Planning;Biomedical imaging;Motion artifacts;Federated Learning;Radiotherapy;MRI-to-CT Translation;CycleGAN;Deep Learning;Spatial Self-Attention;Artificial Intelligence in Healthcare;Generative Adversarial Networks},
  doi={10.1109/IDSTA62194.2024.10746985},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10932572,
  author={Singh, Ajay Pal and Nigam, Ankita and Kumar, Vinod},
  booktitle={2025 2nd International Conference on Computational Intelligence, Communication Technology and Networking (CICTN)}, 
  title={An Analysis of Deep Learning Algorithms for Detection of Pulmonary Illness}, 
  year={2025},
  volume={},
  number={},
  pages={349-354},
  abstract={The necessity for highly precise and rapid methods of diagnosis is highlighted by the important role that pulmonary illnesses make to the global health burden. Enhancing diagnostic accuracy and speeding up detection through the use of algorithms that use deep learning presents a substantial opportunity for better patient outcomes and more efficient healthcare procedures. In proposed article, the authors provide the special technique for recognizing pulmonary illnesses from medical imaging data by using deep learning algorithms. We offer a thorough method that integrates CNNs with additional deep learning methods to diagnose diseases with high accuracy. Through a detailed literature review, we highlight the existing research in this domain and identify gaps and challenges. We discuss the methodology, techniques employed, challenges encountered, and potential future directions. The author’s findings show how well the suggested method works to identify pulmonary diseases, finding the exact path for enhanced diagnostic systems in healthcare. Our study demonstrates algorithms in pulmonary disease detection, outperforming traditional methods, ensuring robustness across diverse datasets, and offering clinical utility with interpretability insights.},
  keywords={Deep learning;Accuracy;Protocols;Pulmonary diseases;Lungs;Neural networks;Medical services;Robustness;Medical diagnostic imaging;Systematic literature review;Convolutional neural networks;medical imaging;CT scan;Diagnostic Methods for Pulmonary Diseases Disease detection},
  doi={10.1109/CICTN64563.2025.10932572},
  ISSN={},
  month={Feb},}@ARTICLE{11124327,
  author={Lu, Liying and Achddou, Raphael and Susstrunk, Sabine},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Dark Noise Diffusion: Noise Synthesis for Low-Light Image Denoising}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={Low-light photography produces images with low signal-to-noise ratios due to limited photons. In such conditions, common approximations like the Gaussian noise model fall short, and many denoising techniques fail to remove noise effectively. Although deep-learning methods perform well, they require large datasets of paired images that are impractical to acquire. As a remedy, synthesizing realistic low-light noise has gained significant attention. In this paper, we investigate the ability of diffusion models to capture the complex distribution of low-light noise. We show that a naive application of conventional diffusion models is inadequate for this task and propose three key adaptations that enable high-precision noise generation: a two-branch architecture to better model signal-dependent and signal-independent noise, the incorporation of positional information to capture fixed-pattern noise, and a tailored diffusion noise schedule. Consequently, our model enables the generation of large datasets for training low-light denoising networks, leading to state-of-the-art performance. Through comprehensive analysis, including statistical evaluation and noise decomposition, we provide deeper insights into the characteristics of the generated data.},
  keywords={Noise;Noise measurement;Diffusion models;Training;Noise reduction;Photonics;Cameras;Image denoising;Data models;Computational modeling;Computational Photography;Low-light Imaging;Image Denoising;Diffusion Models},
  doi={10.1109/TPAMI.2025.3598330},
  ISSN={1939-3539},
  month={},}@INPROCEEDINGS{11042140,
  author={Singh, Nongmeikapam Thoiba and Goyal, Shefali and Rajput, Pragya and Malhotra, Sumit and Kumari, Navjot and Wadhwa, Manoj},
  booktitle={2025 Third International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)}, 
  title={Deep Learning-Powered Resilience for Stability in Financial Networks using Anomaly Detection and Predictive Analytics}, 
  year={2025},
  volume={},
  number={},
  pages={417-422},
  abstract={Network resilience is crucial for the financial industry to maintain services and avoid expensive inefficiency in a time when financial networks are becoming more and more susceptible to interruption. To improve network resilience in finance, this study introduces a deep learning technique and extracts applications of hybrid deep learning models. The model uses network traffic statistics, historical transaction records, and RNNs for failure prediction, CNNs for anomaly detection, and RL for self-healing to reduce interruptions and speed up recovery times. The model utilizes real-world data results to showcase significant advancements that enhance its effectiveness for financial networks. It achieves accuracy in fraud detection and anomaly identification, with an overall precision of 92% and recall of 89%. These promising advances in deep learning techniques will not only make financial networks more resilient and anomaly-free but also pave the way for future innovations in a secure and dependable financial system.},
  keywords={Deep learning;Technological innovation;Telecommunication traffic;Reinforcement learning;Predictive models;Stability analysis;Fraud;Predictive analytics;Anomaly detection;Resilience;network resilience;deep learning;financial networks;failure prediction;anomaly detection;reinforcement learning},
  doi={10.1109/ICAISS61471.2025.11042140},
  ISSN={},
  month={May},}@ARTICLE{11045306,
  author={Hao, Xinghui and Zhang, Qinyu and Xue, Tao and Bai, Yunjie and Yang, Aimin},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Green Transportation Development Optimization Based on G2-HGNN Multiple Traffic States}, 
  year={2025},
  volume={},
  number={},
  pages={1-14},
  abstract={In intelligent transportation systems (ITSs), the collaborative optimization of multimodal traffic data is the core support for improving the efficiency of urban green travel. However, due to the dual contradictions of surging travel demand and resource mismatch faced by the green transportation system, traditional methods are difficult to effectively analyze the heterogeneous associations of multimodal traffic data. Compared with existing methods, the distribution of shared single spatiotemporal data is dynamically unbalanced, and the interactive modeling of multi-modal traffic states lacks dynamic topological adaptive modeling capabilities. To solve this problem, this paper proposes a G2-HGNN framework (GAN-GBC-Hypergraph Neural Network), which integrates the OD matrix of shared bicycles, online car-hailing, and buses and subways into a multi-modal traffic state hypergraph, and constructs a dynamic hypergraph with dual-domain coupling of time and space for traffic state prediction and optimization. Firstly, the spatiotemporal distribution of orders from multiple transportation parties is analyzed, and the GAN network is used to solve the problem of dynamic imbalance of shared bicycles. Secondly, the granular ball computing classifier (GBC) is used to construct feature hyperedges, and a multivariate traffic state graph of traffic mode distribution is constructed. The dynamic G2-HGNN framework is constructed to model the high-order relationships of the hypergraph and dynamically embed nodes. The traffic state prediction optimization is performed through the joint optimization mechanism of hypergraph convolution and topology perception. Finally, it is verified in two travel mode datasets of bimodal (working days) and scattered (rest days) in Luohu District, Shenzhen. Comprehensive experiments show that compared with other benchmark methods, the prediction accuracy, F1-Score, recall rate and precision of the scheme in green transportation planning reach 88.71%, 92.51%, 97.32% and 88.16% respectively, which reflects the superior performance of G2-HGNN in actual traffic planning tasks and provides data and modeling support for future urban transportation development planning.},
  keywords={Transportation;Bicycles;Public transportation;Planning;Data models;Green transportation;Computational modeling;Optimization;Big Data;Green products;Green travel system;traffic spatio-temporal data;generative artificial intelligence;hypergraph neural network;granular sphere computational classifier;ternary traffic state},
  doi={10.1109/TITS.2025.3573125},
  ISSN={1558-0016},
  month={},}@ARTICLE{11091585,
  author={Wang, Chengjie and Zhu, Haokun and Peng, Jinlong and Wang, Yue and Yi, Ran and Wu, Yunsheng and Ma, Lizhuang and Zhang, Jiangning},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={M3DM-NR: RGB-3D Noisy-Resistant Industrial Anomaly Detection via Multimodal Denoising}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={Existing industrial anomaly detection methods primarily concentrate on unsupervised learning with pristine RGB images. Yet, both RGB and 3D data are crucial for anomaly detection, and the datasets are seldom completely clean in practical scenarios. To address above challenges, this paper initially delves into the RGB-3D multi-modal noisy anomaly detection, proposing a novel noise-resistant M3DM-NR framework to leveraging strong multi-modal discriminative capabilities of CLIP. M3DM-NR consists of three stages: Stage-I introduces the Suspected References Selection module to filter a few normal samples from the training dataset, using the multimodal features extracted by the Initial Feature Extraction, and a Suspected Anomaly Map Computation module to generate a suspected anomaly map to focus on abnormal regions as reference. Stage-II uses the suspected anomaly maps of the reference samples as reference, and inputs image, point cloud, and text information to achieve denoising of the training samples through intra-modal comparison and multi-scale aggregation operations. Finally, Stage-III proposes the Point Feature Alignment, Unsupervised Feature Fusion, Noise Discriminative Coreset Selection, and Decision Layer Fusion modules to learn the pattern of the training dataset, enabling anomaly detection and segmentation while filtering out noise. Extensive experiments show that M3DM-NR outperforms state-of-the-art methods in 3D-RGB multi-modal noisy anomaly detection.},
  keywords={Anomaly detection;Feature extraction;Noise measurement;Three-dimensional displays;Training;Noise;Image reconstruction;Noise reduction;Point cloud compression;Solid modeling;Anomaly Detection;Multi-modal Learning;Noisy Learning;Unsupervised Learning},
  doi={10.1109/TPAMI.2025.3592089},
  ISSN={1939-3539},
  month={},}@INPROCEEDINGS{11135143,
  author={Kaushal, Anukriti and Parihar, Yogesh and Tomar, Vatan and Yadav, Uttam Kumar},
  booktitle={2025 6th International Conference on Data Intelligence and Cognitive Informatics (ICDICI)}, 
  title={Study on Deepfake Detection Techniques: Challenges, Limitations and Future Directions}, 
  year={2025},
  volume={},
  number={},
  pages={40-48},
  abstract={As AI-generated content such as deepfakes continue to evolve, it will become increasingly important to figure out what is real and what is fake. The current deepfake detection techniques, challenges and limitations are studied in this paper. We look at how DL models like CNNs and transformers have been used and their accuracy and effectiveness on various datasets. Nonetheless, the existing literature is wanting in robust generalizability across deepfake types and real-world applications. Our work identifies this gap and suggests areas to improve detection accuracy through hybrid schemes, algorithm advancement, and multi-modal analysis. The growing threat of deepfakes in misinformation, fraud, and security motivates the research. In the end, the paper talks about future policies and the need for establishing benchmark validation frameworks.},
  keywords={Measurement;Deepfakes;Accuracy;Protocols;Explainable AI;Benchmark testing;Transformers;Real-time systems;Security;Reliability;Deepfake;GAN;Deepfake Detection;Challenges;Reliability;Detection Algorithms;Media Forensics},
  doi={10.1109/ICDICI66477.2025.11135143},
  ISSN={},
  month={July},}@ARTICLE{11106759,
  author={Wu, Zizhang and Song, Fan and Gan, Yuanzhu and Wu, Yunzhe and Xu, Tianhao and Wang, Xiaoquan and Tang, Rui and Pu, Jian},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Advancing 3D Object Detection with Depth-aware Spatial Knowledge Distillation}, 
  year={2025},
  volume={},
  number={},
  pages={1-16},
  abstract={Accurate 3D object detection from images can be hindered by inherent depth ambiguity. While knowledge distillation (KD) from privileged sensors such as LiDAR offers a promising direction, it often suffers from a critical cross-sensor domain gap. To address this, we introduce DK3D, a novel depth-aware knowledge distillation framework for 3D detection. Our core strategy involves providing the teacher with privileged ground-truth depth during training. This directly avoids the feature representation mismatch and subsequent inefficient knowledge transfer required when distilling from a LiDAR teacher (sparse, geometric) to a camera-based student (dense, semantic). DK3D introduces specialized modules tailored for two primary student paradigms. For depth-assisted models, we employ a channel-wise projection layer (CPL) and an adversarial scoring block (ASB) to align intermediate features at both the pixel and distribution levels. For depth-independent models, a novel vision-depth association module allows the student to implicitly reason about geometry by fusing depth cues with visual features. Both approaches are further enhanced by target-aware spatial response distillation, which captures complex inter-object spatial relationships. Extensive experiments on the KITTI and nuScenes benchmarks demonstrate that DK3D significantly improves performance for both monocular and multi-view 3D detection, outperforming state-of-the-art methods. As a versatile, plug-and-play framework, DK3D boosts existing models without requiring additional training data or increasing the computational cost at inference.},
  keywords={Three-dimensional displays;Object detection;Laser radar;Depth measurement;Training;Feature extraction;Sensors;Solid modeling;Semantics;Knowledge engineering;Monocular 3D Detection;Knowledge Distillation;Privileged Learning},
  doi={10.1109/TPAMI.2025.3594805},
  ISSN={1939-3539},
  month={},}
