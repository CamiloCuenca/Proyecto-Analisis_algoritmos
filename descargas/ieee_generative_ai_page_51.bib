@ARTICLE{11036777,
  author={Leranso Betalo, Mesfin and Ullah, Inam and Berhanu Tesema, Fiseha and Wu, Zongze and Li, Jianqiang and Bai, Xiaoshan},
  journal={IEEE Internet of Things Journal}, 
  title={Generative AI-Driven Multiagent DRL for Task Allocation in UAV-Assisted EMPD Within 6G-Enabled SAGIN Networks}, 
  year={2025},
  volume={12},
  number={17},
  pages={35890-35907},
  abstract={The Internet of Health Monitoring (IoHM) plays a vital role in emergency medical package delivery (EMPD) by enabling real-time monitoring and transmission of critical health data through interconnected devices in 6G networks. Autonomous aerial vehicles (UAVs) act as aerial base stations (ABSs), facilitating data collection and transmission between GAI-IoHM devices and edge servers. This is crucial for efficient communication in 6G-enabled space-air–ground integrated networks (SAGINs). However, UAVs supporting EMPD face challenges related to limited energy and computational capacity, especially during task offloading to edge servers. To address these constraints, this article proposes the integration of generative artificial intelligence (GAI) into UAVs for intelligent policy learning, enabling adaptive decision-making, real-time diagnostics, and efficient path planning under uncertainty. We present a novel multiagent deep reinforcement learning (MADRL)-based joint optimization framework for cooperative task allocation, trajectory planning, and power management (CTATP) in a 6G-enabled SAGIN architecture. The problem is modeled as a partially observable markov decision process (POMDP) to capture dynamic and uncertain operational conditions. To solve this, we introduce the GAI-based deep deterministic double policy gradient (GAI-DD3PG) algorithm, which leverages a generative actor-network to learn adaptive, energy-efficient control policies from latent action spaces. Simulations in urban emergency scenarios with 10–20 UAVs demonstrate GAI-DD3PG’s efficacy. Compared to proximal policy optimization (PPO), deep deterministic policy gradient (DDPG), multiagent federated reinforcement learning (MAFRL), and Greedy heuristics, GAI-DD3PG achieves a 20% energy reduction, 15% higher delivery success rate, 25% shorter trajectories, and 30% improved resource utilization. These results highlight its potential for reliable EMPD in complex 6G SAGIN environments.},
  keywords={Resource management;6G mobile communication;Autonomous aerial vehicles;Real-time systems;Wireless sensor networks;Reliability;Energy efficiency;Adaptation models;Space-air-ground integrated networks;Optimization;Energy-efficient autonomous aerial vehicle (UAV) operation;generative artificial intelligence (GAI);multiagent deep reinforcement learning (MADRL);power optimization;space-air–ground integrated network;trajectory},
  doi={10.1109/JIOT.2025.3579780},
  ISSN={2327-4662},
  month={Sep.},}@INPROCEEDINGS{10337941,
  author={Fu, L. and Qu, Q. and Guo, X. and Shi, X. and Tian, J. and Hu, Z.},
  booktitle={2023 IEEE Nuclear Science Symposium, Medical Imaging Conference and International Symposium on Room-Temperature Semiconductor Detectors (NSS MIC RTSD)}, 
  title={Deep Learning-Based High Resolution Imaging in the Second Near-Infrared Window}, 
  year={2023},
  volume={},
  number={},
  pages={1-1},
  abstract={Molecular imaging technology of the second near-infrared window (NIR-II) performs well in biological imaging with high sensitivity. In clinical practice, the Food and Drug Administration (FDA) approved fluorescent dye indocyanine green (ICG) has week emission light in NIR-II window and can be used for imaging in a shorter wavelength of NIR-II (1000-1300nm), but imaging in this window is affected by light scattering and autofluorescence, resulting in low imaging resolution. In response to the clinical need for precision imaging, a NIR-II fluorescence imaging method based on cyclic domain conversion generative adversarial network is constructed for resolution enhancement. The proposed method enables single-domain feature extraction and cross-domain feature fusion by using a cyclic training scheme. Moreover, the minimization of Gram matrix difference is introduced to keep texture information while improving the image resolution. Fluorescent images in the shorter wavelength of NIR-II can be converted into high-resolution fluorescent images with imaging characteristics of the longer wavelength of NIR-II (1500-1700 nm). Experimental results show that vascular imaging with proposed method can delineate vasovagal patterns, and enhanced neural imaging can guide the implementation of nerve sparing surgery, which is of great significance to clinical decision-making and practice.},
  keywords={Training;Molecular imaging;Microwave integrated circuits;Sensitivity;Semiconductor detectors;Imaging;Surgery},
  doi={10.1109/NSSMICRTSD49126.2023.10337941},
  ISSN={2577-0829},
  month={Nov},}@INBOOK{10614286,
  author={Ojanperä, Tero},
  booktitle={AI Revolution: Mastering AI for Personal and Organizational Growth}, 
  title={6 Intelligent Robots to Our Aid}, 
  year={2024},
  volume={},
  number={},
  pages={101-106},
  abstract={"The AI Revolution" is a practical guide to using new AI tools, such as ChatGPT, DALLE and Midjourney. Learn how to multiply your productivity by guiding or prompting AI in various ways. The book also introduces Microsoft Copilot, Google Bard, and Adobe Photoshop Generative Fill, among other new applications. ChatGPT reached a hundred million users in just two months after its release, faster than any other application before. This marked the advent of the generative AI era. Generative AI models generate text, images, music, videos, and even 3D models in ways previously thought impossible for machines. The book explains in an understandable manner how these AI models work. The book provides examples of how AI increases productivity, which professions are changing or disappearing, and how job markets will evolve in the coming years. With this book, you'll learn to recognize the opportunities and risks AI offers. Understand what this change demands from individuals and companies and what strategic skills are required. The book also covers legal questions caused by generative AI, like copyrights, data protection, and AI regulation. It also ponders societal impacts. AI produces content, thus influencing language, culture, and even worldviews. Therefore, it's crucial to understand by whom and how AI is trained. The AI revolution started by ChatGPT is just the beginning. This handbook is for you if you want to keep up with the rapid development of AI.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770042314},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10614286},}@ARTICLE{10388354,
  author={Liu, Guangyuan and Du, Hongyang and Niyato, Dusit and Kang, Jiawen and Xiong, Zehui and Kim, Dong In and Shen, Xuemin},
  journal={IEEE Network}, 
  title={Semantic Communications for Artificial Intelligence Generated Content (AIGC) Toward Effective Content Creation}, 
  year={2024},
  volume={38},
  number={5},
  pages={295-303},
  abstract={Artificial Intelligence Generated Content (AIGC) Services have significant potential in digital content creation. The distinctive abilities of AIGC, such as content generation based on minimal input, hold huge potential, especially when integrating with semantic communication (SemCom). In this paper, a novel comprehensive conceptual model for the integration of AIGC and SemCom is developed. Particularly, a content generation level is introduced on top of the semantic level that provides a clear outline of how AIGC and SemCom interact with each other to produce meaningful and effective content. Moreover, a novel framework that employs AIGC technology is proposed as an encoder and decoder for semantic information, considering the joint optimization of semantic extraction and evaluation metrics tailored to AIGC services. The framework can adapt to different types of content generated, the required quality and the semantic information utilized. By employing a Deep  $Q$  Network (DQN), a case study is presented that provides useful insights into the feasibility of the optimization problem and its convergence characteristics.},
  keywords={Semantics;Receivers;Wireless networks;Transmitters;Decoding;Encoding;Generative AI;Resource management;Wireless networks;Semantic communications;generative AI;AIGC;resource allocation;wireless network},
  doi={10.1109/MNET.2024.3352917},
  ISSN={1558-156X},
  month={Sep.},}@INPROCEEDINGS{9591692,
  author={John, Maria and Santhanalakshmi, S.},
  booktitle={2021 2nd International Conference on Smart Electronics and Communication (ICOSEC)}, 
  title={Image augmentation using GAN models in Computer Vision}, 
  year={2021},
  volume={},
  number={},
  pages={1194-1201},
  abstract={The efficiency of deep learning algorithms will increase when it is trained on a large size of data. Over fitting problems will also be solved working on a large dataset. To collect a huge quantity of data for training a model is more challenging job. Collecting data will take more time as well as resources. The data augmentation technique will increase the diversity of data that to be trained on deep learning algorithms. This will also help in not collecting new data. This led to the need for generative models. When the set of training data is given to this generative model, it will learn to produce the same statistical data as the set of training data. GANs are used in many fields including computer vision, medical, agriculture etc. In this paper along with the traditional GANs two architecture variant and two loss-variant GANs are reviewed and experiments are conducted to generate images. Detailed reviews on the performance metrics of GAN models are also discussed and observed that FID plot doesn’t give much insight to compare the generated images. Despite of the significant success achieved till date, applying GAN model to real time dataset has some challenging problems. Challenges faced while training GANs including mode collapse, image quality and vanishing gradients are discussed.},
  keywords={Deep learning;Training;Image quality;Computer vision;Computational modeling;Training data;Computer architecture;Artificial Intelligence;Deep learning;Generative Adversarial Networks;GANs;Architecture-variant GANs;Loss- Variant GANs;Data Augmentation},
  doi={10.1109/ICOSEC51865.2021.9591692},
  ISSN={},
  month={Oct},}@ARTICLE{10703091,
  author={Yang, Fan and Abedin, Mohammad Zoynul and Qiao, Yanan and Ye, Lvyang},
  journal={IEEE Transactions on Engineering Management}, 
  title={Toward Trustworthy Governance of AI-Generated Content (AIGC): A Blockchain-Driven Regulatory Framework for Secure Digital Ecosystems}, 
  year={2024},
  volume={71},
  number={},
  pages={14945-14962},
  abstract={Digital platforms are experiencing a growing presence of generative artificial intelligence (AI) content, raising concerns due to the prevalence of misinformation that disrupts market integrity. Consequently, the development of effective regulatory measures for overseeing generative AI content becomes imperative. This necessitates the establishment of mechanisms to detect and filter out inaccuracies, ensuring compliance with regulatory requirements. In addition, collaboration among experts, regulators, and AI developers is essential to encourage responsible AI deployment on digital platforms. Successful governance hinges on principles of transparency, accountability, and proactive risk management to navigate the evolving generative AI on digital platforms. Therefore, in order to address the security issues currently faced by artificial intelligence generated content (AIGC), this article first proposes a method of efficient cache mechanism for AIGC content. The secure method of determining the identity of AIGC content owners is proposed based on blockchain technology. Subsequently, it suggests mechanisms for access control and data encryption for generated content within a blockchain environment. Finally, it presents an efficient data supervision mechanism tailored to the AIGC environment. The methods outlined in this article aim to enhance security from three perspectives: protection of content creators' identities, safeguarding data security, and ensuring effective data supervision within the AIGC framework. The experimental results further confirm that our proposed method not only ensures the security of the AIGC framework but also provides an efficient data analysis and supervision solution for digital platforms.},
  keywords={Security;Generative AI;Artificial intelligence;Regulation;Data privacy;Blockchains;Engineering management;Data security;Data models;Reliability;Artificial intelligence generated content (AIGC) regulation;blockchain governance;consensus mechanism;data security;data traceability},
  doi={10.1109/TEM.2024.3472292},
  ISSN={1558-0040},
  month={},}@INPROCEEDINGS{9559146,
  author={Fokkens, Tanner and Xu, Zhifei and Hoseini Izadi, Omid and Hwang, Chulsoon},
  booktitle={2021 IEEE International Joint EMC/SI/PI and EMC Europe Symposium}, 
  title={Machine Learning Voice Synthesis for Intention Electromagnetic Interference Injection in Smart Speaker Devices}, 
  year={2021},
  volume={},
  number={},
  pages={673-677},
  abstract={This work presents the effectiveness of using machine learning (ML) synthesized voice samples to control smart speaker devices through radiated intentional electromagnetic interference (I-EMI). In previous works, the feasibility of using I-EMI to control smart speaker devices was shown. However, devices that are trained to only recognize a single person’s voice or only execute certain commands from that person will not be as susceptible to this attack. By training a generative adversarial network (GAN) using samples of the target’s voice, this security feature can be bypassed directly, increasing the feasibility of the attack.},
  keywords={Training;Radio frequency;Electromagnetic interference;Europe;Machine learning;Speech recognition;Learning (artificial intelligence);Machine learning (ML);Electromagnetic Interference (EMI);Generative adversarial networks (GAN);Internet of Things (IoT)},
  doi={10.1109/EMC/SI/PI/EMCEurope52599.2021.9559146},
  ISSN={},
  month={July},}@INPROCEEDINGS{10456125,
  author={Dhingra, Lovish},
  booktitle={2023 IEEE International Conference on ICT in Business Industry & Government (ICTBIG)}, 
  title={Intelligent Decision Support System for Cardiac Arrhythmia Management using AI and ECG Data}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Our proposed Intelligent Decision Support System for Cardiac Arrhythmia Management leverages state-of-the-art artificial intelligence (AI) algorithms and electrocardiogram (ECG) data to significantly enhance the accuracy of arrhythmia detection and classification. This method encompasses thorough data preprocessing, feature extraction, model training, and real-time arrhythmia prediction. Raw ECG data undergoes preprocessing to eliminate noise and artifacts using a bandpass filter. Key features, including RR intervals and power spectral density (PSD), are extracted to effectively represent arrhythmia patterns. Three powerful AI algorithms - Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), and Support Vector Machine (SVM) - are employed for model training. An ensemble model is constructed by combining predictions from these models. This approach offers an efficient and reliable decision support system for clinicians, aiding in optimal cardiac arrhythmia management and improving patient outcomes. Our AI-powered technique has several benefits over more conventional methods. Automatically learning from ECG data, it can identify a wide variety of arrhythmias with a high degree of sensitivity and specificity. Lifesaving actions may be implemented sooner thanks to real-time monitoring and notifications. An additional benefit of this system over more conventional, rule-based approaches is that it is constantly learning and adapting to new arrhythmia patterns. This breakthrough has the potential to revolutionize cardiac arrhythmia management by boosting diagnostic precision, operational efficacy, and individual treatment for patients.},
  keywords={Decision support systems;Support vector machines;Arrhythmia;Electrocardiography;Predictive models;Prediction algorithms;Feature extraction;AI-ECG Fusion;Arrhythmia Classification;Convolutional Neural Network (CNN);Electrocardiogram (ECG) Data;Long Short-Term Memory (LSTM);Model Training;Power Spectral Density},
  doi={10.1109/ICTBIG59752.2023.10456125},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10575032,
  author={Kannan, Balaji and Sakthivanitha, M. and Jayashree, S. and Maruthi, R.},
  booktitle={2024 3rd International Conference on Applied Artificial Intelligence and Computing (ICAAIC)}, 
  title={Prediction of Cyber Attacks Utilizing Deep Learning Model using Network/Web Traffic Data}, 
  year={2024},
  volume={},
  number={},
  pages={363-367},
  abstract={Nowadays, cyber-attacks are growing predominantly due to the development of technologies. It will lead to financial losses to a company and the other problems related to attacks. It is very important to predict such attacks from outsiders to safeguard our networking systems to provide effective security. The Artificial Intelligence (AI), Machine Learning (ML) and Deep Learning (DL) techniques leverage enormous amounts of data to identify the cyber attacks. These learning approaches are used to identify a broad range of cyber-attacks by analyzing the web traffic or network traffic to identify potential threats such as malware, network intrusions and other types of attacks. The study demonstrates the various deep learning methods to predict the anomalies and other potential threats with more accuracy in real time.},
  keywords={Deep learning;Computational modeling;Telecommunication traffic;Predictive models;Real-time systems;Malware;Data models;Cyber Attacks;Deep learning;Threats;Network Traffic},
  doi={10.1109/ICAAIC60222.2024.10575032},
  ISSN={},
  month={June},}@INPROCEEDINGS{10322226,
  author={Hu, Yongquan and Hu, Wen and Quigley, Aaron},
  booktitle={2023 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)}, 
  title={Towards Using Generative AI for Facilitating Image Creation in Spatial Augmented Reality}, 
  year={2023},
  volume={},
  number={},
  pages={441-443},
  abstract={The intersection of Generative Artificial Intelligence (GenAI) and Spatial Augmented Reality (SAR) constitutes a relatively unexplored field. The effectiveness of general-purpose generative AI models in numerous distinct scenarios and tasks remains wanting. Addressing this predicament, our paper concentrates on image generation in SAR contexts. We present the Contrastive Learning Integrated with Depth Perceptual Fusion (CLIPF) method, a refined text-plus-image-to-image generative technique, specifically devised to overcome projection-specific hurdles typically inherent in standard diffusion models. Additionally, to substantiate the efficacy of our approach, we construct a system through a cooperative amalgamation of software components, such as ChatGPT, and hardware devices, including the Intel RealSense D435 Depth Camera, thereby fostering an innovative interaction for projection content creation based on natural language. Comprehensive evaluation results validate our approach’s capacity to markedly enhance projection image quality. In summation, we illuminate potential utility avenues for our proposed approach, emphasizing its diverse prospective contributions towards enriching future SAR experiences.},
  keywords={Image quality;Image synthesis;Spatial augmented reality;Natural languages;Chatbots;Software;Hardware;Human-centered computing;Human-computer interaction;Augmented reality;Interactive system},
  doi={10.1109/ISMAR-Adjunct60411.2023.00095},
  ISSN={2771-1110},
  month={Oct},}@ARTICLE{10633290,
  author={Su, Xingzhe and Zheng, Changwen and Qiang, Wenwen and Wu, Fengge and Zhao, Junsuo and Sun, Fuchun and Xiong, Hui},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Manifold Constraint Regularization for Remote Sensing Image Generation}, 
  year={2024},
  volume={62},
  number={},
  pages={1-20},
  abstract={Generative adversarial networks (GANs) have shown notable accomplishments in remote sensing (RS) domain. However, this article reveals that their performance on RS images falls short when compared to their impressive results with natural images. This study identifies a previously overlooked issue: GANs exhibit a heightened susceptibility to overfitting on RS images. To address this challenge, this article analyzes the characteristics of RS images and proposes manifold constraint regularization (MCR), a novel approach that tackles overfitting of GANs on RS images for the first time. Our method includes a new measure for evaluating the structure of the data manifold. Leveraging this measure, we propose the MCR term, which not only alleviates the overfitting problem, but also promotes alignment between the generated and real data manifolds, leading to enhanced quality in the generated images. The effectiveness and versatility of this method have been corroborated through extensive validation on various RS datasets and GAN models. The proposed method not only enhances the quality of the generated images, reflected in a 3.13% improvement in Fréchet inception distance (FID) score, but also boosts the performance of the GANs on downstream tasks, evidenced by a 3.76% increase in classification accuracy. The source code is available at https://github.com/rootSue/Manifold-RSGAN.},
  keywords={Manifolds;Generative adversarial networks;Training;Remote sensing;Image edge detection;Task analysis;Image synthesis;Data manifold;generative adversarial networks (GANs);image generation;remote sensing (RS)},
  doi={10.1109/TGRS.2024.3441631},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{10592990,
  author={Pandita, Vishesh and Mujawar, Akhil M and Norbu, Tsewang and Verma, Vivek and Patil, Priyadarshini},
  booktitle={2024 5th International Conference for Emerging Technology (INCET)}, 
  title={Text Origin Detection: Unmasking the Source – AI vs Human}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={ChatGpt is a conversational artificial intelligence that is a member of the generative pre-trained tranformer of the large language model family. The paper examines the challenges associated with discerning between text generated by ChatGPT, an artificial intelligence model, and naturally written human text. Despite the impressive capabilities of ChatGPT, there is a growing concern about the potential misuse of AI -generated content. The primary objective of this research is to address the critical need for a reliable method to differentiate between ChatGPT-generated text and human-authored text. Our study employs a robust machine learning-based approach for text classification, leveraging a diverse dataset and state-of-the-art classifiers. We meticulously explore the nuanced distinctions that exist between automated content, specifically that gen-erated by ChatGPT, and human-generated text. The culmination of our research involves the development and evaluation of an ensemble model, achieving a noteworthy accuracy rate of 80.29 %. This work contributes significantly to the ongoing discourse on the responsible use of AI -generated content.},
  keywords={Adaptation models;Accuracy;Large language models;Text categorization;User interfaces;Chatbots;Robustness;ChatGpt;Generative AI;Classification;NLP;Graphical User Interface},
  doi={10.1109/INCET61516.2024.10592990},
  ISSN={},
  month={May},}@INPROCEEDINGS{10711605,
  author={Ding, Siyi and Lin, Jia and Zhou, Wenbo and Mao, Xinhua and Zhang, Jie},
  booktitle={2024 IEEE 20th International Conference on Automation Science and Engineering (CASE)}, 
  title={Research on Spindle Dynamic Performance Prediction by CGAN Model based on LSTM and Attention Mechanism}, 
  year={2024},
  volume={},
  number={},
  pages={988-993},
  abstract={The performance requirements of chemical fiber equipment are increasing with the growing production capacity of chemical fiber fabrics. The dynamic performance of the spindles used in filament winder is particularly noticeable. There is a multifactorial coupling relationship between assembly precision and dynamic performance. In addition, acquiring dynamic performance data under varying assembly processes presents a challenge. To address these issues, this paper proposes a performance prediction method based on a conditional generative adversarial network to guide the optimization of spindle assembly processes. First, the spindle dynamic performance prediction model is constructed based on conditional generative adversarial network. Furthermore, the feature layer incorporates a long short-term memory network and an attention mechanism to extract key temporal features. This enables prediction of the spindle dynamic performance using a dataset provided by a winder manufacturer. The ablation experiment confirms its effectiveness with a data correlation of 98.2%.},
  keywords={Attention mechanisms;Predictive models;Optical fiber networks;Feature extraction;Generative adversarial networks;Data models;Optical fiber devices;Assembly;Long short term memory;Chemicals},
  doi={10.1109/CASE59546.2024.10711605},
  ISSN={2161-8089},
  month={Aug},}@ARTICLE{10287612,
  author={Li, Yunxiang and Shao, Hua-Chieh and Liang, Xiao and Chen, Liyuan and Li, Ruiqi and Jiang, Steve and Wang, Jing and Zhang, You},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Zero-Shot Medical Image Translation via Frequency-Guided Diffusion Models}, 
  year={2024},
  volume={43},
  number={3},
  pages={980-993},
  abstract={Recently, the diffusion model has emerged as a superior generative model that can produce high quality and realistic images. However, for medical image translation, the existing diffusion models are deficient in accurately retaining structural information since the structure details of source domain images are lost during the forward diffusion process and cannot be fully recovered through learned reverse diffusion, while the integrity of anatomical structures is extremely important in medical images. For instance, errors in image translation may distort, shift, or even remove structures and tumors, leading to incorrect diagnosis and inadequate treatments. Training and conditioning diffusion models using paired source and target images with matching anatomy can help. However, such paired data are very difficult and costly to obtain, and may also reduce the robustness of the developed model to out-of-distribution testing data. We propose a frequency-guided diffusion model (FGDM) that employs frequency-domain filters to guide the diffusion model for structure-preserving image translation. Based on its design, FGDM allows zero-shot learning, as it can be trained solely on the data from the target domain, and used directly for source-to-target domain translation without any exposure to the source-domain data during training. We evaluated it on three cone-beam CT (CBCT)-to-CT translation tasks for different anatomical sites, and a cross-institutional MR imaging translation task. FGDM outperformed the state-of-the-art methods (GAN-based, VAE-based, and diffusion-based) in metrics of Fréchet Inception Distance (FID), Peak Signal-to-Noise Ratio (PSNR), and Structural Similarity Index Measure (SSIM), showing its significant advantages in zero-shot medical image translation.},
  keywords={Computed tomography;Frequency-domain analysis;Medical diagnostic imaging;Planning;Imaging;Task analysis;Low-pass filters;Medical image translation;diffusion model;cone-beam computed tomography},
  doi={10.1109/TMI.2023.3325703},
  ISSN={1558-254X},
  month={March},}@ARTICLE{9116991,
  author={Kaushik, Shruti and Choudhury, Abhinav and Natarajan, Sayee and Pickett, Larry A. and Dutt, Varun},
  journal={IEEE Access}, 
  title={Medicine Expenditure Prediction via a Variance- Based Generative Adversarial Network}, 
  year={2020},
  volume={8},
  number={},
  pages={110947-110958},
  abstract={Machine learning (ML) offers a wide range of techniques to predict medicine expenditures using historical expenditures data as well as other healthcare variables. For example, researchers have developed multilayer perceptron (MLP), long short-term memory (LSTM), and convolutional neural network (CNN) models for predicting healthcare outcomes. However, recently proposed generative approaches (e.g., generative adversarial networks; GANs) are yet to be explored for time-series prediction of medicine-related expenditures. The primary objective of this research was to develop and test a generative adversarial network model (called “variance-based GAN or V-GAN”) that specifically minimizes the difference in variance between model and actual data during model training. For our model development, we used patient expenditure data of a popular pain medication in the US. In the V-GAN model, we used an LSTM model as a generator network and a CNN model or an MLP model as a discriminator network. The V-GAN model’s performance was compared with other GAN variants and ML models proposed in prior research such as linear regression (LR), gradient boosting regression (GBR), MLP, and LSTM. Results revealed that the V-GAN model using an LSTM generator and a CNN discriminator outperformed other GAN-based prediction models, as well as the LR, GBR, MLP, and LSTM models in correctly predicting medicine expenditures of patients. Through this research, we highlight the utility of developing GAN-based architectures involving variance minimization for predicting patient-related expenditures in the healthcare domain.},
  keywords={Medical services;Data models;Predictive models;Generative adversarial networks;Gallium nitride;Neural networks;Medical diagnostic imaging;Generative adversarial network;long short-term memory;medicine expenditures;multilayer perceptron;regression;time-series prediction;variance minimization},
  doi={10.1109/ACCESS.2020.3002346},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9022605,
  author={Shen, Yuming and Qin, Jie and Chen, Jiaxin and Liu, Li and Zhu, Fan and Shen, Ziyi},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)}, 
  title={Embarrassingly Simple Binary Representation Learning}, 
  year={2019},
  volume={},
  number={},
  pages={2883-2892},
  abstract={Recent binary representation learning models usually require sophisticated binary optimization, similarity measure or even generative models as auxiliaries. However, one may wonder whether these non-trivial components are needed to formulate practical and effective hashing models. In this paper, we answer the above question by proposing an embarrassingly simple approach to binary representation learning. With a simple classification objective, our model only incorporates two additional fully-connected layers onto the top of an arbitrary backbone network, for binary latents and semantic labels respectively, whilst complying with the binary constraints during training. The proposed model lower-bounds the Information Bottleneck (IB) between data samples and their semantics, and can be related to many recent 'learning to hash' paradigms. We show that, when properly designed, even such a simple network can generate effective binary codes, by fully exploring data semantics without any held-out alternating updating steps or auxiliary models. Experiments are conducted on conventional large-scale benchmarks, i.e., CIFAR-10, NUS-WIDE, and ImageNet, where the proposed simple model outperforms the state-of-the-art methods.},
  keywords={Training;Semantics;Optimization;Data models;Encoding;Stochastic processes;Binary codes;Image Retrieval;Representation Learning},
  doi={10.1109/ICCVW.2019.00350},
  ISSN={2473-9944},
  month={Oct},}@INPROCEEDINGS{10542806,
  author={Pornphol, Putsadee and Chittayasothorn, Suphamit},
  booktitle={2024 12th International Conference on Information and Education Technology (ICIET)}, 
  title={Using LLM Artificial Intelligence Systems as Complex SQL Programming Assistants}, 
  year={2024},
  volume={},
  number={},
  pages={477-481},
  abstract={Learning database programming such as SQL programming is a challenging task when the queries become more complex. SQL is a declarative language based on relational calculus which describes the definition of the query results instead of describing the procedure or steps used to obtain the query result. Tutorial sessions using tutorial assistances are generally required to support the learning of advanced part of the language. Recently generative AI systems demonstrated question answering capabilities including programming codes generation. This paper verifies the SQL code generating capabilities of four generative AI systems: Bing, Bard, ChatGPT, and Copilot and their suitability as SQL programming assistants.},
  keywords={Productivity;Structured Query Language;Codes;Generative AI;Databases;Education;Tutorials;SQL;LLM;database;complex queries},
  doi={10.1109/ICIET60671.2024.10542806},
  ISSN={},
  month={March},}@INPROCEEDINGS{10511477,
  author={Sambaragi, Laxmi M and Pradeep Naik, Pratiksha and Kakatkar, Nikhil N and Chikkamath, Satish and S R, Nirmala and Budihal, Suneeta V},
  booktitle={2024 3rd International Conference for Innovation in Technology (INOCON)}, 
  title={Music Generation: A simplified approach}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The process of making music is subjective and varies greatly between people. Creativity also comes in waves. AI a firm can facilitate the process of coming up with new ideas and give musicians different ideas to incorporate into them. Work can be done in conjunction with AI algorithms and human musicians to create original and captivating musical works. Our proposal RNN-based long short-term memory (LSTM) models can handle sequential data and long-term dependencies. The experiments are conducted on various folk tunes from kern and Maestro dataset. The generated music is compared and analysed.},
  keywords={Technological innovation;Music;Data models;Proposals;Artificial intelligence;Long short term memory;Creativity;Music Generation;Long Short Term Memory(LSTM);Recurrent Neural Network(RNN);MIDI},
  doi={10.1109/INOCON60754.2024.10511477},
  ISSN={},
  month={March},}@ARTICLE{8607049,
  author={Wu, Yu and Lin, Yutian and Dong, Xuanyi and Yan, Yan and Bian, Wei and Yang, Yi},
  journal={IEEE Transactions on Image Processing}, 
  title={Progressive Learning for Person Re-Identification With One Example}, 
  year={2019},
  volume={28},
  number={6},
  pages={2872-2881},
  abstract={In this paper, we focus on the one-example person re-identification (re-ID) task, where each identity has only one labeled example along with many unlabeled examples. We propose a progressive framework that gradually exploits the unlabeled data for person re-ID. In this framework, we iteratively: 1) update the convolutional neural network (CNN) model and (2) estimate pseudo labels for the unlabeled data. We split the training data into three parts, i.e., labeled data, pseudo-labeled data, and index-labeled data. Initially, the re-ID model is trained using the labeled data. For the subsequent model training, we update the CNN model by the joint training on the three data parts. The proposed joint training method can optimize the model by both the data with labels (or pseudo labels) and the data without any reliable labels. For the label estimation step, instead of using a static sampling strategy, we propose a progressive sampling strategy to increase the number of the selected pseudo-labeled candidates step by step. We select a few candidates with most reliable pseudo labels from unlabeled examples as the pseudo-labeled data, and keep the rest as index-labeled data by assigning them with the data indexes. During iterations, the index-labeled data are dynamically transferred to pseudo-labeled data. Notably, the rank-1 accuracy of our method outperforms the state-of-the-art method by 21.6 points (absolute, i.e., 62.8% versus 41.2%) on MARS, and 16.6 points on DukeMTMC-VideoReID. Extended to the few-example setting, our approach with only 20% labeled data surprisingly achieves comparable performance to the supervised state-of-the-art method with 100% labeled data.},
  keywords={Data models;Training;Reliability;Task analysis;Learning systems;Indexes;Estimation;Person re-identification;semi-supervised learning;few-example learning},
  doi={10.1109/TIP.2019.2891895},
  ISSN={1941-0042},
  month={June},}@INPROCEEDINGS{9738218,
  author={Rbah, Yahya and Mahfoudi, Mohammed and Balboul, Younes and Fattah, Mohammed and Mazer, Said and Elbekkali, Moulhime and Bernoussi, Benaissa},
  booktitle={2022 2nd International Conference on Innovative Research in Applied Science, Engineering and Technology (IRASET)}, 
  title={Machine Learning and Deep Learning Methods for Intrusion Detection Systems in IoMT: A survey}, 
  year={2022},
  volume={},
  number={},
  pages={1-9},
  abstract={The integration of healthcare-related sensors and devices into IoT has resulted in the evolution of the IoMT (Internet of Medical Things). IoMT that can be viewed as an improvement and investment in order to meet patients' needs more efficiently and effectively. It is progressively replacing traditional healthcare systems, particularly after the worldwide impact of COVID. IoMT devices have enabled real time monitoring in the healthcare field, allowing physicians to provide superior care while also keeping patients safe. As IoMT applications have evolved, the variety and volume of security threats and attacks including routing attacks and DoS (Denial of Service), for these systems have increased, necessitating specific efforts to study intrusion detection systems (IDSs) for IoMT systems. However, IDSs are generally too resource intensive to be managed by small IoMT devices, due to their limited processing resources and energy. In this regard, machine learning and deep learning approaches are the most suitable detection and control techniques for IoMT device-generated attacks. The purpose of this research is to present various methods for detecting attacks in the IoMT system. Furthermore, we review, compare, and analyze different machine learning (ML) and deep learning (DL) based mechanisms proposed to prevent and detect IoMT network attacks, emphasizing the proposed methods, performances, and limitations. Based on a comprehensive analysis of current defensive security measures, this work identifies potential open research related challenges and orientations for the actual design of those systems for IoMT networks, that may guide further research in this field.},
  keywords={Deep learning;Privacy;Smart cities;Soft sensors;Intrusion detection;Medical services;Routing;IoMT;Security;Privacy;intrusion detection system (IDS);Machine Learning (ML);Deep Learning (DL)},
  doi={10.1109/IRASET52964.2022.9738218},
  ISSN={},
  month={March},}@ARTICLE{10028760,
  author={Zhang, Xu-Yao and Xie, Guo-Sen and Li, Xiuli and Mei, Tao and Liu, Cheng-Lin},
  journal={Proceedings of the IEEE}, 
  title={A Survey on Learning to Reject}, 
  year={2023},
  volume={111},
  number={2},
  pages={185-215},
  abstract={Learning to reject is a special kind of self-awareness (the ability to know what you do not know), which is an essential factor for humans to become smarter. Although machine intelligence has become very accurate nowadays, it lacks such kind of self-awareness and usually acts as omniscient, resulting in overconfident errors. This article presents a comprehensive overview of this topic from three perspectives: confidence, calibration, and discrimination. Confidence is an important measurement for the reliability of model predictions. Rejection can be realized by setting thresholds on confidence. However, most models, especially modern deep neural networks, are usually overconfident. Therefore, calibration is a process to ensure confidence matching the actual likelihood of correctness, including two approaches: post-calibration and self-calibration. Calibration reflects the global characteristic of confidence, and the local distinguishing property of confidence is also important. In light of this, discrimination focuses on the performance of accepting positive samples while rejecting negative samples. As a binary classification problem, the challenge of discrimination comes from the missing and nonrepresentativeness of the negative data. Three discrimination tasks are comprehensively analyzed and discussed: failure rejection, unknown rejection, and fake rejection. By rejecting failures, the risk could be controlled especially for mission-critical applications. By rejecting unknowns, the awareness of the knowledge blind zone would be enhanced. By rejecting fakes, security and privacy could be protected. We provide a general taxonomy, organization, and discussion of the methods for solving these problems, which are studied separately in the literature. The connections between different approaches and future directions that are worth further investigation are also presented. With a discriminative and calibrated confidence, learning to reject will let the decision-making process be more practical, reliable, and secure.},
  keywords={Predictive models;Failure analysis;Estimation;Calibration;Sorting;Predictive methods;Probabilistic logic;Calibration;confidence;discrimination;failure;fake;rejection;unknown},
  doi={10.1109/JPROC.2023.3238024},
  ISSN={1558-2256},
  month={Feb},}@INBOOK{10951345,
  author={Hurwitz, Judith S. and Thompson, John K.},
  booktitle={Causal Artificial Intelligence: The Next Step in Effective Business AI}, 
  title={The Future of Causal AI}, 
  year={2024},
  volume={},
  number={},
  pages={271-297},
  abstract={Summary <p>This chapter discusses the future of causal artificial intelligence (AI). It examines the top trends and predictions for the future of causal AI. Generative AI, beyond the breakthroughs associated with large language models or foundational models, has popularized and made entirely new populations aware of and comfortable with conversational interfaces. It has provided an accessible path to encoding a significant portion of the information available on the internet in one model. Causal discovery is intended to expose the underlying causal structure that generated the data. This can be useful for prediction, decision&#x2010;making, and understanding the mechanisms underlying a system. In the future, reinforcement learning will become an important tool to support causal AI. Probabilistic Programming Languages are used to create flexible causal models. These languages are designed to help develop and test causal AI algorithms.</p>},
  keywords={Artificial intelligence;Business;Software;Force;Ecosystems;Companies;Cause effect analysis;Technological innovation;Source coding;Libraries},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394184149},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951345},}@ARTICLE{10048555,
  author={Shen, Wei and Peng, Zelin and Wang, Xuehui and Wang, Huayu and Cen, Jiazhong and Jiang, Dongsheng and Xie, Lingxi and Yang, Xiaokang and Tian, Qi},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={A Survey on Label-Efficient Deep Image Segmentation: Bridging the Gap Between Weak Supervision and Dense Prediction}, 
  year={2023},
  volume={45},
  number={8},
  pages={9284-9305},
  abstract={The rapid development of deep learning has made a great progress in image segmentation, one of the fundamental tasks of computer vision. However, the current segmentation algorithms mostly rely on the availability of pixel-level annotations, which are often expensive, tedious, and laborious. To alleviate this burden, the past years have witnessed an increasing attention in building label-efficient, deep-learning-based image segmentation algorithms. This paper offers a comprehensive review on label-efficient image segmentation methods. To this end, we first develop a taxonomy to organize these methods according to the supervision provided by different types of weak labels (including no supervision, inexact supervision, incomplete supervision and inaccurate supervision) and supplemented by the types of segmentation problems (including semantic segmentation, instance segmentation and panoptic segmentation). Next, we summarize the existing label-efficient image segmentation methods from a unified perspective that discusses an important question: how to bridge the gap between weak supervision and dense prediction – the current methods are mostly based on heuristic priors, such as cross-pixel similarity, cross-label constraint, cross-view consistency, and cross-image relation. Finally, we share our opinions about the future research directions for label-efficient deep image segmentation.},
  keywords={Semantic segmentation;Semantics;Training;Annotations;Task analysis;Taxonomy;Sports equipment;Instance segmentation;panoptic segmentation;semantic segmentation;semi-supervised learning;unsupervised domain adaptation;unsupervised representation learning;weakly-supervised learning},
  doi={10.1109/TPAMI.2023.3246102},
  ISSN={1939-3539},
  month={Aug},}@ARTICLE{9778207,
  author={Tai, Yonghang and Zhang, Liqiang and Li, Qiong and Zhu, Chunsheng and Chang, Victor and Rodrigues, Joel J. P. C. and Guizani, Mohsen},
  journal={IEEE Internet of Things Journal}, 
  title={Digital-Twin-Enabled IoMT System for Surgical Simulation Using rAC-GAN}, 
  year={2022},
  volume={9},
  number={21},
  pages={20918-20931},
  abstract={A digital-twin (DT)-enabled Internet of Medical Things (IoMT) system for telemedical simulation is developed, systematically integrated with mixed reality (MR), 5G cloud computing, and a generative adversarial network (GAN) to achieve remote lung cancer implementation. Patient-specific data from 90 lung cancer with pulmonary embolism (PE)-positive patients, with 1372 lung cancer control groups, were gathered from Qujing and Dehong, and then transmitted and preprocessed using 5G. A novel robust auxiliary classifier GAN (rAC-GAN)-based intelligent network is employed to facilitate lung cancer with the PE prediction model. To improve the accuracy and immersion during remote surgical implementation, a real-time operating room perspective from the perception layer with a surgical navigation image is projected to the surgeon’s helmet in the application layer using the DT-based MR guide clue with 5G. The accuracies of the area under the curve (AUC) of our new intelligent IoMT system were 0.92 and 0.93. Furthermore, the pathogenic features learned from our rAC-GAN model are highly consistent with the statistical epidemiological results. The proposed intelligent IoMT system generates significant performance improvement to process substantial clinical data at cloud centers and shows a novel framework for remote medical data transfer and deep learning analytics for DT-based surgical implementation.},
  keywords={Lung cancer;Digital twins;Biomedical imaging;Medical diagnostic imaging;Surgery;Mixed reality;Medical services;Digital twin (DT);Internet of Medical Things (IoMT);mixed reality (MR);remote surgery;robust auxiliary classifier generative adversarial network (rAC-GAN) model},
  doi={10.1109/JIOT.2022.3176300},
  ISSN={2327-4662},
  month={Nov},}@ARTICLE{10411123,
  author={Cai, Shilv and Chen, Liqun and Zhang, Zhijun and Zhao, Xiangyun and Zhou, Jiahuan and Peng, Yuxin and Yan, Luxin and Zhong, Sheng and Zou, Xu},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={I2C: Invertible Continuous Codec for High-Fidelity Variable-Rate Image Compression}, 
  year={2024},
  volume={46},
  number={6},
  pages={4262-4279},
  abstract={Lossy image compression is a fundamental technology in media transmission and storage. Variable-rate approaches have recently gained much attention to avoid the usage of a set of different models for compressing images at different rates. During the media sharing, multiple re-encodings with different rates would be inevitably executed. However, existing Variational Autoencoder (VAE)-based approaches would be readily corrupted in such circumstances, resulting in the occurrence of strong artifacts and the destruction of image fidelity. Based on the theoretical findings of preserving image fidelity via invertible transformation, we aim to tackle the issue of high-fidelity fine variable-rate image compression and thus propose the Invertible Continuous Codec (I2C). We implement the I2C in a mathematical invertible manner with the core Invertible Activation Transformation (IAT) module. I2C is constructed upon a single-rate Invertible Neural Network (INN) based model and the quality level (QLevel) would be fed into the IAT to generate scaling and bias tensors. Extensive experiments demonstrate that the proposed I2C method outperforms state-of-the-art variable-rate image compression methods by a large margin, especially after multiple continuous re-encodings with different rates, while having the ability to obtain a very fine variable-rate control without any performance compromise.},
  keywords={Image coding;Neural networks;Adaptation models;Codecs;Training;Rate-distortion;Image reconstruction;Image coding;image processing;rate-distortion},
  doi={10.1109/TPAMI.2024.3356557},
  ISSN={1939-3539},
  month={June},}@INPROCEEDINGS{8901951,
  author={Xu, Jie and Lan, Xuguang and Li, Jin and Chen, Xingyu and Zheng, Nanning},
  booktitle={2019 2nd China Symposium on Cognitive Computing and Hybrid Intelligence (CCHI)}, 
  title={EAN: Error Attenuation Network for Long-term Human Motion Prediction}, 
  year={2019},
  volume={},
  number={},
  pages={178-183},
  abstract={Human motion prediction is an important problem in human-robot interaction, computer graphics, and autonomous driving. Currently, there are still some difficulties. Firstly, the error of reasoning about temporal relations accumulates over time. Secondly, the local optimal caused by unbalanced data. For example, leg walking is more common than knee bending or standing. Thirdly, the problem of mean pose is easy to occur in long sequence prediction. In this work, we propose a novel prediction method named Error Attenuation Network (EAN) by taking the Recursive Attenuation Mechanism into consideration with attention model. Firstly, an error attenuation wrapper for optimal function is introduced to alleviate the effect of error accumulation and mean pose. Secondly, the attention model is introduced to restrain incidental actions to balance motions, which aims to mitigate the impact of unbalanced data and mean pose. Experimental results demonstrate that our method predicts the future human motion more accurately, which outperforms the related state-of-the-art approaches on long-term prediction in most cases while having a comparable performance on short-term prediction.},
  keywords={Legged locomotion;Knee;Human-robot interaction;Computer graphics;Predictive models;Bending;Attenuation;Data models;Cognition;Cognitive systems;human-robot interaction;human motion prediction;error attenuation},
  doi={10.1109/CCHI.2019.8901951},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10777265,
  author={Al-Qahtani, Anwar Hussein and Al-Baltah, Ibrahim Ahmed and Ghaleb, Mukhtar},
  booktitle={2024 1st International Conference on Emerging Technologies for Dependable Internet of Things (ICETI)}, 
  title={Comparative Analysis of Deep Learning Techniques for Chatbots Implementation}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Nowadays, advancements in technology have facilitated the development of machines that emulate human-like behavior. One notable application of this is conversational software agents which utilize natural language process (NLP) and artificial intelligence (AI), commonly referred to as Chatbots. These Chatbots serve various purposes and find application across diverse sectors such as business, healthcare, agriculture, and more. The evolution of Chatbots has been remarkable, prompting significant interest and research endeavours. This paper aims to provide a comprehensive survey of the techniques employed in enhancing Chatbot functionalities, offering a comparative analysis among them. Additionally, it delves into the nuances of these techniques, elucidating both their commonalities and distinctions. Through this exploration, the most commonly used algorithms in chatbots are reinforcement learning, BERT, NLP, and hybrid algorithms of artificial neural networks. The paper endeavours to identify research gaps that can guide future improvements in Chatbot technology, ultimately enhancing customer satisfaction levels.},
  keywords={Surveys;Natural languages;Oral communication;Reinforcement learning;Medical services;Chatbots;Software agents;Question answering (information retrieval);Artificial intelligence;Business;Chatbot;AI;DL;DNN;NLP;NLU;RNN;Seq2Seq;LSTM;GRU;BLEU;DRL;BERT},
  doi={10.1109/ICETI63946.2024.10777265},
  ISSN={},
  month={Nov},}@ARTICLE{9036960,
  author={Yu, Wei and Chang, Tao and Guo, Xiaoting and Wang, Xiaodong and Liu, Bo and He, Yang},
  journal={IEEE Access}, 
  title={UGAN: Unified Generative Adversarial Networks for Multidirectional Text Style Transfer}, 
  year={2020},
  volume={8},
  number={},
  pages={55170-55180},
  abstract={Recently, text style transfer has become a very hot research topic in the field of natural language processing. However, the conventional text style transfer is unidirectional, and it is not possible to obtain a model with multidirectional transformations through training once. To address this limitation, we propose a new task called multidirectional text style transfer. It aims to use a single model to transfer the underlying style of text among multiple style attributes and keep its main content unchanged. In this paper, we propose Unified Generative Adversarial Networks (UGAN), a practical approach that combines target vector and generative adversarial techniques to perform multidirectional text style transfer. Our model allows simultaneous training of multi-attribute data on a single network. Such unified structure makes our model more efficient and flexible than existing approaches. We demonstrate the superiority of our approach on three benchmark datasets. Experimental results show that our method not only outperforms other baselines, but also reduces training time by an average of 13%.},
  keywords={Generative adversarial networks;Generators;Training;Task analysis;Neural networks;Natural language processing;Gallium nitride;Multidirectional text style transfer;generative adversarial networks;unified generative adversarial networks},
  doi={10.1109/ACCESS.2020.2980898},
  ISSN={2169-3536},
  month={},}@ARTICLE{11125504,
  author={Qu, Xiaofeng and Liu, Li and Zhang, Huaxiang and Zhu, Lei and Nie, Liqiang and Chang, Xiaojun and Li, Fengling},
  journal={IEEE Transactions on Multimedia}, 
  title={SecureDA: Privacy-preserving Source-free Domain Adaptation for Person Re-identification}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={Conventional domain adaptation (DA) for person reidentification (ReID) aims to bridge the domain gap but often requires direct use of fully labeled source and target domains, raising significant data privacy concerns due to the inclusion of personal identity information (PII) in raw data. Source-free domain adaptation (SFDA) for person ReID effectively preserves PII within the authorized source model. Nevertheless, these methods are vulnerable to data privacy (e.g., portrait rights) of the target domain during retrieval, where attackers can exploit pedestrian images for malicious generation, leading to damage to an individual's reputation. Beyond these limitations, we propose a novel framework called SecureDA to address privacy-preserving SFDA for person ReID, which can generate a privacy key to defend against potential attacks on PII. Technically, we introduce domain-specific adversarial attacks into DA, where the protected query and gallery images are encrypted to ensure secure image retrieval. Furthermore, we employ two simultaneous processes: 1) The global–local adversarial pathway (GLAP) leverages encrypted and original images as adversarial pairs, thereby fostering the development of robust ReID models; 2) The global–local collaborative pathway (GLCP) is mastered through positive pairs collected from the same domain, effectively mitigating the pernicious catastrophic forgetting phenomenon. Extensive experiments show that SecureDA achieves state-ofthe-art performance on multiple DA benchmarks and even outperforms the conventional DA and SFDA methods, which inherently compromise data privacy.},
  keywords={Data privacy;Adaptation models;Data models;Privacy;Training;Protection;Collaboration;Artificial intelligence;Image retrieval;Generative adversarial networks;Person re-identification;privacy protection;source-free domain adaptation;knowledge distillation},
  doi={10.1109/TMM.2025.3599094},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{10200484,
  author={Joo, Jaehan and Seo, Jeongbin and Choi, Geonho and Kim, Suk Chan},
  booktitle={2023 Fourteenth International Conference on Ubiquitous and Future Networks (ICUFN)}, 
  title={GAN-based Image-to-Image Translation of Fundus Photography: Topcon to Eidon}, 
  year={2023},
  volume={},
  number={},
  pages={746-748},
  abstract={This paper proposes a technique to translate Topcon to Eidon fundus photography using a multimodal image-to-image translation technique based on the BicycleGAN model. The proposed approach aims to address the limitations of Topcon-type fundus photography and leverage the advantages of Eidon-type fundus photography, which captures high-resolution images of the retina using a confocal scanning technique. To this end, we constructed a dataset comprising 475 pairs of Topcon and Eidon fundus images from the same subjects, and we used it to train the proposed model. We evaluated the generated Eidon-type fundus images qualitatively and quantitatively using various image quality metrics, including SSIM, MSE, PSNR and FID. Our results demonstrate that the proposed technique can effectively translate Topcon-type fundus photography to high-quality Eidon-type fundus photography. This technique could potentially enhance the diagnosis and treatment of retinal diseases by providing high-resolution images that capture fine details of the retina.},
  keywords={Photography;Measurement;Integrated optics;Pathology;Image resolution;Shape;Retina;Image-to-Image translation;Generative Adversarial Model;Fundus Photography;Eidon;Topcon},
  doi={10.1109/ICUFN57995.2023.10200484},
  ISSN={2165-8536},
  month={July},}@INPROCEEDINGS{10711687,
  author={Kim, Tae-Jung and Ha, Min-Ho and Arshad, Saba and Park, Tae-Hyoung},
  booktitle={2024 IEEE 20th International Conference on Automation Science and Engineering (CASE)}, 
  title={Mask Generation of Inpainting Model for Moire Pattern based 3D Reconstruction}, 
  year={2024},
  volume={},
  number={},
  pages={884-889},
  abstract={In this paper, we aim to enhance the performance of 3D height reconstruction from 2D printed circuit board (PCB) moiré images by removing and reconstructing the noise caused by light reflection and shadows, which interfere with the reconstruction process. To achieve this, we conducted comparative experiments using various generative adversarial network (GAN) models applied to an inpainting model, discovering that mask images play a crucial role in this context. By applying white mask areas over the noise regions in the 2D PCB moiré images using the inpainting model, and reconstructing only those areas, we significantly improve the performance in reconstructing the heights of components within the PCB by removing and reconstructing only the specified noise regions. For setting the mask areas, we employ the fast unsupervised anomaly detection with generative adversarial networks (f-AnoGAN model) as an outlier detection model using GAN, aiming to identify anomalies between images with and without noise to set the mask areas accordingly. Through this approach, we accurately identify and reconstruct only the noise regions, proposing a method for reconstructing the heights of components within PCB using 2D PCB moiré images.},
  keywords={Solid modeling;Three-dimensional displays;Printed circuits;Noise;Generative adversarial networks;Reflection;Integrated circuit modeling;Image reconstruction;Anomaly detection;Context modeling},
  doi={10.1109/CASE59546.2024.10711687},
  ISSN={2161-8089},
  month={Aug},}@INPROCEEDINGS{10578809,
  author={Becerra, Álvaro and Mohseni, Zeynab and Sanz, Javier and Cobos, Ruth},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={A Generative AI-Based Personalized Guidance Tool for Enhancing the Feedback to MOOC Learners}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={The widespread adoption of Massive Open Online Courses (MOOCs) has profoundly influenced higher education by granting learners access to an extensive array of educational materials. However, the substantial volume of data generated by MOOCs presents a considerable challenge for instructors who aim to assess and facilitate effective learner support. In this study, we introduce an innovative GenAI-based (Generative Artificial Intelligence) tool designed to assist and guide MOOC learners in understanding their progress in the course to enhance their performance and prevent dropout. Our proposed approach takes advantage of GenAI's capabilities to analyze and understand anonymized learner educational data, including aspects such as course progression, assignment results, time spent on different types of content, timestamps, and other pertinent information. By applying natural language processing techniques, GenAI identifies patterns and trends within the data, enabling it to provide personalized guidance to learners to help them develop better learning strategies and enhance their performance in the course. The proposed tool, named GePeTo (Generative AI-based Personalized Guidance Tool), not only streamlines the process of analyzing large volumes of educational data but also equips instructors with practical insights into their learners' performance and difficulties. GePeTo offers a promising solution for higher education institutions aiming to leverage the potential of MOOC data for effective learner assessment and support. Automating the analysis of educational data and delivering personalized guidance to learners will also facilitate instructors in making data-driven decisions. Ultimately, this will improve learning outcomes and educational experiences for learners in the digital age of education.},
  keywords={Computer aided instruction;Electronic learning;Generative AI;Market research;Information age;Natural language processing;Arrays;GenAI;Generative Artificial Intelligence;GePeTo;MOOC},
  doi={10.1109/EDUCON60312.2024.10578809},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{9500866,
  author={Xu, Chenxin and Xia, Rong and Xiao, Yong and Li, Yingyu and Shi, Guangming and Chen, Kwang-Cheng},
  booktitle={ICC 2021 - IEEE International Conference on Communications}, 
  title={Federated Traffic Synthesizing and Classification Using Generative Adversarial Networks}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={With the fast growing demand on new services and applications as well as the increasing awareness of data protection, traditional centralized traffic classification approaches are facing unprecedented challenges. This paper introduces a novel framework, Federated Generative Adversarial Networks and Automatic Classification (FGAN-AC), which integrates decentralized data synthesizing with traffic classification. FGAN-AC is able to synthesize and classify multiple types of service data traffic from decentralized local datasets without requiring a large volume of manually labeled dataset or causing any data leakage. Two types of data synthesizing approaches have been proposed and compared: computation-efficient FGAN (FGAN-I) and communication-efficient FGAN (FGAN-II). The former only implements a single CNN model for processing each local dataset and the later only requires coordination of intermediate model training parameters. An automatic data classification and model updating framework has been proposed to automatically identify unknown traffic from the synthesized data samples and create new pseudo-labels for model training. Numerical results show that our proposed framework has the ability to synthesize highly mixed service data traffic and can significantly improve the traffic classification performance compared to existing solutions.},
  keywords={Training;Computational modeling;Conferences;Data protection;Generative adversarial networks;Data models;Numerical models},
  doi={10.1109/ICC42927.2021.9500866},
  ISSN={1938-1883},
  month={June},}@INPROCEEDINGS{10310439,
  author={Zaabi, Marwa and Hariri, Walid and Smaoui, Nadia},
  booktitle={2023 International Conference on Innovations in Intelligent Systems and Applications (INISTA)}, 
  title={A review study of ChatGPT applications in education}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Recent advances in large-scale language models have pushed the boundaries of natural language processing and set new performance standards. It is amazing how convincingly artificial intelligence can imitate human behavior and writing style. Deep learning and natural language processing (NLP) have recently driven the development of large language models. One of these models is ChatGPT (Chat Generative Pre-trained Transformer), created by OpenAI in 2022 for chats with open-ended questions. Numerous fields such as education effectively used ChatGPT in several applications to create exam questions and answers, customise learning experiences, and facilitate online dialogues, among other things. It is an effective tool for natural language processing due to its adaptability and precision. An overview of ChatGPT in the educational space is given in this article. We review the recent innovations and powerful of ChatGPT in many education tasks, and future challenges.},
  keywords={Technological innovation;Ethics;Education;Medical services;Writing;Chatbots;Transformers;ChatGPT;artificial intelligence;education},
  doi={10.1109/INISTA59065.2023.10310439},
  ISSN={2768-7295},
  month={Sep.},}@ARTICLE{10623373,
  author={He, Xiaxia and Wang, Boyue and Gao, Junbin and Wang, Qianqian and Hu, Yongli and Yin, Baocai},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Mixed-Modality Clustering via Generative Graph Structure Matching}, 
  year={2024},
  volume={36},
  number={12},
  pages={8773-8786},
  abstract={The goal of mixed-modality clustering, which differs from typical multi-modality/view clustering, is to divide samples derived from various modalities into several clusters. This task has to solve two critical semantic gap problems: i) how to generate the missing modalities without the pairwise-modality data; and ii) how to align the representations of heterogeneous modalities. To tackle the above problems, this paper proposes a novel mixed-modality clustering model, which integrates the missing-modality generation and the heterogeneous modality alignment into a unified framework. During the missing-modality generation process, a bidirectional mapping is established between different modalities, enabling generation of preliminary representations for the missing-modality using information from another modality. Then the intra-modality bipartite graphs are constructed to help generate better missing-modality representations by weighted aggregating existing intra-modality neighbors. In this way, a pairwise-modality representation for each sample can be obtained. In the process of heterogeneous modality alignment, each modality is modelled as a graph to capture the global structure among intra-modality samples and is aligned against the heterogeneous modality representations through the adaptive heterogeneous graph matching module. Experimental results on three public datasets show the effectiveness of the proposed model compared to multiple state-of-the-art multi-modality/view clustering methods.},
  keywords={Correlation;Semantics;Task analysis;Data models;Web sites;Feature extraction;Bipartite graph;Mixed-modality clustering;multi-view clustering;adaptive graph structure learning;heterogeneous graph matching},
  doi={10.1109/TKDE.2024.3434556},
  ISSN={1558-2191},
  month={Dec},}@INPROCEEDINGS{10971021,
  author={Amirkhanyan, Liana G. and Brom, Alla E.},
  booktitle={2025 7th International Youth Conference on Radio Electronics, Electrical and Power Engineering (REEPE)}, 
  title={Automating Information Retrieval with Semantic Data Processing}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={This report proposes to consider the possibility of automating the search for the necessary information in a corporate database that may contain data of various formats. To implement such a process, it is necessary to use large language models (LLM), but to generate high-quality responses, it is necessary to further train the models using Retrieval-Augmented Generation (RAG) technology, which creates vector databases based on corporate data. These repositories can be constantly updated to assist generative Artificial Intelligence (AI) in providing optimal contextual and timely responses, in addition to connecting the semantic ranking of the results obtained for enhanced accuracy. The work also proposes to evaluate the work of language models using known metrics. This is a result of studying which the problem of the occurrence of errors of the 1st and 2nd kind when generating a response by the LLM model is revealed. Consequently, it has been determined that no universal assessment of models exists.},
  keywords={Analytical models;Adaptation models;Accuracy;Statistical analysis;Large language models;Semantics;Search engines;Data processing;Data models;Vectors;RAG technology;LLM models;artificial intelligence;embedding;semantic data processing},
  doi={10.1109/REEPE63962.2025.10971021},
  ISSN={2831-7262},
  month={April},}@INPROCEEDINGS{8460968,
  author={Tai, Lei and Zhang, Jingwei and Liu, Ming and Burgard, Wolfram},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Socially Compliant Navigation Through Raw Depth Inputs with Generative Adversarial Imitation Learning}, 
  year={2018},
  volume={},
  number={},
  pages={1111-1117},
  abstract={We present an approach for mobile robots to learn to navigate in dynamic environments with pedestrians via raw depth inputs, in a socially compliant manner. To achieve this, we adopt a generative adversarial imitation learning (GAIL) strategy, which improves upon a pre-trained behavior cloning policy. Our approach overcomes the disadvantages of previous methods, as they heavily depend on the full knowledge of the location and velocity information of nearby pedestrians, which not only requires specific sensors, but also the extraction of such state information from raw sensory input could consume much computation time. In this paper, our proposed GAIL-based model performs directly on raw depth inputs and plans in real-time. Experiments show that our GAIL-based approach greatly improves the safety and efficiency of the behavior of mobile robots from pure behavior cloning. The real-world deployment also shows that our method is capable of guiding autonomous vehicles to navigate in a socially compliant manner directly through raw depth inputs. In addition, we release a simulation plugin for modeling pedestrian behaviors based on the social force model.},
  keywords={Force;Navigation;Cloning;Sensors;Mobile robots;Learning (artificial intelligence);Visualization},
  doi={10.1109/ICRA.2018.8460968},
  ISSN={2577-087X},
  month={May},}@INPROCEEDINGS{10940679,
  author={Kumar, Gautam and Goyal, Sandip Kumar},
  booktitle={2025 International Conference on Electronics and Renewable Systems (ICEARS)}, 
  title={Energizing the Future: A Comprehensive Review and Evaluation of Artificial Intelligence based Solar Irradiance Forecasting Model with Swot Analysis of Solar Energy}, 
  year={2025},
  volume={},
  number={},
  pages={307-314},
  abstract={Meeting the fast-growing need of energy is paramount; therefore, solar energy can contribute to playing a very important role in reducing greenhouse gas emissions. Solar radiation depends on several factors such as the availability of sunlight, cloud cover, and panel orientation, so it is the key to a solar energy system. Proper prediction of solar irradiance allows better reliability and efficiency of the system. AI and machine learning models, which are trained by use of historical data on weather, are increasingly applied for this purpose using techniques such as regression, neural networks, and ensemble methods. This review presents a review of the state-of-the- art models for solar irradiance forecasting, covering machine learning, numerical weather prediction, and hybrid approaches, by assessing their accuracy, strengths, and weaknesses. It also delineates the prospective future development possibilities while enunciating the role of interdisciplinary collaboration and technology in merging solar power into the main electricity system. Therefore, this work is going to be a core analysis for future researchers in finding optimum methods leading into medium- and long-term solar irradiance forecasting.},
  keywords={Solar irradiance;Renewable energy sources;Reviews;Neural networks;Weather forecasting;Predictive models;Numerical models;Solar radiation;Reliability;Forecasting;Renewable energy;Solar irradiance;Artificial intelligence;Machine learning;Prediction},
  doi={10.1109/ICEARS64219.2025.10940679},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{11081086,
  author={Thangarasu, Gunasekar and Kannan, K Nattar and Ramamoorthy, M and Manimaran, A and M J, Carmel Mary Belinda and Rajaram, Gnanajeyaraman},
  booktitle={2025 IEEE 15th Symposium on Computer Applications & Industrial Electronics (ISCAIE)}, 
  title={Artificial Intelligence-Driven Image Dehazing Using Deep Convolutional Neural Networks for Enhanced Satellite Imagery Perception}, 
  year={2025},
  volume={},
  number={},
  pages={01-06},
  abstract={Computer vision and image processing have recently garnered significant attention, particularly in the context of image dehazing, which is critical for improving visibility and visual perception. Applications such as autonomous driving, surveillance, and satellite imaging often encounter challenges when haze affects images captured under polluted or adverse weather conditions. Traditional image dehazing methods frequently struggle to achieve optimal results, especially with complex images featuring varying haze levels and intricate details. To address these challenges, a robust and efficient dehazing approach is essential. Although advancements in image dehazing have been made, the development of a comprehensive system capable of effectively handling diverse environmental conditions and weather-related factors remains limited. Deep learning offers a promising solution by leveraging neural network capabilities to learn and adapt to intricate patterns in hazy images. This study introduces an innovative deep learning-based approach to enhance visibility and remove haze from images. The proposed convolutional neural network architecture is designed to efficiently identify and eliminate haze by learning subtle distinctions between clear and hazy images. A large, diverse dataset encompassing various meteorological conditions and levels of visual complexity is used to train the network, ensuring a generalized and adaptable performance. Experimental results demonstrate that the deep learning approach outperforms traditional methods, delivering superior image quality, enhanced contrast, and improved visibility even under extreme conditions. These findings underscore the potential of deep learning as a transformative solution for overcoming the limitations of existing image dehazing techniques.},
  keywords={Deep learning;Support vector machines;Training;Image dehazing;Visualization;PSNR;Explainable AI;User interfaces;Convolutional neural networks;Visual perception;Dehazing;Artificial Intelligence;Deep CNN;Visibility Enhancement},
  doi={10.1109/ISCAIE64985.2025.11081086},
  ISSN={2836-4317},
  month={May},}@ARTICLE{11006738,
  author={Cheng, De and Wei, Lei and Fang, Chaowei and He, Lingfeng and Wang, Nannan and Gao, Xinbo},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Progressive Feature-Attribute Matching via Bi-directional Generation for Transductive Zero-Shot Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Transductive zero-shot learning (TZSL) has been proposed to address the domain shift problem by leveraging additional unlabeled unseen data to enhance the generalization ability from seen classes to unseen target classes. Existing TZSL methods primarily focus on mitigating the distribution bias problem by incorporating these unlabeled samples into the generative models. Although these methods have achieved great success, they do not fully exploit the potential of these unlabeled target data. In this paper, we propose a bidirectional weakly guided conditional generative modeling approach, which utilizes the attribute regressor and the visual generator to synthesize paired training data of unseen classes for each other, thus converting unlabeled target data into matched feature-attribute pairs. Additionally, on top of the generative modeling, we also propose to progressively estimate the associations between visual features and attributes among the unlabeled target data through a semi-supervised pseudo-labeling approach, so as to further facilitate the generative model and enhance the learning of target distributions. Extensive experimental results on four benchmark datasets demonstrate the effectiveness of the proposed method, achieving superior performances to state-of-the-art methods. Our source code is released in https://github.com/LevisWei/semi-zero-master.},
  keywords={Visualization;Zero shot learning;Training;Generators;Data models;Semantics;Generative adversarial networks;Vectors;Labeling;Gold;Transductive Zero-shot Learning;Generative Model;Visual Generator;Attribute Regressor},
  doi={10.1109/TCSVT.2025.3571142},
  ISSN={1558-2205},
  month={},}@ARTICLE{9064715,
  author={Li, Longyuan and Yan, Junchi and Wang, Haiyang and Jin, Yaohui},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Anomaly Detection of Time Series With Smoothness-Inducing Sequential Variational Auto-Encoder}, 
  year={2021},
  volume={32},
  number={3},
  pages={1177-1191},
  abstract={Deep generative models have demonstrated their effectiveness in learning latent representation and modeling complex dependencies of time series. In this article, we present a smoothness-inducing sequential variational auto-encoder (VAE) (SISVAE) model for the robust estimation and anomaly detection of multidimensional time series. Our model is based on VAE, and its backbone is fulfilled by a recurrent neural network to capture latent temporal structures of time series for both the generative model and the inference model. Specifically, our model parameterizes mean and variance for each time-stamp with flexible neural networks, resulting in a nonstationary model that can work without the assumption of constant noise as commonly made by existing Markov models. However, such flexibility may cause the model fragile to anomalies. To achieve robust density estimation which can also benefit detection tasks, we propose a smoothness-inducing prior over possible estimations. The proposed prior works as a regularizer that places penalty at nonsmooth reconstructions. Our model is learned efficiently with a novel stochastic gradient variational Bayes estimator. In particular, we study two decision criteria for anomaly detection: reconstruction probability and reconstruction error. We show the effectiveness of our model on both synthetic data sets and public real-world benchmarks.},
  keywords={Time series analysis;Anomaly detection;Data models;Adaptation models;Estimation;Robustness;Recurrent neural networks;Anomaly detection;deep generative model;recurrent neural network;time series;variational auto-encoder (VAE)},
  doi={10.1109/TNNLS.2020.2980749},
  ISSN={2162-2388},
  month={March},}@INPROCEEDINGS{10960029,
  author={Gan, Wenbin and Sun, Yuan and Yu, Xinguo},
  booktitle={2024 International Conference on Intelligent Education and Intelligent Research (IEIR)}, 
  title={Integrating Educational Assessment and Generative AI for Personalized Knowledge Building: An Exploratory Study}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This study investigates the integration of educational assessment (EA) and generative artificial intelligence (GenAI) for personalized knowledge building in online learning environments. We propose a framework that combines cognitive diagnostic assessment with constrained GenAI to create tailored learning experiences. Our web-based system, built on content from an international assessment study, evaluates learners’ skill mastery and generates personalized remedial content. The preliminary results demonstrate the system’s capacity to provide detailed skill mastery information and generate adaptive remedial questions. While long-term efficacy research is ongoing, initial findings suggest that this EA-GenAI integration enhances the personalization and effectiveness of online learning. This study advances adaptive learning technologies by exploring innovative applications of AI for personalized assessment and dynamic content creation.},
  keywords={Adaptive learning;Adaptive systems;Generative AI;Learning (artificial intelligence);Educational Assessment;cognitive diagnostic assessment;Generative AI;Adaptive Remediation;Adaptive Learning;Intelligent Education},
  doi={10.1109/IEIR62538.2024.10960029},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11025885,
  author={Bucchiarone, Antonio and Bonetti, Federico and Yigitbas, Enes},
  booktitle={2025 IEEE/ACM 20th Symposium on Software Engineering for Adaptive and Self-Managing Systems (SEAMS)}, 
  title={Leveraging Self-Adaptive Systems and Generative AI for Personalizing Educational Serious Games: Architecture and Future Challenges}, 
  year={2025},
  volume={},
  number={},
  pages={103-110},
  abstract={The integration of self-adaptive systems (SAS) with Generative Artificial Intelligence (GAI) opens new possibilities to improve serious games (SG) by enabling dynamic adjustments in gameplay, customized content, and personalized learning experiences. This vision paper explores the potential of combining GAI with the MAPE-K framework to enable the generation and adaptation of real-time content in SGs. We propose a framework that addresses key challenges, including generalizing to different SGs, validating AI-generated content in real time, and tailoring content to individual players, while discussing future challenges such as managing conflicting goals, handling uncertainty, and defining robust evaluation metrics. Practical examples and an adaptable system architecture illustrate the framework envisioned. Finally, we discuss the challenges of evaluating SAS in this domain and outline future research directions.},
  keywords={Measurement;Uncertainty;Generative AI;Systems architecture;Learning (artificial intelligence);Computer architecture;Real-time systems;Serious games;Synthetic aperture sonar;Software engineering;Self-Adaptive Systems;Generative AI;Serious Games;Research Roadmap},
  doi={10.1109/SEAMS66627.2025.00019},
  ISSN={2157-2321},
  month={April},}@INPROCEEDINGS{10893133,
  author={Axelsson, Andreas and Wallgren, Daniel Tomas and Verma, Udit and Cajander, Åsa and Daniels, Mats and Eckerdal, Anna and McDermott, Roger},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={From Assistance to Misconduct: Unpacking the Complex Role of Generative AI in Student Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This research-to-practice full paper discusses students' views on the role of generative artificial intelligence (GenAI) in their learning. The rapid integration of GenAI in educational settings has prompted significant interest in its implications for learning and academic integrity. This study investigates the adoption and impact of GenAI tools among computing students at a university, focusing on how they are utilized for educational purposes and their ethical implications. Semi-structured interviews with nine computing students were used to examine GenAI's specific use and timing. Additionally, it explores students' perceptions of the trustworthiness of GenAI outputs and identifies the students' ethical boundaries concerning its use in academic work. The findings reveal that while GenAI tools might enhance learning efficiency and provide substantial educational support, they raise significant ethical concerns, particularly regarding academic misconduct. The study highlights the need for educational strategies to navigate the challenges posed by GenAI technologies. Finally, three recommendations for computing education are outlined. This research contributes to the ongoing discourse on GenAI in education by describing the student's reflections on GenAI.},
  keywords={Ethics;Generative AI;Navigation;Education;Focusing;Learning (artificial intelligence);Debugging;Reflection;Timing;Interviews;Generative AI;Student learning;Cheating;Motivation;Misconduct},
  doi={10.1109/FIE61694.2024.10893133},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10898626,
  author={Lui, Richard Wing Cheung and Bai, Haoran and Zhang, Aiden Wen Yi and Chu, Elvin Tsun Him},
  booktitle={2024 International Conference on Advances in Electrical Engineering and Computer Applications (AEECA)}, 
  title={GPTutor: A Generative AI-powered Intelligent Tutoring System to Support Interactive Learning with Knowledge-Grounded Question Answering}, 
  year={2024},
  volume={},
  number={},
  pages={702-707},
  abstract={With increasing popularity of artificial intelligence (AI) in the education industry, intelligent tutoring system (ITS) powered by AI have been widely adopted to optimize the learning experience. However, the relationship between students’ engagement level of Generative AI (GenAI) and their academic performance is still under exploration. Also current popular GenAI products like ChatGPT suffer from the hallucination problem, which includes factuality, faithfulness, and maliciousness issues in the generated answer. This paper presents GPTutor, an ITS leveraging GenAI to support students' learning processes. GPTutor integrates a Retrieval-Augmented Generation (RAG) pipeline to deliver actual and contextually rich answers aligned to student questions and intended learning outcomes (ILO). A pilot evaluation involving undergraduate and postgraduate students assessed the system’s association with user experience, engagement, and academic performance. Results demonstrated that students generally recognize the effectiveness of GPTutor. Some students also provided insightful feedback on the benefits of GPTutor in improving learning efficiency and some limitations to be addressed. Notably, students with higher engagement levels showed significantly better academic performance on the final exam. This study proposed GPTutor to provide an interactive and knowledge-grounded learning experience and showed the strong association between students’ engagement in GPTutor and academic performance.},
  keywords={Industries;Electrical engineering;Generative AI;Retrieval augmented generation;Pipelines;Education;Learning (artificial intelligence);Computer applications;User experience;Question answering (information retrieval);intelligent tutoring system;generative AI;interactive learning;knowledge-grounded question-answering;retrieval-augmented generation},
  doi={10.1109/AEECA62331.2024.00124},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10194217,
  author={Wang, Alex X. and Chukova, Stefanka S. and Nguyen, Binh P.},
  booktitle={2023 3rd International Conference on Computer, Control and Robotics (ICCCR)}, 
  title={Data-Centric AI to Improve Churn Prediction with Synthetic Data}, 
  year={2023},
  volume={},
  number={},
  pages={409-413},
  abstract={Churn prediction is a critical operation for many businesses because acquiring new clients often costs more than retaining existing ones. Therefore, being able to detect customer churn early and take marketing actions based on artificial intelligence (AI) systems is imperative for businesses. In general, algorithms and data are two integral components of any AI system. Therefore, the research of AI systems can be classified into two groups: model-centric AI and data-centric AI. While model-centric AI is developed to improve the performance of specific models, data-centric AI aims to improve the quality of the data for downstream machine learning tasks. During model development, while the model-centric approach is to use the same data and iterate on the model hyper-parameters, architecture, and other configurations, the data-centric approach is to improve existing data or integrate new data, then train and evaluate the machine learning algorithms. To the best of our knowledge, no previous research attempts to make a comparative study from a data-centric AI perspective for churn prediction. Therefore, to fill the gap, this study presents a comparative study of the most widely used data synthesis algorithms with different data strategies on the problem of churn prediction. The main focus of this study is to investigate whether we can improve churn prediction by substituting, balancing, and augmenting real data with data synthesis. The main goal of this study is to analyse and benchmark the best data-centric resampling methods for churn prediction. We expect that our study will shed some light on future projects and in other domains.},
  keywords={Machine learning algorithms;Computational modeling;Benchmark testing;Prediction algorithms;Data models;Artificial intelligence;Task analysis;synthetic data;churn prediction;machine learning},
  doi={10.1109/ICCCR56747.2023.10194217},
  ISSN={},
  month={March},}@INPROCEEDINGS{9776095,
  author={Hirano, Masanori and Sakaji, Hiroki and Izumi, Kiyoshi},
  booktitle={2022 IEEE Symposium on Computational Intelligence for Financial Engineering and Economics (CIFEr)}, 
  title={Concept and Practice of Artificial Market Data Mining Platform}, 
  year={2022},
  volume={},
  number={},
  pages={1-10},
  abstract={We proposed a concept called the artificial market data mining platform and presented a practical example for it. This concept is designed to evaluate data mining methods through artificial market simulation. We believe that the proposed platform can help us conduct a fair evaluation of data mining methods for the financial market without actual data dependence, and investigate the impact of financial market factors on predictions of future market movements. In this study, as a practical example, we built a tick-time level artificial market simulation and data mining models to predict short-term price changes and investigated the effect of four financial market factors on the performance of data mining models. Through experimental analysis, we demonstrated the validity and benefits of the proposed concept and practice model. We also discussed the potential and future applications of our proposal.},
  keywords={Economics;Analytical models;Biological system modeling;Computational modeling;Predictive models;Data models;Data mining;Artificial Market;Data Mining;Financial Market;Agent-based Simulation},
  doi={10.1109/CIFEr52523.2022.9776095},
  ISSN={2640-7701},
  month={May},}@ARTICLE{11059888,
  author={Du, Hongyang and Zhang, Ruichen and Niyato, Dusit and Kang, Jiawen and Xiong, Zehui and Cui, Shuguang and Shen, Xuemin and Kim, Dong In},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Reinforcement Learning With LLMs Interaction for Distributed Diffusion Model Services}, 
  year={2025},
  volume={47},
  number={10},
  pages={8838-8855},
  abstract={Distributed Artificial Intelligence-Generated Content (AIGC) has attracted significant attention, but two key challenges remain: maximizing subjective Quality of Experience (QoE) and improving energy efficiency, which are particularly pronounced in widely adopted Generative Diffusion Model (GDM)-based image generation services. In this paper, we propose a novel user-centric Interactive AI (IAI) approach for service management, with a distributed GDM-based AIGC framework that emphasizes efficient and cooperative deployment. The proposed method restructures the GDM inference process by allowing users with semantically similar prompts to share parts of the denoising chain. Furthermore, to maximize the users’ subjective QoE, we propose an IAI approach, i.e., Reinforcement Learning With Large Language Models Interaction (RLLI), which utilizes Large Language Model (LLM)-empowered generative agents to replicate users interactions, providing real-time and subjective QoE feedback aligned with diverse user personalities. Lastly, we present the GDM-based Deep Deterministic Policy Gradient (G-DDPG) algorithm, adapted to the proposed RLLI framework, to allocate communication and computing resources effectively while accounting for subjective user traits and dynamic wireless conditions. Simulation results demonstrate that G-DDPG improves total QoE by 15% compared with the standard DDPG algorithm.},
  keywords={Quality of experience;Noise reduction;Artificial intelligence;Servers;Computational modeling;Rivers;Heuristic algorithms;Forestry;Diffusion models;Large language models;AI-generated content;reinforcement learning;generative diffusion model;generative agents;large language models},
  doi={10.1109/TPAMI.2025.3584698},
  ISSN={1939-3539},
  month={Oct},}@INPROCEEDINGS{10796338,
  author={Rausa, Maria and Gaglio, Salvatore and Augello, Agnese and Caggianese, Giuseppe and Franchini, Silvia and Gallo, Luigi and Sabatucci, Luca},
  booktitle={2024 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)}, 
  title={Enriching Metaverse with Memories Through Generative AI: A Case Study}, 
  year={2024},
  volume={},
  number={},
  pages={371-376},
  abstract={The paper introduces MetaMemory, an approach to generate 3D models from either textual descriptions or photographs of objects, offering dual input modes for enhanced representation. MetaMemory's architecture is discussed presenting the tools employed in extracting the object from the image, generating the 3D mesh from texts or images, and visualizing the object reconstruction in an immersive scenario. Afterwards, a case study in which we experienced reconstructing memories of ancient crafts is examined together with the achieved results, by highlighting current limitations and potential applications.},
  keywords={Solid modeling;Three-dimensional displays;Metaverse;Extended reality;Neural engineering;Metrology;Data models;Artificial intelligence;Image reconstruction;Generative AI;3D reconstruction;3D modeling;Synthetic Data Generation;Virtual Reality},
  doi={10.1109/MetroXRAINE62247.2024.10796338},
  ISSN={},
  month={Oct},}@ARTICLE{9262049,
  author={Wang, Yuxi and Zhang, Zhaoxiang and Hao, Wangli and Song, Chunfeng},
  journal={IEEE Transactions on Image Processing}, 
  title={Multi-Domain Image-to-Image Translation via a Unified Circular Framework}, 
  year={2021},
  volume={30},
  number={},
  pages={670-684},
  abstract={The image-to-image translation aims to learn the corresponding information between the source and target domains. Several state-of-the-art works have made significant progress based on generative adversarial networks (GANs). However, most existing one-to-one translation methods ignore the correlations among different domain pairs. We argue that there is common information among different domain pairs and it is vital to multiple domain pairs translation. In this paper, we propose a unified circular framework for multiple domain pairs translation, leveraging a shared knowledge module across numerous domains. One selected translation pair can benefit from the complementary information from other pairs, and the sharing knowledge is conducive to mutual learning between domains. Moreover, absolute consistency loss is proposed and applied in the corresponding feature maps to ensure intra-domain consistency. Furthermore, our model can be trained in an end-to-end manner. Extensive experiments demonstrate the effectiveness of our approach on several complex translation scenarios, such as Thermal IR switching, weather changing, and semantic transfer tasks.},
  keywords={Task analysis;Semantics;Visualization;Generative adversarial networks;Generators;Feature extraction;Meteorology;Image-to-image transfer;multiple domain pairs;sharing knowledge module;GANs},
  doi={10.1109/TIP.2020.3037528},
  ISSN={1941-0042},
  month={},}@ARTICLE{10214604,
  author={Wu, Hanlin and Ni, Ning and Wang, Shan and Zhang, Libao},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Conditional Stochastic Normalizing Flows for Blind Super-Resolution of Remote Sensing Images}, 
  year={2023},
  volume={61},
  number={},
  pages={1-16},
  abstract={Remote sensing images (RSIs) in real scenes may be disturbed by multiple factors, such as optical blur, undersampling, and additional noise, resulting in complex and diverse degradation models. At present, mainstream super-resolution (SR) algorithms only consider a single and fixed degradation (such as bicubic interpolation) and cannot flexibly handle complex degradations in real scenes. Therefore, designing an SR model that can deal with various degradations has gradually attracted researchers’ attention. Some early studies estimate degradation kernels and then perform degradation-adaptive SR but face the problems of estimation error amplification and insufficient high-frequency details in the results. Although blind SR algorithms based on generative adversarial networks (GANs) have greatly improved visual quality, they still suffer from pseudotexture, mode collapse, and poor training stability. This article proposes a novel blind SR framework based on the stochastic normalizing flow (BlindSRSNF) to address the above problems. BlindSRSNF learns the conditional probability distribution over the high-resolution image space given a low-resolution (LR) image by explicitly optimizing the variational bound on the likelihood. BlindSRSNF is easy to train and can generate photorealistic SR results that outperform GAN-based models. In addition, we introduce a degradation representation strategy based on contrastive learning to avoid the error amplification problem caused by explicit degradation estimation. Comprehensive experiments show that the proposed algorithm can obtain SR results with excellent visual perception quality on both simulated LR and real-world RSIs. The code is available at https://github.com/hanlinwu/BlindSRSNF.},
  keywords={Degradation;Kernel;Training;Brain modeling;Task analysis;Generative adversarial networks;Visualization;Blind super-resolution (SR);deep learning (DL);remote sensing;stochastic normalizing flow (SNF)},
  doi={10.1109/TGRS.2023.3304297},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{10343517,
  author={Sajadi, Susan and Ryan, Olivia and Schibelius, Lisa and Huerta, Mark},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={WIP: Using Generative AI to Assist in Individual Performance Feedback for Engineering Student Teams}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Teamwork is a critical component of engineering education, established as both an ABET competency and recognized by engineers in the workforce as one of the essential skills to their work. As a result, team-based learning throughout engineering education has become increasingly popular, especially in first-year programs. Tools such as CATME (Comprehensive Assessment of Team Member Effectiveness), a web-based program used by instructors, help instructors form student teams based on predefined criteria, facilitate peer evaluations to assess individual contributions and performance, and gather general feedback on student teamwork experiences. Other instructors may collect peer feedback through other methods, such as submitted assignments. Theories in organizational psychology highlight the relationship between performance feedback, psychological safety, and conflict management. To purposefully help students develop essential teamwork skills, such as how to manage conflict and build inclusive, psychologically safe teams effectively, it is important that they receive individual performance feedback. However, negative, unfiltered feedback from peers may also escalate unhealthy team dynamics. Consequently, instructors can be hesitant to share peer evaluation scores and comments with students because students may not be comfortable sharing honest, authentic feedback with their peers. However, withholding this valuable formative feedback to students may come at the expense of their individual professional development, especially in devel-oping teamwork skills. Additionally, these project-based learning (PBL) courses tend to be large, and summarizing formative feedback for individual students based on peer evaluations can be time-consuming and perhaps unrealistic with increasing class sizes. To address this need, we present the use of a generative artificial intelligence (AI) system to create individual performance summaries based on student peer responses. The authors present preliminary work from a pilot study that uses generative AI to produce individual performance summaries using CATME data from a first-year engineering course at a large public university in the mid-Atlantic region of the US. We share a sample output performance summary using a generative AI tool, GPT-4 specifically. Our initial findings indicate AI tools, such as GPT-4, can serve as a solution to provide more confidentiality in peer comments by effectively summarizing peer comments and producing individual performance feedback reviews. This study provides promising initial findings and recommendations on how AI can be leveraged to automate a student feedback process for instructors, allowing students to receive individual performance feedback while also providing an additional layer of confidentiality to support team dynamics and not compromise honest individual assessments.},
  keywords={Psychology;Teamwork;Safety;Artificial intelligence;Engineering students;AI;feedback;peer comments;teamwork},
  doi={10.1109/FIE58773.2023.10343517},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10275144,
  author={Bi, Jinmao and Zhang, Peng and Zhang, Jie and Wang, Ming and Zhao, Chuncai},
  booktitle={2023 28th International Conference on Automation and Computing (ICAC)}, 
  title={Data-Driven Prediction of Polymer Intrinsic Viscosity with Incomplete Time Series Data}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Prediction of polymer intrinsic viscosity is very important for stabilizing the quality of polyester fibers. Data-driven prediction has been applied to solve engineering problems. However, incomplete data are all too frequent to a phenomenon in the workshop due to signal interference, human error, and other reasons. This paper proposes a data-driven approach for polymer intrinsic viscosity prediction with incomplete series data. First, a time series data generative adversarial network (TSDGAN) is presented to fill in the missing data, in which Attention LSTM serves as the generator and CNN as the discriminator. Next, An Informer model is introduced for polymer intrinsic viscosity prediction with the generated time series data. According to the experimental results under different missing rates, the proposed approach achieves better results than traditional and some state-of-the-art time-series prediction methods.},
  keywords={Viscosity;Time series analysis;Interference;Predictive models;Optical fiber networks;Generative adversarial networks;Generators;Polymer Intrinsic Viscosity prediction;Incomplete data;GAN;Informer},
  doi={10.1109/ICAC57885.2023.10275144},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10498369,
  author={Kotin, Kiran Kashinath and Kumar, Sharan and Alabdeli, Haider and Kumar, Gotte Ranjith and A C, Ramachandra},
  booktitle={2024 International Conference on Integrated Circuits and Communication Systems (ICICACS)}, 
  title={Transformer Encoder and Decoder Method for Forest Estimation and Change Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Forest Change Detection (FCD) is difficult component of natural assess monitoring and conservation strategy, enabled informing decision-making. Different techniques using strength of Artificial Intelligence (AI) has implemented to detect and classify modifications in forest cover by Remote Sensing (RS) data. In this research, proposed a Transformer Encoder and Decoder (TED) method for forest estimation and change detection. The Multi Feature Fusion (MFF) is used for effective combine features of various scales. Next, Multilevel decoding named as Multi Scale and Multi Decoder (MSMD) is used at fine the scales much excessively. At last, loss is function is used for minimizing loss of MSMD. The performance of proposed method is analysed with performance measures of Intersection over Union (IoU) and Accuracy. The proposed method attained IoU of 86.23% and 87.45% in forest and background Attained mIoU of 85.21% and 88.92% in forest and background respectively. The proposed method attained accuracy of 92.89% and 92.33% in forest and background. Attained mAcc of 90.54% and 91.48% in forest and background respectively. The proposed method performed effective than previous methods like Multiscale Channelwise Cross Attention Network (MCCANet), UNet and Generative Adversarial Networks (GAN).},
  keywords={Integrated circuits;Estimation;Forestry;Transformers;Generative adversarial networks;Decoding;Sensors;Forest Change Detection;Multi Feature Fusion;Multi Scale and Multi Decoder;Remote Sensing and Transformer Encoder and Decoder},
  doi={10.1109/ICICACS60521.2024.10498369},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10677615,
  author={Liu, Fang and Ding, Bosheng and Guan, Chong and Zhang, Wei and Niyato, Dusit and Tan, Justina},
  booktitle={2024 IEEE Annual Congress on Artificial Intelligence of Things (AIoT)}, 
  title={Demystify Adult Learning: A Social Network and Large Language Model Assisted Approach}, 
  year={2024},
  volume={},
  number={},
  pages={207-212},
  abstract={Adult learning is increasingly recognized as a crucial way for personal development and societal progress. It however is challenging, and adult learners face unique challenges such as balancing education with other life responsibilities. Collecting feedback from adult learners is effective in understanding their concerns and improving learning experiences, and social networks provide a rich source of real-time sentiment data from adult learners. Machine learning technologies especially large language models (LLMs) perform well in automating sentiment analysis. However, none of such models is specialized for adult learning with accurate sentiment understanding. In this paper, we present A-Learn, which enhances adult learning sentiment analysis by customizing existing general-purpose LLMs with domain-specific datasets for adult learning. We collect adult learners’ comments from social networks and label the sentiment of each comment with an existing LLM to form labelled datasets tailored for adult learning. The datasets are used to customize A-Learn from several base LLMs. We conducted experimental studies and the results reveal A-Learn’s competitive sentiment analysis performance, achieving up to 91.3% accuracy with 20% improvement over the base LLM. A-Learn is also employed for word cloud analysis to identify key concerns of adult learners. The research outcome of this study highlights the importance of applying machine learning with educational expertise for teaching improvement and educational innovations that benefit adult learning and adult learners.},
  keywords={Training;Sentiment analysis;Technological innovation;Accuracy;Social networking (online);Large language models;Social sciences;social network;large language model;generative artificial intelligence;sentiment analysis;applied artificial intelligence;adult learning},
  doi={10.1109/AIoT63253.2024.00048},
  ISSN={},
  month={July},}@INPROCEEDINGS{10984062,
  author={Walia, Sanat and Singh, Neetu and Shetty, Ayush and Gupta, Richa and F, Abdul Manaf and Prasad, Rahul},
  booktitle={2024 Eighth International Conference on Parallel, Distributed and Grid Computing (PDGC)}, 
  title={Exploring the StyleGANEX for Morphing Faces with Indian Ethnicity}, 
  year={2024},
  volume={},
  number={},
  pages={437-442},
  abstract={This research explores an approach to face morphing using StyleGANEX, a cutting-edge Generative Adversarial Network (GAN). By projecting source and target images into StyleGANEX’s latent space and interpolating their latent vectors, we achieve a seamless transition between faces, emphasizing realism and visual fidelity. The pre-processing stage integrates facial landmark detection for precise image cropping, ensuring optimal facial feature alignment. The resultant morphed images effectively blended characteristics from both source and target, demonstrating potential applications in entertainment and advanced image manipulation techniques. In this analysis, we specifically blended Indian faces to generate morphing in Indian ethnicity. We observed that StyleGANEX generates high-quality visual results on Indian faces when compared with StyleGAN due to the optimization in latent spaces. Further, StyleGANEX is faster, requires less time for the same number of optimization steps in morphing.},
  keywords={Visualization;Interpolation;Ethnicity;Entertainment industry;Generative adversarial networks;Grid computing;Vectors;Faces;Optimization;Facial features;Indian Faces;Interpolation;Latent vector space;morphing;StyleGAN;StyleGANEX},
  doi={10.1109/PDGC64653.2024.10984062},
  ISSN={2573-3079},
  month={Dec},}@INPROCEEDINGS{11095146,
  author={Zang, Qi and Zhao, Dong and Wang, Shuang and Quan, Dou and Zhong, Zhun},
  booktitle={2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Feature Spectrum Learning for Remote Sensing Change Detection}, 
  year={2025},
  volume={},
  number={},
  pages={12647-12657},
  abstract={Change detection (CD) holds significant implications for Earth observation, in which pseudo-changes between bitemporal images induced by imaging environmental factors are key challenges. Existing methods mainly regard pseudo-changes as a kind of style shift and alleviate it by transforming bitemporal images into the same style using generative adversarial networks (GANs). Nevertheless, their efforts are limited by the complexity of optimizing GANs and the absence of guidance from physical properties. This paper finds that the spectrum transformation (ST) has the potential to mitigate pseudo-changes by aligning in the frequency domain carrying the style. However, the benefit of ST is largely constrained by two drawbacks: 1) limited transformation space and 2) inefficient parameter search. To address these limitations, we propose a Feature Spectrum learning (FeaSpect) that adaptively eliminate pseudo-changes in the latent space. For the drawback 1), FeaSpect directs the transformation towards stylealigned discriminative features via feature spectrum transformation (FST). For the drawback 2), FeaSpect allows FST to be trainable, efficiently discovering optimal parameters via extraction box with adaptive attention and extraction box with learnable strides. Extensive experiments on challenging datasets demonstrate that our method remarkably outperforms existing methods and achieves a commendable trade-off between accuracy and efficiency. Importantly, our method can be easily injected into other frameworks, achieving consistent improvements.},
  keywords={Accuracy;Prevention and mitigation;Frequency-domain analysis;Imaging;Feature extraction;Generative adversarial networks;Environmental factors;Pattern recognition;Remote sensing;Optimization},
  doi={10.1109/CVPR52734.2025.01180},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{9800717,
  author={Sadiki, Siham and Ibadah, Nisrine and Minaoui, Khalid and Benavente-Peces, César},
  booktitle={2022 11th International Symposium on Signal, Image, Video and Communications (ISIVC)}, 
  title={Efficient mobility modeling of autonomous movement planning trajectories using AI algorithms}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={The path planning plays an important role for autonomous systems. Efficient comprehension of the surrounding environment and the effective generation of an optimal collision-free path are two essential elements to resolve a path planning problem. Artificial intelligence permits solving issues related to path planning, where several algorithms are currently implemented for this purpose. In this work, we will consider analytically and theoretically four AI algorithms, namely: RRT, RRT*, Q-Learning and GAN. We will demonstrate the different parameters affecting each algorithm to finally perform a performance analysis for various optimization metrics like execution time through simulation based experiments. Besides implementing each algorithm, we present a reliable contribution of parameters by exploring new environments to give a mobile node fixed trajectories for independent and autonomous mobilities.},
  keywords={Measurement;Analytical models;Machine learning algorithms;Q-learning;Trajectory planning;Heuristic algorithms;Reliability theory;Autonomous mobility;Movement planning;AI algorithm;RRT;RRT*;Q-learning;GAN},
  doi={10.1109/ISIVC54825.2022.9800717},
  ISSN={},
  month={May},}@INPROCEEDINGS{11114014,
  author={M, Murali and N, Haridra and S, Hariharan and NP, Monishasri and K, Kesavan},
  booktitle={2025 5th International Conference on Expert Clouds and Applications (ICOECA)}, 
  title={Secure Access: A Multimodal Authentication and Thread Detection System for Person in Residence Halls}, 
  year={2025},
  volume={},
  number={},
  pages={70-75},
  abstract={This project enhances facial recognition accuracy using state-of-the-art machine learning and computer vision techniques. It employs Haar Cascades for real-time face detection and a ResNet-based model for precise feature extraction, improving both speed and accuracy. To tackle lighting variations, diverse poses, and facial changes, a Generative Adversarial Network (GAN) is used for data augmentation, generating diverse synthetic images to enhance model adaptability. This ensures reliable performance across different environments. While the primary focus is on facial recognition and augmentation, SHA-256 password hashing is implemented for secure authentication. By combining traditional feature extraction with deep learning advancements, this system improves recognition accuracy, robustness, and adaptability in real-world scenarios..},
  keywords={Adaptation models;Accuracy;Face recognition;Computational modeling;Authentication;Passwords;Generative adversarial networks;Feature extraction;Robustness;Real-time systems;SHA-256;facial recognition},
  doi={10.1109/ICOECA66273.2025.00023},
  ISSN={},
  month={March},}@ARTICLE{10554659,
  author={Salierno, Giulio and Leonardi, Letizia and Cabri, Giacomo},
  journal={IEEE Open Journal of Intelligent Transportation Systems}, 
  title={A Big Data Architecture for Digital Twin Creation of Railway Signals Based on Synthetic Data}, 
  year={2024},
  volume={5},
  number={},
  pages={342-359},
  abstract={Industry 5.0 has introduced new possibilities for defining key features of the factories of the future. This trend has transformed traditional industrial production by exploiting Digital Twin (DT) models as virtual representations of physical manufacturing assets. In the railway industry, Digital Twin models offer significant benefits by enabling anticipation of developments in rail systems and subsystems, providing insight into the future performance of physical assets, and allowing testing and prototyping solutions prior to implementation. This paper presents our approach for creating a Digital Twin model in the railway domain. We particularly emphasize the critical role of Big Data in supporting decision-making for railway companies and the importance of data in creating virtual representations of physical objects in railway systems. Our results show that the Digital Twin model of railway switch points, based on synthetic data, accurately represents the behavior of physical railway switches in terms of data points.},
  keywords={Rail transportation;Switches;Digital twins;Big Data;Data models;Computer architecture;Synthetic data;Machine learning;Artificial intelligence;Computer architecture;Big data;digital twin;machine learning;synthetic data;railway industry;artificial intelligence},
  doi={10.1109/OJITS.2024.3412820},
  ISSN={2687-7813},
  month={},}@ARTICLE{11106267,
  author={Xue, Haiwei and Luo, Xiangyang and Hu, Zhanghao and Zhang, Xin and Xiang, Xunzhi and Dai, Yuqin and Liu, Jianzhuang and Zhang, Zhensong and Li, Minglei and Yang, Jian and Ma, Fei and Wu, Zhiyong and Yang, Changpeng and Dai, Zonghong and Yu, Fei Richard},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Human Motion Video Generation: A Survey}, 
  year={2025},
  volume={},
  number={},
  pages={1-20},
  abstract={Human motion video generation has garnered significant research interest due to its broad applications, enabling innovations such as photorealistic singing heads or dynamic avatars that seamlessly dance to music. However, existing surveys in this field focus on individual methods, lacking a comprehensive overview of the entire generative process. This paper addresses this gap by providing an in-depth survey of human motion video generation, encompassing over ten sub-tasks, and detailing the five key phases of the generation process: input, motion planning, motion video generation, refinement, and output. Notably, this is the first survey that discusses the potential of large language models in enhancing human motion video generation. Our survey reviews the latest developments and technological trends in human motion video generation across three primary modalities: vision, text, and audio. By covering over two hundred papers, we offer a thorough overview of the field and highlight milestone works that have driven significant technological breakthroughs. Our goal for this survey is to unveil the prospects of human motion video generation and serve as a valuable resource for advancing the comprehensive applications of digital humans. A complete list of the models examined in this survey is available in Our Repository.},
  keywords={Videos;Surveys;Planning;Electronic mail;Humanities;Diffusion models;Animation;Training;Reviews;Pipelines;Human Motion Video Generation;Multi-Modal Generation;Generative AI},
  doi={10.1109/TPAMI.2025.3594034},
  ISSN={1939-3539},
  month={},}@INPROCEEDINGS{10837153,
  author={Roy, Biswajit Nath and Maity, Soumik and Singh, Kabir Raj and Chowdhury, Pankaj and Das, Arijit and Saha, Diganta},
  booktitle={2024 International Conference on Intelligent Computing and Emerging Communication Technologies (ICEC)}, 
  title={ECGText: Crafting Emotional Texts through GenAI}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The generation of emotionally nuanced text is a growing area of interest in AI, particularly in enhancing human-machine interaction. This paper presents ECGText (Emotionally Cognizant Generation of Text), a novel model that integrates emotional intelligence into GPT-based text generation. The motivation behind this study stems from the limitations of current text generation models, which lack the ability to generate emotionally resonant content. By incorporating sentiment analysis and emotion recognition into the text generation process, ECGText produces emotionally appropriate outputs, enhancing engagement and relatability. Through comprehensive experiments and evaluations using diverse datasets, results demonstrate that ECGText outperforms baseline models in generating sentiment-rich text while maintaining coherence and fluency. This study advances the field of AI-driven communication, bridging the gap between machine-generated text and human emotional expression.},
  keywords={Human computer interaction;Sentiment analysis;Emotion recognition;Coherence;User experience;Communications technology;Artificial intelligence;Audio-visual systems;Generative AI;Text Generation;Robot with Sentiment;Enhancing GPT;ECGText},
  doi={10.1109/ICEC59683.2024.10837153},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8634677,
  author={Yuan, Ye and Zhang, Yong and Wang, Shaofan and Yin, Baocai},
  booktitle={2018 7th International Conference on Digital Home (ICDH)}, 
  title={Sparse Representation-Based Face Object Generative via Deep Adversarial Network}, 
  year={2018},
  volume={},
  number={},
  pages={57-63},
  abstract={How to generate well quality faces objects of automated processes has always been the focus on researchers. Recently, due to the deep generative networks have achieved impressive successes in data generative fields, researchers have tried to introduce deep learning into the 3d objects generate field, such as text2scene, slice-based object generate. However, the generative ability in 3D object is limited by the size of the feature space, because of computational space limitations on hardware. In this paper, we address the problem by reducing amount of calculated on process of learning, and thus generative newly different objects. The problem is intractable, since first the limiting of compute space is so hard that object can't be process in deep network due to the process need to compute many matrix multiplications. To resolve the problem, we propose a sparse representation-based method of generating well-quality faces object. Our method consists of two parts: sparse reconstruction and object generative. First, we verified the possibility of using sparse representations of 3D data by reconstructing 3D object. Second, we design a network architecture of deep adversarial network of generating new sparse representation and combined with the previous reconstruction method of generating new face object. Experiments show that our method has the ability to generate very different and well quality faces objects that contain tens of thousands of points and meshes. Our findings show that sparse representation can be used in 3D object reconstruction and generate via deep generative adversarial model.},
  keywords={Face;Three-dimensional displays;Image reconstruction;Deep learning;Task analysis;Dictionaries;Artificial Intelligence;Machine Learning;Shape Modeling},
  doi={10.1109/ICDH.2018.00019},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10574619,
  author={Vijaya, J. and Gopu, Arunkumar and Suman, Pediredla and Chaitanya, Sambangi},
  booktitle={2024 3rd International Conference on Artificial Intelligence For Internet of Things (AIIoT)}, 
  title={Revolutionising Image Enhancement Leveraging Power OF CNN’S}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Image restoration has several uses, remote sensing, surveillance, medical imaging, and computational photography. Recovering high-quality image content from lower-quality images is its goal. Convolutional neural networks (CNN’s) have shown better results than the existing methods for image restoration in amazing ways. Many of the present CNN-based methods work with either fully-resolution or lower-resolution representations. While the second scenario produces acceptably trustworthy but spatially less accurate outputs, the first instance gives spatially the same but contextually less accurate results, Image restoration has several uses, in the medical field, traffic policies and criminal investigation, and astronomical image enhancement Its purpose is to recover greater quality image content from its old version, which has less quality So, having the overall aim of maintaining spatially intact higher quality representations over the whole network and gaining the maximum contextual information from the previous lower resolution representations. In previous projects, they used RNN and CNN to get the output we are using CNN and aim for better output by doing the project in our kind of way. Our project’s crucial component is a multi-scale residual block, which is made up of several vital components, including (a)exchange of information between the multiresolution streams, (b) channel and special attention mechanisms for contextual information capturing (c) parallel multi-resolution convolution streams for the extracting multi-scaled features,(d) attention multi-scale feature aggregation. In brief, our project will aim towards learning a bunch of features that will maintain higher resolution spatial information and details while combining contextual data from various scales. Thereby increasing the image quality to a greater version resolution, physical constraints, low dynamic range, downsampling, spatial features, and receptive area.},
  keywords={Accuracy;Surveillance;Feature extraction;Image restoration;Convolutional neural networks;Spatial resolution;Streams;Image denoising;Convolutional neural networks;multi-resolution;encoder-decoder},
  doi={10.1109/AIIoT58432.2024.10574619},
  ISSN={},
  month={May},}@ARTICLE{11077808,
  author={Sun, Jiaxiang and Zhao, Rong and Lin, Lehao and Chi, Yuanfang and Leung, Victor C.M. and Cai, Wei},
  journal={IEEE Systems, Man, and Cybernetics Magazine}, 
  title={Blockchain-Based AI-Generated Content (AIGC) Zero-Knowledge Dataset Regulation System: Introducing a Novel System}, 
  year={2025},
  volume={11},
  number={3},
  pages={24-33},
  abstract={The popularity of artificial intelligence (AI)-generated content (AIGC) has experienced significant growth recently. Despite AIGC’s potential to transform content creation in various industries, its dependence on extensive computational resources poses a challenge for widespread adoption. To address this challenge, AIGC as a service has been proposed. However, concerns related to dataset compliance have emerged as a source of apprehension among stakeholders. The complexities associated with manual supervision, apprehensions regarding data leakage, and the potential for malicious behavior by third-party supervisors collectively present formidable challenges in the regulation of datasets within the domain of AIGC service. To tackle these challenges, this article presents a blockchain-based system for regulating AIGC datasets. Our proposed system employs AI, zero-knowledge proofs, and smart contracts as integral components for overseeing dataset compliance. To assess the feasibility and effectiveness of the proposed system, a comprehensive analysis and a series of simulations have been conducted. These evaluations offer valuable insights into the system’s security, privacy, and performance.},
  keywords={Measurement;Privacy;Analytical models;Smart contracts;Transforms;Regulation;Complexity theory;Security;Stakeholders;Artificial intelligence;Generative AI},
  doi={10.1109/MSMC.2024.3482691},
  ISSN={2333-942X},
  month={July},}@INPROCEEDINGS{10882325,
  author={Sharma, Saurabh and Mannepalli, Praveen Kumar and Chourasia, Harshita},
  booktitle={2024 International Conference on Artificial Intelligence and Quantum Computation-Based Sensor Application (ICAIQSA)}, 
  title={Exploring Cutting-Edge Deep Learning Techniques in Image Processing}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This research delves into advanced image processing techniques for computer vision applications. A wide range of feature extraction methods, including LBP, LTP, RGB channel splitting, histogram equalization, grayscale conversion, and resizing are also explored. K-Mean Clustering (K=2) aids in image segmentation. Color transformations like negation, log, and gamma correction are employed. Color spaces (HSV, LAB, YCrCb) are explored. Shape analysis is conducted via GLCM and Haralick Texture analysis. Image sharpening involves Prewitt, Scharr, Sobel filters, and frequency domain analysis using Gaussian filters. This work contributes to enhanced image analysis for various applications.},
  keywords={Image segmentation;Filters;Quantum computing;Shape;Image color analysis;Transportation;Transforms;Robustness;Public security;Security;Image Processing;Feature Extraction;Image Segmentation;Color Transformation;Shape Analysis;Image Sharpening;Computer Vision},
  doi={10.1109/ICAIQSA64000.2024.10882325},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11034613,
  author={Shen, Zepeng and Zhang, Junyi and Chew, Jiajia and Xiao, Xingpeng and Zhang, Yaomin},
  booktitle={2025 4th International Conference on Artificial Intelligence, Internet and Digital Economy (ICAID)}, 
  title={Research on Application of Whale Optimization Algorithm in Financial Payment Fraud Detection}, 
  year={2025},
  volume={},
  number={},
  pages={47-50},
  abstract={Due to the rise in fraudulent activity in financial payment systems, accurate and efficient methods of fraud detection have become paramount for financial security. To address the limitations of traditional machine learning methods on complex and high dimensional financial data, this research presents a Whale Optimization Algorithm (WOA) based financial payment fraud detection model to enhance the detection performance. On the one hand, in order to solve the convergence speed and local optimality of WOA, this paper proposes an adaptive weight adjustment strategy, which can dynamically adjust the movement strategy of individual whales according to the feedback in the search process, so as to avoid falling into local optimal and accelerate global search. Secondly, in order to enhance the stability of the algorithm, the simulated annealing mechanism is integrated with WOA to further optimize the global search ability. Finally, the adaptive feature selection method is integrated into the model, which is used to optimize the feature subset through WOA, retain the features highly related to fraudulent behavior, and reduce the interference and influence of redundant information on the model. Experimental results demonstrate that the improved WOA algorithm achieves higher detection rate and lower false positive rate compared to the traditional WOA and other commonly used algorithm in multiple real financial payment dataset fraud detection tasks.},
  keywords={Adaptation models;Heuristic algorithms;Simulated annealing;Feature extraction;Whale optimization algorithms;Data models;Stability analysis;Fraud;Classification algorithms;Thermal stability;Whale Optimization Algorithm;Financial Payment Fraud Detection;Feature Selection;Optimization Algorithm},
  doi={10.1109/ICAID65275.2025.11034613},
  ISSN={},
  month={April},}@INPROCEEDINGS{10823040,
  author={Guo, Hongrui and Luo, Yuanshuai and Wang, Caoyan and Zheng, Kaiyang and Wang, Zihan and Liu, Xiwei},
  booktitle={2024 6th International Conference on Artificial Intelligence and Computer Applications (ICAICA)}, 
  title={Research on Hyperparameter Optimization Strategy of Lightweight ViT Model Based on SVM}, 
  year={2024},
  volume={},
  number={},
  pages={261-265},
  abstract={This paper investigates a lightweight Vision Transformer (Vi $T$) model based on Support Vector Machine (SVM) optimization, using methods such as structural optimization and hyperparameter optimization that introduce SVM into the ViT model, with the aim of improving the model's performance in target detection tasks. This study addresses several aspects of the lightweight ViT model structure design, SVM optimization strategy, and analysis of the total optimization process. First, SVM is introduced into the structural design of the Vi $T$ model to optimize the feature extraction process. Second, by optimizing the hyperparameters of the ViT model, the training process of the model is accelerated with the powerful classification ability of SVM. Finally, the overall optimization process is analyzed and experimentally validated to demonstrate the superior performance of the optimized model in the target detection task on standard datasets such as the COCO dataset. The introduction of Support Vector Machines (SVMs) into the Vision Transformer (ViT) model allows the model parameters to be effectively reduced in resource-constrained scenarios, improves the training and inference speeds, and significantly improves the overall performance of the model.},
  keywords={Support vector machines;Training;Computer vision;Analytical models;Accuracy;Computational modeling;Object detection;Transformers;Hyperparameter optimization;Optimization;Support Vector Machine (SVM);Vision Transformer (ViT);Lightweight Models;Hyperparametric Optimization},
  doi={10.1109/ICAICA63239.2024.10823040},
  ISSN={2833-8413},
  month={Nov},}@INPROCEEDINGS{10690068,
  author={Deshpande, Himani and Chaudhari, Dhawal and Sarode, Tanmay and Kamath, Ayush},
  booktitle={2024 5th International Conference on Electronics and Sustainable Communication Systems (ICESC)}, 
  title={Exploring LLM and Neural Networks Towards Malicious Prompt Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1531-1535},
  abstract={Atthe forefront of the Artificial Intelligence Revolution is the Generative AI domain which is making splashes in generation of new content from existing Large Language Models. Large Language Models (LLMs) are flexible, effective tools with many uses. On the other hand, they can be tricked by devious provocation. This work explores the detection of fraudulent prompts intended to produce false or damaging outputs using Long Short-Term Memory (LSTM) networks. During this study we analysed the LTSM model against a neural network model. We found a 91.69% accuracy for the LTSM model and a 92.52% accuracy for the simple neural network. However, the simple neural network had a higher F1 score of 0.73 compared to the LTSM score of 0.69. We found that the standard neural model is more efficient at identifying harmful user prompts. Our research highlights the need for taking into account various architectures of models to reduce the risk of malicious prompting in language learning models.},
  keywords={Training;Measurement;Analytical models;Accuracy;Computational modeling;Large language models;Neural networks;Security;Long short term memory;Standards;Malicious prompting;Neural Networks;Long Short Term Memory Models;Generative AI},
  doi={10.1109/ICESC60852.2024.10690068},
  ISSN={2996-5357},
  month={Aug},}@INPROCEEDINGS{11064532,
  author={Gupta, Vinayak and Mishra, Naman and Dash, Yajnaseni and Kumar, Upendra and Abraham, Ajith},
  booktitle={2025 3rd International Conference on Communication, Security, and Artificial Intelligence (ICCSAI)}, 
  title={Graph Convolutional Network-Driven Adaptive Learning Framework for Fraud Detection in Complex Transactional Cryptonetworks}, 
  year={2025},
  volume={3},
  number={},
  pages={685-689},
  abstract={With a growing need to tackle the issue of fraudulent transactions in the financial domain, especially with the boom of cryptocurrency. This study proposes a Graph Convolutional Network (GCN)--based classification model for detecting fraudulent transactions by leveraging graph-structured data. Traditional classification methods often fail to capture complex topological dependencies within financial networks, whereas GCNs effectively learn from node connectivity and feature propagation. The dataset undergoes extensive preprocessing, including KNN imputation, power transformations, polynomial feature engineering, and variance thresholding, ensuring optimal feature selection. To address the class imbalance, a hybrid SMOTE-ADASYN resampling technique is employed. Experimental results demonstrate that the proposed GCN outperforms CatBoost, XGBoost, SVM, Logistic Regression, and Random Forest, achieving an accuracy of 98.75% and an AUC score of 0.97. Additionally, subgraph visualizations provide interpretability into model predictions. This work establishes GCNs as a superior alternative for fraud detection in transaction networks.},
  keywords={Training;Adaptation models;Accuracy;Graph convolutional networks;Data visualization;Predictive models;Polynomials;Data models;Fraud;Cryptocurrency;Graph Convolutional network;Fraud Detection;Cryptocurrency;Graph anomaly detection},
  doi={10.1109/ICCSAI64074.2025.11064532},
  ISSN={},
  month={April},}@ARTICLE{9512395,
  author={He, Dongxiao and Wang, Tao and Zhai, Lu and Jin, Di and Yang, Liang and Huang, Yuxiao and Feng, Zhiyong and Yu, Philip S.},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Adversarial Representation Mechanism Learning for Network Embedding}, 
  year={2023},
  volume={35},
  number={2},
  pages={1200-1213},
  abstract={Network embedding which is to learn a low dimensional representation of nodes in a network has been used in many network analysis tasks. Some network embedding methods, including those based on Generative Adversarial Networks (GAN) (a promising deep learning model), have been proposed recently. Existing GAN-based methods typically use GAN to learn a Gaussian distribution as a prior for network embedding, which makes it difficult to distinguish the node representation from Gaussian distribution. It did not apply the adversarial learning strategy on the representation mechanism but just on representation results. Thus, it does not make full use of the essential advantage of GAN, and leads to compromised performance of the method. To address this problem, we propose a novel adversarial learning framework consisting of three players for network embedding, which applies the adversarial learning strategy on the representation mechanism, called Adversarial representation mechanism GAN (ArmGAN). Specifically, the first two players, named encoder and competitor, aim to learn two different representation mechanisms (i.e., two ways projecting data onto latent space). They compete with each other to improve their representation mechanisms. The third player is the discriminator, which discriminate the representation mechanism of the encoder from that of the competitor. In addition, we design a perturbation strategy to produce fake networks from the original network, and feed the fake networks to the competitor to obtain a “fake” representation mechanism. We evaluated ArmGAN on a variety of tasks including node clustering, node classification, link prediction and visualization. Moreover, we compared ArmGAN with 10 state-of-the-art methods (including DGI, which is well-known for its high accuracy) on 7 real-world networks. The experimental results show the significant superiority of ArmGAN over the existing methods.},
  keywords={Generative adversarial networks;Gaussian distribution;Topology;Network topology;Generators;Games;Task analysis;Network embedding;generative adversarial network;graph neural network;social network analysis},
  doi={10.1109/TKDE.2021.3103193},
  ISSN={1558-2191},
  month={Feb},}@INPROCEEDINGS{9362090,
  author={Gong, Xun and Chen, Zhengyang and Yang, Yexin and Wang, Shuai and Wang, Lan and Qian, Yanmin},
  booktitle={2021 12th International Symposium on Chinese Spoken Language Processing (ISCSLP)}, 
  title={Speaker Embedding Augmentation with Noise Distribution Matching}, 
  year={2021},
  volume={},
  number={},
  pages={1-5},
  abstract={Data augmentation (DA) is an effective strategy to help building robust systems with good generalization ability. In the embedding based speaker verification, data augmentation could be applied to either the front-end embedding extractor or the back-end PLDA. Unlike the conventional back-end augmentation method which adds noises to the raw audios and then extracts augmented embeddings, in this work, we proposed a noise distribution matching (NDM) based algorithm in the speaker embedding space. The basic idea is to use distributions such as Gaussian to model the difference between the clean and original augmented noisy speaker embeddings. Experiments are carried out on SRE16 dataset, where consistent performance improvement could be obtained by the novel NDM. Furthermore, we found that the proposed NDM could be robustly estimated using only a small amount of training data, which saves time and disk cost compared to the conventional augmentation method.},
  keywords={Image color analysis;Training data;Data visualization;Manuals;Gaussian distribution;Noise measurement;Data mining;speaker embedding;data augmentation;distribution matching;speaker verification},
  doi={10.1109/ISCSLP49672.2021.9362090},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10099324,
  author={Sharif, Hanan and Rehman, Faisal and Rida, Amina and Nouman Ali, Chaudhry and Zeeshan Zulfiqar, Rana and Akram, Salman and Kirn, Hina and Hussain, Ayaz and Iftikhar, Razia},
  booktitle={2023 4th International Conference on Computing, Mathematics and Engineering Technologies (iCoMET)}, 
  title={Application of Artificial Neural Networks inSatellite Imaging – A Systematic Review}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Artificial Neural Networks (ANN) and deep learning have been instrumental in the advancement of technology around the world for about 50 years, but because of the high costs associated with developing an optimal training and testing dataset, researchers have had to deal with several issues such as segmentation of images with low spatial resolution, object recognition, classification, and their use in the processing of satellite images has yet to reach its full potential. This work includes a thorough assessment of a significant body of research literature as well as the most important publications released in the last decade. The IEEE digital library, Science Direct, and SCOPUS system database indexing repository were the key sources for the review after applying various criteria, 386 publications pertaining to the case study were discovered. With 30 of them, grounds for exclusion and inclusion are discussed in further detail. Finding an upward trend in the level of research done in recent years indicates that this artificial neural network technology is getting more and more popular and curious.},
  keywords={Deep learning;Training;Satellites;Systematics;Optical distortion;Optical sensors;Object recognition;satellite imaging;neural networks;deep learning;artificial neural networks},
  doi={10.1109/iCoMET57998.2023.10099324},
  ISSN={},
  month={March},}@ARTICLE{9732069,
  author={Tang, Hao and Shao, Ling and Torr, Philip H.S. and Sebe, Nicu},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Local and Global GANs With Semantic-Aware Upsampling for Image Generation}, 
  year={2023},
  volume={45},
  number={1},
  pages={768-784},
  abstract={In this paper, we address the task of semantic-guided image generation. One challenge common to most existing image-level generation methods is the difficulty in generating small objects and detailed local textures. To address this, in this work we consider generating images using local context. As such, we design a local class-specific generative network using semantic maps as guidance, which separately constructs and learns subgenerators for different classes, enabling it to capture finer details. To learn more discriminative class-specific feature representations for the local generation, we also propose a novel classification module. To combine the advantages of both global image-level and local class-specific generation, a joint generation network is designed with an attention fusion module and a dual-discriminator structure embedded. Lastly, we propose a novel semantic-aware upsampling method, which has a larger receptive field and can take far-away pixels that are semantically related for feature upsampling, enabling it to better preserve semantic consistency for instances with the same semantic labels. Extensive experiments on two image generation tasks show the superior performance of the proposed method. State-of-the-art results are established by large margins on both tasks and on nine challenging public benchmarks. The source code and trained models are available at https://github.com/Ha0Tang/LGGAN.},
  keywords={Semantics;Image synthesis;Task analysis;Generators;Kernel;Generative adversarial networks;Interpolation;GANs;local and global;feature upsampling;semantic-guided;image generation},
  doi={10.1109/TPAMI.2022.3155989},
  ISSN={1939-3539},
  month={Jan},}@ARTICLE{10553643,
  author={Karnouskos, Stamatis},
  journal={IEEE Open Journal of the Industrial Electronics Society}, 
  title={The Relevance of Large Language Models for Project Management}, 
  year={2024},
  volume={5},
  number={},
  pages={758-768},
  abstract={The rise of artificial intelligence, particularly the emergence of large language models (LLMs) like ChatGPT, continuously reveals numerous advantages across various domains. However, the area of project management has not yet been sufficiently explored. This study fills the research gap by conducting an empirical evaluation of three well-known LLMs: OpenAI's ChatGPT-3.5 and ChatGPT-4, as well as Google's Bard. The evaluation involves subjecting these LLMs to tests designed to prepare professionals for project management certification by the Project Management Institute. The findings cast a positive light on all three LLMs, with each model achieving scores exceeding 82%. Key insights acquired include: LLMs demonstrate the ability to effectively answer project management certification exam questions; LLMs and project managers should be viewed as a dynamic and complementary partnership; and project management certification should evolve to include an assessment of how project managers collaborate with LLMs to enhance project management.},
  keywords={Project management;Certification;Chatbots;Best practices;Generative AI;Artificial intelligence;Large language models;Bard;ChatGPT;Generative artificial intelligence (AI);large language models (LLMs);project management},
  doi={10.1109/OJIES.2024.3412222},
  ISSN={2644-1284},
  month={},}@ARTICLE{10541919,
  author={Coeurdoux, Florentin and Dobigeon, Nicolas and Chainais, Pierre},
  journal={IEEE Transactions on Image Processing}, 
  title={Plug-and-Play Split Gibbs Sampler: Embedding Deep Generative Priors in Bayesian Inference}, 
  year={2024},
  volume={33},
  number={},
  pages={3496-3507},
  abstract={This paper introduces a stochastic plug-and-play (PnP) sampling algorithm that leverages variable splitting to efficiently sample from a posterior distribution. The algorithm based on split Gibbs sampling (SGS) draws inspiration from the half quadratic splitting method (HQS) and the alternating direction method of multipliers (ADMM). It divides the challenging task of posterior sampling into two simpler sampling problems. The first problem depends on the likelihood function, while the second is interpreted as a Bayesian denoising problem that can be readily carried out by a deep generative model. Specifically, for an illustrative purpose, the proposed method is implemented in this paper using state-of-the-art diffusion-based generative models. Akin to its deterministic PnP-based counterparts, the proposed method exhibits the great advantage of not requiring an explicit choice of the prior distribution, which is rather encoded into a pre-trained generative model. However, unlike optimization methods (e.g., PnP-ADMM and PnP-HQS) which generally provide only point estimates, the proposed approach allows conventional Bayesian estimators to be accompanied by confidence intervals at a reasonable additional computational cost. Experiments on commonly studied image processing problems illustrate the efficiency of the proposed sampling strategy. Its performance is compared to recent state-of-the-art optimization and sampling methods.},
  keywords={Noise reduction;Stochastic processes;Inverse problems;Data models;Bayes methods;Task analysis;Kernel;Bayesian inference;plug-and-play prior;deep generative model;diffusion-based model;Markov chain Monte Carlo;inverse problem},
  doi={10.1109/TIP.2024.3404338},
  ISSN={1941-0042},
  month={},}@INPROCEEDINGS{11159184,
  author={Dominguez, Caroline and Pessoa, Kaline Ligia and Morais, Ana and Cruz, Gonçalo},
  booktitle={2025 6th International Conference of the Portuguese Society for Engineering Education (CISPEE)}, 
  title={How Do Engineering Students View And Use Generative AI For Learning? Exploring Their Habits, Beliefs, And Attitudes}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The emergence of Generative Artificial Intelligence (GAI) is reshaping engineering education. This study explores engineering students’ perceptions of the use of GAI tools to support their learning, focusing on three dimensions: 1) perceived ease of use and usefulness, 2) personalization, interactivity, and confidence, and 3) perceived intelligence and intention to adopt. A descriptive quantitative design was employed, involving 66 BSc and MSc engineering students from a Portuguese university who responded to a 49-item survey. The survey was designed ad hoc by the authors, drawing on recent instruments developed to assess higher education students’ perceptions of GAI use and adoption for learning (e.g., TAME-ChatGPT). Overall results show that students find GAI intuitive and beneficial for learning. However, they also recognize the importance of asking good questions and that these tools can dampen creativity and critical thinking. On the one hand, students are optimistic and inclined to adopt them; on the other hand, they voice ethical and reliability concerns (e.g., information credibility, over-reliance, plagiarism). These findings underscore the need for carefully designed, well-founded integration strategies that can both maximize the potential of GAI tools and minimize their pitfalls. Institutional guidelines, faculty professional development, and AI literacy training initiatives for students may play key roles in fostering the responsible and effective adoption of these tools in academic settings.},
  keywords={Surveys;Hands;Training;Generative AI;Plagiarism;Instruments;Focusing;Reliability;Engineering students;Guidelines;generative artificial intelligence;engineering education;student perceptions;technology adoption},
  doi={10.1109/CISPEE64787.2025.11159184},
  ISSN={},
  month={July},}@INBOOK{10952341,
  author={Carpenter, Perry},
  booktitle={FAIK: A Practical Guide to Living in a World of Deepfakes, Disinformation, and AI-Generated Deceptions}, 
  title={The New Frontiers of Deception}, 
  year={2025},
  volume={},
  number={},
  pages={17-35},
  abstract={Summary <p>The quest to create intelligent machines dates back to the early days of computing. From the theoretical foundations laid by pioneers like Alan Turing to the early experiments with neural networks and machine learning in the 1950s and 60s, the field of AI has been driven by a vision of computers that can think, learn, and solve problems in human&#x2010;like ways. As generative AI advances, we'll see an explosion of synthetic media in every domain. Text, images, audio, and video that are generated by AI will increasingly intermingle with authentic, human&#x2010;created content. The ability to generate synthetic media that seamlessly blends with authentic content threatens to erode trust in communication and reality itself and challenges our assumptions about truth and trust. The rise of generative AI represents a pivotal moment in the history of technology and society.</p>},
  keywords={Artificial intelligence;History;Transformers;Law enforcement;Games;Deepfakes;Chaos;Writing;Turning;Speech recognition},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394299904},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952341},}@INPROCEEDINGS{9202722,
  author={Shahriar, Md Hasan and Haque, Nur Imtiazul and Rahman, Mohammad Ashiqur and Alonso, Miguel},
  booktitle={2020 IEEE 44th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={G-IDS: Generative Adversarial Networks Assisted Intrusion Detection System}, 
  year={2020},
  volume={},
  number={},
  pages={376-385},
  abstract={The boundaries of cyber-physical systems (CPS) and the Internet of Things (IoT) are converging together day by day to introduce a common platform on hybrid systems. Moreover, the combination of artificial intelligence (AI) with CPS creates a new dimension of technological advancement. All these connectivity and dependability are creating massive space for the attackers to launch cyber attacks. To defend against these attacks, intrusion detection system (IDS) has been widely used. However, emerging CPS fields suffer from imbalanced and missing sample data, which makes the training of IDS difficult. In this paper, we propose a generative adversarial network (GAN) based intrusion detection system (G-IDS), where GAN generates synthetic samples, and IDS gets trained on them along with the original ones. G-IDS also fixes the difficulties of imbalanced or missing data problems. We model a network security dataset for an emerging CPS using NSL KDD-99 dataset and evaluate our proposed model's performance using different metrics. We find that our proposed G-IDS model performs much better in attack detection and model stabilization during the training process than a standalone IDS.},
  keywords={Gallium nitride;Generative adversarial networks;Intrusion detection;Data models;Databases;Training;Generative Adversarial Networks, Cyber-Physical Systems Security, Intrusion Detection System},
  doi={10.1109/COMPSAC48688.2020.0-218},
  ISSN={0730-3157},
  month={July},}@ARTICLE{10574843,
  author={Rass, Stefan and König, Sandra and Ahmad, Shahzad and Goman, Maksim},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Metricizing the Euclidean Space Toward Desired Distance Relations in Point Clouds}, 
  year={2024},
  volume={19},
  number={},
  pages={7304-7319},
  abstract={We introduce the concept of an  $\varepsilon $ -semimetric that satisfies the same axioms as a topological metric, except for an arbitrarily small allowance to violate the triangle inequality. Under this modification, we demonstrate the possibility of taking arbitrary points in space, assigning arbitrary desired distances between them (independent of their geometric location relative to each other, that is, independent of their “features”), and constructing an  $\varepsilon $ -semimetric that measures exactly the desired distances in the point cloud. This results in a threat to fairness and objectiveness in applications of clustering algorithms: suppose that an adversary subjectively classifies people according to its whim or discriminatory preferences. Upon accusations of unethical behavior, the malicious data processor can plausibly deny these as follows: it designs a distance function (an  $\varepsilon $ -semimetric) that is (up to a fully controllable numeric “round-off-error”  $\varepsilon $ ) equivalent to a standard distance like the Euclidean. However, this crafted distance will exactly reproduce the (malicious) results and thus confirm them while pretending objectivity and transparency, since only standard and explainable artificial intelligence was used. This demonstration works without any data poisoning. We illustrate the method on randomly chosen points with stochastically independent random classifications assigned to them. Then, we apply standard implementations of k-Means and DBSCAN on the data points, which both exactly reproduce the desired (randomly chosen) classes. We also discuss non-adversarial applications of  $\varepsilon $ -semimetrics, and corroborate the construction with examples and implementation in Octave.},
  keywords={Measurement;Clustering algorithms;Noise;Standards;Classification algorithms;Training;Euclidean distance;Adversarial machine learning;trust management;non-repudiation;security;artificial intelligence (AI);data integrity},
  doi={10.1109/TIFS.2024.3420246},
  ISSN={1556-6021},
  month={},}@ARTICLE{9274378,
  author={Cho, Jeongik and Yoon, Kyoungro},
  journal={IEEE Access}, 
  title={Conditional Activation GAN: Improved Auxiliary Classifier GAN}, 
  year={2020},
  volume={8},
  number={},
  pages={216729-216740},
  abstract={A conditional generative adversarial network (cGAN) is a generative adversarial network (GAN) that generates data with a desired condition from a latent vector. Among the different types of cGAN, the auxiliary classifier GAN (ACGAN) is the most frequently used. In this study, we describe the problems of an AC-GAN and propose replacing it with a conditional activation GAN (CAGAN) to reduce the number of hyperparameters and improve the training speed. The loss function of a CAGAN is defined as the sum of the loss of each GAN created for each condition. The proposed CAGAN is an integration of multiple GANs, where each GAN shares all hidden layers, and their integration can be considered as a single GAN. Therefore, the structure of the integrated GANs does not significantly increase the number of computations. Additionally, to prevent the conditions given in the discriminator of a cGAN from being ignored with batch normalization, we propose mixed batch training, in which every batch for the discriminator keeps the ratio of the real and generated data consistent.},
  keywords={Generative adversarial networks;Training;Generators;Gallium nitride;Probability distribution;Entropy;Artificial neural networks;auxiliary classifier GAN;batch normalization;conditional GAN;deep learning;generative adversarial networks;loss function},
  doi={10.1109/ACCESS.2020.3041480},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10420386,
  author={Kumari, Ankita and Dubey, Rajat and Sharma, Ishu},
  booktitle={2023 Annual International Conference on Emerging Research Areas: International Conference on Intelligent Systems (AICERA/ICIS)}, 
  title={ShNP: Shielding Nuclear Plants from Cyber Attacks Using Artificial Intelligence Techniques}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The potentially catastrophic consequences of a security breach at a nuclear site have elevated concerns around cyberattacks targeting such installations. These attacks may aim to compromise the safety, disrupt the functioning, or acquire sensitive data by targeting various aspects of a nuclear power plant's infrastructure and activities. Cyberattacks against nuclear facilities may use several tactics, including but not limited to phishing emails, malware infiltration, code injection deployment, and exploitation of software and hardware flaws. Artificial intelligence has the capability to do behavioral analysis on both individuals and equipment that are linked to the network of a nuclear facility. AI-powered security analytics solutions have the capability to evaluate vast volumes of data provided by diverse security systems, logs, and sensors. This enables security professionals to get valuable insights that can be acted upon effectively. The system has the capability to detect atypical or questionable activities that might potentially signify a cyber assault, such as illegal login attempts or anomalous data transmission trends. In this research work, an artificial intelligence-based model is proposed to shield nuclear plants from cyber-attacks. The nuclear plant attack dataset considering zero-day attacks is investigated in this experimental study to find out the optimal algorithm for training servers in the nuclear plant architecture.},
  keywords={Training;Phishing;Sensor systems;Safety;Security;Servers;Cyberattack;Nuclear Plant;Intrusion Detection;Artificial Intelligence;Web Server;Honeypot;Client Server Communication},
  doi={10.1109/AICERA/ICIS59538.2023.10420386},
  ISSN={},
  month={Nov},}@ARTICLE{11027406,
  author={Mereu, Isabella and Natale, Mariarosaria and Piconi, Michele and Troiani, Alessio and Suriani, Vincenzo and Bloisi, Domenico Daniele and Burghignoli, Paolo and Costarelli, Danilo and Veneri, Alessandro and Comite, Davide},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={Interpolation Theory and Artificial Intelligence: A Roadmap for Satellite Data Augmentation}, 
  year={2025},
  volume={18},
  number={},
  pages={17422-17448},
  abstract={The analysis and processing of satellite remote sensing data have established new paradigms to observe the Earth and to study climate changes. Data collected by sensors and systems operating across the entire frequency spectrum carry on enormous information content. They enable systematic retrieval and characterization of biogeophysical variables. The retrieval of these variables, however, is often hindered by limitations, such as missing data, low spatial and temporal resolutions, and insufficient co-located ancillary data. These challenges arise due to factors, such as sensor limitations, dead pixels, cloud cover, and discontinuous data acquisition. To overcome these issues, numerous techniques have been proposed, ranging from classical interpolation methods and spectral transforms to modern artificial intelligence-based approaches. This article presents a comprehensive and critical review of satellite remote-sensing data augmentation methods, focusing on how interpolation theory and artificial intelligence techniques can be effectively applied to reconstruct missing data and enhance the quality of retrieved biogeophysical variables. This roadmap offers a comprehensive framework that categorizes and evaluates existing methods, highlights their strengths and limitations, and identifies promising areas for future exploration.},
  keywords={Optical sensors;Sensors;Earth;Remote sensing;Optical scattering;Optical reflection;Optical polarization;Optical imaging;Optical filters;Spatial resolution;Climate change;Satellite communications;Remote sensing;Interpolation;Mathematical models;Artificial intelligence;Machine learning;Neural networks;Environmental factors},
  doi={10.1109/JSTARS.2025.3577534},
  ISSN={2151-1535},
  month={},}@INPROCEEDINGS{10719194,
  author={Hao, Qi and Huang, Jie and Wang, Bin and Zhou, Feng},
  booktitle={2024 IEEE 9th International Conference on Computational Intelligence and Applications (ICCIA)}, 
  title={Convolutional Neural Network Image Classification Method Integrating Classic Image Features}, 
  year={2024},
  volume={},
  number={},
  pages={130-135},
  abstract={Classic image features were once widely used in image classification but have been almost entirely replaced by neural networks today. While the performance of neural networks, especially convolutional neural networks (CNNs), is indisputable, their lack of interpretability has become a significant limitation in recent years. This paper explores the effective combination of classic image features and convolutional image features, investigating their differences and similarities. Through a series of experiments, a method is proposed to effectively integrate these two types of features by employing a multiplicative attention mechanism. This approach combines standardized MPEG-7 descriptors with convolutional features before feeding them into the fully connected layer for classification. The final model demonstrates an improvement in classification accuracy and indicates the potential of learning traditional image features from the integrated features.},
  keywords={Attention mechanisms;Accuracy;Computational modeling;Neural networks;Transform coding;Convolutional neural networks;Computational intelligence;Image classification;image classification;mpeg-7 descriptors;convolutional neural networks;feature fusion},
  doi={10.1109/ICCIA62557.2024.10719194},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{7968584,
  author={Udrea, Andreea and Mitra, George Daniel},
  booktitle={2017 21st International Conference on Control Systems and Computer Science (CSCS)}, 
  title={Generative Adversarial Neural Networks for Pigmented and Non-Pigmented Skin Lesions Detection in Clinical Images}, 
  year={2017},
  volume={},
  number={},
  pages={364-368},
  abstract={Skin cancer is one of the most common malignancies in fair skin population. It can be divided in two main classes: melanoma and non-melanoma skin cancer. This means that pigmented and, also, non-pigmented skin lesions might raise an important risk. Due to the fact that melanoma is more aggressive, pigmented skin lesions gained more attention in terms of automatic diagnosis. One of the most important steps in this procedure is to correctly identify the skin lesion in an image (acquired with a dermoscope or a standard camera). Based on the accurate identification of the lesion, specific automatic algorithms for cancer diagnosis can be developed. In this paper we propose and evaluate an artificial intelligence method for pigmented and non-pigmented lesion segmentation. The method uses generative adversarial neural networks. The network was trained and tested on a large set of images acquired with smartphone cameras. The results show that approximately 92% of the lesions are correctly identified on the test set.},
  keywords={Lesions;Skin;Image segmentation;Training;Gallium nitride;Malignant tumors;Generators;pigmented and non-pigmented skin lesions;contour detection;generative adversarial neural network},
  doi={10.1109/CSCS.2017.56},
  ISSN={2379-0482},
  month={May},}@ARTICLE{9395632,
  author={Mirza, Behroz and Haroon, Danish and Khan, Behraj and Padhani, Ali and Syed, Tahir Q.},
  journal={IEEE Access}, 
  title={Deep Generative Models to Counter Class Imbalance: A Model-Metric Mapping With Proportion Calibration Methodology}, 
  year={2021},
  volume={9},
  number={},
  pages={55879-55897},
  abstract={The most pervasive segment of techniques in managing class imbalance in machine learning are re-sampling-based methods. The emergence of deep generative models for augmenting the size of the under-represented class, prompts one to review the question of the suitability of the model chosen for data augmentation with the metric selected for the-goodness-of classification. This work defines this suitability by using newly-sampled data points from each generative model first to the degree of parity, and studying classification performance on a large set of metrics. We extend the investigation to different proportions of augmented data points for identifying the sensitivity of the metric to the degree of imbalance, leading to the discovery of an optimum proportion against the metric. The models used are GAN, VAE and RBM and the metrics include Precision, Recall, F1-Score, AUC, G-Mean and Balanced Accuracy. We offer a comparison of these models with the established class of data synthesizing counterparts on the aforementioned metrics. Deep generative models outperform the state-of-the-art on 5 metrics on multiple datasets and also comprehensively surpass the baselines. This work thereby recommends the following model-metric mappings: VAE for high Precision and F1-Score, RBM for high Recall and GAN for high AUC, G-Mean and Balanced Accuracy under various recommended proportions of the minority class.},
  keywords={Measurement;Data models;Mathematical model;Context modeling;Clustering algorithms;Sensitivity;Manifolds;Adversarial networks;anomaly detection;class imbalance;deep generative models;density estimation;generative variational auto encoders;instance hardness threshold;machine learning best practices;restricted Boltzmann machines},
  doi={10.1109/ACCESS.2021.3071389},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8974332,
  author={Irfan, Ayesha and Zafar, Adeel and Hassan, Shahbaz},
  booktitle={2019 11th Computer Science and Electronic Engineering (CEEC)}, 
  title={Evolving Levels for General Games Using Deep Convolutional Generative Adversarial Networks}, 
  year={2019},
  volume={},
  number={},
  pages={96-101},
  abstract={Deep Convolutional Generative Adversarial Networks (DCGANs) are a machine learning approach that can learn to mimic any distribution of data. DCGANs consist of a generator and discriminator where generator generates new content and discriminator finds whether the generated content is real or fake. Procedural Content Generation (PCG) for level generation could potentially benefit from such models, particularly for a game where there is an existing level to emulate. In this paper, DCGANs are trained on existing levels generated through a random generator. Three different games (Freeway, Zelda, and Colourescape) are selected from the General Video Game Artificial Intelligence (GVG-AI) framework for level generation. The proposed approach successfully generates various levels which mimic the training levels. Generated levels are also evaluated using agent-based testing to ensure their play-ability.},
  keywords={Deep Convolutional Generative Adversarial Networks;Procedural Content Generation;General Video Game Level Generation;Agent-Based Testing},
  doi={10.1109/CEEC47804.2019.8974332},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10206915,
  author={Vaz, Diogo and Matos, David R. and Pardal, Miguel L. and Correia, Miguel},
  booktitle={2023 53rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks - Supplemental Volume (DSN-S)}, 
  title={Automatic Generation of Distributed Algorithms with Generative AI}, 
  year={2023},
  volume={},
  number={},
  pages={127-131},
  abstract={Fault-tolerant distributed algorithms such as Reliable Broadcast, Causal Broadcast, Total Order Broadcast, and Consensus, are at the core of many modern distributed systems. However, the development of distributed algorithms by humans is a laborious and complex process. This work presents a novel approach to generating distributed algorithms using Generative Artificial Intelligence that allows for automating the process of generating such algorithms. The paper also summarizes our initial results on using the approach to generate Reliable Broadcast algorithms.},
  keywords={Knowledge engineering;Fault tolerance;Machine learning algorithms;Fault tolerant systems;Reinforcement learning;Distributed algorithms;Fault-Tolerant Distributed Algorithms;Reliable Broadcast;Automatic Algorithm Generation;Generative AI;Reinforcement Learning;Automatic Algorithm Validation},
  doi={10.1109/DSN-S58398.2023.00037},
  ISSN={2833-292X},
  month={June},}@ARTICLE{10444637,
  author={Florkowski, Marek and Hayashi, Hideki and Matsuda, Shinji and Moribe, Hirotaka and Moriwaki, Norihiko and Jones, Darren and Pauska, Jeff},
  journal={IEEE Power and Energy Magazine}, 
  title={Digitally Boosted Resilience: Digitalization to Enhance Resilience of Electric Power System}, 
  year={2024},
  volume={22},
  number={2},
  pages={100-109},
  abstract={In an energy business that supports social activities, enhancing the resilience of power systems is becoming a critical issue. As electric power companies use great amounts of equipment over long periods of time, they risk the deterioration of their facilities. In addition, they face the risk of cyberattacks, especially those that target network control systems and distributed energy systems. Moreover, they are exposed to the risk of natural disasters that humans cannot effectively control or even predict. It is necessary for electric power companies to understand these various risks and take countermeasures to make their systems more resilient. This article addresses the trend of digitalization toward resilience and then introduces a maturity model to show the path to realizing resilience, along with an operational framework structure. In this model, the maturity levels were defined in the order of awareness, standardization of work, digitalization, automation, and continuous improvement according to resilience activities. A resilience framework has been proposed that employs the latest artificial intelligence (AI) technologies to effectively perform information analysis and create incident response rules. Specifically, these rules have been digitalized for resilience activities that are standardized as organizational activities and accumulated as organizational knowledge. The collection of such rules will form a playbook that can be automatically executed in response to such incidents. AI technologies then use these rules to create efficient and flexible recovery schedules; these schedules are not meant to be completed once they are created but are adaptively and constantly rescheduled in line with ongoing incidents and changes in response statuses. The intention of the maturity model and playbook-centered framework is to provide structured solutions and a scalable architecture for global use. As the next step for developing the resilience framework, explainable and generative AI is envisioned. As an example of a resilience initiative, a vegetation management use case that is spanned on the proposed framework is presented. One may claim that digitally enhanced resilience will be a strategic element of future power system operators.},
  keywords={Scheduling;Networked control systems;Standardization;Resilience;Power system planning;Artificial intelligence;Image restoration;Power system reliability;Cyberattack;Power system control;Distributed power generation;Risk management;Digital systems;Electricity supply industry;Performance evaluation;Energy management;Governmental factors},
  doi={10.1109/MPE.2023.3344554},
  ISSN={1558-4216},
  month={March},}@INPROCEEDINGS{9206728,
  author={Barredo-Arrieta, Alejandro and Del Ser, Javier},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Plausible Counterfactuals: Auditing Deep Learning Classifiers with Realistic Adversarial Examples}, 
  year={2020},
  volume={},
  number={},
  pages={1-7},
  abstract={The last decade has witnessed the proliferation of Deep Learning models in many applications, achieving unrivaled levels of predictive performance. Unfortunately, the black-box nature of Deep Learning models has posed unanswered questions about what they learn from data. Certain application scenarios have highlighted the importance of assessing the bounds under which Deep Learning models operate, a problem addressed by using assorted approaches aimed at audiences from different domains. However, as the focus of the application is placed more on non-expert users, it results mandatory to provide the means for him/her to trust the model, just like a human gets familiar with a system or process: by understanding the hypothetical circumstances under which it fails. This is indeed the angular stone for this research work: to undertake an adversarial analysis of a Deep Learning model. The proposed framework constructs counterfactual examples by ensuring their plausibility, e.g. there is a reasonable probability that a human could generate them without resorting to a computer program. Therefore, this work must be regarded as valuable auditing exercise of the usable bounds a certain model is constrained within, thereby allowing for a much greater understanding of the capabilities and pitfalls of a model used in a real application. To this end, a Generative Adversarial Network (GAN) and multi-objective heuristics are used to furnish a plausible attack to the audited model, efficiently trading between the confusion of this model, the intensity and plausibility of the generated counterfactual. Its utility is showcased within a human face classification task, unveiling the enormous potential of the proposed framework.},
  keywords={Gallium nitride;Machine learning;Faces;Generators;Analytical models;Generative adversarial networks;Task analysis;Explainable Artificial Intelligence;Deep Learning;Counterfactuals;Generative Adversarial Networks;Multiobjective Optimization;Meta-heuristics},
  doi={10.1109/IJCNN48605.2020.9206728},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{10020494,
  author={Bhowmik, Abhimanyu and Sannigrahi, Madhushree and Chowdhury, Deepraj and Dwivedi, Ashutosh Dhar and Rao Mukkamala, Raghava},
  booktitle={2022 IEEE International Conference on Big Data (Big Data)}, 
  title={DBNex: Deep Belief Network and Explainable AI based Financial Fraud Detection}, 
  year={2022},
  volume={},
  number={},
  pages={3033-3042},
  abstract={The majority of financial transactions are now conducted virtually around the world. The widespread use of credit cards and online transactions encourages fraudulent activity. Thus, one of the most demanding real-world challenges is fraud detection. Unbalanced datasets, in which there are a disproportionately high number of non-fraud samples compared to incidents of fraud, are one of the key obstacles to effective fraud detection. A further factor complicating the learning process for cutting-edge machine learning classifiers is how quickly fraud behaviour changes. Thus, in this study, we suggest an efficient fraud detection methodology. We propose a unique nonlinear embedded clustering to resolve imbalances in the dataset, followed by a Deep Belief Network for detecting fraudulent transactions. The proposed model achieved an accuracy of 94% with a 70:30 ratio of training-validation dataset.},
  keywords={Training;Measurement;Deep learning;Data preprocessing;Finance;Predictive models;Big Data;Financial Fraud Detection;Deep Belief Network;UMAP;DBSCAN;CTGAN;Explainable AI},
  doi={10.1109/BigData55660.2022.10020494},
  ISSN={},
  month={Dec},}@ARTICLE{11000329,
  author={Contreras-Castillo, Juan and Guerrero-Ibañez, Juan and Zeadally, Sherali and Hong, Een-Kee},
  journal={IEEE Communications Standards Magazine}, 
  title={Generative AI for Internet of Vehicles (IoV): Potential and Challenges}, 
  year={2025},
  volume={9},
  number={2},
  pages={106-116},
  abstract={Technological advances help develop urban environments with intelligent transportation systems that reduce traffic problems and improve road safety. The emergence of technologies such as cloud computing, the Internet of Things, and advances in wireless communication technologies caused Vehicular Ad-hoc Networks (VANETs) to evolve into a new concept known as the Internet of Vehicles. The IoV environment generates and shares enormous amounts of data in real time, requiring technologies to process and analyze this information quickly and accurately. This article discusses how generative AI can assist the IoV, describing how they can collaborate and highlighting some applications that would benefit. To determine the benefit of using AI to perform data analysis in traffic conditions and improvement of traffic flow, we compared the results of two generative artificial intelligences (ChatGPT and Gemini) to optimize traffic lights in a route with different weather conditions using a traffic dataset to get the best response. While both platforms successfully reduced travel time, Gemini’s more detailed analysis yielded more significant improvements by addressing the unique characteristics of each traffic light and the specific route conditions.},
  keywords={Artificial intelligence;Internet of Vehicles;Urban areas;Biological system modeling;Training;Ecosystems;Data models;Data mining;Communication standards;User experience;Vehicular ad hoc networks;Vehicular networks;Internet of Vehicles;Integra-on;IoV integra-on;Genera-ve ar-ficial intelligence},
  doi={10.1109/MCOMSTD.2025.3568907},
  ISSN={2471-2833},
  month={June},}@INPROCEEDINGS{10598580,
  author={Liu, Jichuan and Shi, Jun and Hou, Jingyi and Liu, Zhijie and He, Wei},
  booktitle={2024 39th Youth Academic Annual Conference of Chinese Association of Automation (YAC)}, 
  title={Imitation Learning of Robotic Arm with Hierarchical Training Based on Human Videos}, 
  year={2024},
  volume={},
  number={},
  pages={40-44},
  abstract={Human videos encapsulate a diverse spectrum of operational behaviors, serving as invaluable pedagogical resources for imitation learning. In this paper, we introduce an algorithmic framework aimed at emulating expert operational skills gleaned from human videos. The proposed algorithm computes the positional movements of individual steps within a robotic arm by quantifying the disparities between successive frames of the videos, which enables the emulation of skills exhibited in the demonstrations. In detail, we begin by utilizing image translation to seamlessly transition human demonstrations into the realm of the robotic arm, mitigating morphological differences across the multi-joint mechanical structure. Subsequently, we incorporate a keypoint detection network to extract structured information from the transformed images, generating a latent representation that encapsulates motion details for the learning process of the policy network. Experimental results affirm the efficacy of our approach in replicating operational skills.},
  keywords={Training;Automation;Imitation learning;Semantics;Emulation;Manipulators;Feature extraction;imitation learning;human videos;image translation;strategy generation},
  doi={10.1109/YAC63405.2024.10598580},
  ISSN={2837-8601},
  month={June},}@ARTICLE{11164994,
  author={Petkovic, Dragutin},
  journal={IEEE Transactions on Technology and Society}, 
  title={GenAI: Our Tool Or Our Future Master?}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={Tremendous achievements and excitement about Generative Artificial Intelligence (GenAI) technology are shared by many: scientists, professionals of all fields, students and educators, general public, news media, investors and even politicians and religious leaders. By being able to generate content and converse with users in a natural way, unlike “classical AI”, GenAI opened up endless possibilities and captured users’ imagination. With all this came many promises of great possibilities and a new bright future for humanity. However, concerns about GenAI and its impact on society and labor market are emerging in scientific, business, news and public spaces, with words of caution and calls for some form of control or regulation. It is imperative in my opinion for all of us humans to think about how to make GenAI truly a positive development for humanity’s future world and minimize its negative effects. How to foster this revolutionary potential of AI in an effective and safe way, in order to balance the inevitable hunger and need for innovation and business success with the benefits to humanity and society is one of the grand challenges we have to address. This editorial is an attempt to contribute to this discussion by first pointing to some GenAI issues, limitations, and fundamental concerns, and then by discussing some ideas that could help us move forward in order to effectively use GenAI for the benefits of humanity at large. The focus of this editorial, written with no use of GenAI, is on its impact to society and humanity, and not on its technology or business aspects.},
  keywords={Artificial intelligence;Humanities;Business;Media;Technological innovation;Regulation;Complexity theory;Chatbots;Productivity;Motion pictures;Generative AI;GenAI;artificial intelligence;AI;future of work;consequences;issues;limitations;social implications;trustworthy AI},
  doi={10.1109/TTS.2025.3603643},
  ISSN={2637-6415},
  month={},}@INPROCEEDINGS{11009063,
  author={Pham-Phuc, Duc and Nguyen-Nhat-Hieu, Trung and Van-Thien, Luan and Nguyen-Van, Bao and Nguyen-Khanh, Thuat and Le-Trung, Quan},
  booktitle={2024 RIVF International Conference on Computing and Communication Technologies (RIVF)}, 
  title={Enhancing Detection Capacity and Security for Network-based Intrusion Detection Systems in Internet of Things}, 
  year={2024},
  volume={},
  number={},
  pages={194-198},
  abstract={As the number of Internet of Things devices continues to grow, so does the risk of attacks, which significantly impacts financial aspects and the potential loss of sensitive data. This makes Network-based Intrusion Detection Systems (NIDS) using machine learning algorithms more critical than ever. However, a key concern is the input data for the machine learning models. Most models require large datasets to achieve high accuracy, but this data often needs to maintain privacy if it includes personal information. Additionally, the trustworthiness of devices in the system must be ensured, as unreliable devices can reduce the model's effectiveness or lead to significant data loss. To address these challenges, we propose using Generative Adversarial Networks (GAN) to enrich training data and combining Blockchain with Federated Learning (FL) to ensure data privacy and component validation. This approach results in a robust, efficient model that balances lightweight design with high reliability.},
  keywords={Data privacy;Machine learning algorithms;Accuracy;Federated learning;Intrusion detection;Graphics processing units;Generative adversarial networks;Data models;Blockchains;Internet of Things;Artificial intelligence;blockchain;federated learning;generative adversarial networks;machine learning;NIDS},
  doi={10.1109/RIVF64335.2024.11009063},
  ISSN={2473-0130},
  month={Dec},}@ARTICLE{9393473,
  author={Zhang, Libao and Liu, Yanan},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={Remote Sensing Image Generation Based on Attention Mechanism and VAE-MSGAN for ROI Extraction}, 
  year={2022},
  volume={19},
  number={},
  pages={1-5},
  abstract={A variety of deep learning approaches have been applied to region of interest (ROI) extraction, which is a fundamental task in the field of remote sensing image (RSI) processing. However, the unbalanced distribution of positive and negative samples in most RSIs greatly restricts the performance of these deep learning-based methods. In this study, a data augmentation method based on variational autoencoder-multiscale generative adversarial network (VAE-MSGAN) with spatial and channelwise attention (SCA) is proposed to balance the sample distribution and improve the subsequent ROI extraction results. First, we combine the original multispectral information with handcrafted texture features to make full use of the low-level visual features of RSIs. We then design a VAE-MSGAN to generate realistic RSIs with high quality and diversity. Specifically, in the generator construct, SCA blocks are introduced to adaptively recalibrate the varying importance of different channels and spatial regions. We also build a multiscale discriminator architecture to improve the visual quality of the generated samples. Finally, we compare the ROI extraction results before and after the augmentation. Our experimental results demonstrate that the proposed method can not only improve the performance of ROI extraction but also be superior to other classical generative methods.},
  keywords={Training;Generators;Data mining;Task analysis;Remote sensing;Generative adversarial networks;Feature extraction;Generative adversarial networks (GANs);region of interest (ROI) extraction;remote sensing;variational autoencoder (VAE)},
  doi={10.1109/LGRS.2021.3068271},
  ISSN={1558-0571},
  month={},}@ARTICLE{10537094,
  author={Li, Wenli and Zhang, Yinan and Li, Lingxi and Lv, Yisheng and Wang, Mengxin},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={A Pedestrian Trajectory Prediction Model for Right-Turn Unsignalized Intersections Based on Game Theory}, 
  year={2024},
  volume={25},
  number={8},
  pages={9643-9658},
  abstract={This paper aims to propose a pedestrian trajectory prediction model based on pedestrian–vehicle game theory to study pedestrian trajectories during pedestrian–vehicle interaction at unsignalized right-turn intersections. First, pedestrian–vehicle interaction scene data at unsignalized right-turn intersections were collected. Then, a novel pedestrian–vehicle game theory model was established, where its parameters were calibrated using the Nash equilibrium of a complete information static game and the probabilities of pedestrians and vehicles crossing the street. A new pedestrian–vehicle game utility matrix is embedded into the social-generative adversarial network pedestrian trajectory prediction model, which considers information between pedestrians and vehicles and analyzes the state of pedestrian–vehicle-interactions under various decisions through microscopic motion factors and macroscopic game decisions. The experimental results show that the proposed model is more accurate and explanatory than traditional pedestrian trajectory prediction models, such as long short-term memory (LSTM), Social LSTM, Social generative adversarial network(S-GAN), and Sophie.},
  keywords={Pedestrians;Trajectory;Game theory;Predictive models;Long short term memory;Generative adversarial networks;Analytical models;Right-turn intersections;pedestrian trajectory prediction;pedestrian–vehicle interaction;game theory;social-generative adversarial network},
  doi={10.1109/TITS.2024.3398648},
  ISSN={1558-0016},
  month={Aug},}@ARTICLE{10630483,
  author={Kristiansen Nøland, Jonas and Hjelmeland, Martin and Korpås, Magnus},
  journal={IEEE Access}, 
  title={Will Energy-Hungry AI Create a Baseload Power Demand Boom?}, 
  year={2024},
  volume={12},
  number={},
  pages={110353-110360},
  abstract={The rapid expansion of generative artificial intelligence (AI) technologies is projected to significantly affect electricity use in the global data center sector. Earlier research has proposed using data centers for load-balancing the future power grid to allow higher integration of variable renewables. In this paper, we review the expected future electricity consumption of AI and evaluate the behavior of AI data centers in clean energy systems. Our work found that the levelized cost of computing (LCOC) favors higher load factors and shows a relatively low sensitivity to electricity price levels. Under our baseline cost assumptions, a baseload electricity price of  ${\$} {\mathrm {125~}} \mathrm {/MWh}$  benefits load factors higher than 64 %, depending on the market price conditions and variations. Nevertheless, high-tier data centers with higher operational costs and capital expenditures favor even higher load factors to optimize their LCOC. These findings show that a boom in AI energy use could drive significant baseload power demand in future power systems.},
  keywords={Data centers;Artificial intelligence;Costs;Electricity;Power demand;Graphics processing units;Servers;Artificial intelligence (AI);AI energy use;computing cost;computing efficiency;data center;graphical processing units (GPUs);load factor;load shifting},
  doi={10.1109/ACCESS.2024.3440217},
  ISSN={2169-3536},
  month={},}@ARTICLE{10769505,
  author={Li, Mengchang and Feng, Zhixi and Yang, Shuyuan and Ma, Yue and Song, Liangliang and Chen, Shuai and Jiao, Licheng and Zhang, Junkai},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={DAE-GSP: Discriminative Autoencoder With Gaussian Selective Patch for Multimodal Remote Sensing Image Classification}, 
  year={2025},
  volume={63},
  number={},
  pages={1-14},
  abstract={In the field of multimodal remote sensing image (MRSI) classification, self-supervised learning (SSL) algorithms have demonstrated significant advantages, particularly in scenarios with limited labeled samples. Existing SSL methods typically use auxiliary tasks within either contrastive or generative frameworks, focusing on discriminative or structural information separately. In this article, we propose a novel hybrid SSL paradigm, discriminative autoencoder with Gaussian selective patch (DAE-GSP) for MRSI classification. The DAE framework integrates contrastive learning with the masked image modeling (MIM) technique, allowing for simultaneous learning of structural information and discriminative representations from images. Furthermore, a cross-attention-based data-level fusion strategy is introduced during pretraining stage to enhance intermodal interactions, thereby improving the effectiveness of modality fusion. In addition, we propose a novel Gaussian selective patch (GSP) strategy, addressing the limitations of traditional square patch selection methods. Combined with self-supervised auxiliary tasks, this strategy facilitates the improved integration of multiple modalities and encourages the model to capture essential semantic information. Extensive experiments conducted on three public datasets (Houston2013, Augsburg, and Berlin) demonstrate the effectiveness of the proposed approach. With only ten labeled training samples per class, the proposed method achieves overall accuracy (OA) of 90.15%, 82.64%, and 71.03% on the Houston2013, Augsburg, and Berlin datasets, respectively, indicating improvements of 1.31%, 1.22%, and 1.48% over state-of-the-art methods.},
  keywords={Remote sensing;Feature extraction;Semantics;Image reconstruction;Data models;Contrastive learning;Data mining;Computational modeling;Computational complexity;Training;Contrastive learning;cross-attention;few-shot classification;generative self-supervised learning (SSL);multimodal images;patch selection strategy},
  doi={10.1109/TGRS.2024.3507385},
  ISSN={1558-0644},
  month={},}@ARTICLE{9716786,
  author={Du, Chenghu and Yu, Feng and Jiang, Minghua and Hua, Ailing and Wei, Xiong and Peng, Tao and Hu, Xinrong},
  journal={IEEE Transactions on Multimedia}, 
  title={VTON-SCFA: A Virtual Try-On Network Based on the Semantic Constraints and Flow Alignment}, 
  year={2023},
  volume={25},
  number={},
  pages={777-791},
  abstract={An image-based virtual try-on system transfers an in-shop garment to the corresponding garment region of a reference person, which has huge application potential and commercial value in online clothing shopping. Existing methods have difficulty preserving garment texture and body details because of rough garment alignment and imperfect detail-retention strategies. To address this problem, we propose a virtual try-on network based on semantic constraints and flow alignment. The key idea of the framework is as follows: 1) a global-local semantic predictor (GLSP) is proposed to generate a reasonable target semantic map, which clearly guides the correct alignment of the in-shop garment with the body and the generation of try-on result; and 2) a novel appearance flow-based garment alignment network (AFGAN) is proposed to align the in-shop garment with the body, which is important to preserve maximum garment detail and ensure natural and realistic warping; and 3) we propose a synthesis strategy to integrate the aligned garment and the human body to preserve maximum body detail for generating a realistic result and preventing cross-occlusion and pixel confusion between different body parts. Experiments on the existing benchmark dataset demonstrate that the proposed method achieves the best performance on qualitative and quantitative experiments among the state-of-the-art virtual try-on techniques.},
  keywords={Clothing;Semantics;Neck;Image reconstruction;Generative adversarial networks;Three-dimensional displays;Strain;Virtual try-on;human parsing;semantic constraint;flow aligning},
  doi={10.1109/TMM.2022.3152367},
  ISSN={1941-0077},
  month={},}
