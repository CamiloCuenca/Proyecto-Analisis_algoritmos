@INPROCEEDINGS{9236930,
  author={Zhao, Ziyun and Zhang, Shifeng and Hu, Kangying and Chen, Zhan and Guo, Junqi},
  booktitle={2020 IEEE 3rd International Conference on Information Systems and Computer Aided Education (ICISCAE)}, 
  title={An FFM-based Model for Students' In-class Learning Postures Estimation}, 
  year={2020},
  volume={},
  number={},
  pages={200-205},
  abstract={In the recent years, education quality monitoring has been attached great importance by Chinese government, and with the promulgation of the development plan for the new generation of artificial intelligence, the application of this technology in education quality monitoring fields has attracted wide attention of scholars. How to apply relevant algorithms of machine vision to classroom quality assessment is the research focus of smart education. In this paper, considering the timeliness of feedback, the stability of algorithms, the accuracy rate and speed in classroom quality assessment, we propose a model called Face Features Matching (FFM), based on face detection networks and feature points matching methods, which innovatively combines machine learning with parameter estimation and numerical methods. Our model is divided into two sub-modules: face feature extraction and optimal parameter estimation. It can be applied successfully to classroom scenarios and become an important part of automated classroom quality assessment.},
  keywords={Education;Feature extraction;Numerical models;Quality assessment;Mathematical model;Monitoring;Facial features;education quality monitoring;learning postures estimation;machine vision;optimization},
  doi={10.1109/ICISCAE51034.2020.9236930},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10595920,
  author={Bekhouche, Salah Eddine and Hadid, Abdenour},
  booktitle={2024 IEEE 6th International Conference on AI Circuits and Systems (AICAS)}, 
  title={Kinship Verification from Text: Towards Discovering Subtitle Textual Features Shared by Family Members using Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={507-511},
  abstract={The objective of kinship verification is to assess whether two individuals are biologically related or not. Previous research has primarily focused on determining kinship from facial patterns and movements, voice, or human gait. In this paper, we explore for the first time in the literature the problem of kinship verification from text. This is a very timely topic given the emergence of generative artificial intelligence and large language models. Our main hypothesis is that two family members inherit and share subtitle textual features that can be seen in the way of writing. The subtle features can be related to genes, culture, experience etc. To address this problem, we propose a Siamese-based BERT transformer incorporating two novel modules, namely Attention and Fusion. The experiments show promising results on the role textual information in kinship verification.},
  keywords={Social networking (online);Generative AI;Circuits and systems;Large language models;Writing;Transformers;Biology;Kinship;Natural language processing;Deep learning},
  doi={10.1109/AICAS59952.2024.10595920},
  ISSN={2834-9857},
  month={April},}@ARTICLE{9970384,
  author={Raamkumar, Aravind Sesagiri and Yang, Yinping},
  journal={IEEE Transactions on Affective Computing}, 
  title={Empathetic Conversational Systems: A Review of Current Advances, Gaps, and Opportunities}, 
  year={2023},
  volume={14},
  number={4},
  pages={2722-2739},
  abstract={Empathy is a vital factor that contributes to mutual understanding, and joint problem-solving. In recent years, a growing number of studies have recognized the benefits of empathy and started to incorporate empathy in conversational systems. We refer to this topic as empathetic conversational systems. To identify the critical gaps and future opportunities in this topic, this article examines this rapidly growing field using five review dimensions: (i) conceptual empathy models and frameworks, (ii) adopted empathy-related concepts, (iii) datasets and algorithmic techniques developed, (iv) evaluation strategies, and (v) state-of-the-art approaches. The findings show that most studies have centered on the use of the EMPATHETICDIALOGUES dataset, and the text-based modality dominates research in this field. Studies mainly focused on extracting features from the messages of the users and the conversational systems, with minimal emphasis on user modeling and profiling. Notably, studies that have incorporated emotion causes, external knowledge, and affect matching in the response generation models, have obtained significantly better results. For implementation in diverse real-world settings, we recommend that future studies should address key gaps in areas of detecting and authenticating emotions at the entity level, handling multimodal inputs, displaying more nuanced empathetic behaviors, and encompassing additional dialogue system features.},
  keywords={Computational modeling;Behavioral sciences;Emotion recognition;Chatbots;Feature extraction;Artificial intelligence;Task analysis;Affective computing;empathetic conversational systems;empathetic chatbots;empathetic dialogue systems;empathy;empathetic artificial intelligence},
  doi={10.1109/TAFFC.2022.3226693},
  ISSN={1949-3045},
  month={Oct},}@ARTICLE{9844128,
  author={Parras, Juan and Almodóvar, Alejandro and Apellániz, Patricia A. and Zazo, Santiago},
  journal={IEEE Internet of Things Journal}, 
  title={Inverse Reinforcement Learning: A New Framework to Mitigate an Intelligent Backoff Attack}, 
  year={2022},
  volume={9},
  number={24},
  pages={24790-24799},
  abstract={The recent advances in Deep Learning have a significant impact on the security of wireless networks, such as intelligent attackers which are able to successfully exploit a possibly unknown defense mechanism simply by interacting with it. Their capacity of adapting to standard defense mechanisms, such as statistical tests, makes them a significant threat. In this article, we develop two intelligent defense mechanisms using inverse reinforcement learning tools, that can be used to enhance the capabilities of current defense mechanisms. We test our proposal on a backoff attack setup against an intelligent attacker, obtaining very significant gains in the defense performance.},
  keywords={Security;Wireless networks;Deep learning;Reinforcement learning;Dynamical systems;Observability;Markov processes;Artificial intelligence;Artificial intelligence;inverse reinforcement learning (RL);Markov decision process (MDP);security;wireless network},
  doi={10.1109/JIOT.2022.3194694},
  ISSN={2327-4662},
  month={Dec},}@ARTICLE{9916135,
  author={Sun, Shilin and Wang, Tianyang and Yang, Hongxing and Chu, Fulei},
  journal={IEEE Transactions on Cybernetics}, 
  title={An Environmentally Adaptive and Contrastive Representation Learning Method for Condition Monitoring of Industrial Assets}, 
  year={2024},
  volume={54},
  number={3},
  pages={1484-1496},
  abstract={Condition monitoring of assets is significant to the efficiency and reliability of industrial automation systems. However, the accuracy of condition monitoring results is easily impaired by variational environments and volatile operations, especially for complex automation systems. In this article, an environmentally adaptive and contrastive representation learning method is proposed to address the problem. To suppress the unexpected effects of environmental variations on operating data, a regression model between the operational and environmental variables is developed. The variable regression adjustment is achieved by solving a penalized optimization problem based on spline functions, and the solution is explicitly derived. Then, negative samples and pseudo labels are generated based on the designed pattern of data augmentation, and valid data representations for asset condition monitoring can be obtained by contrastive learning. Moreover, the reference statue of healthy assets is established by kernel density estimation, and control charts are employed for online monitoring with alarm thresholds. Taking wind turbine blades as examples, the remarkable performance of the developed method is demonstrated with real-world measurements from wind farms. Furthermore, comparative analysis with benchmark approaches and ablation study are conducted to reveal the superiority and effectiveness of the proposed method.},
  keywords={Condition monitoring;Monitoring;Splines (mathematics);Training;Automation;Representation learning;Artificial intelligence;Contrastive learning;Artificial intelligence;condition monitoring;contrastive learning;representation learning},
  doi={10.1109/TCYB.2022.3209707},
  ISSN={2168-2275},
  month={March},}@INPROCEEDINGS{9140983,
  author={Cerqueira, José Antonio Siqueira de and Almeida, Paulo Santos de and Canedo, Edna Dias and Alves, Gabriel de Oliveira and Giozza, William Ferreira and Mendonça, Fábio Lúcio Lopes de and de Sousa, Rafael T.},
  booktitle={2020 15th Iberian Conference on Information Systems and Technologies (CISTI)}, 
  title={Exploratory Overview on Breaking CAPTCHAs Using the Theory of the Consolidated Meta-Analytic Approach}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={This study sought to provide an integrating model of the main contributions of the literature on CAPTCHAs with an impact in this field. With the expansion of internet access, there is an increasing need for a mechanism to protect websites from attacks, although there are situations where it is interesting to be able to automate some activities. This work consisted of identifying the most influential CAPTCHA-related academic works and trends in the field, which could serve as a metric on what approaches to take when developing new studies. Data such as main authors, current lines of research and more prolific research centers are arrived at using the Theory of the Consolidated Meta-analytic Approach. Inputting the keyword “captcha” in the Web of Science database, 539 records were found, from 2001 to 2020. The main classes retrieved are: (a) Captcha in Security Context (31.9%), (b) Usability in Captcha Design (28%), (c) Captcha Recognition by AI (21.8%), (d) Captcha Approaches and Novel Implementation Proposals (18.2%).},
  keywords={CAPTCHAs;Bibliometrics;Databases;Artificial intelligence;Couplings;Security;Visualization;CAPTCHA;CAPTCHA Breaking;Bibliographic Research;State-of-the-art;Artificial Intelligence},
  doi={10.23919/CISTI49556.2020.9140983},
  ISSN={2166-0727},
  month={June},}@INPROCEEDINGS{10963179,
  author={Imangi, Imesha and Lakshan, Supun and De Silva, Surasi Muthumini and Dimuthu Maduranga Arachchi, H.A. and Samarasinghe, G. D.},
  booktitle={2025 5th International Conference on Advanced Research in Computing (ICARC)}, 
  title={3D - AI Avatar Attributes Impacting on Bank Customers’ Perceived Experience}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={This study focuses on explaining the attributes of AI Avatar that impact bank customers’ perceived service experience. This phenomenon is under-explored in empirical literature and thus calls for empirical investigation. It takes into account ten attributes and based on those, measures the customers’ perceived service experience towards the three groups of AI avatars. Based on the literature review, this study formulated nine hypotheses to explain the research gap. A quantitative methodology with a survey strategy was undertaken with an effective sample size of 150 Gen Z banking consumers. Furthermore, the study focused on the domestic banks in Sri Lanka. The analysis was carried out using SPSS-26 and Smart PLS 4 packages. Based on the results, it shows a significant and positive relationship between avatar attributes of likeability, credibility, attractiveness, pleasure emotions, dominance emotion, and arousal emotion with consumer preference. Moreover, it indicates that these attributes have a positive and significant impact on the buying intention and the electronic word-of-mouth (eWOM), which also have a significant and positive impact on consumer buying intention. These findings contribute to filling the existing knowledge gap and provide a novel insight.},
  keywords={Surveys;Three-dimensional displays;Online banking;Avatars;Filling;Artificial intelligence;Systematic literature review;Artificial Intelligence;Avatar;Customer Experience;Online Banking;Value Percept Disparity Theory;UCD Theory},
  doi={10.1109/ICARC64760.2025.10963179},
  ISSN={},
  month={Feb},}@ARTICLE{10937069,
  author={Xu, Jiahua and Feng, Yebo and Perez, Daniel and Livshits, Benjamin},
  journal={IEEE Transactions on Services Computing}, 
  title={Auto.gov: Learning-Based Governance for Decentralized Finance (DeFi)}, 
  year={2025},
  volume={18},
  number={3},
  pages={1278-1292},
  abstract={Decentralized finance (DeFi) is an integral component of the blockchain ecosystem, enabling a range of financial activities through smart-contract-based protocols. Traditional Decentralized finance (DeFi) governance typically involves manual parameter adjustments by protocol teams or token holder votes, and is thus prone to human bias and financial risks, undermining the system's integrity and security. While existing efforts aim to establish more adaptive parameter adjustment schemes, there remains a need for a governance model that is both more efficient and resilient to significant market manipulations. In this paper, we introduce “Auto.gov”, a learning-based governance framework that employs a Deep Q-network (DQN) Reinforcement learning (RL) strategy to perform semi-automated, data-driven parameter adjustments. We create a DeFi environment with an encoded action-state space akin to the Aave lending protocol for simulation and testing purposes, where Auto.gov has demonstrated the capability to retain funds that would have otherwise been lost to price oracle attacks. In tests with real-world data, Auto.gov outperforms the benchmark approaches by at least 14% and the static baseline model by tenfold, in terms of the preset performance metric—protocol profitability. Overall, the comprehensive evaluations confirm that Auto.gov is more efficient and effective than traditional governance methods, thereby enhancing the security, profitability, and ultimately, the sustainability of DeFi protocols.},
  keywords={Protocols;Finance;Decentralized applications;Machine learning;Economic indicators;Artificial intelligence;Adaptation models;Proposals;Security;Blockchains;Governance;decentralized finance (DeFi);reinforcement learning (RL);artificial intelligence (AI)},
  doi={10.1109/TSC.2025.3553700},
  ISSN={1939-1374},
  month={May},}@INPROCEEDINGS{11006822,
  author={Thuraisingham, Bhavani and Khan, Latifur and Nimon, Kim},
  booktitle={2025 IEEE 11th Conference on Big Data Security on Cloud (BigDataSecurity)}, 
  title={An Education Program for Blockchain Security and Privacy}, 
  year={2025},
  volume={},
  number={},
  pages={20-31},
  abstract={This paper describes an education program we are developing in Blockchain technologies. It describes the need for such a program, how it is drawing from our research in blockchain, the evaluation of the program as well as the course we have taught at the undergraduate level and the more extensive program we are developing at the graduate level at the University of Texas at Dallas.},
  keywords={Data privacy;Education;Data science;Big Data;Blockchains;Security;Artificial intelligence;Blockchain;Security;Privacy;Artificial Intelligence;Data Science},
  doi={10.1109/BigDataSecurity66063.2025.00016},
  ISSN={},
  month={May},}@ARTICLE{11146508,
  author={Fu, Kang and Duan, Huiyu and Zhang, Zicheng and Liu, Xiaohong and Min, Xiongkuo and Wang, Jia and Zhai, Guangtao},
  journal={IEEE Transactions on Multimedia}, 
  title={Multi-Dimensional Quality Assessment for Text-to-3D Assets: Dataset and Model}, 
  year={2025},
  volume={},
  number={},
  pages={1-14},
  abstract={Recent advancements in text-to-image (T2I) generation have spurred the development of text-to-3D asset (T23DA) generation, leveraging pretrained 2D text-to-image diffusion models for text-to-3D asset synthesis. Despite the growing popularity of text-to-3D asset generation, its evaluation has not been well considered and studied. However, given the significant quality discrepancies among various text-to-3D assets, there is a pressing need for quality assessment models aligned with human subjective judgments. To tackle this challenge, we conduct a comprehensive study to explore the T23DA quality assessment (T23DAQA) problem in this work from both subjective and objective perspectives. Given the absence of corresponding databases, we first establish the largest text-to-3D asset quality assessment database to date, termed the AIGC-T23DAQA database. This database encompasses 969 validated 3D assets generated from 170 prompts via 6 popular text-to-3D asset generation models, and corresponding subjective quality ratings for these assets from the perspectives of quality, authenticity, and text-asset correspondence, respectively. Subsequently, we establish a comprehensive benchmark based on the AIGC-T23DAQA database, and devise an effective T23DAQA model to evaluate the generated 3D assets from the aforementioned three perspectives, respectively. Specifically, the proposed method utilizes the projection videos of text-to-3D assets to extract 3D shape, texture and text-asset correspondence features, then fuses them to calculate the final three preference scores respectively. Extensive experimental results demonstrate the effectiveness of the proposed T23DAQA method in evaluating the quality of AI generated 3D asset, which is more consistent with human perception. To the best of our knowledge, this is the first work that studies the problem of text-guided 3D generation quality assessment, and our database and codes will be released to facilitate future research.},
  keywords={Three-dimensional displays;Quality assessment;Databases;Solid modeling;Feature extraction;Artificial intelligence;Text to image;Point cloud compression;Shape;Computational modeling;text-to-3D asset generation;subjective quality assessment;objective quality assessment;artificial intelligence generated content (AIGC)},
  doi={10.1109/TMM.2025.3604905},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{11137140,
  author={Williams, Emily and Rodgers, Jason and Chandler-Crnigoj, Sebastian and Jones, Karl and Robinson, Colin},
  booktitle={2025 International Conference on Computer Systems and Technologies (CompSysTech)}, 
  title={Pandora's Black or White Box: Are AI Tools Undermining Evidence?}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The proliferation of synthetic media, particularly deepfakes, is having a significant impact on society in general and the criminal justice system in particular. The increase in deepfake audio and video evidence presents significant challenges to digital forensics, where accurate detection is essential for maintaining the integrity of evidence. With limited manual methods available for identifying manipulated content, forensic professionals are increasingly turning to AI-enabled detection tools. This research examines whether the application of professional-grade AI tools for deepfake detection introduces changes to original files, such as modifications to metadata, compression artefacts, or structural alterations, that could compromise their integrity and admissibility in legal contexts. The investigation has focused on 2 professional tools currently widely employed within audio and video forensic units of UK police forces. The work undertaken employs controlled testing to assess the extent and nature of such changes. It evaluates whether these tools adhere to ethical and procedural standards, particularly regarding the chain of custody and evidentiary reliability. The findings aim to inform the integration of AI tools into audio/video forensic workflows, addressing critical concerns about balancing advanced detection capabilities with the preservation of file authenticity. Through identifying potential risks and challenges, the study seeks to support policymakers, forensic practitioners, and legal professionals in ensuring that advancements in synthetic media detection uphold the foundational principles of evidence handling and judicial integrity.},
  keywords={Deepfakes;Ethics;Magnetic resonance imaging;Digital forensics;Media;Metadata;Turning;Artificial intelligence;Standards;Testing;Artificial Intelligence;Forensics;Digital Forensics;Deepfake Detection;Policing},
  doi={10.1109/CompSysTech65493.2025.11137140},
  ISSN={},
  month={June},}@INPROCEEDINGS{10830322,
  author={Sharma, Shivansh and Ahuja, Garvita and Priyal and Agarwal, Divya},
  booktitle={2024 International Conference on Computing, Sciences and Communications (ICCSC)}, 
  title={Decoding the Mirage: A Comprehensive Review of DeepFake AI in Image and Video Manipulation}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The evolution of deepfake development technology has increased the development of highly realistic digital media content. Nowadays, this technology is being used to manipulate photos and videos of influential personalities such as celebrities, politicians, or businessmen to either harm their reputation or spread false information. Although deepfake AI has both positive and negative application, this technology is mostly used with malicious intent such as to spread misinformation, engage in digital harassment, and undermine societal trust. This review paper provides a comprehensive examination of the available deepfake generation and detection methods, exploring both the opportunities and challenges presented by this emerging innovation. Detection methodologies based on deep learning and conventional methods as well the threats this emerging technology poses on the society are also surveyed. Overall, this review gives various insights of both generation and detection of deepfakes, combining its applications, approaches and future work.},
  keywords={Deep learning;Deepfakes;Technological innovation;Reviews;Law enforcement;Government;Education;Entertainment industry;Real-time systems;Artificial intelligence;Deepfake;Face manipulation;Face swapping GAN;Face reenactment;Image forgery;Artificial Intelligence},
  doi={10.1109/ICCSC62048.2024.10830322},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11035108,
  author={Likhitha and Rachana, U and Sinchana and Ahmad, Ubair and Varnitha, M},
  booktitle={2025 International Conference on Knowledge Engineering and Communication Systems (ICKECS)}, 
  title={Image Verse AI- Crafting Image Worlds from Text}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={AI is rapidly looking into further uncharted waters of creativity and utility. Among several transnational tools to produce elaborate and visually arresting images from textual descriptions is ImageVerse AI. The system employs advanced deep learning models that couple natural language understanding with image synthesis to bridge the gap between written ideas and visual outputs. An engendering core for the organization of text is ImageVerse AI’s astonishing ability to read and understand that text. Here, further results depend on its grammatical aspects: providing context, saying with intent, and descriptive marks or hints for more accurately aligned endeavors between user input and conceptual images. Such scope goes beyond painting to other pursuits, such applies within advertising, and educational purposes, into VR integration, so accessibility solutions.},
  keywords={Deep learning;Ethics;Visualization;Technological innovation;Collaboration;Text to image;Psychology;Cultural differences;Artificial intelligence;Creativity;ImageVerse AI;text-to-imagesynthesis;artificial intelligence;deep learning;natural LAN processing (NLP);visual creativity;image generation},
  doi={10.1109/ICKECS65700.2025.11035108},
  ISSN={},
  month={April},}@INPROCEEDINGS{11089179,
  author={Prathibanandhi, J. and Vimala, G. S. Annie Grace},
  booktitle={2025 11th International Conference on Communication and Signal Processing (ICCSP)}, 
  title={Enhancing PCOD Detection in Ultrasound Imaging: an Evaluation of Deep Learning Models}, 
  year={2025},
  volume={},
  number={},
  pages={1414-1419},
  abstract={An endocrine disorder that is apparent in many post- childbearing women is polycystic ovarian syndrome, commonly abbreviated as PCOD. Some of the symptoms of the conditions that are associated with hormonal imbalances include infertility couple, anovulation, and hirsutism. This therefore means that there must be early diagnosis of this disease to achieve good control and to avoid the health risks associated with it. Herein below we describe a simple decision making tree for diagnosing PCOD concerning clinical and laboratory abnormalities. This method consists of pre-treatment segmentation and final classification with the support of a holonet Hence, these significant concerns are among the study objectives of this paper in the formulation of a reformed deeper learning model called HoloNet for accurate PCOD recognition and classification in sonography images. The three components, that is Convolution layers, density blocks, and proper pooling algorithms are all integrated into HoloNet making the model uniquely capable of capturing and extracting that essential piece of information from the input. In all four criteria, namely accuracy, recall, F1 score, and precision, the results demonstrate that Holonet outperformed the competition against Resnet 152 and Incepton resnet among others as part of the benchmarking. The benchmark analysis of the performance also reveals that in each of the precisions such as precision, accuracy, recall, and F1 the models of the presented structure of holonet iteratively perform better than the other models. As a result, the use of this technology measures about 98% accuracy.},
  keywords={Deep learning;Image segmentation;Analytical models;Accuracy;Ultrasonic imaging;Ultrasonic variables measurement;Benchmark testing;Reliability;Artificial intelligence;Medical diagnostic imaging;PCOD Detection;Ultrasound Imaging;Deep Learning;Medical Image Analysis;Artificial Intelligence (AI);Resnet152;Inception resnet},
  doi={10.1109/ICCSP64183.2025.11089179},
  ISSN={2836-1873},
  month={June},}@INPROCEEDINGS{11125218,
  author={Maraziotis, Orestis and Mantas, George and Rodriguez, Jonathan and Mallón, María Boado and Gil-Castiñeira, Felipe},
  booktitle={2025 25th Anniversary International Conference on Transparent Optical Networks (ICTON)}, 
  title={Smart Residential Buildings in the 6G Edge Network: Security and Privacy Threats}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Energy, political and urbanization factors have driven the rise of Smart Cities and Smart Residential Buildings within them, aiming to improve the quality of life for residents and to reduce the energy consumption of cities. Ultra-Dense Networks and 6G edge networks can be the backbone of their infrastructure, enabling ultra-high data rates and seamless AI integration. Nevertheless, 6G's dense interconnectivity, AI and edge connectivity introduce various types of security and privacy threats, posing immediate risks to Smart Residential Buildings. Given this and the fact that residents' privacy is of critical importance in Smart Residential Buildings, there is a strong necessity for novel security mechanisms to preserve the privacy and security of Smart Residential Buildings before Smart Residential Buildings reach their full market potential. With this objective, in this paper, security and privacy threats are investigated, highlighting the most significant ones for Smart Residential Buildings and outlining their potential countermeasures. Moreover, an Intrusion Detection System that integrates Anomaly Detection and privacy-preserving technologies is proposed as a future work to mitigate such threats in Smart Residential Buildings.},
  keywords={6G mobile communication;Privacy;Image edge detection;Buildings;Intrusion detection;Vectors;Security;Artificial intelligence;Ultra-dense networks;Anomaly detection;Smart Residential Buildings (SRBs);6G Edge Networks;Ultra-Dense Networks (UDNs);Intrusion Detection System (IDS);Artificial Intelligence (AI);Federated Learning (FL);Compressive Sensing (CS);Privacy;Security;Anomaly Detection (AD);Privacy-Preserving Mechanisms},
  doi={10.1109/ICTON67126.2025.11125218},
  ISSN={2161-2064},
  month={July},}@INPROCEEDINGS{10941577,
  author={Sheikh, Mohammed Firdos Alam and Bhuyan, Ajatray Swagat and Dhiman, Ankita and Sharma, Chandni and Diya and Joshi, Mayurika and Ritu},
  booktitle={2024 Asian Conference on Intelligent Technologies (ACOIT)}, 
  title={Preserving Information Integrity: Analyzing the Impact of Deepfake Videos on Social Media Trust and Security}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={The proliferation of deepfake videos on social media has raised huge issues about disinformation, identity manipulation, and fraud. Advanced AI techniques now enable the creation of pretty convincing fake films, posing threats to character and countrywide security, eroding consider in digital media, and undermining online discourse. This research paper aims to develop a strong deepfake detection set of rules that leverages superior laptop vision and device getting to know strategies to accurately pick out manipulated films on social media. We will look at the unfold of deepfakes throughout social media platforms, examine their effect on on line discourse, and evaluate the effectiveness of our detection set of rules on numerous platforms. Furthermore, we will provide insights and recommendations for social media organizations, policymakers, and users to mitigate the dangers associated with deepfakes. Our last intention is to make contributions to a safer and greater honest on line surroundings with the aid of combating the spread of deepfakes and disinformation. The study will include a comprehensive literature evaluation on deepfake detection and social media vulnerabilities, experiments and analyses on a massive dataset of deepfake and real motion pictures, visualizations and information illustrating the spread and effect of deepfakes, and an assessment of our detection algorithm’s performance the use of metrics such as accuracy, precision, consider, and F1-score. Relevant legal guidelines, rules, and ethical guidelines related to deepfakes and social media may also be cited.},
  keywords={Deepfakes;Visualization;Portable computers;Social networking (online);Films;Virtual environments;Security;Reliability;Artificial intelligence;Guidelines;deepfake detection;social media;identity manipulation;artificial intelligence;computer vision},
  doi={10.1109/ACOIT62457.2024.10941577},
  ISSN={},
  month={Sep.},}@ARTICLE{9739135,
  author={Cho, Jae Won and Kim, Dong-Jin and Jung, Yunjae and Kweon, In So},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={MCDAL: Maximum Classifier Discrepancy for Active Learning}, 
  year={2023},
  volume={34},
  number={11},
  pages={8753-8763},
  abstract={Recent state-of-the-art active learning methods have mostly leveraged generative adversarial networks (GANs) for sample acquisition; however, GAN is usually known to suffer from instability and sensitivity to hyperparameters. In contrast to these methods, in this article, we propose a novel active learning framework that we call Maximum Classifier Discrepancy for Active Learning (MCDAL) that takes the prediction discrepancies between multiple classifiers. In particular, we utilize two auxiliary classification layers that learn tighter decision boundaries by maximizing the discrepancies among them. Intuitively, the discrepancies in the auxiliary classification layers’ predictions indicate the uncertainty in the prediction. In this regard, we propose a novel method to leverage the classifier discrepancies for the acquisition function for active learning. We also provide an interpretation of our idea in relation to existing GAN-based active learning methods and domain adaptation frameworks. Moreover, we empirically demonstrate the utility of our approach where the performance of our approach exceeds the state-of-the-art methods on several image classification and semantic segmentation datasets in active learning setups.},
  keywords={Task analysis;Training;Learning systems;Generative adversarial networks;Semantics;Generators;Deep learning;Active learning;classifier discrepancy;data issues;deep learning;visual recognition},
  doi={10.1109/TNNLS.2022.3152786},
  ISSN={2162-2388},
  month={Nov},}@ARTICLE{10878495,
  author={Zhou, Zhenghong and Chen, Junwei and Lin, Shenggeng and Hong, Liang and Wei, Dong-Qing and Xiong, Yi},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={GRATCR: Epitope-Specific T Cell Receptor Sequence Generation With Data-Efficient Pre-Trained Models}, 
  year={2025},
  volume={29},
  number={3},
  pages={2271-2283},
  abstract={T cell receptors (TCRs) play a crucial role in numerous immunotherapies targeting tumor cells. However, their acquisition and optimization present significant challenges, involving laborious and time-consuming wet lab experimental resource. Deep generative models have demonstrated remarkable capabilities in functional protein sequence generation, offering a promising solution for enhancing the acquisition of specific TCR sequences. Here, we propose GRATCR, a framework incorporates two pre-trained modules through a novel “grafting” strategy, to de-novo generate TCR sequences targeting specific epitopes. Experimental results demonstrate that TCRs generated by GRATCR exhibit higher specificity toward desired epitopes and are more biologically functional compared with the state-of-the-art model, by using significantly fewer training data. Additionally, the generated sequences display novelty compared to natural sequences, and the interpretability evaluation further confirmed that the model is capable of capturing important binding patterns.},
  keywords={Immune system;Training;Biological system modeling;Decoding;Tumors;Transformers;Bioinformatics;Artificial intelligence;Antigens;Predictive models;Deep learning;pre-training;t cell receptor;epitope;sequence generation},
  doi={10.1109/JBHI.2024.3514089},
  ISSN={2168-2208},
  month={March},}@ARTICLE{11095799,
  author={Tang, Lingzhi and Zhang, Zitian and Yang, Jinzhu and Feng, Yong and Wang, Qisen and Sun, Song and Shao, Haibo},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Intervention-based Mixup Augmentation for Multiple Instance Learning in Whole-Slide Image Survival Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={In the field of computational pathology, multiple instance learning (MIL) has become a critical modeling framework for analyzing gigapixel whole-slide images (WSIs). Data scarcity, particularly in survival analyses requiring long-term follow-up, is a prevalent challenge that is often mitigated through data augmentation. Although data augmentation methods for multi-instance classification have progressed, they remain insufficient for multi-instance regression in survival analysis. Compared to classification tasks, data augmentation for survival analysis faces two major challenges: i) higher quality requirements for pseudo-labels on newly generated samples, and ii) imbalanced data distribution, exhibiting the long-tail distribution. To address these challenges, this paper introduces InterMix, a novel plug-and-play multi-instance data augmentation scheme inspired by the concept of intervention. To provide high-quality pseudo-labels, sub-bag assessment rules are proposed to screen out stable and consistent sub-bags before mixing. To alleviate the long-tail problem, this paper proposes the complementary mix strategy to generate minority-augmented instances with high diversity based on the risk distribution of patients. Extensive experiments are conducted on three datasets to demonstrate the superiority of InterMix. In addition, it enables the model to focus more on key areas of concern for pathologists. Our source code has been made available at github.com/lingzhi-T/InterMIx.},
  keywords={Feature extraction;Data augmentation;Pathology;Computational modeling;Heavily-tailed distribution;Accuracy;Training;Data models;Tumors;Cancer;Intervention;Mixup;Whole-Slide Image;Survival Anlysis},
  doi={10.1109/TMI.2025.3592359},
  ISSN={1558-254X},
  month={},}@INPROCEEDINGS{10741409,
  author={Ventura, Enrico},
  booktitle={2024 IEEE Workshop on Complexity in Engineering (COMPENG)}, 
  title={Learning and Unlearning: Bridging classification, memory and generative modeling in Recurrent Neural Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={The human brain is a complex system that is fascinating scientists since a long time. Its remarkable capabilities include categorization of concepts, retrieval of memories and creative generation of new examples. At the same time, modern artificial neural networks are trained on large amounts of data to accomplish these same tasks with a considerable degree of precision. By contrast with biological systems, machines appear to be either significantly slow and energetically expensive to train, suggesting the need for a paradigmatic change in the way they learn. We here review a general learning prescription that allows to perform classification, memorization and generation of new examples in bio-inspired artificial neural networks. The training procedure can be split into a prior Hebbian learning phase and a subsequent anti-Hebbian one (usually referred to as Unlearning). The separation of training in two epochs allows the algorithm to go fully unsupervised while partially aligning with some modern biological theories of learning.},
  keywords={Training;Recurrent neural networks;Reviews;Heuristic algorithms;Conferences;Learning (artificial intelligence);Complexity theory;Classification algorithms;Hebbian theory;Complex systems;Nonlinear Dynamical Systems;Complex Systems;Complex Networks;Biophysics;Machine Learning;Neuroscience},
  doi={10.1109/COMPENG60905.2024.10741409},
  ISSN={2688-2582},
  month={July},}@ARTICLE{8805261,
  author={Liu, Zhao-Hua and Lu, Bi-Liang and Wei, Hua-Liang and Chen, Lei and Li, Xiao-Hua and Rätsch, Matthias},
  journal={IEEE Transactions on Systems, Man, and Cybernetics: Systems}, 
  title={Deep Adversarial Domain Adaptation Model for Bearing Fault Diagnosis}, 
  year={2021},
  volume={51},
  number={7},
  pages={4217-4226},
  abstract={Fault diagnosis of rolling bearings is an essential process for improving the reliability and safety of the rotating machinery. It is always a major challenge to ensure fault diagnosis accuracy in particular under severe working conditions. In this article, a deep adversarial domain adaptation (DADA) model is proposed for rolling bearing fault diagnosis. This model constructs an adversarial adaptation network to solve the commonly encountered problem in numerous real applications: the source domain and the target domain are inconsistent in their distribution. First, a deep stack autoencoder (DSAE) is combined with representative feature learning for dimensionality reduction, and such a combination provides an unsupervised learning method to effectively acquire fault features. Meanwhile, domain adaptation and recognition classification are implemented using a Softmax classifier to augment classification accuracy. Second, the effects of the number of hidden layers in the stack autoencoder network, the number of neurons in each hidden layer, and the hyperparameters of the proposed fault diagnosis algorithm are analyzed. Third, comprehensive analysis is performed on real data to validate the performance of the proposed method; the experimental results demonstrate that the new method outperforms the existing machine learning and deep learning methods, in terms of classification accuracy and generalization ability.},
  keywords={Fault diagnosis;Feature extraction;Rolling bearings;Deep learning;Data mining;Data models;Training;Adversarial network;bearing;deep learning;deep neural networks;domain adaptation (DA);fault diagnosis;feature extraction;machine learning;stack autoencoder (SAE);unsupervised learning},
  doi={10.1109/TSMC.2019.2932000},
  ISSN={2168-2232},
  month={July},}@INPROCEEDINGS{10200390,
  author={Nguyen, Tri-Hai and Park, Heejae and Seol, Kihyun and So, Seonghyeon and Park, Laihyuk},
  booktitle={2023 Fourteenth International Conference on Ubiquitous and Future Networks (ICUFN)}, 
  title={Applications of Deep Learning and Deep Reinforcement Learning in 6G Networks}, 
  year={2023},
  volume={},
  number={},
  pages={427-432},
  abstract={As the demand for data-driven applications and emerging technologies such as extended reality, autonomous vehicles, and the Internet of Things (IoT) continues to grow, the development of a next-generation wireless communication system, 6G, becomes necessary. To fulfill the stringent requirements of 6G networks, new enabling technologies are necessary. Deep learning (DL) and deep reinforcement learning (DRL) are two promising technologies that have gained significant attention in recent years. In this paper, we provide an overview of the applications and advancements of DL and DRL in 6G networks. We discuss the latest research and identify areas for further exploration in this field.},
  keywords={6G mobile communication;Deep learning;Wireless communication;Surveys;Technological innovation;Extended reality;Reinforcement learning;6G;deep learning;deep reinforcement learning;wireless communications},
  doi={10.1109/ICUFN57995.2023.10200390},
  ISSN={2165-8536},
  month={July},}@INPROCEEDINGS{9190228,
  author={Blasch, Erik P. and Niu, Ruixin and O'Rourke, Sean},
  booktitle={2020 IEEE 23rd International Conference on Information Fusion (FUSION)}, 
  title={Target Tracking Analysis for Stone Soup}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={The International Society of Information Fusion (ISIF) Stone Soup project seeks to bring together advances in target tracking through an open-source repository of software libraries. Additionally, the ISIF uncertainty reasoning working group provides an open-source ontology. This paper seeks to demonstrate the correspondence between the open source tracking repository and the Uncertainty Representation and Reasoning Evaluation Framework (URREF) ontology. For example, many target tracking challenge problems propose a scenario for data fusion techniques to solve, from which various performance metrics are considered for evaluation. The Stone Soup framework has the MetricGenerator class and the URREF has the accuracy class. The example presented in the paper utilizes the cubature Kalman filter to determine the impact of corrupted measurements on the track accuracy as an instance of the Stone Soup and URREF metrics.},
  keywords={Target tracking;Uncertainty;Ontologies;Radar tracking;Semantics;Estimation;Information Fusion;URREF;uncertainty;precision-recall;relevance;veracity;OSTEWG},
  doi={10.23919/FUSION45008.2020.9190228},
  ISSN={},
  month={July},}@INPROCEEDINGS{10627886,
  author={Krishnamoorthy, P. and Swetha, Devulapally and Geetha, Pamidimukkala Sai and Karunambiga, K. and Ayyasamy, Ramesh Kumar and Kiran, Ajmeera},
  booktitle={2024 International Conference on Signal Processing, Computation, Electronics, Power and Telecommunication (IConSCEPT)}, 
  title={Revolutionizing Medical Diagnostics: Exploring Creativity in AI for Biomedical Image Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Biomedical image analysis plays a crucial role in the early and accurate diagnosis of diseases, significantly impacting patient outcomes. This study presents an innovative approach to biomedical image analysis by integrating machine learning techniques with a user-friendly web interface. The system takes input images uploaded through the web interface and processes them using advanced machine learning algorithms implemented in Python. The goal is to automate the detection of diseases from these images, enhancing the efficiency and precision of diagnosis. Convolutional Neural Networks (CNNs), a specialized class of deep learning models designed for image analysis, are employed to learn and characterize disease-specific patterns. The proposed approach is evaluated using diverse biomedical images encompassing various diseases and conditions. Extensive experiments demonstrate the system's effectiveness, achieving high accuracy, sensitivity, and specificity in disease detection. Integrating machine learning with a web interface simplifies the diagnostic process and enables remote consultations, making healthcare services more accessible and timelier. In conclusion, this study presents a robust framework for automated biomedical image analysis, demonstrating the potential of machine learning and web technologies in revolutionizing healthcare diagnostics. The system's accuracy and user-friendly interface make it a valuable tool for healthcare professionals, contributing to early disease detection and improved patient care.},
  keywords={Accuracy;Machine learning algorithms;Image analysis;Medical services;Signal processing;Sensitivity and specificity;Robots;Radiomics;Image Segmentation;Image Classification;Feature Extraction},
  doi={10.1109/IConSCEPT61884.2024.10627886},
  ISSN={},
  month={July},}@INPROCEEDINGS{9626986,
  author={Blasch, Erik P. and Braines, David},
  booktitle={2021 IEEE 24th International Conference on Information Fusion (FUSION)}, 
  title={Scalable Information Fusion Trust}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={Key concerns for the deployment of information fusion systems is conformance to standards, methods for certifiability, and assessment of machine techniques to enhance human situation awareness. Two key elements of recent interest are methods to explore scalability and whether systems can be trusted. This paper explores the metrics from trust towards that of scalable information fusion systems designs. Building on experience from human testing with information fusion products, designing training material, providing checklists for fusion products, and feedback from operators; the paper explores methods of information fusion trust and scalability from extensible graphical information fusion techniques. The adapted results indicate a positive correlation between scalability (i.e., data prioritization) and trust (i.e., human attention) from data fusion support to user task analysis.},
  keywords={Measurement;Deep learning;Correlation;Scalability;Current measurement;Data integration;Design tools;Information Fusion;graphical methods;scalability;trust;physics-based and human-derived information fusion (PHIF)},
  doi={10.23919/FUSION49465.2021.9626986},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10064946,
  author={Arora, Lakshay and Kumar, Kshitiz},
  booktitle={2022 4th International Conference on Artificial Intelligence and Speech Technology (AIST)}, 
  title={Android Ransomware Detection Toolkit}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={Ransomware is a type of malware that illegally encrypts the data of victims' devices to attain financial gains. The impact of ransomware is not limited to corporate desktops but also extends to the very lucrative mobile devices market, whose major chunk is backed by Android OS. These ransomware attacks lead to huge financial, reputational, and data losses to the masses of people. The implemented research uses the static and dynamic artifacts generated by the ransomware to designate an android application as a malign or benign sample. The static artifacts used are the permissions and the APIs invoked by the ransomware. These static artifacts are passed through a branched artificial neural network to attain the best metrics. The dynamically generated network traffic was passed through a fine-tuned LGBMClassifier to detect ransomware on the network. Both of these models amalgamate together to defeat the state-of-the-art solutions present in the contemporary world.},
  keywords={Measurement;Computational modeling;Computer network reliability;Memory management;Telecommunication traffic;Mobile handsets;Ransomware;Computer Security;Physical Security;Ransomware},
  doi={10.1109/AIST55798.2022.10064946},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9476057,
  author={Meyer, Torstein and Kaloudi, Nektaria and Li, Jingyue},
  booktitle={2021 IEEE/ACM 2nd International Workshop on Engineering and Cybersecurity of Critical Systems (EnCyCriS)}, 
  title={A Systematic Literature Review on Malicious Use of Reinforcement Learning}, 
  year={2021},
  volume={},
  number={},
  pages={21-28},
  abstract={Since the inception of reinforcement learning (RL), there has been a growing interest in its application in various complex domains. Although these RL methods offer significant benefits of learning by their own experiences without an accurate system model, RL methods can also be used maliciously. This paper presents a systematic literature review of the state-of-the art RL-based cyberattacks to facilitate and motivate further research to address the potential RL misuse. We reviewed 30 recent primary papers and categorized them into (i) RL for attack planning, (ii) RL for performing intrusions, and (iii) RL for attack optimization. We also proposed an RL-based cyber attacks framework. Our insights on the status and limitations of the existing studies can help motivate related future studies.},
  keywords={Systematics;Protocols;Art;Bibliographies;Conferences;Reinforcement learning;Planning;security;cyberattacks;reinforcement learning;cyber-physical systems;systematic literature review},
  doi={10.1109/EnCyCriS52570.2021.00011},
  ISSN={},
  month={June},}@INPROCEEDINGS{10895085,
  author={K, Sriramdharnish and R, Arun and R, Parvin Raj and H, Haseeb Batcha and A, Sanjay},
  booktitle={2024 International Conference on Emerging Research in Computational Science (ICERCS)}, 
  title={Vision Park - Next Gen Computer Vision for Efficient Parking Space Monitoring}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The increasing number of vehicles and limited parking spaces in urban areas have highlighted the need for efficient parking space detection systems. Traditional methods, often reliant on manual monitoring or mobility sensors, face limitations in scalability and efficiency. This project proposes an innovative solution utilizing computer vision technology to automate the detection of occupied parking spaces. By deploying a camera to monitor the entire parking area, Deep learning models (CNN) are employed for object detection. The chosen approach involves creating masks to isolate specific regions of interest, followed by image segmentation using OpenCV. This method enhances accuracy and scalability compared to traditional techniques, offering a robust and automated parking space management solution. The study outlines the methodologies involved, with a focus on the development of the mask and image segmentation process.},
  keywords={Space vehicles;Computer vision;Image segmentation;Accuracy;Computational modeling;Scalability;Real-time systems;Electric vehicle charging;Monitoring;Meteorology;Smart parking system;OpenCV;Parking lot;CNN;Image Segmentation},
  doi={10.1109/ICERCS63125.2024.10895085},
  ISSN={},
  month={Dec},}@ARTICLE{10909292,
  author={Xue, Xingsi and Mei, Yi and Zhao, Baozhong and Zhang, Mengjie},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Adaptive Similarity Feature Construction for Ontology Matching via Multi-Layer Hybrid Genetic Programming}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Ontology is a kernel technique of the semantic web, which defines concepts, properties, and their relationships to establish a shared understanding of domain knowledge. Ontology matching identifies semantically similar entities across different ontologies, which uses similarity features to measure their similarity from different perspectives. However, due to the complexity of the entity heterogeneity, no single similarity feature is universally effective. In recent years, genetic algorithms have proven effective in constructing similarity features for ontology matching, but their potential is limited by the reliance on default classification strategies, empirical determination of the number of high-level features, the requirement for manually selecting, combining these features, and tuning the associated combination parameters. To overcome these drawbacks, we propose a multi-layer hybrid genetic programming approach to automatically construct high-level similarity features. This approach includes three novel components. First, a new multi-layer individual representation is designed, which faciliates the algorithm to adaptively explore the search space of constructing high-level similarity features. Second, to enhance the search effectiveness, a new initialization method and a mutation operator are developed, which use a weight-based strategy to adaptively select and construct a more diverse set of similarity features. Third, a compact genetic algorithm-based optimizer is designed to refine the tree structures of elite individuals. The experimental results on the ontology alignment evaluation initiative’s benchmark show that our algorithm can generate high-quality ontology matching results across various matching tasks, significantly outperforming the state-of-the-art ontology matching methods.},
  keywords={Ontologies;Accuracy;Genetic programming;Medical diagnostic imaging;Electronic mail;Diseases;Diabetes;Vocabulary;Semantics;Genetic algorithms;Ontology Matching;Genetic Programming},
  doi={10.1109/TEVC.2025.3547578},
  ISSN={1941-0026},
  month={},}@ARTICLE{11134836,
  author={Li, Yuanbiao and Yu, Lei and Wei, Yinsheng},
  journal={IEEE Transactions on Aerospace and Electronic Systems}, 
  title={Siamese Sparse Reconstruction Network for Ionospheric Clutter Suppression in HFSWR}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={High frequency surface wave radar (HFSWR) suffers from performance degradation due to strong ionospheric clutter. We proposes a deep learning-based method, siamese sparse reconstruction network (SSRN), for ionospheric clutter suppression in HFSWR. The SSRN integrates sparse coding into a siamese encoder-decoder structure tailored for complex-valued radar data. The convolutional layers perform iterative approximation of the range-doppler spectrum degradation function. The RD spectrum reconstruction loss preserves phase characteristics. The enhancement in signal to clutter and noise ratio (SCNR) gain within the ionospheric clutter using the wavelet series oblique projection filter suppression algorithm is observed to be approximately 4 dB. Experiments demonstrate the advantages of SSRN in clutter suppression over traditional sparse reconstruction and deep learning methods. This data-driven approach combining deep learning and sparse coding holds promise for enhancing HFSWR clutter mitigation.},
  keywords={Clutter;Radar clutter;Sparse matrices;Image reconstruction;Optimization;Estimation;Superresolution;Doppler radar;Dictionaries;Antenna arrays;High frequency surface wave radar (HFSWR);ionospheric clutter suppression;Siamese network;sparse reconstruction},
  doi={10.1109/TAES.2025.3602048},
  ISSN={1557-9603},
  month={},}@ARTICLE{11077739,
  author={Ezemaduka, Chibuikem and Abouzeid, Alhussein A.},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Spec-GNN: Spectrum Enforcement Through Graph Neural Networks in Dynamic Spectrum Access Systems}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={The underlay access mode in dynamic spectrum access (DSA) systems permits secondary users to transmit concurrently with the primary user, provided that the cumulative interference imposed on the primary user does not exceed a set threshold. A spectrum outage is said to have occurred when the interference threshold has been exceeded. To limit the occurrence of an outage, the spectrum sharing policy mandates that all secondary users transmit within set power limits. However, an outage could still occur due to “spectrum violators” who are secondary users that fail to adhere to the spectrum policy, or it could occur due to unforeseen noise within the spectrum environment. In this work, we design an algorithm for detecting and identifying spectrum violators (if any), which we collectively term "enforcement". We propose a novel graph neural network (GNN) based algorithm, Spec-GNN, to identify which secondary users, if any, are spectrum violators when an outage occurs. Because of the noise in a communication system, outages can occur even without the presence of violators, and thus a key challenge is to keep the false alarm rate low. Spec-GNN performs by utilizing as input, a graph of the DSA system formed from data collected from monitoring sensors deployed in the environment. Spec-GNN then learns the roles of each secondary user in the graph, allowing it to classify them as violators or not. We extensively evaluate Spec-GNN across diverse settings with varying number of available sensors, secondary users, and violators. The results show that even with low sensor densities, Spec-GNN can achieve accuracy of around 95% with false alarm rates as low as under 0.03 in realistic outage scenarios. We also show that Spec-GNN’s performance is quite robust to the amount of participating secondary users in the DSA system. Even when the number of violators makes up as much as 50% of the secondary users, Spec-GNN is still able to achieve a classification accuracy of close to 92%, while keeping the false alarm rate under 0.04.},
  keywords={Interference;Sensors;Resource management;Graph neural networks;Noise;Deep learning;Wireless communication;Monitoring;Accuracy;Transmitters;Dynamic spectrum sharing;spectrum misuse;power allocation;interference management;deep learning},
  doi={10.1109/TCCN.2025.3587801},
  ISSN={2332-7731},
  month={},}@ARTICLE{11003068,
  author={Liu, Mengbing and An, Jiancheng and Huang, Chongwen and Yuen, Chau},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Over-the-Air ODE-Inspired Neural Network for Dual Task-Oriented Semantic Communications}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Analog machine-learning hardware platforms promise greater speed and energy efficiency than their digital counterparts. Specifically, over-the-air analog computation allows offloading computation to the wireless propagation through carefully constructed transmitted signals. In addition, reconfigurable intelligent surface (RIS) is emerging as a promising solution for next-generation wireless networks, offering the ability to tailor the communication environment. Leveraging the advantages of RIS, we design and implement the ordinary differential equation (ODE) neural network using over-the-air computation (AirComp) and demonstrate its effectiveness for dual tasks. We engineer the ambient wireless propagation environment through distributed RISs to create an architecture termed the over-the-air ordinary differential equation (Air-ODE) network. Unlike the conventional digital ODE-inspired neural network, the Air-ODE block utilizes the physics of wave reflection and the reconfigurable phase shifts of RISs to implement an ODE block in the analog domain, enhancing spectrum efficiency. Moreover, the advantages of Air-ODE are demonstrated in a deep learning-based semantic communication (DeepSC) system by extracting effective semantic information to reduce the data transmission load, while achieving the dual functions of image reconstruction and semantic tagging simultaneously at the receiver. Simulation results show that the analog Air-ODE network can achieve similar performance to the digital ODE-inspired network. Specifically, for the image reconstruction and semantic tagging task, compared with the analog network without the Air-ODE block, the Air-ODE block can achieve around 2 times gain in both reconstruction quality and tagging accuracy.},
  keywords={Image reconstruction;Semantic communication;Reconfigurable intelligent surfaces;Training;Tagging;Internet of Things;Decoding;Wireless networks;Data mining;Data communication;Over-the-air computation;reconfigurable intelligent surfaces;analog neural network;deep learning-based semantic communication},
  doi={10.1109/TCCN.2025.3569604},
  ISSN={2332-7731},
  month={},}@INPROCEEDINGS{10920175,
  author={Sielemann, Anne and Loercher, Lena and Schumacher, Max-Lion and Wolf, Stefan and Roschani, Masoud and Ziehn, Jens and Beyerer, Juergen},
  booktitle={2024 IEEE 27th International Conference on Intelligent Transportation Systems (ITSC)}, 
  title={Synset Signset Germany: a Synthetic Dataset for German Traffic Sign Recognition}, 
  year={2024},
  volume={},
  number={},
  pages={3383-3390},
  abstract={In this paper, we present a synthesis pipeline and dataset for training / testing data in the task of traffic sign recognition that combines the advantages of data-driven and analytical modeling: GAN-based texture generation enables data-driven dirt and wear artifacts, rendering unique and realistic traffic sign surfaces, while the analytical scene modulation achieves physically correct lighting and allows detailed parameterization. In particular, the latter opens up applications in the context of explainable AI (XAI) and robustness tests due to the possibility of evaluating the sensitivity to parameter changes, which we demonstrate with experiments. Our resulting synthetic traffic sign recognition dataset Synset Signset Germany contains a total of 105500 images of 211 different German traffic sign classes, including newly published (2020) and thus comparatively rare traffic signs. In addition to a mask and a segmentation image, we also provide extensive metadata including the stochastically selected environment and imaging effect parameters for each image. We evaluate the degree of realism of Synset Signset Germany on the real-world German Traffic Sign Recognition Benchmark (GTSRB) and in comparison to CATERED, a state-of-the-art synthetic traffic sign recognition dataset.},
  keywords={Training;Sensitivity;Pipelines;Modulation;Lighting;Metadata;Rendering (computer graphics);Robustness;Surface texture;Synthetic data},
  doi={10.1109/ITSC58415.2024.10920175},
  ISSN={2153-0017},
  month={Sep.},}@INPROCEEDINGS{10527599,
  author={Brahmaiah, Oguluri. Veera and Raju, Mallela Siva Naga and Jahnavi, Vaka. and Varshini, Murukutla},
  booktitle={2024 Third International Conference on Intelligent Techniques in Control, Optimization and Signal Processing (INCOS)}, 
  title={Dense Net-Based Acute Lymphoblastic Leukemia Classification and Interpretation through Gradient-Weighted Class Activation Mapping}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Deep learning models have shown remarkable accuracy in Acute Lymphoblastic Leukemia classification tasks, but their decision-making process remains challenging to interpret. Gradient-weighted Class Activation Mapping (Grad-CAM)is employed to address this opacity. By visualizing the regions of input images that contribute most to predictions, this project provides insights into the decision-making rationale of the models. The approach of this project involves generating augmented data using various techniques such as flipping, rotating, and zooming to remove data imbalance in a dataset. After that, split the data into training and testing data, fine-tune the DenseNet model on the trained data, and evaluate the performance of both models using testing data based on Area Under Curve, recall, accuracy, precision, and f1-score, then Integrate the model into a grad- CAM to visualize the key image region. The model achieves an accuracy of 94.881 %. Comparative performance metrics, including Area Under Curve, recall, accuracy, precision, and fl-score, highlight the superiority of the DenseNet model over MobileNet and EfficientNet B3 for ALL classification. This suggests that DenseN et is particularly well-suited for handling the complexities of the CNMC Leukemia dataset. By visualizing important regions in the images, Grad-CAM provides users with a comprehensive understanding of the decision-making process within the DenseNet model.},
  keywords={Training;Measurement;Decision making;Data visualization;Signal processing;Predictive models;Data models;Acute Lymphoblastic Leukemia(ALL);Classification;Data Preprocessing Gradient-weighted Class Activation Mapping (Grad-CAM);Visualization;Deep Learning;Dense Net},
  doi={10.1109/INCOS59338.2024.10527599},
  ISSN={},
  month={March},}@INPROCEEDINGS{10882559,
  author={Yadav, Dheeraj and Ojha, Rajesh and Rao, Priya Guruprakash and Govindankutty, Sreeprasad and Goel, Om and Vashishtha, Sangeet},
  booktitle={2024 13th International Conference on System Modeling & Advancement in Research Trends (SMART)}, 
  title={Enhancing User Experience with AI-Generated CSS Through Machine Learning for Adaptive Web Design}, 
  year={2024},
  volume={},
  number={},
  pages={300-305},
  abstract={This paper focuses on a deep comparison of five models—Naive Bayes, Logistic Regression, SVM, an, and a Proposed Model—in the definition of the problems used in binary classification to establish intrinsic performance criteria such as ROC curve analysis, F1 score, Recall, Accuracy, and Precision to compare the most effective model by its capability for distinguishing between classes like positive and negative to give less error. Its performance is excellent with a very high accurate AUC of 0.96 in a performance providing excellent discrimination. It is quite close to the performance between the Logistic Regression and SVM models compared. The AUCs are at 0.93 and 0.94, respectively. In all cases, the Proposed Model performed better with consistent results. For instance, it was at 97% F1 score, 97% accuracy, and had a top AUC of 0.97, thereby proving it excellent and outstandingly able for prediction. The experiments have shown that Proposed Model is much more effective from a classification point of view and categorizes as one of the most trustworthy and accurate models from those tested.},
  keywords={Support vector machines;Analytical models;Adaptation models;Logistic regression;Accuracy;Web design;Machine learning;Market research;User experience;Bayes methods;Template;Scribbr;IEEE;Format Binary classification;Naive Bayes;Logistic Regression;SVM;Proposed Model;Accuracy;Precision;ROC curve;F1 score;Area Under Curve (AUC)},
  doi={10.1109/SMART63812.2024.10882559},
  ISSN={2767-7362},
  month={Dec},}@ARTICLE{11163665,
  author={Ji, Xun and Dai, Chengsong and Hao, Li-Ying and Cai, Chengtao and Liu, Siyuan},
  journal={IEEE Sensors Journal}, 
  title={PAC-Net: Physics-Aware Constraint Network for Underwater Image Enhancement}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Optical sensors in underwater environments typically suffer from significant challenges in capturing high-quality underwater images due to complex oceanographic conditions, including light scattering, non-uniform illumination, and noise from aquatic media. These issues inevitably lead to a reduction in contrast and color cast in underwater images, which severely affects the quality of subsequent downstream tasks. To this end, this paper proposes an innovative Physics-Aware Constraint Network (PAC-Net) to achieve underwater image enhancement. Specifically, the salient properties of our PAC-Net are: 1) a Physics-Aware Constraint Module (PACM) is developed, which utilizes the self-attention mechanism in the Transformer architecture to imitate the underwater light transmission process, providing sufficient prior knowledge for the model to facilitate enhancement of underwater images, 2) an Asymmetric Feature Cross Excitation Module (AFCEM) is designed, which can achieve sufficient feature extraction and representation through an innovative feature cross excitation mechanism, and 3) a Cascade Feature Recalibration Module (CFRM) is constructed, which aims to further facilitate adaptive feature recalibration by constructing a multi-stage progressive refinement structure. Experimental results demonstrate the effectiveness of our model on several real-world datasets acquired by underwater optical sensors, and the ablation studies further confirm the effectiveness of each component in our network. The source code is available at https://github.com/XXX.},
  keywords={Feature extraction;Computer architecture;Optical sensors;Image color analysis;Degradation;Image enhancement;Transformers;Training;Mathematical models;Lighting;Underwater optical sensor;underwater image enhancement;underwater image formation model;deep learning;self-attention mechanism},
  doi={10.1109/JSEN.2025.3606908},
  ISSN={1558-1748},
  month={},}@INPROCEEDINGS{10984458,
  author={Sen, Shubhojit and Bhushan, Bharat},
  booktitle={2024 International BIT Conference (BITCON)}, 
  title={Image Quality Comparison Between Nvidia’s Deep Learning Super Sampling and AMD’s FidelityFX Super Resolution}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The increase in GPU performance required to render modern graphic intensive titles and tech demos has increased exponentially. To save on GPU resources and increase frame rate for rendering, image upscalers came in place. Primarily used to enhance performance and improve image quality, it is now a widely used technology, supported in almost all modern GPUs. In this paper, we perform a comparison between the widely adapted rendering techniques – Nvidia’s Deep Learning Super Sampling (DLSS) and AMD's FidelityFX Super Resolution (FSR). Further, we perform an analysis using various image quality metrics. These upscalers come with a frame generation algorithm as well, but we will only be considering the image upscaling. The image metrics work on different aspects of the image, including noise levels, artefacts etc. By using various comparison tools, we analyze the data retrieved from these image metrics. Finally, we conclude which upscaler is better for the task on the basis of the metrics and analysis.},
  keywords={Measurement;Image quality;Deep learning;Data analysis;Superresolution;Graphics processing units;Rendering (computer graphics);Distortion;Noise level;DLSS;FSR;Image Upscaling;Deep Learning;Super Resolution;Image Metrics;Data Analysis},
  doi={10.1109/BITCON63716.2024.10984458},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11087910,
  author={Escobedo, Libia Romero and Straßburger, Steffen and Bär, Thomas},
  booktitle={2025 IEEE 8th International Conference on Industrial Cyber-Physical Systems (ICPS)}, 
  title={Demonstration-Based AI Learning for Dynamic Motion Response in Metal Powder 3D Printing}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={In the manufacturing of metal components for buses, where additive manufacturing remains in an experimental phase, the inclusion of AI algorithms could enhance quality assurance and resilience to unexpected scenarios. Current research primarily focuses on the application of Machine Learning trained with data from simulation. However, more advanced techniques, such as Adversarial Inverse Reinforcement Learning (AIRL), remain underexplored in this domain. This study investigates the application of AIRL to train an AI model for dynamic motion control in the TruPrint 3000. Automated C# scripts generated stochastic values for episodic operation sequences, producing demonstration data that captures expert control logic. After training, the policy was evaluated using the reward network, achieving a reward value of 1199,85 close to the maximum possible reward of 2105. The experimental AI model achieves a reward close to the expert, indicating learned strategies and the need for further development, highlighting the potential of simulation-driven AI.},
  keywords={Training;Solid modeling;Quality assurance;Powders;Dynamics;Metals;Stochastic processes;Reinforcement learning;Three-dimensional printing;Resilience;Digital Twin;Inverse Reinforcement Learning;Imitation Learning;3D Printing},
  doi={10.1109/ICPS65515.2025.11087910},
  ISSN={2769-3899},
  month={May},}@INPROCEEDINGS{11085549,
  author={Fulara, Vidhi and Thakur, Puja and Chahar, Shagun and Tyagi, Swarnim and Sharma, Prakhar},
  booktitle={2025 6th International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV)}, 
  title={A Survey on Diabetic Retinopathy Detection}, 
  year={2025},
  volume={},
  number={},
  pages={505-509},
  abstract={The Diabetic Retinopathy Detection System is a groundbreaking approach that uses machine learning to tackle one of the most common complications of diabetes which is diabetic retinopathy and its detection. This condition, if left unchecked, can lead to severe vision problems and even blindness. By analyzing the data of the patient like blood sugar levels, the period of diabetes, and high-quality retinal images, the system can identify patterns that indicate early signs of DR. This allows doctors to categorize patients based on their risk level and recommend timely, personalized treatment plans.What makes this system especially valuable is its ability to highlight the most important warning signs of diabetic retinopathy. By detecting features like small blood vessel damage (microaneurysms), abnormal fluid buildup (exudates), or tiny areas of bleeding (hemorrhages), it gives eye specialists the tools to focus on what matters most during their assessments. Combining these insights with detailed retinal imaging ensures that even subtle changes in the eyes are identified early—before they become a bigger problem.In short, this system is a game-changer for managing diabetic eye health. By combining cutting-edge technology with a focus on patient-centered care, it offers a smarter, more efficient way to detect and address diabetic retinopathy early, helping patients maintain their vision and live healthier lives.},
  keywords={Training;Surveys;Diabetic retinopathy;Explainable AI;Medical services;Retina;Feature extraction;Convolutional neural networks;Hemorrhaging;Biomedical imaging;machine learning;diabetic retinopathy;eye health;early detection;personalized treatment;healthcare technology;explainable AI (XAI);medical imaging;real-time monitoring;intelligent systems;patient care},
  doi={10.1109/ICICV64824.2025.11085549},
  ISSN={},
  month={June},}@INPROCEEDINGS{11022039,
  author={Sarker, Shuvashis and Refat, Shamim Rahim and Preotee, Faika Fairuj and Islam, Shifat and Muhammad, Tashreef and Hoque, Mohammad Ashraful},
  booktitle={2024 27th International Conference on Computer and Information Technology (ICCIT)}, 
  title={An Exploratory Approach Towards Investigating and Explaining Vision Transformer and Transfer Learning for Brain Disease Detection}, 
  year={2024},
  volume={},
  number={},
  pages={3224-3229},
  abstract={The brain is a highly complex organ that manages many important tasks, including movement, memory and thinking. Brain-related conditions, like tumors and degenerative disorders, can be hard to diagnose and treat. Magnetic Resonance Imaging (MRI) serves as a key tool for identifying these conditions, offering high-resolution images of brain structures. Despite this, interpreting MRI scans can be complicated. This study tackles this challenge by conducting a comparative analysis of Vision Transformer (ViT) and Transfer Learning (TL) models such as VGG16, VGG19, Resnet50V2, MobilenetV2 for classifying brain diseases using MRI data from Bangladesh based dataset. ViT, known for their ability to capture global relationships in images, are particularly effective for medical imaging tasks. Transfer learning helps to mitigate data constraints by fine-tuning pre-trained models. Furthermore, Explainable AI (XAI) methods such as GradCAM, GradCAM++, LayerCAM, ScoreCAM, and Faster-ScoreCAM are employed to interpret model predictions. The results demonstrate that ViT surpasses transfer learning models, achieving a classification accuracy of 94.39%. The integration of XAI methods enhances model transparency, offering crucial insights to aid medical professionals in diagnosing brain diseases with greater precision.},
  keywords={Computer vision;Accuracy;Explainable AI;Magnetic resonance imaging;Transfer learning;Predictive models;Brain modeling;Transformers;Medical diagnostic imaging;Diseases;Vision Transformer (ViT);Transfer Learning (TL);Explainable AI (XAI);Magnetic Resonance Imaging (MRI);State-of-the-Art (SOTA)},
  doi={10.1109/ICCIT64611.2024.11022039},
  ISSN={2474-9656},
  month={Dec},}@INBOOK{10132634,
  author={Carpo, Mario},
  booktitle={Beyond Digital: Design and Automation at the End of Modernity}, 
  title={3 A Tale of Two Sciences, or The Rise of the Anti-Modern Science of Computation}, 
  year={2023},
  volume={},
  number={},
  pages={79-127},
  abstract={On a snowy day in the early winter of what must have been 1978, or 1979, I took a walk on a footpath next to the small village, high in the Western Alps, where I used to spend most of my school holidays as a child and teenager. I was then in my second or third year in college and walking with a friend around the same age&#x2014;I studied architecture and he engineering, hence some occasional disciplinary tension between the two of us. There were a few feet of fresh snow on the ground and we were both walking on snowshoes&#x2014;the rather primitive snowshoes of the time: ours looked like tennis racquets without the handle, with a hardwood frame holding a web of interlacing strings. It was a laborious walk; and after a while I noticed that my friend&#x0027;s pace looked odd and almost unnatural&#x2014;as if he hesitated before shifting his weight to either side, applying pressure to each snowshoe in slow motion, in a stunted, almost arrested way. Are you already exhausted or training for ballet dancing, or what, I asked. None of the above, he answered; I am an engineer, so I calculate before I act. In this instance, he continued, my gradual way of applying pressure to each snowshoe little by little, by restrained increments at every step, saves plenty of energy and effort. That is patently wrong, I retorted&#x2014;after some consideration: at the end of each movement, no matter how you move, your weight will be the same; and assuming the snow is an elastic material, which it may as well be for the limited purpose of our reasoning, its displacement under pressure, hence the sinking of your foot in the snow, will be the same regardless of how you transfer and apply your weight, and regardless of the time it takes for you to do so. I have studied that at school, I think I added: elasticity is a linear phenomenon; if you apply twice the weight, you get double deformation under pressure; apply half the weight, you get half displacement; hence, if you apply the same pressure all at once, or little by little, if you do it fast or slow, or in any order you like, the final deformation or compression of the snow under your weight, hence your effort, will still be the same.},
  keywords={},
  doi={},
  ISSN={},
  publisher={MIT Press},
  isbn={9780262373401},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10132634},}@INPROCEEDINGS{11167691,
  author={Sitaraman, Surendar Rama and Gattupalli, Kalyan and Bhavana Harish Gollavilli, Venkata Surya and Nagarajan, Harikumar and Alagarsundaram, Poovendran and Nagendran, R},
  booktitle={2025 3rd International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)}, 
  title={Privacy-Centric and Explainable AI Frameworks: Combining Edge Analytics, DAG-based Systems, and GANs for Pandemic Preparedness and Healthcare Innovation}, 
  year={2025},
  volume={},
  number={},
  pages={1255-1261},
  abstract={The proposed title effectively emphasizes the integration of AI techniques in healthcare innovation, but could be improved by hyphenizing "DAG-Based Systems" and simplifying the phrasing. The study explores the potential of advanced techniques like lightweight CNNs, blockchain alternatives, and capsule networks in healthcare to improve data confidentiality, diagnostic precision, and real-time processing. It aims to develop a scalable framework using DAGs, GANs, lightweight CNNs, and capsule networks for better scalability and precision. The system incorporates Capsule Networks for enhanced feature representation, lightweight CNNs for real-time illness diagnosis, and blockchain alternatives for safe data processing. The proposed solution has excellent scalability of 1200 TPS, strong data integrity of 99.9%, and great accuracy of 96.4%. Its energy economy and low latency make it suitable for real-time, resource-constrained settings. The abstract has been thoroughly revised to enhance originality and clearly reflect the unique contributions of this study, minimizing similarity with existing literature.},
  keywords={Technological innovation;Pandemics;Explainable AI;Scalability;Data security;Medical services;Real-time systems;Blockchains;Low latency communication;Next generation networking;Next-generation healthcare framework;DAGs;lightweight CNNs;Capsule Networks;real-time diagnostics;data security;modular healthcare systems},
  doi={10.1109/ICSCDS65426.2025.11167691},
  ISSN={},
  month={Aug},}@ARTICLE{10926517,
  author={Liu, Bangzhen and Xu, Yangyang and Xu, Cheng and Xu, Xuemiao and He, Shengfeng},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Open-Set Mixed Domain Adaptation via Visual-Linguistic Focal Evolving}, 
  year={2025},
  volume={35},
  number={9},
  pages={8495-8507},
  abstract={We introduce a new task, Open-set Mixed Domain Adaptation (OSMDA), which considers the potential mixture of multiple distributions in the target domains, thereby better simulating real-world scenarios. To tackle the semantic ambiguity arising from multiple domains, our key idea is that the linguistic representation can serve as a universal descriptor for samples of the same category across various domains. We thus propose a more practical framework for cross-domain recognition via visual-linguistic guidance. On the other hand, the presence of multiple domains also poses a new challenge in classifying both known and unknown categories. To combat this issue, we further introduce a visual-linguistic focal evolving approach to gradually enhance the classification ability of a known/unknown binary classifier from two aspects. Specifically, we start with identifying highly confident focal samples to expand the pool of known samples by incorporating those from different domains. Then, we amplify the feature discrepancy between known and unknown samples through dynamic entropy evolving via an adaptive entropies min/max game, enabling us to accurately identify possible unknown samples in a gradual manner. Extensive experiments demonstrate our method’s superiority against the state-of-the-arts in both open-set and open-set mixed domain adaptation.},
  keywords={Adaptation models;Entropy;Linguistics;Training;Compounds;Circuits and systems;Visualization;Data models;Artificial intelligence;Semantics;Domain adaptation;mixed domain;open-set;visual-linguistic model;entropy evolving},
  doi={10.1109/TCSVT.2025.3551234},
  ISSN={1558-2205},
  month={Sep.},}@ARTICLE{10198568,
  author={LIU, Hong and SUN, Yuling and LI, Yuanyuan},
  journal={Chinese Journal of Electronics}, 
  title={Modeling and Path Generation Approaches for Crowd Simulation Based on Computational Intelligence}, 
  year={2012},
  volume={21},
  number={4},
  pages={636-641},
  abstract={Modeling and simulating group behaviours have been an active research topic in the field of computer animation and game. This paper presents some novel approaches for supporting entity modeling and path generation in crowd simulation. It analyses related work about crowd simulation first. Then, an entity modeling approach based on CGA (Cellular genetic algorithm) and NURBS (Non uniform relational B splines) technologies is presented. Next, following the analysis to PSO (Particle swarm optimization) and ABC (Artificial bee colony) algorithms, a crowd path generative approach based on ABC- PSO is put forward. After that, a simulating example of crowd cohesion and performance comparison are exhibited for showing the efficiency of the algorithms. Finally, the current work is summarized and an outlook for the future work is given.},
  keywords={Surface reconstruction;Computational modeling;Sociology;Animation;Classification algorithms;Surface topography;Splines (mathematics);Crowd simulation;Entity modeling;Cellular genetic algorithm;PSO (Particle swarm optimization) algorithm;ABC algorithm;Path generation},
  doi={},
  ISSN={2075-5597},
  month={October},}@ARTICLE{9063432,
  author={Liu, Shaohua and Liu, Haibo and Bi, Huikun and Mao, Tianlu},
  journal={IEEE Access}, 
  title={CoL-GAN: Plausible and Collision-Less Trajectory Prediction by Attention-Based GAN}, 
  year={2020},
  volume={8},
  number={},
  pages={101662-101671},
  abstract={Predicting plausible and collisionless trajectories is critical in various applications, such as robotic navigation and autonomous driving. This is a challenging task due to two major factors. First, it is difficult for deep neural networks to understand how pedestrians move to avoid collisions and how they react to each other. Second, given observed trajectories, there are multiple possible and plausible trajectories followed by pedestrians. Although an increasing number of previous works have focused on modeling social interactions and multimodality, the trajectories generated by these methods still lead to many collisions. In this work, we propose CoL-GAN, a new attention-based generative adversarial network using a convolutional neural network as a discriminator, which is able to generate trajectories with fewer collisions. Through experimental comparisons with prior works on publicly available datasets, we demonstrate that Col-GAN achieves state-of-the-art performance in terms of accuracy and collision avoidance.},
  keywords={Trajectory;Generative adversarial networks;Gallium nitride;Predictive models;Collision avoidance;Decoding;Generators;Trajectory prediction;generative adversarial network;deep learning},
  doi={10.1109/ACCESS.2020.2987072},
  ISSN={2169-3536},
  month={},}@ARTICLE{10552854,
  author={Chushig-Muzo, David and Calero-Díaz, Hugo and Lara-Abelenda, Francisco J. and Gómez-Martínez, Vanesa and Granja, Conceição and Soguero-Ruiz, Cristina},
  journal={IEEE Access}, 
  title={Interpretable Data-Driven Approach Based on Feature Selection Methods and GAN-Based Models for Cardiovascular Risk Prediction in Diabetic Patients}, 
  year={2024},
  volume={12},
  number={},
  pages={84292-84305},
  abstract={Noncommunicable diseases (NCDs) are the leading cause of morbidity and mortality worldwide. Cardiovascular diseases (CVDs) and diabetes are the most prevalent NCDs, causing 1.9 and 1.5 million deaths yearly. Individuals diagnosed with type 1 diabetes (T1D) are at high risk of developing CVDs. Machine learning (ML) models have provided outstanding results in different domains, including healthcare, allowing to obtain models with high predictive performance. The aim of this study was to develop an interpretable data-driven approach to predict the 10-year CVD risk for T1D older individuals, aiming to provide both reasonable predictive performance and the identification of risk factors associated with CVDs. Data from T1D individuals at the Steno Diabetes Center Copenhagen were used. Different ML-based models were considered, including KNN, decision tree, random forest, and multilayer perceptron (MLP). To enhance the predictive performance of ML models, the conditional tabular generative adversarial network (CTGAN) was used to create synthetic data and increase the size of the training data. Several filter and wrapper feature selection (FS) techniques were considered for identifying the most relevant features involved in CVD risk and enhancing the performance of the ML-based models used. To gain interpretability on predictive models, we used the post-hoc methods: SHAP and accumulated local effects. The experimental results showed a great performance of FS and ML-based models for predicting CVD risk. In particular, the MLP obtained the best results, with a mean absolute error of 0.0088 and mean relative absolute error of 0.0817. Regarding risk factors, age, Hba1c, and albuminuria were identified as crucial in CVD risk prediction, which is in line with recent clinical evidence. Our study contributes to identifying CVD risk and associated risk factors in a data-driven manner, helping to make early interventions and adequate treatments to prevent CVDs.},
  keywords={Diabetes;Predictive models;Training;Radio frequency;Data models;Biological system modeling;Feature extraction;Cardiovascular system;Generative adversarial networks;Cardiovascular risk prediction;type 1 diabetes;machine learning;interpretable methods;feature selection;generative adversarial networks;accumulated local effects;post-hoc interpretability;CTGAN},
  doi={10.1109/ACCESS.2024.3412789},
  ISSN={2169-3536},
  month={},}@ARTICLE{10858703,
  author={Zareer, Mohamed N. and Selmic, Rastko R.},
  journal={IEEE Access}, 
  title={Maximizing Opinion Polarization Using Double Deep Q-Learning in Social Networks}, 
  year={2025},
  volume={13},
  number={},
  pages={57398-57412},
  abstract={Social media networks, such as Facebook and X (formerly Twitter), have become crucial platforms for public discourse, but they also contribute to the rise of misinformation and opinion polarization. This polarization has profound social, economic, and political implications, making it a critical area of study. In this research, we investigate the impact of automated adversary agents on social media networks by introducing a novel approach using Double-Deep Q-learning reinforcement learning (RL) to deliberately increase polarization within social media networks. The RL agent requires minimal interaction with the system and can flexibly adapt to changes within the network, allowing it to effectively exploit structural vulnerabilities and amplify divisions among users. By learning how to influence the flow of information, the agent intensifies polarization and disagreement with fewer interventions compared to traditional methods. Through simulations and experiments with real-world datasets, we demonstrate that our RL-based approach significantly outperforms conventional techniques in escalating polarization. These findings underscore the risks posed by such techniques and the urgent need to develop safeguards against malicious manipulation of social media platforms by intelligent adversary agents.},
  keywords={Social networking (online);Vectors;Mathematical models;Fake news;Data models;Symmetric matrices;Blogs;Stochastic processes;Laplace equations;Heuristic algorithms;Opinion dynamics;consensus;polarization;disagreement;reinforcement learning;artificial intelligence},
  doi={10.1109/ACCESS.2025.3537397},
  ISSN={2169-3536},
  month={},}@ARTICLE{10819351,
  author={A, Sugunapriya and S, Markkandan},
  journal={IEEE Access}, 
  title={Studies on Underwater Image Processing Using Artificial Intelligence Technologies}, 
  year={2025},
  volume={13},
  number={},
  pages={3929-3969},
  abstract={Underwater image processing is a dynamic field that has garnered increasing interest due to its critical applications in marine biology, geological explorations and military reconnaissance. This paper presents a comprehensive survey of the methodologies employed in the enhancement and restoration of underwater imaging with a specific focus on the challenges posed by aquatic medium such as light absorption, scattering and color distortion. The survey reviews a range of techniques from traditional histogram equalization and white balancing methods to cutting edge AI approaches, including CNNs and GANs. Through examination of various datasets and quality metrics, we assess the performance of these methodologies in overcoming the inherent challenges of undersea imaging. Our study highlights the significant advances in AI driven underwater image processing technologies with a need for more resilient and flexible algorithms that can manage the intricacies of an undersea environment. The findings of this survey suggest promising directions for future research, particularly in the development of more sophisticated deep learning models that can further improve image quality and contribute to the underwater exploration and monitoring system.},
  keywords={Image color analysis;Surveys;Image enhancement;Image processing;Histograms;Image recognition;Deep learning;Object detection;Measurement;Videos;Underwater image enhancement;detection;restoration;tracking;underwater datasets},
  doi={10.1109/ACCESS.2024.3524593},
  ISSN={2169-3536},
  month={},}@INBOOK{10880595,
  author={Reddy, Yashashwini and Reddy, Chinthala Kishor Kumar and Lippert, Kari and Reddy, Sahithi},
  booktitle={Generative Artificial Intelligence for Biomedical and Smart Health Informatics}, 
  title={Classification Methods of Deep Learning for Detecting Autism Spectrum Disorder in Children (4&#x2013;12 Years)}, 
  year={2025},
  volume={},
  number={},
  pages={297-319},
  abstract={Summary <p>Autism spectrum disorder is considered as a neurodevelopmental disability. There is a rise in autism cases among children around the world at present. Autistic children will face developmental issues such as sensory integration, poor social networking skills, and speech delay if not diagnosed early and if they do not receive appropriate treatment from healthcare experts. Although there are some common practices performed by doctors to detect autism in children, the accuracy of the prediction of the presence of autism is low. To precisely detect this disorder and to know the severity of this condition, deep learning methods will be an advantage. In this research, we propose the CNN model, which is part of the deep learning concept to detect autism in children. The CNN method shows a high accuracy of 98.76% with a sensitivity of 0.9677, a specificity of 0.9679, and shows an error rate of 1.24%. The other methods, such as artificial neural networks, support vector machine, logistic regression, K&#x2010;nearest neighbor, Naive Bayes, one&#x2010;dimensional convolutional neural network, and temporal convolutional network (TCN), which are the techniques that come under artificial intelligence are analyzed to detect autism in children.</p>},
  keywords={Autism;Medical treatment;Lead;Faces;Depression},
  doi={10.1002/9781394280735.ch15},
  ISSN={},
  publisher={IEEE},
  isbn={9781394280728},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10880595},}@INPROCEEDINGS{9580031,
  author={Khichi, Manish and Kumar Yadav, Rajesh},
  booktitle={2021 12th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={A Threat of Deepfakes as a Weapon on Digital Platform and their Detection Methods}, 
  year={2021},
  volume={},
  number={},
  pages={01-08},
  abstract={Advances in machine learning, deep learning, and Artificial Intelligence(AI) allows people to exchange other people's faces and voices in videos to make it look like what they did or say whatever you want to say. These videos and photos are called “deepfake” and are getting more complicated every day and this has lawmakers worried. This technology uses machine learning technology to provide computers with real data about images, so that we can make forgeries. The creators of Deepfake use artificial intelligence and machine learning algorithms to mimic the work and characteristics of real humans. It differs from counterfeit traditional media because it is difficult to identify. As In the 2020 elections loomed, AI-generated deepfakes were hit the news cycle. DeepFakes threatens facial recognition and online content. This deception can be dangerous, because if used incorrectly, this technique can be abused. Fake video, voice, and audio clips can do enormous damage. This paper examines the algorithms used to generate deepfakes as well as the methods proposed to detect them. We go through the threats, research patterns, and future directions for deepfake technologies in detail. This research provides a detailed description of deep imitation technology and encourages the creation of new and more powerful methods to deal with increasingly severe deep imitation by studying the history of deep imitation.},
  keywords={Machine learning algorithms;Weapons;Voting;Neural networks;Media;Forgery;History;Deepfake;Convolutional Neural Networks(CNNs);Deep Neural Networks(DNNs);Recurrent Neural Networks(RNNs);Generative Adversarial Networks(GANs);Deepfake Detection Challenge(DFDC)},
  doi={10.1109/ICCCNT51525.2021.9580031},
  ISSN={},
  month={July},}@INPROCEEDINGS{11154530,
  author={Mani, Nariman and Attaranasl, Salma},
  booktitle={2025 IEEE/ACIS 23rd International Conference on Software Engineering Research, Management and Applications (SERA)}, 
  title={A Privacy-Preserving System for AI-Powered Dynamic Group Assignment, Behavioral Insights, and Personalized Coaching}, 
  year={2025},
  volume={},
  number={},
  pages={209-216},
  abstract={This paper presents a privacy-preserving framework leveraging artificial intelligence (AI) to enhance adherence and optimize group dynamics in personalized lifestyle coaching platforms. Integrating reinforcement learning (RL) for dynamic group assignment and generative AI for personalized coaching, our approach ensures secure handling of sensitive user data through pseudonymization and encryption. An evaluation involving 2,800 a commercially deployed, industry-level digital health platform users demonstrated substantial improvements in adherence ($35 \%$ to $68 \%$), engagement, and reduced dropout rates. Privacy assessments confirmed zero sensitive data leakage, while user surveys indicated strong acceptance, with over 82% reporting enhanced motivation. This scalable and secure framework offers valuable insights into integrating AI-driven personalization and privacy solutions for healthcare informatics.},
  keywords={Surveys;Privacy;Data privacy;Generative AI;Social networking (online);Reinforcement learning;Encryption;Electronic healthcare;Informatics;Software engineering;Privacy-Preserving AI;Generative AI;Reinforcement Learning;Personalized Coaching;Social Networking in Healthcare;Nutrition Adherence;Peer Accountability;Adaptive Healthcare Systems},
  doi={10.1109/SERA65747.2025.11154530},
  ISSN={2770-8209},
  month={May},}@INPROCEEDINGS{10795589,
  author={Tona, Claudia and Juárez-Ramírez, Reyes and Jiménez, Samantha and Durán, Mayra},
  booktitle={2024 12th International Conference in Software Engineering Research and Innovation (CONISOFT)}, 
  title={Exploring LLM Tools Through the Eyes of Industry Experts and Novice Programmers}, 
  year={2024},
  volume={},
  number={},
  pages={313-321},
  abstract={At present, Large Language Models (LLM) and Generative AI models have emerged and impacted industry and society. LLMs are Artificial intelligence (AI) systems designed to understand and generate human language. The rise in popu-1arity of LLM-based systems has motivated research into their use in education, including code generation tools, automated feedback systems, and support for student software projects. The release of ChatGPT™ marked a significant milestone, providing an accessible tool for IA interaction. ChatGPT™ has gained popularity among students, not only in software areas. This study analyzes the perspectives of software engineering students and software engineers on using LLM tools such as ChatGPT™ for software development projects. In this study, we use a questionnaire to analyze different viewpoints and graphics to show the experiment results between these groups. The findings of this study are expected to provide valuable contributions to the understanding of how LLM tools are perceived in the context of software development and their potential implications for educational practices and industry standards.},
  keywords={Industries;Graphics;Technological innovation;Generative AI;Large language models;Software;Standards;Programming profession;Software engineering;Software development management;Programming Education;Generative AI;Large Language Models;Software Engineering},
  doi={10.1109/CONISOFT63288.2024.00048},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10683276,
  author={Sha, Zifan and Yue, Wenwei and Wang, Shuo and Cheng, Nan and Wu, Jiaming and Li, Changle},
  booktitle={2024 IEEE 99th Vehicular Technology Conference (VTC2024-Spring)}, 
  title={Generative AI-Enabled Sensing and Communication Integration for Urban Air Mobility}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The deepening process of urbanization poses formidable challenges to the current transportation carrying capacity. The utilization of near-ground space (NGS) and urban air mobility (UAM) greatly enhance spatial dimensions and traffic flexibility of the transportation system. However, the current limited sensing capability falls short in meeting the real-time collaborative environmental sensing and intelligent control requirements of aerial transportation. Integrated sensing and communication (ISAC) combines the sensing system of UAM with 6G communication technologies, enabling them to collaborate and achieve data sensing, transmission, processing, and decision control. The use of artificial intelligence-generated content (AIGC) facilitates real-time data fusion and decision-making, adapting to dynamic and unpredictable environments. In this paper, we first model and analyze the traffic flow in three-dimensional space, achieving knowledge embedding based on artificial potential energy field theory. Next, we design a multimodal data fusion neural network structure, which utilizes the Variational Autoencoder (VAE) to generatively achieve feature fusion and compression. Finally, we construct a UAM digital simulation platform using AirSim, which generates considerable aerial data. The simulation results demonstrate that our proposed approach achieves a feature recognition accuracy of 90.38%. The total latency is below 0.6ms, which exhibits high real-time performance.},
  keywords={6G mobile communication;Solid modeling;Vehicular and wireless technologies;Accuracy;Transportation;Digital simulation;Data integration;Urban air mobility;6G;Integrated sensing and communication;Artificial intelligence-generated content},
  doi={10.1109/VTC2024-Spring62846.2024.10683276},
  ISSN={2577-2465},
  month={June},}@ARTICLE{9817110,
  author={Jeong, Jae-Hun and Lee, Eunbin and Lee, Jong-Hyun and Ahn, Chang Wook},
  journal={IEEE Access}, 
  title={Multi-Objective Deep Network-Based Estimation of Distribution Algorithm for Music Composition}, 
  year={2022},
  volume={10},
  number={},
  pages={71973-71985},
  abstract={In the field of evolutionary algorithm music composition, most of the current researches focus on how to enhance environmental selection based on multi-objective evolutionary algorithms (MOEAs). However, the real music composition process defined as large-scale multi-optimization problems (LSMOP) involve the number of combinations, and the existing MOEA-based optimization process can be challenging to effectively explore the search space. To address this issue, we propose a new Multi-Objective Generative Deep network-based Estimation of Distribution Algorithm (MODEDA) based on dimensionality reduction in decision space. In order to alleviate the difficulties with dimensional transformation, we propose a novel solution search method that optimizes in the transformed space and ensures consistency between the pareto sets of the original problem. The proposed algorithm is tested on the knapsack problems and music composition experiments. The experimental results have demonstrated that the proposed algorithm has excellency in terms of its optimization performance and computational efficiency in LSMOP.},
  keywords={Optimization;Estimation;Search problems;Statistics;Space exploration;Sociology;Music;Evolutionary music composition;multi-objective optimization;generative deep networks;estimation of distribution algorithm;artificial intelligent music composition},
  doi={10.1109/ACCESS.2022.3189163},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11106099,
  author={Birzniece, Ilze and Andersone, Ilze and Bicans, Janis and Balina, Signe},
  booktitle={2025 11th International Conference on Computing and Artificial Intelligence (ICCAI)}, 
  title={Sentiment and Response Priority Detection in Latvian E-mails Using Large Language Models: A Case Study for Low-Resource Languages}, 
  year={2025},
  volume={},
  number={},
  pages={333-341},
  abstract={This study investigates the capabilities of large language models (LLMs) in addressing sentiment analysis and response prioritization in Latvian texts, focusing on e-mails used in organizational workflows. In this work, we propose a response priority estimation schema based on detected severity, urgency, sentiment, and emotional level. To detect those attributes, we established a two-phase experimental approach for detecting urgency, severity, emotional intensity, and sentiment from e-mails using LLM with a zero-shot prompt technique. Considering the challenges associated with low-resource languages such as Latvian and the domain-specific requirement to maintain on-premise data processing, this study evaluates two LLMs: Meta’s Llama3 8B and Llama3.1 70B. Results highlight significant improvements in classification accuracy through refined prompt engineering, achieving up to 96-100% format accuracy, 74.6% for urgency, $\mathbf{7 4. 3 \%}$ for severity in two-class settings, and $\mathbf{9 3. 2 \%}$ and $\mathbf{9 5. 7 \%}$ for emotional intensity and sentiment detection, respectively. However, challenges persist, including discrepancies between human evaluations and model predictions. The findings emphasize the potential of LLMs for enhancing email management in lowresource language settings while outlining further improvement directions. This research advances the field of automated severity and urgency detection using LLMs, addressing a relatively underexplored area compared to the more extensively studied domains of sentiment analysis and affective computing, particularly in the context of low-resource languages.},
  keywords={Sentiment analysis;Accuracy;Large language models;Employment;Organizations;Machine learning;Predictive models;Electronic mail;Prompt engineering;Information systems;Large language models;Generative AI;Lowresource languages;Sentiment analysis;Emotion recognition;Context modeling;Machine learning},
  doi={10.1109/ICCAI66501.2025.00058},
  ISSN={},
  month={March},}@INPROCEEDINGS{8237667,
  author={Zheng, Zhedong and Zheng, Liang and Yang, Yi},
  booktitle={2017 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Unlabeled Samples Generated by GAN Improve the Person Re-identification Baseline in Vitro}, 
  year={2017},
  volume={},
  number={},
  pages={3774-3782},
  abstract={The main contribution of this paper is a simple semi-supervised pipeline that only uses the original training set without collecting extra data. It is challenging in 1) how to obtain more training data only from the training set and 2) how to use the newly generated data. In this work, the generative adversarial network (GAN) is used to generate unlabeled samples. We propose the label smoothing regularization for outliers (LSRO). This method assigns a uniform label distribution to the unlabeled images, which regularizes the supervised model and improves the baseline. We verify the proposed method on a practical problem: person re-identification (re-ID). This task aims to retrieve a query person from other cameras. We adopt the deep convolutional generative adversarial network (DCGAN) for sample generation, and a baseline convolutional neural network (CNN) for representation learning. Experiments show that adding the GAN-generated data effectively improves the discriminative ability of learned CNN embeddings. On three large-scale datasets, Market-1501, CUHK03 and DukeMTMC-reID, we obtain +4.37%, +1.6% and +2.46% improvement in rank-1 precision over the baseline CNN, respectively. We additionally apply the proposed method to fine-grained bird recognition and achieve a +0.6% improvement over a strong baseline. The code is available at https://github.com/layumi/ Person-reID_GAN.},
  keywords={Training;Gallium nitride;Pipelines;Data models;Semisupervised learning;Generators;Training data},
  doi={10.1109/ICCV.2017.405},
  ISSN={2380-7504},
  month={Oct},}@INPROCEEDINGS{10203204,
  author={Shim, Jaehyeok and Kang, Changwoo and Joo, Kyungdon},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Diffusion-Based Signed Distance Fields for 3D Shape Generation}, 
  year={2023},
  volume={},
  number={},
  pages={20887-20897},
  abstract={We propose a 3D shape generation framework (SDF-Diffusion in short) that uses denoising diffusion models with continuous 3D representation via signed distance fields (SDF). Unlike most existing methods that depend on discontinuous forms, such as point clouds, SDF-Diffusion generates high-resolution 3D shapes while alleviating memory issues by separating the generative process into two-stage: generation and super-resolution. In the first stage, a diffusion-based generative model generates a low-resolution SDF of 3D shapes. Using the estimated low-resolution SDF as a condition, the second stage diffusion model performs super-resolution to generate high-resolution SDF. Our framework can generate a high-fidelity 3D shape despite the extreme spatial complexity. On the ShapeNet dataset, our model shows competitive performance to the state-of-the-art methods and shows applicability on the shape completion task without modification.},
  keywords={Point cloud compression;Solid modeling;Computer vision;Three-dimensional displays;Shape;Superresolution;Noise reduction;3D from multi-view and sensors},
  doi={10.1109/CVPR52729.2023.02001},
  ISSN={2575-7075},
  month={June},}@ARTICLE{10274090,
  author={Mustafaev, Bekhzod and Kim, Sungwon and Kim, Eungsoo},
  journal={IEEE Access}, 
  title={Enhancing Metal Surface Defect Recognition Through Image Patching and Synthetic Defect Generation}, 
  year={2023},
  volume={11},
  number={},
  pages={113339-113359},
  abstract={Preventing surface defects of metal products during the production process is challenging due to manufacturing complexity, material properties and environmental factors. Relying on human inspectors for quality control can introduce human error, which increases the risk of delivering defective products to customers. To address these challenges, we propose an Inception-CNN model specifically designed for surface defect recognition in servo motor housings (SMHs). The model incorporates an inception module between convolutional layers to effectively capture multi-scale local information and extract complex and abstract features. Additionally, we introduce an image patching technique that enhances defect recognition for small defects by reducing image complexity while maintaining defect visibility. Moreover, we propose a surface defect generation GAN (SDG-GAN) method, a novel approach that addresses the data imbalance problem and improves the accuracy and robustness of the classification model through generating diverse and high-quality synthetic defect images. The original data was collected using a line scan camera installed in the SMHSI system. We ensured model generalization through 10-fold cross-validation using the SMHSD-P-GAN dataset. Evaluation results indicate that our classification model outperformed other CNN models and achieved strong generalization, with 99.40% accuracy in cross-validation and 99.23% on the original test data. This represents a substantial 32.31% improvement over a baseline CNN model trained on the SMHSD-O-TA dataset, underscoring the effectiveness of our proposed approaches in enhancing classification performance Our method efficiently processes 12 images per second, making it ideal for real-time defect inspection in SMHs. Its successful integration into the SMHSI system confirms its practicality and effectiveness in real-world industrial applications.},
  keywords={Inspection;Surface treatment;Generative adversarial networks;Feature extraction;Data models;Training;Image recognition;Deep learning;Surface contamination;Convolutional neural networks;Deep learning;surface defect recognition;convolutional neural network;image patching;synthetic defect generation},
  doi={10.1109/ACCESS.2023.3322734},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10763323,
  author={Shah, Prachi N. and Khan, Rais Abdul Hamid},
  booktitle={2024 4th International Conference on Sustainable Expert Systems (ICSES)}, 
  title={A Review Paper on Innovative Deep Learning and Machine Learning Algorithms for Improved Cervical Cancer Identification}, 
  year={2024},
  volume={},
  number={},
  pages={1095-1100},
  abstract={Cervical cancer is a major problem, especially in nations with low or middle incomes where access to cutting-edge healthcare and regular screening is constrained. Early detection and precise diagnosis are essential for effective therapy and higher survival rates. The identification of cervical cancer has shown outstanding and more accurate results with recent methods in machine learning (ML) and deep learning (DL). More accurate and efficient diagnostic tools are required since the use of conventional screening methods, like Pap smears and HPV tests, is restricted. The research looks into feature extraction techniques like Histogram of Oriented Gradients (HOG) and Gray Level Co-occurrence Matrix (GLCM) in addition to machine learning approaches like support vector machines (SVM), random forests, and k-nearest neighbors (k-NN). Convolution neural networks (CNNs) and transfer learning are addressed in order to achieve better performance on fewer datasets. Recurrent neural networks (RNNs) and generative adversarial networks (GANs), two cutting-edge deep learning techniques, are also studied. Some of the future directions include the development of individualized medical strategies, the application of ML and DL models to clinical practice, and the fusion of multiple communication data sources to increase diagnosis accuracy.},
  keywords={Deep learning;Support vector machines;Accuracy;Recurrent neural networks;Reviews;Soft sensors;Transfer learning;Data models;Cervical cancer;Random forests;Cervical Cancer;Healthcare;Pap Smear Test;HPV Testing;SVM technique;KNN algorithm;CNN methodology},
  doi={10.1109/ICSES63445.2024.10763323},
  ISSN={},
  month={Oct},}@ARTICLE{11028879,
  author={Zhao, Junhong and Xue, Bing and Zhang, Mengjie},
  journal={IEEE Transactions on Image Processing}, 
  title={Anisotropic Spherical Gaussians Lighting Priors for Indoor Environment Map Estimation}, 
  year={2025},
  volume={34},
  number={},
  pages={3635-3647},
  abstract={High Dynamic Range (HDR) environment lighting is essential for augmented reality and visual editing applications, enabling realistic object relighting and seamless scene composition. However, the acquisition of accurate HDR environment maps remains resource-intensive, often requiring specialized devices such as light probes or 360° capture systems, and necessitating stitching during postprocessing. Existing deep learning-based methods attempt to estimate global illumination from partial-view images but often struggle with complex lighting conditions, particularly in indoor environments with diverse lighting variations. To address this challenge, we propose a novel method for estimating indoor HDR environment maps from single standard images, leveraging Anisotropic Spherical Gaussians (ASG) to model intricate lighting distributions as priors. Unlike traditional Spherical Gaussian (SG) representations, ASG can better capture anisotropic lighting properties, including complex shape, rotation, and spatial extent. Our approach introduces a transformer-based network with a two-stage training scheme to predict ASG parameters effectively. To leverage these predicted lighting priors for environment map generation, we introduce a novel generative projector that synthesizes environment maps with high-frequency textures. To train the generative projector, we propose a parameter-efficient adaptation method that transfers knowledge from SG-based guidance to ASG, enabling the model to preserve the generalizability of SG (e.g., spatial distribution and dominance of light sources) while enhancing its capacity to capture fine-grained anisotropic lighting characteristics. Experimental results demonstrate that our method yields environment maps with more precise lighting conditions and environment textures, facilitating the realistic rendering of lighting effects. The implementation code for ASG extraction can be found at https://github.com/junhong-jennifer-zhao/ASG-lighting},
  keywords={Lighting;Estimation;Anisotropic;Accuracy;Rendering (computer graphics);Shape;Light sources;Training;Standards;Indoor environment;Environment light estimation;Anisotropic Spherical Gaussians;image-based lighting},
  doi={10.1109/TIP.2025.3575902},
  ISSN={1941-0042},
  month={},}@ARTICLE{11071917,
  author={Li, Junjie and Chi, Kaichen and Chang, Yue and Wang, Qi},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={DFG-DDM: Deep Frequency-Guided Denoising Diffusion Model for Remote Sensing Image Dehazing}, 
  year={2025},
  volume={63},
  number={},
  pages={1-12},
  abstract={Haze removal in remote sensing (RS) images has become increasingly vital due to their capacity to contain essential information for accurate geospatial analysis. Notably, this phenomenon is particularly pronounced in both spatial and spectral distributions of buildings, complex terrain, and landforms. Inspired by the success of generative models in enhancing details incrementally and suppressing noise, we propose a deep frequency-guided denoising diffusion model (DFG-DDM) for RS imagery dehazing. The pixel-level generative capability of the diffusion model is fully leveraged, and the fast Fourier transform (FFT) is utilized to extract frequency-domain information. This enables the separate mining of semantic information from RS images in both spatial and spectral domains. Concurrently, the continuity of the image in the frequency domain is ensured without altering the diffusion process, thus achieving detailed retention while improving overall clarity. Furthermore, to address the scarcity of physically realistic training data for spatially heterogeneous atmospheric degradation, we construct a random haze distribution dataset for remote sensing (RHDRS) dehazing. RHDRS randomly simulates the spatial distribution and thickness of haze, containing 4500 hazy images along with the corresponding ground truths (GTs). Experiments demonstrate that our approach outperforms existing state-of-the-art techniques. The dataset and the code can be accessed at https://github.com/Junjie-LLL/DFG-DDM},
  keywords={Frequency-domain analysis;Diffusion models;Noise;Image restoration;Noise reduction;Diffusion processes;Remote sensing;Feature extraction;Data mining;Training;Denoising diffusion models (DDMs);fast Fourier transform (FFT);image dehazing;remote sensing (RS) image},
  doi={10.1109/TGRS.2025.3585894},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{11042915,
  author={Dang, Tingting and Fang, Wenxuan and Li, Jiaqiang and Liu, Qiqi and Gu, Junhua and Jin, Yaochu},
  booktitle={2025 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={An Elite-Guided Large-Scale Multi-Objective Evolutionary Algorithm Driven by Denoising Diffusion Probabilistic Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={As the dimensionality of the decision space in multi-objective optimization problems increases, the decision space expands exponentially, presenting significant challenges to the search efficiency of traditional multi-objective evolutionary algorithms in large-scale multi-objective optimization problems. To quickly locate promising search regions in the vast decision space, this paper proposes utilizing denoising diffusion probabilistic models to generate promising solutions, based on which a novel elite-guided large-scale multi-objective evolutionary algorithm is introduced. Specifically, in our proposed method, the population is divided into elite and poor solutions, with each poor solution paired with an elite solution. The elite solutions serve as generation targets, and their paired poor solutions act as conditions during the training of the generative model. Our approach allows the model to not only capture the distribution of elite solutions but also effectively model the evolutionary trajectory from poor solutions to elite solutions. The entire population is used as conditions, and the trained generative model generates ideal positions, which are then updated to produce offspring solutions. Experimental results on large-scale multi-objective benchmark functions demonstrate that the proposed algorithm outperforms four state-of-the-art large-scale multi-objective evolutionary algorithms.},
  keywords={Training;Computational modeling;Noise reduction;Evolutionary computation;Diffusion models;Search problems;Trajectory;Computational efficiency;Optimization;Faces;Large-scale multi-objective optimization problems;denoising diffusion probabilistic models;elite-guided;large-scale multi-objective evolutionary algorithm},
  doi={10.1109/CEC65147.2025.11042915},
  ISSN={},
  month={June},}@ARTICLE{11048639,
  author={Dong, Hua and Zhang, Xiaohua and Meng, Hongyun and Jiao, Licheng},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Noise-to-Abundance Translation: Unsupervised Hyperspectral Unmixing Based on Diffusion Models}, 
  year={2025},
  volume={63},
  number={},
  pages={1-18},
  abstract={Hyperspectral unmixing is an important issue in the remote sensing field for identifying the constituent materials and their respective distributions in a scene. In recent years, a large number of data-driven HSI unmixing methods have been proposed. These methods reformulate the unmixing task as a transformation from spectral pixels to abundance. Diffusion models, a recently emerging class of generative models, have shown potential in converting noise into other meaningful representations. However, applying diffusion models to unsupervised hyperspectral unmixing faces the following challenges: stochasticity of the generative process, neglect of the quality and prior knowledge of the estimation of original data, and difficulty in solving the learning optimization problem. To address these issues, we propose a novel diffusion-based unsupervised hyperspectral unmixing framework, enabling the transformation from noise to abundance maps. First, we embed the diffusion process into an autoencoder (AE) architecture and introduce a denoising guidance generator to extract robust guidance from hyperspectral images, directing the reverse diffusion process to produce spatially aligned and physically plausible abundances. Second, we design an abundance evaluation module that supervises the original data, that is, abundances in this context, using decoder-based reconstruction evaluation and unmixing prior knowledge. Additionally, we adopt a stage-wise freezing training strategy to progressively stabilize the model and address the learning optimization problem. Experimental results on both simulated and real-world datasets demonstrate that the proposed method effectively addresses the challenges of unsupervised hyperspectral unmixing, producing accurate, physically meaningful, and robust unmixing results.},
  keywords={Hyperspectral imaging;Diffusion models;Noise;Training;Autoencoders;Optimization;Noise reduction;Feature extraction;Image reconstruction;Generators;Autoencoder (AE) network;diffusion model;feature extraction;hyperspectral unmixing},
  doi={10.1109/TGRS.2025.3582029},
  ISSN={1558-0644},
  month={},}@INBOOK{10953419,
  author={Peters, Nate},
  booktitle={Machine Learning and the City: Applications in Architecture and Urban Design}, 
  title={Enabling Alternative Architectures}, 
  year={2022},
  volume={},
  number={},
  pages={193-200},
  abstract={<p>This project began with an interest in participatory design in architecture, specifically as it has been applied to solutions proposed for mass housing. In architecture, &#x2018;participatory design&#x2019; refers to the inclusion of the future occupants of a space in the design process. A successful participatory design system needs to solve two distinct problems: the system and the interface. The user interface of the application was written in JavaScript. The open&#x2010;source library Three.js was used for drawing and editing geometry, rendering the scene, and creating interactive camera controls. The suggestion algorithm that runs on the backend of the application is powered by a generative adversarial network, which is a type of neural network architecture proposed by Ian Goodfellow in 2014.</p>},
  keywords={Pediatrics;Medical services;Hospitals;Cloud computing;Ventilators;Support vector machines;Deep learning;Nose;Monitoring;Machine learning algorithms},
  doi={10.1002/9781119815075.ch16},
  ISSN={},
  publisher={Wiley},
  isbn={9781119749585},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10953419},}@ARTICLE{11029001,
  author={Zhang, Yanqin and Zhang, Zhanling},
  journal={IEEE Access}, 
  title={High-Order Vehicular Pattern Learning and Privacy-Preserving and Unsupervised GAN for Privacy Protection Toward Vehicular Parts Detection}, 
  year={2025},
  volume={13},
  number={},
  pages={100987-101004},
  abstract={This paper introduces High-order Vehicular Pattern Learning (HVPL), a novel framework designed to enhance vehicular pattern detection while ensuring privacy protection, associated with authentication through the integration of Privacy-Preserving and Unsupervised GAN (PPUP-GAN). To preserve data privacy, we use the PPUP-GAN to create massive-scale vehicular data that well mimics real data. Afterward, HVPL improves upon traditional methods by constructing a large-scale hypergraph that models complex relationships among vehicular pattern features, uncovering high-order interactions that conventional models fail to detect. The model also uses a Gaussian Mixture Model (GMM)-based posterior probability to rank candidate patches for vehicular pattern detection, prioritizing high-risk areas and minimizing false positives. Experiments demonstrated that our method outperforms its counterparts by achieving higher precision and stability in vehicular pattern detection, with a notable improvement of up to 33.39% in Average Precision (AP) and 62.62% in AP_50.},
  keywords={Deep learning;Generative adversarial networks;Data models;Data privacy;Optimization;Processor scheduling;Predictive models;Computational modeling;Accuracy;Training;Vehicular pattern detection;privacy protection;high-order vehicular pattern learning;privacy-preserving and unsupervised GAN;hypergraph modeling},
  doi={10.1109/ACCESS.2025.3578006},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8967385,
  author={Saleem, Summra and Dilawari, Aniqa and Ghani Khan, Muhammad Usman and Husnain, Muhammad},
  booktitle={2019 International Conference on Robotics and Automation in Industry (ICRAI)}, 
  title={Voice Conversion and Spoofed Voice Detection from Parallel English and Urdu Corpus using Cyclic GANs}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={With the advent of Generative Adversarial Networks (GANs), the fake news epidemic is booming; which not only encompasses pictures and videos but also audio. This is a big issue in an automatic speech verification (ASV) devices allowing anyone to steal an identity from a database of users. We aim to address this issue for a database of speaker utterances in the Urdu language by a two-fold solution. First, we will describe a Cyclic GAN based one-to-one conversion method that can generate speech from given speaker to a target voice bi-directionally. Cyclic GANs have much more strong mapping capabilities than ordinary GANs due to the property of Cyclic consistency loss. This framework ensures that given sufficient training data, generated output is very similar to the input. Furthermore, adversarial examples generated by the model are used for spoofed voice detection. We will use a Gradient Boosting method to learn to distinguish the voice utterances of various speakers that are stored in a database from the adversarial examples. For the testing of English language, we used the VCTK dataset and for the Urdu language, we used Urdu speech recordings containing a single word utterance from each speaker. This is tested for male → male, male → female, female → male and female → female voice conversions. The results obtained from learning from the adversarial examples are optimistic but more data and efforts are needed to make it usable into practical systems that can support speech verification at large scale.},
  keywords={Industries;Databases;Training data;Production;Generative adversarial networks;Feature extraction;Recording;Robotics and automation;Videos;Testing;Cyclic generative adversarial networks;voice conversion;GAN;latent space;cyclic consistency loss;mean opinion score},
  doi={10.1109/ICRAI47710.2019.8967385},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10536454,
  author={Gottsacker, Matt and Bruder, Gerd and Welch, Gregory F.},
  booktitle={2024 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, 
  title={rlty2rlty: Transitioning Between Realities with Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={1160-1161},
  abstract={We present a system for visually transitioning a mixed reality (MR) user between two arbitrary realities (e.g., between two virtual worlds or between the real environment and a virtual world). The system uses artificial intelligence (AI) to generate a 360° video that transforms the user's starting environment to another environment, passing through a liminal space that could help them relax between tasks or prepare them for the ending environment. The video can then be viewed on an MR headset.},
  keywords={Headphones;Three-dimensional displays;Generative AI;Conferences;Mixed reality;Transforms;Switches;Human-centered computing—Human computer interaction (HCI)—Interaction paradigms—Mixed / augmented reality},
  doi={10.1109/VRW62533.2024.00374},
  ISSN={},
  month={March},}@INPROCEEDINGS{10672966,
  author={Dhairya and Hrishikesh, Jeeri and Sonu, Gollapalli Persis and Vaishnavi, Dandla and Sanapala, Srinuvasarao and Pallavi, L.},
  booktitle={2024 7th International Conference on Circuit Power and Computing Technologies (ICCPCT)}, 
  title={Skillify: Enhanced Learning Management System Using Generative AI}, 
  year={2024},
  volume={1},
  number={},
  pages={1527-1532},
  abstract={Traditionally, students faced challenges in acquiring knowledge from textbooks due to difficulties in access and the high cost associated with them. Online learning aims to overcome these hurdles by providing a digital alternative that is accessible to everyone. Students can overcome geographical obstacles by using online platforms, gaining access to a wealth of instructional resources. This digital paradigm shift seeks to democratize education by making it more equitable and inclusive. However, the accessibility of online learning remains a significant challenge, especially for those who are visually impaired. Additionally, the vast number of courses offered on online platforms can make it challenging for learners to select the right course that can advance their careers. Learners often struggle to identify the best courses to improve their skills. To overcome accessibility challenges for the visually impaired, our platform incorporates a text-to-speech feature, which converts written text into spoken words. To address the problem of choosing the right course, we are implementing a course recommendation system to enable learners to acquire new skills that are beneficial to their advancement. Our platform encompasses three distinct modules: user, professor, and admin. Each module serves a specific role within our system. This project exemplifies the potential of artificial intelligence in revolutionizing education through enhanced learning experiences. Our proposed model aims to improve the efficiency of existing models by implementing text-to-speech and course recommendation features.},
  keywords={Computers;Learning management systems;Electronic learning;Costs;Engineering profession;Generative AI;Education;Online courses;Virtual classrooms;Web-based training;E-learning platforms;Diverse learning ability},
  doi={10.1109/ICCPCT61902.2024.10672966},
  ISSN={},
  month={Aug},}@ARTICLE{10912448,
  author={Adão, Telmo and Cerqueira, João and Adão, Miguel and Silva, Nuno and Pascoal, David and Magalhães, Luís G. and Barros, Tiago and Premebida, Cristiano and Nunes, Urbano J. and Peres, Emanuel and Morais, Raul},
  journal={IEEE Access}, 
  title={PROMORE: A Procedural Modeler of Virtual Rural Environments With Artificial Dataset Generation Capabilities for Remote Sensing Contexts}, 
  year={2025},
  volume={13},
  number={},
  pages={47632-47652},
  abstract={Remote sensing (RS) is a rapidly evolving field that facilitates the study of phenomena on the Earth’s surface. Through various platforms, including satellites, manned aircraft, and remotely piloted aerial vehicles (RPAV), RS has been strategically applied to critical sectors like agriculture and forestry, which are essential for humanity’s sustenance. Key applications include crops classification, yield estimation and livestock monitoring and quantification. In the era of artificial intelligence (AI), the development of deep learning (DL) models for such applications often requires extensive field data collection and labor-intensive image labeling, which are both time-consuming and resource-intensive. To address these challenges, this paper presents Procedural Modeling of Rural Environments (PROMORE), a parameterizable, ontology-driven system designed to generate 3D virtual environments encompassing forestry, farmland – mainly focused on vineyards – and village settings. This system also implements functionalities to automate the extraction of training data for deep learning applications in remote sensing, with the declared aim of providing complementary capabilities to data augmentation techniques, encompassing both traditional methods (e.g., flips, rotations, zooming) and advanced approaches such as generative adversarial networks (GANs). By simulating RPAV flights and managing virtual object visibility, PROMORE enables the automatic labeling, delineation, and highlighting of elements of interest (e.g., vine plants, trees, buildings), facilitating the generation of datasets tailored for tasks such as semantic segmentation, and object detection.},
  keywords={Three-dimensional displays;Remote sensing;Object oriented modeling;Production;Context modeling;Virtual environments;Solid modeling;Pipelines;Ontologies;Buildings;Computer graphics;virtual environments;3D modeling;procedural modeling;artificial data engineering;artificial dataset;deep learning},
  doi={10.1109/ACCESS.2025.3548513},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11166156,
  author={Hahn, Waldemar and Sedlmayr, Martin and Wolfien, Markus},
  booktitle={2025 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)}, 
  title={Genetic Algorithm for Subset Selection in Synthetic Tabular Data}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Subset selection has been widely studied but remains underexplored for synthetic tabular data, particularly in data sharing contexts that require high quality data. While generative models can produce large volumes of synthetic data, directly sampling and releasing such data risks including low quality or unrepresentative samples, which can reduce data utility. An alternative approach is to generate more data than needed and subsequently select a subset that better meets specific quality criteria. This paper introduces a genetic algorithm (GA)-based method for optimizing such subset selection. The proposed GA is independent of any specific fitness function, enabling adaptation to diverse evaluation metrics, their combinations, or varying use case requirements. We benchmarked the method on five medical datasets, each synthesized by multiple generative architectures, and consistently found that the GA selected subsets outperformed both the initial synthetic datasets and a random subset selection baseline. Notably, initializing the GA with systematically generated synthetic subsets led to nearly twice the improvement over the baselines compared to random initialization, emphasizing the importance of more informed starting solutions. The proposed GA-based method proved especially beneficial for smaller datasets, which are frequently encountered in clinical domains, such as rare disease research. While performance gains diminished for larger datasets due to combinatorial complexity, this work highlights the potential of GA-driven optimization as a foundation for future research into scalable and adaptive subset selection methods for synthetic data sharing.},
  keywords={Measurement;Computer architecture;Performance gain;Benchmark testing;Data models;Complexity theory;Optimization;Genetic algorithms;Synthetic data;Diseases;synthetic data;tabular data;genetic algorithm;subset selection},
  doi={10.1109/ACDSA65407.2025.11166156},
  ISSN={},
  month={Aug},}@ARTICLE{10487038,
  author={Ngo, Thi Thuy An and Tran, Thanh Tu and An, Gia Khuong and Nguyen, Phuong Thy},
  journal={IEEE Transactions on Learning Technologies}, 
  title={ChatGPT for Educational Purposes: Investigating the Impact of Knowledge Management Factors on Student Satisfaction and Continuous Usage}, 
  year={2024},
  volume={17},
  number={},
  pages={1341-1352},
  abstract={The growing prevalence of advanced generative artificial intelligence chatbots, such as ChatGPT, in the educational sector has raised considerable interest in understanding their impact on student knowledge and exploring effective and sustainable implementation strategies. This research investigates the influence of knowledge management factors on the continuous usage of ChatGPT for educational purposes while concurrently evaluating student satisfaction with its use in learning. Using a quantitative approach, a structured questionnaire was administered to 513 Vietnamese university students via Google Forms for data collection. The partial least squares structural equation modeling statistical technique was employed to examine the relationships between identified factors and evaluate the research model. The results provided strong support for several hypotheses, revealing significant positive effects of expectation confirmation on perceived usefulness and satisfaction, as well as perceived usefulness on user satisfaction and continuous usage of ChatGPT. These findings suggest that when students recognize the usefulness of ChatGPT for their learnings, they experience higher satisfaction and are more likely to continue using it. In addition, knowledge acquisition significantly impacts both satisfaction and continuous usage of ChatGPT, while knowledge sharing and application influence satisfaction exclusively. This indicates that students prioritize knowledge acquisition over sharing and applying knowledge through ChatGPT. The study has theoretical and practical implications for ChatGPT developers, educators, and future research. Theoretically, it contributes to understanding satisfaction and continuous usage in educational settings, utilizing the expectation confirmation model and integrating knowledge management factors. Practically, it provides insights into comprehension and suggestions for enhancing user satisfaction and continuous usage of ChatGPT in education.},
  keywords={Chatbots;Education;Knowledge management;Generative AI;Oral communication;Mathematical models;Knowledge acquisition;ChatGPT;continuous usage (CUS);generative artificial intelligence (AI);knowledge management (KM);satisfaction},
  doi={10.1109/TLT.2024.3383773},
  ISSN={1939-1382},
  month={},}@INBOOK{10897036,
  author={Islam, Mohammad Rubyet},
  booktitle={Generative AI, Cybersecurity, and Ethics}, 
  title={The Human Factor and Ethical Hacking}, 
  year={2025},
  volume={},
  number={},
  pages={255-271},
  abstract={Summary <p>The rapid advancement of generative artificial intelligence (GenAI) and ethical hacking necessitates new regulatory frameworks emphasizing adaptability and international collaboration while safeguarding fundamental rights. GenAI's transformative impact on sectors like cybersecurity highlights the importance of human insight and ethical oversight. In cybersecurity, a human&#x2010;centric approach to GenAI implementation is crucial to protect critical infrastructure and personal data from sophisticated threats. This chapter explores frameworks such as Human&#x2010;in&#x2010;the&#x2010;Loop (HITL), Human&#x2010;on&#x2010;the&#x2010;Loop (HOTL), and Human&#x2010;Centered GenAI (HCAI), emphasizing the indispensable role of human judgment and ethical governance. The chapter also delves into training cybersecurity professionals for a GenAI&#x2010;augmented future, addressing accountability, bias prevention, crisis management, and ethical hacking.</p>},
  keywords={Ethics;Predictive models;Data models;Computer security;Training;Reviews;Decision making;Data collection;Human in the loop;Automation},
  doi={10.1002/9781394279326.ch10},
  ISSN={},
  publisher={Wiley},
  isbn={9781394279319},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10897036},}@ARTICLE{8601324,
  author={Yang, Yun and Nan, Fengtao and Yang, Po and Meng, Qiang and Xie, Yingfu and Zhang, Dehai and Muhammad, Khan},
  journal={IEEE Access}, 
  title={GAN-Based Semi-Supervised Learning Approach for Clinical Decision Support in Health-IoT Platform}, 
  year={2019},
  volume={7},
  number={},
  pages={8048-8057},
  abstract={With the development of the Internet of Things (IoT) technology, its application in the medical field becomes more and more extensive. However, with a dramatic increase in medical data obtained from the IoT-based health service system, labeling a large number of medical data requires high cost and relevant domain knowledge. Therefore, how to use a small number of labeled medical data reasonably to build an efficient and high-quality clinical decision support model in the IoT-based platform has been an urgent research topic. In this paper, we propose a novel semi-supervised learning approach in association with generative adversarial networks (GANs) for supporting clinical decision making in the IoT-based health service system. In our approach, GAN is adopted to not only increase the number of labeled data but also to compensate the imbalanced labeled classes with additional artificial data in order to improve the semi-supervised learning performance. Extensive evaluations on a collection of benchmarks and real-world medical datasets show that the proposed technique outperforms the others and provides a potential solution for practical applications.},
  keywords={Semisupervised learning;Generative adversarial networks;Gallium nitride;Support vector machines;Generators;Supervised learning;Medical diagnostic imaging;Internet of Things;clinical decision support;semi-supervised learning;generative adversarial networks},
  doi={10.1109/ACCESS.2018.2888816},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8695610,
  author={Zhao, Ying and Li, Qi and Wang, Donghui and Yu, Aiping},
  booktitle={2018 11th International Symposium on Computational Intelligence and Design (ISCID)}, 
  title={Image Processing Strategies Based on Deep Neural Network for Simulated Prosthetic Vision}, 
  year={2018},
  volume={01},
  number={},
  pages={200-203},
  abstract={Due to the limited number of implantable electrodes, correcting the input image such that the electrode stimulus ultimately reaching the visual pathway contains sufficient topological information is a challenging task. Some image processing strategies have been applied to the image-to-electrode mapping process previously in order to obtain better recognition performance under simulated prosthetic vision. In this work, a method for foreground extraction and pixelation of images containing simple objects using the state-of-the-art deep learning techniques was proposed. For that, accurate foreground extraction results were obtained by training the U-net network model, pixelated them and paired with the original images. These paired samples were then used to train a Pix2pix generative adversarial network in order to achieve the image-to-pixelated image translation. The experimental results indicated that the U-net network had better foreground extraction effect than the traditional image processing strategies, and the pixelated images generated by the Pix2pix generative model contained more abundant and precise details than other strategies.},
  keywords={Image quality;Feature extraction;Training;Prosthetics;Generators;Task analysis;simulated prosthetic vision;image processing strategies;deep neural networks},
  doi={10.1109/ISCID.2018.00052},
  ISSN={2473-3547},
  month={Dec},}@INPROCEEDINGS{9699471,
  author={Davaji, Benyamin and Cook, Peter A and Kor, Bahar and Luo, Ziwang and Chen, Jiaxian and Clark, Jeremy and Bordonaro, Garry and Genova, Vincent and Heuser, Marco and Ayres, Steve and Ober, Christopher K and Doerschuk, Peter C and Lal, Amit},
  booktitle={2022 IEEE 35th International Conference on Micro Electro Mechanical Systems Conference (MEMS)}, 
  title={Deep Learning for Predicting CD-SEMS of NEMS Devices}, 
  year={2022},
  volume={},
  number={},
  pages={462-465},
  abstract={This paper presents an AI model that predicts the process output from photolithography and plasma etching based on CD-SEM data. This contrasts with physics-based models that are used in conventional TCAD tools. A large dataset was generated consisting of nanostructure CD-SEMs (~150,000) from outcomes of an ASML DUV lithography stepper and an Oxford Cobra ICP plasma etcher. The AI model is an Image-to-Image Translation deep learning algorithm that learns from a training set of the CD-SEMs. This deep learning model enables an evolving TCAD model in which layouts can be actively modified as data from the cleanroom is collected continuously. This model can be helpful to improve yield and device homogeneity and performance, hence time to market, for advanced sub-micron NEMS and MEMS. This nature of this dataset ensures the applicability of the presented algorithms to academic and industrial cleanrooms.},
  keywords={Training;Semiconductor device modeling;Deep learning;Nanoelectromechanical systems;Lithography;Predictive models;Data models;Nanofabrication;Artificial Intelligence;Deep Learning;Photolithography;Plasma Etch},
  doi={10.1109/MEMS51670.2022.9699471},
  ISSN={2160-1968},
  month={Jan},}@INPROCEEDINGS{9022122,
  author={Thasarathan, Harrish and Ebrahimi, Mehran},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)}, 
  title={Artist-Guided Semiautomatic Animation Colorization}, 
  year={2019},
  volume={},
  number={},
  pages={3157-3160},
  abstract={There is a delicate balance between automating repetitive work in creative domains while staying true to an artist's vision. The animation industry regularly outsources large animation workloads to foreign countries where labor is inexpensive and long hours are common. Automating part of this process can be incredibly useful for reducing costs and creating manageable workloads for major animation studios and outsourced artists. We present a method for automating line art colorization by keeping artists in the loop to successfully reduce this workload while staying true to an artist's vision. By incorporating color hints and temporal information to an adversarial image-to-image framework, we show that it is possible to meet the balance between automation and authenticity through artist's input to generate colored frames with temporal consistency.},
  keywords={Image color analysis;Art;Animation;Generators;Production;Training;Gallium nitride;animation;colorization;artificial intelligence;temporal consistency},
  doi={10.1109/ICCVW.2019.00388},
  ISSN={2473-9944},
  month={Oct},}@INPROCEEDINGS{10271948,
  author={Li, Zhehui and Chong, Yung-Wey and Ab Wahab, Mohd Nadhir and Lim, Gin-Keat and Dawood, Rahmad},
  booktitle={2023 4th International Conference on Big Data Analytics and Practices (IBDAP)}, 
  title={Classification and Prediction of Pineapple Quality using Deep Learning}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Pineapple, a popular tropical fruit with widespread consumption, necessitates precise classification and quality prediction to ensure its marketability and profitability. Prior research has explored various methods, including thermal imaging and acoustic spectroscopy, to evaluate pineapple quality, but these methods often require costly equipment. In this research, deep learning techniques are used for pineapple classification and quality prediction. The primary objective is to develop a model that integrates VGG16, LSTM, and GAN techniques to classify pineapple maturity based on color, shape, and texture while utilizing YOLO for grading. The dataset used in this study comprises images of MD2 pineapples obtained from Malaysian farms. The developed prototype extracts pertinent features from images captured by established farm standards in Malaysia. Through an automated process, the model effectively classifies the quality of these pineapples.},
  keywords={Deep learning;Spectroscopy;Shape;Profitability;Prototypes;Predictive models;Feature extraction;pineapple classification;artificial intelligence;smart agriculture;quality prediction},
  doi={10.1109/IBDAP58581.2023.10271948},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10649346,
  author={Song, Yangyi and Ren, Hao and Jing, Fengshi and He, Chaocheng and Xie, Yewei and Zhou, Jiandong},
  booktitle={2024 2nd International Conference on Big Data and Privacy Computing (BDPC)}, 
  title={Enhancing Pneumonia Diagnosis Using a Ensemble Transformer-Based Attention Network for Chest X-Ray Image Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={154-159},
  abstract={The intersection of artificial intelligence (AI) and medical imaging has significantly advanced the diagnosis of pneumonia, a leading cause of mortality worldwide. This paper presents a novel ensemble transformer-based attention network architecture that enhances the detection of pneumonia in chest X-ray images, leveraging the comprehensive Chest X-ray14 dataset. Our model integrates the strengths of GoogleNet, DenseNet, and MobileNet, refined by a sophisticated attention mechanism, yielding a robust framework for medical diagnosis. In a comparative study against established models such as GoogleNet, ResNet50, DenseNet, p-ResNet, and MobileNet, our approach demonstrated superior diagnostic performance, particularly for pneumonia, with an AVC of 91.3. The proposed model also showed exceptional capabilities in identifying other thoracic pathologies like Cardiomegaly, Edema, and Emphysema, with competitive performance in Effusion and Mass detection. These results not only set a new benchmark in the field but also suggest the transformative potential of AI-enhanced diagnostic systems for timely and accurate pneumonia detection, paving the way for their integration into clinical workflows and the advancement of precision medicine.},
  keywords={Pathology;Pneumonia;Precision medicine;Network architecture;Transformers;Medical diagnosis;Artificial intelligence;Ensemble Transformer Network;Pneumonia Detection;Medical Image Diagnosis;Chest X-ray Analysis},
  doi={10.1109/BDPC59998.2024.10649346},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10486217,
  author={Gogna, Anish and Rajpal, Abhishek and Yamini, B.},
  booktitle={2024 IEEE International Conference on Computing, Power and Communication Technologies (IC2PCT)}, 
  title={A Unique Strengthening Mango Farming Model Combining Disease Surveillance, Quality Control and Production Management}, 
  year={2024},
  volume={5},
  number={},
  pages={1380-1383},
  abstract={The popularity of mangoes is a part and parcel of their horticultural economy, that makes business in fruit. In this paper, we have elaborated a user friendly point and click system for disease detection grading as well as classification in mango leaves which is coupled with strategic farming management methods. The suggested system uses modern technology to detect the diseases in mango leaves accurately; with image processing and machine learning for classification & gradation using Deep Learning algorithms like Efficient Net B3. Moreover, it enhances functional farm management strategies to prevent contagion and conducive crop health. This system is targeted towards the effective detection at an appropriate time of specific diseases, and identification to manage subsequent interventions upon crops during mango cultivation so as to help in proactive disease management with overall increased yields food quality.},
  keywords={Deep learning;Production management;Surveillance;Scalability;Crops;Transforms;Agriculture;Image Processing;Artificial Intelligence;Deep Learning;Agriculture;Sustainable solution;Efficient Net B3;Data Augmentation;Database Management System;Microservices;Optimization},
  doi={10.1109/IC2PCT60090.2024.10486217},
  ISSN={},
  month={Feb},}@ARTICLE{9223631,
  author={Xu, Hao and Li, Chen and Rahaman, Md Mamunur and Yao, Yudong and Li, Zihan and Zhang, Jinghua and Kulwa, Frank and Zhao, Xin and Qi, Shouliang and Teng, Yueyang},
  journal={IEEE Access}, 
  title={An Enhanced Framework of Generative Adversarial Networks (EF-GANs) for Environmental Microorganism Image Augmentation With Limited Rotation-Invariant Training Data}, 
  year={2020},
  volume={8},
  number={},
  pages={187455-187469},
  abstract={The main obstacle to image augmentation with Generative Adversarial Networks (GANs) is the need for a large amount of training data, but this is difficult for small datasets like Environmental Microorganisms (EMs). EM image analysis plays a vital role in environmental monitoring and protection, but it is often encountered with small datasets due to the difficulty of EM image collection. To this end, we propose an Enhanced Framework of GANs (EF-GANs) that combines geometric transformation methods and GANs for EM image augmentation. First of all, the color of an EM image has an insignificant impact on its class label, based on this fact, we perform color space augmentation to the original EM images. Secondly, we train EF-GANs with augmented EM images to generate utterly new EM images. Finally, we rotate the generated samples in various directions to obtain a more natural performance. In this study, we use VGG16 and ResNet50 networks to evaluate the proposed EF-GANs on 21 different types of EMs (420 EM images). It is observed that the average precision (AP) of VGG16 increases between 4.5% and 84.1% in 20 EM classes and one class remains unchanged. The AP of Resnet50 rises between 8.7% and 38.7% in 12 EM classes and reaches 100% in two EM classes. Furthermore, to reflect the generalization performance of EF-GANs, we employ an utterly new EM image dataset (630 EM images) to test the previous VGG16 networks. We select the VGG16 networks with original and optimal settings for all the EM classes, and for testing, optimal settings for a single EM class is considered. In the 20 of 21 one-vs-rest EM image classification tasks, the AP of VGG16 increases between 1.66% and 88.1%. The results demonstrate that the proposed EF-GANs can achieve outstanding performance in augmenting single EM images with high quality and resolution, thus, to improve the APs of EM image classification.},
  keywords={Microorganisms;Gallium nitride;Microscopy;Image color analysis;Environmental management;Training;Task analysis;Image augmentation;environmental microorganism;microscopic image;small dataset;generative adversarial networks;image analysis;image classification},
  doi={10.1109/ACCESS.2020.3031059},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10271797,
  author={Xu, Minrui and Niyato, Dusit and Zhang, Hongliang and Kang, Jiawen and Xiong, Zehui and Mao, Shiwen and Han, Zhu},
  booktitle={2023 IEEE International Conference on Metaverse Computing, Networking and Applications (MetaCom)}, 
  title={Generative AI-empowered Effective Physical-Virtual Synchronization in the Vehicular Metaverse}, 
  year={2023},
  volume={},
  number={},
  pages={607-611},
  abstract={Metaverse seamlessly blends the physical world and virtual spaces through ubiquitous communication and computing equipment and infrastructure. In intelligent transportation systems, the vehicular Metaverse can provide a fully immersive and hyperreal travel experience (e.g., via augmented reality head-up displays, AR-HUDs) to drivers and passengers in autonomous vehicles (AVs) through roadside units (RSUs). However, providing real-time and immersive services requires effective physical-virtual synchronization between AVs and virtual simulators. This paper proposes a generative AI-empowered physical-virtual synchronization framework for the vehicular Metaverse. In physical-to-virtual synchronization, digital twin (DT) tasks generated by AVs are offloaded for execution in RSUs with future route generation. In virtual-to-physical synchronization, virtual simulators customize diverse and personalized AR content via generative AI models based on user preferences. Furthermore, we propose a multi-task enhanced auction-based mechanism to match and price AVs and virtual simulators for RSUs to provide real-time and effective services. Finally, property analysis and experimental results demonstrate that the proposed mechanism is strategy-proof and adverse-selection free while increasing social surplus.},
  keywords={Metaverse;Head-up displays;Multitasking;Real-time systems;Space exploration;Synchronization;Task analysis;Vehicular Metaverse;generative artificial intelligence;digital twin;augmented reality;auction theory},
  doi={10.1109/MetaCom57706.2023.00106},
  ISSN={},
  month={June},}@ARTICLE{9246542,
  author={Zhao, Yawu and Zhang, Hualan and Liu, Yihui},
  journal={IEEE Access}, 
  title={Protein Secondary Structure Prediction Based on Generative Confrontation and Convolutional Neural Network}, 
  year={2020},
  volume={8},
  number={},
  pages={199171-199178},
  abstract={In the field of bioinformatics, the prediction of protein secondary structure is a challenging task, and it is extremely important for determining the structure and function of proteins. In this paper, the generation of adversarial network and convolutional neural network model are combined for protein secondary structure prediction. Firstly, generate a confrontation network to extract protein features, and then combine the extracted features with the original PSSM data as the input of the convolutional neural network to obtain prediction results. Testsets CASP9, CASP10, CASP11, CASP12, CB513 and PDB25 obtained 87.06%, 87.24%, 87.31%, 87.39%, 88.13% and 88.93%, which are 3.88%, 4.6%, 7.97%,5.85%, 5.78%, 4.25% higher than one using the convolutional neural network alone. The experimental results show that the feature extraction ability of generating adversarial networks is very significant.},
  keywords={Proteins;Biological system modeling;Neural networks;Predictive models;Feature extraction;Convolutional neural networks;Bioinformatics;Bioinformatics;generative adversarial network;convolutional neural network;protein secondary structure prediction},
  doi={10.1109/ACCESS.2020.3035208},
  ISSN={2169-3536},
  month={},}@ARTICLE{10734204,
  author={Wen, Ming Hui and Chun-Wei Lin, Jerry},
  journal={IEEE Access}, 
  title={Twin3: Pluralistic Personal Digital Twins via Blockchain}, 
  year={2024},
  volume={12},
  number={},
  pages={178997-179009},
  abstract={In the era of generative artificial intelligence (GAI), preserving personal authenticity is crucial for maintaining trust in online communities. Blockchain technology, with its unique blend of anonymity and data transparency, has facilitated the development of decentralized identities (DIDs) on the internet. These DIDs serve as digital representatives for individuals online, enhancing user trust through self-sovereign identity, transparency, and user control, while strengthening privacy. Current DID solutions, such as Proof-of-Personhood and Proof-of-Reputation, have demonstrated technological maturity and paved the way for identity applications in Web3. Building on this foundation, the Twin3 project advances the concept further by introducing the innovative Proof-of-Authenticity (PoA) to represent pluralistic human characteristics in digital format. Specifically, Twin3 employs blockchain-based Soulbound Tokens (SBTs) to transform human identities into a programmable hexadecimal matrix with 256 characteristic spaces, representing a comprehensive spectrum of human attributes, akin to a digital DNA (Decentralized Nexus of Authenticity). This study presents the Twin3 system architecture, user data management,demonstrating how this approach can enhance personal digital identity verification and management. The potential applications of Twin3 SBTs in creating personal AI agents and facilitating participation in the agentic economy are explored, demonstrating how Twin3 can digitize human attributes comprehensively and empower individuals within emerging agent-based workflows and digital ecosystems.},
  keywords={Digital twins;Blockchains;Reliability;Generative AI;Humanities;Buildings;Ecosystems;Collaboration;Biological system modeling;Privacy;Web3;decentralized identity (DID);blockchain;soulbound token (SBT);digital twin;proof-of-authenticity (PoA);agent workflow},
  doi={10.1109/ACCESS.2024.3486033},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10270559,
  author={Mulla, Nikahat and Gharpure, Prachi},
  booktitle={2023 3rd Asian Conference on Innovation in Technology (ASIANCON)}, 
  title={Pre-Trained Generative Architectures for Question-Asking Chatbots on Technical Text: A Case Study}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={In recent years, chatbots' usefulness has spread to an ever-expanding number of domains. Chatbots can be used in educational contexts to ask students questions about topics they are studying for self-testing. Designing models for dialogue systems includes the crucial step of generating appropriate responses. In this study, we propose using chatbots which ask questions specifically catered to a technical domain of interest. To that purpose, we've chosen the fundamental concepts of the Java programming language as our domain. We begin by creating a collection of Java-based dialogues with various sets of question-answer pairings of varying difficulty across various topics. Our Java dialogue dataset includes 10000 multi-turn dialogues generated by an algorithm that simulates a Java interview on basic concepts. Every conversation serves as a training example for our proposed framework. Then, for training on our dataset, we use versions of two different transformer-based pre-trained generative architectures. We compare and evaluate the architectures based on standard automatic metrics for dialogue response generation and other parameters specific to our use-case. We observe that the usage of generative architectures pre-trained as dialog models can generate newer questions, in most cases meaningful in the context of the interview. However, the model design could benefit from incorporating a further knowledge component in order to improve the production of questions both in terms of topic and suitable level of difficulty.},
  keywords={Training;Measurement;Java;Technological innovation;Production;Oral communication;Chatbots;Chatbots;Natural Language Processing;Generative Models;Artificial Intelligence},
  doi={10.1109/ASIANCON58793.2023.10270559},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10679411,
  author={Johnson, Saul and Hassing, Remco and Pijpker, Jeroen and Loves, Rob},
  booktitle={2024 IEEE International Conference on Cyber Security and Resilience (CSR)}, 
  title={A Modular Generative Honeypot Shell}, 
  year={2024},
  volume={},
  number={},
  pages={387-394},
  abstract={In this work, we present Limbosh, a generative honeypot shell written in Python that places attackers in a conversation with a large language model (LLM) configured to behave like a real shell. The use of generative AI in place of traditional honeypot shell software admits the development of arbitrary honeypot configurations by adjusting the prompt used to seed the LLM context. Key features of Limbosh include: a flexible prompt generation system based on text templating and reusable prompt fragments; the ability to make use of arbi-trary LLMs; sophisticated prompt injection mitigation measures; and a highly modular and configurable architecture permitting straightforward expansion of its feature set and enhancement of its capabilities. To demonstrate its utility and practicality, we ran a single-blind, within-subjects study of the interaction of four cybersecurity professionals with Limbosh compared to a control shell. We find that Limbosh is capable of convincingly emulating real shell software, even when faced with professional users. We present our experimental results, and make the Limbosh software itself open-source and freely available.},
  keywords={Prevention and mitigation;Large language models;Computer architecture;Oral communication;Software;Software measurement;Prompt engineering;honeypot;shell;generative artificial intelligence;large language models},
  doi={10.1109/CSR61664.2024.10679411},
  ISSN={},
  month={Sep.},}@ARTICLE{10982376,
  author={Wang, Chong and Chen, Yuanhong and Liu, Fengbei and Liu, Yuyuan and McCarthy, Davis James and Frazer, Helen and Carneiro, Gustavo},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Mixture of Gaussian-Distributed Prototypes With Generative Modelling for Interpretable and Trustworthy Image Recognition}, 
  year={2025},
  volume={47},
  number={8},
  pages={6974-6989},
  abstract={Prototypical-part methods, e.g., ProtoPNet, enhance interpretability in image recognition by linking predictions to training prototypes, thereby offering intuitive insights into their decision-making. Existing methods, which rely on a point-based learning of prototypes, typically face two critical issues: 1) the learned prototypes have limited representation power and are not suitable to detect Out-of-Distribution (OoD) inputs, reducing their decision trustworthiness; and 2) the necessary projection of the learned prototypes back into the space of training images causes a drastic degradation in the predictive performance. Furthermore, current prototype learning adopts an aggressive approach that considers only the most active object parts during training, while overlooking sub-salient object regions which still hold crucial classification information. In this paper, we present a new generative paradigm to learn prototype distributions, termed as Mixture of Gaussian-distributed Prototypes (MGProto). The distribution of prototypes from MGProto enables both interpretable image classification and trustworthy recognition of OoD inputs. The optimisation of MGProto naturally projects the learned prototype distributions back into the training image space, thereby addressing the performance degradation caused by prototype projection. Additionally, we develop a novel and effective prototype mining strategy that considers not only the most active but also sub-salient object parts. To promote model compactness, we further propose to prune MGProto by removing prototypes with low importance priors. Experiments on CUB-200-2011, Stanford Cars, Stanford Dogs, and Oxford-IIIT Pets datasets show that MGProto achieves state-of-the-art image recognition and OoD detection performances, while providing encouraging interpretability results.},
  keywords={Prototypes;Training;Image recognition;Degradation;Feature extraction;Australia;Computational modeling;Image classification;Gaussian mixture model;Deep learning;Interpretability;prototypical-part networks;Gaussian mixture;horse racing;generative modelling;prototype mining},
  doi={10.1109/TPAMI.2025.3566425},
  ISSN={1939-3539},
  month={Aug},}@INPROCEEDINGS{11152929,
  author={Wang, Xiucheng and Zheng, Peilin and Cheng, Nan and Sun, Ruijin and Chen, Junting and Tao, Keda and Yin, Zhisheng and Liu, Zhiquan and Zeng, Yong},
  booktitle={IEEE INFOCOM 2025 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, 
  title={RadioDiff-Turbo: Lightweight Generative Large Electromagnetic Model for Wireless Digital Twin Construction}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={In this paper, we propose a novel and practical real-time wireless digital twin (WDT) construction approach, which can demonstrate and update the spatial distribution of the wireless channel features in the digital space in real-time whenever the features of the environment or the wireless transmitter are varied. Different from traditional computing costly electromagnetic (EM) computation based methods, such as EM ray tracing, a diffusion-based large generative EM model is proposed for the inference of spatial distribution of the wireless channel features in the digital space. Furthermore, addressing the computational efficiency bottleneck of traditional large generative models, in this paper a series of turbo learning methods are used to lighten the RadioDiff model, which is the previous state-of-the-art (SOTA) EM model. First of all, through the analysis of the properties of the stochastic differential equation (SDE) corresponding to the sampling process, it is revealed that the number of sampling steps can be significantly reduced by more than 100x by adjusting the upper limit of the integral. By removing structure-group parameters, we find that the computational efficiency of each sampling step can be further improved. Experimental results show that the proposed RadioDiff-Turbo method can improve the inference efficiency of RadioDiff by 10x, achieving an inference speed of the order of tens of milliseconds, thus providing a practical construction method for real-time WDT. Remarkably, we find that the lightened RadioDiff-Turbo, without any fine-tuning or post-training from RadioDiff, reaches a new SOTA performance, which provides an insightful direction for the research of wireless large models.},
  keywords={Wireless communication;Graphical models;Computational modeling;Wireless networks;Stochastic processes;Real-time systems;Mathematical models;Digital twins;Computational efficiency;Distribution functions;wireless digital twin;generative artificial intelligence;diffusion;large model;efficiency},
  doi={10.1109/INFOCOMWKSHPS65812.2025.11152929},
  ISSN={2833-0587},
  month={May},}@INPROCEEDINGS{10978321,
  author={Liu, Yuanling and Yao, Haipeng and He, Wenji and Mai, Tianle},
  booktitle={2025 IEEE Wireless Communications and Networking Conference (WCNC)}, 
  title={Generative- AiEnabled Lightweight Traffic Detection Architecture for Programmable Gateways in Wireless Networks}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The rapid growth of 5G and 6G networks has introduced complex traffic patterns and stringent real-time demands. Traditional SDN architectures struggle to meet the low-latency and dynamic requirements of wireless environments due to high communication overhead and rigid hardwares. Programmable switches, with their ability to dynamically cus-tomize data plane behavior, offer a more flexible solution for real-time traffic management at the network edge. However, most existing solutions rely on offline models with limited real-time detection capabilities, resulting in increased overhead and suboptimal performance. In this paper, we present Gendetect, a generative-AI enabled lightweight traffic detection architec-ture for programmable wireless gateways. Gendetect employs generative knowledge distillation to train decision tree-based models, enabling efficient online training and adaptive updates. By generating synthetic training data in real-time, it reduces the need for frequent control plane interactions, mitigating north-south overhead. Additionally, a feature selection mechanism optimizes resource utilization, balancing table entry consumption and detection accuracy. Extensive simulations demonstrate that Gendetect significantly improves traffic detection performance while reducing match-action table entries, making it well-suited for dynamic and resource-constrained wireless networks.},
  keywords={Training;Adaptation models;Accuracy;Wireless networks;Training data;Logic gates;Traffic control;Feature extraction;Dynamic scheduling;Real-time systems;Traffic detection;Programmable data plane;Generative Artificial Intelligence;Knowledge distillation},
  doi={10.1109/WCNC61545.2025.10978321},
  ISSN={1558-2612},
  month={March},}@INPROCEEDINGS{10939663,
  author={Imhof, Greta and Kanta, Aikaterini and Scanlon, Mark},
  booktitle={2024 Cyber Research Conference - Ireland (Cyber-RCI)}, 
  title={Context-based Password Cracking Dictionary Expansion Using Generative Pre-trained Transformers}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={With the rise of online criminal activity leading to the increasing importance of digital forensics, efficient and effective password-cracking tools are necessary to collect evidence in a timely manner, leading to solved crimes. Recent advances in machine learning and artificial intelligence have led to the development of context-based and large language model approaches, significantly improving the accuracy and efficiency of password cracking. This work focusses on these more modern techniques, specifically creating context-based contextual password dictionaries through training a series of PassGPTs, a large language model capable of creating password candidates from leaked password dictionary lists. This paper explores possible improvements in password cracking techniques to help law enforcement agencies in digital forensic investigations by combining PassGPT with a contextual approach.},
  keywords={Training;Dictionaries;Accuracy;Law enforcement;Large language models;Digital forensics;Passwords;Machine learning;Transformers;Context modeling;Password cracking;dictionary lists;artificial intelligence;large language models;context-based decryption},
  doi={10.1109/Cyber-RCI60769.2024.10939663},
  ISSN={},
  month={Nov},}@ARTICLE{10812917,
  author={Gao, Zhen and Deng, Jie and Reviriego, Pedro and Liu, Shanshan and Pozo, Alejando and Lombardi, Fabrizio},
  journal={IEEE Nanotechnology Magazine}, 
  title={Operating Conversational Large Language Models (LLMs)in the Presenceof Errors}, 
  year={2025},
  volume={19},
  number={1},
  pages={31-37},
  abstract={Conversational Large Language Models have taken the center stage of the artificial intelligence landscape. As they are pervasive, there is a need to evaluate their dependability, i.e., performance when errors appear due to the underlying hardware implementation. In this paper we consider the evaluation of the dependability of a widely used conversational LLM: Mistral-7B. Error injection is conducted, and the Multitask Language Understanding (MMLU) benchmark is used to evaluate the impact on performance. The drop in the percentage of correct answers due to errors is analyzed and the results provide interesting insights: Mistral-7B has a large intrinsic tolerance to errors even at high bit error rates. This opens the door to the use of nanotechnologies that trade-off errors for energy dissipation and complexity to further improve the LLM implementation. Also, the error tolerance is larger for 8-bit quantization than for 4-bit quantization, so suggesting that there will be also a trade-off between quantization optimizations to reduce memory requirements and error tolerance. In addition, we also show the different impact of errors on different types of weights, which is valuable information for selective protection designs.},
  keywords={Quantization (signal);Benchmark testing;Transformers;Codes;Translation;Memory management;Logic gates;Integrated circuit modeling;Hardware;Computational modeling;Large language models;Multitasking;Error analysis;Dependability;generative artificial intelligence;large language models;errors},
  doi={10.1109/MNANO.2024.3513112},
  ISSN={1942-7808},
  month={Feb},}@ARTICLE{10562194,
  author={Pan, Junren and Zuo, Qiankun and Wang, Bingchuan and Chen, C.L. Philip and Lei, Baiying and Wang, Shuqiang},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={DecGAN: Decoupling Generative Adversarial Network for Detecting Abnormal Neural Circuits in Alzheimer's Disease}, 
  year={2024},
  volume={5},
  number={10},
  pages={5050-5063},
  abstract={One of the main reasons for Alzheimer's disease (AD) is the disorder of some neural circuits. Existing methods for AD prediction have achieved great success, however, detecting abnormal neural circuits from the perspective of brain networks is still a big challenge. In this work, a novel decoupling generative adversarial network (DecGAN) is proposed to detect abnormal neural circuits for AD. Concretely, a decoupling module is designed to decompose a brain network into two parts: one part is composed of a few sparse graphs that represent the neural circuits largely determining the development of AD; the other part is a supplement graph, whose influence on AD can be ignored. Furthermore, the adversarial strategy is utilized to guide the decoupling module to extract the feature more related to AD. Meanwhile, by encoding the detected neural circuits to hypergraph data, an analytic module associated with the hyperedge neurons algorithm is designed to identify the neural circuits. More importantly, a novel sparse capacity loss based on the spatial-spectral hypergraph similarity is developed to minimize the intrinsic topological distribution of neural circuits, which can significantly improve the accuracy and robustness of the proposed model. Experimental results demonstrate that the proposed model can effectively detect the abnormal neural circuits at different stages of AD, which is helpful for pathological study and early treatment.},
  keywords={Neural circuits;Integrated circuit modeling;Brain modeling;Feature extraction;Alzheimer's disease;Neuroimaging;Diffusion tensor imaging;Brain networks;decoupling algorithm;multimodal neuroimaging;hypergraph;sparse capacity loss},
  doi={10.1109/TAI.2024.3416420},
  ISSN={2691-4581},
  month={Oct},}@INPROCEEDINGS{8022700,
  author={Bai, Wenjun and Quan, Changqin and Luo, Zhiwei},
  booktitle={2017 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)}, 
  title={Alleviating adversarial attacks via convolutional autoencoder}, 
  year={2017},
  volume={},
  number={},
  pages={53-58},
  abstract={In order to defend adversarial attacks in computer vision models, the conventional approach arises on actively incorporate such samples into the training datasets. Nonetheless, the manual production of adversarial samples is painful and labor intensive. Here we propose a novel generative model: Convolutional Autoencoder Model to add unsupervised adversarial training, i.e., the production of adversarial images from the encoded feature representation, on conventional supervised convolutional neural network training. To accomplish such objective, we first provide a novel statistical understanding of convolutional neural network to translate convolution and pooling computations equivalently as a hierarchy of encoders, and sampling tricks, respectively. Then, we derive our proposed Convolutional Autoencoder Model with the `adversarial decoders' to automate the generation of adversarial samples. We validated our proposed Convolutional Autoencoder Model on MNIST dataset, and achieved the clear-cut performance improvement over the normal Convolutional Neural Network.},
  keywords={Convolution;Decoding;Training;Computational modeling;Neural networks;Statistical learning;Kernel;Convolutional Neural Network;Adversarial Attacks;Encoder and Decoder;Generative Models},
  doi={10.1109/SNPD.2017.8022700},
  ISSN={},
  month={June},}@INPROCEEDINGS{10899904,
  author={Song, Xue},
  booktitle={2024 4th International Conference on Artificial Intelligence, Robotics, and Communication (ICAIRC)}, 
  title={Leveraging AIGC and Human-Computer Interaction Design to Enhance Efficiency and Quality in E-commerce Content Generation}, 
  year={2024},
  volume={},
  number={},
  pages={772-775},
  abstract={In light of the accelerated growth of e-commerce, the generation of high-quality and efficient content has emerged as a pivotal factor in enhancing user experience and business value. However, conventional methods of content creation are prone to inefficiencies and creative constraints. This paper puts forth a comprehensive model based on the combination of existing generative pre-trained models and human-computer interaction design, with the objective of enhancing the efficiency and quality of e-commerce content generation. In particular, the initial stage of the process involves the utilisation of multi-modal data fusion technology, which facilitates the integration of diverse input sources, including images, videos, and textual data. This approach enhances the model's capacity to comprehend the multifaceted nature of products and services, thereby optimising the generation process. Secondly, a cross-domain sentiment analysis and recommendation engine was designed, which combined the self-attention mechanism in deep learning with the objective of analysing the popularity of the generated content according to consumer behaviour in real time and adjusting the generation strategy. Furthermore, the real-time feedback loop mechanism has been innovatively introduced, which enables the dynamic optimisation of content generation in accordance with user evaluation and click-through rate. This facilitates an improvement in the personalisation and accuracy of content. The experimental results demonstrate that the model markedly enhances the efficiency of content generation and user satisfaction on the e-commerce platform.},
  keywords={Human computer interaction;Analytical models;Sentiment analysis;Accuracy;Semantics;Real-time systems;Data models;User experience;Electronic commerce;Videos;Generative pre-trained models;multimodal data fusion;human-computer interaction design;sentiment analysis},
  doi={10.1109/ICAIRC64177.2024.10899904},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10223873,
  author={Lee, Eric and Gong, Jiayu and Cao, Qinghong},
  booktitle={2023 26th ACIS International Winter Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD-Winter)}, 
  title={Object Oriented BDD and Executable Human-Language Module Specification}, 
  year={2023},
  volume={},
  number={},
  pages={127-133},
  abstract={This paper presents an approach to software development which uses a generative AI Model as compiler to translate human language requirements into high-level programming language. We propose an executable human-language module specification and a tool to support it, which has been used successfully for human-language UI test automation. We anticipate further development of this approach to enable complex software to be programmed in human language, allowing for more intuitive and efficient software development.},
  keywords={Computer languages;Program processors;Automation;Object oriented modeling;Computational modeling;Software;Behavioral sciences;OOBDD (Object-oriented Behavior Driven Development);GPT;SDD (Specification Driven Development);BDD;HLP (Human Language Programming);LLM (Large Language Model);Generative AI},
  doi={10.1109/SNPD-Winter57765.2023.10223873},
  ISSN={},
  month={July},}@INPROCEEDINGS{10605365,
  author={Cooper, J. and Issa, T. B. and Vinegoni, C. and Weissleder, R.},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Providing Real-World Benchmarks for Super-Resolving Fluorescence Microscope Imagery Using Generative Adversarial Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1154-1161},
  abstract={Super-resolving and de-noising video-rate acquisition microscope imagery can eliminate the need for practitioners to choose between image acquisition speed and image quality. This task provides a convenient use case for Generative Adversarial Networks (GANs), which have demonstrated impressive pixel-wise reconstruction metrics in microscope image super-resolution tasks. However, the benchmarks which report these metrics typically do so on low-resolution images generated through simple synthetic degradations, which fail to recreate the natural distortions imparted by experimental image acquisition. Because most reported synthetic data generation pipelines rely on the bicubic downsampling of a few high-resolution images, networks trained to correct for this distortion eventually fail downstream when required to super-resolve images containing natural distortions. The literature therefore provides us with an unreliable assessment of GANs’ ability to super-resolve microscope imagery in the field. In this work, we present one of the few examples of GANs successfully super-resolving a large cache of experimentally gathered microscope imagery. For our main result, we demonstrate a reliable baseline for the super-resolution task using GAN, in which we obtain a peak-signal-to-noise ratio (PSNR) of 29.21 and a structural similarity index (SSIM) of 0.845 by using all available image pairs and averaging across all sub-datasets. To demonstrate robustness on this task, we present the model with a blind super-resolution task, in which it achieves a PSNR of 25.75 and SSIM of 0.676 after averaging across all sub-datasets. To affirm our results as a reliable baseline, we demonstrate that GANs can fail in the video-rate super-resolution task even when trained on higher-order synthetic degradation pipelines. We confirm this effect by training our model on purely synthetic data, using the pipeline mentioned above, and testing it on a single sub-dataset. In doing so, we observe a −0.06 loss in SSIM and −0.75 loss in PSNR, accompanied by significant quality degradation of the reconstructed images in the form of severe distortion and artifact generation.},
  keywords={Degradation;Training;Microscopy;Superresolution;Pipelines;Fluorescence;Benchmark testing;GAN;PSNR;SSIM;super-resolution;bicubic downsampling},
  doi={10.1109/CAI59869.2024.00206},
  ISSN={},
  month={June},}@ARTICLE{11127130,
  author={Saha, Sayan and Das, Monidipa and Bandyopadhyay, Sanghamitra},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Gen-GraphEx: Generative In-Distribution Graph Explanations for Time-Efficient Model-Level Interpretability of GNNs}, 
  year={2025},
  volume={},
  number={},
  pages={1-16},
  abstract={Graph neural networks (GNNs) have become the prevailing methodology for addressing graph data-related tasks, permeating critical domains like recommendation systems and drug development. The necessity for trustworthiness and interpretability of GNNs has risen to the forefront, especially given their direct impact on end users’ lives. To address this need, we present Gen-GraphEx, a model-agnostic, model-level explanation method that prioritizes user centricness by eliminating the need for having access to the hidden layers of the GNN model it seeks to explain. Given a particular class label, Gen-GraphEx learns a graph generative model (GGM) that produces explanation graphs that not only contain discriminative patterns that the GNN has learned for that class but also lie in distribution with real graphs that belong to that class according to the GNN. Unlike existing state-of-the-art models, Gen-GraphEx also has the unique ability to interpolate the GGMs of two target classes to generate instances that lie near the decision boundary of the two classes giving a deeper insight into the model’s decision-making. Its advantages over existing methods in the literature also include nonreliance on another subsequent deep learning module for explanation generation, ability to generate graphs with various node and edge features, and being more computationally efficient. Extensive validation and thorough comparative analysis of the proposed approach is carried out across an array of real and synthetic datasets that consistently demonstrate its exceptional performance and competitiveness ranking alongside state-of-the-art model-level explainers. Our code is available at https://github.com/amisayan/Gen-GraphEx},
  keywords={Predictive models;Graph neural networks;Deep learning;Data models;Decision making;Computational modeling;Complexity theory;Analytical models;Vectors;Training;Deep learning;explainable artificial intelligence;neural networks},
  doi={10.1109/TNNLS.2025.3589330},
  ISSN={2162-2388},
  month={},}@INPROCEEDINGS{11041261,
  author={Cleetus, Jeffery Lean and T, Mega Dharshan and A, Sriprasanna T and A, Murugesan},
  booktitle={2025 3rd International Conference on Artificial Intelligence and Machine Learning Applications Theme: Healthcare and Internet of Things (AIMLA)}, 
  title={Enhancing the Farmland Rover for Muddy Terrain with IoT}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={This paper presents the Enhancing the Farmland Rover for Muddy Terrain with Iot to improve the precision agriculture by automating field operations, resource efficiency, and supporting real-time data collection. This rover features a GPS-based navigation system with IMU and LiDAR for accurate, autonomous path-following and obstacle avoidance in diverse terrains. This design is proposed in use solar energy and rechargeable batteries and it supports sustainable, extended operation with reduced environmental impact. This rover design has proficient attachment for advanced sensors for soil health to monitor the moisture, pH, nutrient levels and crop condition monitoring (multispectral cameras for pest and stress detection). It integrated AI and machine learning. It can identify crops health patterns and predicts potential issues, enabling targeted interventions such as precision watering and nutrient delivery. Data gathered is accessible in real-time via a mobile app or web platform, aiding informed decision-making for optimized field management. Modular and scalable, the rover is adaptable to different crops, field sizes, and climate conditions, making it suitable for various farming practices Designed using Fusion 360's generative design tool. Prototype testing confirms its precision, reliability, and contribution to resource-efficient agriculture. This project highlights the potential of autonomous rovers to transform modern farming by minimizing labour, reducing resource use, and enhancing productivity through data-driven agriculture. Early Disease Detection Process and disease affected cotton plant leaves are detected using Ai and machine learning are presented. The model has trained 90% data from the entire dataset for training the model and remaining 10% data for testing the model for Accuracy graph & Loss graph analysed using the alexnet software. The accuracy graph shows proposed CNN- architecture performs much better than the AlexNet and VGG-16. The opportunities and Challenges for Implementing Irrigation Improvements Opportunities are discussed in the paper.},
  keywords={Precision agriculture;Analytical models;Crops;Machine learning;Soil;Real-time systems;Data models;Monitoring;Farming;Diseases;Autonomous Farmland Rover;Precision Agriculture;GPS Navigation;Soil Health Monitoring;Early Disease Detection Process;AI and Machine Learning in Agriculture;Sustainable Farming;Fusion 360's generative design},
  doi={10.1109/AIMLA63829.2025.11041261},
  ISSN={},
  month={April},}@INPROCEEDINGS{11101520,
  author={Joshi, Vijay and Band, Iver},
  booktitle={2025 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT)}, 
  title={Disrupting Test Development with AI Assistants}, 
  year={2025},
  volume={},
  number={},
  pages={421-425},
  abstract={Recent advancements in large language models, including GPT-4 and its variants, and Generative AI-assisted coding tools like GitHub Copilot, ChatGPT, and Tabnine, have significantly transformed software development. This paper analyzes how these innovations impact productivity and software test development metrics. These tools enable developers to generate complete software programs with minimal human intervention before deployment. However, thorough review and testing by developers are still crucial. Utilizing the Test Pyramid concept, which categorizes tests into unit, integration, and end-to-end tests, we evaluate three popular AI coding assistants by generating and comparing unit tests for open-source modules. Our findings show that AIgenerated tests are of equivalent quality to original tests, highlighting differences in usage and results among the tools. This research enhances the understanding and capabilities of AI-assistant tools in automated testing.},
  keywords={Technological innovation;Standards organizations;Organizations;Documentation;Chatbots;Software;Test pattern generators;Thermal stability;Testing;Software development management;Unit Testing;AI-assistant Tools;Generative AI;ChatGPT;Tabnine;LLMs;GitHub Copilot;Testing Automation;Testing Pyramid},
  doi={10.1109/IAICT65714.2025.11101520},
  ISSN={2834-8249},
  month={July},}@INPROCEEDINGS{9968317,
  author={Yang, Qiongqian and Chen, Ye and Zhang, Jianfeng and Li, Zhenting},
  booktitle={2022 International Conference on Frontiers of Artificial Intelligence and Machine Learning (FAIML)}, 
  title={A Comprehensive Survey and Outlook for Cross-Resolution Person Re-Identification}, 
  year={2022},
  volume={},
  number={},
  pages={204-208},
  abstract={Person re-identification (Re-ID) is a fundamental task in computer vision which has achieved significant progress in recent years. However, the existing promising algorithms are typically based on the assumption that all the images have the same and sufficiently high resolution (HR), ignoring the fact that the images are often captured with different resolutions. This study intends to present a comprehensive overview of cross-resolution (CR) person Re-ID to promote a deeper understanding of this topic and further research. We first group the current techniques into three categories: dictionary-learning-based, super-resolution-based, and generative-adversarial-network-based methods. The motivation, principles, benefits, and drawbacks of these techniques are extensively discussed. Then, the ways to construct synthetic multi-low-resolution (MLR) datasets and the performance comparisons of the state-of-the-art algorithms on five MLR datasets are demonstrated. Finally, challenges and potential research directions are further discussed.},
  keywords={Computer vision;Image resolution;Machine learning algorithms;Buildings;Machine learning;Task analysis;person re-identification;cross-resolution;dictionary learning;super-resolution;generative adversarial gan},
  doi={10.1109/FAIML57028.2022.00047},
  ISSN={},
  month={June},}@INPROCEEDINGS{11042294,
  author={K, Chenna Kesavan and M, Balaji and S, Harish and C, Geetha},
  booktitle={2025 2nd International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)}, 
  title={Advanced Skin Lesion Classification Using Generative AI and Deep Learning Techniques}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Skin cancer, an abnormal lesion growth, is one of the deadliest types of cancer. The accurate diagnosis and classification of skin lesions while distinguishing the malignant tumors from dermoscopic images are among the challenging tasks set by the professional dermatologists. This research seeks to employ advanced deep learning techniques, specifically Convolutional Neural Networks (CNNs) in combination with Generative Adversarial Networks (GANs), toward efficacious improvement of skin lesion classification and cancer detection. The dataset was processed using the ISIC 2024 benchmark and includes steps such as resizing, noise reduction, and data augmentation. GANs afforded synthetically generated training image data, effectively increasing both the augmentation in size and diversity of the training set as well as addressing the common challenge of class imbalance. Pre-Trained models conceived such as Resnet50 and Inceptionv3 (GoogLeNet) use transfer learning to extract hierarchical features from images and categorize skin lesions into malignant or benign classes. The results from these models were merged together to attain higher accuracy in the classification. Using the GANs significantly boosted these CNN models’ performance by enriching training data with synthetic but realistic samples, achieving a higher accuracy. This approach would avail an accurate and automated system for skin lesion classification, which in turn may assist in their early diagnosis regarding skin cancer by classifying them as malignant or benign, besides enhancing clinical decision-making with improved patient outcomes. Such applications of GANs for data augmentation emphasize their ability to address data limitations in medical imaging.},
  keywords={Training;Deep learning;Accuracy;Data augmentation;Feature extraction;Skin;Lesions;Convolutional neural networks;Skin cancer;Residual neural networks;CNN;GANs;ResNet50;InceptionV3;Malignant;Benign},
  doi={10.1109/RMKMATE64874.2025.11042294},
  ISSN={},
  month={May},}
