@INPROCEEDINGS{10217901,
  author={Chen, Long and Song, Yanqing and Chen, Jianguo},
  booktitle={2023 IEEE Symposium on Computers and Communications (ISCC)}, 
  title={A Framework for Few-Shot Network Threats Based on Generative Adversarial Networks}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={A small amount of malicious logs is confusing and unbalanced for a large number of normal logs. We proposed a framework of network threats sample based on Generative Adversarial Networks(GAN). This paper solves the imbalance problem of multidimensional sample data such as logs, traffic, programs, and feature spaces in the field of cyberspace security by generating confrontation networks. We carried out a large-scale confrontation generation experiment of security event logs based on SeqGAN and generated corresponding log text for data enhancement, which effectively solve the problem of few-shot. The results in this section show that the use of the AC-GAN augmentation dataset is enhanced compared to the original non-equilibrium dataset using the artificial synthesis of the SMOTE dataset Network traffic data set to improve the performance of supervised learning classification. It has inestimable effects on threat detection, various types of offensive to defensive, and cryptography algorithms.},
  keywords={Training;Supervised learning;Semantics;Telecommunication traffic;Generative adversarial networks;Iterative algorithms;Threat assessment;Few-shot;Data augmentation;Network threats;Log data;Network traffic;Generative adversarial networks},
  doi={10.1109/ISCC58397.2023.10217901},
  ISSN={2642-7389},
  month={July},}@INPROCEEDINGS{9760668,
  author={Cheggoju, Naveen and Madhavi, K and Jayadeep, Mallela},
  booktitle={2022 2nd International Conference on Artificial Intelligence and Signal Processing (AISP)}, 
  title={InDiP: Intelligent Digital Painter for Low Resolution Face Inpainting}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={In the recent years Artificial Intelligence (AI) has become a go to approach to solve any kind of real-world problems. In these pandemic times, there are many issues arising around the world. One of such issues is the identification of a masked person. It has become difficult to even recognize the very well-known persons due to masks, which has made the field of surveillance suffer a lot. The Object of this research is to solve this issue by reconstructing the face behind the mask using deep learning models. We are proposing a network called as Intelligent Design Painter (InDiP) with capabilities of reconstructing the face behind the mask at low resolutions. This would make the recognition of the masked persons easier. To achieve this target initially work has been done on reconstructing the general human images for fine tuning. After fine tuning the algorithm it has applied on masked faces to obtain the desired results. When checked the accuracy with the original image, the results seem satisfactory. In this approach a sequence Transformer is trained to forecast pixels based on data from a succession of 2D inputs without taking into consideration any of the 2D input structure. Even though the GPT-2 scale model has been trained on low-resolution ImageNet datasets without labels, the network is able to perform satisfactorily. So by using this model ONE can deduce the facial images of the masked people.},
  keywords={Representation learning;Image resolution;Face recognition;Computational modeling;Surveillance;Transformers;Artificial intelligence;Face inpainting;mask detection;Artificial Intelligence;BERT;GPT-2},
  doi={10.1109/AISP53593.2022.9760668},
  ISSN={2640-5768},
  month={Feb},}@INPROCEEDINGS{11011884,
  author={Kodhai, E. and B, Harishwar},
  booktitle={2025 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI)}, 
  title={Emerging Threats to Personal Data: AI-Powered Cyberattacks}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Artificial Intelligence plays a dual role in the cyber security domain impacting personal data security. It acts as a tool for both the cyber criminals enhancing their offensive capabilities and also as a defense mechanism enhancing personal data security. The review brings out the emerging threats of AI-driven cyberattacks, increased vulnerability of personal data, and possible countermeasures that may reduce such risks. To fight these emerging threats, AI is used for malware detection, threat prediction, and anomaly detection. Another aspect of this paper stresses AI-based security tools for combating personal data attacks that have been highly sophisticated of recent times.},
  keywords={Technological innovation;Reviews;Data security;Malware;Regulation;Artificial intelligence;Computer crime;Protection;Anomaly detection;Stress;Artificial Intelligence;cybersecurity;personal data security;AI-driven attacks;anomaly detection;machine learning;encryption},
  doi={10.1109/ICDSAAI65575.2025.11011884},
  ISSN={},
  month={March},}@INPROCEEDINGS{5298902,
  author={Trescak, Tomas and Esteva, Marc and Rodriguez, Inma},
  booktitle={2009 Sixth International Conference on Computer Graphics, Imaging and Visualization}, 
  title={General Shape Grammar Interpreter for Intelligent Designs Generations}, 
  year={2009},
  volume={},
  number={},
  pages={235-240},
  abstract={Shape grammars play an important role in a new generation of tools for the analysis and design of products. In this work we present a general tool named Shape Grammar Interpreter (SGI) for the automatic generation of designs. The developed shape grammar framework allows designers to obtain automatically generated designs and to participate in the design process. In that way the generated design complies with both the desired functionality and an attractive aspect. Great effort has been devoted on having a comfortable way of defining shapes and later using them in shape grammar rules and designs' generation process. We have also implemented and incorporated in the tool an optimized subshape detection algorithm. Hence, subshapes of the existing shapes can be detected in the generation process obtaining more appealing designs.},
  keywords={Artificial intelligence;Production systems;Visualization;Councils;Product design;Process design;Shape control;Computer graphics;Mathematics;Image analysis;shape grammars;electronic institution;virtual world;3D;interpreter},
  doi={10.1109/CGIV.2009.74},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10762313,
  author={Wang, Xinlong and Li, Xu and Yin, Yinghui and Li, Yang},
  booktitle={2024 5th International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE)}, 
  title={Implicit aspect-based generative model for sentiment analysis based on prompt learning}, 
  year={2024},
  volume={},
  number={},
  pages={94-97},
  abstract={In aspect-based sentiment analysis, there may be implicit aspect items and opinion items in the text that do not appear explicitly but can be identified through semantic reasoning. The existence of this implicit information increases the complexity and challenge of semantic understanding. Since these terms do not appear directly in the text, the model needs to have a deeper understanding of the context and capture hidden semantic clues to correctly identify and analyze these implicit aspects and sentiment relations. In order to solve the problem of implicit aspect-based sentiment analysis, this paper proposes a generative model for implicit aspect-based sentiment analysis based on prompt learning, which employs a generative pre-training model T5 and combines it with prompt learning to capture prompt and semantic information in the context to understand implicit sentiments, as well as the aspects and opinions in the quadruple task are expressed in the form of an index, which is intended to reduce the dimensionality of the output space to improve the accuracy of the model. Compared to the existing state-of-the-art models, the proposed model improves the F1 value by $\mathbf{0 . 4 7 \%}$ on the standard dataset restaurantACOS and $0.64 \%$ on the LaptopACOS dataset. Ablation experiments demonstrated that each improvement was effective for aspect-based sentiment analysis.},
  keywords={Sentiment analysis;Analytical models;Semantics;Multitasking;Cognition;Complexity theory;Indexes;Standards;Context modeling;Software engineering;Implicit aspect-based sentiment analysis;generative pre-training model;prompt learning;styling;index},
  doi={10.1109/ICBASE63199.2024.10762313},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11041549,
  author={Harini, M. and Kalaivaani, PCD.},
  booktitle={2025 3rd International Conference on Artificial Intelligence and Machine Learning Applications Theme: Healthcare and Internet of Things (AIMLA)}, 
  title={Enhancing Image Quality Through Photon Based Generative Denoising with Hyper Parameter Tuning}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Poisson shot noise is a problem in low-light imaging because photon detection is random, and it frequently arises when fluorescence microscopy aims to minimise light damage while maintaining image quality. Although deep learning techniques such as Content-Aware Image Restoration (CARE) have demonstrated potential for noise reduction, they necessitate paired noisy-clean images, which are challenging to acquire. We suggest using the Generative Accumulation of Photons (GAP) framework to address this, a self-supervised method reinterpreting image formation as photon accumulation over time. GAP predicts the distribution of future photon arrivals, enabling effective denoising and generating diverse clean images from a single noisy input. Additionally, GAP serves as a fully generative model capable of creating images from scratch via iterative photon prediction. To support benchmarking, we introduce the shot noise-corrupted conv pc dataset, providing a valuable resource for advancing noise reduction in microscopy.},
  keywords={Image quality;Deep learning;Microscopy;Noise reduction;Noise;Medical services;Predictive models;Noise measurement;Tuning;Photonics;Poisson Shot Noise;Deep Learning Denoising;Content-Aware ImageRestoration (CARE);Generative Accumulation of Photons (GAP)},
  doi={10.1109/AIMLA63829.2025.11041549},
  ISSN={},
  month={April},}@ARTICLE{9233968,
  author={Yan, Yichao and Qin, Jie and Ni, Bingbing and Chen, Jiaxin and Liu, Li and Zhu, Fan and Zheng, Wei-Shi and Yang, Xiaokang and Shao, Ling},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Learning Multi-Attention Context Graph for Group-Based Re-Identification}, 
  year={2023},
  volume={45},
  number={6},
  pages={7001-7018},
  abstract={Learning to re-identify or retrieve a group of people across non-overlapped camera systems has important applications in video surveillance. However, most existing methods focus on (single) person re-identification (re-id), ignoring the fact that people often walk in groups in real scenarios. In this work, we take a step further and consider employing context information for identifying groups of people, i.e., group re-id. On the one hand, group re-id is more challenging than single person re-id, since it requires both a robust modeling of local individual person appearance (with different illumination conditions, pose/viewpoint variations, and occlusions), as well as full awareness of global group structures (with group layout and group member variations). On the other hand, we believe that person re-id can be greatly enhanced by incorporating additional visual context from neighboring group members, a task which we formulate as group-aware (single) person re-id. In this paper, we propose a novel unified framework based on graph neural networks to simultaneously address the above two group-based re-id tasks, i.e., group re-id and group-aware person re-id. Specifically, we construct a context graph with group members as its nodes to exploit dependencies among different people. A multi-level attention mechanism is developed to formulate both intra-group and inter-group context, with an additional self-attention module for robust graph-level representations by attentively aggregating node-level features. The proposed model can be directly generalized to tackle group-aware person re-id using node-level representations. Meanwhile, to facilitate the deployment of deep learning models on these tasks, we build a new group re-id dataset which contains more than $3.8K$3.8K images with $1.5K$1.5K annotated groups, an order of magnitude larger than existing group re-id datasets. Extensive experiments on the novel dataset as well as three existing datasets clearly demonstrate the effectiveness of the proposed framework for both group-based re-id tasks.},
  keywords={Task analysis;Deep learning;Measurement;Visualization;Context modeling;Layout;Group re-identification;person re-identification;context learning;graph neural networks},
  doi={10.1109/TPAMI.2020.3032542},
  ISSN={1939-3539},
  month={June},}@ARTICLE{9638494,
  author={Wu, Aming and Shin, Juyong and Ahn, Jae-Kwang and Kwon, Young-Woo},
  journal={IEEE Access}, 
  title={Augmenting Seismic Data Using Generative Adversarial Network for Low-Cost MEMS Sensors}, 
  year={2021},
  volume={9},
  number={},
  pages={167140-167153},
  abstract={The performance of a deep learning (DL) model depends on sufficient training datasets and its algorithmic structure. Even though seismological research using low-cost micro-electro-mechanical systems (MEMS) sensor received much attention recently, because of the lack of data recorded by such MEMS sensors whose data are usually polluted by different types of noise. Therefore, increasing seismic datasets is required by intelligently generating seismic data through data-augmentation techniques. However, it is difficult to characterize and measure the evolution process of seismic sequences, making the feature extraction and data generation of seismic sequences still a significant challenge. By combining the framework of Generative Adversarial Network (GAN) with long short-term memory (LSTM), attention mechanism and neural network (NN), a novel deep generation model (DGM) named EQGAN is developed to overcome the challenges, which can automatically capture the different time histories and dimension characteristics of seismic sequences, meanwhile stably generating high-quality seismic data. The reality of generated data is qualitatively clarified through the analysis of frequency domain and data autocorrelation distribution. Based on the High-throughput Screening (HTS) Theory, the quantitative evaluation index of statistical metrics is designed, and the generation performance of different machine learning models (standard GAN, LSTM, NN) is compared to prove the stability and effectiveness of EQGAN. The experimental results denote that the EQGAN has excellent stability and performance (up to 81%, much higher than that of other generation models), which provides a suitable data expansion approach for the field of seismological research.},
  keywords={Hidden Markov models;Generative adversarial networks;Earthquakes;Data models;Feature extraction;Training;Deep learning;Deep learning;generative adversarial network;data augmentation;Wasserstein distance},
  doi={10.1109/ACCESS.2021.3132901},
  ISSN={2169-3536},
  month={},}@ARTICLE{8794565,
  author={Sun, Yuan and Chen, Chaofan and Xia, Tianci and Zhao, Xiaobing},
  journal={IEEE Access}, 
  title={QuGAN: Quasi Generative Adversarial Network for Tibetan Question Answering Corpus Generation}, 
  year={2019},
  volume={7},
  number={},
  pages={116247-116255},
  abstract={In recent years, the large-scale open Chinese and English question answering (QA) corpora have provided important support for the application of deep learning in the Chinese and English QA systems. However, for low-resource languages, such as Tibetan, it is difficult to construct satisfactory QA systems, owing to the lack of large-scale Tibetan QA corpora. To solve this problem, this paper proposes a QA corpus generation model, called QuGAN. This model combines Quasi-Recurrent Neural Networks and Reinforcement Learning. The Quasi-Recurrent Neural Networks model is used as a generator for Generative Adversarial Network, which speeds up the generation of text. At the same time, the reward strategy and Monte Carlo search strategy are optimized to effectively update the generator network. Finally, we use the Bidirectional Encoder Representations from Transformers model to correct the generated questions at the grammatical level. The experimental results show that our model can generate a certain amount of effective Tibetan QA corpus, and the BLEU-2 value increases by 13.07% than baseline. Moreover, the speed of the model has been greatly improved.},
  keywords={Generators;Reinforcement learning;Data models;Gallium nitride;Monte Carlo methods;Maximum likelihood estimation;Generative adversarial networks;Quasi generative adversarial network;Tibetan;QA corpus generation;reinforcement learning;Monte Carlo search strategy},
  doi={10.1109/ACCESS.2019.2934581},
  ISSN={2169-3536},
  month={},}@ARTICLE{10474008,
  author={Khan, Zakir and Shirazi, Syed Hamad and Shahzad, Muhammad and Munir, Arslan and Rasheed, Assad and Xie, Yong and Gul, Sarah},
  journal={IEEE Access}, 
  title={A Framework for Segmentation and Classification of Blood Cells Using Generative Adversarial Networks}, 
  year={2024},
  volume={12},
  number={},
  pages={51995-52015},
  abstract={Blood smear analysis is often used to diagnose diseases like malaria, Anemia, Leukemia, etc. Morphological changes, such as size, shapes, and color, are receiving much attention in pathological analysis. Existing methods for detecting, diagnosing and analyzing blood smears cannot quantify overlapped, irregular boundaries and complex structures. This work proposes and evaluates a framework that utilizes Generative adversarial networks (GANs) for the segmentation and classification of blood elements, that is, white blood cells (WBCs), red blood cells (RBCs), and platelets (PLTs) simultaneously. The Generator of the network determines the mapping from microscopic images of blood cells to a confidence map. This mapping stipulates the probabilities of the pixel of the microscopic blood cell images with respect to ground truth. The Discriminator of the network is essential to castigate the mismatch between the microscopic blood cells images and confidence map. Additionally, adversarial learning enables the Generator to generate a qualitative confidence map that is converted into segmented images. We have calculated minimum, maximum, and average losses to judge the performance of the proposed model. We measure structural similarity, peak signal-to-noise ratio, pixel classification error, and finally, classified cells. The proposed framework can analyze all the blood cell elements simultaneously. The proposed framework shows a significant improvement in the segmentation and classification of blood cell elements compared to state-of-the-art techniques. During the training process, generator total loss reduces by 12.18%, 5.39%, and 3.62% for RBCs, WBCs, and PLTs, respectively. Our results demonstrate that the proposed framework outperforms existing state-of-the-art techniques, achieving the highest pixel correctly classified (PCC) ratio for the segmentation of blood cells as 99.8%, 93.4%, and 99.9% for WBCs, RBCs, and PLTs, respectively. Our framework attains 95.45% and 88.89% classification accuracy for WBCs on ALL-IDB-I and ALL-IDB-II datasets. The dataset used for this study can be found at https://drive.google.com/drive/folders/1F7kZ1SRWUD9R6aHLMkj3wsjcHnvlGuwP?usp=sharing},
  keywords={Blood;Cells (biology);Image segmentation;Generative adversarial networks;Shape;Generators;Feature extraction;Segmentation;classification;convolutional neural network;generator;discriminator;generative adversarial network;healthcare;medical imaging},
  doi={10.1109/ACCESS.2024.3378575},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10940300,
  author={Shivhare, Mani and Dhir, Saru and Shrivastava, Santosh Kumar},
  booktitle={2025 International Conference on Pervasive Computational Technologies (ICPCT)}, 
  title={Next-Generation Intrusion Detection: Navigating Challenges and Embracing AI}, 
  year={2025},
  volume={},
  number={},
  pages={788-792},
  abstract={The emergence of networked autonomous systems has brought a new wave of security threats. Because of not be able to adopt the traditional intrusion detection approaches with the new threats, AIML based cybersecurity defences have gain more attention in recent times. The current state of AIML-based intrusion and abuse detection is examined in this paper, with a focus on significant scientific advancements and the real-world obstacles preventing its broad deployment. As cyberattacks become more sophisticated, one thing has remained the same: Intrusion Detection Systems are a must for protecting digital infrastructures, and they need to be robust. This review summarises the awareness of IDS from traditional signature-based methods to an upcoming disruptive focus on Artificial Intelligence, especially ML and DL. We present a comparison of the advantages and disadvantages of these techniques, emphasizing challenges such as dataset limitations, adaptability to operate in real-time and detecting unseen attacks. Forthcoming, we examine new research directions (hybrid methods, ensemble learning and challenging advanced datasets) to improve the efficacy of IDS on ever more complicated network landscapes.},
  keywords={Reviews;Navigation;Intrusion detection;Training data;Network security;Real-time systems;Ensemble learning;Artificial intelligence;Computer crime;Next generation networking;IDS;ML;DL;Cybersecurity;Network Security;Anomaly Detection;Zero-Day Attacks},
  doi={10.1109/ICPCT64145.2025.10940300},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10980405,
  author={Hosseini, Seyed Ali and Niccolai, Alessandro and Grimaccia, Francesco},
  booktitle={2025 IEEE Symposium on Computational Intelligence for Financial Engineering and Economics Companion (CiFer Companion)}, 
  title={Innovative Pattern Extraction and Synthetic High-Frequency Data Generation in European Carbon Emmision Markets Using GAN Networks}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={This study analyzed high-frequency tick-by-tick data of carbon emission allowances in the European emissions trading system, resampled into 5 -minute intervals, to identify innovative price patterns and extract key features for anticipatory insights. A dataset of pattern sequences and features was constructed, and a GAN model with LSTM and Self-Attention layers was used to generate synthetic sequences, producing artificial interval data. The synthetic data was validated using key financial metrics, demonstrating it effectively emulates real market behavior. The results support applications in risk management, algorithmic trading, market simulation, and stress testing under varying conditions.},
  keywords={Europe;Carbon dioxide;Emissions trading;Generative adversarial networks;Feature extraction;Data models;Risk management;Data mining;Long short term memory;Synthetic data;Financial Data Analysis;High-Frequency Financial Data Generation;Generative Adversarial Networks (GANs);Pattern Detection;Self-Attention Mechanisms;Long Short-Term Memory (LSTM)},
  doi={10.1109/CiFerCompanion65204.2025.10980405},
  ISSN={},
  month={March},}@ARTICLE{9648355,
  author={Chen, Jiaxuan and Chen, Shuang and Liu, Yuyan and Chen, Xiaoxian and Fan, Xiaoyan and Rao, Yujing and Zhou, Chengjiang and Yang, Yang},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={IGS-Net: Seeking Good Correspondences via Interactive Generative Structure Learning}, 
  year={2022},
  volume={60},
  number={},
  pages={1-13},
  abstract={Feature matching, which aims to seek good correspondences from an image pair of the same or similar scene, is one of the important studies on digital remote sensing (RS) image processing. However, alongside the common degradation problems, such as geometric distortion, RS images also often face nonlinear radiation distortions, thereby posing more complex matching patterns. To reduce the cost of establishing reliable correspondences, this article proposes a simple, but effective end-to-end hierarchical learning framework, termed interactive generative structure learning network (IGS-Net). The key thinking of our approach is to offer a structure self-generate learning mechanism, called interactive generative structure learning (IGSL) block, for modeling the local context information of potential correspondences. Specifically, IGSL contains two novel operations: adaptive structure-aware representation (ASR) and physical constraint embedding. Besides, we introduce a coarse-to-fine geometry estimation pipeline aligning two sets of feature points to weaken the degree of randomness in matching patterns, thus improving the generalization ability of representation learning. Overall, this differentiable representation learning architecture can be inserted into existing classification models easily for robust outlier detection and removal. In order to demonstrate that our IGS-Net can boost the baselines, we intensively experiment on both single modality and multimodal RS image datasets. The large amounts of experiment results reveal that the matching performances of IGS-Net are significantly improved over eight state-of-the-art competitors.},
  keywords={Feature extraction;Remote sensing;Geometry;Transforms;Task analysis;Representation learning;Nonlinear distortion;Coarse-to-fine learning;feature matching;image registration;outlier rejection;representation learning},
  doi={10.1109/TGRS.2021.3135430},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{10582386,
  author={Andriyanov, Nikita and Kim, Alexandr and Fao, Xenin},
  booktitle={2024 X International Conference on Information Technology and Nanotechnology (ITNT)}, 
  title={Using Generative Models to Improve Fire Detection Efficiency}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={The paper discusses generative artificial intelligence technologies used to improve the efficiency of fire detection in satellite images. Different detector architectures are proposed and compared in terms of accuracy. It is found that the use of generative models to expand the training sample is on average 1–2% more effective than the use of standard augmentations. The combined method of expanding the training image base can improve the accuracy by 4-5%. In addition, the right approach in generative prompts can also improve the accuracy metrics of the models.},
  keywords={Training;Measurement;YOLO;Accuracy;Image databases;Detectors;Satellite images;fire detection;satellite image processing;generative models;diffusion models;generative-adversarial networks;variational autoencoder},
  doi={10.1109/ITNT60778.2024.10582386},
  ISSN={},
  month={May},}@ARTICLE{10580977,
  author={Zeng, Shaoting and Cai, Yifei and Zhang, Renshui and Lyu, Xin},
  journal={IEEE Access}, 
  title={Research on Human-Machine Collaborative Aesthetic Decision-Making and Evaluation Methods in Automotive Body Design: Based on DCGAN and ANN Models}, 
  year={2024},
  volume={12},
  number={},
  pages={91575-91589},
  abstract={The main content of this study is the human-machine collaborative design research, taking the car body design as the carrier. The research framework focused on two phases of car body design process, that of design ideation and evaluation. In the ideation stage, we trained an imperfect Deep Convolutional Generative Adversarial Network (DCGAN) model that just could generate blur automobile images as the blur design motherboards for the iterative sketching, which had design uncertainties and blanks, thus activating designers’ subjective initiative and aesthetic intuition to provide more creative deepen sketches. We leveraged motherboards to address uncertainty through sketching and aesthetic intuition, refining options and ultimately selecting an optimal design. In the evaluation phase, we initially constructed a parametric 3D model with 20 parameters based on the optimal design, and invited 32 designers conducting participatory design experiments, getting 1024 human-designed schemes. Following this, we administered an online survey to assess the aesthetic qualities of a total of 1024 design schemes. Leveraging the collected score data (The first round of surveys engaged 279 participants, while the second round involved 73 participants), we trained an Artificial Neural Network (ANN) model to serve as an aesthetic evaluation score predictor for unknown parameter configurations. The machine could evaluate designs autonomously, thus selecting best design from 20,000 schemes generated randomly by machine. We utilized the parametric design converting sketching images to the numeric parameters, switching the qualitative ideation to the quantitative evaluation, thus achieving aesthetic evaluation and optimization. This study explores the relationship between human cognitive intuition and machine intelligence and how they can collaborate with each other.},
  keywords={Automobiles;Generators;Training;Collaboration;Human-machine systems;Solid modeling;Noise measurement;Machine learning;Design for manufacture;Automotive components;Human-machine collaboration;human calculating and machine computing;machine learning;aesthetic evaluation and optimization;automotive body design},
  doi={10.1109/ACCESS.2024.3422134},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10503047,
  author={Ajalkar, Deepika and Mahindrakar, Abhishek and Popale, Akshay and Meshram, Ashish and Khillarkar, Prabal},
  booktitle={2024 IEEE International Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation (IATMSI)}, 
  title={Live Streaming Surveillance Video Upscaling Using Generative AI With Anomaly Identification}, 
  year={2024},
  volume={2},
  number={},
  pages={1-5},
  abstract={This research addresses the challenge of low-resolution CCTV footage in criminal investigations through the application of generative artificial intelligence (AI). Leveraging Generative Adversarial Networks (GANs) and Super-Resolution Convolutional Neural Networks (SRCNNs), our approach focuses on real-time upscaling to improve the quality of surveillance video. The proposed system involves preprocessing low-resolution frames and utilizing generative AI models to produce high-resolution images, enhancing crucial visual details for effective crime scene analysis. Extensive experiments on real-world CCTV datasets demonstrate the superiority of our method in terms of accuracy, visual fidelity, and real-time processing compared to conventional upscaling techniques. Furthermore, our research explores the novel use of generative AI for crime scene identification. By automatically analyzing the enhanced footage, the system detects and identifies potential evidence such as objects, vehicles, and individuals. This capability contributes to more efficient criminal investigations, aiding law enforcement agencies in solving cases effectively. While advancing the field of computer vision and AI-assisted law enforcement, our work provides a practical and effective solution for real-time CCTV footage upscaling and crime scene identification. The deployment of this technology has the potential to significantly improve the speed and accuracy of investigations, thereby enhancing public safety and security. However, ethical considerations, including privacy and potential biases, are crucial aspects that require careful attention during implementation.},
  keywords={Visualization;Technological innovation;Generative AI;Law enforcement;Surveillance;Superresolution;Streaming media;GANs;upscaling;surveillance;CCTV;crime;security},
  doi={10.1109/IATMSI60426.2024.10503047},
  ISSN={},
  month={March},}@INBOOK{10982311,
  author={Bergeret, Olivier and Abbasi, Asif and Farvault, Joel},
  booktitle={GenAI on AWS: A Practical Approach to Building Generative AI Applications on AWS}, 
  title={Generative AI on AWS Labs}, 
  year={2025},
  volume={},
  number={},
  pages={295-310},
  abstract={<p>This chapter guides us through practical, hands&#x2010;on exercises using Generative artificial intelligence (AI) on AWS, enabling us to gain valuable firsthand experience with these technologies. The workshop is designed to help introduce Generative AI concepts through dozens of hands&#x2010;on exercises. The workshop will guide the participants to build simple Generative AI demo applications while learning key concepts of Generative AI. Labs include prompt engineering, security and guardrails, chatbots, retrieval&#x2010;augmented generation, image generation/editing, and multimodal capabilities. This workshop offers two options for the readers, primarily based on the skillset of the workshop attendees. They are: Option 1: PartyRock Prompt Engineering Guide (for Non&#x2010;Technical and Technical Audiences) and Option 2: Amazon Bedrock Labs (for Technical Audiences). Within this series of labs, we will go through some of the most common Generative AI usage patterns we are seeing with our customers across the globe.</p>},
  keywords={Conferences;Prompt engineering;Prototypes;Costs;Codes;Chatbots;Buildings;Python;Pricing;Image synthesis},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394281305},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10982311},}@INPROCEEDINGS{10809928,
  author={Ventayen, Randy Joy M.},
  booktitle={2024 9th International Conference on Information Technology and Digital Applications (ICITDA)}, 
  title={OpenAI ChatGPT-4 and Google Bard: Proposed Guidelines Based on the Analysis and Educators' Perspectives on the Use of Generative AI Contents Trends}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This study presents a simple analysis of OpenAI's ChatGPT-4 and Google's Bard, focusing on their similarity indexed, analysis of the content, and the perspectives of educators regarding their application in educational settings. The test was run in the first month 2024 and the research utilized a mixed-methods approach. The research evaluates the similarities and differences between these two leading AI language models. The study assesses similarity indexed and accuracy. Additionally, it gathers insights from educators who are PSU Open University Systems Graduate Students via surveys, exploring their views on the benefits, and challenges of integrating these AI tools in education. The findings reveal distinct strengths and limitations of each model, with ChatGPT-4 excelling in creative content generation and Bard in providing data-backed information. This paper contributes to a deeper understanding of AI's role in education, highlighting the need for balanced and ethically informed AI integration in teaching and learning processes. The paper also suggest a general guidelines in the use of Generative AI.},
  keywords={Surveys;Ethics;Generative AI;Plagiarism;Education;Market research;Internet;Indexes;Information technology;Guidelines;artificial intelligence;AI in education;OpenAI},
  doi={10.1109/ICITDA64560.2024.10809928},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10698398,
  author={Sai, Kolli Nethre and Wable, Upamanyu and Singh, Ayush and S, Koundinya N V S and Gonuguntla, Harichandana and Jain, Chirag},
  booktitle={2024 International Conference on Electrical, Computer and Energy Technologies (ICECET}, 
  title={Harnessing Multimodal AI for Creative Design: Performance Evaluation of Stable Diffusion and DALL-E 3 in Fashion Apparel and Typography}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In recent years, multimodal AI (Artificial Intelligence) models have exhibited promising capabilities in generating diverse forms of creative content. This review paper critically evaluates and compares the performance of two prominent multimodal models, Stable Diffusion and DALL-E, in the context of fashion apparel and typography design generation. The evaluation methodology encompasses both human judgment and automatic evaluation metrics, including CLIP Score, Image Reward, and Inception Score, to provide a comprehensive assessment of the generated outputs. Through a systematic analysis of the results, this paper highlights the strengths and limitations of each model, shedding light on their respective abilities to capture design nuances, maintain coherence, and exhibit creativity. Additionally, the review discusses the impact of training data, model architecture, and hyperparameters on the quality and diversity of generated designs. The findings of this review contribute to a deeper understanding of the capabilities of multimodal AI models in creative design tasks and offer insights into their potential applications in the fashion and design industries. This paper aims to guide researchers and practitioners in selecting suitable models for specific design generation tasks while fostering advancements in multimodal AI research.},
  keywords={Industries;Performance evaluation;Systematics;Reviews;Transfer learning;Training data;Prompt engineering;Artificial intelligence;Research and development;Context modeling;multimodal;generative AI;inferencing;evaluation metric},
  doi={10.1109/ICECET61485.2024.10698398},
  ISSN={},
  month={July},}@INPROCEEDINGS{11113553,
  author={Ortega, John Heland Jasper C.},
  booktitle={2025 International Symposium on Educational Technology (ISET)}, 
  title={The AI-Artist Collaboration: Impact of Generative AI on Digital Creators and Multimedia Arts Education}, 
  year={2025},
  volume={},
  number={},
  pages={01-05},
  abstract={Generative AI is transforming digital creation by providing artists with tools that enhance efficiency and unlock new creative possibilities. In multimedia arts, including the growing digital art scene in the Philippines, AI-powered platforms are being used to accelerate workflows, automate tasks, and introduce innovative artistic techniques. While these advancements enable Filipino digital creators to experiment and increase productivity, they also raise concerns about originality, authenticity, and the diminishing value of traditional artistic skills. This study examines student perspectives on AI's impact using aspect-based sentiment analysis. The findings reveal that while students appreciate AI's accessibility and time-saving benefits, many remain cautious about its long-term influence on artistic growth. The Diffusion of Innovations Theory was applied to analyze AI adoption, highlighting both its advantages and challenges. Ethical concerns, such as copyright issues, fair attribution, and the potential devaluation of human-created art, continue to spark debate. These results emphasize the importance of an educational approach that integrates AI as a supportive tool rather than a replacement for human creativity. For Filipino digital creators, especially those in animation, graphic design, and content creation, it is crucial to balance AI's advantages with a strong foundation in artistic expression. Future studies should explore how AI can be leveraged to empower artists while preserving the unique cultural and creative identity of Filipino multimedia arts.},
  keywords={Productivity;Visualization;Technological innovation;Sentiment analysis;Ethics;Art;Generative AI;Educational technology;Media;Sparks;Artificial Intelligence;Visual Arts;Digital Creators;Digital Media;Multimedia Arts;Educational Technology},
  doi={10.1109/ISET65607.2025.00037},
  ISSN={2766-2144},
  month={July},}@ARTICLE{8995782,
  author={Zhang, Feifei and Zhang, Tianzhu and Mao, Qirong and Xu, Changsheng},
  journal={IEEE Transactions on Image Processing}, 
  title={Geometry Guided Pose-Invariant Facial Expression Recognition}, 
  year={2020},
  volume={29},
  number={},
  pages={4445-4460},
  abstract={Driven by recent advances in human-centered computing, Facial Expression Recognition (FER) has attracted significant attention in many applications. However, most conventional approaches either perform face frontalization on a non-frontal facial image or learn separate classifier for each pose. Different from existing methods, this paper proposes an end-to-end deep learning model that allows to simultaneous facial image synthesis and pose-invariant facial expression recognition by exploiting shape geometry of the face image. The proposed model is based on generative adversarial network (GAN) and enjoys several merits. First, given an input face and a target pose and expression designated by a set of facial landmarks, an identity-preserving face can be generated through guiding by the target pose and expression. Second, the identity representation is explicitly disentangled from both expression and pose variations through the shape geometry delivered by facial landmarks. Third, our model can automatically generate face images with different expressions and poses in a continuous way to enlarge and enrich the training set for the FER task. Our approach is demonstrated to perform well when compared with state-of-the-art algorithms on both controlled and in-the-wild benchmark datasets including Multi-PIE, BU-3DFE, and SFEW. The code is included in the supplementary material.},
  keywords={Face recognition;Face;Geometry;Task analysis;Image recognition;Training;Feature extraction;Facial expression recognition;facial image synthesis;generative adversarial network;facial landmarks},
  doi={10.1109/TIP.2020.2972114},
  ISSN={1941-0042},
  month={},}@INPROCEEDINGS{9613311,
  author={Li, Guangwei and Ding, Shuxue and Li, Yujie},
  booktitle={2021 13th International Conference on Wireless Communications and Signal Processing (WCSP)}, 
  title={Novel LSTM-GAN Based Music Generation}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={With the rapid development of deep learning, many models for music generation have emerged. There are, however, many problems for methods based on the general neural network model, such as slow calculation speed, complex calculation, and long-term dependence. This study proposes a combined model method for music generation, in which the long short-term memory (LSTM) neural network and generative adversarial network (GAN) are combined to form an LSTM-GAN model. In this paper, a new data preprocessing conversion rule is proposed to process the musical instrument digital interface (MIDI) message data obtained by the performance coding method. Finally, the effectiveness of the proposed model by the maximum mean discrepancy assessment is verified. Experimental results demonstrate that the proposed model can produce novel music automatically and have good performance.},
  keywords={Training;Wireless communication;Deep learning;Musical instrument digital interfaces;Neural networks;Data preprocessing;Signal processing;Deep neural network;long short-term memory;generative adversarial network;audio conversion},
  doi={10.1109/WCSP52459.2021.9613311},
  ISSN={2472-7628},
  month={Oct},}@INPROCEEDINGS{10992119,
  author={Jiang, Chunlan and He, Ying},
  booktitle={2024 4th International Conference on Digital Society and Intelligent Systems (DSInS)}, 
  title={Evaluation of English-Chinese Translation Effects in Intelligent Translation Teaching with GPT Language Model}, 
  year={2024},
  volume={},
  number={},
  pages={224-227},
  abstract={This paper addresses common issues in English-Chinese translation teaching, such as low translation quality and unnatural expression, by proposing a method to evaluate translation effects using the GPT (Generative Pre-trained Transformer) language model. It identifies bottlenecks in traditional translation methods, particularly the limitations of machine translation in fluency and semantic expression. The study employs an experimental comparison method, translating selected texts with various tools and comparing them to translations generated by GPT-4. Results indicate that GPT-4 outperforms traditional tools, achieving an average BLEU score of 86.5% for accuracy, with only one grammatical error on average, and a naturalness similarity score of 0.89. Overall, GPT-4 enhances students' understanding of complex syntax and authentic expressions, providing a scientific basis for high-quality translation teaching.},
  keywords={Translation;Accuracy;Terminology;Generative Pre-trainer transformer;Education;Semantics;Coherence;Syntactics;Transformers;Machine translation;Intelligent Translation Teaching;GPT Language Model;English-Chinese Translation;Semantic Understanding},
  doi={10.1109/DSInS64146.2024.10992119},
  ISSN={},
  month={Nov},}@ARTICLE{10818591,
  author={Huang, Zhen-Zhen and Zhang, Wei-Tao and Li, Yang and Cui, Jian and Zhang, Ya-Ru},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={TCGAN: Temporal Convolutional Generative Adversarial Network for Fetal ECG Extraction Using Single-Channel Abdominal ECG}, 
  year={2025},
  volume={29},
  number={5},
  pages={3478-3487},
  abstract={Noninvasive fetal ECG (FECG) monitoring holds significant importance in ensuring the normal development of the fetus. Since FECG is usually submerged by maternal ECG (MECG) and background noise in abdominal ECG (AECG), it is challenging to exactly restore the waveform details of FECG from AECG. To address this issue, a temporal convolutional generative adversarial network (TCGAN) is proposed for FECG extraction using single-channel AECG. In order to utilize both the global and local ECG features in time domain, we built an encoder-decoder architecture for designing generator. The model architecture consists of temporal convolution blocks, transpose convolutions and skip connections. The skip connections attempt to achieve the purpose of amalgamating information from feature maps extracted by convolutional layers using transpose convolution operations, which facilitates the decoder for extracting more detail information. TCGAN is rigorously evaluated using both synthetic dataset FECGSYDB and real-world dataset ADFECGDB. The experimental results on above datasets demonstrate the outstanding performance of TCGAN in terms of fetal QRS complex detection, achieving PPV of 99.54% and 99.02%, respectively. Comparing with the state-of-the-art methods, TCGAN could extract FECG with well-preserved waveform details. This helps doctors achieve more accurate assessment of fetal development.},
  keywords={Convolution;Electrocardiography;Feature extraction;Generators;Data mining;Generative adversarial networks;Bioinformatics;Monitoring;Decoding;Recording;Fetal ECG;maternal abdominal ECG;temporal convolutional separative adversarial network;single-channel recordings},
  doi={10.1109/JBHI.2024.3524085},
  ISSN={2168-2208},
  month={May},}@INPROCEEDINGS{9561075,
  author={Zabala, Unai and Rodriguez, Igor and Martínez-Otzeta, José María and Irigoien, Itziar and Lazkano, Elena},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Which gesture generator performs better?}, 
  year={2021},
  volume={},
  number={},
  pages={3345-3352},
  abstract={Talking gestures are a fundamental part of body language and, therefore, are also important for social robots. Gesture generation by generative approaches is supposed to produce a more appropriate behavior than rule-based approaches. Usually, the evaluation of generated gestures is carried out by subjective visual evaluation, which could be cultural dependent and influenced by external factors. In this work we extend previous research on quantitative evaluation methods, comparing two generative methods and showing that their results correlate with subjective evaluation by a sizable group of people. The final goal is to offer a quantitative tool to help the researchers to automate the evaluation of their gesture generation systems, as a complementary measure to subjective methods.},
  keywords={Visualization;Automation;Conferences;Tools;Generators;Cultural differences;Robots},
  doi={10.1109/ICRA48506.2021.9561075},
  ISSN={2577-087X},
  month={May},}@INPROCEEDINGS{11016560,
  author={Jackson, Jonathan},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={“Who's Doing the Thinking Here?”: A Pedagogy-First Approach to Integrating Large Language Models in Higher Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-3},
  abstract={Large Language Models (LLMs), a subset of Generative Artificial Intelligence (GenAl), have been popularised through the widely publicised launch of tools such as ChatGPT. While capable of responding to human input in an apparently conversational manner, these models do not possess understanding in the same way that humans do and their outputs, based on probabilistic algorithms, are susceptible to presenting falsehoods as facts (hallucinations). Despite the risks, there are potential benefits for embedding LLMs in learning experiences if educators can cultivate a safe learning environment that supports students' interactions with LLMs while empowering students to develop their higher-order thinking skills (HOTS). Educators should be empowered to make well-informed decisions about the use of LLMs and help students work towards co-creation in collaboration with LLMs without compromising academic integrity or their own agency. In the context of GenAl, the apposite question has become “who's doing the thinking here?”, particularly with the prevalence of LLM outputs which are adept at masquerading as intelligent thought. Bloom's revised taxonomy is proposed as an effective lens through which educators can evaluate the use of LLMs in subject-specific learning contexts, particularly with a focus on developing students' HOTS. Some practical examples of prompts are included for educators to try as part of their own experimentation with GenAl. This paper aims to empower educators by offering an initial set of “Higher Order Prompting” principles to support the decision making of how - or indeed if - to use LLMs with students, while contributing to the ongoing discourse of how Generative AI is impacting Higher Education.},
  keywords={Generative AI;Large language models;Taxonomy;Decision making;Collaboration;Probabilistic logic;Chatbots;Engineering education;Lenses;Large Language Models;Generative AI;Artificial Intelligence;Higher Education;Blooms Taxonomy},
  doi={10.1109/EDUCON62633.2025.11016560},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10949551,
  author={Elgiriyewithana, Nidula and Kodikara, N D},
  booktitle={2024 4th International Conference on Robotics, Automation and Artificial Intelligence (RAAI)}, 
  title={A Comprehensive Review on Generative Models for Speech Enhancement}, 
  year={2024},
  volume={},
  number={},
  pages={236-252},
  abstract={This review paper provides an exhaustive analysis of the current state of generative models used for speech enhancement, with a focus on Autoencoders, Diffusion models, and Generative Adver- sarial Networks (GANs). Particular emphasis is placed on understanding their principles, architecture, and applicability to speech enhancement. Furthermore, we delve into the advantages and limitations of these models, highlighting methodological progression, and recent trends. The study also emphasizes the significance of Public Perception of Current Speech Enhancement Methods and discusses potential future directions and challenges in the field - exploring strategies for improving generalization, robustness, and the incorporation of multi-modal information. The conclusion summarizes the key findings of the collected literature, suggesting potential applications and impacts of the discussed generative models for speech enhancement.},
  keywords={Analytical models;Reviews;Autoencoders;Noise reduction;Speech enhancement;Signal processing;Diffusion models;Market research;Robustness;Robots;Audio Processing;Diffusion Models;Generative Models;Generative Adversarial Networks (GANs);Signal Processing;Speech Enhancement;Variational Autoencoders (VAEs);Deep Learning for Audio;Noise Reduction;Acoustic Modeling},
  doi={10.1109/RAAI64504.2024.10949551},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11139922,
  author={Gayathri, Bala Sai and Sarma, Kakara Venkata Nithish and Bunga, Krishna Chaitanya},
  booktitle={2025 8th International Conference on Computing Methodologies and Communication (ICCMC)}, 
  title={Harnessing Gen AI for Accurate Sentiment Detection in Text}, 
  year={2025},
  volume={},
  number={},
  pages={1650-1654},
  abstract={The increasing dependence on textual information for the decision-making process has seen the need to derive appropriate and effective sentiment-detecting methods. This research focuses on using generative artificial intelligence (GenAI) models to analyze sentiments within a given piece of text. The models rely on deep learning architectures, such as transformer models, in grasping intricate linguistic patters, contextual nuances, which overshadow the abilities of the traditional approaches, such as lexical-based and statistical methods. This shows that through fine-tuning on diverse datasets covering varying contexts and languages, GenAI models better capture subtle emotional tones, such as mixed and neutral sentiments. The present research continues the work to analyze implications of these developments in areas such as customer experience management, real-time social media analysis, and predictive market strategies. Results show that GenAI enhances accuracy and scales well across the different applications while being a very transformative tool in the digital era for sentiment analysis. The work brings forward the flexibility of generative AI with problems such as sarcasm, idiomatic expressions, and domain-specific jargona challenge many other traditional techniques used in sentiment analysis often fail to deal with. In the sense that transfer learning and multimodal approaches may be able to use data from images, audio, or even metadata to help grasp better contextual understanding of sentiments expressed in the text. It digresses into matters of ethics and practical concerns in the deployment of GenAI for sentiment analysis purposes, emphasizing questions of transparency, fairness, and the reduction of bias in the outputs of these models. It also argues on how GenAI can further the interest of inclusive sentiment analysis by allowing the support of underrepresented languages and dialects to make access to insights from around the world via AI equal.},
  keywords={Sentiment analysis;Analytical models;Accuracy;Text analysis;Generative AI;Social networking (online);Transfer learning;Transformers;Real-time systems;Context modeling;Generative Artificial Intelligence;Sentiment Analysis;deep Learning;Transformers;Linguistic Patterns;Emotional Tones},
  doi={10.1109/ICCMC65190.2025.11139922},
  ISSN={},
  month={July},}@ARTICLE{11096614,
  author={Gao, Dahua and Yi, Yujie and Yang, Minxi and Li, Jiaxuan and Liu, Danhua and Xu, Wenlong},
  journal={IEEE Wireless Communications Letters}, 
  title={Bridging Semantic Scale Gaps in Image Transmission Through Multi-scale Joint Perception and Generation}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Semantic communication, leveraging deep network-based Joint Source-Channel Coding (JSCC), has garnered increasing attention in recent years. However, existing methods are primarily suitable for transmitting single-scale semantics such as pixels, but not for adaptively fusing multi-scale semantics such as objects and scenes. Owing to substantial variations in data volume across different semantic scales, selecting the appropriate semantic scale for transmission based on varying Channel State Information (CSI) can significantly enhance the efficiency of conveying semantic information. This letter introduces a cross-scale Generative Semantic Communication (GSC) method for image transmission, named BriGSC. Under the constraints of CSI, our method can jointly perceives textual and visual features to represent semantics at different scales, achieves rate-adaptive encoding, transmission, decoding and image generation. The experiment results show that compared with semantic communication methods based on deep learning (SwinJSCC) and generative models (SGD-JSCC), our method has better competitive noise resistance and coding efficiency through jointly encoding multi-scale semantic features. Under various channel conditions, the average values of FID and LPIPS were 35% and 25% lower than SwinJSCC and SGD-JSCC respectively.},
  keywords={Semantics;Visualization;Feature extraction;Diffusion models;Decoding;Channel coding;Signal to noise ratio;Semantic communication;Image coding;Training;generative semantic communication;image transmission;adaptive bit allocation;multi-scale fusion},
  doi={10.1109/LWC.2025.3592689},
  ISSN={2162-2345},
  month={},}@ARTICLE{10227345,
  author={Ma, Song and Xu, Zeng-Song and Sun, Tao},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Parallel Generative Adversarial Imputation Network for Multivariate Missing Time-Series Reconstruction and Its Application to Aeroengines}, 
  year={2023},
  volume={72},
  number={},
  pages={1-16},
  abstract={The reconstruction and imputation of missing values in multivariate time series (MTS) are pressing issues in the field of industrial artificial intelligence. To address this problem, an end-to-end deep learning model called the “time-series generative adversarial imputation network (TSGAIN) with preimputation, parallel convolution, and transformer encoder (PPCTE)” is proposed in this article. Specifically, the proposed TSGAIN framework is an improved generative adversarial network (GAN) for imputation of missing time series, which can consider both distribution and time information. Next, a preimputation module is advanced to obtain more accurate input information for the proposed model. Then, as two crucial components of the proposed model, the generator and discriminator are further improved. In particular, in terms of feature correlation, a parallel convolution (PC) module is designed, which further enhances the potential of the proposed model to extract feature correlation in multivariate data. In terms of temporality, by introducing the transformer encoder (TE) module with multihead attention mechanism, the ability of the proposed model to mine the temporal correlation of time-series data is further strengthened. Finally, a series of simulation experiments are carried out on the commercial modular aviation propulsion system simulation (C-MAPSS) experimental data provided by National Aeronautics and Space Administration (NASA), verifying the effectiveness of the proposed modules and the superiority of the proposed method in the imputation process of aeroengine missing sensor data.},
  keywords={Correlation;Data models;Time series analysis;Feature extraction;Aircraft propulsion;Deep learning;Data mining;Data imputation and reconstruction;deep learning;industrial artificial intelligence;missing time series},
  doi={10.1109/TIM.2023.3307765},
  ISSN={1557-9662},
  month={},}@INPROCEEDINGS{10298467,
  author={Xu, Bowen and Nguyen, Thanh-Dat and Le-Cong, Thanh and Hoang, Thong and Liu, Jiakun and Kim, Kisub and Gong, Chen and Niu, Changan and Wang, Chenyu and Le, Bach and Lo, David},
  booktitle={2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={Are We Ready to Embrace Generative AI for Software Q&A?}, 
  year={2023},
  volume={},
  number={},
  pages={1713-1717},
  abstract={Stack Overflow, the world's largest software Q&A (SQA) website, is facing a significant traffic drop due to the emergence of generative AI techniques. ChatGPT is banned by Stack Overflow after only 6 days from its release. The main reason provided by the official Stack Overflow is that the answers generated by ChatGPT are of low quality. To verify this, we conduct a comparative evaluation of human-written and ChatGPT-generated answers. Our methodology employs both automatic comparison and a manual study. Our results suggest that human-written and ChatGPT-generated answers are semantically similar, however, human-written answers outperform ChatGPT-generated ones consistently across multiple aspects, specifically by 10% on the overall score. We release the data, analysis scripts, and detailed results at https://github.com/maxxbw54/GAI4SQA.},
  keywords={Data analysis;Manuals;Chatbots;Software;Artificial intelligence;Software engineering;Generative AI;large language model;Software Q&A;Stack Overflow;ChatGPT},
  doi={10.1109/ASE56229.2023.00023},
  ISSN={2643-1572},
  month={Sep.},}@INPROCEEDINGS{10350098,
  author={Heidrich, David and Schreiber, Andreas},
  booktitle={2023 IEEE Working Conference on Software Visualization (VISSOFT)}, 
  title={Visualizing Source Code as Comics Using Generative AI}, 
  year={2023},
  volume={},
  number={},
  pages={40-44},
  abstract={The architecture and inner structure of software is often only implicitly available in the form of its source code and thus not tangible and intuitively easy to understand for non-programmers and laymen. Our goal is to create visualizations as automatically as possible, with which such people can neverthe-less understand the software or parts of the software and get a feel for the structure of the software and how its methods work. Especially for newcomers to software projects, for management or even for students and pupils, it can be helpful to get a non-technical insight into the software. We use the concept of visualizing information as comics to present aspects of the software as strikingly as possible, as comics are an effective way to present complex systems and interrelationships for certain target groups. For this purpose, we present a method to generate comics from source code. Our semi-automated process is based on generating a prompt for an LLM from source code, which in turn generates a prompt for a comic image generation using the text-to-image model Stable Diffusion. We show that generative AI methods can be used to rapidly generate human-compatible artistic representations from source code. However, further research is needed to validate the understandability of the results.},
  keywords={Visualization;Image synthesis;Source coding;Computer architecture;Software;Artificial intelligence;Pupils;visualization;software visualization;comics;generative ai;stable diffusion},
  doi={10.1109/VISSOFT60811.2023.00014},
  ISSN={2832-6555},
  month={Oct},}@ARTICLE{10375128,
  author={Wu, Yingying and Liu, Jinchao and Wang, Yan and Gibson, Stuart and Osadchy, Margarita and Fang, Yongchun},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Reconstructing Randomly Masked Spectra Helps DNNs Identify Discriminant Wavenumbers}, 
  year={2024},
  volume={46},
  number={5},
  pages={3845-3861},
  abstract={Nondestructive detection methods, based on vibrational spectroscopy, are vitally important in a wide range of applications including industrial chemistry, pharmacy and national defense. Recently, deep learning has been introduced into vibrational spectroscopy showing great potential. Different from images, text, etc. that offer large labeled data sets, vibrational spectroscopic data is very limited, which requires novel concepts beyond transfer and meta learning. To tackle this, we propose a task-enhanced augmentation network (TeaNet). The key component of TeaNet is a reconstruction module that inputs randomly masked spectra and outputs reconstructed samples that are similar to the original ones, but include additional variations learned from the domain. These augmented samples are used to train the classification model. The reconstruction and prediction parts are trained simultaneously, end-to-end with back-propagation. Results on both synthetic and real-world datasets verified the superiority of the proposed method. In the most difficult synthetic scenarios TeaNet outperformed CNN by 17%. We visualized and analysed the neuron responses of TeaNet and CNN, and found that TeaNet's ability to identify discriminant wavenumbers was excellent compared to CNN. Our approach is general and can be easily adapted to other domains, offering a solution to more accurate and interpretable few-shot learning.},
  keywords={Training;Task analysis;Image reconstruction;Spectroscopy;Data augmentation;Training data;Minerals;Masked CNN;deep learning;vibrational spectroscopy},
  doi={10.1109/TPAMI.2023.3347617},
  ISSN={1939-3539},
  month={May},}@INPROCEEDINGS{11082909,
  author={Maryam, Afifa and Fatima, Noor and Zeeshan, Muhammad and Saleem, Shahzad and Ullah, Inam},
  booktitle={2025 International Conference on Innovation in Artificial Intelligence and Internet of Things (AIIT)}, 
  title={Secure Synthetic Image Generation Using Self-Attention GAN and Blockchain}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Privacy concerns are paramount in today’s digital era, particularly in AI-driven environments. Traditional privacy preservation approaches are inadequate due to their reliance on outdated methods, highlighting the need for innovative solutions to ensure robust security and confidentiality. This paper proposes a robust AI framework, Secure Self-Attention GAN (SSA-GAN), to safeguard image data. Our methodology combines advanced clustering algorithms and blockchain technology to ensure privacy and security. SSA-GAN generates highly realistic synthetic face images, while mini-batch K-means clustering groups them for enhanced privacy. Blockchain integration provides a transparent and secure storage solution. We evaluate the proposed framework on VGGFace2 datasets, achieving outstanding results: an Inception-Score(IS) of 12.49 and a Fréchet Inception Distance(FID) of 29.70, displayed significant improvements over baseline approaches. Our clustering approach successfully identifies unique facial attribute clusters, and blockchain integration maintains data privacy and security with 87% precision, 82% recall, 84% F1-score, and 92% ROC accuracy. This framework advances the state of the art in privacy-preserving AI, enabling critical applications like identity verification and medical image management.},
  keywords={Privacy;Technological innovation;Image synthesis;Memory;Blockchains;Security;Internet of Things;Artificial intelligence;Secure storage;Facial features;Self-Attention GAN;Blockchain;Privacy-Preserving AI;Secure Data Storage;Mini-batch K-means Clustering},
  doi={10.1109/AIIT63112.2025.11082909},
  ISSN={},
  month={May},}@INPROCEEDINGS{10203862,
  author={Cui, Kaiwen and Yu, Yingchen and Zhan, Fangneng and Liao, Shengcai and Lu, Shijian and Xing, Eric},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={KD-DLGAN: Data Limited Image Generation via Knowledge Distillation}, 
  year={2023},
  volume={},
  number={},
  pages={3872-3882},
  abstract={Generative Adversarial Networks (GANs) rely heavily on large-scale training data for training high-quality image generation models. With limited training data, the GAN discriminator often suffers from severe overfitting which directly leads to degraded generation especially in generation diversity. Inspired by the recent advances in knowledge distillation (KD), we propose KD-DLGAN, a knowledge-distillation based generation framework that introduces pre-trained vision-language models for training effective data-limited generation models. KD-DLGAN consists of two innovative designs. The first is aggregated generative KD that mitigates the discriminator overfitting by challenging the discriminator with harder learning tasks and distilling more generalizable knowledge from the pre-trained models. The second is correlated generative KD that improves the generation diversity by distilling and preserving the diverse image-text correlation within the pre-trained models. Extensive experiments over multiple benchmarks show that KD-DLGAN achieves superior image generation with limited training data. In addition, KD-DLGAN complements the state-of-the-art with consistent and substantial performance gains. Note that codes will be released.},
  keywords={Training;Correlation;Image synthesis;Diversity reception;Training data;Performance gain;Generative adversarial networks;Image and video synthesis and generation},
  doi={10.1109/CVPR52729.2023.00377},
  ISSN={2575-7075},
  month={June},}@ARTICLE{10054417,
  author={Troullinou, Eirini and Tsagkatakis, Grigorios and Losonczy, Attila and Poirazi, Panayiota and Tsakalides, Panagiotis},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={A Generative Neighborhood-Based Deep Autoencoder for Robust Imbalanced Classification}, 
  year={2024},
  volume={5},
  number={1},
  pages={80-91},
  abstract={Deep learning models perform remarkably well on many classification tasks recently. The superior performance of deep neural networks relies on the large number of training data, which at the same time must have an equal class distribution in order to be efficient. However, in most real-world applications, the labeled data may be limited with high imbalance ratios among the classes, and thus, the learning process of most classification algorithms is adversely affected resulting in unstable predictions and low performance. Three main categories of approaches address the problem of imbalanced learning, i.e., data-level, algorithmic level, and hybrid methods, which combine the two aforementioned approaches. Data generative methods are typically based on generative adversarial networks, which require significant amounts of data, while model-level methods entail extensive domain expert knowledge to craft the learning objectives, thereby being less accessible for users without such knowledge. Moreover, the vast majority of these approaches are designed and applied to imaging applications, less to time series, and extremely rare to both of them. To address the above issues, we introduce GENDA, a generative neighborhood-based deep autoencoder, which is simple yet effective in its design and can be successfully applied to both image and time-series data. GENDA is based on learning latent representations that rely on the neighboring embedding space of the samples. Extensive experiments, conducted on a variety of widely-used real datasets demonstrate the efficacy of the proposed method.},
  keywords={Data models;Classification algorithms;Time series analysis;Artificial intelligence;Predictive models;Data augmentation;Data augmentation;image data;imbalanced classification;latent space;time-series data},
  doi={10.1109/TAI.2023.3249685},
  ISSN={2691-4581},
  month={Jan},}@INPROCEEDINGS{11133642,
  author={Ahi, Kiarash and Valizadeh, Saeed},
  booktitle={2025 Silicon Valley Cybersecurity Conference (SVCC)}, 
  title={Large Language Models (LLMs) and Generative AI in Cybersecurity and Privacy: A Survey of Dual-Use Risks, AI-Generated Malware, Explainability, and Defensive Strategies}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Large Language Models (LLMs) and generative AI (GenAI) systems, such as ChatGPT, Claude, Gemini, LLaMA, Copilot, Stable Diffusion by OpenAI, Anthropic, Google, Meta, Microsoft, Stability AI, respectively, are revolutionizing cybersecurity, enabling both automated defense and sophisticated attacks. These technologies power real-time threat detection, phishing defense, secure code generation, and vulnerability exploitation at unprecedented scales. LLM-generated malware alone is projected to account for 50% of detected threats in 2025, up from just 2% in 2021, emphasizing the need for next-generation security frameworks.This paper presents a comprehensive survey of the beneficial and malicious applications of LLMs in cybersecurity, including zero-day detection, DevSecOps, federated learning, synthetic content analysis, and explainable AI (XAI). Drawing on a review of over 70 academic papers, industry reports, and technical documents, this work synthesizes insights from real-world case studies across platforms like Google Play Protect, Microsoft Defender, Amazon Web Services (AWS), Apple’s App Store, OpenAI Plugin Stores, Hugging Face Spaces, and GitHub, alongside emerging initiatives like the SAFE Framework and AI-driven anomaly detection.We conclude with practical recommendations for responsible and transparent LLM deployment, including model watermarking, adversarial defense, and cross-industry collaboration—setting a new benchmark for rigorous, holistic cybersecurity research at the intersection of AI and threat defense—and offering a roadmap for secure, scalable LLM systems that serves as a critical reference for researchers, engineers, and security leaders navigating the complex challenges of AI-driven cybersecurity.},
  keywords={Surveys;Generative AI;Web services;Federated learning;Large language models;Malware;Threat assessment;Stability analysis;Computer security;Software development management;Large Language Models (LLMs);Generative AI;Cybersecurity;Dual-Use AI;AI-Driven Malware;Explainable AI (XAI);Zero-Day Detection;Federated Learning;Platform Integrity;ChatGPT;Claude;Gemini;LLaMA;Copilot;Stable Diffusion;OpenAI;Anthropic;Google;Meta;Microsoft;Stability AI;Amazon Web Services (AWS);Apple App Store;OpenAI Plugin Stores;Microsoft Defender;Google Play Protect;GitHub;AI Governance;Deepfakes;Synthetic Content;AI Security;Threat Detection;Anomaly Detection},
  doi={10.1109/SVCC65277.2025.11133642},
  ISSN={},
  month={June},}@INPROCEEDINGS{10902899,
  author={Kodali, Ravi Kishore and Upreti, Yatendra Prasad and Boppana, Lakshmi},
  booktitle={TENCON 2024 - 2024 IEEE Region 10 Conference (TENCON)}, 
  title={A Novel Approach to Generative AI Translation}, 
  year={2024},
  volume={},
  number={},
  pages={698-702},
  abstract={Machine translation, increasingly adopted by companies, involves fine-tuning Large Language Models (LLMs) for tasks like text translation. The author introduces a data curation pipeline for creating a relevant parallel corpus and a new metric to assess the understandability of OpenHathi LLM translations. Studies show that prompting strategies improve the clarity of culturally specific translations. Additionally, adapter-based, parameter-efficient coarse-tuning methods match or exceed the performance of advanced LLMs in reasoning tasks with fewer parameters. As technology advances, translators can maintain quality while reducing costs. However, challenges remain, including inaccuracies and biases in translations for under-resourced languages, but AI translation offers significant potential for grasping context and cultural nuances.},
  keywords={Measurement;Translation;Generative AI;Large language models;Pipelines;Grasping;Machine translation;Cultural differences;Artificial intelligence;IEEE Regions;Fine-Tuning;LLM;LoRA;Translation},
  doi={10.1109/TENCON61640.2024.10902899},
  ISSN={2159-3450},
  month={Dec},}@INPROCEEDINGS{11115657,
  author={Ehab, Mina and Hany, Menna S. and Tamer, Karen and Emil, Peter and Hany, Marwa S. and Ibrahim, Tamer M. and Aboulhassan, Amal},
  booktitle={2025 International Conference on Machine Intelligence and Smart Innovation (ICMISI)}, 
  title={A Deep Learning Pipeline for Generating New PTR1 Inhibitors Targeting Leishmania Disease}, 
  year={2025},
  volume={},
  number={},
  pages={251-256},
  abstract={Drug discovery and material design aim at finding new molecules with properties of interest. However the process is expensive and time consuming. To address these limitations, Artificial Intelligence (AI) has been introduced recently in literature. In this paper, AI tools were utilized to generate new compounds that target the Leishmania disease for the first time. A combination of Variational Auto encoders and Reinforcement learning were trained on newly collected dataset as well as Zinc dataset. The validity and quality of generated compounds were evaluated using two methods: a collection of computed metrics and docking scores. The results achieved high scores with respect to validity and uniqueness which demonstrates the potential of this framework to operate on larger datasets relevant to our research.},
  keywords={Measurement;Deep learning;Technological innovation;Pipelines;Autoencoders;Reinforcement learning;Compounds;Artificial intelligence;Zinc;Diseases;deep learning;Variational Autoencoders VAE);leishmania DHFR;molecular docking;bioinformatics},
  doi={10.1109/ICMISI65108.2025.11115657},
  ISSN={},
  month={May},}@INPROCEEDINGS{10981392,
  author={Ciampi, Melany M. and Brito, Claudio R and Feldgen, Maria and Clua, Osvaldo},
  booktitle={2025 IEEE Engineering Education World Conference (EDUNINE)}, 
  title={Plenary: Education in the Age of Generative AI: Embracing Digital Transformation}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={May be the main challenge of using AI in education is ensuring that its use does not compromise the originality or credibility of the research. In addition, there is a risk that excessive use of AI could lead to ethical issues, such as plagiarism, obvious inaccuracies, or a general dilution of the intellectual contribution. In an effort to mitigate these risks, institutions should provide additional guidelines on the ethical use of AI and promote best practices among researchers.AI has the potential to enrich academic research by increasing productivity, improving communication, and in some ways making research more available. The key element will be the ethical responsibility by the scientists and researchers in the use of AI as a helper more than a science producer. As any other disruptive technology available the human beings will certainly take the best of AI as it has happening along the history of new Technologies.},
  keywords={Productivity;Ethics;Technological innovation;Privacy;Generative AI;Digital transformation;Urban areas;Medical services;Real-time systems;Artificial intelligence;academy;AI;digital transformation;disruptive education;publications},
  doi={10.1109/EDUNINE62377.2025.10981392},
  ISSN={},
  month={March},}@INBOOK{10789148,
  author={Patel, Rutwik and Mehendale, Ninad},
  booktitle={Computational Intelligence for Managing Pandemics}, 
  title={13 Deep learning on medical images to combat a pandemic}, 
  year={2021},
  volume={},
  number={},
  pages={231-258},
  abstract={Humanity is suffering immensely due to the coronavirus disease (COVID-19) pandemic. Learning from all the previous pandemics, it is understood that there is a need for faster patient diagnosis in times like these. Owing to scarce human resources, we need to utilize artificial intelligence (AI) to develop quicker and more cost-effective tools. Individuals who feel they are experiencing symptoms or feel that they might have been in contact with a patient should get tested. But not everyone who undergoes the test is infected. Thus, preprocessing medical images using deep learning algorithms classify patients into different categories and thus helps in detecting infected patients. The common medical images used for diagnosis are X-rays, CT (computer tomography), MRI (magnetic resonance imaging), and ultrasound. There are significant differences between these medical images of an infected and noninfected person. Radiologists must study these images carefully and perform various calculations for an accurate diagnosis. AI can be used to automate some analysis reducing human error, leading to faster results. Such solutions can predict if a patient must be transferred to the intensive care unit, which helps decrease the burden on hospital resources. Through the use of AI, a large number of medical images can be analyzed quickly. This helps radiologists to smoothly treat and diagnose their patients even during a pandemic without any interruptions. In this chapter, we go through the different imaging techniques used for diagnosis and how AI models can be built for each of them. We also analyze distinct possibilities and ideas for the classification of images. Additionally, we propose two models that can accurately identify COVID-infected patients from CT scans and X-rays.},
  keywords={X-ray imaging;Magnetic resonance imaging;Diseases;Pandemics;Artificial intelligence;Ultrasonic imaging;Medical diagnostic imaging;COVID-19;Computed tomography;Cancer},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9783110712278},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10789148},}@INBOOK{10948969,
  author={Banafa, Ahmed},
  booktitle={Artificial Intelligence in Action: Real-World Applications and Innovations}, 
  title={26 Finding Your AI Ally: Choosing the Right AI for Your Business and Expanding Your Horizons with Powerful Tools}, 
  year={2025},
  volume={},
  number={},
  pages={171-174},
  abstract={This comprehensive book dives deep into the current landscape of AI, exploring its fundamental principles, development challenges, potential risks, and the cutting-edge breakthroughs that are propelling it forward. Artificial intelligence (AI) is rapidly transforming industries and societies worldwide through groundbreaking innovations and real-world applications. Starting with the core concepts, the book examines the various types of AI systems, generative AI models, and the complexities of machine learning. It delves into the programming languages driving AI development, data pipelines, model creation and deployment processes, while shedding light on issues like AI hallucinations and the intricate path of machine unlearning. The book then showcases the remarkable real-world applications of AI across diverse domains. From preventing job displacement and promoting environmental sustainability, to enhancing disaster response, drone technology, and even nuclear energy innovation, it highlights how AI is tackling complex challenges and driving positive change. The book also explores the double-edged nature of AI, recognizing its tremendous potential while cautioning about the risks of misuse, unintended consequences, and the urgent need for responsible development practices. It examines the intersection of AI and fields like operating system design, warfare, and semiconductor technology, underscoring the wide-ranging implications of this transformative force. As the quest for artificial general intelligence (AGI) and superintelligent AI systems intensifies, the book delves into cutting-edge research, emerging trends, and the pursuit of multimodal, explainable, and causally aware AI systems. It explores the symbiotic relationship between AI and human creativity, the rise of user-friendly "casual AI," and the potential of AI to tackle open-ended tasks. This is an essential guide for understanding the profound impact of AI on our world today and its potential to shape our future. From the frontiers of innovation to the challenges of responsible development, this book offers a comprehensive and insightful exploration of the remarkable real-world applications and innovations driving the AI revolution.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770046190},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10948969},}@INBOOK{10948946,
  author={Banafa, Ahmed},
  booktitle={Artificial Intelligence in Action: Real-World Applications and Innovations}, 
  title={34 AI and the Challenge of Causal Reasoning and Reasoning Under Uncertainty}, 
  year={2025},
  volume={},
  number={},
  pages={217-224},
  abstract={This comprehensive book dives deep into the current landscape of AI, exploring its fundamental principles, development challenges, potential risks, and the cutting-edge breakthroughs that are propelling it forward. Artificial intelligence (AI) is rapidly transforming industries and societies worldwide through groundbreaking innovations and real-world applications. Starting with the core concepts, the book examines the various types of AI systems, generative AI models, and the complexities of machine learning. It delves into the programming languages driving AI development, data pipelines, model creation and deployment processes, while shedding light on issues like AI hallucinations and the intricate path of machine unlearning. The book then showcases the remarkable real-world applications of AI across diverse domains. From preventing job displacement and promoting environmental sustainability, to enhancing disaster response, drone technology, and even nuclear energy innovation, it highlights how AI is tackling complex challenges and driving positive change. The book also explores the double-edged nature of AI, recognizing its tremendous potential while cautioning about the risks of misuse, unintended consequences, and the urgent need for responsible development practices. It examines the intersection of AI and fields like operating system design, warfare, and semiconductor technology, underscoring the wide-ranging implications of this transformative force. As the quest for artificial general intelligence (AGI) and superintelligent AI systems intensifies, the book delves into cutting-edge research, emerging trends, and the pursuit of multimodal, explainable, and causally aware AI systems. It explores the symbiotic relationship between AI and human creativity, the rise of user-friendly "casual AI," and the potential of AI to tackle open-ended tasks. This is an essential guide for understanding the profound impact of AI on our world today and its potential to shape our future. From the frontiers of innovation to the challenges of responsible development, this book offers a comprehensive and insightful exploration of the remarkable real-world applications and innovations driving the AI revolution.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770046190},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10948946},}@INBOOK{10948956,
  author={Banafa, Ahmed},
  booktitle={Artificial Intelligence in Action: Real-World Applications and Innovations}, 
  title={About the Author}, 
  year={2025},
  volume={},
  number={},
  pages={331-332},
  abstract={This comprehensive book dives deep into the current landscape of AI, exploring its fundamental principles, development challenges, potential risks, and the cutting-edge breakthroughs that are propelling it forward. Artificial intelligence (AI) is rapidly transforming industries and societies worldwide through groundbreaking innovations and real-world applications. Starting with the core concepts, the book examines the various types of AI systems, generative AI models, and the complexities of machine learning. It delves into the programming languages driving AI development, data pipelines, model creation and deployment processes, while shedding light on issues like AI hallucinations and the intricate path of machine unlearning. The book then showcases the remarkable real-world applications of AI across diverse domains. From preventing job displacement and promoting environmental sustainability, to enhancing disaster response, drone technology, and even nuclear energy innovation, it highlights how AI is tackling complex challenges and driving positive change. The book also explores the double-edged nature of AI, recognizing its tremendous potential while cautioning about the risks of misuse, unintended consequences, and the urgent need for responsible development practices. It examines the intersection of AI and fields like operating system design, warfare, and semiconductor technology, underscoring the wide-ranging implications of this transformative force. As the quest for artificial general intelligence (AGI) and superintelligent AI systems intensifies, the book delves into cutting-edge research, emerging trends, and the pursuit of multimodal, explainable, and causally aware AI systems. It explores the symbiotic relationship between AI and human creativity, the rise of user-friendly "casual AI," and the potential of AI to tackle open-ended tasks. This is an essential guide for understanding the profound impact of AI on our world today and its potential to shape our future. From the frontiers of innovation to the challenges of responsible development, this book offers a comprehensive and insightful exploration of the remarkable real-world applications and innovations driving the AI revolution.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770046190},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10948956},}@INPROCEEDINGS{8954283,
  author={Zhu, Minfeng and Pan, Pingbo and Chen, Wei and Yang, Yi},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={DM-GAN: Dynamic Memory Generative Adversarial Networks for Text-To-Image Synthesis}, 
  year={2019},
  volume={},
  number={},
  pages={5795-5803},
  abstract={In this paper, we focus on generating realistic images from text descriptions. Current methods first generate an initial image with rough shape and color, and then refine the initial image to a high-resolution one. Most existing text-to-image synthesis methods have two main problems. (1) These methods depend heavily on the quality of the initial images. If the initial image is not well initialized, the following processes can hardly refine the image to a satisfactory quality. (2) Each word contributes a different level of importance when depicting different image contents, however, unchanged text representation is used in existing image refinement processes. In this paper, we propose the Dynamic Memory Generative Adversarial Network (DM-GAN) to generate high-quality images. The proposed method introduces a dynamic memory module to refine fuzzy image contents, when the initial images are not well generated. A memory writing gate is designed to select the important text information based on the initial image content, which enables our method to accurately generate images from the text description. We also utilize a response gate to adaptively fuse the information read from the memories and the image features. We evaluate the DM-GAN model on the Caltech-UCSD Birds 200 dataset and the Microsoft Common Objects in Context dataset. Experimental results demonstrate that our DM-GAN model performs favorably against the state-of-the-art approaches.},
  keywords={Adaptation models;Shape;Image color analysis;Fuses;Memory modules;Logic gates;Writing;Image and Video Synthesis;Deep Learning;Vision + Language},
  doi={10.1109/CVPR.2019.00595},
  ISSN={2575-7075},
  month={June},}@ARTICLE{9034117,
  author={Yoon, Jinsung and Drumright, Lydia N. and van der Schaar, Mihaela},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Anonymization Through Data Synthesis Using Generative Adversarial Networks (ADS-GAN)}, 
  year={2020},
  volume={24},
  number={8},
  pages={2378-2388},
  abstract={The medical and machine learning communities are relying on the promise of artificial intelligence (AI) to transform medicine through enabling more accurate decisions and personalized treatment. However, progress is slow. Legal and ethical issues around unconsented patient data and privacy is one of the limiting factors in data sharing, resulting in a significant barrier in accessing routinely collected electronic health records (EHR) by the machine learning community. We propose a novel framework for generating synthetic data that closely approximates the joint distribution of variables in an original EHR dataset, providing a readily accessible, legally and ethically appropriate solution to support more open data sharing, enabling the development of AI solutions. In order to address issues around lack of clarity in defining sufficient anonymization, we created a quantifiable, mathematical definition for “identifiability”. We used a conditional generative adversarial networks (GAN) framework to generate synthetic data while minimize patient identifiability that is defined based on the probability of re-identification given the combination of all data on any individual patient. We compared models fitted to our synthetically generated data to those fitted to the real data across four independent datasets to evaluate similarity in model performance, while assessing the extent to which original observations can be identified from the synthetic data. Our model, ADS-GAN, consistently outperformed state-of-the-art methods, and demonstrated reliability in the joint distributions. We propose that this method could be used to develop datasets that can be made publicly available while considerably lowering the risk of breaching patient confidentiality.},
  keywords={Generative adversarial networks;Gallium nitride;Machine learning;Generators;Medical services;Synthetic data generation;anonymization;identifiability;generative adversarial networks;electronic health records},
  doi={10.1109/JBHI.2020.2980262},
  ISSN={2168-2208},
  month={Aug},}@INPROCEEDINGS{8546268,
  author={Jia, Li and Song, Yonghong and Zhang, Yuanlin},
  booktitle={2018 24th International Conference on Pattern Recognition (ICPR)}, 
  title={Face Aging with Improved Invertible Conditional GANs}, 
  year={2018},
  volume={},
  number={},
  pages={1396-1401},
  abstract={Due to the continuous development of GAN, vivid faces can be generated, and the use of GAN for face aging becomes a novel trend. However, many existing works for face aging require tedious pre-processing of datasets. This brings a lot of computational burden and limits the application of face aging. In order to solve these problems, a face aging network is constructed using IcGAN without any data pre-processing which map a face image into personality and age vector spaces through encoders Z and Y. Different from the previous work, we make an emphasis on the preservation of both personalized and aging features. Thus, the minimize absolute reconstructing loss is proposed to optimize vector z, which can remain the personality characteristics, meanwhile preserving the pose, hairstyle and background of the input face. Additionally, we introduce a novel age vector optimization approach by classifying reconstruction loss and introduce the parameter λ which is well-balanced between large age features and subtle texture features. The experimental results demonstrate our proposed AlGAN provides better aging faces over other state-of-the-art age progression methods.},
  keywords={Face;Aging;Gallium nitride;Hair;Generative adversarial networks;Image reconstruction;Optimization;Face Aging;GAN;feature vector;age vector;optimization},
  doi={10.1109/ICPR.2018.8546268},
  ISSN={1051-4651},
  month={Aug},}@INPROCEEDINGS{9054016,
  author={Devaraj, Chinmaya and Chowdhury, Aritra and Jain, Arpit and Kubricht, James R. and Tu, Peter and Santamaria-Pang, Alberto},
  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={From Symbols to Signals: Symbolic Variational Autoencoders}, 
  year={2020},
  volume={},
  number={},
  pages={3317-3321},
  abstract={We introduce Symbolic Variational Autoencoders which generate images from symbols that represent semantic concepts. Unlike generic Variational Autoencoders (VAEs) or Generative Adversarial Networks (GANs), the latent distribution from the Symbolic Variational Autoencoder is discrete. The symbols are learned in a completely unsupervised manner by reconstructing images from symbolic encodings. We demonstrate the efficacy of our symbolic approach on the MNIST and FashionMNIST datasets. Results indicate that symbolic encodings naturally form a grammar, where unique strings of symbols map to different semantic concepts. We further explore how changing these symbols affects the final image that is generated.},
  keywords={Image coding;Semantics;Footwear;Transforms;Encoding;Grammar;Image reconstruction;Emergent languages;Variational Autoencoders;Explainability},
  doi={10.1109/ICASSP40776.2020.9054016},
  ISSN={2379-190X},
  month={May},}@ARTICLE{10659041,
  author={Xie, Weicheng and Niu, Zenghao and Lin, Qinliang and Song, Siyang and Shen, Linlin},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Generative Imperceptible Attack With Feature Learning Bias Reduction and Multi-Scale Variance Regularization}, 
  year={2024},
  volume={19},
  number={},
  pages={7924-7938},
  abstract={Existing studies have shown that malicious and imperceptible adversarial samples may significantly weaken the reliability and validity of deep learning systems. Since gradient-based attack algorithms may result in higher generation latency or demand large computation overhead, generative attack methods are frequently considered. However, the effectiveness and imperceptibility are still the main concerns for these generative attacks, 1) biased feature learning may occur, i.e., these algorithms may generate undesirable feature perturbations for samples that are less likely to be successfully attacked; 2) the produced perturbation noises may be easily perceived by human eyes. To this end, we propose a novel generative attack by manipulating the feature update. The proposed algorithm has two main merits, 1) our Bias-reduced Feature Manipulation (BrFM) that differentiates the hard-to-attack (Hard2Attack) and easy-to-attack (Easy2Attack) features, can avoid the possible learning shortcut for different difficulties of features in attack process, by customizing perturbations for Hard2Attack features to make them behave oppositely to those of benign features; 2) our Multi-scale Variance Regularization (MsVR) can reduce the unnatural transitions of perturbations in mask edges and flat areas with low contrast, while simultaneously trading off a reasonable attack capacity. Extensive experiments on the datasets of Caltech-101 and Imagenette in terms of the attack success rate and four imperceptibility metrics, show the effectiveness of our attack paradigm over the related state-of-the-art generative attack methods. Our codes will be made publicly available.},
  keywords={Perturbation methods;Noise;Diffusion models;Measurement;Training;Task analysis;Computational modeling;Generative adversarial attack;imperceptible perturbation;imperceptibility metric;feature regularization loss;robust object classification},
  doi={10.1109/TIFS.2024.3451689},
  ISSN={1556-6021},
  month={},}@INPROCEEDINGS{10957020,
  author={KM, Swaroopa and Chetty, Girija and White, Matthew},
  booktitle={2025 International Conference on Intelligent Control, Computing and Communications (IC3)}, 
  title={Deep Learning Framework Based on Generative AI for Medical Image Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={493-501},
  abstract={Application of deep machine learning algorithms for diagnosing and providing treatment plans is a considerably vital and hopeful domain of concern which can significantly help clinicians. Deep learning is heavily reliant on large amounts of data. Medical data sets are a bit complex to analyse as compared to natural images, as they are relatively of bad quality (as a result of multiple image acquisition artefacts) and infrequently public because of personal privacy restrictions relating to the sharing of patient data. The generation of substitute/synthetic images can save the day, where the synthetic images can have improved quality without any noisy artefacts, have zero privacy concerns as there are no individuals in such images, and synthetic images can be distributed publicly without any issues. This paper presents a novel computational framework based on generative artificial intelligence for creating synthetic or surrogate medical images for diverse downstream medical image analytics tasks, specific for analyzing a large corpus of radiology images across multimodality inputs, especially:diagnosis, tracking, and treatment of complex diseases, with an extensive focus on medical image analytics within the radiation oncology or cancer domain.},
  keywords={Deep learning;Privacy;Image analysis;Machine learning algorithms;Generative AI;Radiology;Oncology;Noise measurement;Medical diagnostic imaging;Intelligent control;Generative AI;Deep Learning;Medical Image Analysis;Oncology;Synthetic Images},
  doi={10.1109/IC363308.2025.10957020},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10633372,
  author={Banday, Banooqa H. and Islam, Tanzima Z. and Marathe, Aniruddha},
  booktitle={2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={PERFGEN: A Synthesis and Evaluation Framework for Performance Data using Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={188-197},
  abstract={Collecting data in High-Performance Computing (HPC) is a laborious task, demanding that application scientists execute the application multiple times with different configurations. Due to the essential nature of performance modeling and root cause analysis as initial phases of performance enhancement, the data collection phase prolongs the optimization process. Motivated by this observation, we investigate the feasibility of leveraging the recent advancement in the field of generative Artificial Intelligence (AI) to synthesize performance samples. However, generating synthetic performance data introduces an additional hurdle: the absence of ground truths to assess the quality of the synthetic data. This work takes a step toward bridging this gap where we propose a framework-PERFGEN-for generating performance data and evaluating its quality using a novel metric called Dissimilarity. Our experiments with three performance and five machine learning datasets (including three classification and two regression datasets), confirm that our proposed Dissimilarity correlates with model accuracy better than three of the state-of-the-art metrics-SD quality, Kullback-Leibler Divergence (KL), and TabSyndex, demonstrating that the Dissimilarity metric strongly correlates with the quality of generated scientific data. We evaluate the quality by measuring how well the generated data enables a downstream Machine Learning (ML) task to generalize. Since performance data is a special case of scientific data-typically stored in tabular format and consisting of numerical, categorical, and ordinal features-our methodologies and metrics apply to scientific data from other domains as well.},
  keywords={Measurement;Accuracy;Generative AI;Computational modeling;Machine learning;Predictive models;Data models;Large Language Model;Generative Modeling;Evaluation;Scientific Data},
  doi={10.1109/COMPSAC61105.2024.00035},
  ISSN={2836-3795},
  month={July},}@INPROCEEDINGS{10892479,
  author={Demirel, Gökhan and Hauf, Jan and Butt, Hallah and Förderer, Kevin and Schäfer, Benjamin and Hagenmeyer, Veit},
  booktitle={2024 IEEE Sustainable Power and Energy Conference (iSPEC)}, 
  title={Synthesizing Distribution Grid Congestion Data Using Multivariate Conditional Time Series Generative Adversarial Networks}, 
  year={2024},
  volume={},
  number={},
  pages={385-390},
  abstract={Distribution grid congestion is a significant obstacle to integrating distributed energy resources, leading to voltage instability and overloading grid elements. Existing probabilistic models cannot directly generate realistic multivariate time series data with grid bottleneck characteristics. Generating multivariate time series data that capture photovoltaic and load patterns across correlated buses while performing power flow calculations is inherently complex. These challenges, data compliance issues, and the need for more training data suggest the exploration of Artificial Intelligence methods and the generation of edge test data. This paper introduces Multivariate Conditional Time-series Generative Adversarial Networks (MC- TimeGAN), designed for the conditioned generation of synthetic load and photovoltaic generation profiles. MC-TimeGAN simulates severe grid con-gestion scenarios by purposefully manipulating the respective labels passed to the model and provides data augmentation. Applying this methodology to a validated benchmark dataset for distribution grid shows a significant and realistic increase in grid congestion. Evaluation by power flow calculations, using the dataset generated by MC- TimeGAN shows increase the mean transformer load by 8% and the mean line load by up to 14% compared to the original data. Together with dimensionality reduction techniques, we demonstrate that synthetic data are similar to original data.},
  keywords={Photovoltaic systems;Time series analysis;Training data;Voltage;Generative adversarial networks;Transformers;Data models;Load modeling;Load flow;Synthetic data;Deep learning;distribution grid congestion;generative models;multivariate time series;photovoltaic power systems},
  doi={10.1109/iSPEC59716.2024.10892479},
  ISSN={2837-522X},
  month={Nov},}@INPROCEEDINGS{10674171,
  author={Yang, Bo and Johnson-Shapoval, Sophie},
  booktitle={2024 IEEE 4th International Conference on Software Engineering and Artificial Intelligence (SEAI)}, 
  title={Exploring Social Media Sentiment Polarity: A Case Study Utilizing Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={215-219},
  abstract={Large language models are crucial for processing social media data, aiding in recommendation systems, sentiment analysis, and more. This study proposes a method to enhance sentiment analysis accuracy by combining word embeddings with insights from a language-based model. Focused on consumer reviews, sentiments are categorized based on extreme polarities, excluding intermediate ratings. Empirical assessments show superior outcomes when combining opinions, summaries, and pre-processed summaries. Machine learning algorithms are applied to hybrid vectors to classify sentiments accurately, distinguishing between positive and negative viewpoints. This approach offers nuanced sentiment analysis within consumer feedback, facilitating understanding of product reviews. Overall, the method integrates feature extraction and machine learning to analyze binary polar data, providing sentiment estimates in a concise vector form, with promising implications for sentiment analysis and consumer sentiment understanding.},
  keywords={Sentiment analysis;Accuracy;Social networking (online);Reviews;Heuristic algorithms;Software algorithms;Estimation;sentiment analysis;polarity categorization;language models;artificial intelligence;natural language processing},
  doi={10.1109/SEAI62072.2024.10674171},
  ISSN={},
  month={June},}@INPROCEEDINGS{11091853,
  author={Wu, Lan and Tong, Haochen and Pian, Yang and Wang, Axi},
  booktitle={2025 7th International Conference on Computer Science and Technologies in Education (CSTE)}, 
  title={Research on the Influencing Factors and Mechanisms of Preservice Teachers' Human-Machine Collaborative Instructional Design Abilities}, 
  year={2025},
  volume={},
  number={},
  pages={201-205},
  abstract={Generative artificial intelligence(GenAI) like ChatGPT has been widely integrated into education, thereby empowering educators and gaining attention for human-machine collaborative education. The human-machine collaborative teaching ability has become one of the essential core competencies for teachers. There is an urgent need to explore the factors and mechanism to assist teachers in collaborating with GenAI more efficiently. This study carried out an empirical research, collecting multidimensional performances such as technological experience, technological beliefs, higher-order thinking, and prior knowledge from 44 preservice teachers. Based on the results of multiple linear regression analysis, we found that higher-order thinking and prior knowledge had a significant impact on the level of human-machine collaborative instructional design(H-M CID), while there was a negative impact relationship between technological beliefs and the level of higher-order thinking, as well as the technological experience. Those findings could lay the foundation for cultivating teachers’ H-M CID abilities.},
  keywords={Computer science;Navigation;Generative AI;Human-machine systems;Education;Linear regression;Collaboration;Chatbots;Standards;generative artificial intelligence (GenAI);human-machine collaborative instructional design (H-M CID);technological experience;technological beliefs;higher-order thinking;prior knowledge},
  doi={10.1109/CSTE64638.2025.11091853},
  ISSN={},
  month={April},}@ARTICLE{9570308,
  author={Choi, Jung-Gu and Nah, Yoonjin and Ko, Inhwan and Han, Sanghoon},
  journal={IEEE Access}, 
  title={Deep Learning Approach to Generate a Synthetic Cognitive Psychology Behavioral Dataset}, 
  year={2021},
  volume={9},
  number={},
  pages={142489-142505},
  abstract={Synthetic data generation is critical in machine and deep learning research to overcome the shortage of samples or dataset sizes. Various algorithms, including the generative adversarial network and autoencoder models, have been applied to generate artificial datasets in previous studies. In this study, we propose a synthetic data generation framework for a tabular dataset collected from cognitive psychology behavioral experiments based on deep learning algorithms. Tabular datasets for the Stroop task were used to develop our framework. On account of the relatively small sample size (N=102) of the dataset used in our study, we used a pre-trained generative adversarial network model to complement the size of the dataset. Furthermore, we proposed and applied five evaluation methods with statistical tests (overlapped sample test, constraint reflection test, correlation reflection test, distribution distance test, and feature distance test) to validate generation performance based on internal levels of table structure (instance level, feature level, and whole-set level evaluations). The proposed framework with a fine-tuned generative adversarial network algorithm was compared with a random generation method to verify generation performance, including the representation of the statistical characteristics of the original datasets. We found that the generated datasets from the proposed framework exhibited more similar statistical characteristics with the original dataset than the randomly generated datasets based on five evaluation methods. The results of this study provide not only generation algorithms for cognitive psychological datasets with tabular type but also a solution to the sample size issue for researchers.},
  keywords={Psychology;Deep learning;Task analysis;Reflection;Generative adversarial networks;Brain modeling;Data models;Behavioral experimental dataset;cognitive psychology;data augmentation;generative adversarial network;tabular dataset;synthetic data generation},
  doi={10.1109/ACCESS.2021.3120083},
  ISSN={2169-3536},
  month={},}@ARTICLE{10272577,
  author={Choi, Hyun-Tae and Sohn, Bong-Soo and Hong, Byung-Woo},
  journal={IEEE Access}, 
  title={Unsupervised Image to Image Translation With Additional Mask}, 
  year={2023},
  volume={11},
  number={},
  pages={110522-110529},
  abstract={With the development of deep learning, the performance of image-to-image translation is also increasing. However, most of the image-to-image translation models depend on the implicit method which does not explain why the models alter specific parts of the original input images. In this work, we assume that we can control the extent to which the models translate the input images using an explicit method. We explicitly create masks that will be added to the input images, aiming to highlight the difference between the inputs and the translated images. Since limiting the area of the masks directly affects the shape of the translated images, we can adjust the model through a simple regularization parameter. Our proposed method demonstrates that a simple regularization parameter, which regularizes the generated masks, can control where the model needs to change and remain. Furthermore, by adjusting the degree of the regularization parameter, we can generate diverse translated images from one original image.},
  keywords={Generative adversarial networks;Generators;Optimization;Decoding;Training;Supervised learning;Mathematical models;Multimodal sensors;Generative adversarial network;multi-modal image-to-image translation},
  doi={10.1109/ACCESS.2023.3322146},
  ISSN={2169-3536},
  month={},}@ARTICLE{8517125,
  author={Wu, Lin and Wang, Yang and Shao, Ling},
  journal={IEEE Transactions on Image Processing}, 
  title={Cycle-Consistent Deep Generative Hashing for Cross-Modal Retrieval}, 
  year={2019},
  volume={28},
  number={4},
  pages={1602-1612},
  abstract={In this paper, we propose a novel deep generative approach to cross-modal retrieval to learn hash functions in the absence of paired training samples through the cycle consistency loss. Our proposed approach employs adversarial training scheme to learn a couple of hash functions enabling translation between modalities while assuming the underlying semantic relationship. To induce the hash codes with semantics to the input-output pair, cycle consistency loss is further delved into the adversarial training to strengthen the correlation between the inputs and corresponding outputs. Our approach is generative to learn hash functions, such that the learned hash codes can maximally correlate each input-output correspondence and also regenerate the inputs so as to minimize the information loss. The learning to hash embedding is thus performed to jointly optimize the parameters of the hash functions across modalities as well as the associated generative models. Extensive experiments on a variety of large-scale cross-modal data sets demonstrate that our proposed method outperforms the state of the arts.},
  keywords={Semantics;Binary codes;Training;Correlation;Gallium nitride;Data models;Cross-modal retrieval;generative hash;cycle-consistency},
  doi={10.1109/TIP.2018.2878970},
  ISSN={1941-0042},
  month={April},}@ARTICLE{8701425,
  author={Baek, Jae-Yong and Yoo, Yong-Sang and Bae, Seung-Hwan},
  journal={IEEE Access}, 
  title={Adversarial Learning With Knowledge of Image Classification for Improving GANs}, 
  year={2019},
  volume={7},
  number={},
  pages={56591-56605},
  abstract={Generating realistic images with fine details are still challenging due to difficulties of training GANs and mode collapse. To resolve this problem, our main idea is that leveraging the knowledge of an image classification network, which is pre-trained by a large scale dataset (e.g. ImageNet), would improve a GAN. By using the gradient of the network (i.e. discriminator) with high discriminability during training, we can, therefore, guide the gradient of a generator gradually toward the real data region. However, excessive negative feedback of the powerful classifier often prevents a generator from producing diverse images. Based on the main idea, we design a GAN including the added discriminator and propose a novel energy function in order to transfer the pre-trained knowledge to a generator and control the feedback of the added discriminator. We also present an incremental learning method to prevent the density of the generator to be the low-entropy distribution when training our GAN with respect to the energy function. We incorporate our method to DCGAN and demonstrate the ability to enhance the image quality even in high resolution on several datasets compared to DCGAN. In addition, we compare our method with recent GANs for the diversity of generated samples on CIFAR-10 and STL-10 datasets and provide the extensive ablation studies to prove the benefits of our method.},
  keywords={Generative adversarial networks;Generators;Gallium nitride;Training;Image resolution;Learning systems;Data models;Generative adversarial network;image classification network;image generation;generative model;deep learning;convolutional neural network},
  doi={10.1109/ACCESS.2019.2913697},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9362384,
  author={Khivasara, Yash and Khare, Yash and Bhadane, Tejas},
  booktitle={2020 IEEE Pune Section International Conference (PuneCon)}, 
  title={Fake News Detection System using Web-Extension}, 
  year={2020},
  volume={},
  number={},
  pages={119-123},
  abstract={Internet is a supreme one-stop source of information that enables the sharing of news and curated user-content at a rapid, effortless, and in a routine manner. News is a global medium of daily events worldwide, offering absorption of quick information. With ample availability of news content online, these news articles has by-products in information generation in both ways -real and fake news. Considering the context and volume of information shared online, it is challenging to establish authenticity of news. This leads to the immense growth of fake news on various websites, which can lead to serious concerns in society, fading away the correct news content to reach the users creating misconceptions and deceived views of the readers. To ensure the readers have the credibility of the content, we propose a web-based extension enabling them to distinguish from the fake and real news content. The proposed web extension in the paper uses multiple deep learning models. The first is based on our model trained on LSTM, and the other uses OPEN AI's well-developed AI-generated text classifier GPT-2. The devised web-extension displays both probabilities of news being either AI-generated or written by an individual.},
  keywords={Fading channels;Deep learning;IEEE Sections;Conferences;Text categorization;Internet;Artificial intelligence;AI (Artificial Intelligence);Web Extension;LSTM (Long Short-Term Memory);GPT-2 (Generative Pre-trained Transformer)},
  doi={10.1109/PuneCon50868.2020.9362384},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10765263,
  author={Wong, Andrew and Zhao, Yinshu and Baghaei, Nilufar},
  booktitle={2024 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)}, 
  title={Effects of Customizable Intelligent VR Shopping Assistant on Shopping for Stress Relief}, 
  year={2024},
  volume={},
  number={},
  pages={304-308},
  abstract={Shopping has long since been a method of distraction and relieving stress. Virtual Reality (VR) effectively simulates immersive experiences, including shopping through head-mounted displays (HMD), which create an environment through realistic renderings and sounds. Current studies in VR have shown that assistants can support users by reducing stress, indicating their ability to improve mental health within VR. Customization and personalization have also been used to enhance the user experience with users preferring the tailored experience and leading to a greater sense of immersion. There is a gap in knowledge on the effects of customization on a VR assistant’s ability to reduce stress within the VR retailing space. This research aims to identify relationships between customization and shopping assistants within VR to better understand its effects on the user experience. Understanding this will help the development of VR assistants for mental health and consumer-ready VR shopping experiences.},
  keywords={Head-mounted displays;Mental health;Resists;Rendering (computer graphics);User experience;Artificial intelligence;Augmented reality;Virtual reality;virtual shopping assistant;stress;generative artificial intelligence},
  doi={10.1109/ISMAR-Adjunct64951.2024.00069},
  ISSN={2771-1110},
  month={Oct},}@INPROCEEDINGS{10342958,
  author={Chen, Yanwen and Kumar, Ashish and Li, Xin},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Exploring Possibilities of AI-Enabled Image Synthesis and Design in Education}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={We explore the usage of generative artificial intelligence (GAI) for image synthesis and design as learning tools. The emergence of GAI is expected to change the ways architects, designers, and students work by reducing their design cycle, lightening their design load, and providing them with richer and more diverse design ideas. We foresee that in the near future, the field of design work will become increasingly integrated with AI technologies. In this study, we trained a GAI model for image synthesis in a design task and evaluated its effectiveness in education. An experimental setup is scheduled for the coming months to evaluate our design in the context of diverse STEM major students.},
  keywords={Image synthesis;Learning (artificial intelligence);Task analysis;Load modeling;Generative AI;Design;Text2Image},
  doi={10.1109/FIE58773.2023.10342958},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{11140668,
  author={M, Kabilan and S, Logeswaran and S, Kubersrinivash and J, Alfred Daniel},
  booktitle={2025 8th International Conference on Computing Methodologies and Communication (ICCMC)}, 
  title={Advanced Temporal Analysis for Deepfake Detection using XceptionNet in Media Forensics}, 
  year={2025},
  volume={},
  number={},
  pages={1224-1228},
  abstract={Deepfakes videos through advanced AI models, pose a significant threat due to their deceptive realism. This paper presents a deepfake detection framework based on XceptionNet, which provides depthwise separable convolutions for fine-grained image analysis. The proposed system processes both static images and video by detecting and aligning faces, enabling consistent frame-level analysis. Furthermore, for videos, each frame is analyzed using XceptionNet, followed by temporal feature extraction through LSTM and CNN to capture subtle facial expressions and motion variations. The model was evaluated on multiple datasets, achieving strong precision, recall, and F1-scores at both frame and video levels. Results show that the XceptionNet-based approach reliably distinguishes real from manipulated content. However, limitations remain due to dataset diversity and computational complexity, highlighting directions for future research.},
  keywords={Deepfakes;Computational modeling;Forensics;Media;Feature extraction;Real-time systems;Face detection;Computational complexity;Artificial intelligence;Long short term memory;Deepfake Detection;Media Forensics. XceptionNet;Generative Models;Artificial Intelligence;Synthetic Media;Face Detection;Temporal Feature Analysis},
  doi={10.1109/ICCMC65190.2025.11140668},
  ISSN={},
  month={July},}@ARTICLE{10097455,
  author={Girdhar, Mansi and Hong, Junho and Moore, John},
  journal={IEEE Open Journal of Vehicular Technology}, 
  title={Cybersecurity of Autonomous Vehicles: A Systematic Literature Review of Adversarial Attacks and Defense Models}, 
  year={2023},
  volume={4},
  number={},
  pages={417-437},
  abstract={Autonomous driving (AD) has developed tremendously in parallel with the ongoing development and improvement of deep learning (DL) technology. However, the uptake of artificial intelligence (AI) in AD as the core enabling technology raises serious cybersecurity issues. An enhanced attack surface has been spurred on by the rising digitization of vehicles and the integration of AI features. The performance of the autonomous vehicle (AV)-based applications is constrained by the DL models' susceptibility to adversarial attacks despite their great potential. Hence, AI-enabled AVs face numerous security threats, which prevent the large-scale adoption of AVs. Therefore, it becomes crucial to evolve existing cybersecurity practices to deal with risks associated with the increased uptake of AI. Furthermore, putting defense models into practice against adversarial attacks has grown in importance as a field of study amongst researchers. Therefore, this study seeks to provide an overview of the most recent adversarial defensive and attack models developed in the domain of AD.},
  keywords={Artificial intelligence;Accidents;Safety;Autonomous vehicles;Adversarial machine learning;Computer vision;Cyberattack;Deep learning;Autonomous vehicles;artificial intelligence;adversarial machine learning;computer vision;cyber-attacks;cybersecurity;deep learning;defense strategies;tensor perturbations},
  doi={10.1109/OJVT.2023.3265363},
  ISSN={2644-1330},
  month={},}@ARTICLE{10668871,
  author={Yee Por, Lip and Dai, Zhen and Juan Leem, Siew and Chen, Yi and Yang, Jing and Binbeshr, Farid and Yuen Phan, Koo and Soon Ku, Chin},
  journal={IEEE Access}, 
  title={A Systematic Literature Review on AI-Based Methods and Challenges in Detecting Zero-Day Attacks}, 
  year={2024},
  volume={12},
  number={},
  pages={144150-144163},
  abstract={The detection of zero-day attacks remains one of the most critical challenges in cybersecurity. This systematic literature review focuses on the various AI-based methods employed for detecting zero-day attacks, identifying both the strengths and weaknesses of these approaches. By critically evaluating existing literature, this review provides new insights and highlights the gaps that future research must address. The findings suggest that while artificial intelligence, particularly machine learning, offers promising solutions, there are significant challenges related to data availability, algorithmic complexity, and real-time application. This review contributes to the field by providing a comprehensive analysis of current AI-driven methods and proposing future research directions to enhance zero-day attack detection.},
  keywords={Artificial intelligence;Databases;Intrusion detection;Systematics;Search problems;Object recognition;Anomaly detection;Zero-day attack;CrowdStrike;intrusion detection;anomaly detection;machine learning;artificial intelligence;cybersecurity},
  doi={10.1109/ACCESS.2024.3455410},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8982520,
  author={Belhi, Abdelhak and Gasmi, Houssem and Al-Ali, Abdulaziz Khalid and Bouras, Abdelaziz and Foufou, Sebti and Yu, Xi and Zhang, Haiqing},
  booktitle={2019 13th International Conference on Software, Knowledge, Information Management and Applications (SKIMA)}, 
  title={Deep Learning and Cultural Heritage: The CEPROQHA Project Case Study}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  abstract={Cultural heritage takes an important part of the history of humankind as it is one of the most powerful tools for the transfer and preservation of moral identity. As a result, these cultural assets are considered highly valuable and sometimes priceless. Digital technologies provided multiple tools that address challenges related to the promotion and information access in the cultural context. However, the large data collections of cultural information have more potential to add value and address current challenges in this context with the recent progress in artificial intelligence (AI) with deep learning and data mining tools. Through the present paper, we investigate several approaches that are used or can potentially be used to promote, curate, preserve and value cultural heritage through new and evolutionary techniques based on deep learning tools. The deep learning approaches entirely developed by our team are intended to classify and annotate cultural data, complete missing data, or map existing data schemes and information to standardized schemes with language processing tools.},
  keywords={Deep learning;Ethics;Data collection;Software;Information management;Cultural differences;History;Data mining;Artificial intelligence;Cultural Heritage;Digital Heritage;Deep Learning;CEPROQHA Project;Artificial Intelligence},
  doi={10.1109/SKIMA47702.2019.8982520},
  ISSN={2573-3214},
  month={Aug},}@ARTICLE{10798108,
  author={Guo, Shaolong and Wang, Yuntao and Zhang, Ning and Su, Zhou and Luan, Tom H. and Tian, Zhiyi and Shen, Xuemin},
  journal={IEEE Communications Surveys & Tutorials}, 
  title={A Survey on Semantic Communication Networks: Architecture, Security, and Privacy}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={With the rapid advancement and deployment of intelligent agents and artificial general intelligence (AGI), a fundamental challenge for future networks is enabling efficient communications among agents. Unlike traditional human-centric, data-driven communication networks, the primary goal of agent-based communication is to facilitate coordination among agents. Therefore, task comprehension and collaboration become the key objectives of communications, rather than data synchronization. Semantic communication (SemCom) aims to align information and knowledge among agents to expedite task comprehension. While significant research has been conducted on SemCom for two-agent systems, the development of semantic communication networks (SemComNet) for multi-agent systems remains largely unexplored. In this paper, we provide a comprehensive and up-to-date survey of SemComNet, focusing on their fundamentals, security, and privacy aspects. We introduce a novel three-layer architecture for multi-agent interaction, comprising the control layer, semantic transmission layer, and cognitive sensing layer. We explore working modes and enabling technologies, and present a taxonomy of security and privacy threats, along with state-of-the-art defense mechanisms. Finally, we outline future research directions, paving the way toward intelligent, robust, and energy-efficient SemComNet. This survey represents the first comprehensive analysis of SemComNet, offering detailed insights into its core principles as well as associated security and privacy challenges.},
  keywords={Security;Surveys;Privacy;Artificial intelligence;Knowledge based systems;Collaboration;Training;Sensors;Wireless communication;Computer hacking;Semantic communication;artificial intelligence;security;privacy;trust},
  doi={10.1109/COMST.2024.3516819},
  ISSN={1553-877X},
  month={},}@ARTICLE{10438210,
  author={Gogate, Mandar and Dashtipour, Kia and Hussain, Amir},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Robust Real-time Audio-Visual Speech Enhancement based on DNN and GAN}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={The human auditory cortex contextually integrates audio-visual (AV) cues to better understand speech in a cocktail party situation. Recent studies have shown that AV speech enhancement (SE) models can significantly improve speech quality and intelligibility in low signal-to-noise ratios (SNR < −5dB) environments compared to audio-only (A-only) SE models. However, despite substantial research in the area of AV SE, development of real-time processing models that can generalise across various types of visual and acoustic noises remains a formidable technical challenge. This paper introduces a novel framework for low-latency, speaker-independent AV SE. The proposed framework is designed to generalise to visual and acoustic noises encountered in real world settings. In particular, a generative adversarial network (GAN) is proposed to address the issue of visual speech noise including poor lighting in real noisy environments. In addition, a novel real-time AV SE based on a deep neural network is proposed. The model leverages the enhanced visual speech from the GAN to deliver robust SE. The effectiveness of the proposed framework is evaluated on synthetic AV datasets using objective speech quality and intelligibility metrics. Furthermore, subjective listening tests are conducted using real noisy AV corpora. The results demonstrate that the proposed real-time AV SE framework improves the mean opinion score by 20% as compared to state-of-the-art SE approaches including recent DNN based AV SE models.},
  keywords={Visualization;Speech enhancement;Noise measurement;Real-time systems;Lips;Generative adversarial networks;Auditory system;audio-visual;speech enhancement;generative adversarial network},
  doi={10.1109/TAI.2024.3366141},
  ISSN={2691-4581},
  month={},}@ARTICLE{10647114,
  author={Blika, Afroditi and Palmos, Stefanos and Doukas, George and Lamprou, Vangelis and Pelekis, Sotiris and Kontoulis, Michael and Ntanos, Christos and Askounis, Dimitris},
  journal={IEEE Open Journal of the Communications Society}, 
  title={Federated Learning for Enhanced Cybersecurity and Trustworthiness in 5G and 6G Networks: A Comprehensive Survey}, 
  year={2025},
  volume={6},
  number={},
  pages={3094-3130},
  abstract={In the fast-progressing field of wireless communications, the forthcoming 6G networks are expected to revolutionize the way we communicate, offering unparalleled speed, minimal latency, and seamless connectivity. However, amid this evolution, the paramount concern remains the security and privacy of the data traversing these networks. Traditional centralized artificial intelligence (AI) techniques already struggle to keep up with the vast amount of data of future 6G networks and deal with the increasing worries about privacy. Federated learning (FL), emerges as a key enabler of Trustworthy AI (TAI), empowering the engagement of distributed network nodes in AI training without the need for exchanging raw data, thereby mitigating the risks associated with centralized data processing. In this paper, we provide a comprehensive survey on the potential of FL in enhancing the security of 6G networks. Particularly, we begin by providing the necessary background on 5G networks and FL, setting the stage for understanding their current and future implications. We then explore the current state-of-the-art of FL applications within 5G networks and their relevance to the future threat landscape of 6G. Subsequently, we examine the inherent vulnerabilities of FL systems, major attacks against FL in the context of 5G networks, and corresponding defense mechanisms. Finally, we discuss the integration of advanced FL technologies and concepts towards enhanced cybersecurity and privacy in 6G networks, aiming to cover all aspects and future perspectives of FL within the context of the forthcoming 6G threat landscape.},
  keywords={6G mobile communication;Surveys;Wireless communication;Training;Privacy;Data privacy;5G mobile communication;Federated learning;Artificial intelligence;Computer security;5G networks;6G networks;cybersecurity;edge computing;federated learning;trustworthy artificial intelligence},
  doi={10.1109/OJCOMS.2024.3449563},
  ISSN={2644-125X},
  month={},}@INPROCEEDINGS{9643320,
  author={Li, Dan and Liu, Shuang and Lyu, Zhengxin and Xiang, Weilai and He, Wei and Liu, Fengqi and Zhang, Zhen},
  booktitle={2021 IEEE 33rd International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Use mean field theory to train a 200-layer vanilla GAN}, 
  year={2021},
  volume={},
  number={},
  pages={420-426},
  abstract={Training a deep generative adversarial network (GAN) with hundreds or even thousands of layers is difficult. The backpropagation depth of generator is deeper than discriminator, leading it to occur vanishing/exploding gradients easily. This paper proposes a method to train deep vanilla GAN based on mean field theory. By adjusting the parameter variances and activation of the GAN, a 200-layer vanilla GAN can be trained steadily without adding any batch normalization layers or residual blocks. We demonstrate that deep GAN is very sensitive to the parameter variances $\sigma _w^2$ , $\sigma _b^2$ in the initialization scheme, and explain why hard tanh is more suitable than relu as an activation in a deep vanilla GAN. Experiments on the MNIST and Fashion-MNIST data sets validate that our method trains a deep vanilla GAN well and can produce high-quality images.},
  keywords={Training;Image quality;Correlation coefficient;Backpropagation;Conferences;Complex networks;Generative adversarial networks;Mean Field Theory;Generative Adversarial Network;Deep Networks},
  doi={10.1109/ICTAI52525.2021.00068},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{9722628,
  author={Song, Seunghwan and Baek, Jun-Geol},
  booktitle={2022 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Defect Information Synthesis via Latent Mapping Adversarial Networks}, 
  year={2022},
  volume={},
  number={},
  pages={017-022},
  abstract={This research presents a new image synthesis methodology for automated visual inspection (AVI) in steel manufacturing process. We develop a novel methodology, termed Latent Mapping Adversarial Networks. As the end product of the manufacturing process is directly linked to economic factors, various methods are being utilized to improve the quality of the product. Among them, the defect detection steps carried out in advance are important as it greatly impacts productivity. However, new challenges have emerged for several reasons. First, it requires prior knowledge of the expert to define the defect image and perform detection. To alleviate this problem, various companies have started utilizing AVI to reduce this dependence on domain knowledge. Secondly, defect detection is an arduous task since fewer defect images are available compared to normal images. This underlying problem leads to a classification model that is biased toward the majority class, which degrades the final performance. In this paper, we propose a method to synthesize defect images to solve the above-mentioned problems. Inspired by StyleGAN, we build mapping networks for latent space of the generator. Through this, we can synthesize defect images of various sizes in the manufacturing process. In addition, we experiment to find the most suitable loss function to solve the common problems of Generative Adversarial Networks (GAN). We also optimized the proposed method in terms of convergence and computation speed by estimating the size of optimal latent space. The experimental results using quantitative metrics illustrate the improved performance of the proposed methodology. As a result, it is now possible to solve the quality problem and increase productivity by reducing misclassification in the model through AVI experiments using the generated images},
  keywords={Productivity;Measurement;Visualization;Manufacturing processes;Image synthesis;Inspection;Generative adversarial networks;Automated visual inspection;generative adversarial networks;latent mapping;mapping network;synthesize defect},
  doi={10.1109/ICAIIC54071.2022.9722628},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10512186,
  author={Gagneja, Shivangi and Kaur, Bhavneet and Gupta, Ruchika and Kumar, Vaneet},
  booktitle={2024 3rd International Conference for Innovation in Technology (INOCON)}, 
  title={Deep Learning and AI for Alzheimer’s Disease Prediction}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Alzheimer disease (AD) is a degenerative condition of the nervous system that affects both cognition and memory. Early detection and prognosis of the illness are essential for effective disease management and therapy.Alzheimer’s disease is usually difficult to detect and can only be definitively identified post-mortem by study of brain tissue. Despite the importance of early diagnosis and treatment for improving patient outcomes, this illness is frequently difficult to identify. Alzheimer’s disease is diagnosed using a combination of clinical evaluation, cognitive testing, and neuroimaging techniques including MRI and PET scans. In this study, we offer a prediction model for Alzheimer’s disease on which Convolutional Neural Networks (CNN) are trained for deep learning (DL) and artificial intelligence (AI) technologies. Deep learning recognises and categorises AD based on criteria including growth, lifestyle, pace, and size. In medical science, both picture and text-based report-based data may have impurities such differing size, alignment, or consistency that lead to biased study results and complicated prediction and analysis. As an outcome, using CNN and Random Forest in a Python laboratory setting increases prediction accuracy to 86.91},
  keywords={Deep learning;Neuroimaging;Technological innovation;Predictive models;Convolutional neural networks;Alzheimer's disease;Artificial intelligence;Alzheimer Disease;Artificial Intelligence;Brain Disease;CNN;Deep Learning;MRI},
  doi={10.1109/INOCON60754.2024.10512186},
  ISSN={},
  month={March},}@INPROCEEDINGS{10536243,
  author={Rozo-Torres, Alexander and Sarmiento, Wilson J.},
  booktitle={2024 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, 
  title={Coffee Masterclass: An Experience of Co-Creation with Prompt Engineering and Generative AI for Immersive Environments Development}, 
  year={2024},
  volume={},
  number={},
  pages={1170-1171},
  abstract={This work presents the design and development process of an immersive experience applying a co-creation approach between humans and generative artificial intelligence tools. From the point of view of any user, Coffee Masterclass is an immersive experience that brings anyone to the art and pleasure of preparing specialty coffees. However, the Coffee Masterclass is the result of the inclusion of prompt engineering outputs in each stage of the building process. The co-creation approach is included in all development processes, i.e., from the narrative to the visual content generated through code writing, which has been co-created between the creative team and GenAI. This work tells details of this approach, including how the generative artificial intelligence tools were used in each stage of immersive experience development. This work shows the advantage of involvement in a development team of people with skills in prompt engineering and interaction with Large Language Models. Also, it includes recommendations to other development teams, including generative artificial intelligence tools by future developments.},
  keywords={Visualization;Three-dimensional displays;Codes;Art;Conferences;Buildings;Immersive experience;Computing methodologies-Computer graphics-Graphics systems and interfaces-Mixed/augmented reality},
  doi={10.1109/VRW62533.2024.00379},
  ISSN={},
  month={March},}@INPROCEEDINGS{10041324,
  author={Wadekar, Suhrid A.},
  booktitle={2023 15th International Conference on COMmunication Systems & NETworkS (COMSNETS)}, 
  title={A Push-Pull Train for Safety of Autonomous Vehicle Software}, 
  year={2023},
  volume={},
  number={},
  pages={287-294},
  abstract={A new software engineering framework is provided for assessing and enhancing the safety of artificial-intelligence (AI) based software for controlling autonomous vehicles. The new framework is based on specifying and sharing datasets used for training AI-based systems.},
  keywords={Training;Software;Safety;Artificial intelligence;Autonomous vehicles;Software engineering;autonomous vehicle;artificial intelligence;software engineering;safety},
  doi={10.1109/COMSNETS56262.2023.10041324},
  ISSN={2155-2509},
  month={Jan},}@INPROCEEDINGS{10574621,
  author={Rochana, B Sheryl and Juliet, Sujitha},
  booktitle={2024 3rd International Conference on Artificial Intelligence For Internet of Things (AIIoT)}, 
  title={Virtual Dress Trials: Leveraging GANs for Realistic Clothing Simulation}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={As a result of technological developments, the fashion industry has seen a dramatic move towards digitization. A virtual dress trial driven by Generative Adversarial Networks (GANs), an advanced size suggestion system, with chat support is proposed in this work. Clothing and a plethora of accessories are part of our fashion collection. Through a safe online store, customers may make selections, and complete purchases. The size recommendation system enhances shopping precision. Chat assistance are AI-driven chatbots to help customers, enhancing user engagement and support. Users may also rate and review items, which helps build trust. Data protection and payment processing are our top priorities. Collaboration with other e-commerce businesses is a possibility presented, which serves the interests of fashion-conscious customers. This one-stop shopping platform changes the game for discovering, trying on, and buying clothing.},
  keywords={Training;Reviews;Computational modeling;Scalability;Clothing;Training data;Generative adversarial networks;virtual dress trial;generative adversarial networks (GANs);clothing segmentation;garment synthesis;conditional GAN;virtual try-on;fabric textures;online shopping;fashion design},
  doi={10.1109/AIIoT58432.2024.10574621},
  ISSN={},
  month={May},}@ARTICLE{11172285,
  author={Verma, Kavya and Mittal, Divyanshi and Samanta, Sagnik and Gulati, Kabir and Kulkarni, Ojas and Dar, Muzaffar Ahmad and Biji, C. L.},
  journal={IEEE Access}, 
  title={Deepfake Audio Detection: A Comparative Study of Advanced Deep Learning Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={The rapid advancements in artificial intelligence (AI) have significantly enhanced audio synthesis capabilities, enabling deepfake technology to replicate human speech with near-perfect accuracy. This poses severe security threats to various domains, including banking, customer service, and law enforcement, as malicious actors can exploit speech synthesis techniques such as voice conversion, replay attacks, and text-to-speech (TTS) to manipulate or impersonate individuals. Both spectral and temporal features were extracted from the audio recordings for feature extraction. This paper explores state-of-the-art detection frameworks for deepfake audio, highlighting the effectiveness of advanced deep learning (DL) frameworks. Specifically, the performance of the bidirectional long short-term memory (BLSTM) network, a custom convolutional neural network (CNN), a residual CNN integrated with an attention mechanism and bidirectional gated recurrent unit (ResCNN-Attention-BGRU), WIREnet (a variant of BLSTM), the residual network for fully connected (ResNet FC), and a squeeze-and-excitation-enhanced one-dimensional CNN (SE-Enhanced 1D-CNN) were compared. The proposed models achieved notable testing accuracies, with SE-Enhanced 1D-CNN reaching the highest at 97.64%, followed by ResNet FC (97.46%) and WIREnet (97.20%), demonstrating strong generalization across the evaluated architectures. Furthermore, we experimented with different numbers of mel-frequency cepstral coefficients (MFCCs), specifically 13, 26, and 39, in combination with other spectral and temporal features. The experimental results demonstrated that MFCC-39, together with spectral and temporal features, had a robust feature representation and achieved the best performance for deepfake detection.},
  keywords={Deepfakes;Feature extraction;Accuracy;Benchmark testing;Artificial intelligence;Security;Convolutional neural networks;Computer architecture;Transfer learning;Deep learning;Deepfake audio;Artificial Intelligence;Convolutional Neural Network;Mel-frequency Cepstral Coefficients;SE-Enhanced 1D-CNN Bidirectional Long Short-term Memory Network},
  doi={10.1109/ACCESS.2025.3611839},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11019936,
  author={Mohaamed Salman, A. and Sivasakthi, T. and Brindha, S and Suresh kumar, M},
  booktitle={2025 International Conference on Computing and Communication Technologies (ICCCT)}, 
  title={Cardiac Signal Regeneration Using Regenerative AI}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Cardiac signal regeneration represents an innovative approach that leverages artificial intelligence (AI) to delve into the intricate electrical signals produced by the heart. These signals, measured in electrocardiograms (ECGs), hold invaluable insights into cardiac health and function. Through advanced AI algorithms, it's now possible to analyse ECGs more deeply, revealing patterns, abnormalities, and biomarkers that might otherwise go undetected. The goal of cardiac signal regeneration is to identify signs of cardiac damage early on and to monitor the heart's capacity for regeneration or recovery over time. By recognizing specific patterns associated with various stages of cardiac health, AI systems can provide more precise and personalized insights into a patient's condition. This level of detail enables physicians to make more informed treatment decisions, potentially catching issues before they become critical and adjusting treatment strategies to improve patient outcomes. This AI-driven approach could revolutionize how cardiac diseases are diagnosed, treated, and managed. With the potential to predict risks and detect changes in cardiac health long before they manifest clinically, cardiac signal regeneration offers hope for preventive care. It could help clinicians tailor interventions and monitor recovery more effectively, making cardiac healthcare more proactive and less reactive. As research and development in this area progress, cardiac signal regeneration may transform heart disease treatment, potentially reducing hospitalizations and healthcare costs while saving countless lives. The promise of this technology lies not only in improved survival rates but also in enhanced quality of life for millions of individuals suffering from cardiac conditions worldwide. The classification model demonstrates high accuracy across all heartbeat classes, with accuracies ranging from 93.85% to 99.16%, indicating its effectiveness in detecting and classifying diverse arrhythmia types.},
  keywords={Heart;Accuracy;Medical services;Transforms;Electrocardiography;Pattern recognition;Artificial intelligence;Biomedical monitoring;Monitoring;Research and development;Regenerative AI;Cardiac Signal Regeneration;Electro Cardiogram;Deep learning;Artificial Intelligence},
  doi={10.1109/ICCCT63501.2025.11019936},
  ISSN={2995-3197},
  month={April},}@INPROCEEDINGS{10575829,
  author={Kadam, Shubhan and Jani, Jay and Kudtarkar, Aniket and Mulla, Nikahat},
  booktitle={2024 3rd International Conference on Applied Artificial Intelligence and Computing (ICAAIC)}, 
  title={A Comparative Analysis of DCGAN and WGAN in Logo Generation}, 
  year={2024},
  volume={},
  number={},
  pages={1217-1226},
  abstract={This research paper explores the impact of Generative Adversarial Networks (GANs) on logo generation, focusing on three variants: Deep Convolutional GAN (DCGAN), Wasserstein GAN (WGAN), and Conditional GAN (cGAN). The study evaluates their strengths and weaknesses, aiming to contribute insights to the ongoing discourse on GANs. Results indicate that DCGAN excels in capturing fine details but faces mode collapse, limiting diversity, while WGAN demonstrates enhanced training stability, consistently delivering diverse and visually appealing logos. Numerical results reveal a mean rating of 3.173/5 across sample sets, with approximately 14/64 images deemed useful, resulting in a usability rating of 2.2/10. The survey findings, based on assessments from 57 participants, consistently rate DCGAN-generated images slightly higher in terms of visual appeal and usage preferences compared to those produced by WGAN. While DCGAN exhibits superior image quality, WGAN offers more variety. This suggests a trade-off between variety and image quality, underscoring the specific strengths of each model in meeting subjective criteria for visual excellence.},
  keywords={Training;Image quality;Surveys;Visualization;Stability criteria;Generative adversarial networks;Reliability;Generative Adversarial Networks (GANs);Logo Generation;Deep Convolutional GAN (DCGAN);Wasserstein GAN (WGAN);Conditional GAN (cGAN);Wasserstein Distance Metric;Qualitative Analysis;Image Quality Assessment},
  doi={10.1109/ICAAIC60222.2024.10575829},
  ISSN={},
  month={June},}@INPROCEEDINGS{10859422,
  author={Anjanamma, C. and Sirisha, G. and Sravani, B. and Shilpa, K. and Lakshmi Narayana, C V and Vivekanandhan, V.},
  booktitle={2024 9th International Conference on Communication and Electronics Systems (ICCES)}, 
  title={Personalized Food Nutrient Recommendations for Kids using AI and Behavior Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1805-1810},
  abstract={This article introduces a custom-made dietary recommendation system for children that harnesses artificial intelligence (AI) and the Internet of Medical Things (IoMT) to provide adaptable, context-sensitive nutrition plans. It integrates a Decision Tree-based Nutritional Assessment, employs Reinforcement Learning (RL) for dietary modification, and incorporates a Context-Aware Recommendation Model to flexibly modify dietary advice based on individual health profiles and environmental variables such as ambient weather. Constructed using Python and evaluated on a robust computing platform featuring IoT-enabled wearables for real-time monitoring of calorie intake, the model exhibited notable advancements over pre-existing methods, achieving 92% accuracy, 90% precision, 91% recall, and an F1-score of 91%. These metrics affirm its effectiveness in providing pertinent dietary guidance. During a 30-day evaluation, compliance with diet plans rose from 75% to 90%, in contrast to other models with a top adherence of 85%. Furthermore, the context-aware feature of the model offered efficient caloric adjustments that boosted adherence by 10% in cooler climates compared to models lacking contextual inputs. User satisfaction surveys revealed that 80% of participants reported being “Very Satisfied” or “Satisfied,” illustrating the system's versatility and user-oriented approach. These results suggest the model's significant promise for real-world utilization in personalized child nutrition, enhancing dietary compliance, precision, and user involvement by fusion of context-driven modifications and RL.},
  keywords={Measurement;Pediatrics;Adaptation models;Accuracy;Computational modeling;Reinforcement learning;Decision trees;Artificial intelligence;Context modeling;Meteorology;Personalized Nutrition;Dietary Recommendation System;Artificial Intelligence;Reinforcement Learning;Internet of Medical Things (IoMT)},
  doi={10.1109/ICCES63552.2024.10859422},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11099896,
  author={Zhang, Pan and Zheng, Baofeng and Ding, Hongbi and Ruan, Jun},
  booktitle={2025 4th International Conference on Electronics, Integrated Circuits and Communication Technology (EICCT)}, 
  title={Cybersecurity: Challenges, Technologies and Future Trends}, 
  year={2025},
  volume={},
  number={},
  pages={485-489},
  abstract={This article comprehensively explores the core issues, key technologies, and future development directions in the field of cybersecurity. With the acceleration of the digitalization process, cybersecurity has become a global focus of attention.The article first analyzes the current situation and challenges of cybersecurity, including the evolution of the threat landscape, the diversification of attack types, and the vulnerability of the defense system. Subsequently, it conducts an in-depth study of the key technical system of cybersecurity, covering aspects such as encryption technology, identity authentication, intrusion detection, and blockchain applications.The article further explores the impact of emerging technologies such as artificial intelligence, the Internet of Things, and quantum computing on cybersecurity, and proposes corresponding defense strategies.Finally, it looks ahead to the future development trends of cybersecurity and emphasizes the importance of talent cultivation and international cooperation. This research provides theoretical references and practical guidance for building a more secure cyber environment.},
  keywords={Security management;Intrusion detection;Authentication;Market research;Encryption;Blockchains;Internet of Things;Risk management;Computer security;Artificial intelligence;encryption technology;intrusion detection;risk management;artificial intelligence;internet of things security},
  doi={10.1109/EICCT65471.2025.11099896},
  ISSN={},
  month={July},}@INPROCEEDINGS{10878209,
  author={Al Bashaireh, Rasha},
  booktitle={2024 IEEE International Conference on Technology Management, Operations and Decisions (ICTMOD)}, 
  title={Environmental Change Detection During Route-Clearance Operation via Autonomous Vehicle (AV): A Proposed AI-Based Approach}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Autonomous Vehicles (AV) are capable of performing tasks without human intervention and assistance. They serve prominently in tasks that pose a significant risk to humans, especially in outdoor environment exploration. It's essential to save humans‘ lives and prevent them from outdoor roads dangerous factors such as mines, explosives, and ammunition. However, there is a need to design a system that can identify objects ahead of and detect them continuously in a real-time setting during AV driving in a route-clearance operation in urban cities. This assists the AV in identifying danger factors early through the environmental change detection process. Since the change in the dynamic scenes of the environment is still of interest to scientists, therefore, this paper proposes an idea of a practical approach based on Artificial Intelligence (AI) techniques for environmental change detection and avoidance of dangerous factors by AV during a route-clearance operation. The suggested approach aims to develop a comprehensive real-time change detection system ensuring the AV's immediate avoidance of danger factors in the explored environment. Where an operator inside the AV classifies the detected changes and assesses whether they pose a threat. This proposal presents a potentially vital solution for detecting change and danger factors by AVs, highlighting the immediate need to understand and respond to the changes in our environment in real-time settings under multiple road patterns, weather conditions, and illuminations.},
  keywords={Technology management;Roads;Urban areas;Real-time systems;Proposals;Object recognition;Artificial intelligence;Vehicle dynamics;Autonomous vehicles;Robots;Robotics;Autonomous Vehicles;Artificial Intelligence;Computer Vision;Change Detection},
  doi={10.1109/ICTMOD63116.2024.10878209},
  ISSN={2159-5119},
  month={Nov},}@INPROCEEDINGS{9175531,
  author={Yin, Yehang and Chen, Zewen and Zhao, Yanji and Li, Jiongqi and Zhang, Kejun},
  booktitle={2020 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)}, 
  title={Automated Chinese Seal Carving Art Creation with AI Assistance}, 
  year={2020},
  volume={},
  number={},
  pages={394-395},
  abstract={Artificial intelligence is providing new possibilities for pre-serving and reviving traditional arts and crafts. Here we present a method to automate the creation of seal carving artworks with deep learning generated glyphs, an interactive user interface for seal design, and fast mechanical engraving to turn the design into a physical entity. People with no prior experience of seal carving created personalized Han-dynasty-style seals using the interface we developed. Our method allows novices to be engaged in the creative design of Chinese seals and greatly improve the efficiency of the seal carving process, which used to be time-consuming and require high expertise.},
  keywords={Seals;Art;Graphical user interfaces;Gallium nitride;Generative adversarial networks;Numerical models;Artificial intelligence;AI-aided art;Deep learning;GAN;Chinese seal carving},
  doi={10.1109/MIPR49039.2020.00086},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10459760,
  author={Wang, Jingjing and Luo, Joshua and Yang, Grace and Hong, Allen and Luo, Feng},
  booktitle={2023 International Conference on Machine Learning and Applications (ICMLA)}, 
  title={Is GPT Powerful Enough to Analyze the Emotions of Memes?}, 
  year={2023},
  volume={},
  number={},
  pages={1338-1343},
  abstract={Large Language Models (LLMs), representing a significant achievement in artificial intelligence (AI) research, have demonstrated their ability in a multitude of tasks. This project aims to explore the capabilities of GPT-3.5, a leading example of LLMs, in processing the sentiment analysis of Internet memes. Memes, which include both verbal and visual aspects, act as a powerful yet complex tool for expressing ideas and sentiments, demanding an understanding of societal norms and cultural contexts. Notably, the detection and moderation of hateful memes pose a significant challenge due to their implicit offensive nature. This project investigates GPT's proficiency in such subjective tasks, revealing its strengths and potential limitations. The tasks include the classification of meme sentiment, determination of humor type, and detection of implicit hate in memes. The performance evaluation, using datasets from SemEval-2020 Task 8 and Facebook hateful memes, offers a comparative understanding of GPT responses against human annotations. Despite GPT's remarkable progress, our findings underscore the challenges faced by these models in handling subjective tasks, which are rooted in their inherent limitations including contextual understanding, interpretation of implicit meanings, and data biases. This research contributes to the broader discourse on the applicability of AI in handling complex, context-dependent tasks, and offers valuable insights for future advancements.},
  keywords={Performance evaluation;Visualization;Sentiment analysis;Social networking (online);Machine learning;Data models;Internet;memotion analysis;hateful memes detection;GPT model},
  doi={10.1109/ICMLA58977.2023.00202},
  ISSN={1946-0759},
  month={Dec},}@INPROCEEDINGS{10607369,
  author={Samad, A. and Izani, M. and Abdulla, D. and Faiz, M. and Wadood, R. and Hamdan, A.},
  booktitle={2024 IEEE Symposium on Industrial Electronics & Applications (ISIEA)}, 
  title={Innovative Workflow for AI-Generated Video: Addressing Limitations, Impact and Implications}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={The integration of artificial intelligence (AI) into video production has ushered in an era of significant transformation within the media landscape. This paper presents an in-depth analysis of AI-driven video generation, with a specific focus on the SORA platform, to illuminate the present capabilities, limitations, and future prospects of this emergent technology. Our study synthesizes expert discussions, developmental forums, and experimental assessments using text-to-video generation tools to elucidate the current state and trajectory of AI's role in video production. We identify a set of comprehensive best practices for maximizing the utility of AI-generated video content while mitigating the associated risks and challenges. Our findings reveal a striking potential for AI in enhancing the efficiency of content creation, the democratization of media production, and the realization of novel creative visions. However, the research also underscores critical concerns such as the preservation of authenticity, management of biases, and safeguarding against ethical misuse. Through this exploration, we aim to contribute a robust framework for integrating AI within traditional filmmaking workflows, thereby advancing the discourse on AI's implications for the creative industry. The proposed framework advocates for a human-centered approach to AI deployment, emphasizing ethical considerations and the imperative of maintaining the human essence within the storytelling art form. This paper seeks to provide a pivotal resource for filmmakers, content creators, and technologists as they navigate the evolving confluence of AI capabilities and creative aspirations.},
  keywords={Ethics;Visualization;Navigation;Semantics;Production;Media;Trajectory;AI-generated video;SORA;filmmaking;video production;text-to-video technology;ethical considerations;media democratization},
  doi={10.1109/ISIEA61920.2024.10607369},
  ISSN={2472-7660},
  month={July},}@ARTICLE{11106721,
  author={Xue, Hui and An, Yuexuan and Qin, Yongchun and Li, Wenqian and Wu, Yixin and Che, Yongjuan and Fang, Pengfei and Zhang, Min-Ling},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Towards Few-Shot Learning in the Open World: A Review and Beyond}, 
  year={2025},
  volume={},
  number={},
  pages={1-20},
  abstract={Human intelligence is characterized by our ability to absorb and apply knowledge from the world around us, especially in rapidly acquiring new concepts from minimal examples, underpinned by prior knowledge. Few-shot learning (FSL) aims to mimic this capacity by enabling significant generalizations and transferability. However, traditional FSL frameworks often rely on assumptions of clean, complete, and static data, conditions that are seldom met in real-world environments. Such assumptions falter in the inherently uncertain, incomplete, and dynamic contexts of the open world. This paper presents a comprehensive review of recent advancements designed to adapt FSL to open-world environments. We categorize existing methods into three distinct types of FSL in the open world: those involving varying instances, varying classes, and varying distributions. Each category is discussed in terms of its specific challenges and methods, as well as its strengths and weaknesses. We standardize experimental settings and metric benchmarks across scenarios and provide a comparative analysis of the performance of various methods. In conclusion, we outline potential future research directions for this evolving field. It is our hope that this review will catalyze further development of effective solutions to these complex challenges, thereby advancing the field of artificial intelligence.},
  keywords={Noise measurement;Few shot learning;Training;Reviews;Noise;Adaptation models;Uncertainty;Surveys;Optimization;Incremental learning;Few-Shot Learning;Open World;Few-Shot Learning with Varying Instances;Few-Shot Learning with Varying Classes;Few-Shot Learning with Varying Distributions},
  doi={10.1109/TPAMI.2025.3594686},
  ISSN={1939-3539},
  month={},}@INPROCEEDINGS{10851751,
  author={El Husseini, Fatema and Noura, Hassan and Salman, Ola and Chehab, Ali},
  booktitle={2024 8th Cyber Security in Networking Conference (CSNet)}, 
  title={Advanced Machine Learning Approaches for Zero-Day Attack Detection: A Review}, 
  year={2024},
  volume={},
  number={},
  pages={297-304},
  abstract={Zero-day attacks provide an essential challenge in cybersecurity because of their unpredictability and absence of pre-existing defenses. To detect these threats, this paper thor-oughly examines machine learning (ML) and artificial intelligence (AI) methodologies, encompassing supervised, unsupervised, and hybrid models. It underscores the capabilities of modern AI technologies, including deep learning, federated learning, and lightweight AI models, especially in real-time detection and resource-constrained environments. The research highlights the considerable deficiencies in the availability and uniformity of zero-day datasets, discusses the advantages and limitations of ML-based detection methods, and proposes directions for future inquiry, such as adversarial learning, privacy-preserving strategies, and the enhancement of real-time detection. The results intend to assist researchers and practitioners in formulating more resilient, scalable approaches to address zero-day vulnerabilities.},
  keywords={Deep learning;Reviews;Federated learning;Real-time systems;Adversarial machine learning;Computer crime;Zero-day attacks;supervised learning;unsupervised learning;hybrid learning;deep learning;federated learning;adversarial machine learning;lightweight AI models;real-time detection;resource-constrained environments;zero-day datasets;privacy-preserving methodologies;security strategies},
  doi={10.1109/CSNet64211.2024.10851751},
  ISSN={2768-0029},
  month={Dec},}@INPROCEEDINGS{10968102,
  author={Chandra, Joydeep and Kaur, Ramanjot and Sahay, Rashi},
  booktitle={2025 IEEE 14th International Conference on Communication Systems and Network Technologies (CSNT)}, 
  title={Integrated Framework for Equitable Healthcare AI: Bias Mitigation, Community Participation, and Regulatory Governance}, 
  year={2025},
  volume={},
  number={},
  pages={819-825},
  abstract={Artificial intelligence (AI) has revolutionized healthcare by enhancing diagnostic precision, personalizing treatments, and optimizing clinical workflows. However, algorithmic biases arising from imbalanced training data dis-proportionately affect marginalized populations, perpetuating health disparities. For instance, a widely-used predictive model underprioritized Black patients by equating healthcare costs with illness severity, restricting access to essential care. To address these challenges, this paper introduces an integrated framework combining adversarial debiasing, reinforcement learning (RL)-driven threshold optimization, synthetic data augmentation, and community engagement strategies. Empirical evaluations using the MIMIC-III dataset demonstrate near-perfect Area Under the ROC Curve (AUC = 0.994) alongside significant reductions in demographic parity (DP = 0.000) and error rate differences across subgroups. While the RL-optimized threshold ensures no missed diagnoses, it increases false positives, highlighting the trade-offs between fairness and precision. This work underscores the importance of synthesizing technical, regulatory, and community-driven approaches to promote equitable AI deployments. By embedding participatory design principles and aligning with emerging governance frameworks like the European Union’s AI Act, the proposed methodology offers a scalable pathway toward transparent, accountable, and high-impact healthcare AI solutions.},
  keywords={Ethics;Prevention and mitigation;Training data;Medical services;Reinforcement learning;Prediction algorithms;Optimization;Standards;Synthetic data;Guidelines;Healthcare AI;Bias;Fairness Metrics;Reinforcement Learning(RL);Threshold Optimization;Synthetic Data Augmentation;Demographic Parity;Predictive Equity;Community Engagement;Regulatory Governance},
  doi={10.1109/CSNT64827.2025.10968102},
  ISSN={2473-5655},
  month={March},}@INBOOK{10950555,
  author={Bainey, Kristian},
  booktitle={AI-Driven Project Management: Harnessing the Power of Artificial Intelligence and ChatGPT to Achieve Peak Productivity and Success}, 
  title={Introducing ChatGPT: The AI Revolution in Project Management}, 
  year={2024},
  volume={},
  number={},
  pages={3-8},
  abstract={Summary <p>This chapter explores the essence of ChatGPT: what it is, how to access it, and why every modern project manager should grasp its potential and utilize it. Project managers face challenges every day, but with these challenges come great opportunities for innovation and growth through generative artificial intelligence tools like ChatGPT. This introduction presents an overview of the key concepts discussed in the subsequent chapters of this book. The book gives an overview of the foundation, laying the groundwork by emphasizing the revolutionary features of ChatGPT as well as impacts and relevant ethical issues relating to project management&#x2010;artificial Intelligence (PM&#x2010;AI). It offers a deep look into practical applications using ChatGPT for accurate project forecasting, professional development, and blending human interaction for PM&#x2010;AI. The book introduces PM&#x2010;AI modality model, which integrates AI technologies like large language models and prompt engineering.</p>},
  keywords={Chatbots;Artificial intelligence;Project management;Decision making;Translation;Time factors;Productivity;Planning;Data analysis;Uniform resource locators},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394232239},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10950555},}@INPROCEEDINGS{10791124,
  author={Marthana Yusa, I Made and Adi Sudi Anggara, I Gede and Darma Yasa, Ngakan Putu and Novitasari, Dwi and Widhi Adnyana, I Nyoman},
  booktitle={2024 IEEE International Symposium on Consumer Technology (ISCT)}, 
  title={Exploring AI Applications in Digital Art Creation of Hanoman Balinese Dance Animation}, 
  year={2024},
  volume={},
  number={},
  pages={191-197},
  abstract={This paper examines the integration of Artificial Intelligence (AI) in the digital creation of Balinese dance animations, with a specific focus on the Hanoman dance character as the case study. Hanoman dance as a part of Balinese dance, known for its intricate movements, unique costume and cultural significance, presents a unique challenge for digital artists. AI technologies, such as machine learning and computer vision, offer novel approaches to capturing and animating these complex dance forms. This study examines current AI applications in this domain, assesses their effectiveness, and discusses the potential advancements and limitations. Through the use of rotoscoping and motion capture techniques, this study adeptly examines the intricate movements of the Hanoman dance, an integral part of Balinese dance heritage, employing text-to-animation and AI models for video footage motion capture. The thorough processes of data collection, preprocessing, and model training emphasized in the study highlight the necessity of a meticulous methodology. Furthermore, incorporating expert feedback during the validation and refinement phases ensures that the digital representations are both authentic and expressive. The study concludes that AI technologies can play a crucial role in preserving Balinese dance, offering educational tools and digital archives that uphold the cultural integrity of this traditional art form.},
  keywords={Training;Computer vision;Computational modeling;Digital representation;Machine learning;Data collection;Animation;Motion capture;Data models;Cultural differences;AI Application;Digital Art Creation;Hanoman Balinese Dance;Animation},
  doi={10.1109/ISCT62336.2024.10791124},
  ISSN={2159-1423},
  month={Aug},}@INPROCEEDINGS{10737576,
  author={Beke, Eva and Hanka, László},
  booktitle={2024 IEEE 22nd Jubilee International Symposium on Intelligent Systems and Informatics (SISY)}, 
  title={The Prediction of Global Spending Trends on Security Using Holt-Winters Model}, 
  year={2024},
  volume={},
  number={},
  pages={000357-000362},
  abstract={Over the years, threat actors have grown in their capabilities and diversified in their attack methods, increasing the ingenuity and pervasiveness of their threats. The massive data generation in modern-day digital interactions has enabled cyber security teams to amass large data to hand over to machine learning models for discerning patterns. As artificial intelligence (AI) becomes increasingly integrated into security frameworks, organizations face the dual challenge of mitigating AI-related threats while optimizing their security expenditure. This research delves into the complexities involved in managing these risks effectively. It explores the impact of emerging AI threats within cybersecurity landscapes and other relevant fields. It discusses the critical importance of efficiently forecasting the growth of allocated resources to bolster security measures. By emphasizing a balanced approach, this paper aims to provide insights into the intricate interplay between AI threats and security spending, offering a forecasting mathematical model to navigate this dynamic landscape in the future.},
  keywords={Training;Data privacy;Face recognition;Time series analysis;Predictive models;Market research;Mathematical models;Data models;Forecasting;Computer crime;cyber threats;cybersecurity;Holt-Winters time series forecasting model;global spending on security},
  doi={10.1109/SISY62279.2024.10737576},
  ISSN={1949-0488},
  month={Sep.},}@INPROCEEDINGS{9022422,
  author={Zhou, Aven Le},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)}, 
  title={Walking Through Shanshui: Generating Chinese Shanshui Paintings via Real-Time Tracking of Human Position}, 
  year={2019},
  volume={},
  number={},
  pages={3185-3188},
  abstract={Shanshui is a traditional East Asian style of ink brush painting that depicts natural landscapes in a semi-abstract fashion. To create a Shanshui painting, ancient Chinese scholar-artists rely heavily on their travel experiences as well as their movements in natural spaces. In this paper, we propose an interactive system - "Walking Through Shanshui" - based on AI using Generative Adversarial Networks and various computer vision techniques. The system is an interactive art installation that helps bring the original experience of creating Shanshui to participants by tracking their movement through walking in a virtual space. It uses position tracking as input to generate Shanshui from participant's movements and to paint with a custom generative Sketch-to-Shanshui translation model. The system detects the participant's position in real-time and automatically traces it to generate a Shanshui painting instantly.},
  keywords={Painting;Artificial intelligence;Art;Real-time systems;Legged locomotion;Tracking;TV;AI Art;Chinese Heritage;Shanshui;Generative Machine Learning;Generative Art;Interactive Installation;Custom Data Set},
  doi={10.1109/ICCVW.2019.00395},
  ISSN={2473-9944},
  month={Oct},}@INPROCEEDINGS{10212359,
  author={Kumar Sharma, Parveen and Singla, Parveen and Gupta, Vikas and Paras and Garg, Priyanka},
  booktitle={2023 2nd International Conference on Edge Computing and Applications (ICECAA)}, 
  title={An Era of ChatGPT: Systematic Analysis of Utility and Challenges}, 
  year={2023},
  volume={},
  number={},
  pages={897-902},
  abstract={Modern Artificial Intelligence (AI) algorithms are used by ChatGPT (Generative Pre-trained Transformer), a ground-breaking technology, to produce natural language answers to input or prompts. It has been applied in a variety of industries, including content development, customer support, and natural language processing. With the increase in the growth of AI technology, the company like OpenAI created the chatGPT prototype which is used as chatting machine. ChatGPT has several limitations even if it is wonderful and creates interesting stories, poems, songs, essays, and other writing. The bot will respond to queries from users with relevant, persuasive subjects and arguments. Here in this work, a brief introduction about chatGPT like how it came, what are the opportunities, various applications, implementing issues, and future is presented. A variety of chatGPT tools and software used is also analyzed.},
  keywords={Training;Ethics;Systematics;Oral communication;Transforms;Writing;Chatbots;Artificial Intelligence;OpenAI;ChatGPT;Chatbot;Natural Language;Model},
  doi={10.1109/ICECAA58104.2023.10212359},
  ISSN={},
  month={July},}@INPROCEEDINGS{10988462,
  author={Kim, Taesoo and Yoon, Jiwon and Choi, Seonguk and Kim, Haeyeon and Suh, Haeseok and An, Hyunjun and Ahn, Jungmin and Park, Hyunah and Kim, Joungho},
  booktitle={2024 IEEE Electrical Design of Advanced Packaging and Systems (EDAPS)}, 
  title={Design and Analysis of Twin Tower High Bandwidth Memory (HBM) Architecture for Large Memory Capacity and High Bandwidth System}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={The rapid advancement of AI, driven by generative AI based on transformer models, demands memory systems with higher capacity and bandwidth, yet current HBM technologies face scaling limitations due to architectural and manufacturing constraints. To address this, we propose the twin tower HBM architecture, integrating two DRAM stacks on a single, elongated base die to double memory capacity and enhance bandwidth. The extended base die also allows for architectural flexibility, including the integration of near-memory computing units. Supporting up to 12 DRAM stacks per GPU, this architecture achieves 576 GB capacity and 1,638 GB/s bandwidth—a 27.9% improvement over HBM3e—while maintaining robust signal integrity through optimized interposer channel designs validated via EM and SPICE simulations. This innovative solution provides a cost-effective path to scaling AI infrastructure and overcoming memory bottlenecks in next-generation workloads.},
  keywords={Poles and towers;Memory management;Memory architecture;Random access memory;Bandwidth;Packaging;Silicon;Artificial intelligence;Next generation networking;Signal integrity;AI computing;bandwidth;high bandwidth memory (HBM);memory capacity;signal integrity (SI);silicon interposer},
  doi={10.1109/EDAPS64431.2024.10988462},
  ISSN={2151-1233},
  month={Dec},}@ARTICLE{10310125,
  author={Bi, Xia-an and Huang, YangJun and Yang, Zicheng and Chen, Ke and Xing, Zhaoxu and Xu, Luyun and Li, Xiang and Liu, Zhengliang and Liu, Tianming},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Structure Mapping Generative Adversarial Network for Multi-View Information Mapping Pattern Mining}, 
  year={2024},
  volume={46},
  number={4},
  pages={2252-2266},
  abstract={Multi-view learning is dedicated to integrating information from different views and improving the generalization performance of models. However, in most current works, learning under different views has significant independency, overlooking common information mapping patterns that exist between these views. This paper proposes a Structure Mapping Generative adversarial network (SM-GAN) framework, which utilizes the consistency and complementarity of multi-view data from the innovative perspective of information mapping. Specifically, based on network-structured multi-view data, a structural information mapping model is proposed to capture hierarchical interaction patterns among views. Subsequently, three different types of graph convolutional operations are designed in SM-GAN based on the model. Compared with regular GAN, we add a structural information mapping module between the encoder and decoder wthin the generator, completing the structural information mapping from the micro-view to the macro-view. This paper conducted sufficient validation experiments using public imaging genetics data in Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. It is shown that SM-GAN outperforms baseline and advanced methods in multi-label classification and evolution prediction tasks.},
  keywords={Generative adversarial networks;Deep learning;Data models;Data mining;Training;Task analysis;Predictive models;Multi-view learning;structural information mapping;graph convolution;generative adversarial network},
  doi={10.1109/TPAMI.2023.3330795},
  ISSN={1939-3539},
  month={April},}@ARTICLE{10480226,
  author={Dong, Haiwei and Liu, Yang and Chu, Ted and Saddik, Abdulmotaleb El},
  journal={IEEE Consumer Electronics Magazine}, 
  title={Bringing Robots Home: The Rise of AI Robots in Consumer Electronics}, 
  year={2025},
  volume={14},
  number={1},
  pages={4-6},
  abstract={On march 18, 2024, NVIDIA unveiled Project GR00T, a general-purpose multimodal generative AI model designed specifically for training humanoid robots. Preceding this event, Tesla's revealing of the Optimus Gen 2 humanoid robot on December 12, 2023, underscored the profound impact robotics is poised to have on reshaping various facets of our daily lives. While robots have long dominated industrial settings, their presence within our homes is a burgeoning phenomenon. This can be attributed, in part, to the complexities of domestic environments and the challenges of creating robots that can seamlessly integrate into our daily routines.},
  keywords={Robots;Robot sensing systems;Robot kinematics;Artificial intelligence;Sensors;Service robots;Mobile robots},
  doi={10.1109/MCE.2024.3381573},
  ISSN={2162-2256},
  month={Jan},}@INPROCEEDINGS{11016499,
  author={Becerra, Alvaro and Cobos, Ruth},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Enhancing the Professional Development of Engineering Students through an AI-Based Collaborative Feedback System}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={Peer and self-assessment are widely recognized as effective strategies for fostering critical thinking, reflective learning, and the development of professional skills in educational contexts. These approaches enable students to actively participate in the learning process by evaluating their own work and that of their peers. Despite their potential benefits, traditional assessment methods often encounter significant challenges, such as inconsistent feedback quality, limited student engagement, and a lack of actionable insights that students can use to improve their performance. Addressing these limitations, this paper introduces AICoFe (“Artificial Intelligence-based Collaborative Feedback system”), an innovative platform designed to enhance the feedback process through the integration of generative artificial intelligence (GenAI) and Learning Analytics dashboards. AICoFe facilitates both peer and self-assessments using rubric-based frameworks that combine quantitative scores with qualitative observations. By leveraging GenAI, through an adapted version of GePeTo, the system provides personalized, actionable feedback tailored to individual student performance. This feedback is displayed on Learning Analytics dashboards, which also allow students to compare their performance against peers and reflect on their results through comparative graphs. Additionally, AICoFe includes video recordings of student performances to promote self-reflection and a deeper understanding of strengths and areas for improvement. These functionalities enable students to engage more effectively with the provided feedback, fostering continuous learning and development. The system's effectiveness was evaluated through a case study involving final-year engineering students tasked with improving their oral presentation skills. A customized rubric was designed to assess various aspects of effective presentations. Preliminary findings demonstrated that the feedback provided by AICoFe was perceived as clear, specific, and actionable. The study underscores the transformative potential of combining AI-driven feedback with dynamic visualization tools to create a holistic and engaging assessment process. Future work will explore additional features, such as advanced video and audio analysis, and expand the system's application to other skill areas, solidifying its role as a versatile tool for modern educational needs.},
  keywords={Visualization;Generative AI;Collaboration;Learning (artificial intelligence);Engineering students;Video recording;Feedback;Dashboard;GenAI;Generative Artificial Intelligence;Learning Analytics;Oral Presentation;Peer Assessment;Skill Development},
  doi={10.1109/EDUCON62633.2025.11016499},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10393677,
  author={Yan, Haijun and Huang, Lingcao},
  booktitle={2023 IEEE 6th International Conference on Information Systems and Computer Aided Education (ICISCAE)}, 
  title={Research on Totem Pattern Generation Technology of Yunnan Province Based on Artificial Intelligence}, 
  year={2023},
  volume={},
  number={},
  pages={752-756},
  abstract={This paper studies the graphic elements and composition rules of Yunnan totem. The research on the personalized web design of Yunnan totem graphics is carried out by using HTML as a tool. This paper introduces a dictionary-based markup method for multi-markup learning. This method integrates lexicographic independence and coefficient similarity organically into multi-labeling, which can effectively improve the accuracy of multi-labeling. So as to achieve the purpose of marking Yunnan culture pattern automatically. The experimental results show that the online marking system of Yunnan pattern can solve the existing problems of pattern marking well. Through the customization of graphics and composition templates and the combination of database technology, it is possible to independently edit graphics, colors, composition templates and other graphics. Finally, the designed graphics are output in JPG, PNG, SVG and other formats for subsequent printing. Through digital means, the generative protection and design application of Yunnan totem pattern are realized.},
  keywords={Graphics;Printing;Web design;Machine learning;Software;Real-time systems;HTML;Yunnan culture;artificial intelligence;totem generation system;multi-label dictionary learning labeling algorithm},
  doi={10.1109/ICISCAE59047.2023.10393677},
  ISSN={2770-663X},
  month={Sep.},}@INPROCEEDINGS{10860334,
  author={Liu, Xunjie and Wang, Haotian and Guo, Binghui and Wang, Yutian and Gao, Haiwei},
  booktitle={2024 4th International Conference on New Energy and Power Engineering (ICNEPE)}, 
  title={Research on Heterogeneity Problem of Federated Learning Based on Knowledge Distillation-Translate}, 
  year={2024},
  volume={},
  number={},
  pages={1286-1303},
  abstract={With rising computing power, data-driven AI algorithms have become essential in fields like image processing, with significant applications in electricity inspection image detection. However, competition and privacy concerns prevent data sharing between electricity companies, limiting the development of smart inspection technologies. Federated learning offers a solution, enabling companies to collaboratively train a global model without sharing raw data, thus enhancing model performance and data efficiency. When data distribution is inconsistent (non-IID), traditional federated learning faces challenges that affect training efficiency and accuracy. To address this, we propose FedTSD, a federated learning algorithm designed for electricity inspection tasks. By dynamically exchanging teacher-student roles between the global and local models, FedTSD uses a central server to transfer additional knowledge, boosting generalization and reducing overfitting. Experiments on CIFAR-10 and SVHN datasets show that FedTSD outperforms traditional methods, achieving higher accuracy and smoother training, with faster convergence, which is crucial for efficient electricity inspections.},
  keywords={Training;Accuracy;Federated learning;Electricity;Companies;Inspection;Data models;Generators;Servers;Convergence;Federated Learning;Knowledge Distillation;Electricity Inspection;Generative Adversarial Networks;Data Heterogeneity},
  doi={10.1109/ICNEPE64067.2024.10860334},
  ISSN={},
  month={Nov},}@ARTICLE{11091277,
  author={Wu, Yujie and Wu, Mengze and Cui, Tianyi and Lin, Jiani and Liao, Qingke and Shu, Jinqiu},
  journal={IEEE Access}, 
  title={AI-Driven Detection of Alkali-Silica Reaction in Concrete Structures Using Feature-Enhanced Deep Learning Models}, 
  year={2025},
  volume={13},
  number={},
  pages={134070-134079},
  abstract={Concrete’s affordability, adaptability, and resilience make it a cornerstone of construction, yet its vulnerability to degradation, particularly Alkali-Silica Reaction (ASR), poses significant challenges. ASR induces cracking and structural instability, necessitating efficient detection methods to mitigate its impacts. This study explores the use of Artificial Intelligence (AI) techniques for ASR crack identification, employing image enhancement and advanced models such as ResNet-18, InceptionV3, and AlexNet. A dataset of ASR-affected images was developed and augmented through feature enhancement processes, improving crack visibility and classification accuracy. Among the tested models, InceptionV3 demonstrated superior performance with high accuracy and robustness. The findings reveal that AI-based approaches, combined with image enhancement, effectively identify ASR cracks without requiring structural surface treatment. This research offers a scalable, automated solution to ASR detection, advancing structural health monitoring technologies and contributing to the preservation of critical infrastructure.},
  keywords={Accuracy;Iron;Feature extraction;Silicon dioxide;Diseases;Monitoring;Deep learning;Manuals;Concrete;Chemicals;Alkali-silica reaction (ASR);artificial intelligence;deep learning;structural health monitoring;feature enhancement},
  doi={10.1109/ACCESS.2025.3591865},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10959234,
  author={Stankovski, Stevan and Ostojić, Gordana and Zhang, Xioshuan and Popović, Božidar and Lubura, Slobodan},
  booktitle={2025 24th International Symposium INFOTEH-JAHORINA (INFOTEH)}, 
  title={New Approach to Student Education Based on Chatbot}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={In recent years, we have seen a shift in the way we search, collect and verify knowledge on the Internet. Instead of the traditional way of typing questions into a web browser and selecting the appropriate answer, users are increasingly turning to chatbots to answer their questions. The answers provided by a generative chatbot are not always adequate and therefore it is important to use those chatbots that have a predefined set of knowledge that is used to get answers. In this paper, we present the results of the application of educational chatbots in different subjects studied in different study curriculums and at different universities.},
  keywords={Education;Chatbots;Turning;Internet;Browsers;Artificial intelligence;component;formatting;style;styling;insert (key words)},
  doi={10.1109/INFOTEH64129.2025.10959234},
  ISSN={2767-9470},
  month={March},}@INPROCEEDINGS{10033029,
  author={Huang, Jiaqi and Wu, Chenye},
  booktitle={2022 IEEE Sustainable Power and Energy Conference (iSPEC)}, 
  title={Privacy Leakage in GAN Enabled Load Profile Synthesis}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={Load profile synthesis is a commonly used technique for preserving smart meter data privacy. Recent efforts have successfully integrated advanced generative models, such as the Generative Adversarial Networks (GAN), to synthesize high-quality load profiles. Such methods are becoming increasingly popular for conducting privacy-preserving load data analytics. It is commonly believed that performing analyses on synthetic data can ensure certain privacy.In this paper, we examine this common belief. Specifically, we reveal the privacy leakage issue in load profile synthesis enabled by GAN. We first point out that the synthesis process cannot provide any provable privacy guarantee, highlighting that directly conducting load data analytics based on such data is extremely dangerous. The sample re-appearance risk is then presented under different volumes of training data, which indicates that the original load data could be directly leaked by GAN without any intentional effort from adversaries. Furthermore, we discuss potential approaches that might address this privacy leakage issue.},
  keywords={Training;Privacy;Data privacy;Training data;Closed box;Generative adversarial networks;Smart meters;Privacy;Data Synthesis;GAN;Differential Privacy;Load Profiling},
  doi={10.1109/iSPEC54162.2022.10033029},
  ISSN={},
  month={Dec},}
