@INPROCEEDINGS{11042618,
  author={Lingham N, Siva Rama and Kumar R, Prasanna},
  booktitle={2025 2nd International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)}, 
  title={Quantum-classical generative adversarial networks based computer vision solution for human and construction vehicle detection}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Detection of human and construction vehicle is an important step when it comes to automation of safety and productivity on construction sites. The technique of Computer Vision in its conventional forms has issues in cases where shadows, noise or large differences in illumination and occlusions occur. Although there are such challenges, the application of classical Generative Adversarial Networks (GANs) has promising solutions to such problems, but the training and optimization may take longer time and may not converge. The arrival of quantum computation allow for improvements on GAN characteristics through dimensional modeling and optimization at a high speed. Nevertheless, fully quantum models are still limited by hardware and can only be solved with the help of mixed-classifications. For construction vehicle detection, this research work suggests a combined Quantum-Classical Generative Adversarial Network (QC-GAN) approach. The connection component introduces quantum aspects into the procedure to capture elaborate features of the image data and enhance feature engineering and its generalisability. To enhance functioning of the QC-GAN, we incorporate the Leopard Seal Optimization (LSO) algorithm to function based on hunting attributes of leopard seal. The present LSO algorithm successfully navigates through the optimization landscape for better training stability and faster convergence. The introduced approach attains higher accuracy as 99%.},
  keywords={Training;Computer vision;Quantum computing;Accuracy;Computational modeling;Vehicle detection;Seals;Generative adversarial networks;Stability analysis;Optimization;Computer vision;Generative Adversarial Networks;Quantum-Classical;Leopard Seal Optimization},
  doi={10.1109/RMKMATE64874.2025.11042618},
  ISSN={},
  month={May},}@INPROCEEDINGS{10281062,
  author={Guo, Lingxu and Zhang, Yue and Shan, Lianfei and Qiao, Yongtian and Jiang, Tao and Wang, Yu and Zhao, Shengao},
  booktitle={2023 2nd International Conference on Robotics, Artificial Intelligence and Intelligent Control (RAIIC)}, 
  title={The Method of Power Grid Fault Disposal Auxiliary Decision Generation Based on Generative Adversarial Imitation Agent}, 
  year={2023},
  volume={},
  number={},
  pages={269-274},
  abstract={It is difficult to deal with the randomness and volatility of the new power system in the fault disposal mode of the power grid, and this paper proposes a method of power grid fault disposal auxiliary decision generation based on generative adversarial imitation agent. Firstly, a generator network is constructed, and the fault disposal auxiliary decision is generated by observing the power grid operation status and fault condition. The expert dispatch experience and sensitivity calculation results are used as expert strategies to guide the learning of the generator network. Then, the discriminant network is constructed to identify the generation strategy and the expert dispatch strategy and output discrimination results to assist generator network in updating itself. In the game confrontation between the generator and the discriminator, both of them reach the Nash equilibrium state, and power grid fault disposal auxiliary decision generation agent is built based on generative adversarial imitation learning. Through the operation data verification of a certain regional power grid, the proposed fault disposal auxiliary decision agent converges quickly in off-line training and has high decision efficiency in online application, which can quickly generate the power grid fault disposal auxiliary decision.},
  keywords={Training;Sensitivity;Reinforcement learning;Nash equilibrium;Generative adversarial networks;Power grids;Generators;power grid dispatch;fault disposal;generative adversarial network;imitation learning;agent},
  doi={10.1109/RAIIC59453.2023.10281062},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10581574,
  author={Yang, Fan and Wang, Pengbo and Li, Xinheng and Zhao, Qi and Wei, Shuwu and Chen, Lei},
  booktitle={2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={Data Sample Augmentation for Power Transformer Fault Diagnosis via Multi-Fault Generative Adversarial Networks with Gradient Penalty Optimization}, 
  year={2024},
  volume={},
  number={},
  pages={1827-1832},
  abstract={Intelligent fault diagnosis of power transformers often suffers from limited fault sample sizes and imbalance in data across different fault categories, leading to insufficient accuracy and generalization of diagnostic models, which significantly impacts the effectiveness of transformer fault analysis. This paper presents a deep learning-based fault data augmentation method named MFGAN (Multi-Fault Generative Adversarial Network). Compared to the traditional Conditional WGAN-GP (Wasserstein Generative Adversarial Network with Gradient Penalty) model, MFGAN integrates fault category label information into the random variables fed to the generator and introduces an auxiliary classification head to the discriminator, specifically generating different types of fault samples. Consequently, it effectively enhances the quality of fault diagnosis samples. The paper evaluates the effectiveness of the MFGAN approach for data augmentation using a database derived from DGA (Dissolved Gas Analysis) in transformer oil, focusing on the uncoded ratio of the gases. Results demonstrate that MFGAN not only addresses data imbalance issues more effectively than the classical SMOTE (Synthetic Minority Over-sampling Technique) and Conditional WGAN-GP model, improving fault classification outcomes, but also exhibits a certain degree of universality and generalization across different classification algorithms.},
  keywords={Training;Seminars;Oil insulation;Data augmentation;Generative adversarial networks;Data models;Stability analysis;component;data sample augmentation;multi-fault generative adversarial networks;gradient penalty optimization},
  doi={10.1109/AINIT61980.2024.10581574},
  ISSN={},
  month={March},}@INPROCEEDINGS{10763168,
  author={Prabhu Rajasekar, K. and Vezhaventhan, D.},
  booktitle={2024 4th International Conference on Sustainable Expert Systems (ICSES)}, 
  title={Artificial Intelligence Based Fraud Detection, Data Security and Privacy for Telecommunication Systems}, 
  year={2024},
  volume={},
  number={},
  pages={402-406},
  abstract={Globally, fraud is increasing and has the potential to cost firms billions of dollars and inflict serious financial harm. Scholars hailing from several domains of application have put forth distinct methodologies. Examining these concepts can help us see the problems more clearly. Examining several approaches to fraud detection and prevention in the communications industry is the aim of this article. This paper gives a summary of the various categories of telecom fraud, problems that arise throughout the detection process, and some recommendations for how to solve them. The efficacy of the existing methodologies is documented at, succeeded by suggestions and suggestions for selecting the performance measurements that best suit the needs. There has been a notable shift in the use of advanced AI-driven solutions for fraud management in the telecom industry. The development of Generative AI is a significant breakthrough, giving CSPs powerful instruments to fight fraud. As a result of the transition from conventional to AI-based methodologies, fraud management is becoming more proactive and predictive, enabling CSPs to stay one step ahead of criminals.},
  keywords={Technological innovation;Consumer behavior;Banking;Media;Real-time systems;Robustness;Fraud;Telecommunications;Sensors;Internet of Things;Banking;Communication Service Providers;Consumers;Electronics;Industry;Real time Security},
  doi={10.1109/ICSES63445.2024.10763168},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10828708,
  author={Rakhmetulayeva, Sabina and Bolshibayeva, Aigerim},
  booktitle={2024 International Conference on Artificial Intelligence, Metaverse and Cybersecurity (ICAMAC)}, 
  title={A Comprehensive Analysis of Modern Generative Models for Echocardiography Image Synthesis}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The use of machine learning (ML) in the medical field is hindered by the scarcity of high-quality data. This work tackles the deficiency of echocardiogram pictures (echoCG) by using advanced generative models for synthetic creation. We provide a comprehensive practical assessment of these approaches and ascertain their limits. Our study examines the efficacy of a cycle-consistent generative adversarial network (CycleGAN), a contrastive unpaired translation (CUT) approach, and a latent diffusion model (Stable Diffusion 1.5). We outline our data generating approach, exhibit picture examples, describe our assessment strategy, and offer findings from a user study measuring the perceived quality and medical validity of the produced samples, done with licensed cardiologists and surgeons.},
  keywords={Analytical models;Translation;Metaverse;Image synthesis;Echocardiography;Surgery;Generative adversarial networks;Diffusion models;Computer security;Biomedical imaging;echocardiography;generative models;CycleGAN;medical imaging;data augmentation},
  doi={10.1109/ICAMAC62387.2024.10828708},
  ISSN={},
  month={Oct},}@ARTICLE{9832012,
  author={Zhou, Dongdong and Xu, Qi and Wang, Jian and Xu, Hongming and Kettunen, Lauri and Chang, Zheng and Cong, Fengyu},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Alleviating Class Imbalance Problem in Automatic Sleep Stage Classification}, 
  year={2022},
  volume={71},
  number={},
  pages={1-12},
  abstract={For real-world automatic sleep-stage classification tasks, various existing deep learning-based models are biased toward the majority with a high proportion. Because of the unique sleep structure, most of the current polysomnography (PSG) datasets suffer an inherent class imbalance problem (CIP), in which the number of each sleep stage is severely unequal. In this study, we first define the class imbalance factor (CIF) to describe the level of CIP quantitatively. Afterward, we propose two balancing methods to alleviate this problem from the dataset quantity and the relationship between the class distribution and the applied model, respectively. The first one is to employ the data augmentation (DA) with the generative adversarial network (GAN) model and different intensities of Gaussian white noise (GWN) to balance samples, thereinto, GWN addition is specifically tailored to deep learning-based models, which can work on raw electroencephalogram (EEG) data while preserving their properties. In addition, we try to balance the relationship between the imbalanced class and biased network model to achieve a balanced state with the help of class distribution and neuroscience principles. We further propose an effective deep convolutional neural network (CNN) model utilizing bidirectional long short-term memory (Bi-LSTM) with single-channel EEG as the baseline. It is used for evaluating the efficiency of two balancing approaches on three imbalanced PSG datasets (CCSHS, Sleep-EDF, and Sleep-EDF-V1). The qualitative and quantitative evaluation of experimental results demonstrates that the proposed methods could not only show the superiority of class balancing through the confusion matrix and classwise metrics, but also get better N1 stage and whole stages classification accuracies compared to other state-of-the-art approaches.},
  keywords={Brain modeling;Generative adversarial networks;Electroencephalography;Databases;White noise;Sleep apnea;Feature extraction;Class imbalance problem (CIP);data augmentation (DA);deep neural network;generative adversarial network (GAN);network connection;sleep-stage classification},
  doi={10.1109/TIM.2022.3191710},
  ISSN={1557-9662},
  month={},}@INPROCEEDINGS{10354803,
  author={Gaertner, Sebastian and Patel, Vrushti and Cabera, Dayanara and Rafikia, Emily and Nkululeko, Risa and Mehta, Khanjan},
  booktitle={2023 IEEE Global Humanitarian Technology Conference (GHTC)}, 
  title={Using Generative AI to Strategize Entrepreneurial Endeavors}, 
  year={2023},
  volume={},
  number={},
  pages={250-251},
  abstract={Entrepreneurial ventures aim to create something that has never been created before. To do so they must come up with ways to visualize and communicate their proposed solution. Oftentimes this can prove difficult as the entrepreneurs may be working on projects without complete access to the resources necessary to complete their work. Recent developments in generative AI provide unique ways for entrepreneurs to overcome their limitations in resources to produce content that otherwise would have been out of reach. In this paper, we will be delving into work done with generative AI by the Zero Hunger College team. We will explore what technologies were used and how they allowed the team to improve their work.},
  keywords={Visualization;Entrepreneurship;Chatbots;Solids;Software;Product design;Artificial intelligence;Generative AI;Entrepreneurship;Chat GPT;DALLE-2},
  doi={10.1109/GHTC56179.2023.10354803},
  ISSN={2473-5728},
  month={Oct},}@ARTICLE{10701540,
  author={Yao, Wei and Lai, Rucong and Tian, Yong and Li, Xiaoyu and Tian, Jindong},
  journal={IEEE Transactions on Transportation Electrification}, 
  title={State of Health Estimation of Lithium-Ion Batteries Using Data Augmentation and Feature Mapping}, 
  year={2025},
  volume={11},
  number={1},
  pages={4895-4905},
  abstract={Accurate state of health (SOH) estimation is crucial for the operating safety and reliability of lithium-ion batteries (LIBs). Currently, data-driven SOH estimation methods have been widely used in both academic and industrial communities. Nevertheless, they are still confronted with challenges, including time-consuming data collection and poor adaptability to different batteries. This article proposes a deep learning framework with a generative adversarial network (GAN) for data augmentation and a feature mapping module. To make the GAN’s generator learn feature distribution of limited original data better, consistent Gaussian noise is applied to the same cycle sequence during data generation. In consideration of the prominent noises introduced by the GAN to short-cycle batteries, a feature mapping module is proposed to reduce the difference in features of different battery datasets. Experiments using estimators trained on different batteries and directly transferred to other batteries are carried out. Results indicated that the accuracy of about 87% of the total 60 samples is improved after data augmentation, and the average absolute error (AE) is below 2%. Furthermore, the embedded feature mapping module achieves a root mean square error (RMSE) of lower than 1%, and half of them are below 0.5%.},
  keywords={Batteries;Estimation;Generative adversarial networks;Data models;Voltage;Degradation;Discharges (electric);Adaptation models;Data augmentation;Aging;Feature mapping-based transfer learning;generative adversarial network (GAN);lithium-ion batteries (LIBs);MLP-Trans;state of health (SOH)},
  doi={10.1109/TTE.2024.3471867},
  ISSN={2332-7782},
  month={Feb},}@INPROCEEDINGS{11038038,
  author={Lee, Jungeon and Lee, Sun-Woo and Kim, Taek-Soo and Kwon, Daeil},
  booktitle={2025 IEEE 75th Electronic Components and Technology Conference (ECTC)}, 
  title={Artificial Intelligence-Based Warpage Prediction Model for Accelerating Thermo-Mechanical Simulation in Advanced Packaging}, 
  year={2025},
  volume={},
  number={},
  pages={1570-1576},
  abstract={One of the most challenging issues in advanced packaging is the increasing design complexity, which necessitates the expenditure of more effort in finding an optimal design, compared with traditional packaging methods. The use of multiple chiplets with 3D stacked dies and a number of passive components increases the dimensionality of design variables, making finite element thermomechanical simulations more computationally demanding. Moreover, as the variety of materials used in advanced packaging increases, coefficient of thermal expansion (CTE) mismatches are more likely to occur and lead to geometrically uneven warpage. Given these challenges, a machine learning-based warpage prediction model can be adopted to accelerate the design process. A well-trained model can provide immediate results without solving iterative and nonlinear governing equations while also handling high-dimensional design optimization problems. This study presents a machine learning-based warpage prediction model that shows less computation time, compared with thermomechanical simulation. Considering the uneven warpage characteristics of advanced packaging, we developed a conditional generative adversarial network (cGAN)-based model capable of predicting the global warpage distribution across the entire package surface. The training dataset for the cGAN model was generated from a warpage simulation model of a commercial 2.5D package with multiple chiplets, high bandwidth memory, and a Si-bridge interposer. The thermomechanical properties of the epoxy molding compound, including the CTE, thickness of the Sibridge interposer, and process temperature, were considered as key design variables influencing warpage. The warpage distribution predicted by the cGAN model was evaluated against actual thermomechanical simulation results under the same conditions. The developed cGAN model enables rapid warpage prediction and design space exploration, which reduces the total computation time, compared with repetitive thermomechanical simulation. This study concludes by discussing future applications of the presented model for the acceleration of global warpage optimization in advanced packaging, including experimental validation.},
  keywords={Training;Computational modeling;Chiplets;Thermomechanical processes;Predictive models;Packaging;Generative adversarial networks;Mathematical models;Finite element analysis;Optimization;Finite Element Analysis Acceleration;Machine Learning;Warpage Prediction;Advanced Packaging;Conditional GAN},
  doi={10.1109/ECTC51687.2025.00268},
  ISSN={2377-5726},
  month={May},}@ARTICLE{9896812,
  author={Zhao, Chen and Lv, Yisheng and Jin, Junchen and Tian, Yonglin and Wang, Jiangong and Wang, Fei-Yue},
  journal={IEEE Intelligent Transportation Systems Magazine}, 
  title={DeCAST in TransVerse for Parallel Intelligent Transportation Systems and Smart Cities: Three Decades and Beyond}, 
  year={2022},
  volume={14},
  number={6},
  pages={6-17},
  abstract={Parallel transportation management and control was proposed three decades ago as a new paradigm for conducting complex transportation operations and has led to today’s DeCAST in TransVerse platform designed and constructed according to the principle of decentralized/distributed autonomous operations and organizations. This article presents an overview of its architectures, processes, operating procedures, and major applications. The developments and applications have demonstrated clearly that parallel transportation systems are effective for networked traffic control and distributed logistical operations. The existing challenges and emerging opportunities are also addressed. A transportation foundation model based on parallel learning and federated intelligence is proposed as a potential path to the next-generation parallel intelligent transportation systems.},
  keywords={Smart cities;Data models;Traffic control;Road traffic;Computational modeling;Complex systems;Adaptation models;Urban planning;Urban areas},
  doi={10.1109/MITS.2022.3199557},
  ISSN={1941-1197},
  month={Nov},}@ARTICLE{11142676,
  author={Shao, Yuheng and Liu, Shiyi and Chen, Gongyan and Ma, Ruofei and Wang, Xingbo and Li, Quan},
  journal={IEEE Computer Graphics and Applications}, 
  title={FashionCook: A Visual Analytics System for Human–AI Collaboration in Fashion E-Commerce Design}, 
  year={2025},
  volume={},
  number={},
  pages={1-15},
  abstract={Fashion e-commerce design requires the integration of creativity, functionality, and responsiveness to user preferences. While AI offers valuable support, generative models often miss the nuances of user experience, and task-specific models, although more accurate, lack transparency and real-world adaptability—especially with complex multimodal data. These issues reduce designers' trust and hinder effective AI integration. To address this, we present FashionCook, a visual analytics system designed to support human–AI collaboration in the context of fashion e-commerce. The system bridges communication among model builders, designers, and marketers by providing transparent model interpretations, “what-if” scenario exploration, and iterative feedback mechanisms. We validate the system through two real-world case studies and a user study, demonstrating how FashionCook enhances collaborative workflows and improves design outcomes in data-driven fashion e-commerce environments.},
  keywords={Artificial intelligence;Collaboration;Electronic commerce;Predictive models;Interviews;Computational modeling;Visual analytics;Data models;Forecasting;Decision making},
  doi={10.1109/MCG.2025.3597849},
  ISSN={1558-1756},
  month={},}@INPROCEEDINGS{10582940,
  author={Mudabbiruddin, Mohammed and Mosavi, Amir and Imre, Felde},
  booktitle={2024 IEEE 11th International Conference on Computational Cybernetics and Cyber-Medical Systems (ICCC)}, 
  title={From Deep Learning to ChatGPT for Materials Design}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Large language models (LLMs) provide competitive advantages to various fields of research. This survey explores the journey from using deep learning to adopting ChatGPT in materials design. It covers how methodologies have shifted, moving away from traditional deep learning models to embracing LLMs such as ChatGPT, in advancing materials design research. The focus is on methods and applications, highlighting how LLMs are shaping the landscape of materials design. The survey aims to provide insights into the essential role of ChatGPT in this domain, offering a comprehensive view of its methods and diverse applications.},
  keywords={Deep learning;Surveys;Technological innovation;Materials science and technology;Computational modeling;Large language models;Predictive models;artificial intelligence;deep learning;ChatGPT;eXplainable Artificial Intelligence;material science;large language models;machine learning;LLMs;big data;data science;mathematics;applied artificial intelligence;XAI;natural-language programming;medical sciences;soft computing;applied machine learning;applied mathematics;applied informatics;generative artificial intelligence;generative AI},
  doi={10.1109/ICCC62278.2024.10582940},
  ISSN={},
  month={April},}@ARTICLE{8954940,
  author={Zhang, Libao and Chen, Donghui and Ma, Jie and Zhang, Jue},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Remote-Sensing Image Superresolution Based on Visual Saliency Analysis and Unequal Reconstruction Networks}, 
  year={2020},
  volume={58},
  number={6},
  pages={4099-4115},
  abstract={Remote-sensing images (RSIs) generally have strong spatial characteristics for surface features. Various ground objects, such as residential areas, roads, forests, and rivers, differ substantially. According to this visual attention characteristic, regions with complicated texture features require more realistic details to reflect a better description of the topography, while regions such as farmlands should be smooth and have less noise. However, most existing single-image superresolution (SISR) methods fail to fully utilize these properties and therefore apply a uniform reconstruction strategy to the whole image. In this article, we propose a novel saliency-driven unequal single-image reconstruction network in which the demands of various regions in the superresolution (SR) process are distinguished by saliency maps. First, we design a new gradient-based saliency analysis method to produce more accurate saliency maps with imagewise annotations. The method utilizes the superiority of a multireception field to extract both high-level features and low-level features. Second, we propose a novel saliency-driven gate conditional generative adversarial network, where the saliency map is regarded as a medium during the training procedure of the whole network. The saliency map is regarded as a pixelwise condition in a generator to enhance the training capability of the network. Additionally, we design a new loss function that combines normalized content loss, saliency-driven perceptual loss, and gate-control adversarial loss to further refine details of texture-complex areas for RSIs. We evaluate the performance of our algorithm and compare it with many other state-of-the-art SR methods using a remote-sensing data set. The experimental results show that our approach achieves the optimal outcome in salient areas. Our method attains the best effect on global quality and visual performance.},
  keywords={Image reconstruction;Logic gates;Visualization;Remote sensing;Training;Feature extraction;Deep learning;generative adversarial network;remote sensing;saliency;single-image superresolution (SISR);unequal reconstruction},
  doi={10.1109/TGRS.2019.2960781},
  ISSN={1558-0644},
  month={June},}@INPROCEEDINGS{10333837,
  author={Wang, Zhangyun and Ning, Nianwen and Tian, Shihan and Lu, Ning and Cheng, Nan and Zhou, Yi},
  booktitle={2023 IEEE 98th Vehicular Technology Conference (VTC2023-Fall)}, 
  title={Vehicular Multimodal Motion Forecasting via Conditional Score-based Modeling}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Accurately forecasting the future motions of road participants is essential for proactive hazard avoidance and safety planning of autonomous vehicles. Existing methods for motion prediction based on probabilistic generative models are limited to low-accuracy likelihood calculations and relatively finite mode distributions. Recent studies show that score-based models can naturally overcome these limitations. In this work, we present a novel paradigm of conditional score-based models for vehicle motion prediction, called Motion-CSM. First, we model scene contextual representations of interaction regions at the feature level via graph convolutional networks. We then interpolate these representations as conditions into the solution process of the continuous-time reverse stochastic differential equation (SDE) to guide trajectory generation, which progressively converts the known prior distributions into multimodal trajectories including the ground truth modes. The designed stacked Transformer structure with dual control conditions is adopted to learn the score function approximation of the Gaussian perturbation kernel. Finally, we develop multiple consistency constraints to align the inference results of Motion-CSM in reverse SDE solving to improve the self-consistency and stability of multimodal trajectory generation. Experimental results on the real-world motion dataset demonstrate that the multimodal forecasting accuracy of Motion-CSM outperforms state-of-the-art methods.},
  keywords={Solid modeling;Vehicular and wireless technologies;Predictive models;Transformers;Data models;Mathematical models;Trajectory;Autonomous vehicles;multimodal motion forecasting;score-based models;probabilistic generative models},
  doi={10.1109/VTC2023-Fall60731.2023.10333837},
  ISSN={2577-2465},
  month={Oct},}@INPROCEEDINGS{11101684,
  author={Zheng, Jiahao and Ren, Jinke and Xu, Peng and Yuan, Zhihao and Xu, Jie and Wang, Fangxin and Gui, Gui and Cui, Shuguang},
  booktitle={2024 IEEE Globecom Workshops (GC Wkshps)}, 
  title={Generative Semantic Communication for Text-to-Speech Synthesis}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Semantic communication is a promising technology to improve communication efficiency by transmitting only the semantic information of the source data. However, traditional semantic communication methods primarily focus on data reconstruction tasks, which may not be efficient for emerging generative tasks such as text-to-speech (TTS) synthesis. To address this limitation, this paper develops a novel generative semantic communication framework for TTS synthesis, leveraging generative artificial intelligence technologies. Firstly, we utilize a pre-trained large speech model called WavLM and the residual vector quantization method to construct two semantic knowledge bases (KBs) at the transmitter and receiver, respectively. The KB at the transmitter enables effective semantic extraction, while the KB at the receiver facilitates lifelike speech synthesis. Then, we employ a transformer encoder and a diffusion model to achieve efficient semantic coding without introducing significant communication overhead. Finally, numerical results demonstrate that our framework achieves much higher fidelity for the generated speech than four baselines, in both cases with additive white Gaussian noise channel and Rayleigh fading channel.},
  keywords={Transmitters;Speech coding;Generative AI;Vector quantization;Knowledge based systems;Receivers;Semantic communication;Transformers;Diffusion models;Text to speech},
  doi={10.1109/GCWkshp64532.2024.11101684},
  ISSN={2166-0077},
  month={Dec},}@INPROCEEDINGS{10650777,
  author={Zhao, Yunlong and Ni, Ziyi and Hu, Zefa and Xu, Shuang and Xu, Bo},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Bridge the Query and Document: Contrastive Learning for Generative Document Retrieval}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Generative retrieval has garnered significant attention for its end-to-end optimization and exceptional performance. Compared with the dense retrieval paradigm, the generative retrieval paradigm maps a query to a relevant document ID only relying on its model parameters, greatly simplifying the retrieval process. However, generative retrieval faces two challenges: it does not explicitly model the semantic relevance between query and document, and there exists a gap between the representation of query and document. To this end, we propose the Contrastive Search Index (ConSI), a simple but effective contrastive learning framework for generative document retrieval, to address the above challenges. Experiments show that the proposed ConSI consistently surpasses the previous generative retrieval baselines, NCI. Further analysis of different factors and indicators verifies the performance enhancement brought by our method. Besides, our ConSI also achieves excellent performance in the dense retrieval paradigm, demonstrating that the designed framework boosts representation learning ability and can be directly used as a dense retriever.},
  keywords={Bridges;Representation learning;Semantics;Neural networks;Contrastive learning;Task analysis;Optimization;Document Retrieval;Generative Retrieval;Contrastive Learning},
  doi={10.1109/IJCNN60899.2024.10650777},
  ISSN={2161-4407},
  month={June},}@ARTICLE{10121493,
  author={Pei, Zhaodi and Wei, Fulin and Zhu, Zhiyuan and Wu, Xia},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Few-Shot Synthetic Online Transfer Learning for Cross-Site Neurological Disease Diagnosis}, 
  year={2024},
  volume={11},
  number={2},
  pages={2201-2209},
  abstract={Cross-site datasets expand the data size and could improve the disease diagnosis capabilities of machine learning models. However, differences in data distribution between different sites can lead to poor model generalizability. Although transfer learning is a mainstream method often used to tackle the issue, most transfer learning studies assume that all the target samples are given in the training procedure, which is not available in clinical applications where the target samples arrive sequentially. Online transfer learning (OTL) aims to accomplish clinical diagnostic tasks by adaptively updating the ensemble model containing source and target classifiers. However, OTL is limited by zero initialization and requires numbers of samples to iterate. This results in the underperformance of OTL in clinical applications where few samples can be obtained. In this article, we propose a new framework named few-shot synthetic OTL (FSOTL) to address this issue. FSOTL uses synthetic data to warm up the model in an online fashion. It not only alleviates the problem of scarcity of samples in the target domain but also enables the model to gain more knowledge. Our experiments show that FSOTL performs more stably and achieves more accurate results with few target samples, thereby offering a promising cross-site online computer-aided diagnosis system for large-scale applications.},
  keywords={Transfer learning;Data models;Brain modeling;Adaptation models;Generative adversarial networks;Computational modeling;Computer-assisted diagnosis;data augmentation;few-shot learning;model generalization;online transfer learning (OTL)},
  doi={10.1109/TCSS.2023.3270569},
  ISSN={2329-924X},
  month={April},}@INPROCEEDINGS{10976085,
  author={Zhang, Hui and Wang, Qi},
  booktitle={2025 14th International Conference on Educational and Information Technology (ICEIT)}, 
  title={The Impact of GenAI Assistance on Knowledge Building in Tasks of Different Difficulty Levels}, 
  year={2025},
  volume={},
  number={},
  pages={556-561},
  abstract={Online learning has emerged as the preferred learning modality for numerous learners. However, during this process, learners' discussions are frequently confined to simplistic question-and-answer sessions, thereby impeding the attainment of high-level knowledge building. Generative Artificial Intelligence (GenAI), equipped with its capabilities of personalized content recommendation and knowledge generation, presents novel practical opportunities for facilitating the construction of high-level knowledge among learners. In this study, a sample of 143 in-service graduate students was selected as participants, and epistemic network analysis was employed to investigate the impact of GenAl on learners' knowledge building processes across different levels of learning tasks. The results of the study indicate that GenAI exerts a relatively weak influence on both low-level and middle-level tasks. Under the GenAl-assisted learning model, learners demonstrated more prominent performance in high-level tasks, showcasing stronger individual analytical abilities and autonomous cognitive characteristics. Nevertheless, GenAI might potentially undermine social interaction and collaboration within their learning process. Based on these findings, this study offers empirical evidence and corresponding recommendations for the application of GenAI in classroom instruction.},
  keywords={Knowledge engineering;Analytical models;Generative AI;Collaboration;Network analyzers;Information technology;generative artificial intelligence;knowledge building;epistemic network analysis},
  doi={10.1109/ICEIT64364.2025.10976085},
  ISSN={},
  month={March},}@ARTICLE{10301978,
  author={Sato, Maki and McKinney, Jonathan},
  journal={Artificial Life}, 
  title={The Enactive and Interactive Dimensions of AI: Ingenuity and Imagination Through the Lens of Art and Music}, 
  year={2022},
  volume={28},
  number={3},
  pages={310-321},
  abstract={Dualisms are pervasive. The divisions between the rational mind, the physical body, and the external natural world have set the stage for the successes and failures of contemporary cognitive science and artificial intelligence.1 Advanced machine learning (ML) and artificial intelligence (AI) systems have been developed to draw art and compose music. Many take these facts as calls for a radical shift in our values and turn to questions about AI ethics, rights, and personhood. While the discussion of agency and rights is not wrong in principle, it is a form of misdirection in the current circumstances. Questions about an artificial agency can only come after a genuine reconciliation of human interactivity, creativity, and embodiment. This kind of challenge has both moral and theoretical force. In this article, the authors intend to contribute to embodied and enactive approaches to AI by exploring the interactive and contingent dimensions of machines through the lens of Japanese philosophy. One important takeaway from this project is that AI/ML systems should be recognized as powerful tools or instruments rather than as agents themselves.},
  keywords={Japanese philosophy;enactivism;AI ethics;interactivity;contingency;embodiment},
  doi={10.1162/artl_a_00376},
  ISSN={1064-5462},
  month={Aug},}@ARTICLE{11091436,
  author={Sood, Aditya K. and Zeadally, Sherali},
  journal={IEEE Technology and Society Magazine}, 
  title={The Unprecedented Surge in Generative AI: Empirical Analysis of Trusted and Malicious Large Language Models (LLMs)}, 
  year={2025},
  volume={44},
  number={3},
  pages={98-108},
  abstract={Trusted large language models (LLMs) inherit ethical guidelines to prevent generating harmful content, whereas malicious LLMs are engineered to enable the generation of unethical and toxic responses. Both trusted and malicious LLMs use guardrails in differential contexts per the requirements of the developers and attackers, respectively. We explore the multifaceted world of guardrails implementation in LLMs by conducting an empirical analysis to assess the effectiveness of guardrails using prompts. Our results revealed that guardrails deployed in the trusted LLMs could be bypassed using prompt manipulation techniques such as “pretend” and “persist” to generate harmful content. In addition, we also discovered that malicious LLMs still deploy weak guardrails to evade detection by generating human-like content. This empirical analysis provides insights into the design of the malicious and trusted LLMs. We also propose recommendations to defend against prompt manipulation and guardrails bypass while designing LLMs.},
  keywords={Artificial intelligence;Training;Data models;Chatbots;Large language models;Ethics;Computer crime;Computational modeling;Codes;Trusted computing;Malware},
  doi={10.1109/MTS.2025.3582667},
  ISSN={1937-416X},
  month={Sep.},}@INPROCEEDINGS{11048130,
  author={Wujie, Li and Fangyu, Zhao and Jiehao, Chen and Rui, Li and Binxiang, Hong},
  booktitle={2025 5th International Conference on Artificial Intelligence and Industrial Technology Applications (AIITA)}, 
  title={The Current Development Status and Challenges of Data Processing Unit}, 
  year={2025},
  volume={},
  number={},
  pages={1417-1420},
  abstract={With the vigorous development of the digital economy, especially the rapid formation of new economic growth poles such as generative artificial intelligence, autonomous driving, and the low-altitude economy, the global demand for large-scale computing power is experiencing a sharp increase. Data Processing Unit, leveraging their superior data processing performance and unique advantages in heterogeneous computing, are accelerating the evolution of computing facilities towards larger scale, higher bandwidth, and lower latency. The development of Data Processing Unit is showing a robust momentum, yet challenges such as the lack of unified standards, constrained technical research and development approaches, and relatively singular business models persist. There is an urgent need to focus on standard formulation, technological breakthroughs, and industrial collaboration to build self-innovative computing facilities. This will propel data processors to become the “powerhouse of computing” in future data centers.},
  keywords={Data centers;Technological innovation;Generative AI;Computational modeling;Biological system modeling;Data processing;Heterogeneous networks;Standards;Autonomous vehicles;Business;data processing unit;big data;digital economy;chip design},
  doi={10.1109/AIITA65135.2025.11048130},
  ISSN={},
  month={March},}@ARTICLE{9163292,
  author={Li, Zeyu and Deng, Cheng and Yang, Erkun and Tao, Dacheng},
  journal={IEEE Transactions on Multimedia}, 
  title={Staged Sketch-to-Image Synthesis via Semi-supervised Generative Adversarial Networks}, 
  year={2021},
  volume={23},
  number={},
  pages={2694-2705},
  abstract={Sketch-based image synthesis is a challenging problem in computer graphics and vision. Existing approaches either require exact edge maps or rely on the retrieval of existing photographs, which limits their applications in real-world scenarios. Accordingly in this work, we propose a staged semi-supervised generative adversarial networks based method for sketch-to-image synthesis, which can directly generate realistic images from novice sketches. More specifically, we first adopt a conditional generative adversarial network (CGAN) to extract class-wise representations from unpaired images. These class-wise representations are then exploited and incorporated with another CGAN, which are used to generate realistic images from sketches. By incorporating the class-wise representations, our method can leverage both the general class information from unpaired images and the targeted object information from input sketches. Additionally, this network architecture also enables us to take full advantage of widely available unpaired images and learn more accurate class representations. Extensive experiments demonstrate, compared with state-of-the-art image translation methods, our approach can achieve more promising results and synthesize images with significantly better Inception Scores and Fréchet Inception Distance.},
  keywords={Gallium nitride;Generative adversarial networks;Image generation;Training;Image edge detection;Task analysis;Image retrieval;Gan;image generation;sketch},
  doi={10.1109/TMM.2020.3015015},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{9534001,
  author={Li, Zheng and Ma, Chao and Shi, Xiaochuan and Zhang, Dian and Li, Wei and Wu, Libing},
  booktitle={2021 International Joint Conference on Neural Networks (IJCNN)}, 
  title={TSA-GAN: A Robust Generative Adversarial Networks for Time Series Augmentation}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={Time series classification (TSC) is widely used in various real-world applications such as human activity recognition, smart city governance, etc. Unfortunately, due to different reasons, only part of time series could be collected which may obviously degrade the performance of time series classifiers. To alleviate this problem, time series augmentation aims to generate synthetic time series by learning useful features from collected time series. As the popular generative model, generative adversarial networks (GAN) is regarded as a promising model for time series augmentation. However, applying GAN to the time series data suffers from a challenge in which the generated instances hold low quality but the model has gotten saturation. In this paper, for time series augmentation, we proposed TSA-GAN which is a robust GAN model with a self-adaptive recovering strategy to solve this problem. On 85 datasets of the UCR 2015 archive, our proposed TSA-GAN helps time series classifiers achieve performance improvements ranging from 8.3% to 12.5%, which is far better than the baseline.},
  keywords={Training;Smart cities;Time series analysis;Neural networks;Generative adversarial networks;Generators;Distance measurement;time series augmentation;GANs;training saturation},
  doi={10.1109/IJCNN52387.2021.9534001},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{10627914,
  author={Muthazhagu, Veera Harish and Surendiran, B and Arulmurugaselvi, N},
  booktitle={2024 International Conference on Signal Processing, Computation, Electronics, Power and Telecommunication (IConSCEPT)}, 
  title={Navigating the AI Landscape: A Comparative Study of Models, Applications, and Emerging Trends}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={In today's technology world, Artificial Intelligence (AI) has grown omnipresent, transforming industries and affecting many facets of our everyday lives. Given the abundance of AI models in many categories, it is critical to comprehend their advantages, disadvantages, and uses in order to make well-informed decisions and progress the field. NLP, Computer Vision, Speech Recognition, Robotics, Machine Learning (ML) algorithms, Deep Learning models, Reinforcement Learning, Generative Adversarial Networks (GANs), Expert Systems, Au- tonomous Vehicles, Recommendation Systems, and Predictive Analytics are just a few of the categories that this paper compares and reviews in depth. We assess each model's performance, scalability, and appropriateness for various applications through a methodical examination. By combining extant research with practical examples, we illustrate the state of AI technologies now and offer predictions for their future development. The goal of this assessment is to help experts in the industry, researchers, and practitioners navigate the intricate AI ecosystem and realize AI's full potential for the good of society.},
  keywords={Industries;Ethics;Reviews;Navigation;Computational modeling;Biological system modeling;Speech recognition;Artificial Intelligence;AI Models;Comparative Analysis;Applications;Future Trends},
  doi={10.1109/IConSCEPT61884.2024.10627914},
  ISSN={},
  month={July},}@INPROCEEDINGS{11113526,
  author={Li, Junzhuo and Long, Taotao and Zhu, Xiaomeng and Pan, Dongchen},
  booktitle={2025 International Symposium on Educational Technology (ISET)}, 
  title={Collaborative and Cognitive Interaction Pattern Between Generative AI and Engineering Students in Scripted Gamification}, 
  year={2025},
  volume={},
  number={},
  pages={149-153},
  abstract={This study focuses on the role of Generative AI (GAI) in enhancing engineering students' Collaborative Problem-Solving (CPS) performance within STEM gamified learning environments. It aims to uncover the interaction patterns of human-computer collaboration and cognition in complex learning activities, striving to achieve a synergistic human-AI collaboration effect where “$1+1>2$.” Given the significance of STEM education in fostering real-world problem-solving abilities and the potential of AI-driven gamification to enhance learner motivation and performance, this research constructed a unique coding framework based on CPS theory to explore the interaction patterns between GAI and students in gamified learning tasks, and employed epistemic network analysis to analyze the data. The results demonstrate that GAI has a positive impact on students' CPS performance in gamified STEM activities (H1). Distinct collaborative and cognitive interaction patterns emerge during GAI-student interactions (H2), with different learner types exhibiting varying interaction styles (H3). Based on the results, the study proposes future direction to optimize the application of GAI in complex gamification and learning, offering practical guidance for educators and insights for the development of GAI educational products. Additionally, his research provides a theoretical foundation and empirical evidence for understanding the interaction patterns of GAI in STEM learning environments, facilitating the effective integration of GAI into teaching and learning.},
  keywords={Generative AI;Federated learning;Collaboration;Network analyzers;Educational technology;Encoding;Cognition;Problem-solving;Engineering students;STEM;Generative AI;Collaborative Problem Solving;Human-AI collaboration;Gamification Education;STEM},
  doi={10.1109/ISET65607.2025.00038},
  ISSN={2766-2144},
  month={July},}@ARTICLE{10091533,
  author={Chan, Robin Kuok Cheong and Lim, Joanne Mun-Yee and Parthiban, Rajendran},
  journal={IEEE Access}, 
  title={Missing Traffic Data Imputation for Artificial Intelligence in Intelligent Transportation Systems: Review of Methods, Limitations, and Challenges}, 
  year={2023},
  volume={11},
  number={},
  pages={34080-34093},
  abstract={Missing data in Intelligent Transportation Systems (ITS) could lead to possible errors in the analyses of traffic data. Applying Artificial Intelligence (AI) in these circumstances can mitigate such problems. Past works focused only on specific data imputation methods, such as tensor factorization or a specific neural network model. While there are review papers covering singular topics regarding missing data, there are none in the field of traffic, to the best of our knowledge, that introduces the process of missing data collection and the viability of the traffic data collected while also broadly covering the popularly used models of recent years. This has led to non-uniformity of the terms used in missing data imputation, limited research in areas where datasets are not available, and a narrowed view of the methods used for data imputation. Hence, this paper aims to standardize the terms used in missing data classifications, look into the limitations of using available public or private datasets for urban traffic research, and discuss popular statistical and data-driven methods used by recent AI and ITS papers. It was found that tensor decomposition-based methods are the most popular for missing data imputation, followed by Generative Adversarial Networks and Graph Neural Networks, all of which rely on a large training dataset. Meanwhile, Probability Principle Component Analysis (PPCA) methods provide valuable insights via traffic analysis and are used for real-time traffic imputation. This paper also highlights the need for more efficient and reliable methods for traffic data collection, such as online APIs.},
  keywords={Data models;Data collection;Road traffic;Real-time systems;Detectors;Cameras;Tensors;Intelligent transportation systems;Communication systems;Intelligent transportation systems;artificial intelligence;communication system operations and management;reviews},
  doi={10.1109/ACCESS.2023.3264216},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10976186,
  author={Li, Yi and Xiang, Xiuzhen},
  booktitle={2025 14th International Conference on Educational and Information Technology (ICEIT)}, 
  title={Exploring the Utilization of Large Language Models in Translation Teaching}, 
  year={2025},
  volume={},
  number={},
  pages={39-44},
  abstract={With the advancement of generative artificial intelligence, the deployment of large language models in education has become a fast-growing research hotspot. The extensive application and innovative prospects of large language models also yielded vigorous discussions in translation research and teaching. Being one of the pivotal drivers in the development of translation technology, large language models bring a significant change in translation teaching. This paper first employed a questionnaire to gather feedback for the views towards large language models from undergraduates majoring in translation in China, and then explored the application of large language models in teaching translation courses, aiming to devise the approach of using emerging generative artificial intelligence tools within translation teaching.},
  keywords={Surveys;Training;Translation;Accuracy;Generative AI;Large language models;Education;Market research;Information technology;large language models;generative artificial intelligence;translation teaching},
  doi={10.1109/ICEIT64364.2025.10976186},
  ISSN={},
  month={March},}@ARTICLE{10531073,
  author={Zhang, Ruichen and Du, Hongyang and Liu, Yinqiu and Niyato, Dusit and Kang, Jiawen and Sun, Sumei and Shen, Xuemin and Poor, H. Vincent},
  journal={IEEE Network}, 
  title={Interactive AI With Retrieval-Augmented Generation for Next Generation Networking}, 
  year={2024},
  volume={38},
  number={6},
  pages={414-424},
  abstract={With the advance of artificial intelligence (AI), the concept of interactive AI (IAI) has been introduced, which can interactively understand and respond not only to human user input but also to dynamic system and network conditions. In this article, we explore an integration and enhancement of IAI in networking. We first review recent developments and future perspectives of AI and then introduce the technology and components of IAI. We then explore the integration of IAI into next-generation networks, focusing on how implicit and explicit interactions can enhance network functionality, improve user experience, and promote efficient network management. Subsequently, we propose an IAI-enabled network management and optimization framework, which consists of environment, perception, action, and brain units. We also design a pluggable large language model (LLM) module and retrieval augmented generation (RAG) module to build the knowledge base and contextual memory for decision-making in the brain unit. We demonstrate through case studies that our IAI framework can effectively perform optimization problem design. Finally, we discuss potential research directions for IAI-based networks.},
  keywords={Artificial intelligence;Data models;Optimization;Heuristic algorithms;Predictive models;Prediction algorithms;Large language models;Problem-solving;IAI;networking;pluggable LLM module;AGI;RAG;problem formulation},
  doi={10.1109/MNET.2024.3401159},
  ISSN={1558-156X},
  month={Nov},}@ARTICLE{10355065,
  author={Aceto, Giuseppe and Ciuonzo, Domenico and Montieri, Antonio and Persico, Valerio and Pescapé, Antonio},
  journal={IEEE Communications Magazine}, 
  title={AI-Powered Internet Traffic Classification: Past, Present, and Future}, 
  year={2024},
  volume={62},
  number={9},
  pages={168-175},
  abstract={Traffic classification (TC) is pivotal for network traffic management and security. Over time, TC solutions leveraging artificial intelligence (AI) have undergone significant advancements, primarily fueled by machine learning (ML). This article analyzes the history and current state of AI-powered TC on the Internet, highlighting unresolved research questions. Indeed, despite extensive research, key desiderata goals to product-line implementations remain. AI presents untapped potential for addressing the complex and evolving challenges of TC, drawing from successful applications in other domains. We identify novel ML topics and solutions that address unmet TC requirements, shaping a comprehensive research landscape for the TC future. We also discuss the interdependence of TC desiderata and identify obstacles hindering AI-powered next-generation solutions. Overcoming these roadblocks will unlock two intertwined visions for future networks: self-managed and human-centered networks.},
  keywords={Artificial intelligence;Internet;Robustness;Feature extraction;Context modeling;Adaptation models;Training;Telecommunication traffic;Internet;Classification algorithms},
  doi={10.1109/MCOM.001.2300361},
  ISSN={1558-1896},
  month={Sep.},}@INPROCEEDINGS{10437125,
  author={Sapavath, Naveen Naik and Kim, Brian and Chowdhury, Kaushik and Shah, Vijay K},
  booktitle={GLOBECOM 2023 - 2023 IEEE Global Communications Conference}, 
  title={Experimental Study of Adversarial Attacks on ML-Based xApps in O-RAN}, 
  year={2023},
  volume={},
  number={},
  pages={6352-6357},
  abstract={Open Radio Access Network (O-RAN) is considered as a major step in the evolution of next-generation cellular networks given its support for open interfaces and utilization of artificial intelligence (AI) into the deployment, operation, and maintenance of RAN. However, due to the openness of the O-RAN architecture, such AI models are inherently vulnerable to various adversarial machine learning (ML) attacks, i.e., adversarial attacks which correspond to slight manipulation of the input to the ML model. In this work, we showcase the vulnerability of an example ML model used in O-RAN, and experimentally deploy it in the near-real time (near-RT) RAN intelligent controller (RIC). Our ML-based interference classifier xAp$p$ (extensible application in near-RT RIC) tries to classify the type of interference to mitigate the interference effect on the O-RAN system. We demonstrate the first-ever scenario of how such an xApp can be impacted through an adversarial attack by manipulating the data stored in a shared database inside the near-RT RIC. Through a rigorous performance analysis deployed on a laboratory O-RAN testbed, we evaluate the performance in terms of capacity and the prediction accuracy of the interference classifier xApp using both clean and perturbed data. We show that even small adversarial attacks can significantly decrease the accuracy of ML application in near-RT RIC, which can directly impact the performance of the entire O-RAN deployment.},
  keywords={Databases;Interference;Maintenance engineering;Performance analysis;Global communication;Artificial intelligence;Next generation networking},
  doi={10.1109/GLOBECOM54140.2023.10437125},
  ISSN={2576-6813},
  month={Dec},}@INPROCEEDINGS{10825734,
  author={Anastasiou, Theodora and Pastellas, Ioannis and Karagiorgou, Sophia},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={Adversarial Explanations for Informed Civilian and Environmental Protection}, 
  year={2024},
  volume={},
  number={},
  pages={2672-2681},
  abstract={Combating crime and conditions of high physical risk in cities, the environment, and critical infrastructures requires a multifaceted approach. For sensitive problems, such as advanced situational awareness in the fields of civilian applications and environmental protection, Artificial Intelligence (AI) and Neural Network (NN) adoption has been slow due to concerns about their reliability, leading to several algorithms for explaining their decisions. Despite the possibilities for AI in critical infrastructure protection and civilian applications, many challenges still exist. For instance: (i) there are complex and high risks meaning that AI systems need to be transparent and interpretable to gain decision-maker trust; (ii) AI models may be vulnerable to imperceptible manipulations of input data even without any knowledge about the AI technique that is used; (iii) the need to efficiently process distributed, multimodal and big data coming from different, but however cheap, Internet of Things (IoT) and sensory devices (e.g., drones, cameras, accelerometers, telemetry, geomagnetic field, and proximity sensors); and (iv) many AI methods based on Machine Learning (ML) require huge amounts of training data, resulting in a Big Data computation problem. We introduce, benchmark, and demonstrate an adversarial explanations approach that we can efficiently tackle both adversarial robustness and explanation complexity of AI systems. To achieve this, we train robustified NNs and transparent explainers on big imagery data and leverage the attacks’ knowledge as explanations to gain greater fidelity to the AI model. The merit of the proposed approach is that the new and robustified model has a great performance against new, unseen types of perturbations and attacks. This way, we pave the adoption of more informed and responsible AI integration in sensitive application domains.},
  keywords={Location awareness;Urban areas;Big Data;Data models;Critical infrastructure;Complexity theory;Internet of Things;Artificial intelligence;Heat maps;Protection;adversarial explanations;robust and trustworthy explainability;AI model interpretability with confidence scores},
  doi={10.1109/BigData62323.2024.10825734},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{10762409,
  author={Rajput, Aditi and Jaiwani, Megha and Singh, Saumya and Gandhi, Aradhana and Gopalkrishnan, Santosh},
  booktitle={2024 International Seminar on Application for Technology of Information and Communication (iSemantic)}, 
  title={Influencer Marketing Redefined: The Era of AI-Powered Personalization}, 
  year={2024},
  volume={},
  number={},
  pages={482-488},
  abstract={Integrating Artificial Intelligence (AI) with social media algorithms is pivotal in optimizing content visibility and engagement across platforms. By leveraging AI's analytical power, marketers can predict which content will perform best, aligning campaigns with audience preferences and boosting success rates. This study investigates the impact of AI-driven personalized content on customer engagement and purchase intentions in the marketing industry. We examined how AI-driven personalization maximizes customer engagement and influences purchasing behavior through surveys administered to 322 followers who consume social media content and have purchased products through that content or social media influencers. The research highlights the positive interactions between influencers and followers, demonstrating the significant impact of tailored content on brand awareness and consumer decision-making. These insights are valuable for influencers, marketers, and customers. Influencers can refine their content strategies to engage their audience better, resulting in stronger follower relationships and increased influence. Marketers gain a deeper understanding of how AI personalization can enhance campaign effectiveness, leading to higher customer engagement and sales. Customers benefit from more relevant and appealing content, improving their overall experience and satisfaction. The findings of the study could be utilized by marketers to improve influencer campaigns, elevate customer engagement, and bolster brand awareness, driving sales in the digital marketing environment.},
  keywords={Surveys;Seminars;Industries;Visualization;Social networking (online);Shape;Decision making;Prediction algorithms;Artificial intelligence;Usability;Influencer marketing;AI Personalization;Brand Awareness;Purchase Intent;Marketing Experience;E-Commerce},
  doi={10.1109/iSemantic63362.2024.10762409},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10325940,
  author={Jafarzade, Kamran},
  booktitle={2023 5th International Conference on Problems of Cybernetics and Informatics (PCI)}, 
  title={The Role of GPT Models in Education: Challenges and Solutions}, 
  year={2023},
  volume={},
  number={},
  pages={1-3},
  abstract={This paper investigates the transformative potential of Generative Pretrained Transformer (GPT) models in education and highlights the associated challenges and solutions. The applications of GPT models in education span a wide spectrum, including personalized tutoring, content generation, and intelligent feedback mechanisms. However, their effective integration into educational systems faces hurdles such as a lack of interpretability, privacy concerns, ethical dilemmas, and standardization issues. This paper proposes solutions that include the development of explainable AI (XAI), robust data protection measures, comprehensive ethics guidelines, and standardization norms. Further research directions such as improving personalization, developing reliable evaluation metrics, training models on domain-specific data, and fostering AI literacy among educators and students are discussed.},
  keywords={Training;Measurement;Ethics;Privacy;Transformers;Data models;Regulation;Generative Pretrained Transformer;GPT models;AI in education;explainable AI;data privacy;AI ethics;standardization;personalization;content accuracy;AI literacy;learning experience},
  doi={10.1109/PCI60110.2023.10325940},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10754728,
  author={Hamada, Amal and Hassan, Salwa Mohamed and Samy, Salma and Azab, Mohamed and Fathalla, Efat},
  booktitle={2024 IEEE 15th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)}, 
  title={A Review: State-of-the-Art of Integrating AI Models with Moving-target Defense for Enhancing IoT Networks Security}, 
  year={2024},
  volume={},
  number={},
  pages={108-114},
  abstract={The rapid proliferation of IoT devices across various sectors has significantly expanded the attack surface for cyber threats. Traditional security strategies, which rely on static defenses, often fail to adequately protect these diverse and resource-constrained devices, rendering them vulnerable to attacks. To address this challenge, proactive security mechanisms like Moving-Target Defense (MtD) introduce dynamic, real-time changes, making systems less predictable and more challenging for attackers to exploit. However, deploying MtD strategies in IoT networks presents various limitations and trade-offs between the network’s trustworthiness, performance, and compatibility. To overcome these challenges, AI-based MtD strategies offer a promising solution by dynamically adapting and optimizing defense mechanisms, thereby enhancing system resilience and unpredictability. This paper systematically reviews the use of Artificial Intelligence (AI) models to improve security in IoT networks, with a particular focus on integrating AI with MtD techniques to bolster network resilience. The review adheres to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) model principles and employs a systematic mapping process to analyze AI’s effectiveness in predicting and mitigating IoT attacks while exploring the potential of MtD mechanisms.},
  keywords={Performance evaluation;Systematics;Predictive models;Network security;Rendering (computer graphics);Mobile communication;Real-time systems;Internet of Things;Artificial intelligence;Resilience;IoT network;potential IoT attacks;AI;IoT resource constraints;proactive defense;Decision-making;MtD;Reinforcement Learning;security metrics},
  doi={10.1109/UEMCON62879.2024.10754728},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11051879,
  author={Kumar, Ashutosh and Yadav, Aditya and Chahar, Shantanu and Uchoi, Enjula},
  booktitle={2025 International Conference on Engineering, Technology & Management (ICETM)}, 
  title={Smart Mirror with Deep Learning for Health Evaluation, Skincare, and Virtual Enhancement}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper introduces a novel AI-powered smart mirror system that combines computer vision, augmented reality (AR), and smart home technologies to offer personalized recommendations for health, skincare, and beauty. The suggested system uses sophisticated facial recognition and skin analysis algorithms to evaluate user’s facial features, skin health, and emotional state in real-time. By integrating AR capabilities, the mirror provides virtual makeup try-ons and fitness tracking visualizations, and it also integrates with smart home devices to offer a comprehensive wellness experience. Our results show notable improvements in user engagement and satisfaction when compared to traditional mirrors, with a $92 \%$ accuracy in skin condition analysis and an $87 \%$ user preference rate for AR- based features. This smart mirror technology has the potential to transform personal care routines and improve overall well-being.},
  keywords={Computer vision;Accuracy;Face recognition;Smart homes;Medical services;Skin;Real-time systems;Mirrors;Artificial intelligence;Augmented reality;Artificial Intelligence (AI);Computer Vision;Augmented Reality (AR);Smart Mirror Technology},
  doi={10.1109/ICETM63734.2025.11051879},
  ISSN={},
  month={May},}@INPROCEEDINGS{10973884,
  author={Survawanshi, Vaishnavi and Shivam and Singh, Kulvinder and Kumari, Smriti and Sagar, Sudhanshu and Kumar, Harshvardhan},
  booktitle={2024 International Conference on Progressive Innovations in Intelligent Systems and Data Science (ICPIDS)}, 
  title={AI - Powered Financial Fraud Detection and Prevention Framework}, 
  year={2024},
  volume={},
  number={},
  pages={89-95},
  abstract={A financial fraud detection system which relies on AI technologies makes use of advanced machine learning and artificial intelligence techniques to detect and avoid fraudulent activity in financial transactions. The system is designed to be very effective in the analysis of large data with a minimal potential of false positive ensuring that genuine transactions are not wrongly categorized as fraud. New data is integrated into the system automatically without any thrashing improving algorithms as time passes. Also adversarial learning techniques are included to subdue changes in fraud model, which would allow the system to be able to fore see and counter any potentially threatening adversaries learning the counter fraud strategies that evolve along with time. This system is capable of operating either independently or being incorporated within the existing finance system and there is no requirement of manual effort or real time training of employees to prevent or control fraud.},
  keywords={Training;Technological innovation;Prevention and mitigation;Finance;Adversarial machine learning;Real-time systems;Fraud;Blockchains;Security;Artificial intelligence;Adversarial Learning;Explainable AI (XAI);Fraudulent Transaction;Big Data Analytics;Blockchain Integration;False Positive Reduction},
  doi={10.1109/ICPIDS65698.2024.00023},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10827479,
  author={Jang, Yong Hun and Oh, Seung Hyun and Lee, Sang Hyun and Lee, Hoon},
  booktitle={2024 15th International Conference on Information and Communication Technology Convergence (ICTC)}, 
  title={Cooperative AI Techniques for Ocean Path Planning of Maritime Autonomous Surface Ships}, 
  year={2024},
  volume={},
  number={},
  pages={246-251},
  abstract={This paper explores the use of Artificial Intelligence (AI) techniques for collaborative path planning in Maritime Autonomous Surface Ships (MASS). To improve both safety and efficiency in navigation, path planning is enhanced with AI-driven approaches that align with International Regulations for Preventing Collisions at Sea (COLREGs) set forth by the International Maritime Organization (IMO). The challenges of path planning, both at global and local levels, are addressed to emphasize the role of the cooperation among vessels in optimizing the AI performance. Furthermore, various cooperative frameworks are discussed by focusing on technical aspects, such as sharing positional and control data between vessels, and by developing advanced message-passing methods to enhance real-time navigation accuracy. Finally, a feasibility study is investigated presented, showing the potential of AI-based cooperative strategies to lower collision risks and boost the maritime navigation effectiveness.},
  keywords={Training;Sea surface;Navigation;Simulation;Sea measurements;Path planning;Safety;Reliability;Artificial intelligence;Marine vehicles},
  doi={10.1109/ICTC62082.2024.10827479},
  ISSN={2162-1241},
  month={Oct},}@INPROCEEDINGS{11070335,
  author={Shivamani, S. Sai and Regulwar, Ganesh B. and Reddy, A. Siri and Vamshi, K. and Sawant, Prathamesh Satish and Vandana, T. Sri},
  booktitle={2025 4th OPJU International Technology Conference (OTCON) on Smart Computing for Innovation and Advancement in Industry 5.0}, 
  title={Synthetic soundscapes: Deep Learning and AI in Music}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Advances in neural network topologies and deep learning have sparked a great deal of interest in music production based on artificial intelligence. Based on transformer models enhanced with attention processes, we provide a novel music generation system in this study. The system employs a comprehensive preprocessing pipeline to prepare the MIDI input for model training, ensuring that the musical elements are accurately represented. A well-designed transformer model is then trained to generate new musical compositions by capturing both short-term and long-term relationships within the music.},
  keywords={Deep learning;Training;Computational modeling;Pipelines;Neural networks;Data preprocessing;Music;Transformers;Data models;Artificial intelligence;Neural Networks in Music;Transformer Models;AI-based Music Systems;MIDI Data Preprocessing;Music Generation System;Sequential Data Modeling},
  doi={10.1109/OTCON65728.2025.11070335},
  ISSN={},
  month={April},}@INPROCEEDINGS{11049098,
  author={Ibrahim, Rahmeh and Qaddomi, Ashraf},
  booktitle={2025 12th International Conference on Information Technology (ICIT)}, 
  title={A Novel Genetic Algorithm-Optimized Selective Encryption for Enhanced Privacy in Medical Imaging}, 
  year={2025},
  volume={},
  number={},
  pages={228-235},
  abstract={With the increasing application of artificial intelligence (AI) in medicine, ensuring the privacy and security of sensitive medical image information is a critical concern. Traditional encryption methods, which encrypt entire images, are usually associated with large computational overhead and low efficiency. This article presents a novel approach to enhance data security through selective encryption of limited key blocks of images while significantly debilitating AI-driven classification. The selection of the most influential non-overlapping image blocks, affecting classification results most, is optimized using a genetic algorithm (GA). Optimization is done based on an optimized fitness function that maximizes misclassification rates while minimizing the number of encrypted blocks and thus ensuring computational efficiency. The selected blocks are then securely encrypted using the Advanced Encryption Standard (AES) for ensuring data confidentiality without the extra overhead of processing. Experimental findings indicate that the suggested scheme effectively degrades classification accuracy using minimal levels of encryption, realizing the best trade-off among data security, computational complexity, and practicability. Selective encryption provides a viable solution to medical image data protection without sacrificing resource optimality, making it highly suitable for real-world healthcare applications.},
  keywords={Privacy;Medical services;Encryption;Computational efficiency;Artificial intelligence;Information technology;Standards;Optimization;Genetic algorithms;Biomedical imaging;Genetic Algorithm;Advanced Encryption Standard;Optimization;Block Encryption;Healthcare},
  doi={10.1109/ICIT64950.2025.11049098},
  ISSN={2831-3399},
  month={May},}@INPROCEEDINGS{11101575,
  author={De Filippo, Bruno and Amatetti, Carla and Campana, Riccardo and Guidotti, Alessandro and Vanelli-Coralli, Alessandro},
  booktitle={2024 IEEE Globecom Workshops (GC Wkshps)}, 
  title={An SCMA Receiver for 6G NTN based on Multi-Task Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Future 6G networks are envisioned to enhance the user experience in a multitude of different ways. The unification of existing terrestrial networks with non-terrestrial network (NTN) components will provide users with ubiquitous connectivity. Multi-access edge computing (MEC) will enable low-latency services, with computations performed closer to the end users, and distributed learning paradigms. Advanced multiple access schemes, such as sparse code multiple access (SCMA), can be employed to efficiently move data from edge nodes to spaceborne MEC servers. However, the non-orthogonal nature of SCMA results in interference, limiting the effectiveness of traditional SCMA receivers. Hence, NTN links should be protected with robust channel codes, significantly reducing the uplink throughput. Thus, we investigate the application of artificial intelligence (AI) to SCMA receivers for 6G NTNs. We train an AI model with multi-task learning to optimally separate and receive superimposed SCMA signals. Through link level simulations, we evaluate the block error rate (BLER) and the aggregated theoretical throughput achieved by the AI model as a function of the received energy per bit over noise power spectral density ratio (Eb/N0). We show that the proposed receiver achieves a target 10% BLER with 3.5dB lower Eb/N0 with respect to the benchmark algorithm. We conclude the assessment discussing the complexity-related challenges to the implementation of the AI model on board of a low earth orbit satellite.},
  keywords={6G mobile communication;Codes;Satellites;Low earth orbit satellites;Receivers;Multitasking;Throughput;Servers;Artificial intelligence;Uplink;Non-Orthogonal Multiple Access;Deep Learning;Multi-Task Learning;Non-Terrestrial Networks},
  doi={10.1109/GCWkshp64532.2024.11101575},
  ISSN={2166-0077},
  month={Dec},}@INPROCEEDINGS{11136074,
  author={Kaur, Manpreet and V, Athulya Jayan and Maurya, Nikhil and Mahesh, Kute Sahil and Singh, Sammerjit},
  booktitle={2025 International Conference on Sensors and Related Networks (SENNET) Special Focus on Digital Healthcare(64220)}, 
  title={Enhanced U-Net-Based Deep Learning Model for Accurate Skin Cancer Detection and Prognosis}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Skin cancer stands as one of the leading cancers worldwide but requires early diagnosis to produce successful results during treatment. This paper develops an AI (Artificial Intelligence) and DL (Deep Learning) method for exact skin lesion segmentation on the HAM10000 dataset, which contains 10,015 dermatological images. A U-Net architecture with encoder-decoder design and skip connections proves successfully capable of preserving spatial information throughout different resolution ranges. Research showed a test accuracy of 93.70% while precision reached 85.88% and recall amounted to 93.96%. The key metric of interest was the Dice coefficient which reached 85.36%. Training required a combination of the Binary Cross Entropy and Dice coefficient metrics for class-imbalanced segmentation tasks together with purpose-driven data augmentation procedures. The model maintained reliable performance throughout ten epochs due to an optimized learning rate reduction protocol which controlled the overfitting risks that occurred during later epochs. The presented research adds value to dermatologic clinical expertise through a strong interpretable segmentation algorithm that supports early detection of skin cancer while improving diagnostic potential.},
  keywords={Deep learning;Measurement;Training;Image segmentation;Accuracy;Skin;Sensors;Artificial intelligence;Spatial resolution;Skin cancer;U-Net Architecture;Deep Learning;Image Segmentation;Dice Coefficient},
  doi={10.1109/SENNET64220.2025.11136074},
  ISSN={},
  month={July},}@INPROCEEDINGS{10971593,
  author={Sisson, Eric Scott and Puckett, Steven C.},
  booktitle={SoutheastCon 2025}, 
  title={Securing Digital Media in the Age of AI and Deepfakes: A Hardware-Based Solution}, 
  year={2025},
  volume={},
  number={},
  pages={1171-1176},
  abstract={The current capabilities of deepfake and Artificial Intelligence (AI) technologies make it difficult to distinguish what is original from what is fabricated. Electronic documents can be digitally signed to verify and authenticate their information, making them admissible as evidence in court. In contrast, images and videos from Internet of Things (IoT) devices-such as police body cameras, security cameras, and smartphones are susceptible to deepfake manipulation, which can undermine their authenticity in legal proceedings. This research hypothesizes that digitally signing image and video data utilizing hardware cryptographic coprocessors could render them admissible in court. Utilizing our processes will also identify if any manipulation of the image data has occurred. Our approach addresses a critical need in the justice system to combat the challenges deepfakes pose and could pave the way for enhanced trust in digital evidence, bolstering the integrity of the judicial process.},
  keywords={Deepfakes;Law enforcement;Media;Cameras;Hardware;Cryptography;Internet of Things;Artificial intelligence;Digital signatures;Coprocessors;deepfake;hashing;digital signature;cryptographic coprocessor;digital media},
  doi={10.1109/SoutheastCon56624.2025.10971593},
  ISSN={1558-058X},
  month={March},}@ARTICLE{9919765,
  author={Yang, Liu and Li, Yun and Yang, Simon X. and Lu, Yinzhi and Guo, Tan and Yu, Keping},
  journal={IEEE Network}, 
  title={Generative Adversarial Learning for Intelligent Trust Management in 6G Wireless Networks}, 
  year={2022},
  volume={36},
  number={4},
  pages={134-140},
  abstract={The emerging sixth generation (6G) is the integration of heterogeneous wireless networks, which can seamlessly support anywhere and anytime networking. But high quality of trust should be offered by 6G to meet mobile user expectations. Artificial intelligence (AI) is considered as one of the most important components in 6G. AI-based trust management is a promising paradigm to provide trusted and reliable services. In this article, a generative-adversarial-learning-en-abled trust management method is presented for 6G wireless networks. Some typical AI-based trust management schemes are first reviewed, and then a potential heterogeneous and intelligent 6G architecture is introduced. Next, the integration of AI and trust management is developed to optimize intelligence and security. Finally, the presented AI-based trust management method is applied to secure clustering to achieve reliable and real-time communications. Simulation results have demonstrated its excellent performance in guaranteeing network security and service quality.},
  keywords={6G mobile communication;Wireless networks;Simulation;Network security;Real-time systems;Adversarial machine learning;Telecommunication network management;Quality of service;Telecommunication network reliability},
  doi={10.1109/MNET.003.2100672},
  ISSN={1558-156X},
  month={July},}@INPROCEEDINGS{9613282,
  author={Gerlach, Tobias and Eggink, Derk H.D.},
  booktitle={2021 26th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA )}, 
  title={Generative Adversarial Networks for spot weld design}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={Joining element and assembly design remain largely a manual process. This increases risks of more costly and longer development trajectories. Current automation solutions do not consider historical data and traditional machine learning approaches have limitations. Meanwhile, generative adversary networks became benchmark methodologies to perform generation tasks in computer vision. Products in manufacturing industry may contain thousands of spot welds, thus design automation enables engineers to focus on their core competencies. This work presents a methodology to predict spot weld locations using generative adversarial networks. A 2D-based approach implements a variant of StarGAN_v2 to predict locations. It uses domain-based prediction concepts that integrate clustering of geometrical and product manufacturing information, as well as reference guided style generation. Results indicate that generative adversarial networks can predict spot weld positions based on 2D image data.},
  keywords={Training;Manufacturing industries;Visualization;Manuals;Spot welding;Generative adversarial networks;Trajectory;joining elements;machine learning;spot welding;engineering;automation;geometry;GAN;generative adversary network;neural networks;design;artificial intelligence},
  doi={10.1109/ETFA45728.2021.9613282},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10784676,
  author={Teo, Desmond Kai Xiang and Maul, Tomas and Tan, Michelle Tien Tien},
  booktitle={2024 IEEE SENSORS}, 
  title={Synthetic Electrochemical Biosensor Data with Conditional Variational Autoencoders for Enhanced Predictive Modeling}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Electrochemical biosensors (EB) have revolutionized various domains with their rapid and sensitive analyte detection capabilities. However, as EBs advance to tackle more challenging targets, the complexity of post hoc analysis intensifies, posing a significant bottleneck. Integrating AI with biosensing devices offers a promising solution, yet widespread adoption faces hurdles such as limited data availability. This study introduces a novel approach leveraging Conditional Variational Autoencoders to generate synthetic electrochemical data for augmenting training datasets. This approach aims to address the specific issue of data scarcity in the post hoc analysis of electrochemical biosensing data. Evaluation experiments demonstrate the effectiveness of incorporating synthetic data in enhancing prediction model performance, reducing the MRE by 41.16%, and achieving similar performance to a model trained with the full dataset by using only 50% of the training data supplemented with synthetic data. This work highlights a critical advancement, bridging the gap between AI and electrochemical biosensing, ultimately improving the efficiency and accuracy of post hoc analysis in this vital field.},
  keywords={Training;Biological system modeling;Training data;Predictive models;Data models;Sensors;Biosensors;Artificial intelligence;Faces;Synthetic data;Artificial Neural Network;Voltammetry;Electrochemical Biosensor;Multilayer Perceptron;Synthetic Data Generation;Variational Autoencoder},
  doi={10.1109/SENSORS60989.2024.10784676},
  ISSN={2168-9229},
  month={Oct},}@ARTICLE{9343871,
  author={Zhang, Xi and Zhang, Feifei and Xu, Changsheng},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Joint Expression Synthesis and Representation Learning for Facial Expression Recognition}, 
  year={2022},
  volume={32},
  number={3},
  pages={1681-1695},
  abstract={Facial expression recognition (FER) is a challenging task due to the large appearance variations and the lack of sufficient training data. Conventional deep approaches either learn a good representation through deep models or synthesize images automatically to enlarge the training set. In this paper, we perform both tasks jointly and propose an end-to-end deep model for simultaneous facial expression recognition and facial image synthesis. The proposed model is based on Generative Adversarial Network (GAN) and enjoys several merits. First, the facial image synthesis and facial expression recognition tasks can boost their performance for each other via the unified model. Second, paired images are not required in our facial image synthesis network, which makes the proposed model much more general and flexible. Meanwhile, the generated facial images largely expand the training set and ease the overfitting problem in our FER task. Third, different expressions are encoded in a disentangled manner in a latent space, which enables us to synthesize facial images with arbitrary expressions by exchanging certain parts of their latent identity features. Quantitative and qualitative evaluations on both controlled and in-the-wild FER benchmarks (Multi-PIE, MMI, and RAF-DB) demonstrate the effectiveness of our proposed method on both facial image synthesis and facial expression recognition task.},
  keywords={Face recognition;Task analysis;Generative adversarial networks;Image synthesis;Image recognition;Faces;Training;Facial expression recognition;facial image synthesis;generative adversarial network;representation learning},
  doi={10.1109/TCSVT.2021.3056098},
  ISSN={1558-2205},
  month={March},}@ARTICLE{10681072,
  author={Ferdous, Jannatul and Islam, Rafiqul and Mahboubi, Arash and Zahidul Islam, Md},
  journal={IEEE Access}, 
  title={AI-Based Ransomware Detection: A Comprehensive Review}, 
  year={2024},
  volume={12},
  number={},
  pages={136666-136695},
  abstract={Ransomware attacks are becoming increasingly sophisticated, thereby rendering conventional detection methods less effective. Recognizing this challenge, this study reviews advanced detection mechanisms and explores the potential of artificial intelligence (AI) techniques to improve detection capabilities. This study reviews the recent literature, including journal articles, conference proceedings, and online resources since 2017, to offer insights into the current state of AI-based ransomware detection and suggests future research directions. This study contributes significantly to the development of a systematic evaluation framework that evaluates each component of the AI-based detection model framework using specific criteria and methodologies and analyzes how various AI algorithms respond to different ransomware attacks, thereby providing insights for more effective and robust detection methods. This review begins with an overview of AI and ransomware, and discusses various types of ransomware attacks, the process of an attack chain, and emerging trends. We then review the existing literature on the core components of AI-based ransomware detection models, including the datasets and challenges arising during data collection, data pre-processing, feature engineering techniques, model training, and performance evaluation for effective model training. This study assessed the detection performance of AI models using metrics such as accuracy, precision, recall, and F1-score. By synthesizing these findings, we identify gaps in the current research and suggest future directions for enhancing AI-based ransomware detection techniques. The insights provided aim to guide researchers and practitioners in developing more robust methods for detecting and mitigating ransomware attacks by using AI.},
  keywords={Ransomware;Artificial intelligence;Reviews;Prevention and mitigation;Computer security;Systematics;Natural language processing;Cyberattack;Deep learning;Machine learning;Artificial intelligence;cyberattack;deep learning;feature engineering;machine learning;ransomware attack;ransomware datasets},
  doi={10.1109/ACCESS.2024.3461965},
  ISSN={2169-3536},
  month={},}@ARTICLE{10811907,
  author={Alnoman, Ali and Khwaja, Ahmed Shaharyar and Anpalagan, Alagan and Woungang, Isaac},
  journal={IEEE Access}, 
  title={Emerging AI and 6G-Based User Localization Technologies for Emergencies and Disasters}, 
  year={2024},
  volume={12},
  number={},
  pages={197877-197906},
  abstract={This paper presents state-of-the-art user localization technologies that can effectively assist the authorities and first responders to localize individuals during emergency and disaster scenarios. Localization is an essential tool that ensures preparedness, response, and coordination between first responders and impacted people. Many of these technologies employ artificial intelligence techniques to improve the localization accuracy using the information collected by a variety of sensing equipment such as sensors, unmanned aerial vehicles, wireless access points, cameras, and smart load meters. The paper also highlights the emerging sixth-generation (6G) wireless technologies such as integrated sensing and localization, THz communications, satellite-based non-terrestrial networks, and reconfigurable intelligent surfaces that can modify the reflection properties of materials to enable device localization. These technologies are expected to play a key role in enabling emergency services. Other localization technologies include WiFi, Bluetooth, radio frequency identification, and long range wide area network. In addition, crowd sensing and smart meter-based non-intrusive load monitoring (NILM) techniques that are supported by deep learning and federated learning techniques are also presented in the context of device localization. To the best of our knowledge, this paper introduces NILM for the first time as a useful technique that can provide information about the inhabitants’ behaviour in residential and commercial buildings to assist in emergency and public safety applications. All the technologies reviewed in this paper can play an effective role in device localization, and are presented to serve as a foundation for researchers to further investigate and conduct research in this domain.},
  keywords={Location awareness;Sensors;Disasters;6G mobile communication;Artificial intelligence;Accuracy;Global Positioning System;Intelligent sensors;Cameras;Terahertz communications;Localization;artificial intelligence;deep learning;6G;THz communications;reconfigurable intelligent surfaces;crowd sensing;unmanned aerial vehicles;non-intrusive load monitoring},
  doi={10.1109/ACCESS.2024.3521005},
  ISSN={2169-3536},
  month={},}@ARTICLE{10108979,
  author={Topsakal, Oguzhan and Dobratz, Eric J. and Akbas, Mustafa Ilhan and Dougherty, William M. and Akinci, Tahir Cetin and Celikoyar, Mehmet Mazhar},
  journal={IEEE Access}, 
  title={Utilization of Machine Learning for the Objective Assessment of Rhinoplasty Outcomes}, 
  year={2023},
  volume={11},
  number={},
  pages={42135-42145},
  abstract={Machine Learning started to provide solutions to various challenges in many fields, including medicine. The objective assessment of rhinoplasty results has been a challenge since the assessment of beauty is subjective in nature. This study explores if Machine Learning can be used to accomplish the complex task of objective evaluating the outcome evaluation and automated scoring for rhinoplasty. We introduce a methodology to map the aesthetics of visual appearance to the quantified measurements of pre-surgery, planned outcome, and post-surgery using machine learning. To develop the methodology, we generated synthetic 3D models utilizing artificial intelligence tools and applied various nasal deformities to simulate the pre-surgery, planned outcome, and post-surgery scans of rhinoplasty patients. The simulated outcomes were scored by reviewing the 3D visuals and corresponding measurements to prepare the training data for machine learning models. AutoGluon AutoML framework is used to generate the best-performing machine learning model. Machine learning models performed with 82% to 88% accuracy depending on the scoring method. We also identified the measurements that are highly influential in determining the scores. This is the first study that correlates the visual appearance and quantitative facial measurements of simulated rhinoplasty outcomes. The results suggest that an AI-based objective rhinoplasty outcome scoring tool is possible when machine learning algorithms are trained using consensus scores along with patients’ pre-surgery, planned, and post-surgery measurements. This study introduces a methodology regarding how to map the aesthetics of visual appearance to the quantified measurements of pre-surgery, planned outcome, and post-surgery using machine learning.},
  keywords={Three-dimensional displays;Solid modeling;Nose;Machine learning;Surgery;Artificial intelligence;Machine learning algorithms;Artificial intelligence;evaluation;machine learning;plastic surgery;rhinoplasty},
  doi={10.1109/ACCESS.2023.3270438},
  ISSN={2169-3536},
  month={},}@ARTICLE{10721463,
  author={Lewis, Jovita Relasha and Pathan, Sameena and Kumar, Preetham and Dias, Cifha Crecil},
  journal={IEEE Access}, 
  title={AI in Endoscopic Gastrointestinal Diagnosis: A Systematic Review of Deep Learning and Machine Learning Techniques}, 
  year={2024},
  volume={12},
  number={},
  pages={163764-163786},
  abstract={Gastrointestinal (GI) diseases are most common worldwide and the death rate can be reduced by early detection. Endoscopy is widely regarded as the gold standard for diagnosing and managing digestive disorders, affecting both the upper and lower GI tracts. Endoscopy is performed to uncover biopsy tissues used to check the presence of cancerous or benign cells, Helicobacter pylori (H. pylori) infection, or perform colonoscopy in case of the removal of polyps. A systematic review was conducted on databases like PubMed, Scopus, Google Scholar, and IEEE Explore, including research papers published up to May 2023, through the systematic search, 33 papers were identified. This review offers valuable insights to physicians and technological guidance to future researchers by examining GI tract diseases. It provides a detailed analysis of Machine learning (ML) techniques like preprocessing, segmentation, feature extraction, and classification. Additionally, Deep Learning (DL) approaches like transfer learning (TL), Convolution Neural Networks (CNN), optimization, transformer, and reinforcement learning have been analyzed for GI diagnosis. The DL approach has increased its use in GI diseases and CNN was the most commonly used architecture. Lastly, the review highlights the research published in the specialized GI fields and provides technological suggestions and insights for future research prospects. Overall, this study broadens the body of knowledge regarding the existing Artificial Intelligence (AI) techniques in gastroenterology as a manual for creating and assessing AI models.},
  keywords={Cancer;Diseases;Stomach;Artificial intelligence;Endoscopes;Medical services;Solid modeling;Lesions;Feature extraction;Optimization;Gastrointestinal tract;Deep learning;Convolutional neural networks;Transfer learning;Gastrointestinal disease;artificial intelligence;endoscopy;deep learning;machine learning;colon cancer;gastric cancer;early diagnosis;preprocessing;segmentation;feature extraction;classification;CNN;transfer learning;optimization},
  doi={10.1109/ACCESS.2024.3483432},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8489550,
  author={Zhang, Lujuan and Li, Jun and Huang, Tao and Ma, Zhenyuan and Lin, Zhiyong and Prasad, Mukesh},
  booktitle={2018 International Joint Conference on Neural Networks (IJCNN)}, 
  title={GAN2C: Information Completion GAN with Dual Consistency Constraints}, 
  year={2018},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper proposes an information completion technique, GAN2C, by imposing dual consistency constraints (2C) to a closed loop encoder-decoder architecture based on the generative adversarial nets (GAN). When adopting deep neural networks as function approximators, GAN2C enables highly effective multi-modality image conversion with sparse observation in the target modes. For empirical demonstration and model evaluation, we show that trained deep neural networks in GAN2C can infer colors for grayscale images, as well as estimate rich 3D information of a scene by densely predicting the depths. The results of the experiments show that in both tasks GAN2C as a generic framework has been comparable to or advanced the state-of-the-art performance which are achieved by highly specialized systems. Code is available at https://github.com/AdalinZhang/GAN2C.},
  keywords={Image color analysis;Gallium nitride;Task analysis;Neural networks;Gray-scale;Generative adversarial networks;Probabilistic logic;Deep Neural Networks;Image Processing;Generative Adversarial Nets},
  doi={10.1109/IJCNN.2018.8489550},
  ISSN={2161-4407},
  month={July},}@ARTICLE{10804758,
  author={Khan, Murad Ali and Naqvi, Syed Shehryar Ali and Faseeh, Muhammad and Kim, Do-Hyeun},
  journal={IEEE Access}, 
  title={Transformer-Driven Inverse Learning for AI-Powered Ceramic Material Innovation With Advanced Data Preprocessing}, 
  year={2025},
  volume={13},
  number={},
  pages={7574-7589},
  abstract={In the advanced landscape of materials science, particularly in the development of ceramic materials, artificial intelligence (AI) emerged as a transformative tool for accelerating innovation. This study proposed a comprehensive analysis of the Transformer-based Inverse Learning model to optimize component and process recommendations. K-Nearest Neighbors (KNN) imputation was first applied, improving data accuracy and completeness to address data gaps. Subsequently, Variational Autoencoders (VAE) were used for data augmentation, enriching the dataset’s diversity. The Transformer model, leveraging this enhanced data, demonstrated strong predictive performance, achieving an R2 score of 0.966 for component analysis and an outstanding R2 score of 0.982 for process analysis in Barium Titanate (BaTiO3) material data. These results show the effectiveness of combining imputation, augmentation, and advanced AI modeling in capturing complex material properties. The study highlights the potential of AI-driven methodologies to significantly improve prediction accuracy in material discovery, offering valuable insights for developing future ceramic materials.},
  keywords={Data models;Transformers;Predictive models;Nearest neighbor methods;Data augmentation;Artificial intelligence;Materials science and technology;Ceramics;Imputation;Accuracy;Artificial intelligence (AI);materials science;ceramic materials;transformer-based model;inverse learning;data augmentation;k-nearest neighbors (KNN);barium Titanate;potassium sodium Niobate},
  doi={10.1109/ACCESS.2024.3519390},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10393694,
  author={Gupta, Shreya and Rani, Ritu and Jaiswal, Garima and Sharma, Arun},
  booktitle={2023 International Conference on Evolutionary Algorithms and Soft Computing Techniques (EASCT)}, 
  title={Enhancing the Classification Accuracy using CNN, GANs, and data Augmentation Techniques}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={This research paper’s primary objective revolves around addressing the critical issue of handling imbalanced data sets, particularly in the context of image classification tasks with an uneven distribution of images. The imbalanced data set can lead to biased predictions, which can have adverse impacts in numerous domains such as medical diagnostics and agriculture. This clearly shows the urgency of addressing this problem and finding effective solutions to mitigate its impact. Hence, this study began with an imbalanced image data set, resulting in biased accuracy, and to address this problem, this research has proposed an innovative two-step approach using data augmentation and generative adversarial networks (GANs) to balance the data set. This balanced data set was then used to train the CNN classification model, achieving impressive results with an accuracy of 97.03%, a precision of 0.75, a recall of 0.83, and an F1-score of 0.79. Hence, the proposed methodology significantly improves classification accuracy and performance, demonstrating the potential of this approach to rectify imbalances in image classification tasks.},
  keywords={Neural networks;Evolutionary computation;Generative adversarial networks;Data augmentation;Data models;Agriculture;Medical diagnosis;Generative Adversarial Networks (GANs);Convolutional Neural Network (CNN);Deep CNN;Image Augmentation;Imbalanced Dataset},
  doi={10.1109/EASCT59475.2023.10393694},
  ISSN={},
  month={Oct},}@ARTICLE{9686068,
  author={Lin, Qiuzhen and Fang, Zhixiong and Chen, Yi and Tan, Kay Chen and Li, Yun},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, 
  title={Evolutionary Architectural Search for Generative Adversarial Networks}, 
  year={2022},
  volume={6},
  number={4},
  pages={783-794},
  abstract={The Generative Adversarial Network (GAN) has shown powerfulness in various real-world artificial intelligence applications. However, its network architecture is generally designed through a manual trial-and-error process, which is relatively tedious, slow, and sub-optimal. This paper hence develops an evolutionary architectural search (EAS) technique to automate the entire design process of the GAN. In particular, different objective functions are used in the generator of a GAN as variation operators. This helps train the generator with various candidate architectures and their associated weights to play adversarial training against the discriminator of the GAN. Following evaluations by the discriminator, superior candidate generators survive to the next generation and evolve for potentially better architectures and their weights simultaneously, leading to more stabilized GANs with improved performance. The GAN designed through EAS is termed an EAS-GAN in this paper and is tested against existing evolutionary and other state-of-the-art GANs. The test results show that the EAS-GAN offers better generative performance overall, with the Fréchet inception distance scoring 22.1, 38.8, and 8.3 on the CIFAR-10, STL-10, and LSUN bedroom data sets, respectively.},
  keywords={Generators;Training;Computer architecture;Generative adversarial networks;Search problems;Evolutionary computation;Network architecture;Generative adversarial networks;evolutionary algorithm;neural architecture search},
  doi={10.1109/TETCI.2021.3137377},
  ISSN={2471-285X},
  month={Aug},}@INPROCEEDINGS{10655270,
  author={Zhang, Hui and Dong, Xingbo and Lai, YenLung and Zhou, Ying and Zhang, Xiaoyan and Lv, Xingguo and Jin, Zhe and Li, Xuejun},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Validating Privacy-Preserving Face Recognition Under a Minimum Assumption}, 
  year={2024},
  volume={},
  number={},
  pages={12205-12214},
  abstract={The widespread use of cloud-based face recognition technology raises privacy concerns, as unauthorized access to face images can expose personal information or be exploited for fraudulent purposes. In response, privacy-preserving face recognition (PPFR) schemes have emerged to hide visual information and thwart unauthorized access. However, the validation methods employed by these schemes often rely on unrealistic assumptions, leaving doubts about their true effectiveness in safeguarding facial privacy. In this paper, we introduce a new approach to pri-vacy validation called Minimum Assumption Privacy Protection Validation (Map2 V). This is the first exploration of formulating a privacy validation method utilizing deep image priors and zeroth-order gradient estimation, with the potential to serve as a general framework for PPFR eval-uation. Building upon Map2v, we comprehensively vali-date the privacy-preserving capability of PPFRs through a combination of human and machine vision. The exper-iment results and analysis demonstrate the effectiveness and generalizability of the proposed Map2v, showcasing its superiority over native privacy validation methods from PPFR works of literature. Additionally, this work exposes privacy vulnerabilities in evaluated state-of-the-art P P FR schemes, laying the foundation for the subsequent effective proposal of countermeasures. The source code is available at https://github.com/Beauty9882/MAP2V.},
  keywords={Privacy;Visualization;Face recognition;Source coding;Machine vision;Noise;Estimation;Privacy-Preserving Face Recognition;Privacy Validation;Minimum Assumption;Deep Generative Prior;Zeroth-order Gradient Estimation},
  doi={10.1109/CVPR52733.2024.01160},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{10826078,
  author={Olawoyin, Anifat M. and Leung, Carson K. and Nguyen, Hoang Hai and Cuzzocrea, Alfredo},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={Privacy-Preserving Publishing with Generative Adversarial Network (GAN) for Supporting Contact Tracing of Infectious Diseases}, 
  year={2024},
  volume={},
  number={},
  pages={6298-6307},
  abstract={Generative artificial intelligence (AI) has become popular. The combination of increasingly complex datasets beyond human comprehension and the widespread availability of advanced computing systems—such as graphics processing unit (GPU) and tensor processing unit (TPU)—has driven the rapid advancement of generative AI. This technology has found applications in areas such as voice recognition, recommendation systems and data privacy preservation, which foster more data sharing and reuse. While challenges related to bias, fairness and uncertainty in AI continue to evolve, emerging government regulations aim to ensure ethical use and maximize societal benefits. In this paper, we present a system that leverages generative adversarial network (GAN) to enable privacy-preserving data publishing. The system supports contact tracing for infectious diseases like coronavirus disease 2019 (COVID-19) and monkey-pox. Evaluation using COVID-19 data highlights the practicality and effectiveness of our system.},
  keywords={COVID-19;Uncertainty;Tensors;Infectious diseases;Publishing;Generative AI;Graphics processing units;Contact tracing;Generative adversarial networks;Systems support;Big data;Privacy;Computer;Resilience;Sustainability;Cyber-physical world;Data management;Spatial data;Temporal data;Co-occurrence data},
  doi={10.1109/BigData62323.2024.10826078},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{10812465,
  author={Wang, Chuyu and Yang, Fan and Zhu, Keren},
  booktitle={2024 IEEE International Symposium on Radio-Frequency Integration Technology (RFIT)}, 
  title={AI-Enabled Layout Automation for Analog and RF IC: Current Status and Future Directions}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={This paper provides an overview of AI-enabled layout automation for analog and RF integrated circuits (ICs). We examine recent advancements in machine learning algorithms, optimization techniques, and AI-driven design methodologies tailored to the unique challenges of analog and RF IC layout. The paper highlights the benefits, limitations, and key achievements of these AI approaches and identifies existing gaps. Finally, we discuss future directions and research opportunities, emphasizing AI's potential to enhance the efficiency and accuracy of IC layout design.},
  keywords={Radio frequency;Integrated circuits;Productivity;Automation;Machine learning algorithms;Large language models;Layout;Reinforcement learning;Routing;Optimization},
  doi={10.1109/RFIT60557.2024.10812465},
  ISSN={2836-3825},
  month={Aug},}@INPROCEEDINGS{11081572,
  author={Meza, Jaime and Saltos, María Fernanda Linzan and Campoverde, Elkin Uday Velastegui and Cejas, Mercedes Carolina Navarro and Castro, Valeria Carolina Argüello},
  booktitle={2025 Eleventh International Conference on eDemocracy & eGovernment (ICEDEG)}, 
  title={AI Regulation for Ecuador}, 
  year={2025},
  volume={},
  number={},
  pages={311-316},
  abstract={Generative AI has emerged exponentially. However, countries should prepare the administrative conditions to face the challenges and risks of AI. This research explores the regulatory design and governance processes of Artificial Intelligence (AI) at the European and American levels to compare them with the practices implemented in Ecuador from 2021-2024 by analyzing the role of institutions in this process and the results generated. It used Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) to pick up scientific documents. Data were chosen from three databases: IEEE Digital Library, Scopus, and Science Direct; furthermore, the theoretical Lens of Normative Institutionalism was applied to analyze the social relations of actors for the practice executed in Ecuador, front to international practices. Outcomes found that the standard practices between different countries around the world are based on (i) fairness, (ii) reliability, safety, and control, (iii) privacy and security, (iv) inclusiveness, (v) transparency, (vi) accountability and (vii) in pursuit of human benefits and happiness. In Ecuador, the road map has started to agree with international trends. However, future efforts will require mapping current institutional capacities and existing legal structures to determine what can be used.},
  keywords={Privacy;Roads;Reliability theory;Market research;Regulation;Libraries;Safety;Security;Standards;Systematic literature review;IA;governance;framework;risk;government},
  doi={10.1109/ICEDEG65568.2025.11081572},
  ISSN={2573-1998},
  month={June},}@INPROCEEDINGS{10705184,
  author={Harjamäki, Janne and Sillberg, Pekka and Saari, Mika and Rantanen, Petri and Soini, Jari and Abrahamsson, Pekka},
  booktitle={2024 IEEE 12th International Conference on Intelligent Systems (IS)}, 
  title={From Data to Documentation: Exploring the Use of ChatGPT's Custom Instructions for Report Generation}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Generative artificial intelligence has attracted global attention and interest in software engineering research, practical applications, and in business, especially in the past two years. Tools like Gemini, Copilot, and ChatGPT have been widely studied in various professional contexts for their exceptional ability to produce human-like content. Furthermore, the number of these artificial intelligence tools is increasing explosively. Within this context we have picked a very specific use case: namely, converting notes into a full, uniform report using ChatGPT's custom instructions. In this paper, we present the process of creating custom instructions for a certain task, how the instructions were tested, and the results of our study. The study shows that even though using custom instructions alone is perhaps not quite sufficient yet for fully automatic report generation, the approach can still save a considerable amount of time and resources. This study also highlights the pitfalls and obstacles faced, and should help those who are planning to embark on a similar quest.},
  keywords={Reviews;Generative AI;Chatbots;Planning;Artificial intelligence;Intelligent systems;Text processing;Software engineering;Business;Generative AI;ChatGPT;Custom Instructions;Reports},
  doi={10.1109/IS61756.2024.10705184},
  ISSN={2767-9802},
  month={Aug},}@INPROCEEDINGS{11158984,
  author={S, Prabu and R, Saravanan and T, Gomathi and R, Surendran and R, Deepa},
  booktitle={2025 International Conference on Computing Technologies & Data Communication (ICCTDC)}, 
  title={Generative Adversarial Networks for Endoscopic Image Classification}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Generative Adversarial Networks (GANs) have shown tremendous potential in medical image processing, particularly for the classification of endoscopic images. Endoscopic Image Classification using Machine Learning Algorithms (EIC-MLA) leverages GANs to enhance image generation and classification accuracy, enabling better diagnosis in gastrointestinal examinations. Existing methods for endoscopic image classification often suffer from low accuracy due to challenges such as poor image quality, limited datasets, and difficulty in differentiating between healthy and abnormal tissues. These issues hinder the reliability and precision of automated diagnostic systems. The proposed EIC-MLA framework addresses these limitations by utilizing a Generative Adversarial Network (GAN) model to improve data augmentation and enhance image quality, which is critical for accurate classification. The GAN-based framework generates high-quality synthetic images that closely mimic real endoscopic images, thereby expanding the training dataset and improving the performance of the classification algorithm. This method applies GAN-generated images in conjunction with a machine learning classifier to improve the differentiation between normal and abnormal tissue, enhancing diagnostic reliability. The integration of deep learning with GANs allows for a more robust classification model that can handle variations in image quality and appearance. The outcome of the proposed method demonstrates improved accuracy in endoscopic image classification, offering more precise and reliable diagnostic support. The enhanced performance of the EIC-MLA framework suggests that it could significantly contribute to the early detection of gastrointestinal diseases, improving patient outcomes. The EIC-MLA framework demonstrates exceptional performance, achieving 97.14% accuracy, 93.17% early detection, 98.29% improved patient outcomes, 95.11% image quality enhancement, and 98.31 % diagnostic reliability.},
  keywords={Image quality;Training;Deep learning;Accuracy;Generative adversarial networks;Gastrointestinal tract;Reliability;Medical diagnosis;Image classification;Diseases;endoscopic;image classification;generative adversarial networks;machine learning},
  doi={10.1109/ICCTDC64446.2025.11158984},
  ISSN={},
  month={July},}@INPROCEEDINGS{9722622,
  author={Kim, Chung-Il and Shin, Saim and Park, Han-Mu},
  booktitle={2022 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={CIAFill: Lightweight and Fast Image Inpainting with Channel Independent Attention}, 
  year={2022},
  volume={},
  number={},
  pages={221-229},
  abstract={Image inpainting is a classic technique in computer vision research. The quality of image inpainting has improved significantly since the advent of convolutional neural networks. However, this approach generally results in blurry and semantically inconsistent reconstruction because of operating valid and invalid pixels with equal weight. The gated convolution computing feature attention is proposed to resolve this issue but this attention mechanism was less efficient and computationally expensive. This study proposed CIAFill that alleviates this problem using channel independent attention. This mechanism applied channel attention to each channel for activating valid channels and reduced the computational cost to the dimension of the channel. The proposed architecture included a channel attention generator and a channel attention projection PatchGAN that utilize the channel independent attention mechanism. This study proved that CIAFill could successfully train the inpainting model with 1/1600 smaller gating parameters than the earlier gated convolution-based study. CIAFill achieved comparable performance to other feature attention-based approaches in the experiments on CelebA-HQ and Places2 datasets.},
  keywords={Computer vision;Image resolution;Convolution;Computer architecture;Logic gates;Real-time systems;Generators;inpainting;attention module;generative adversarial net},
  doi={10.1109/ICAIIC54071.2022.9722622},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{9593359,
  author={Mitra, Jhimli and MacDonald, Michael and Venugopal, Prem and Wallace, Kirk and Abdou, Hossam and Richmond, Michael and Elansary, Noha and Edwards, Joseph and Patel, Neerav and Morrison, Jonathan and Marinelli, Luca},
  booktitle={2021 IEEE International Ultrasonics Symposium (IUS)}, 
  title={Integrating artificial intelligence and color Doppler US for automatic hemorrhage detection}, 
  year={2021},
  volume={},
  number={},
  pages={1-4},
  abstract={Hemorrhage control has been identified as a priority focus area for the United States military because exsanguination is the most common cause of preventable death in battlefield. Non-compressible torso hemorrhage (NCTH) has high mortality rate and there are no available therapies for NCTH. New therapies, which include High Intensity Focused Ultrasound (HIFU) has emerged as a promising method for hemorrhage control as it can non-invasively cauterize bleeding tissue deep within the body without injuring uninvolved regions. A major challenge in the application of HIFU is the accurate targeting of therapeutic beam to the location of the bleed, requiring an expert sonographer to interpret images in real-time, currently limiting the utility of this therapy in remote environments. In this work, we investigated the use of an unsupervised anomaly detection network that learns a manifold of normal blood flow variability and subsequently identifies anomalous flow patterns that fall outside the learned manifold. As an initial feasibility study, we collected ultrasound color Doppler images of femoral arteries in an animal model of vascular injury ($\mathrm{N}=5$ pigs). The images were pre-processed to mask out velocities in surrounding tissues and were subsequently cropped, resized, augmented and normalized. The network was trained on normotensive images from 4 pigs and tested on normotensive, immediately after injury and 10 minutes post-injury images of 1 other pig. The residual images or the reconstructed error maps show promise in detecting hemorrhages with 81% and 64% sensitivity immediately and 10 minutes post-injury respectively and 70% specificity.},
  keywords={Manifolds;Ultrasonic imaging;Sensitivity;Image color analysis;Medical treatment;Doppler effect;Hemorrhaging;hemorrhage detection;color Doppler ultrasound;unsupervised anomaly detection;generative adversarial network;deep learning},
  doi={10.1109/IUS52206.2021.9593359},
  ISSN={1948-5727},
  month={Sep.},}@INBOOK{10897050,
  author={Islam, Mohammad Rubyet},
  booktitle={Generative AI, Cybersecurity, and Ethics}, 
  title={Foundations of Ethics in GenAI}, 
  year={2025},
  volume={},
  number={},
  pages={111-162},
  abstract={Summary <p>This chapter explores the ethical considerations essential for the responsible development and deployment of generative artificial intelligence (GenAI). It underscores the importance of guiding principles such as fairness, accountability, and transparency to mitigate biases and ensure privacy. The chapter traces the evolution of ethics in technology from ancient philosophies to contemporary artificial intelligence (AI) guidelines, highlighting pivotal regulatory frameworks like the EU's Ethics Guidelines for Trustworthy AI. It also emphasizes the need for adaptive and internationally converged regulatory approaches to address the unique challenges posed by GenAI, ensuring its alignment with societal values and ethical norms.</p>},
  keywords={Ethics;Artificial intelligence;Organizations;Intellectual property;Guidelines;Stakeholders;Nuclear weapons;Navigation;Decision making;Data protection},
  doi={10.1002/9781394279326.ch5},
  ISSN={},
  publisher={Wiley},
  isbn={9781394279319},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10897050},}@INBOOK{10897145,
  author={Islam, Mohammad Rubyet},
  booktitle={Generative AI, Cybersecurity, and Ethics}, 
  title={Privacy in GenAI in Cybersecurity}, 
  year={2025},
  volume={},
  number={},
  pages={179-201},
  abstract={Summary <p>This chapter dives into the critical aspect of privacy in generative artificial intelligence (GenAI) within cybersecurity. As artificial intelligence (AI) systems process vast amounts of sensitive data, the protection of personal information becomes paramount to prevent identity theft, fraud, and other malicious acts. This chapter explores the privacy challenges posed by GenAI, such as data leakage, reidentification, and deepfakes, and outlines best practices and techniques for privacy protection, including differential privacy, federated learning, and robust data governance. Through case studies and analysis of regulatory frameworks, the chapter emphasizes the necessity of transparency, accountability, and adherence to legal standards to safeguard individual privacy while leveraging GenAI for cybersecurity.</p>},
  keywords={Data privacy;Data models;Analytical models;Synthetic data;Protection;Differential privacy;Training data;Training;Privacy;Artificial intelligence},
  doi={10.1002/9781394279326.ch7},
  ISSN={},
  publisher={Wiley},
  isbn={9781394279319},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10897145},}@INPROCEEDINGS{10549103,
  author={Lin, Qingming and Li, Tengfei and Zhao, Yang and Guan, Jianyang and Zhang, Wenhui and Wang, Xiaocun},
  booktitle={2023 2nd International Conference on Clean Energy Storage and Power Engineering (CESPE)}, 
  title={Research on Charging Infrastructure Related Detection Technology Based on GAN}, 
  year={2023},
  volume={},
  number={},
  pages={57-62},
  abstract={With the rapid evolution of the power system and the widespread adoption of electric vehicles, efficiently harnessing vast and multifaceted power data for charging infrastructure detection has become a paramount technical challenge confronting the power and electric vehicle industries. When compared to conventional machine learning algorithms, deep learning stands out by offering the capability for data dimensionality reduction, along with its prowess in nonlinear modeling and feature extraction. Generative Adversarial Network (GAN), a prototypical deep learning model, can enhance and generate power data samples. This article first introduces the basic principles of GAN and analyzes its advantages and disadvantages. Subsequently, specific scenario examples of applying GAN-derived models in power system-related detection will be introduced, followed by a detailed overview of the current application status of GAN in power systems, and the GAN models and their characteristics used in each application scenario will be summarized. At the same time, introduces the specific scenarios in which the GAN model is applied to charging piles in current charging infrastructure, and explores the application and assistance of the GAN model in detecting abnormal data of charging piles. Finally, summarize the challenges awaiting resolution to facilitate the deeper integration of GANs into power systems and charging infrastructure detection, and also anticipate the prospects of their application.},
  keywords={Deep learning;Industries;Power engineering;Machine learning algorithms;Generative adversarial networks;Electric vehicles;Feature extraction;deep learning;generating adversarial networks;charging infrastructure;data augmentation;anomaly detection},
  doi={10.1109/CESPE60923.2023.00022},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10791271,
  author={Park, Yeongshin and Pawana, I Wayan Adi Juliawan and Kim, Bonam and You, Ilsun},
  booktitle={2024 IEEE International Symposium on Consumer Technology (ISCT)}, 
  title={Harnessing GAN to Create Realistic FBS(False Base Station) Attack Data in 5G}, 
  year={2024},
  volume={},
  number={},
  pages={404-408},
  abstract={The threat of false base stations (FBS) has evolved with the advancement of mobile communication, posing severe risks in the 5G era. FBSs can mimic legitimate stations, leading to various malicious activities like man-in-the-middle attacks, denial-of-service attacks, and spreading fake disaster messages. Detecting FBSs is crucial, but existing methods relying on machine learning face challenges due to insufficient datasets. To address this, Generative Adversarial Networks (GANs) are explored to augment limited datasets by generating realistic data. This paper investigates using GANs to enhance datasets for FBS detection, compares the similarity between generated and real datasets, and assesses detection accuracy. Furthermore, we trained machine learning models on GAN-generated data and utilized it to implement an FBS detection Network Function (NF) for 5G environments. Ultimately, we generated a dataset with a high similarity, with a Pearson correlation coefficient of 0.85, using GAN s. We confirmed the possibility of utilizing this dataset for FBS detection and applied it in a 5G environment.},
  keywords={Correlation coefficient;Base stations;5G mobile communication;Training data;Machine learning;Generative adversarial networks;Data models;Real-time systems;Noise measurement;Data mining;FBS;GAN;5G;NF},
  doi={10.1109/ISCT62336.2024.10791271},
  ISSN={2159-1423},
  month={Aug},}@INBOOK{11104986,
  author={Nag, Anindya and Hassan, Md. Mehedi and Karim, Asif and Kumar Reddy C, Kishor},
  booktitle={Generative AI in Neurodegenerative Disorders: Innovations, Views, and Obstacles}, 
  title={13 Generative AI Novel Drug Discovery Avenues}, 
  year={2025},
  volume={},
  number={},
  pages={331-358},
  abstract={This book delves into the transformative power of AI in the realm of neurodegenerative diseases, covering topics such as ALS, Huntington's, Parkinson's, and Alzheimer's. Generative AI provides new opportunities for early diagnosis, precise therapy, and individualized rehabilitation, which are crucial as these conditions remain major obstacles for healthcare providers and researchers. Researchers, physicians, AI developers, and healthcare professionals will find this book an invaluable resource for understanding how AI is influencing the development of treatments for neurodegenerative diseases. It describes important obstacles and future directions while providing insights into the newest breakthroughs, thus bridging the gap between technology and practical clinical applications. Anyone involved in neurodegenerative healthcare, from scientists conducting AI-driven medical research to physicians seeking to incorporate AI into patient care or AI professionals investigating new healthcare applications, will find the information and insights they need in this comprehensive book. Predictive analytics, biomarker identification, and drug discovery are being transformed by AI-driven models, such as deep neural networks, generative adversarial networks (GANs), and variational autoencoders (VAEs). This book offers a comprehensive examination of these developments. Robots, wearable sensors, and cognitive therapy platforms are some of the AI-enhanced rehabilitation tools covered, as are AI-integrated cutting-edge technologies like fMRI and MRI, gene-editing methods like CRISPR, and more. In addition to discussing recent technical developments, this book takes a close look at the data privacy, ethics, and regulatory issues that arise when using AI to study neurodegenerative disorders. Issues like algorithmic bias, model explainability, and fair AI-driven healthcare are thoroughly investigated in light of the growing usage of AI models in clinical decision-making, mental health applications, and cognitive rehabilitation.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788743801740},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11104986},}@INPROCEEDINGS{10534674,
  author={Capodieci, Noelle and Sanchez-Adames, Christopher and Harris, Joesph and Tatar, Unal},
  booktitle={2024 Systems and Information Engineering Design Symposium (SIEDS)}, 
  title={The Impact of Generative AI and LLMs on the Cybersecurity Profession}, 
  year={2024},
  volume={},
  number={},
  pages={448-453},
  abstract={This paper explores the evolving role of Generative AI (GenAI) and Large Language Models (LLMs) in cybersecurity. The motivation behind this research is the rapid advancement of GenAI technologies and their potential implications for cybersecurity professionals. This work focuses on assessing how GenAI and LLMs influence cybersecurity practices, including both the opportunities and risks they present. It specifically examines the use of GenAI in cybersecurity, its functions and industries, and the potential impact on the profession. The methodology involves conducting semi-structured interviews with eight cybersecurity professionals to gather insights on their experiences and perspectives regarding GenAI and LLMs. This qualitative approach allows for a deep exploration of the subjective experiences of these professionals in their work environments. The results indicate a cautious approach towards the adoption of GenAI in cybersecurity. While some professionals have begun to utilize these technologies, there are concerns regarding ethical and safety considerations, information security, and the potential for GenAI to influence the nature of cyber threats. The findings highlight the need for a balanced approach that recognizes the potential of GenAI while addressing the associated risks.},
  keywords={Training;Ethics;Generative AI;Phishing;Employment;Safety;Recycling},
  doi={10.1109/SIEDS61124.2024.10534674},
  ISSN={2994-3531},
  month={May},}@INPROCEEDINGS{10633568,
  author={Kobayashi, Atsuya and Yamaguchi, Saneyasu},
  booktitle={2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Extraction of Subjective Information from Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1612-1617},
  abstract={Large Language Models (LLMs) have been advancing natural language processing technologies for several years. Especially in the last year, generative AI (Artificial Intelligence) models have improved remarkably and attracted attention. Then, there has been a great discussion about these models, such as extracting the knowledge in these models. However, these existing works were mainly for the extraction of objective information. In this paper, we study the extraction of subjective information from LLMs by focusing on GPT, Gemini Pro, and Claude2. We then show that such information extraction can be severely limited in LLMs, but that information extraction is possible from some models.},
  keywords={Generative AI;Large language models;Computational modeling;Focusing;Information retrieval;Software;Natural language processing;large language model (LLM);generative AI;natural language processing (NLP);pre-trained language model;GPT;Gemini;Claude2},
  doi={10.1109/COMPSAC61105.2024.00253},
  ISSN={2836-3795},
  month={July},}@INPROCEEDINGS{11157935,
  author={Kumar, Rakesh and Kumar, Deepak and Sharma, Ayushi and Paikaray, Bijay Kumar and Yamsani, Nagendar and Sinha, Aashna},
  booktitle={2025 International Conference on Advancements in Smart, Secure and Intelligent Computing (ASSIC)}, 
  title={Application of Internet of Things (IOT) and Machine Learning in Indirect Tax Collection: Opportunity and Challenges}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Efficient and cost-effective Tax collection is an important challenge for tax authority, specifically indirect tax. Goods and services tax (GST) introduced on the concept of one nation one tax. Manual process required more manpower and there is risk of accuracy, fraud, tax evasion and tax diversification. Technology like artificial intelligence, block chain technology, internet of thing (IOT) and machine learning are some important tools which are effective in tax collection. With the help of technology tax evasion can be reduced with minimum cost and human effort. Artificial intelligence can integrate taxpayers and tax authority which brought out transparency. This study focuses on how IOT and machine learning are important in goods and services tax collection. The study finds that without technology GST law could not be implemented. Further study revealed that collection increased after automation in tax collection.},
  keywords={Costs;Tracking;Government;Finance;Machine learning;Manuals;Fraud;Blockchains;Internet of Things;Business;Internet of thing;GST;Taxation;assessment;Machine learning},
  doi={10.1109/ASSIC64892.2025.11157935},
  ISSN={},
  month={May},}@INPROCEEDINGS{10845598,
  author={Mestre, António and Marques, Ruben and Fernandes, Alexander and Silva, Bruno},
  booktitle={2024 8th International Symposium on Innovative Approaches in Smart Technologies (ISAS)}, 
  title={RAGNAR: Retrieval-Augmented Generation using Networked and Advanced Relational Data}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The technological evolution carried out in recent years has enabled significant developments in various areas of Artificial Intelligence (AI), such as Generative AI. Large Language Models (LLMs) are becoming increasingly complex, allowing for better results and enhancing their real-world applicability. However, these models still face issues such as hallucination or outdated information. This last one occurs due to the temporal gap between the training process and the model’s use. A Retrieval-Augmented Generation (RAG) architecture can address these issues since the information source used is not involved in the training phase, which also facilitates the reuse of models for different applications. One of the challenges of RAG is its applicability when the data source is a relational database, becoming even more challenging as the database size and complexity increase. This article proposes a potential architecture and approach for solving this problem and implementing a RAG architecture using a relational database as the data source.},
  keywords={Training;Generative AI;Soft sensors;Large language models;Retrieval augmented generation;Relational databases;Complexity theory;Faces;RAG;LLM;Generative AI;Relational Database},
  doi={10.1109/ISAS64331.2024.10845598},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11108780,
  author={Yang, Xiaoli and Cui, Rongyu and Xie, Xin},
  booktitle={2025 IEEE 5th International Conference on Software Engineering and Artificial Intelligence (SEAI)}, 
  title={AI - Driven Automated UML Modeling Framework Design and Practice}, 
  year={2025},
  volume={},
  number={},
  pages={144-148},
  abstract={The Unified Modeling Language (UML) is a core modeling tool in the field of software engineering, playing an irreplaceable role in system design and team collaboration. However, traditional UML modeling tools suffer from inefficiency, version conflicts, and disconnection between design and code. In recent years, breakthroughs in Generative Artificial Intelligence (AIGC) have provided new solutions for automated modeling. This study proposes a deep learning-based UML intelligent generation framework, aiming to directly generate standardized PlantUML code from natural language requirements. The framework achieves end-to-end automated generation from requirements to UML models through deep semantic parsing, multi-view collaborative mechanisms, and dynamic syntax validation pipelines. Experimental results show that the framework can compress the modeling cycle from hours to minutes, significantly improving modeling efficiency and providing a new paradigm for intelligent software engineering.},
  keywords={Codes;Costs;Architecture;Unified modeling language;Pipelines;Collaboration;Computer architecture;Syntactics;Modeling;Software engineering;AIGC;UML modeling;automated modeling;natural language processing},
  doi={10.1109/SEAI65851.2025.11108780},
  ISSN={},
  month={June},}@ARTICLE{10628100,
  author={Allen, Mia and Naeem, Usman and Gill, Sukhpal Singh},
  journal={IEEE Transactions on Education}, 
  title={Q-Module-Bot: A Generative AI-Based Question and Answer Bot for Module Teaching Support}, 
  year={2024},
  volume={67},
  number={5},
  pages={793-802},
  abstract={Contributions: In this article, a generative artificial intelligence (AI)-based Q&A system has been developed by integrating information retrieval and natural language processing techniques, using course materials as a knowledge base and facilitating real-time student interaction through a chat interface. Background: The rise of advanced AI exemplified by ChatGPT developed by OpenAI, has sparked interest in its application within higher education. AI has the potential to reshape education delivery through chatbots and related tools, improving remote learning and mitigating challenges, such as student isolation and educator administrative burdens. Yet, ChatGPT’s practical applications in education remain uncertain, potentially due to its novel and enigmatic nature. Additionally, current e-learning chatbot systems often suffer from development complexity and a lack of input from key stakeholders, leading to developer-focused solutions rather than user-centered ones. Intended Outcomes: In this manuscript, we introduce a practical implementation of AI in education by creating a system called Q-Module-Bot that is accessible for both technical and nontechnical educators to harness e-learning benefits and demystify generative pretraining transformer (GPT). Application Design: The proposed Q-Module-Bot system has utilized pretrained large language models (LLMs) to build a Q&A system that helps students with their queries and supports education delivery using content extracted from a virtual learning environment (VLE). Findings: The prototype and system evaluation confirm the effectiveness of a scalable cross-departmental tool featuring source attribution and real-time responses. While successful in encouraging wider acceptance of GPT use cases in higher education, refinements are needed for full integration into the VLE and expansion to other modules/courses.},
  keywords={Chatbots;Education;Artificial intelligence;Stakeholders;Electronic learning;Real-time systems;Plagiarism;Artificial intelligence (AI);chatbots;ChatGPT;e-learning;generative AI;information retrieval (IR);virtual learning environment (VLE)},
  doi={10.1109/TE.2024.3435427},
  ISSN={1557-9638},
  month={Oct},}@INPROCEEDINGS{11016479,
  author={Qadir, Junaid},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Generative AI in Undergraduate Classrooms: Lessons from Implementing a Customized GPT Chatbot for Learning Enhancement}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={The advent of Generative Artificial Intelligence (GenAI) has sparked significant interest in education, offering ways to support learning, personalize student experiences, and boost engagement. Generative AI holds the promise of transforming education with personalized learning, instant feedback, and assistance with complex problem-solving. However, its integration into classrooms requires careful management due to ethical concerns, misinformation risks, and potential misuse. While many articles explore the potential of generative AI in education, empirical studies on its real-world classroom use are limited. This paper presents an experience report on deploying a customized GPT-powered chatbot at Qatar University to support learning in two undergraduate courses: Data and Computer Communications Networks (technical) and Computer Ethics. Working across these diverse courses allows a thorough analysis of generative AI's strengths and weaknesses in different academic contexts, offering a comprehensive evaluation of its applicability and effectiveness. We used a mixed-methods approach with over 100 students, collecting quantitative and qualitative data via questionnaires to assess the chatbot's impact. Findings are analyzed with established theoretical frameworks to contextualize the pedagogical impact of generative AI, aligned with UNESCO guidelines for ethical integration. This paper details the chatbot's technical customization to meet course-specific needs, provides evidence-based insights into practical challenges and opportunities, and offers strategic recommendations for effective AI-assisted pedagogy. Directions for further research are also outlined to explore and refine the role of generative AI in classroom settings. By examining two distinct courses, this study demonstrates how generative AI can be adapted across academic disciplines for more nuanced applications in education.},
  keywords={Ethics;Generative AI;Terminology;Learning (artificial intelligence);Chatbots;Reflection;Real-time systems;Problem-solving;Fake news;Guidelines;ChatGPT;generative AI;pedagogy;education},
  doi={10.1109/EDUCON62633.2025.11016479},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11094413,
  author={Li, Shuo and Liu, Fang and Hao, Zehua and Wang, Xinyi and Li, Lingling and Liu, Xu and Chen, Puhua and Ma, Wenping},
  booktitle={2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Logits DeConfusion with CLIP for Few-Shot Learning}, 
  year={2025},
  volume={},
  number={},
  pages={25411-25421},
  abstract={With its powerful visual-language alignment capability, CLIP performs well in zero-shot and few-shot learning tasks. However, we found in experiments that CLIP’s logits suffer from serious inter-class confusion problems in down-stream tasks, and the ambiguity between categories seriously affects the accuracy. To address this challenge, we propose a novel method called Logits DeConfusion, which effectively learns and eliminates inter-class confusion in logits by combining our Multi-level Adapter Fusion (MAF) module with our Inter-Class Deconfusion (ICD) module. Our MAF extracts features from different levels and fuses them uniformly to enhance feature representation. Our ICD learnably eliminates inter-class confusion in logits with a residual structure. Experimental results show that our method can significantly improve the classification performance and alleviate the inter-class confusion problem. The code is available at https://github.com/LiShuo1001/LDC.},
  keywords={Computer vision;Accuracy;Codes;Fuses;Image representation;Benchmark testing;Feature extraction;Pattern recognition;Few shot learning},
  doi={10.1109/CVPR52734.2025.02366},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{10605474,
  author={Huang, Donghao and Hu, Zhenda and Wang, Zhaoxia},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Performance Analysis of Llama 2 Among Other LLMs}, 
  year={2024},
  volume={},
  number={},
  pages={1081-1085},
  abstract={Llama 2, an open-source large language model developed by Meta, offers a versatile and high-performance solution for natural language processing, boasting a broad scale, competitive dialogue capabilities, and open accessibility for research and development, thus driving innovation in AI applications. Despite these advancements, there remains a limited understanding of the underlying principles and performance of Llama 2 compared with other LLMs. To address this gap, this paper presents a comprehensive evaluation of Llama 2, focusing on its application in in-context learning — an AI design pattern that harnesses pre-trained LLMs for processing confidential and sensitive data. Through a rigorous comparative analysis with other open-source LLMs and OpenAI models, this study sheds light on Llama 2’s performance, quality, and potential use cases. Our findings indicate that Llama 2 holds significant promise for applications involving in-context learning, with notable strengths in both answer quality and inference speed. This research offers valuable insights for the fields of LLMs and serves as an effective reference for companies and individuals utilizing such large models. The source codes and datasets of this paper are accessible at https://github.com/inflaton/Llama-2-eval.},
  keywords={Technological innovation;Analytical models;Source coding;Large language models;Focusing;Companies;Transformers;large language model;in-context learning;generative pre-trained transformer;model evaluation},
  doi={10.1109/CAI59869.2024.00108},
  ISSN={},
  month={June},}@ARTICLE{10557596,
  author={Zheng, Lijun and Li, Chenglong},
  journal={IEEE Access}, 
  title={Real-Time Emotion-Based Piano Music Generation Using Generative Adversarial Network (GAN)}, 
  year={2024},
  volume={12},
  number={},
  pages={87489-87500},
  abstract={Automatic creation of real-time, emotion-based piano music pieces remains a challenge for deep learning models. While Generative Adversarial Networks (GANs) have shown promise, existing methods can struggle with generating musically coherent pieces and often require complex manual configuration. This paper proposes a novel model called Learning Automata-based Self-Attention Generative Adversarial Network (LA-SAGAN) to address these limitations. The proposed model uses a Generative Adversarial Network (GAN), combined with Self-Attention (SA) mechanism to reach this goal. The benefits of using SA modules in GAN architecture is twofold: First, SA mechanism results in generating music pieces with homogenous structure, which means long-distance dependencies in generated outputs are considered. Second, the SA mechanism utilizes the emotional features of the input to produce output pieces. This results in generating music pieces with desired genre or theme. In order to control the complexity of the proposed model, and optimize its structure, a set of Learning Automata (LA) models have been used to determine the activity state of each SA module. To do this, an iterative algorithm based on cooperation of LAs is introduced which optimizes the model by deactivating unnecessary SA modules. The efficiency of the proposed model in generating piano music has been evaluated. Evaluations demonstrate LA-SAGAN’s effectiveness: at least 14.47% improvement in entropy (diversity) and improvements in precision (at least 2.47%) and recall (at least 2.13%). Moreover, human evaluation confirms superior musical coherence and adherence to emotional cues.},
  keywords={Generative adversarial networks;Learning automata;Deep learning;Music;Instruments;Complexity theory;Computational modeling;Reinforcement learning;Real-time music generation;generative adversarial network;self-attention mechanism;reinforcement learning;learning automata;emotion-based music},
  doi={10.1109/ACCESS.2024.3414673},
  ISSN={2169-3536},
  month={},}@ARTICLE{9210026,
  author={Kang, Byeongkeun and Tripathi, Subarna and Nguyen, Truong Q.},
  journal={IEEE Access}, 
  title={Generating Images in Compressed Domain Using Generative Adversarial Networks}, 
  year={2020},
  volume={8},
  number={},
  pages={180977-180991},
  abstract={In this article, we present a generative adversarial network framework that generates compressed images instead of synthesizing raw RGB images and compressing them separately. In the real world, most images and videos are stored and transferred in a compressed format to save storage capacity and data transfer bandwidth. However, since typical generative adversarial networks generate raw RGB images, those generated images need to be compressed by a post-processing stage to reduce the data size. Among image compression methods, JPEG has been one of the most commonly used lossy compression methods for still images. Hence, we propose a novel framework that generates JPEG compressed images using generative adversarial networks. The novel generator consists of the proposed locally connected layers, chroma subsampling layers, quantization layers, residual blocks, and convolution layers. The locally connected layer is proposed to enable block-based operations. We also discuss training strategies for the proposed architecture including the loss function and the decoding between its generator and its discriminator. The proposed method is evaluated using the publicly available CIFAR-10 dataset and LSUN bedroom dataset. The results demonstrate that the proposed method is able to generate compressed data with competitive qualities.},
  keywords={Image coding;Gallium nitride;Generators;Transform coding;Generative adversarial networks;Quantization (signal);Decoding;Generative adversarial networks;image generation;image synthesis},
  doi={10.1109/ACCESS.2020.3027800},
  ISSN={2169-3536},
  month={},}@ARTICLE{10517914,
  author={Zhang, Yujia and Li, Qianzhong and Pan, Yi and Zhao, Xiaoguang and Tan, Min},
  journal={IEEE Transactions on Image Processing}, 
  title={Multi-Stage Image-Language Cross-Generative Fusion Network for Video-Based Referring Expression Comprehension}, 
  year={2024},
  volume={33},
  number={},
  pages={3256-3270},
  abstract={Video-based referring expression comprehension is a challenging task that requires locating the referred object in each video frame of a given video. While many existing approaches treat this task as an object-tracking problem, their performance is heavily reliant on the quality of the tracking templates. Furthermore, when there is not enough annotation data to assist in template selection, the tracking may fail. Other approaches are based on object detection, but they often use only one adjacent frame of the key frame for feature learning, which limits their ability to establish the relationship between different frames. In addition, improving the fusion of features from multiple frames and referring expressions to effectively locate the referents remains an open problem. To address these issues, we propose a novel approach called the Multi-Stage Image-Language Cross-Generative Fusion Network (MILCGF-Net), which is based on one-stage object detection. Our approach includes a Frame Dense Feature Aggregation module for dense feature learning of adjacent time sequences. Additionally, we propose an Image-Language Cross-Generative Fusion module as the main body of multi-stage learning to generate cross-modal features by calculating the similarity between video and expression, and then refining and fusing the generated features. To further enhance the cross-modal feature generation capability of our model, we introduce a consistency loss that constrains the image-language similarity and language-image similarity matrices during feature generation. We evaluate our proposed approach on three public datasets and demonstrate its effectiveness through comprehensive experimental results.},
  keywords={Feature extraction;Visualization;Task analysis;Representation learning;Location awareness;Linguistics;Grounding;Video-based referring expression comprehension;multi-stage learning;image-language cross-generative fusion;consistency loss},
  doi={10.1109/TIP.2024.3394260},
  ISSN={1941-0042},
  month={},}@ARTICLE{11022721,
  author={Xiong, Zuobin and Li, Wei and Li, Yingshu and Cai, Zhipeng},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Distributed Generative Model: A Data Synthesizing Framework for Multi-Source Heterogeneous Data}, 
  year={2025},
  volume={},
  number={},
  pages={1-13},
  abstract={Recent advancement in generative AI influenced a broad area with successful applications across multiple domains, including computer vision, natural language processing, and the Internet of Things (IoT). However, many existing implementations rely on centralized architectures, which introduce security and privacy concerns while also increasing communication overhead. Limited research has explored the development of distributed generative models, particularly in scenarios where training data originates from various heterogeneous sources. To fill the gap, this paper introduces a distributed generative model framework aimed at enhancing data generation in hierarchical IoT systems. The proposed framework supports distributed data generation across three distinct scenarios: feature-related data, label-related data, and feature-label non-related data. Furthermore, both synchronous and asynchronous update mechanisms are incorporated to accommodate diverse application requirements within IoT environments. Comprehensive experiments using simulated, image, and tabular datasets are conducted to assess the performance of the proposed framework in comparison with state-of-the-art methods. The results indicate that the framework effectively produces high-quality synthetic data while preserving the integrity of downstream tasks. Beyond large language models (LLMs), these findings suggest that generative AI have the potential to transform data generation in distributed IoT systems and be extended to a broader range of applications.},
  keywords={Distributed databases;Data models;Training;Internet of Things;Generators;Data collection;Servers;Artificial intelligence;Computational modeling;Soft sensors;Distributed Learning;Generative Adversarial Networks;Multi-source Heterogeneous Data;Federated Learning},
  doi={10.1109/TAI.2025.3575548},
  ISSN={2691-4581},
  month={},}@ARTICLE{10379828,
  author={Zhang, Yu and Chen, Jianqi and Liu, Liqin and Chen, Keyan and Shi, Zhenwei and Zou, Zhengxia},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Generating Imperceptible and Cross-Resolution Remote Sensing Adversarial Examples Based on Implicit Neural Representations}, 
  year={2024},
  volume={62},
  number={},
  pages={1-15},
  abstract={Deep neural networks (DNNs) have been widely applied in remote sensing, and the research on its adversarial attack algorithm is the key to evaluating its robustness. Current adversarial attack methods primarily prioritize maximizing the attack success rate, disregarding the imperceptibility of the generated adversarial noise to human visual perception. Moreover, research on adversarial sample transferability has mostly focused on cross-model and cross-dataset scenarios, overlooking the investigation of adversarial attacks across different resolutions, while the rarely studied cross-resolution adversarial attacks are critical for remote sensing with different resolutions. In this article, we propose a novel method for generating imperceptible adversarial samples for cross-resolution remote sensing images based on implicit neural representations (INRs). By mapping the discrete images to a continuous neural functional space, we explicitly guarantee the visual quality of adversarial samples and decouple the model input from the image resolution. To enhance the visual fidelity of the generated adversarial samples, a multiscale discriminative learning scheme is proposed for the optimization process. For cross-resolution adversarial attacks, we align with images of different resolutions and generate cross-resolution adversarial perturbation by benefiting from the natural properties of the continuous resolution of INRs. To validate the effectiveness of our method, we compare it with the existing adversarial attacking methods using four evaluation metrics. Experiments show that our method achieves the best results in terms of attack success rate, imperceptibility, and cross-resolution attack transferability. Our code will be made publicly available.},
  keywords={Remote sensing;Visualization;Perturbation methods;Image resolution;Measurement;Visual perception;Task analysis;Adversarial examples (AEs);cross-resolution;implicit neural representation (INR);remote sensing;visual harmony},
  doi={10.1109/TGRS.2023.3349373},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{10596650,
  author={Singh, Aishwarya and Smriti and Bhat, Tejjus S. and Sharma, Uditi and Sharma, Yash},
  booktitle={2024 Sixth International Conference on Computational Intelligence and Communication Technologies (CCICT)}, 
  title={inQuery- Online AI Application Formatting and Management System}, 
  year={2024},
  volume={},
  number={},
  pages={523-529},
  abstract={Written applications, with standardized fields like date, subject, sender and receiver, serve various purposes such as leave requests, misconduct appeals and suggestions. Surprisingly, even in today’s tech-driven world, these applications often remain paper-based, leading to repetitive tasks like leave requests and complaints, which can be time-consuming and inefficient. Managing paper applications also poses challenges like misplacement and physical storage needs.Our methodology addresses this by designing the application’s UI in Figma, exporting assets to Android Studio and creating a new project. In Android Studio, we implement the UI and functionality using these design assets, integrating Firebase services for authentication, real-time database and storage. Artificial Intelligence will be used for formatting the applications. We then test the application and ensure ongoing maintenance and updates.Our observations reveal that many institutions still rely on traditional application methods. We recommend institutions adopt online application writing and management systems, as demonstrated by our Android app, “inQuery: An Application for Applications,” simplifying and enhancing this process.},
  keywords={Generative AI;Education;Receivers;Writing;Real-time systems;Filling;Safety;Online Applications;E-Applications;Artificial Intelligence;Application Management;Android Studio;Figma;Firebase;Generative AI},
  doi={10.1109/CCICT62777.2024.00088},
  ISSN={},
  month={April},}@INPROCEEDINGS{11147668,
  author={Campi, Riccardo and Borrego, Santiago and De Santis, Antonio and Bianchi, Matteo and Tocchetti, Andrea and Brambilla, Marco},
  booktitle={2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={Towards Synthetic Concept Activation Vectors via Generative Models}, 
  year={2025},
  volume={},
  number={},
  pages={2711-2719},
  abstract={In recent years, the field of Explainable Artificial Intelligence (XAI) has developed a new paradigm called conceptbased XAI, which fosters using human-understandable concepts to verify hypotheses or test models against biases. A Concept Activation Vector (CAV) is the representation of a concept in a vision model's embedding space. However, training a CAV requires a properly sized dataset containing images of the selected concept. This may represent a limitation, as acquiring such a dataset can be difficult and timeconsuming. In this context, a text-to-image generation system may help analysts build CAVs directly from texts, reducing time requirements while maintaining faithfulness. This work lays the foundations of synthetic CAV generation using pre-trained text-to-image generative models. Our approach consists of producing synthetic concept images from a descriptive prompt and using them to train a CAV in the space of a pre-trained vision model. The methodology also includes a quality control step with a multi-modal embedding model to discard images containing errors or artifacts. We evaluate the quality of our proposal by running experiments on popular ImageNet CNNs using a set of randomly chosen concepts and then comparing the synthetic CAVs with the ones from real images. Our results show that it is possible to train faithful CAVs by generating concept images, particularly for simpler concepts such as textures. Finetuning generative models with a few real images also yields promising results.},
  keywords={Training;Phase measurement;Explainable AI;Natural languages;Measurement uncertainty;Text to image;Quality control;Vectors;Pattern recognition;Proposals;post-hoc explainability;computer vision explainability;concept-based xai;concept activation vector;synthetic concept generation;synthetic cav;generative models;user-defined concepts;prompt engineering;multimodal xai},
  doi={10.1109/CVPRW67362.2025.00256},
  ISSN={2160-7516},
  month={June},}@ARTICLE{9496194,
  author={Sharan, Lalith and Romano, Gabriele and Koehler, Sven and Kelm, Halvar and Karck, Matthias and De Simone, Raffaele and Engelhardt, Sandy},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Mutually Improved Endoscopic Image Synthesis and Landmark Detection in Unpaired Image-to-Image Translation}, 
  year={2022},
  volume={26},
  number={1},
  pages={127-138},
  abstract={The CycleGAN framework allows for unsupervised image-to-image translation of unpaired data. In a scenario of surgical training on a physical surgical simulator, this method can be used to transform endoscopic images of phantoms into images which more closely resemble the intra-operative appearance of the same surgical target structure. This can be viewed as a novel augmented reality approach, which we coined <i>Hyperrealism</i> in previous work. In this use case, it is of paramount importance to display objects like needles, sutures or instruments consistent in both domains while altering the style to a more tissue-like appearance. Segmentation of these objects would allow for a direct transfer, however, contouring of these, partly tiny and thin foreground objects is cumbersome and perhaps inaccurate. Instead, we propose to use landmark detection on the points when sutures pass into the tissue. This objective is directly incorporated into a CycleGAN framework by treating the performance of pre-trained detector models as an additional optimization goal. We show that a task defined on these sparse landmark labels improves consistency of synthesis by the generator network in both domains. Comparing a baseline CycleGAN architecture to our proposed extension (<i>DetCycleGAN</i>), mean precision (PPV) improved by <inline-formula><tex-math notation="LaTeX">$+61.32$</tex-math></inline-formula>, mean sensitivity (TPR) by <inline-formula><tex-math notation="LaTeX">$+37.91$</tex-math></inline-formula>, and mean <inline-formula><tex-math notation="LaTeX">$F_1$</tex-math></inline-formula> score by <inline-formula><tex-math notation="LaTeX">$+0.4743$</tex-math></inline-formula>. Furthermore, it could be shown that by dataset fusion, generated intra-operative images can be leveraged as additional training data for the detection network itself.},
  keywords={Task analysis;Surgery;Valves;Maintenance engineering;Training;Semantics;Generative adversarial networks;Generative adversarial networks;surgical simulation;surgical training;CycleGAN;landmark localization;landmark detection;mitral valve repair},
  doi={10.1109/JBHI.2021.3099858},
  ISSN={2168-2208},
  month={Jan},}@ARTICLE{9784948,
  author={Song, Peipei and Guo, Dan and Zhou, Jinxing and Xu, Mingliang and Wang, Meng},
  journal={IEEE Transactions on Cybernetics}, 
  title={Memorial GAN With Joint Semantic Optimization for Unpaired Image Captioning}, 
  year={2023},
  volume={53},
  number={7},
  pages={4388-4399},
  abstract={Most works of image captioning are implemented under the full supervision of paired image–caption data. Limited to expensive cost of data collection, the task of unpaired image captioning has attracted researchers’ attention. In this article, we propose a novel memorial GAN (MemGAN) with the joint semantic optimization for unpaired image captioning. The core idea is to explore implicit semantic correlation between disjointed images and sentences through building a multimodal semantic-aware space (SAS). Concretely, each modality is mapped into a unified multimodal SAS, where SAS includes the semantic vectors of image  ${I}$ , visual concepts  ${O}$ , unpaired sentence  ${S}$ , and the generated caption  ${C}$ . We adopt the memory unit based on multihead attention and relational gate as a backbone to preserve and transit crucial multimodal semantics in the SAS for image caption generation and sentence reconstruction. Then, the memory unit is embedded into a GAN framework to exploit the semantic similarity and relevance in SAS, that is, imposing a joint semantic-aware optimization on SAS without supervision clues. To summarize, the proposed MemGAN learns the latent semantic relevance of SAS’s multimodalities in an adversarial manner. Extensive experiments and qualitative results demonstrate the effectiveness of MemGAN, achieving improvements over state of the arts on unpaired image captioning benchmarks.},
  keywords={Semantics;Synthetic aperture sonar;Visualization;Task analysis;Optimization;Generative adversarial networks;Correlation;Generative adversarial network;memory network;semantic-aware space (SAS);unpaired image captioning},
  doi={10.1109/TCYB.2022.3175012},
  ISSN={2168-2275},
  month={July},}@ARTICLE{9417738,
  author={Feng, Fangxiang and Niu, Tianrui and Li, Ruifan and Wang, Xiaojie},
  journal={IEEE Transactions on Multimedia}, 
  title={Modality Disentangled Discriminator for Text-to-Image Synthesis}, 
  year={2022},
  volume={24},
  number={},
  pages={2112-2124},
  abstract={Text-to-image (T2I) synthesis aims at generating photo-realistic images from text descriptions, which is a particularly important task in bridging vision and language. Each generated image consists of two parts: the content part related to the text and the style part irrelevant to the text. The existing discriminator does not distinguish between the content part and the style part. This not only precludes the T2I synthesis models from generating the content part effectively but also makes it difficult to manipulate the style of the generated image. In this paper, we propose a modality disentangled discriminator that distinguishes between the content part and the style part at a specific layer. Specifically, we enforce the early layers of a certain number in the discriminator to become the disentangled representation extractor through two losses. The extracted common representation for the content part can make the discriminator more effective for capturing the text-image correlation, while the extracted modality-specific representation for the style part can be directly transferred to other images. The combination of these two representations can also improve the quality of the generated images. Our proposed discriminator is used to substitute the discriminator of each stage in the representative model AttnGAN and the SOTA model DM-GAN. Extensive experiments are conducted on three widely used datasets, i.e. CUB, Oxford-102, and COCO, for the T2I synthesis task, demonstrating the superior performance of the modality disentangled discriminator over the base models. Code for DM-GAN with our modality disentangled discriminator is available at https://github.com/FangxiangFeng/DM-GAN-MDD.},
  keywords={Task analysis;Correlation;Image synthesis;Image reconstruction;Generative adversarial networks;Image representation;Visualization;text-to-image synthesis;generative adversarial networks;multi-modal disentangled representation learning},
  doi={10.1109/TMM.2021.3075997},
  ISSN={1941-0077},
  month={},}@ARTICLE{10025663,
  author={Xiong, Gang and Li, Zhishuai and Zhao, Meihua and Zhang, Yu and Miao, Qinghai and Lv, Yisheng and Wang, Fei-Yue},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={TrajSGAN: A Semantic-Guiding Adversarial Network for Urban Trajectory Generation}, 
  year={2024},
  volume={11},
  number={2},
  pages={1733-1743},
  abstract={Simulating human mobility contributes to city behavior discovery and decision-making. Although the sequence-based and image-based approaches have made impressive achievements, they still suffer from respective deficiencies such as omitting the depiction of spatial properties or ordinal dependency in trajectory. In this article, we take advantage of the above two paradigms and propose a semantic-guiding adversarial network (TrajSGAN) for generating human trajectories. Specifically, we first devise an attention-based generator to yield trajectory locations in a sequence-to-sequence manner. The encoded historical visits are queried with semantic knowledge (e.g., travel modes and trip purposes) and their important features are enhanced by the multihead attention mechanism. Then, we designate a rollout module to complete the unfinished trajectory sequence and transform it into an image that can depict its spatial structure. Finally, a convolutional neural network (CNN)-based discriminator signifies how “real” the trajectory image looks, and its output is regarded as a reward signal to update the generator by the policy gradient. Experimental results show that the proposed TrajSGAN model significantly outperforms the benchmarks under the MTL-Trajet mobility dataset, with the divergence of spatial-related metrics such as radius of gyration and travel distance reduced by 10%–27%. Furthermore, we apply the real and synthetic trajectories, respectively, to simulate the COVID-19 epidemic spreading under three preventive actions. The coefficient of determination metric between real and synthetic results achieves 91%–98%, indicating that the synthesized data from TrajSGAN can be leveraged to study the epidemic diffusion with an acceptable difference. All of these results verify the superiority and utility of our proposed method.},
  keywords={Trajectory;Semantics;Hidden Markov models;Measurement;Computational modeling;Generative adversarial networks;Human activity recognition;Urban areas;Generative adversarial networks (GANs);human mobility simulation;urban trajectory},
  doi={10.1109/TCSS.2023.3235923},
  ISSN={2329-924X},
  month={April},}@ARTICLE{10464342,
  author={Zhang, Jiale and Liu, Chengxin and Xian, Ke and Cao, Zhiguo},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Hierarchical Feature Warping and Blending for Talking Head Animation}, 
  year={2024},
  volume={34},
  number={8},
  pages={7301-7314},
  abstract={Talking head animation transforms a source anime image to a target pose, where the transformation includes the change of facial expression and head movement. In contrast to existing approaches that operate on the low-resolution image ( $256\times 256$ ), we study this task at a higher resolution, e.g.,  $512\times 512$ . High-resolution talking head animation, however, raises two major challenges: i) how to achieve smooth global transformation while maintaining rich details of anime characters under large-displacement pose variations; ii) how to address the shortage of data, because no related dataset is publicly available. In this paper, we present a Hierarchical Feature Warping and Blending (HFWB) model, which tackles talking head animation hierarchically. Specifically, we use low-level features to control global transformation and high-level features to determine the details of anime characters, under the guidance of feature flow fields. These features are then blended by selective fusion units, outputting transformed anime images. In addition, we construct an anime pose dataset—AniTalk-2K, aiming to alleviate the shortage of data. It contains around 2000 anime characters with thousands of different face/head poses at a resolution of  $512\times 512$ . Extensive experiments on AniTalk-2K demonstrate the superiority of our approach in generating high-quality anime talking heads over state-of-the-art methods.},
  keywords={Image resolution;Generators;Animation;Iterative methods;Generative adversarial networks;Pose estimation;Image processing;Talking head animation;generative adversarial networks;pose transformation;anime image generation;anime dataset},
  doi={10.1109/TCSVT.2024.3375330},
  ISSN={1558-2205},
  month={Aug},}@ARTICLE{10955724,
  author={Xu, Xiaoxia and Liu, Yuanwei and Mu, Xidong and Xing, Hong and Nallanathan, Arumugam},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Accelerating Mobile Edge Generation (MEG) by Constrained Learning}, 
  year={2025},
  volume={11},
  number={3},
  pages={1854-1869},
  abstract={A novel mobile edge generation (MEG) framework is proposed for low-latency image generation on mobile devices. Exploiting a latent diffusion model (LDM) distributed across the edge server (ES) and the user equipment (UE), only low-dimension features need to be transmitted for creating artificial intelligence generative content (AIGC). Two novel modules, namely dynamic diffusion and feature merging, are conceived to compress the diffusion model and transmitted features, respectively. By jointly optimizing compression rates of denoising steps and feature merging, the image quality maximization problem is formulated subject to latency and energy consumption constraints. To address this problem in dynamic channel conditions, a low-complexity compression protocol is developed. First, a backbone LDM architecture is learned by offline distillation to support various compression options. Then, compression rates are predicted in online environment specific to channel and task features. To solve the resultant constrained Markov Decision Process (MDP), a constrained variational policy optimization (CVPO) based MEG algorithm, MEG-CVPO, is further developed to learn constraint-guaranteed optimization. Numerical results demonstrate that: 1) The proposed framework improves image distortions while reducing over 40% latency compared to conventional generation schemes. 2) MEG-CVPO stringently guarantee constraints and realizes a flexible trade-off between generation qualities and overheads. Code is available at https://github.com/xiaoxiaxusummer/LowLatencyMEG.},
  keywords={Image coding;Image edge detection;Artificial intelligence;Edge AI;Computational modeling;Mobile handsets;Merging;Videos;Noise reduction;Neurons;Artificial intelligence generated content (AIGC);edge artificial intelligence (AI);generative AI (GAI);mobile edge generation (MEG);reinforcement learning (RL)},
  doi={10.1109/TCCN.2025.3558975},
  ISSN={2332-7731},
  month={June},}@INPROCEEDINGS{10815898,
  author={De Souza, Lucas Airam C. and Sammarco, Matteo and Achir, Nadjib and Campista, Miguel Elias M. and Costa, Luís Henrique M. K.},
  booktitle={2024 IEEE 13th International Conference on Cloud Networking (CloudNet)}, 
  title={AutoMHS-GPT: Automated Model and Hyperparameter Selection with Generative Pre-Trained Model}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Automated Machine Learning emerges as a solution to reduce the instantiation time of systems that rely on Artificial Intelligence (AI) by accelerating the search process for models and hyperparameters. These techniques, however, still require high execution time. In critical applications, such as intrusion detection in vehicular networks, delays in applying countermeasures can provoke accidents. Therefore, it is essential to guarantee accurate models in the shortest possible time to detect threats effectively. This work proposes AutoMHS-GPT, a system that uses generative artificial intelligence to reduce the time it takes to define hyperparameters and models when implementing machine learning to detect threats in vehicular networks. Based on a description of the problem, the generative model returns a text containing the appropriate model with its hyperparameters for training. Results show that AutoMSH-GPT produces models with higher threat classification performance than automated machine learning approaches AutoKeras and Auto-Sklearn, increasing in the best case the recall by 9%. Furthermore, the current proposal reduces the model search and training process, carrying out the task in around 30 minutes, while the other evaluated frameworks require two to three days.},
  keywords={Training;Accuracy;Generative AI;Intrusion detection;Automated machine learning;Delays;Proposals;Accidents;Machine Learning;Generative AI;Network Security;Vehicular Networks;AutoML},
  doi={10.1109/CloudNet62863.2024.10815898},
  ISSN={2771-5663},
  month={Nov},}@ARTICLE{10979259,
  author={Zhang, Meng and Zhong, Ruikang and Mu, Xidong and Liu, Yuanwei and Peng, Mugen},
  journal={IEEE Transactions on Wireless Communications}, 
  title={Energy Consumption Minimization for Mobile Edge Generation}, 
  year={2025},
  volume={24},
  number={9},
  pages={7702-7718},
  abstract={The novel concept of mobile edge generation (MEG) is investigated, where the generative artificial intelligence (GAI) model is partitioned into sub-models to be distributed in the network edge, thus enabling latent feature exchange between the edge server and user equipments (UEs). A seed coding module is introduced to encode the intermediate latent features generated by the GAI sub-model at the edge server into flexibly-sized seed for transmission to UEs, instead of transmitting large-size raw data. A weighted energy consumption minimization problem is formulated by jointly optimizing the seed coding ratio (SCR), transmit power, and computing frequencies while guaranteeing the quality-of-generation requirements including total latency and peak signal-to-noise ratio (PSNR). To enhance the resilience of the MEG models against the channel noise, a joint fine-tuning scheme based on low-rank adaption is proposed to train the introduced rank-reduced bypass matrices and seed coding module. Based on the fine-tuned results, a PSNR model regarding SCR and communication signal-to-noise ratio is established to overcome the optimization difficulty due to the lack of the explicit PSNR model. A proximal policy optimization-based MEG energy consumption optimization (MEG-ECO) algorithm is proposed to solve the formulated problem, where the order of magnitude balancing on state and penalty shaping are exploited for more efficient learning. Numerical results reveal that 1) the fine-tuned MEG models have superior resilience against the channel noise; 2) the proposed MEG-ECO algorithm can significantly reduce energy consumption by up to 87.4% compared to conventional centralized generation and up to 33.5% against MEG without seed coding module; and 3) the energy consumption decreases when more partial models are assigned to the edge server, whereas this impact diminishes as the latency threshold is relaxed.},
  keywords={Servers;Energy consumption;Adaptation models;Computational modeling;Image edge detection;Encoding;Artificial intelligence;Resource management;PSNR;Optimization;Artificial intelligence-generated content;energy consumption;generative artificial intelligence;mobile edge generation;deep reinforcement learning},
  doi={10.1109/TWC.2025.3562731},
  ISSN={1558-2248},
  month={Sep.},}@INPROCEEDINGS{10578690,
  author={Karpouzis, Kostas and Pantazatos, Dimitris and Taouki, Joanna and Meli, Kalliopi},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Tailoring Education with GenAI: A New Horizon in Lesson Planning}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={The advent of Generative AI (GenAI) in education presents a transformative approach to traditional teaching methodologies, which often overlook the diverse needs of individual students. This study introduces a GenAI tool, based on advanced natural language processing, designed as a digital assistant for educators, enabling the creation of customized lesson plans. The tool utilizes an innovative feature termed ‘interactive mega-prompt,’ a comprehensive query system that allows educators to input detailed classroom specifics such as student demographics, learning objectives, and preferred teaching styles. This input is then processed by the GenAI to generate tailored lesson plans. To evaluate the tool's effectiveness, a comprehensive methodology incorporating both quantitative (i.e., % of time savings) and qualitative (i.e., user satisfaction) criteria was implemented, spanning various subjects and educational levels, with continuous feedback collected from educators through a structured evaluation form. Preliminary results show that educators find the GenAI-generated lesson plans effective, significantly reducing lesson planning time and enhancing the learning experience by accommodating diverse student needs. This AI-driven approach signifies a paradigm shift in education, suggesting its potential applicability in broader educational contexts, including special education needs (SEN), where individualized attention and specific learning aids are paramount.},
  keywords={Generative AI;Education;Natural language processing;Planning;Engineering education;Generative AI;ChatGPT;educational technology;personalization;adaptative learning;lesson plans},
  doi={10.1109/EDUCON60312.2024.10578690},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10578748,
  author={Martins Ferreira, José Manuel},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={A Strategy for AI-Supplemented Teaching and Learning}, 
  year={2024},
  volume={},
  number={},
  pages={01-10},
  abstract={This paper presents a strategy designed to evaluate AI-supplemented teaching and learning in a course belonging to a master program in Computer Science at the University of South-Eastern Norway. The strategy was closely related to the delivery format adopted in this program, where students take only one course at a time. Each course lasts for 6 weeks, comprising an initial “reading week”, an “intensive lectures” week, a 3-week “project assignment”, and one “assessment week”. The university supported the cost of OpenAI Plus account subscriptions offered to each student while the course was running, and specific activities were proposed to the class exploring the different ways in which AI tutoring could be used during each one of the 4 phases included in the course work plan. The strategy can be adapted to other program delivery formats by redistributing the proposed activities in accordance with the planned sequence of learning activities. It is also independent of which generative AI tool is selected, although OpenAI Plus accounts allow access to specific features that offer relevant pedagogical benefits, e.g., a simple process to create private language models that are easily customizable to each course subject.},
  keywords={Costs;Generative AI;Operating systems;Education;Intellectual property;Writing;Chatbots;generative AI;teaching and learning model},
  doi={10.1109/EDUCON60312.2024.10578748},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10765179,
  author={Zhang, Lei and Bagasra, Anisah and Kaye, Erica and Lichtenthal, Wendy G.},
  booktitle={2024 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)}, 
  title={Designing Generative Artificial Intelligence Integrated Immersive Virtual Reality Therapeutic Experiences to Support Meaning-centered Grief Therapies for Bereaved Parents}, 
  year={2024},
  volume={},
  number={},
  pages={299-303},
  abstract={Bereaved parents often struggle to make sense of and find meaning in and after their loss due to the untimely nature of their child’s death. Challenges with finding meaning have been associated with prolonged grief symptoms that can adversely affect grieving parents’ quality of life. Recently, meaning-centered grief interventions that focus on facilitating adaptive meaning-making after loss have shown therapeutic benefits in reducing prolonged grief symptoms in bereaved individuals. However, these interventions are mostly administered in one-on-one, in-person settings, which limits their accessibility to a broader population due to logistical and locational constraints. While existing videoconferencing applications can provide remote bereavement support and deliver grief therapies, they often lack engaging user experiences and features to support high interactivity, guided imagery and mindfulness exercises commonly used in meaning-centered grief therapies. We hypothesize that the immersive and interactive nature of a networked immersive virtual reality (IVR) system, enhanced with custom content creation features from text-to-image generative artificial intelligence (genAI) models, will create a unique and individualized therapeutic experience that supports meaning-centered grief techniques and activities for bereaved parents in a shared virtual world. This work-in-progress paper presents the design concept of the system prototype, preliminary survey results on user acceptance of the technology, and selected user experience scenarios.},
  keywords={Surveys;Solid modeling;Generative AI;Medical treatment;Text to image;Prototypes;Video conferencing;User experience;Augmented reality;virtual reality;generative AI;mental health;grief therapy;bereaved parents;human-computer interaction},
  doi={10.1109/ISMAR-Adjunct64951.2024.00068},
  ISSN={2771-1110},
  month={Oct},}@INPROCEEDINGS{10589186,
  author={Balahadia, Francis F. and Miranda, John Paul P. and Hernandez, Hilene E.},
  booktitle={2023 IEEE 15th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management (HNICEM)}, 
  title={Teachers’ and Students’ Awareness on the Uses of ChatGPT: A Cross-Sectional Case Study}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={This research seeks to bridge an existing knowledge gap by investigating the awareness level of ChatGPT among faculty and students in selected universities in the Philippines, with the overarching goal of formulating effective strategies to harness its potential benefits while addressing associated concerns. This study employs a descriptive cross-sectional research survey design that uses simple random sampling techniques and descriptive statistics to evaluate the prevalence and depth of awareness within specific demographic segments. The results indicate a moderate level of awareness across various domains among teachers and students. Notably, teachers exhibit slightly greater awareness of ChatGPT's capabilities, which may extend to other generative AI tools, presenting an opportunity for integrating such technologies into educational curricula to enhance teaching tools and elevate student engagement. In light of these findings, the study recommends that higher education institutions organize educational seminars and workshops to facilitate teachers' and students' effective utilization of AI tools. Furthermore, regular evaluations should be instituted to ensure that students, teachers, and school administrators remain well-informed about emerging AI technologies.},
  keywords={Surveys;Seminars;Bridges;Generative AI;Conferences;Education;Humanoid robots;ChatGPT;awareness;teachers;students;cross-sectional;AI tool;generative AI},
  doi={10.1109/HNICEM60674.2023.10589186},
  ISSN={2770-0682},
  month={Nov},}@INPROCEEDINGS{10894026,
  author={MeenaPrakash, R. and Kamali, B. and Vimala, M. and Madhuvandhana, K. and Krishnaleela, P.},
  booktitle={2025 International Conference on Multi-Agent Systems for Collaborative Intelligence (ICMSCI)}, 
  title={A DenseNet-Enhanced GAN Model for Classification of Medical Images into Original and Fake}, 
  year={2025},
  volume={},
  number={},
  pages={1540-1545},
  abstract={Medical image analysis has seen a revolution in recent years because of the use of generative adversarial networks (GANs). A unique GAN framework with a DenseNet-based discriminator is presented in this work for the reliable and accurate categorization of medical images into original and fake. The proposed model leverages the feature extraction capabilities of DenseN et, known for its densely connected convolutional blocks, to enhance the detection of subtle and complex patterns in medical images such as X-rays, MRIs, and CT scan. The generator within the GAN model is designed to synthesize high-quality, realistic images from random noise, which are then evaluated by the DenseN et-based discriminator to determine their authenticity. By integrating DenseNet's powerful hierarchical feature learning, the discriminator achieves high classification accuracy, distinguishing between real and artificial images with precision. A dataset made up of medical images is used for training, and the GAN model is optimized for accuracy and performance across several epochs. Our method offers potential applications, showing notable improvements in the classification of complex medical images into original and fake. Furthermore, the medical images categorization system can be expanded to other fields where quick and precise decision-making is essential, such as security and self-sufficient monitoring. According to experimental findings, the suggested DenseN et-GAN model outperforms conventional GAN architectures in terms of image quality, classification accuracy, and generalization to new data.},
  keywords={Image quality;Accuracy;Magnetic resonance imaging;X-rays;Generative adversarial networks;Feature extraction;Real-time systems;Generators;Security;Medical diagnostic imaging;Generative Adversarial Networks (GANs);DenseNet;Medical Images},
  doi={10.1109/ICMSCI62561.2025.10894026},
  ISSN={},
  month={Jan},}@INBOOK{10951890,
  author={Janagi, K. and Balaji, Devarajan and Renuka, P. and Bhuvaneswari, S.},
  booktitle={Mathematical Models Using Artificial Intelligence for Surveillance Systems}, 
  title={Machine Learning and Artificial Intelligence in the Detection of Moving Objects Using Image Processing}, 
  year={2024},
  volume={},
  number={},
  pages={19-49},
  abstract={Summary <p>Digital technology plays a major role in various fields like real life, science and engineering. This chapter deals with the uses of digital technology in detecting and tracking of objects. In particular, it applies LBF algorithm, background subtraction algorithm, GMM model (Gaussian Mixture Model), GANN (Generative adversarial neural networks), Kalman filter, Fuzzy c&#x2010;mean, End&#x2010;of&#x2010;Queue (EOQ), Delaunay triangulation, robust approaches, RPCA (Robust Principal Component Analysis), Semi&#x2010;Automatic Vehicle Detection System (SAVDS), and 3D LiDAR (Light Detection and Ranging). Based on the above&#x2010;mentioned algorithms one can easily detect the moving object or track the object (in most of the cases a human being) more accurately. Generally, all the algorithms including RPCA, NLTFN (Non&#x2010;Convex Logarithm Fraction Norms), RNLTFN (Robust Non&#x2010;Convex Logarithm Fraction Norms) are mostly used to segregate the human images from other images, detection of images in poor weather conditions, monitoring the traffic in the vibrant work places and so on. These algorithms can be combined to provide the solutions as human intelligence. It can be envisaged to predict the technology based on the trend being observed by literatures.</p>},
  keywords={Surveillance;Feature extraction;Object detection;Streaming media;Real-time systems;Mathematical models;Cameras;Accuracy;Vehicle dynamics;Training},
  doi={10.1002/9781394200733.ch2},
  ISSN={},
  publisher={Wiley},
  isbn={9781394200726},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951890},}@INPROCEEDINGS{10910535,
  author={S, Srinithin and S, Suganthan and R, Ranjith and G, Brindha},
  booktitle={2024 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES)}, 
  title={Weapon Detection Using Genai and Yolo}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={In order to improve real-time weapon identification, we recommend integrating the You Only Look Once (YOLO) series algorithms with Generative AI (GenAl). It uses the capabilities of GenAl to generate and improve image datasets, which are necessary for training comparable, precise models. Because of these progressive principles, YOLO can quickly and accurately identify weapons in these environments. Since the method combines the global generation features of GenAl with the regional detection efficacy in YOLO, it improves detection rates and reduces false discoveries. Also, enhancing the dependability of monitoring systems in the most susceptible areas (e.g., airports, schools, public areas), this collaboration facilitates the faster assessment and management of the threat level. The integration of both technologies would be a significant and forward-thinking step in public safety and security.},
  keywords={YOLO;Training;Generative AI;Weapons;Surveillance;Real-time systems;Threat assessment;Public security;Security;Time factors;Generative AI;YOLO;weapon detection;real-time surveillance;security systems;image datasets;object detection;threat management},
  doi={10.1109/ICSES63760.2024.10910535},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9731132,
  author={Pu, Yusheng and Liu, Ruonan and Chen, Qiang and Chen, Dongyue and Yu, Wenlong and Cao, Di},
  booktitle={2021 5th Asian Conference on Artificial Intelligence Technology (ACAIT)}, 
  title={POC: Periodical Orthogonal Center Loss For Open Set Classification}, 
  year={2021},
  volume={},
  number={},
  pages={433-438},
  abstract={When designing classification models, people usually do not assume that there will be unknown classes in the test set, which never appeared in the training set. However, this tricky situation is very common in practical applications. Such test conditions are called Open Set environments. Now, how to make models have the ability to identify unknown classes in the open environment has become a topic of great concern to researchers. In this paper, we follow up on previous research, which focusses on using orthogonal class centers to detect the unknown. We explain the reasons for the poor performance of the previous class center update strategy and propose using the orthogonal loss applied to the class centers to restrict the update direction. In addition, we use the multi-head attention layer for centers’ calculation to find suitable projection space adaptively. Experiments show that our method improves the performance of preceding orthogonal center methods.},
  keywords={Training;Learning (artificial intelligence);Open-set;classification;metric learning},
  doi={10.1109/ACAIT53529.2021.9731132},
  ISSN={},
  month={Oct},}@ARTICLE{10381805,
  author={Kim, Seung-Bin and Lee, Sang-Hoon and Choi, Ha-Yeong and Lee, Seong-Whan},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Audio Super-Resolution With Robust Speech Representation Learning of Masked Autoencoder}, 
  year={2024},
  volume={32},
  number={},
  pages={1012-1022},
  abstract={This paper proposes Fre-Painter, a high-fidelity audio super-resolution system that utilizes robust speech representation learning with various masking strategies. Recently, masked autoencoders have been found to be beneficial in learning robust representations of audio for speech classification tasks. Following these studies, we leverage these representations and investigate several masking strategies for neural audio super-resolution. In this paper, we propose an upper-band masking strategy with the initialization of the mask token, which is simple but efficient for audio super-resolution. Furthermore, we propose a mix-ratio masking strategy that makes the model robust for input speech with various sampling rates. For practical applicability, we extend Fre-Painter to a text-to-speech system, which synthesizes high-resolution speech using low-resolution speech data. The experimental results demonstrate that Fre-Painter outperforms other neural audio super-resolution models.},
  keywords={Superresolution;Task analysis;Speech processing;Self-supervised learning;Computational modeling;Decoding;Training;Audio super-resolution;bandwidth extension;self-supervised learning;masked autoencoder;audio synthesis},
  doi={10.1109/TASLP.2023.3349053},
  ISSN={2329-9304},
  month={},}
