@INPROCEEDINGS{11042744,
  author={Thilagavathy, A. and Therasa, P.R. and R, Balaguru and M, Gnana Prakash and Susanth Reddy, Chittani},
  booktitle={2025 2nd International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)}, 
  title={Text Extraction from Video Using Generative AI Models: A Multimodal Approach}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Text plays a pivotal role in human communication and information exchange, making accurate extraction of text from videos essential for various applications, including transcription, video analysis, and content understanding. Traditional methods face significant challenges in real-world scenarios due to motion blur, varying text orientations, low resolution, and complex video backgrounds, which hinder recognition accuracy. To address these challenges, this work introduces a generative AI-based framework for video text extraction. By utilizing advanced vision-language models within a robust multi-stage pipeline, our approach ensures accurate detection and recognition of textual data. The framework integrates frame clarity evaluation, leveraging sharpness and edge detection algorithms to select high-quality frames for analysis. These frames are processed using generative AI models, capable of capturing contextual and visual semantics beyond conventional OCR capabilities. The system is designed as an end-to-end solution, supporting video recording, frame processing, and seamless text extraction with enhanced robustness against noise and image degradation. Extensive validation highlights the proposed system’s superior performance in handling diverse text styles, orientations, and dynamic video content. The integration of generative AI significantly improves text extraction accuracy and scalability, demonstrating its potential for applications in automated transcription, digital archiving, and intelligent multimedia systems.},
  keywords={Accuracy;Generative AI;Text recognition;Computational modeling;Pipelines;Text detection;Transformers;Data models;Robustness;Videos;ext Extraction;Generative AI;Vision-Language Models;Scene Text Recognition;End-to-End Framework},
  doi={10.1109/RMKMATE64874.2025.11042744},
  ISSN={},
  month={May},}@INPROCEEDINGS{11050042,
  author={Wu, Le and Wu, Liji and Ba, Zhiwei and Zhang, Xiangmin},
  booktitle={2025 IEEE International Symposium on Hardware Oriented Security and Trust (HOST)}, 
  title={An Input Recovery Side-Channel Attack on Dnn Accelerator with Three-Dimensional Power Surface}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={Amid the rapid evolution of diverse Deep Neural Network (DNN) accelerators, the potential side-channel leakage poses a serious threat to the security of Artificial intelligence (AI) devices. This hardware vulnerability will leak sensitive input data of DNN models, allowing adversaries to steal individual privacy and trade secrets. We propose a novel Side-Channel Attack (SCA) methodology leveraging the Three-Dimensional Power Surface (3DPS) for DNN accelerators. 3DPS facilitates structured feature reconstruction of matrix multiplications, overcoming the limitations of the power trace analysis method in both spatial and temporal dimensions. Following 3DPS preprocessing, we devise the Deep-Learning Side-Channel Attack (DL-SCA) methodologies and successfully recover high-quality input images. In our methodology, we achieve a high accuracy rate with a minimal number of training samples. Furthermore, our work demonstrates the effectiveness of input image recovery under random noise injection. Finally, we delve deeper into the effectiveness of our attack in recovering more intricate images under diverse attack conditions with different loss functions and kernel sizes.},
  keywords={Training;Surface reconstruction;Noise;Artificial neural networks;Side-channel attacks;Hardware;Security;Artificial intelligence;Kernel;Image reconstruction;Three-Dimensional Power Surface;Input Recovery;Side-Channel Attack;Deep Neural Network Accelerator;Gradient Analysis},
  doi={10.1109/HOST64725.2025.11050042},
  ISSN={2765-8406},
  month={May},}@ARTICLE{10906408,
  author={Zhu, Li and Ye, Zijie and Wang, Hongwei and Yu, Richard and Tao, Tang},
  journal={IEEE Internet of Things Journal}, 
  title={IoT-Enhanced Generative AI for Dynamic Train Control in Virtually Coupled Train Set Systems}, 
  year={2025},
  volume={12},
  number={10},
  pages={13415-13427},
  abstract={With the rapid development of the Internet of Things (IoT), train control systems have emerged as a successful application scenario. The virtually coupled train set (VCTS), as a new paradigm for train control, relies on more efficient vehicle-to-vehicle and vehicle-to-ground communication to achieve closer train spacing. This enhanced communication allows trains to capture more complex and detailed state information. However, traditional train control algorithms, limited by their data processing capabilities, often cannot fully utilize this additional information, leading to conservative control strategies to ensure safety and stability. Generative Artificial Intelligence (GAI), particularly generative diffusion models, has recently shown great potential in optimizing IoT scenarios by handling more complex environments. This article proposes a GAI-based control algorithm framework that leverages diffusion models to optimize train trajectories. By integrating the extensive real-time data generated by IoT systems, the GAI-driven approach enhances decision-making processes, offering more precise and adaptive control strategies tailored to the demands of VCTS. This framework demonstrates the potential of combining IoT data with GAI to achieve higher control accuracy, ensuring safety and performance in dynamic and complex urban rail transit scenarios. Experimental results validate the effectiveness of the proposed method, highlighting its robustness and adaptability across various conditions.},
  keywords={Internet of Things;Sensors;Real-time systems;Safety;Diffusion models;Control systems;Rails;Sensor systems;Process control;Vehicle dynamics;Diffusion models;generative artificial intelligence (GAI);Internet of Things (IoT);train control optimization;urban rail transit;virtually coupled train set (VCTS)},
  doi={10.1109/JIOT.2025.3546016},
  ISSN={2327-4662},
  month={May},}@ARTICLE{10974956,
  author={Zhang, Mingyan and Wang, Yiqing and Hung, Jui-Long and Wang, Jie and Duan, Chao},
  journal={IEEE Access}, 
  title={An Early Warning Method Based on Blending of Deep Generative Model and Oversampling Model for Online Learning}, 
  year={2025},
  volume={13},
  number={},
  pages={72248-72268},
  abstract={Early warning for learning performance requires to identify the maximum number of at-risk students as early as possible within a semester. However, educational data often suffer from the issue of data imbalance, making it challenging to simultaneously achieve both high precision (accurate identification) and high recall (comprehensive coverage) in at-risk student detection. Deep generative models and oversampling models are effective methods to solve data imbalance issues, which can improve classification performance. This paper proposes a method that combines the advantages of deep generative models and oversampling models to build a blending model for dealing with imbalanced educational data, which can effectively improve the precision, recall, F1-score and AUC for online learning early warning. First, we compare baseline models to select the best classifier, then choose the highest-precision deep generative model and the highest-recall oversampling model to construct blending models, which are shown to improve early warning prediction metrics. Finally, interpretable models are used to analyze differences in at-risk student prediction between the blending model, deep generative model, and oversampling model. The proposed models are validated on both extremely imbalanced datasets and new semester datasets. Results show that: (1) Compared to the baseline model, both the base learners built by the deep generative model and the oversampling model can improve the evaluation metrics of the model, the deep generative base learners achieve higher precision than the oversampling model, while the oversampling base learners achieve higher recall than the deep generative base learners. (2) The blending model composed of deep generative base learner and oversampling base learner can further improve the F1-score and AUC based on their individual strengths, the proposed blending model can also conduct effective early warning three units earlier than baseline models. (3) Compared to its base learners, blending model G-B-Blending changes the key variables for prediction, and the at-risk students identified by the blending model come from the union set of at-risk students identified by GAN+GB and B-SMOTE+GB individually. (4) The blending model proposed in this paper achieves better prediction results than the baseline on both extremely imbalanced datasets and new semesters datasets, it can identify more at-risk students more accurately at earlier units, allowing teachers to save more energy and time for teaching interventions. This research provides significant insights for dealing with imbalanced datasets by blending with deep generative model and oversampling model in education.},
  keywords={Predictive models;Data models;Education;Analytical models;Accuracy;Measurement;Machine learning algorithms;Autoencoders;Support vector machines;Solid modeling;Online learning early warning;deep generative model;oversampling model;blending model;interpretable AI;at-risk student identification},
  doi={10.1109/ACCESS.2025.3563642},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10870706,
  author={Bolisetty, Pujiita Srieya and N A, Lakkshmi Yogesh and Kosuri, Siva Dhanush and Sravan, Puppala and Sai Karthik, Sivaraju Venkata and C.B, Rajesh},
  booktitle={2024 4th International Conference on Artificial Intelligence and Signal Processing (AISP)}, 
  title={Comparative Analysis of CNN Models' Accuracy Using Synthetic and Original Datasets for Cotton Leaf Classification}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In agriculture, finding diseases in plants as soon as possible is very important for getting the most crops and making sure there is enough food for everyone. A potential way to quickly and accurately diagnose diseases is to use Artificial Intelligence (AI) tools, especially image classification models. But the quality and variety of the training sample have a big impact on how well these models work. In many cases, it's hard to get a fair collection with enough samples. In order to solve this problem, we suggest a new way to classify cotton leaf diseases that uses both fake and real datasets. First, we use the Deep Convolutional Generative Adversarial Network (DCGAN) method to make a fake dataset. This makes fake pictures that look like the ones in the real dataset. After that, we use both the real and mixed datasets to train different Convolutional Neural Network (CNN) models, such as DenseNet121, InceptionV3, MobileNetV2, ResNet50, VGG16, and VGG19. To see how well each model does on both sets of data, evaluation measures like accuracy, Fl score, and classification results are used. Our results show that the accuracy rates of the combined dataset with simulated pictures are higher than those of the original dataset alone.},
  keywords={Training;Analytical models;Accuracy;Crops;Signal processing;Data augmentation;Data models;Convolutional neural networks;Cotton;Synthetic data;Artificial Intelligence;Agriculture;Disease Detection;Image Classification;Synthetic Dataset;Original Dataset;CNN Models;Accuracy Analysis},
  doi={10.1109/AISP61711.2024.10870706},
  ISSN={2640-5768},
  month={Oct},}@INPROCEEDINGS{10064732,
  author={Zhang, Wenwei and Kong, Dehua and He, Xiaoyang and Xia, Mingyao},
  booktitle={2022 International Applied Computational Electromagnetics Society Symposium (ACES-China)}, 
  title={AI-TCM-based Solver for Scattering Problems by Two-dimensional PEC Objects}, 
  year={2022},
  volume={},
  number={},
  pages={1-3},
  abstract={This paper presents a strategy to solve 2D scattering problems using artificial intelligence (AI) and the theory of characteristic mode (TCM). Because the characteristic modes (CMs) are independent of incident waves, the artificial neural network (ANN) can focus on extracting the inherent features of the target, which in terms of CMs are the generalized characteristic values and wave coefficients. A combined convolutional neural network (CNN) and attention-based neural network is employed in this paper. Numerical results show that the proposed scheme can well predict the scattering field by 2D PEC targets with arbitrary incident direction.},
  keywords={Three-dimensional displays;Shape;Two dimensional displays;Electromagnetic scattering;Feature extraction;Computational electromagnetics;Dielectrics;Artificial Intelligence;Attention-based Neural Network;Convolutional Neural Network;Scattering Prediction;Theory of Characteristic Mode},
  doi={10.1109/ACES-China56081.2022.10064732},
  ISSN={},
  month={Dec},}@ARTICLE{10639525,
  author={Qin, Zhijin and Liang, Le and Wang, Zijing and Jin, Shi and Tao, Xiaoming and Tong, Wen and Li, Geoffrey Ye},
  journal={Proceedings of the IEEE}, 
  title={AI Empowered Wireless Communications: From Bits to Semantics}, 
  year={2024},
  volume={112},
  number={7},
  pages={621-652},
  abstract={Artificial intelligence (AI) and machine learning (ML) have shown tremendous potential in reshaping the landscape of wireless communications and are, therefore, widely expected to be an indispensable part of the next-generation wireless network. This article presents an overview of how AI/ML and wireless communications interact synergistically to improve system performance and provides useful tips and tricks on realizing such performance gains when training AI/ML models. In particular, we discuss in detail the use of AI/ML to revolutionize key physical layer and lower medium access control (MAC) layer functionalities in traditional wireless communication systems. In addition, we provide a comprehensive overview of the AI/ML-enabled semantic communication systems, including key techniques from data generation to transmission. We also investigate the role of AI/ML as an optimization tool to facilitate the design of efficient resource allocation algorithms in wireless communication networks at both bit and semantic levels. Finally, we analyze major challenges and roadblocks in applying AI/ML in practical wireless system design and share our thoughts and insights on potential solutions.},
  keywords={Wireless communication;Artificial intelligence;Semantics;Wireless networks;6G mobile communication;Optimization;Machine learning;Media Access Protocol;Semantics;Communication systems;Resource management;Data processing;Artificial intelligence (AI);machine learning (ML);semantic communications;wireless communications},
  doi={10.1109/JPROC.2024.3437730},
  ISSN={1558-2256},
  month={July},}@ARTICLE{10429762,
  author={Yu, Ting and Wang, Shuai and Chen, Wei and Yu, F. Richard and Leung, Victor C. M. and Tian, Zijian},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, 
  title={Self-Supervised Adaptive Illumination Estimation for Low-Light Image Enhancement}, 
  year={2024},
  volume={8},
  number={2},
  pages={1882-1893},
  abstract={In low-light image enhancement tasks, global structure and local texture details have different effects on illumination estimation. However, most existing works fail to effectively explore the intrinsic association within them. To effectively balance the structure-preserving and texture-smoothing for illumination maps, this paper introduces a new illumination smoothing loss and proposes a self-supervised adaptive illumination estimation network (AIE-Net). The illumination smoothing loss achieves a balance between structure-preserving and texture-smoothing mainly through L2 norm, truncated Huber, and Gaussian kernel function with color affinity. To construct AIE-Net, we introduce a local-global adaptive modulation (LGAM) module in deep feature extraction. The module allows local and global features to be adaptively fused in a spatially varying manner by predicting scaling and adding factors. Finally, we separately estimate the illumination maps for the input image and its inverted image, and then achieve exposure correction with multi-exposure fusion. Extensive experiments show that the proposed method can improve image quality under different light conditions, and has better performance and generalization ability than other methods on several datasets.},
  keywords={Lighting;Smoothing methods;Estimation;Image color analysis;Feature extraction;Task analysis;Image enhancement;Adaptive fusion;illumination smoothing loss;low-light image enhancement;vision transformer},
  doi={10.1109/TETCI.2024.3359051},
  ISSN={2471-285X},
  month={April},}@INPROCEEDINGS{10579029,
  author={Chan, S.},
  booktitle={2024 IEEE World AI IoT Congress (AIIoT)}, 
  title={Cascading Succession of Models for an Enhanced Long-Tail Discernment AI System}, 
  year={2024},
  volume={},
  number={},
  pages={393-401},
  abstract={A Spatio-Temporal Knowledge Graph (STKG) with a Type-Sensitive extension (a.k.a., TS-STKG or T2S2KG) and a quintuple representation for spatio-temporal facts is examined for prospective use. Certain embedding models — to contend with complex relationships (e.g., 1-to-N, N-to-1, N-to-N, etc.) — are utilized in a cascading fashion. Various negative sampling techniques are used at each major cascade, and this ensemble was explored against the Yet Another Great Ontology (YAGO)3-10 dataset. As the long-tail phenomenon is prevalent, with its concomitant unbalanced data (and bias towards favoring head classes), selected T2S2TKG Embedding (T2S2TKGE) techniques were utilized to better balance between head and tail classes. These were sorted into cascades based upon their performance against the various complex relationships, and their time as well as space complexities were considered as well. Various architectural constructs were explored, and a Graph Convolutional Network (GCN)-Bidirectional Long Short-Term Memory (BiLSTM)-“GraphSAGE”-inspired Graph-Attention-Network (GSGAT) mechanism along with a Robust Convex Relaxation (RCR)-based Deep Convolutional Neural Network (DCNN) Generative Adversarial Network (GAN) (DCGAN)-DCNN-1,2,3 amalgam shows promise for operationalizing the aforementioned.},
  keywords={Graph convolutional networks;Knowledge graphs;Tail;Ontologies;Generative adversarial networks;Complexity theory;Artificial intelligence;artificial intelligence;discernment;long-tail relationships;machine learning;negative sampling;spatio-temporal knowledge graph completion;type-sensitive extension;quintuple representation},
  doi={10.1109/AIIoT61789.2024.10579029},
  ISSN={},
  month={May},}@ARTICLE{1634335,
  author={Hong Chen and Song-Chun Zhu},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={A generative sketch model for human hair analysis and synthesis}, 
  year={2006},
  volume={28},
  number={7},
  pages={1025-1040},
  abstract={In this paper, we present a generative sketch model for human hair analysis and synthesis. We treat hair images as 2D piecewise smooth vector (flow) fields and, thus, our representation is view-based in contrast to the physically-based 3D hair models in graphics. The generative model has three levels. The bottom level is the high-frequency band of the hair image. The middle level is a piecewise smooth vector field for the hair orientation, gradient strength, and growth directions. The top level is an attribute sketch graph for representing the discontinuities in the vector field. A sketch graph typically has a number of sketch curves which are divided into 11 types of directed primitives. Each primitive is a small window (say 5 times 7 pixels) where the orientations and growth directions are defined in parametric forms, for example, hair boundaries, occluding lines between hair strands, dividing lines on top of the hair, etc. In addition to the three level representation, we model the shading effects, i.e., the low-frequency band of the hair image, by a linear superposition of some Gaussian image bases and we encode the hair color by a color map. The inference algorithm is divided into two stages: 1) We compute the undirected orientation field and sketch graph from an input image and 2) we compute the hair growth direction for the sketch curves and the orientation field using a Swendsen-Wang cut algorithm. Both steps maximize a joint Bayesian posterior probability. The generative model provides a straightforward way for synthesizing realistic hair images and stylistic drawings (rendering) from a sketch graph and a few Gaussian bases. The latter can be either inferred from a real hair image or input (edited) manually using a simple sketching interface. We test our algorithm on a large data set of hair images with diverse hair styles. Analysis, synthesis, and rendering results are reported in the experiments},
  keywords={Humans;Hair;Rendering (computer graphics);Inference algorithms;Animation;Computer graphics;Computer vision;Extraterrestrial measurements;Gaussian processes;Bayesian methods;Hair modeling;hair analysis and synthesis;flow patterns;generative models;orientation field;texture;nonphotorealistic rendering.},
  doi={10.1109/TPAMI.2006.131},
  ISSN={1939-3539},
  month={July},}@INPROCEEDINGS{10578894,
  author={Kallonas, Christos and Piki, Andriani and Stavrou, Eliana},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Empowering Professionals: A Generative AI Approach to Personalized Cybersecurity Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={We are navigating an era of ongoing technological transformations characterized by a growing need for developing digital skills, including cybersecurity and Artificial Intelligence (AI) literacy. The skills gap in cybersecurity has been acknowledged by the academic and business community at large, which faces an ongoing challenge in terms of finding and attaining talents. Even though different initiatives have been launched to upskill and reskill individuals, they are either ineffective in developing the required competencies or fail to motivate participants to learn and advance their competencies in relation to a cybersecurity job role. A key factor hindering these efforts is the adoption of a generic training approach rather than tailoring learning to the needs of individual learners. It is imperative to identify novel ways to motivate and engage learners, fostering a lifelong learning mindset that is essential for cybersecurity professional development and progression. This work aims to investigate how generative AI can be leveraged to empower professionals to take ownership of their learning by assisting them to create a personalized cybersecurity study plan. The objective is to inspire the design of innovative solutions focusing on accelerating skills development and contributing to increasing the supply of skilled cybersecurity professionals.},
  keywords={Training;Ethics;Generative AI;Navigation;Engineering profession;Focusing;Computer security;Cybersecurity learning;cybersecurity professional development;cybersecurity career;generative AI;personalized learning;ChatGPT;learning autonomy},
  doi={10.1109/EDUCON60312.2024.10578894},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10822177,
  author={Greca, Attilio Della and Amaro, Ilaria and Barra, Paola and Rosapepe, Emanuele and Tortora, Genoveffa},
  booktitle={2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Enhancing therapeutic engagement in Mental Health through Virtual Reality and Generative AI: a co-creation approach to trust building}, 
  year={2024},
  volume={},
  number={},
  pages={6805-6811},
  abstract={Trust is a fundamental component of effective therapeutic relationships, significantly influencing patient engagement and treatment outcomes in mental health care. This paper presents a preliminary study aimed at enhancing trust through the co-creation of virtual therapeutic environments using generative artificial intelligence (AI). We propose a multimodal AI model, integrated into a virtual reality (VR) platform developed in Unity, which generates three-dimensional (3D) objects from textual descriptions. This approach allows patients to actively participate in shaping their therapeutic environment, fostering a collaborative atmosphere that enhances trust between patients and therapists. The methodology is structured into four phases, combining non-immersive and immersive experiences to co-create personalized therapeutic spaces and 3D objects symbolizing emotional or psychological states. Preliminary results demonstrate the system’s potential in improving the therapeutic process through the real-time creation of virtual objects that reflect patient needs, with high-quality mesh generation and semantic coherence. This work offers new possibilities for patient-centered care in mental health services, suggesting that virtual co-creation can improve therapeutic efficacy by promoting trust and emotional engagement.},
  keywords={Solid modeling;Three-dimensional displays;Generative AI;Atmospheric modeling;Semantics;Virtual environments;Mental health;Transforms;Real-time systems;Mesh generation;Virtual Reality (VR);Generative AI;Mental Health;Trust;Personalized Therapy},
  doi={10.1109/BIBM62325.2024.10822177},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{11106651,
  author={Vidmar, Matjaz and Lynn, Robert and Panas, Daga and Leret, Inés Cámara and Antonioletti, Mario and Seth, Sohan and Hemment, Drew and Morgan, Evan},
  booktitle={2025 IEEE International Conference on Engineering, Technology, and Innovation (ICE/ITMC)}, 
  title={Open Prototyping – A Toolkit for Open Engineering?: The Case of The New Real Observatory, an Environmentally-Conscious Generative AI Platform}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={The framework of Open Engineering (OE) describes the practical realization of collaborative interdisciplinary and cross-organisational innovation projects, combining the Research and Development (R&D) processes and knowledge management, with stakeholder engagement and hands-on (systems) engineering activities. However, these concepts have so far been used analytically and practical tools are needed to turn them into integrated applied practices. In this paper we describe the development and use of one such methodology and process model called Open Prototyping (OP). We are examining its six stages as used in developing The New Real Observatory, a generative Artificial Intelligence (AI) platform for environmentally-conscious exploration of data processing. The results demonstrate the utility of this toolkit and its alignment with OE framework, whilst also exposing the critical role of facilitators in managing stakeholders' expectations as well as negotiating values and possibilities to ensure eventual delivery of successful outputs. This reinforces the previous work on practices of OE and the critical role of innovation intermediaries in advancing collaborative high-tech R&D.},
  keywords={Technological innovation;Observatories;Art;Generative AI;Collaboration;Data processing;Knowledge management;Stakeholders;Modeling;Research and development;open engineering;innovation process;prototyping;knowledge management;research methodology;The New Real Observatory;generative AI;arts;environment},
  doi={10.1109/ICE/ITMC65658.2025.11106651},
  ISSN={2693-8855},
  month={June},}@INPROCEEDINGS{10893561,
  author={Vemula, Srikanth},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Enriching Python Programming Education With Generative AI: Leveraging Large Language Models for Personalized Support and Interactive Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This innovative practice full paper describes the exploration of the transformative potential of Generative Artificial Intelligence (AI) and Large Language Models (LLMs) in Python programming education. A Python Educational Support Assistant (PESA-8B-FT) was introduced, an LLM-powered virtual assistant designed to provide personalized instruction, foster interactive learning, and deliver immediate feedback on programming tasks. The growing demand for skilled Python programmers necessitates flexible and effective educational frameworks. PESA-8B-FT addresses this need by offering 24/7 availability, accommodating diverse learning styles and schedules, and providing real-time support regardless of geographical constraints. The study demonstrates PESA-8B-FT's significant impact on Python programming education. The model achieved a perplexity score of 18.82, outperforming competing models, and received positive feedback from 90% of participants. These results highlight PESA-8B-FT's potential to enhance learning outcomes, complement traditional teaching methods, and alleviate the instructional burden on educators. By leveraging advanced LLM capabilities, this research contributes to the development of more accessible, personalized, and effective programming education methodologies.},
  keywords={Adaptation models;Generative AI;Virtual assistants;Large language models;Education;Real-time systems;Time factors;Programming profession;Python;Context modeling;Generative AI;Large Language Models;Python Programming Education;Personalized Learning;Interactive Learning},
  doi={10.1109/FIE61694.2024.10893561},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10067068,
  author={Kumar, Neeraj and Narang, Anish},
  booktitle={2023 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Generalized Spatio-Temporal Adaptive Normalization Framework}, 
  year={2023},
  volume={},
  number={},
  pages={116-121},
  abstract={In this paper, we propose Generalized Spatio-Temporal Adaptive Normalization (GSTAN) Framework for Generative Adversarial and Deep Learning Inference Architectures. By leveraging higher-order derivatives based temporal feature maps along with spatial feature map, our normalization approach leads to: (a) efficient generation of high-quality videos with better details and enhanced temporal coherence, and, (b) higher accuracy inference on multiple tasks. In order to evaluate model generalization, we performed experimental evaluation on multiple tasks including: video to video generation, video segmentation and activity recognition (classify the activity out of 101 activity classes, for a given input video). Detailed experimental analysis over a variety of datasets including CityScape, UCF101 and CK+ demonstrates superior performance of GSTAN and also provides the impact of its various configurations, including parallel GSTAN and sequential GSTAN.},
  keywords={Deep learning;Coherence;Activity recognition;Task analysis;Artificial intelligence;Videos},
  doi={10.1109/ICAIIC57133.2023.10067068},
  ISSN={2831-6983},
  month={Feb},}@ARTICLE{10713176,
  author={Cuenca, Andrei and Moncayo, Hever and Gavilanez, Gabriela},
  journal={IEEE Transactions on Aerospace and Electronic Systems}, 
  title={Artificial-Intelligence-Assisted Geomagnetic Navigation Framework}, 
  year={2025},
  volume={61},
  number={2},
  pages={2477-2490},
  abstract={Over the past few decades, the paradigm of geomagnetic navigation has been under consideration as a potential alternative to GPS in situations where GPS signals are subject to interference or are inaccessible. However, navigation methodologies that rely on magnetic fields continue to face practical development challenges due to their complex characterization, which has so far resulted in modest localization performance compared to GPS. This article presents the design and development of an innovative intelligent geomagnetic-based framework for navigation within GPS-denied environments. Two artificial-intelligence-based concepts, i.e., generative adversarial networks and deep reinforcement learning, are integrated within the framework with a Rao–Blackwellized particle filter in an attempt to introduce the onboard intelligence necessary to perform navigation using earth's magnetic anomalies with an acceptable performance. This article includes a detailed formulation of the proposed framework, its components, and demonstration of selected key capabilities through numerical simulations. The results show the promising characteristics of the proposed navigation strategy and the potential to bridging the gap that separates geomagnetic-based navigation from practical applications and deployment.},
  keywords={Navigation;Magnetic separation;Magnetometers;Magnetic field measurement;Aircraft navigation;Geomagnetism;Accuracy;Military aircraft;Magnetosphere;Magnetic resonance imaging;DQN;Earth Magnetic Anomaly Grid (EMAG) model;geomagnetic navigation;machine learning;magnetic anomaly fields;reinforcement learning (RL);sensor fusion;superimage resolution},
  doi={10.1109/TAES.2024.3477416},
  ISSN={1557-9603},
  month={April},}@INPROCEEDINGS{10469056,
  author={Kumari, Ankita and Sharma, Ishu},
  booktitle={2024 Fourth International Conference on Advances in Electrical, Computing, Communication and Sustainable Technologies (ICAECT)}, 
  title={Securing Vulnerabilities: Fuzzer Detection with Machine Learning Classification}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Fuzzy logic, machine learning, and artificial intelligence (AI) together provide a ground-breaking approach to increased security. This change in perspective creates new opportunities that may aid in identifying vulnerabilities and strengthening protocols, networks, and software. Fuzzer activities and other anomalies in a network may be easily identified by machine learning because to its ability to analyze historical data and observe events in real time. Future-facing features like as sophisticated threat models, artificial intelligence (AI)-powered automated responses, and the integration of threat intelligence will transform vulnerability discovery. In order to strengthen defensive efforts, collaboration amongst other areas, adherence to safety regulations, and user education will be necessary. The promising combination of machine learning and fuzzer identification might make the internet a safer place since cyber dangers are always evolving. In this research paper, a systematic approach is employed for early detection of fuzzer attack using UNSW-NB15 dataset. The research work’s proposed method archives noteworthy performance of finding changes from how the network usually works and quickly letting admins know about any possible security vulnerabilities or threats. Because of this early notice, companies can take steps to protect their digital assets and make it less likely that they will be misused. The experiments are performed to evaluate the capability of logistic regression, gaussian naïve bayes and LSTM machine learning techniques on dataset for fuzzer attack and benign traffic patterns and comparative anlyais are presented in the research paper.},
  keywords={Threat modeling;Systematics;Machine learning;Transforms;Traffic control;Software;Regulation;Logistic Regression;Gaussian Naive Bayes;LSTM Algorithm;Network Security;Privacy;Attack Detection},
  doi={10.1109/ICAECT60202.2024.10469056},
  ISSN={},
  month={Jan},}@ARTICLE{10130745,
  author={Yang, Zhengwei and Zhong, Xian and Zhong, Zhun and Liu, Hong and Wang, Zheng and Satoh, Shin'Ichi},
  journal={IEEE Transactions on Image Processing}, 
  title={Win-Win by Competition: Auxiliary-Free Cloth-Changing Person Re-Identification}, 
  year={2023},
  volume={32},
  number={},
  pages={2985-2999},
  abstract={Recent person Re-IDentification (ReID) systems have been challenged by changes in personnel clothing, leading to the study of Cloth-Changing person ReID (CC-ReID). Commonly used techniques involve incorporating auxiliary information (e.g., body masks, gait, skeleton, and keypoints) to accurately identify the target pedestrian. However, the effectiveness of these methods heavily relies on the quality of auxiliary information and comes at the cost of additional computational resources, ultimately increasing system complexity. This paper focuses on achieving CC-ReID by effectively leveraging the information concealed within the image. To this end, we introduce an Auxiliary-free Competitive IDentification (ACID) model. It achieves a win-win situation by enriching the identity (ID)-preserving information conveyed by the appearance and structure features while maintaining holistic efficiency. In detail, we build a hierarchical competitive strategy that progressively accumulates meticulous ID cues with discriminating feature extraction at the global, channel, and pixel levels during model inference. After mining the hierarchical discriminative clues for appearance and structure features, these enhanced ID-relevant features are crosswise integrated to reconstruct images for reducing intra-class variations. Finally, by combing with self- and cross-ID penalties, the ACID is trained under a generative adversarial learning framework to effectively minimize the distribution discrepancy between the generated data and real-world data. Experimental results on four public cloth-changing datasets (i.e., PRCC-ReID, VC-Cloth, LTCC-ReID, and Celeb-ReID) demonstrate the proposed ACID can achieve superior performance over state-of-the-art methods. The code is available soon at: https://github.com/BoomShakaY/Win-CCReID.},
  keywords={Clothing;Image color analysis;Feature extraction;Degradation;Computer science;Adversarial machine learning;Skeleton;Person re-identification;auxiliary-free;cloth-changing;competitive strategy},
  doi={10.1109/TIP.2023.3277389},
  ISSN={1941-0042},
  month={},}@INPROCEEDINGS{10345949,
  author={Virvou, Maria and Tsihrintzis, George A.},
  booktitle={2023 14th International Conference on Information, Intelligence, Systems & Applications (IISA)}, 
  title={Is ChatGPT Beneficial to Education? A Holistic Evaluation Framework Based on Intelligent Tutoring Systems}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={The recent launch of ChatGPT by OpenAI has created a profound global impact, initiating deep questions among educators about how it might affect education, syllabi and teaching methods. Currently, the full scope of potential benefits and risks associated with ChatGPT in education remains unclear, given that its impact surpasses the level of preparation educators and institutions may have had for such a pre-trained generative AI tool. While Artificial Intelligence in Education has long been a subject of research, with a particular focus on developing Intelligent Tutoring Systems, the emergence of ChatGPT marks a distinctive advancement in this field. Unlike dedicated Intelligent Tutoring Systems, ChatGPT is readily available to a diverse spectrum of educational stakeholders, including teachers, students, schools, universities, and educational institutions. Scholars have initiated assessments of ChatGPT's effectiveness across various educational disciplines, even though ChatGPT was not explicitly designed for educational purposes. However, the widespread accessibility of ChatGPT, coupled with its extensive knowledge base, necessitates the development of comprehensive evaluation frameworks. In this paper, we introduce a holistic evaluation framework tailored for ChatGPT. This framework takes into account both soft and hard skills, and it is designed to seamlessly incorporate ChatGPT into Intelligent Tutoring Systems, making it suitable for a wide range of educational fields. By establishing a connection between ITS and ChatGPT, as they are both AI tools, we can benefit from the substantial background work achieved by previous research in ITSs to evaluate the educational influence of ChatGPT.},
  keywords={Ethics;Education;Knowledge based systems;Chatbots;Cognition;Stakeholders;ChatGPT;AI in Education;Intelligent Tutoring Systems;e-learning;Educational Evaluation Frameworks;educational software;large language models;generative AI},
  doi={10.1109/IISA59645.2023.10345949},
  ISSN={},
  month={July},}@ARTICLE{10755095,
  author={Song, Myung Keun and Niaz, Asim and Umraiz, Muhammad and Iqbal, Ehtesham and Soomro, Shafiullah and Choi, Kwang Nam},
  journal={IEEE Access}, 
  title={Denoising Diffusion-Based Image Generation Model Using Principal Component Analysis}, 
  year={2024},
  volume={12},
  number={},
  pages={170487-170498},
  abstract={In recent years, advancements in GPU technology and increased data collection have significantly enhanced the performance of artificial intelligence and image generation models. However, in specific areas such as medical imaging or facial images, constraints in data collection and class imbalance issues have posed challenges to improving image quality. This study proposes the integration of Principal Component Analysis (PCA) into image generation models to address these challenges. Specifically, to overcome the limitations of conventional image generation models like GANs and VAEs, we utilize the Denoise Diffusion Probabilistic Model (DDPM) as the backbone, integrating it with PCA techniques. Using the CIFAR10 and FFHQ datasets, we evaluated the image quality of the proposed PCA-DDPM, the traditional DDPM, and DCGAN. As a result, the PCA-DDPM demonstrated superior image quality and efficiency. Notably, it maintained high performance even when trained with a limited amount of data. The findings of this research contribute significantly to the advancement of image generation technology and are expected to be applied in various domains.},
  keywords={Principal component analysis;Image synthesis;Feature extraction;Data models;Noise;Diffusion models;Computational modeling;Training;Noise reduction;Analytical models;Artificial intelligence;deep learning;denoising diffusion;image generation;principal component analysis},
  doi={10.1109/ACCESS.2024.3500212},
  ISSN={2169-3536},
  month={},}@ARTICLE{11119723,
  author={Zhang, Jianing and Zheng, Yuchao and Li, Ziwei and Dai, Qionghai and Yuan, Xiaoyun},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={GBR: Generative Bundle Refinement for High-fidelity Gaussian Splatting with Enhanced Mesh Reconstruction}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Gaussian splatting has gained attention for its efficient representation and rendering of 3D scenes using continuous Gaussian primitives. However, it struggles with sparse-view inputs due to limited geometric and photometric information, causing ambiguities in depth, shape, and texture. We propose GBR: Generative Bundle Refinement, a method for high-fidelity Gaussian splatting and meshing using only 4–6 input views. GBR integrates a neural bundle adjustment module to enhance geometry accuracy and a generative depth refinement module to improve geometry fidelity. More specifically, the neural bundle adjustment module integrates a foundation network to produce initial 3D point maps and point matches from unposed images, followed by bundle adjustment optimization to improve multiview consistency and point cloud accuracy. The generative depth refinement module employs a diffusion-based strategy to enhance geometric details and fidelity while preserving the scale. Finally, for Gaussian splatting optimization, we propose a multimodal loss function incorporating depth and normal consistency, geometric regularization, and pseudo-view supervision, providing robust guidance under sparse-view conditions. Experiments on widely used datasets show that GBR significantly outperforms existing methods under sparse-view inputs. Additionally, GBR demonstrates the ability to reconstruct and render large-scale real-world scenes, such as the Pavilion of Prince Teng and the Great Wall, with remarkable details using only 6 views. More results can be found on our project page https://gbrnvs.github.io.},
  keywords={Image reconstruction;Accuracy;Surface reconstruction;Geometry;Cameras;Rendering (computer graphics);Point cloud compression;Neural radiance field;Optimization;Bundle adjustment;Sparse-view Gaussian Splatting;Meshing;Generative Bundle Refinement;Neural Rendering},
  doi={10.1109/TCSVT.2025.3596613},
  ISSN={1558-2205},
  month={},}@INPROCEEDINGS{8490425,
  author={Karavolos, Daniel and Liapis, Antonios and Yannakakis, Georgios N.},
  booktitle={2018 IEEE Conference on Computational Intelligence and Games (CIG)}, 
  title={Using a Surrogate Model of Gameplay for Automated Level Design}, 
  year={2018},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper describes how a surrogate model of the interrelations between different types of content in the same game can be used for level generation. Specifically, the model associates level structure and game rules with gameplay outcomes in a shooter game. We use a deep learning approach to train a model on simulated playthroughs of two-player deathmatch games, in diverse levels and with different character classes per player. Findings in this paper show that the model can predict the duration and winner of the match given a top-down map of the level and the parameters of the two players' character classes. With this surrogate model in place, we investigate which level structures would result in a balanced match of short, medium or long duration for a given set of character classes. Using evolutionary computation, we are able to discover levels which improve the balance between different classes. This opens up potential applications for a designer tool which can adapt a human authored map to fit the designer's desired gameplay outcomes, taking account of the game's rules.},
  keywords={Games;Computational modeling;Adaptation models;Machine learning;Weapons;Tools;Generators;deep learning;surrogate model;artificial evolution;procedural content generation;computational creativity},
  doi={10.1109/CIG.2018.8490425},
  ISSN={2325-4289},
  month={Aug},}@ARTICLE{9229132,
  author={Du, Changde and Du, Changying and Huang, Lijie and Wang, Haibao and He, Huiguang},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Structured Neural Decoding With Multitask Transfer Learning of Deep Neural Network Representations}, 
  year={2022},
  volume={33},
  number={2},
  pages={600-614},
  abstract={The reconstruction of visual information from human brain activity is a very important research topic in brain decoding. Existing methods ignore the structural information underlying the brain activities and the visual features, which severely limits their performance and interpretability. Here, we propose a hierarchically structured neural decoding framework by using multitask transfer learning of deep neural network (DNN) representations and a matrix-variate Gaussian prior. Our framework consists of two stages, Voxel2Unit and Unit2Pixel. In Voxel2Unit, we decode the functional magnetic resonance imaging (fMRI) data to the intermediate features of a pretrained convolutional neural network (CNN). In Unit2Pixel, we further invert the predicted CNN features back to the visual images. Matrix-variate Gaussian prior allows us to take into account the structures between feature dimensions and between regression tasks, which are useful for improving decoding effectiveness and interpretability. This is in contrast with the existing single-output regression models that usually ignore these structures. We conduct extensive experiments on two real-world fMRI data sets, and the results show that our method can predict CNN features more accurately and reconstruct the perceived natural images and faces with higher quality.},
  keywords={Decoding;Image reconstruction;Functional magnetic resonance imaging;Visualization;Task analysis;Brain;Correlation;Deep neural network (DNN);functional magnetic resonance imaging (fMRI);image reconstruction;multioutput regression;neural decoding},
  doi={10.1109/TNNLS.2020.3028167},
  ISSN={2162-2388},
  month={Feb},}@ARTICLE{8708955,
  author={Sarkar, Achintya Kumar and Tan, Zheng-Hua and Tang, Hao and Shon, Suwon and Glass, James},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Time-Contrastive Learning Based Deep Bottleneck Features for Text-Dependent Speaker Verification}, 
  year={2019},
  volume={27},
  number={8},
  pages={1267-1279},
  abstract={There are a number of studies about extraction of bottleneck (BN) features from deep neural networks (DNNs) trained to discriminate speakers, pass-phrases, and triphone states for improving the performance of text-dependent speaker verification (TD-SV). However, a moderate success has been achieved. A recent study presented a time contrastive learning (TCL) concept to explore the non-stationarity of brain signals for classification of brain states. Speech signals have similar non-stationarity property, and TCL further has the advantage of having no need for labeled data. We therefore present a TCL based BN feature extraction method. The method uniformly partitions each speech utterance in a training dataset into a predefined number of multi-frame segments. Each segment in an utterance corresponds to one class, and class labels are shared across utterances. DNNs are then trained to discriminate all speech frames among the classes to exploit the temporal structure of speech. In addition, we propose a segment-based unsupervised clustering algorithm to re-assign class labels to the segments. TD-SV experiments were conducted on the RedDots challenge database. The TCL-DNNs were trained using speech data of fixed pass-phrases that were excluded from the TD-SV evaluation set, so the learned features can be considered phrase-independent. We compare the performance of the proposed TCL BN feature with those of short-time cepstral features and BN features extracted from DNNs discriminating speakers, pass-phrases, speaker+pass-phrase, as well as monophones whose labels and boundaries are generated by three different automatic speech recognition (ASR) systems. Experimental results show that the proposed TCL-BN outperforms cepstral features and speaker+pass-phrase discriminant BN features, and its performance is on par with those of ASR derived BN features. Moreover, the clustering method improves the TD-SV performance of TCL-BN and ASR derived BN features with respect to their standalone counterparts. We further study the TD-SV performance of fusing cepstral and BN features.},
  keywords={Feature extraction;Training;Speech recognition;Phonetics;Clustering methods;Mel frequency cepstral coefficient;DNNs;time-contrastive learning;bottleneck feature;GMM-UBM;speaker verification},
  doi={10.1109/TASLP.2019.2915322},
  ISSN={2329-9304},
  month={Aug},}@INPROCEEDINGS{10331858,
  author={Reddy, Nalagatla Mohaneesh and Reddy, Thellapally Jagadishwar and Kiran, M Udaya and Adharsh, Veldi Vivek and Natarajan, B and Bhuvaneswari, R},
  booktitle={2023 International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS)}, 
  title={Enhanced Visual Clarity in Noise-Reduced Image Environment}, 
  year={2023},
  volume={},
  number={},
  pages={859-866},
  abstract={This research introduces an advanced deep learning approach aimed at restoring highly degraded aging photographs. While conventional restoration tasks in supervised learning are effective, real-world image degradation is intricate, making it challenging for the network to generalize due to the disparity between artificial images and genuine aged photographs. The proposed research pioneers a distinctive triplet domain translation network, leveraging a comprehensive dataset containing both artificial image pairs and genuine snapshots to address these complexities. The approach involves training two variational autoencoders (VAEs) to encode clean images and aged photos into distinct latent spaces, facilitating translation between these latent representations. The existence of a discernible gap in the latent space enables the proposed translation strategy to effectively generalize to real photos, overcoming real-world degradation challenges. Moreover, this research incorporates a global branch integrated with a partial nonlocal block to tackle structural defects and multiple mixed deteriorations within a single aged image. Additionally, an extra branch is introduced to handle unstructured defects such as noise, blurriness, scratches, and dust spots. The fusion of these branches in the latent space translation significantly enhances the capability to address a wide array of defects commonly found in antique photos. Furthermore, a specialized face refinement network is employed to extract intricate facial details from the old photos, resulting in enhanced perceptual quality of the restored images. The effectiveness of the proposed method is demonstrated through extensive evaluations, showcasing its superior performance in terms of visual quality for restoring ancient images compared to both current state-of-the-art techniques and existing commercial technologies.},
  keywords={Degradation;Training;Visualization;Supervised learning;Training data;Learning (artificial intelligence);Aging;Variational Auto Encoder;Mixed declination;Latent Space translation;Deep learning},
  doi={10.1109/ICSSAS57918.2023.10331858},
  ISSN={},
  month={Oct},}@ARTICLE{10201840,
  author={Joshi, Amol S. and Dabouei, Ali and Dawson, Jeremy and Nasrabadi, Nasser M.},
  journal={IEEE Access}, 
  title={Fingerphoto Deblurring Using Attention-Guided Multi-Stage GAN}, 
  year={2023},
  volume={11},
  number={},
  pages={82709-82727},
  abstract={Using fingerphoto images acquired from mobile cameras, low-quality sensors, or crime scenes, it has become a challenge for automated identification systems to verify the identity due to various acquisition distortions. A significant type of photometric distortion that notably reduces the quality of a fingerphoto is the blurring of the image. This paper proposes a deep fingerphoto deblurring model to restore the ridge information degraded by the image blurring. As the core of our model, we utilize a conditional Generative Adversarial Network (cGAN) to learn the distribution of natural ridge patterns. We perform several modifications to enhance the quality of the reconstructed (deblurred) fingerphotos by our proposed model. First, we develop a multi-stage GAN to learn the ridge distribution in a coarse-to-fine framework. This framework enables the model to maintain the consistency of the ridge deblurring process at different resolutions. Second, we propose a guided attention module that helps the generator to focus mainly on blurred regions. Third, we incorporate a deep fingerphoto verifier as an auxiliary adaptive loss function to force the generator to preserve the ID information during the deblurring process. Finally, we evaluate the effectiveness of the proposed model through extensive experiments on multiple public fingerphoto datasets as well as real-world blurred fingerphotos. In particular, our method achieves 5.2 dB, 8.7%, and 7.6% improvement in PSNR, AUC, and EER, respectively, compared to a state-of-the-art deblurring method.},
  keywords={Fingerprint recognition;Generative adversarial networks;Cameras;Distortion;Generators;Biometrics (access control);Photography;Biometrics;contactless fingerprints;fingerphoto deblurring;generative adversarial networks;guided attention;multi-stage generative architecture},
  doi={10.1109/ACCESS.2023.3301467},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11137330,
  author={Gumonan, Kenn Migan Vincent C. and Bernus, Judy U. and Godinez, Von Alphonse L. and Sayson, Jensar Joey Z.},
  booktitle={2025 11th International Conference on Education and Training Technologies (ICETT)}, 
  title={ChatGPT Perception and Usage in Object-Oriented Programming of Students from a Philippine Private University}, 
  year={2025},
  volume={},
  number={},
  pages={50-56},
  abstract={This study investigates the ChatGPT perception and usage of the 271 Bachelor of Science in Information Technology students at Cebu Institute of Technology University towards their Object-Oriented Programming learning journey using the Java programming language. The students’ responses were gathered through an online survey using a 5-point Likert scale. The students were purposively sampled. All the students have already completed the OOP course. The quantitative and qualitative data were analyzed using Google Colaboratory. All the students were able to use ChatGPT at some point in their OOP course. 91.14% of the students responded that they tried to solve any programming problems in OOP on their own before attempting to use ChatGPT. While most of the students agreed with 60.89% about the negative impact of using ChatGPT, 76.01% of the students disagree and strongly disagree that ChatGPT can replace teachers in programming. The ChatGPT usage and perception of the students are both not significant towards OOP performance. The result of this study provides an insight into how students used ChatGPT and how it affects their studies, particularly in the application of their programming skills in OOP. This study also contributes to the expanding body of knowledge that gauges the impact and promotes responsible use of ChatGPT for better computer programming education in this age of technology where Artificial Intelligence continuously evolves.},
  keywords={Training;Surveys;Java;Computer languages;Generative AI;Chatbots;Internet;Object oriented programming;Information technology;Programming profession;ChatGPT;Object-Oriented Programming;Perception and Usage;Natural Language Processing;Generative Artificial Intelligence},
  doi={10.1109/ICETT66247.2025.11137330},
  ISSN={},
  month={May},}@ARTICLE{10335924,
  author={Kurisummoottil Thomas, Christo and Saad, Walid and Xiao, Yong},
  journal={IEEE Journal on Selected Areas in Information Theory}, 
  title={Causal Semantic Communication for Digital Twins: A Generalizable Imitation Learning Approach}, 
  year={2023},
  volume={4},
  number={},
  pages={698-717},
  abstract={A digital twin (DT) leverages a virtual representation of the physical world, along with communication (e.g., 6G), computing (e.g., edge computing), and artificial intelligence (AI) technologies to enable many connected intelligence services. In order to handle the large amounts of network data based on digital twins (DTs), wireless systems can exploit the paradigm of semantic communication (SC) for facilitating informed decision-making under strict communication constraints by utilizing AI techniques such as causal reasoning. In this paper, a novel framework called causal semantic communication (CSC) is proposed for DT-based wireless systems. The CSC system is posed as an imitation learning (IL) problem, where the transmitter, with access to optimal network control policies using a DT, teaches the receiver using SC over a bandwidth-limited wireless channel how to improve its knowledge to perform optimal control actions. The causal structure in the transmitter’s data is extracted using novel approaches from the framework of deep end-to-end causal inference, thereby enabling the creation of a semantic representation that is causally invariant, which in turn helps generalize the learned knowledge of the system to new and unseen situations. The CSC decoder at the receiver is designed to extract and estimate semantic information while ensuring high semantic reliability. The receiver control policies, semantic decoder, and causal inference are formulated as a bi-level optimization problem within a variational inference framework. This problem is solved using a novel concept called network state models, inspired from world models in generative AI, that faithfully represents the environment dynamics leading to data generation. Furthermore, the proposed framework includes an analytical characterization of the performance gap that results from employing a suboptimal policy learned by the receiver that uses the transmitted semantic information to construct a model of the physical environment. The CSC system utilizes two concepts, namely the integrated information theory principle in the theory of consciousness and the abstract cell complex concept in topology, to precisely express the information content conveyed by the causal states and their relationships. Through this analysis, novel formulations of semantic information, semantic reliability, distortion, and similarity metrics are proposed, which extend beyond Shannon’s concept of uncertainty. Simulation results demonstrate that the proposed CSC system outperforms conventional wireless and state-of-the-art SC systems by achieving better semantic reliability with reduced bits and enabling better control policies over time thanks to the generative AI architecture.},
  keywords={Semantics;Wireless communication;Artificial intelligence;Information theory;Reinforcement learning;Inference mechanisms;Digital twins;Semantic communication;imitation learning;integrated information theory;model-based reinforcement learning;and causal inference},
  doi={10.1109/JSAIT.2023.3336538},
  ISSN={2641-8770},
  month={},}@INPROCEEDINGS{10503540,
  author={Adapa, Chathurya and Avulamanda, Sai Sindhuri and Anjana, A R K and Victor, Ajay},
  booktitle={2024 IEEE International Conference for Women in Innovation, Technology & Entrepreneurship (ICWITE)}, 
  title={AI-Powered Code Review Assistant for Streamlining Pull Request Merging}, 
  year={2024},
  volume={},
  number={},
  pages={323-327},
  abstract={WatsonX, a comprehensive data and AI platform, adeptly addresses contemporary challenges by meticulously training, validating, tuning, and deploying data to drive impactful business outcomes. The intricate task of timely merging Pull Requests (PRs) poses a significant challenge for software development teams, directly influencing business operations. This paper introduces an innovative solution leveraging AI, particularly harnessing generative AI techniques with the Falcon40-B model through the platform. The AI bot facilitates an initial PR review, offering insightful feedback on code formatting, best practices, and minor issues and streamlines collaboration by automatically assigning and notifying PR reviewers. The overarching goal is the continuous evolution of this AI bot into an intelligent reviewer, capable of assessing code from a functional standpoint. The implementation of this solution holds the promise of significantly enhancing PR management and expediting the entire development workflow.},
  keywords={Training;Codes;Reviews;Merging;Chatbots;Software;Task analysis;WatsonX;Generative AI;Pull request;Falcon40B;Code review;GitHub webhooks;Intelligent bot},
  doi={10.1109/ICWITE59797.2024.10503540},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10768247,
  author={Humayun, Muhammad Farhan and Zontone, Pamela and Marcenaro, Lucio and Gómez, David Martín and Regazzoni, Carlo},
  booktitle={2024 IEEE Workshop on Signal Processing Systems (SiPS)}, 
  title={Incremental Learning Through Fusion of Discrete Anomaly Models from Odometry Signals in Autonomous Agent Navigation}, 
  year={2024},
  volume={},
  number={},
  pages={83-88},
  abstract={This paper presents a dynamic data-driven approach for efficient anomaly detection, extraction, and fusion of multiple heterogeneous anomaly models in a generative fashion. First, we propose an adaptive Bayesian filtering technique based on a combination of Null force hypothesis and Particle filtering to accurately track the trajectories of normal and abnormal cases. We then analyze the generalized vectors and clusters generated from adaptive filtering and sequential clustering procedures to effectively detect areas with high abnormalities. To achieve this, we use probabilistic distance measurements. Finally, to increase the agent's vocabulary, we fuse different anomaly distributions to generate coupled anomaly models that allow the agent to have incremental learning capabilities. Our approach is completely data-driven and does not require any previous knowledge of the data or the environment. We show that our proposed method can effectively detect anomalies using low-dimensional odometry data and can eventually improve itself over time through iterative generation of fused anomaly models.},
  keywords={Adaptation models;Incremental learning;Filtering;Fuses;Data models;Autonomous agents;Trajectory;Bayes methods;Odometry;Anomaly detection;Anomaly detection;Adaptive Particle filtering;Generative model fusion;Incremental learning;Self-aware agent},
  doi={10.1109/SiPS62058.2024.00023},
  ISSN={2374-7390},
  month={Nov},}@INPROCEEDINGS{11127242,
  author={Davidoff, Alexandra and Vonderhaar, Lynn and Elvira, Timothy and Ochoa, Omar},
  booktitle={2025 IEEE International Conference on Artificial Intelligence Testing (AITest)}, 
  title={Formal Verification of Synthetic Image Datasets using Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={77-84},
  abstract={The growth in popularity of synthetic image generation through the usage of Artificial Intelligence has garnered interest regarding its efficacy in generating training data for downstream Machine Learning models. However, such synthetic training data must still conform to specified properties to ensure that the downstream models behave as intended, a task that can require manual verification of the correctness of generated datasets. This becomes increasingly crucial in safety critical applications when error tolerance is low. In this paper, we propose a formal approach for verifying the conformity of a synthetic dataset to specifications formalized in Linear Temporal Logic (LTL). The tool, named the Synthetic Data Formal Verifier (SDFV), analyzes an input image dataset and outputs specific LTL violations by leveraging a Large Language Model. Benefits of the tool include time saved when vetting an image dataset and a provided formal check on the dataset that can then be further reviewed. The preliminary experiments with the SDFV result in error rates of $9.5 \%, 14.3 \%$, and $33.3 \%$. However, after modification, we achieved error rates of only $4.8 \%, 4.8 \%$, and $9.5 \%$. Experiments with the SDFV show promise for further work and demonstrate the tool’s ability to both understand and reason about LTLs and synthetic images.},
  keywords={Error analysis;Large language models;Training data;Object detection;Manuals;Machine learning;Data models;Safety;Logic;Synthetic data;Formal Methods;Verification;Generative AI;Image Classifiers;Object Detection},
  doi={10.1109/AITest66680.2025.00016},
  ISSN={2835-3560},
  month={July},}@INPROCEEDINGS{10837607,
  author={Mitre, Xhulio and Zeneli, Muhamet},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Using AI to Improve Accessibility and Inclusivity in Higher Education for Students with Disabilities}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Around 1.3 billion, or more than 15% of the global population, suffer from a significant form of disability, with students and researchers in this category being underrepresented in higher education. This paper examines the use of Interactive Artificial Intelligence solutions to improve the inclusivity and accessibility of students with disabilities in higher education. The paper addresses the failure of traditional education methods to accommodate the diverse needs of people with disabilities. Through an exploratory literature review, several AI-driven solutions, like assistive technologies, adaptive-learning systems, and generative AI chatbots and virtual assistants, have been reviewed to understand how AI could be leveraged to create an inclusive learning environment. Key results show AI-driven solutions' potential to transform the learning process of people with disabilities by creating personalized learning paths, increasing access to educational resources, and supporting real-time communication. Additionally, the research highlights ethical concerns about the integration of AI in education, emphasizing the need for the participation of disabled individuals in the developmentprocess.},
  keywords={Training;Ethics;Virtual assistants;Education;Transforms;People with disabilities;Chatbots;Real-time systems;Text to speech;Artificial intelligence;Disability;Artificial Intelligence;Higher Education;Accessibility;Inclusivity},
  doi={10.1109/ITHET61869.2024.10837607},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{10764615,
  author={Min, Jun and Gao, Zhiwei and Wang, Lei and Cai, Zhenxiang and Wu, Haimeng and Zhang, Aihua},
  booktitle={2024 International Symposium on Electrical, Electronics and Information Engineering (ISEEIE)}, 
  title={A Sentiment-Controllable Music Generation System Based on Conditional Variational Autoencoder}, 
  year={2024},
  volume={},
  number={},
  pages={352-357},
  abstract={Intelligent music generation is a significant application of artificial intelligence. To better achieve the function of video background music generation, finer-grained control is necessary to enable emotional transitions in music. Therefore, distinct from the variational autoencoder model, this study combines convolutional neural networks with conditional variational auto encoders to improve the intelligent music generation model. We propose enhancements such as the measure-level regularization mechanism and Kullback-Leibler cyclic annealing mechanism, which not only optimize the posterior collapse issue but also further improve the model's representation performance in the latent space and its controllability in generation, aiming to achieve better music representation and finer-grained generative control.},
  keywords={Measurement;Technological innovation;Annealing;Neural networks;Process control;Learning (artificial intelligence);Aerospace electronics;Controllability;Decoding;Convolutional neural networks;artificial intelligence;music generation;variational autoencoders;convolutional neural networks},
  doi={10.1109/ISEEIE62461.2024.00072},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10825958,
  author={Patel, Abhi and Sultana, Kazi Zakia and Samanthula, Bharath K.},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={A Comparative Analysis between AI Generated Code and Human Written Code: A Preliminary Study}, 
  year={2024},
  volume={},
  number={},
  pages={7521-7529},
  abstract={In today’s world where generative artificial intelligence has almost become an integral part of the coding, new challenges must be faced. Therefore, evaluating software bugs in both human written and AI generated code can be useful for the developers. A comparative analysis of these two coding practices is not only helpful for the decisions taken by the developers, it will also assist to give a direction on how to improve the quality of AI driven code. Currently, researchers have leveraged the role of software metrics to compare human written code and AI generated code as these metrics have long been utilized for software bug and vulnerability prediction by the researchers. They also analyzed the secure coding practices in terms of the number of bugs found in both AI and human written code. Our study is an extension of the current works as this study focuses on a set of metrics and a set of bugs as identified by some static analyzer tools. Investigating these two coding practices from different angles can help to reveal unknown relationships and factors that further can be analyzed to improve code quality of recent AI tools. Therefore, the main objective of our work is to identify the relationships between software metrics and bugs in AI generated code and human written code to compare and contrast the coding profiles of the two approaches. This will offer developers critical knowledge to enhance their strategies in mitigating potential bug risks across different coding methodologies. We have utilized top-rated Java solutions to 90 LeetCode problems, generated corresponding AI Java solutions to them, and utilized various static analysis tools to collect metrics and bugs. In this study, we found that two software metrics CountLineCodeDecl and CountLineCodeExe are positively correlated with the bug DLS_DEAD_LOCAL_STORE and the metric AvgCyclomatic is related to the bug AvoidLiteralsInIfCondition in both human written and AI generated code. These findings provide developers with critical insights into potential bug risks, enabling more effective mitigation strategies across different coding methodologies.},
  keywords={Java;Codes;Prevention and mitigation;Computer bugs;Static analysis;Encoding;Software;Software measurement;Object recognition;Artificial intelligence;Artificial Intelligence;Static Code Analysis;Bugs;Software Metrics},
  doi={10.1109/BigData62323.2024.10825958},
  ISSN={2573-2978},
  month={Dec},}@INBOOK{10952528,
  author={Rashidi, Sol},
  booktitle={Your AI Survival Guide: Scraped Knees, Bruised Elbows, and Lessons Learned from Real-World AI Deployments}, 
  title={Overcoming the Inertia}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={Summary <p>The business case for AI is that it gives business leaders and practitioners the information and resources they need without consistently relying on head count and investments as our typical business practices. AI has proven to improve the productivity of 61% of employees. Business professionals who use AI can write 59% more business documents per hour. Eighty&#x2010;three percent of organizations worldwide claim that AI is a top priority for their business. Gartner estimates that about 80% of enterprises will have used generative AI API's and models by 2026 and/or deployed generative AI applications in production environments. The industry value of AI is projected to rise by 13 times over the next 7 years, which is good news for AI&#x2010;oriented businesses in 2024. China will be the world leader in AI technology with 26.1% of the global market share by 2030.</p>},
  keywords={Artificial intelligence;Business;Companies;Engineering profession;Art;Technological innovation;Manuals;Machine learning;Knee;Faces},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394272655},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952528},}@INBOOK{10951269,
  author={Baker, Pam},
  booktitle={Generative AI For Dummies}, 
  title={Collaborating Creatively with GenAI}, 
  year={2025},
  volume={},
  number={},
  pages={35-48},
  abstract={Summary <p>Collaborating creatively with Generative artificial intelligence (GenAI) is much like engaging with a highly adaptable and tireless creative assistant. This technology can elevate the creative process by sparking and developing creative concepts, providing unique insights, generating content, and even refining ideas. This chapter discovers how creative work with GenAI is most effective when approached as a dynamic interplay between human creativity and AI's generative power. AI&#x2010;powered tools are enabling artists to push the boundaries of creativity. In the realm of music, AI is being used to compose, arrange, and even perform music. AI can analyze musical trends and suggest harmonies, rhythms, and melodies, assisting composers in creating complex and innovative pieces. Using GenAI as a creative tool offers a multitude of benefits that can enhance human creativity and productivity. Responsible AI is a movement aimed at ensuring AI systems are developed and used in a manner that is ethical, transparent, and aligns with societal values.</p>},
  keywords={Writing;Search engines;Generative AI;Production;Internet;Creativity;Art;Visualization;Ethics;Refining},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394270767},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951269},}@ARTICLE{10409290,
  author={Bird, Jordan J. and Lotfi, Ahmad},
  journal={IEEE Access}, 
  title={CIFAKE: Image Classification and Explainable Identification of AI-Generated Synthetic Images}, 
  year={2024},
  volume={12},
  number={},
  pages={15642-15650},
  abstract={Recent advances in synthetic data have enabled the generation of images with such high quality that human beings cannot distinguish the difference between real-life photographs and Artificial Intelligence (AI) generated images. Given the critical necessity of data reliability and authentication, this article proposes to enhance our ability to recognise AI-generated images through computer vision. Initially, a synthetic dataset is generated that mirrors the ten classes of the already available CIFAR-10 dataset with latent diffusion, providing a contrasting set of images for comparison to real photographs. The model is capable of generating complex visual attributes, such as photorealistic reflections in water. The two sets of data present as a binary classification problem with regard to whether the photograph is real or generated by AI. This study then proposes the use of a Convolutional Neural Network (CNN) to classify the images into two categories; Real or Fake. Following hyperparameter tuning and the training of 36 individual network topologies, the optimal approach could correctly classify the images with 92.98% accuracy. Finally, this study implements explainable AI via Gradient Class Activation Mapping to explore which features within the images are useful for classification. Interpretation reveals interesting concepts within the image, in particular, noting that the actual entity itself does not hold useful information for classification; instead, the model focuses on small visual imperfections in the background of the images. The complete dataset engineered for this study, referred to as the CIFAKE dataset, is made publicly available to the research community for future work.},
  keywords={Artificial intelligence;Visualization;Data models;Image recognition;Computational modeling;Synthetic data;Image classification;AI-generated images;generative AI;image classification;latent diffusion},
  doi={10.1109/ACCESS.2024.3356122},
  ISSN={2169-3536},
  month={},}@ARTICLE{9810961,
  author={Ryu, Seunghyoung and Yim, Jiyeon and Seo, Junghoon and Yu, Yonggyun and Seo, Hogeon},
  journal={IEEE Access}, 
  title={Quantile Autoencoder With Abnormality Accumulation for Anomaly Detection of Multivariate Sensor Data}, 
  year={2022},
  volume={10},
  number={},
  pages={70428-70439},
  abstract={Anomaly detection (AD) is a crucial task in various industrial sectors where large amounts of data are generated from multiple sensors. Deep learning-based methods have made significant progress in AD, owing to big data and deep neural networks (DNN). Most methods for deep anomaly detection (DAD) utilize reconstruction error (i.e., the difference between the original and reconstructed values) as a measure of abnormality. However, AD performance can be improved by diversifying the source of anomaly score. To support this, we introduce the concept of anomaly source diversification and provide mathematical proofs to support this idea. In this regard, we propose a quantile autoencoder (QAE) with abnormality accumulation (AA) as a novel DAD approach that leverages data uncertainty and iteratively obtains reconstruction errors as additional sources. The anomaly score with QAE is derived from both the reconstruction error and the uncertainty term which is the range between the two quantiles. In addition, AA aggregates the errors obtained from the recursive reconstruction of the input, after which calculates the anomaly score based on the Mahalanobis distance. This process induces the score distributions of both the normal and abnormal samples farther apart by narrowing the width of the distributions, which contributes to the improvement of AD performance. The performance of the proposed QAE-AA was verified through the experiments on multi-variate sensor datasets in various domains; QAE-AA achieves 4-23% higher AUROC score on average compared to the other AD methodologies.},
  keywords={Uncertainty;Generative adversarial networks;Anomaly detection;Deep learning;Sensors;Biological neural networks;Measurement uncertainty;Deep learning;anomaly detection;autoencoder;quantile regression;anomaly score},
  doi={10.1109/ACCESS.2022.3187426},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11035589,
  author={Liu, Jian and Shen, Ruotong},
  booktitle={2025 4th International Conference on Distributed Computing and Electrical Circuits and Electronics (ICDCECE)}, 
  title={Recognition and Processing of Visual Communication Images based on Image Generation Algorithm}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={In the field of visual communication, the development of image recognition and processing technology is very important to improve the efficiency and accuracy of information transmission. Aiming at the problem that traditional image recognition methods are not accurate enough in complex scenes, this paper puts forward a visual communication image recognition and processing method based on GAN. This paper first describes the process of data collection and preprocessing, including obtaining image data from multiple channels, fine labeling, image cleaning, size adjustment, normalization and data enhancement. Then this paper designs an image generation algorithm based on GAN, optimizes the image quality through the confrontation training between generator and discriminator, and applies it to key links such as feature extraction, classification and detection. The data shows that the recognition accuracy of GAN in 10 image sets is significantly higher than that of SVM. In the first image set, the recognition accuracy of GAN is 90.9%, while that of SVM is only 69.4%. In addition, the average processing time of GAN is 866.1 milliseconds, which is lower than that of SVM, showing a faster processing speed. Based on the comprehensive experimental results, this study proves the superior performance of GAN in visual communication image recognition and processing, especially in terms of accuracy and processing efficiency, which provides new ideas and methods for the development of image recognition technology.},
  keywords={Support vector machines;Training;Adaptation models;Analytical models;Image recognition;Accuracy;Visual communication;Image synthesis;Generative adversarial networks;Convolutional neural networks;Image recognition;GAN;visual communication;support vector machine},
  doi={10.1109/ICDCECE65353.2025.11035589},
  ISSN={},
  month={April},}@ARTICLE{10463124,
  author={Zhang, Tianyi and Koutsoumpis, Antonis and Oostrom, Janneke K. and Holtrop, Djurre and Ghassemi, Sina and de Vries, Reinout E.},
  journal={IEEE Transactions on Affective Computing}, 
  title={Can Large Language Models Assess Personality From Asynchronous Video Interviews? A Comprehensive Evaluation of Validity, Reliability, Fairness, and Rating Patterns}, 
  year={2024},
  volume={15},
  number={3},
  pages={1769-1785},
  abstract={The advent of Artificial Intelligence (AI) technologies has precipitated the rise of asynchronous video interviews (AVIs) as an alternative to conventional job interviews. These one-way video interviews are conducted online and can be analyzed using AI algorithms to automate and speed up the selection procedure. In particular, the swift advancement of Large Language Models (LLMs) has significantly decreased the cost and technical barrier to developing AI systems for automatic personality and interview performance evaluation. However, the generative and task-unspecific nature of LLMs might pose potential risks and biases when evaluating humans based on their AVI responses. In this study, we conducted a comprehensive evaluation of the validity, reliability, fairness, and rating patterns of two widely-used LLMs, GPT-3.5 and GPT-4, in assessing personality and interview performance from an AVI. We compared the personality and interview performance ratings of the LLMs with the ratings from a task-specific AI model and human annotators using simulated AVI responses of 685 participants. The results show that LLMs can achieve similar or even better zero-shot validity compared with the task-specific AI model when predicting personality traits. The verbal explanations for predicting personality traits generated by LLMs are interpretable by the personality items that are designed according to psychological theories. However, LLMs also suffered from uneven performance across different traits, insufficient test-retest reliability, and the emergence of certain biases. Thus, it is necessary to exercise caution when applying LLMs for human-related application scenarios, especially for significant decisions such as employment.},
  keywords={Interviews;Task analysis;Reliability;Affective computing;Psychology;Analytical models;Computational modeling;Asynchronous video interviews;large language models;personality recognition;personnel selection},
  doi={10.1109/TAFFC.2024.3374875},
  ISSN={1949-3045},
  month={July},}@ARTICLE{10203002,
  author={Alsharhan, Abdulla and Al-Emran, Mostafa and Shaalan, Khaled},
  journal={IEEE Transactions on Engineering Management}, 
  title={Chatbot Adoption: A Multiperspective Systematic Review and Future Research Agenda}, 
  year={2024},
  volume={71},
  number={},
  pages={10232-10244},
  abstract={Studies on Chatbot adoption are gaining traction across different fields. Previous studies have outlined several drivers of Chatbot adoption through the lenses of various technology adoption theories. However, these studies have not been thoroughly reviewed and synthesized. Therefore, this article aims to analyze the technology adoption theories, antecedents, moderators, domains, methodologies, and participants through a multiperspective viewpoint. Out of 3942 studies collected, 219 studies were analyzed. The main findings indicated that the technology acceptance model, social presence theory, and computers are social actors are the main dominant theories in explaining Chatbot adoption. Most studies focused on examining the usage intention of Chatbots, with limited investigations on actual use and continuous intention. Nearly 63% of the analyzed studies did not employ moderators, and those that did tend to do so most frequently focused on gender, Chatbot/technical experience, and age. This article presents a fresh viewpoint that deepens our understanding of Chatbot adoption and proposes several agendas for future research. The agenda incorporates research directions for Chatbots adoption in general and generative artificial intelligence in specific. It also offers several theoretical contributions and provides relevant information to Chatbot developers, decision-makers, practitioners, IT vendors, and policymakers.},
  keywords={Chatbots;Electronic commerce;Customer services;Productivity;Organizations;Market research;Databases;Adoption;Chatbot;factors;generative artificial intelligence (AI);systematic review;technology adoption theories},
  doi={10.1109/TEM.2023.3298360},
  ISSN={1558-0040},
  month={},}@INPROCEEDINGS{9599106,
  author={Day, Min-Yuh and Shaw, Sheng-Ru},
  booktitle={2021 IEEE 22nd International Conference on Information Reuse and Integration for Data Science (IRI)}, 
  title={AI Customer Service System with Pre-trained Language and Response Ranking Models for University Admissions}, 
  year={2021},
  volume={},
  number={},
  pages={395-401},
  abstract={The application of chatbots in the field of customer service systems is already an indispensable technology. In the admissions of colleges and universities, the customer service system is one of the most important models. The objective of this study is to evaluate the efficacy of an intelligent enrollment customer service robot system established using the Generative Pre-Training-2 (GPT-2) model. In this study, we combine the customer service field of chat robots with the enrollment field to construct a customer service system with enrollment as the field. This study uses the GPT-2 natural language processing model proposed by OpenAI to construct a customer service system in the university admissions field. BLEU is utilized to generate an evaluation model to evaluate the similarity between the text generated by the university admissions customer service system and the reference text to determine if the generated text by this model is good or bad. The research contributions of this paper are that we proposed an artificial intelligence (AI) customer service system with a pre-trained language model and a response-ranking model for university admissions and conducted a user evaluation of the proposed AI system.},
  keywords={Training;Analytical models;Matched filters;Customer services;Chatbots;User experience;Rough surfaces;Artificial Intelligence;Chatbot;Customer Service System;Natural Language Processing;Generative Pre-Training-2 (GPT-2)},
  doi={10.1109/IRI51335.2021.00062},
  ISSN={},
  month={Aug},}@INBOOK{11164797,
  author={Erik, Herman},
  booktitle={AI Revealed: Theory, Applications and Ethics}, 
  title={Preface}, 
  year={2024},
  volume={},
  number={},
  pages={xvii-xx},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9781501520631},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11164797},}@ARTICLE{8826712,
  author={},
  journal={Journal of Communications and Networks}, 
  title={Call for papers}, 
  year={2019},
  volume={21},
  number={4},
  pages={430-430},
  abstract={},
  keywords={Wireless networks;Big Data;Deep learning;Reinforcement learning},
  doi={10.1109/JCN.2019.100020},
  ISSN={1976-5541},
  month={Aug},}@INPROCEEDINGS{10536521,
  author={Teixeira, João Marcelo and Peres, Fabiana and Mauricio, Claudio},
  booktitle={2024 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, 
  title={AI-Powered 360 Panoramas: Unveiling Challenges for Realistic XR Prototyping}, 
  year={2024},
  volume={},
  number={},
  pages={410-414},
  abstract={This paper explores and evaluates the main limitations associated with AI-based 360 panorama generation. We make use of a free AI-based 360 panorama generator, Skybox AI, to highlight some of the current limitations present in automatic panorama generation from text input. By recognizing and addressing these constraints, researchers and practitioners can pave the way for enhanced al-gorithms and systems capable of delivering more immersive and realistic panoramic experiences.},
  keywords={Three-dimensional displays;Codes;Design methodology;Conferences;User interfaces;Generators;Internet;Human-centered computing—Human computer interaction (HCI)—Interaction paradigms—Virtual reality;Human-centered computing—Human computer interaction (HCI)—HCI design and evaluation methods—Heuristic evaluations},
  doi={10.1109/VRW62533.2024.00079},
  ISSN={},
  month={March},}@INPROCEEDINGS{10911168,
  author={Kumar, Atul and Guleria, Kalpna},
  booktitle={2024 4th International Conference on Advancement in Electronics & Communication Engineering (AECE)}, 
  title={Mitigating Adversarial Threats: Safeguarding AI-Driven Fraud Detection Systems Against Malicious Exploits}, 
  year={2024},
  volume={},
  number={},
  pages={736-740},
  abstract={The proliferation of AI-driven fraud detection systems increases the capability of organizations to a large extent in terms of fraud detection and prevention. These systems, however, are fast becoming the targets of adversarial threats that look to exploit their vulnerabilities. This paper focuses on the various machine learning algorithms such as Logistic Regression, Random Forest, and Decision Tree, that are deployed to mitigate such adversarial threats. Comparative analysis may show that, among the various algorithms considered, decision trees are most robust against malicious exploits. Particularly, the hierarchical structure of a decision tree and its split criteria provide resistance through the effective segregation of anomalous patterns of data and treating them differently. Our results indicate that, compared with others, the Decision Tree algorithm does a better job in fraudulent activity detection, performing well in stability and reliability under attacks. These findings suggest the importance of choosing appropriate machine learning models to strengthen AI-driven fraud detection systems against new types of cyber threats so they are both potent and trustworthy in real-world applications.},
  keywords={Resistance;Machine learning algorithms;Prevention and mitigation;Stability criteria;Organizations;Fraud;Decision trees;Security;Reliability;Random forests;Adversarial Threats;fraud detection;Machine learning;vulnerabilities;Security;Decision tree;Financial Inclusion},
  doi={10.1109/AECE62803.2024.10911168},
  ISSN={},
  month={Nov},}@ARTICLE{10323083,
  author={Pu, Jiyao and Duan, Haoran and Zhao, Junzhe and Long, Yang},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Rules for Expectation: Learning to Generate Rules via Social Environment Modeling}, 
  year={2024},
  volume={34},
  number={8},
  pages={6874-6887},
  abstract={The evolution of natural life is guided by a perpetually adaptive set of rules, encompassing natural laws, human policies, and game mechanics. Automated game design, through the creation of simulated environments populated by AI agents, embodies these rules, aligning with the objectives of artificial life research that seeks to replicate the dynamics of biological life through computational models. This paper presents a comprehensive framework, the Rule Generation Networks (RGN), devised for automated rule design, evaluation, and evolution in line with controllable expectations. We refine and formalize three cardinal elements - rules, strategies, and evaluation - to elucidate the intricate relationships inherent in rule generation tasks. The RGN integrates generative neural networks for rule design and a suite of reinforcement learning models for rule evaluation. To exemplify rule evolution and adaptation across varying environments, we introduce a controllability metric to gauge game dynamics and evolve the rule designer accordingly. Furthermore, we develop two game environments, Maze Run and Trust Evolution, modelling human exploration and societal trade dynamics, to gamify and evaluate the generated rules.},
  keywords={Games;Task analysis;Metaverse;Computational modeling;Biological system modeling;Reinforcement learning;Artificial intelligence;Rule generation;procedural content generation;artificial life;generative networks;reinforcement learning;automated game design},
  doi={10.1109/TCSVT.2023.3334526},
  ISSN={1558-2205},
  month={Aug},}@ARTICLE{11112664,
  author={Yin, Hang and Qiao, Li and Ma, Yu and Sun, Shuo and Li, Kan and Gao, Zhen and Niyato, Dusit},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={Generative Video Semantic Communication Via Multimodal Semantic Fusion With Large Model}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Despite significant advancements in traditional syntactic communications based on Shannon's theory, these methods struggle to meet the requirements of 6 G immersive communications, especially under challenging transmission conditions. With the development of generative artificial intelligence (GenAI), progress has been made in reconstructing videos using high-level semantic information. In this paper, we propose a scalable generative video semantic communication framework that extracts and transmits semantic information to achieve high-quality video reconstruction. Specifically, at the transmitter, description and other condition signals (e.g., first frame, sketches, etc.) are extracted from the source video, functioning as text and structural semantics, respectively. At the receiver, the diffusion-based GenAI large models are utilized to fuse the semantics of the multiple modalities for reconstructing the video. Simulation results demonstrate that, at an ultra-low channel bandwidth ratio (CBR), our scheme effectively captures semantic information to reconstruct videos aligned with human perception under different signal-to-noise ratios. Notably, the proposed First Frame+Desc. scheme consistently achieves CLIP score exceeding 0.92 at CBR = 0.0031 for SNR $>$ 0 dB. This demonstrates its robust performance even under low SNR conditions.},
  keywords={Videos;Semantics;Visualization;Receivers;Image reconstruction;Signal to noise ratio;Semantic communication;Diffusion models;Propagation losses;Video description;video semantic communication;visual compression;generative artificial intelligence (GenAI);large model;diffusion model},
  doi={10.1109/TVT.2025.3595688},
  ISSN={1939-9359},
  month={},}@INPROCEEDINGS{10475302,
  author={Saffarzadeh, Sina and Haghighi, Mehdi Salkhordeh},
  booktitle={2024 20th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP)}, 
  title={Identifying Spam Tweets in Social Networks with Combined Approaches of Feature Selection and Deep Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Spam detection in social media is troublesome because of language features. Spammers can bypass filtering methods by changing their behavior and following legitimate accounts. The practical method for detecting spam is to classify posts based on their content using a text classification method based on deep learning. This manuscript aims to identify spam in social networks based on content. This paper presents a three-step method for detecting spam in social networks. The convolutional neural network (CNN) is used for feature extraction in the first step. Several feature selection methods are used in the second stage, with the majority voting for feature selection. In the third stage, the combined learning and classification methods are used. In the proposed method, the combined feature selection is made using the chi-square method, random trees, and recursive elimination method. Examinations on the Twitter dataset show that the proposed method in spam detection has accuracy, sensitivity, and precision of 99.46%, 99.36%, and 99.32%, The proposed method is more accurate in CNN+SVM, and CNN+SVM+LSTM.},
  keywords={Support vector machines;Radio frequency;Deep learning;Training;Logistic regression;Sensitivity;Social networking (online);Spam;Social networks;Deep learning;Convolutional neural network (CNN)},
  doi={10.1109/AISP61396.2024.10475302},
  ISSN={2640-5768},
  month={Feb},}@ARTICLE{9027849,
  author={Cai, Weiwei and Wei, Zhanguo},
  journal={IEEE Access}, 
  title={PiiGAN: Generative Adversarial Networks for Pluralistic Image Inpainting}, 
  year={2020},
  volume={8},
  number={},
  pages={48451-48463},
  abstract={The latest methods based on deep learning have achieved amazing results regarding the complex work of inpainting large missing areas in an image. But this type of method generally attempts to generate one single “optimal” result, ignoring many other plausible results. Considering the uncertainty of the inpainting task, one sole result can hardly be regarded as a desired regeneration of the missing area. In view of this weakness, which is related to the design of the previous algorithms, we propose a novel deep generative model equipped with a brand new style extractor which can extract the style feature (latent vector) from the ground truth. Once obtained, the extracted style feature and the ground truth are both input into the generator. We also craft a consistency loss that guides the generated image to approximate the ground truth. After iterations, our generator is able to learn the mapping of styles corresponding to multiple sets of vectors. The proposed model can generate a large number of results consistent with the context semantics of the image. Moreover, we evaluated the effectiveness of our model on three datasets, i.e., CelebA, PlantVillage, and MauFlex. Compared to state-of-the-art inpainting methods, this model is able to offer desirable inpainting results with both better quality and higher diversity. The code and model will be made available on https://github.com/vivitsai/PiiGAN.},
  keywords={Feature extraction;Generative adversarial networks;Generators;Semantics;Training;Gallium nitride;Face;Deep learning;generative adversarial networks;image inpainting;diversity inpainting},
  doi={10.1109/ACCESS.2020.2979348},
  ISSN={2169-3536},
  month={},}@ARTICLE{9632806,
  author={Ullah, Imtiaz and Mahmoud, Qusay H.},
  journal={IEEE Access}, 
  title={A Framework for Anomaly Detection in IoT Networks Using Conditional Generative Adversarial Networks}, 
  year={2021},
  volume={9},
  number={},
  pages={165907-165931},
  abstract={While anomaly detection and the related concept of intrusion detection are widely studied, detecting anomalies in new operating behavior in environments such as the Internet of Things (IoT) is an active field of research. Anomaly detection models trained on datasets that are likely imbalanced have poor results, but the ability of Generative Adversarial Networks (GANs) to emulate complex high-dimensional distributions seen in real-world data suggests that they can be effective for anomaly detection. This paper proposes a novel framework for detecting anomalies in IoT networks utilizing conditional GANs (cGANs) to build realistic distributions for a given feature set to overcome the issue of data imbalance. To this end, a one class cGAN (ocGAN) model was utilized to learn the minority data class to balance the dataset. Then, the binary class cGAN (bcGAN) model generates augmented data for the binary balance dataset. The performance of the ocGAN and bcGAN models in binary and multiclass classification environments were evaluated using a Feed Forward Neural Network (FFN) and tested on two network-based anomaly detection datasets and five IoT network-based anomaly detection datasets. The proposed models outperformed other anomaly detection models in the standard metrics of accuracy, precision, recall, and F1 score.},
  keywords={Measurement;Neural networks;Intrusion detection;Generative adversarial networks;Data models;Internet of Things;Security;Anomaly detection;Feature extraction;Internet of Things;generative adversarial networks (GANs);conditional GANs;feed-forward neural network;anomaly detection;deep learning;network security},
  doi={10.1109/ACCESS.2021.3132127},
  ISSN={2169-3536},
  month={},}@ARTICLE{9042283,
  author={Huang, Jun and Le, Zhuliang and Ma, Yong and Fan, Fan and Zhang, Hao and Yang, Lei},
  journal={IEEE Access}, 
  title={MGMDcGAN: Medical Image Fusion Using Multi-Generator Multi-Discriminator Conditional Generative Adversarial Network}, 
  year={2020},
  volume={8},
  number={},
  pages={55145-55157},
  abstract={In this paper, we propose a novel end-to-end model for fusing medical images characterizing structural information, i.e., IS, and images characterizing functional information, i.e., IF, of different resolutions, by using a multi-generator multi-discriminator conditional generative adversarial network (MGMDcGAN). In the first cGAN, the generator aims to generate a real-like fused image based on a specifically designed content loss to fool two discriminators, while the discriminators aim to distinguish the structure differences between the fused image and source images. On this basis, we employ the second cGAN with a mask to enhance the information of dense structure in the final fused image, while preventing the functional information from being weakened. Consequently, the final fused image is forced to concurrently keep the structural information in IS and the functional information in IF. In addition, as a unified method, MGMDcGAN can be applied to different kinds of medical image fusion, i.e., MRI-PET, MRI-SPECT, and CT-SPECT, where MRI and CT are two kinds of IS of high resolution, PET and SPECT are typical kinds of IF of low resolution. Qualitative and quantitative experiments on publicly available datasets demonstrate the superiority of our MGMDcGAN over the state-of-the-art.},
  keywords={Image fusion;Image resolution;Medical diagnostic imaging;Deep learning;Generative adversarial networks;Magnetic resonance imaging;Medical image fusion;generative adversarial network;different resolutions;end-to-end;unified method},
  doi={10.1109/ACCESS.2020.2982016},
  ISSN={2169-3536},
  month={},}@ARTICLE{9171249,
  author={Munawar, Faizan and Azmat, Shoaib and Iqbal, Talha and Grönlund, Christer and Ali, Hazrat},
  journal={IEEE Access}, 
  title={Segmentation of Lungs in Chest X-Ray Image Using Generative Adversarial Networks}, 
  year={2020},
  volume={8},
  number={},
  pages={153535-153545},
  abstract={Chest X-ray (CXR) is a low-cost medical imaging technique. It is a common procedure for the identification of many respiratory diseases compared to MRI, CT, and PET scans. This paper presents the use of generative adversarial networks (GAN) to perform the task of lung segmentation on a given CXR. GANs are popular to generate realistic data by learning the mapping from one domain to another. In our work, the generator of the GAN is trained to generate a segmented mask of a given input CXR. The discriminator distinguishes between a ground truth and the generated mask, and updates the generator through the adversarial loss measure. The objective is to generate masks for the input CXR, which are as realistic as possible compared to the ground truth masks. The model is trained and evaluated using four different discriminators referred to as D1, D2, D3, and D4, respectively. Experimental results on three different CXR datasets reveal that the proposed model is able to achieve a dice-score of 0.9740, and IOU score of 0.943, which are better than other reported state-of-the art results.},
  keywords={Lung;Image segmentation;Generative adversarial networks;X-ray imaging;Computed tomography;Generators;Diseases;Deep learning;generative adversarial networks;lung segmentation;medical imaging},
  doi={10.1109/ACCESS.2020.3017915},
  ISSN={2169-3536},
  month={},}@ARTICLE{9448108,
  author={Gajera, Binit and Kapil, Siddhant Raj and Ziaei, Dorsa and Mangalagiri, Jayalakshmi and Siegel, Eliot and Chapman, David},
  journal={IEEE Access}, 
  title={CT-Scan Denoising Using a Charbonnier Loss Generative Adversarial Network}, 
  year={2021},
  volume={9},
  number={},
  pages={84093-84109},
  abstract={We propose a Generative Adversarial Network (GAN) optimized for noise reduction in CT-scans. The objective of CT scan denoising is to obtain higher quality imagery using a lower radiation exposure to the patient. Recent work in computer vision has shown that the use of Charbonnier distance as a term in the perceptual loss of a GAN can improve the performance of image reconstruction and video super-resolution. However, the use of a Charbonnier structural loss term has not yet been applied or evaluated for the purpose of CT scan denoising. Our proposed GAN makes use of a Wasserstein adversarial loss, a pretrained VGG19 perceptual loss, as well as a Charbonnier distance structural loss. We evaluate our approach using both applied Poisson noise distribution in order to simulate low-dose CT imagery, as well as using an anthropomorphic thoracic phantom at different exposure levels. Our evaluation criteria are Peek Signal to Noise (PSNR) as well as Structured Similarity (SSIM) of the denoised images, and we compare the results of our method versus recent state of the art deep denoising GANs. In addition, we report global noise through uniform soft tissue mediums. Our findings show that the incorporation of the Charbonnier Loss with the VGG-19 network improves the performance of the denoising as measured with the PSNR and SSIM, and that the method greatly reduces soft tissue noise to levels comparable to the NDCT scan.},
  keywords={Noise reduction;Computed tomography;Image reconstruction;Indexes;Generative adversarial networks;X-ray imaging;PSNR;CT-scan denoising;machine learning;computed tomography;medical diagnostic imaging;generative adversarial network},
  doi={10.1109/ACCESS.2021.3087424},
  ISSN={2169-3536},
  month={},}@ARTICLE{9006873,
  author={Wu, Bin and Liu, Le and Yang, Yanqing and Zheng, Kangfeng and Wang, Xiujuan},
  journal={IEEE Access}, 
  title={Using Improved Conditional Generative Adversarial Networks to Detect Social Bots on Twitter}, 
  year={2020},
  volume={8},
  number={},
  pages={36664-36680},
  abstract={The detection and removal of malicious social bots in social networks has become an area of interest in industry and academia. The widely used bot detection method based on machine learning leads to an imbalance in the number of samples in different categories. Classifier bias leads to a low detection rate of minority samples. Therefore, we propose an improved conditional generative adversarial network (improved CGAN) to extend imbalanced data sets before applying training classifiers to improve the detection accuracy of social bots. To generate an auxiliary condition, we propose a modified clustering algorithm, namely, the Gaussian kernel density peak clustering algorithm (GKDPCA), which avoids the generation of data-augmentation noise and eliminates imbalances between and within social bot class distributions. Furthermore, we improve the CGAN convergence judgment condition by introducing the Wasserstein distance with a gradient penalty, which addresses the model collapse and gradient disappearance in the traditional CGAN. Three common oversampling algorithms are compared in experiments. The effects of the imbalance degree and the expansion ratio of the original data on oversampling are studied, and the improved CGAN performs better than the others. Experimental results comparing with three common oversampling algorithms show that the improved CGAN achieves the higher evaluation scores in terms of F1-score, G-mean and AUC.},
  keywords={Feature extraction;Machine learning;Twitter;Classification algorithms;Generative adversarial networks;Clustering algorithms;Social bot detection;conditional generative adversarial networks;data augmentation;supervised classification;imbalanced data},
  doi={10.1109/ACCESS.2020.2975630},
  ISSN={2169-3536},
  month={},}@ARTICLE{10058512,
  author={Branikas, Efstathios and Murray, Paul and West, Graeme},
  journal={IEEE Access}, 
  title={A Novel Data Augmentation Method for Improved Visual Crack Detection Using Generative Adversarial Networks}, 
  year={2023},
  volume={11},
  number={},
  pages={22051-22059},
  abstract={Condition monitoring and inspection are core activities for assessing and evaluating the health of critical infrastructure spanning from road networks to nuclear power stations. Defect detection on visual inspections of such assets is a field that enjoys increasing attention. However, data-based models are prone to a lack of available data depicting cracks of various modalities and present a great data imbalance. This paper introduces a novel data augmentation technique by deploying the CycleGan Generative Adversarial Network (GAN). The proposed model is deployed between different image datasets depicting cracks, with a nuclear application as the main industrial example. The aim of this network is to improve the segmentation accuracy on these datasets using deep convolutional neural networks. The proposed GAN generates realistic images that are challenging to segment and under-represented in the original datasets. Different deep networks are trained with the augmented datasets while introducing no labelling overhead. A comparison is drawn between the performance of the different neural networks on the original data and their augmented counterparts. Extensive experiments suggest that the proposed augmentation method results in superior crack detection in challenging cases across all datasets. This is reflected by the respective increase in the quantitative evaluation metrics.},
  keywords={Generative adversarial networks;Inspection;Image segmentation;Visualization;Task analysis;Data models;Data augmentation;Crack segmentation;generative adversarial networks (GANs);nuclear inspections;data augmentation;image-to-image translation},
  doi={10.1109/ACCESS.2023.3251988},
  ISSN={2169-3536},
  month={},}@ARTICLE{9387292,
  author={Huang, Lei and Zhuang, Jihui and Cheng, Xiaoming and Xu, Riming and Ma, Hongjie},
  journal={IEEE Access}, 
  title={STI-GAN: Multimodal Pedestrian Trajectory Prediction Using Spatiotemporal Interactions and a Generative Adversarial Network}, 
  year={2021},
  volume={9},
  number={},
  pages={50846-50856},
  abstract={Predicting the future trajectories of multiple pedestrians in certain scenes has become a key task for ensuring that autonomous vehicles, socially interactive robots and other autonomous mobile platforms can navigate safely. The social interactions between people and the multimodal nature of pedestrian movement make pedestrian trajectory prediction a challenging task. In this paper, the problem is solved using a generative adversarial network (GAN) and a graph attention network (GAT) based on the spatiotemporal interaction information about pedestrians. Our method, STI-GAN, is based on an end-to-end GAN model that simulates the pedestrian distribution to capture the uncertainty of the predicted paths and generate more reasonable future trajectories. The complex interactions between people are modeled by a GAT, and spatiotemporal interaction information is used to improve the performance of trajectory prediction. We verify the robustness and improvement of our framework by evaluating its results on various datasets and comparing them with the results of several existing baselines. Compared with the existing pedestrian trajectory prediction methods, our method reduces the average displacement error (ADE) and final displacement error (FDE) by 21.9% and 23.8% respectively.},
  keywords={Trajectory;Predictive models;Generative adversarial networks;Spatiotemporal phenomena;Gallium nitride;Generators;Feature extraction;Pedestrian trajectory prediction;graph attention mechanism;generative adversarial networks;spatiotemporal},
  doi={10.1109/ACCESS.2021.3069134},
  ISSN={2169-3536},
  month={},}@ARTICLE{9406803,
  author={Tian, Miao and Song, Kaikai},
  journal={IEEE Access}, 
  title={Boosting Magnetic Resonance Image Denoising With Generative Adversarial Networks}, 
  year={2021},
  volume={9},
  number={},
  pages={62266-62275},
  abstract={Denoising plays an important role in the Magnetic Resonance Imaging (MRI) applications for medical diagnosis. MRI images usually contain undesired noises which would negatively affect the exactitude of pathological diagnosis. Recently, many models for MRI denoising have been developed from deep learning networks. In this paper, we propose a novel MRI image denoising method using the conditional Generative Adversarial Networks (GANs). Specifically, a Convolutional Neural Network (CNN) is utilized as the discriminator in the process to distinguish whether the image pair obtained from the conditional GAN is a real pair which consists of a noisy image and a noise-free image or a fake pair which, on the other hand, contains a noisy image and a denoised image. In our design, the convolutional encoder-decoder networks-based generator is used to remove the noise in the noisy MRI images as much as possible. The whole architecture is trained by adversarial learning. Experiments using both synthetic and real clinical MRI datasets are conducted. When tested on the synthetic T1w images with 10% noise level, our method performed better in terms of reaching a high structural similarity index (SSIM) at 0.9489 while that of the next best method was only 0.7485. Moreover, when the image noise level was increased from 1% to 10%, our method was more stable that the SSIM only dropped about 3.2% while that of the next best method dropped about 23.7%. Simulation results demonstrate that the proposed method is more robust and outperforms the conventional methods in both the denoising level and preservation of the anatomical structures and defined contrast.},
  keywords={Magnetic resonance imaging;Noise reduction;Noise measurement;Generators;Image denoising;Generative adversarial networks;Convolution;Magnetic resonance imaging;image denoising;deep learning;generative adversarial networks;convolutional neural networks},
  doi={10.1109/ACCESS.2021.3073944},
  ISSN={2169-3536},
  month={},}@ARTICLE{8949485,
  author={Kang, Jiayin and Lu, Wu and Zhang, Wenjuan},
  journal={IEEE Access}, 
  title={Fusion of Brain PET and MRI Images Using Tissue-Aware Conditional Generative Adversarial Network With Joint Loss}, 
  year={2020},
  volume={8},
  number={},
  pages={6368-6378},
  abstract={Positron emission tomography (PET) has rich pseudo color information that reflects the functional characteristics of tissue, but lacks structural information and its spatial resolution is low. Magnetic resonance imaging (MRI) has high spatial resolution as well as strong structural information of soft tissue, but lacks color information that shows the functional characteristics of tissue. For the purpose of integrating the color information of PET with the anatomical structures of MRI to help doctors diagnose diseases better, a method for fusing brain PET and MRI images using tissue-aware conditional generative adversarial network (TA-cGAN) is proposed. Specifically, the process of fusing brain PET and MRI images is treated as an adversarial machine between retaining the color information of PET and preserving the anatomical information of MRI. More specifically, the fusion of PET and MRI images can be regarded as a min-max optimization problem with respect to the generator and the discriminator, where the generator attempts to minimize the objective function via generating a fused image mainly contains the color information of PET, whereas the discriminator tries to maximize the objective function through urging the fused image to include more structural information of MRI. Both the generator and the discriminator in TA-cGAN are conditioned on the tissue label map generated from MRI image, and are trained alternatively with joint loss. Extensive experiments demonstrate that the proposed method enhances the anatomical details of the fused image while effectively preserving the color information from the PET. In addition, compared with other state-of-the-art methods, the proposed method achieves better fusion effects both in subjectively visual perception and in objectively quantitative assessment.},
  keywords={Magnetic resonance imaging;Generative adversarial networks;Positron emission tomography;Image color analysis;Generators;Image fusion;Gallium nitride;Positron emission tomography;magnetic resonance imaging;image fusion;generative adversarial network;loss function},
  doi={10.1109/ACCESS.2019.2963741},
  ISSN={2169-3536},
  month={},}@ARTICLE{8673546,
  author={Yang, Yang and Hou, Chunping and Lang, Yue and Yue, Guanghui and He, Yuan},
  journal={IEEE Access}, 
  title={One-Class Classification Using Generative Adversarial Networks}, 
  year={2019},
  volume={7},
  number={},
  pages={37970-37979},
  abstract={One-class classification (OCC) problem has drawn increasing attention in recent years. It expands the range of classification from pre-defined categories to undefined categories. Since the vast diversity of negative samples, it is hard to acquire complete knowledge of unknown classes and construct a negative set for training a one-class classifier, which remains a difficult problem. In this paper, we propose a new OCC model by modifying the generative adversarial network model to address the OCC problem. Taking the generator's outputs as outliers, the discriminator in our model is trained with these synthetic data and target training data, and it manages to distinguish them from each other. Moreover, a new evaluation protocol named classification recall index is put forward to indicate the classifier's performances on both positive and negative sets. The extensive experiments on the MNIST dataset and the Street View House Numbers (SVHN) dataset demonstrate that the proposed model is competitive over a variety of OCC methods.},
  keywords={Generative adversarial networks;Training;Indexes;Training data;Task analysis;Generators;Gallium nitride;Generative adversarial networks;one-class;image classification},
  doi={10.1109/ACCESS.2019.2905933},
  ISSN={2169-3536},
  month={},}@ARTICLE{9306822,
  author={Liu, Xu and Gherbi, Abdelouahed and Wei, Zhenzhou and Li, Wubin and Cheriet, Mohamed},
  journal={IEEE Access}, 
  title={Multispectral Image Reconstruction From Color Images Using Enhanced Variational Autoencoder and Generative Adversarial Network}, 
  year={2021},
  volume={9},
  number={},
  pages={1666-1679},
  abstract={Since multispectral images (MSIs) have much more sufficient spectral information than RGB images (RGBs), reconstructing MS images from RGB images is a severely underconstrained problem. We have to generate colossally different information between the two scopes. Almost all previous approaches are based on static and dependent neural networks, which fail to explain how to supplement the massive lost information. This paper presents a low-cost and high-efficiency approach, “VAE-GAN”, based on stochastic neural networks to directly reconstruct high-quality MSIs from RGBs. Our approach combines the advantages of the Generative Adversarial Network (GAN) and the Variational Autoencoder (VAE). The VAE undertakes the generation of the lost variational MS distributions by reparameterizing the latent space vector with sampling from Gaussian distribution. The GAN is responsible for regulating the generator to produce MSI-like images. In this way, our approach can create huge missed information and make the outputs look real, which also solves the previous problem. Moreover, we use several qualitative and quantitative methods to evaluate our approach and obtain excellent results. In particular, with much less training data than the previous approaches, we obtained comparable results on the CAVE dataset and surpassed state-of-the-art results on the ICVL dataset.},
  keywords={Image reconstruction;Neural networks;Gallium nitride;Hyperspectral imaging;Image color analysis;Generators;Generative adversarial networks;Generative adversarial network (GAN);variational autoencoder (VAE);VAE-GAN;normal distribution;stochastic neural network;multispectral image;RGB image;image processing;color vision;spectral reconstruction},
  doi={10.1109/ACCESS.2020.3047074},
  ISSN={2169-3536},
  month={},}@ARTICLE{10522999,
  author={Rahman, Wahidur and Hossain, Muhammad Minoar and Hasan, Md. Mahedi and Iqbal, Md. Sadiq and Rahman, Mohammad Motiur and Fida Hasan, Khondokar and Moni, Mohammad Ali},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Automated Detection of Harmful Insects in Agriculture: A Smart Framework Leveraging IoT, Machine Learning, and Blockchain}, 
  year={2024},
  volume={5},
  number={9},
  pages={4787-4798},
  abstract={Paddy cultivation is a significant global economic sector, with rice production playing a crucial role in influencing worldwide economies. However, insects in paddy farms predominantly impact the growth rate and ecological equilibrium of the agricultural field. Hence, the precise and timely identification of insects in agricultural settings presents a potential strategy for addressing this issue. This study aims to implement an automated system for paddy farming by employing a real-time framework that incorporates the Internet of Things (IoT), blockchain technology, and Deep Learning (DL) algorithms. The primary emphasis of the DL-based system is on the timely identification of pests. In contrast, integrating the IoT and blockchain technologies facilitates stablishing a fully automated system with security within the agricultural domain. The DL-based system includes a secondary dataset of paddy insects, and then preprocessing, feature extraction, and identification have been performed. Besides, an IoT-based system is embodied with a camera module and microprocessor, accompanied by some apparatus required to automate the whole system. In addition, the research also includes the blockchain to secure each individual data transmission among the several IoT components and the cloud server. While examining the proposed solution, various experimental data have been systematically documented and analyzed. The proposed framework attained a peak accuracy of 98.91% using the VGG19 model and ensemble classifiers to detect the pest with a specificity of 99.14% and a precision of 98.21%. The study additionally quantifies the mean duration of the cloud response when integrated with IoT, yielding an average time of 1.71 s after pest identification. Nevertheless, the system has exhibited a high level of efficacy in the context of real-time monitoring and automation of paddy farms.},
  keywords={Internet of Things;Crops;Blockchains;Insects;Artificial intelligence;Real-time systems;Cloud computing;Blockchain;deep learning (DL);farm monitoring;insect prevention;Internet of Things (IoT)},
  doi={10.1109/TAI.2024.3394799},
  ISSN={2691-4581},
  month={Sep.},}@ARTICLE{9201442,
  author={Ezeme, Okwudili M and Mahmoud, Qusay H. and Azim, Akramul},
  journal={IEEE Access}, 
  title={Design and Development of AD-CGAN: Conditional Generative Adversarial Networks for Anomaly Detection}, 
  year={2020},
  volume={8},
  number={},
  pages={177667-177681},
  abstract={Whether in the realm of software or hardware, datasets representing the state of systems are mostly imbalanced. This imbalance is because these systems' reliability requirements make the occurrence of an anomaly a rare phenomenon. Hence, most datasets on anomaly detection have a relatively small percentage that captures the anomaly. Recently, generative adversarial networks (GAN) have shown promising results in image generation tasks. Therefore, in this research work, we build on conditional GANs (CGAN) to generate plausible distributions of a given profile to solve the challenge of data imbalance in anomaly detection tasks and present a novel framework for anomaly detection. Firstly, we learn the pattern of the minority class data samples using a single class CGAN. Secondly, we use the knowledge base of the single class CGAN to generate samples that augment the minority class samples so that a binary class CGAN can train on the typical and malicious profiles with a balanced dataset. This approach inherently eliminates the bias imposed on algorithms from the dataset and results in a robust framework with improved generalization. Thirdly, the binary class CGAN generates a knowledge base that we use to construct the cluster-based anomaly detector. During testing, we do not use the single class CGAN, thereby providing us with a lean and efficient algorithm for anomaly detection that can do anomaly detection on semi-supervised and non-parametric multivariate data. We test the framework on logs and image-based anomaly detection datasets with class imbalance. We compare the performance of AD-CGAN with GAN-derived and non-GAN-derived state of the art algorithms on benchmark datasets. AD-CGAN outperforms most of the algorithms in the standard metrics of Precision, Recall, and F-1 Score. Where AD-CGAN does not perform better in the parameters used, it has the advantage of being lightweight. Therefore, it can be deployed for both online and offline anomaly detection tasks since it does not use an input sample inversion strategy.},
  keywords={Anomaly detection;Machine learning;Hidden Markov models;Generative adversarial networks;Gallium nitride;Data models;Context modeling;Anomaly detection;transfer learning;deep learning;generative adversarial networks},
  doi={10.1109/ACCESS.2020.3025530},
  ISSN={2169-3536},
  month={},}@ARTICLE{10531741,
  author={Brandão Lent, Daniel M. and da Silva Ruffo, Vitor G. and Carvalho, Luiz F. and Lloret, Jaime and Rodrigues, Joel J. P. C. and Lemes Proença, Mario},
  journal={IEEE Access}, 
  title={An Unsupervised Generative Adversarial Network System to Detect DDoS Attacks in SDN}, 
  year={2024},
  volume={12},
  number={},
  pages={70690-70706},
  abstract={Network management is a crucial task to maintain modern systems and applications running. Some applications have become vital for society and are expected to have zero downtime. Software-defined networks is a paradigm that collaborates with the scalability, modularity and manageability of systems by centralizing the network’s controller. However, this creates a weak point for distributed denial of service attacks if unprepared. This study proposes an anomaly detection system to detect distributed denial of service attacks in software-defined networks using generative adversarial neural networks with gated recurrent units. The proposed system uses unsupervised learning to detect unknown attacks in an interval of 1 second. A mitigation algorithm is also proposed to stop distributed denial-of-service attacks from harming the network’s operation. Two datasets were used to validate this model: the first developed by the computer networks study group Orion from the State University of Londrina. The second is a well-known dataset: CIC-DDoS2019, widely used by the anomaly detection community. Besides the gated recurrent units, other types of neurons are also tested in this work, they are: long short-term memory, convolutional and temporal convolutional. The detection module reached an F1-score of 99@ in the first dataset and 98@ in the second, while the mitigation module could drop 99@ of malicious flows in both datasets.},
  keywords={Logic gates;Generators;Generative adversarial networks;Control systems;Neurons;Training;Biological neural networks;Anomaly detection;Deep learning;Software defined networking;Anomaly detection;deep learning;generative adversarial networks;software-defined networks},
  doi={10.1109/ACCESS.2024.3402069},
  ISSN={2169-3536},
  month={},}@ARTICLE{9606736,
  author={Saypadith, Savath and Onoye, Takao},
  journal={IEEE Access}, 
  title={An Approach to Detect Anomaly in Video Using Deep Generative Network}, 
  year={2021},
  volume={9},
  number={},
  pages={150903-150910},
  abstract={Anomaly detection in the video has recently gained attention due to its importance in the intelligent surveillance system. Even though the performance of the state-of-art methods has been competitive in the benchmark dataset, the trade-off between the computational resource and the accuracy of the anomaly detection should be considered. In this paper, we present a framework to detect anomalies in video. We proposed a “multi-scale U-Net” network architecture, the unsupervised learning for anomaly detection in video based on generative adversarial network (GAN) structure. Shortcut Inception Modules (SIMs) and residual skip connection are employed to the generator network to increase the ability of the training and testing of the neural network. An asymmetric convolution has been applied instead of traditional convolution layers to decrease the number of training parameters without performance penalty in terms of detection accuracy. In the training phase, the generator network was trained to generate the normal events and attempt to make the generated image and the ground truth to be similar. A multi-scale U-Net kept useful features of an image that were lost during training caused by the convolution operator. The generator network is trained by minimizing the reconstruction error on the normal data and then using the reconstruction error as an indicator of anomalies in the testing phase. Our proposed framework has been evaluated on three benchmark datasets, including UCSD pedestrian, CHUK Avenue, and ShanghaiTech. As a result, the proposed framework surpasses the state-of-the-art learning-based methods on all these datasets, which achieved 95.7%, 86.9%, and 73.0% in terms of AUC. Moreover, the numbers of training and testing parameters in our framework are reduced compared to the baseline network architecture, while the detection accuracy is still improved.},
  keywords={Training;Convolution;Feature extraction;Anomaly detection;Generators;Generative adversarial networks;Network architecture;Inception module;video anomaly detection;generative network},
  doi={10.1109/ACCESS.2021.3126335},
  ISSN={2169-3536},
  month={},}@ARTICLE{8915846,
  author={Qi, Lin and Zhang, Haoran and Tan, Wenjun and Qi, Shouliang and Xu, Lisheng and Yao, Yudong and Qian, Wei},
  journal={IEEE Access}, 
  title={Cascaded Conditional Generative Adversarial Networks With Multi-Scale Attention Fusion for Automated Bi-Ventricle Segmentation in Cardiac MRI}, 
  year={2019},
  volume={7},
  number={},
  pages={172305-172320},
  abstract={Accurate segmentation of bi-ventricle from cardiac magnetic resonance images (MRI) is a critical step in cardiac function analysis and disease diagnosis. Due to the morphological diversification of the heart and the factors of MRI itself, fully automated and concurrent bi-ventricle segmentation is a well-known challenge. In this paper, we propose cascaded conditional generative adversarial networks (C-cGANs) to divide the problem into two segmentation subtasks: binary segmentation for region of interest (ROI) extraction and bi-ventricle segmentation. In both subtasks, we adopt adversarial training that makes discriminator network to discriminate segmentation maps either from generator network or ground-truth which aims to detect and correct pixel-wise inconsistency between the sources of segmentation maps. For capturing more spatial information with multi-scale semantic features, in the generator network, we insert a multi-scale attention fusion (MSAF) module between the encoder and decoder paths. The experiment on ACDC 2017 dataset shows that the proposed model outperforms other state-of-the-art methods in most metrics. Moreover, we validate the generalization capability of this model on MS-CMRSeg 2019 and RVSC 2012 datasets without fine-tuning, and the results demonstrate the effectiveness and robustness of the proposed method for bi-ventricle segmentation.},
  keywords={Image segmentation;Generative adversarial networks;Two dimensional displays;Three-dimensional displays;Magnetic resonance imaging;Training;Biomedical imaging;Bi-ventricle segmentation;ROI extraction;cascaded conditional generative adversarial networks (C-cGANs);MSAF module},
  doi={10.1109/ACCESS.2019.2956210},
  ISSN={2169-3536},
  month={},}@ARTICLE{9336620,
  author={Park, Chihyun and Oh, Ilhwan and Choi, Jonghwan and Ko, Soohyun and Ahn, Jaegyoon},
  journal={IEEE Access}, 
  title={Improved Prediction of Cancer Outcome Using Graph-Embedded Generative Adversarial Networks}, 
  year={2021},
  volume={9},
  number={},
  pages={20076-20088},
  abstract={Precise prognosis of cancer patients is important because it is associated with suggesting appropriate therapeutic strategies. Several computational and statistical methods have been proposed, but further improvement of these methods in terms of prediction accuracy is required. This paper presents a deep learning-based method for learning networks of prognostic genes, instead of only individual biomarker genes, for more accurate cancer prognosis prediction. This method utilizes generative adversarial networks, where the generator uses a biological network instead of a traditional fully connected network to learn the distributions of gene expression (mRNA), copy number variation, single nucleotide polymorphism, and DNA methylation data from cancer patients. The proposed model was applied to seven cancer types and exhibited higher prediction accuracy as compared to the existing state-of-the-art methods. On average, the area under the curve (AUC) was improved by 4% compared to the best performing existing methods for seven cancer types. In particular, for pancreatic adenocarcinoma, AUC was improved by 27.9%. The identified prognostic genes were reproducible and functionally meaningful. To the best of our knowledge, the proposed method represents the first attempt to learn genetic networks from multi-omics data.},
  keywords={Cancer;Prognostics and health management;Biological system modeling;Predictive models;Gene expression;Data models;Generative adversarial networks;Graph-embedded generative adversarial networks;prediction of cancer prognosis;multi-omics integrated prediction model;discovery of prognostic genes},
  doi={10.1109/ACCESS.2021.3054894},
  ISSN={2169-3536},
  month={},}@ARTICLE{9007390,
  author={Ni, Jiancheng and Zhang, Susu and Zhou, Zili and Hou, Jie and Gao, Feng},
  journal={IEEE Access}, 
  title={Instance Mask Embedding and Attribute-Adaptive Generative Adversarial Network for Text-to-Image Synthesis}, 
  year={2020},
  volume={8},
  number={},
  pages={37697-37711},
  abstract={Existing image generation models have achieved the synthesis of reasonable individuals and complex but low-resolution images. Directly from complicated text to high-resolution image generation still remains a challenge. To this end, we propose the instance mask embedding and attribute-adaptive generative adversarial network (IMEAA-GAN). Firstly, we use the box regression network to compute a global layout containing the class labels and locations for each instance. Then the global generator encodes the layout, combines the whole text embedding and noise to preliminarily generate a low-resolution image; the instance embedding mechanism is used firstly to guide local refinement generators obtain fine-grained local features and generate a more realistic image. Finally, in order to synthesize the exact visual attributes, we introduce the multi-scale attribute-adaptive discriminator, which provides local refinement generators with the specific training signals to explicitly generate instance-level features. Extensive experiments based on the MS-COCO dataset and the Caltech-UCSD Birds-200-2011 dataset show that our model can obtain globally consistent attributes and generate complex images with local texture details.},
  keywords={Generators;Layout;Image generation;Gallium nitride;Generative adversarial networks;Visualization;Training;Generative adversarial network;global generator;local refinement generator;instance mask embedding;attribute-adaptive discriminator},
  doi={10.1109/ACCESS.2020.2975841},
  ISSN={2169-3536},
  month={},}@ARTICLE{9139965,
  author={Yang, Shuqiang and Qin, Huafeng and Liu, Xia and Wang, Jun},
  journal={IEEE Access}, 
  title={Finger-Vein Pattern Restoration With Generative Adversarial Network}, 
  year={2020},
  volume={8},
  number={},
  pages={141080-141089},
  abstract={Finger-vein recognition technology has attracted more and more attention because of its high security and convenience. However, the finger-vein image capturing is affected by various factors, which results that some vein patterns are missed in acquired image. Matching minutiae features in such images ultimately degrades verification performance of the finger-vein recognition system. To overcome this problem, in this paper, a novel finger-vein image restoration approach is proposed to recover the missed patterns based on generative adversarial network (GAN), as the first attempt in this area. Firstly, we employ the segmentation algorithm to extract finger-vein network, which is further subject to thinning operation. Secondly, the resulting thinning image is taken as an input of a GAN model to restore the missed vein patterns. Thirdly, the minutiae points are extracted from restoration finger-vein pattern. Finally, we propose a matching approach for verification. Experimental results show that the proposed method can restore the missed vein pattern and reduce the equal error rate (EER) of the finger-vein verification system.},
  keywords={Veins;Image restoration;Generative adversarial networks;Gallium nitride;Image segmentation;Feature extraction;Generators;Finger-vein recognition;vein restoration;generative adversarial network},
  doi={10.1109/ACCESS.2020.3009220},
  ISSN={2169-3536},
  month={},}@ARTICLE{9749241,
  author={Alshehri, Abeer and Taileb, Mounira and Alotaibi, Reem},
  journal={IEEE Access}, 
  title={DeepAIA: An Automatic Image Annotation Model Based on Generative Adversarial Networks and Transfer Learning}, 
  year={2022},
  volume={10},
  number={},
  pages={38437-38445},
  abstract={Automatic image annotation (AIA) has been adopted in different applications such as image retrieval and classification. Deep Learning is used in AIA to extract image features and then convert these features into text descriptions and labels. However, conventional AIA models that employ deep learning methods suffer from various shortcomings, such as poor annotation performance. This work proposes an AIA model based on convolutional neural networks (CNNs), generative adversarial networks (GANs), and transfer learning. GANs have attracted a lot of interest because of its ability to generate data without explicitly using probability density. Thus, it has proven its usefulness in image annotation and image augmentation. In this work, an Auxiliary classifier-GAN (ACGAN) has been used, where the discriminator predicts the class of an image rather than taking it as a given input; therefore, the stabilization of the training stage is ensured, and the generation of high-quality images is provided. Transfer learning is also used to enhance the performance of the classification. The proposed model outperforms the best state-of-the-art models in terms of MiAP, F-measure and error rate using ImageClef, ESPGame and IAPR-TC12 datasets.},
  keywords={Training;Annotations;Generative adversarial networks;Brain modeling;Feature extraction;Transfer learning;Deep learning;Automatic image annotation;convolutional neural network;generative adversarial network;transfer learning},
  doi={10.1109/ACCESS.2022.3165077},
  ISSN={2169-3536},
  month={},}@ARTICLE{9828400,
  author={Cao, Liying and Li, Hongda and Liu, Xuerui and Chen, Guifen and Yu, Helong},
  journal={IEEE Access}, 
  title={Semantic Segmentation of Plant Leaves Based on Generative Adversarial Network and Attention Mechanism}, 
  year={2022},
  volume={10},
  number={},
  pages={76310-76317},
  abstract={Due to the rapid growth of the population, the pressure on food is increasing and the demand for higher crop yields is rising. It is crucial to periodically monitor plant phenotypic traits, and deep learning has a good effect on image recognition and segmentation. This paper proposes a method based on generative adversarial network and attention mechanism to improve the accuracy of semantic segmentation of plant leaves. First, the data set is standardized and divided into a training set and test set. The generator that produces the confrontation network uses Segnet as the backbone network and adds an attention mechanism to extract the phenotypic characteristics of plants. The discriminator utilizes a dual-input fully connected layer for true and false estimate. The experimental results show that compared with the original Segnet segmentation network, the proposed strategy improves the precision of pixel recognition PA. Also, the suggested technique has a high level of robustness and feature extraction precision. In addition to providing technical assistance for future crop cultivation and breeding, monitoring crop growth, ensuring yields as well as solving the food shortage problem.},
  keywords={Image segmentation;Semantics;Generators;Training;Generative adversarial networks;Convolution;Deep learning;Semantic segmentation;attention mechanism;generative adversarial network;Segnet;phenotypic characteristics},
  doi={10.1109/ACCESS.2022.3190347},
  ISSN={2169-3536},
  month={},}@ARTICLE{8902093,
  author={Wang, Li and Wang, Huan},
  journal={IEEE Access}, 
  title={Water Hazard Detection Using Conditional Generative Adversarial Network With Mixture Reflection Attention Units}, 
  year={2019},
  volume={7},
  number={},
  pages={167497-167506},
  abstract={Water hazard detection is an important yet challenging task in autonomous driving as the complex underwater geography brings many hidden risks, e.g. puddles, which could make self-driving cars unsafe. Fully convolutional networks (FCN) have achieved remarkable performance on many image segmentation tasks, but water hazard detection problems are always hard to deal with due to the reflection characteristic of water. In this paper, we use Conditional Generative Adversarial Networks (cGAN) to deal with the water hazard detection. It has been proved that the Reflection Attention Unit (RAU) can improve the performance of deep networks for water hazard detection when added into the deep networks. We take advantage of RAU and carefully investigate its effect when placed in different layers of cGAN, with the best configuration being our proposed method: cGAN-mRAU. The `Puddle-1000' dataset is employed to evaluate our method. We use two subsets respectively and combine them together. We randomly choose some images and their ground-truth masks to train the model, and we use other images to test the model. We find many annotation mistakes in the dataset and correct them through re-annotation. Compared with FCN-8s with focal loss and 5 RAUs (FCN-8s-FL-5RAU), which is the state-of-the-art over `Puddle-1000', both cGAN and cGAN-mRAU outperform the FCN-8s-FL-5RAU in F1-measure, where cGAN achieves the best performance on `Off Road' subset and cGAN-mRAU achieves the best performance on `On Road' subset as well as whole dataset.},
  keywords={Hazards;Generators;Task analysis;Generative adversarial networks;Feature extraction;Roads;Image segmentation;Water hazard detection;generative adversarial networks;deep learning;image segmentation;reflection attention unit},
  doi={10.1109/ACCESS.2019.2953768},
  ISSN={2169-3536},
  month={},}@ARTICLE{9321336,
  author={Jia, Aiwen and Jia, Zhen-Hong and Yang, Jie and Kasabov, Nikola K.},
  journal={IEEE Access}, 
  title={Single-Image Snow Removal Based on an Attention Mechanism and a Generative Adversarial Network}, 
  year={2021},
  volume={9},
  number={},
  pages={12852-12860},
  abstract={Bad weather, such as snowfall, can seriously decrease the quality of images and pose great challenges to computer vision algorithms. In view of the negative effect of snowfall, this paper presents a single-image snow removal method based on a generative adversarial network (GAN). Unlike previous GANs, our GAN includes an attention mechanism in the generator component. By injecting attention information, the network can pay increased attention to areas covered by snow and improve its capability to perform local repairs. At the same time, we improve the traditional U-Net network by combining it with the residual network to enhance the effect of the model when removing snowflakes from a single image. Our experiments on both synthetic and real-word images show that our method produces better results than those of other state-of-the-art methods.},
  keywords={Snow;Rain;Feature extraction;Training;Generators;Gallium nitride;Generative adversarial networks;Snow removal;generative adversarial networks;attention mechanisms},
  doi={10.1109/ACCESS.2021.3051359},
  ISSN={2169-3536},
  month={},}@ARTICLE{8673567,
  author={Kim, San and Suh, Doug Young},
  journal={IEEE Access}, 
  title={Recursive Conditional Generative Adversarial Networks for Video Transformation}, 
  year={2019},
  volume={7},
  number={},
  pages={37807-37821},
  abstract={Conditional generative adversarial networks (cGANs) are used in various transformation applications, such as super-resolution, colorization, image denoising, and image inpainting. So far, cGANs have been applied to the transformation of still images, but their use could be extended to the transformation of video contents, which has a much larger market. This paper considers problems with the cGAN-based transformation of video contents. The major problem is flickering caused by the discontinuity between adjacent image frames. Several postprocessing algorithms have been proposed to reduce that effect after transformation. We propose a recursive cGAN in which the previous output frame is used as an input in addition to the current input frame to reduce the flickering effect without losing the objective quality of each image. Compared with previous postprocessing algorithms, our approach performed better in terms of various evaluation metrics for video contents.},
  keywords={Generative adversarial networks;Image sequences;Gallium nitride;Histograms;Image resolution;Task analysis;Data models;Image-to-image transformation;generative adversarial network;reducing flicker;video transformation},
  doi={10.1109/ACCESS.2019.2906472},
  ISSN={2169-3536},
  month={},}@ARTICLE{9478861,
  author={Shaheen, Nusrat and Raza, Basit and Shahid, Ahmad Raza and Malik, Ahmad Kamran},
  journal={IEEE Access}, 
  title={Autonomic Workload Performance Modeling for Large-Scale Databases and Data Warehouses Through Deep Belief Network With Data Augmentation Using Conditional Generative Adversarial Networks}, 
  year={2021},
  volume={9},
  number={},
  pages={97603-97620},
  abstract={Databases and warehouses are experiencing workload of different types such as Decision Support System (DSS), Online Transaction Processing (OLTP) and Mixed workloads. Handling variety of workload in autonomic systems is a critical task. After self-configuring the workload, the next challenge is workload performance tuning that motives towards self-predictive systems. Existing studies provide performance modeling solutions on small-scale data repositories of Database Management System (DBMS) and Data Warehouse (DWH) using either classical eager or lazy learning approaches. However, in real-world problems, we normally have to deal with large-scale data repositories. Therefore, there is a need to develop performance models that provide data augmentation to solve large-scale data repositories that are not publicly available. In this study, deep learning approaches have been investigated for performance tuning of large-scale data repositories. We propose a performance prediction model called Optimized GAN-based Deep Learning (OGDL) model. For data augmentation, Conditional Generative Adversarial Networks (CGAN) is applied. For autonomic perspective, we incorporated MAPE-K model to manage the workload autonomically. Different deep learning models are applied, and it was observed that Deep Belief Network (DBN) performed better as compared to other deep learning models such as Deep Neural Network (DNN). We performed a number of experiments and from results it is observed that deep learning models performed the best in comparison with classical machine learning and lazy learning and a $6-8\%$ increase in accuracy is recorded in our experiments using DBN. The proposed OGDL model performed the best in workload performance predictions in an optimized way.},
  keywords={Data models;Deep learning;Predictive models;Computational modeling;Generative adversarial networks;Tuning;Training data;Autonomic computing;generative adversarial networks;stacked genetic algorithm;deep belief network;large-scale data repositories},
  doi={10.1109/ACCESS.2021.3096039},
  ISSN={2169-3536},
  month={},}@ARTICLE{8869769,
  author={Liao, Huadong and He, Jiawei and Shu, Kunxian},
  journal={IEEE Access}, 
  title={Generative Model With Dynamic Linear Flow}, 
  year={2019},
  volume={7},
  number={},
  pages={150175-150183},
  abstract={Flow-based generative models are a family of exact log-likelihood models with tractable sampling and latent-variable inference, hence conceptually attractive for modeling complex distributions. However, flow-based models are limited by density estimation performance issues as compared to state-of-the-art autoregressive models. Autoregressive models, which also belong to the family of likelihood-based methods, however suffer from limited parallelizability. In this paper, we propose Dynamic Linear Flow (DLF), a new family of invertible transformations with partially autoregressive structure. Our method benefits from the efficient computation of flow-based methods and high density estimation performance of autoregressive methods. We demonstrate that the proposed DLF yields state-of-the-art performance on ImageNet 32 × 32 and 64 × 64 out of all flow-based methods. Additionally, DLF converges significantly faster than previous flow-based methods such as Glow.},
  keywords={Data models;Estimation;Computational modeling;Jacobian matrices;Training;Couplings;Hardware;Exact likelihood;generative models;invertible transformation},
  doi={10.1109/ACCESS.2019.2947567},
  ISSN={2169-3536},
  month={},}@ARTICLE{10609392,
  author={O’Dwyer Boyle, Albha and Nikandish, Reza},
  journal={IEEE Access}, 
  title={A Hybrid Quantum-Classical Generative Adversarial Network for Near-Term Quantum Processors}, 
  year={2024},
  volume={12},
  number={},
  pages={102688-102701},
  abstract={In this article, we present a hybrid quantum-classical generative adversarial network (GAN) for near-term quantum processors. The hybrid GAN comprises a variational generator and a discriminator quantum neural network, which are trained using a classic computer. The generator network is realized using angle-encoding and variational quantum circuits. The discriminator network is realized using multi-stage trainable encoding quantum circuits. A modular design approach is proposed for quantum neural networks which allows control on their depth to compromise accuracy and circuit complexity. Moreover, this modular approach makes the quantum neural networks amenable to scaling up the dimension of dataset and the number of qubits. Gradients of the loss functions are derived using the same quantum circuits used for the implementation of quantum neural networks to prevent the need for extra quantum circuits or auxiliary qubits. The quantum simulations are performed using the IBM Qiskit open-source software development kit (SDK), while the training of the hybrid quantum-classical GAN is conducted using the mini-batch stochastic gradient descent (SGD) optimization on a classic computer. The hybrid quantum-classical GAN is realized using a two-qubit system with different discriminator network structures. The best performance is achieved using a five-stage discriminator network comprising 63 quantum gates and 31 trainable parameters, with the Kullback-Leibler (KL) and Jensen-Shannon (JS) divergence scores of 0.39 and 0.52, respectively, for the similarity between the real and generated data distributions.},
  keywords={Generative adversarial networks;Quantum computing;Program processors;Quantum circuit;Computers;Qubit;Generators;Neural networks;Generative adversarial network (GAN);hybrid quantum-classical model;noisy intermediate-scale quantum (NISQ);quantum circuit;quantum computing;quantum machine learning;quantum neural network (QNN);variational quantum algorithm (VQA)},
  doi={10.1109/ACCESS.2024.3433383},
  ISSN={2169-3536},
  month={},}@ARTICLE{9527232,
  author={Xiong, Fang and Liu, Jian and Zhao, Min and Yao, Min and Guo, Ruipeng},
  journal={IEEE Access}, 
  title={Positron Image Super-Resolution Using Generative Adversarial Networks}, 
  year={2021},
  volume={9},
  number={},
  pages={121329-121343},
  abstract={Positron images generated by positron non-destructive testing technology under rapid detection scenes such as low concentration dose, low exposure time and short imaging time, which have some problems like low-resolution and poor definition. These issues cannot be solved for the being time. To solves these problems, this research super-resolves the low-resolution positron images to generate images with high-resolution and clear details. To make the generated super-resolution images more capable of restoring the features of low- resolution images, this research proposed a positron image super-resolution reconstruction method based on generative adversarial networks. In order to improve the input information utilization rate, long skip connections were added into the generator. In addition, the discriminant model, where composed of an image discriminator and a feature discriminator, can stimulate the generator to generate clearer super-resolution images which contain more details. In attempting to solve the problem of dataset matching, a special positron image super-resolution dataset is constructed for network application scenarios. In the adversarial training stage, perceptual similarity loss and adversarial loss are used to replace the traditional mean squared error loss to improve the images perception quality. Experimental results show that the proposed model can reconstruct low-resolution images by four times super-resolution in 0.16 seconds. The super-resolution images obtained are superior to other algorithms in visual effect, which have clearer detail structure and higher objective performance values. Hence this model can meet the requirements of rapid non-destructive testing of industrial parts.},
  keywords={Positrons;Superresolution;Image reconstruction;Testing;Hydraulic systems;Generative adversarial networks;Generators;Super-resolution reconstruction;deep learning;generative adversarial networks;positron image},
  doi={10.1109/ACCESS.2021.3109634},
  ISSN={2169-3536},
  month={},}@ARTICLE{10974979,
  author={Cheema, Muhammad Omar and Mohy-Ud-Din, Zia and Imran, Azhar and Khan, Fawad Salam and Al-Rawi, Mahmood Basil A. and El-Meligy, Mohammed A. and Gul, Jahan Zeb},
  journal={IEEE Access}, 
  title={Electrohysterogram Data Augmentation Using Generative Adversarial Network for Pregnancy Outcome Prediction}, 
  year={2025},
  volume={13},
  number={},
  pages={92468-92482},
  abstract={There are many difficulties in managing and detecting preterm pregnancies, especially in the early stages. Analyzing electrohysterogram data, which show the electrical activity of uterine muscles, is a promising non-invasive method for classifying term and preterm pregnancies. However, the effectiveness of machine learning classifiers is hampered by the inherent class imbalance in datasets. In order to overcome this constraint, this study uses a Generative Adversarial Network to produce high-quality synthetic EHG data while maintaining the statistical properties of actual signals. By successfully reducing class imbalance, the enhanced dataset makes it possible for machine learning models to be trained with resilience. Real and synthetic features did not differ significantly, according to statistical validation using a t-test (p > 0.05). With this method, the Random Forest classifier obtained a ROC-AUC of 0.99 and a 10-fold cross-validation accuracy of 98%. The suggested GAN-based method’s simplicity and efficacy demonstrate its promise for resolving class imbalance and developing reliable classification systems for diagnostic applications.},
  keywords={Pregnancy;Generative adversarial networks;Accuracy;Synthetic data;Pediatrics;Data models;Data augmentation;Computational modeling;Uterus;Training;Data augmentation;data enhancement;electrohysterogram;generative adversarial network;machine learning;term preterm;vanilla GAN;classification},
  doi={10.1109/ACCESS.2025.3563623},
  ISSN={2169-3536},
  month={},}@ARTICLE{10843681,
  author={Shoaib, Muhammad and Husnain, Ghassan and Sayed, Nasir and Yasin Ghadi, Yazeed and Alajmi, Masoud and Qahmash, Ayman},
  journal={IEEE Access}, 
  title={Automated Generation of Multiple-Choice Questions for Computer Science Education Using Conditional Generative Adversarial Networks}, 
  year={2025},
  volume={13},
  number={},
  pages={16697-16715},
  abstract={This work presents a novel perspective towards generating automated multiple-choice questions (MCQs)-a task fundamentally different due to the highly dynamic nature of computer science education, which spans several sub-domains. Taking advantage of Conditional Generative Adversarial Networks (cGANs), our model provides a versatile approach to addressing the need for diversity and context in relevant MCQ generation across proficiency levels, topic areas. Resulting MCQs inspire implementations within a variety of educational environments - from classrooms, to online courses, and finally exams - equipping teachers with an instrument that could be easily adapted based on the specific needs o students. The model is trained on a carefully constructed dataset that includes material from more than 20 subareas in computer science, consisting of materials such as textbooks, online encyclopedias and Q&A websites. Through rigorous evaluation using comprehensive performance metrics, including Question Relevance Score (QRS), Diversity Index (DI), and Difficulty Alignment Accuracy (DAA), we demonstrate the efficacy and robustness of our framework in generating high-quality MCQs. Moreover, we address ethical considerations inherent in AI-driven educational assessment, ensuring fairness, transparency, and accountability in the MCQ generation process. The cGAN architecture facilitates the generation of contextually relevant MCQs across various proficiency levels and subject domains, enhancing the educational assessment process. The comprehensive dataset developed for this study encompasses diverse computer science topics curated from authoritative textbooks, online resources, question banks, and instructor-generated content. Additionally, a user-friendly QT application has been developed, enabling seamless integration of the cGAN model into educational environments. Through rigorous evaluation and ethical considerations, this framework demonstrates its efficacy, ensuring fairness, transparency, and accountability in MCQ generation. This interdisciplinary work represents a significant advancement in computer science education, providing educators with a powerful tool to enhance student engagement and learning outcomes.},
  keywords={Education;Computer science;Computer science education;Generative adversarial networks;Computational modeling;Indexes;Ethics;Chatbots;Training;Testing;Automated MCQ generation;conditional generative adversarial networks (cGANs);computer science education;dataset curation;educational assessment},
  doi={10.1109/ACCESS.2025.3530474},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10649461,
  author={Lokesh, S. and Madhavan, Arvind and Ramanathan, RM Prakash and Anand, Krteen},
  booktitle={2024 International Conference on Smart Systems for Electrical, Electronics, Communication and Computer Engineering (ICSSEECC)}, 
  title={Intelligent Systems for Data Driven Agriculture: Enhancing Farmer Productivity Through Automation and Artificial Intelligence}, 
  year={2024},
  volume={},
  number={},
  pages={433-438},
  abstract={Numerous obstacles endanger the livelihoods of smallholder farmers and global food security. Crop output losses due to plant diseases alone are estimated to be between 15% to 25% every year. However, farmers' capacity to recognize and treat illnesses in a timely manner is hampered by things like a lack of agronomic expertise, limited access to actionable insights, and information gaps. The work proposes a comprehensive end-to-end web application that uses machine learning models to help farmers with configurable expert advice, smart farm management, and automatic disease detection. Thus, enabling farmers to identify the infection using their smart phones and obtain crop - fertilizer recommendations for the crops to be treated in the farmer's area based on historical data analysis of yield-influencing elements such as geography, weather, and soil. The proposed system will employ Generative Artificial Intelligence, such as ChatGPT's natural language processing and generation capabilities, to engage in conversational interactions with farmers. The work achieves close to 95% accuracy after utilizing 30 epochs in the area of disease detection and 97% accurate models are achieved for fertilizer outputs. These features along with it's high accuracy can assist farmers in making informed decisions, utilising the data obtained to reduce crop output losses.},
  keywords={Smart agriculture;Productivity;Plant diseases;Accuracy;Neural networks;Crops;Soil;Machine Learning;ChatGPT;Generative AI;Convoluted Neural Network},
  doi={10.1109/ICSSEECC61126.2024.10649461},
  ISSN={},
  month={June},}@ARTICLE{9210484,
  author={Chang, Yifan and Li, Wenbo and Peng, Jian and Li, Haifeng and Kang, Yu and Huang, Yingliang},
  journal={IEEE Access}, 
  title={Memory Protection Generative Adversarial Network (MPGAN): A Framework to Overcome the Forgetting of GANs Using Parameter Regularization Methods}, 
  year={2020},
  volume={8},
  number={},
  pages={179942-179954},
  abstract={Generative adversarial networks (GANs) suffer from catastrophic forgetting when learning multiple consecutive tasks. Parameter regularization methods that constrain the parameters of the new model in order to be close to the previous model through parameter importance are effective in overcoming forgetting. Many parameter regularization methods have been tried, but each of them is only suitable for limited types of neural networks. Aimed at GANs, this paper proposes a unified framework called Memory Protection GAN (MPGAN), in which many parametrization methods can be used to overcome forgetting. The proposed framework includes two modules: Protecting Weights in Generator and Controller. In order to incorporate parameter regularization methods into MPGAN, the Protecting Weights in Generator module encapsulates different parameter regularization methods into a “container”, and consolidates the most important parameters in the generator through a parameter regularization method selected from the container. In order to differentiate tasks, the Controller module creates unique tags for the tasks. Another problem with existing parameter regularization methods is their low accuracy in measuring parameter importance. These methods always rely on the first derivative of the output function, and ignore the second derivative. To assess parameter importance more accurately, a new parameter regularization method called Second Derivative Preserver (SDP), which takes advantage of the second derivative of the output function, is designed into MPGAN. Experiments demonstrate that MPGAN is applicable to multiple parameter regularization methods and that SDP achieves high accuracy in parameter importance.},
  keywords={Gallium nitride;Task analysis;Generators;Generative adversarial networks;Training;Neural networks;Knowledge engineering;Catastrophic forgetting;generative adversarial network;parameter regularization methods},
  doi={10.1109/ACCESS.2020.3028067},
  ISSN={2169-3536},
  month={},}@ARTICLE{10636131,
  author={Eyglys Araújo Dos Santos, Keylly and Duarte Dória Neto, Adrião and de Medeiros Martins, Allan},
  journal={IEEE Access}, 
  title={Face Representation for Online Interactions Using Bidirectional Generative Adversarial Networks (BiGANs)}, 
  year={2024},
  volume={12},
  number={},
  pages={132701-132713},
  abstract={In this research, a new method for face representation is presented, which utilizes Bidirectional Generative Adversarial Networks (BiGANs), showing significant progress compared to conventional methods of video transmission using MPEG-2 compression techniques. In scenarios such as online meetings, our approach takes advantage of the inherent bidirectional capabilities of BiGANs in virtual environments to produce compact yet highly expressive facial representations. As a result, the amount of data required for transmission is reduced. The effectiveness of our approach in generating high-quality synthetic face images that closely resemble the original faces was demonstrated through our experiments, which were conducted on a dataset consisting of 813 frames of an individual’s face. Furthermore, the method’s capability to preserve higher values of the Structural Similarity Index (SSIM) and Peak Signal-to-Noise Ratio (PSNR) highlights its potential to generate synthetic facial images with minimal degradation in quality. This makes it an encouraging approach for real-time online communication, especially in situations with limited bandwidth.},
  keywords={Generative adversarial networks;Training;Generators;Vectors;Tensors;Bidirectional control;Face recognition;Deep learning;Bidirectional generative adversarial networks (BiGANs);face representation;efficient data transmission;online interactions;deep learning},
  doi={10.1109/ACCESS.2024.3443643},
  ISSN={2169-3536},
  month={},}@ARTICLE{10720776,
  author={Wu, Houmin and Lim, Sangguk and Xiao, Bin},
  journal={IEEE Access}, 
  title={Animated Avatar Generation Technology Research Based on Deep Convolutional Generative Adversarial Network Integrated With Self-Attention and Spectral Normalization}, 
  year={2024},
  volume={12},
  number={},
  pages={154614-154630},
  abstract={The burgeoning field of large language models (LLMs), exemplified by DALL-E and Stable Diffusion, has made image generation a reality. However, the computationally intensive GPU training these models necessitate incurs substantial financial burdens. Moreover, while a plethora of image datasets are accessible, specialized anime avatar datasets remain elusive and are often entangled in copyright disputes. This scarcity presents a significant research opportunity: developing a cost-effective, user-friendly anime avatar generation technique that circumvents these challenges. This paper introduces a novel method for creating animated avatars, leveraging the deep convolutional generative adversarial network(DCGAN) architecture and enhanced with Self-Attention (SA) and Spectral Normalization (SN), termed the SA+SN-DCGAN. The integration of the SA mechanism into the generator significantly elevates the quality of the output. Meanwhile, the application of SN to the discriminator effectively combats the notorious vanishing or exploding gradients, and thereby diminishing the likelihood of over-fitting. Our methodology involved sourcing anime avatars from reputable public domains and standardizing them using OpenCV. A meticulous grid search was employed to fine-tune model hyper-parameters. After 300 epochs of rigorous training, the generator and discriminator achieved stable error rates, with the synthesized images closely mirroring the fidelity of authentic avatars. Comparative evaluations against prevailing models underscore the SA+SN_DCGAN method’s superiority in producing highly realistic anime avatars, affirming its exceptional overall performance. This study not only contributes a novel solution to the domain of anime avatar generation but also paves the way for future research in the field.},
  keywords={Avatars;Generative adversarial networks;Generators;Training;Noise measurement;Computer architecture;Visualization;Unsupervised learning;Speech coding;Semantics;Generative adversarial network;anime avatar;self-attention model;spectral normalization},
  doi={10.1109/ACCESS.2024.3482989},
  ISSN={2169-3536},
  month={},}@ARTICLE{10754649,
  author={Yang, Jiacheng and Wang, Yuanda and Dong, Lu and Xue, Lei and Sun, Changyin},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Active Robust Adversarial Reinforcement Learning Under Temporally Coupled Perturbations}, 
  year={2025},
  volume={6},
  number={4},
  pages={874-884},
  abstract={Robust reinforcement learning (RL) aims to improve the generalization of agents under model mismatch. As a major branch of robust RL, adversarial approaches formulate the problem as a zero-sum game in which adversaries seek to apply worst case perturbations to the dynamics. However, the potential constraints of adversarial perturbations are seldom addressed in existing approaches. In this article, we consider temporally coupled settings, where adversarial perturbations change continuously at a bounded rate. This kind of constraint can commonly arise in a variety of real-world situations (e.g., changes in wind speed and ocean currents). We propose a novel robust RL approach, named active robust adversarial RL (ARA-RL), that tackles this problem in an adversarial architecture. First, we introduce a type of RL adversary that generates temporally coupled perturbations on agent actions. Then, we embed a diagnostic module in the RL agent, enabling it to actively detect temporally coupled perturbations in unseen environments. Through adversarial training, the agent seeks to maximize its worst case performance and thus achieve robustness under perturbations. Finally, extensive experiments demonstrate that our proposed approach provides significant robustness against temporally coupled perturbations and outperforms other baselines on several continuous control tasks.},
  keywords={Perturbation methods;Robustness;Training;Uncertainty;Games;Game theory;Reinforcement learning;Artificial intelligence;Wind speed;Sun;Adversarial training;policy robustness;reinforcement learning (RL)},
  doi={10.1109/TAI.2024.3499938},
  ISSN={2691-4581},
  month={April},}@ARTICLE{10707638,
  author={Li, Jing and Wang, Jichen and Li, Zerui and Kang, Yu and Lv, Wenjun},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Partial Domain Adaptation for Building Borehole Lithology Model Under Weaker Geological Prior}, 
  year={2024},
  volume={5},
  number={12},
  pages={6645-6658},
  abstract={Lithology identification plays a pivotal role in stratigraphic characterization and reservoir exploration. The promising field of intelligent logging lithology identification, which employs machine learning algorithms to infer lithology from logging curves, is gaining significant attention. However, models trained on labeled wells currently face challenges in accurately predicting the lithologies of new unlabeled wells due to significant discrepancies in data distribution among different wells caused by the complex sedimentary environment and variations in logging equipment. Additionally, there is no guarantee that newly drilled wells share the same lithology classes as previously explored ones. Therefore, our research aims to leverage source logging and lithology data along with target logging data to train a model capable of directly discerning the lithologies of target wells. The challenges are centered around the disparities in data distribution and the lack of prior knowledge regarding potential lithology classes in the target well. To tackle these concerns, we have made concerted efforts: 1) proposing a novel lithology identification framework, sample transferability weighting based partial domain adaptation (ST-PDA), to effectively address the practical scenario of encountering an unknown label space in target wells; 2) designing a sample transferability weighting module to assign higher weights to shared-class samples, thus effectively mitigating the negative transfer caused by unshared-class source samples; 3) developing a module, convolutional neural network with integrated channel attention mechanism (CG${}^{2}$CA), to serve as the backbone network for feature extraction; and 4) incorporating a target sample reconstruction module to enhance the feature representation and further facilitating positive transfer. Extensive experiments on 16 real-world wells demonstrated the strong performance of ST-PDA and highlighted the necessity of each component in the framework.},
  keywords={Geology;Feature extraction;Reservoirs;Artificial intelligence;Accuracy;Predictive models;Long short term memory;Noise;Attention mechanisms;Adaptation models;Channel attention;lithology identification;PDA;sample transferability weighting;target sample reconstruction},
  doi={10.1109/TAI.2024.3476434},
  ISSN={2691-4581},
  month={Dec},}@ARTICLE{10976574,
  author={Yang, Xiao and Sun, Zhan-Li and Liu, Mengya and Zeng, Zhigang and Lam, Kin-Man and Wang, Xin},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={RSMBSP-DON: RNA-Small Molecule Binding Sites Prediction by Dual-path feature extraction and One-dimensional multi-scale feature fusion Network}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={Due to the significant differences between the structural and sequence information of RNA, accurately predicting RNA-small molecule binding sites by utilizing these two attributes remains a challenging task. This study introduces a novel network for predicting RNA-small molecule binding sites, employing a two-stage approach that integrates feature extraction and fusion processes. On one hand, in order to capture the diverse characteristic information of RNA, a dual-path feature extraction module is proposed to extract features from both short-range and long-range perspectives, by incorporating convolutional and attention networks. On the other hand, a one-dimensional multi-scale feature fusion module, consisting of parallel one-dimensional convolutional kernels, is proposed to extract feature information at multiple granularities and to effectively integrate the features of nucleotides on the RNA chain and their neighboring nucleotides. Experimental results demonstrate that RSMBSP-DON is competitive with some recently reported methods. All datasets and resource codes are available at https://github.com/zhlSunLab/RSMBSP-DON.},
  keywords={RNA;Feature extraction;Mathematical models;Training;Encoding;Artificial intelligence;Vectors;Proteins;Deep learning;Data mining;Binding sites prediction;deep learning;feature fusion;feature extraction},
  doi={10.1109/TAI.2025.3564243},
  ISSN={2691-4581},
  month={},}@ARTICLE{11121160,
  author={Bandória, Luís H. T. and Silva, Walquiria N. and De Almeida, Madson C.},
  journal={IEEE Access}, 
  title={Impact of Normalization Techniques on Synthetic Load Profile Generation Using Deep Generative Models}, 
  year={2025},
  volume={13},
  number={},
  pages={140900-140913},
  abstract={Synthetic load profiles are increasingly employed in power system studies as a cost-effective and privacy-preserving alternative to extensive smart meter deployments, with deep generative models (DGMs) showing promising results in capturing complex demand patterns. However, the impact of data normalization on their performance remains insufficiently explored. Using datasets from a university smart grid and industrial consumers in Germany, this work systematically evaluates five normalizations techniques-Min-Max, Standard, Robust, Max-Abs, and Quantile—on four representative DGMs: Wasserstein GAN with gradient penalty (WGAN-GP), variational autoencoder (VAE), nonlinear independent component estimation (NICE), and denoising diffusion implicit models (DDIM). Additionally, this study introduces DDIM for synthetic load profile generation, providing a deterministic and faster sampling approach compared to traditional probabilistic denoising models. Results based on statistical and temporal metrics indicate that Max-Abs normalization consistently yields more accurate and stable synthetic profiles across all models and datasets, while Robust and Quantile methods often degrade essential distributional features. These findings highlight the critical role of normalization in developing effective synthetic data generation pipelines for power system applications.},
  keywords={Load modeling;Data models;Power systems;Standards;Synthetic data;Noise reduction;Training;Generative adversarial networks;Buildings;Autoencoders;Data normalization;synthetic load profiles;generative adversarial networks;variational autoencoders;normalizing flows;denoising diffusion models},
  doi={10.1109/ACCESS.2025.3597160},
  ISSN={2169-3536},
  month={},}@ARTICLE{11026875,
  author={Zhong, Kai and Zhu, Hengchang and Zhang, Xiaoming and Huang, Darong and Han, Min},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Contrastive Learning based Collaborative Modelling of Heterogeneous Data for Few-shot Fault Diagnosis}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={Few-shot diagnosis has received extensive attention recently. Existing methods rarely consider the consistency within and between heterogeneous data, leading to suboptimal diagnosis performance. To address this issue, a contrastive learning based collaborative modelling for few-shot diagnosis is proposed. First of all, a heterogeneous data enhancement workflows with distribution consistency assessment is designed to acquire sufficient industrial process information, which can also mitigate the inconsistency between enhanced data and original data. Following this, convolutional networks with customized structures are used to extract the multimodal features from heterogeneous signals. After that, the collaborative modelling and diagnosis module is devised through the joint optimization of contrastive loss and cross entropy loss, which can shorten the distance of similar samples in feature space and retain cross structure consistency. Finally, the effectiveness and superiority of the proposed method are substantiated through simulated and the real world cases.},
  keywords={Fault diagnosis;Data models;Contrastive learning;Collaboration;Wavelet transforms;Kernel;Convolution;Artificial intelligence;Vectors;Metalearning;Few-shot diagnosis;contrastive learning;heterogeneous data;collaborative modelling},
  doi={10.1109/TAI.2025.3577119},
  ISSN={2691-4581},
  month={},}@ARTICLE{11030454,
  author={Pulford, Graham W.},
  journal={IEEE Access}, 
  title={Quasi-Analytical Least-Squares Generative Adversarial Networks: Further 1-D Results and Extension to Two Data Dimensions}, 
  year={2025},
  volume={13},
  number={},
  pages={107872-107889},
  abstract={Generative adversarial networks (GANs) are notoriously difficult to analyse, necessitating empirical studies in high dimensional spaces that suffer from stochastic sampling noise. Quasi-analytical, low-dimensional GANs can be developed in various special cases to elucidate aspects of GAN training in a manageable, precise setting where variables of interest can be easily visualised. A previously developed 1-D Rayleigh/Square/Exponential/Erf (R/S/E/E) least squares GAN (LSGAN), with 1-D latent variable z and 1-D data x, is extended to the case of 2-D exponentially distributed data. The 2-D R/S/E/E LSGAN has 8 parameters and its dynamics under gradient descent ascent (GDA) are analysable to high accuracy via two 1-D numerical integrals. Visualisation strategies are given for the cost function and parameter trajectories during training. Numerical performance is compared with the equivalent stochastic GDA algorithm, obtaining precise agreement. It is shown that the 2-D R/S/E/E LSGAN, which satisfies  ${{ dim}}(z)\lt { { dim}}(x)$ , has an optimal discriminator that is not differentiable, does not depend on the data PDF and is nowhere equal to 1/2, contradicting conventional GAN theory. For numerical simulations in the 1-D case, when the functional form of the optimal discriminator (a scaled logistic function) is fixed but its parameters are not matched to the optimal generator and can vary, convergence to the optimal settings does not occur, and, for certain initial settings, severe error propagation results. It is proven that the optimal generator setting cannot be a stable point of the GDA recursion. For a specific 1-D case, we also characterise the range of initial conditions for which convergence to the neighbourhood of the optimal generator occurs in a given number of steps. Finally, the extension to an exponential mixture data PDF is considered. A 2-D mixture R/S/E/E LSGAN with bifurcating (chaotic) parameter trajectories is exhibited. Empirical evidence is provided of long-term oscillatory behaviour in the parameters and cost function when both the step size (learning rate) and the support of the data distribution are large. In this instance, the oscillations are not due to mode collapse.},
  keywords={Generative adversarial networks;Generators;Cost function;Convergence;Training;Data visualization;Trajectory;Stochastic processes;Oscillators;Analytical models;Bifurcation;error propagation;explicit low-dimensional model;exponential mixture;generative adversarial network;loss surface;mode collapse;oscillations;quasi-analytical model},
  doi={10.1109/ACCESS.2025.3578826},
  ISSN={2169-3536},
  month={},}@ARTICLE{10714346,
  author={Lin, Hsi-Ju and Cheng, Wei-Yuan and Chen, Duan-Yu},
  journal={IEEE Access}, 
  title={Frequency-Aware Axial-ShiftedNet in Generative Adversarial Networks for Visible-to-Infrared Image Translation}, 
  year={2024},
  volume={12},
  number={},
  pages={151432-151443},
  abstract={Infrared imagery is indispensable for capturing temperature data by detecting infrared radiation, particularly in challenging environments characterized by low-light conditions where visual perception is compromised. As a result, there has been considerable interest in the conversion of visible images into their infrared counterparts. In this research, we present the Freq-ShiftedNet model, which employs an adversarial generative network approach for training. By harnessing the power of the Haar wavelet transform, we adeptly preserve frequency information, directing low-frequency features to the Decoder and high-frequency features to the Encoder. Analysis of the KAIST dataset demonstrates that our model outperforms InfraGAN, achieving a Structural Similarity (SSIM) score of 0.825, marking a 5.4% improvement, and a Learned Perceptual Image Patch Similarity (LPIPS) score of 0.228, indicating a 41.3% decrease. Similarly, using the VEDAI dataset, Freq-ShiftedNet surpasses InfraGAN with an SSIM score of 0.938, representing a 6.6% improvement. These results highlight the effectiveness of our proposed generator, the successful integration of wavelet features into the Freq-ShiftedNet model, and its suitability for real-world applications.},
  keywords={Generators;Feature extraction;Wavelet transforms;Training;Decoding;Computational modeling;Wavelet analysis;Generative adversarial networks;Frequency-domain analysis;Convolutional neural networks;Infrared imaging;Image processing;Infrared image;generative adversarial model;wavelet transform;image translation},
  doi={10.1109/ACCESS.2024.3478356},
  ISSN={2169-3536},
  month={},}@ARTICLE{11060923,
  author={Hu, Cong and Song, Jiangtao and Wu, Xiao-Jun},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={PGR: Pseudo Graph Regularization for Semi-Supervised Classification}, 
  year={2025},
  volume={},
  number={},
  pages={1-14},
  abstract={Semi-supervised learning (SSL) is gaining attention for its intrinsic ability to extract valuable information from labeled and unlabeled data with improved performance. Recently, consistency regularization methods have gained interest due to their efficient learning procedures. However, they are confined to pseudo-label or feature representation-level perturbations, negating the benefit of having both forms in a single framework. This leads to the model remaining robust to either the pseudo-label or the feature representation. To this end, we propose Pseudo Graph Regularization (PGR) for Semi-Supervised Classification, which leverages graph-based contrastive learning to unify pseudo-labels and feature embeddings in a single semi-supervised framework. The model imposes graph regularization on both pseudo-labels and feature embeddings of unlabeled data to retain the intrinsic geometric structure. Feature embeddings into the model impose constraints on the class probability, forcing the class probability distributions of unlabeled data subject to different perturbations to be consistent. The pseudo-labels regularly optimize the embedding space’s structure through graph-based contrastive learning, which allows data with similar pseudo-labels to have similar feature embeddings in latent space. PGR unifies pseudo-label and feature representation of unlabeled data to improve the ability of model to resist noise interference and generalization ability. Extensive experiments on four benchmark datasets demonstrate that PGR can generate higher quality pseudo-labels for unlabeled data, and is superior to the state-of-the-art (SOTA) methods. The code is available at https://github.com/song-leap/PGR.},
  keywords={Data models;Contrastive learning;Training;Predictive models;Artificial intelligence;Adaptation models;Data augmentation;Computational modeling;Perturbation methods;Feature extraction;Semi-supervised learning;Contrastive learning;Graph regularization},
  doi={10.1109/TAI.2025.3585095},
  ISSN={2691-4581},
  month={},}@ARTICLE{10643032,
  author={Chatziparaskevas, Georgios and Mademlis, Ioannis and Pitas, Ioannis},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Generative Representation Learning in Recurrent Neural Networks for Causal Timeseries Forecasting}, 
  year={2024},
  volume={5},
  number={12},
  pages={6412-6425},
  abstract={Feed-forward deep neural networks (DNNs) are the state of the art in timeseries forecasting. A particularly significant scenario is the causal one: when an arbitrary subset of variables of a given multivariate timeseries is specified as forecasting target, with the remaining ones (exogenous variables) causing the target at each time instance. Then, the goal is to predict a temporal window of future target values, given a window of historical exogenous values. To this end, this article proposes a novel deep recurrent neural architecture, called generative-regressing recurrent neural network (GRRNN), which surpasses competing ones in causal forecasting evaluation metrics, by smartly combining generative learning and regression. During training, the generative module learns to synthesize historical target timeseries from historical exogenous inputs via conditional adversarial learning, thus internally encoding the input timeseries into semantically meaningful features. During a forward pass, these features are passed over as input to the regression module, which outputs the actual future target forecasts in a sequence-to-sequence fashion. Thus, the task of timeseries generation is synergistically combined with the task of timeseries forecasting, under an end-to-end multitask training setting. Methodologically, GRRNN contributes a novel augmentation of pure supervised learning, tailored to causal timeseries forecasting, which essentially forces the generative module to transform the historical exogenous timeseries to a more appropriate representation, before feeding it as input to the actual forecasting regressor. Extensive experimental evaluation on relevant public datasets obtained from disparate fields, ranging from air pollution data to sentiment analysis of social media posts, confirms that GRRNN achieves top performance in multistep long-term forecasting.},
  keywords={Forecasting;Recurrent neural networks;Vectors;Training;Task analysis;Representation learning;Predictive models;Generative adversarial network (GAN);multitask learning;recurrent neural network (RNN);representation learning;timeseries forecasting},
  doi={10.1109/TAI.2024.3446465},
  ISSN={2691-4581},
  month={Dec},}@ARTICLE{9003391,
  author={Qu, Xinghua and Sun, Zhu and Ong, Yew-Soon and Gupta, Abhishek and Wei, Pengfei},
  journal={IEEE Transactions on Cognitive and Developmental Systems}, 
  title={Minimalistic Attacks: How Little It Takes to Fool Deep Reinforcement Learning Policies}, 
  year={2021},
  volume={13},
  number={4},
  pages={806-817},
  abstract={Recent studies have revealed that neural-network-based policies can be easily fooled by adversarial examples. However, while most prior works analyze the effects of perturbing every pixel of every frame assuming white-box policy access, in this article, we take a more restrictive view toward adversary generation—with the goal of unveiling the limits of a model’s vulnerability. In particular, we explore minimalistic attacks by defining three key settings: 1) Black-Box Policy Access: where the attacker only has access to the input (state) and output (action probability) of an RL policy; 2) Fractional-State Adversary: where only several pixels are perturbed, with the extreme case being a single-pixel adversary; and 3) Tactically Chanced Attack: where only significant frames are tactically chosen to be attacked. We formulate the adversarial attack by accommodating the three key settings, and explore their potency on six Atari games by examining four fully trained state-of-the-art policies. In Breakout, for example, we surprisingly find that: 1) all policies showcase significant performance degradation by merely modifying 0.01% of the input state and 2) the policy trained by DQN is totally deceived by perturbing only 1% frames.},
  keywords={Optimization;Neural networks;Games;Perturbation methods;Learning (artificial intelligence);Analytical models;Reinforcement learning;Generative adversarial networks;Adversarial attack;reinforcement learning (RL)},
  doi={10.1109/TCDS.2020.2974509},
  ISSN={2379-8939},
  month={Dec},}@INPROCEEDINGS{9844459,
  author={Zeng, Deyi},
  booktitle={2022 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)}, 
  title={Anomaly Detection by Unsupervised Adversarial Generative Self-labelling Autoencoder}, 
  year={2022},
  volume={},
  number={},
  pages={1012-1021},
  abstract={Conventionally, autoencoder is applied to unsupervised anomaly detection but suffers from over-lapping distributions between reconstruction errors of normal and anomalous samples, which is also known as lack of learnability, as the autoencoder does not know the characteristic difference between normal and anomalous samples (autoencoder is trained on the normal samples, without any anomalous samples). Recently, the generative adversarial network is proposed, provided as another method instead of the autoencoder. However, the training process is time-consuming and unstable compared to the autoencoder. We propose an unsupervised adversarial generative self-labeling autoencoder (AGSA), optimizing the discriminator and autoencoder by adversarial training, and integrating the supervised learning into unsupervised learning: The discriminator evolves by including pseudo-labeled samples for training, then the autoencoder is required to decorate itself such that the reconstructed samples by the autoencoder score high in the discriminator, therefore resembling the normal samples and avoiding being similar to anomalous ones. In this case, reconstruction errors of anomalous samples are maximized and that of normal ones are minimized, compared to the previous autoencoder. Therefore, the overlapping part is lessened, and we are safe and confident to self-label more samples for training discriminators. An adversarial cycle is formed. AGSA replaces the conventional decision criteria using an anomaly score which highly relies on the prior knowledge of the dataset and is sensitive to the extreme and noisy samples of the dataset, with a well-trained discriminator which is less affected by the extreme and noisy samples. Transfer learning is used for constructing the discriminator for accelerating the training and avoid overfitting. AGSA has been applied to the clouds dataset and marble dataset, achieving satisfying results.},
  keywords={Training;Conferences;Transfer learning;Supervised learning;Computer applications;Generative adversarial networks;Noise measurement;Anomaly Detection;Adversarial Training;Self-Labelling;Autoencoder},
  doi={10.1109/ICAICA54878.2022.9844459},
  ISSN={},
  month={June},}@INPROCEEDINGS{8802975,
  author={Chen, Zerui and Huang, Yan and Wang, Liang},
  booktitle={2019 IEEE International Conference on Image Processing (ICIP)}, 
  title={Augmented Visual-Semantic Embeddings for Image and Sentence Matching}, 
  year={2019},
  volume={},
  number={},
  pages={290-294},
  abstract={The task of image and sentence matching has witnessed significant progress recently, but it is still challenging arising from the tremendous semantic gap between a pixel-level image and its matched sentences. Due to limited training data, it is rather challenging to optimize the visual-semantic embeddings. In this work, we propose to augment visual-semantic embeddings via enlarging the training dataset. With more data, models can learn discriminative features with high-quality semantic concepts. More specifically, we augment data by generating sentences for given images. Our method consists of two steps. At first, to enlarge the training dataset, given an image, we perform image captioning. Instead of introducing redundancy to our augmented dataset, we hope that our generated sentences are in diverse style and maintain its fidelity at the same time. Therefore, we consult to generative adversarial networks (GANs) which can produce more flexible expressions compared to methods based on the maximum likelihood principle. Then, we augment visual-semantic embeddings with the augmented training dataset and obtain the model for the task of image and sentence matching. Experiments on the popular benchmark demonstrate the effectiveness of our method by achieving superior results compared to our baseline.},
  keywords={Task analysis;Training;Semantics;Generators;Feature extraction;Training data;Data models;Generative Adversarial Networks;Image and Sentence Matching;Visual-Semantic Embeddings},
  doi={10.1109/ICIP.2019.8802975},
  ISSN={2381-8549},
  month={Sep.},}@ARTICLE{9762888,
  author={Liu, Yang and Gao, Xinbo and Han, Jungong and Shao, Ling},
  journal={IEEE Transactions on Cybernetics}, 
  title={A Discriminative Cross-Aligned Variational Autoencoder for Zero-Shot Learning}, 
  year={2023},
  volume={53},
  number={6},
  pages={3794-3805},
  abstract={Zero-shot learning (ZSL) aims to classify unseen samples based on the relationship between the learned visual features and semantic features. Traditional ZSL methods typically capture the underlying multimodal data structures by learning an embedding function between the visual space and the semantic space with the Euclidean metric. However, these models suffer from the hubness problem and domain bias problem, which leads to unsatisfactory performance, especially in the generalized ZSL (GZSL) task. To tackle such a problem, we formulate a discriminative cross-aligned variational autoencoder (DCA-VAE) for ZSL. The proposed model effectively utilizes a modified cross-modal-alignment variational autoencoder (VAE) to transform both visual features and semantic features obtained by the discriminative cosine metric into latent features. The key to our method is that we collect principal discriminative information from visual and semantic features to construct latent features which contain the discriminative multimodal information associated with unseen samples. Finally, the proposed model DCA-VAE is validated on six benchmarks including the large dataset ImageNet, and several experimental results demonstrate the superiority of DCA-VAE over most existing embedding or generative ZSL models on the standard ZSL and the more realistic GZSL tasks.},
  keywords={Visualization;Semantics;Task analysis;Training;Solid modeling;Prototypes;Generative adversarial networks;Autoencoder;cosine;discriminative;latent;zero-shot learning (ZSL)},
  doi={10.1109/TCYB.2022.3164142},
  ISSN={2168-2275},
  month={June},}@INPROCEEDINGS{10021011,
  author={Javaid, Uzair and Li, Zhen and Aman, Muhammad Naveed and Shao, Dongxu and Yee, Kevin and Sikdar, Biplab},
  booktitle={2022 IEEE International Conference on Big Data (Big Data)}, 
  title={Blockchain based Secure Group Data Collaboration in Cloud with Differentially Private Synthetic Data and Trusted Execution Environment}, 
  year={2022},
  volume={},
  number={},
  pages={3919-3927},
  abstract={Data collaboration with cloud technologies is becoming more popular for personal use as well as business applications. Due to the increasing data protection regulations worldwide, different cryptographic techniques have been designed to enable secure data sharing for a user or a group of users. Although, these techniques have seen enterprise adoption, they fail to offer data visibility as data remains encrypted throughout the data sharing routine. This is why these techniques fail to offer a key features to data users, e.g., joining different datasets together and sharing it with all the users involved. This paper presents a blockchain based architecture for secure data collaboration in cloud using differentially private synthetic data and trusted execution environment (TEE). The proposed solution protects data confidentiality and integrity with TEEs, supports public-key infrastructure (PKI) with blockchain, and prevents privacy leakages with synthetic data. The results show that our synthetic data performs as good as real data and demonstrates how different users can securely aggregate their datasets and openly share among themselves.},
  keywords={Collaboration;Public key;Data protection;Big Data;Data aggregation;Generative adversarial networks;Regulation;Synthetic Data;Blockchain;Trusted Execution Environment (TEE);Generative Adversarial Network (GAN)},
  doi={10.1109/BigData55660.2022.10021011},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10692837,
  author={Norizan, Azir Rezha and Mohamad Zamri, Mohamad Farid},
  booktitle={2024 International Visualization, Informatics and Technology Conference (IVIT)}, 
  title={Visual Generative AI Tools Acceptance by Multimedia and Animation University Students}, 
  year={2024},
  volume={},
  number={},
  pages={101-107},
  abstract={This study investigates the factors influencing multimedia and animation students’ behavioral intention regarding visual generative AI tools, using a modified Unified Theory of Acceptance and Use of Technology 2 (UTAUT2) model. The significance of the study resembles the need to look into potential for adopting AI image, video or animation generative tools in related industry trends. This research is pivotal in ensuring that the integration of AI technologies into these sectors is both effective and beneficial. The findings reveal that performance expectancy, effort expectancy, facilitating condition, hedonic motivation, and personal innovativeness significantly positively impact students' behavioral intentions to adopt these tools. In contrast, social influence, perceived risk, price value, and habit do not significantly influence their intentions. Additionally, a strong relationship between behavioral intention and actual use behavior underscores the importance of fostering positive student’s intentions to drive technology adoption. These results provide theoretical insights and practical implications for developers and marketers to enhance the design, functionality, and promotional strategies of visual generative AI tools.},
  keywords={Industries;Visualization;Generative AI;Streaming media;Animation;Market research;Informatics;Visual generative AI;UTAUT2;students’ acceptance},
  doi={10.1109/IVIT62102.2024.10692837},
  ISSN={},
  month={Aug},}@ARTICLE{11007552,
  author={Xie, Gaochang and Xiong, Zehui and Xie, Renchao and Deng, Xiumei and Guo, Song and Guizani, Mohsen and Han, Zhu},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Mixture of Experts-Enabled Parallel Scheduling and Processing for Vehicular Generative AI Services}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Foundation models (FMs) have revolutionized generative AI (GAI) lifecycle with their pre-trained intelligence capabilities. While the recent success of web-based models like GPT-4 has spurred interest in extending FMs to edge scenarios like the Internet of Vehicles (IoV), challenges such as data privacy, network congestion, and limited edge resource awareness hinder the direct application of cloud-based FMs. To address these challenges, this paper reconfigures the mixture of experts (MoE) architecture to deploy Transformer-based FM experts across vehicles for distributed GAI inference. Specifically, we propose an MoE-empowered vehicular FM system with two key innovations: a physical gating network that dynamically adapts to wireless environments, and a vehicle-to-vehicle (V2V) communication-based expert parallelism mechanism to enhance efficiency and resource utilization. Then, we formulate the communication, computation, and memory models for analyzing inference latency. Furthermore, to optimize the computational resource allocation for enhancing inference performance, we establish a Stackelberg game and propose the Gradient Ascent and Evolutionary Optimization-based Competitive Pricing and Allocation (GECPA) algorithm, which balances resource allocation and usage costs by combining the rapid convergence of gradient ascent with the broader exploration capability of evolutionary optimization. Simulation results demonstrate the superior parallel processing efficiency and reduced latency of the proposed MoE-based FM inference scheme. Compared with the best-performing benchmark algorithm, GECPA improves the average utility of infrastructure vehicles by up to 2.01 times, reduces inference latency by 16.58%, and increases the successful execution rate of GAI tasks by 10.66%, thereby achieving a better balance between efficiency and incentive compatibility in dynamic IoV environments.},
  keywords={Frequency modulation;Parallel processing;Resource management;Computer architecture;Computational modeling;Training;Collaboration;Cloud computing;Adaptation models;Artificial intelligence;Generative AI (GAI);mixture of experts (MoE);resource allocation;Internet of Vehicles (IoV);foundation models (FMs);expert parallelism},
  doi={10.1109/TCCN.2025.3571753},
  ISSN={2332-7731},
  month={},}
