@INBOOK{10954797,
  author={Tabrizi, Rogayeh},
  booktitle={Behavioral AI: Unleash Decision Making with Data}, 
  title={Real&#x2010;World Impact}, 
  year={2025},
  volume={},
  number={},
  pages={95-135},
  abstract={Summary <p>This chapter aims to bridge the gap between theoretical understanding and practical application, showing how artificial intelligence (AI) and machine learning (ML) can transform abstract concepts into real&#x2010;world solutions. Through a series of real&#x2010;world examples and case studies, we will discover how predictive models, enriched with behavioral insights, can uncover hidden patterns in data, enhance decision&#x2010;making, and create substantial value. From optimizing supply chains and improving customer experiences to predicting consumer preferences, the stories in the chapter will highlight the transformative potential of AI and ML. It shows how the ideas we've explored come to life, offering a clear road map for leveraging these technologies to achieve strategic objectives. The chapter aims to illuminate the diverse applications of AI and ML models, showcasing how they can be strategically leveraged to drive efficiencies, generate revenue, and de&#x2010;risk critical decisions.</p>},
  keywords={Artificial intelligence;Biological system modeling;Technological innovation;Predictive models;Organizations;Generative AI;Transforms;Social networking (online);Industries;Data models},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394196845},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10954797},}@ARTICLE{10322868,
  author={Arif, Rahat Maqsood and Aslam, Muhammad and Al-Otaibi, Shaha and Martinez-Enriquez, Ana Maria and Saba, Tanzila and Bahaj, Saeed Ali and Rehman, Amjad},
  journal={IEEE Access}, 
  title={A Deep Reinforcement Learning Framework to Evade Black-Box Machine Learning Based IoT Malware Detectors Using GAN-Generated Influential Features}, 
  year={2023},
  volume={11},
  number={},
  pages={133717-133729},
  abstract={In the internet of things (IoT) networks, machine learning (ML) is significantly used for malware and adversary detection. Recently, research has shown that adversarial attacks have put ML-based models at risk. This problem is exacerbated in an IoT environment because of the absence of adequate security measures. Consequently, it is crucial to evaluate the strength of such malware detectors using powerful adversarial samples. The existing adversarial sample generation strategies either rely on high-level image features or an unfiltered feature set, making it challenging to determine which feature modifications are crucial in evading malware detection systems, without compromising the malware functionality. This encourages us to propose an evasion framework named IF-MalEvade, based on Generative Adversarial Network (GAN) and Deep Reinforcement Learning (DRL) that effectively generates fully-working, malware samples with several effective perturbations such as header Section manipulation and benign bytes insertion. The DRL framework selects a few suitable action sequences to change malicious samples, thus allowing our malware samples to bypass various black-box ML based malware detectors and the detection search engines of VirusTotal, while maintaining the executability and malicious behavior of the original malware samples. The neural networks of GAN take in the unfiltered feature set of malware dataset and using minimax objective function yields a set of useful features that are subsequently used by the DRL agent to make effective changes. Experimental results illustrated that by utilizing the influential features in sequence of transformations, the adversarial samples generated by our model outperformed the state-of-the-art evasion models with an impressive evasion rate. Additionally, the detection rate of well-known machine learning models was also brought down to up to 97%. Furthermore, when the machine learning models were retrained using adversarial samples, a 35% increase in detection accuracy was observed.},
  keywords={Malware;Generative adversarial networks;Detectors;Feature extraction;Closed box;Internet of Things;Reinforcement learning;Generative adversarial network;portable executable PE malware;adversarial attack;malware evasion;deep reinforcement learning;technological development},
  doi={10.1109/ACCESS.2023.3334645},
  ISSN={2169-3536},
  month={},}@ARTICLE{9893785,
  author={Din, Nizam Ud and Bae, Seho and Javed, Kamran and Park, Hyunkyu and Yi, Juneho},
  journal={IEEE Access}, 
  title={Cross Modal Facial Image Synthesis Using a Collaborative Bidirectional Style Transfer Network}, 
  year={2022},
  volume={10},
  number={},
  pages={99077-99087},
  abstract={In this paper, we present a novel collaborative bidirectional style transfer network based on generative adversarial network (GAN) for cross modal facial image synthesis, possibly with large modality gap. We think that representation decomposed into content and style can be effectively exploited for cross modal facial image synthesis. However, we have observed that unidirectional application of decomposed representation based style transfer in case of large modality gap does not work well for this purpose. Unlike existing image synthesis methods that typically formulate image synthesis as an unidirectional feed forward mapping, our network utilizes mutual interaction between two opposite mappings in a collaborative way to address complex image synthesis problem with large modality gap. The proposed bidirectional network aligns shape content from two modalities and exchanges their appearance styles using feature maps of the layers in the encoder space. This allows us to effectively retain the shape content and transfer style details for synthesizing each modality. Focusing on facial images, we consider facial photo, sketch, and color-coded semantic segmentation as different modalities. The bidirectional synthesis results for the pairs of these modalities show the effectiveness of the proposed approach. We further apply our network to style-content manipulation to generate multiple photo images with various appearance styles for a same content shape. The proposed method can be adopted for solving other cross modal image synthesis tasks. The dataset and source code are available at https://github.com/kamranjaved/Bidirectional-style-transfer-network.},
  keywords={Image synthesis;Image segmentation;Face recognition;Generative adversarial networks;Bidirectional control;Collaborative work;Generative adversarial network;image synthesis;unidirectional style transfer network;bidirectional style transfer network;collaborative learning},
  doi={10.1109/ACCESS.2022.3207288},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10413675,
  author={Tanurhan, Y. and Paulin, P. and Michiels, T.},
  booktitle={2023 International Electron Devices Meeting (IEDM)}, 
  title={Generative AI on a Budget: Processing Transformer- based Neural Networks at the Edge}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={In this paper, we explore the emerging trends in generative AI and the role of transformer-based neural networks at their core. We investigate the distinct attributes of transformers and how they diverge from conventional convolutional neural networks (CNNs). The paper underscores that CNN-optimized hardware accelerators do not effectively scale for transformers. We introduce the NPX6 neural processing unit (NPU) and demonstrate its efficient handling and optimization of transformer-based models.},
  keywords={Generative AI;Navigation;Neural networks;Transformer cores;Transformers;Market research;Optimization},
  doi={10.1109/IEDM45741.2023.10413675},
  ISSN={2156-017X},
  month={Dec},}@INPROCEEDINGS{10770919,
  author={Jadhav, Suraj G. and Sarnikar, Surendra},
  booktitle={2024 Conference on AI, Science, Engineering, and Technology (AIxSET)}, 
  title={Deriving Strategic Insights from Earnings Calls: Leveraging Human Experts, AI-Based Search, and Generative AI for Synthesis and Summarization}, 
  year={2024},
  volume={},
  number={},
  pages={290-293},
  abstract={Earnings transcript analyses have historically been processed manually and often augmented with AI techniques for natural language processing. Advances in Generative AI open up further opportunities for insights. Instead of looking in silos, we propose an integrated methodology that leverages human expertise, AI-based search, and Gen AI to improve the speed, accuracy, and relevance of insights along with enhanced explainability of Gen AI summaries. Our proposed methodology can augment executives with insights for informed decision-making in their business environment.},
  keywords={Productivity;Accuracy;Uncertainty;Generative AI;Social networking (online);Navigation;Soft sensors;Decision making;Natural language processing;Business;earnings calls;LLM;AI;financial disclosures},
  doi={10.1109/AIxSET62544.2024.00031},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11088064,
  author={Grover, Lovdeep and Gupta, Vikas},
  booktitle={2025 Seventh International Conference on Computational Intelligence andCommunication Technologies (CCICT)}, 
  title={A Review and Research Challenge analysis of Artificial Intelligence based Solar Irradiance Forecasting Model with Swot Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={7-14},
  abstract={Meeting the fast-growing need of energy is paramount; therefore, solar energy can contribute to playing a very important role in reducing greenhouse gas emissions. Solar radiation depends on several factors such as the availability of sunlight, cloud cover, and panel orientation, so it is the key to a solar energy system. Proper prediction of solar irradiance allows better reliability and efficiency of the system. AI and machine learning models, which are trained by use of historical data on weather, are increasingly applied for this purpose using techniques such as regression, neural networks, and ensemble methods. This paper presents a review of the state-of-the- art models for solar irradiance forecasting, covering machine learning, numerical weather prediction, and hybrid approaches, by assessing their accuracy, strengths, and weaknesses. It also delineates the prospective future development possibilities while enunciating the role of interdisciplinary collaboration and technology in merging solar power into the main electricity system. Therefore, this work is going to be a core analysis for future researchers in finding optimum methods leading into medium- and long-term solar irradiance forecasting.},
  keywords={Solar irradiance;Renewable energy sources;Reviews;Neural networks;Weather forecasting;Predictive models;Numerical models;Solar radiation;Reliability;Forecasting;Renewable energy;Solar irradiance;Artificial intelligence;Machine learning;Prediction},
  doi={10.1109/CCICT65753.2025.00012},
  ISSN={},
  month={April},}@INPROCEEDINGS{10826068,
  author={Pawlicka, Aleksandra and Pawlicki, Marek and Jaroszewska-Choraś, Dagmara and Puchalski, Damian and Kozik, Rafał and Choraś, Michał},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={When an Old Telecommunication Law Meets Generative AI: the Manifesto to Unbundle AI}, 
  year={2024},
  volume={},
  number={},
  pages={5872-5875},
  abstract={The emergence and consecutive entrance of Generative AI (particularly ChatGPT) into the mainstream has provoked all kinds of reactions, from excitement to apprehension, but it has not been definitely decided whether it is a boon or a bane yet. We wish to voice the still unmentioned relation between AI accessibility and social injustice. So far, the initial access to tools such as ChatGPT has been free or low-cost. This is predicated on the availability of open-source or inexpensively sourced data. As the value of models hinges upon high quality, diverse data, the demand for it will increase, resulting in the rising costs of its procuration. We worry that the free models will then turn into expensive commodities, limiting their use only to the privileged entities. This potential shift causes major concerns about ethics and social equity, with the concept of unbundling being one of the potential solutions.},
  keywords={Ethics;Limiting;Costs;Generative AI;Fasteners;Big Data;Chatbots;Data models;Communications technology;AI;AI Act;ChatGPT;equity;ethics;LLM},
  doi={10.1109/BigData62323.2024.10826068},
  ISSN={2573-2978},
  month={Dec},}@ARTICLE{10547576,
  author={De, Suman and Mitra, Pabitra},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={A Novel Technique of Synthetic Data Generation for Asset Administration Shells in Industry 4.0 Scenarios}, 
  year={2024},
  volume={5},
  number={10},
  pages={5258-5266},
  abstract={Manufacturing plants are highly dependent on machines and involve a significant number of equipment to produce a finished product. Industry 4.0 helps structure the processes involved in such setups and enables the functionalities of how the equipment and machines interact with each other. With the advancement of visualizing these types of equipment as digital twins, multiple opportunities have developed for automating processes and optimizing various aspects of the assembly, especially for original equipment manufacturers (OEMs). One problem that concerns a network of manufacturers is the availability of equipment and spare parts data which are sometimes confidential but are required by a new member in the network for several analytical applications. This article looks at this problem statement to turn this into an opportunity by introducing a novel concept of AASGAN that combines the knowledge representation of a digital twin data in the asset administration shell (AAS) and a synthetic data generation technique of generative adversarial network (GAN) to generate fake data that is identical to real data. This article also explains how this concept helps perform analytical operations using industry grade solutions for the automotive industry available for managing digital twins and other scenarios for industrial automation.},
  keywords={Digital twins;Generative adversarial networks;Synthetic data;Fourth Industrial Revolution;Industrial engineering;Context;Convolutional neural networks;Knowledge management;Knowledge representation;Agent-based simulation;artificial intelligence (AI) in industrial engineering;context analysis;convolutional neural networks;knowledge management;knowledge representation},
  doi={10.1109/TAI.2024.3409516},
  ISSN={2691-4581},
  month={Oct},}@INPROCEEDINGS{10606560,
  author={Dong, Shuang and Jin, Huaiping and Wang, Bin and Yang, Biao and Liu, Haipeng},
  booktitle={2024 IEEE 13th Data Driven Control and Learning Systems Conference (DDCLS)}, 
  title={Soft Sensor Method based on Quality-related Virtual Sample Generation and Sample-weighted Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1318-1324},
  abstract={In process industry, data-driven soft sensor often faces the problem of data shortage in modeling due to factors such as high cost of label samples acquisition and high data repetition rate. The virtual sample generation (VSG) method has been proposed for data augmentation to solve the above problems. Most of the conventional generative models cannot generate virtual samples with labeled data, at the same time, previous data augmentation methods have ignored the quality differences of the generated virtual samples themselves. Thus, this paper proposes a soft sensor method based on quality-related virtual sample generation and sample-weighted learning (QRVSG-SWL). Firstly, this method combines the respective advantages of variational autoencoder (VAE) and generative adversarial network (GAN) to generate labeled virtual samples. Secondly, a prediction model is constructed using virtual samples to calculate the prediction accuracy and distribution differences on real labeled data. Then, sample similarity calculation under supervised latent structures.is performed. Finally, model learns virtual sample weights. The effectiveness of the proposed method is validated by the industrial chlortetracycline (CTC) fermentation process.},
  keywords={Learning systems;Industries;Accuracy;Soft sensors;Predictive models;Generative adversarial networks;Linear programming;Soft sensor;Virtual sample generation;Sample-weighted learning;Supervised variational autoencoder;Data augmentation},
  doi={10.1109/DDCLS61622.2024.10606560},
  ISSN={2767-9861},
  month={May},}@INPROCEEDINGS{9925840,
  author={Xie, Yibing and Gardi, Alessandro and Sabatini, Roberto},
  booktitle={2022 IEEE/AIAA 41st Digital Avionics Systems Conference (DASC)}, 
  title={Cybersecurity Trends in Low-Altitude Air Traffic Management}, 
  year={2022},
  volume={},
  number={},
  pages={1-9},
  abstract={Cybersecurity is a well-recognised issue in the aviation system but effective protection measures have not been implemented yet. Moreover, Artificial Intelligence (AI) algorithms and autonomous technologies are driving innovation, especially with Unmanned Aircraft Systems (UAS)-based commercial transportation methods, which implies the need for enhanced capabilities in critical infrastructures such as Communication, Navigation and Surveillance (CNS), as well as ground networks. Cybercrime is, therefore, seriously threatening the safety of traditional ATM and future UAS Traffic Management (UTM). These threats have gradually evolved from traditional invasion methods to AI-based techniques. Further uptake of AI technologies in aviation is bound to increase the complexity and interdependence of CNS/ATM systems, resulting in an increase in the attack surface. Therefore, it is necessary to address both existing and emerging cyber threats by exploiting AI algorithms and developing adequate defences. This paper analyses a number of cybersecurity issues that are potentially encountered in ATM and UTM systems. The various possible threat agents and threat targets are categorised based on goals, motivations and capabilities. Additionally, the possible attack and corresponding defence methods based on traditional and AI-based techniques are introduced and discussed.},
  keywords={Wireless communication;Transportation;Aerospace electronics;Aircraft navigation;Complexity theory;Air traffic control;Artificial intelligence;Cybersecurity;ATM;UTM;UAS network;Cyber-attacks;Communication;Navigation;Surveillance},
  doi={10.1109/DASC55683.2022.9925840},
  ISSN={2155-7209},
  month={Sep.},}@INPROCEEDINGS{10286608,
  author={Daiyrbayeva, Elmira and Yerimbetova, Aigerim and Maratov, Zhanbolat and Sakenov, Bakzhan},
  booktitle={2023 8th International Conference on Computer Science and Engineering (UBMK)}, 
  title={Information Hiding in Images Using Neural Network}, 
  year={2023},
  volume={},
  number={},
  pages={444-448},
  abstract={This research work is very relevant in the field of image processing using artificial intelligence techniques. In today's world where information security plays an important role, developing methods to detect and analyze hidden data in images is a necessity. The aim of the research is to investigate and develop image processing methods using artificial intelligence techniques to improve the accuracy and efficiency of image processing. This may include creating new neural network models, exploring different data preprocessing techniques, optimizing computational processes and exploring the use of generative models for image synthesis and enhancement. During the experiment, it was proved that, as a result of training the neural network, the values of the loss function decreases during the training process, which in turn means improvements in the model. The model was trained in the Kaggle service.},
  keywords={Training;Computer science;Steganography;Computational modeling;Neural networks;Computer architecture;Speech recognition;steganography;image;neural network;secret message},
  doi={10.1109/UBMK59864.2023.10286608},
  ISSN={2521-1641},
  month={Sep.},}@INPROCEEDINGS{10860208,
  author={Jiao, Hongwei},
  booktitle={2024 International Conference on Integrated Intelligence and Communication Systems (ICIICS)}, 
  title={Evaluation of Sustainable Utilization of Urban Land Resources based on DensN et20 1 and Inception Version 3}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Recent days, urbanization is developed tremendously that providing economic growth and accesses to markets, entrepreneurship and industries. This Urban development leverages land resources in creating booming cities with diverse industries, institutions, and transportation infrastructure. As these constructions are increasing it is also very important to evaluate the urban land resources for flexible future generation's capability to happen their personal needs. The existing methods in evaluation failed in modeling temporary alteration in urban land use and development. Therefore, this paper proposes DensNet201-InceptionVersion 3 (V3) for efficient evaluation of sustain ability of urban land resources. The proposed method employed on deep globe land cover classification dataset that incorporates various land cover classes' satellite images. The collected image data is preprocessed using min max scaling for normalizing all images pixel values into similar ranges. This preprocessed data optimal features are extracted using DensNet201. The obtained relevant features are classified using Inception V3for evaluating the utilization of urban land resources are sustainable or not. The proposed DensNet201-InceptionV3 achieved better results in terms of accuracy of (99.82%), Specificity of (99.45%), Sensitivity of (99.73%), and Recall of (99.76%) when compared with existing Artificial Neural Network (ANN).},
  keywords={Industries;Sensitivity;Accuracy;Urban areas;Land surface;Artificial neural networks;Feature extraction;Satellite images;Data mining;Water resources;artificial neural network;densnet201;inception version 3;urban land resources;transportation infrastructure},
  doi={10.1109/ICIICS63763.2024.10860208},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10896065,
  author={Tong, Yuqi and Qiu, Yue and Li, Ruiyang and Qiu, Shi and Heng, Pheng-Ann},
  booktitle={2025 IEEE International Conference on Artificial Intelligence and eXtended and Virtual Reality (AIxVR)}, 
  title={MS2Mesh-XR: Multi-Modal Sketch-to-Mesh Generation in XR Environments}, 
  year={2025},
  volume={},
  number={},
  pages={272-276},
  abstract={We present MS2Mesh-XR, a novel multimodal sketch-to-mesh generation pipeline that enables users to create realistic 3D objects in extended reality (XR) environments using hand-drawn sketches assisted by voice inputs. In specific, users can intuitively sketch objects using natural hand movements in mid-air within a virtual environment. By integrating voice inputs, we devise ControlNet to infer realistic images based on the drawn sketches and interpreted text prompts. Users can then review and select their preferred image, which is subsequently reconstructed into a detailed 3D mesh using the Convolutional Reconstruction Model. In particular, our proposed pipeline can generate a high-quality 3D mesh in less than 20 seconds, allowing for immersive visualization and manipulation in runtime XR scenes. We demonstrate the practicability of our pipeline through two use cases in XR settings. By leveraging natural user inputs and cutting-edge generative AI capabilities, our approach can significantly facilitate XR-based creative production and enhance user experiences. Our code and demo will be available at: https://yueqiu0911.github.io/MS2Mesh-XR/.},
  keywords={Convolutional codes;Solid modeling;Visualization;Adaptation models;Three-dimensional displays;Generative AI;Pipelines;Virtual environments;Real-time systems;Image reconstruction},
  doi={10.1109/AIxVR63409.2025.00052},
  ISSN={2771-7453},
  month={Jan},}@ARTICLE{10916629,
  author={Park, Jae H. and Madisetti, Vijay K.},
  journal={IEEE Access}, 
  title={CAPRI: A Context-Aware Privacy Framework for Multi-Agent Generative AI Applications}, 
  year={2025},
  volume={13},
  number={},
  pages={43168-43177},
  abstract={While the swift advancement of cloud-based Large Language Models (LLMs) has significantly increased the efficiency and automation in business processes, it has also introduced considerable privacy concerns regarding Personally Identifiable Information (PII) and other protected data in multimodal forms, such as text, video, or images, being exported, potentially insecurely, outside the corporate environments. Although traditional anonymization-based techniques can alleviate these risks in offline applications, such as summarization or classification, incorporating it into online LLM workflows poses substantial challenges, particularly when these workflows encompass real-time transactions involving multiple stakeholders, as commonly observed in multi-agent generative AI applications. This study explores these challenges and proposes novel context-aware privacy frameworks and methods to address these issues. We employ a local privacy-focused gatekeeper LLM to contextually pseudonymize PII and assign unique identifiers as part of a new mapping process, thereby facilitating re-identification in real-time operations while safeguarding privacy when interacting with cloud-based LLMs. Our proposed methodologies and frameworks adeptly integrate privacy considerations into LLM and LLM Agent workflows, preserving both privacy and data utility while maintaining operational efficiency and utility comparable to non-anonymized generative AI processes.},
  keywords={Data privacy;Synthetic data;Privacy;Identification of persons;Generative AI;Cognition;Real-time systems;Semantics;Logic gates;Large language models;Generative AI (Gen AI);large language model (LLM);pseudonymization},
  doi={10.1109/ACCESS.2025.3549312},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10849458,
  author={Shen, Jiyang and Wei, Tianlan and Cao, Cong},
  booktitle={2024 IEEE 36th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Stable Discrete Segmented Reverse Diffusion Model for Solving Class Imbalance in Malicious Websites Detection}, 
  year={2024},
  volume={},
  number={},
  pages={556-563},
  abstract={In order to address the class imbalance issue experienced during training for malicious website detection, we developed a deep generative model based on the diffusion model that was able to generate the features of malicious websites. The use of the binary encoder method effectively solved the problem experienced with traditional diffusion models, which are unable to generate the discrete and integer features of malicious websites. Moreover, we modified the reverse diffusion algorithm so that, in the final step of the reverse diffusion process, the original data was restored by predicting the noise rather than by sampling the original data distribution through calculating mean and variance. This method enhanced the stability of the features generated and improved their quality.},
  keywords={Training;Impedance matching;Noise;Focusing;Learning (artificial intelligence);Diffusion models;Sampling methods;Prediction algorithms;Feature extraction;Stability analysis;generative model;diffusion model;discrete data;class imbalance;machine learning;deep learning},
  doi={10.1109/ICTAI62512.2024.00084},
  ISSN={2375-0197},
  month={Oct},}@INPROCEEDINGS{10432913,
  author={Lohaj, Oliver and Paralič, Ján and Kushnir, Daria and Vanko, Jakub Ivan},
  booktitle={2024 IEEE 22nd World Symposium on Applied Machine Intelligence and Informatics (SAMI)}, 
  title={Usability of a synthetically generated dataset for decision support}, 
  year={2024},
  volume={},
  number={},
  pages={000435-000440},
  abstract={This article deals mainly with the issue of usability of a synthetically generated data set. The work focuses on providing a brief overview of synthesizing medical data and presenting suitable methods for evaluating their quality. The work is divided into a theoretical and a practical part, where the theoretical part contains basic concepts, methods and metrics, and the practical part deals with the generation of synthetic data and their qualitative evaluation. One of the most suitable methods for generating synthetic data is the GAN (Generative Adversarial Network) method. We used the CTGAN model for generating synthetic data set from electronic health records. We have evaluated the generated synthetic data with various metrics, like accuracy of models trained on synthetic data, similarity with original data and security of synthetic data. The accuracy of models trained on synthetic data decreased a bit, e.g., from 0.9444 to 0.8704 with Random Forest classifier, in comparison with the original data. The similarity value reached 0.9044, but all the rows in synthetic data were new and none match the original data set, which is important in case of anonymization patients’ data. We also received a resulting privacy value for two model situations of 0.9988 and 0.6507 resp., which show that data has some level of privacy, but it can be improved. The CTGAN method was deemed usable.},
  keywords={Measurement;Data privacy;Medical services;Generative adversarial networks;Data models;Usability;Synthetic data;usability;synthetic medical data generation;GAN;CTGAN;SDV},
  doi={10.1109/SAMI60510.2024.10432913},
  ISSN={2767-9438},
  month={Jan},}@INPROCEEDINGS{10810245,
  author={Song, Yaodong},
  booktitle={2024 5th International Symposium on Computer Engineering and Intelligent Communications (ISCEIC)}, 
  title={Research on Unsupervised Adaptive Semantic Segmentation based on “Template” and “Paint” Generative Model}, 
  year={2024},
  volume={},
  number={},
  pages={327-330},
  abstract={In unsupervised domain adaptive semantic segmentation, the lack of labeled data in the target domain is a common challenge. The traditional method generates a composite image in the style of the target domain by generating the joint distribution of the source domain and the target domain by generating the model, but the problems of poor sample quality and high training cost still exist. Therefore, this paper proposes a new generation strategy, which takes the label data in the source domain as a “template” and the generated data as a “paint”, and colors different object categories in the label data in the target domain style, and generates image data with the target domain style and consistent with the source domain labels. This method can improve the performance of the segmentation model while maintaining the quality of the generated samples, and significantly reduce the consumption of training time and computing resources. Experimental results show that the proposed method has achieved significant improvement in the semantic segmentation task of the target domain, and shows good robustness and generalization ability.},
  keywords={Training;Adaptation models;Costs;Image color analysis;Computational modeling;Semantic segmentation;Data models;Robustness;Labeling;Paints;Unsupervised domain adaptation;Semantic segmentation;Generative models;Label template coloring},
  doi={10.1109/ISCEIC63613.2024.10810245},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10738994,
  author={Soni, Arpita and Arora, Rajeev and Kumar, Anoop and Panwar, Dheerendra},
  booktitle={2024 International Conference on Electrical Electronics and Computing Technologies (ICEECT)}, 
  title={Evaluating Domain Coverage in Low-Resource Generative Chatbots: A Comparative Study of Open-Domain and Closed-Domain Approaches Using BLEU Scores}, 
  year={2024},
  volume={1},
  number={},
  pages={1-6},
  abstract={Chatbots employ Natural Language Processing (NLP) and Artificial Intelligence (AI) to conduct automated chats and provide online assistance to users. Chatbots fall into two categories—generative models and retrieval models. E-commerce is the main application for retrieval-based chatbots—which provide pre-programmed responses and are easy to use with controlled interactions. While generative-based chatbots are more appropriate for research applications—they are more difficult to train and maintain. This is because they produce unique responses based on large conversational datasets. Therefore, in order to establish whether open-domain or closed-domain techniques work better—this study examines the domain coverage of low-resource generative chatbots. We compare their performance using Bilingual Evaluation Understudy (BLEU) scores in different domains to determine which method performs better.},
  keywords={Computers;Chatbots;Electronic commerce;Artificial intelligence;artificial intelligence;chatbots;generative;low-resource;natural language processing},
  doi={10.1109/ICEECT61758.2024.10738994},
  ISSN={},
  month={Aug},}@ARTICLE{10810272,
  author={Jiang, Yuhua and Gao, Feifei and Jin, Shi and Jun Cui, Tie},
  journal={IEEE Transactions on Wireless Communications}, 
  title={Electromagnetic Property Sensing Based on Diffusion Model in ISAC System}, 
  year={2025},
  volume={24},
  number={3},
  pages={2036-2051},
  abstract={Integrated sensing and communications (ISAC) has opened up numerous game-changing opportunities for future wireless systems. In this paper, we develop a novel ISAC scheme that utilizes the diffusion model to sense the electromagnetic (EM) property of the target in a predetermined sensing area. Specifically, we first estimate the sensing channel by using both the communications and the sensing signals echoed back from the target. Then we employ the diffusion model to generate the point cloud that represents the target and thus enables 3D visualization of the target’s EM property distribution. In order to minimize the mean Chamfer distance (MCD) between the ground truth and the estimated point clouds, we further design the communications and sensing beamforming matrices under the constraint of a maximum transmit power and a minimum communications achievable rate for each user equipment (UE). Simulation results demonstrate the efficacy of the proposed method in achieving high-quality reconstruction of the target’s shape, relative permittivity, and conductivity. Besides, the proposed method can sense the EM property of the target effectively in any position of the sensing area.},
  keywords={Integrated sensing and communication;Diffusion models;Artificial intelligence;Three-dimensional displays;Vectors;Point cloud compression;Covariance matrices;Array signal processing;Shape;Receiving antennas;Electromagnetic (EM) property sensing;integrated sensing and communications (ISAC);diffusion model;generative artificial intelligence (GAI)},
  doi={10.1109/TWC.2024.3516008},
  ISSN={1558-2248},
  month={March},}@INPROCEEDINGS{10241865,
  author={Lu, Yifan and Zhang, Maochun and Huang, Wenxuan and Guan, Shouqin},
  booktitle={2023 IEEE 18th Conference on Industrial Electronics and Applications (ICIEA)}, 
  title={Digitalizing the Dress-up Experience: An Exploration of Virtual Try-On for Traditional Chinese Costume}, 
  year={2023},
  volume={},
  number={},
  pages={495-500},
  abstract={With the recent rapid developments in artificial intelligence (AI) technology, virtual try-on technology empowered by generative approaches has reached a level of maturity that is ripe for commercialization. However, the application of virtual try-on technology to traditional cultural costumes has not received adequate attention from research institutions and enterprises. To address this research gap, we present a novel virtual try-on system for traditional Chinese costume that incorporates diverse AI technologies, including generative models, pose estimation, human parsing, and image processing algorithms, to provide an accurate and immersive virtual try-on experience. In particular, we leverage five distinct techniques Human Keypoint Detection, Human Parsing, Densepose Parts Segmentation, Cloth Mask Extraction, and Clothing-Agnostic Representation - to realize a web service that can effectively handle the specific challenges of traditional Chinese costume, such as the need to preserve cultural authenticity and ensure accurate fit and drape. Finally, we conduct various experiments to evaluate the system’s performance and have received positive feedback from users, indicating that it provides a realistic and engaging virtual try-on experience. Our work contributes to the growing body of research on virtual try-on technology and has the potential to impact the way traditional cultural costumes are designed, marketed, and worn.},
  keywords={Industries;Image segmentation;Solid modeling;Web services;Synthesizers;Clothing;Pose estimation;Virtual Try-on;Generative Model;Chinese Traditional Cultural Costume},
  doi={10.1109/ICIEA58696.2023.10241865},
  ISSN={2158-2297},
  month={Aug},}@INPROCEEDINGS{9641530,
  author={Lakshminarayanan, Meenakshi and John, Neha Sara and Channegowda, Janamejaya and Raj, Aditya and Naaz, Falak},
  booktitle={2021 IEEE Mysore Sub Section International Conference (MysuruCon)}, 
  title={Devising High Fidelity Synthetic Data using Generative Adversarial Networks for Energy Storage Systems}, 
  year={2021},
  volume={},
  number={},
  pages={202-205},
  abstract={Artificial Intelligence (AI) has revolutionized technology in the recent past. AI in the energy sector has proven to be of great importance at forecasting energy loads in power systems and predicting state of charge in batteries. Although ample improvements have been made in the energy sector, access to experimental battery datasets has hampered progress. This has resulted in restricted improvement of machine learning models. This paper aims to provide guidelines to produce high fidelity battery parameter data using Generative Adversarial Networks (GANs). This approach was used to produce synthetic data using the NASA Prognostic Data Repository and smartphone battery dataset. Discriminative and predictive scores of 0.0422, 0.0703 and 0.0638, 0.1427 were obtained for the smartphone charge dataset and NASA Prognostic dataset respectively.},
  keywords={IEEE Sections;NASA;Neural networks;Training data;Machine learning;Generative adversarial networks;Batteries;Battery;Energy Storage System;Synthetic Data;Neural Networks},
  doi={10.1109/MysuruCon52639.2021.9641530},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10467765,
  author={Pillai, Mukesh and Thakur, Pallavi},
  booktitle={2024 2nd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)}, 
  title={Developing a Website to Analyze and Validate Projects Using LangChain and Streamlit}, 
  year={2024},
  volume={},
  number={},
  pages={1493-1501},
  abstract={This research study provides a new approach to project analysis and validation through the creation of a website using LangChain, a framework for building applications powered by Language Models, and Streamlit which is used to create LLM powered and Generative AI web applications quickly. In an era of rapid technological change, the necessity for effective project assessment tools has become increasingly crucial. The goal of this research is to overcome this obstacle by utilizing LangChain's natural language processing and understanding capabilities. The proposed website serves as a basic platform for project validation, making it easier to assess project feasibility, technical requirements, and work allocation. It serves as a starting point for developing a comprehensive system. The features of LangChain allow for the extraction of valuable insights from project data, technology, and team experience, resulting in a more automated and intelligent decision-making process. The developed website encompasses two main functionalities: individual and team project validation and task allocation. For individual projects, users can input project details and technologies, and their resume after which LangChain processes the information to determine feasibility and generate technical specifications based on the assessment of their resume. On the other hand, the team task allocation feature, utilizes LangChain to analyze frontend and backend specifications, and project requirements to intelligently allocate tasks based on team's experience level.},
  keywords={Technical requirements;Prototypes;Feature extraction;Software;Natural language processing;Resource management;Time factors;LangChain;Streamlit;Project Analysis;Validation;Task Allocation;Feasibility Analysis;Large Language Mode (LLM)l;Generative Artificial Intelligence (AI)},
  doi={10.1109/IDCIoT59759.2024.10467765},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10967799,
  author={Sarada, Ch. and Mallika, S. Suguna and Swetha, G. and Lakshmi, K Vijaya and Swathi, P.},
  booktitle={2025 International Conference on Machine Learning and Autonomous Systems (ICMLAS)}, 
  title={Brain Tumor Detection Developments: Analysis of Deep Learning and Hybrid Model Approaches}, 
  year={2025},
  volume={},
  number={},
  pages={68-75},
  abstract={Brain Tumor detection remains a difficult task in Medical Imaging. Recent developments in deep learning techniques, mainly Convolutional Neural Networks and hybrid models have significantly enhanced the correctness and competence of Tumor classification, segmentation and detection. This study presents a complete review of leading-edge studies focused on Brain Tumor detection with an emphasis on deep learning models and hybrid methodologies. The review includes a variety of approaches such as convolutional neural network (CNN), Capsule Networks, Generative Adversarial Networks, hybrid Convolutional Neural Network - Support Vector Machine (CNN-SVM) and Convolutional Neural Network, and RNN stands for Recurrent Neural Network(CNN-RNN) models. These techniques have demonstrated remarkable success in overcoming challenges such as data scarcity, computational complexity and multi-class Tumor classification. In addition to discussing the methodologies employed in these models, their advantages, limitations and detection accuracy are analysed. Finally, we highlight the emerging trends in AI -based Tumor detection and provide directions for future research aimed at improving diagnostic performance and clinical applicability.},
  keywords={Deep learning;Analytical models;Accuracy;Reviews;Computational modeling;Brain tumors;Brain modeling;Generative adversarial networks;Hybrid power systems;Convolutional neural networks;Convolutional neural network (CNN);Capsule Networks;Generative Adversarial Networks;hybrid CNN-SV;CNN-RNN},
  doi={10.1109/ICMLAS64557.2025.10967799},
  ISSN={},
  month={March},}@INPROCEEDINGS{10148198,
  author={Hou, Xiangdan and Song, Jinlin and Liu, Hongpu},
  booktitle={2022 4th International Conference on Intelligent Information Processing (IIP)}, 
  title={Unpaired Image-To-Image Translation Using Generative Adversarial Networks With Coordinate Attention Loss}, 
  year={2022},
  volume={},
  number={},
  pages={68-76},
  abstract={Image stylization is an important research direction in image processing, graphics, and computer vision. At present, methods based on deep learning, especially generative adversarial network, have made great progress in image stylization migration. However, there are several limitations to the current mainstream methods, the biggest of which is the inability to perform geometry changes, remove large objects, or ignore irrelevant textures in unpaired scenarios. This paper proposes a style transfer algorithm CAGAN based on Adversarial Consistency Loss Generative Adversarial Network and Coordinate Attention. The stylized transfer of high perceptual quality in mismatched scenes is achieved by combating consistency loss and attention mechanism, and the Laplacian noise module is added to generate multi-modal output. Through a lot of experiments, it is verified that the algorithm can achieve high quality stylization effect.},
  keywords={Graphics;Geometry;Deep learning;Computer vision;Adaptation models;Laplace equations;Image processing;Image stylization;attention mechanisms;convolutional layers;generative adversarial networks;multimodal output},
  doi={10.1109/IIP57348.2022.00021},
  ISSN={},
  month={Oct},}@ARTICLE{9229197,
  author={Wang, Chaoyue and Xu, Chang and Tao, Dacheng},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Self-Supervised Pose Adaptation for Cross-Domain Image Animation}, 
  year={2020},
  volume={1},
  number={1},
  pages={34-46},
  abstract={Image animation is to animate a still image of the object of interest using poses extracted from another video sequence. Through training on a large-scale video dataset, most existing approaches aim to explore disentangled appearance and pose representations of training frames. Then, the desired output with a specific appearance and pose can be synthesized via recombining learned representations. However, in some real-world applications, test images may lack the corresponding video ground-truth or follow a different distribution than the distribution of the training video frames (i.e., different domains), which largely limit the performance of existing methods. In this paper, we propose domain-independent pose representations that are compatible with and accessible by still images from a different domain. Specifically, we devise a two-stage self-supervised pose adaptation framework for general image animation tasks. A domain-independent pose adaptation generative adversarial network (DIPA-GAN) and a shuffle-patch generative adversarial network (Shuffle-patch GAN) are proposed to penalize the rationality of the synthesized frame's pose and appearance, respectively. Finally, experiments evaluated on various image animation tasks, which include same/cross-domain moving objects, facial expression transfer and human pose retargeting, demonstrate the superiority of the proposed framework over prior literature. Impact Statement—Image animation is a popular technology in video production. Benefiting from the rapid development of artificial intelligence (AI), recent image animation algorithms have been widely used in real-world applications, such as virtual AI news anchor, virtual try-on, and face swapping. However, most existing methods are designed for specific cases. To animate a new portrait, users are asked to collect hundreds of images of the same person and train a new model. The technology proposed in this paper overcomes these training limitations and generalizes image animations. In the challenging cross-domain facial expression transfer task, the user study demonstrated that our technology achieved more than 20% increase in animation success rate. The proposed technology could benefit users in a wide variety of industries including movie production, virtual reality, social media and online retail.},
  keywords={Animation;Task analysis;Training;Generative adversarial networks;Artificial intelligence;Solid modeling;Adaptation models;Adversarial learning;deep learning;representation learning},
  doi={10.1109/TAI.2020.3031581},
  ISSN={2691-4581},
  month={Aug},}@ARTICLE{10829636,
  author={Zhong, Yue and Kang, Jiawen and Wen, Jinbo and Ye, Dongdong and Nie, Jiangtian and Niyato, Dusit and Gao, Xiaozheng and Xie, Shengli},
  journal={IEEE Transactions on Mobile Computing}, 
  title={Generative Diffusion-Based Contract Design for Efficient AI Twin Migration in Vehicular Embodied AI Networks}, 
  year={2025},
  volume={24},
  number={5},
  pages={4573-4588},
  abstract={Embodied Artificial Intelligence (AI) bridges the cyberspace and the physical space, driving advancements in autonomous systems like the Vehicular Embodied AI NETwork (VEANET). VEANET integrates advanced AI capabilities into vehicular systems to enhance autonomous operations and decision-making. Embodied agents, such as Autonomous Vehicles (AVs), are autonomous entities that can perceive their environment and take actions to achieve specific goals, actively interacting with the physical world. Embodied Agent Twins (EATs) are digital models of these embodied agents, with various Embodied Agent AI Twins (EAATs) for intelligent applications in cyberspace. In VEANETs, EAATs act as in-vehicle AI assistants to perform diverse tasks supporting autonomous driving using generative AI models. Due to limited onboard computational resources, AVs offload EAATs to nearby RoadSide Units (RSUs). However, the mobility of AVs and limited RSU coverage necessitates dynamic migrations of EAATs, posing challenges in selecting suitable RSUs under information asymmetry. To address this, we construct a multi-dimensional contract theoretical model between AVs and alternative RSUs. Considering that AVs may exhibit irrational behavior, we utilize prospect theory instead of expected utility theory to model the actual utilities of AVs. Finally, we employ a Generative Diffusion Model (GDM)-based algorithm to identify the optimal contract designs, thus enhancing the efficiency of EAAT migrations. Numerical results demonstrate the superior efficiency of the proposed GDM-based scheme in facilitating EAAT migrations compared with traditional deep reinforcement learning methods.},
  keywords={Artificial intelligence;Contracts;Real-time systems;Decision making;Vehicle dynamics;Solid modeling;Computational modeling;Adaptation models;Navigation;Diffusion models;Vehicular embodied AI;multi-dimensional contract theory;generative diffusion model;prospect theory},
  doi={10.1109/TMC.2025.3526230},
  ISSN={1558-0660},
  month={May},}@INPROCEEDINGS{10911649,
  author={Bharati, P. Vijaya},
  booktitle={2024 IEEE 4th International Conference on ICT in Business Industry & Government (ICTBIG)}, 
  title={A Hybrid Approach for Denoising and Recognition of Handwritten Characters Using Deblur GAN-CNN}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Handwritten Character Recognition (HCR) is a critical area of research within pattern recognition and artificial intelligence, with applications spanning from document digitization, optical character recognition (OCR), and handwriting analysis. Despite significant technological advancements, accurate recognition of handwritten characters remains challenging due to variations in writing styles, sizes, and inherent distortions.This paper presents a novel approach to HCR, utilizing a combination of Deblur Generative Adversarial Networks (GAN) and Convolutional Neural Networks (CNN) to effectively address these challenges. Unlike traditional deblurring methods, which often introduce artifacts or blur the edges of characters, Deblur GAN is specifically trained to enhance the clarity of handwritten images while preserving essential character features. This allows the subsequent CNN to extract more accurate and discriminative features, leading to improved character recognition.Through extensive experimentation on benchmark datasets such as MNIST, an approach that significantly outperforms the existing methods is demonstrated in terms of recognition accuracy, particularly in scenarios involving blurred or indistinct handwriting. These findings highlight the potential of integrating deblurring techniques with deep learning models to address persistent challenges in handwritten character recognition, paving the way for enhanced automation and efficiency in text analysis tasks.},
  keywords={Deep learning;Handwriting recognition;Accuracy;Text analysis;Optical character recognition;Writing;Generative adversarial networks;Feature extraction;Character recognition;Convolutional neural networks;Handwritten character recognition (HCR);CNN;GAN;DeblurGAN-CNN;Deep Learning},
  doi={10.1109/ICTBIG64922.2024.10911649},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10465124,
  author={Swindell, Jonathan E. and Egbert, Austin and Goad, Adam C. and Haug, Sam and Latham, Casey and Ozalas, Matthew and Howard, Andy and McClearnon, Daren and Baylis, Charles and Marks II, Robert J.},
  booktitle={2024 United States National Committee of URSI National Radio Science Meeting (USNC-URSI NRSM)}, 
  title={Multi-Dimensional Image Completion for Automated Power Amplifier Design}, 
  year={2024},
  volume={},
  number={},
  pages={259-259},
  abstract={Widely used methods to characterize maximum power, efficiency, or linear performance for power amplifiers require many iterative impedance measurements. This cumbersome process has been simplified by applying a Wasserstein Generative Adversarial Network (WGAN) Image Completion network trained for load-pull extrapolation (A. Egbert, C. Baylis, and R. J. Marks, “Extrapolation of Load-Pull Data: A Novel Use of GAN Artificial Intelligence Image Completion,” IEEE Transactions on Microwave Theory and Techniques, vol. 70, no. 11, pp. 4849–4856, Nov. 2022). In this work, randomly generated linear S-parameters were used to train a model that could predict the load reflection coefficients for both linear and nonlinear devices with a median optimal error below 0.1. The Smith Chart can be extended into a 3rd dimension and is called a Smith Tube, which can be used to illustrate device characteristics' dependencies on additional design variables aside from impedance. This presentation considers possible approaches and expected challenges of extending this work to multidimensional characterization using the Smith Tube.},
  keywords={Microwave measurement;Extrapolation;Power amplifiers;Predictive models;Generative adversarial networks;Microwave theory and techniques;Electron tubes},
  doi={10.23919/USNC-URSINRSM60317.2024.10465124},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{11065719,
  author={Xiao, Kaile and Chen, Guang and Sun, ZhiYuan and Zhao, Haiyan},
  booktitle={2025 5th International Symposium on Computer Technology and Information Science (ISCTIS)}, 
  title={Dynamic Resource Allocation and Energy Consumption Optimization Strategy in Edge Intelligent Networks Based on GANs}, 
  year={2025},
  volume={},
  number={},
  pages={584-587},
  abstract={With the rapid development of the Internet of Things and artificial intelligence technology, edge intelligent networks have been widely applied in many fields, and their resource allocation and energy consumption optimization have become key issues. This article aims to meet energy constraints and minimize latency by introducing Generative Adversarial Networks (GANs). The generator generates task offloading and resource allocation schemes based on the network state, and the discriminator judges the quality of the schemes. Through adversarial training of the two, continuous optimization of resource allocation schemes is achieved. The experimental results show that compared to traditional algorithms, the algorithm proposed in this paper has significant advantages in resource utilization and system energy consumption, and can effectively improve the resource allocation performance of edge intelligent networks.},
  keywords={Training;Intelligent networks;Energy consumption;Information science;Heuristic algorithms;Generative adversarial networks;Dynamic scheduling;Resource management;Internet of Things;Optimization;Edge intelligent network;GAN;Dynamic allocation of resources;Energy consumption optimization},
  doi={10.1109/ISCTIS65944.2025.11065719},
  ISSN={},
  month={May},}@INPROCEEDINGS{11086327,
  author={Puyalnithi, Thendral and S, Prasanna Venkatesh and L V, Timothy Florian},
  booktitle={2025 Second International Conference on Cognitive Robotics and Intelligent Systems (ICC - ROBINS)}, 
  title={Transformer-Induced Generative Adversarial Network with Adaptive Learning for One-to-One Voice Conversion}, 
  year={2025},
  volume={},
  number={},
  pages={43-49},
  abstract={Voice conversion is a rapidly evolving field in speech synthesis, with applications in automated dubbing, speech- tosinging transformation, and personalized voice assistants. This research proposes a novel voice conversion framework that integrates adaptive learning with transformer-induced mechanisms in a Generative Adversarial Network (GAN)-based architecture. The Transformer-Induced GAN for Voice Conversion (TI-GAN- VC) enhances feature learning and voice similarity through a dense residual network structure and adaptive learning mechanisms. Experimental evaluations on the CMU Arctic and VCC 2018 datasets demonstrate significant improvements in naturalness and speaker similarity compared to the existing approaches.},
  keywords={Training;Adaptive learning;Adaptation models;Adaptive systems;Vocoders;Transformers;Generative adversarial networks;Speech;Optimization;Standards;Adaptive Learning;Transformer;CycleGAN-VC;Voice Conversion (VC)},
  doi={10.1109/ICC-ROBINS64345.2025.11086327},
  ISSN={},
  month={June},}@INPROCEEDINGS{10205695,
  author={Cahyadi, Michael and Rafi, Muhammad and Shan, William and Lucky, Henry and Moniaga, Jurike V.},
  booktitle={2023 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT)}, 
  title={Accuracy and Fidelity Comparison of Luna and DALL-E 2 Diffusion-Based Image Generation Systems}, 
  year={2023},
  volume={},
  number={},
  pages={108-112},
  abstract={Image generation system is a system which generates images using prompts in form of text. Due to the large-scale use of automatic image generation, mainly diffusion-based systems, there needs to be an evaluation regarding the output quality generated. We conduct a qualitative analysis of the accuracy and fidelity of two image generation systems, DALL-E 2 and Luna, which differ greatly in their training datasets, algorithms, prompt handling, and output scaling. We employ a qualitative benchmarking methodology and find that DALL-E 2 outperforms Luna significantly in terms of both alignment and fidelity.},
  keywords={Training;Ethics;Image synthesis;Image edge detection;Companies;Benchmark testing;Data models;diffusion-based image generation;DALL-E;Luna;accuracy;fidelity},
  doi={10.1109/IAICT59002.2023.10205695},
  ISSN={2834-8249},
  month={July},}@INPROCEEDINGS{10934475,
  author={Peng, Xue and Han, Yan},
  booktitle={2025 International Conference on Intelligent Systems and Computational Networks (ICISCN)}, 
  title={Quality Evaluation of Ideological and Political Education for College Students based on Artificial Neural Networks}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={From past few years, assessing and evaluating quality of college students Ideological and Political Education (IPE) played a vital role by enabling educators to pinpoint areas for improvement and gauge the effectiveness of education by enhancing student learning outcomes. Traditional approaches for evaluating political and ideological education had faced several challenges which include inability to handle complex data and lack of real-time assessment. Therefore, this research proposes Artificial Neural Networks (ANN) for evaluating political and ideological education. Initially, evaluation system is developed for IPE by integrating multitask learning and softmax regression for ensuring accurate assessments. Then, ANN is designed for evaluating IPE by learning complex relationships between input variables and output predictions. These ANN gave comprehensive evaluation output based on various criterions like educational effectiveness, campus style, and social reputation by providing robust assessment of IPE. The proposed ANN attained better results in terms of Mean Percentage Error Ratio MPER (90%) when compared with existing Radial Basis Function Neural Network (RBFNN).},
  keywords={Accuracy;Input variables;Education;Artificial neural networks;Radial basis function networks;Learning (artificial intelligence);Computer architecture;Real-time systems;Blockchains;Intelligent systems;artificial neural network;ideological and political education;multitask learning;quality evaluation;softmax regression},
  doi={10.1109/ICISCN64258.2025.10934475},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10899728,
  author={Mohammed, Roshan and Rezvy, Shahadate},
  booktitle={2024 7th International Conference on Algorithms, Computing and Artificial Intelligence (ACAI)}, 
  title={Transparent Ransomware Detection in Bitcoin Transactions: Leveraging Machine Learning and Explainable AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Ransomware presents a significant threat within the Bitcoin ecosystem, necessitating robust detection methods. This study leverages machine learning techniques, particularly Random Forest Model, to identify ransomware activities in Bitcoin transactions using the BitcoinHeist dataset. We integrate explainable AI (XAI) tools, specifically LIME, to enhance model transparency and provide insights into predictions. Innovative feature engineering techniques are employed to capture critical transaction patterns, such as loops and volume changes, which improve detection accuracy. Our ensemble models achieve high performance metrics, including accuracy, precision, recall, and ROC-AUC scores. The use of XAI mitigates challenges like false positives and adapts to evolving ransomware tactics by elucidating the factors influencing model decisions. This research underscores the necessity of interpretability in ransomware detection systems, laying the groundwork for future studies focused on real-time detection and adaptive learning in cybersecurity.},
  keywords={Adaptation models;Adaptive learning;Accuracy;Explainable AI;Ecosystems;Bitcoin;Predictive models;Ransomware;Computer security;Random forests;Ransomware Detection;BitcoinHeist Dataset;Machine Learning;Cybersecurity;Explainable AI;Blockchain Analysis},
  doi={10.1109/ACAI63924.2024.10899728},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10986774,
  author={Salam, Ridha and J, Sahanna Rachel and Kumar B, Naveen and V, Ramachandra H and K, Sameeksha M and Madari, Vishwa},
  booktitle={2025 International Conference on Artificial Intelligence and Data Engineering (AIDE)}, 
  title={Survey Paper: Comparative Analysis of Detection Methods for Real vs. AI-Generated Images}, 
  year={2025},
  volume={},
  number={},
  pages={659-664},
  abstract={The rapid evolution of AI-generated image technologies, including GANs and diffusion models, has blurred the lines between real and synthetic content. In this survey, we explore state-of-the-art methods for detecting fake images. Traditional forensic techniques, deep learning approaches, and advanced methods like Explainable AI (XAI) and blockchain-based verification are used. We evaluate these methods using performance metrics and derive insights into their strengths and limitations. A comparative analysis of existing research papers is provided, examining the approaches used, feature extraction techniques, classifiers employed, and datasets utilized. Additionally, it puts forth actional research directions like diffusion models, multimodal analysis, and expansion of dataset that can contribute towards the advancement of this field. Practical examples and visualizations make this survey both insightful and tutorial-like, offering valuable guidance for researchers and practitioners.},
  keywords={Surveys;Deep learning;Explainable AI;Scalability;Transfer learning;Media;Feature extraction;Diffusion models;Robustness;Real-time systems;AI-generated images;Deep Learning;CNN;Transfer Learning;Ensemble Learning;LLM;Image Authentication;Feature Analysis},
  doi={10.1109/AIDE64228.2025.10986774},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{11108929,
  author={Lu, Shuang and Hu, Yuanfa and Jiang, Xiang},
  booktitle={2025 IEEE 5th International Conference on Software Engineering and Artificial Intelligence (SEAI)}, 
  title={Fusion of Reinforcement Learning and Residual Correction for Underwater Image Enhancement}, 
  year={2025},
  volume={},
  number={},
  pages={84-88},
  abstract={Underwater images often exhibit degradation problems, including color distortion, reduced contrast, and blurred details due to light absorption, scattering, and complex water conditions. These problems hinder the observation and analysis of underwater scenes. Conventional enhancement techniques often struggle to address the complexity of these degradations and rely on pairs of reference images. To overcome these limitations, we propose a new underwater image enhancement framework that uniquely incorporates reinforcement learning (RL) and residual correction mechanisms. By describing the enhancement process as a reinforcement learning task, our approach enables intelligent agents to dynamically adapt and optimize enhancement strategies. The intelligent agent uses perceptual, color, and residual features to guide its decision-making, and residual correction provides real-time feedback on the effectiveness of the enhancement. This integration not only enhances the adaptation of enhancement operations to different underwater environments but also improves visual quality and structural fidelity. Our approach does not require large amounts of paired training data and exhibits better performance compared to existing model-based and deep learning approaches.},
  keywords={Measurement;Degradation;Visualization;Adaptation models;Image color analysis;Atmospheric modeling;Reinforcement learning;Distortion;Intelligent agents;Image enhancement;Underwater image;image enhancement;reinforcement learning;residual correction},
  doi={10.1109/SEAI65851.2025.11108929},
  ISSN={},
  month={June},}@INPROCEEDINGS{11063852,
  author={Nayak, Ashu and Raghatate, Kapesh Subhash},
  booktitle={2025 3rd International Conference on Communication, Security, and Artificial Intelligence (ICCSAI)}, 
  title={Deep Learning in Autonomous Vehicles for Dynamic Decision-Making: Enhancing Safety and Navigation}, 
  year={2025},
  volume={3},
  number={},
  pages={497-501},
  abstract={Self-driving cars (SDCS) are beginning to selfdisrupt the transport industry through the guaranteed improvement of safety, speed, and comfort. However, the volatile and complex road conditions present great difficulties to the decision-making process of such systems. This research work outlines a new deep learning framework for real-time decision making for AVs that encompass perception, behavior prediction, path planning and control of motion. The described framework also utilizes modern methodologies, specifically, YOLOv5 to detect objects or events of interest, RNNs with attention models to predict the dynamic behavior, PPO with A* algorithms for path planning, and motion control. These are proved by comprehensive evaluation and analysis of applicability and scalability of the system in a variety of driving contexts such as urban traffic, rural roads, highways, and unfavorable weather conditions. The perception module was able to accomplish a detection accuracy of 96.4% further minimizing latency and the behavioral prediction module was 91.8% accurate in terms of trajectory prediction. Implementation of path planning for autonomous vehicles concluded that fuel efficiency and collision avoidance rates were on higher level in order to provide comfortable journey and safety to passengers. This study underlines the future of deep learning in AV systems with interactive, responsive, and safe operational decision making in real environments. Through identifying major milestones in navigation and safety, this work advances the subsequent generation of AV solutions to formulate their societal utility.},
  keywords={Deep learning;Accuracy;Navigation;Roads;Decision making;Dynamics;Real-time systems;Safety;Vehicle dynamics;Autonomous vehicles;Autonomous vehicles;deep learning;dynamic decision-making;YOLOv5;trajectory prediction;path planning;motion control;reinforcement learning;safety;real-time navigation},
  doi={10.1109/ICCSAI64074.2025.11063852},
  ISSN={},
  month={April},}@INPROCEEDINGS{11166041,
  author={Robinson, Rachel John},
  booktitle={2025 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)}, 
  title={The Prompt culture in Generative AI for Active Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Academic writing is an important part of scholarly development and a key opportunity to practice scientific, critical thinking. Among its types such as seminar papers, term papers, case studies, and project reports—essay writing stands out for its open-ended nature. These formats challenge students to apply their present knowledge to real-world or simulated scenarios, often without a clearly defined path to a solution. This ambiguity showcases professional environments, where complete information is rarely available. With the advent of AI systems like Gemini, Copilot and ChatGPT, the landscape of academic writing has shifted. Unlike traditional programming, these applications allow users to issue instructions in natural language, making them more accessible collaborators. However, to use them effectively, users must learn to craft clear and purposeful prompts. This paper introduces the BITE approach—Behavioral instructions, Interaction modeling, Task elaboration, and External context—as a practical framework for writing effective and uncomplicated prompts. Prompts in the GPT world are instructions in natural language. We do not have to learn programming-specific syntax to get the machine to do something but can speak to it more or less in the same way as we would speak to a human collaborator. The BITE method supports active learning by encouraging students to engage critically with AI applications/tools during their writing process. Preliminary testing show that applying BITE leads to more coherent and desirable outputs and improved writing efficiency compared to unstructured prompting strategies used in both academic and industry settings.},
  keywords={Seminars;Adaptation models;Active learning;Natural languages;Writing;Syntactics;Search engines;Chatbots;Artificial intelligence;Testing;Academic writing;AI systems;natural language prompts;BITE approach;Active Learning},
  doi={10.1109/ACDSA65407.2025.11166041},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10835685,
  author={Zhu, Yujin and Geng, Yang and Gong, Tiantian and Chen, Chen},
  booktitle={2024 3rd International Conference on Data Analytics, Computing and Artificial Intelligence (ICDACAI)}, 
  title={Simulating Electric Vehicle Impact on Power Grids—A Comparative Analysis of Modeling Approaches}, 
  year={2024},
  volume={},
  number={},
  pages={578-582},
  abstract={The advent of electric vehicles (EVs) promises a greener alternative to fossil fuel-dependent transportation but introduces new challenges to power grid stability due to their unique demand characteristics. As the penetration rate of EVs accelerates, understanding their impact on power grids becomes crucial. This paper presents a comparative analysis of different modeling approaches for simulating the impact of EVs on power grids. Through this analysis, we aim to highlight the significance of robust simulation models in evaluating grid responses to EV charging demands, exploring demand response strategies, and facilitating vehicle-to-grid integration. The comparison spans several modeling techniques, from traditional steady-state analyses to dynamic agent-based models, providing insights into their applicability, strengths, and limitations in capturing the complexities of EV-grid interactions.},
  keywords={Analytical models;Vehicle-to-grid;Transportation;Power system stability;Power grids;Stability analysis;Steady-state;Vehicle dynamics;Sustainable development;Resilience;Electric Vehicles;Power Grids;Simulation;Modeling;Demand Response;Vehicle-to-Grid Integration},
  doi={10.1109/ICDACAI65086.2024.00111},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10708059,
  author={Song, Meng and Song, Xuan and Qin, Kunwen},
  booktitle={2024 3rd International Conference on Artificial Intelligence and Autonomous Robot Systems (AIARS)}, 
  title={Signal Detection and Demodulation Algorithm Based on Deep Learning in Communication Network}, 
  year={2024},
  volume={},
  number={},
  pages={461-466},
  abstract={With the continuous development of communication network, the demand for signal detection and demodulation algorithms is increasing. Traditional methods based on feature engineering and model often face performance bottlenecks in complex communication environments. In recent years, the rapid development of deep learning technology provides new possibilities for solving this problem. In this paper, a signal detection and demodulation algorithm based on deep learning is proposed. By constructing an end-to-end neural network model, the automatic identification and demodulation of communication signals are realized. In the experiment, this paper compares the proposed deep learning model with the traditional support vector machine (SVM), Gaussian mixture model (GMM) and maximum likelihood estimation (MLE) methods, and evaluates the performance under various modulation formats and signal-to-noise ratios. The experimental results show that the proposed deep learning model has obvious advantages in accuracy and generalization ability, and has higher performance and faster convergence speed than the traditional methods. In addition, through error analysis, this paper further discusses the performance of deep learning model in misjudgment, missed judgment and multiple judgment, and puts forward the possible improvement direction and application prospect. Therefore, this study provides a new idea and method for the research and application of signal detection and demodulation algorithm based on deep learning in communication networks.},
  keywords={Deep learning;Support vector machines;Maximum likelihood estimation;Accuracy;Error analysis;Signal processing algorithms;Data models;Communication networks;Signal detection;Demodulation;Deep learning;Signal detection;demodulation;communication network},
  doi={10.1109/AIARS63200.2024.00091},
  ISSN={},
  month={July},}@ARTICLE{9707604,
  author={Srinivasan, Vignesh and Müller, Klaus-Robert and Samek, Wojciech and Nakajima, Shinichi},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Langevin Cooling for Unsupervised Domain Translation}, 
  year={2023},
  volume={34},
  number={10},
  pages={7675-7688},
  abstract={Domain translation is the task of finding correspondence between two domains. Several deep neural network (DNN) models, e.g., CycleGAN and cross-lingual language models, have shown remarkable successes on this task under the unsupervised setting—the mappings between the domains are learned from two independent sets of training data in both domains (without paired samples). However, those methods typically do not perform well on a significant proportion of test samples. In this article, we hypothesize that many of such unsuccessful samples lie at the fringe—relatively low-density areas—of data distribution, where the DNN was not trained very well, and propose to perform the Langevin dynamics to bring such fringe samples toward high-density areas. We demonstrate qualitatively and quantitatively that our strategy, called Langevin cooling (L-Cool), enhances state-of-the-art methods in image translation and language translation tasks.},
  keywords={Task analysis;Cooling;Transformers;Superresolution;Perturbation methods;Manifolds;Training;Domain translation (DT);generative models;image-to-image translation;Langevin dynamics;language translation},
  doi={10.1109/TNNLS.2022.3145812},
  ISSN={2162-2388},
  month={Oct},}@INPROCEEDINGS{10475266,
  author={Ghaffari, Shervin and Yousefimehr, Behnam and Ghatee, Mehdi},
  booktitle={2024 20th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP)}, 
  title={Generative-AI in E-Commerce: Use-Cases and Implementations}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In recent years, the advancement of generative AI has profoundly influenced its application across various industries. One such industry is e-commerce where this technology can enhance both customer experience as well as merchants’ productivity and profitability. In this paper, our objective is to review some of the potential use cases of generative AI technology in different areas of an online store. Specifically, we will focus on the use cases of product description generation, sentiment analysis of product reviews, and product tagging and categorization. We utilize various prompt engineering techniques to suggest exemplary implementations of these applications using large language models (LLMs). Lastly, the paper will discuss the possible risks and challenges that come with using generative AI in these contexts.},
  keywords={Productivity;Industries;Sentiment analysis;Ethics;Reviews;Profitability;Tagging;product description;taxonomy;generative AI;large language models (LLMs);e-commerce;product reviews},
  doi={10.1109/AISP61396.2024.10475266},
  ISSN={2640-5768},
  month={Feb},}@ARTICLE{8964412,
  author={Gao, Yun and Liu, Xiaoyang and Xiang, Jiawei},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={FEM Simulation-Based Generative Adversarial Networks to Detect Bearing Faults}, 
  year={2020},
  volume={16},
  number={7},
  pages={4961-4971},
  abstract={Complete fault sample is essential to activate artificial intelligent (AI) models. A novel fault detection scheme is proposed to build a bridge between AI and real-world running mechanical systems. First, the finite element method simulation is used to simulate samples with different faults to overcome the shortcoming of missing fault samples. Second, to enlarge datasets, new samples similar to the simulation and measurement fault samples are generated by generative adversarial networks and further combined with the original simulation and measurement samples to obtain synthetic samples. Finally, the synthetic and unknown fault samples are severed as the training and test samples, respectively, to the classifiers of AI models, and the unknown fault types will be finally determined. A public datasets of bearings have been used to verify the effectiveness of the proposed scheme. It is expected that the proposed scheme can be extended to complex mechanical systems.},
  keywords={Finite element analysis;Artificial intelligence;Training;Mechanical systems;Gallium nitride;Generative adversarial networks;Fault detection;Bearings;detection;fault samples;finite element method (FEM);generative adversarial networks},
  doi={10.1109/TII.2020.2968370},
  ISSN={1941-0050},
  month={July},}@INPROCEEDINGS{8803540,
  author={Xu, Yucheng and Ning, Shiyu and Xie, Rong and Song, Li},
  booktitle={2019 IEEE International Conference on Image Processing (ICIP)}, 
  title={Gan Based Multi-Exposure Inverse Tone Mapping}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  abstract={High dynamic range (HDR) imaging provide larger range of luminosity and wider color gamut than conventional low dynamic range (LDR) imaging. The method which transforms LDR contents to HDR contents is called inverse tone mapping. After deep neural networks are used in inverse tone mapping problem, researchers mostly focus on transforming normal exposure LDR images to HDR. However, when people use inverse tone mapping in practice, they get some ill-exposed images as well. The state-of-art algorithms can't transform these images to HDR well.In this work, we propose an end-to-end multi-exposure inverse tone mapping (MITM) framework based on existing generative adversarial network (GAN). This framework can transform a single LDR image not only at normal exposure, but also at unsuitable exposure to a normal exposure HDR image. We use histogram equalization to preprocess the luma of the input LDR images; when training the model, we use intrinsic image decomposition to divide the output HDR images into illuminance and reflectance components and use these two components to constrain the luminance information and the color information separately. This framework can adjust the unsuitable exposure and provide a better viewing experience than other state-of-art algorithms in the experimental results.},
  keywords={Generators;Transforms;Image color analysis;Generative adversarial networks;Gallium nitride;Deep learning;Dynamic range;High dynamic range;inverse tone mapping;deep learning;generative adversarial network},
  doi={10.1109/ICIP.2019.8803540},
  ISSN={2381-8549},
  month={Sep.},}@INPROCEEDINGS{10915297,
  author={Chilupuri, Harshitha and Ramesh, G. and Praveen, J. and Gude, Venkataramaiah},
  booktitle={2025 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)}, 
  title={AI-Powered Advertisement Design: A PIL-Based Approach for Quality and Performance Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The paper presents the development of a Data Science solution that applies generative AI models in order to create high-quality images to be used in visual marketing and advertising. Using the Python library PIL (Pillow) along with machine learning frameworks, the solution combines predefined product images with the selected backgrounds, enhancing image synthesis techniques for more appealing and contextually relevant visuals. This leads to improved efficiency and effectiveness in the creation of content by automatically placing product images onto the background images used in marketing campaigns. The approach demonstrated a 98.06% SSIM (Structural similarity Index) score, indicating significant visual quality improvement. Initial results suggest a 15% enhancement in visual appeal compared to traditional image creation methods.},
  keywords={Visualization;Image transformation;Generative AI;Data science;Libraries;Performance analysis;Indexes;Advertising;Optimization;Python;generative ai;visual marketing;data science;pil (pillow);pandas;numpy;product image integration;background image blending;image processing;marketing content creation;ai-driven design;algorithm efficiency;digital marketing tools;content personalization;deep learning in advertising},
  doi={10.1109/IITCEE64140.2025.10915297},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9349409,
  author={Zhang, Zihao and Zhang, Huayan and Liu, Hui and Xin, Shan and Xiao, Ning and Zhang, Lei},
  booktitle={2021 International Conference on Computer, Control and Robotics (ICCCR)}, 
  title={Frontal Face Generation Based Multi-angle Face Identification System}, 
  year={2021},
  volume={},
  number={},
  pages={329-334},
  abstract={Precise identity recognition is a pre-condition for robots to enter the human living environment. Most of the existed face identification methods cannot work on the non-frontal face since the severe texture loss. In this paper, we propose a novel system to deal with multi-angle face identification in video sequence based on frontal face generation, which replaces the process of detection, alignment in the typical face identification system. To solve the problem of face texture loss in large pose variation, we creatively combine generative adversarial networks (GAN) with the state-of-the-art facial landmark localization method. The proposed system was tested on video database containing multi-angle faces, and the experimental results indicate that our system can recognize more faces in the frames, and improve the accuracy of identification for multi-angle face by 130%.},
  keywords={Location awareness;Databases;Face recognition;Video sequences;Two dimensional displays;Generative adversarial networks;Robots;face frontalization;face identification;image processing;generative adversarial network},
  doi={10.1109/ICCCR49711.2021.9349409},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10781923,
  author={Yang, Yulin and Liu, Jing and Chen, Qingqing and Li, Yinhao and Han, Xian-Hua and Hu, Hongjie and Lin, Lanfen and Chen, Yen-Wei},
  booktitle={2024 46th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}, 
  title={GANs-guided Conditional Diffusion Model for Synthesizing Contrast-enhanced Computed Tomography Images}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={In contrast to non-contrast computed tomography (NC-CT) scans, contrast-enhanced (CE) CT scans can highlight discrepancies between abnormal and normal areas, commonly used in clinical diagnosis of focal liver lesions. However, the use of contrast agents in CE-CT scans imposes significant physical and economic burdens on patients in clinical practice. Recently, Generative Adversarial Networks (GANs)-based synthesis models offer an alternative approach that obtains CE-CT images from NC-CT images. However, poor coverage and mode collapse greatly limit their performance. Diffusion models (DMs)-based methods have demonstrated superior performance in natural image synthesis tasks. Nevertheless, our experiment shows that CE-CT images synthesized from DMs-based method exhibit higher overall quality but lower local quality. The quality of local areas, particularly those related to lesion areas, is crucial in medical image synthesis tasks. Hence, we propose a GANs-guided conditional diffusion model (GANs-CDM), combining the GANs and conditional diffusion model (CDM), to generate CECT images. In the proposed GANs-CDM, the GANs is to generate a preliminary CE-CT image, serving as conditional input for guiding the subsequent CDM to produce refined CE-CT images. Qualitative and quantitative evaluation on arterial and portal venous phase synthesis tasks demonstrates that our proposed GANs-CDM can significantly improve both the local and global quality of synthetic images.},
  keywords={Economics;Image synthesis;Computed tomography;Biological system modeling;Liver;Diffusion models;Generative adversarial networks;Lesions;Portals;Medical diagnostic imaging;Generative Adversarial Networks;Conditional diffusion models;CE-CT image synthesis;GANs-CDM},
  doi={10.1109/EMBC53108.2024.10781923},
  ISSN={2694-0604},
  month={July},}@INPROCEEDINGS{10605975,
  author={Thakkar, Jinal Jagdishkumar and Kaur, Arashdeep},
  booktitle={2024 47th International Conference on Telecommunications and Signal Processing (TSP)}, 
  title={From Deepfakes to Digital Truths: The Role of Watermarking in AI-Generated Image Verification}, 
  year={2024},
  volume={},
  number={},
  pages={216-222},
  abstract={The evolution of Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) has introduced deepfake technology. Deepfake technology is a form of digital manipulation that alters video, image, and audio content with the help of Generative AI. Those deepfakes have increased concerns in various fields, including education, art, and they also raise ethical and security concerns due to their potential for deceptive content. Reviewing the increasing challenge of identifying high-quality deepfakes, there's a pressing need for robust measures to counter them. This review explores various watermarking techniques and their use to protect content authenticity and origin. Watermarking embeds a subtle watermark and provides a strong defense against deepfake technologies and similar AI-driven tools. The paper discusses current watermarking methods, their strengths and weaknesses, and potential improvements to verify AI-generated content.},
  keywords={Deepfakes;Ethics;Reviews;Watermarking;Pressing;Learning (artificial intelligence);Media;Artificial Intelligence;Content Authentication;Deepfake Detection;Digital Media Integrity;Digital Watermarking;Generative AI;Machine Learning},
  doi={10.1109/TSP63128.2024.10605975},
  ISSN={2768-3311},
  month={July},}@INPROCEEDINGS{10393958,
  author={Yan, Lan and Zheng, Wenbo and Li, Kenli},
  booktitle={2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={Where Characteristics Effect Night-to-Day Translation Performance?}, 
  year={2023},
  volume={},
  number={},
  pages={378-383},
  abstract={Inspired by the huge success of generative adversarial networks (GANs), GAN-based night-to-day translation methods have achieved excellent results. However, these methods have not been well visualized and understood, and thus cannot find the characteristics about their night-to-day translation performance. To this end, we present a simple clustering-based parsing approach to effectively understand the internal representations of the GAN-based night-to-day translator. In particular, we first cluster the internal representations of specific layers of the translator into a number of classes. Then, according to the proposed selection strategy, the class that has the most significant impact on the translation performance can be identified. Through experiments on three publicly available datasets, we find the answer of the question (title) is that the characteristics at the junction of bright and dark regions affect the performance of night-to-day translation.},
  keywords={Visualization;Generative adversarial networks;Junctions;Cybernetics;Clustering;night-to-day translation;generative adversarial networks},
  doi={10.1109/SMC53992.2023.10393958},
  ISSN={2577-1655},
  month={Oct},}@INPROCEEDINGS{11066056,
  author={Li, Zhichao and Shen, Mingxue and Tian, Li},
  booktitle={2025 IEEE 14th Data Driven Control and Learning Systems (DDCLS)}, 
  title={Bearing Fault Diagnosis for Imbalanced Data Based on Multi-Scale Data Generation and Ensemble Modeling}, 
  year={2025},
  volume={},
  number={},
  pages={1943-1948},
  abstract={Accurate fault diagnosis of bearings is of utmost importance, as bearings are crucial components in rotating machinery. Deep Learning (DL) has developed rapidly in recent years and is widely used in the field of fault diagnosis. The bearing fault diagnosis method based on DL needs a lot of fault data, but it is difficult to obtain in the actual engineering scene. This problem of data imbalance seriously affects the accuracy of fault diagnosis. To solve this problem, a bearing fault diagnosis model based on Multi-Scale Generative Adversarial Network (MSGAN) and Ensemble Convolutional Neural Network (ECNN) is proposed in this paper. Firstly, MSGAN is used to generate fault samples with different scale features and balance the corresponding scale feature samples. Then an ECNN fault diagnosis model is established to improve the diagnosis accuracy. During training, the model is able to learn features of different scales from samples. During training, the model is capable of learning features at different scales from the samples. During testing, it outputs classification results based on the average probability. The experimental results demonstrate that this method achieves high fault diagnosis accuracy under imbalanced conditions.},
  keywords={Fault diagnosis;Training;Vibrations;Learning systems;Accuracy;Generative adversarial networks;Data models;Convolutional neural networks;Machinery;Testing;Generative adversarial networks;Imbalance;Fault diagnosis;Ensemble Convolutional neural network},
  doi={10.1109/DDCLS66240.2025.11066056},
  ISSN={2767-9861},
  month={May},}@INPROCEEDINGS{10878693,
  author={Li, Jiayu and Zhao, Yunbo and Liu, Binkun},
  booktitle={2024 11th International Forum on Electrical Engineering and Automation (IFEEA)}, 
  title={Functional Evaluation for Printed Circuit Board Based on Surface Mount Technology Process Data}, 
  year={2024},
  volume={},
  number={},
  pages={18-21},
  abstract={Functional test strategy adjustment can save testing time and testing costs for companies. Since focusing on testing possible defective products can save a lot of testing time, a natural idea is to evaluate the functionality of the printed circuit boards (PCBs) based on surface mount technology (SMT) process data. Considering the important impact of electrical pathways on PCB functional evaluation, we propose a generative adversarial network method based on circuit layout (CL-GAN). Specifically, the generator is mainly composed of electrical node attribute feature extraction module and electrical connection feature extraction module. These modules are used to model the quality attributes of key nodes in PCB electrical pathways and model electrical connection relationships. The discriminator is trained to perform PCB functional evaluation. Experimental results demonstrate that CL-GAN achieves a 33.34% improvement in F1 score, along with a 96.64% reduction in testing time and a 64.77% decrease of total cost.},
  keywords={Costs;Layout;Surface mount technology;Feature extraction;Generative adversarial networks;Data models;Generators;Production facilities;Integrated circuit modeling;Testing;functional test;PCB;generative adversarial network},
  doi={10.1109/IFEEA64237.2024.10878693},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10890232,
  author={Wu, Jinfeng and Shi, Wu},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Improving GAN Performance Using Confidence-Aware Discrimination}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Generative Adversarial Networks (GAN) involve the competition between a generator and a discriminator. The large variance of training data can bring difficulty to GAN resulting in mode collapse, training instability and low quality. As the distribution of generated samples evolves, the discriminator will have different levels of confidence for its predictions. To mitigate these problems, we introduce confidence-aware discrimination (CAD) to guide the training and sampling of GANs. To adapt confidence estimation for GANs, we design a new architecture based on StyleGAN2, and propose a confidence-aware adversarial loss. Extensive experiments are conducted on face, scene and object generation benchmarks. In the training stage, CAD can progressively learn the training data with the guide of confidence estimation and lead to a better convergence. In the inference stage, the confidence score can provide a new dimension of metric to assess the quality of generated samples and can further improve the performance by resampling and finetuning.},
  keywords={Training;Measurement;Estimation;Training data;Signal processing;Generative adversarial networks;Linear programming;Generators;Speech processing;Faces;generative adversarial networks;uncertainty estimation;image generation;quality assessment},
  doi={10.1109/ICASSP49660.2025.10890232},
  ISSN={2379-190X},
  month={April},}@ARTICLE{11023537,
  author={Sangaiah, Arun Kumar and Anandakrishnan, Jayakrishnan and Kumar, Sujith and Bian, Gui-Bin and AlQahtani, Salman A. and Draheim, Dirk},
  journal={IEEE Internet of Things Journal}, 
  title={Point-KAN: Leveraging Trustworthy AI for Reliable 3D Point Cloud Completion With Kolmogorov Arnold Networks for 6G-IoT Applications}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={3D point clouds are data points defining the morphology of environments, and completion refers to the reconstruction of missing points. 6G Internet of Things (6G-IoT) connected with 3D mapping devices needs reliable, consistent, high-fidelity real-time point cloud completion for accurate environment registration. Trustworthy AI, modeled with dependable Deep Learning (DL), enables reliable and robust point completion with spatial-geometrical consistency for deployment with 6G-IoT devices. Although several DL-based completion techniques are integrated with 6G-IoT devices, they have reliability issues, limiting key trustworthy AI characteristics. This research focuses on the reliability and robustness aspects of trustworthy AI to propose Point-KAN, a dependable real-time 3D point cloud completion model for 6G IoT-connected 3D mapping devices. Point-KAN integrates multi-head attention and Kolmogorov-Arnold Networks (KAN) within the modules of Attention Enhanced-Embedded Feature Collector (AEFC) and KAN-Enhanced Feature Mapper (KEFM) for trustworthy point cloud completion. Empirical evaluations on the ShapeNet demonstrate the superiority of Point-KAN against state-of-the-art (SOTA). Results concrete Point-KAN’s evolution as a trustworthy AI framework ensures reliability and robustness for real-time deployment in 6G-IoT-connected devices, facilitating 3D environment mapping.},
  keywords={Point cloud compression;Artificial intelligence;Three-dimensional printing;6G mobile communication;Real-time systems;Accuracy;Robustness;Shape;Training;Robot sensing systems;Trustworthy AI;3D Point Cloud Completion;6G;IoT;Kolmogorov-Arnold Networks (KANs)},
  doi={10.1109/JIOT.2025.3576434},
  ISSN={2327-4662},
  month={},}@INPROCEEDINGS{10067330,
  author={Bagido, Rufaidah},
  booktitle={2022 Fifth National Conference of Saudi Computers Colleges (NCCC)}, 
  title={Generating New Arabic Letters-Rawashin Design using GAN}, 
  year={2022},
  volume={},
  number={},
  pages={186-192},
  abstract={The artificial intelligence algorithm Generative Adversarial Networks (GAN) is excellent in creating works that simulate human output. As a result, many researchers have created impressive and satisfying art pieces such as images of non-existent people or expressive paintings. The Hijazi heritage is full of unique art forms, including the Rawashin that adorn Hijazi buildings. With the remarkable technical progress of recent years, it has become necessary to highlight this identity in a contemporary way. This work aims to exploit and explore the capabilities of artificial intelligence techniques and GAN networks in creating and producing innovative new shapes with regard to Rawashin (wooden windows). The aim is to integrate such shapes with Arabic lettering in order to produce unprecedented designs in terms of Hijazi buildings. This is done by training the machine using a dataset consisting of images of different building shapes containing Rawashin and some Arabic calligraphy using two types of GAN models. As a result, the model was able to learn and produce a new style of Rawashin.},
  keywords={Training;Art;Shape;Computational modeling;Buildings;Process control;Generative adversarial networks;GAN;VQ-GAQN;Rawashin;Arabic calligraphy;deep learning;generated images;generative models},
  doi={10.1109/NCCC57165.2022.10067330},
  ISSN={},
  month={Dec},}@ARTICLE{10443388,
  author={Islam, Tasin and Miron, Alina and Liu, Xiaohui and Li, Yongmin},
  journal={IEEE Access}, 
  title={Deep Learning in Virtual Try-On: A Comprehensive Survey}, 
  year={2024},
  volume={12},
  number={},
  pages={29475-29502},
  abstract={Virtual try-on technology has gained significant importance in the retail industry due to its potential to transform the way customers interact with products and make purchase decisions. It allows users to virtually try on clothing and accessories, providing a realistic representation of how the items would look and fit without the need for physical interaction. The ability to virtually try on products addresses common challenges associated with online shopping, such as uncertainty about fit and style, ultimately enhancing the overall customer experience and satisfaction. As a result, virtual try-on technology has the potential to reduce returns and optimise conversion rates for businesses, making it a valuable tool in the e-commerce landscape. In this paper, we provide a comprehensive review of deep learning based virtual try-on models, focusing on their functionality, technical details, dataset usage, weaknesses, and impact on customer satisfaction. The models are categorised into three main types: image-based, multi-pose, and video virtual try-on models, with detailed examples and technical summaries provided for each category. Additionally, we identify and discuss similarities and differences in these methods. Furthermore, we examine the datasets currently available for building and evaluating virtual try-on models, including the number of images/videos and their resolutions. We present the commonly used methods for both qualitative and quantitative evaluations, comparing synthesised images with previous work and performing quantitative evaluations across various metrics and benchmark datasets. We discuss the weaknesses of current deep learning based virtual try-on models, including challenges in preserving clothing characteristics and textures, the level of accuracy of applying the clothing to the person, and the preservation of facial identities. Additionally, we address dataset bias, particularly the domination of female models, limited diversity in clothing featured, and relatively simple and clean backgrounds in the datasets, which can negatively impact the model’s ability to handle challenging situations. Moreover, we explore the impact of virtual try-ons on customer satisfaction, highlighting the benefits that customers can enjoy, which also reduces returns and optimises conversion rates for businesses.},
  keywords={Clothing;Solid modeling;Deep learning;Data models;Artificial intelligence;Surveys;Generative adversarial networks;Virtual reality;Market research;Customer satisfaction;User experience;Electronic commerce;Customer services;Consumer behavior;Virtual try-on (VTO);deep learning;image synthesis;generative adversarial networks (GANs);diffusion models (DMs)},
  doi={10.1109/ACCESS.2024.3368612},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9902712,
  author={Zhu, Huijuan and Kang, Yu and Zhao, Yunbo and Yan, Xiaohui and Zhang, Junqiang},
  booktitle={2022 41st Chinese Control Conference (CCC)}, 
  title={Anomaly detection for surface of laptop computer based on PatchCore GAN algorithm}, 
  year={2022},
  volume={},
  number={},
  pages={5854-5858},
  abstract={Timely detection of notebook appearance defects is an important means to prevent products from being delivered to customers before leaving the factory. In industrial production, more emphasis is placed on fast and accurate detection methods, but the existing difficulties: 1. Defect samples are rare and difficult to obtain; 2. In high-resolution images, there are slight differences between abnormal samples and normal samples; 3. Slowly detection and insufficient accuracy. The existing methods mainly use a large amount of abnormal samples, so it is difficult to extend to the field of notebook appearance anomaly detection. To solve this problem, we designed a method that firstly uses unsupervised PatchCore which the algorithm was trained on normal samples and Defect GAN is used in test phase. To create a large number of verisimilitude abnormal samples and test these samples with PatchCore. On TKP-Surface datasets, the AUROC score of image-level anomaly detection achieves 96.1 %, which meets the requirements of industrial applications.},
  keywords={Location awareness;Industries;Portable computers;Image resolution;Keyboards;Feature extraction;Production facilities;Laptop computer;Data augmentation;PatchCore Gan algorithm;Anomaly detection},
  doi={10.23919/CCC55666.2022.9902712},
  ISSN={1934-1768},
  month={July},}@ARTICLE{11106421,
  author={Liu, Keyu and Li, Shibo and Qiu, Yajun and Chen, Feiyu and Zhu, Shuyuan and Zeng, Bing and Zhang, Fan},
  journal={IEEE MultiMedia}, 
  title={Perception-aware Contrastive Learning-based Progressive Image Inpainting}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={Deep learning-based image inpainting has demonstrated impressive performance in improving visual quality of the inpainted content. However, existing methods still generate unpleasant content, especially in cases with large broken areas. To solve this problem, we propose a perception-aware contrastive learning-based progressive image inpainting approach, which is implemented in an iterative way to refine the details of the inpainted images. In order to produce results with improved visual quality, a contrastive learning strategy coupled with a perceptual loss is adopted in the refinement process for model optimization. The experimental results demonstrate the excellent performance of the proposed method, as proved by up to 5.48% gain on the Frechet inception distance (FID) and 1.87% gain on the learned perceptual image patch similarity (LPIPS), compared with the state-of-the-art approach.},
  keywords={Contrastive learning;Visualization;Training;Semantics;Iterative methods;Feature extraction;Data mining;Artificial intelligence;Taylor series;Representation learning},
  doi={10.1109/MMUL.2025.3594221},
  ISSN={1941-0166},
  month={},}@INPROCEEDINGS{10481245,
  author={Minglan, Zhang and Weiqi, Cheng and Yisheng, Zou and Chun, Zhao and Linfu, Sun and Min, Han},
  booktitle={2023 18th International Conference on Intelligent Systems and Knowledge Engineering (ISKE)}, 
  title={A Multi-scale Deep Image Completion Model Fused Capsule Network}, 
  year={2023},
  volume={},
  number={},
  pages={288-293},
  abstract={Image completion is an important research area in digital image processing, and image completion integrating multi-scale information is a hot research topic in recent years. However, most existing works are based on convolutional neural networks to extract image features without considering the multi-scale spatial structure information of the original image, and it's difficult effectively utilize local features and global information. Therefore, this paper proposes a multi-scale deep image completion model (CapsNet-GL) by fusing capsule networks. By combining the Globally and Locally Consistent Image Completion (GL) algorithm, firstly, a Mask region is randomly generated on the real image and input to the complementary network for feature extraction and reconstruction. Then, Capsule Network (CapsNet) is used to improve the global discriminator of GL to obtain richer multi-scale information. Subsequently, the complementation results are input to the global discriminator and the local discriminator respectively to fuse the local information with the global information. Finally, the experimental results on the CelebA-HQ dataset show that the image quality generated by the model proposed in this paper is better in terms of content and structure, and can effectively obtain multi-scale image information and ensure the reliability of the image completion results and their consistency with the original image.},
  keywords={Training;Knowledge engineering;Image quality;Fuses;Digital images;Neural networks;Feature extraction;Image completion;Digital image processing;Capsule network;Multi-scale information fusion},
  doi={10.1109/ISKE60036.2023.10481245},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9497906,
  author={Lou, Zeyu and Le, Kening and Tian, Xiaolin},
  booktitle={2021 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)}, 
  title={NU-Net Based GAN: Using Nested U-Structure for Whole Heart Auto Segmentation}, 
  year={2021},
  volume={},
  number={},
  pages={601-604},
  abstract={Cardiac CT segmentation of the whole heart plays a decisive role in the preliminary diagnosis of cardiovascular diseases and help doctors do early effective treatment. Nevertheless, due to CT images always have high particularity and complexity, and the scarcity of cardiac CT data, challenge appears in automatic cardiac CT segmentation. The U-structure can use fewer data to train better network models. And U2-Net can make the network deeper while retaining the high-resolution feature map. This study proposed an NU-Net based GAN. This method uses cGAN as the main architecture. The generative network of the method is the NU-Net, and the discriminator is FCN. Our experiment about automatic whole heart segmentation has achieved a 0.899 Dice score on the dataset from MM-WHS 2017 challenge, better than most deep learning methods.},
  keywords={Heart;Deep learning;Image segmentation;Computed tomography;Conferences;Medical services;Generative adversarial networks;cGAN;Cardiac CT;whole heart segmentation;NU-Net},
  doi={10.1109/ICAICA52286.2021.9497906},
  ISSN={},
  month={June},}@INPROCEEDINGS{9844421,
  author={Wang, Jingzhong and Yao, Lin},
  booktitle={2022 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)}, 
  title={Unrolled GAN-based Oversampling of Credit Card Dataset for Fraud Detection}, 
  year={2022},
  volume={},
  number={},
  pages={858-861},
  abstract={The excellent performance of most classification algorithms is based on the balance of classes. However, in anomaly detection, the classes are mostly biased. The performance of traditional machine learning algorithms applied to anomaly detection of ten fails to achieve the target effect. Considering the data source, oversampling method addresses class imbalance from data source. In light of the capability of capturing the original sample data distribution, Generative Adversarial Networks offer an inspiring oversampling solution. In this research we demonstrate the applicability of an oversampling method based on Unrolled GAN with credit card data sets. We contrast that method with traditional oversampling methods. Empirical results show the capacity of Unrolled GAN-based oversampling.},
  keywords={Training;Machine learning algorithms;Soft sensors;Conferences;Computer applications;Generative adversarial networks;Credit cards;Unrolled GAN;class imbalance;fraud detection;oversampling},
  doi={10.1109/ICAICA54878.2022.9844421},
  ISSN={},
  month={June},}@INPROCEEDINGS{9550797,
  author={Yang, Mingyu and He, Jianjun},
  booktitle={2021 4th International Conference on Pattern Recognition and Artificial Intelligence (PRAI)}, 
  title={Image Style Transfer Based on DPN-CycleGAN}, 
  year={2021},
  volume={},
  number={},
  pages={141-145},
  abstract={Image style transfer has always been a hot topic in the field of image generation. Generative Adversarial Network (GAN) is used to realize image style transfer can greatly reduce the workload, and get more fruitful results. The traditional image style transfer algorithm needs to convert between two paired images, but the paired data set used for training is difficult to obtain. In order to avoid being limited by data sets and improve the efficiency of image style transfer, this paper proposes an improved Cycle-Consistent Adversarial Network (DPN-CycleGAN), which uses Dual Path Network (DPN) replaces the Deep Residual Network (ResNet) of the original network generator, and adds Identity Loss on the basis of the original loss. The changes make the network structure more simplified, reduce the computational complexity, improve the network performance to a certain extent, and improve the quality of the image generated by style transfer. Finally, the experimental results show that the SSIM value and PSNR value of the generated images are increased by 3.6% and 9.7% on average, which proves the effectiveness of the DPN-CycleGAN image style transfer algorithm proposed by this paper.},
  keywords={Training;Image synthesis;Computational modeling;Generative adversarial networks;Generators;Pattern recognition;Computational complexity;GAN;CycleGAN;ResNet;DPN;image style transfer},
  doi={10.1109/PRAI53619.2021.9550797},
  ISSN={},
  month={Aug},}@ARTICLE{9717293,
  author={Leng, Changfa and Yang, Chungang and Chen, Sifan and Wu, Qing and Peng, Yao},
  journal={IEEE Internet of Things Journal}, 
  title={GAN for Load Estimation and Traffic-Aware Network Selection for 5G Terminals}, 
  year={2022},
  volume={9},
  number={17},
  pages={16353-16362},
  abstract={In the face of the user-centric access network architecture adopted by the fifth-generation (5G) mobile communication network terminals, the communication capability of terminals faces significant challenges. In this case, the combination of 5G and artificial intelligence (AI) has become a significant trend to meet the various communication needs of terminal devices. Toward the problem that the data analysis and decision making for cell load estimation are primarily accomplished on the access side of the network, terminals can only passively access the network, but cannot predict the load estimation on the access side of the network in advance and cannot make network selection decisions in real time. In this article, we propose a cell load estimation algorithm based on a generative adversarial network (GAN) for 5G mobile communication networks, which considers estimating the cell load according to the wireless information measured by the terminals. The algorithm effectively estimates the cell load at the terminal side, which reflects the intelligence of the terminals and solves the problems of low data transmission rate, high signaling cost, and time delay in the existing techniques for load estimation schemes at the network side, assisting users in making a real-time decision. The performance is evaluated through the system-level simulation, and the results indicate that the proposed model improves load estimation accuracy, simultaneously improving the network throughput and reducing the packet queuing delay, suitable for different heterogeneous network scenarios.},
  keywords={Estimation;Generative adversarial networks;5G mobile communication;Load modeling;Artificial intelligence;Real-time systems;Delays;Fifth-generation (5G);generative adversarial network (GAN);intelligent terminals;load estimation;network selection;small cell network},
  doi={10.1109/JIOT.2022.3152729},
  ISSN={2327-4662},
  month={Sep.},}@ARTICLE{10602758,
  author={Majeed, Abdul and Hwang, Seong Oun},
  journal={IEEE Reliability Magazine}, 
  title={Reliability Issues of LLMs: ChatGPT a Case Study}, 
  year={2024},
  volume={1},
  number={4},
  pages={36-46},
  abstract={ChatGPT is a groundbreaking artificial intelligence (AI) invention, and this technology will see tremendous growth per the IEEE Computer Society’s 2024 technology predictions report.1 According to the report, generative AI applications top the list, and this paradigm is predicted to experience most of the advancements in the coming years. ChatGPT, a generative AI product, has demonstrated its effectiveness in many ways (e.g., answering questions, summarizing text, generating computer code, fixing programming bugs, and generating synthetic data). Despite the many promising applications, ChatGPT cannot produce desirable results for many difficult and pragmatic tasks [1]. For example, the inaccuracy from ChatGPT answers related to the emotional text is significantly high, owing to limited amounts of data—or no available data—concerning these tasks [1]. Similarly, ChatGPT can be manipulated to generate fake content, which can be hard to distinguish from real content. There are two schools of thought in the AI community about ChatGPT technology.},
  keywords={Chatbots;Codes;Servers;Reliability engineering;Generative AI;Training;Artificial intelligence;Generative AI;Large language models},
  doi={10.1109/MRL.2024.3420849},
  ISSN={2641-8819},
  month={Dec},}@INPROCEEDINGS{9288181,
  author={Sultan, K. M. Arefeen and Jubair, Mohammad Imrul and Islam, MD. Nahidul and Khan, Sayed Hossain},
  booktitle={2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={toon2real: Translating Cartoon Images to Realistic Images}, 
  year={2020},
  volume={},
  number={},
  pages={1175-1179},
  abstract={In terms of Image-to-image translation, Generative Adversarial Networks (GANs) has achieved great success even when it is used in the unsupervised dataset. In this work, we aim to translate cartoon images to photo-realistic images using GAN. We apply several state-of-the-art models to perform this task; however, they fail to perform good quality translations. We observe that the shallow difference between these two domains causes this issue. Based on this idea, we propose a method based on CycleGAN model for image translation from cartoon domain to photo-realistic domain. To make our model efficient, we implemented Spectral Normalization which added stability in our model. We demonstrate our experimental results and show that our proposed model has achieved the lowest Fréchet Inception Distance score and better results compared to another state-of-the-art technique, UNIT.},
  keywords={Training;Geometry;Tools;Generative adversarial networks;Stability analysis;Task analysis;Image reconstruction;GANs;Image-to-image-translation;Cartoon-to-real},
  doi={10.1109/ICTAI50040.2020.00178},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{9670782,
  author={Gao, Shan and Li, Hongtao and Zhao, Ke and Li, Yujie and Liu, Yongfei and Ma, Jingtan},
  booktitle={2021 International Conference on Sensing, Measurement & Data Analytics in the era of Artificial Intelligence (ICSMD)}, 
  title={A GAN-based Background Noise Removal Method on Infrared Image of Gas-Insulated Transmission Line}, 
  year={2021},
  volume={},
  number={},
  pages={1-5},
  abstract={Results of infrared inspection on 1100kV pipe gallery gas-insulated transmission line (GIL) project are seriously interfered by background noise such as the LED lights and induced heating on steel structures. In this paper, an image background noise removal method based on generative adversarial network (GAN) is proposed. Firstly, convolution neural network (CNN) is used to classify the different parts of GIL. Secondly, the method of threshold and graying are used to mark the classified parts. Finally, the general adverse network is used to repair marked interference parts of noise. In which the generator of GAN is used to repair the marked region to generate new infrared images without noise, and the discriminator is used to discriminate whether the new image output by the generator is successfully repaired. The results show that the proposed method can achieve better background removal effect on infrared images, and the texture feature of the image can preserve well when using GAN to remove the image noise compared with the image de-noising method of VAE. The application results on site show that it takes 0.26 seconds to classify each infrared image using CNN and 4 seconds to remove noise using GAN.},
  keywords={Temperature distribution;Inspection;Maintenance engineering;Generative adversarial networks;Generators;Background noise;Convolutional neural networks;GIL;GAN;background noise removal},
  doi={10.1109/ICSMD53520.2021.9670782},
  ISSN={},
  month={Oct},}@ARTICLE{10900565,
  author={Li, Shaofei and Guo, Junnan and Liu, Zhongyong and Mao, Lei},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Multi-channel Dual-attention Generative Adversarial Network for HVSR Fault Diagnosis under Imbalanced Data Condition}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Fault diagnosis of high-voltage shunt reactors (HVSR) is essential for ensuring the secure operation of power grids. Loose faults in reactors can significantly impact grid safety, necessitating prompt fault diagnosis. However, challenges arise from the difficulty in obtaining HVSR fault data in the real-world scenarios, leading to imbalanced datasets that greatly hinder effective fault diagnosis. To solve that problem, this paper proposes a novel multi-channel dual-attention generative adversarial network for dealing with imbalanced HVSR fault diagnosis (MC-DA-GAN). Firstly, the time-series vibration signal is transformed into multi-channel feature maps, which enables the comprehensive description of signal characteristics from different perspectives, including temporal, time-frequency, and spatial structural domains. Then, dual-attention module is embedded into generative adversarial network (GAN) to capture the robust and representative features of intra-channel and inter-channel, based on which sufficient and high-quality fault samples can be generated. Finally, the resulting rebalanced dataset is utilized to train the diagnosis network, thereby boosting its classification performance under imbalanced HVSR data condition. The effectiveness of the proposed MC-DA-GAN network is verified using vibration data at various HVSR loose faulty states. Compared with the existing state-of-the-art methods, the proposed method can achieve high diagnosis accuracy under different imbalance ratios, even under extreme conditions.},
  keywords={Vibrations;Fault diagnosis;Feature extraction;Continuous wavelet transforms;Time-frequency analysis;Inductors;Generative adversarial networks;Data mining;Training;Time-domain analysis;Fault diagnosis;imbalanced data;high-voltage shunt reactor;attention mechanism;deep learning},
  doi={10.1109/TIM.2025.3544725},
  ISSN={1557-9662},
  month={},}@INPROCEEDINGS{10760646,
  author={Muhsina, N. and Dhoulath Beegum, J},
  booktitle={2024 2nd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS)}, 
  title={Objective and Subjective Analysis of Audio Source Separation using GAN}, 
  year={2024},
  volume={},
  number={},
  pages={434-438},
  abstract={The study centers on audio separation and conducts a thorough quality assessment through objective and subjective analysis. A key area of research in source separation is Blind Source Separation (BSS), which aims to estimate source signals from mixed signals with minimal information about the sources or the mixing process. Researchers have primarily utilized various signal processing techniques to address the source separation challenge. Recently, deep learning methods, especially those involving sound and image recognition, have shown significant effectiveness and have been applied in previous studies in this field. These networks employ various mathematical functions to aggregate multiple inputs, resulting in separated outputs. The model in this study was trained using audio samples from the Audio Source Separation Dataset, with training conducted through Generative Adversarial Networks (GANs). The generated estimates were evaluated using various objective analysis methods designed for assessing audio signals. Experimental evaluations demonstrated the effectiveness of the approach through metrics such as Signal-to-Distortion Ratio (SDR), Signal-to-Interference Ratio (SIR), Signal-to-Artifacts Ratio (SAR), and Image-to-Signal Ratio (ISR).},
  keywords={Training;Analytical models;Speech coding;Speech recognition;Speech enhancement;Generative adversarial networks;Distortion;Blind source separation;Tuning;Signal to noise ratio;Principal Component Analysis;Generator Adversarial Networks;Signal to Distortion Ratio;Source to Interference Ratio;Signal to Artifacts Ratio;Image to Spatial Distortion Ratio},
  doi={10.1109/ICSSAS64001.2024.10760646},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11140550,
  author={Chen, Ziyi and Bi, Xuezi and Dai, Mingcheng and Cong, Yulai},
  booktitle={2025 4th International Symposium on Robotics, Artificial Intelligence and Information Engineering (RAIIE)}, 
  title={High-Quality SAR Ship Image Generation via Physically-Guided Diffusion Models}, 
  year={2025},
  volume={},
  number={},
  pages={12-16},
  abstract={Accurate synthetic aperture radar (SAR) ship image generation plays a critical role in maritime surveillance and naval reconnaissance, where high-quality simulated data can significantly enhance the performance of deep learning models. However, existing generative adversarial network (GAN) approaches suffer from three fundamental limitations: training instability leading to mode collapse, inability to precisely model SAR-specific noise characteristics, and poor controllability over ship category features. To address these challenges, we propose ShipDM, an innovative physically-guided hierarchical diffusion model that implements diffusion probabilistic models for SAR ship generation through three key technological breakthroughs: (1) category-guided cascaded Transformer blocks with hierarchical attention mechanisms for fine-grained feature control, (2) a Multi-Attribute Composition-Controlled Block, and (3) a Scattering-Center-Adaptive Weighting Mechanism for diffusion optimization. Evaluated on the FUSAR-Ship dataset, ShipDM enables the generation controlled by a combination of various attributes, including background, target category, polarization mode and orientation angle, thus providing a powerful support tool for large-scale customized SAR ship augmentation.},
  keywords={Training;Visualization;Technological innovation;Image synthesis;Diffusion models;Transformers;Generative adversarial networks;Marine vehicles;Synthetic aperture radar;Optimization;Synthetic aperture radar;diffusion model;ship image generation;Transformer},
  doi={10.1109/RAIIE65740.2025.11140550},
  ISSN={},
  month={June},}@INPROCEEDINGS{10169373,
  author={Shashank, H S and Acharya, Aniruddh and Sivaraman, E},
  booktitle={2023 International Conference on Artificial Intelligence and Applications (ICAIA) Alliance Technology Conference (ATCON-1)}, 
  title={Facial Image Super Resolution and Feature Reconstruction using SRGANs with VGG-19-based Adaptive Loss Function}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Image reconstruction and super resolution has various applications. Several deep learning techniques are being employed to constantly improve this space. The aim of this experiment is to showcase a unique deep learning approach to try and super resolve human faces from low resolution images. The experiment makes use of a machine learning framework designed to improve image quality called Super Resolution Generative Adversarial Neural (SRGANs) with a loss function based on the features accumulated from multiple layers of a trained Convolutional Neural Network named Visual Geometry Group-19 (VGG-19). The model super resolves lower quality image input and gives out image output of a superior quality},
  keywords={Deep learning;Image quality;Geometry;Visualization;Image color analysis;Superresolution;Generative adversarial networks;GANs;Image Super-Resolution;Neural Network;CNNs;VGG;Feature Reconstruction},
  doi={10.1109/ICAIA57370.2023.10169373},
  ISSN={},
  month={April},}@INPROCEEDINGS{8942258,
  author={Hsieh, Cheng-Pan and Lee, Shih-Kai and Liao, Ya-Yi and Huang, Ren-Jie and Wang, Jung-Hua},
  booktitle={2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)}, 
  title={Binarization Using Morphological Decomposition Followed by cGAN}, 
  year={2019},
  volume={},
  number={},
  pages={208-2083},
  abstract={This paper presents a novel binarization scheme for stained decipherable patterns. First, the input image is downsized, which not only saves the computation time, but the key features necessary for the successful decoding is preserved. Then, high or low contrast areas are decomposed by applying morphological operators to the downsized gray image, and subtracting the two resulting output images from each other. If necessary, these areas are further subjected to decomposition to obtain finer separation of regions. After the preprocessing, the binarization can be done either by GMM to estimate a binarization threshold for each region, or the binarization problem is treated as an image-translation task and hence the conditional generative adversarial network (cGAN) is trained using the high or low contrast areas as conditional inputs.},
  keywords={Training;Generative adversarial networks;Oceans;Gray-scale;Thresholding (Imaging);Generators;Decoding;morphology, binarization, image downsizing, gaussian mixture model, deep learning, cGAN},
  doi={10.1109/AIVR46125.2019.00044},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11106089,
  author={Khan, Le Minh and Hoang, Hien Do and Ngo-Khanh, Khoa and Duy, Phan The and Pham, Van-Hau},
  booktitle={2025 11th International Conference on Computing and Artificial Intelligence (ICCAI)}, 
  title={GSQLi: A GAN-based Approach for Adversarial SQL Injection Sample Generation against WAF}, 
  year={2025},
  volume={},
  number={},
  pages={788-793},
  abstract={Web application firewalls (WAFs) are critical for detecting and blocking malicious activities, offering essential protection for web applications. However, to defend against the complexity of modern attacks, penetration testers must regularly evaluate WAFs to identify potential weaknesses. A key aspect of this process involves bypassing WAFs or attack detectors, and utilizing machine learning (ML) significantly enhances the effectiveness of testing. Using ML not only increases the efficiency of identifying vulnerabilities but also reduces the need for manual intervention. In this paper, we propose a novel method named GSQLi to mutate payload for SQL Injection (SQLi) attacks, one of the most popular attacks on web applications, to deceive WAFs or detectors. By leveraging the Generative Adversarial Network (GAN), SQLi payloads are generated by applying several mutations on the original ones, making it challenging for detectors to identify them as malicious. Additionally, these mutated payloads retain their ability to exploit vulnerabilities effectively. Experimental results prove the capability of payloads generated by our approach to bypassing machine learning-based attack detectors and ModSecurity, a real-world WAF. This reveals potential vulnerabilities in current defense systems, enabling defenders to address weaknesses more swiftly and enhance protection against advanced attacks on web applications.},
  keywords={Cross-site scripting;Detectors;Reinforcement learning;SQL injection;Generative adversarial networks;Real-time systems;Security;Protection;Payloads;Testing;—;GAN;SQL injection;adversarial sample generation;security pen-testing},
  doi={10.1109/ICCAI66501.2025.00122},
  ISSN={},
  month={March},}@INPROCEEDINGS{10452610,
  author={Gayathri, M. and Kavitha, V.},
  booktitle={2023 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI)}, 
  title={Deep Learning-based Cluster Analysis for Healthcare Data Classification}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The use of cutting-edge technology in the medical field results in the production of massive volumes of data on a daily basis. Various categories of information are applied in the domain of healthcare, including clinic information, medical record data, and genetic information. In addition, real-time monitoring in the medical industry produces enormous volumes of data, and properly interpreting such enormous amounts of data is a significant problem. The evaluation of medical information becomes more required so that suitable drugs may be supplied and issues can be avoided by taking appropriate measures depending on the history of the patient. Automation makes data analysis more effective, but performance might deteriorate when there are problems with data integrity, diversity, or consistency. Automation makes data analysis more effective. In order to handle the management of massive amounts of data, many models that are powered by neural networks have been developed; still researchers are currently attempting to develop a superior model that is more accurate. Hence, fuzzy c denotes the process of clustering, whereas generative adversarial networks are used in this study to clusters and classify medical data, aiming to achieve the maximum degree of efficiency in classification. The experiment will use both the benchmark lung cancer sample and the arrhythmias sample. The proposed model achieves a maximum accuracy of 97.3% for dataset 1 and 98.2% for dataset 2, outperforming other methods such as support vector machine, decision tree, and random forest algorithms.},
  keywords={Machine learning algorithms;Data analysis;Clustering algorithms;Medical services;Generative adversarial networks;Data models;Classification algorithms;Data analysis;Electronic Health care data;Classification;Clustering;Machine Learning},
  doi={10.1109/ICDSAAI59313.2023.10452610},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10887999,
  author={Bai, Jingqi and Zhou, Jingkai and Wang, Benzhi and Chen, Weihua and Yang, Yang and Lei, Zhen and Wang, Fan},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Layer-Animate for Transparent Video Generation}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Transparent videos with alpha channels play a crucial role in film production, advertising, and augmented reality fields. However, there is currently no available method for producing transparent videos. Traditional methods are time-consuming and labor-intensive, and employing alternative approaches for this task will result in inaccurate transparent regions, constrained motion, and artifacts. To address these challenges, we propose Layer-Animate, the first method capable of generating transparent videos. Our method comprises two stages: in the first stage, transparent images are generated as the base images to provide content and transparency information for the next stage. In the second stage, Inter-Frame Attention is applied to decouple content from motion, enabling the motion module to focus better on action. Layer-Animate is the first method used to generate transparent videos with accurate transparent regions, sufficient motion, and no artifacts, as demonstrated by notable improvements in qualitative and quantitative metrics.},
  keywords={Accuracy;Production;Signal processing;Acoustic measurements;Robustness;Acoustics;Speech processing;Advertising;Augmented reality;Videos;diffusion models;transparent videos;deep generative models;video generation},
  doi={10.1109/ICASSP49660.2025.10887999},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{11117073,
  author={Liu, Houze and Zhang, Bo and Xiang, Yanlin and Hu, Yuxiang and Shen, Aoran and Lin, Yang},
  booktitle={2024 5th International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)}, 
  title={Adversarial Neural Networks in Medical Imaging Advancements and Challenges in Semantic Segmentation}, 
  year={2024},
  volume={},
  number={},
  pages={470-474},
  abstract={Recent advancements in artificial intelligence (AI) have precipitated a paradigm shift in medical imaging, particularly revolutionizing the domain of brain imaging. This paper systematically investigates the integration of deep learning-a principal branch of AI-into the semantic segmentation of brain images. Semantic segmentation serves as an indispensable technique for the delineation of discrete anatomical structures and the identification of pathological markers, essential for the diagnosis of complex neurological disorders. Historically, the reliance on manual interpretation by radiologists, while noteworthy for its accuracy, is plagued by inherent subjectivity and inter-observer variability. This limitation becomes more pronounced with the exponential increase in imaging data, which traditional methods struggle to process efficiently and effectively. In response to these challenges, this study introduces the application of adversarial neural networks, a novel AI approach that not only automates but also refines the semantic segmentation process. By leveraging these advanced neural networks, our approach enhances the precision of diagnostic outputs, reducing human error and increasing the throughput of imaging data analysis. The paper provides a detailed discussion on how adversarial neural networks facilitate a more robust, objective, and scalable solution, thereby significantly improving diagnostic accuracies in neurological evaluations. This exploration highlights the transformative impact of AI on medical imaging, setting a new benchmark for future research and clinical practice in neurology.},
  keywords={Training;Deep learning;Neurology;Accuracy;Semantic segmentation;Brain modeling;Convolutional neural networks;Artificial intelligence;Biological neural networks;Biomedical imaging;Deep Learning;Semantic Segmentation;Medical Imaging;Convolutional Neural Networks},
  doi={10.1109/ICBAIE63306.2024.11117073},
  ISSN={},
  month={Oct},}@INBOOK{11173598,
  author={Shishodia, Sonia Kumari and Sharma, Shuchi and Khan, Eram and Babu, Logesh},
  booktitle={Handbook of Intelligent Automation Systems Using Computer Vision and Artificial Intelligence}, 
  title={Unveiling the Visual World Through AI&#x2010;Powered Computer Vision}, 
  year={2025},
  volume={},
  number={},
  pages={493-510},
  abstract={Summary <p>Computer vision is commonly at the cutting edge of technological innovation and is progressively being incorporated and enhanced in various industries to facilitate the digitalization and automation of industrial processes. Computer vision seeks to enhance operations, improve efficiency, and mitigate risks by enabling machines to independently perform intelligent tasks such as analysis, reasoning, judgment, conception, and decision&#x2010;making. This ultimately reduces reliance on human labor. The combined efforts of artificial intelligence (AI) and computer vision have led to significant advancements in our ability to perceive and comprehend visual data in recent times. These advancements have been made possible through the examination of digital videos and images, the field of computer vision is primarily concerned with the development of methods that will enable machines to comprehend and interpret the visual world. It is the purpose of this book chapter to provide information about the significant role that AI plays in the transformation of computer vision. AI enables machines to comprehend and interact with the visual realm in ways that have never been seen before. AI makes use of sophisticated algorithms and deep learning techniques to make it possible for computer vision systems to process, analyze, and extract valuable insights from images and videos in an organized and efficient manner. The profound partnership between AI and computer vision has had a wide range of implications across a variety of industries, including healthcare, autonomous vehicles, security, and entertainment, among others. Through an examination of recent developments and emerging patterns, here, we have explored the potential of AI&#x2010;driven computer vision to revolutionize our perception, comprehension, and interaction with the visual world.</p>},
  keywords={Computer vision;Artificial intelligence;Visualization;Cornea;Lenses;Retina;Pupils;Image recognition;Deep learning;Videos},
  doi={10.1002/9781394302734.ch22},
  ISSN={},
  publisher={Wiley},
  isbn={9781394302703},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11173598},}@ARTICLE{9261598,
  author={Lv, Chengkan and Shen, Fei and Zhang, Zhengtao and Xu, De and He, Yonghao},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={A Novel Pixel-Wise Defect Inspection Method Based on Stable Background Reconstruction}, 
  year={2021},
  volume={70},
  number={},
  pages={1-13},
  abstract={In this article, an anomaly detection method based on background reconstruction is proposed to perform defect inspection on the texture surface of the industrial products. This method consists of two modules: 1) an autoencoder integrated with a generative adversarial network is utilized to reconstruct the textured background of the original image as a defect-free reference. Specifically, extra anomalous images are introduced and a mapping method of anomaly is given to improve the stability of reconstruction. 2) A U-net based inspection network is trained to perform pixel-wise analysis of the differences between the original and the reconstructed defect-free image. During these processes, only artificial synthesized defective images are utilized to train the model without any real defective samples. A series of experiments are conducted on several texture image data sets and the industrial production line. The experimental results reveal the effectiveness and versatility of the proposed method.},
  keywords={Image reconstruction;Training;Inspection;Gallium nitride;Production;Generative adversarial networks;Anomaly detection;Anomaly detection;autoencoder;background reconstruction;defect inspection},
  doi={10.1109/TIM.2020.3038413},
  ISSN={1557-9662},
  month={},}@INPROCEEDINGS{10602803,
  author={Li, Yuandong and Wang, Siye and Lai, Jinlin and Nie, Saijun and Mai, Ji},
  booktitle={2024 4th International Conference on Computer Communication and Artificial Intelligence (CCAI)}, 
  title={Lightweight Anomaly Diagnosis for Spacecraft via Heterogeneous Computing}, 
  year={2024},
  volume={},
  number={},
  pages={509-514},
  abstract={This study presents an AI-based solution for real-time and accurate anomaly diagnosis in spacecraft with limited computing resources. A robust solution using artificial intelligence for spacecraft system anomaly diagnosis is introduced, featuring a heterogeneous computing approach. The methodology employed here entails a novel workflow that captures temporal and spatial features from data sequences, enabling advanced temporal characteristic learning for more accurate diagnostic results. An innovative data preprocessing technique is also presented, integrating datasets from various sources into a unified framework, thereby reducing model complexity and enhancing flexibility and practical application. This improvement significantly enhances the model's capacity to manage inconsistent data commonly encountered in real-world scenarios. To facilitate efficient deployment in actual hardware environments and achieve heterogeneous computing, a fine-grained, soft-filter-based weighted pruning approach and 8-bit quantization are utilized for the lightweight processing of diagnostic models. Experimental trials with diverse anomaly data structures and origins demonstrate the model's robustness: maintaining a high accuracy rate of 99.20% after a significant 60% pruning, indicating a minimal accuracy loss of less than 1 % from its initial state, along with a 60% reduction in parameters and a 44% decrease in floating-point operations (FLOPs).},
  keywords={Space vehicles;Accuracy;Computational modeling;Space missions;Heterogeneous networks;Data models;Stability analysis;spacecraft anomaly diagnosis;model light-weighting;cross-source data analysis;heterogeneous computing},
  doi={10.1109/CCAI61966.2024.10602803},
  ISSN={},
  month={May},}@INPROCEEDINGS{11052045,
  author={Kelmendi, Erza and Jashari, Korab and Samanta, Debabrata},
  booktitle={2025 International Conference on Intelligent and Cloud Computing (ICoICC)}, 
  title={Deep Neural Networks: Improved Object Detection for Autonomous Vehicles}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Deep neural networks may have the potential to revolutionize the way an autonomous vehicle perceives the world through methodologies such as object detection. This will require the interaction of neural networks of different kinds to equip the vehicle with capabilities to identify, for example, signage, images, and other entities associated with vehicles, thereby improving transport efficiency. According to many researchers, deep neural networks do not provide varied performance and low accuracy in identification of images. The study shows challenges that number mock image recognition neural networks thus trying to fill up the gap of integration of different neural networks with an autonomous vehicle system. General methods of the study consist of careful observation of the already existing literature, comparative analysis of deep learning networks, and interpretive figures and tables. As much of the study goes on, so many findings about how autonomous vehicles are added to neural networks for deception detection and optimization through the merging of different deep networks have emerged. Finally, the outputs of this paper constitute one of the very critical aspects of the automotive industry, the technology area of sensors, and artificial intelligence.},
  keywords={YOLO;Deep learning;Technological innovation;Accuracy;Artificial neural networks;Real-time systems;Artificial intelligence;Autonomous vehicles;Automotive engineering;Synthetic data;Neural Networks;Autonomous Vehicles;Object detection;Artificial Intelligence;Image-to-Image Networks},
  doi={10.1109/ICoICC64033.2025.11052045},
  ISSN={},
  month={May},}@INPROCEEDINGS{10222744,
  author={Song, Junrong and Yip, David},
  booktitle={2023 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)}, 
  title={Exploring the Intersection of AI Art and Film: A Case Study of Giant}, 
  year={2023},
  volume={},
  number={},
  pages={347-352},
  abstract={Artificial intelligence (AI) has recently been used as a tool for various visual storytelling, but text-to-image models are a stochastic machine learning process that requires human intervention to assist creation better. As we all know, pre-visualization is an important stage in film production, involving subjective choices by the creators. This paper investigates how AI can assist filmmakers during the pre-production stage by generating mood boards from text. We propose a novel preproduction pipeline and guidelines that leverage text-to-image models to create visual previews of film projects. We also conduct a case study to validate and evaluate our approach's effectiveness. Our case study suggests that following the guidelines we have developed can assist filmmakers in generating mood boards that effectively convey the desired atmosphere of their projects and potentially contribute to enhancing the creative process. Our paper aims to contribute to the field of AI art and the film industry.},
  keywords={Visualization;Art;Mood;Atmospheric modeling;Pipelines;Stochastic processes;Entertainment industry;AI;Pre-visualization;Film;Mood Board;Artificial Creativity;Human-machine collaboration},
  doi={10.1109/ICMEW59549.2023.00066},
  ISSN={},
  month={July},}@ARTICLE{10891474,
  author={He, Wenji and Yao, Haipeng and Ren, Xiaoxu and Ouyang, Tianhao and Xiong, Zehui and He, Yuan and Liu, Yunhao},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Dual-Circulation Generative AI for Optimizing Resource Allocation in Multi-Granularity Heterogeneous Federated Learning}, 
  year={2025},
  volume={11},
  number={2},
  pages={817-831},
  abstract={The rapid proliferation of Internet of Things (IoT) devices and the deployment of edge computing infrastructures have significantly advanced data processing and network communications. Federated Learning (FL), leveraging these developments, offers a decentralized approach to learning across edge devices while preserving local privacy. However, traditional FL paradigms encounter challenges related to non-IID data distributions, diverse computational capabilities of edge devices, and multimodal tasks. This paper proposes a novel Dual-Circulation Generative Artificial Intelligence (GAI) framework for Clustered Federated Learning (GAI-CFL), designed to address multi-granularity heterogeneity including data, resources, and task heterogeneity. The GAI-CFL framework integrates Generative Diffusion Models (GDMs) and Reinforcement Learning (RL) strategies to optimize data generation and resource allocation processes. GAI techniques are employed to reduce intra-cluster data heterogeneity by generating data, thereby enriching local datasets and enhancing model convergence. To address inter-cluster data and task heterogeneity, a dual-circulation optimization strategy is implemented, utilizing RL with GDMs to generate optimal strategies based on input data characteristics dynamically. Additionally, a Mixture of Experts (MoE) approach is incorporated within GDMs to select the best expert models for denoising steps, ensuring efficient data generation strategies. Comprehensive simulations clarify that the proposed GAI-CFL framework significantly presents benchmark schemes, achieving lower energy consumption and enhanced system performance under the same delay and performance constraints.},
  keywords={Data models;Computational modeling;Training;Resource management;Performance evaluation;Optimization;Federated learning;Distributed databases;Data augmentation;Convergence;Clustered federated learning;generative artificial intelligence;generative diffusion models;heterogeneous data;resource optimization},
  doi={10.1109/TCCN.2025.3542862},
  ISSN={2332-7731},
  month={April},}@INPROCEEDINGS{9065197,
  author={Yoshino, Yuriko and Lu, Huimin and Kim, Hyoungseop and Aoki, Takatoshi and Kido, Shoji},
  booktitle={2020 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={3D-CNN with residual sub-blocks for automatic detection of lung nodules from temporal subtraction images}, 
  year={2020},
  volume={},
  number={},
  pages={647-652},
  abstract={Temporal subtraction (TS) technique is one of computer aided diagnosis (CAD) systems. A TS image is obtained by subtracting a previous image, which are warped to match between the structures of the previous image and one of a current image, from the current image. TS technique removes normal structures and enhances interval changes. However, many subtraction artifacts that can be detected as false positives still remain on a TS image. In this paper, we propose 3D-CNNs with residual sub-blocks based on 3D-VGG16-like architecture for detection of nodules accurately from TS images.},
  keywords={Convolution;Lung;Three-dimensional displays;Sensitivity;Computed tomography;Artificial neural networks;Visualization;CAD;CT;Lung nodule;ODE;Residual block;3D convolutional neural network},
  doi={10.1109/ICAIIC48513.2020.9065197},
  ISSN={},
  month={Feb},}@INBOOK{10789524,
  author={Gressling, Thorsten},
  booktitle={Data Science in Chemistry: Artificial Intelligence, Big Data, Chemometrics and Quantum Computing with Jupyter}, 
  title={38 Third generation: deep learning models (ANN)}, 
  year={2021},
  volume={},
  number={},
  pages={196-203},
  abstract={},
  keywords={Feature extraction;Data models;Artificial neural networks;Vectors;Neurons;Long short term memory;Deep learning;Recurrent neural networks;Brain modeling;Biological system modeling},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9783110630534},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10789524},}@INBOOK{10953239,
  author={Singh, Shiv},
  booktitle={Marketing with AI For Dummies}, 
  title={Launching into the AI Marketing Era}, 
  year={2025},
  volume={},
  number={},
  pages={45-60},
  abstract={Summary <p>Open artificial intelligence (OpenAI) &#x2014; which seems ready to become a billion&#x2010;dollar&#x2010;revenue company &#x2014; launched its new enterprise product, ChatGPT Enterprise. Adopting a new technology in the marketing efforts may seem straightforward, but readers need to master more than just how to use the technology. The change also requires cultural adaptation. Senior marketers and marketing managers may get caught in the crossfire between the intrapreneurs and traditionalists. Some of these marketers may look to external agencies and tech companies for guidance so that they don't have to do their own research to discern how to seamlessly integrate AI into their departments. At the ascent phase of AI incorporation, readers initiate hands&#x2010;on experimentation in a structured and strategic way. In the escape&#x2010;velocity phase, marketers systematically roll out AI projects across a range of use cases that leverage enterprise&#x2010;level AI technology and reflect harmony with the company's broader strategy.</p>},
  keywords={Internet;Generative AI;Advertising;Chatbots;Hands;Companies;Web sites;Automation;Video on demand;Prompt engineering},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394237210},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10953239},}@ARTICLE{9046754,
  author={Liu, Jia and Ke, Yan and Zhang, Zhuo and Lei, Yu and Li, Jun and Zhang, Minqing and Yang, Xiaoyuan},
  journal={IEEE Access}, 
  title={Recent Advances of Image Steganography With Generative Adversarial Networks}, 
  year={2020},
  volume={8},
  number={},
  pages={60575-60597},
  abstract={In the past few years, the Generative Adversarial Network (GAN), which proposed in 2014, has achieved great success. There have been increasing research achievements based on GAN in the field of computer vision and natural language processing. Image steganography is an information security technique aiming at hiding secret messages in common digital images for covert communication. Recently, research on image steganography has demonstrated great potential by introducing GAN and other neural network techniques. In this paper, we review the art of steganography with GANs according to the different strategies in data hiding, which are cover modification, cover selection, and cover synthesis. We discuss the characteristics of the three strategies of GAN-based steganography and analyze their evaluation metrics. Finally, some existing problems of image steganography with GAN are summarized and discussed. Potential future research topics are also forecasted.},
  keywords={Gallium nitride;Generative adversarial networks;Cryptography;Measurement;Graphics;Computational modeling;Image steganography;generative adversarial nets;cover synthesis;generative model},
  doi={10.1109/ACCESS.2020.2983175},
  ISSN={2169-3536},
  month={},}@ARTICLE{8733072,
  author={Wang, Kai and Dong, Jiaqing and Wang, Ying and Yin, Hao},
  journal={IEEE Access}, 
  title={Securing Data With Blockchain and AI}, 
  year={2019},
  volume={7},
  number={},
  pages={77981-77989},
  abstract={Data is the input for various artificial intelligence (AI) algorithms to mine valuable features, yet data in Internet is scattered everywhere and controlled by different stakeholders who cannot believe in each other, and usage of the data in complex cyberspace is difficult to authorize or to validate. As a result, it is very difficult to enable data sharing in cyberspace for the real big data, as well as a real powerful AI. In this paper, we propose the SecNet, an architecture that can enable secure data storing, computing, and sharing in the large-scale Internet environment, aiming at a more secure cyberspace with real big data and thus enhanced AI with plenty of data source, by integrating three key components: 1) blockchain-based data sharing with ownership guarantee, which enables trusted data sharing in the large-scale environment to form real big data; 2) AI-based secure computing platform to produce more intelligent security rules, which helps to construct a more trusted cyberspace; 3) trusted value-exchange mechanism for purchasing security service, providing a way for participants to gain economic rewards when giving out their data or service, which promotes the data sharing and thus achieves better performance of AI. Moreover, we discuss the typical use scenario of SecNet as well as its potentially alternative way to deploy, as well as analyze its effectiveness from the aspect of network security and economic revenue.},
  keywords={Artificial intelligence;Data security;Blockchain;Big Data;Internet;Cyberspace;Data security;data systems;artificial intelligence;cyberspace},
  doi={10.1109/ACCESS.2019.2921555},
  ISSN={2169-3536},
  month={},}@ARTICLE{10780969,
  author={Yoon, Jee Seok and Oh, Kwanseok and Shin, Yooseung and Mazurowski, Maciej A. and Suk, Heung-Il},
  journal={Proceedings of the IEEE}, 
  title={Domain Generalization for Medical Image Analysis: A Review}, 
  year={2024},
  volume={112},
  number={10},
  pages={1583-1609},
  abstract={Medical image analysis (MedIA) has become an essential tool in medicine and healthcare, aiding in disease diagnosis, prognosis, and treatment planning, and recent successes in deep learning (DL) have made significant contributions to its advances. However, deploying DL models for MedIA in real-world situations remains challenging due to their failure to generalize across the distributional gap between training and testing samples—a problem known as domain shift. Researchers have dedicated their efforts to developing various DL methods to adapt and perform robustly on unknown and out-of-distribution (OOD) data distributions. This article comprehensively reviews domain generalization (DG) studies specifically tailored for MedIA. We provide a holistic view of how DG techniques interact within the broader MedIA system, going beyond methodologies to consider the operational implications on the entire MedIA workflow. Specifically, we categorize DG methods into data-level, feature-level, model-level, and analysis-level methods. We show how those methods can be used in various stages of the MedIA workflow with DL equipped from data acquisition to model prediction and analysis. Furthermore, we critically analyze the strengths and weaknesses of various methods, unveiling future research opportunities.},
  keywords={Data models;Brain modeling;Medical services;Predictive models;Medical diagnostic imaging;Analytical models;Magnetic resonance imaging;Deep learning;Biomedical imaging;Image analysis;Training data;Deep learning (DL);domain generalization (DG);medical image analysis (MedIA);out-of-distribution (OOD)},
  doi={10.1109/JPROC.2024.3507831},
  ISSN={1558-2256},
  month={Oct},}@ARTICLE{9016238,
  author={Chonwiharnphan, Parichat and Thienprapasith, Pipop and Chuangsuwanich, Ekapol},
  journal={IEEE Access}, 
  title={Generating Realistic Users Using Generative Adversarial Network With Recommendation-Based Embedding}, 
  year={2020},
  volume={8},
  number={},
  pages={41384-41393},
  abstract={User data has been used by many companies to understand user behaviors and finding new business strategies. However, common techniques cannot be used when it comes to new products that have not yet been released due to the fact that there are no prior data available. In this work, we propose a framework for generating realistic user data on new products which can then be analyzed for insights. Our model uses Conditional Generative Adversarial Network (CGAN) with the Straight-Through Gumbel estimator which can also handle discrete-valued outputs. The CGAN is conditioned on product features learned using a recommendation system which can better capture the relationship between products. Experiments using a dataset consisting of view logs from a real estate listing website shows that our model outperforms other baselines on four performance metrics, and can effectively predict the finer characteristics of new products.},
  keywords={Gallium nitride;Generative adversarial networks;Generators;Training;Decoding;Companies;Generative adversarial networks;deep learning;generative model;data generation;Gumbel-softmax trick;product embedding},
  doi={10.1109/ACCESS.2020.2976491},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10714278,
  author={D'Urso, Stefano and Martini, Barbara and Sciarrone, Filippo},
  booktitle={2024 28th International Conference Information Visualisation (IV)}, 
  title={A Novel LLM Architecture for Intelligent System Configuration}, 
  year={2024},
  volume={},
  number={},
  pages={326-331},
  abstract={This paper presents a comparative analysis of novel LLM-based architectures designed specifically for system configuration purposes. Generative Artificial Intelligence (Gen AI) has rapidly evolved, offering transformative capabilities in content generation across various domains. Large Language Models (LLMs) stand at the forefront of this evolution, revolutionizing natural language understanding and enabling sophisticated conversational systems. Leveraging the potential of LLMs, our study introduces a novel system architecture centered around an intelligent chatbot tailored to assist learners in complex network configurations. By integrating Generative Pre-trained Transformer-based models with Retrieval Augmented Generation (RAG) and Function Calling features, our architecture aims to provide a co-pilot-like experience, guiding users through understanding requirements and generating configuration scripts. Through a comparative analysis of three LLM architectures, each tailored to handle system network configuration, we evaluate their effectiveness, strengths, and limitations. Our findings offer valuable insights into the potential applications of Generative AI in network operations and highlight avenues for future research and development.},
  keywords={Visualization;Generative AI;Navigation;Large language models;Systems architecture;Complex networks;Chatbots;Transformers;Intelligent systems;Research and development;Generative Artificial Intelligence;Large Language Models;Retrieval Augmented Generation;Function Calling;Intelligent Chatbots},
  doi={10.1109/IV64223.2024.00063},
  ISSN={2375-0138},
  month={July},}@INPROCEEDINGS{10500140,
  author={Khurdula, Harsha Vardhan and Pagutharivu, Anbilparithi and Soung Yoo, Jin},
  booktitle={SoutheastCon 2024}, 
  title={The Future of Feelings: Leveraging Bi-LSTM, BERT with Attention, Palm V2 & Gemini Pro for Advanced Text-Based Emotion Detection}, 
  year={2024},
  volume={},
  number={},
  pages={275-278},
  abstract={This research explores advanced text based emotion detection by leveraging Bidirectional Long Short-Term Memory (Bi-LSTM), Bidirectional Encoder Representations from Trans-formers (BERT) with attention mechanisms, and the latest in Generative Artificial Intelligence, including Palm V2 and Gemini Pro. Unlike traditional supervised learning approaches that rely on pre-defined labels, our methodology employs generative models to adaptively recognize a broad spectrum of human emotions in real-time. By finetuning generative AI, we aim to surpass current approaches in emotion detection accuracy and provide a more nuanced understanding of textual sentiment. Our work outlines the novel approach, dataset preparation, model architecture adjustments, and comprehensive evaluation metrics to demonstrate the efficacy of combining these technologies for enhanced emotion detection.},
  keywords={Emotion recognition;Adaptation models;Recurrent neural networks;Generative AI;Supervised learning;Bidirectional control;Transformers;Emotion Detection;Natural Language Pro-cessing;Recurring Neural Networks;Transformers;Generative Artificial Intelligence},
  doi={10.1109/SoutheastCon52093.2024.10500140},
  ISSN={1558-058X},
  month={March},}@INPROCEEDINGS{10705238,
  author={Traykov, Kiril},
  booktitle={2024 IEEE 12th International Conference on Intelligent Systems (IS)}, 
  title={A Framework for Security Testing of Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={The purpose of this paper is to present a framework for testing of large language models (LLMs) for security vulnerabilities before their implementation to production environment. The paper discusses the latest developments in the Artificial Intelligence (AI) and Generative Artificial Intelligence (Generative AI) adoption in the industry, the expectations for further accelerated adoption and evolving regulatory landscape. An overview of the most significant risks and vulnerabilities of the LLMs such as prompt injection and denial of service have been presented with their mitigation strategies. A testing approach and testing framework have been developed and implemented with simple chatbot app. The test scenarios have been executed and results have been obtained for three open-source LLMs from which two pass the test and one failed and demonstrated the application of the proposed testing framework. Source code of the application and test script are published open source for reproducibility and reuse. In conclusion the with the confirmation of the results the limitation of the reliance on semantic similarity for the responses of the models was discussed together with three areas for further development: expanding the test scenarios to significant risks, integration with popular cloud continuous development platforms and integrating blockchain for transparent publication of the final test results.},
  keywords={Industries;Generative AI;Large language models;Prevention and mitigation;Source coding;Semantics;Reproducibility of results;Blockchains;Computer crime;Testing;Large language models (LLMs);Cybersecurity;LLM Security;LLM Risks;LLM Vulnerabilities;Secure Software Development;Software Testing},
  doi={10.1109/IS61756.2024.10705238},
  ISSN={2767-9802},
  month={Aug},}@INPROCEEDINGS{9628933,
  author={Ružička, Marek and Vološin, Marcel and Gazda, Juraj and Maksymyuk, Taras and Bobalo, Yuriy},
  booktitle={2021 IEEE 4th International Conference on Advanced Information and Communication Technologies (AICT)}, 
  title={Correcting Defective Trajectories using Conditional GAN}, 
  year={2021},
  volume={},
  number={},
  pages={206-211},
  abstract={The end-user mobility patterns play a key role in the process of 5G network design. During tracking end-users via GPS, errors can appear. While we are still constrained with a very limited number of commercially available trajectory datasets, a possible solution is to extend an existing dataset using a generative adversarial network (GAN). Our previous work showed that the utilization of GAN in a form of artificial trajectory generator is possible but not flawless as it introduces the issue with unreasonable gaps between trajectory’s consecutive GPS coordinates. To overcome this issue with a generated dataset and with authentic data as well a special type of GAN called conditional GAN can be used. By leveraging this approach we are not only able to generate a potentially unlimited number of new data samples but as well to correct the existing ones. The number of missing datapoints in the trajectory can go as low as 95% of all points. This artificial intelligence approach has the potential to be used in various use cases where trajectory data are defective and need to be corrected.},
  keywords={5G mobile communication;Conferences;Generative adversarial networks;Generators;Trajectory;Information and communication technology;Artificial intelligence;trajectory;generative adversarial networks;mobility models;5G},
  doi={10.1109/AICT52120.2021.9628933},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10617048,
  author={Verma, Rajan and Suma, S and Radha, N and Joshi, Abhishek and Shnain, Ammar Hameed and Praveenkumar, C},
  booktitle={2024 4th International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)}, 
  title={The use of Integration of H Level Communication with the Extended Identity Power Process to Have Intelligent Vehicles: An Empirical Review}, 
  year={2024},
  volume={},
  number={},
  pages={1534-1538},
  abstract={The arrival of sixth-generation (6 G) wireless technology has ushered in a new era of connectivity, promising innovative services such as the Internet of Things (IoT) and, more importantly, when it is stimulating research into sixthgeneration networks (6G). However, the widespread integration of artificial intelligence (AI) into intelligent vehicles faces significant challenges. These challenges include limited resources, lack of high-quality labelled data, and lack of AIoptimized architecture. Edge Intelligence is emerging as a promising solution that aims to seamlessly integrate artificial intelligence with intelligent vehicles. This paper describes the key requirements and trends driving the understanding of 6 G networks, with an emphasis on self-learning techniques to develop intelligent vehicles. This study suggests a framework focused on automated learning based on onboard awareness, with the goal of reducing human intervention by automating data processing and model development. This architecture uses a Generative Adversarial Network (GAN) to aggregate labelled data for Al training, ensuring scalability, adaptability and efficiency. A case study in a connected traffic network demonstrates the effectiveness of the architecture for intelligent vehicles. The proposed architecture not only addresses the challenges of 6 G networks but also aligns with their requirements for efficiency, adaptability, and human-centricity By leveraging self-learning mechanisms, it paves the way for autonomous adaptation and evolution in dynamic network environments.},
  keywords={Wireless communication;Training;Intelligent vehicles;Reviews;Scalability;Computer architecture;Generative adversarial networks;intelligent vehicles;6 G networks;Edge intelligence and Augmented Reality},
  doi={10.1109/ICACITE60783.2024.10617048},
  ISSN={},
  month={May},}@INPROCEEDINGS{10400592,
  author={He, Y. and Xing, B. and Xu, C.},
  booktitle={5th International Conference on Artificial Intelligence and Advanced Manufacturing (AIAM 2023)}, 
  title={Based on atrous spatial convolutional and attention mechanism cycle-consistent generative adversarial defogging network}, 
  year={2023},
  volume={2023},
  number={},
  pages={458-464},
  abstract={In order to solve the problem of poor de-fogging effect caused by incomplete prior knowledge of atmospheric scattering model and lack of actual paired image data set in image de-fogging method, a cycle-consistent generative adversarial network based on convolution and attention modules of void space is proposed for image defogging. The unsupervised defogging of unpaired images is completed by using the constrained transfer learning ability and cyclic structure of cycle-consistent generative adversarial network. Considering the serious detail loss of the target object and the complexity of fog distribution in actual imaging, combined with the real visual features, the common convolution is replaced by the empty space convolution ASPP module, the attention module CBAM is integrated into the network to realize the non-homogenization of different features and different regions. The experimental results show that the proposed method has better results on both the synthetic image data set and the real fog data set.},
  keywords={},
  doi={10.1049/icp.2023.2977},
  ISSN={},
  month={Oct},}@ARTICLE{11096548,
  author={Lu, Ching-Ta and Lu, Yen-Yu and Lu, Yi-Ru and Pan, Ying-Chen and Liu, Yu-Chun},
  journal={IEEE Access}, 
  title={Implementation of an AI English-Speaking Interactive Training System Using Multi-Model Neural Networks}, 
  year={2025},
  volume={13},
  number={},
  pages={132052-132066},
  abstract={Many people can read and listen to English well but may need help to speak it well. This paper aims to implement an AI English-speaking interactive training (AIESIT) system based on AI for special-purpose English-speaking training research, enabling students to express and communicate in professional English naturally. We will provide new tools for solving the software design in English-speaking training. The proposed AIESIT system integrates generative AI, speech recognition, and body recognition. The AIESIT system uses generative AI to generate an AI agent with mouth shapes that match the English speech, which enhances the user’s feeling of being in the real world. The speech recognition system recognizes the voice content of the user’s response for passing the evaluation. Since the AIESIT system does not have a natural person online, users can speak English boldly to improve their oral skills. During the learning process, OpenPoseNet is used to recognize whether the user has poor posture or leaves the seat during the learning process. Eye CNN is used to recognize whether the user falls asleep during the learning process and as a reference for continuing the lesson. Finally, the learning trajectory, including the recognition rate and response time, is output to score the performance of the English dialogues. The results of multiple user tests have shown that increasing the number of practice sessions can improve the English speaking, encouraging users to keep practicing, and this system helps improve their English speaking.},
  keywords={Artificial intelligence;Training;Speech recognition;Education;Real-time systems;Urban areas;Adaptive learning;Grammar;Anxiety disorders;Vocabulary;AI agent;convolutional neural network;interactive English-speaking practice;learning status recognition},
  doi={10.1109/ACCESS.2025.3592632},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10905127,
  author={De Silva, Ulindu and Fernando, Leon and Bandara, Kalinga and Nawaratne, Rashmika},
  booktitle={IECON 2024 - 50th Annual Conference of the IEEE Industrial Electronics Society}, 
  title={Video Summarisation with Incident and Context Information using Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The proliferation of video content production has led to vast amounts of data, posing substantial challenges in terms of analysis efficiency and resource utilization. Addressing this issue calls for the development of robust video analysis tools. This paper proposes a novel approach leveraging Generative Artificial Intelligence (GenAI) to facilitate streamlined video analysis. Our tool aims to deliver tailored textual summaries of user-defined queries, offering a focused insight amidst extensive video datasets. Unlike conventional frameworks that offer generic summaries or limited action recognition, our method harnesses the power of GenAI to distil relevant information, enhancing analysis precision and efficiency. Employing YOLO-V8 for object detection and Gemini for comprehensive video and text analysis, our solution achieves heightened contextual accuracy. By combining YOLO with Gemini, our approach furnishes textual summaries extracted from extensive CCTV footage, enabling users to swiftly navigate and verify pertinent events without the need for exhaustive manual review. The quantitative evaluation revealed a similarity of 72.8%, while the qualitative assessment rated an accuracy of 85%, demonstrating the capability of the proposed method.},
  keywords={YOLO;Accuracy;Text analysis;Generative AI;Reviews;Navigation;Pipelines;Production;Streaming media;Resource management;Gemini;Surveillance Video Analysis;Generative Artificial Intelligence;Object Detection},
  doi={10.1109/IECON55916.2024.10905127},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11094032,
  author={Ni, Junfeng and Liu, Yu and Lu, Ruijie and Zhou, Zirui and Zhu, Song-Chun and Chen, Yixin and Huang, Siyuan},
  booktitle={2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Decompositional Neural Scene Reconstruction with Generative Diffusion Prior}, 
  year={2025},
  volume={},
  number={},
  pages={6022-6033},
  abstract={Decompositional reconstruction of 3D scenes, with complete shapes and detailed texture of all objects within, is intriguing for downstream applications but remains challenging, particularly with sparse views as input. Recent approaches incorporate semantic or geometric regularization to address this issue, but they suffer significant degradation in underconstrained areas and fail to recover occluded regions. We argue that the key to solving this problem lies in supplementing missing information for these areas. To this end, we propose DP-Recon, which employs diffusion priors in the form of Score Distillation Sampling (SDS) to optimize the neural representation of each individual object under novel views. This provides additional information for the underconstrained areas, but directly incorporating diffusion prior raises potential conflicts between the reconstruction and generative guidance. Therefore, we further introduce a visibility-guided approach to dynamically adjust the per-pixel SDS loss weights. Together these components enhance both geometry and appearance recovery while remaining faithful to input images. Extensive experiments across Replica and ScanNet++ demonstrate that our method significantly outperforms state-of-the-art methods. Notably, it achieves better object reconstruction under 10 views than the baselines under 100 views. Our method enables seamless text-based editing for geometry and appearance through SDS optimization and produces decomposed object meshes with detailed UV maps that support photo-realistic Visual effects (VFX) editing. The project page is available at https://dp-recon.github.io/.},
  keywords={Geometry;Degradation;Three-dimensional displays;Shape;Semantics;Pipelines;Visual effects;Pattern recognition;Image reconstruction;Optimization;3d scene reconstruction;sparse view reconstruction;generative prior},
  doi={10.1109/CVPR52734.2025.00565},
  ISSN={2575-7075},
  month={June},}@ARTICLE{10804099,
  author={Chen, Shuai and Feng, Zhixi and Yang, Shuyuan and Ma, Yue and Liu, Jun and Qi, Zhuoyue},
  journal={IEEE Transactions on Wireless Communications}, 
  title={A Generative Self-Supervised Framework for Cognitive Radio Leveraging Time-Frequency Features and Attention-Based Fusion}, 
  year={2025},
  volume={24},
  number={3},
  pages={1866-1880},
  abstract={With the advancement of cognitive radio technology (CRT) in radio communication networks, deep learning (DL) has become instrumental in enhancing spectrum efficiency. However, supervised DL methods demand extensive labeled data and incur high manual costs. Consequently, practical applications of CRT increasingly necessitate techniques capable of learning robust representations from large volumes of unlabeled data. Although recent DL advancements have driven the use of self-supervised learning (SSL) in CRT through time-domain contrastive methods, these approaches fall short in extracting high-level spectral representations due to their neglect of time-frequency features. To address these limitations, a generative SSL framework is proposed for CRT applications. First, SSL pretraining is conducted in the time-frequency domain by reconstructing masked spectrograms using a Masked Autoencoder. Then, to recover the spectrogram under extreme radio conditions, mutual information maximization is employed to extract high-level spectral information obscured by noise patterns. Additionally, an attention-based channel-spectrum fusion module is designed to automatically extract and integrate features from the channel and spectral domains. The feasibility of the proposed framework is evaluated across multiple downstream tasks on four public datasets. Experimental results demonstrate that the proposed framework significantly outperforms existing methods in various downstream tasks.},
  keywords={Feature extraction;Time-frequency analysis;Data mining;Spectrogram;Transformers;Modulation;Radio communication;Noise reduction;Cognitive radio;Time-domain analysis;Generative framework;self-supervised learning (SSL);cognitive radio technology (CRT)},
  doi={10.1109/TWC.2024.3513980},
  ISSN={1558-2248},
  month={March},}@ARTICLE{10517304,
  author={Du, Zhilin and Liu, Zhenyu and Li, Haozhen and Fan, Shilong and Gu, Xinyu and Zhang, Lin},
  journal={IEEE Wireless Communications Letters}, 
  title={Dig-CSI: A Distributed and Generative Model Assisted CSI Feedback Training Framework}, 
  year={2024},
  volume={13},
  number={8},
  pages={2035-2039},
  abstract={The advent of deep learning (DL)-based models has significantly advanced Channel State Information (CSI) feedback mechanisms in wireless communication systems. However, traditional approaches often suffer from high communication overhead and potential privacy risks due to the centralized nature of CSI data processing. Specifically, contrasting with conventional approaches that lead to bandwidth inefficiency in distributed data collection, this letter proposes Dig-CSI which adopts a unique approach where each user equipment (UE) acts as a distributed lightweight generator for dataset creation, utilizing local data without necessitating uploads. This design involves each UE training an autoencoder, with its decoder acting as the distributed generator, which enhances reconstruction accuracy and generative performance. Our experimental results reveal that Dig-CSI efficiently trains a global CSI feedback model, matching the performance of conventional centralized learning models while significantly minimizing communication overhead.},
  keywords={Generators;Training;Data models;Distributed databases;Servers;Computational modeling;Codes;Massive MIMO;generative neural network;CSI feedback;distributed system},
  doi={10.1109/LWC.2024.3395843},
  ISSN={2162-2345},
  month={Aug},}@INPROCEEDINGS{10473909,
  author={Yuan, Zehua and Pan, Junhao and Zhang, Xiaofan and Chen, Deming},
  booktitle={2024 29th Asia and South Pacific Design Automation Conference (ASP-DAC)}, 
  title={HomeSGN: A Smarter Home with Novel Rule Mining Enabled by a Scorer-Generator GAN}, 
  year={2024},
  volume={},
  number={},
  pages={102-108},
  abstract={Most contemporary research in advanced smart homes has been primarily focused on understanding the environment and identifying activities. However, it can never translate these insights into actionable rules that could improve residents’ quality of life, much less optimize the entire home environment. Addressing this gap, our paper introduces HomeSGN, an end-to-end trainable Scorer-Generator system founded on the Generative Adversarial Network (GAN) architecture. Specifically tailored for smart home applications, HomeSGN extracts, assesses, and proffers beneficial rules from residents’ everyday activities, thereby improving living conditions and optimizing the home environment with adaptable targets. Complemented by pioneering data augmentation and rectification strategies, the system assures model stability, avoids mode collapse, and maintains data integrity throughout GAN training. Integrating HomeSGN into an existing smart home infrastructure establishes a seamless sensor-to-rule pipeline. The effectiveness of HomeSGN is underscored by significant benefits, notably an enhancement of life quality by over 50% in single-user homes and 30% in multi-user scenarios, thus truly embodying the promise of “smart” in smart homes.},
  keywords={Training;Design automation;Pipelines;Neural networks;Smart homes;Generative adversarial networks;Data augmentation;Smart Home;Internet of Things;Artificial Intelligence},
  doi={10.1109/ASP-DAC58780.2024.10473909},
  ISSN={2153-697X},
  month={Jan},}@INPROCEEDINGS{11035698,
  author={Chen, Xinyi and Lei, Weimin and Zhang, Dekang and Zhang, Yuxin},
  booktitle={2025 IEEE 6th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={Personalized Semantic Feature Reconstruction Based Generative Portrait Video Compression}, 
  year={2025},
  volume={},
  number={},
  pages={1567-1573},
  abstract={Traditional visual data (e.g., images and videos) compression focuses on signal fidelity to remove redundancy, while reducing semantic redundancy offers further potential to improve video compression performance. To this end, we propose a novel generative approach for portrait video compression using personalized semantic feature reconstruction. Specifically, we represent the semantic feature in portrait videos with personalized and common features. To achieve efficient feature extraction, we design a personalized feature extraction network that infers edge details, serving as a critical condition for generation. For realistic reconstruction, we introduce a two-stage feature fusion generative adversarial network (GAN). This network utilizes decoded personalized features for conditional generation while integrating common information like texture and color. Both qualitative and quantitative experimental results demonstrate that our method can achieve perceptually pleasing results at ultra-low bitrates with higher semantic fidelity.},
  keywords={Visualization;Image color analysis;Semantics;Redundancy;Bit rate;Video compression;Feature extraction;Generative adversarial networks;Image reconstruction;Videos;portrait video compression;semantic fidelity;personalized feature;generative adversarial network},
  doi={10.1109/AINIT65432.2025.11035698},
  ISSN={},
  month={April},}@INPROCEEDINGS{10176967,
  author={Luo, Nan and Ma, Ying and Li, Jianmin and Xie, Yanqi},
  booktitle={2023 4th International Conference on Electronic Communication and Artificial Intelligence (ICECAI)}, 
  title={A Just-in-time Software Defect Detection Method Using Generative Adversarial Networks}, 
  year={2023},
  volume={},
  number={},
  pages={37-45},
  abstract={As a branch of software defect detection research, Juts-in-time software defect prediction mainly detects defects with the detection granularity of change level. Change-level defect detection means that when the project developer commits code, whether there are defects in the introduced code are detected. When the defect detection model classifies the code submitted by project developers as introducing defects to commit changes, developers need to modify their submitted changes to be classified as clean classes. Investigation shows that some project developers choose to ignore the classification results of the software defect detection model, and only modify the code structure in the submitted changes, but not the code semantics, so that the software defect detection model marks their submitted changes as clean changes. This action by the developer is often referred to as a semantically preserved change. This paper introduces a just-in-time software defect detection model based on generative adversarial networks. The semantic equivalent code segments are generated by the generative adversarial model, and the generated data and original data are used to train the defect detection model, to improve the performance of the software defect detection model. The proposed method is tested on six project datasets commonly used in the field of just-in-time defect detection. The experimental results show that the proposed method can effectively detect whether there are software defects introduced by semantically preserved changes in the submitted changes.},
  keywords={Training;Codes;Semantics;Computer architecture;Syntactics;Generative adversarial networks;Software;Semantically preserved changes changes;Defect detection detection;Generative Adversarial Networks Networks;Abstract Syntax Tree},
  doi={10.1109/ICECAI58670.2023.10176967},
  ISSN={},
  month={May},}
