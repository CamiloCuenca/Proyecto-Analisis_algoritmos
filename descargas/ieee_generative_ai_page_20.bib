@INPROCEEDINGS{10286762,
  author={Caliskan, Handenur and Yayla, Omer Faruk and Genc, Yakup},
  booktitle={2023 8th International Conference on Computer Science and Engineering (UBMK)}, 
  title={A Comparative Analysis of Synthetic Data Generation with VAE and CTGAN Models on Financial Credit Loan Offer Data}, 
  year={2023},
  volume={},
  number={},
  pages={212-217},
  abstract={Creating synthetic data is a practical approach to provide a solution for privacy and scalability issues of data in machine learning applications. Data science in finance is encountering an increasing need for anonymized data for the same reasons: strict privacy regulations, and need for balanced data for many modeling tasks. In this work, we address three problems in machine learning applications for financial application and offer solutions. First, we successfully generate synthetic data using a set of actual credit loan offer data by training a custom variational autoencoder and a GAN model. Second, we present a comparative analysis of these models using statistical methods. As far as we know, there are no golden standards for the assessment of synthetically generated data for finance applications. Lastly, we introduce a performance comparison method to evaluate synthetically generated data. Our experimental analysis has shown that the proposed methods achieve a satisfactory performance with the generated data in various machine learning models.},
  keywords={Training;Analytical models;Data privacy;Visualization;Computational modeling;Finance;Data models;synthetic data;finance;machine learning;artificial intelligence;autoencoder;generative models},
  doi={10.1109/UBMK59864.2023.10286762},
  ISSN={2521-1641},
  month={Sep.},}@ARTICLE{9138445,
  author={Song, Xiaoning and Chen, Yao and Feng, Zhen-Hua and Hu, Guosheng and Yu, Dong-Jun and Wu, Xiao-Jun},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={SP-GAN: Self-Growing and Pruning Generative Adversarial Networks}, 
  year={2021},
  volume={32},
  number={6},
  pages={2458-2469},
  abstract={This article presents a new Self-growing and Pruning Generative Adversarial Network (SP-GAN) for realistic image generation. In contrast to traditional GAN models, our SP-GAN is able to dynamically adjust the size and architecture of a network in the training stage by using the proposed self-growing and pruning mechanisms. To be more specific, we first train two seed networks as the generator and discriminator; each contains a small number of convolution kernels. Such small-scale networks are much easier and faster to train than large-capacity networks. Second, in the self-growing step, we replicate the convolution kernels of each seed network to augment the scale of the network, followed by fine-tuning the augmented/expanded network. More importantly, to prevent the excessive growth of each seed network in the self-growing stage, we propose a pruning strategy that reduces the redundancy of an augmented network, yielding the optimal scale of the network. Finally, we design a new adaptive loss function that is treated as a variable loss computational process for the training of the proposed SP-GAN model. By design, the hyperparameters of the loss function can dynamically adapt to different training stages. Experimental results obtained on a set of data sets demonstrate the merits of the proposed method, especially in terms of the stability and efficiency of network training. The source code of the proposed SP-GAN method is publicly available at https://github.com/Lambert-chen/SPGAN.git.},
  keywords={Gallium nitride;Training;Generative adversarial networks;Generators;Adaptation models;Convolution;Stability analysis;Adaptive loss function;generative adversarial networks (GANs);pruning;self-growing},
  doi={10.1109/TNNLS.2020.3005574},
  ISSN={2162-2388},
  month={June},}@INPROCEEDINGS{11073367,
  author={Kumar, J. Hema Sai Sarath and Kumar, T. Kishore},
  booktitle={IEEE EUROCON 2025 - 21st International Conference on Smart Technologies}, 
  title={Acute Intracranial Hemorrhage Detection and Classification using AI}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Intracranial Hemorrhage (ICH) refers to bleeding within the brain. Conventional CT examinations performed by radiologists are time-consuming and may lead to ambiguity. The application of artificial intelligence methods for Intracranial Hemorrhage (ICH) detection and classification can aid radiologists in accurately identifying the specific subtype of this condition. Traditional feature extraction methods utilising convolutional neural networks (CNNs) often result in redundant feature extraction, failing to account for the interdependencies between image slices and consequently diminishing the overall performance. To address these issues, this study introduced a transformer-based approach for feature extraction and classification. To tackle the data imbalance issues in the dataset, Generative Adversarial Neural Networks(GAN) are used to generate additional images of the minority epidural class. The model was trained and tested on the Standard Radiologist Society of North America (RSNA) 2019 dataset, and the proposed model achieved accuracies of $\mathbf{9 0. 8 6 \%}, \mathbf{9 9. 7 1 \%}, \mathbf{9 6. 7 6 \%}, \mathbf{9 6. 9 9 \%}, \mathbf{9 5. 9 9 \%}$, and $\mathbf{9 4. 8 1 \%}$ for detecting any, epidural hemorrhage (EH), intraventricular hemorrhage (IVH), intra-parenchymal hemorrhage (IH), subarachnoid hemorrhage (SH), and subdural hemorrhage (SAH) subtypes respectively.},
  keywords={Decision making;Feature extraction;Transformers;Convolutional neural networks;Hemorrhaging;Artificial intelligence;North America;Kernel;Standards;Principal component analysis;Intracranial Hemorrhage detection;Attention;Classification;Generative Adversarial Neural Networks;Principal Component analysis},
  doi={10.1109/EUROCON64445.2025.11073367},
  ISSN={2837-7990},
  month={June},}@INPROCEEDINGS{10413369,
  author={Zhang, Duo and Ye, Qisheng and Wang, Di and Liang, Weixiang and Hu, Guanghui and Yang, Zhi-Xin},
  booktitle={2023 29th International Conference on Mechatronics and Machine Vision in Practice (M2VIP)}, 
  title={Real-Time Location-to-Image Generative Adversarial Networks with Sparse Sensor Data}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The prevailing machine vision-based system monitoring faces challenges in complex optical environments, such as insufficient lumination or over-exposed light, which results in a severe reduction in the accuracy of visual surveillance. To fill the gap, this work proposes a novel dual generative adversarial networks model for real-time location-to-image transformation from the sparse distributed positional sensors. The conditional generative adversarial network (cGANis applied to learn high-dimensional features from pre-generated images for enhanced accuracy. The cycleGAN, with improved structure loss and key point loss functions, further improves the generation accuracy. The effectiveness of the proposed method is verified by real monitoring experiments designed to collect a few training data for both sensor data and real images. Experimental results show that the proposed method outperforms the mainstream cGANs variants in terms of overall generation quality and detail edge sharpening.},
  keywords={Visualization;Surveillance;Training data;Generative adversarial networks;Optical imaging;Real-time systems;Optical sensors;Real-time detection;location-to-image generation;GANs;UWB IMU sensors},
  doi={10.1109/M2VIP58386.2023.10413369},
  ISSN={},
  month={Nov},}@ARTICLE{10409272,
  author={Phillips, Connor and Jiao, Junfeng and Clubb, Emmalee},
  journal={IEEE Computer Graphics and Applications}, 
  title={Testing the Capability of AI Art Tools for Urban Design}, 
  year={2024},
  volume={44},
  number={2},
  pages={37-45},
  abstract={This study aimed to evaluate the performance of three artificial intelligence (AI) image synthesis models, Dall-E 2, Stable Diffusion, and Midjourney, in generating urban design imagery based on scene descriptions. A total of 240 images were generated and evaluated by two independent professional evaluators using an adapted sensibleness and specificity average metric. The results showed significant differences between the three AI models, as well as differing scores across urban scenes, suggesting that some projects and design elements may be more challenging for AI art generators to represent visually. Analysis of individual design elements showed high accuracy in common features like skyscrapers and lawns, but less frequency in depicting unique elements such as sculptures and transit stops. AI-generated urban designs have potential applications in the early stages of exploration when rapid ideation and visual brainstorming are key. Future research could broaden the style range and include more diverse evaluative metrics. The study aims to guide the development of AI models for more nuanced and inclusive urban design applications, enhancing tools for architects and urban planners.},
  keywords={Artificial intelligence;Art;Image synthesis;Generators;Biological system modeling;Transformers;Context modeling;Computer graphics;Urban planning;Computer graphics;urban planning;artificial intelligence},
  doi={10.1109/MCG.2024.3356169},
  ISSN={1558-1756},
  month={March},}@INPROCEEDINGS{9343366,
  author={Zhang, Fangjiao and Cui, Xiang and Wang, Zhi and Chen, Shaomian and Liu, Qixu and Liu, Chaoge},
  booktitle={2020 IEEE 14th International Conference on Big Data Science and Engineering (BigDataSE)}, 
  title={A Systematic Study of AI Applications in Cybersecurity Competitions}, 
  year={2020},
  volume={},
  number={},
  pages={138-146},
  abstract={With more and more advanced persistent threats and other advanced attacks emerging, the cybersecurity situation becomes complicated and grim. Owing to its unique advantages, artificial intelligence (AI) is widely used in cybersecurity and playing an increasingly important role. However, cybersecurity talents, especially those with AI skills (defined as AISec talents) are in short supply, and talents cultivation becomes a top priority. Cybersecurity competition is one of the most effective ways to identify talents. In order to reduce the gap between supply and demand of AISec talents, we investigate the existing cybersecurity competitions concerning AI applications in the paper. We summarize several existing forms of competing in cybersecurity competitions and discuss the ways AI impacts on cybersecurity. Based on the work of above, AI competitions in categories and how AI is applied in competitions are illustrated in detail. By analyzing and summarizing, we reveal the current problems and point out the direction for future competitions to better serve in talents cultivation and selection.},
  keywords={Systematics;Supply and demand;Conferences;Big Data;Computer security;Artificial intelligence;cybersecurity competition;artificial intelligence;AI;talents cultivation},
  doi={10.1109/BigDataSE50710.2020.00026},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10871800,
  author={Fatima, Masroor and Banu, Ruqiya and Shojae Chaeikar, Saman and Khanian Najafabadi, Maryam},
  booktitle={2024 International Conference on Intelligent Computing and Next Generation Networks (ICNGN)}, 
  title={Biometric Systems in Focus: A Review of Methods, Challenges, and Future Directions}, 
  year={2024},
  volume={},
  number={},
  pages={01-07},
  abstract={Biometric authentication has emerged as an important component in strengthening cyber security, providing a superior alternative to conventional password-based systems because of their distinctive and difficult-to-duplicate attributes. This study examines diverse biometric techniques—including fingerprint, facial recognition, palm vein, and behavioral biometrics—and the incorporation of Artificial Intelligence (AI) methodologies such as Convolutional Neural Networks (CNNs) and Support Vector Machines (SVMs) to improve their dependability. Innovations including multi-modal biometrics, cancelable biometrics, and Genetic Encryption Algorithms (GEA) are examined, emphasizing their capacity to enhance security while mitigating privacy issues. The research additionally investigates continuous authentication inside IoT systems and future themes such as federated learning and quantum-resistant algorithms. Despite these developments, issues of computing complexity, scalability, consumer acceptance, and data privacy remain. The report concludes with recommendations for future research focused on optimizing biometric systems for broad implementation, improving data privacy, and creating adaptive, AI-driven methodologies to enhance biometric security.},
  keywords={Biometrics;Privacy;Data privacy;Scalability;Face recognition;Authentication;Fingerprint recognition;Biometric authentication;Security;Artificial intelligence;Biometric Authentication;Cyber Security;Artificial Intelligence;SVMs;CNNs;Multi-modal Biometrics;Machine Learning},
  doi={10.1109/ICNGN63705.2024.10871800},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10915428,
  author={Rahaman, Habibur and Chatterjee, Atri and Bhunia, Swarup},
  booktitle={2024 IEEE 33rd Asian Test Symposium (ATS)}, 
  title={Secure AI Systems: Emerging Threats and Defense Mechanisms}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The capability of artificial intelligence (AI), increasingly embedded in critical domains, faces a complex array of security threats. It has motivated researchers to explore the security vulnerability of AI solutions and propose effective countermeasures. This article offers a comprehensive exploration of diverse attacks on AI models, including backdoors (Trojans), adversarial, fault injection, data poisoning, model inversion, model extraction, membership inference attacks, etc. These security vulnerabilities are classified into two broad categories, namely, Supply Chain Attacks and Runtime Attacks. We highlight threat models, attack strategies, and defenses to secure AI systems against these attacks. The work also underscores the significance of developing secure and robust AI models and their implementation to safeguard sensitive data and embedded systems. We present some emerging research directions on secure AI systems.},
  keywords={Threat modeling;Runtime;Embedded systems;Supply chains;Machine learning;Data models;Security;Trojan horses;Artificial intelligence;Faces;Artificial Intelligence;Machine Learning;Security;Adversarial Attacks;Threat Model;and Countermeasures},
  doi={10.1109/ATS64447.2024.10915428},
  ISSN={2377-5386},
  month={Dec},}@INPROCEEDINGS{10957143,
  author={Putra, Kurniawan Andhika and Setiadi, Timothy Ansell and Nadia and Junior, Franz Adeta},
  booktitle={2024 International Conference on Informatics, Multimedia, Cyber and Information System (ICIMCIS)}, 
  title={False Information Detection with Deep Learning}, 
  year={2024},
  volume={},
  number={},
  pages={155-160},
  abstract={As we know, Artificial Intelligence (AI) technology is increasingly advanced and developing globally. AI technology has been widely used in many fields, one of which is digital forensics. With the development of AI, there are also many negative impacts such as deepfakes and voice cloning. This research aims to identify several deep learning models adapted for this detection task. The study also seeks to assess the effectiveness of various deep learning approaches in identifying deepfakes and deeper voice cloning, which can be a reliable technique to combat the spread of deepfakes and voice cloning as well. In this research we focus on looking for several models that can detect information manipulation by AI. In this experiment we want to between 2 different datasets for deepfakes and do several iterations to test the datasets. And for voice cloning, we want to test with 2 different methods, namely CNN and LSTM which are carried out in several iterations to get accurate results. The results obtained, for deepfakes, the quality of the image affects the results. For high quality, the highest percentage is 84.87% and low quality is 88.89%. Meanwhile, the voice AI model LSTM shows a higher percentage figure than CNN, namely 99.30%.},
  keywords={Deep learning;Deepfakes;Accuracy;Multimedia systems;Digital forensics;Cloning;Reliability;Artificial intelligence;Informatics;Long short term memory;Artificial Intelligence;deepfake;voice AI;manipulation},
  doi={10.1109/ICIMCIS63449.2024.10957143},
  ISSN={2837-5203},
  month={Nov},}@ARTICLE{11091381,
  author={Lan, Guipeng and Zhu, Yong and Xiao, Shuai and Iqbal, Muddesar and Yang, Jiachen},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Mitigating Data Bias in Healthcare AI with Self-Supervised Standardization}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={The rapid advancement of artificial intelligence (AI) in healthcare has accelerated innovations in medical algorithms, yet its broader adoption faces critical ethical and technical barriers. A key challenge lies in algorithmic bias stemming from heterogeneous medical data across institutions, equipment, and workflows, which may perpetuate disparities in AI-driven diagnoses and exacerbate inequities in patient care. While AI's ability to extract deep features from large-scale data offers transformative potential, its effectiveness heavily depends on standardized, high-quality datasets. Current standardization gaps not only limit model generalizability but also raise concerns about reliability and fairness in real-world clinical settings, particularly for marginalized populations. Addressing these urgent issues, this paper proposes an ethical AI framework centered on a novel self-supervised medical image standardization method. By integrating self-supervised image style conversion, channel attention mechanisms, and contrastive learning-based loss functions, our approach enhances structural and style consistency in diverse datasets while preserving patient privacy through decentralized learning paradigms. Experiments across multi-institutional medical image datasets demonstrate that our method significantly improves AI generalizability without requiring centralized data sharing. By bridging the data standardization gap, this work advances technical foundations for trustworthy AI in healthcare.},
  keywords={Medical diagnostic imaging;Standardization;Artificial intelligence;Attention mechanisms;Feature extraction;Training;Medical services;Data models;Codes;Generators;Medical image standardization;artificial intelligence;medical image analysis},
  doi={10.1109/JBHI.2025.3588196},
  ISSN={2168-2208},
  month={},}@INPROCEEDINGS{11104890,
  author={Pantin, Roman and Yunusova, Rimma and Abdullaeva, Barno and Yuldasheva, Saodat},
  booktitle={2025 International Conference on Smart Learning Courses (SCME)}, 
  title={AI Integration with Digital Infrastructure: Advancing Governance, Efficiency, and Inclusivity}, 
  year={2025},
  volume={},
  number={},
  pages={136-145},
  abstract={Artificial intelligence (AI) and digital public infrastructure (DPI) are transforming public governance and service delivery. However, limited research has examined the integration of AI, particularly deep learning, into DPI systems. This study explores how AI-DPI convergence can improve governance efficiency, inclusivity, and scalability. The central research question guiding this paper is: How can deep learning facilitate the integration of AI into DPI to advance public value? The research applies thematic analysis to 60 peer-reviewed publications from 2022–2024, selected for relevance, novelty, and credibility. Key findings identify deep learning as a fusion mechanism enhancing language localization, fraud detection, personalized services, and data fusion within DPI systems. Results show that while such integration holds transformative potential, it also raises ethical, technical, and legacy system challenges. This paper contributes an interdisciplinary analytical framework and policy recommendations, offering actionable insights for future development of intelligent, inclusive digital infrastructures.},
  keywords={Deep learning;Ethics;Scalability;Public infrastructure;Standardization;Aging;Fraud;Stakeholders;Artificial intelligence;Recommender systems;Artificial Intelligence;Digital Public Infrastructure;Deep Learning;Public Services;Policy;Recommender Systems;NLP},
  doi={10.1109/SCME62582.2025.11104890},
  ISSN={},
  month={July},}@INPROCEEDINGS{10778711,
  author={Gyimah, Frank Offei and Ofori-Mensah, Ernest and Boowuo, Henrietta and Aggrawal, Sakhi},
  booktitle={2024 Cyber Awareness and Research Symposium (CARS)}, 
  title={Friend or Foe? AI and the Evolving Landscape of Ransomware-as-a-Service (RaaS)}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper examines Ransomware-as-a-Service (RaaS) and its impact on cybercrime. RaaS has made sophisticated attacks accessible to a wider range of criminals, increasing the number of ransomware attacks. The paper explores how Artificial Intelligence (AI) is being used by both attackers and defenders in this evolving landscape. AI empowers RaaS attackers by improving target selection, vulnerability identification, and social engineering tactics. It also automates attack processes, making them more efficient. For defenders, AI offers potential in threat detection, vulnerability assessment, and incident response through real-time data analysis. However, challenges like model development complexity, false positives, and the need for explainable AI models exist for both sides. The paper concludes that AI use by both attackers and defenders creates an "AI arms race" in cybersecurity. It further aim(s) to illuminate future cybersecurity strategies and equip defenders with proactive measures against evolving cyber threats.},
  keywords={Data analysis;Explainable AI;Weapons;Fasteners;Threat assessment;Real-time systems;Ransomware;Artificial intelligence;Computer crime;Research and development;Ransomware;AI in Cybersecurity;Artificial Intelligence;Cybersecurity;Ransomware-as-a-Service;RaaS;Attackers;Defenders;Cybercrime},
  doi={10.1109/CARS61786.2024.10778711},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10092230,
  author={Harguess, Josh and Ward, Chris M.},
  booktitle={2022 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)}, 
  title={Is the Next Winter Coming for AI? Elements of Making Secure and Robust AI}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={While the recent boom in Artificial Intelligence (AI) has given rise to the technology's use and popularity across many domains, the same boom has exposed vulnerabilities of the technology to many threats that could cause the next "AI winter". AI is no stranger to "winters", or drops in funding and interest in the technology and its applications. Many in the field consider the early 1970's as the first AI winter with another proceeding in the late 1990's and early 2000's. There is some consensus that another AI winter is all but inevitable in some shape or form, however, current thoughts on the next winter do not consider secure and robust AI and the implications of the success or failure of these areas. The emergence of AI as an operational technology introduces potential vulnerabilities to AI's longevity. The National Security Commission on AI (NSCAI) report outlines recommendations for building secure and robust AI, particularly in government and Department of Defense (DoD) applications. However, are they enough to help us fully secure AI systems and prevent the next "AI winter"? An approaching "AI Winter" would have a tremendous impact in DoD systems as well as those of our adversaries. Understanding and analyzing the potential of this event would better prepare us for such an outcome as well as help us understand the tools needed to counter and prevent this "winter" by securing and robustifying our AI systems. In this paper, we introduce the following four pillars of AI assurance, that if implemented, will help us to avoid the next AI winter: security, fairness, trust, and resilience.},
  keywords={Measurement;Shape;Robustness;US Department of Defense;Pattern recognition;Security;History},
  doi={10.1109/AIPR57179.2022.10092230},
  ISSN={2332-5615},
  month={Oct},}@BOOK{10745316,
  author={Clinton, David},
  booktitle={The Complete Obsolete Guide to Generative AI},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={The last book on AI you’ll ever need. We swear! AI technology moves so fast that this book is probably already out of date! But don’t worry—The Complete Obsolete Guide to Generative AI is still an essential read for anyone who wants to make generative AI into a tool rather than a toy. It shows you how to get the best out of AI no matter what changes come in the future. You’ll be able to use common automation and scripting tools to take AI to a new level, and access raw (and powerful) GPT models via API. Inside The Complete Obsolete Guide to Generative AI you will find:  Just enough background info on AI! What an AI model is how it works Ways to create text, code, and images for your organization's needs Training AI models on your local data stores or on the internet Business intelligence and analytics uses for AI Building your own custom AI models Looking ahead to the future of generative AI  Where to get started? How about creating exciting images, video, and even audio with AI. Need more? Learn to harness AI to speed up any everyday work task, including writing boilerplate code, creating specialized documents, and analyzing your own data. Push beyond simple ChatGPT prompts! Discover ways to double your productivity and take on projects you never thought were possible! AI—and this book—are here to show you how.},
  keywords={models;text;code;images;custom;API;ChatGPT;Copilot;OpenAI;LLMs;large language models;video;voice;prompts;business intelligence;analytics;productivity;interactive},
  doi={},
  ISSN={},
  publisher={Manning},
  isbn={9781633436985},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10745316},}@INBOOK{10953261,
  author={Lopez-Lira, Alejandro},
  booktitle={The Predictive Edge: Outsmart the Market using Generative AI and ChatGPT in Financial Forecasting}, 
  title={Front Matter}, 
  year={2024},
  volume={},
  number={},
  pages={i-xix},
  abstract={<p>The prelims comprise: <ul> <li>Half&#x2010;Title Page</li> <li>Title Page</li> <li>Copyright Page</li> <li>Dedication Page</li> <li>Contents</li> <li>Preface</li> <li>Introduction</li> </ul> </p>},
  keywords={},
  doi={10.1002/9781394308286.fmatter},
  ISSN={},
  publisher={Wiley},
  isbn={9781394242733},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10953261},}@INPROCEEDINGS{10335522,
  author={Maitra, Sarit and Mishra, Vivek and Verma, Pratima and Chopra, Manav and Nath, Priyanka},
  booktitle={2023 International Conference on Electrical and Information Technology (IEIT)}, 
  title={Sampling - Variational Auto Encoder - Ensemble: In the Quest of Explainable Artificial Intelligence}, 
  year={2023},
  volume={},
  number={},
  pages={43-50},
  abstract={Explainable Artificial Intelligence (XAI) models have recently attracted a great deal of interest from a variety of application sectors. Despite significant developments in this area, there are still no standardized methods or approaches for understanding AI model outputs. A systematic and cohesive framework is also increasingly necessary to incorporate new techniques like discriminative and generative models to close the gap. This paper contributes to the discourse on XAI by presenting an empirical evaluation based on a novel framework: Sampling - Variational Auto Encoder (VAE) - Ensemble Anomaly Detection (SVEAD). It is a hybrid architecture where VAE combined with ensemble stacking and SHapley Additive exPlanations is used for imbalanced classification. The finding reveals that combining ensemble stacking, VAE, and SHAP can not only lead to better model performance but also provide an easily explainable framework. This work has used SHAP combined with Permutation Importance and Individual Conditional Expectations to create a powerful interpretability of the model. The finding has an important implication in the real world, where the need for XAI is paramount to boost confidence in AI applications.},
  keywords={Additives;Systematics;Scalability;Stacking;Feature extraction;Data models;Ensemble learning;discriminative model;explainable artificial intelligence;generative model;sampling-variational auto encoder - ensemble anomaly detection;shapley additive explanations},
  doi={10.1109/IEIT59852.2023.10335522},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8834492,
  author={Singh, Vedant and Oza, Manan and Vaghela, Himanshu and Kanani, Pratik},
  booktitle={2019 International Conference of Artificial Intelligence and Information Technology (ICAIIT)}, 
  title={Auto-Encoding Progressive Generative Adversarial Networks for 3D Multi Object Scenes}, 
  year={2019},
  volume={},
  number={},
  pages={481-485},
  abstract={3D multi object generative models allow us to synthesize a large range of novel 3D multi object scenes and also identify objects, shapes, layouts and their positions. But multi object scenes are difficult to create because of the dataset being multimodal in nature. The conventional 3D generative adversarial models are not efficient in generating multi object scenes, they usually tend to generate either one object or generate fuzzy results of multiple objects. Auto-encoder models have much scope in feature extraction and representation learning using the unsupervised paradigm in probabilistic spaces. We try to make use of this property in our proposed model. In this paper we propose a novel architecture using 3DConvNets trained with the progressive training paradigm that has been able to generate realistic high resolution 3D scenes of rooms, bedrooms, offices etc. with various pieces of furniture and objects. We make use of the adversarial auto-encoder along with the WGAN-GP loss parameter in our discriminator loss function. Finally this new approach to multi object scene generation has also been able to generate more number of objects per scene.},
  keywords={Three-dimensional displays;Generators;Generative adversarial networks;Solid modeling;Training;Shape;Computational modeling;GANs;3D;progressive GANs;auto-encoder},
  doi={10.1109/ICAIIT.2019.8834492},
  ISSN={},
  month={March},}@INBOOK{10897226,
  author={Islam, Mohammad Rubyet},
  booktitle={Generative AI, Cybersecurity, and Ethics}, 
  title={Introduction}, 
  year={2025},
  volume={},
  number={},
  pages={1-16},
  abstract={Summary <p>In today's fast&#x2010;paced digital world, the intersection of generative artificial intelligence (GenAI), cybersecurity, and ethics presents both thrilling opportunities and significant challenges. This book embarks on an exciting journey, showcasing how GenAI enhances digital security while addressing the ethical dilemmas that arise. From safeguarding personal data to thwarting complex cyberattacks, understanding the link between AI and cybersecurity is more crucial than ever. As we unlock GenAI's potential, we also encounter new ethical challenges, necessitating responsible harnessing of these advanced technologies. This introductory chapter explores pivotal themes in GenAI, cybersecurity, and ethics, laying the foundation for a comprehensive examination of this captivating subject.</p>},
  keywords={Artificial intelligence;Deep learning;Biological neural networks;Virtual assistants;Technological innovation;Propulsion;Programming;Generative AI;Data visualization;Virtual environments},
  doi={10.1002/9781394279326.ch1},
  ISSN={},
  publisher={Wiley},
  isbn={9781394279319},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10897226},}@INPROCEEDINGS{11027810,
  author={Zhang, Xiaoran and Cai, Shixuan and Wu, Wenqi and Wu, Songruoyao and Shen, Hanshu and Zhang, Kejun},
  booktitle={2024 17th International Symposium on Computational Intelligence and Design (ISCID)}, 
  title={A New Strategy to Reduce Design Fixation: Presenting Virtual Model Text to Designers in a Mixed Sequential Manner}, 
  year={2024},
  volume={},
  number={},
  pages={79-83},
  abstract={Design fixation refers to the phenomenon where designers adhere to a limited set of ideas during the design process, thereby hindering innovation. Utilizing various types of stimulus materials is considered a significant method to alleviate design fixation. With the rapid development of generative artificial intelligence technologies, designers can efficiently access a variety of inspirational stimulus materials. However, research on how to best combine multiple types of stimulus materials to mitigate design fixation is sparse. This study combined two types of stimulus materials—text and virtual models—and experimentally explored the impact of stimulus timing (synchronous, virtual model before text, and text before virtual model) and combination forms (matching and mixed) on design fixation. The results indicate that presenting the physical model before the text in a mixed sequential manner effectively alleviates design fixation.},
  keywords={Technological innovation;Generative AI;Design methodology;Timing;Computational intelligence;Multi-modal stimuli;Combination forms;Stimulus timing;Generative artificial intelligence;Design fixation},
  doi={10.1109/ISCID63852.2024.00027},
  ISSN={2473-3547},
  month={Dec},}@INPROCEEDINGS{11167458,
  author={Poornima, G. and Poorvadevi, R. and Bebitha, J. and Kumar, T. Dinesh and Archana, M. A. and Karthikeyan, B.},
  booktitle={2025 3rd International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)}, 
  title={Generative AI in Medical Imaging: Enhancing Lung Nodule Detection using GANs}, 
  year={2025},
  volume={},
  number={},
  pages={1624-1629},
  abstract={Lung cancer continues to be a predominant cause of cancer-related mortality globally, and early diagnosis with computed tomography (CT) imaging markedly enhances patient outcomes. The limited availability of annotated medical imaging data presents a significant obstacle in developing effective deep learning models for lung nodule detection. This paper presents a system based on Generative Adversarial Networks (GANs) to generate realistic lung nodule images, tackling the issues of data imbalance and augmentation in medical imaging. Utilizing the LIDC-IDRI dataset, comprising expert-annotated thoracic CT scans, we train a conditional GAN to produce high-quality synthetic lung nodule patches based on size and malignancy characteristics. Synthetic data is combined with real samples to train a convolutional neural network (CNN) classifier, leading to enhanced performance metrics in accuracy, sensitivity, and AUC-ROC. Qualitative and quantitative assessments indicate that our GAN-generated images closely mimic authentic nodules, as validated by radiomic feature distributions and visual Turing tests. The suggested generative methodology improves model generalizability, facilitates clinical decision-making, and establishes a foundation for data-efficient AI systems in pulmonary diagnostics. This study emphasizes the capacity of generative AI to enhance medical datasets and facilitate early-stage lung cancer identification.},
  keywords={Generative Adversarial Networks;Lung Nodule Detection;Medical Imaging;LIDC-IDRI Dataset;Conditional GAN;Deep Learning;Radiomics;Data Augmentation;Malignancy Classification;AI in Healthcare},
  doi={10.1109/ICSCDS65426.2025.11167458},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{11022117,
  author={Imdadul Alam, Gazi Mohammad and Tasnia, Naima and Hasan, Muhammad Asif and Binte Rahman, Rubaba},
  booktitle={2024 27th International Conference on Computer and Information Technology (ICCIT)}, 
  title={Blood Cell Identification Using Deep Transfer Learning and Explainable Artificial Intelligence Techniques}, 
  year={2024},
  volume={},
  number={},
  pages={957-962},
  abstract={Blood cell identification is a critical task in medical diagnosis, particularly for detecting and monitoring various hematological conditions. Automation of blood cell detection offers a solution to these challenges. This study presents a comprehensive study on the application of deep learning for automated blood cell identification, specifically, the Inception V3 model, showcasing its potential to revolutionize diagnostic accuracy in medical imaging. By employing advanced pre-processing techniques, and optimal model design, the InceptionV3 model achieved impressive results with 98.8% test accuracy on a dataset of high-quality microscopic blood cell images. To enhance decision-making transparency, the study employs Explainable AI (XAI) approaches such as Grad-CAM and Grad-CAM++ to produce heatmaps that highlight significant regions influencing the model’s identification. The study incorporated a comparative investigation with other deep-learning models, including VGG16, VGG19, and RESNET50. The efficacy of blood cell identification is demonstrated by evaluation measures like precision, recall, F1 score, Jaccard similarity, MCC score, and overall accuracy. The combination of strong performance and transparency through XAI techniques makes it a valuable tool for precise and dependable diagnoses. The potential of integrating advanced deep learning and XAI methods to improve the reliability and clinical adoption of automated blood cell identification systems is highlighted in this study.},
  keywords={Deep learning;Accuracy;Explainable AI;Microscopy;Transfer learning;Reliability;Blood;Monitoring;Medical diagnostic imaging;Residual neural networks;Deep Learning;Medical Image Analysis;Blood Cell;Explainable AI (XAI);Grad-CAM},
  doi={10.1109/ICCIT64611.2024.11022117},
  ISSN={2474-9656},
  month={Dec},}@INPROCEEDINGS{9907905,
  author={Xu, Tongyang and Wei, Zhongxiang},
  booktitle={2022 13th International Symposium on Communication Systems, Networks and Digital Signal Processing (CSNDSP)}, 
  title={Waveform Defence Against Deep Learning Generative Adversarial Network Attacks}, 
  year={2022},
  volume={},
  number={},
  pages={503-508},
  abstract={Physical layer (PHY) in communications is open to public and therefore it is highly vulnerable to over-the-air attacks such as spoofing, which will cause malicious communication resource occupation and result in reduced spectral efficiency. Traditional countermeasures rely on physical layer authentication (PLA) where unique hardware features and propagation channel features from legitimate users are difficult for an attacker to replicate. However, due to the advancement of artificial intelligence (AI), an intelligent attack method, based on generative adversarial network (GAN), is becoming more challenging. The GAN framework can use deep learning to impersonate a legitimate user including its signal pattern, hardware impairments and wireless channel characteristics. Therefore, traditional PLA methods will not work well in such GAN attack scenarios. This work will deal with the GAN attack challenge from a waveform design perspective. We investigate three waveform candidates with unique signal features such as orthogonality, non-orthogonality and windowing. Simulation results reveal that GAN attackers can successfully learn waveforms with either orthogonal or nonorthogonal features while it is difficult to learn the windowing characteristic. Therefore, this work reveals a robust waveform defence solution to combat with intelligent GAN attacks.},
  keywords={Deep learning;Wireless communication;Spectral efficiency;OFDM;Authentication;Programmable logic arrays;Generative adversarial networks;Deep learning;adversarial;generative adversarial network (GAN);waveform;fingerprint;signal classification;physical layer authentication (PLA);security;privacy},
  doi={10.1109/CSNDSP54353.2022.9907905},
  ISSN={},
  month={July},}@INPROCEEDINGS{9845081,
  author={Duan, Xiaowei and Han, Yiliang and Wang, Chao and Ni, Huanhuan},
  booktitle={2022 International Conference on Blockchain Technology and Information Security (ICBCTIS)}, 
  title={Optimization of Encrypted Communication Model Based on Generative Adversarial Network}, 
  year={2022},
  volume={},
  number={},
  pages={20-24},
  abstract={With the progress of cryptography computer science, designing cryptographic algorithms using deep learning is a very innovative research direction. Google Brain designed a communication model using generation adversarial network and explored the encrypted communication algorithm based on machine learning. However, the encrypted communication model it designed lacks quantitative evaluation. When some plaintexts and keys are leaked at the same time, the security of communication cannot be guaranteed. This model is optimized to enhance the security by adjusting the optimizer, modifying the activation function, and increasing batch normalization to improve communication speed of optimization. Experiments were performed on 16 bits and 64 bits plaintexts communication. With plaintext and key leak rate of 0.75, the decryption error rate of the decryptor is 0.01 and the attacker can't guess any valid information about the communication.},
  keywords={Training;Machine learning algorithms;Error analysis;Computational modeling;Generative adversarial networks;Brain modeling;Stability analysis;Generative adversarial networks;Artificial intelligence;Convolutional neural network;Plaintext leakage},
  doi={10.1109/ICBCTIS55569.2022.00016},
  ISSN={},
  month={July},}@INPROCEEDINGS{11155695,
  author={Liang, Yo-Wen and Liu, Zih-Syuan},
  booktitle={2025 IEEE Gaming, Entertainment, and Media Conference (GEM)}, 
  title={Using Generative AI to Develop Product Forms for Interactive Virtual Reality Educational Tools}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={The purpose of this study is to optimize the product design of existing VR devices by using generative AI with high development potential, and at the same time, to improve the usability of VR devices by remedying the weaknesses of current generative AI through collaborative design by designer. In this study, 30 students with interactive VR teaching needs were collected to experiment to analyze the usability of three types of VR devices: original, AI design, and AI + designer design handles. The participants were asked to operate the three VR devices, and after completing the tasks set in the experiment through the VR devices, the participants were asked to fill out the SUS scale to evaluate the usability. The results show that the usability of the AI + designer- designed devices is higher than that of the original and AI design devices, reaching statistical significance. This indicates that AI + designer design is one of the product design directions worth investigating in the future, which cannot only effectively utilize the advantages of AI's rapid proposal, but also compensate for the pain points of AI technology that cannot satisfy users' needs at this stage, and ultimately improve the effectiveness of product design.},
  keywords={Generative AI;Pain;Education;Entertainment industry;Collaboration;Virtual reality;Media;Product design;Proposals;Usability;virtual reality;generative AI;product design;usability},
  doi={10.1109/GEM66882.2025.11155695},
  ISSN={2766-6530},
  month={July},}@INPROCEEDINGS{9206847,
  author={Liu, Ruijiao and Li, Yangyang and Jiao, Licheng},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, 
  title={SAR Image Specle Reduction based on a Generative Adversarial Network}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={Synthetic aperture radar (SAR) image despeckling is recognized as the basis for SAR image processing and interpretation. Over the past decades, many impressed speckle reduction methods have been developed and achieved good performance under certain circumstances. However, how to suppress speckle noise in a homogeneous region while more effectively protecting details and avoid distortion of data features caused by homomorphic transformation is still an urgent problem. In this paper, a novel speckle reduction algorithm based on generative adversarial network (GAN) is proposed, which contains a generator and a discriminator. For the generator that is used directly for subsequent noise reduction, a total variation (TV) loss function is added. Meanwhile, we directly learn the mapping between the input image and the ground truth rather than the logarithmic transformation. Indeed, the improved lightweight discriminative network will also provide learning guidance for the generator. Experiments on simulatedSAR images and real SAR images demonstrate the improvement in visual and statistical performance comparing to the state-of-the-art despeckling algorithms.},
  keywords={Speckle;Generators;Generative adversarial networks;Gallium nitride;Synthetic aperture radar;TV;Transforms;SAR image;despeckling;GAN;generator;discriminator;TV},
  doi={10.1109/IJCNN48605.2020.9206847},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{10181524,
  author={Noureen, Sadia and Syed, Iqrar Hussain and Abdellatif, Alaa Awad and Mehmood, Muhammad Qasim and Massoud, Yehia},
  booktitle={2023 IEEE International Symposium on Circuits and Systems (ISCAS)}, 
  title={Reducing Complexity and data-set-Size Through Physics Inspired Tandem Neural Network}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Owing to ample potential and versatile capabilities of artificial intelligence to solve intricate scientific problems, two regression-based artificial neural network (ANN) models are proposed to design and optimize nano-structured meta-atoms. The proposed forward predicting ANN depicts that considering the complete structural and material information of the cylindrical nano-pillar meta-atoms could predict the corresponding electromagnetic (EM) response (amplitude and phase of transmission) with a mean squared error (MSE) as low as $\mathbf{2.1}\times \mathbf{10}^{-\mathbf{3}}$. Thus, it replaces the conventional EM simulations performed using high-end commercial software's, while significantly saving time and computational resources. Inverse design deep-learning model is also presented, which is connected with the pre-trained forward model and trained in a tandem architecture to provide an optimum set of dimensions and material, given the target response as its input. Furthermore, a comparative study regarding the number of hidden layers of the ANN and the amount of training dataset size is performed for the proposed forward and tandem inverse models to analyze the effect of considering extra underlying physics related information, i.e., wavelength regime and the EM spectral information. This study reveals that considering the extra information can lead to a significant reduction in the obtained MSE. Specifically, the proposed model could achieve a decent MSE even with a smaller amount of training dataset. Hence, the use of artificial intelligence models significantly reduces the training time and computational complexity of the proposed solution.},
  keywords={Training;Inverse problems;Computational modeling;Artificial neural networks;Computer architecture;Software;Electromagnetics;artificial intelligence;nano-structures;tandem inverse design},
  doi={10.1109/ISCAS46773.2023.10181524},
  ISSN={2158-1525},
  month={May},}@INBOOK{10948950,
  author={Banafa, Ahmed},
  booktitle={Artificial Intelligence in Action: Real-World Applications and Innovations}, 
  title={37 Collective AI: The Power of Collaboration in Artificial Intelligence}, 
  year={2025},
  volume={},
  number={},
  pages={239-244},
  abstract={This comprehensive book dives deep into the current landscape of AI, exploring its fundamental principles, development challenges, potential risks, and the cutting-edge breakthroughs that are propelling it forward. Artificial intelligence (AI) is rapidly transforming industries and societies worldwide through groundbreaking innovations and real-world applications. Starting with the core concepts, the book examines the various types of AI systems, generative AI models, and the complexities of machine learning. It delves into the programming languages driving AI development, data pipelines, model creation and deployment processes, while shedding light on issues like AI hallucinations and the intricate path of machine unlearning. The book then showcases the remarkable real-world applications of AI across diverse domains. From preventing job displacement and promoting environmental sustainability, to enhancing disaster response, drone technology, and even nuclear energy innovation, it highlights how AI is tackling complex challenges and driving positive change. The book also explores the double-edged nature of AI, recognizing its tremendous potential while cautioning about the risks of misuse, unintended consequences, and the urgent need for responsible development practices. It examines the intersection of AI and fields like operating system design, warfare, and semiconductor technology, underscoring the wide-ranging implications of this transformative force. As the quest for artificial general intelligence (AGI) and superintelligent AI systems intensifies, the book delves into cutting-edge research, emerging trends, and the pursuit of multimodal, explainable, and causally aware AI systems. It explores the symbiotic relationship between AI and human creativity, the rise of user-friendly "casual AI," and the potential of AI to tackle open-ended tasks. This is an essential guide for understanding the profound impact of AI on our world today and its potential to shape our future. From the frontiers of innovation to the challenges of responsible development, this book offers a comprehensive and insightful exploration of the remarkable real-world applications and innovations driving the AI revolution.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770046190},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10948950},}@INPROCEEDINGS{9102917,
  author={Hong, Yan and Niu, Li and Zhang, Jianfu and Zhang, Liqing},
  booktitle={2020 IEEE International Conference on Multimedia and Expo (ICME)}, 
  title={Matchinggan: Matching-Based Few-Shot Image Generation}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={To generate new images for a given category, most deep generative models require abundant training images from this category, which are often too expensive to acquire. To achieve the goal of generation based on only a few images, we propose matching-based Generative Adversarial Network (GAN) for few-shot generation, which includes a matching generator and a matching discriminator. Matching generator can match random vectors with a few conditional images from the same category and generate new images for this category based on the fused features. The matching discriminator extends conventional GAN discriminator by matching the feature of generated image with the fused feature of conditional images. Extensive experiments on three datasets demonstrate the effectiveness of our proposed method.},
  keywords={Generators;Generative adversarial networks;Gallium nitride;Training;Fuses;Decoding;Image generation;Few-shot learning;generative adversarial network},
  doi={10.1109/ICME46284.2020.9102917},
  ISSN={1945-788X},
  month={July},}@ARTICLE{9492295,
  author={Xie, Qin and Zhang, Peng and Yu, Boseon and Choi, Jaesik},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Semisupervised Training of Deep Generative Models for High-Dimensional Anomaly Detection}, 
  year={2022},
  volume={33},
  number={6},
  pages={2444-2453},
  abstract={Abnormal behaviors in industrial systems may be early warnings on critical events that may cause severe damages to facilities and security. Thus, it is important to detect abnormal behaviors accurately and timely. However, the anomaly detection problem is hard to solve in practice, mainly due to the rareness and the expensive cost to get the labels of the anomalies. Deep generative models parameterized by neural networks have achieved state-of-the-art performance in practice for many unsupervised and semisupervised learning tasks. We present a new deep generative model, Latent Enhanced regression/classification Deep Generative Model (LEDGM), for the anomaly detection problem with multidimensional data. Instead of using two-stage decoupled models, we adopt an end-to-end learning paradigm. Instead of conditioning the latent on the class label, LEDGM conditions the label prediction on the learned latent so that the optimization goal is more in favor of better anomaly detection than better reconstruction that the previously proposed deep generative models have been trained for. Experimental results on several synthetic and real-world small- and large-scale datasets demonstrate that LEDGM can achieve improved anomaly detection performance on multidimensional data with very sparse labels. The results also suggest that both labeled anomalies and labeled normal are valuable for semisupervised learning. Generally, our results show that better performance can be achieved with more labeled data. The ablation experiments show that both the original input and the learned latent provide meaningful information for LEDGM to achieve high performance.},
  keywords={Anomaly detection;Data models;Semisupervised learning;Generative adversarial networks;Training;Generators;Unsupervised learning;Anomaly detection;deep generative models;semisupervised learning;variational autoencoder (VAE)},
  doi={10.1109/TNNLS.2021.3095150},
  ISSN={2162-2388},
  month={June},}@INPROCEEDINGS{10779781,
  author={Priya, K. M. and Soundarya, P. and Kungumaraj, E. and Bhagyarathi, P. and Subathra, P. and Varghese, Susmi Mariam},
  booktitle={2024 IEEE International Conference on Signal Processing, Informatics, Communication and Energy Systems (SPICES)}, 
  title={Harnessing Generative AI for IoT Enhanced Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper explores the integration of Generative Artificial Intelligence (AI) techniques with the Internet of Things (IoT) to revolutionize educational paradigms. Leveraging Generative AI, such as deep learning models, alongside IoT devices opens up new avenues for personalized and immersive learning experiences. Through the analysis of real-time data collected by IoT sensors, coupled with Generative AI's ability to synthesize content, educational environments can be dynamically adapted to individual learning styles and preferences. This abstract presents a framework for the synergy between Generative AI and IoT, emphasizing their combined potential to create interactive educational platforms. By harnessing Generative AI for content generation and IoT for data collection and analysis, educational systems can be tailored to cater to diverse learners, fostering engagement, retention, and comprehension. The integration of these technologies promises to reshape the landscape of education, offering adaptive, interactive, and enriched learning experiences for students across various disciplines and demographics.},
  keywords={Technological innovation;Ethics;Generative AI;Education;Signal processing;SPICE;Real-time systems;Internet of Things;Intelligent sensors;Investment;Generative AI;Internet of Things (IoT);Education;Personalization;Adaptive learning},
  doi={10.1109/SPICES62143.2024.10779781},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10308936,
  author={Belanec, Róbert and Lacko, Peter and Malinovská, Kristína},
  booktitle={2023 World Symposium on Digital Intelligence for Systems and Machines (DISA)}, 
  title={Controlling the Output of a Generative Model by Latent Feature Vector Shifting}, 
  year={2023},
  volume={},
  number={},
  pages={24-30},
  abstract={State-of-the-art generative models (e.g. StyleGAN3 [1]) often generate photorealistic images based on vectors sampled from their latent space. However, the ability to control the output is limited. Here we present our novel method for latent vector shifting for controlled output image modification utilizing semantic features of the generated images. In our approach we use a pre-trained model of StyleGAN3 that generates images of realistic human faces in relatively high resolution. We complement the generative model with a convolutional neural network classifier, namely ResNet34, trained to classify the generated images with binary facial features from the CelebA dataset. Our latent feature shifter is a neural network model with a task to shift the latent vectors of a generative model into a specified feature direction. We have trained latent feature shifter for multiple facial features, and outperformed our baseline method in the number of generated images with the desired feature. To train our latent feature shifter neural network, we have designed a dataset of pairs of latent vectors with and without a certain feature. Based on the evaluation, we conclude that our latent feature shifter approach was successful in the controlled generation of the StyleGAN3 generator.},
  keywords={Image resolution;Neural networks;Semantics;Generative adversarial networks;Generators;Indexes;Digital intelligence;Index Terms: generative adversarial networks;controlled generation},
  doi={10.1109/DISA59116.2023.10308936},
  ISSN={},
  month={Sep.},}@ARTICLE{10931029,
  author={Lopes, Felipe A. and Sagan, Vasit and Sarkar, Supria and Stylianou, Abby and Esposito, Flavio},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Geospatial Time Machine: A Generative Model to Enhance Spectral–Temporal Data Resolution}, 
  year={2025},
  volume={63},
  number={},
  pages={1-13},
  abstract={Geospatial artificial intelligence (GeoAI) and data processing techniques have significantly advanced object detection, prediction, and classification tasks. However, the availability of machine learning-ready, labeled data for specific applications such as plant disease detection remains the major challenge for the broader adoption of GeoAI. For instance, collecting temporal unmanned aerial vehicle (UAV) imagery of agricultural crops to track disease emergence and progress requires substantial human labor and resources, which is often limited to a small spatial scale. Recognizing the pivotal role of temporal data in pattern recognition, object detection, and scene reconstruction, we introduce an innovative approach to augment multispectral temporal datasets: the geospatial time machine (GTM). Our proposed methodology combines graph neural network (GNN) and generative adversarial network (GAN) architectures to generate comprehensive synthetic temporal data encompassing multivariate time series. The results demonstrate that imagery generated through backcasting can enhance the accuracy of downstream classification tasks by up to 53% in plant disease detection, particularly in the initial stages of analyzing a crop growth using multispectral and multitemporal datasets.},
  keywords={Data models;Predictive models;Accuracy;Image reconstruction;Generative adversarial networks;Graph neural networks;Time series analysis;Imputation;Remote sensing;Crops;Data augmentation;deep learning;generative adversarial networks (GANs);generative artificial intelligence (GenAI);graph neural networks (GNNs);multispectral},
  doi={10.1109/TGRS.2025.3552629},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{10255179,
  author={Oh, Subin and Shon, Taeshik},
  booktitle={2023 International Conference on Platform Technology and Service (PlatCon)}, 
  title={Cybersecurity Issues in Generative AI}, 
  year={2023},
  volume={},
  number={},
  pages={97-100},
  abstract={Generative AI technology is being applied in various fields. However, the advancement of these technologies also raises cybersecurity issues. In fact, there are cases of cyber attack using Generative AI, and the number is increasing. Therefore, this paper analyzes the potential cybersecurity issues associated with Generative AI. First, we looked at the fields where Generative AI is used. Representatively, Generative AI is being used in text, image, video, audio, and code. Based on these five fields, cybersecurity issues that may occur in each field were analyzed. Finally, we discuss the obligations necessary for the future development and use of Generative AI.},
  keywords={Ethics;Codes;Education;Regulation;Artificial intelligence;Computer security;Cyberattack;Generative AI;Generative Models;Cybersecurity},
  doi={10.1109/PlatCon60102.2023.10255179},
  ISSN={2766-4198},
  month={Aug},}@INPROCEEDINGS{10932090,
  author={Patil, Apurva and Surendran, Surya and Ranade, Neeta},
  booktitle={2024 International Conference on Communication, Control, and Intelligent Systems (CCIS)}, 
  title={Enigma Sound : AI driven Music Generation with Emotional Intelligence}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={AI-driven music generation with emotional intelligence(EI) is a new discipline that blends emotional detection and artificial intelligence to create personalised musical experiences. The Artificial Intelligence(AI) system can analyze data from various sources such as user inputs, physiological signals, facial expressions, among many others,in order to create music in resonance with an individual’s emotional state. This project aims at developing an AI system that enables the design and generation of music which recognizes and responds to the human emotions through incorporation of emotional intelligence. The system will recognize the user’s emotional state and produce music that responds to their needs by using face identification, text analysis, and audio processing. These systems use natural language processing and deep learning models to comprehend emotions and generate music.},
  keywords={Emotion recognition;Text analysis;Text recognition;Face recognition;Music;Process control;Natural language processing;Resonance;Physiology;Multiple signal classification;Audio Processing;Emotional Intelligence;Face detection;Machine Learning;Music;NLP;Text Analysis},
  doi={10.1109/CCIS63231.2024.10932090},
  ISSN={},
  month={Dec},}@ARTICLE{10966017,
  author={Hu, Hailong and Pang, Jun},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Ownership Infringement Detection for Generative Adversarial Networks against Model Stealing}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={Generative adversarial networks (GANs) have shown remarkable success in image synthesis, making GAN models themselves commercially valuable to legitimate model owners. Therefore, it is critical to technically protect the intellectual property of GANs. Prior works need to tamper with the training set or training process to verify the ownership of a GAN. In this paper, we show that these methods are not robust to emerging model extraction attacks. Then, we propose a new method GAN-Guards which utilizes the common characteristics of a target model and its stolen models for ownership infringement detection. Our method can be directly applicable to all well-trained GANs as it does not require retraining target models. Extensive experimental results show that our new method achieves superior detection performance, compared to watermark-based and fingerprint-based methods. Finally, we demonstrate the effectiveness of our method with respect to the number of generations of model extraction attacks, the number of generated samples, and adaptive attacks.},
  keywords={Generative adversarial networks;Training;Watermarking;Fingerprint recognition;Generators;Adaptation models;Intellectual property;Generative AI;Codes;Hands;Ownership Detection;Generative Adversarial Networks;Watermarks;Fingerprints;Model Confidentiality},
  doi={10.1109/TAI.2025.3560921},
  ISSN={2691-4581},
  month={},}@INPROCEEDINGS{8834544,
  author={Sami, Mirza and Mobin, Iftekharul},
  booktitle={2019 International Conference of Artificial Intelligence and Information Technology (ICAIIT)}, 
  title={A Comparative Study on Variational Autoencoders and Generative Adversarial Networks}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  abstract={Generative Adversarial Networks (GAN) have been remarkable at generating artificial data, especially realistic looking images. This learning framework has proven itself to be effective in synthetic image generation, semantic image hole filling, semantic image editing, style transfer and many more. On the other hand, variational auto-encoders (VAE) have also been quite effective, so much so that mathematically it is often more accurate at generating images resembling to its original dataset. Nevertheless, images generated by VAE suffer from blurriness and are generally less realistic looking from human perception. In this paper we take a broad view on both systems and propose a theoretical approach to combine them and bring out the best of both.},
  keywords={Generators;Data models;Training;Generative adversarial networks;Computational modeling;Decoding;Gallium nitride;GAN;Autoencoders;Variational Inference},
  doi={10.1109/ICAIIT.2019.8834544},
  ISSN={},
  month={March},}@ARTICLE{10711270,
  author={Zheng, Yue and Chang, Chip-Hong and Huang, Shih-Hsu and Chen, Pin-Yu and Picek, Stjepan},
  journal={IEEE Journal on Emerging and Selected Topics in Circuits and Systems}, 
  title={An Overview of Trustworthy AI: Advances in IP Protection, Privacy-Preserving Federated Learning, Security Verification, and GAI Safety Alignment}, 
  year={2024},
  volume={14},
  number={4},
  pages={582-607},
  abstract={AI has undergone a remarkable evolution journey marked by groundbreaking milestones. Like any powerful tool, it can be turned into a weapon for devastation in the wrong hands. Understanding that no model is perfect, trustworthy AI is initiated with an intuitive aim to mitigate the harm it can inflict on people and society by prioritizing socially responsible AI ideation, design, development, and deployment towards effecting positive changes. The scope of trustworthy AI is encompassing, covering qualities such as safety, security, privacy, transparency, explainability, fairness, impartiality, robustness, reliability, and accountability. This overview paper anchors on recent advances in four research hotspots of trustworthy AI with compelling and challenging security, privacy, and safety issues. The topics discussed include the intellectual property protection of deep learning and generative models, the trustworthiness of federated learning, verification and testing tools of AI systems, and the safety alignment of generative AI systems. Through this comprehensive review, we aim to provide readers with an overview of the most up-to-date research problems and solutions. By presenting the rapidly evolving factors and constraints that motivate the emerging attack and defense strategies throughout the AI life-cycle, we hope to inspire more research effort into guiding AI technologies towards beneficial purposes with greater robustness against malicious use intent.},
  keywords={Artificial intelligence;Security;Data models;Protection;Integrated circuit modeling;Training;Circuits and systems;Privacy;Training data;Mathematical models;Federated learning;deep neural network;generative AI;large language model;formal verification;safety alignment;trustworthy AI;model poisoning;data poisoning;backdoor;watermarking;fingerprinting;security;privacy-preservation},
  doi={10.1109/JETCAS.2024.3477348},
  ISSN={2156-3365},
  month={Dec},}@ARTICLE{10925432,
  author={Zheng, Jie and Niyato, Dusit and Zhang, Haijun and Du, Hongyang and Wang, Jiacheng and Kang, Jiawen and Xiong, Zehui},
  journal={IEEE Network}, 
  title={Over-the-air Wireless Federated Learning Model for Generative AI}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Generative artificial intelligence (GenAI) technologies represent an important advancement in the field of AI, particularly for their capabilities in text and image generation. Over-the-air wireless federated learning (OA-WFL) can utilize the wireless waveform superposition property to achieve efficient model aggregation, thereby providing support for GenAI training and deployment. Therefore, this article investigates the support of OA-WFL for GenAI, focusing on potential applications and specific examples. We first discuss the OA-WFL and GenAI models, emphasizing their functionalities and the potential benefits arising from their interaction. We then explore its application in various GenAI scenarios, including large-scale edge device content generation, efficient distributed training of GenAI models, and reduction of bandwidth requirements and device load. Next, a framework is proposed to apply OA-WFL to diffusion models, such as those used in image generation, and validate its effectiveness through simulation results. Finally, we discuss prospective research directions for the application of OA-WFL for GenAI.},
  keywords={Training;Data models;Servers;Wireless networks;Artificial intelligence;Computational modeling;Diffusion models;Adaptation models;Generative adversarial networks;Federated learning;Generative AI;over-the-air computation;wireless federated learning},
  doi={10.1109/MNET.2025.3550959},
  ISSN={1558-156X},
  month={},}@INPROCEEDINGS{9034368,
  author={Mudavathu, Kalpana Devi Bai. and Rao, M. V. P. Chandra Sekhara and Ramana, K. V.},
  booktitle={2018 3rd International Conference on Inventive Computation Technologies (ICICT)}, 
  title={Auxiliary Conditional Generative Adversarial Networks for Image Data Set Augmentation}, 
  year={2018},
  volume={},
  number={},
  pages={263-269},
  abstract={Adversarial models have been widely used for data generation and classification in the fields of Computer Vision and Artificial Intelligence. These adversarial models are defined over a framework in neural networks called Generative Adversarial Networks. In this paper, we use auxiliary conditional generative models which are special kinds of GANs employing label conditioning that result in newly generated images exhibiting global coherence. This conditional version of generative models is constructed by feeding data that we wish to condition on generator network and discriminator network in a GAN. The analysis has experimented on a high-resolution dataset called FMNIST across 60,000 samples of training images with reshaped image resolution size of $28^{\ast}28$. The following procedure is used for image dataset augmentation which improves the accuracy of image classifiers/segmentation techniques.},
  keywords={Generators;Gallium nitride;Training;Biological neural networks;Generative adversarial networks;Computer architecture;Generative Adversarial Networks;Convolutional Neural Networks;Dataset Augmentation;Probabilistic Computation;Neural Networks},
  doi={10.1109/ICICT43934.2018.9034368},
  ISSN={},
  month={Nov},}@ARTICLE{10994563,
  author={López-Pernas, Sonsoles and Misiejuk, Kamila and Kaliisa, Rogers and Saqr, Mohammed},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Capturing the Process of Students' AI Interactions When Creating and Learning Complex Network Structures}, 
  year={2025},
  volume={18},
  number={},
  pages={556-568},
  abstract={Despite the growing use of large language models (LLMs) in educational contexts, there is no evidence on how these can be operationalized by students to generate custom datasets suitable for teaching and learning. Moreover, in the context of network science, little is known about whether LLMs can replicate real-life network properties. This study addresses these gaps by evaluating the use of generative artificial intelligence (AI), specifically LLMs, to create synthetic network datasets for educational use. The analyzed data include students’ AI-generated network datasets, their interactions with the LLMs, and their perceptions and evaluations of the task's value. The results indicate that the LLM-generated networks had properties closer to real-life networks, such as higher transitivity, network density, and smaller mean distances compared to randomly generated networks. Thus, our findings show that students can use LLMs to produce synthetic networks with realistic structures while tailoring to the individual preferences of each student. The analysis of students’ interactions (prompts) with the LLMs revealed a predominant use of direct instructions and output specifications, with less emphasis on providing contextual details or iterative refinement of the LLM's responses, which highlights the need for AI literacy training to optimize students’ use of generative AI. Students’ perceptions of the use of AI were overall positive; they found using LLMs time saving and beneficial, although opinions on output relevance and quality varied, especially for assignments requiring replication of specific networks.},
  keywords={Synthetic data;Generative AI;Artificial intelligence;Data collection;Training;Social networking (online);Large language models;Training data;Privacy;Network analyzers;Artificial intelligence (AI) in education;generative AI;large language models (LLMs);learning analytics;sequence analysis;social network analysis;synthetic data generation;transition network analysis},
  doi={10.1109/TLT.2025.3568599},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{9071823,
  author={Sedigh, Pooyan and Sadeghian, Rasoul and Masouleh, Mehdi Tale},
  booktitle={2019 7th International Conference on Robotics and Mechatronics (ICRoM)}, 
  title={Generating Synthetic Medical Images by Using GAN to Improve CNN Performance in Skin Cancer Classification}, 
  year={2019},
  volume={},
  number={},
  pages={497-502},
  abstract={One of the main reasons of slow progress in using deep learning methods for cancer detection is the lack of data, especially the annotated data which is usually used for supervised learning algorithms. This paper presents a Convolutional Neural Network (CNN) to detect skin cancer. The primary database which is used to train the designed CNN algorithm has 97 members (50 benign and 47 malignant), which are collected from the International Skin Imaging Collaboration (ISIC). In order to compensate the lack of data for training the proposed CNN algorithm, a Generative Adversarial Network (GAN) is designed to produce synthetic skin cancer images. The classification performance of the designed trained CNN without the obtained synthetic images is near 53%, but by adding the synthetic images to the primary database the performance of the model is increased to 71%.},
  keywords={Gallium nitride;Generative adversarial networks;Databases;Skin cancer;Medical diagnostic imaging;Skin Cancer Detection;Convlutional Neural Networks;Generative Adversarial Network;Artificial Intelligence},
  doi={10.1109/ICRoM48714.2019.9071823},
  ISSN={2572-6889},
  month={Nov},}@INPROCEEDINGS{9429048,
  author={Ardhita, Nicolaus Boby and Maulidevi, Nur Ulfa},
  booktitle={2020 7th International Conference on Advance Informatics: Concepts, Theory and Applications (ICAICTA)}, 
  title={Robust Adversarial Example as Captcha Generator}, 
  year={2020},
  volume={},
  number={},
  pages={1-4},
  abstract={Adversarial example as one of the weaknesses of Deep Learning, can be used to attack image recognition models. Image recognition model can be used to attack common image CAPTCHA schemes, as the AI algorithm can recognize images to pass the test. So with applying robust adversarial example to image CAPTCHA, we produced a way to synthesize a robust CAPTCHA generator that are robust and cannot be easily attacked by image recognition algorithms.},
  keywords={Deep learning;Image recognition;Generators;Informatics;Artificial intelligence;CAPTCHAs;CAPTCHA;adversarial example;robust},
  doi={10.1109/ICAICTA49861.2020.9429048},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11027872,
  author={Shou, Yuancong and Zhu, Kesi and Yin, Yang and Zhang, Xiyuan and Chai, Chunlei and Sun, Shouqian},
  booktitle={2024 17th International Symposium on Computational Intelligence and Design (ISCID)}, 
  title={ArtAgent: A Creativity Support Tool Designed for Novices in Painting}, 
  year={2024},
  volume={},
  number={},
  pages={71-74},
  abstract={Generative artificial intelligence has shown great potential in assisting novices. However, the challenges users encounter when constructing effective prompts may increase their cognitive load, which is not conducive to creative expression. To address this issue, this study developed a creativity support tool called ArtAgent, which uses artificial intelligence agents to simulate the role of teachers in art teaching and assist novices in optimizing prompts. Through comparative experiments, we found that ArtAgent has improved novices' expression and performance levels while reducing their frustration in art creation tasks compared to baseline AI tools. These results emphasize the potential application of multi-agent systems in artistic creation and education.},
  keywords={Art;Generative AI;Education;Psychology;Cognitive load;Creativity;Optimization;Tuning;Multi-agent systems;Painting;creativity support tool;artificial intelligence;art education;prompt optimization},
  doi={10.1109/ISCID63852.2024.00025},
  ISSN={2473-3547},
  month={Dec},}@INPROCEEDINGS{11013511,
  author={Somanna, Nayakallu and Ahammed, Mohammed Junaid and Narendra, Dasari and Manideep, Kommera and Sudheer, Gadi},
  booktitle={2025 8th International Conference on Trends in Electronics and Informatics (ICOEI)}, 
  title={Enhancing Skin Disease Classification Through GAN-Generated Synthetic Images for Improved CNN Training and Generalization}, 
  year={2025},
  volume={},
  number={},
  pages={1351-1357},
  abstract={The work in this project helps in improving the classification of skin diseases using the combination of Generative Adversarial Networks (GANs) and Convolutional Neural Networks (CNNs). GANs were used to generate synthetic, realistic images of the rare underrepresented skin lesion types to address the problem of lack of labeled data and class imbalance. When trained on the CNN model, the model performed well, especially with a combination of experiments on real vs synthetic data, and was better able to provide improved accuracy and generalization for rare conditions like actinic keratosis and vascular lesions. Other than this, other advanced techniques like WeightedRandomSampler and especially mixed precision training provided other performance gains, by better balancing the class representation as well as speeding up the training. To detect the skin disease in clinical settings, imp and Flask have been used to deploy the skin disease classification model in real time. Through this solution we only integrate synthetic data, balanced sampling and real time inference to offer a simple, robust and scalable solution for early and accurate skin disease diagnosis. The central idea of the project is to use the advantage of GANs with CNNs to enhance the already existing classification of skin diseases. Since the authors work on a rare skin lesion diagnosis in which annotated images are scarce, availability of training data marked by class imbalance was a major avenue of concern to them. The project applies GANs to produce new, but realistic, images of underrepresented skin lesion types thereby broadening the training data set and handles this problem. Moreover, elaborate experiments concerning CNN's behaviour with both real and synthetic data are presented as additional research. Findings also demonstrate that it is accurate and capable of fulfilling the criterion of a good diagnostic tool, and further applying it to the cases of the newly discovered diseases such as actinic keratosis and vascular lesions. The features utilized to ensure the balance between the classes of the dataset and to increase the training speed, but the accuracy improvement is retained, are the use of features such as WeightedRandomSampler and mixed precision training. Thus, it is utilized as a real-time source using streamlit and Flask to generate real world inferences for clinic use skin disease classification models. Last but not least, considering the efficient synthesization of data corrupted because of balanced sampling techniques and nimble deployment of models in a friendly environment, this project provides a sound and scalable model for an early and accurate skin disease diagnosis thereby improving patients' experience in the field of dermatology.},
  keywords={Training;Accuracy;Generative adversarial networks;Skin;Real-time systems;Data models;Lesions;Convolutional neural networks;Diseases;Synthetic data;Skin Disease Classification;Generative Adversarial Networks (GANs);Convolutional Neural Networks (CNNs);Data Augmentation;Class Imbalance;Real-Time Inference;Mixed-Precision Training;WeightedRandomSampler},
  doi={10.1109/ICOEI65986.2025.11013511},
  ISSN={},
  month={April},}@INPROCEEDINGS{10281345,
  author={Gao, Yanyang and Cai, Qingsong},
  booktitle={2023 4th International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)}, 
  title={A WGAN-based Missing Data Causal Discovery Method}, 
  year={2023},
  volume={},
  number={},
  pages={136-139},
  abstract={The state-of-the-art causal discovery algorithms are typically based on complete observed data. However, in reality, technical issues, human errors, and data collection methods among other reasons result in missing data. The methods for handling missing data mainly involve statistical and machine learning approaches, where statistical methods are simple and practical, while machine learning methods offer higher accuracy. The typical approach for causal structure discovery in the presence of missing data involves two steps: First, applying missing data imputation algorithms to address the issue of missing data, and then using causal discovery algorithms to identify the causal structure. However, this two-step approach is suboptimal because imputing missing data may introduce biases in the underlying data distribution, making it challenging to accurately assess causal effects between variables. This paper proposes an iterative approach based on generative models for both missing data imputation and causal structure discovery. This approach incorporates an architecture based on Wasserstein generative adversarial networks and autoencoders (AE) to respectively impute missing data and output the causal structure. Through extensive experiments comparing against various state-of-the-art baseline algorithms, the effectiveness and superiority of this method are validated, providing valuable insights for further research on causal structures in the context of missing data.},
  keywords={Machine learning algorithms;Statistical analysis;Machine learning;Learning (artificial intelligence);Big Data;Generative adversarial networks;Data models;Missing data;Causality;Causal Discovery;Observational Data;Structure Learning;Machine Learning},
  doi={10.1109/ICBAIE59714.2023.10281345},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10842937,
  author={Rao, Daivik and Sriram, P Yatish and M, Dakshayani and Gupta, Aniket},
  booktitle={2024 2nd DMIHER International Conference on Artificial Intelligence in Healthcare, Education and Industry (IDICAIEI)}, 
  title={ImageCraft - Text To Image Synthesis}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In computer vision and natural language processing, text-to-image creation creates an image from a textual description. Text-to-picture generation aims to produce an image that visually appeals to the eye and captures the essence of a textual description. Generative adversarial networks (GANs), variational autoencoders (VAEs), and reinforcement learning are some of the methods used in text-to-image generation. Every strategy has pros and cons, and the best course of action relies on the particular demands of the work at hand. The objective of this project is to set up an experimental workbench on Amazon Sage Maker where the Deep Learning model is trained to generate synthetic images from a text prompt by the user, the model tested shows a significant increase in the quality of images when compared to a model using reduced vocabulary size for the input text embedding vector.},
  keywords={Industries;Hands;Vocabulary;Image color analysis;Text to image;Reinforcement learning;Medical services;Generative adversarial networks;Vectors;Natural language processing;Generative adversarial networks (GAN);Discriminator;Generator;Text-to-Image generation (TTI)},
  doi={10.1109/IDICAIEI61867.2024.10842937},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10778876,
  author={Ma, Hao and Yao, Xiaoting and Wang, Xiao},
  booktitle={2024 IEEE 4th International Conference on Digital Twins and Parallel Intelligence (DTPI)}, 
  title={Metaverses for Parallel Transportation: From General 3D Traffic Environment Construction to Virtual-Real I2TS Management and Control}, 
  year={2024},
  volume={},
  number={},
  pages={598-603},
  abstract={Metaverse technologies have enabled the creation of highly realistic artificial traffic system via real-time multi-source data fusion, while generative artificial intelligence (GAI) has facilitated the construction of large-scale traffic scenarios and the evaluation of strategies. This integration allows for the modeling of traffic environments that blend virtual and real-world interactions, providing digital proving grounds for the management and control (M&C) of intelligent transportation systems (ITS). This paper comprehensively reviews the evolution of traffic modeling tools, from traditional 2D and 3D traffic simulations to the construction of generative 3D traffic environments based on digital twin (DT) technologies and the metaverse. Furthermore, to address the challenges posed by social diversity and uncertainty in mixed traffic, as well as the limitations of traditional methods, we propose a virtual-real interaction M&C strategy based on GAI. This strategy integrates the metaverse into parallel traffic systems (PTS), enabling bidirectional interaction and collaboration between virtual and physical environments. Through specific case studies, this research demonstrates the potential of combining the metaverse with PTS to enhance the efficiency of mixed traffic systems.},
  keywords={Solid modeling;Three-dimensional displays;Uncertainty;Metaverse;Reviews;Diversity reception;Transportation;Traffic control;Real-time systems;Digital twins;Generative Artificial Intelligence;Social Diversity and Uncertainty;Interactive Intelligent Transportation System;Traffic Metaverse;Parallel Traffic System;Mixed Traffic},
  doi={10.1109/DTPI61353.2024.10778876},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11016423,
  author={Lukhmanov, Yevgeniy and Perveen, Asma and Tsakalerou, Mariza},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={ChatGPT in Engineering Teaching & Learning: Student and Faculty Perspective}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={The rise of Artificial Intelligence (AI) in education is reshaping traditional learning environments, with AI-powered tools increasingly being integrated into teaching and learning processes. AI chatbots are being used in engineering education for personalized concept explanations, generating practice problems, and assisting students in formulating their thoughts on complex engineering topics [1]. AI tools offer opportunities to enhance learning outcomes and teaching strategies, yet they also present challenges. This study focuses on the integration of AI-driven learning in engineering education at an English-speaking university, examining both student and faculty perspectives across various engineering disciplines, including, but not limited to chemical, civil, electrical, mechanical engineering and engineering management. While AI tools can enhance educational experiences by providing personalized feedback, generating content, and assisting with research tasks, they also pose risks of plagiarism and misuse, as students may rely on AI-generated outputs without proper oversight or attribution [2]. Recent studies [3] discuss that the rapid adoption of AI tools in education presents a significant challenge in maintaining academic integrity, with concerns over the fabrication of information and the ethical use of AI-generated content, prompting the need for clearer guidelines and frameworks to support responsible usage. Previous studies have demonstrated the efficacy of AI tools in enhancing language skills and supporting English for Specific Purposes (ESP) courses. Our research extends this focus to the engineering field, where both technical and communication skills are critical. This research investigates the use of AI tools for educators and learners and how they affect the learning outcomes, their critical thinking, the student engagement, and how this affects the offering of personalized (or the lack thereof) learning experiences. By focusing on the perspectives of both students and faculty, the study seeks to understand how these tools impact educational outcomes and shape teaching methodologies. In particular, this research investigates the following question: How do students and faculty perceive and use AI chatbots in academic settings? A survey was used to gather data from both groups where descriptive and inferential statistics were performed to evaluate the broader implications of AI integration in educational contexts. The study was conducted in the context of the university's commitment to integrating AI tools into higher education, focusing on developing skills for effective and ethical AI use. In conclusion, this study provides valuable insights into both the benefits and limitations of AI-driven tools in engineering education. It highlights the opportunities these technologies present, while also addressing the need for much needed ethical considerations and digital literacy training for both students and educators. However, it's important to note that the survey method may not fully capture the complex impact of AI, and the focus on a single institution may limit the generalizability of the findings. Despite this, the findings contribute to ongoing discussions on how AI tools can be effectively integrated into higher education to foster innovation, enhance learning, and maintain academic standards.},
  keywords={Surveys;Training;Ethics;Technological innovation;Education;Focusing;Learning (artificial intelligence);Chatbots;Artificial intelligence;Engineering education;engineering education;higher education;AIassisted learning;generative AI;chatbots},
  doi={10.1109/EDUCON62633.2025.11016423},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10797222,
  author={Cinquetti, Ettore and Zanni, Guglielmo and Menegaz, Gloria and Storti, Silvia F.},
  booktitle={2024 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)}, 
  title={EEG-driven GAN for Alpha Rhythm Generation in Passive BCI}, 
  year={2024},
  volume={},
  number={},
  pages={389-394},
  abstract={Passive brain-computer interface (BCI) based on electroencephalographic (EEG) signals show promise for monitoring human vigilance in critical settings that continuously strain human attention. However, the lack of extensive public datasets limits progress in artificial intelligence research. To overcome this problem, we implemented generative adversarial networks (GANs) to augment existing EEG datasets. We focused on two datasets: a publicly available resting-state dataset and a custom one simulating industrial activities. After extracting time-variant alpha indices using continuous wavelet transform, we compared the generated data with real data using the L2 distance metric and autocorrelation function. We additionally assessed two forecasting models trained on original and augmented datasets, comparing their predictions. The integration of synthetic data led to an improvement in signal behavior prediction, as evidenced by a 32% reduction in mean absolute error for the resting-state dataset. Furthermore, a metric inspired by the Frechét Inception Distance was computed using the forecasting model to discern the distributions of embeddings for the real and generated data, with results showing a strong resemblance between the two. This study challenges the limitation of acquiring domain-specific EEG data and aims to develop a robust signal generation framework.},
  keywords={Measurement;Computational modeling;Predictive models;Brain modeling;Generative adversarial networks;Electroencephalography;Data models;Forecasting;Artificial intelligence;Synthetic data;passive BCI;EEG;AI;deep learning;GAN;data augmentation;vigilance},
  doi={10.1109/MetroXRAINE62247.2024.10797222},
  ISSN={},
  month={Oct},}@ARTICLE{9767588,
  author={Won, Dong-Ok and Jang, Yong-Nam and Lee, Seong-Whan},
  journal={IEEE Transactions on Emerging Topics in Computing}, 
  title={PlausMal-GAN: Plausible Malware Training Based on Generative Adversarial Networks for Analogous Zero-Day Malware Detection}, 
  year={2023},
  volume={11},
  number={1},
  pages={82-94},
  abstract={Zero-day malicious software (malware) refers to a previously unknown or newly discovered software vulnerability. The fundamental objective of this paper is to enhance detection for analogous zero-day malware by efficient learning to plausible generated data. To detect zero-day malware, we proposed a malware training framework based on the generated analogous malware data using generative adversarial networks (PlausMal-GAN). Thus, the PlausMal-GAN can suitably produce analogous zero-day malware images with high quality and high diversity from the existing malware data. The discriminator, as a detector, learns various malware features using both real and generated malware images. In terms of performance, the proposed framework showed higher and more stable performances for the analogous zero-day malware images, which can be assumed to be analogous zero-day malware data. We obtained reliable accuracy performances in the proposed PlausMal-GAN framework with representative GAN models (i.e., deep convolutional GAN, least-squares GAN, Wasserstein GAN with gradient penalty, and evolutionary GAN). These results indicate that the use of the proposed framework is beneficial for the detection and prediction of numerous and analogous zero-day malware data from noted malware when developing and updating malware detection systems.},
  keywords={Malware;Generative adversarial networks;Generators;Training;Training data;Big Data;Linear programming;Analogous malware detection;generative adversarial networks;malware augmentation;malware data;zero-day malware},
  doi={10.1109/TETC.2022.3170544},
  ISSN={2168-6750},
  month={Jan},}@INPROCEEDINGS{10625342,
  author={Deo, Anuj Kumar Aditya and Gupta, Swayam and Kundu, Roumo and Jaiswal, Piyush and Fatma, Taha and Dehury, Mohan Kumar},
  booktitle={2024 2nd International Conference on Sustainable Computing and Smart Systems (ICSCSS)}, 
  title={Performance and Metrics Analysis Between Python3 via Mojo}, 
  year={2024},
  volume={},
  number={},
  pages={1291-1297},
  abstract={In the field of programming languages, Mojo and Python have gained significant popularity and recognition among developers. While Mojo, a newly emerging language, and Python, a well-established language, both have their own merits and features that make them suitable for various programming tasks. Recent AI techniques such as transformers in Natural Language Processing (NLP), Reinforcement Learning (RL), and Generative Adversarial Networks (GANs) have shown remarkable advancements. However, these techniques face challenges like high computational costs, scalability issues, and integration complexity. While Python features user-friendly syntax and extensive libraries, its interpreted nature can hinder performance for computationally intensive tasks. This research addresses this limitation by introducing Mojo, a high-performance language specifically designed for AI applications. Mojo leverages compilation and advanced optimization techniques to achieve significantly faster execution speeds compared to Python. The Mojo programming language can address these challenges by offering high-performance computation, efficient memory management, and seamless integration with AI frameworks. This can lead to faster processing times, better scalability, and more streamlined development workflows for advanced AI systems. The paper presents empirical evidence demonstrating the substantial performance gains offered by Mojo. Furthermore, the analysis explores several advantages of Mojo beyond raw speed. These include static typing, which enhances code reliability and maintainability, and built-in support for parallelism, enabling efficient utilization of multi-core processors. Additionally, Mojo's seamless integration with existing Python codebases allows developers to leverage the extensive Python ecosystem while enjoying the performance benefits of Mojo.},
  keywords={Scalability;Syntactics;Parallel processing;Natural language processing;Libraries;Computational efficiency;Artificial intelligence;Mojo;Python;Programming Languages;Performance;AI Applications;Machine Learning;Static Typing;Memory Safety;Multithreading},
  doi={10.1109/ICSCSS60660.2024.10625342},
  ISSN={},
  month={July},}@ARTICLE{10817549,
  author={Oh, Sejun},
  journal={IEEE Access}, 
  title={Evaluating Mathematical Problem-Solving Abilities of Generative AI Models: Performance Analysis of o1-preview and gpt-4o Using the Korean College Scholastic Ability Test}, 
  year={2025},
  volume={13},
  number={},
  pages={1227-1235},
  abstract={This study utilized the Korean College Scholastic Ability Test questions to evaluate the mathematical problem-solving abilities of the latest Generative AI models, o1-preview and gpt-4o. The performance of the AI models was analyzed using 92 questions from the mathematics sections of the 2023 and 2024 tests and compared with the performance of human learners. The results showed that the o1-preview model achieved an average accuracy rate of 81.52%, performing at a level comparable to top-tier human learners. The gpt-4o model demonstrated mid to lower-tier performance with an average accuracy rate of 49.46%. When analyzing different problem types, this study found that both models did better on multiple-choice questions, but their accuracy decreased as the problems got harder. AI uses reasoning processes similar to those of humans when solving mathematical problems. This study is significant because it offers new insights into AI’s mathematical abilities and shows the potential for using AI in education.},
  keywords={Chatbots;Accuracy;Mathematical models;Generative AI;Artificial intelligence;Cognition;Problem-solving;Education;Data models;Analytical models;Generative AI;mathematical problem-solving;o1-preview;college scholastic ability test;AI educational applications},
  doi={10.1109/ACCESS.2024.3523703},
  ISSN={2169-3536},
  month={},}@ARTICLE{10845784,
  author={Eglynas, Tomas and Lizdenis, Dovydas and Raudys, Aistis and Jakovlev, Sergej and Voznak, Miroslav},
  journal={IEEE Access}, 
  title={Exploring Generative Adversarial Networks: Comparative Analysis of Facial Image Synthesis and the Extension of Creative Capacities in Artificial Intelligence}, 
  year={2025},
  volume={13},
  number={},
  pages={19588-19597},
  abstract={Neural networks have become foundational in modern technology, driving advancements across diverse domains such as medicine, law enforcement, and information technology. By enabling algorithms to learn from data and perform tasks autonomously, they eliminate the need for explicit programming. A significant challenge in this field is replicating the uniquely human capacity for creativity—envisioning and realizing novel concepts and tangible creations. Generative Adversarial Networks (GANs), a leading approach in this effort, are especially notable for synthesizing realistic human facial images. Despite the success of GANs, comprehensive comparative studies of face-generating GAN methodologies are limited. This paper addresses this gap by analyzing the scope and capabilities of facial generation, detailing the principles of the original GAN framework, and reviewing prominent GAN variants specifically designed for facial synthesis. Through performance evaluations and fidelity analysis of generated images, this study contributes to a deeper understanding of GAN potential in advancing artificial intelligence creativity through performance evaluations and fidelity analysis of generated images.},
  keywords={Generative adversarial networks;Generators;Training;Faces;Noise;Synthetic data;Data models;Loss measurement;Decoding;Computational modeling;Human image synthesis;image processing;computer graphics;visualization;photorealism},
  doi={10.1109/ACCESS.2025.3531726},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10911005,
  author={Anaie, Shireen and Safatly, Lise},
  booktitle={2025 5th IEEE Middle East and North Africa Communications Conference (MENACOMM)}, 
  title={Generative AI in Arabic Music: Composition and Innovation}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper explores the power of artificial intelligence in the generation of Arabic music, a domain where traditional musical complexity meets modern computational techniques. It focuses on pulling Long Short-Term Memory (LSTM) networks and Convolutional Neural Networks (CNNs) to model and generate music sequences that maintain the distinctive qualities of traditional Arabic compositions. Utilizing a unique dataset of MIDI files from iconic Arabic songs, the study aims to demonstrate the capabilities of AI in understanding and reproducing the complex patterns of Arabic music. This research not only contributes to the academic field by filling the gap in studies concerning Arabic music generation but also enhances practical applications by providing tools that enable non-experts to produce music autonomously.},
  keywords={Technological innovation;Generative AI;Computational modeling;Neural networks;Refining;Machine learning;Data models;Convolutional neural networks;Long short term memory;Overfitting;Arabic Music;Artificial Intelligence;Long Short Term Memory;Convolutional Neural Networks},
  doi={10.1109/MENACOMM62946.2025.10911005},
  ISSN={2837-4894},
  month={Feb},}@INPROCEEDINGS{10842667,
  author={Joseph, Shenson and Joshi, Herat and Singh, Somya and Mayekar, Onkar and Wagh, Madhao},
  booktitle={2024 2nd DMIHER International Conference on Artificial Intelligence in Healthcare, Education and Industry (IDICAIEI)}, 
  title={Hybrid VGG-SVM Framework for Melanoma Detection: Integrating GAN-Augmented Data and LIME Interpretability}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Melanoma is a severe form of skin cancer that requires early detection for effective treatment. This study explores the use of advanced AI techniques to enhance the accuracy of melanoma diagnosis. We proposed a hybrid VGG-SVM model that incorporates GAN-based data augmentation to enhance the training process. Additionally, we used LIME (Local Interpretable Model-agnostic Explanations) to gain insights into the model's decision-making. By training on large datasets of dermatoscopic images, our method aimed to detect subtle melanoma characteristics with high accuracy while maintaining explainability. The proposed VGG-SVM model, combined with LIME, achieved an accuracy, precision, and F1-score of 96%, surpassing previous state-of-the-art methods. This significant improvement in both accuracy and interpretability addresses a critical scientific gap in AI-assisted melanoma diagnosis, potentially enhancing early detection rates and clinical trust in AI systems. Our study demonstrates the potential of hybrid AI models in medical image analysis and highlights the importance of interpretability in clinical applications. Future work will focus on clinical validation and exploration of transfer learning techniques to further improve model performance across diverse patient populations.},
  keywords={Training;Industries;Privacy;Accuracy;Generative AI;Transfer learning;Melanoma;Medical services;Medical diagnostic imaging;Testing;GAN-based data augmentation;Melanoma;Skin Cancer;LIME;VGG-SVM},
  doi={10.1109/IDICAIEI61867.2024.10842667},
  ISSN={},
  month={Nov},}@ARTICLE{10639408,
  author={Park, Sangjun and Kim, Young-Joo and Oh, Sangyoon and Jeong, Chanki},
  journal={IEEE Access}, 
  title={Robust Bare-Bone CNN Applying for Tactical Mobile Edge Devices}, 
  year={2024},
  volume={12},
  number={},
  pages={122671-122683},
  abstract={Artificial intelligence (AI) technologies such as image recognition, classification, and generative AI are constantly evolving rapidly. Many of these techniques operate in high-performance computing environments because they use complex architectural models and millions of parameters to improve inference and prediction performance. In recent years, there has been a growing demand for AI applications in the defense domain, and considerable research has been conducted. In tactical environments, images are used for various functions, such as creating an operational overlay and analyzing information, and AI can be leveraged for these functions. However, tactical mobile edge devices have insufficient computing resources, which limits their ability to simultaneously perform various applications such as service-proven command and control, intelligence analysis, and fire operations, as well as applications using existing AI models. Therefore, a robust bare-bone convolutional neural network (CNN) model that can support reliable services on tactical mobile edge devices was proposed. The proposed model uses only four convolutional layers, has a performance equivalent to or better than that of existing CNN models, and has a stable and sufficient performance potential to perform multiple applications simultaneously. For experimental validation of the proposed model, a military symbol inferencer using self-collected handwritten military symbol images was implemented. This inferencer has an average accuracy of 95.42% when used alone, with CPU utilization reduced by up to 31.3% and inference time reduced by up to 47.2%. When running multiple applications in parallel, CPU utilization was reduced by up to 23.7% and inference time by up to 55.9%.},
  keywords={Artificial intelligence;Computational modeling;Symbols;Convolutional neural networks;Performance evaluation;Weapons;Image edge detection;Multi-access edge computing;Generative AI;Robust;bare-bone;CNN;tactical mobile edge device;military symbol},
  doi={10.1109/ACCESS.2024.3445911},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11016291,
  author={Xu, Zhengguang and Hei, Xiaojun},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Application of Generative AI in Experimental Teaching of Communication Principles}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Generative AI, a cutting-edge technology, involves artificial intelligence models capable of producing new data or contents based on task inputs. The Principles of Communications, a required pivotal course for aspiring telecommunication engineers, leverages communication system experiments to bridge theoretical concepts with real-world applications. This paper delves into the utilization of Generative AI in designing communication system experiments from both the teacher's and students' perspectives. Specifically, we explore how teachers can employ Generative AI to craft experiment prompts and guide ChatGPT to generate desired lab results. The methodologies outlined in this paper are not limited to telecommunication courses but can be extrapolated to other experimental disciplines, offering a valuable resource for teachers and students.},
  keywords={Bridges;Accuracy;Generative AI;Communication systems;Chatbots;Reliability engineering;Data models;Engineering education;Generative AI;ChatGPT;Principles of Communications;Communication System Experiments},
  doi={10.1109/EDUCON62633.2025.11016291},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11093125,
  author={Shrestha, Ajay Kumar and Barthwal, Ankur and Campbell, Molly and Shouli, Austin and Syed, Saad and Joshi, Sandhya and Vassileva, Julita},
  booktitle={2024 IEEE 15th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON)}, 
  title={Navigating AI to Unpack Youth Privacy Concerns: An In-Depth Exploration and Systematic Review}, 
  year={2024},
  volume={},
  number={},
  pages={116-123},
  abstract={This systematic literature review investigates perceptions, concerns, and expectations of young digital citizens regarding privacy in artificial intelligence (AI) systems, focusing on social media platforms, educational technology, gaming systems, and recommendation algorithms. Using a rigorous methodology, the review started with 2,000 papers, narrowed down to 552 after initial screening, and finally refined to 108 for detailed analysis. Data extraction focused on privacy concerns, data-sharing practices, the balance between privacy and utility, trust factors in AI, transparency expectations, and strategies to enhance user control over personal data. Findings reveal significant privacy concerns among young users, including a perceived lack of control over personal information, potential misuse of data by AI, and fears of data breaches and unauthorized access. These issues are worsened by unclear data collection practices and insufficient transparency in AI applications. The intention to share data is closely associated with perceived benefits and data protection assurances. The study also highlights the role of parental mediation and the need for comprehensive education on data privacy. Balancing privacy and utility in AI applications is crucial, as young digital citizens value personalized services but remain wary of privacy risks. Trust in AI is significantly influenced by transparency, reliability, predictable behavior, and clear communication about data usage. Strategies to improve user control over personal data include access to and correction of data, clear consent mechanisms, and robust data protection assurances. The review identifies research gaps and suggests future directions, such as longitudinal studies, multicultural comparisons, and the development of ethical AI frameworks. The findings have significant implications for policy development and educational initiatives aimed at empowering young users to manage their data effectively, addressing the evolving privacy landscape shaped by AI technologies.},
  keywords={Privacy;Ethics;Technology;Data protection;Information sharing;Data breach;Reliability;Artificial intelligence;Standards;Systematic literature review;Privacy;Artificial Intelligence;Data-sharing;Transparency;User control;Trust;Youth;Generative AI},
  doi={10.1109/IEMCON62851.2024.11093125},
  ISSN={},
  month={Oct},}@ARTICLE{9785455,
  author={Salucci, Marco and Arrebola, Manuel and Shan, Tao and Li, Maokun},
  journal={IEEE Transactions on Antennas and Propagation}, 
  title={Artificial Intelligence: New Frontiers in Real-Time Inverse Scattering and Electromagnetic Imaging}, 
  year={2022},
  volume={70},
  number={8},
  pages={6349-6364},
  abstract={In recent years, artificial intelligence (AI) techniques have been developed rapidly. With the help of big data, massive parallel computing, and optimization algorithms, machine learning (ML) and (more recently) deep learning (DL) strategies have been equipped with enhanced learning and generalization capabilities. Besides becoming an essential framework in image and speech signal processing, AI has also been widely applied to solve several electromagnetic (EM) problems with unprecedented computational efficiency, including inverse scattering (IS) and EM imaging. In this article, a review of the most recent progresses in the application of ML and DL for such problems is given. We humbly hope a brief summary could help us better understand the pros and cons of this research topic and foster future research in using AI to address paramount challenges in the field of EM vision.},
  keywords={Imaging;Three-dimensional displays;Electromagnetics;Artificial intelligence;Inverse problems;Deep learning;Technological innovation;Artificial intelligence (AI);deep learning (DL);electromagnetic (EM) imaging;inverse scattering (IS);learning by examples (LBE);machine learning (ML)},
  doi={10.1109/TAP.2022.3177556},
  ISSN={1558-2221},
  month={Aug},}@ARTICLE{9091215,
  author={Lu, Ya and Stathopoulou, Thomai and Vasiloglou, Maria F. and Christodoulidis, Stergios and Stanga, Zeno and Mougiakakou, Stavroula},
  journal={IEEE Transactions on Multimedia}, 
  title={An Artificial Intelligence-Based System to Assess Nutrient Intake for Hospitalised Patients}, 
  year={2021},
  volume={23},
  number={},
  pages={1136-1147},
  abstract={Regular monitoring of nutrient intake in hospitalised patients plays a critical role in reducing the risk of disease-related malnutrition. Although several methods to estimate nutrient intake have been developed, there is still a clear demand for a more reliable and fully automated technique, as this could improve data accuracy and reduce both the burden on participants and health costs. In this paper, we propose a novel system based on artificial intelligence (AI) to accurately estimate nutrient intake, by simply processing RGB Depth (RGB-D) image pairs captured before and after meal consumption. The system includes a novel multi-task contextual network for food segmentation, a few-shot learning-based classifier built by limited training samples for food recognition, and an algorithm for 3D surface construction. This allows sequential food segmentation, recognition, and estimation of the consumed food volume, permitting fully automatic estimation of the nutrient intake for each meal. For the development and evaluation of the system, a dedicated new database containing images and nutrient recipes of 322 meals is assembled, coupled to data annotation using innovative strategies. Experimental results demonstrate that the estimated nutrient intake is highly correlated (>0.91) to the ground truth and shows very small mean relative errors (<20%), outperforming existing techniques proposed for nutrient intake assessment.},
  keywords={Databases;Estimation;Image segmentation;Artificial intelligence;Hospitals;Training data;Visualization;Artificial Intelligence;nutrient intake assessment;few-shot learning},
  doi={10.1109/TMM.2020.2993948},
  ISSN={1941-0077},
  month={},}@ARTICLE{9812489,
  author={Masur, Paul H. and Reed, Jeffrey H. and Tripathi, Nishith K.},
  journal={IEEE Aerospace and Electronic Systems Magazine}, 
  title={Artificial Intelligence in Open-Radio Access Network}, 
  year={2022},
  volume={37},
  number={9},
  pages={6-15},
  abstract={This article outlines the proposed open-radio access network (O-RAN) deployment for fifth-generation (5G) wireless networks. O-RAN seeks to supplant hardware-specific radio access network (RAN) components with generic hardware, specialized software, and open signaling interfaces. The virtualization and network slicing features of 5G allow for software to replace previously hardware-specific functions. The software further provides faster analytics, thus supporting 5G's latency requirements and advanced usage scenarios (i.e., enhanced mobile broadband, massive machine type communications, and ultra-reliable low latency communications). Furthermore, as software annexes control of the RAN, there is the freedom to integrate artificial intelligence/machine learning algorithms into RAN management (particularly at the user plane). This integration is one of the goals of O-RAN. Finally, relying on generic hardware and specialized, open-source software eliminates reliance upon specific device manufacturers. This article will provide questions regarding O-RAN's future, with a focus on 5G network device security.},
  keywords={Hardware;5G mobile communication;Radio frequency;Optimization;Artificial intelligence;Costs;Wireless networks;Artificial Intelligence;Cellular Radio;Communication standards;Communication systems},
  doi={10.1109/MAES.2022.3186966},
  ISSN={1557-959X},
  month={Sep.},}@INPROCEEDINGS{8851910,
  author={Gao, Ziping and Peng, Bo and Li, Tianrui and Gou, Cong},
  booktitle={2019 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Generative Adversarial Networks for Road Crack Image Segmentation}, 
  year={2019},
  volume={},
  number={},
  pages={1-8},
  abstract={In this paper, we present a road crack segmentation method based on generative adversarial networks (GAN). Our GAN networks consist of two neural network models in terms of a generator and a discriminator, where two improved networks CU-Net and FU-Net are proposed based on U-Net. The U-Net, CU-Net and FU-Net are used as the generator, while two-class networks are used as the discriminator. The purpose of using the generator is to generate fake crack images which are very similar to real crack images. And the recognition is done by the discriminator to distinguish the real crack images from the fake crack images. After iterative training between the generator and the discriminator, the generator can generate fake crack images that are very similar to the real crack image. Finally, the generator can be used to segment the road crack images. Compared with the other state-of-the-art methods on three datasets, the proposed method achieves better performance. Specifically, the precision, recall and F1-score are 91.46%, 73.40%, and 77.33%, respectively on one of the public datasets.},
  keywords={Image segmentation;Generators;Generative adversarial networks;Roads;Feature extraction;Neural networks;Road Crack segmentation;Neural Networks;U-Net;Generative Adversarial Networks (GAN)},
  doi={10.1109/IJCNN.2019.8851910},
  ISSN={2161-4407},
  month={July},}@ARTICLE{10780947,
  author={Chen, Jin and Fu, Liangzun and Xiang, Rikui and Luo, Shaobo and Huang, Xiwei and Yu, Hao and Sun, Lingling},
  journal={IEEE Sensors Journal}, 
  title={Artificial Intelligence-Assisted Microfluidic Bio-Imaging—From Sensors to Applications: A Review}, 
  year={2025},
  volume={25},
  number={2},
  pages={2056-2072},
  abstract={In recent years, the convergence of artificial intelligence (AI) and microfluidic technologies has given rise to unprecedented advancements in various fields, ranging from healthcare to environmental monitoring. Among which the AI-assisted microfluidic biological imaging has been one most widely applied examples due to its advantages, such as high-throughput and high-content imaging capability as well as the outstanding abilities in analyzing and mining massive data generated by microfluidic bio-imaging systems. AI exhibits significant potential in assisting microfluidic bio-imaging by enhancing imaging resolution and improving classification and detection performances. Therefore, in this review, we focus on some key technologies and recent advancements in AI-assisted microfluidic bio-imaging sensors and presenting discussion from three aspects: sensing devices, AI, and corresponding applications. In the aspect of sensing devices, we offer a detailed introduction to the structure and design of commonly used imaging sensors, including frame-based image sensors and event-based image sensors, and we present two types of frame-based image sensors: charge-coupled devices (CCDs) and complementary metal-oxide-semiconductor (CMOS) image sensors (CISs). In terms of AI, we present the development process of AI, summarizing various machine learning and deep learning algorithms commonly used in the field of bio-imaging, such as super-resolution (SR), classification, and detection. In terms of application, we provide a list of recent practical applications that integrate various AI techniques with diverse imaging sensors. Finally, we conclude with discussion on the current challenges faced in the field and present potential directions in the future.},
  keywords={Microfluidics;Image sensors;Sensors;Imaging;Artificial intelligence;CMOS image sensors;Biosensors;Optical sensors;Sensor systems;Noise;Artificial intelligence (AI);dynamic vision sensor (DVS);frame-based image sensor;microfluidic bio-imaging;microfluidic flow cytometry},
  doi={10.1109/JSEN.2024.3507081},
  ISSN={1558-1748},
  month={Jan},}@INPROCEEDINGS{11120167,
  author={Othman, Nashwan Adnan and Mohsin, Sarah Kadhim and Alanssari, Ali Ihsan and Fahidhil, Eay and Khalil, Salim Yahya Kasim and Hussein, Abdul},
  booktitle={2024 IEEE 9th International Conference on Engineering Technologies and Applied Sciences (ICETAS)}, 
  title={6G-Assisted Internet of Things Security Using Artificial Intelligence}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={There are now several privacy and security issues associated with the IoT. Inadequate device updates, user ignorance, weak security measures, and the notorious active device monitoring constitute only some issues affecting the Internet of Things. Many researchers have narrowed in on the challenges of ensuring the secure functioning of the Internet of Things (IoT) due to the interplay of many factors and security principles. However, to maximize the advantages of artificial intelligence in an IoT environment using the 6G communication network. To address this issue, a 6G-assisted IoT security method using AI has been developed (6G-ISM-AI). The suggested model comprises two major components: a security module using a refined deep neural network and a powerefficient 6G real-time communication framework architecture. Improved network longevity and spectrum efficiency are only two of the benefits of the first module, which guarantees optimum energy usage and latency. Simultaneously, the second module guarantees a private, trustworthy, always-on IoT connection. The suggested technique has been shown to perform better in simulations than comparable models using 5G communication with reliable IoT security. The numerical finding of 6G-ISM-AI achieves management of energy consumption of 89.3 %, precision in computation of 98.4 %, efficiency ratio of 94.4%, network security using IoT technology of 99.4%, and UAV network security of 96.6%.},
  keywords={6G mobile communication;Privacy;Computational modeling;Network security;Real-time systems;Numerical models;Internet of Things;Reliability;Artificial intelligence;Monitoring;Artificial Intelligence;Internet of Things;6G;Security;Energy-efficiency;Communication},
  doi={10.1109/ICETAS62372.2024.11120167},
  ISSN={2769-4518},
  month={Nov},}@BOOK{10769240,
  author={Bourne, Keith and Es, Shahul},
  booktitle={Unlocking Data with Generative AI and RAG: Enhance generative AI systems by integrating internal data with large language models using RAG},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Leverage cutting-edge generative AI techniques such as RAG to realize the potential of your data and drive innovation as well as gain strategic advantageKey FeaturesOptimize data retrieval and generation using vector databasesBoost decision-making and automate workflows with AI agentsOvercome common challenges in implementing real-world RAG systemsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionGenerative AI is helping organizations tap into their data in new ways, with retrieval-augmented generation (RAG) combining the strengths of large language models (LLMs) with internal data for more intelligent and relevant AI applications. The author harnesses his decade of ML experience in this book to equip you with the strategic insights and technical expertise needed when using RAG to drive transformative outcomes. The book explores RAG’s role in enhancing organizational operations by blending theoretical foundations with practical techniques. You’ll work with detailed coding examples using tools such as LangChain and Chroma’s vector database to gain hands-on experience in integrating RAG into AI systems. The chapters contain real-world case studies and sample applications that highlight RAG’s diverse use cases, from search engines to chatbots. You’ll learn proven methods for managing vector databases, optimizing data retrieval, effective prompt engineering, and quantitatively evaluating performance. The book also takes you through advanced integrations of RAG with cutting-edge AI agents and emerging non-LLM technologies. By the end of this book, you’ll be able to successfully deploy RAG in business settings, address common challenges, and push the boundaries of what’s possible with this revolutionary AI technique.What you will learnUnderstand RAG principles and their significance in generative AIIntegrate LLMs with internal data for enhanced operationsMaster vectorization, vector databases, and vector search techniquesDevelop skills in prompt engineering specific to RAG and design for precise AI responsesFamiliarize yourself with AI agents' roles in facilitating sophisticated RAG applicationsOvercome scalability, data quality, and integration issuesDiscover strategies for optimizing data retrieval and AI interpretabilityWho this book is forThis book is for AI researchers, data scientists, software developers, and business analysts looking to leverage RAG and generative AI to enhance data retrieval, improve AI accuracy, and drive innovation. It is particularly suited for anyone with a foundational understanding of AI who seeks practical, hands-on learning. The book offers real-world coding examples and strategies for implementing RAG effectively, making it accessible to both technical and non-technical audiences. A basic understanding of Python and Jupyter Notebooks is required.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835887912},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10769240},}@INPROCEEDINGS{11103391,
  author={Afzal, Muhammad Muzammil and Guo, Shuaishuai and Saeed, Nasir},
  booktitle={2025 IEEE International Workshop on Radio Frequency and Antenna Technologies (iWRF&AT)}, 
  title={Intelligent UAV Base Station Placement with Generative AI and Retrieval-Augmented LLMs}, 
  year={2025},
  volume={},
  number={},
  pages={392-397},
  abstract={Fixed network infrastructure is often insufficient in addressing dynamic communication demands, particularly in densely populated urban areas. Unmanned Aerial Vehicles (UAVs), specifically UAV-based stations (UAV-BS), offer a flexible and adaptive solution by acting as mobile base stations to alleviate data traffic congestion. This paper introduces a novel framework that leverages generative artificial intelligence (GAI) to optimize the placement of UAV-BS in urban environments. The proposed system integrates GAI agents with LlamaIndex and retrieval-augmented generation (RAG) techniques powered by large language models (LLMs) to enhance decision-making. LlamaIndex serves as an intermediary between user queries and a curated database of UAV-related research, enabling the framework to retrieve and utilize semantically relevant information through RAG. This combination allows the GAI agents to dynamically adapt to real-time data and user requirements, optimizing UAV-BS deployment for maximum efficiency. Simulation results highlight the accuracy and computational efficiency of the proposed approach, demonstrating its superiority in resolving UAV-BS placement challenges compared to traditional methods. This work offers a scalable and intelligent solution for next-generation urban network deployment, paving the way for smart and responsive communication systems.},
  keywords={Base stations;Generative AI;Large language models;Simulation;Urban areas;Retrieval augmented generation;Autonomous aerial vehicles;Vehicle dynamics;Optimization;Traffic congestion;Large language models;Retrieval-Augmented generation;UAVs;base stations;AI agents;crew-ai;optimization;data traffic optimization},
  doi={10.1109/iWRFAT65352.2025.11103391},
  ISSN={},
  month={May},}@ARTICLE{10749978,
  author={Sun, Geng and Xie, Wenwen and Niyato, Dusit and Du, Hongyang and Kang, Jiawen and Wu, Jing and Sun, Sumei and Zhang, Ping},
  journal={IEEE Network}, 
  title={Generative AI for Advanced UAV Networking}, 
  year={2025},
  volume={39},
  number={4},
  pages={244-253},
  abstract={With the impressive achievements of chatGPT and Sora, generative artificial intelligence (GAI) has received increasing attention. Not limited to the field of content generation, GAI is also widely used to solve the problems in wireless communication scenarios due to its powerful learning and generalization capabilities. Therefore, we discuss key applications of GAI in improving unmanned aerial vehicle (UAV) communication and networking performance in this article. Specifically, we first review the key technologies of GAI and the important roles of UAV networking. Then, we show how GAI can improve the communication, networking, and security performances of UAV systems. Subsequently, we propose a novel framework of GAI for advanced UAV networking, and then present a case study of UAV-enabled spectrum map estimation and transmission rate optimization based on the proposed framework to verify the effectiveness of GAI-enabled UAV systems. Finally, we discuss some important open directions.},
  keywords={Autonomous aerial vehicles;Artificial intelligence;Optimization;Generative adversarial networks;Training;Base stations;Relays;Transformers;Generative AI;Radio spectrum management;Generative AI;UAV communications and networking;optimization;UAV spectrum estimation;diffusion model},
  doi={10.1109/MNET.2024.3494862},
  ISSN={1558-156X},
  month={July},}@INPROCEEDINGS{10447299,
  author={Chen, Jia and Qin, Jinlong and Zhong, Saishang and Yang, Kai and Hu, Xinrong and Peng, Tao and Li, Rui},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={SGM: A Dataset for 3D Garment Reconstruction from Single Hand-Drawn Sketch}, 
  year={2024},
  volume={},
  number={},
  pages={2510-2514},
  abstract={High-fidelity garment reconstruction is essential for various applications such as garment design and virtual try-on. While image-based reconstruction methods have made significant progress with deep generative models, generating 3D models from hand-drawn sketches to meet design intentions remains challenging. One of the main obstacles is the limited availability of large-scale 3D garment models accompanied by corresponding sketches. To address this issue, we propose SGM, a comprehensive dataset comprising 656 garment models categorized into short and long sleeves. Each garment model in SGM is accompanied by four types of rendered images and a series of UDF values. Furthermore, we introduce a novel baseline approach for sketch-based garment reconstruction using an end-to-end generative network capable of generating garment models from single hand-drawn sketches. Extensive experimental results highlight the significance and value of our proposed dataset and method. We plan to make SGM publicly available upon publication.},
  keywords={Solid modeling;Three-dimensional displays;Clothing;Signal processing;Reconstruction algorithms;Acoustics;Speech processing;Garment reconstruction;Sketch;UDF;Dataset;Deep generative models},
  doi={10.1109/ICASSP48485.2024.10447299},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10690576,
  author={Rokade, Darpan and Jabde, Meenal K. and Patil, Chandrashekhar H.},
  booktitle={2024 10th International Conference on Smart Computing and Communication (ICSCC)}, 
  title={Screening Application of Dyslexia and Dysgraphia Using Cognitive AI}, 
  year={2024},
  volume={},
  number={},
  pages={182-186},
  abstract={Redefining Early Identification: A cognitive AI-Powered Screening Software of Dyslexia and Dysgraphia. In the today's world people are suffering with many types of mental disabilities than physical. Dyslexia and Dysgraphia this are mental and brain disabilities where the people are not aware with this. Dyslexia is unexpected learning difficulty in reading in an individual who has the intelligence to be much better reader. Dysgraphia is neurological condition in which someone has difficulty turning their thoughts into written language for their age and ability to think, despite exposure to adequate instruction and education. In Our software we are taking audio file of people who have Dyslexia and by machine learning and cognitive artificial intelligence we can analyze the audio file with symptoms and with database of normal people. For Dysgraphia we are taking one handwritten document and then we analyze the document with normal people and symptoms of Dysgraphia. We are also planning to add some course and some direction or some therapy who have dysgraphia or dyslexia. This paper introduces a novel screening application for dyslexia and dysgraphia that harnesses the power of cognitive artificial intelligence (CAI) to provide personalized assessments and early intervention insights. Moving beyond traditional symptom-based screening, the application delves into the cognitive underpinnings of these learning difficulties, offering a more nuanced and accurate approach to identification.},
  keywords={Ethics;Accuracy;Data integrity;Medical treatment;Machine learning;Dyslexia;Turning;Software;Planning;Artificial intelligence;dyslexia;dysgraphia;early identification;machine learning;handwriting analysis;eye tracking;learning disorders;education technology},
  doi={10.1109/ICSCC62041.2024.10690576},
  ISSN={},
  month={July},}@ARTICLE{9475913,
  author={Blasch, Erik and Pham, Tien and Chong, Chee-Yee and Koch, Wolfgang and Leung, Henry and Braines, Dave and Abdelzaher, Tarek},
  journal={IEEE Aerospace and Electronic Systems Magazine}, 
  title={Machine Learning/Artificial Intelligence for Sensor Data Fusion–Opportunities and Challenges}, 
  year={2021},
  volume={36},
  number={7},
  pages={80-93},
  abstract={During Fusion 2019 Conference (https://www.fusion2019.org/program.html), leading experts presented ideas on the historical, contemporary, and future coordination of artificial intelligence/machine learning (AI/ML) with sensor data fusion (SDF). While AI/ML and SDF concepts have had a rich history since the early 1900s—emerging from philosophy and psychology—it was not until the dawn of computers that both AI/ML and SDF researchers initiated discussions on how mathematical techniques could be implemented for real-time analysis. ML, and in particular deep learning, has demonstrated tremendous success in computer vision, natural language understanding, and data analytics. As a result, ML has been proposed as the solution to many problems that inherently include multi-modal data. For example, success in autonomous vehicles has validated the promise of ML with SDF, but additional research is needed to explain, understand, and coordinate heterogeneous data analytics for situation awareness. The panel identified opportunities for merging AI/ML and SDF such as computational efficiency, improved decision making, expanding knowledge, and providing security; while highlighting challenges for multi-domain operations, human-machine teaming, and ethical deployment strategies.},
  keywords={Uncertainty;Data analysis;Psychology;Reinforcement learning;Big Data;Data models;Robustness},
  doi={10.1109/MAES.2020.3049030},
  ISSN={1557-959X},
  month={July},}@ARTICLE{10510596,
  author={Anas, Mohammad and Saiyeda, Anam and Sohail, Shahab Saquib and Cambria, Erik and Hussain, Amir},
  journal={IEEE Intelligent Systems}, 
  title={Can Generative AI Models Extract Deeper Sentiments as Compared to Traditional Deep Learning Algorithms?}, 
  year={2024},
  volume={39},
  number={2},
  pages={5-10},
  abstract={Recent advances in the context of deep learning have led to the development of generative artificial intelligence (AI) models which have shown remarkable performance in complex language understanding tasks. This study proposes an evaluation of traditional deep learning algorithms and generative AI models for sentiment analysis. Experimental results show that RoBERTa outperforms all models, including ChatGPT and Bard, suggesting that generative AI models are not yet able to capture the nuances and subtleties of sentiment in text. We provide valuable insights into the strengths and weaknesses of different models for sentiment analysis and offer guidance for researchers and practitioners in selecting suitable models for their tasks.},
  keywords={Deep learning;Generative AI;Analytical models;Context modeling;Chatbots;Sentiment analysis},
  doi={10.1109/MIS.2024.3374582},
  ISSN={1941-1294},
  month={March},}@INPROCEEDINGS{11024656,
  author={Alwadi, Ali and Chetty, Girija and Alwadi, Mohammad and Alnaimi, Jawad and Gawanmeh, Amjad and Mahmoud, Khaled Zuhair Said},
  booktitle={2024 International Conference on Sustainable Technology and Engineering (i-COSTE)}, 
  title={Lung Pathology Using Artificial Intelligence Analysis of Ultrasound Images: A Survey}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper first studies and analyses the Artificial Intelligence algorithms that can potentially be used to identify various diseases from medical images and scans. Then researches the related work in this area to find a suitable Machine Learning model that can be used to identify Interstitial Syndrome in Lung Ultra Sound images. By researching similar applications of the latest Machine Learning algorithms, this team of researchers are adopting a Vision Transformer system developed on a Convolutional Neural Network-based algorithm. The later has proven to be efficient in the area of UltraSound image processing in general and more flexible to configure and parameterize in the training process. The Vision Transformer system is a segmentation-based model that divides the input image to smaller subset of images of the same size. By merging the adjacent small patches into bigger layers, bigger windows to perform self-attention on, the system extracts the points of interest out of these frames.},
  keywords={Training;Surveys;Image segmentation;Computer vision;Ultrasonic imaging;Machine learning algorithms;Lungs;Transformers;Convolutional neural networks;Diseases;Machine learning;Neural networks;Deep learning;Image processing;Segmentation based model transformer},
  doi={10.1109/i-COSTE63786.2024.11024656},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11081262,
  author={Manoranjitham, R and Janish Raphel Dev, R},
  booktitle={2025 International Conference on Advances in Modern Age Technologies for Health and Engineering Science (AMATHE)}, 
  title={Enhanced Diabetic Retinopathy Assessment Using Multiple Instance Learning and Explainable Vision Transformers Integrated with Generative Adversarial Networks}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Diabetic Retinopathy (DR) is a leading cause of preventable blindness, necessitating early detection for effective intervention. Conventional DR screening is labor-intensive and subject to inter-observer variability, making automated solutions essential. This study proposes an enhanced DR assessment framework integrating Multiple Instance Learning (MIL) and Vision Transformers (ViT) to improve detection accuracy and explainability. The MIL-ViT model leverages self-attention mechanisms to capture long-range dependencies in retinal fundus images, enhancing classification performance. Additionally, YOLOv8-based segmentation identifies microaneurysms, hemorrhages, and exudates, while EigenCAM explainability visualizations provide interpretable heat maps. The system was evaluated using multiple deep learning models, with EfficientNetB0 achieving 93.09% accuracy and an AUC-ROC of 0.96, outperforming traditional CNN architectures. The framework is deployed via a Streamlit-based interactive interface, enabling real-time DR grading and segmentation for clinical and teleophthalmology applications. This research advances automated, interpretable, and scalable DR screening solutions, which are particularly beneficial for resourceconstrained settings.},
  keywords={Deep learning;Diabetic retinopathy;Computer vision;Visualization;Accuracy;Weak supervision;Explainable AI;Streaming media;Transformers;Real-time systems;Diabetic Retinopathy;Vision Transformers;Multiple Instance Learning;Deep Learning;YOLOv8;Explainable AI;EigenCAM;Medical Image Processing;Teleophthalmology},
  doi={10.1109/AMATHE65477.2025.11081262},
  ISSN={},
  month={April},}@INBOOK{10951181,
  author={Orange, Erica},
  booktitle={AI + The New Human Frontier: Reimagining the Future of Time, Trust + Truth}, 
  title={From AI to IA: Intelligence Augmentation}, 
  year={2024},
  volume={},
  number={},
  pages={69-77},
  abstract={Summary <p>The integration of AI into our workforce does not only mean job loss or obsolescence; rather, it presents an opportunity for growth and innovation by allowing AI to take on the monotonous tasks that, some could argue, humans weren't meant to be doing in the first place. Perhaps the best strategy for getting the most out of AI is to tap even deeper into our most human cognitive abilities. For all the talk about generative AI becoming more creative, perhaps the opposite is true&#x2014;perhaps it will force us to rethink traditional notions of creativity and make us more creative in the process. While much of the recent discussion around AI centers on its ability to augment things such as creativity and knowledge, we must also consider how it is impacting the backbone of our society: blue&#x2010;collar workers.</p>},
  keywords={Artificial intelligence;Creativity;Cognitive load;Technological innovation;Robots;Generative AI;Chatbots;Automation;Social intelligence;National Institutes of Health},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394276998},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951181},}@INPROCEEDINGS{9935984,
  author={Jiwtode, Mayur and Asati, Aman and Kamble, Shailesh and Damahe, Lalit},
  booktitle={2022 IEEE International Conference on Blockchain and Distributed Systems Security (ICBDS)}, 
  title={Deepfake Video Detection using Neural Networks}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={Over the past few years, free mobile application tools on Artificial Intelligence and deep learning have made it easy to create reliable face exchanges in a video called “DeepFake” (DF) video that leaves a little hint of traces to check if its fake. Creating a computerized edited video has been demonstrated for quite a long time by actually taking advantage of enhanced visual effects. Recently, Artificial Intelligence has led to a rise in fake content and the ability to access free tools to create it. These purported AI-engineered media are normally called DeepFake(DF). Making a DF with a computerized AI tool is a simple job. However, with regards to identifying this DF, it's a major challenging dispute. Preparing the calculations and training the model to distinguish DF is difficult. The challenge to train an algorithm model to spot the DeepFake (DF) is not simple. We have tried recognizing DF with the use of CNN and RNN. The framework utilizes a CNN for feature extraction at the frame level. The model uses features extracted from the frame level to train the RNN, which then learns to classify videos according to their temporal inconsistencies. Anticipated results, when compared with a large number of hoax videos, were gathered from standard datasets. Using a simple architecture, we will show you how this errand can make your framework accurate.},
  keywords={Training;Deepfakes;Computational modeling;Streaming media;Feature extraction;Visual effects;Reliability;Artificial Intelligence;RNN;CNN;Hoax Video Detection;DeepFakes},
  doi={10.1109/ICBDS53701.2022.9935984},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10456106,
  author={Deshpande, Aniket S. and Gupta, Shalu},
  booktitle={2023 IEEE International Conference on ICT in Business Industry & Government (ICTBIG)}, 
  title={GenAI in the Cyber Kill Chain: A Comprehensive Review of Risks, Threat Operative Strategies and Adaptive Defense Approaches}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Generative artificial intelligence (GAI) has become an effective instrument capable of creating realistic content on its own in a variety of fields. GAI's growing adoption raises concerns about potential misuse for cyber threats, such as creating, convincing, phishing emails, producing deep fake videos and distributing false information through posts that appear to be genuine on social media. This is accurate even though its potential uses in data synthesis, virtual assistants, content development and the creative arts are exciting. These difficulties appeal for a careful analysis of GAI's place in cybersecurity (CS). This paper offers a comprehensive analysis of the possible threats connected to the offensive GAI technique used in the Cyber Kill Chain (CKC) framework. In addition, our proposal includes defense tactics that leverage GAI capabilities. These strategies include the areas of detection, deception and adversarial training, with the aim of reducing the potential risks associated with cyber threats induced by GAI. Threat actors employ the use of GAI to augment Evasion, obfuscation and deception techniques, hence increasing the effectiveness and difficulty of detecting their attacks. This study highlights the importance of using proactive defense measures. The dual capability of GAI for legal and illegal usage highlights the need to comprehend and mitigate its influence inside the CKC framework. To combat the evolving gamut of GAI-induced cyber threats, organizations should employ attack-aware and adaptable GAI-enabled defense strategies.},
  keywords={Training;Law;Generative AI;Social networking (online);Reviews;Virtual assistants;Phishing;Generative artificial intelligence (GAI);Cyber Security (CS);Cyber Kill Chain (CKC);Security},
  doi={10.1109/ICTBIG59752.2023.10456106},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10605418,
  author={Mohandoss, Ramaswami},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Context-based Semantic Caching for LLM Applications}, 
  year={2024},
  volume={},
  number={},
  pages={371-376},
  abstract={Large Language Models (LLM), aided by the popularity of ChatGPT, have provided a paradigm shift to engineering AI Chatbots. LLMs offer many conveniences to the AI engineer, and the most important benefit is their robustness in handling semantic matches of user queries. In other words, an engineer building an AI conversational assistant does not need to train the agent for semantic user query matches explicitly. This benefit comes with a cost, which is felt in two ways. Firstly, LLMs need an expensive infrastructure like GPUs, large RAMs, etc. Secondly, even with all the cutting-edge infrastructure, their response time will not be sub-second anytime soon. So, AI applications that use LLMs are likely to be expensive and suffer from high latency. One way to reduce cost and response time is by introducing a caching solution between the LLMs and the UX layer. Such a caching layer can help minimize calls to LLMs when the queries are similar and repetitive. However, traditional caching methods cannot be used as they are for LLM-based applications. The reason is that queries handled by AI-based conversational assistants are unstructured, i.e., free-flowing user-generated text, and will not always be context-free. In other words, end users tend to query from their point of view. Existing solutions like GPTCache work well for context-free questions, but caching context-sensitive user queries needs an evolved design. In this paper, we shall explore a novel design that, by exploiting the power of context, shall provide effective caching solutions to user-generated queries (both context-free and context-sensitive) that offer improved performance without compromising on the quality of response.},
  keywords={Costs;Large language models;Semantics;Random access memory;White spaces;Chatbots;Vectors;LLM;Large Language Models;Semantic cache;Natural Language Processing;Artificial Intelligence;Generative AI;Conversational Assistants;Chatbot},
  doi={10.1109/CAI59869.2024.00075},
  ISSN={},
  month={June},}@ARTICLE{11002439,
  author={Yu, Siyang and Duan, Mingxing and Wang, Kezhi and Yang, Shenghong},
  journal={Big Data Mining and Analytics}, 
  title={RUP-GAN: A Black-Box Attack Method for Social Intelligence Recommendation Systems Based on Adversarial Learning}, 
  year={2025},
  volume={8},
  number={4},
  pages={820-836},
  abstract={Cyber Physical Social Intelligence (CPSI) emphasizes the integration of social information and artificial system information from virtual spaces, enabling Social Intelligence Recommendation Systems (SIRS) to make intelligent decisions and optimizations based on more comprehensive data, thereby enhancing the accuracy of recommendations and user experience. However, as the combined application of CPSI and SIRS becomes increasingly widespread, they also face the risk of shilling attacks. Traditional shilling attacks are limited in terms of low stealthiness, specificity to certain systems, and generation of unrealistic fake profiles. In this paper, we propose a black-box attack method, Real User Preference Generative Adversarial Networks (RUP-GAN), based on adversarial learning. RUP-GAN optimizes the authenticity of user profiles and enhances the hit rate of target items within users' top-k recommendation lists. Through experiments conducted on real-world datasets, it has been proved that RUP-GAN surpasses baseline shilling attack methods in attack effectiveness, transferability, and invisibility. Our proposed model can effectively mitigate the risks posed by shilling attacks, and provide valuable insights for the defense research of CPSI and SIRS.},
  keywords={Costs;Closed box;Predictive models;Generative adversarial networks;Adversarial machine learning;User experience;Stability analysis;Social intelligence;User preference;Recommender systems;Social Intelligence Recommendation Systems (SIRS);Generative Adversarial Networks (GAN);shilling attacks},
  doi={10.26599/BDMA.2025.9020002},
  ISSN={2097-406X},
  month={August},}@INPROCEEDINGS{10932905,
  author={Rogozinnikov, E. I. and Doskalesku, K.V. and Ivanov, A.A. and Marinov, Y.A. and Morozov, S.M. and Yakunin, A.V.},
  booktitle={2024 7th International Youth Scientific and Technical Conference on Relay Protection and Automation (RPA)}, 
  title={Training Generative Models for the Task of Object Description in A Strict Format: Analysis of the Efficiency of Their Architectures}, 
  year={2024},
  volume={1},
  number={},
  pages={1-15},
  abstract={In the modern world, digitalization is increasingly penetrating into people's daily lives and covers a wide variety of areas of human activity. Electric power industry is no exception. The introduction of SCADA systems has increased the observability of processes occurring in the network and increased the efficiency and speed of decision-making aimed at maintaining a stable operating mode of the EPS. The next step in the development of digital electric power industry is digital twins, which could be integrated into digital services for their visual display or, for example, for conducting processes of modeling the operating mode of the EPS. The introduction of artificial intelligence (AI) is also gaining popularity. More and more advanced AI models are constantly emerging, capable of solving increasingly complex problems. The introduction of generative artificial intelligence can significantly speed up the process of building digital models. This article provides a comparative review of various generative AI models that are further trained to generate descriptions of electric power substations in a strictly formalized form that can be further computer processed.},
  keywords={Training;Industries;Analytical models;Visualization;Substations;Generative AI;Software packages;Computational modeling;Computer architecture;Transformers;Generative AI;LLM;AI Model Training;Recurrent Neural Networks;GPT;Transformers;Digital Models},
  doi={10.1109/RPA65165.2024.10932905},
  ISSN={2832-1278},
  month={Nov},}@ARTICLE{9537763,
  author={Madono, Koki and Tanaka, Masayuki and Onishi, Masaki and Ogawa, Tetsuji},
  journal={IEEE Access}, 
  title={SIA-GAN: Scrambling Inversion Attack Using Generative Adversarial Network}, 
  year={2021},
  volume={9},
  number={},
  pages={129385-129393},
  abstract={This paper presents a scrambling inversion attack using a generative adversarial network (SIA-GAN). This method aims to evaluate the privacy protection level achieved by image scrambling method. For privacy-preserving machine learning, scrambled images are often used to protect visual information, assuming that searching the scramble parameters is highly difficult for an attacker due to the application of complex image scrambling operations. However, the security of such methods has not been thoroughly investigated. SIA-GAN learns the mapping between pairs of scrambled images and original images, then attempts to invert image scrambling. Therefore, the attacker is assumed to have real images whose domain is the same as that of scrambled images. Experimental results demonstrate that scrambled images cannot be recovered if block shuffling is applied as a scrambling operation. The experimental code of SIA-GAN is available at https://github.com/MADONOKOUKI/SIA-GAN.},
  keywords={Training;Feature extraction;Visualization;Generators;Generative adversarial networks;Transforms;Machine learning;Artificial intelligence;machine learning;computer vision;visual information hiding;image scrambling},
  doi={10.1109/ACCESS.2021.3112684},
  ISSN={2169-3536},
  month={},}@ARTICLE{10492675,
  author={Tariang, Diangarti and Corvi, Riccardo and Cozzolino, Davide and Poggi, Giovanni and Nagano, Koki and Verdoliva, Luisa},
  journal={IEEE Security & Privacy}, 
  title={Synthetic Image Verification in the Era of Generative Artificial Intelligence: What Works and What Isn’t There yet}, 
  year={2024},
  volume={22},
  number={3},
  pages={37-49},
  abstract={In this work, we present an overview of approaches for the detection and attribution of synthetic images and highlight their strengths and weaknesses. We also point out and discuss hot topics in this field and outline promising directions for future research.},
  keywords={Training;Image synthesis;Generative adversarial networks;Forensics;Computer architecture;Robustness;Artificial intelligence;Synthetic data;Image analysis;Generative AI},
  doi={10.1109/MSEC.2024.3376637},
  ISSN={1558-4046},
  month={May},}@INPROCEEDINGS{10487383,
  author={Mohammed, Mahmood and Talburt, John R. and Syed, Huzaifa and Mehjabeen},
  booktitle={2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE)}, 
  title={Metadata: An Integral Component of the Modern Data Strategy}, 
  year={2023},
  volume={},
  number={},
  pages={1628-1631},
  abstract={This paper explores the pivotal role of metadata within the data management practices of organizations, and its subsequent impact on business decision-making. This paper presents a comprehensive exploration of the application of Generative AI in the realm of data analytics. As the volume and complexity of data continue to grow, effective metadata management becomes pivotal to understanding and utilizing data. With the ability to simulate human inferencing processes and generate contextual insights, generative AI offers promising avenues in improving metadata understanding, governance, integration, and quality. A crucial point of discussion in this paper is how the quality of metadata directly influences the output of Generative AI models. We present a proof-of-concept that illustrates this relationship using the COVID19 dataset and OpenAI text-ada-002 embeddings with GPT3.5 chat completion API. The paper further acknowledges potential concerns related to security, bias, privacy, IP, and the long-term effects on critical thinking abilities.},
  keywords={Privacy;Data analysis;Generative AI;Decision making;Organizations;Documentation;Metadata;Metadata;Artificial Intelligence;Data Analytics;Data Governance;Data Management},
  doi={10.1109/CSCE60160.2023.00267},
  ISSN={},
  month={July},}@INBOOK{11173775,
  author={Singh, Ajay Pal and Rahi, Parvez and Kumar, Vinod},
  booktitle={Handbook of Intelligent Automation Systems Using Computer Vision and Artificial Intelligence}, 
  title={An Image Synthesis Using Progressive Generative Adversarial Networks (PGANs)}, 
  year={2025},
  volume={},
  number={},
  pages={163-184},
  abstract={Summary <p>This chapter provides a summary of the utilization of generative adversarial networks (GANs) in the domain of computer vision&#x2014;image synthesis and manipulation. GANs are composed of two intricate neural networks, specifically, two competitively trained components&#x2014;a discriminator and a generator. Owing to the formidable capabilities of deep neural networks and their adversarial training approach, GANs exhibit the ability to generate realistic and plausible images, thereby demonstrating remarkable prowess across various applications in the realm of image synthesis and manipulation. This survey paper delves into recent GAN&#x2010;related research. Working on the technique of progressive GANs model helps to find out how capable is it than other GANs algorithms. Two brain organizations make up GANs for image synthesis: a discriminator and a generator. The discriminator determines if a picture is real (from a dataset) or fake (created by the generator), whereas the generator creates artificial images from erratic noise. In preparation, the discriminator aims to improve its ability to distinguish authentic from counterfeit images, while the generator plans to provide images that are indistinct from real ones. The generator creates increasingly realistic images as a result of this adversarial process. In domains like PC vision and designs, GANs have been widely used to generate superb images, creative representations, and information expansion.</p>},
  keywords={Generators;Training;Generative adversarial networks;Image synthesis;Synthetic data;Noise;Computer vision;Vectors;Training data;Surveys},
  doi={10.1002/9781394302734.ch8},
  ISSN={},
  publisher={Wiley},
  isbn={9781394302703},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11173775},}@ARTICLE{10041783,
  author={Zhang, Jun and Jiao, Licheng and Ma, Wenping and Liu, Fang and Liu, Xu and Li, Lingling and Chen, Puhua and Yang, Shuyuan},
  journal={IEEE Transactions on Multimedia}, 
  title={Transformer Based Conditional GAN for Multimodal Image Fusion}, 
  year={2023},
  volume={25},
  number={},
  pages={8988-9001},
  abstract={Multimodal Image fusion is becoming urgent in multi-sensor information utilization. However, existing end-to-end image fusion frameworks ignore a priori knowledge integration and long-distance dependencies across domains, which brings challenges to the network convergence and global image perception in complex scenes. In this article, a conditional generative adversarial network with transformer (TCGAN) is proposed for multimodal image fusion. The generator is to generate a fused image with the source images content. The discriminators are adopted to distinguish the differences between the fused image and the source images. Adversarial training makes the final fused image to maintain the structural and textural details in the cross-modal images simultaneously. In particular, a wavelet fusion module makes the inputs contain image content from different domains as much as possible. The extracted convolutional features interact in the multiscale cross-modal transformer fusion module to fully complement the associated information. It makes the generator to focus on both local and global context. TCGAN fully considers the training efficiency of the adversarial process and the integrated retention of redundant information. Various experimental results of TCGAN have highlighted targets, rich details, and fast convergence properties on public datasets.},
  keywords={Image fusion;Generators;Training;Feature extraction;Transformers;Generative adversarial networks;Thermal sensors;Generative adversarial network;multimodal image fusion;transformer},
  doi={10.1109/TMM.2023.3243659},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{10833955,
  author={Liu, Yishan and Chen, Zhen and Xie, Xin and Hu, Yaodong and Zhang, Lie and Xu, Dong and Wang, Yijing},
  booktitle={2024 Artificial Intelligence x Humanities, Education, and Art (AIxHEART)}, 
  title={MoodMonster: Integrating AI and Art for Emotional Journaling}, 
  year={2024},
  volume={},
  number={},
  pages={92-97},
  abstract={With the continuous evolution of artificial intelligence technology, its role in the field of mental health has become increasingly prominent. This paper focuses on mental sub-healthy people, based on journal-based psychological interventions and emotion-focused therapy, combined with mental health theories to explore the application of artificial intelligence in emotion-regulating journaling tools, whose core functions include: generating healing cartoon illustrations and images from user's journal text, recognizing textual emotions and guiding the user to express their emotions in a more positive language with personalized images, and anonymous sharing. Finally, the user research confirms its effectiveness and feasibility in regulating users' emotions and meeting users' needs for personalized journal records. From a deeper level, this paper is a useful attempt to improve the self-knowledge and emotion management ability of mental sub-healthy people with the help of artificial intelligence technology.},
  keywords={Emotion recognition;Visualization;Art;Image recognition;Accuracy;Text recognition;Image synthesis;Medical treatment;Mental health;Artificial intelligence;AIGC;GPT-4;emotional journaling;mental health;emotion visualization;journal-based psychological interventions;textual sentiment analysis},
  doi={10.1109/AIxHeart62327.2024.00022},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10223577,
  author={Ryspayeva, Marya},
  booktitle={2023 IEEE International Conference on Smart Information Systems and Technologies (SIST)}, 
  title={Generative Adversarial Network as Data Balance and Augmentation Tool in Histopathology of Breast Cancer}, 
  year={2023},
  volume={},
  number={},
  pages={99-104},
  abstract={This paper explores Wasserstein Generative Adversarial Network Gradient-Penalty (WGAN-GP) for data balance in the medical domain where data scarcity and imbalance are common. The study applies Transfer Learning with pre-trained models from ImageNet on histopathological breast cancer data, both unbalanced and balanced. WGAN-GP was used to overcome the challenge of generating synthetic images to balance the data and improve the accuracy of the classification task. The highest results were shown by VGG16 with a balanced dataset by WGAN-GP in 300 epochs (95.40% accuracy, 96.56% sensitivity, 94.91% specificity). Results showed an improvement in accuracy from 84.25% to 95.40%.},
  keywords={Sensitivity;Histopathology;Transfer learning;Generative adversarial networks;Data augmentation;Breast cancer;Data models;generative adversarial network;GAN;WGAN-GP;data balance;histopathology;breast cancer;transfer learning;artificial intelligence},
  doi={10.1109/SIST58284.2023.10223577},
  ISSN={},
  month={May},}@INBOOK{10951023,
  author={Khan, Ian},
  booktitle={The Quick Guide to Prompt Engineering: Generative AI Tips and Tricks for ChatGPT, Bard, Dall-E, and Midjourney}, 
  title={Your Future in Prompt Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={445-460},
  abstract={Summary <p>Prompt engineering, an emerging subfield in the vast world of artificial intelligence (AI), is opening up an array of opportunities for tech enthusiasts, linguists, and creative thinkers alike. Prompt engineering is an intersection of linguistics, technology, and human psychology. Its emergence in the AI realm underscores the need for enhancing AI models to better understand and respond to human inputs. This chapter discusses some potential directions one can pursue. They are: AI Model Trainer; AI Consultant; Research Scientist; AI Educator; Ethics Officer in AI; Content Creator with AI Assistance; Business Analyst; AI Product Manager; Freelance AI Expert; and AI Interface Designer. The chapter explains how we can build a compelling portfolio in prompt engineering. It also explains how one can engage and thrive within this burgeoning global community. In conclusion, prompt engineering is at the intersection of linguistic creativity and technical acumen.</p>},
  keywords={Artificial intelligence;Prompt engineering;Training;Ethics;Engineering profession;Companies;Collaboration;Technological innovation;Shape;Games},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394243341},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951023},}@INPROCEEDINGS{10391222,
  author={Wu, Yanwen and Han, Yuan and Shao, Fenghua and Guo, Ziyu},
  booktitle={2023 International Conference on Intelligent Education and Intelligent Research (IEIR)}, 
  title={Research Personalized Learning Report Generation--An Example from a Course on Integration of Information Technology and Physics Curriculum}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The rapid development of artificial intelligence technology represented by AIGC has pushed the generation of learning reports from traditional manual writing to automated generation. In order to efficiently, objectively diagnose the effective learning behaviors of students in the learning process and automatically generate learning situation reports, this paper starts from a multimodal perspective, collects data related to students’ learning behaviors by using smart classrooms and online learning platforms and carries out feature extraction and metrics, and builds datasets, and constructs a text generation model for learning situation diagnosis based on the Generative Adversarial Network to automatically generate diagnostic texts for learning behaviors. Finally, Freemaker templating is used to generate the learning diagnosis report. Empirical studies have shown that the automatic generation of learning situation report based on multimodal data can accurately reflect the students’ learning situation, make classroom teaching intelligent, whole process, and accurate, and provide the basis for teachers to make targeted and accurate policy, and improve the quality of teachers’ teaching.},
  keywords={Measurement;Education;Refining;Writing;Generative adversarial networks;Data models;Real-time systems;multimodal data;Natural language processing;Generative adversarial networks;Text generation techniques},
  doi={10.1109/IEIR59294.2023.10391222},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10600693,
  author={Yılmaz, Emirkan Burak and Akgül, Yusuf Sinan and Tan, Funda},
  booktitle={2024 32nd Signal Processing and Communications Applications Conference (SIU)}, 
  title={Architectural Works of the Early Republic Period from an Artificial Intelligence Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={This study presents a versatile approach integrating various neural network architectures with a focus on classifying architectural works. To address the lack of suitable datasets in the literature, a custom dataset has been created and made publicly available. The study aims to determine the most effective model, taking into account fine details in architectural styles. In this context, a comparative analysis has been conducted on four different convolutional neural network (CNN) architectures, including a baseline model trained from scratch and models using transfer learning methods with VGG, ResNet, and EfficientNet architectures. Through experiments, the EfficientNet architecture was fine-tuned, achieving an accuracy of %84.65 for 3 architects and %74.08 for 16 architects. Additionally, the two obtained models were used as feature extractors to visualize relationships among architects in a 2D space using t-SNE dimension reduction technique. These promising results indicate that these techniques can significantly contribute to architectural style analysis and serve as valuable tools for creating innovative designs through the use of generative artificial intelligence.},
  keywords={Dimensionality reduction;Analytical models;Visualization;Generative AI;Transfer learning;Neural networks;Signal processing;image classification;deep learning;convolutional neural network;architectural style},
  doi={10.1109/SIU61531.2024.10600693},
  ISSN={2165-0608},
  month={May},}@INPROCEEDINGS{10772761,
  author={Garima, Sogani and Swapnil, Morande and Shashank, Shah},
  booktitle={2024 ITU Kaleidoscope: Innovation and Digital Transformation for a Sustainable World (ITU K)}, 
  title={Harnessing the Power of Language Models for Intelligent Digital Health Services}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This research proposes a novel framework that integrates state-of-the-art large language models (LLMs) with curated medical knowledge bases to enable personalized, reliable, and user-centric digital health services. The architecture combines advanced generative models, retrieval-augmented generation, and domain adaptation strategies to ensure the safety and ethical alignment of AI-driven health recommendations. Empirical evaluations, including automated benchmarks and user studies, demonstrate the framework’s ability to provide accurate, relevant, and personalized health information that resonates with patients and providers. The results highlight the potential of this approach to bridge the gap between general-purpose LLMs and domain-specific healthcare applications. However, the work also underscores the challenges in responsibly developing and deploying generative AI for healthcare, such as safety, robustness, fairness, privacy, and interpretability. The research advocates for multidisciplinary collaboration to address these challenges and realize the potential of AI in enhancing health and well-being worldwide. By prioritizing patient agency, clinical validity, and ethical practices, this work contributes to the growing body of knowledge at the intersection of AI and healthcare, laying the foundation for future research and innovation in personalized, equitable, and trustworthy AI health services.},
  keywords={Technological innovation;Ethics;Privacy;Generative AI;Large language models;Knowledge based systems;Robustness;Safety;Electronic healthcare;ITU;generative AI;personalized healthcare;knowledge retrieval;language models;ethical AI},
  doi={10.23919/ITUK62727.2024.10772761},
  ISSN={},
  month={Oct},}@INBOOK{10950698,
  author={Singh, Shiv},
  booktitle={Marketing with AI For Dummies}, 
  title={Diving into Personalized Marketing}, 
  year={2025},
  volume={},
  number={},
  pages={299-317},
  abstract={Summary <p>This chapter covers the fundamentals of personalization as they relate to business practices and the emerging possibilities for marketers with the advent of generative artificial intelligence (AI). It explores the application of generative AI in personalization, explains the advantages of personalization and explores core personalization concepts from a customer's perspective. These concepts include understanding the importance of data collection, segmentation, and targeting, as well as the role of predictive analytics and machine learning algorithms in delivering personalized experiences. Consumers expect high levels of personalization in customer service. Consumers increasingly expect highly tailored and personalized experiences at every point of their interaction with a business. AI technology and deep learning models transform personalization by enabling more sophisticated recommendations for both marketers and customers. Personalization starts with the thorough collection and management of data. Predictive analytics is a powerful tool that allows businesses to anticipate customer needs and preferences.</p>},
  keywords={Artificial intelligence;Business;Real-time systems;Generative AI;Customer services;Companies;Predictive analytics;Market research;Electronic mail;Data privacy},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394237210},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10950698},}@INBOOK{10950752,
  author={Singh, Shiv},
  booktitle={Marketing with AI For Dummies}, 
  title={Churn Modeling and Measurement with AI}, 
  year={2025},
  volume={},
  number={},
  pages={165-180},
  abstract={Summary <p>This chapter delves into the nuanced aspects of churn modeling, beginning with an overview and exploring artificial intelligence (AI) techniques that make churn modeling all the more effective in the AI era. Churn modeling processes use historical customer data to detect patterns of behavior and indicators that precede customers' cancellation of a product or service. The art of churn modeling includes both traditional statistical methods and newer, AI&#x2010;driven approaches. The advent of AI, particularly generative AI, has significantly transformed churn modeling by enabling more nuanced insights and predictive capabilities. Generative AI enhances churn modeling by simulating customer behaviors and responses to various stimuli or changes in service. Customer retention strategies are essential for businesses aiming to reduce churn and enhance customer lifetime value. Integrating AI&#x2010;driven data collection and monitoring can transform measurement operations into dynamic systems that track performance and enhance decision&#x2010;making by providing intelligent, data&#x2010;driven insights.</p>},
  keywords={Churn;Artificial intelligence;Data models;Predictive models;Business;Adaptation models;Accuracy;Generative AI;Consumer behavior;Testing},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394237210},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10950752},}@ARTICLE{11124585,
  author={Huo, Jing and Jin, Shiyin and Li, Jiashen and Tian, Pingzhuo and Li, Wenbin and Wu, Jing and Lai, Yu-Kun and Gao, Yang},
  journal={IEEE Transactions on Multimedia}, 
  title={Dictionary Based Generative Adversarial Network for Multi-Collection Style Transfer}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={Most collection-based style transfer methods require training a separate model for each individual collection of styles, making the extension to multiple collections of styles less flexible. Besides, the existing collection-based methods are also less flexible in extending to new style collections in a continual manner. To address these issues, we propose a novel MultI-Dictionary Generative Adversarial Network framework (MID-GAN) for multi-collection style transfer. Specifically, we design a multi-dictionary architecture within a GAN, with each dictionary consisting of a set of local style codes for a specific style collection. Benefiting from the local style codes used in the dictionary, a stylization module with aligned skip connections is further proposed, which can better preserve both the local details and the overall image structure. The dictionary design allows a flexible extension to new style collections by readily adding new dictionaries and we propose a continual training strategy that can both preserve the style transfer ability of old styles and achieve good transfer results for newly added styles. Extensive experiments are performed to show that the proposed method is better than existing collection-based style transfer methods. We also demonstrate the proposed method can generate diverse meaningful style transfer results of the same style collection.},
  keywords={Dictionaries;Training;Generative adversarial networks;Feature extraction;Logic gates;Decoding;Continuing education;Kernel;Artificial intelligence;Transformers;Generative adversarial network;style transfer;continual learning},
  doi={10.1109/TMM.2025.3599024},
  ISSN={1941-0077},
  month={},}@ARTICLE{10897884,
  author={Li, Lixu and Xin, Xiaohua and Xing, Xinjie and Liu, Yaoqi and Chen, Lujie},
  journal={IEEE Transactions on Engineering Management}, 
  title={Tailoring Success: Harnessing the Creational Affordances of Generative Artificial Intelligence to Drive Market Performance}, 
  year={2025},
  volume={72},
  number={},
  pages={676-688},
  abstract={The rapid evolution of generative artificial intelligence (GenAI) has revolutionized various industries through its creational affordances. However, the impact of these affordances on business outcomes remains underexplored. Drawing on the resource-based view, we examine the relationships among GenAI's creational affordances, customer orientation, customization, and market performance. Using survey data from 196 information technology (IT) firms in mainland China, we reveal that both product and service customization significantly mediate the positive relationship between GenAI's creational affordances and market performance. Furthermore, customer orientation merely enhances the mediation effect of service customization, underscoring its critical role in maximizing the strategic benefits of GenAI. We contribute to existing technology-driven operations management research by emphasizing the moderated mediation mechanism in the relationship between GenAI's creational affordances and market performance. Our findings not only assist IT firms in better implementing their AI strategies but also offer a reference for the development of other firms.},
  keywords={Affordances;Business;Artificial intelligence;Technological innovation;Electronic mail;Roads;Mediation;Ethics;Customer satisfaction;Creativity;Customer orientation;customization;generative artificial intelligence;information technology (IT) firms;market performance;resource-based view (RBV)},
  doi={10.1109/TEM.2025.3542764},
  ISSN={1558-0040},
  month={},}@INPROCEEDINGS{9529432,
  author={Ma, Jiachen and Saxena, Piyush and Ahamed, Sheikh Iqbal},
  booktitle={2021 IEEE 45th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={A Comprehensive Qualitative and Quantitative Review of Current Research in GANs}, 
  year={2021},
  volume={},
  number={},
  pages={1675-1682},
  abstract={Generative Adversarial Networks (GANs) are among the most actively researched neural networks in today’s artificial intelligence research. Scientists across different domains, particularly in image processing, constantly utilize variants of GANs to conduct research. The topic has increasingly drawn attention and interest in recent years. Our survey paper reviews the current literature and applications of GANs from both qualitative and quantitative perspectives. This survey also summarizes the challenges and improvement techniques of training GANs. We hope this paper may help researchers interested in GANs and serve as an informative source for ongoing and future work in this field.},
  keywords={Training;Image processing;Conferences;Neural networks;Market research;Generative adversarial networks;Software;Generative Adversarial Networks;Neural Net-works;Artificial Intelligence;Machine Learning;Data Science},
  doi={10.1109/COMPSAC51774.2021.00250},
  ISSN={0730-3157},
  month={July},}@INPROCEEDINGS{10814860,
  author={Tafferner, Zoltán and Géczy, Attila},
  booktitle={2024 IEEE 30th International Symposium for Design and Technology in Electronic Packaging (SIITME)}, 
  title={Comparing large language model artificial intelligence tools in aid of electrical engineering}, 
  year={2024},
  volume={},
  number={},
  pages={9-14},
  abstract={Conversational AI (artificial intelligence) systems have broken into the digital technology sphere at the end of 2022. Many scientists, engineers, and authors have begun using them despite a lack of evidence for their applicability. Research has been conducted in several fields, including electrical engineering, on the applicability of generative AI in many fields, such as chemical engineering, programming, medicine, and even electrical engineering. Most, although not all, of the existing research focuses on applying specific AI models. This case study compares several generative AI models (ChatGPT, Bard, Bing AI, Copilot) through tasks in electrical engineering design. We qualitatively evaluated the AI responses to the questions. We have found that although AI tools are applicable and perform similarly well in general questions, their use is highly questionable in more specific cases, for example, in circuit design. Lastly, AIs perform equally unacceptably in tasks that require specific data, such as literature reviews. We conclude that the bots should be used sparingly with strict supervision and professional knowledge.},
  keywords={Electrical engineering;Codes;Generative AI;Bibliographies;Large language models;Cognition;Internet;Circuit synthesis;Artificial intelligence;Integrated circuit modeling;ChatGPT;large language model;generative AI;electrical engineering},
  doi={10.1109/SIITME63973.2024.10814860},
  ISSN={2642-7036},
  month={Oct},}@ARTICLE{10445413,
  author={Islam, Showrov and Aziz, Md. Tarek and Nabil, Hadiur Rahman and Jim, Jamin Rahman and Mridha, M. F. and Kabir, Md. Mohsin and Asai, Nobuyoshi and Shin, Jungpil},
  journal={IEEE Access}, 
  title={Generative Adversarial Networks (GANs) in Medical Imaging: Advancements, Applications, and Challenges}, 
  year={2024},
  volume={12},
  number={},
  pages={35728-35753},
  abstract={Generative Adversarial Networks are a class of artificial intelligence algorithms that consist of a generator and a discriminator trained simultaneously through adversarial training. GANs have found crucial applications in various fields, including medical imaging. In healthcare, GANs contribute by generating synthetic medical images, enhancing data quality, and aiding in image segmentation, disease detection, and medical image synthesis. Their importance lies in their ability to generate realistic images, facilitating improved diagnostics, research, and training for medical professionals. Understanding its applications, algorithms, current advancements, and challenges is imperative for further advancement in the medical imaging domain. However, no study explores the recent state-of-the-art development of GANs in medical imaging. To overcome this research gap, in this extensive study, we began by exploring the vast array of applications of GANs in medical imaging, scrutinizing them within recent research. We then dive into the prevalent datasets and pre-processing techniques to enhance comprehension. Subsequently, an in-depth discussion of the GAN algorithms, elucidating their respective strengths and limitations, is provided. After that, we meticulously analyzed the results and experimental details of some recent cutting-edge research to obtain a more comprehensive understanding of the current development of GANs in medical imaging. Lastly, we discussed the diverse challenges encountered and future research directions to mitigate these concerns. This systematic review offers a complete overview of GANs in medical imaging, encompassing their application domains, models, state-of-the-art results analysis, challenges, and research directions, serving as a valuable resource for multidisciplinary studies.},
  keywords={Image segmentation;Medical diagnostic imaging;Generative adversarial networks;Reviews;Image reconstruction;Image synthesis;Magnetic resonance imaging;Artificial intelligence;Biomedical imaging;Medical services;Systematics;Training;Generative adversarial networks;medical imaging;medical image synthesis;medical image enhancement;medical image augmentation;medical image segmentation},
  doi={10.1109/ACCESS.2024.3370848},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10664825,
  author={Simaremare, Mario E. S. and Pardede, Chandro and Tampubolon, Irma N. I. and Simangunsong, Daniel A. and Manurung, Putri E.},
  booktitle={2024 IEEE Integrated STEM Education Conference (ISEC)}, 
  title={The Penetration of Generative AI in Higher Education: A Survey}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Context: The global teacher shortage crisis is a severe challenge. The crisis also rises in Indonesia, where the problem extends to unequal teaching quality and learning facilities. This situation seriously threatens the Indonesian 2045 vision of being a developed country with knowledgeable human resources. The advancement of AI brings opportunities to address the challenges. In recent years, there has been a wave of generative AI (GenAI) technologies and their adoption in education. However, there is no research on the penetration of such technology in our learning environment. Objective: In this study, we investigate the penetration of GenAI by students in a higher education setting. Method: We surveyed 1,157 students of Institut Teknologi Del, a private university in western Indonesia, and developed local knowledge based on the responses. Results: Our results show that most students are well aware of GenAI technologies (70.96%) and have used them to support their learning (98.96%). The top five most used GenAI tools are GitHub Copilot, OpenAI ChatGPT, Codex, Grammarly, and ChatPDF. Conclusion: GenAI is already part of the daily learning process. We believe that, sooner or later, GenAI will be one of many deciding factors in our future education systems, and we must be ready to adapt to it.},
  keywords={Surveys;Ethics;Generative AI;Source coding;Education;Knowledge based systems;Chatbots;education;generative AI;student;survey},
  doi={10.1109/ISEC61299.2024.10664825},
  ISSN={2473-7623},
  month={March},}@INPROCEEDINGS{10818160,
  author={Kilsby, Paul and Kun, Leo Ah},
  booktitle={2024 Eighth IEEE International Conference on Robotic Computing (IRC)}, 
  title={Enabling Intelligent Robotic Visual Inspection in the Railway Industry with Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={275-277},
  abstract={The use of robotics and generative AI has the potential to increase automation of industrial inspection processes, leading to improved asset management and significant cost savings. This paper describes how vision language models can be used to process image data acquired by robots to perform inspection and streamline the maintenance response. The application of this technology is considered with respect to deploying robotics for visual inspection of railway assets. Whilst there are some industry specific constraints and benefits, the general concepts presented should be readily applicable to other asset intensive industries.},
  keywords={Industries;Visualization;Service robots;Generative AI;Computational modeling;Inspection;Streaming media;Rail transportation;Robots;Testing;robotics;railway;computer vision inspection;vision language models;generative AI},
  doi={10.1109/IRC63610.2024.00051},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10883930,
  author={Jain, Alok and William, P. and Ayasrah, Firas Tayseer and Lakshmi, G. Prasanna and Diwan, Tarun Dhar},
  booktitle={2024 11th International Conference on Software Defined Systems (SDS)}, 
  title={Analyzing Automatic Code Generation for Learning Models in Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={50-58},
  abstract={Independent code generation models produced by generative AI provide a new way to software development. These models automatically generate code using machine learning based on input samples. This study examines the fundamentals, applications, problems, and future prospects of AI-related automated code generation technologies. Model-based software, domain-specific code, and testing procedures are examples of these research topics. Performance analysis and assessment are used to assess the efficacy, efficiency, and reliability of several automated code generating methods. The fact that these models have pros and cons and room for development is highlighted.},
  keywords={Analytical models;Codes;Generative AI;Training data;Software;Software reliability;Performance analysis;Research and development;Software development management;Testing;Automatic code generation;Generative AI;machine learning;software development;testing methodologies;model-based development;domain-specific code generation},
  doi={10.1109/SDS64317.2024.10883930},
  ISSN={},
  month={Dec},}
