@INPROCEEDINGS{10836028,
  author={Ahmed, Waqas and Sentosa, Ilham and Hizam, Sheikh Muhamad and Mat, Che Rosmawati Che and Hernandez, Martin Spraggon},
  booktitle={2023 International Conference on Data, Information and Computing Science (CDICS)}, 
  title={Evaluating the Acceptance of Enhanced Generative AI Services}, 
  year={2023},
  volume={},
  number={},
  pages={73-77},
  abstract={The rapid advancement of artificial intelligence (AI) has introduced a spectrum of generative AI services that promise to enhance various professional and personal tasks. This study aims to explore the factors influencing users’ intentions to transition from basic to premium generative AI services, focusing on Performance Expectancy (PE), Technology Self-Efficacy (TSE), Personal Innovativeness (PI), and Social Influence (SI). A survey of 193 individuals, primarily university students with an IT background, revealed that PE, TSE, and SI significantly affect the Behavioral Intention (BI) to adopt enhanced services, with SI being the most influential. Contrary to expectations, PI did not predict BI, indicating that innovation alone does not drive the adoption of advanced AI capabilities. The findings suggest that the practicality of AI tools, user confidence in their technical skills, and the persuasive power of social networks are pivotal in the decision-making process for upgrading AI services. This research contributes to the understanding of AI adoption patterns and provides insights for developers and marketers to tailor user experiences and educational initiatives that align with user needs and social dynamics. It also underscores the importance of addressing ethical considerations as AI continues to permeate various aspects of society.},
  keywords={Surveys;Technological innovation;Ethics;Generative AI;Social networking (online);Decision making;Focusing;Chatbots;Generative AI;ChatGPT;Technology Acceptance;User Behavior;Social Influence},
  doi={10.1109/CDICS61497.2023.00022},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11145008,
  author={Izani, M. and Gabr, Mona and Razak, A. and Kaleel, Akhmed},
  booktitle={2025 IEEE Region 10 Symposium (TENSYMP)}, 
  title={A Principle-Based Evaluation of Generative AI Animation}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Generative AI technologies have revolutionized animation production, yet their adherence to the foundational principles of animation remains underexplored. This study evaluates the extent to which AI-generated animations align with the ten fundamental principles defined by Thomas and Johnston. Five animations were systematically analyzed through expert evaluations and statistical methods, including inter-rater reliability, chi-square tests, factor analysis, analysis of variance (ANOVA), and logistic regression. The results revealed that while principles such as Staging, Solid Drawing, and Appeal were consistently adhered to, dynamic motion-related principles like Squash and Stretch, Anticipation, and Exaggeration were entirely absent. For intermediate principles like Timing and Follow-Through were variable, it shows the constraints of AI's ability to reproduce temporal motion control. This research contributes to the animation field by providing an analysis of the animation principles in AI-generated animation, identifying both strengths and weaknesses. Practical significance highlights the potential for hybrid workflows wherein AI is employed for static composition tasks, and nuanced motion design is reserved for human animators. The results enable the development of generative artificial intelligence technologies, and the necessity for models capable of grasping the artistry and sophistication involved in conventional animation is now clear. The study presents actionable guidance to researchers, developers, and practitioners interested in closing the gap between technological advancement and artistic design.},
  keywords={Visualization;Art;Systematics;Generative AI;Animation;Solids;Remote working;Timing;Motion control;Analysis of variance;Generative AI;Animation Principles;AI-Generated Animations;Temporal Motion Control;Hybrid Workflows},
  doi={10.1109/TENSYMP63728.2025.11145008},
  ISSN={2642-6102},
  month={July},}@INPROCEEDINGS{10971689,
  author={Haque, Sean and Tanveer, Muhammad Hassan and Voicu, Razvan Cristian},
  booktitle={SoutheastCon 2025}, 
  title={AI-Driven 3D Printing: Generative Gcode for Quality and Efficiency}, 
  year={2025},
  volume={},
  number={},
  pages={1282-1287},
  abstract={Artificial Intelligence (AI) is transforming the landscape of three-dimensional (3D) printing by enabling generative approaches that extend beyond conventional, parameter-tuning strategies. Rather than merely adjusting nozzle temperatures or speeds, modern AI models can create or refine Gcode paths themselves, seeking to balance objectives such as print strength, dimensional accuracy, and defect minimization. This paper introduces a holistic AI-driven workflow for automated Gcode generation. We demonstrate that generative Large Language Models (LLMs) can parse, synthesize, and optimize printing instructions, thus offering an alternative to human-engineered slicing parameters. Our approach incorporates a continuous feedback loop in which a predictive model evaluates each generated Gcode script for potential print outcomes. Experimental results illustrate strong correlations between the number of lines in generated Gcode and key performance metrics (tensile strength, defect rate, and dimensional accuracy). Notably, some scripts with fewer lines reduced material defects yet slightly degraded dimensional accuracy, while more complex scripts improved measurement fidelity but also introduced minor flaws. These findings illuminate the trade-offs in AI-driven 3D printing and highlight the method's capacity for ongoing improvement. By exploring future expansions, such as continuous-function printing trajectories and multi-material prints, this study shows that AI-based Gcode generation can significantly advance 3D printing quality and customization across diverse applications.},
  keywords={Solid modeling;Accuracy;Generative AI;Large language models;Machine learning;Predictive models;Three-dimensional printing;Minimization;Trajectory;Optimization;3D Printing;Generative AI;Gcode;Machine Learning;Print Optimization;AI Generated 3D Models;Additive Manufacturing},
  doi={10.1109/SoutheastCon56624.2025.10971689},
  ISSN={1558-058X},
  month={March},}@ARTICLE{10113601,
  author={Wu, Tianyu and He, Shizhu and Liu, Jingping and Sun, Siqi and Liu, Kang and Han, Qing-Long and Tang, Yang},
  journal={IEEE/CAA Journal of Automatica Sinica}, 
  title={A Brief Overview of ChatGPT: The History, Status Quo and Potential Future Development}, 
  year={2023},
  volume={10},
  number={5},
  pages={1122-1136},
  abstract={ChatGPT, an artificial intelligence generated content (AIGC) model developed by OpenAI, has attracted world-wide attention for its capability of dealing with challenging language understanding and generation tasks in the form of conversations. This paper briefly provides an overview on the history, status quo and potential future development of ChatGPT, helping to provide an entry point to think about ChatGPT. Specifically, from the limited open-accessed resources, we conclude the core techniques of ChatGPT, mainly including large-scale language models, in-context learning, reinforcement learning from human feedback and the key technical steps for developing Chat-GPT. We further analyze the pros and cons of ChatGPT and we rethink the duality of ChatGPT in various fields. Although it has been widely acknowledged that ChatGPT brings plenty of opportunities for various fields, mankind should still treat and use ChatGPT properly to avoid the potential threat, e.g., academic integrity and safety challenge. Finally, we discuss several open problems as the potential development of ChatGPT.},
  keywords={Three-dimensional displays;Web and internet services;Reinforcement learning;Chatbots;Robot sensing systems;Transformers;History;AIGC;ChatGPT;GPT-3;GPT-4;human feedback;large language models},
  doi={10.1109/JAS.2023.123618},
  ISSN={2329-9274},
  month={May},}@INPROCEEDINGS{10848675,
  author={Ondiba, Hesborn},
  booktitle={2025 IEEE 4th International Conference on AI in Cybersecurity (ICAIC)}, 
  title={Proactive AI-Driven Cybersecurity for Endangered Language Preservation: Safeguarding the Suba Linguistic Corpus}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper explores the integration of proactive AIdriven cybersecurity measures in developing endangered language corpora, with a case study focusing on the Suba language of Kenya. Given the sensitive nature of linguistic data and the cultural significance embedded within, securing the Suba language corpus against cyber threats is critical to its preservation. This study combines a comprehensive literature review on endangered language preservation, AI applications, and cybersecurity risks with the author’s practical experience in corpus development. By leveraging machine learning, anomaly detection, and blockchain-based access control, this paper proposes a robust framework for securing linguistic data from unauthorized access, data corruption, and breaches during collection, transmission, and storage. It emphasizes ethical data management and the role of AI technologies in safeguarding the integrity and confidentiality of Indigenous knowledge, contributing to broader efforts in preserving linguistic diversity.},
  keywords={Ethics;Protocols;Prevention and mitigation;Machine learning;Linguistics;Cultural differences;Computer security;Protection;Anomaly detection;Systematic literature review;Artificial Intelligence;Linguistic Corpus;Cybersecurity;Suba},
  doi={10.1109/ICAIC63015.2025.10848675},
  ISSN={},
  month={Feb},}@ARTICLE{9529210,
  author={Lang, Wangjie and Hu, Yihua and Gong, Chao and Zhang, Xiaotian and Xu, Hui and Deng, Jiamei},
  journal={IEEE Transactions on Transportation Electrification}, 
  title={Artificial Intelligence-Based Technique for Fault Detection and Diagnosis of EV Motors: A Review}, 
  year={2022},
  volume={8},
  number={1},
  pages={384-406},
  abstract={The motor drive system plays a significant role in the safety of electric vehicles as a bridge for power transmission. Meanwhile, to enhance the efficiency and stability of the drive system, more and more studies based on AI technology are devoted to the fault detection and diagnosis (FDD) of the motor drive system. This article reviews the application of AI techniques in motor FDD in recent years. AI-based FDD is divided into two main steps: feature extraction and fault classification. The application of different signal processing methods in feature extraction is discussed. In particular, the application of traditional machine learning and deep learning algorithms for fault classification is presented in detail. In addition, the characteristics of all techniques reviewed are summarized. Finally, the latest developments, research gaps, and future challenges in fault monitoring and diagnosis of motor faults are discussed.},
  keywords={Induction motors;Rotors;Circuit faults;Permanent magnet motors;Synchronous motors;Stator windings;Electric motors;AI-based techniques;deep learning;machine learning (ML);motor fault},
  doi={10.1109/TTE.2021.3110318},
  ISSN={2332-7782},
  month={March},}@ARTICLE{7332941,
  author={Menze, Bjoern H. and Van Leemput, Koen and Lashkari, Danial and Riklin-Raviv, Tammy and Geremia, Ezequiel and Alberts, Esther and Gruber, Philipp and Wegener, Susanne and Weber, Marc-André and Székely, Gabor and Ayache, Nicholas and Golland, Polina},
  journal={IEEE Transactions on Medical Imaging}, 
  title={A Generative Probabilistic Model and Discriminative Extensions for Brain Lesion Segmentation— With Application to Tumor and Stroke}, 
  year={2016},
  volume={35},
  number={4},
  pages={933-946},
  abstract={We introduce a generative probabilistic model for segmentation of brain lesions in multi-dimensional images that generalizes the EM segmenter, a common approach for modelling brain images using Gaussian mixtures and a probabilistic tissue atlas that employs expectation-maximization (EM), to estimate the label map for a new image. Our model augments the probabilistic atlas of the healthy tissues with a latent atlas of the lesion. We derive an estimation algorithm with closed-form EM update equations. The method extracts a latent atlas prior distribution and the lesion posterior distributions jointly from the image data. It delineates lesion areas individually in each channel, allowing for differences in lesion appearance across modalities, an important feature of many brain tumor imaging sequences. We also propose discriminative model extensions to map the output of the generative model to arbitrary labels with semantic and biological meaning, such as “tumor core” or “fluid-filled structure”, but without a one-to-one correspondence to the hypo- or hyper-intense lesion areas identified by the generative model. We test the approach in two image sets: the publicly available BRATS set of glioma patient scans, and multimodal brain images of patients with acute and subacute ischemic stroke. We find the generative model that has been designed for tumor lesions to generalize well to stroke images, and the extended discriminative -discriminative model to be one of the top ranking methods in the BRATS evaluation.},
  keywords={Brain modeling;Image segmentation;Lesions;Probabilistic logic;Biological system modeling;Mathematical model;Medical diagnostic imaging;anatomical structure;tumors;image segmentation;object segmentation;Bayes methods},
  doi={10.1109/TMI.2015.2502596},
  ISSN={1558-254X},
  month={April},}@INPROCEEDINGS{10512032,
  author={Das, Tulip and Nayak, Chinmaya Kumar and Pattnayak, Parthasarathi},
  booktitle={2024 3rd International Conference for Innovation in Technology (INOCON)}, 
  title={Alzheimer’s Disease Diagnosis Using Artificial Intelligence and MRI Images of the Brain}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={One major neurodegenerative disease that primarily affects the senior citizen and pre-elderly population is Alzheimer’s disease. Advances in AI-enhanced detection for Alzheimer’s disease have been spurred by recent developments in MRI technology, raising hopes for early detection and prompt therapies. This advancement has made it possible to create complicated models and algorithms that can analyse imaging data, improving the efficiency and accuracy of diagnosis. It gives rise to hope for the groundbreaking possibilities in transforming the management of Alzheimer’s disease and more successful treatment plans and better patient outcomes. This article aims to give a thorough overview of current advancements in DL techniques used to classify different stages of Alzheimer’s disease based on brain MRI scans, with a focus on early diagnosis. It also discusses possible obstacles and future research possibilities, highlighting the shortcomings of the current research.},
  keywords={Technological innovation;Sequential analysis;Magnetic resonance imaging;Sociology;Medical treatment;Brain modeling;Data models;Deep learning;Brain MRI images;Alzheimer’s disease;stage prediction;early diagnosis},
  doi={10.1109/INOCON60754.2024.10512032},
  ISSN={},
  month={March},}@INPROCEEDINGS{9412542,
  author={Li, Ling and Li, Yaochen and Wu, Chuan and Dong, Hang and Jiang, Peilin and Wang, Fei},
  booktitle={2020 25th International Conference on Pattern Recognition (ICPR)}, 
  title={Detail Fusion GAN: High-Quality Translation for Unpaired Images with GAN-based Data Augmentation}, 
  year={2021},
  volume={},
  number={},
  pages={1731-1736},
  abstract={Image-to-image translation, a task to learn the mapping relation between two different domains, is a rapid-growing research field in deep learning. Although existing Generative Adversarial Network (GAN)-based methods have achieved decent results in this field, there are still some limitations in generating high-quality images for practical applications (e.g., data augmentation and image inpainting). In this work, we aim to propose a GAN-based network for data augmentation which can generate translated images with more details and less artifacts. The proposed Detail Fusion Generative Adversarial Network (DFGAN) consists of a detail branch, a transfer branch, a filter module, and a reconstruction module. The detail branch is trained by a super-resolution loss and its intermediate features can be used to introduce more details to the transfer branch by the filter module. Extensive evaluations demonstrate that our model generates more satisfactory images against the state-of-the-art approaches for data augmentation.},
  keywords={Deep learning;Image segmentation;Computer vision;Superresolution;Generative adversarial networks;Information filters;Data models},
  doi={10.1109/ICPR48806.2021.9412542},
  ISSN={1051-4651},
  month={Jan},}@INPROCEEDINGS{10331818,
  author={T., Ganga Bhavani and Chokkalingam, Sp.},
  booktitle={2023 International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS)}, 
  title={Enhancing Intrusion Detection in Wireless Sensor Networks Using Deep Learning-Based K-Barriers Prediction}, 
  year={2023},
  volume={},
  number={},
  pages={1208-1215},
  abstract={For wireless sensor networks (WSNs) to remain secure, effective intrusion detection is a vital requirement. This research work enhances a feed-forward artificial neural network (ANN) based on deep learning as a novel approach to intrusion detection. The proposed approach focuses on precisely forecasting the count of k-barriers, which is essential for efficient intrusion detection and mitigation. Important characteristics, such as the region of interest, sensor sensing area, sensor count, and sensor sensing transmission area, all derived via Monte Carlo simulation, are utilize to train and evaluate the model. The model successfully estimates k-barrier counts, which is demonstrated by the achieved Root Mean Square Error and correlation coefficients. A conditional generative adversarial network (CGAN) based intrusion detection system and an extreme gradient boosting (XGBoost) classifier for quick result comparison and visualization are developed to further increase the system's effectiveness. The suggested approach has the ability to drastically reduce false alarms and eliminate the requirement for additional sensors to produce false data. The created deep learning architecture uses a fully linked feed-forward ANN with a focus on quick intrusion detection and prevention. Through thorough training and evaluation, this ANN achieves amazing accuracy in predicting k-barrier counts. Comparative assessments demonstrate the suggested method's advantage in terms of precision and computational effectiveness, supporting its value in enhancing wireless sensor network security.},
  keywords={Training;Wireless sensor networks;Monte Carlo methods;Intrusion detection;Artificial neural networks;Generative adversarial networks;Sensors;Intrusion detection;Deep learning;K-barriers prediction;Wireless sensor networks},
  doi={10.1109/ICSSAS57918.2023.10331818},
  ISSN={},
  month={Oct},}@ARTICLE{10365525,
  author={Zhao, Liang and Li, Tianyu and Zhang, Enchao and Lin, Yun and Wan, Shaohua and Hawbani, Ammar and Guizani, Mohsen},
  journal={IEEE Transactions on Mobile Computing}, 
  title={Adaptive Swarm Intelligent Offloading Based on Digital Twin-assisted Prediction in VEC}, 
  year={2024},
  volume={23},
  number={8},
  pages={8158-8174},
  abstract={Vehicular Edge Computing (VEC) is the transportation version of Mobile Edge Computing (MEC). In VEC, task offloading enables vehicles to offload computing tasks to nearby Roadside Units (RSUs), thereby reducing the computation cost. Recent trends in task offloading cause a proliferation of studies in academia. However, the existing offloading schemes still face many challenges, such as high-dynamic network topology, massive and complex data, dynamic scenes with high-speed vehicles and low-latency requirements. Digital Twin (DT)-based VEC is emerging as a promising solution. It monitors the state of the VEC network in real time through mappings and interactions between the physical and virtual entities. Consequently, the task offloading scheme can make more reasonable offloading decisions at the physical layer and further improve the efficiency of VEC. Above all, we propose a VEC computing offloading scheme, namely, Adaptive Swarm Intelligent Offloading Scheme Based on Digital-Twin-Assisted PRediction In VEC (STRIVE). The VEC network architecture is established to combines DT with an improved Generative Adversarial Network (GAN). The powerful prediction ability of GAN is used to assist in constructing DT in the pre-processing phase, reducing the size of the decision space. To adapt to the dynamic nature of VEC, we establish an adaptive model to adjust the real-time parameter under various scenarios. Then, we deploy an improveD genetIc simulatEd annealing-baSEd particLe swarm optimization (DIESEL) algorithm to task offloading decision-making, which can provide reliable computing services for vehicles at a lower cost. The simulation results demonstrate that the proposed scheme can effectively reduce computing delay and energy consumption compared with its counterparts.},
  keywords={Task analysis;Heuristic algorithms;Vehicle dynamics;Adaptation models;Space vehicles;Real-time systems;Mobile computing;Digital twin;generative adversarial network;mobile edge computing;swarm intelligence;task offloading;vehicular edge computing},
  doi={10.1109/TMC.2023.3344645},
  ISSN={1558-0660},
  month={Aug},}@INPROCEEDINGS{10825992,
  author={Shan, Richard},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={A Deep Dive into Vector Stores: Classifying the Backbone of Retrieval-Augmented Generation}, 
  year={2024},
  volume={},
  number={},
  pages={8831-8833},
  abstract={Vector stores represent a crucial building block for Retrieval-Augmented Generation (RAG), efficiently storing and retrieving high-dimensional embeddings to ensure relevance and accuracy for generative AI applications. This paper introduces a classification scheme that categorizes vector stores into four main classes of systems: lightweight and local solutions, open-source and distributed platforms, cloud-native and commercial services, and semantic/contextual search-oriented systems. We discuss the architectures, capabilities, strengths, weaknesses, and use cases of one representative vector database in each category: FAISS, Milvus, Pinecone, and Weaviate. Practical guidelines on the implementation are presented, focused on optimization techniques, strategies for data management, and considerations on security. Comparative insights enable practitioners to align the selection of the vector store with the workflow of RAG solutions. Future trends are explored, such as hybrid search and explainability.},
  keywords={Generative AI;Databases;Retrieval augmented generation;Big Data;Market research;Vectors;Security;Optimization;Best practices;Guidelines;Retrieval-Augmented Generation;vector store;landscape;FAISS;Chroma;Milvus;Pinecone;Weaviate;generative AI;implementation best practices;classification},
  doi={10.1109/BigData62323.2024.10825992},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{10698580,
  author={Arora, Pragya and Desu, Lohith and Kumar, Ashish and S, Ravi Kumar and Marinescu, Adriana},
  booktitle={2024 International Conference on Electrical, Computer and Energy Technologies (ICECET}, 
  title={Enhancing Profitability through AI-Optimized Accounts Receivable: Reducing Cash Conversion Cycles}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The management of accounts receivable is crucial to a company's profitability and overall growth, as it directly influences financial performance. Specifically, firms with longer cash conversion cycle periods exhibit lower profitability compared to those with shorter cash conversion cycle periods. The processes involved in this domain are often laborious, time-intensive, and susceptible to mistakes. This research paper aims to improve efficiency of accounts receivable procedures across various industries, ultimately enhancing the daily operations of collectors and reducing the cash conversion cycle. The proposed solution consists of a comprehensive architecture which leverages Generative AI to improve the efficiency and effectiveness of accounts receivable processing. Additionally, it addresses challenges such as customer segmentation, credit management support, collector assistance, dispute verification, and the customization of emails in accordance with customer strategies. Integration of Langchain-based QA system further enhances and optimizes the business operations.},
  keywords={Industries;Costs;Automation;Profitability;Generative AI;Computer architecture;Manuals;Delays;Resource management;Business;Accounts Receivable (AR);I2C (Invoice to Cash);Generative AI;LLM's;Improved Operational Efficiency;Reduced Cash Conversion Cycle},
  doi={10.1109/ICECET61485.2024.10698580},
  ISSN={},
  month={July},}@INBOOK{10952094,
  author={Yousif, Shermeen and Bolojan, Daniel},
  booktitle={Artificial Intelligence in Performance-Driven Design: Theories, Methods, and Tools}, 
  title={An Integrative Deep Performance Framework for Daylight Prediction in Early Design Ideation}, 
  year={2024},
  volume={},
  number={},
  pages={81-96},
  abstract={Summary <p>The evolution from expert systems to learning systems has ushered in a novel age in artificial intelligence (AI) and a profound and irreversible paradigm shift in the field of architecture. This research is a contribution to the Performative AI research line, which delves into the interface of AI and performance&#x2010;driven design strategies. Specifically, this study investigates the development of a new automated method for daylight performance simulation that yields a high degree of accuracy in prediction. The research is part of a larger scheme that aims to automate environmental evaluation in design systems. The technique created, called Deep Performance ( DP ), exploits deep learning to create a surrogate model ( SM ) that is trained on numerous floor plans and daylight analysis meshes of buildings. This SM can detect various architectural floor plan features, such as walls and openings, and make precise predictions of corresponding daylight analysis meshes. The precision of synthetic daylight meshes was evaluated against real simulations with two metrics, resulting in an overall accuracy of 90%. The DP method is also 600 times faster than the typical annual daylight simulation. The transformation from simulation&#x2010;based to prediction&#x2010;based approaches has considerable importance, as it enables designers to explore the creative design space while obtaining real&#x2010;time predictions of environmental metrics for evolving design options in generative design systems. This is particularly vital when daylight is incorporated in initial design phases when decision&#x2010;making is highly impactful, and the cost of design change is low (MacLeamy 2004). Daylight analysis empowers architects to experiment with passive design strategies and create variations for massing studies, interior layout designs, and envelope designs, to determine optimum solutions. The ultimate objective of this research is to facilitate achieving environmentally efficient and cost&#x2010;effective designs for the built environment through the use of data&#x2010;driven solutions.</p>},
  keywords={Buildings;Predictive models;Computational modeling;Real-time systems;Data models;Artificial intelligence;Accuracy;Performance evaluation;Energy efficiency;Computational fluid dynamics},
  doi={10.1002/9781394172092.ch4},
  ISSN={},
  publisher={Wiley},
  isbn={9781394172085},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952094},}@INPROCEEDINGS{11140795,
  author={Balakrishnan, T. Suresh and S, Caleb and Ashok, P and S, Sandhiya Vani and S, Suganya and V, Thirueswaran},
  booktitle={2025 6th International Conference for Emerging Technology (INCET)}, 
  title={Enhanced Intrusion Detection System using Deep Learning with Explainable AI and GenAI}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={This project aims to improve the cybersecurity defense by taking advantage of deep learning, XAI, and GenAI for improving the current system. For instance, its traditional IDS models have a poor capability to monitor sophisticated cyber threats and many IDS models are based on a high degree of a black-box model that is difficult for security analysts to comprehend. We use deep learning in our approach to achieve higher detection accuracy, and rely on XAI (eXplainable Artificial Intelligence) techniques such as SHAP (SHapley Additive exPlanations), LIME (Local Interpre table Model agnostic Explanations), to add interpretability to a model's decisions and allow for building trust towards automated systems. Also, humans lack cybersecurity data to label and the scarcity of data forces us to create synthetic data so the deep learning model can process different attack scenarios. This coupled with these two aims aims to ultimately decrease false positives and improve real time detection capabilities in a more reliable and powerful intrusion detection system against dynamic, evolving cyber threat landscapes.},
  keywords={Deep learning;Analytical models;Explainable AI;Intrusion detection;Real-time systems;Data models;Reliability;Computer security;Monitoring;Synthetic data;Intrusion Detection;Deep Learning;Explainable AI;Generative AI;Cybersecurity;Real-Time Detection;Data Scarcity;Model Interpretability},
  doi={10.1109/INCET64471.2025.11140795},
  ISSN={2996-4490},
  month={May},}@INPROCEEDINGS{11011465,
  author={Chennareddy, Srihith and Appala, Vamshi Krishna},
  booktitle={2025 3rd International Conference on Advancement in Computation & Computer Technologies (InCACCT)}, 
  title={Optimizing AI Model Training Costs with Stratified Sampling and Self-Adaptive Testing}, 
  year={2025},
  volume={},
  number={},
  pages={605-609},
  abstract={The data processing and generation of datasets which are required for training Large Language Models (LLMs) and Generative AI (GenAI) applications have become costly these days. This paper presents an approach to optimize the cost of generating model training datasets by combining a stratified sampling algorithm integrated with a self-adaptive, comprehensive test suite framework. The methodology proposed in this paper will reduce the size of training datasets without impacting model performance and data integrity. This helps to reduce the cost of AI model training. Our empirical analyses demonstrate that our proposed approach reduces the cost of generating datasets up to 60%, without losing model accuracy and performances. It provides a way for efficient use of compute and storage resources for generation of high quality datasets for AI model training.},
  keywords={Training;Industries;Adaptation models;Costs;Accuracy;Generative AI;Computational modeling;Large language models;Optimization;Testing;adaptive testing;Generative AI;model training;stratified sampling;large language models;model performance;model training cost optimization},
  doi={10.1109/InCACCT65424.2025.11011465},
  ISSN={},
  month={April},}@BOOK{11006483,
  author={Kapoor, Dr. Amita},
  booktitle={​Hands-On Artificial Intelligence for IoT: Expert machine learning and deep learning techniques for developing smarter IoT systems},
  year={2025},
  volume={},
  number={},
  pages={},
  abstract={Master AI and IoT integration, from fundamentals to advanced techniques, and revolutionize your approach to building intelligent, data-driven solutions across industriesKey FeaturesLeverage the power of Python libraries such as TensorFlow and Keras to work with real-time IoT dataEnhance your IoT solutions with advanced AI techniques, including deep learning, optimization, and generative adversarial networksGain practical insights through industry-specific IoT case studies in manufacturing, smart cities, and automationPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionTransform IoT devices into intelligent systems with this comprehensive guide by Amita Kapoor, Chief AI Officer at Tipz AI. Drawing on 25 years of expertise in developing intelligent systems across industries, she demonstrates how to harness the combined power of artificial intelligence and IoT technology. A pioneer in making AI and neuroscience education accessible worldwide, Amita guides you through creating smart, efficient systems that leverage the latest advances in both fields. This new edition is updated with various optimization techniques in IoT used for enhancing efficiency and performance. It introduces you to cloud platforms such as Platform as a Service (PaaS) and Infrastructure as a Service (IaaS) for analyzing data generated using IoT devices. You’ll learn about machine learning algorithms, deep learning techniques, and practical applications in real-world IoT scenarios and advance to creating AI models that work with diverse data types, including time series, images, and audio. You’ll also harness the power of widely used Python libraries, TensorFlow and Keras, to build a variety of smart AI models. By the end of the book, you’ll emerge as a master of AI-driven IoT, armed with invaluable experience in optimizing IoT devices, boosting their performance, and integrating AI algorithms to make intelligent decisions.What you will learnIntegrate AI and IoT for enhanced device intelligenceUnderstand how to build scalable and efficient IoT systemsMaster both supervised and unsupervised machine learning techniques for processing IoT dataExplore the full potential of deep learning in IoT applicationsDiscover AI-driven strategies to optimize IoT system efficiencyImplement real-world IoT projects that leverage AI capabilitiesImprove device performance and decision-making using AI algorithmsWho this book is forThis book is for IoT developers, engineers, and tech enthusiasts, particularly those with a background in Python, looking to integrate artificial intelligence and machine learning into IoT systems. Python developers eager to apply their knowledge in new, innovative ways will find it useful. It’s also an invaluable guide for anyone with a foundational understanding of IoT concepts ready to take their skills to the next level and shape the future of intelligent devices.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835462966},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11006483},}@INPROCEEDINGS{10420306,
  author={Vayadande, Kuldeep and Bhemde, Suyash and Rajguru, Varun and Ugile, Pratik and Lade, Rahul and Raut, Nishith},
  booktitle={2023 International Conference on Recent Advances in Science and Engineering Technology (ICRASET)}, 
  title={AI-Based Image Generator Web Application using OpenAI’s DALL-E System}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={In this project we delve into the creation of a web application that generates images based on descriptions using OpenAI’s DALL E system. The backend of the application is built using Node.js utilizing the Express framework and OpenAI Node package to interact with the API. For the frontend we employ HTML, CSS and vanilla JavaScript. To get started we establish the Node.js project. Install dependencies such, as Express, OpenAI and dotenv for managing environment variables. Organizing our structure involves creating a routes folder with files defining routes related to OpenAI functionality. The server actively listens for requests while setting up a route to handle image generation via post requests. Additionally, we develop an OpenAI controller for processing logic associated with image generation. By employing a request function in this controller we send a request to the OpenAI API along with specified prompts. Upon receiving a response from the API we process it accordingly to extract the URL of generated images before sending it as a JSON response. On our frontend side an HTML file incorporates a user form enabling text input alongside options for selecting image sizes. CSS styles are applied to create an UI design featuring both a showcase area and section, for displaying images.},
  keywords={Uniform resource locators;Training;Image synthesis;Process control;Reflection;Servers;Artificial intelligence;OpenAI;DALL-E system;web app;Node.js;Express;AI;machine learning;natural language;image generation},
  doi={10.1109/ICRASET59632.2023.10420306},
  ISSN={},
  month={Nov},}@ARTICLE{10516609,
  author={Guan, Weinan and Wang, Wei and Dong, Jing and Peng, Bo},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Improving Generalization of Deepfake Detectors by Imposing Gradient Regularization}, 
  year={2024},
  volume={19},
  number={},
  pages={5345-5356},
  abstract={The rapid development of face forgery technology has posed a significant threat to information security. While deepfake detection has proven to be an effective countermeasure, it often struggles to detect fake images generated by unknown forgery methods. Thus, the generalization ability of deepfake detectors to unseen forgery data is a critical concern. Despite many efforts aimed at discovering new forgery artifacts, they often fail to generalize to new manipulation technologies. In this paper, we tackle this challenge by focusing on the difference in texture patterns between training forgeries and unseen forgeries, which can lead to a degradation of generalization. Based on this principle, we propose a new conjecture that encourages deepfake detectors to reduce their sensitivity to forgery texture patterns, thereby improving the detection performance. To this end, we introduce an additional gradient regularization term to the original empirical loss during training. However, computing the Hessian matrix in the gradient calculation process of the regularization term poses a computational complexity. In order to overcome this issue, we optimize the formulation of the gradient regularization term using a first-order approximation method based on Taylor expansion and design a Perturbation Injection Module (PIM) to simplify the implementation process. Additionally, we provide a theoretical analysis from an optimization perspective and explore an interesting aspect of our method. Extensive experiments demonstrate the effectiveness of our approach in improving the generalization ability of deepfake detectors. Importantly, our method is orthogonal to recent advancements in powerful backbones and training data augmentation techniques. When combined with other effective techniques, our method achieves state-of-the-art experimental results.},
  keywords={Deepfakes;Forgery;Faces;Detectors;Training;Feature extraction;Data models;Deepfake detection;forgery texture patterns},
  doi={10.1109/TIFS.2024.3396064},
  ISSN={1556-6021},
  month={},}@INPROCEEDINGS{10788633,
  author={Portilla Jaimes, Jorge Omar and Contreras, Mauricio Rojas and Suarez, Oscar J.},
  booktitle={2024 International Symposium on Accreditation of Engineering and Computing Education (ICACIT)}, 
  title={Intelligent Computational Architecture for Improving the Quality of Higher Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents an intelligent computational architecture designed to enhance the quality of higher education in an academic ecosystem. By integrating generative artificial intelligence (GenAI), complex systems, and blockchain technology, this architecture aims to invigorate formative research and optimize educational processes. The proposed architecture seeks to facilitate effective collaboration and enhance educational quality by modeling academic ecosystems as complex networks and using smart contracts for intellectual property management, coupled with the incorporation of participation incentives through blockchain-based social tokens. The resulting architecture employs autonomous agents to propose projects and automatically recruit participants by combining complex networks with GenAI, preserving intellectual property via blockchain and managing incentives with social tokens.},
  keywords={Generative AI;Education;Ecosystems;Smart contracts;Collaboration;Computer architecture;Intellectual property;Complex networks;Blockchains;Complex systems;Large language model;generative artificial intelligence;intelligent computational architecture;social token;academic ecosystem},
  doi={10.1109/ICACIT62963.2024.10788633},
  ISSN={2771-6058},
  month={Oct},}@INPROCEEDINGS{10975957,
  author={Han, Huirui and Zhan, Heqing and Liu, Wei},
  booktitle={2025 14th International Conference on Educational and Information Technology (ICEIT)}, 
  title={Research on AI-Driven Teaching of Medical Data Mining Courses Under the BOPPPS Model}, 
  year={2025},
  volume={},
  number={},
  pages={506-511},
  abstract={As interdisciplinary integration deepens, the demand for applying engineering principles to address biological and medical challenges is on the rise. While machine learning serves as a crucial tool for processing complex medical data, the effective application of its techniques remains a significant challenge. Therefore, the “Medical Data Mining” course is designed to cultivate students' theoretical and practical skills in biomedical engineering. Current pedagogical practices are hindered by excessive teacher dominance and insufficient student interaction. To address these issues, this study introduces generative artificial intelligence technologies and interactive teaching models, integrated with the BOPPPS instructional design framework. This approach is designed to stimulate deep thinking, enhance student engagement and knowledge retention, and foster the development of critical and creative thinking skills among learners.},
  keywords={Technological innovation;Generative AI;Biological system modeling;Education;Machine learning;Data models;Data mining;Information technology;Context modeling;Biomedical engineering;biomedical engineering;machine learning;medical data mining;generative artificial intelligence;BOPPPS model},
  doi={10.1109/ICEIT64364.2025.10975957},
  ISSN={},
  month={March},}@INPROCEEDINGS{9534192,
  author={Ranade, Priyanka and Piplai, Aritran and Mittal, Sudip and Joshi, Anupam and Finin, Tim},
  booktitle={2021 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Generating Fake Cyber Threat Intelligence Using Transformer-Based Models}, 
  year={2021},
  volume={},
  number={},
  pages={1-9},
  abstract={Cyber-defense systems are being developed to automatically ingest Cyber Threat Intelligence (CTI) that contains semi-structured data and/or text to populate knowledge graphs. A potential risk is that fake CTI can be generated and spread through Open-Source Intelligence (OSINT) communities or on the Web to effect a data poisoning attack on these systems. Adversaries can use fake CTI examples as training input to subvert cyber defense systems, forcing their models to learn incorrect inputs to serve the attackers' malicious needs. In this paper, we show how to automatically generate fake CTI text descriptions using transformers. Given an initial prompt sentence, a public language model like GPT-2 with fine-tuning can generate plausible CTI text that can mislead cyber-defense systems. We use the generated fake CTI text to perform a data poisoning attack on a Cybersecurity Knowledge Graph (CKG) and a cybersecurity corpus. The attack introduced adverse impacts such as returning incorrect reasoning outputs, representation poisoning, and corruption of other dependent AI-based cyber defense systems. We evaluate with traditional approaches and conduct a human evaluation study with cyber-security professionals and threat hunters. Based on the study, professional threat hunters were equally likely to consider our fake generated CTI and authentic CTI as true.},
  keywords={Training;Neural networks;Transformers;Cognition;Computer crime;Open source software;Cybersecurity;Cyber Threat Intelligence;Artificial Intelligence;Data Poisoning Attack},
  doi={10.1109/IJCNN52387.2021.9534192},
  ISSN={2161-4407},
  month={July},}@ARTICLE{11087555,
  author={Wu, Mingkang and Cao, Yongcan},
  journal={IEEE Control Systems Letters}, 
  title={Robust Human-Machine Teaming through Reinforcement Learning from Failure via Sparse Reward Densification}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Learning control policies in sparse reward environments is a challenging task for many robotic control tasks. The existing studies focus on designing reinforcement learning algorithms that take human inputs in the form of demonstrations such that control policies are learned via uncovering the value of these demonstrations. One typical approach is to learn an inherent reward function that can explain why demonstrations are better than other randomly generated samples. Albeit powerful, the use of human demonstrations is typically costly and difficult to collect, indicating the lack of robustness in these studies. To enhance robustness, we here propose to use failed experiences, namely, failure, due to the easiness of obtaining failure dataset, requiring only common sense rather than domain knowledge needed to generate expert demonstrations. In particular, this paper proposes a new reward densification technique that trains a discriminator to evaluate the similarity between the agent’s current behavior and failure dataset provided by humans. This reward densification technique provides an effective mechanism to obtain state-action values for environments with sparse rewards, via quantifying their (dis)similarity with failure. Additionally, the value of the current behavior, formulated as advantage function, is employed based on the densified reward to refine the control policy’s search direction. We finally conduct several experiments to demonstrate the effectiveness of the proposed approach by comparing with state-of-art methods.},
  keywords={Training;Reinforcement learning;Generators;Standards;Generative adversarial networks;Robots;Linear programming;Entropy;Trajectory;Robustness;Failed experience;reinforcement learning;reward densification;sparse reward environments},
  doi={10.1109/LCSYS.2025.3591199},
  ISSN={2475-1456},
  month={},}@INPROCEEDINGS{9924133,
  author={Yang, Chao and Wang, Ziqi and Mao, Shiwen},
  booktitle={2022 IEEE 12th International Conference on RFID Technology and Applications (RFID-TA)}, 
  title={RFPose-GAN: Data Augmentation for RFID based 3D Human Pose Tracking}, 
  year={2022},
  volume={},
  number={},
  pages={138-141},
  abstract={In the age of Artificial Intelligence of Things (AIoT), human pose tracking has attracted increasing interest in many fields. To address the limitations of conventional vision based pose tracking techniques, Radio Frequency (RF) based pose monitoring has been proposed in recent years. However, most of the existing RF-based approaches depend on a vision-aided multi-model learning model, which requires extensive labeled data for supervised training. Collecting such large amounts of training data is time-consuming and costly. In this paper, we address this issue by proposing a Generative Adversarial Network (GAN) based data augmentation method, termed RFPose-GAN, to generate synthesized datasets to assist the training of multi-model neural networks. Our experimental results demonstrate the efficacy of the proposed data augmentation approach on improving the performance of 3D human pose tracking when there is only a limited amount of training data.},
  keywords={Training;Radio frequency;Solid modeling;Three-dimensional displays;Training data;Generative adversarial networks;Data models;Radio-frequency identification (RFID);3D human pose tracking;Generative Adversarial Network (GAN);Data augmentation},
  doi={10.1109/RFID-TA54958.2022.9924133},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{7337968,
  author={Mugica, Francisco and Paz, Iván and Nebot, Àngela and Romero, Enrique},
  booktitle={2015 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)}, 
  title={A Fuzzy Inductive approach for rule-based modelling of high level structures in algorithmic composition systems}, 
  year={2015},
  volume={},
  number={},
  pages={1-8},
  abstract={Algorithmic composition systems are now widely understood. However, its capacity for producing outputs consistently showing high level structures is still a field of research. In the present work, the Fuzzy Inductive Reasoning (FIR) methodology and an extension of it, the Linguistic rules in FIR (LR-FIR) are the main tools chosen for modeling such features. FIR/LR-FIR operates over the produced outputs of an algorithmic composition system, and through qualitative user evaluation is able to extract rules using configurations of low level characteristics that models high level features. Subsequently, the rules are used for the exploration of all possible outputs of an algorithmic system finding a subset of outputs showing the desired property. Finally extracted rules are evaluated and discussed in the context of musical knowledge.},
  keywords={Finite impulse response filters;Feature extraction;Algorithm design and analysis;Signal processing algorithms;Compaction;Hidden Markov models;Artificial intelligence;algorithmic composition;fuzzy inductive reasoning methodology;rule extraction;high-level musical features},
  doi={10.1109/FUZZ-IEEE.2015.7337968},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10838072,
  author={L N, Priyanka Bharathi and K, Sri Sathvig and A, Siromita and Pugalenthi, R.},
  booktitle={2024 4th Asian Conference on Innovation in Technology (ASIANCON)}, 
  title={Text to Video Generation using Natural Language Processing and Machine Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Press Reports in general have been published in text based format for a vast period of time, although the old way of publishing reports may have been effective initially, it has led to a decrease in audience engagement and attention span. The study offers a novel solution to the problem of users’ attention spans getting shorter. Therefore, to retain user engagement and increase content quality, the proposed solution aims to create an automated system that uses press reports to generate dynamic video content. This technology improves user comprehension and engagement by utilizing audio-visual synthesis and natural language processing techniques. The models that are implemented have performed well during the Testing Phase by showing an average accuracy of 82 percentage from the NLP Large Language Models and 89 percentage from the Machine Learning Models and the outcomes reveal increased knowledge retention and user engagement. Finally, this study offers a novel method of communication by automatically converting press releases into videos for maximum viewer engagement.},
  keywords={Presses;Technological innovation;Accuracy;Text summarization;Machine learning;Transforms;Natural language processing;Text to video;Video recording;Testing;Text to Video generation;Natural Language Processing;Automation;Machine Learning},
  doi={10.1109/ASIANCON62057.2024.10838072},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10980577,
  author={Maruvada, Vineeth and Kaur, Karamjit and Selway, Matt and Stumptner, Markus},
  booktitle={2025 17th International Conference on Computer and Automation Engineering (ICCAE)}, 
  title={Evaluating Deep Learning Methods for Virtual Sensors in Water Infrastructure Digital Twins}, 
  year={2025},
  volume={},
  number={},
  pages={236-240},
  abstract={Water scarcity is an increasing global issue, with the demand for water potentially exceeding supply, and organizations failing to balance current and future needs. Continuous monitoring and accurate prediction of water availability, proactive leakage detection and optimising water consumption are crucial, necessitating advanced, cost-effective, and highly accurate methods for effective water management. The integration of the Internet of Things (IoT) with Artificial Intelligence (AI) in Industry 4.0 has significantly enhanced monitoring, automated industrial processes and enabled forecasting. High-quality data is essential to deliver precise insights and optimal performance. Virtual sensors, which digitally replicate failed IoT sensors, offer a smart solution for data generation, that impacts water infrastructure monitoring. This study employs deep learning models Generative Adversarial Networks (GAN), Long Short-Term Memory (LSTM), and Variational Autoencoders (VAE), to generate synthetic data for virtual sensors. The findings indicate that LSTM provide better outputs, paving the way for further development and implementation of virtual sensors in Water Infrastructure Digital Twins.},
  keywords={Deep learning;Industries;Accuracy;Soft sensors;Generative adversarial networks;Stability analysis;Digital twins;Internet of Things;Long short term memory;Synthetic data;Water Industry;Digital Twins;Internet of Things;Deep Learning;Generative Adversarial Networks;Variational Autoencoders;Long Short-Term Memory;Virtual Sensors;Synthetic Data},
  doi={10.1109/ICCAE64891.2025.10980577},
  ISSN={2154-4360},
  month={March},}@ARTICLE{9966484,
  author={Li, Xuelong and Li, Chen and Kou, Kai and Zhao, Bin},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Weather Translation via Weather-Cue Transferring}, 
  year={2024},
  volume={35},
  number={6},
  pages={7988-7998},
  abstract={In this article, the weather translation task is proposed, which aims to transfer the weather type of the image from one category to another. Weather translation is a complicated image weather editing task that changes the weather cue of an image across multiple weather types, and it is related to image restoration, image editing, and photographic style transfer tasks. Although lots of approaches have been developed for traditional image translation and restoration tasks, only few of them are capable of handling the multicategory weather types problem with a single network due to the rich categories and highly complicated semantic structures of weather images. Especially, it is difficult to change the weather cue while preserving the weather-invariant area. To solve these issues, we developed a weather-cue guided multidomain translation approach based on StarGAN v2, termed WeatherGAN. In the proposed model, the core generator is redesigned to transfer the weather cue according to the target weather type. The weather segmentation module is first introduced to acquire the weather semantic structure of images in a weakly supervised multitask manner. In addition, a weather clues module is presented to reprocess the weather segmentation into a weather-specific clues map, which identifies the weather-invariant and weather-cue areas clearly. Extensive studies and evaluations show that our approach outperforms the state of the art. The data and source code will be publicly available soon after the manuscript is accepted.},
  keywords={Meteorology;Task analysis;Generators;Image restoration;Semantics;Rain;Generative adversarial networks;Generative adversarial networks (GANs);weather translation;weather-cue segmentation;weather-specific clues map},
  doi={10.1109/TNNLS.2022.3223081},
  ISSN={2162-2388},
  month={June},}@ARTICLE{10542343,
  author={Savazzi, Stefano and Fieramosca, Federica and Kianoush, Sanaz and D’Amico, Michele and Rampa, Vittorio},
  journal={IEEE Open Journal of Antennas and Propagation}, 
  title={Electromagnetic-Informed Generative Models for Passive RF Sensing and Perception of Body Motions}, 
  year={2024},
  volume={5},
  number={4},
  pages={958-973},
  abstract={Electromagnetic (EM) body models predict the impact of human presence and motions on the Radio-Frequency (RF) field originated from wireless devices nearby. Despite their accuracy, EM models are time-consuming methods which prevent their adoption in strict real-time computational imaging and estimation problems, such as passive localization, RF tomography, and holography. Physicsinformed Generative Neural Network (GNN) models have recently attracted a lot of attention thanks to their potential to reproduce a process by incorporating relevant physical laws and constraints. They can be used to simulate or reconstruct missing data or samples, reproduce EM propagation effects, approximated EM fields, and learn a physics-informed data distribution, i.e., the Bayesian prior. Generative machine learning represents a multidisciplinary research area weaving together physical/EM modelling, signal processing, and Artificial Intelligence (AI). The paper discusses two popular techniques, namely Variational Auto-Encoders (VAEs) and Generative Adversarial Networks (GANs), and their adaptations to incorporate relevant EM body diffraction methods. The proposed EM-informed GNN models are verified against classical EM tools driven by diffraction theory, and validated on real data. The paper explores emerging opportunities of GNN tools targeting real-time passive RF sensing in communication systems with dense antenna arrays. Proposed tools are also designed, implemented, and verified on resource constrained wireless devices. Simulated and experimental analysis reveal that GNNs can limit the use of time-consuming and privacy-sensitive training stages as well as intensive EM computations. On the other hand, they require hyper-parameter tuning to achieve a good compromise between accuracy and generalization.},
  keywords={Sensors;Radio frequency;Computational modeling;Diffraction;Bayes methods;Numerical models;Wireless communication;EM body models;generative models;variational autoencoders;generative adversarial networks;radio tomography;integrated sensing and communication;localization},
  doi={10.1109/OJAP.2024.3407199},
  ISSN={2637-6431},
  month={Aug},}@INPROCEEDINGS{10450978,
  author={Gao, Xuange and Wang, Xinyuan and Wang, Danli and Liu, Weiran},
  booktitle={2023 China Automation Congress (CAC)}, 
  title={Action Unit Based Smiling Face Generation Method}, 
  year={2023},
  volume={},
  number={},
  pages={4697-4702},
  abstract={The widespread usage of facial expression processing in digital entertainment and data augmentation has drawn rising attention. However, the existing works on facial expression generation still fall short in reality and continuity, especially on smiling faces, which is not natural enough. In this paper, we propose a smiling face generation method based on Action Unit (AU) to address the aforementioned problems. Our method mainly adjusts the magnitude of target AU according to the features of smiling faces and the person itself to achieve better generation effect. We propose two ways to adjust AU, called average AU and relative AU respectively. Average AU reflects the AU configuration with universal smiling face expression and relative AU combines the AUs represent smiling expression with other AU of source image. We collect smiling face images to accumulate new datasets where we find the intrinsic pattern of AU. We leverage average AU and relative AU to optimize the process of smiling faces generation and the experiment results indicate that our method can achieve better facial expression manipulation compared with the baseline models. In addition, we conduct user evaluation experiment from which we get following results: 1) the results of L2 distance and Fréchet Inception Distance (FID) indicate that degree of the facial expression realization of the images generated by our method is improved greatly; 2) the results of the questionnaire indicate that the images generated by our method win more human visual preferences and are of higher quality.},
  keywords={Gold;Visualization;Automation;Process control;Entertainment industry;Generative adversarial networks;Data augmentation;Action Unit (AU);Facial Expression Manipulation;Generative Adversarial Networks (GAN)},
  doi={10.1109/CAC59555.2023.10450978},
  ISSN={2688-0938},
  month={Nov},}@INBOOK{10952572,
  author={Khan, Ian},
  booktitle={The Quick Guide to Prompt Engineering: Generative AI Tips and Tricks for ChatGPT, Bard, Dall-E, and Midjourney}, 
  title={Video Synthesis with VQ&#x2010;VAE}, 
  year={2024},
  volume={},
  number={},
  pages={429-443},
  abstract={Summary <p>Vector quantized variational autoencoder (VQ&#x2010;VAE) represents a nexus point in deep learning's journey, elegantly merging the worlds of autoencoders and vector quantization to pioneer a unique direction for generative modeling. By synergizing the foundational principles of autoencoders and vector quantization, VQ&#x2010;VAE offers a refreshing perspective on data representation and synthesis. This chapter delves into how prompts play an essential role in shaping the outcome and nuances of video synthesis using VQ&#x2010;VAE. It explores some real&#x2010;world use cases and examples where VQ&#x2010;VAE is making a mark. VQ&#x2010;VAE represent a leap forward in the domain of video synthesis, offering the capability to generate high&#x2010;quality videos through deep learning mechanisms. However, like all technologies, VQ&#x2010;VAE has its limitations and areas that beckon further refinement.</p>},
  keywords={Vectors;Autoencoders;Vector quantization;Training;Solid modeling;Prompt engineering;Dynamics;Visualization;Training data;Merging},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394243341},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952572},}@ARTICLE{10815068,
  author={Lin, Haitao and Tan, Cheng and Wu, Lirong and Liu, Zicheng and Gao, Zhangyang and Li, Stan Z.},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={An Extensive Survey With Empirical Studies on Deep Temporal Point Process}, 
  year={2025},
  volume={37},
  number={4},
  pages={1599-1619},
  abstract={Temporal point process as the stochastic process on a continuous domain of time is commonly used to model the asynchronous event sequence featuring occurrence timestamps. Thanks to the strong expressivity of deep neural networks, they are emerging as a promising choice for capturing the patterns in asynchronous sequences, in the context of temporal point process. In this paper, we first review recent research emphasis and difficulties in modeling asynchronous event sequences with deep temporal point process, which can be concluded into four fields: encoding of history sequence, formulation of conditional intensity function, relational discovery of events, and learning approaches for optimization. We introduce most of the recently proposed models by dismantling them into four parts and conduct experiments by re-modularizing the first three parts with the same learning strategy for a fair empirical evaluation. Besides, we extend the history encoders and conditional intensity function family and propose a Granger causality discovery framework for exploiting the relations among multi-types of events. Because the Granger causality can be represented by the Granger causality graph, discrete graph structure learning in the framework of Variational Inference is employed to reveal latent structures of the graph. Further experiments show that the proposed framework with latent graph discovery can both capture the relations and achieve an improved fitting and predicting performance.},
  keywords={Cause effect analysis;History;Reviews;Mathematical models;Fitting;Stochastic processes;Statistical learning;Optimization;Time series analysis;Artificial neural networks;Deep learning;granger causality;graph structure learning;temporal point process},
  doi={10.1109/TKDE.2024.3522114},
  ISSN={1558-2191},
  month={April},}@INBOOK{10952754,
  author={Ma, Andeed and Ong, James and Tan, Siok Siok},
  booktitle={AI for Humanity: Building a Sustainable AI for the Future}, 
  title={The AI Trap}, 
  year={2024},
  volume={},
  number={},
  pages={27-51},
  abstract={Summary <p>Using AI, anyone can now create deep fakes, cheap and fast. Deep fakes use machine learning algorithms to replicate a person's appearance and movements by analyzing image and video datasets. The AI trap springs from our ignorance of how AI reflects and refracts human nature. AI mirrors us because we are the ones who design, deploy, and improve the algorithms that power AI. The world of AI is like an infinity mirror, constantly reflecting and refracting the inputs it receives, both good and bad. We train AI algorithms on vast amounts of data, and if that data contains biases, then AI will learn and perpetuate them. AI's infinity mirror effects show how social media algorithms reflect, refract, and amplify conspiracy theories. The AI trap, a labyrinth of ethical and strategic decisions, challenges companies to navigate a landscape where profit motives often collide with the quest for responsible impact.</p>},
  keywords={Artificial intelligence;Deepfakes;Social networking (online);Faces;Weapons of mass destruction;Mirrors;Machine intelligence;Games;Drugs;Virtual assistants},
  doi={10.1002/9781394310524.ch2},
  ISSN={},
  publisher={Wiley},
  isbn={9781394180318},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952754},}@ARTICLE{10896942,
  author={Li, Ao and Wu, Minchao and Ouyang, Rui and Wang, Yongming and Li, Fan and Lv, Zhao},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={A Multimodal-Driven Fusion Data Augmentation Framework for Emotion Recognition}, 
  year={2025},
  volume={6},
  number={8},
  pages={2083-2097},
  abstract={The pursuit of imbuing computers with emotional intelligence has driven extensive research into physiological signal analysis for emotion recognition. Deep learning techniques offer promising avenues for analyzing physiological signals in this domain. Despite numerous studies on emotion recognition using various physiological signals, challenges persist in classifying multimodal physiological signals due to data scarcity. Current research lacks focus on addressing data insufficiency for multimodal physiological signals. This article proposes an innovative method to address this issue and improve the effect of emotion recognition using multimodal physiological signal data. Our model comprises a physiological signal encoder, a multimodal data generator, and a multimodal emotion recognizer. Specifically, we introduce a customized ConvNeXt-attention fusion model (CNXAF) to fuse diverse physiological signals, generating fused multimodal data. The multimodal data generator employs a conditional self-attention generative adversarial network (c-SAGAN) to synthesize additional data across different categories, augmenting original datasets. Finally, the multimodal emotion recognizer utilizes the ConvNeXt-t classifier for emotion recognition on the extended dataset. Through extensive experimentation, our model achieves accuracies of 96.06$\%$ on the DEAP dataset and 95.70$\%$ on the WESAD dataset, demonstrating the effectiveness of our approach in accurately recognizing emotions. Experimental results underscore the superior performance of our method compared to existing approaches in multimodal emotion recognition research.},
  keywords={Emotion recognition;Physiology;Brain modeling;Data models;Electroencephalography;Artificial intelligence;Generators;Data augmentation;Training;Accuracy;Data augmentation;data fusion;deep learning;multimodal emotion recognition;physiological signals},
  doi={10.1109/TAI.2025.3537965},
  ISSN={2691-4581},
  month={Aug},}@ARTICLE{11124461,
  author={Li, Yixuan and Liu, Xuelin and Wang, Xiaoyang and Lee, Bu Sung and Wang, Shiqi and Rocha, Anderson and Lin, Weisi},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={FakeBench: Probing Explainable Fake Image Detection via Large Multimodal Models}, 
  year={2025},
  volume={20},
  number={},
  pages={8730-8745},
  abstract={The ability to distinguish whether an image is generated by artificial intelligence (AI) is a crucial ingredient in human intelligence, usually accompanied by a complex and dialectical forensic and reasoning process. However, current fake image detection models and databases focus on binary classification without understandable explanations for the general populace. This weakens the credibility of authenticity judgment and may conceal potential model biases. Meanwhile, large multimodal models (LMMs) have exhibited immense vision-language capabilities on various tasks, bringing the potential for explainable fake image detection. Therefore, we pioneer the probe of LMMs for explainable fake image detection by presenting a multimodal database encompassing descriptions of textual authenticity, the FakeBench. For construction, we first introduce a fine-grained taxonomy of generative visual forgery concerning human perception, based on which we collect forgery descriptions in human natural language with a human-in-the-loop strategy. FakeBench examines LMMs with four evaluation criteria: detection, reasoning, explanation and fine-grained forgery analysis, to obtain deeper insights into image authenticity-relevant capabilities. Experiments on various LMMs confirm their merits and demerits in different aspects of fake image detection tasks. This research presents a paradigm shift towards transparency for the fake image detection area and reveals the need for greater emphasis on forensic elements in visual-language research and AI risk control. FakeBench will be available at https://github.com/Yixuan423/FakeBench},
  keywords={Forgery;Artificial intelligence;Cognition;Visualization;Natural languages;Hair;Skin;Generators;Faces;Urban areas;Large multimodal models;fake image detection;explainability;benchmark;image forensics},
  doi={10.1109/TIFS.2025.3597211},
  ISSN={1556-6021},
  month={},}@INPROCEEDINGS{11158477,
  author={Rajakakarlapudi, Rajeev Varma},
  booktitle={2025 International Conference on Advancements in Smart, Secure and Intelligent Computing (ASSIC)}, 
  title={AI-Based Dynamic Spectrum Allocation for Hybrid Satellite-5G Networks}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Given the imminent introduction of Reduced Capability (RedCap) devices in 5G networks, the computational and communications limitations of these devices note new challenges for network slicing.Adaptive network slicing is required to optimize resource allocation and to maintain quality of service (QoS) across the wide variety of scenarios encountered in RedCap use cases.Finally Generative Artificial Intelligence (GenAI) represents a promising way forward: we use it to predict network conditions, effect automatic slice reconfiguration, and govern flexible resource distribution.In this paper, we look into the handicap of genai models such as generative opposition networks (GANS) and variationally auto-encoders (VAEs) assisted network slicing for RedCap enabled 5G networks.Synthetic network traffic patterns can be created by GenAI, allowing it to forecast congestion and adjust slice parameters ahead of time on the basis of what it has learned.A reinforcement learning-driven network model lends itself to real-time decision-making, which will improve spectral efficiency, lowers delays, and will result in optimized power consumption.This paper presents a framework that applies GenAI to handle slice elasticity. If network conditions were changing, be in the future or in the middle of a task, this would ensure the operation of services with minimal interruption. The method was evaluated by simulation and found to be successful in dynamically balancing traffic loads and maintaining QoS levels in RedCap scenarios. Our work demonstrates that adaptive slicing driven by GenAI greatly enhances network efficiency, making 5G RedCap deployments more robust and scalable. Once the satellite communication system becomes integrated with 5G networks,postcodes will offer chances for high speed Internet access to those remote and longneglected areas. However, satisfactory spectrum management remains the principal difficulty here in the hybrid satellite-5G environment, on account of the wide and ever-changing radio frequency spectrum. This paper introduces an AI-based Dynamic Spectrum Allocation (DSA) system aimed at optimizing spectrum usage in hybrid satellite-5G networks. It applies machine learning algorithms, especially reinforcement learning (RL), to forecast and dynamically allocate radio resources based on actual demand, interference levels, and network conditions. In this integrated network management system, AI keeps monitoring the use of spectrum both in satellite 5Geap and terrestrially based networks, making adjustments in response to changes in subscriber traffic and ambient environmental conditions. The RL model learns how to make intelligent decisions on spectrum sharing which strike a balance between high-throughput communication quality and the avoidance of interference. This paper also looks at how deep learning techniques can be used to forecast user demand for spectrum and change over points between satellite and 5G base stations. The AI-based DSA method proposed in this paper not only enhances spectrum utilization but it also reduces latency, minimizes interference and raises the overall service level in hybrid networks. Experimental results show the potential strength of the AI-based framework compared with traditional static allocation methods which outperform gives significant improvements in throughput, user experience and network efficiency.},
  keywords={Satellites;5G mobile communication;Heuristic algorithms;Satellite broadcasting;Interference;Quality of service;Predictive models;Dynamic scheduling;Throughput;Resource management;AI-driven Spectrum Management;Dynamic Spectrum Allocation;Hybrid Satellite-5G Networks;Machine Learning for Spectrum Optimization and 5G-Satellite Integration},
  doi={10.1109/ASSIC64892.2025.11158477},
  ISSN={},
  month={May},}@INPROCEEDINGS{9368650,
  author={Cheng, Xiaohui and Zhao, Jun and Kang, Yanping},
  booktitle={2020 IEEE 2nd International Conference on Civil Aviation Safety and Information Technology (ICCASIT}, 
  title={Information Hiding Mechanism Based on Generative Adversarial Networks}, 
  year={2020},
  volume={},
  number={},
  pages={625-629},
  abstract={With the rapid development of artificial intelligence and the Internet of Things technology, the demand for concealment of data and information is increasingly strong, and information hiding technology plays a key role in information security. At present, there are some problems in the generative steganography mechanism based on deep learning, such as low quality of generative steganography and weak anti-steganographic analysis ability. In view of the above problem, this paper proposes a Realness-DCGAN based information hiding mechanism, this mechanism will secret information mapping division and the noise vector generator, according to the noise generated vector containing the secret image by using fidelity distribution as a standard of judging output, constraint generator to generate a higher quality of the secret image, finally using an extractor to extract the secret information. Experiments show that compared with the traditional steganography mechanism based on deep learning, the information hiding mechanism proposed in this paper by embedding RealnessGAN into the traditional DCGAN can significantly improve the quality of generated images containing secrets, and improve the accuracy and security of information extraction.},
  keywords={Deep learning;Resists;Generators;Safety;Data mining;Cryptography;Standards;information hiding;generate adversarial networks;generative steganography;information security},
  doi={10.1109/ICCASIT50869.2020.9368650},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10531512,
  author={Ramadoss, Poonkuzhali and P, Suvinkumar and S, Vignesh and K, Yeswanth},
  booktitle={2024 2nd International Conference on Artificial Intelligence and Machine Learning Applications Theme: Healthcare and Internet of Things (AIMLA)}, 
  title={Utilizing Natural Language Representation For Health Condition Identification Using Clinical Notes}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In the landscape of modern medicine, the convergence of advanced clinical data management systems and artificial intelligence techniques has opened the doors to personalized healthcare. This paradigm shift has found particularly fertile ground in the highly digitized and data-rich environments of intensive care units (ICUs), offering a unique opportunity for pioneering research. In alignment with this trend, a retrospective clinical investigation utilizing a prospective ICU database has been conducted to explore the early detection of heart failure in critically ill children through the utilization of clinical natural language processing. Our methodology centered around empirical experimentation with a algorithm tailored to decipher the nuanced interpretation and presentation of clinical notes data. These notes, comprising discrete lines of text, formed the basis of our analysis. A standardized approach was employed, wherein two independent physicians classified cases into positive and negative categories based on predefined criteria. The findings of our study underscored the superiority of the multilayer perceptron neural network over alternative classifiers, encompassing both discriminative and generative models. Consequently, our proposed framework exhibited remarkable overall classification performance, achieving commendable accuracy, recall, and precision rates. In summary, this study represents a significant advancement in the application of learning representation and machine learning algorithms for the identification of heart failure cases using clinical natural language within a healthcare institution. Looking ahead, future research endeavors should aim to extend this methodology to encompass diverse linguistic contexts and healthcare settings, thereby broadening its applicability and impact.},
  keywords={Acute respiratory distress syndrome;Pediatrics;Machine learning algorithms;Neural networks;Medical services;Machine learning;Natural language processing;Personalized medicine;Clinical data management systems;Artificial intelligence;Intensive care units (ICUs);Clinical natural language processing},
  doi={10.1109/AIMLA59606.2024.10531512},
  ISSN={},
  month={March},}@ARTICLE{8288664,
  author={Li, Yanchun and Xiao, Nanfeng and Ouyang, Wanli},
  journal={IEEE Access}, 
  title={Improved Boundary Equilibrium Generative Adversarial Networks}, 
  year={2018},
  volume={6},
  number={},
  pages={11342-11348},
  abstract={Boundary equilibrium generative adversarial networks (BEGANs) can generate impressively realistic face images, but there is a trade-off between the quality and the diversity of generated images. Based on BEGANs, we propose an effective approach to generate images with higher quality and better diversity. By adding a second loss function (a denoising loss) to the discriminator, the discriminator can learn more useful information about the distribution of real images. Naturally, the ability of discriminator in distinguishing between real and generated images is improved, which further guides the generator to produce more realistic images to confuse the discriminator. We also find that using technique of batch normalization in BEGANs architecture can improve the diversity of generated images. By using batch normalization and adding a denoising loss to the objective of discriminator, we achieve comparative generations on CIFAR-10 and CelebA data sets. In addition, we evaluate the effect of several techniques on BEGANs framework through "Inception-Score", a measure which has been found to correlate well with human assessment of generated samples.},
  keywords={Noise reduction;Gallium nitride;Training;Generators;Face;Linear programming;Image generation;Generative adversarial networks (GANs);boundary equilibrium generative adversarial networks (BEGANs);deep generative model;image generation},
  doi={10.1109/ACCESS.2018.2804278},
  ISSN={2169-3536},
  month={},}@ARTICLE{9416434,
  author={Chong, Chee Keong and Ho, Eric Tatt Wei},
  journal={IEEE Access}, 
  title={Synthesis of 3D MRI Brain Images With Shape and Texture Generative Adversarial Deep Neural Networks}, 
  year={2021},
  volume={9},
  number={},
  pages={64747-64760},
  abstract={Generative Adversarial Networks (GAN) are emerging as an exciting training paradigm which promises a step improvement to the impressive feature learning capabilities of deep neural networks. Unlike supervised learning approaches, GAN learns generalizable features without requiring labeled images to achieve new capabilities like distinguishing previously unseen anomalies, creating novel instances of data and factorizing learned features into explainable dimensions in fully unsupervised fashion. The advanced feature learning property of GAN will enable the next generation of computational image understanding tasks. However, GAN models are difficult to train to converge towards good models, especially for high resolution and high dimensional datasets like image volumes. We develop a GAN approach to learn a generative model of T1-contrast 3D MRI image volumes of the healthy human brain by training on 1112 MRI images from the Human Connectome Project. Our method utilizes a first unconditional Super-Resolution GAN, dubbed the shape network, to learn the 3D shape variations in adult brains and a second conditional pix2pix GAN, dubbed the texture network, to upgrade image slices with realistic local contrast patterns. Novel 3D MRI images are synthesized by first applying the 3D voxel-wise deformation map which is generated from the shape network to deform the Montreal Neurological Institute (MNI) brain template and subsequently performing style transfer on axial-wise slices using the texture network. The Maximum Mean Discrepancy (MMD) and Multi-scale Structural Similarity Index Measure (MS-SSIM) scores of MRI image volumes synthesized using our GAN approach are competitive with state-of-art GAN methods. Our work establishes the feasibility of an alternative approach to high-dimensional GAN learning - splitting the type of information content learned among several GANs can be an effective form of regularization and complementary to latent code shaping or super-resolution approaches in state-of-the-art methods.},
  keywords={Generative adversarial networks;Brain modeling;Magnetic resonance imaging;Training;Three-dimensional displays;Biological neural networks;Task analysis;Generative adversarial networks;MRI brain images;brain morphometry;deep neural networks;computational brain anatomy},
  doi={10.1109/ACCESS.2021.3075608},
  ISSN={2169-3536},
  month={},}@ARTICLE{9376855,
  author={Kim, Dahye and Hong, Byung-Woo},
  journal={IEEE Access}, 
  title={Unsupervised Feature Elimination via Generative Adversarial Networks: Application to Hair Removal in Melanoma Classification}, 
  year={2021},
  volume={9},
  number={},
  pages={42610-42620},
  abstract={Eliminating the undesirable features is crucial to computer vision applications since undesirable features degrade the visibility of images. For that purpose, denoising, dehazing and deraining have been actively studied in both traditional model-based approaches and modern deep learning methods. However, elimination of hair in dermoscopic images has not received sufficient attention despite its significance and potential. Meanwhile, hair removal algorithms remain within the classical morphological methodologies, while only a few attempts apply the latest data-driven techniques. Hair is desired to be removed in dermoscopy applications because it causes undesired effects such as occlusions in lesion areas. However, removing hair is challenging because of its inherent complex structure and variations. In this paper, we propose a new unsupervised algorithm for hair removal and evaluate it on a real-world melanoma dataset. The proposed method eliminates hair from dermoscopic images by inducing a reconstructed distribution of images with hair to resemble a hairless distribution using generative adversarial learning. In the generative adversarial learning framework, hair features are characterized with a coarse-grained label simply via a binary classifier. At the same time, the important features of the lesions are preserved by minimizing L1-norm reconstruction loss based on Laplace noise assumption. The qualitative evaluation of the hair-removed results show that the proposed algorithm is robust to hair variations, and the quantitative results demonstrate that applying our hair removal algorithm considerably improves the performance of melanoma classification, outperforming the benchmarks.},
  keywords={Hair;Image reconstruction;Generative adversarial networks;Gallium nitride;Melanoma;Lesions;Deep learning;Deep learning application;dermoscopy;generative adversarial networks;hair removal;medical imaging;skin lesion classification;unsupervised learning},
  doi={10.1109/ACCESS.2021.3065701},
  ISSN={2169-3536},
  month={},}@ARTICLE{8861335,
  author={Lin, Song and He, Zhiyong and Sun, Lining},
  journal={IEEE Access}, 
  title={Defect Enhancement Generative Adversarial Network for Enlarging Data Set of Microcrack Defect}, 
  year={2019},
  volume={7},
  number={},
  pages={148413-148423},
  abstract={This paper presents a micro defect data set expansion method focuses on the microcrack defect of magnetic ring. Deep neural networks require a mass of training samples to be fully optimized. However, it is difficult to obtain a mass of defective samples in industrial field. In the case of insufficient samples, using GANs (Generative Adversarial Networks) for data expansion can effectively solve the problems of model over-fitting and low detection accuracy caused by insufficient training samples. However, it is difficult for conventional GANs to generate microcrack defective samples of high quality. This paper presents Defect Enhancement Generative Adversarial Network (DEGAN). This model can generate microcrack defects with obvious defect characteristics and high diversity. The experimental results show that the defective samples generated by DEGAN are very close to the real ones. The data set amplified by this model can significantly optimize deep neural network and achieve higher defect detection accuracy.},
  keywords={Generative adversarial networks;Generators;Training;Feature extraction;Neural networks;Data models;Image reconstruction;Convolutional neural network (CNN);generative adversarial networks(GANs);intelligent manufacturing;defect detection;deeplearning},
  doi={10.1109/ACCESS.2019.2946062},
  ISSN={2169-3536},
  month={},}@ARTICLE{9097443,
  author={Xiao, Jian and Bi, Xiaojun},
  journal={IEEE Access}, 
  title={Multi-Scale Attention Generative Adversarial Networks for Video Frame Interpolation}, 
  year={2020},
  volume={8},
  number={},
  pages={94842-94851},
  abstract={Video frame interpolation is a fundamental task in computer vision. Recent methods usually apply convolutional neural networks to generate intermediate frame with two consecutive frames as inputs. But sometimes existing methods fail to handle with complex motion and long-range dependencies. In this paper, a multi-scale dense attention generative adversarial network is proposed. First, a multi-scale generative adversarial framework is established for video frame interpolation. Generators from coarse to fine can better combine global and local information. Second, an attention module introduced to generator makes network accurately focus on moving objects. Third, a sequence discriminator is designed to improve the ability of capturing spatial and temporal consistency in frame sequence. Experimental results of ablation study prove the effectiveness of our three contributions. And results on several datasets demonstrate that our approach attains higher performance and produce more photo-realistic in-between frame comparing with previous works.},
  keywords={Interpolation;Generators;Optical flow;Generative adversarial networks;Kernel;Convolution;Estimation;Video frame interpolation;generative adversarial networks;multi-scale pyramid;spatial and temporal consistency;sequence discriminator},
  doi={10.1109/ACCESS.2020.2995705},
  ISSN={2169-3536},
  month={},}@ARTICLE{10061161,
  author={Kausar, Tasleem and Lu, Yun and Kausar, Adeeba and Ali, Mustajab and Yousaf, Adnan},
  journal={IEEE Access}, 
  title={SD-GAN: A Style Distribution Transfer Generative Adversarial Network for Covid-19 Detection Through X-Ray Images}, 
  year={2023},
  volume={11},
  number={},
  pages={24545-24560},
  abstract={The Covid-19 pandemic is a prevalent health concern around the world in recent times. Therefore, it is essential to screen the infected patients at the primary stage to prevent secondary infections from person to person. The reverse transcription polymerase chain reaction (RT-PCR) test is commonly performed for Covid-19 diagnosis, while it requires significant effort from health professionals. Automated Covid-19 diagnosis using chest X-ray images is one of the promising directions to screen infected patients quickly and effectively. Automatic diagnostic approaches are used with the assumption that data originating from different sources have the same feature distributions. However, the X-ray images generated in different laboratories using different devices experience style variations e.g., intensity and contrast which contradict the above assumption. The prediction performance of deep models trained on such heterogeneous images of different distributions with different noises is affected. To address this issue, we have designed an automatic end-to-end adaptive normalization-based model called style distribution transfer generative adversarial network (SD-GAN). The designed model is equipped with the generative adversarial network (GAN) and task-specific classifier to transform the style distribution of images between different datasets belonging to different race people and carried out Covid-19 detection effectively. Evaluated results on four different X-ray datasets show the superiority of the proposed model to state-of-the-art methods in terms of the visual quality of style transferred images and the accuracy of Covid-19 infected patient detection. SD-GAN is publicly available at: https://github.com/tasleem-hello/SD-GAN/tree/SD-GAN.},
  keywords={COVID-19;X-ray imaging;Biomedical imaging;Task analysis;Generative adversarial networks;Adaptation models;Chest X-ray;covid-19;style transfer;generative adversarial learning},
  doi={10.1109/ACCESS.2023.3253282},
  ISSN={2169-3536},
  month={},}@ARTICLE{8918322,
  author={Zhao, Bingxin and Li, Weihong and Gong, Weiguo},
  journal={IEEE Access}, 
  title={Deep Pyramid Generative Adversarial Network With Local and Nonlocal Similarity Features for Natural Motion Image Deblurring}, 
  year={2019},
  volume={7},
  number={},
  pages={185893-185907},
  abstract={It is of great importance to capture long-range dependency in image deblurring based on deep learning. Existing methods often capture long-range dependency by a large receptive field, which contributes by deep stacks of local convolutional operations. Therefore, it restricts network representation ability and causes unpleasant artifacts of restored images. In this paper, we propose a deep pyramid generative adversarial network with local and nonlocal similarity features, called LNL-PGAN, for natural motion image deblurring. First, we propose a nonlocal feature block as an essential component of the pyramid generator for obtaining nonlocal similarity features at multiple levels. Second, we design a local feature block as another essential component to make a great balance between local and nonlocal similarity features. The local and nonlocal feature blocks capture meaningful short-range and long-range dependencies in the pyramid generator to increase network representation ability. Third, we design a multiscale generative adversarial loss to preserve edge details and facilitate sharp edge prediction of restored images, and we introduce a multistage training strategy to facilitate network training, which can further improve the quality of the restored image. Extensive experimental results demonstrate that the proposed method yields superior performance against state-of-the-art methods on natural motion image deblurring in terms of visual quality and objective index, and it can be used as a unified network for single and dynamic motion image deblurring.},
  keywords={Image restoration;Kernel;Generative adversarial networks;Estimation;Generators;Training;Decoding;Motion deblurring;long-range dependency;nonlocal similarity feature;generative adversarial network},
  doi={10.1109/ACCESS.2019.2956947},
  ISSN={2169-3536},
  month={},}@ARTICLE{9906977,
  author={Sun, Kelei and Wen, Qiufen and Zhou, Huaping},
  journal={IEEE Access}, 
  title={Ganster R-CNN: Occluded Object Detection Network Based on Generative Adversarial Nets and Faster R-CNN}, 
  year={2022},
  volume={10},
  number={},
  pages={105022-105030},
  abstract={Object detection has shown noticeably rapid improvement, despite most existing methods still scrabbling in occluded object detection. In response to this problem, this paper proposes a method for occluded object detection called Ganster R-CNN, which is on a basis of improved Generative Adversarial Nets (IGAN) and Faster R-CNN to enhance the detection ability of occluded objects. IGAN combines the generator of Generative Adversarial Nets and the detector of Faster R-CNN. By considering the lack of diversity of information in the feature maps, we first integrated feature maps from the shallow layer to the deep layer using Feature Pyramid Network. Next, the generator can generate occluded fake samples, and the scale of the training samples and the proportion of occluded objects in the dataset are expanded. Thus, the precision rate of occluded objects can be improved. Thus, the adversarial learning strategy can improve the detection ability of Faster R-CNN detector. Experiments show that compared with Faster R-CNN, this method achieves an improvement of +10.3 AP on the MS COCO dataset, and the mean average precision of this method is improved by 4.31% on the VOC2007 dataset and 3.92% on the VOC2012 dataset. Compared with classically existing models on PASCAL VOC datasets and some Transformer based models on MS COCO dataset, this method improves the average precision value and the mean average precision value of occluded objects.},
  keywords={Feature extraction;Generators;Detectors;Semantics;Object detection;Convolutional neural networks;Adversarial machine learning;Generative adversarial networks;Learning systems;Adversarial learning strategy;feature maps;feature pyramid network;generative adversarial nets},
  doi={10.1109/ACCESS.2022.3211394},
  ISSN={2169-3536},
  month={},}@ARTICLE{10572264,
  author={Meftah, Leila Haj and Cherif, Asma and Braham, Rafik},
  journal={IEEE Access}, 
  title={Improving Autonomous Vehicles Maneuverability and Collision Avoidance in Adverse Weather Conditions Using Generative Adversarial Networks}, 
  year={2024},
  volume={12},
  number={},
  pages={89679-89690},
  abstract={In recent years, there has been a significant increase in the development of autonomous vehicles. One critical task for ensuring their safety and dependability, is obstacle avoidance in challenging weather conditions. However, no studies have explored the use of data augmentation to generate training data for Deep learning (DL) models aimed at navigating obstacles in extreme weather conditions. This study makes a substantial contribution to the field of autonomous vehicle obstacle avoidance by introducing an innovative approach that utilizes a Generative Adversarial Network (GAN) model for data augmentation, with the objective of enhancing the accuracy of DL models. The use of a GAN model to generate a training dataset and integrate images depicting challenging weather conditions has been pivotal in enhancing the accuracy of the DL models. The extensive training dataset, consisting of 64,336 images, was created using three cameras installed in VSim-AV, an autonomous vehicle simulator, thereby ensuring a diverse and comprehensive dataset for training purposes. Three DL models (ResNet50, ResNet101, and VGG16 transfer learning) were trained on this dataset both before and after applying the data augmentation techniques. The performance of the augmented models was evaluated in a real-time environment using the autonomous mode of the VSim-AV simulator. The testing phase resulted in the highest accuracy rate of 97.2% when employing Resnet101 following the implementation of GAN. It was observed that the autonomous car could navigate without any collisions, showcasing a remarkable reaction time of 0.105 seconds, thus affirming the effectiveness of the approach. The comparison between the original and augmented datasets demonstrate the originality and value of this study, showcasing its significant contribution to the advancement of autonomous vehicle obstacle avoidance technology. This paper makes significant advances to the field of autonomous vehicle navigation by exploiting Generative Adversarial Networks (GANs) to improve obstacle avoidance capabilities in severe weather conditions, hence increasing safety and dependability in real-world applications.},
  keywords={Meteorology;Data models;Autonomous vehicles;Accuracy;Collision avoidance;Generative adversarial networks;Deep learning;Collision avoidance;Meteorology;Data augmentation;Autonomous-vehicles;obstacle-avoidance;avoiding collision;VSim-AV;deep learning (DL);generative adversarial network (GAN);severe weather conditions;data augmentation;fine-tuning},
  doi={10.1109/ACCESS.2024.3419029},
  ISSN={2169-3536},
  month={},}@ARTICLE{10360129,
  author={Habib, Md. Ahsan and Wadud, Md. Anwar Hussen and Pinky, Lubna Yeasmin and Talukder, Mehedi Hasan and Rahman, Mohammad Motiur and Mridha, M. F. and Okuyama, Yuichi and Shin, Jungpil},
  journal={IEEE Access}, 
  title={GACnet-Text-to-Image Synthesis With Generative Models Using Attention Mechanisms With Contrastive Learning}, 
  year={2024},
  volume={12},
  number={},
  pages={9572-9585},
  abstract={The generation of high-quality images from textual descriptions is a challenging task in computer vision and natural language processing. The goal of text-to-image synthesis, a current topic of research, is to produce excellent images from written descriptions. This study proposes a hybrid approach to evaluating a dataset consisting of various text-image pairs by efficiently combining conditional generative adversarial networks (C-GAN), attention mechanisms, and contrastive learning (C-GAN+ATT+CL). We suggest a two-step method to improve image quality that starts by utilizing generative adversarial networks (GANs) with attention mechanisms to create low-resolution images and then contrastive learning to improve. Contrastive learning modules train on a separate dataset of high-resolution pictures; GANs learn on datasets of low-resolution text and image pairs. The Conditional GAN with Attention Mechanism and Contrastive Learning Method provides state-of-the-art performance in terms of image quality, diversity, and visual realism, among the several methods. The results of this study demonstrate that the proposed approach works better than all other methods, achieving an Inception Score (IS) of 35.23, a Fréchet Inception Distance (FID) of 18.2, and an R-Precision of 89.14. Our findings demonstrate that our “C-GAN+ATT+CL” approach significantly improves image quality and diversity and offers exciting paths for further study.},
  keywords={Generative adversarial networks;Generators;Image synthesis;Training;Tokenization;Computer science;Text processing;Image processing;Text-to-image synthesis;generative adversarial networks;C-GAN;attention mechanism;contrastive learning technique;consistency},
  doi={10.1109/ACCESS.2023.3342866},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9560928,
  author={Fan, Chen-Chen and Xie, Haiqun and Peng, Liang and Yang, Hongjun and Ni, Zhen-Liang and Wang, Guan’an and Zhou, Yan-Jie and Chen, Sheng and Fang, Zhijie and Huang, Shuyun and Hou, Zeng-Guang},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Group Feature Learning and Domain Adversarial Neural Network for aMCI Diagnosis System Based on EEG}, 
  year={2021},
  volume={},
  number={},
  pages={9340-9346},
  abstract={Medical diagnostic robot systems have been paid more and more attention due to its objectivity and accuracy. The diagnosis of mild cognitive impairment (MCI) is considered an effective means to prevent Alzheimer's disease (AD). Doctors diagnose MCI based on various clinical examinations, which are expensive and the diagnosis results rely on the knowledge of doctors. Therefore, it is necessary to develop a robot diagnostic system to eliminate the influence of human factors and obtain a higher accuracy rate. In this paper, we propose a novel Group Feature Domain Adversarial Neural Network (GF- DANN) for amnestic MCI (aMCI) diagnosis, which involves two important modules. A Group Feature Extraction (GFE) module is proposed to reduce individual differences by learning group- level features through adversarial learning. A Dual Branch Domain Adaptation (DBDA) module is carefully designed to reduce the distribution difference between the source and target domain in a domain adaption way. On three types of data set, GF-DANN achieves the best accuracy compared with classic machine learning and deep learning methods. On the DMS data set, GF-DANN has obtained an accuracy rate of 89.47%, and the sensitivity and specificity are 90% and 89%. In addition, by comparing three EEG data collection paradigms, our results demonstrate that the DMS paradigm has the potential to build an aMCI diagnose robot system.},
  keywords={Deep learning;Neural networks;Medical services;Human factors;Sensitivity and specificity;Feature extraction;Robot sensing systems},
  doi={10.1109/ICRA48506.2021.9560928},
  ISSN={2577-087X},
  month={May},}@ARTICLE{9448164,
  author={Lv, Guoyun and Israr, Syed Muhammad and Qi, Shengyong},
  journal={IEEE Access}, 
  title={Multi-Style Unsupervised Image Synthesis Using Generative Adversarial Nets}, 
  year={2021},
  volume={9},
  number={},
  pages={86025-86036},
  abstract={Unsupervised cross-domain image-to-image translation is a very active topic in computer vision and graphics. This task has two challenges: 1) lack of paired training data and 2) numerous possible outputs from a single image. The existing methods rely on either paired data or perform one-to-one translation. A novel Multi-Style Unsupervised image synthesis model using Generative Adversarial Nets (MSU-GAN) is proposed in this paper to overcome these disadvantages. Firstly, the encoder-decoder structure is used to map the image to domain-shared content features space and domain-specific style features space. Secondly, to translate an image into another domain, the content code and the style code are combined to synthesize the resulting image. Finally, the bidirectional cycle-consistency loss is used for the unpaired training data; the inter-domain adversarial loss and the reconstruction loss are used to ensure the output image's realism. Simultaneously, MSU-GAN is able to synthesize multi-style images due to disentangled representation. A Multi-Style Unsupervised Feature-Wise image synthesis model using Generative Adversarial Nets (MSU-FW-GAN) based on the MSU-GAN is proposed for the shape variation tasks. There are two different testing strategies, which include random style transfer and style guide transfer. For objective comparison, the proposed model performs well on all evaluation metrics. The random style transfer experiment results show that compared with CycleGAN on the photo2portraits dataset, MSU-FW-GAN FID, IS scores dropped by 12.77% and 8.06%. For the summer2winter dataset, MSU-GAN FID and IS scores increased by 24.51% and 3.64%. Qualitative results show that without paired training data, MSU-GAN and MSU-FW-GAN can synthesize multi-style and better realistic images on various tasks.},
  keywords={Generators;Task analysis;Image synthesis;Training data;Generative adversarial networks;Shape;Training;Generative Adversarial Nets;convolutional neural network;image synthesis;ResNet},
  doi={10.1109/ACCESS.2021.3087665},
  ISSN={2169-3536},
  month={},}@ARTICLE{10121015,
  author={Li, Jingru and Chen, Xiaofeng and Zheng, Peiyu and Wang, Qiang and Yu, Zhi},
  journal={IEEE Access}, 
  title={Deep Generative Knowledge Distillation by Likelihood Finetuning}, 
  year={2023},
  volume={11},
  number={},
  pages={46441-46453},
  abstract={Knowledge Distillation (KD) is designed to train smaller student models using a larger pretrained teacher model. However, in decentralized data systems such as blockchain, privacy concerns may arise, making the data inaccessible. To address this issue, Data-Free KD (DFKD) methods have been proposed, which extract prior knowledge from teacher networks and use it to synthesize data for KD. Previous DFKD methods faced challenges due to the large search space of data generation. Recently, deep generative models (DGMs) have been proposed to learn data distribution using deep networks, which provides an efficient way to reduce the search space by generating a set of pseudo data. In this paper, we explore the performance of KD trained using pseudo samples generated by pretrained DGMs and find that the correlation with image quality is not always positive. Based on this observation, we propose a new DFKD framework called Generative Knowledge Distillation (GenKD) that reduces the search space by constructing a prior distribution modeled by DGMs for their power of likelihood estimation. Specifically, we use energy-based models (EBM) to generate data from the Maximum Likelihood Estimation (MLE) of the EBM and gradients from downstream KD tasks by policy gradient. We then train the student model using the pretrained teacher model and pseudo samples. We also implement our GenKD framework on several widely-used benchmarks, including CIFAR100, CIFAR10, and SVHN. Our experiments demonstrate that we can generate high-quality pseudo samples quantitatively and qualitatively using GenKD. Additionally, the top-1 accuracy of the student network can approach state-of-the-art (SOTA) DFKD methods trained using fewer pseudo samples and less generation time.},
  keywords={Data models;Training;Maximum likelihood estimation;Task analysis;Blockchains;Generators;Image quality;Knowledge engineering;Deep learning;Generative adversarial networks;Knowledge distillation;deep generative model;image quality evaluation;data-free knowledge distillation},
  doi={10.1109/ACCESS.2023.3273952},
  ISSN={2169-3536},
  month={},}@ARTICLE{10217826,
  author={Zhan, Ming and Fan, Jingjing and Guo, Jianying},
  journal={IEEE Access}, 
  title={Generative Adversarial Inverse Reinforcement Learning With Deep Deterministic Policy Gradient}, 
  year={2023},
  volume={11},
  number={},
  pages={87732-87746},
  abstract={Although the issue of sparse expert samples at the early stage of training in inverse reinforcement learning (IRL) is successfully resolved by the introduction of generative adversarial network (GAN), the inherent drawbacks of GAN result in ineffective generated samples. Therefore, we propose an algorithm for generative adversarial inverse reinforcement learning that is based on deep deterministic policy gradient (DDPG). We use the deterministic strategy to replace the random noise input of the initial GAN model and reconstruct the generator of the GAN based on the Actor-Critic mechanism in order to improve the quality of GAN-generated samples during adversarial training. Meanwhile, we mix the GAN-generated virtual samples with the original expert samples of IRL as the expert sample set of IRL. Our approach not only solves the problem of sparse expert samples at the early stage of training, but most importantly, it makes the decision-making process of IRL occurring under GAN more efficient. In the subsequent IRL decision-making process, we also analyze the differences between the mixed expert samples and the non-expert trajectory samples generated by the initial strategy to determine the best reward function. The learned reward function is used to drive the RL process positively for policy updating and optimization, on which further non-expert trajectory samples are generated. By comparing the differences between the new non-expert samples and the mixed expert sample set, we hope to iteratively arrive at the reward function and optimal policy. Performance tests in the MuJoCo physical simulation environment and trajectory prediction experiments in Grid World show that our model improves the quality of GAN-generated samples and reduces the computational cost of the network training by approximately 20% for each given environment, applying to decision planning for autonomous driving.},
  keywords={Generative adversarial networks;Reinforcement learning;Training;Trajectory;Task analysis;Generators;Autonomous vehicles;Inverse problems;Deep learning;Inverse reinforcement learning;generative adversarial networks;deep deterministic policy gradient},
  doi={10.1109/ACCESS.2023.3305453},
  ISSN={2169-3536},
  month={},}@ARTICLE{8737929,
  author={Jia, Li-Li and Lv, Xiao-Yang and Cao, Yang-Jie and Yang, Cong and Li, Xue-Xiang and Li, Jie},
  journal={IEEE Access}, 
  title={Pscenegan: Multi-Domain Particular Scenes Generation Based on Conditional Generative Adversarial Networks}, 
  year={2019},
  volume={7},
  number={},
  pages={79477-79490},
  abstract={Generative adversarial networks (GANs) have made remarkable success in image generations. However, how to deal with the multi-domain particular scenes generation, which converts specific object images to different reasonable scene domians, is still an open problem. In this paper, we propose a multi-domain particular scene generation model named PSceneGAN (Particular Scene Generative Adversarial Nets) that is a novel dual-condition GAN. PSceneGAN is the first model to achieve one-to-many specific scene generation under the guidance of semantics using only one model. In addititon, we collect and label a novel high-quality clothing data set named DRESS and use it to verify our PSceneGAN through a challenging task. The results show that PSceneGAN not only accurately generates corresponding reasonable scene images according to input scene and semantic descriptions, but also achieves desired results in quantitative and qualitative evaluation, among which frechet inception distance (FID) and inception score (IS) are 25.40 and 36.24, respectively.},
  keywords={Semantics;Generators;Generative adversarial networks;Feature extraction;Decoding;Task analysis;Computer vision;Generative adversarial networks;multi-domain scenes generation;semantic control;spectral normalization},
  doi={10.1109/ACCESS.2019.2923418},
  ISSN={2169-3536},
  month={},}@ARTICLE{10614157,
  author={Ahsan Habib, Md and Anwar Hussen Wadud, Md and Fazlul Karim Patwary, Md and Motiur Rahman, Mohammad and Mridha, M. F. and Okuyama, Yuichi and Shin, Jungpil},
  journal={IEEE Access}, 
  title={Exploring Progress in Text-to-Image Synthesis: An In-Depth Survey on the Evolution of Generative Adversarial Networks}, 
  year={2024},
  volume={12},
  number={},
  pages={178401-178440},
  abstract={The emergence of generative adversarial networks (GANs) has ignited substantial interest in the domain of synthesizing images from textual descriptions. This approach has demonstrated remarkable versatility and user-friendliness in producing conditioned images, showcasing notable progress in areas like diversity, visual realism, and semantic alignment in recent years. Notwithstanding these developments, the discipline still faces difficulties, such as producing high-resolution pictures with several objects and developing trustworthy evaluation standards that are in line with human vision. The goal of this study is to provide a comprehensive overview of the state of stochastic text-to-image creation models as of right now. It examines how they have changed over the previous five years and suggests a classification system depending on the degree of supervision required. The paper highlights shortcomings, provides a critical evaluation of current approaches for assessing text-to-image synthesizing models, and suggests further study areas. These goals include improving the training of models and designs for architecture, developing more reliable assessment criteria, and fine-tuning datasets. This review, which focuses on text-to-image synthesizing, is a useful addition to earlier surveys on adversarial networks that are generative and offers guidance for future studies on the subject.},
  keywords={Text to image;Surveys;Generative adversarial networks;Solid modeling;Image synthesis;Visualization;Training;Text to image;Generative adversarial networks;attention mechanism;C-GAN;consistency;text-to-image synthesis},
  doi={10.1109/ACCESS.2024.3435541},
  ISSN={2169-3536},
  month={},}@ARTICLE{10107599,
  author={Watanabe, Yuto and Togo, Ren and Maeda, Keisuke and Ogawa, Takahiro and Haseyama, Miki},
  journal={IEEE Access}, 
  title={Text-Guided Image Manipulation via Generative Adversarial Network With Referring Image Segmentation-Based Guidance}, 
  year={2023},
  volume={11},
  number={},
  pages={42534-42545},
  abstract={This study proposes a novel text-guided image manipulation method that introduces referring image segmentation into a generative adversarial network. The proposed text-guided image manipulation method aims to manipulate images containing multiple objects while preserving text-unrelated regions. The proposed method assigns the task of distinguishing between text-related and unrelated regions in an image to segmentation guidance based on referring image segmentation. With this architecture, the adversarial generative network can focus on generating new attributes according to the text description and reconstructing text-unrelated regions. For the challenging input images with multiple objects, the experimental results demonstrate that the proposed method outperforms conventional methods in terms of image manipulation precision.},
  keywords={Image segmentation;Text recognition;Generative adversarial networks;Image color analysis;Visualization;Image reconstruction;Text processing;Text-guided image manipulation;text-to-image synthesis;generative adversarial network;referring image segmentation},
  doi={10.1109/ACCESS.2023.3269847},
  ISSN={2169-3536},
  month={},}@ARTICLE{10643979,
  author={Cretu, Ioana and Tindale, Alexander and Balachandran, Wamadeva and Abbod, Maysam and William Khir, Ashraf and Meng, Hongying},
  journal={IEEE Access}, 
  title={Synthesis of Multimodal Cardiological Signals Using a Conditional Wasserstein Generative Adversarial Network}, 
  year={2024},
  volume={12},
  number={},
  pages={133994-134007},
  abstract={Cardiovascular diseases (CVDs) are the leading cause of mortality worldwide. Recent advancements in machine learning have significantly enhanced early detection and treatment strategies for CVDs. While electrocardiogram (ECG) signals are commonly used for detection, additional signals like arterial blood pressure (ABP) and central venous pressure (CVP) provide a comprehensive view of the cardiovascular system. However, acquiring such extensive datasets is challenging due to resource constraints, privacy issues, and ethical considerations. This paper introduces a novel Multichannel Conditional Wasserstein Generative Adversarial Network (MC-WGAN) capable of simultaneously generating synthetic ECG, ABP, and CVP signals. The MC-WGAN model addresses the data scarcity issue by providing high-fidelity synthetic data that mirrors real physiological signals, facilitating better simulation, diagnosis, and treatment planning. Evaluation against the MIT-BIH Arrhythmia Database demonstrated the model’s strong performance, with competitive metrics such as RMSE, PRD, and FD, particularly excelling in the generation of ECG and ABP signals. MC-WGAN surpasses other generative models by simultaneously replicating multiple physiological signals, offering a comprehensive view of cardiovascular health. This advancement enhances diagnostic accuracy and risk stratification, setting a new standard in synthetic biomedical signal generation, and paving the way for more personalized and effective clinical interventions.},
  keywords={Electrocardiography;Generators;Generative adversarial networks;Training;Solid modeling;Data models;Convolution;Blood pressure measurement;Biomedical signal processing;Generative adversarial network;electrocardiogram;blood pressure;biosignals},
  doi={10.1109/ACCESS.2024.3449134},
  ISSN={2169-3536},
  month={},}@ARTICLE{10742345,
  author={Wang, Yan and Deng, Lianbing},
  journal={IEEE Access}, 
  title={Enhanced Data Augmentation for Infrared Images With Generative Adversarial Networks Aided by Pretrained Models}, 
  year={2024},
  volume={12},
  number={},
  pages={176739-176750},
  abstract={Infrared imaging emerges as a promising technique for vision tasks within environments characterized by low or obscured visibility. However, the scarcity of infrared datasets, particularly those comprising paired infrared-visible images, addresses significant challenges for the training of high-performance deep learning models. This paper investigates the application of generative adversarial networks (GANs) for data augmentation in infrared imaging. Our work encompasses a range of GAN models including Pix2Pix, CycleGAN, StyleGAN3, and the proposed Cycle-aided model, which incorporates vision-aided loss to enhance both model training and stability. The results demonstrate that CycleGAN encounters stability issues and is prone to mode collapse, leading to less satisfactory performance. By contrast, the Cycle-aided model that leverages pre-trained models to substantially improve both the discriminative and generative capabilities of GANs, evidenced by a 51% increase in peak signal-to-noise ratio (PSNR), a 43% increase in structural similarity index (SSIM) and an 18% decrease in the Fréchet inception distance (FID) over CycleGAN. These improvements underscore the potential of GANs to improve data augmentation practices for infrared imaging in low-visibility environments. The insights gained also pave the way for future research aimed at developing architectures and training strategies of GANS for fully exploiting the unique properties of data augmentation.},
  keywords={Training;Data augmentation;Data models;Vectors;Generators;Feature extraction;Training data;PSNR;Infrared imaging;Generative adversarial networks;Infrared Images;data augmentation;generative adversarial networks},
  doi={10.1109/ACCESS.2024.3491167},
  ISSN={2169-3536},
  month={},}@ARTICLE{10930449,
  author={Long, Pujun and Liang, Mi and Chen, Hongjian and Yang, Qin},
  journal={IEEE Access}, 
  title={An Enhanced Generative Adversarial Network Prediction Model Based on LSTM and Attention for Corrosion Rate in Pipelines}, 
  year={2025},
  volume={13},
  number={},
  pages={50260-50273},
  abstract={To address the pervasive issue of internal pipeline corrosion in the oil and gas industry, this paper proposes a hybrid intelligent model for predicting corrosion rates. This model integrates an improved Generative Adversarial Network with Grey Wolf Optimization and Support Vector Regression (LAGAN-GWO-SVR). In this model, the traditional Generative Adversarial Network is combined with the Long Short-Term Memory network and the Multi-head Attention mechanism. The Long Short-Term Memory is used to capture and analyze the sequential features in internal pipeline corrosion data, effectively uncovering latent relationships within the sequences. Meanwhile, the Multi-head Attention mechanism focuses on key features, further enhancing the model’s ability to concentrate on critical information. In addition, to more accurately predict the corrosion rate of internal pipeline in complex environments, this paper utilizes Grey Wolf Optimization to optimize the hyper-parameters in Support Vector Regression. Three sets of experiments were conducted, including different data augmentation algorithms, various improvement strategies, and comparisons with other benchmark models. The experimental results show that the model offers significant advantages in predicting internal pipeline corrosion rates. The LAGAN-GWO-SVR in this paper achieves a Root Mean Square Error of 0.013 and a coefficient of determination of 0.982.},
  keywords={Corrosion;Generative adversarial networks;Pipelines;Predictive models;Generators;Data models;Accuracy;Optimization;Oils;Prediction algorithms;Internal pipeline corrosion;grey wolf optimization;support vector regression;generative adversarial network},
  doi={10.1109/ACCESS.2025.3552096},
  ISSN={2169-3536},
  month={},}@ARTICLE{11104825,
  author={Shi, Kaize and Peng, Xueping and Zhu, Yifan and He, Hui and Yi, Kun and Niu, Zhendong},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={Multi-KGS: Generating Social Network-Based Meteorological Decision Reports Fusing With Multiple Knowledge}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={The increasing prevalence of meteorological disasters necessitates advanced spatiotemporal data analytics to enhance emergency response in smart cities. Social networks, as real-time crowdsourcing sensors, provide critical data streams that Generative AI (GenAI) can fuse and summarize to generate comprehensive meteorological decision reports for enhanced emergency response during abrupt weather crises. This paper introduces a Multiple Knowledge Guided Summarization (Multi-KGS) model designed to generate meteorological decision reports by fusing posts from Sina Weibo. Specifically, the Multi-KGS model comprises a summary generation module and a multiple knowledge guidance module. The summary generation module synthesizes the content of the decision report, while the multiple knowledge guidance module steers and constrains the summarization process using knowledge of meteorological events and geographical locations, ensuring that the generated report highlights the core knowledge expressed in the source posts. Compared to baseline models, Multi-KGS achieves superior performance in content evaluation, as measured by ROUGE-1, ROUGE-2, and ROUGE-L, as well as in sentiment evaluation, with the best F1 score. This study provide a generative decision support paradigm for servicing urban computing.},
  keywords={Semantics;Blogs;Consumer electronics;Biological system modeling;Decoding;Data mining;Training;Long short term memory;Knowledge engineering;Weather forecasting;Smart Cities;Social Sensors;Generative Decision Support;GenAI-based Emergency Management;Urban Computing},
  doi={10.1109/TCE.2025.3594146},
  ISSN={1558-4127},
  month={},}@ARTICLE{10325514,
  author={Muramudalige, Shashika R. and Jayasumana, Anura P. and Wang, Haonan},
  journal={IEEE Access}, 
  title={A Feature Mapping Technique for Complex Data Object Generation With Likelihood and Deep Generative Approaches}, 
  year={2023},
  volume={11},
  number={},
  pages={136643-136653},
  abstract={When a sufficient amount of training data is available, Machine Learning (ML) models show great promise for solving problems involving complex and dynamic patterns. Social and behavioral domains are rich with such challenging problems, with complex object data extracted from documents, surveys, etc., and represented in forms such as graphs and trees. However, many social and behavioral data sets are inherently sparse and incomplete. The same data field may be unavailable in different records of a data set due to different causes, e.g., because it was not measured, not known, or simply not applicable to that particular record. Furthermore, collection challenges, cost, lack of participation, small affected populations, etc., result in very small sets of data. Resulting unconventional datasets cannot be directly used with potent approaches such as machine learning. A technique to model and synthesize large sets of such complex data objects while maintaining the same statistical and topological characteristics of original data helps overcome these challenges. We propose a novel feature mapping technique to eliminate data inconsistencies and model data objects from unconventional datasets. The feature-mapped data objects are used to synthesize data using two likelihood approaches, i.e., multi-variate Gaussian and regular vine copulas, and one generative adversarial approach using an adversarial autoencoder (AAE). We demonstrate the robustness of the proposed technique with three real-world datasets representing disparate domains and validate the performance of likelihood and deep-generative approaches with these object synthesis strategies.},
  keywords={Data models;Behavioral sciences;Synthetic data;Social factors;Social networking (online);Object oriented modeling;Generative adversarial networks;Adversarial autoencoder;copulas;synthetic data generation;generative adversarial networks},
  doi={10.1109/ACCESS.2023.3335375},
  ISSN={2169-3536},
  month={},}@ARTICLE{10518126,
  author={Huang, Zijie and Wu, Yulei and Tempini, Niccolò and Tang, Haina},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Ethical Decision-Making for the Inside of Autonomous Buses Moral Dilemmas}, 
  year={2024},
  volume={5},
  number={10},
  pages={5153-5166},
  abstract={The emergence of moral dilemmas inside autonomous buses can lead to unpredictable consequences for maneuver and amplify potential harms to passengers onboard. However, most existing approaches solely focus on ensuring ethical decision-making in scenarios outside of vehicles. To ensure ethical decision-making for autonomous buses when moral dilemmas occur inside, there are many urgent challenges that need to be addressed. First, the noncommensurability of ethical values presents difficulties in designing quantifiable environments and decision-making models. Moreover, ethical dilemmas involve multiple conflicting objectives, often necessitating the consideration of multiple moral theories to comprehensively evaluate different perspectives. Additionally, accurately representing these dilemmas and identifying optimal solutions that address conflicting objectives poses further challenges. This article proposes a general ethical decision-making system to handle ethical dilemmas inside autonomous buses. The system's design adheres to multiple ethical principles, and it comprises two stages: 1) develop a generative adversarial network (GAN) based human-value-aligned data collection scheme to gather representative moral values and generate comprehensive moral scenarios, which address the incommensurable ethical metrics issue; and 2) propose an ethical compliant multiobjective thresholded lexicographic Deep Q-learning method to ensure optimal policies that satisfy multiple ethical objectives. In a case study of autonomous bus route planning, our system outperforms benchmarks in showing a greater number and more evenly distributed policies in the Pareto Front and a 27% increase in coverage rate. Extensive experiments against nonethical systems show superior outcomes in convergence, average reward and cost. Finally, user studies demonstrate the system's accuracy and usability.},
  keywords={Ethics;Decision making;Artificial intelligence;Q-learning;Mathematical models;Autonomous vehicles;Roads;Autonomous bus;ethical decision-making;moral dilemmas;multiobjective reinforcement learning},
  doi={10.1109/TAI.2024.3396415},
  ISSN={2691-4581},
  month={Oct},}@INPROCEEDINGS{9369820,
  author={Lee, Seungyeon and Park, Taewon and Lee, Minho},
  booktitle={2021 International Conference on Electronics, Information, and Communication (ICEIC)}, 
  title={4W1H Keyword Extraction based Summarization Model}, 
  year={2021},
  volume={},
  number={},
  pages={1-4},
  abstract={In this internet era, with rapidly growing online information, there is a need for automatic summarization of textual documents from plethora of available information, making it an interesting area of research. Automatic keyword extraction and text summarization are Natural Language Processing (NLP) tasks for extracting relevant information from the large text documents. 4W1H (Who, When, Where, What, How) keywords are crucial for sentence generation. Despite the potential of 4W1H keywords, there have not been approaches that utilize the keywords in NLP tasks, particularly summarization. In this paper, we propose a new summarization method based on 4W1H keywords extraction which extracts the answer to a question corresponding to each event in QA format. We apply our methods to BERT and ELECTRA models to generate a summary, which are well-known pre-trained Language Models (LMs) in NLP domain, as a baseline. In experiments, our 4W1H keyword extraction method shows promising performance on AI Hub**https://www.aihub.or.kr/aidata/86 Machine Reading Comprehension (MRC) dataset, recording an extraction performance of an F1-score as 84.93%. Moreover, we show the results of generating a rule-based summarization using keywords extracted with 4W1H.},
  keywords={Deep learning;Bit error rate;Natural language processing;Data mining;Task analysis;Artificial intelligence;Natural Language Processing;Summarization;Question Answering;Machine Reading Comprehension;4W1H;Text Extraction},
  doi={10.1109/ICEIC51217.2021.9369820},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10317102,
  author={Russo, Paolo and Ciaccio, Fabiana Di},
  booktitle={2023 IEEE International Workshop on Metrology for the Sea; Learning to Measure Sea Health Parameters (MetroSea)}, 
  title={Recent advances in AI for enhanced environmental monitoring and preservation}, 
  year={2023},
  volume={},
  number={},
  pages={127-132},
  abstract={This paper explores the potential applications of cutting-edge Artificial Intelligence (AI) technologies, specifically Vision Transformer and Diffusion models in the field of environmental monitoring and preservation. By analyzing the current state of the art, we highlight the potential of these advanced techniques in capturing, analyzing, and communicating environmental data. Vision Transformer models demonstrate their effectiveness in identifying and classifying environmental features, while Diffusion models offer realistic image generation capabilities. We discuss the diverse applications of these models, such as visualizing environmental impacts, enhancing data quality, and generating synthetic images for training datasets. By bridging the gap between AI advancements and environmental research, this paper paves the way for improved accuracy, efficiency, and communication in the realm of sustainable environmental practices.},
  keywords={Visualization;Image synthesis;Transfer learning;Sea measurements;Transformers;Data models;Environmental monitoring;AI technologies;Environmental monitoring;Environment preservation;Vision Transformer;Diffusion models},
  doi={10.1109/MetroSea58055.2023.10317102},
  ISSN={},
  month={Oct},}@ARTICLE{9903615,
  author={Yang, Rui and Vo, Duc Minh and Nakayama, Hideki},
  journal={IEEE Access}, 
  title={Stochastically Flipping Labels of Discriminator’s Outputs for Training Generative Adversarial Networks}, 
  year={2022},
  volume={10},
  number={},
  pages={103644-103654},
  abstract={Generative Adversarial Networks (GANs) play the adversarial game between two neural networks: the generator and the discriminator. Many studies treat the discriminator’s outputs as an implicit posterior distribution prior to the input image distribution. Thus, increasing the discriminator’s output dimensions can represent richer information than a single output dimension of the discriminator. However, increasing the output dimensions will lead to a very strong discriminator, which can easily surpass the generator and break the balance of adversarial learning. Solving such conflict and elevating the generation quality of GANs remains challenging. Hence, we propose a simple yet effective method to solve this conflict problem based on a stochastic selecting method by extending the flipped and non-flipped non-saturating losses in BipGAN. We organized our experiments based on the famous BigGAN and StyleGAN models for comparison. Our experiments successfully validated our approach to strengthening the generation quality within limited output dimensions via several standard evaluation metrics and real-world datasets and achieved competitive results in the Human face generation task.},
  keywords={Games;Generative adversarial networks;Training data;Image generation;Measurement;Generative adversarial networks;Stochastic processes;Stochastic discriminator;label flipping;image generation},
  doi={10.1109/ACCESS.2022.3210130},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10796059,
  author={Ramagundam, Shashishekhar and Karne, Niharika},
  booktitle={2024 4th International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME)}, 
  title={A Survey of Generative AI: A Game Changer for Free Streaming Services and Ad Personalization with Current Techniques, Identifying Research Gaps and Addressing Challenges}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={The rapidly evolving digital landscape witnessing a significant shift as the convergence of advanced personalized advertising aligns with free streaming services. As consumer preferences increasingly lean towards on-demand video, streaming providers are challenged with delivering consistent, high-quality content while also devising profitable and non-intrusive monetization strategies. In response to this balancing act, cutting-edge advertising methods that utilize data analytics to tailor the viewing experience have been developed, benefiting both viewers and advertisers. Despite the plethora of surveys exploring Artificial Intelligence's (AI) role across various sectors, there remains a notable gap in comprehensive, in-depth research specifically examining the impact of Generative AI (Gen AI) on free streaming services and personalized advertising. Therefore, this paper focuses on the diverse techniques of Gen AI that drive transformation in free streaming services and Ad personalization. To achieve this, a thorough literature review is conducted on papers from the past decades that explore Gen AI in this context. The Gen AI techniques used for free streaming services and ad personalization are analyzed and categorized. Performance metrics are compiled and listed to enhance the understanding of the processes involved. Additionally, these reviews identify and outline the research gaps in the conventional applications of Gen AI for free streaming services and ad personalization to aid future studies.},
  keywords={Surveys;Mechatronics;Data analysis;Generative AI;Reviews;Current measurement;Games;Streaming media;Market research;Advertising;Generative AI;Game Changer for Free Streaming Services and Ad Personalization;Problem Solved by Generative AI Techniques;Performance Measures;Research Gaps and Future Trends},
  doi={10.1109/ICECCME62383.2024.10796059},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9657391,
  author={Fernando, P.D.C. and Fernando, B.A.N. and Wanaguru, I.U. and Perera, M.A.P.A. and Buddhika, Thilini and Kodagoda, Nuwan and Ganegoda, Devanshi},
  booktitle={2021 6th International Conference on Information Technology Research (ICITR)}, 
  title={Thuryalankara: Artificial Intelligence Based Audio Plugin For Sri Lankan Percussion Instruments}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Sri Lankan music is yet to prove its musical prowess by incorporating artificial intelligence tools, therefore, this research introduces a novel invention, an automated audio plugin for music producers, so the process of creating, mixing, mastering, and producing music is easier. To achieve this, the research introduces a Variational AutoEncoder (VAE) machine learning model to create and generate music, an artificial intelligence (AI) system that can automate the mastering process. This research also introduces an innovative component, a virtual instrumentation tool using MIDI technology for the Sri Lankan percussion instruments that allow users to play the instrument virtually using a MIDI keyboard, and alongside it, a preset beat generator that automatically maintain tempo consistency. Thuryalankara was able to receive a collective average of 80% accuracy rate exceeding the predicted accuracy rate of 65% from the software benchmarking test and the physical survey conducted with music producers. Finally, with the inclusion of powerful tools like this, the ultimate objective of this research is to take the Sri Lankan instruments to the international level where any producer from little to plenty experience is able to use this plugin to enhance their musical production.},
  keywords={Technological innovation;Instruments;Music;Keyboards;Production;Machine learning;Benchmark testing;Audio plugin;Sri Lankan music;Machine Learning;Virtual Instrumentation;Mix and Master},
  doi={10.1109/ICITR54349.2021.9657391},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10957016,
  author={Dong, Yingying and Guo, Suping and Dai, Sijing and Yang, Zongliang},
  booktitle={2025 International Conference on Electrical Automation and Artificial Intelligence (ICEAAI)}, 
  title={Power Detection Image Recognition Analysis Based on Image Fusion Extended Training}, 
  year={2025},
  volume={},
  number={},
  pages={1351-1355},
  abstract={The operation and maintenance of power system are paid more and more attention. How to solve the contradiction between economic development and electric power construction is the key problem faced by the development of the current national power industry. Image recognition technology realizes the transformation from artificial to intelligent power grid in power system operation and maintenance. With the help of computer vision algorithms and deep learning modes, the automatic detection and remote control of power system equipment and lines are realized. Image recognition techniques generate desired image samples through image synthesis algorithms, but the lack of image samples in power inspection leads to poor performance of the recognition algorithm. To solve this problem, this chapter gives two methods to expand the sample of power inspection. Firstly, the image synthesis algorithm based on image fusion is introduced. For some samples, the Poisson fusion algorithm is used to smooth the gradient of the boundary. Then, the image generation algorithm is introduced and the required samples are directly generated through Deep Convolutional Generative Adversarial Networks (DCGAN). Finally, two sample set augmentation methods are evaluated by experiments. Experiments are conducted to evaluate the effect of the two sample augmentation methods. In the experiment, the F1-score of the trained detection model on the same test set is improved from 0.802 to 0.873 after using image fusion to expand the training set. After using the images generated by DCGAN to expand the training set, the F1-score of the trained detection model on the same test set is improved from 0.769 to 0.877 after using image fusion to expand the training set, 12.3% increase. The F1-score of the trained detection model on the same test set is improved from 0.769 to 0.877 after using image fusion to expand the training set, 12.3% increase.},
  keywords={Training;Image recognition;Image synthesis;Inspection;Feature extraction;Data models;Power grids;Maintenance;Object recognition;Image fusion;image recognition;power inspection;synthesis algorithm;DCGAN},
  doi={10.1109/ICEAAI64185.2025.10957016},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{11157015,
  author={Kusuma, Quin Derbi and Wiharja, Kemas Rahmat Saleh},
  booktitle={2025 International Conference on Data Science and Its Applications (ICoDSA)}, 
  title={Building an Online News Article Recommendation System Using Generative Recommendation}, 
  year={2025},
  volume={},
  number={},
  pages={97-102},
  abstract={Selecting news articles to read has become increasingly challenging in the era of artificial intelligence due to the overwhelming amount of content generated daily by diverse news outlets. With the rapid expansion of digital media, users are often inundated with choices, leading to decision fatigue and difficulties in finding content that aligns with their preferences. To address these challenges, we developed a cutting-edge recommendation system powered by generative AI, specifically leveraging the capabilities of diffusion models. Unlike traditional recommendation systems that rely heavily on textual or visual content, our approach focuses on analyzing user interaction patterns with news articles to generate personalized recommendations. This method minimizes the reliance on additional data modalities while maintaining high performance. The development of this system involved rigorous data preprocessing and transformation techniques, which were employed to enhance the model’s ability to understand and infer relationships between users and articles. By optimizing these processes, we ensured that the model could accurately capture the nuances of user behavior, improving the relevance and quality of the recommendations. Experimental evaluations demonstrated that our Diffusion model significantly outperforms other state-of-the-art models, such as FairGAN, across all major evaluation metrics, including precision, recall, and NDCG. This research not only highlights the potential of diffusion models in recommendation systems but also underscores their effectiveness in striking an optimal balance between exploration and exploitation in content delivery. This advantage is driven by the gradual refinement of the diffusion model results using probabilistic sampling. As a result, the model provides more relevant, diverse, and high-quality news recommendations, aimed at enhancing user experience and engagement.},
  keywords={Measurement;Adaptation models;Visualization;Media;Diffusion models;Probabilistic logic;Generative adversarial networks;User experience;Data models;Recommender systems;generative recommender systems;online news recommendation;generative adversarial networks (GANs);diffusion model},
  doi={10.1109/ICoDSA67155.2025.11157015},
  ISSN={},
  month={July},}@INPROCEEDINGS{10724165,
  author={Saju, Sreelekshmi and Harikumar, Sandhya and Surendran, Simi and Anil, Anisha},
  booktitle={2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Fetal Heart Ultrasound Image Enhancement and Anatomical Feature Recognition via GAN and GradCAM}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Ultrasound, an essential component of effective prenatal care, is a primary source of valuable information concerning fetal health and development. This study presents a novel approach to solving common issues in the fetus’s heart. This study addresses the intricacies that come with biological studies concerning fetal heart ultrasound diagnosis by applying cluster analysis and the generative adversarial network, specifically the Pix2Pix Model. This study focuses on issues in fetal heart imaging, such as the small size and unclear anatomical appearance of fetal heart artifacts in ultrasound images. In addition, introducing the Grad-CAM-AI visualization significantly improves the available, interpretable assets and usability for healthcare professionals. This comprehensive approach aims to increase the quality of care for mothers and their babies using this new feature and advanced imaging technologies.},
  keywords={Image segmentation;Ultrasonic imaging;Accuracy;Computational modeling;Imaging;Generative adversarial networks;Data models;Complexity theory;Anatomy;Fetal heart;Generative adversarial networks;Grad-CAM;Cluster Analysis;Prenatal Care},
  doi={10.1109/ICCCNT61001.2024.10724165},
  ISSN={2473-7674},
  month={June},}@ARTICLE{11122422,
  author={Bai, Hao and He, Kun and Li, Yuqing and Chen, Jing and Li, Haowei and Liu, Zhongmou and Yang, Xuanang and Du, Ruiying},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={GetFed: Accurate, Differentially Private Federated Learning with GAN-based Data Generation}, 
  year={2025},
  volume={},
  number={},
  pages={1-16},
  abstract={Federated Learning (FL) aims to train neural network models using distributed data resources from multiple clients without sharing raw data. One of the key challenges in FL is non-independent and identically distributed (non-IID) data, which may affect model accuracy. To address this issue, some schemes leverage Generative Adversarial Networks (GANs) to generate virtual data and combine it with the real data to achieve a balanced data distribution. However, there are risks of privacy leakage from the collected virtual data and aggregated gradients. In this paper, we propose GetFed, an accurate and differentially private FL framework with GAN-based Data Generation on non-IID Data. We integrate Differential Privacy (DP) into the GAN training and federated aggregation phases to prevent clients' privacy leakage. To balance privacy and accuracy, we first design a privacy-preserving virtual sample generation algorithm for GAN training that dynamically reduces unnecessary noise as the quality of virtual samples improves. Additionally, we design an adaptive DP-based secure aggregation algorithm that decreases the added noise as the model approaches convergence. Furthermore, we implement a real-virtual ensemble training algorithm, employing an ensemble learning strategy to better mix virtual and real samples for enhanced global model accuracy. This approach ensures clients benefit from both the authenticity of real samples and the balanced data distribution provided by virtual samples, effectively mitigating the data heterogeneity inherent in non-IID scenarios. Extensive experiments demonstrate that compared with state-of-the-art schemes, GetFed improves model accuracy by 6–47% and reduces training time by 50%.},
  keywords={Accuracy;Noise;Training;Adaptation models;Privacy;Generative adversarial networks;Data models;Sensitivity;Differential privacy;Generators;Federated Learning;Non-IID Data;Generative Adversarial Network;Differential Privacy},
  doi={10.1109/TDSC.2025.3597635},
  ISSN={1941-0018},
  month={},}@INPROCEEDINGS{11105257,
  author={Kumi, Sandra and Lomotey, Richard K. and Ray, Madhurima and Cunningham, Emma and Milovich, Stephanie and Deters, Ralph},
  booktitle={2025 IEEE World AI IoT Congress (AIIoT)}, 
  title={A Data-Driven Digital Twin for Student Engagement Prediction in e-Learning Systems}, 
  year={2025},
  volume={},
  number={},
  pages={0560-0566},
  abstract={Machine Learning (ML) models are increasingly applied to Learning Management System (LMS) data to predict student engagement and performance. LMS data often contain missing values that can be informative. However, existing modeling approaches in education remove or impute missing values, which can lead to inaccurate or biased models. In this paper, we propose the use of digital twins to model students’ engagement based on their learning activities on LMS while preserving the missingness patterns. We leveraged synthetic data generators such as Conditional Tabular Generative Adversarial Network (CTGAN), Tabular Variational Autoencoder (TVAE), and RealTabFormer with reversible data transformations to create a virtual replica of students’ data. The CTGAN and TVAE generated balanced synthetic data that accurately captured the meaningful patterns of the real data. Moreover, XGBoost trained on a balanced virtual replica of the students’ learning activities data obtained an F1-score of above 80% in predicting the students’ engagement levels when evaluated on real data with both complete and incomplete entries. Our findings demonstrate how digital twins can be used to address the complexities of data in the education sector, improve the generalization of models, and reduce bias in real-world performance.},
  keywords={Learning management systems;Electronic learning;Education;Predictive models;Generative adversarial networks;Data models;Real-time systems;Generators;Digital twins;Synthetic data;Digital Twin;Education;Learning Activities;Student Engagement Modeling;Learning Management Systems;MOOC;Synthetic Data Generative Models},
  doi={10.1109/AIIoT65859.2025.11105257},
  ISSN={},
  month={May},}@INPROCEEDINGS{9651658,
  author={Hashimoto, Ryosuke and Itaya, Toshiya and Nishimura, Hitoshi and Fukuchi, Syunsuke and Kato, Hiroki and Ito, Junya and Nakagawa, Kyoma},
  booktitle={2021 6th International Conference on Intelligent Informatics and Biomedical Sciences (ICIIBMS)}, 
  title={Nondestructive inspection technology for plant steel structures using magneto-optical images using deep generative models}, 
  year={2021},
  volume={6},
  number={},
  pages={10-15},
  abstract={Measures against deterioration of infrastructures that were built during the high economic growth period are facing significant challenges with regard to the maintenance of infrastructures in Japan. The development of optimal nondestructive sensing and imaging technology according to the material and structure of buildings is underway to contribute to efficient and reliable maintenance of infrastructures. However, owing to the large number of materials and structures used for buildings, as well as the types of defects to be targeted, many basic studies are yet to reach the stage of practical use. In this study, we developed a magneto-optical (MO) sensor in order to visualize a “crack” in the plant steel structure and automatically detected the defects in the plant steel structure by performing deep learning on the MO image obtained. As a pretreatment for detecting anomalies in defects using the AI, we focused on the nondestructive inspection using MO imaging and performed an unprecedented image filter processing. As a result, automatically evaluation the several types of MO images using AI, the accuracy of defection identification was improved.},
  keywords={Visualization;Biological system modeling;Buildings;Materials reliability;Inspection;Maintenance engineering;Robot sensing systems;artificial intelligence;variational autoencoder;nondestructive inspection;magneto-optical imaging},
  doi={10.1109/ICIIBMS52876.2021.9651658},
  ISSN={2189-8723},
  month={Nov},}@ARTICLE{9443091,
  author={Saha, Monjoy and Guo, Xiaoyuan and Sharma, Ashish},
  journal={IEEE Access}, 
  title={TilGAN: GAN for Facilitating Tumor-Infiltrating Lymphocyte Pathology Image Synthesis With Improved Image Classification}, 
  year={2021},
  volume={9},
  number={},
  pages={79829-79840},
  abstract={Tumor-infiltrating lymphocytes (TILs) act as immune cells against cancer tissues. The manual assessment of TILs is usually erroneous, tedious, costly and subject to inter- and intraobserver variability. Machine learning approaches can solve these issues, but they require a large amount of labeled data for model training, which is expensive and not readily available. In this study, we present an efficient generative adversarial network, TilGAN, to generate high-quality synthetic pathology images followed by classification of TIL and non-TIL regions. Our proposed architecture is constructed with a generator network and a discriminator network. The novelty exists in the TilGAN architecture, loss functions, and evaluation techniques. Our TilGAN-generated images achieved a higher Inception score than the real images (2.90 vs. 2.32, respectively). They also achieved a lower kernel Inception distance (1.44) and a lower Fréchet Inception distance (0.312). It also passed the Turing test performed by experienced pathologists and clinicians. We further extended our evaluation studies and used almost one million synthetic data, generated by TilGAN, to train a classification model. Our proposed classification model achieved a 97.83% accuracy, a 97.37% F1-score, and a 97% area under the curve. Our extensive experiments and superior outcomes show the efficiency and effectiveness of our proposed TilGAN architecture. This architecture can also be used for other types of images for image synthesis.},
  keywords={Generative adversarial networks;Computer architecture;Pathology;Image synthesis;Convolution;Cancer;Generators;Digital pathology;deep learning;generative adversarial network;lung cancer;artificial intelligence},
  doi={10.1109/ACCESS.2021.3084597},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10647820,
  author={Chen, Bolin and Yin, Shanzhi and Chen, Peilin and Wang, Shiqi and Ye, Yan},
  booktitle={2024 IEEE International Conference on Image Processing (ICIP)}, 
  title={Generative Visual Compression: A Review}, 
  year={2024},
  volume={},
  number={},
  pages={3709-3715},
  abstract={Artificial Intelligence Generated Content (AIGC) is leading a new technical revolution for the acquisition of digital content and impelling the progress of visual compression towards competitive performance gains and diverse functionalities over traditional codecs. This paper provides a thorough review on the recent advances of generative visual compression, illustrating great potentials and promising applications in ultra-low bitrate communication, user-specified reconstruction/filtering, and intelligent machine analysis. In particular, we review the visual data compression methodologies with deep generative models, and summarize how compact representation and high-quality reconstruction could be actualized via generative techniques. In addition, we generalize related generative compression technologies for machine vision with different-domain analysis. Finally, we discuss the fundamental challenges on generative visual compression techniques and envision their future research directions.},
  keywords={Visualization;Image coding;Reviews;Machine vision;Data compression;Performance gain;Data models;Visual data compression;deep generative models;intelligent coding/analytics},
  doi={10.1109/ICIP51287.2024.10647820},
  ISSN={2381-8549},
  month={Oct},}@ARTICLE{9165737,
  author={Varkarakis, Viktor and Bazrafkan, Shabab and Costache, Gabriel and Corcoran, Peter},
  journal={IEEE Access}, 
  title={Validating Seed Data Samples for Synthetic Identities – Methodology and Uniqueness Metrics}, 
  year={2020},
  volume={8},
  number={},
  pages={152532-152550},
  abstract={This work explores the identity attribute of synthetic face samples derived from Generative Adversarial Networks. The goal is to determine if individual samples are unique in terms of identity, firstly with respect to the seed dataset that trains the GAN model and secondly with respect to other synthetic face samples. Two approaches are introduced to enable the comparative analysis of large sets of synthetic face samples. The first of these uses ROC curves to determine identity uniqueness using a number of large publicly available datasets of real facial samples to provide reference ROCs as a baseline. The second approach uses a thresholding technique utilizing again large publicly available datasets as a reference. For this approach, new metrics are introduced, and a technique is provided to remove the most connected data samples within a large synthetic dataset. The remaining synthetic samples can be considered as unique as data samples gathered from different real individuals. Several StyleGAN models are used to create the synthetic datasets, and variations in key model parameters are explored. It is concluded that the resulting synthetic data samples exhibit excellent uniqueness when compared with the original training dataset, but significantly less uniqueness when comparisons are made within the synthetic dataset. Nevertheless, it is possible to remove the most highly connected synthetic data samples. Thus, in some cases, up to 92% of the data samples in a 20k synthetic dataset can be shown to exhibit similar uniqueness to data samples taken from real public datasets.},
  keywords={Gallium nitride;Face;Measurement;Computational modeling;Task analysis;Generative adversarial networks;Training;Artificial intelligence;computer vision;face recognition;generative adversarial networks (GANs);StyleGAN;synthetic face;synthetic identity;uniqueness metrics},
  doi={10.1109/ACCESS.2020.3016097},
  ISSN={2169-3536},
  month={},}@ARTICLE{11119052,
  author={Khan, Muhammad Attique and Alasiry, Areej and Marzougui, Mehrez and Bayhan, Isa and Kuna, Siva Sarana and Rao, G. Siva Nageswara and Algamdi, Shabbab Ali and Aldossary, Haya},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Securing Intelligent Transportation Systems: A Dual-Framework Approach for Privacy Protection and Cybersecurity Using Generative AI}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={Integrating Generative AI (GenAI) into Intelligent Transportation Systems (ITS) raises both enormous opportunities and major worries, especially in the areas of privacy and cybersecurity, which are already at the forefront of these developments. Developing and implementing robust security measures to secure sensitive data and address new cyber threats is of utmost importance, especially with the growing dependence on AI technology in transportation networks. This article looks at GenAI and how it may improve ITS intelligence and efficiency while addressing the risks of using it a lot. It delves into the difficulties of protecting AI-driven systems against hostile assaults (AI-MA), particularly emphasizing transportation infrastructure security, intrusion detection, and data privacy. The research stresses the significance of modern encryption methods, real-time monitoring threats, and adaptive security frameworks to ensure ITS are secure and resilient. In addition, it delves into how transportation systems are affected by ever-changing cyber threats, offering proactive security solutions to combat these dangers and strengthen ITS. This paper’s overarching goal is to lay out a course of action for integrating GenAI into ITS in a way that strikes a good balance between fostering innovation and ensuring privacy and security via thorough analysis. The proposed AI-MA model achieves a high threat detection accuracy of 96.2%, a privacy protection score of 91.8%, a computational efficiency of 92.9%, a resilience score of 97.8%, and a network reliability ratio of 92.6% compared to other existing models.},
  keywords={Security;Computer security;Privacy;Real-time systems;Encryption;Protection;Generative AI;Monitoring;Data privacy;Artificial intelligence;GenAI;privacy protection;security protocols;cyber threats;intelligent transportation system},
  doi={10.1109/TITS.2025.3591007},
  ISSN={1558-0016},
  month={},}@INPROCEEDINGS{10068480,
  author={Vakil, Asad and Blasch, Erik and Ewing, Robert and Li, Jia},
  booktitle={2022 9th International Conference on Soft Computing & Machine Intelligence (ISCMI)}, 
  title={MVI-DCGAN Insights into Heterogenous EO and Passive RF Fusion}, 
  year={2022},
  volume={},
  number={},
  pages={146-151},
  abstract={As technology trends towards automation, deep neural network (DNN) based methods become more and more desirable from a technological, economical, and societal standpoint. However, owing to the way that these black box technologies operate, it can be difficult to troubleshoot potential errors, especially when dealing with data that the human mind cannot intuitively understand. For this reason, the use of explainable artificial intelligence (XAI) is integral to obtaining interpretability and understanding of these systems' techniques. The paper explores some of the known uses of XAI in Generative Adversarial Networks (GANs); i.e., in processing electro-optical (EO) and passive radiofrequency (Passive RF) data to achieve heterogenous sensor fusion. GANs are capable of generating realistic images, music text, and other forms of data, and the use of deep convolutional generative adversarial networks (DCGANs) to process such information provides “richer” corrective feedback from which the model can train from. Using the DCGAN approach, tone can provide visualizations from different types of neural networks and use them as a training source for the multiple visualizations input (MVI) DCGAN. The MVI-DCGAN uses these visualizations in order to track the vehicle target and further differentiate between other overlay visualization data and the generated overlay input visualizations. The paper demonstrates multiple sources of visualization input from different neural networks for the training of the MVI-DCGAN for a more robust training and directing the discriminator towards focusing on the P-RF aspects of the visualizations.},
  keywords={Training;Radio frequency;Measurement;Target tracking;Neural networks;Data visualization;Sensor fusion;explainable artificial intelligence;heterogenous sensor fusion;GAN;EO;passive RF},
  doi={10.1109/ISCMI56532.2022.10068480},
  ISSN={2640-0146},
  month={Nov},}@ARTICLE{10839238,
  author={Sun, Geng and Xie, Wenwen and Niyato, Dusit and Mei, Fang and Kang, Jiawen and Du, Hongyang and Mao, Shiwen},
  journal={IEEE Wireless Communications}, 
  title={Generative AI for Deep Reinforcement Learning: Framework, Analysis, and Use Cases}, 
  year={2025},
  volume={32},
  number={3},
  pages={186-195},
  abstract={As a form of artificial intelligence (AI) technology based on interactive learning, deep reinforcement learning (DRL) has been widely applied across various fields and has achieved remarkable accomplishments. However, DRL faces certain limitations, including low sample efficiency and poor generalization. Therefore, in this article, we show how to leverage generative AI (GAI) to address these issues and enhance the performance of DRL algorithms. We first introduce several classic GAI and DRL algorithms and demonstrate the applications of GAI-enhanced DRL algorithms. Then, we discuss how to use GAI to improve DRL algorithms from the data and policy perspectives. Subsequently, we introduce a framework that demonstrates an actual and novel integration of GAI with DRL, that is, GAI-enhanced DRL. Additionally, we provide a case study of the framework for UAV-assisted integrated near-field/far-field communication to validate the performance of the proposed framework. Moreover, we present several future directions. Finally, the related code is available at: https://xiewenwen22.github.io/GAI-enhanced-DRL.},
  keywords={Codes;Generative AI;Decision making;Learning (artificial intelligence);Deep reinforcement learning;Transformers;Interactive systems},
  doi={10.1109/MWC.001.2400176},
  ISSN={1558-0687},
  month={June},}@ARTICLE{10872776,
  author={Xia, Le and Sun, Yao and Liang, Chengsi and Zhang, Lei and Imran, Muhammad Ali and Niyato, Dusit},
  journal={IEEE Wireless Communications}, 
  title={Generative AI for Semantic Communication: Architecture, Challenges, and Outlook}, 
  year={2025},
  volume={32},
  number={1},
  pages={132-140},
  abstract={Semantic communication (SemCom) is expected to be a core paradigm in future communication networks, yielding significant benefits in terms of spectrum resource saving and information interaction efficiency. However, the existing SemCom structure is limited by the lack of context-reasoning ability and background knowledge provisioning, which, therefore, motivates us to seek the potential of incorporating generative artificial intelligence (GAI) technologies with SemCom. Recognizing GAI's powerful capability in automating and creating valuable, diverse, and personalized multimodal content, this article first highlights the principal characteristics of the combination of GAI and SemCom along with their pertinent benefits and challenges. To tackle these challenges, we further propose a novel GAI-integrated SemCom network (GAI-SCN) framework in a cloud-edge-mobile design. Specifically, by employing global and local GAI models, our GAI-SCN enables multimodal semantic content provisioning, semantic-level joint-source-channel coding, and AIGC acquisition to maximize the efficiency and reliability of semantic reasoning and resource utilization. Afterward, we present a detailed implementation workflow of GAI-SCN, followed by corresponding initial simulations for performance evaluation in comparison with two benchmarks. Finally, we discuss several open issues and offer feasible solutions to unlock the full potential of GAI-SCN.},
  keywords={Semantic communication;Communication networks;Generative AI;Artificial intelligence;Multimodal sensors;Resource management;Performance evaluation;Encoding;Character recognition;Benchmark testing},
  doi={10.1109/MWC.003.2300351},
  ISSN={1558-0687},
  month={February},}@ARTICLE{11154972,
  author={Shen, Jiacheng and Lin, Zhi and Ma, Ruiqian and An, Kang and Han, Chen and Sun, Yifu and He, Yuanzhi and Niyato, Dusit},
  journal={IEEE Network}, 
  title={Unraveling Spherical Wavefront Complexities: A New Channel Estimation Paradigm for Near-Field Communications via Generative Adversarial Networks}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={Near-field communication (NFC) offers unprecedented spatial multiplexing gains and centimeter-level positioning precision by leveraging tightly focused energy beams. However, its unique electromagnetic characteristics, including high-dimensional parameter spaces and nonlinear distortions from spherical wavefront interactions, pose significant challenges for accurate channel estimation. To address these issues, this paper proposes a novel channel estimation paradigm based on generative adversarial networks (GANs), which excel at nonlinear modeling of complex electromagnetic behaviors. Specifically, we design a GAN-enabled NFC framework that integrates network architecture with advanced generative artificial intelligence for robust channel estimation. Through a case study, we introduce the Regularized Relativistic Pairing GAN (ReRpGAN), which significantly enhances the stability and precision of NFC channel estimation. Experimental results demonstrate the superiority of our approach over traditional methods. This work not only advances the application of GANs in NFC channel estimation but also outlines key future research directions for promoting generative AI development in next-generation NFC systems.},
  keywords={Channel estimation;Electromagnetic scattering;Accuracy;Wireless communication;Estimation;Computational modeling;Antenna arrays;Wireless sensor networks;Generative adversarial networks;Integrated sensing and communication},
  doi={10.1109/MNET.2025.3600405},
  ISSN={1558-156X},
  month={},}@INPROCEEDINGS{10500049,
  author={Simeon, Quilee and Venâncio, Leandro and Skuhersky, Michael A. and Nayebi, Aran and Boyden, Edward S. and Yang, Guangyu Robert},
  booktitle={SoutheastCon 2024}, 
  title={Scaling Properties for Artificial Neural Network Models of a Small Nervous System}, 
  year={2024},
  volume={},
  number={},
  pages={516-524},
  abstract={The nematode worm C. elegans provides a unique opportunity for exploring in silico data-driven models of a whole nervous system, given its transparency and well-characterized nervous system facilitating a wealth of measurement data from wet-lab experiments. This study explores the scaling properties that may govern learning the underlying neural dynamics of this small nervous system by using artificial neural network (ANN) models. We investigate the accuracy of self-supervised next time-step neural activity prediction as a function of data and models. For data scaling, we report a monotonic log-linear reduction in mean-squared error (MSE) as a function of the amount of neural activity data. For model scaling, we find MSE to be a nonlinear function of the size of the ANN models. Furthermore, we observe that the dataset and model size scaling properties are influenced by the particular choice of model architecture but not by the precise experimental source of the C. elegans neural data. Our results fall short of producing long-horizon predictive and generative models of C. elegans whole nervous system dynamics but suggest directions to achieve those. In particular our data scaling properties extrapolate that recording more neural activity data is a fruitful near-term approach to obtaining better predictive ANN models of a small nervous system.},
  keywords={Neural activity;Artificial neural networks;Learning (artificial intelligence);Predictive models;Nervous system;Data models;Recording;nervous system;neural networks;machine learning;neuroscience;scaling laws},
  doi={10.1109/SoutheastCon52093.2024.10500049},
  ISSN={1558-058X},
  month={March},}@INPROCEEDINGS{9725866,
  author={Tanwar, Nakul and Hasija, Yasha},
  booktitle={2022 International Conference for Advancement in Technology (ICONAT)}, 
  title={Deep Learning: A tool in Biomedical Science}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={The development of technologies in health care and biomedical sciences outcomes with a large amount of data that limits the human capability, which highlights the urgency of predictive and analysis tools. Their outcomes will catalyst betterment judgments and decision-making in medical/healthcare organizations, at the same time; it'll also unfasten various prospects of research. In consideration of this, artificial intelligence and its branches not only replicate human intelligence but also analyze the data and manifest excellent results. Machine learning is one of them, that is assigned with computer learning patterns for a specific dataset and produces results that are new and have unseen data. This involves the least amount of human intervention as machines learn how to optimize themselves to produce astounding outcomes. But it also has its drawbacks as these algorithms do not learn accurately and lack the capability of learning deep patterns. Deep learning algorithms have been developed to overcome those drawbacks. In a deep learning environment, there are many layers or levels of abstraction which helps in defining the complexity of the patterns behind the data. The purpose of this paper is to explore the role of deep learning in healthcare and biomedical sector. Following that, evolution in artificial neural network (ANNs) and deep learning architecture is discussed.},
  keywords={Deep learning;Biological system modeling;Atmospheric modeling;Decision making;Medical services;Computer architecture;Artificial neural networks;Artificial neural network;Deep Learning;Deep patterns;medical and healthcare organizations;Predictive analysis},
  doi={10.1109/ICONAT53423.2022.9725866},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10992577,
  author={Lin, Xihua and Song, Xiaodan and Zuo, Xuguang and Li, Xuyang and Gao, Dahua and Xie, Xuemei and Shi, Guangming},
  booktitle={2025 Data Compression Conference (DCC)}, 
  title={Affine Transformation-Based Generative Face Video Compression}, 
  year={2025},
  volume={},
  number={},
  pages={387-387},
  abstract={In this paper, we propose a generative face video compression framework based on affine transformations to better represent large movements without parameter transmission. It mainly consists of an encoder and decoder, and our encoder is similar to the one in [1]. Intra frame are compressed by the existing encoder, while subsequent inter frames are compressed into compact inter frame features. In the decoder, feature alignment is first established to map the decoded intra frame and inter frame features into the same domain. The aligned features are then combined with the appearance features extracted by the appearance encoder from the intra frame and fed into the coarse-fine affine transform module to establish motion estimation and compensation. The coarse affine transform focuses on global motion, while the fine affine transform deals with local motion, such as lip motion. Finally, the transformed features are fed into the image generation module to obtain the final reconstruction results.},
  keywords={Image synthesis;Motion estimation;Lips;Data compression;Transforms;Video compression;Feature extraction;Decoding;Faces;Image reconstruction},
  doi={10.1109/DCC62719.2025.00074},
  ISSN={2375-0359},
  month={March},}@INPROCEEDINGS{10920714,
  author={Park, Jinhyeong and Shaheryar, Muhammad and Lee, Seangmin and Jung, Soon Ki},
  booktitle={2025 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Navigating h-Space for Multi-Attribute Editing in Diffusion Models}, 
  year={2025},
  volume={},
  number={},
  pages={1129-1133},
  abstract={Multi-attribute editing in generative models has been a challenging problem, especially in achieving realistic and disentangled transformations across multiple attributes simultaneously. In this work, we propose an approach for multi-attribute editing in the h-space of diffusion models, where multiple attributes such as aging, gender and eyeglasses can be edited simultaneously. Unlike existing methods that require separate models for each attribute or operate in a highly coupled latent space, our method harnesses the power of a unified framework. We learn interpretable attribute directions in the latent space through supervised training, enabling fine-grained control over specific attributes without affecting others. This disentangled editing allows for complex transformations, such as modifying both age and hairstyle while preserving identity. By performing edits in the h-space, we ensure high-quality, coherent transformations, demonstrating the potential for rich and flexible editing capabilities. The ability to perform multi-attribute modifications in a single, unified model opens up new possibilities for applications in computer vision, digital media, and personalized content creation, making our method a significant advancement in generative modeling.},
  keywords={Training;Image transformation;Navigation;Computational modeling;Semantics;Transforms;Aerospace electronics;Media;Diffusion models;Image reconstruction;Multi attribute Editing;Image Transformation;Generative Models;Latent space},
  doi={10.1109/ICAIIC64266.2025.10920714},
  ISSN={2831-6983},
  month={Feb},}@INPROCEEDINGS{10825572,
  author={Libin, Alexander and Treitler, Jonah and Vasaitis, Tadas and Shao, Yijun},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={Evaluating and Reducing Subgroup Disparity in AI Models Predicting Pediatric COVID-19 Test Outcomes}, 
  year={2024},
  volume={},
  number={},
  pages={5033-5042},
  abstract={Artificial Intelligence (AI) fairness in healthcare settings has attracted significant attention due to the concerns to propagate existing health disparities. Despite ongoing research, the frequency and extent of subgroup fairness have not been sufficiently studied. In this study, we extracted a nationally representative pediatric dataset (ages 0-17, n=9,935) from the US National Health Interview Survey (NHIS) concerning COVID-19 test outcomes. For subgroup disparity assessment, we trained 50 models using five machine learning algorithms. We assessed the models’ area under the curve (AUC) on 12 small (<15% of the total n) subgroups defined using social economic factors versus the on the overall population. Our results show that subgroup disparities were prevalent (50.7%) in the models. Subgroup AUCs were generally lower, with a mean difference of 0.01, ranging from -0.29 to +0.41. Notably, the disparities were not always statistically significant, with four out of 12 subgroups having statistically significant disparities across models. Additionally, we explored the efficacy of synthetic data in mitigating identified disparities. The introduction of synthetic data enhanced subgroup disparity in 57.7% of the models. The mean AUC disparities for models with synthetic data decreased on average by 0.03 via resampling and 0.04 via generative adversarial network methods.},
  keywords={COVID-19;Surveys;Machine learning algorithms;Biological system modeling;Medical services;Predictive models;Data models;Artificial intelligence;Socioeconomics;Synthetic data;AI fairness;health risk;group parity;machine learning;pediatric population;prediction model;synthetic data},
  doi={10.1109/BigData62323.2024.10825572},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{10869028,
  author={Hu, Qi and Xu, Lvqing},
  booktitle={2024 4th International Conference on Educational Technology (ICET)}, 
  title={Intent Research on the Use of Generative AI by Student Teachers: An Integration Model Based on S-O-R and TAM}, 
  year={2024},
  volume={},
  number={},
  pages={408-413},
  abstract={In November 2022, ChatGPT caused a global wave of human-computer interaction with its disruptive impact on text generation, transforming practices in education, especially in teacher training. Generative AI’s superior interactive intelligence and content creation capabilities are essential to facilitate a seamless transition to technology-driven education. What factors affect normal school students’ acceptance of generative AI? In this study, the intention of student teachers to use generative AI is discussed, and an integrated model based on the Stimulus-Bio-Response (S-O-R) framework and the Technology Acceptance model (TAM) is proposed. Then, a questionnaire survey was conducted on 343 student teachers. Through the path analysis of structural equation model, the structural model of the influencing factors of student teachers ‘willingness to use generative artificial intelligence was obtained. The model results showed that perceived usefulness, perceived ease of use and perceived control were the influencing factors of military student teachers’ willingness to use generative artificial intelligence. Further analysis found that teaching skills, adoption intention, teaching innovation, generative media, personalization, software support, perceived trust, community influence, perceived risk and decision-making authority were the stimulating factors of student teachers’ willingness to use generative artificial intelligence. Finally, this paper helped student teachers to use generative artificial intelligence in education scenarios from enhancing perceived usefulness, improving perceived ease of use, strengthening perceived control and broadening the education field of generative artificial intelligence.},
  keywords={Training;Technological innovation;Analytical models;Technology acceptance model;Generative AI;Education;Decision making;Media;Mathematical models;Software;Generative AI;Student Teachers;TAM;S-O-R},
  doi={10.1109/ICET62460.2024.10869028},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10211278,
  author={Xie, Yanxi and Li, Ziyue and Li, Chao and Zhu, Yonghui and Zhang, Hao},
  booktitle={2023 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)}, 
  title={Blockchain-Aided Distributed Device-Free Wireless Sensing with IoT Devices in Edge Network}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Recently, the popularity of Internet of Things (IoT) devices has brought massive amounts of sensing data to edge networks. How to use distributed sensing data to train artificial intelligence (AI) models for ubiquitous intelligent wireless sensing in IoT, while considering privacy is an open problem. In this paper, we propose an edge intelligence (EI) and blockchain powered device-free wireless sensing framework to supply IoT applications in edge networks. We design a cross-domain wireless sensing scheme for human-computer interaction by adopting adversarial transfer learning in this framework and verify the effectiveness of the method.},
  keywords={Wireless communication;Human computer interaction;Training;Wireless sensor networks;Transfer learning;Data models;Sensors;Edge intelligence;blockchain;wireless sensing},
  doi={10.1109/BMSB58369.2023.10211278},
  ISSN={2155-5052},
  month={June},}@ARTICLE{10238401,
  author={Zhang, Yuxin and He, Ruisi and Ai, Bo and Yang, Mi and Chen, Ruifeng and Wang, Chenlong and Zhang, Zhengyu and Zhong, Zhangdui},
  journal={China Communications}, 
  title={Generative adversarial networks based digital twin channel modeling for intelligent communication networks}, 
  year={2023},
  volume={20},
  number={8},
  pages={32-43},
  abstract={Integration of digital twin (DT) and wireless channel provides new solution of channel modeling and simulation, and can assist to design, optimize and evaluate intelligent wireless communication system and networks. With DT channel modeling, the generated channel data can be closer to realistic channel measurements without requiring a prior channel model, and amount of channel data can be significantly increased. Artificial intelligence (AI) based modeling approach shows outstanding performance to solve such problems. In this work, a channel modeling method based on generative adversarial networks is proposed for DT channel, which can generate identical statistical distribution with measured channel. Model validation is conducted by comparing DT channel characteristics with measurements, and results show that DT channel leads to fairly good agreement with measured channel. Finally, a link-layer simulation is implemented based on DT channel. It is found that the proposed DT channel model can be well used to conduct link-layer simulation and its performance is comparable to using measurement data. The observations and results can facilitate the development of DT channel modeling and provide new thoughts for DT channel applications, as well as improving the performance and reliability of intelligent communication networking.},
  keywords={Generative adversarial networks;Wireless communication;Generators;Channel models;Training;Delays;Digital twins;digital twin;channel modeling;generative adversarial networks;intelligent communication networking},
  doi={10.23919/JCC.fa.2023-0206.202308},
  ISSN={1673-5447},
  month={Aug},}@INPROCEEDINGS{9523178,
  author={Cai, Haoming and He, Jingwen and Qiao, Yu and Dong, Chao},
  booktitle={2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={Toward Interactive Modulation for Photo-Realistic Image Restoration}, 
  year={2021},
  volume={},
  number={},
  pages={294-303},
  abstract={Modulating image restoration level aims to generate a restored image by altering a factor that represents the restoration strength. Previous works mainly focused on optimizing the mean squared reconstruction error, which brings high reconstruction accuracy but lacks finer texture details. This paper presents a Controllable Unet Generative Adversarial Network (CUGAN) to generate high-frequency textures in the modulation tasks. CUGAN consists of two modules - base networks and condition networks. The base networks comprise a generator and a discriminator. In the generator, we realize the interactive control of restoration levels by tuning the weights of different features from different scales in the Unet architecture. Moreover, we adaptively modulate the intermediate features in the discriminator according to the severity of degradations. The condition networks accept the condition vector (encoded degradation information) as input, then generate modulation parameters for both the generator and the discriminator. During testing, users can control the output effects by tweaking the condition vector. We also provide a smooth transition between GAN and MSE effects by a simple transition method. Extensive experiments demonstrate that the proposed CUGAN achieves excellent performance on image restoration modulation tasks.},
  keywords={Degradation;Modulation;Generative adversarial networks;Generators;Image restoration;Pattern recognition;Task analysis},
  doi={10.1109/CVPRW53098.2021.00039},
  ISSN={2160-7516},
  month={June},}@ARTICLE{10187134,
  author={Tang, Haolin and Catak, Ferhat Ozgur and Kuzlu, Murat and Catak, Evren and Zhao, Yanxiao},
  journal={IEEE Access}, 
  title={Defending AI-Based Automatic Modulation Recognition Models Against Adversarial Attacks}, 
  year={2023},
  volume={11},
  number={},
  pages={76629-76637},
  abstract={Automatic Modulation Recognition (AMR) is one of the critical steps in the signal processing chain of wireless networks, which can significantly improve communication performance. AMR detects the modulation scheme of the received signal without any prior information. Recently, many Artificial Intelligence (AI) based AMR methods have been proposed, inspired by the considerable progress of AI methods in various fields. On the one hand, AI-based AMR methods can outperform traditional methods in terms of accuracy and efficiency. On the other hand, they are susceptible to new types of cyberattacks, such as model poisoning or adversarial attacks. This paper explores the vulnerabilities of an AI-based AMR model to adversarial attacks in both single-input-single-output and multiple-input-multiple-output scenarios. We show that these attacks can significantly reduce the classification performance of the AI-based AMR model, which highlights the security and robustness concerns. Therefore, we propose a widely used mitigation method (i.e., defensive distillation) to reduce the vulnerabilities of the model against adversarial attacks. The simulation results indicate that the AI-based AMR model can be highly vulnerable to adversarial attacks, but their vulnerabilities can be significantly reduced by using mitigation methods.},
  keywords={Perturbation methods;Modulation;Feature extraction;Solid modeling;Computational modeling;Iterative methods;Training;Artificial intelligence;Next generation networking;Generative adversarial networks;Artificial intelligence;next-generation networks;automatic modulation recognition;adversarial attacks;model poisoning;defensive distillation},
  doi={10.1109/ACCESS.2023.3296805},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10134921,
  author={Lasrado, Rohan Nolan and Vijayasherly, V.},
  booktitle={2023 3rd International conference on Artificial Intelligence and Signal Processing (AISP)}, 
  title={Unconditional Generation of Scalable Chinese Characters as Bézier Curve Sequences}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={Neural generative modelling of sketches has been an active research direction. SketchRNN set a milestone with their sequence-to-sequence variational autoencoder architecture being able to generate hand drawn sketches in various classes by modelling them as sequences of displacements between consecutive stroke points. The diversity and variety in the set of handwritten Chinese characters makes them a good candidate for such generative modelling enabling their unconditional generation. However, modelling them as sequences of points causes coarse looking strokes and much longer sequences, consequently requiring use of polygonal approximation algorithms to cut down on points. Instead, we propose and investigate the modelling of Chinese characters as sequences of Bézier curves using the SketchRNN architecture with a few modifications, to allow the model to directly generate smooth curves. This way the encoded representation is smaller while more of the stroke’s characteristics are retained and the generated characters are truly scalable. We also suggest the appropriate preprocessing strategy for the KanjiVG dataset to make it suitable for this purpose. Qualitative evaluation of the results suggests the model demonstrates generation of characters with mostly well-structured and ordered strokes. This was substantiated by quantitative evaluation based on the FrFréchetchet Inception Distance score.},
  keywords={Measurement;Graphics;Signal processing;Approximation algorithms;Artificial intelligence;SketchRNN;Variational Autoencoders;Generative modelling;Bézier Curves;Sketch generation;Scalable graphics},
  doi={10.1109/AISP57993.2023.10134921},
  ISSN={2640-5768},
  month={March},}@INPROCEEDINGS{9837351,
  author={Verma, Akshay and Gupta, Dipesh and Srivastava, Manish Kumar},
  booktitle={2021 First International Conference on Advances in Computing and Future Communication Technologies (ICACFCT)}, 
  title={Deepfake Detection using Inception-ResnetV2}, 
  year={2021},
  volume={},
  number={},
  pages={39-41},
  abstract={Deep learning has benefited us in resolving many complex problems. Computer vision is a subcategory of it. With the ability to find patterns from unstructured data, Deep learning has immense potential. Big techs are very keen on producing a computer with human brain-like decision-making capabilities. With all these sweeter sides comes the bitter side of it. Deepfake is one such occurrence. It creates a mask which contain properties of a particular person and can be applied to some other person. In this way the target is depicted doing deeds which he never did. With the increased capacity of a specific field i.e. Generative Adversarial Network (GAN); now we can create high-quality deepfakes. Deepfakes nowadays can easily deceive human eyes. The consequences of this can be devastating and unforeseeable. Creating chaos, privacy threats are some of the major reasons why people are questioning deepfakes. Victims’ size has started including common public. What could be done is to keep a check over its spreading. This work has taken into consideration the problems that emerged by deepfakes and proposed a method to detect forgery among videos.},
  keywords={Deep learning;Chaos;Deepfakes;Privacy;Computer vision;Decision making;Generative adversarial networks;Deep Learning;DeepFakes;Artificial Intelligence;Inception-ResnetV2},
  doi={10.1109/ICACFCT53978.2021.9837351},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10520423,
  author={Chandra, Pragati and Joshi, Gauri and Bhagwat, Radhika},
  booktitle={2023 IEEE Engineering Informatics}, 
  title={ChatGPT's Evolution in Reshaping Cognitive Behavioral Therapy}, 
  year={2023},
  volume={},
  number={},
  pages={1-9},
  abstract={The evolution of ChatGPT has been driven by advancements in Natural Language Processing (NLP), with a transformative impact on various domains. ChatGPT's NLP-driven adaptability enhances accessibility, making CBT tailored to different age groups and genders. It fosters therapeutic conversations and provides self-help resources, empowering individuals on their mental health journey. This paper explores ChatGPT's role in reshaping Cognitive Behavioral Therapy (CBT), focusing on adaptability across age groups and genders and its diverse CBT applications. The paper delves into the mechanics of ChatGPT's response generation and its influence on CBT. Acknowledging limitations and ethical concerns, the paper weighs the positive aspects and challenges posed by ChatGPT. It also proposes future research directions, including emotionally aware ChatGPT models, advanced progress tracking, and diversified datasets. This paper would be a valuable reference for researchers, mental health experts, technology innovators, and policymakers. It offers insights into the profound impact that ChatGPT can have on mental health care. It also underscores the importance of maintaining ethical standards when applying this technology.},
  keywords={Bridges;Ethics;Medical treatment;Focusing;Mental health;Oral communication;Chatbots;Artificial Intelligence;ChatGPT;Natural Language Processing;Cognitive Behavioral Therapy;Generative Pre-trained Transformer},
  doi={10.1109/IEEECONF58110.2023.10520423},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10756295,
  author={Hardi, Hajar and Eddine Fatani, Imade Fahd},
  booktitle={2024 Sixth International Conference on Intelligent Computing in Data Sciences (ICDS)}, 
  title={Optimizing Video Compression Quality Using AI-Boosted HEVC}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={There has been increased demand for more immersive video content to enhance the Quality of Service. This prompted the need for newer compression algorithms which would retain or even improve the original video quality. This research specifically delves into the implementation of a lossless Generative Adversarial Network (GAN)-based H.265 video compression. The main employed methods and applied treatments are briefly described. Subsequently, this work's findings are presented in the results sections. The conclusion indicates the effectiveness of (GAN)-based algorithm utilized in the video compression process.},
  keywords={Visualization;Quality of service;Streaming media;Video compression;Generative adversarial networks;Signal reconstruction;Quality assessment;Compression algorithms;Video recording;Optimization;HEVC;H.265;GAN;Machine Learning;Deep Learning;Artificial Intelligence;QoS},
  doi={10.1109/ICDS62089.2024.10756295},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9922697,
  author={Esper, Ian de Medeiros and Romanov, Dmytro and Korostynska, Olga and From, Pål Johan and Mason, Alex},
  booktitle={2022 IEEE 10th Jubilee International Conference on Computational Cybernetics and Cyber-Medical Systems (ICCC)}, 
  title={Ex-vivo Porcine Model for Generating an Internal Surface in Biological Subjects using 3D-GAN}, 
  year={2022},
  volume={},
  number={},
  pages={000209-000214},
  abstract={Robotic automation in the medical industry is complex because of the biological nature of the processed materials and the risks to the patient. Everyone is different, which means that each individual has their own characteristics; different size, bone structure, joint positions, etc. This makes it hard for robots to autonomously operate on humans. RGB-D consumer devices and computing power are revolutionising the way robots interact with the environment. With the camera’s intrinsic parameters and the depth frame, a point cloud, i.e., a set of points in a Cartesian space $\mathrm{IR}^{3}$, can be generated giving more complete information to the application in real-time. This work investigates a GAN (Generative Adversarial Network) to generate the internal surface of an ex-vivo porcine left ham, as a precursor to consideration of human models. That is important as a prediction of the internal structure. A good internal ham surface could be generated even with a small dataset. The complexity of the shapes in the generated data are shown and structures like the ball-joint attachment can be seen.},
  keywords={Point cloud compression;Industries;Service robots;Shape;Biological system modeling;Generative adversarial networks;Bones;Artificial Intelligence;3D-GAN;Ex-vivo porcine;Robotic},
  doi={10.1109/ICCC202255925.2022.9922697},
  ISSN={},
  month={July},}@INPROCEEDINGS{11088917,
  author={Bande, Sayli Pankaj and N, Vinutha and K, Pradeep Kumar},
  booktitle={2025 6th International Conference on Recent Advances in Information Technology (RAIT)}, 
  title={Augmenting Medical Diagnostics with AI: A Dual Approach Using RAG-Based Chatbots and Nano GPT Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={A pioneering dual approach is proposed to enhance medical diagnostics through the integration of RAG-based chatbots and Nano GPT models. Leveraging AI advancements, our methodology aims to revolutionize medical practice by improving diagnostic accuracy, patient care, and healthcare efficiency. The research encompasses a comprehensive exploration of hyperparameters critical for optimizing the Nano Generative Pre-trained Transformer model, focusing on parameters such as learning rate, batch size, and layer configuration. Through systematic experimentation, we evaluated various hyperparameter configurations to minimize both training and validation loss of 0.4889 and 1.4031 respectively for 1.34 million parameters, ensuring the model’s ability to learn from medical data while effectively generalizing to unseen patient cases. Our findings demonstrate the intricate interplay between model complexity, regularization techniques, and generalization capabilities. We further propose a sampling mechanism tailored for generating medical text from the GPT-like language model, facilitating model setup and fine-tuning generation details. The proposed dual approach, integrating interactive patient consultations with advanced diagnostic analysis, showcases promising results, marking a significant step toward the future of AI-driven healthcare. Future work will focus on conducting clinical trials to further validate the chatbot’s performance in real-world scenarios.},
  keywords={Training;Accuracy;Generative Pre-trainer transformer;Clinical trials;Chatbots;Transformers;Medical diagnosis;Medical diagnostic imaging;Tuning;Testing;Artificial Intelligence;Large Language Models;Medical Diagnostic;Nano GPT models;Retrieval-Augmented Generation (RAG)-based chatbots},
  doi={10.1109/RAIT65068.2025.11088917},
  ISSN={2994-287X},
  month={March},}@INPROCEEDINGS{10277977,
  author={Wei, Jiacheng and Song, Huijia and Lin, Xiaozhu and Jin, Shaoning and Chen, Senliu and Zhou, Tianqian},
  booktitle={2023 4th International Conference on Intelligent Computing and Human-Computer Interaction (ICHCI)}, 
  title={Folded Handwritten Digit Recognition Based on WGAN-GP Model}, 
  year={2023},
  volume={},
  number={},
  pages={01-04},
  abstract={The study of overlapped handwritten digit recognition algorithms is critical for improving automated recognition accuracy, improving document processing, and automating recognition systems. The majority of current research in this field is focused on detecting two overlapped handwritten numbers. However, when one handwritten digit is folded onto another, recognition becomes more difficult, and there is currently no well-established recognition algorithm for this circumstance. To solve the issue of folded digit recognition, a method is provided that reconstructs the folded handwritten digit images using Generative Adversarial Networks (GANs) and transformation optimization algorithm, followed by recognition using a recognition network. The MNIST dataset is used to validate the suggested approach. The experimental findings demonstrate that the recognition accuracy reaches 97.22%, proving the suggested approach's considerable promise in solving the recognition of folded handwritten digit images.},
  keywords={Human computer interaction;Handwriting recognition;Image recognition;Automation;Generative adversarial networks;Image restoration;Optimization;Machine learning;Artificial intelligence;Pattern Recognition;Restoration;Folded images},
  doi={10.1109/ICHCI58871.2023.10277977},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10581129,
  author={Dhamiwal, Anjali and Shubham and Mahajan, Shilpa},
  booktitle={2024 International Conference on Intelligent Systems for Cybersecurity (ISCS)}, 
  title={Adversarial Machine Learning for Blockchain Security}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper explores the intersection of adversarial machine learning (AML) and blockchain security, presenting a comprehensive analysis of the challenges and solutions in leveraging AML techniques to protect blockchain networks. The decentralized and non-regular nature of blockchain technology exposes it to various adversarial threats, including 51% attacks, double spending, and smart contract vulnerabilities. To address these challenges, AML offers a range of techniques, such as adversarial training, generative adversarial networks (GANs), feature engineering, and robust ML models. These techniques enhance the resilience of blockchain systems against adversarial attacks and safeguard sensitive data. However, implementing ML models in blockchain environments presents challenges, including scalability and cross-chain compatibility. The paper discusses these challenges and proposes solutions to overcome them, emphasizing the importance of integrating AML into blockchain security frameworks. Overall, the paper highlights the potential of AML in enhancing the security of blockchain networks and mitigating the evolving threats posed by malicious actors.},
  keywords={Training;Systematics;Scalability;Smart contracts;Generative adversarial networks;Adversarial machine learning;Blockchains;Adversarial Machine Learning;Blockchain Security;Artificial Intelligence;Distributed Ledger Technology},
  doi={10.1109/ISCS61804.2024.10581129},
  ISSN={},
  month={May},}@ARTICLE{8565906,
  author={Liu, Jinhai and Qu, Fuming and Hong, Xiaowei and Zhang, Huaguang},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={A Small-Sample Wind Turbine Fault Detection Method With Synthetic Fault Data Using Generative Adversarial Nets}, 
  year={2019},
  volume={15},
  number={7},
  pages={3877-3888},
  abstract={The limited fault information caused by small fault data samples is a major problem in wind turbine (WT) fault detection. This paper proposes a small-sample WT fault detection method with the synthetic fault data using generative adversarial nets (GANs). First, based on prior knowledge, a rough fault data generation process is developed to transform the normal data to the rough fault data. Second, a rough fault data refiner is developed by GANs to make the rough fault data more similar with the real fault data. Moreover, to make the generated data better suited to the WT conditions, GANs are improved in both the generative model and the discriminative model. Third, artificial intelligence (AI)-based WT fault detection models can be well trained by using only the generated data in the condition of small fault data sample. Finally, three groups of generated data evaluation experiments and four groups of WT fault detection comparative experiments are conducted using real WT data collected from a wind farm in northern China. The results indicate that the method proposed in this paper is effective.},
  keywords={Fault detection;Data models;Gallium nitride;Smoothing methods;Training;Wind turbines;Correlation;Fault detection;generative adversarial nets (GANs);small sample;supervisory control and data acquisition (SCADA) data;wind turbine (WT)},
  doi={10.1109/TII.2018.2885365},
  ISSN={1941-0050},
  month={July},}@INPROCEEDINGS{9433806,
  author={Yang, Yang and Chen, Jiancong and Wang, Ruixuan and Ma, Ting and Wang, Lingwei and Chen, Jie and Zheng, Wei-Shi and Zhang, Tong},
  booktitle={2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)}, 
  title={Towards Unbiased Covid-19 Lesion Localisation And Segmentation Via Weakly Supervised Learning}, 
  year={2021},
  volume={},
  number={},
  pages={1966-1970},
  abstract={Despite tremendous efforts, it is very challenging to generate a robust model to assist in the accurate quantification assessment of COVID-19 on chest CT images. Due to the nature of blurred boundaries, the supervised segmentation methods usually suffer from annotation biases. To support unbiased lesion localisation and to minimise the labelling costs, we propose a data-driven framework supervised by only image level labels. The framework can explicitly separate potential lesions from original images, with the help of an generative adversarial network and a lesion-specific decoder. Experiments on two COVID-19 datasets demonstrates the effectiveness of the proposed framework and its superior performance to several existing methods.},
  keywords={Location awareness;COVID-19;Image segmentation;Visualization;Computed tomography;Supervised learning;Lung;Weakly supervised learning;lesion localization and segmentation;GAN;CT;COVID-19},
  doi={10.1109/ISBI48211.2021.9433806},
  ISSN={1945-8452},
  month={April},}
