@ARTICLE{11123836,
  author={Chen, Min and Liu, Feixiang and Liang, Donggui and Zhong, Shuying and Li, Yunting},
  journal={IEEE Access}, 
  title={Entity Recognition for Power Equipment Data Based on Optional Word Vectors and Feature Fusion}, 
  year={2025},
  volume={13},
  number={},
  pages={143767-143780},
  abstract={Power equipment is an essential part of the power system. Regular inspection and maintenance of power equipment are of great significance. However, the existing entity recognition methods for power equipment data have certain limitations. Therefore, this paper introduces Continuous Bag of Words to optimize Convolutional Neural Network and Long Short-Term Memory network. Meanwhile, Variational Autoencoder is introduced to improve Conditional Generative Adversarial Network. These two methods are combined to form an algorithm that integrates textual data and image information features. On this basis, conditional random field is used for secondary optimization, and an intelligent recognition model is constructed. Its superiority and feasibility are verified by comparison with three traditional models. The results show that the proposed model achieves an accuracy of 96.8%, a recall of 97.6%, an average error of 0.11%, and a loss rate of 0.18%. In practical applications, the model achieves a recall of 97.6% and an Area Under the Curve value of 0.831. When facing different datasets, its average sensitivity reaches 97.6%. Comparative experiments also demonstrate its robustness and generalization ability. All experimental data and results outperform the three comparative models. In conclusion, the proposed model ensures the quality of power equipment data entity recognition and effectively improves recognition efficiency, making an important contribution to the healthy development of the power system in China.},
  keywords={Logic gates;Feature extraction;Vectors;Mathematical models;Long short term memory;Maintenance;Accuracy;Generators;Generative adversarial networks;Data models;Optional word vector;continuous bag of words model;feature fusion;variational autoencoder;power equipment;data recognition},
  doi={10.1109/ACCESS.2025.3598316},
  ISSN={2169-3536},
  month={},}@ARTICLE{9370004,
  author={Mulyadi, Ahmad Wisnu and Jun, Eunji and Suk, Heung-Il},
  journal={IEEE Transactions on Cybernetics}, 
  title={Uncertainty-Aware Variational-Recurrent Imputation Network for Clinical Time Series}, 
  year={2022},
  volume={52},
  number={9},
  pages={9684-9694},
  abstract={Electronic health records (EHR) consist of longitudinal clinical observations portrayed with sparsity, irregularity, and high dimensionality, which become major obstacles in drawing reliable downstream clinical outcomes. Although there exist great numbers of imputation methods to tackle these issues, most of them ignore correlated features, temporal dynamics, and entirely set aside the uncertainty. Since the missing value estimates involve the risk of being inaccurate, it is appropriate for the method to handle the less certain information differently than the reliable data. In that regard, we can use the uncertainties in estimating the missing values as the fidelity score to be further utilized to alleviate the risk of biased missing value estimates. In this work, we propose a novel variational-recurrent imputation network, which unifies an imputation and a prediction network by taking into account the correlated features, temporal dynamics, as well as uncertainty. Specifically, we leverage the deep generative model in the imputation, which is based on the distribution among variables, and a recurrent imputation network to exploit the temporal relations, in conjunction with utilization of the uncertainty. We validated the effectiveness of our proposed model on two publicly available real-world EHR datasets: 1) PhysioNet Challenge 2012 and 2) MIMIC-III, and compared the results with other competing state-of-the-art methods in the literature.},
  keywords={Uncertainty;Data models;Predictive models;Correlation;Task analysis;Stochastic processes;Time series analysis;Bioinformatics;deep generative model;deep learning;electronic health records (EHR);in-hospital mortality prediction;missing value imputation;time-series modeling;uncertainty},
  doi={10.1109/TCYB.2021.3053599},
  ISSN={2168-2275},
  month={Sep.},}@INPROCEEDINGS{10823063,
  author={Haifeng, Li and Lin, Niu and Nannan, Gao and Qinghua, Yin and Fengmin, Xing and Wenhua, Chai},
  booktitle={2024 6th International Conference on Artificial Intelligence and Computer Applications (ICAICA)}, 
  title={A Training Knowledge Base and System for the Principles of HVDC Systems in Converter Stations Based on Large Models}, 
  year={2024},
  volume={},
  number={},
  pages={78-82},
  abstract={In response to the training needs for the knowledge of HVDC systems in converter stations, a training knowledge base for the principles of HVDC systems in converter stations based on large models has been designed, integrating retrieval-enhanced generative technology to develop an online Q&A assistant for DC knowledge. Through personalized training and learning of DC operation and maintenance knowledge, not only is the level of intelligent knowledge of DC system principles improved, but new solutions are also provided for intelligent operation and maintenance and training in other vertical fields.},
  keywords={Training;HVDC transmission;Computational modeling;Interactive systems;Knowledge based systems;Natural languages;Knowledge graphs;Information retrieval;Data models;Maintenance;DC system knowledge training;Knowledge base;Online Q&A;Large model},
  doi={10.1109/ICAICA63239.2024.10823063},
  ISSN={2833-8413},
  month={Nov},}@ARTICLE{9727093,
  author={Cai, Qing and Li, Jinxing and Li, Huafeng and Yang, Yee-Hong and Wu, Feng and Zhang, David},
  journal={IEEE Transactions on Image Processing}, 
  title={TDPN: Texture and Detail-Preserving Network for Single Image Super-Resolution}, 
  year={2022},
  volume={31},
  number={},
  pages={2375-2389},
  abstract={Single image super-resolution (SISR) using deep convolutional neural networks (CNNs) achieves the state-of-the-art performance. Most existing SISR models mainly focus on pursuing high peak signal-to-noise ratio (PSNR) and neglect textures and details. As a result, the recovered images are often perceptually unpleasant. To address this issue, in this paper, we propose a texture and detail-preserving network (TDPN), which focuses not only on local region feature recovery but also on preserving textures and details. Specifically, the high-resolution image is recovered from its corresponding low-resolution input in two branches. First, a multi-reception field based branch is designed to let the network fully learn local region features by adaptively selecting local region features in different reception fields. Then, a texture and detail-learning branch supervised by the textures and details decomposed from the ground-truth high resolution image is proposed to provide additional textures and details for the super-resolution process to improve the perceptual quality. Finally, we introduce a gradient loss into the SISR field and define a novel hybrid loss to strengthen boundary information recovery and to avoid overly smooth boundary in the final recovered high-resolution image caused by using only the MAE loss. More importantly, the proposed method is model-agnostic, which can be applied to most off-the-shelf SISR networks. The experimental results on public datasets demonstrate the superiority of our TDPN on most state-of-the-art SISR methods in PSNR, SSIM and perceptual quality. We will share our code on https://github.com/tocaiqing/TDPN.},
  keywords={Visualization;Convolutional neural networks;Superresolution;Generative adversarial networks;Feature extraction;Convolution;Learning systems;Single image super-resolution (SISR);convolutional neural network (CNN);texture and detail-preserving network (TDPN);multi-branch network;multi-reception field module},
  doi={10.1109/TIP.2022.3154614},
  ISSN={1941-0042},
  month={},}@ARTICLE{10304171,
  author={Huang, Xunhua and Zhang, Fengbin and Wang, Ruidong and Lin, Xiaohui and Liu, Han and Fan, Haoyi},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={KalmanAE: Deep Embedding Optimized Kalman Filter for Time Series Anomaly Detection}, 
  year={2023},
  volume={72},
  number={},
  pages={1-11},
  abstract={The Kalman filter performs well in system state estimation by inferring a joint probability distribution over time variables, which has numerous technological applications in time series analysis. However, the complex Kalman filter parameter settings prevent it from optimally estimating the system state, and this suboptimal estimation makes it difficult to effectively distinguish between normal and anomalous system states in anomaly detection. In this article, we propose a deep embedding-optimized Kalman filter for unsupervised time series anomaly detection, where the system state of a normal time series can be fit by the embedding-optimized Kalman filter in an unsupervised manner and anomalies can be detected from data points that deviate from the normal system state. Specifically, we use an autoencoder-enhanced Kalman filter to capture the normal pattern of the time series, where the original time series signal is first fed into the Kalman filter, then the autoencoder encodes the filtered signal and reconstructs the original signal, and the learned embedding from the encoder is used to sequentially optimize the Kalman filter. Finally, the optimized filter captures the normal pattern of the time series, and the reconstruction error from the filtered signal can be measured to detect anomalies. The validity of the method is verified on real-world time series datasets.},
  keywords={Kalman filters;Anomaly detection;Time series analysis;Feature extraction;Deep learning;Neural networks;Generative adversarial networks;Anomaly detection;deep learning;Kalman filter;system state;time series},
  doi={10.1109/TIM.2023.3329098},
  ISSN={1557-9662},
  month={},}@INPROCEEDINGS{10866814,
  author={Kumar, Gautam},
  booktitle={2024 3rd Edition of IEEE Delhi Section Flagship Conference (DELCON)}, 
  title={A Doctor Assistance Tool: Personalized Healthcare Treatment Recommendations Journey from Deep Reinforcement Learning to Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={In personalized patient healthcare treatment recommendation, the goal is to recommend the most suitable course of treatment for an individual patient based on patient-specific data, including prior medical history, electronic health records (EHR), genetic information, lifestyle factors, and treatment outcomes. This study aims to extend the paradigm of personalized treatment recommendations from Deep Reinforcement Learning (DRL) to Generative Artificial Intelligence (GenAI). A DRL algorithm is employed to derive the best policy for personalized treatment recommendations. At the same time, the Med-PaLM-2 large language model (LLM) is used to generate diagnosis reports tailored to the individual patient. I propose a Personalized Treatment Healthcare Recommendation System (PTHRS), using a fine-tuned Med-PaLM-2 model on the Intensive Care Unit (ICU) dataset and the Medical Information Mart for Intensive Care (MIMIC-III) dataset. The system is designed to formulate the best treatment policies and generate clinical documentation, including discharge summaries, progress notes, customer care notes, treatments, healthcare, medication, doctor consultations, nutrition, exercise, and medical reports. These documents capture essential information and generate personalized recommendations for diagnosis and treatment plans. Experimental results prove that the model achieves an accuracy of 66%, a BLEU score of 0.66, and a clinical validation success rate of 80%, outperforming baseline DRL techniques in generating the best policies for personalized treatment recommendations.},
  keywords={Accuracy;Generative AI;Large language models;MIMICs;Medical services;Deep reinforcement learning;Genetics;History;Medical diagnostic imaging;Recommender systems;Personalized Treatment Healthcare Recommendation System (PTHRS);GenAI;LLMs;personalized patient treatment;drug discovery;deep reinforcement learning (DRL)},
  doi={10.1109/DELCON64804.2024.10866814},
  ISSN={},
  month={Nov},}@ARTICLE{10365143,
  author={Mubarak, Rami and Alsboui, Tariq and Alshaikh, Omar and Inuwa-Dutse, Isa and Khan, Saad and Parkinson, Simon},
  journal={IEEE Access}, 
  title={A Survey on the Detection and Impacts of Deepfakes in Visual, Audio, and Textual Formats}, 
  year={2023},
  volume={11},
  number={},
  pages={144497-144529},
  abstract={In the rapidly evolving digital landscape, the generation of fake visual, audio, and textual content poses a significant threat to the trust of society, political stability, and integrity of information. The generation process has been enhanced and simplified using Artificial Intelligence techniques, which have been termed deepfake. Although significant attention has been paid to visual and audio deepfakes, there is also a burgeoning need to consider text-based deepfakes. Due to advancements in natural language processing and large language models, the potential of manipulating textual content to reshape online discourse and misinformation has increased. This study comprehensively examines the multifaceted nature and impacts of deep-fake-generated media. This work explains the broad implications of deepfakes in social, political, economic, and technological domains. State-of-the-art detection methodologies for all types of deepfake are critically reviewed, highlighting the need for unified, real-time, adaptable, and generalised solutions. As the challenges posed by deepfakes intensify, this study underscores the importance of a holistic approach that integrates technical solutions with public awareness and legislative action. By providing a comprehensive overview and establishing a framework for future exploration, this study seeks to assist researchers, policymakers, and practitioners navigate the complexities of deepfake phenomena.},
  keywords={Deepfakes;Visualization;Surveys;Social networking (online);Deep learning;Generative adversarial networks;Audio systems;Text analysis;Deepfakes;visual;audio;text},
  doi={10.1109/ACCESS.2023.3344653},
  ISSN={2169-3536},
  month={},}@ARTICLE{9693527,
  author={Alsmadi, Izzat and Aljaafari, Nura and Nazzal, Mahmoud and Alhamed, Shadan and Sawalmeh, Ahmad H. and Vizcarra, Conrado P. and Khreishah, Abdallah and Anan, Muhammad and Algosaibi, Abdulelah and Al-Naeem, Mohammed Abdulaziz and Aldalbahi, Adel and Al-Humam, Abdulaziz},
  journal={IEEE Access}, 
  title={Adversarial Machine Learning in Text Processing: A Literature Survey}, 
  year={2022},
  volume={10},
  number={},
  pages={17043-17077},
  abstract={Machine learning algorithms represent the intelligence that controls many information systems and applications around us. As such, they are targeted by attackers to impact their decisions. Text created by machine learning algorithms has many types of applications, some of which can be considered malicious especially if there is an intention to present machine-generated text as human-generated. In this paper, we surveyed major subjects in adversarial machine learning for text processing applications. Unlike adversarial machine learning in images, text problems and applications are heterogeneous. Thus, each problem can have its own challenges. We focused on some of the evolving research areas such as: malicious versus genuine text generation metrics, defense against adversarial attacks, and text generation models and algorithms. Our study showed that as applications of text generation will continue to grow in the near future, the type and nature of attacks on those applications and their machine learning algorithms will continue to grow as well. Literature survey indicated an increasing trend in using pre-trained models in machine learning. Word/sentence embedding models and transformers are examples of those pre-trained models. Adversarial models may utilize same or similar pre-trained models as well. In another trend related to text generation models, literature showed effort to develop universal text perturbations to be used in both black-and white-box attack settings. Literature showed also using conditional GANs to create latent representation for writing types. This usage will allow for a seamless lexical and grammatical transition between various writing styles. In text generation metrics, research trends showed developing successful automated or semi-automated assessment metrics that may include human judgement. Literature showed also research trends of designing and developing new memory models that increase performance and memory utilization efficiency without validating real-time constraints. Many research efforts evaluate different defense model approaches and algorithms. Researchers evaluated different types of targeted attacks, and methods to distinguish human versus machine generated text.},
  keywords={Generators;Training;Security;Market research;Machine learning algorithms;Generative adversarial networks;Adversarial machine learning;Adversarial machine learning;generative adversarial networks;GAN;text generation},
  doi={10.1109/ACCESS.2022.3146405},
  ISSN={2169-3536},
  month={},}@ARTICLE{9410550,
  author={Lee, Hyunhee and Kim, Gyeongmin and Hur, Yuna and Lim, Heuiseok},
  journal={IEEE Access}, 
  title={Visual Thinking of Neural Networks: Interactive Text to Image Synthesis}, 
  year={2021},
  volume={9},
  number={},
  pages={64510-64523},
  abstract={Reasoning, a trait of cognitive intelligence, is regarded as a crucial ability that distinguishes humans from other species. However, neural networks now pose a challenge to this human ability. Text-to-image synthesis is a class of vision and linguistics, wherein the goal is to learn multimodal representations between the image and text features. Hence, it requires a high-level reasoning ability that understands the relationships between objects in the given text and generates high-quality images based on the understanding. Text-to-image translation can be termed as the visual thinking of neural networks. In this study, our model infers the complicated relationships between objects in the given text and generates the final image by leveraging the previous history. We define diverse novel adversarial loss functions and finally demonstrate the best one that elevates the reasoning ability of the text-to-image synthesis. Remarkably, most of our models possess their own reasoning ability. Quantitative and qualitative comparisons with several methods demonstrate the superiority of our approach.},
  keywords={Cognition;Visualization;Neural networks;Generative adversarial networks;Image synthesis;Image registration;Text recognition;Generative adversarial networks;image generation;multimodal learning;multimodal representation;text-to-image synthesis},
  doi={10.1109/ACCESS.2021.3074973},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10215856,
  author={Lee, Hyeon Joon and Simo-Serra, Edgar},
  booktitle={2023 18th International Conference on Machine Vision and Applications (MVA)}, 
  title={Using Unconditional Diffusion Models in Level Generation for Super Mario Bros}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={This study introduces a novel methodology for generating levels in the iconic video game Super Mario Bros. using a diffusion model based on a UNet architecture. The model is trained on existing levels, represented as a categorical distribution, to accurately capture the game’s fundamental mechanics and design principles. The proposed approach demonstrates notable success in producing high-quality and diverse levels, with a significant proportion being playable by an artificial agent. This research emphasizes the potential of diffusion models as an eﬃcient tool for procedural content generation and highlights their potential impact on the development of new video games and the enhancement of existing games through generated content.},
  keywords={Video games;Machine vision;Games},
  doi={10.23919/MVA57639.2023.10215856},
  ISSN={},
  month={July},}@INPROCEEDINGS{9010824,
  author={Aumentado-Armstrong, Tristan and Tsogkas, Stavros and Jepson, Allan and Dickinson, Sven},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Geometric Disentanglement for Generative Latent Shape Models}, 
  year={2019},
  volume={},
  number={},
  pages={8180-8189},
  abstract={Representing 3D shapes is a fundamental problem in artificial intelligence, which has numerous applications within computer vision and graphics. One avenue that has recently begun to be explored is the use of latent representations of generative models. However, it remains an open problem to learn a generative model of shapes that is interpretable and easily manipulated, particularly in the absence of supervised labels. In this paper, we propose an unsupervised approach to partitioning the latent space of a variational autoencoder for 3D point clouds in a natural way, using only geometric information, that builds upon prior work utilizing generative adversarial models of point sets. Our method makes use of tools from spectral geometry to separate intrinsic and extrinsic shape information, and then considers several hierarchical disentanglement penalties for dividing the latent space in this manner. We also propose a novel disentanglement penalty that penalizes the predicted change in the latent representation of the output,with respect to the latent variables of the initial shape. We show that the resulting latent representation exhibits intuitive and interpretable behaviour, enabling tasks such as pose transfer that cannot easily be performed by models with an entangled representation.},
  keywords={Shape;Three-dimensional displays;Computational modeling;Quaternions;Task analysis;Gallium nitride;Geometry},
  doi={10.1109/ICCV.2019.00827},
  ISSN={2380-7504},
  month={Oct},}@INPROCEEDINGS{10585687,
  author={Joshi, Chiragee C. and Payyavula, Jaya S. S. K. and Patel, Soham and Alginahi, Yasser M.},
  booktitle={2024 IEEE 3rd International Conference on Computing and Machine Intelligence (ICMI)}, 
  title={ML-Based Wildfire Prediction and Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper provides a comprehensive study on prediction and detection of wildfire using Machine Learning and Deep Learning algorithms. Due to the current environmental trends, wildfire possess a great threat to the ecosystem and human lives at a great cost. Multiple factors are the root cause for wildfires which include environmental factors like temperature, humidity, air pressure index, forest terranean, vegetation. Taking these factors into consideration, a Machine Learning model was built considering diverse algorithms to learn the previous trends and predict future wildfires instances. Based on the satellite imagery of previous wildfires, using CNN and AlexNet algorithms to detect wildfires that are currently taking place for early detection so to contain and control the fire without it causing any damage. Amalgamating these two algorithms, in a single graphical user interface, enhances user accessibility and convenience, providing an invaluable tool in wildfire management. The algorithm achieved an accuracy of average 96.33 % to predict wildfires and was able to detect them based on images at the rate of 93.66%.},
  keywords={Temperature sensors;Wildfires;Machine learning algorithms;Accuracy;Prediction algorithms;Market research;Data models;Convolutional Neural Networks;Deep Learning (DL);Machine Learning (ML);Wildfire Detection},
  doi={10.1109/ICMI60790.2024.10585687},
  ISSN={},
  month={April},}@ARTICLE{10711944,
  author={Li, Shuying and Ren, Chao and Qin, Yuemei and Li, Qiang},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Semantic-Explicit Filtering Network for Remote Sensing Image Change Detection}, 
  year={2024},
  volume={62},
  number={},
  pages={1-11},
  abstract={Remote sensing image change detection (RSI-CD) aims to explore surface change information from aligned dual-phase images. However, RSI-CD currently encounters two major challenges. The first issue is the inadequate object-level semantic representation during the feature extraction in CD networks. The other issue is the spectral resolution of the RS image is limited, which leads to a mixture of pseudochange and real change. In order to explore the above-mentioned two challenges, we propose a semantic-explicit filtering network (SFNet) based on a neighborhood feature attention module (NFAM) and multiple-receptive-field semantic filtering mechanism (MSFM). First, the NFAM exploits the correlation of multiscale features and fuses features from the proximity layer to enhance the semantic-explicit representation of the object level. Then, the MSFM takes the weight map after the enhanced semantic representation as input and progressively refines the weight map through a multiple-receptive-field parallel convolution (MPC). This process filters out pseudochange from the predicted result while retaining the real-change information. The experiments on two benchmark datasets demonstrate that the proposed approach presents satisfactory performance over the existing methods.},
  keywords={Feature extraction;Semantics;Filtering;Attention mechanisms;Remote sensing;Convolutional neural networks;Decoding;Accuracy;Telecommunications;Measurement;Change detection (CD);multiple receptive field (RF);neighborhood feature attention;remote sensing (RS)},
  doi={10.1109/TGRS.2024.3476992},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{10311812,
  author={Liu, Xinpeng and Du, Xiaocong and Yang, Xianqiang and Cai, Chao},
  booktitle={IECON 2023- 49th Annual Conference of the IEEE Industrial Electronics Society}, 
  title={Improved Stochastic Recurrent Networks for Nonlinear State Space System Identification}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents an improved version of the stochastic recurrent networks (STORN) for identification of non-linear state space systems with more complex model structures, including long short-term memory network (LSTM) and bidirectional gated recurrent unit (BiGRU). Both LSTM and BiGRU are recurrent neural networks with multiple state variables, which can store different information in the modeling of sequential data. Applying such a priori information into the prediction of data distribution can lead to better model performance. In this paper, several information fusion techniques are compared, and the effectiveness of the method is verified on three benchmark identification datasets. Our model outperforms the state-of-the-art baseline by 0.3 percent with 8 times fewer parameters.},
  keywords={Industrial electronics;Recurrent neural networks;Stochastic processes;Logic gates;Benchmark testing;Predictive models;Size measurement;Nonlinear state space system identification;re-current networks;long short-term memory network (LSTM);bidirectional gated recurrent unit network (BiGRU)},
  doi={10.1109/IECON51785.2023.10311812},
  ISSN={2577-1647},
  month={Oct},}@INPROCEEDINGS{10397938,
  author={Quadir, Munleef and Agrawal, Prateek and Gupta, Charu},
  booktitle={2023 6th International Conference on Contemporary Computing and Informatics (IC3I)}, 
  title={A Comparative Analysis of Deepfake Detection Techniques: A Review}, 
  year={2023},
  volume={6},
  number={},
  pages={1035-1041},
  abstract={Every person in this new generation has access to all of humanity's wisdom. Many technological possibilities are available. Nonetheless, we misuse this benefit by using deepfake for face swap. The deep fake method of machine learning, which is popular on social media, superimposes one person's face over another person's face. Deep learning, which has allowed researchers to produce deepfake images and videos considerably more rapidly and affordably, is the main ingredient in deepfakes. Even though the word “deepfakes” has a terrible image, more people are using the technology privately and practically. Although it is still fairly new, recent technological advancements have made it more difficult to tell the difference between deep fakes and synthetic images. Deepfake technology is evolving, and there is rising unease. The analysis of deep fakes has already been done by a number of researchers utilizing techniques like GAN, Convolution Neural Network with or without LSTM, Support Vector Machine, and Machine Learning. This paper analyzes the many techniques that have been used by researchers to identify Deepfake videos and rates the performance of multiple Deepfake video detection systems. According to our analysis, integrating CNN and the LSTM together produces superior outcomes and accuracy, which could also be improved by applying the concept of image enhancement.},
  keywords={Deep learning;Surveys;Deepfakes;Social networking (online);Films;Motion pictures;Faces;Artificial Intelligence;Deepfake;Generative Adversarial Networks;LSTM;Security},
  doi={10.1109/IC3I59117.2023.10397938},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9653432,
  author={Islam, Khawar and Lee, Sujin and Han, Dongil and Moon, Hyeonjoon},
  booktitle={2021 36th International Conference on Image and Vision Computing New Zealand (IVCNZ)}, 
  title={Face Recognition Using Shallow Age-Invariant Data}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Face aging is a challenging research area in face recognition and verification. However, recognizing identical faces with an immense age gap gives rise to various difficulties because of the diversity in face appearance caused by aging. In real-world applications, the pre-training dataset is very limited (e.g only two age-invariant face images) are present for each identity. We define this term as Shallow Age-Invariant Face Learning, and find it difficult with existing methods. Different from large-scale and shallow face data, the age-invariant dataset is lacking intra-class distance. Thus, mostly face recognition algorithms are collapsed, feature dimensions easily gets into over-fitting and degeneration problems. To examine such discrepancies and evaluate recent state-of-the-art methods (SOTA), we investigate the performance of SOTA models on different metrics learning approaches. Further, we re-organize three age-invariant datasets into negative and positive pairs with a mixed interval of ages. We select the face aging dataset (FG-NET) to cover all age groups with aging and occlusion, the longitudinal dataset (MORPH-Album 2) for illumination and low-resolution, and the age database (Age-DB) for pose and noise. Although for major factors, Arc-Face and Face-Net outperform others. Another interesting finding of our research, the training performance on age-invariant pairs is still saturated with a clear margin. This research provides further directions for future research and insights.},
  keywords={Training;Measurement;Computer vision;Databases;Face recognition;Computational modeling;Lighting},
  doi={10.1109/IVCNZ54163.2021.9653432},
  ISSN={2151-2205},
  month={Dec},}@INPROCEEDINGS{10318477,
  author={Chen, Jinghang and Zhang, Chi and Feng, Xiaodan and Liu, Yuehu},
  booktitle={2023 IEEE International Conference on Unmanned Systems (ICUS)}, 
  title={Text-Guided Image Generation for Railway Intrusion Anomaly Detection}, 
  year={2023},
  volume={},
  number={},
  pages={1481-1486},
  abstract={Railway intrusion are characterized by strong suddenness, high unpredictability and many disturbing factors, which are key factors affecting railway safety. Currently, the deep neural network-based intrusion object detection algorithm relies on the diversity of training data. However, the data of railway intrusion image is scarce and difficult to obtain. Existing image generation methods face the problem of insufficient realism in the generated images and difficulty in generating large amounts of data. We aim to explore a text-guided image data generation framework for specific visual tasks by using an existing large language model combined with a text-to-image diffusion model. In this paper, we construct a framework for railway intrusion image generation guided by textual prompts and build a dataset of railway intrusion images based on this framework. The dataset generated in this paper contains a wide range of intrusion images and includes a variety of environmental factors such as weather and time, which provides better diversity than existing datasets. The evaluation results show that the intrusion images generated in this paper have high quality and realism.},
  keywords={Visualization;Image synthesis;Diversity reception;Natural languages;Training data;Railway safety;Object detection;railway intrusion anomaly detection;conditional generative learning;conditional diffusion models;large natural language models;cross-attention mechanisms},
  doi={10.1109/ICUS58632.2023.10318477},
  ISSN={2771-7372},
  month={Oct},}@ARTICLE{10225329,
  author={Kang, Seoungyoon and Kim, Minjae and Shim, Hyunjung},
  journal={IEEE Access}, 
  title={F2RPC: Fake to Real Portrait Control From a Virtual Character}, 
  year={2023},
  volume={11},
  number={},
  pages={92120-92134},
  abstract={Existing methods for generating virtual character videos focus on improving either appearance or motion. However, achieving both photo- and motion-realistic characters is critical in real services. To address both aspects, we propose Fake to Real Portrait Control (F2RPC), a unified framework for image destylization and face reenactment. F2RPC employs a blind face restoration model to circumvent GAN inversion limitations, such as identity loss and alignment sensitivity, while preserving GAN’s generation quality. This framework includes two novel sub-modules: AdaGPEN for destylization and PCGPEN for reenactment, both leveraging the same restoration model as a backbone. AdaGPEN exploits GAN prior of the restoration model via blending features from the original and its blurred image using the AdaMix block. PCGPEN reenacts the input image to follow the input motion condition via flow-based feature editing. These components function in an end-to-end manner, enhancing efficiency and lowering computational overhead. We evaluate F2RPC using synthetic character dataset and high-resolution talking face datasets for destylization and reenactment, respectively. The results show that F2RPC outperforms the combined use of state-of-the-art methods for destylization (i.e., DualStyleGAN) and reenactment (i.e., StyleHEAT). F2RPC improves the FID by 26.4% and preserves identity similarity by 95% more at a resolution of  $512\times 512$  video. This evidences F2RPC’s efficacy and superiority in the photo- and motion-realistic virtual character video generation task.},
  keywords={Videos;Image restoration;Three-dimensional displays;Generative adversarial networks;Cloning;Task analysis;Face detection;Morphological operations;Face morphing;facial reenactment;generative adversarial networks;virtual character destylization},
  doi={10.1109/ACCESS.2023.3306836},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10446285,
  author={Liu, Yongqi and Zhou, Jiashuang and Du, Xiaoqin},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Human Motion Generation via Conditioned GMVAE with TUNet}, 
  year={2024},
  volume={},
  number={},
  pages={6140-6144},
  abstract={In recent years, Variational Autoencoders (VAEs) have been proposed for motion synthesis to model action-label-conditioned human motion. However, these approaches only use Gaussian distribution as a prior assumption, this hard constraint might be too restrictive for the latent space and hurt the performance of the model. To address the issues, we model the latent space as a Gaussian mixture distribution and derive a new evidence lower bound (ELBO). Furthermore, to enhance the expressiveness of the model, we introduce Fisher discriminant as a regularization. We develop the attention mechanism and enable the Transformer-based U-Net to generate motions that correspond to semantic information only using action labels. The proposed CGMVAE-TU model has been evaluated on various datasets, and it surpasses the SOTA on almost all metrics. The generated human motions are realistic and natural.},
  keywords={Training;Measurement;Semantics;Aerospace electronics;Signal processing;Gaussian distribution;Transformers;generative model;human motion generation;action-label-conditioned synthesis;GMVAE},
  doi={10.1109/ICASSP48485.2024.10446285},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10218053,
  author={Liu, Yunhao and Zhong, Songyi and Li, Zhenglin and Zhou, Yang},
  booktitle={2023 IEEE Symposium on Computers and Communications (ISCC)}, 
  title={Contrastive Learning with Attention Mechanism and Multi-Scale Sample Network for Unpaired Image-to-Image Translation}, 
  year={2023},
  volume={},
  number={},
  pages={1335-1339},
  abstract={The aim of unpaired image translation is to learn how to transform images from a source to a target domain, while preserving as many domain-invariant features as possible. Previous methods have not been able to separate foreground and background well, resulting in texture being added to the background. Moreover, these methods often fail to distinguish different objects or different parts of the same object. In this paper, we propose an attention-based generator (AG) that can redistribute the weights of visual features, significantly enhancing the network's performance in separating foreground and background. We also embed a multi-scale multilayer perceptron (MSMLP) into the framework to capture features across a broader range of scales, which improves the discrimination of various parts of objects. Our method outperforms existing methods on various datasets in terms of Fréchet inception distance. We further analyze the impact of different modules in our approach through subsequent ablation experiments.},
  keywords={Computers;Visualization;Computational modeling;Transforms;Multilayer perceptrons;Generators;Task analysis;image translation;Attention mechanism;Contrastive Learning;Generative Adversarial Networks;Multi-scale Sample},
  doi={10.1109/ISCC58397.2023.10218053},
  ISSN={2642-7389},
  month={July},}@ARTICLE{10021250,
  author={Qiao, Yuanyuan and Yin, Jiaxin and Wang, Wei and Duarte, Fábio and Yang, Jie and Ratti, Carlo},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Survey of Deep Learning for Autonomous Surface Vehicles in Marine Environments}, 
  year={2023},
  volume={24},
  number={4},
  pages={3678-3701},
  abstract={Within the next several years, there will be a high level of autonomous technology that will be available for widespread use, which will reduce labor costs, increase safety, save energy, enable difficult unmanned tasks in harsh environments, and eliminate human error. Compared to software development for other autonomous vehicles, maritime software development, especially in aging but still functional fleets, is described as being in a very early and emerging phase. This presents great challenges and opportunities for researchers and engineers to develop maritime autonomous systems. Recent progress in sensor and communication technology has introduced the use of autonomous surface vehicles (ASVs) in applications such as coastline surveillance, oceanographic observation, multi-vehicle cooperation, and search and rescue missions. Advanced artificial intelligence technology, especially deep learning (DL) methods that conduct nonlinear mapping with self-learning representations, has brought the concept of full autonomy one step closer to reality. This article reviews existing work on the implementation of DL methods in fields related to ASV. First, the scope of this work is described after reviewing surveys on ASV developments and technologies, which draws attention to the research gap between DL and maritime operations. Then, DL-based navigation, guidance, control (NGC) systems and cooperative operations are presented. Finally, this survey is completed by highlighting current challenges and future research directions.},
  keywords={Sensors;Sea surface;Sensor systems;Marine vehicles;Control systems;Deep learning;Task analysis;Autonomous surface vehicle;deep learning;NGC system;intelligent autonomous systems;neural network},
  doi={10.1109/TITS.2023.3235911},
  ISSN={1558-0016},
  month={April},}@ARTICLE{9905704,
  author={Zhang, Yukun and Qiu, Shuang and Wei, Wei and Ma, Xuelin and He, Huiguang},
  journal={IEEE Transactions on Cognitive and Developmental Systems}, 
  title={Dynamic Weighted Filter Bank Domain Adaptation for Motor Imagery Brain–Computer Interfaces}, 
  year={2023},
  volume={15},
  number={3},
  pages={1348-1359},
  abstract={A motor imagery (MI)-based brain–computer interface (BCI) is a promising system that can help neuromuscular injury patients recover or replace their motor abilities. Currently, before one uses MI-BCI, we need to collect a large amount of training data to train the decoding model, and this process is time consuming. When trained with a small amount of data, existing decoding methods generally do not perform well in MI decoding tasks. Therefore, it is important to improve the decoding performance with short calibration data. In this study, we propose a dynamic weighted filter bank domain adaptation framework that uses data from an existing subject to reduce the requirement of data from the new subject. A filter bank is used to explore information from different frequency subbands. A feature extractor with two 1-D convolutional layers is designed to extract electroencephalography features. The class-specific Wasserstein generative adversarial network (WGAN)-based domain adaptation network aligns the distribution of each class between the data from the new subject and the data from the existing subject. Additionally, we apply an attention network to dynamically allocate different weights for different frequency bands. We evaluate our method on a public MI data set and a self-collected data set. The experimental results show that the proposed method achieves the best decoding accuracy among the compared methods with different amounts of training data. On the public data set, our method achieves 8.88% and 7.16% higher decoding accuracy than the best comparing method with one block of training data on the two sessions, respectively. This indicates that our method can enhance MI decoding accuracy with a small amount of training data.},
  keywords={Decoding;Feature extraction;Electroencephalography;Brain modeling;Task analysis;Filter banks;Convolution;Attention network;brain–computer interface (BCI);domain adaptation;filter bank;motor imagery (MI)},
  doi={10.1109/TCDS.2022.3209801},
  ISSN={2379-8939},
  month={Sep.},}@INPROCEEDINGS{10331449,
  author={Reddy, Regatte Varshith and Nethi, Anish and Sukhija, Sanatan and Gupta, Yayati},
  booktitle={2023 International Conference on Emerging Techniques in Computational Intelligence (ICETCI)}, 
  title={Detecting DeepFakes: A Deep Convolutional Neural Network Approach with Depth Wise Separable Convolutions}, 
  year={2023},
  volume={},
  number={},
  pages={33-38},
  abstract={This paper presents a deep learning based approach for detecting deepfake images and videos. With the rise of free and easily accessible software tools, such as GANs, creating deep-fakes has become effortless. However, detecting these deepfakes has proven to be a significant challenge. Our method uses a deep convolutional neural network architecture that involves depth-wise separable convolutions to classify whether an image or video is real or fake. We trained and evaluated our model on the CelebDF V2 dataset, achieving high accuracy rates of 98.8% and 97.4% for image and video classification, respectively. Our work is a significant contribution towards mitigating the spread of deepfakes, and we plan to expand our research to detect AI-generated audio in future work. We also propose the development of an online browser extension to make our detection method accessible to the general public and to integrate it into various social media and messaging platforms to prevent the spread of deepfakes.},
  keywords={Deep learning;Deepfakes;Social networking (online);Computational modeling;Computer architecture;Predictive models;Media;deepfakes;generative adversarial networks (GANs);computer vision;machine learning;artificial intelligence;image and video manipulation;misinformation and disinformation;social media},
  doi={10.1109/ICETCI58599.2023.10331449},
  ISSN={},
  month={Sep.},}@ARTICLE{10374121,
  author={Aboutalebi, Hossein and Shafiee, Mohammad Javad and Tai, Chi-En Amy and Wong, Alexander},
  journal={IEEE Access}, 
  title={Knowing is Half the Battle: Enhancing Clean Data Accuracy of Adversarial Robust Deep Neural Networks via Dual-Model Bounded Divergence Gating}, 
  year={2024},
  volume={12},
  number={},
  pages={48174-48188},
  abstract={Significant advances have been made in recent years in improving the robustness of deep neural networks, particularly under adversarial machine learning scenarios where the data has been contaminated to fool networks into making undesirable predictions. However, such improvements in adversarial robustness has often come at a significant cost in model accuracy when dealing with uncontaminated data (i.e., clean data), making such defense mechanisms challenging to adapt for real-world practical scenarios where data is primarily clean and accuracy needs to be high. Motivated to find a better balance between adversarial robustness and clean data accuracy, we propose a new model-agnostic adversarial defense mechanism named Dual-model Bounded Divergence (DBD), driven by a theoretical and empirical analysis of the bias-variance trade-off within an adversarial machine learning context. More specifically, the proposed DBD mechanism is premised on the observation that the variance in deep neural networks tends to increase in the presence of adversarial perturbations in the input data. As such, DBD employs a gating mechanism to decide on the final model prediction output based on a novel dual-model variance measure (coined DBD Variance), which is a bounded version of KL-Divergence between models. Not only is the proposed DBD mechanism itself training-free, but it can be combined with existing adversarial defense mechanisms to boost the balance between clean data accuracy and adversarial robustness. Comprehensive experimental results across over 10 different state-of-the-art adversarial defense mechanisms using both CIFAR-10 and ImageNet benchmark datasets across different adversarial attacks (e.g., APGD, AutoAttack) demonstrates that the integration of DBD can lead to as much as a 6% improvement on clean data accuracy without compromising much on adversarial robustness.},
  keywords={Computational modeling;Data models;Training;Perturbation methods;Mathematical models;Artificial neural networks;Solid modeling;Adversarial attack;computer vision;deep learning;neural networks},
  doi={10.1109/ACCESS.2023.3347498},
  ISSN={2169-3536},
  month={},}@ARTICLE{10838596,
  author={Ping, Jingyi and Ming, Zhongxing and Cui, Laizhong},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={RAPID: Retrieval and Predictability for Improved Stable Diffusion}, 
  year={2025},
  volume={11},
  number={2},
  pages={1091-1102},
  abstract={Latent Diffusion Models (LDM) have emerged as a prominent approach within the broader field of generative AI, particularly for consumer-level image generation tasks. These models enable efficient inference of Diffusion Models (DM) by leveraging latent space representations, reducing computational requirements while preserving output quality and flexibility. Advanced sampling algorithms further enhance inference speed and quality, enabling large-scale, low-latency image generation services. However, image generation inference remains time-consuming, and there is no specialized scheduling system in the domain of large-scale image generation models to ensure high resource utilization and latency guarantees. To address this, we introduce a two-stage method of saving intermediate samples, which helps to bypass initial sampling steps and accelerates image generation time. To provide predictable and high-utilization services for large-scale image generation requests, we conduct an in-depth analysis of the LDM structure and find that the response computation time is highly predictable. We further propose RAPID, an online acceleration scheduling framework designed for LDM-based networking request services. RAPID effectively reduces latency and optimizes load balancing across heterogeneous GPUs through precise computation scheduling tailored to specific GPUs. Extensive experiments indicate that RAPID achieves a ~37% increase in inference speed in multi-GPU high-concurrency environments.},
  keywords={Image synthesis;Diffusion models;Computational modeling;Predictive models;Generative AI;Analytical models;Time factors;Noise reduction;Gaussian noise;Scheduling;Latent diffusion model;serving;scheduling;optimization},
  doi={10.1109/TCCN.2025.3528895},
  ISSN={2332-7731},
  month={April},}@ARTICLE{10158032,
  author={Cheng, Zhihao and Shen, Li and Zhu, Miaoxi and Guo, Jiaxian and Fang, Meng and Liu, Liu and Du, Bo and Tao, Dacheng},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Prescribed Safety Performance Imitation Learning From a Single Expert Dataset}, 
  year={2023},
  volume={45},
  number={10},
  pages={12236-12249},
  abstract={Existing safe imitation learning (safe IL) methods mainly focus on learning safe policies that are similar to expert ones, but may fail in applications requiring different safety constraints. In this paper, we propose the Lagrangian Generative Adversarial Imitation Learning (LGAIL) algorithm, which can adaptively learn safe policies from a single expert dataset under diverse prescribed safety constraints. To achieve this, we augment GAIL with safety constraints and then relax it as an unconstrained optimization problem by utilizing a Lagrange multiplier. The Lagrange multiplier enables explicit consideration of the safety and is dynamically adjusted to balance the imitation and safety performance during training. Then, we apply a two-stage optimization framework to solve LGAIL: (1) a discriminator is optimized to measure the similarity between the agent-generated data and the expert ones; (2) forward reinforcement learning is employed to improve the similarity while considering safety concerns enabled by a Lagrange multiplier. Furthermore, theoretical analyses on the convergence and safety of LGAIL demonstrate its capability of adaptively learning a safe policy given prescribed safety constraints. At last, extensive experiments in OpenAI Safety Gym conclude the effectiveness of our approach.},
  keywords={Safety;Task analysis;Optimization;Costs;Reinforcement learning;Standards;Robots;Imitation learning;safe imitation learning;inverse reinforcement learning;generative adversarial imitation;Lagrange multiplier},
  doi={10.1109/TPAMI.2023.3287908},
  ISSN={1939-3539},
  month={Oct},}@INPROCEEDINGS{10883903,
  author={Komarchesqui, Mateus and Lent, Daniel Matheus Brandão and Da Silva Ruffo, Vitor Gabriel and Carvalho, Luiz Fernando and Lloret, Jaime and Proenca, Mario Lemes},
  booktitle={2024 11th International Conference on Software Defined Systems (SDS)}, 
  title={Explainable AI Feature Selection in Generative Adversarial Networks System aiming to detect DDoS Attacks}, 
  year={2024},
  volume={},
  number={},
  pages={27-34},
  abstract={With the rapid expansion of global networks and the proliferation of IoT devices, the complexity and scale of traffic have grown exponentially. This surge in connectivity demands larger, faster, and more serviceable architectures, like Software Defined Networks (SDNs). Motivated by various interests, malicious agents seek to compromise services within the network with different attacks. Intrusion Detection Systems (IDSs) are solutions often implemented in SDN using Deep Learning algorithms. These methods are more challenging to explain as they grow in complexity and become less trustworthy for handling sensitive issues like cyber security. This work uses SHapley Additive exPlanations (SHAP) to explain a consolidated IDS that combines Gated Recurrent Units (GRU) with Generative Adversarial Network’s discriminator. We conducted a feature selection based on the SHAP explanation and used its insights to better tune the time series’s window size hyperparameter. The optimized model performed similarly to the original, with a margin for improvement upon further hyperparameter tuning. It was also more stable in the training phase and faster to execute. This new version of the model was also explained by SHAP and presented a more consistent behavior.},
  keywords={Training;Computational modeling;Closed box;Telecommunication traffic;Feature extraction;Entropy;Complexity theory;Surges;Tuning;Optimization;XAI;GAN;SDN;DDoS;SHAP;IDS},
  doi={10.1109/SDS64317.2024.10883903},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10873153,
  author={Hao, Yu and Jiang, Wanjun and Xu, Qian},
  booktitle={2024 International Seminar on Artificial Intelligence, Computer Technology and Control Engineering (ACTCE)}, 
  title={Analysis of Data-Free Extraction Models Based on Deep Neural Networks}, 
  year={2024},
  volume={},
  number={},
  pages={402-406},
  abstract={Knowledge distillation is an effective method for compressing deep neural networks. However, in many cases, people are unable to access the raw data due to restrictions on user data privacy, data confidentiality, or data transmission. Existing data-free knowledge distillation methods only use a single teacher model for biased feature statistics, resulting in diversity and poor generalization compared to the original data. As a solution to this problem, this paper proposes a generative deep contrastive inversion algorithm that trains an image generator solely through pre-trained models to generate samples of old classes, enabling data acquisition in data-free scenarios. This algorithm improves discrimination among samples of the same class by introducing additional discriminators to assess and penalize the similarity between reconstructed data. It mitigates the issue of single-styled image reconstruction in existing deep inversion techniques and further enhances the knowledge transfer capability of reconstructed data. For various data-free knowledge distillation tasks, training the image generator once is sufficient for generalization across different model training scenarios.},
  keywords={Training;Knowledge engineering;Seminars;Analytical models;Data privacy;Artificial neural networks;Generators;Data models;Image reconstruction;Knowledge transfer;knowledge distillation;feature statistics;image reconstruction},
  doi={10.1109/ACTCE65085.2024.00087},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10581722,
  author={Xin, Diye},
  booktitle={2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={Advancements in High-Resolution Style Transfer: Unveiling the Precision-Enhanced-Cycle-GAN}, 
  year={2024},
  volume={},
  number={},
  pages={1353-1361},
  abstract={As Cycle-Consistent Generative Adversarial Networks enables style transfer between two distinct domains using unpaired data, allowing affective image-to-image transformation in scenarios lacking direct corresponding datasets. Sometimes, the low accuracy of the generated images, the requirement of the real-time processing and the single style of synthesis are questions. We demonstrate a new approach which can raise the accuracy of the Cycle-GANs called Precision-Enhanced-Cycle-GAN (PEC-GAN), intends to optimize the process of the style transference while preserving the content integrity of the original image. The new network structure introduces an image matching mechanism at the output layer, using an evolution function to detect some low-quality generated samples and leave high-quality samples for the next training step. Additionally, we introduce an encoding mechanism to make artificial images with various kinds of style. Through improved network architecture and training strategies, our method demonstrates advantages in processing high-resolution images, while also being able to adapt to a wider range of artistic styles. The experimental results show that this method can obtain target images faster than traditional style transfer techniques while also maintaining real-time processing capabilities, demonstrating technological progress and application potential.},
  keywords={Training;Seminars;Accuracy;Image coding;Image matching;Network architecture;Generative adversarial networks;Cycle-GAN;Style-Transfer;High-Resolution;Image-Encoding Mechanism;Threshold Loss Function},
  doi={10.1109/AINIT61980.2024.10581722},
  ISSN={},
  month={March},}@ARTICLE{10815956,
  author={Iwai, Shoma and Miyazaki, Tomo and Omachi, Shinichiro},
  journal={IEEE Access}, 
  title={Dual-Conditioned Training to Exploit Pre-Trained Codebook-Based Generative Model in Image Compression}, 
  year={2024},
  volume={12},
  number={},
  pages={198184-198200},
  abstract={Learned image compression (LIC) is increasingly gaining attention. To improve the perceptual quality of reconstructions, generative LIC has been studied, using generative models such as Generative Adversarial Networks (GANs). State-of-the-art generative LIC methods have achieved remarkable performance even in low bit rate settings. Unlike most approaches trained from scratch, we propose a generative LIC that utilizes a pre-trained codebook-based generative model, Vector-Quantized GAN (VQGAN). Specifically, our model is designed to exploit its powerful image-generation capabilities to enhance compression performance. Our approach reconstructs an image from a transmitted bitstream in two steps: (1) estimating VQGAN tokens and feeding them into the pre-trained VQGAN decoder, and (2) modifying the decoder’s intermediate features to address artifacts and distortions. Our preliminary experiments reveal that the information allocation between (1) and (2) is pivotal for reconstruction quality. Moreover, we found that the ideal allocation varies based on the target bit rate. Motivated by these findings, we propose a novel Dual-Conditioned training. Through the training, the model learns to adjust the total bit rate and information allocation between (1) and (2) based on two conditional inputs. Subsequently, we explore the conditional inputs to achieve the optimal results for each target bit rate. This training strategy enables us to effectively exploit the generation capability of VQGAN across different bit rates. Our method, named Dual Conditioned VQGAN-based Image Compression (DC-VIC), outperforms state-of-the-art generative LIC methods in rate-distortion-perception performance. Code will be available at https://github.com/iwa-shi/DC_VIC},
  keywords={Image coding;Decoding;Image reconstruction;Training;Bit rate;Entropy;Estimation;Resource management;Distortion;Transforms;Generative adversarial networks;image compression;VQGAN},
  doi={10.1109/ACCESS.2024.3522238},
  ISSN={2169-3536},
  month={},}@ARTICLE{9502126,
  author={Chaudhury, Subhajit and Roy, Hiya and Mishra, Sourav and Yamasaki, Toshihiko},
  journal={IEEE Access}, 
  title={Adversarial Training Time Attack Against Discriminative and Generative Convolutional Models}, 
  year={2021},
  volume={9},
  number={},
  pages={109241-109259},
  abstract={In this paper, we show that adversarial training time attacks by a few pixel modifications can cause undesirable overfitting in neural networks for both discriminative and generative models. We propose an evolutionary algorithm to search for an optimal pixel attack using a novel cost function inspired by domain adaptation literature to design our training time attack. The proposed cost function explicitly maximizes the generalization gap and domain divergence between clean and corrupted images. Empirical evaluations demonstrate that our adversarial training attack can achieve significantly low testing accuracy (with high training accuracy) on multiple datasets by just perturbing a single pixel in the training images. Even under the use of popular regularization techniques, we identify a significant performance drop compared to clean data training. Our attack is more successful than previous pixel-based training time attacks on state-of-the-art Convolutional Neural Networks (CNNs) architectures, as evidenced by significantly lower testing accuracy. Interestingly, we find that the choice of optimization plays an essential role in robustness against our attack. We empirically observe that Stochastic Gradient Descent (SGD) is resilient to the proposed adversarial training attack, different from adaptive optimization techniques such as the popular Adam optimizer. We identify that such vulnerabilities are caused due to over-reliance on the cross-entropy (CE) loss on highly predictive features. Therefore, we propose a robust loss function that maximizes the mutual information between latent features and input images, in addition to optimizing the CE loss. Finally, we show that the discriminator in Generative Adversarial Networks (GANs) can also be attacked by our proposed training time attack resulting in poor generative performance. Our paper is one of the first works to design attacks for generative models.},
  keywords={Training;Neural networks;Perturbation methods;Optimization;Testing;Noise measurement;Generative adversarial networks;Generalization in deep learning;data poisoning;adaptive optimization;training time attack;variational information bottleneck},
  doi={10.1109/ACCESS.2021.3101282},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9163723,
  author={Kurniawati, Arik and Suprapto, Yoyon Kusnendar and Yuniarno, Eko Mulyanto},
  booktitle={2020 International Seminar on Intelligent Technology and Its Applications (ISITIA)}, 
  title={Multilayer Perceptron for Symbolic Indonesian Music Generation}, 
  year={2020},
  volume={},
  number={},
  pages={228-233},
  abstract={Music is one of the arts of a beauty that cannot be separated from humans. But not all humans can create beautiful music. Therefore, this paper's objective was to design a creative aid to musical composition with minimum human intervention. This paper purpose builds generative music using Multilayer Perceptron (MLP) Neural Networks as architecture to create predicted chord as musical accompaniment. In contrast, the previous work in music generation has mainly been focused on creating subsequent next music patterns. Using the symbolic Indonesian music dataset (note and chord) to train the models. Finally, we predict sequential chords using symbolic notes from the data test. Later, the generated Chords by Neural Network is compared with the original music Indonesian.},
  keywords={Multilayer perceptrons;Bars;Image coding;Artificial intelligence;Rhythm;music generation;multilayer perceptron;symbolic},
  doi={10.1109/ISITIA49792.2020.9163723},
  ISSN={},
  month={July},}@INPROCEEDINGS{10571010,
  author={Yang, Wanting and Xiong, Zehui and Du, Hongyang and Yuan, Yanli and Quek, Tony Q.S.},
  booktitle={2024 IEEE Wireless Communications and Networking Conference (WCNC)}, 
  title={Semantic Change Driven Generative Semantic Communication Framework}, 
  year={2024},
  volume={},
  number={},
  pages={01-06},
  abstract={The burgeoning generative artificial intelligence technology offers novel insights into the development of semantic communication (SemCom) frameworks. These frameworks hold the potential to address the challenges associated with the black-box nature inherent in existing end-to-end training manner for the existing SemCom framework, as well as deterioration of the user experience caused by the inevitable error floor in deep learning-based SemCom. In this paper, we focus on the widespread remote monitoring scenario, and propose a semantic change driven generative SemCom framework. Therein, the semantic encoder and semantic decoder can be optimized independently. Specifically, we develop a modular semantic encoder with value of information based semantic sampling function. In addition, we propose a conditional denoising diffusion probabilistic mode-assisted semantic decoder that relies on received semantic information from the source, namely, the semantic map, and the local static scene information to remotely regenerate scenes. Moreover, we demonstrate the effectiveness of the proposed semantic encoder and decoder as well as the considerable potential in reducing energy consumption through simulation based on the realistic F composite channel fading model. The code is available at https://github.com/wty2011jl/SCDGSC.git.},
  keywords={Training;Energy consumption;Generative AI;Simulation;Semantics;Closed box;User experience;Conditional DDPM;semantic sampling;generative AI;remote monitoring;value of information},
  doi={10.1109/WCNC57260.2024.10571010},
  ISSN={1558-2612},
  month={April},}@INPROCEEDINGS{10556135,
  author={Zhang, Dawen and Xia, Boming and Liu, Yue and Xu, Xiwei and Hoang, Thong and Xing, Zhenchang and Staples, Mark and Lu, Qinghua and Zhu, Liming},
  booktitle={2024 IEEE/ACM 3rd International Conference on AI Engineering – Software Engineering for AI (CAIN)}, 
  title={Privacy and Copyright Protection in Generative AI: A Lifecycle Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={92-97},
  abstract={The advent of Generative AI has marked a significant milestone in artificial intelligence, demonstrating remarkable capabilities in generating realistic images, texts, and data patterns. However, these advancements come with heightened concerns over data privacy and copyright infringement, primarily due to the reliance on vast datasets for model training. Traditional approaches like differential privacy, machine unlearning, and data poisoning only offer fragmented solutions to these complex issues. Our paper delves into the multifaceted challenges of privacy and copyright protection within the data lifecycle. We advocate for integrated approaches that combines technical innovation with ethical foresight, holistically addressing these concerns by investigating and devising solutions that are informed by the lifecycle perspective. This work aims to catalyze a broader discussion and inspire concerted efforts towards data privacy and copyright integrity in Generative AI.CCS CONCEPTS• Software and its engineering Software architectures; • Information systems World Wide Web; • Security and privacy Privacy protections; • Social and professional topics Copyrights; • Computing methodologies Machine learning.},
  keywords={Training;Data privacy;Technological innovation;Generative AI;Software architecture;Copyright protection;Software;Privacy;Copyrights;Generative AI;Data Lifecycle;Software Architecture;Software Engineering for AI},
  doi={},
  ISSN={},
  month={April},}@INPROCEEDINGS{10578821,
  author={Strachan, Rebecca and Oguna, Cynthia and Oruche, Ugochukwu},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={The Postgraduate Student Perspective on Academic Misconduct in the Era of Essay Mills and Generative AI: A Case Study from Northeast England}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Globally the number of students at university has been growing with UNESCO reporting in 2023, that there are now 235 million university students across the world, double the number from 20 years ago. Higher education is now a key area of economic growth for many countries and thus has also become a target for exploitation, evidenced by the growing numbers of essay mills and similar services, and even more recently by some of the generative Artificial Intelligence (AI) tools. The UK has also seen a growth in student numbers, particularly at postgraduate and for international students. In computing for example, UK PGT student numbers have increased rapidly with the UK Higher Education Statistics Agency reporting 25,225 computing PGT students in 2019/2020 rising to 47,410 in 2021/22, with 69% of these students being classed as international. These students can find it challenging to adapt to education in the UK and can have differing levels of abilities including digital literacy. Alongside this growth, the variety/incidence of student academic misconduct (AM) has also been rising. Previous research has tended to focus on plagiarism but there is an increasing need to explore the implications arising from the widespread availability of essay mills and generative AI tools. This study aims to provide a greater understanding of AM from the perspective of the computing PGT student. Adopting a case study approach, computing PGT students (n=358) were surveyed at one UK university in Spring 2023 with a follow up focus group. The study employed two PG students as researchers and this enabled a more trusted and student-centered approach to the survey, focus group and analysis. Thematic analysis of the data from the survey (responses n=26) and focus group (n=7) show students believe AM affects academic standards and understand the reasons behind this. They believe the university is providing clear AM guidance, but have more mixed opinions on whether they think the AM process is appropriate/fair. The analysis demonstrates the need for a holistic and concerted effort between staff and students based around six main areas: assessment; educational provision; staff attitudes/support; student opportunity/motivation; student belonging/engagement; and student-friendly AM guidance/resources. Future work is building on these recommendations to create a framework and set of practical interventions to promote academic integrity, and address the current AM challenges.},
  keywords={Surveys;Economics;Generative AI;Target recognition;Engineering profession;Plagiarism;Buildings;Academic integrity;academic misconduct;student perspective;essay mills;generative AI},
  doi={10.1109/EDUCON60312.2024.10578821},
  ISSN={2165-9567},
  month={May},}@ARTICLE{11168870,
  author={Ni, Junjie and Wu, Tong and Chen, Zhiyong and Xu, Yin and Tao, Meixia and Zhang, Wenjun},
  journal={IEEE Communications Letters}, 
  title={Mixture of Semantics Transmission for Generative AI-Enabled Semantic Communication Systems}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={In this paper, we propose a mixture of semantics (MoS) transmission strategy for wireless semantic communication systems based on generative artificial intelligence (AI). At the transmitter, we divide an image into regions of interest (ROI) and reigons of non-interest (RONI) to extract their semantic information respectively. Semantic information of ROI can be allocated more bandwidth, while RONI can be represented in a compact form for transmission. At the receiver, a diffusion model reconstructs the full image using the received semantic information of ROI and RONI. Compared to existing generative AI-based methods, MoS enables more efficient use of channel resources by balancing visual fidelity and semantic relevance. Experimental results demonstrate that appropriate ROI-RONI allocation is critical. The MoS achieves notable performance gains in peak signal-to-noise ratio (PSNR) of ROI and CLIP score of RONI.},
  keywords={Receivers;Image reconstruction;Generative AI;Measurement;Diffusion models;Semantic communication;Image segmentation;Transmitters;Training;Symbols;Semantic Communications;Generative AI;Mixture of Semantics},
  doi={10.1109/LCOMM.2025.3611002},
  ISSN={1558-2558},
  month={},}@INPROCEEDINGS{11016486,
  author={Charalambous, Apostolos and Piki, Andriani and Kävrestad, Joakim and Stavrou, Eliana},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Balancing Generative AI and Critical Thinking to Develop Written Communication Skills in Cybersecurity}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={As cybersecurity education continues to evolve, the need for curricula that effectively balance the capabilities of generative Artificial Intelligence (AI) tools with the development of critical thinking and active learning skills has become increasingly urgent. This study addresses this challenge by proposing a curriculum for postgraduate cybersecurity education that focuses on developing transferable skills, particularly critical thinking and written communication. These skills are essential for cybersecurity professionals to excel in both their technical and communicationoriented responsibilities, meeting the growing demand of the cybersecurity industry in the age of AI. The proposed curriculum emphasizes the integration of constructivist learning principles and Bloom's taxonomy, two widely applied pedagogical models, to enhance learners' critical thinking and written communication skills. Designed for a penetration testing module, the curriculum follows a structured, step-by-step approach to build the necessary competences and empower aspiring cybersecurity professionals to meet the expectations of the cybersecurity industry. Through targeted activities, learners develop foundational knowledge while refining advanced written communication skills, equipping them to produce professional-level documentation, such as penetration testing reports. Generative AI is incorporated in the curriculum, providing opportunities for learners to experiment with AIgenerated content while fostering the cognitive skills needed to critically assess its accuracy, relevance, and alignment with professional standards. This study contributes to cybersecurity education by presenting a replicable curriculum model that equips learners with vital skills, preparing them to navigate the complexities of written communication responsibilities in cybersecurity roles and adapt to the evolving demands of the AI era.},
  keywords={Industries;Generative AI;Navigation;Education;Taxonomy;Refining;Stakeholders;Mentoring;Standards;Penetration testing;Cybersecurity;penetration testing report;generative AI;transferable skills;written communication skills;postgraduate education;curriculum design},
  doi={10.1109/EDUCON62633.2025.11016486},
  ISSN={2165-9567},
  month={April},}@ARTICLE{10146000,
  author={Javeed, Danish and Gao, Tianhan and Kumar, Prabhat and Jolfaei, Alireza},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={An Explainable and Resilient Intrusion Detection System for Industry 5.0}, 
  year={2024},
  volume={70},
  number={1},
  pages={1342-1350},
  abstract={Industry 5.0 is a emerging transformative model that aims to develop a hyperconnected, automated, and data-driven industrial ecosystem. This digital transformation will boost productivity and efficiency throughout the production process but will be more prone to new sophisticated cyber-attacks. Deep learning-based Intrusion Detection Systems (IDS) have the potential to recognize intrusions with high accuracy. However, these models are complex and are treated as a black box by developers and security analysts due to the inability to interpret the decisions made by these models. Motivated by the challenges, this paper presents an explainable and resilient IDS for Industry 5.0. The proposed IDS is designed by combining bidirectional long short-term memory networks (BiLSTM), a bidirectional-gated recurrent unit (Bi-GRU), fully connected layers and a softmax classifier to enhance the intrusion detection process in Industry 5.0. We employ the SHapley Additive exPlanations (SHAP) mechanism to interpret and understand the features that contributed the most in the decision of the proposed cyber-resilient IDS. The evaluation of the proposed model using the explainability can ensure that the model is working as expected. The experimental results based on the CICDDoS2019 dataset confirms the superiority of the proposed IDS over some recent approaches.},
  keywords={Intrusion detection;Security;Data models;Cyberattack;Deep learning;Explainable AI;Fifth Industrial Revolution;Bidirectional long short term memory;Deep learning (DL);cyber-attacks;explainable artificial intelligence;intrusion detection system (IDS);Industry 5.0},
  doi={10.1109/TCE.2023.3283704},
  ISSN={1558-4127},
  month={Feb},}@ARTICLE{9435010,
  author={Guo, Yijin and Shan, Huasong and Huang, Shixin and Hwang, Kai and Fan, Jianping and Yu, Zhibin},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={GML: Efficiently Auto-Tuning Flink's Configurations Via Guided Machine Learning}, 
  year={2021},
  volume={32},
  number={12},
  pages={2921-2935},
  abstract={The increasingly popular fused batch-streaming big data framework, Apache Flink, has many performance-critical as well as untamed configuration parameters. However, how to tune them for optimal performance has not yet been explored. Machine learning (ML) has been chosen to tune the configurations for other big data frameworks (e.g., Apache Spark), showing significant performance improvements. However, it needs a long time to collect a large amount of training data by nature. In this article, we propose a guided machine learning (GML) approach to tune the configurations of Flink with significantly shorter time for collecting training data compared to traditional ML approaches. GML innovates two techniques. First, it leverages generative adversarial networks (GANs) to generate a part of training data, reducing the time needed for training data collection. Second, GML guides a ML algorithm to select configurations that the corresponding performance is higher than the average performance of random configurations. We evaluate GML on a lab cluster with 4 servers and a real production cluster in an internet company. The results show that GML significantly outperforms the state-of-the-art, DAC (Datasize-Aware-Configuration) (Z. Yu et al. 2018) for tuning the configurations of Spark, with 2.4× of reduced data collection time but with 30 percent reduced 99th percentile latency. When GML is used in the internet company, it reduces the latency by up to 57.8× compared to the configurations made by the company.},
  keywords={Training data;Machine learning;Generative adversarial networks;Big Data;Optimization;Tuning;Big data systems;batch-stream fused processing;flink;configuration optimization;generative adversarial networks (GAN)},
  doi={10.1109/TPDS.2021.3081600},
  ISSN={1558-2183},
  month={Dec},}@ARTICLE{10231110,
  author={Zhong, Hongyu and Yu, Samson and Trinh, Hieu and Lv, Yong and Yuan, Rui and Wang, Yanan},
  journal={IEEE Sensors Journal}, 
  title={A Novel Small-Sample Dense Teacher Assistant Knowledge Distillation Method for Bearing Fault Diagnosis}, 
  year={2023},
  volume={23},
  number={20},
  pages={24279-24291},
  abstract={Recently, deep learning models have been widely studied and applied in fault diagnosis. However, two common drawbacks are: 1) they usually require a large amount of storage resources, making it difficult to run them on embedded devices and 2) there is usually no access to sufficient reliable training data to train a comprehensive diagnosis model. In this study, a fusion approach is proposed based on knowledge distillation and generative adversarial network (GAN). This approach is named small-sample dense teacher assistant knowledge distillation (SS-DTAKD), which aims to enable bearing fault diagnosis with small samples and limited on-board storage resources. First, the proposed self-attention GAN (SGAN) is used to expand the training data for the diagnostic model. The advantage is that the generator and discriminator embedded with the self-attention module can help improve the quality of the generated data. Then, the DTAKD method is proposed to compress the model parameter, where the dense distillation of multiple teacher-assistant networks helps the student network learn correct knowledge without requiring additional data and storage resources. Additionally, the dual-type data hierarchical training (DDHT) method is applied to train the student network, which is designed to utilize actual data to improve the student network’s performance. Extensive experiments on two bearing fault datasets demonstrate that the data generated by the SGAN has high similarity and robustness. Furthermore, compared to other existing knowledge distillation methods, the proposed SS-DTAKD method can obtain higher fault diagnosis accuracy with small samples and limited on-board storage resources.},
  keywords={Generative adversarial networks;Knowledge engineering;Fault diagnosis;Generators;Convolutional neural networks;Training;Data models;Dense connection;generative adversarial network (GAN);intelligent fault diagnosis;knowledge distillation},
  doi={10.1109/JSEN.2023.3307425},
  ISSN={1558-1748},
  month={Oct},}@INPROCEEDINGS{9096799,
  author={Lima, Servio and Terán, Luis and Portmann, Edy},
  booktitle={2020 Seventh International Conference on eDemocracy & eGovernment (ICEDEG)}, 
  title={A Proposal for an Explainable Fuzzy-based Deep Learning System for Skin Cancer Prediction}, 
  year={2020},
  volume={},
  number={},
  pages={29-35},
  abstract={Explainable deep learning (XDL) is a research field that aims to make deep learning predictions or classifications more understandable for humans. Literature shows that deep learning (DL) algorithms are more precise in terms of their prediction than traditional machine learning (ML) algorithms. Nevertheless, they lack the interpretability and explainability that less complex algorithms are more fitted. Nowadays, one of the main goals of XDL research is to make these algorithms highly precise and explainable. There exist different systems and techniques, but only limited research on explaining deep neural networks using soft computing approaches. The purpose of this research is to propose the theoretical fundamentals of an explainable fuzzy-based deep learning (EFBDL) system that is both precise and explainable. The system comprises two main parts. First, the deep network part composed of a convolutional neural network (CNN) based on Inception V4 for image classification, a transfer learning mechanism, and a feature extraction algorithm based on neuron perturbation. Second, a soft computing part comprised of a fuzzy rule-based system (FRBS), a hierarchical network for natural language generation named granular linguistic model of a phenomenon (GLMP), and a human-machine integration methodology for linguistic rules named highly interpretable linguistic knowledge (HILK). The output of the overall system is an explanation of the neural network decision using natural language. This system focuses on preventing skin cancer rather than healing it. Thus, governments could use this kind of system for implementing policies focused on prevention and save in overall treatment costs of the disease.},
  keywords={Skin cancer;Machine learning;Prediction algorithms;Linguistics;Fuzzy logic;Biological neural networks;Explainable deep learning;artificial intelligence;skin cancer prediction},
  doi={10.1109/ICEDEG48599.2020.9096799},
  ISSN={2573-1998},
  month={April},}@ARTICLE{9757866,
  author={Sedjelmaci, Hichem and Ansari, Nirwan},
  journal={IEEE Consumer Electronics Magazine}, 
  title={On Cooperative Federated Defense to Secure Multiaccess Edge Computing}, 
  year={2024},
  volume={13},
  number={4},
  pages={24-31},
  abstract={The research of cyber security for multiaccess edge computing (MEC) has not yet received great interest. Specifically, the attack detection issue is considered as a major concern since the MEC network, which handles attractive information, is prone to several internal and external network attacks. Recently, the federated learning (FL) and generative adversarial network (GAN) have been used to detect and prevent attacks from targeting the wireless mobile networks. In this article, we present the state of the art of MEC attack detection and defense frameworks, which incorporate FL and GAN algorithms. Moreover, we propose a new cyber defense framework based on a federated generative adversarial network algorithm and a noncooperative game to improve over time the precision of attack detection.},
  keywords={Security;Servers;Image edge detection;Training;Generative adversarial networks;Monitoring;Mobile handsets;MEC;Security;FL;GAN and Game theory},
  doi={10.1109/MCE.2022.3167527},
  ISSN={2162-2256},
  month={July},}@INPROCEEDINGS{10913228,
  author={Sun, Qi and Xue, Yayun and Song, Zhijun},
  booktitle={2024 6th International Conference on Frontier Technologies of Information and Computer (ICFTIC)}, 
  title={Adaptive User Interface Generation Through Reinforcement Learning: A Data-Driven Approach to Personalization and Optimization}, 
  year={2024},
  volume={},
  number={},
  pages={1386-1391},
  abstract={This study introduces an adaptive user interface generation technology, emphasizing the role of Human-Computer Interaction (HCI) in optimizing user experience. By focusing on enhancing the interaction between users and intelligent systems, this approach aims to automatically adjust interface layouts and configurations based on user feedback, streamlining the design process. Traditional interface design involves significant manual effort and struggles to meet the evolving personalized needs of users. Our proposed system integrates adaptive interface generation with reinforcement learning and intelligent feedback mechanisms to dynamically adjust the user interface, better accommodating individual usage patterns. In the experiment, the OpenAI CLIP Interactions dataset was utilized to verify the adaptability of the proposed method, using click-through rate (CTR) and user retention rate (RR) as evaluation metrics. The findings highlight the system's ability to deliver flexible and personalized interface solutions, providing a novel and effective approach for user interaction design and ultimately enhancing HCI through continuous learning and adaptation.},
  keywords={Human computer interaction;Adaptation models;Adaptive systems;Layout;Focusing;Reinforcement learning;System integration;Real-time systems;User experience;Optimization;Reinforcement learning;adaptive generation;user interface;interaction design;human-computer interaction;artificial intelligence},
  doi={10.1109/ICFTIC64248.2024.10913228},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10031813,
  author={Zeyu, Ding and Yaakob, Razali and Azman, Azreen},
  booktitle={2022 IEEE International Conference on Computing (ICOCO)}, 
  title={A Review of Deep Learning-Based Detection Methods for Tuberculosis}, 
  year={2022},
  volume={},
  number={},
  pages={68-73},
  abstract={Tuberculosis (TB) causes exceptionally high mortality rates, and early identification of TB is the key to saving patients. Deep learning techniques have proven to be an essential tool to assist radiologists in detecting abnormalities and multiple diseases. This study categorizes and analyzes deep learning-based techniques for TB diagnosis. Available public datasets are presented, and each method’s performance is compared comprehensively for the use of future researchers. Finally, we explore the challenges of detecting TB using deep learning algorithms and the future research prospects in this field.},
  keywords={Deep learning;Knowledge engineering;Adaptation models;Tuberculosis;Computational modeling;Transformers;Convolutional neural networks;deep learning;tuberculosis;TB;artificial intelligence},
  doi={10.1109/ICOCO56118.2022.10031813},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10767452,
  author={Chapagain, Devendra and Kshetri, Naresh and Aryal, Bindu},
  booktitle={2024 International Conference on Emerging Trends in Networks and Computer Communications (ETNCC)}, 
  title={Deepfake Disasters: A Comprehensive Review of Technology, Ethical Concerns, Countermeasures, and Societal Implications}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={Deepfakes are fake videos or pictures created using AI software to make them appear real by superimposing someone's face. This paper investigates the ethical implications of deepfake technology and its effects on society, examining the potential impacts on privacy, trust, misinformation, cyberbullying, and the well-being of individuals and communities. A thorough review was conducted by carefully collecting and categorizing approximately 50 papers from renowned academic databases and journals to ensure their validity and relevance. Each paper's relevance, methodological quality, and field contribution were carefully assessed during the selection process. A strict screening process selected 32 papers for the in-depth review conducted in this study. The research relies on these papers, which are deemed the most significant and influential in the field. In addition, this study emphasizes the imperative need for ethical guidelines and the responsible application of deepfake technology to mitigate its negative effects. To address the challenges posed by deepfakes, it is essential to raise awareness, implement regulatory measures, and promote media literacy, according to the findings of this study. This study carefully gathers, sorts, and chooses papers to give a full and useful summary of Review on Deepfakes. Finally, the paper will propose a code of conduct for the responsible creation and application of deepfake technologies.},
  keywords={Deepfakes;Ethics;Privacy;Reviews;Voting;Prevention and mitigation;Market research;Software;Monitoring;Guidelines;Artificial Intelligence;Deepfake;Misinformation;Privacy;Security},
  doi={10.1109/ETNCC63262.2024.10767452},
  ISSN={},
  month={July},}@INPROCEEDINGS{10481497,
  author={Li, Yixin and Wu, Weijie and Luo, Xintao and Zheng, Minjia and Zhang, Yinning and Peng, Bo},
  booktitle={2023 18th International Conference on Intelligent Systems and Knowledge Engineering (ISKE)}, 
  title={A Survey: Navigating the Landscape of Incremental Learning Techniques and Trends}, 
  year={2023},
  volume={},
  number={},
  pages={163-169},
  abstract={In traditional machine learning, model training usually involves training the model from scratch using the entire dataset. However, this approach often leads to catastrophic forgetting, i.e., the model rapidly and significantly forgets previously learned knowledge while training on samples from new tasks or new data distributions, when dealing with streaming data. Incremental learning, a particular machine learning paradigm, has drawn widespread attention as it allows the model to continuously learn from new data without forgetting the previously acquired knowledge. This paper comprehensively reviews existing incremental learning methods. The main contents of this survey include: the scenarios of incremental learning, a systematic review of incremental learning, a summary of performance evaluation metrics, and a discussion of open problems and future research directions in the area of incremental learning.},
  keywords={Training;Surveys;Performance evaluation;Systematics;Reviews;Navigation;Market research;artificial intelligence theories;machine learning;incremental learning;catastrophic forgetting},
  doi={10.1109/ISKE60036.2023.10481497},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10593473,
  author={Kaur, Mandeep and V, Dankan Gowda and Prasad, KDV and Ashreetha, B. and Eswar, Kamarthi Tej and Sandeep, Gandluru},
  booktitle={2024 5th International Conference for Emerging Technology (INCET)}, 
  title={A Comprehensive AI-ML Study on Enhanced Classification of Benign and Malignant Cells in Brain MRI}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={AI-ML integration into medical diagnostics will revolutionize the way cellular formations in brain MRI are recognized and classified. This research article focuses on the creation and validation of highly-sophisticated AI-ML models specifically designed to accurately distinguish between benign and malignant cells within MRIs of the brain, with an intention of contributing to the early detection and treatment strategies for brain tumors. The work starts with an AI-ML framework that is based on deep learning and convolutional neural networks, which is used to analyze brain MRI data with high accuracy. This approach is constructed to recognize minor trends and differences suggestive of cancers and is quite accurate in its detection. Validation on a set of huge MRI scans of the brain shows that the model outperforms current diagnostic methods for many metrics such as accuracy, precision, recall, and F1-score. Data handling, model training as well as ethical challenges are explored in detail which reveals the complexity of implementation of AI-ML in the medical imaging area. The proposed model is integrated into existing clinical workflow which in turn gives it a place in assisting diagnosis and decision making by the healthcare workers. The results emphasize the effect of AI-ML technologies on the improvement of the accuracy and the speed of the targeting of brain cells in MRI scans. The presented research shows that AI-ML has a high potential to improve the diagnostic process and therefore increases the patient care outcomes in neuro-oncology.},
  keywords={Deep learning;Training;Accuracy;Magnetic resonance imaging;Brain modeling;Medical diagnosis;Convolutional neural networks;Artificial Intelligence;Machine Learning;Brain MRI;Benign and Malignant Cells;Deep Learning;Convolutional Neural Networks;Medical Imaging;Diagnostic Accuracy},
  doi={10.1109/INCET61516.2024.10593473},
  ISSN={},
  month={May},}@INPROCEEDINGS{10449251,
  author={Ding, Xinhui and Wu, Siqi and Zhou, Miaoyi and Cao, Feng and Liu, Kaiyuan},
  booktitle={2023 IEEE Smart World Congress (SWC)}, 
  title={A Survey of Industrial Internet Platform: the Powerful Tool Combining Industrial Internet of Things with Machine Learning}, 
  year={2023},
  volume={},
  number={},
  pages={816-821},
  abstract={Due to the increasing importance of the Industrial Internet of Things(IIoT) in modern society’s information infrastructure, a series of strategies have been proposed by a number of countries to promote the development and deployment of IIoT in various industrial applications. On the other hand, as powerful information technology, machine learning has empowered industries in the form of industrial software. Industrial Internet platforms, as a kind of industrial software, have received a lot of attention from both the academic and industrial communities. Many Industrial Internet platforms have been proposed with various features and functions targeted at different industrial sectors. In order to assist end-users to make a better decision in selecting their platforms, this paper reviews a number of typical industrial examples and white papers and provides a unified view of the technical architecture and functional classification of Industrial Internet platforms. Firstly, we clarify the definition and the technical architecture of the data-driven Industrial Internet platform. Secondly, we propose a series of models focusing on the functions of the Industrial Internet platform mentioned above. At the end of the paper, we discuss the technical difficulties that need to be overcome by the community.},
  keywords={Surveys;Focusing;Computer architecture;Machine learning;Software;Internet;Industrial Internet of Things;Industrial Internet of Things;Machine Learning;Industrial Internet Platform;Artificial Intelligence},
  doi={10.1109/SWC57546.2023.10449251},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9454090,
  author={Prasad, Sathya and Bhat, Raghavendra S},
  booktitle={2021 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={India Industry-University Collaboration - A Novel Approach Combining Technology, Innovation, and Entrepreneurship}, 
  year={2021},
  volume={},
  number={},
  pages={373-380},
  abstract={Research in fast-evolving technologies like AI & ML requires the collaborative effort of various stakeholders including industries and universities. In developed economies, industry-university collaboration (IUC) is mature and delivers benefits to both stakeholders. In a developing nation like India, there is relatively less emphasis on IUC and when present, is restricted to a small set of premier institutions. At the undergraduate level, the collaboration between industry and university is very minimal to none. This poses major challenges to industry (insufficient qualified talent pool, higher cost of training fresh recruits, limited choice of external research partners) as well as universities (curriculum lagging latest technology, not reaching full research and innovation potential, source for research funding). This paper summarizes the IUC effort undertaken by Intel Technology India Ltd and the Center for Innovation and Entrepreneurship at PES University to create mutually rewarding outcomes for both partners and describes a new model encompassing technology, innovation, and entrepreneurship in addition to the traditional elements of IUC. We present the IUC considerations and processes adopted to deal with the challenges and share the outcomes and impact at the end of two years of engagement and hope that key aspects of this IUC can be leveraged by other industry and university stakeholders for mutually rewarding outcomes.},
  keywords={Industries;Training;Technological innovation;Conferences;Collaboration;Entrepreneurship;Stakeholders;Industry-University Collaboration;Higher Education;Technology;Innovation;Research;Entrepreneurship;Artificial Intelligence;Machine Learning;Deep Learning;Advanced Driver Assistance System},
  doi={10.1109/EDUCON46332.2021.9454090},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10208393,
  author={Ali, Hazrat and Grönlund, Christer and Shah, Zubair},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={Leveraging GANs for data scarcity of COVID-19: Beyond the hype}, 
  year={2023},
  volume={},
  number={},
  pages={659-667},
  abstract={Artificial Intelligence (AI)-based models can help in diagnosing COVID-19 from lung CT scans and X-ray images; however, these models require large amounts of data for training and validation. Many researchers studied Generative Adversarial Networks (GANs) for producing synthetic lung CT scans and X-Ray images to improve the performance of AI-based models. It is not well explored how good GAN-based methods performed to generate reliable synthetic data. This work analyzes 43 published studies that reported GANs for synthetic data generation. Many of these studies suffered data bias, lack of reproducibility, and lack of feedback from the radiologists or other domain experts. A common issue in these studies is the unavailability of the source code, hindering reproducibility. The included studies reported rescaling of the input images to train the existing GANs architecture without providing clinical insights on how the rescaling was motivated. Finally, even though GAN-based methods have the potential for data augmentation and improving the training of AI-based models, these methods fall short in terms of their use in clinical practice. This paper highlights research hotspots in countering the data scarcity problem, identifies various issues as well as potentials, and provides recommendations to guide future research. These recommendations might be useful to improve acceptability for the GAN-based approaches for data augmentation as GANs for data augmentation are increasingly becoming popular in the AI and medical imaging research community.},
  keywords={COVID-19;Training;Computed tomography;Source coding;Lung;Data augmentation;Data models},
  doi={10.1109/CVPRW59228.2023.00073},
  ISSN={2160-7516},
  month={June},}@INPROCEEDINGS{10322923,
  author={Saouabe, Abdelkrim and Tkatek, Said and Mazar, Merouane and Mourtaji, Imad},
  booktitle={2023 10th International Conference on Wireless Networks and Mobile Communications (WINCOM)}, 
  title={Evolution of Image Captioning Models: An Overview}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={This article presents a state-of-the-art review of image captioning methodologies developed in the past five years. Image captioning, which aims to generate text describing the visual content of an image, has gained increasing interest in the field of artificial intelligence. The article analyzes how image captioning methods have evolved, transitioning from traditional machine learning-based approaches to deep learning-based methods that have become dominant due to their effectiveness in efficiently extracting image features. The article also explores two main approaches to image captioning: dense (region-based) captioning and whole-scene captioning. It discusses approaches based on visual space and multimodal space for text generation. Furthermore, the article examines reinforcement learning methods, semantic enhancements, the use of self-attention transformer models, and pretrained models such as the Generative Pre-trained Transformer (GPT) that have improved the performance of image captioning. Finally, the article highlights various applications of this technique, including human-machine interaction, biomedicine, automatic medical prescription, children’s education, industrial quality control, traffic data analysis, and assistive technologies for visually impaired individuals.},
  keywords={Visualization;Pediatrics;Biological system modeling;Wireless networks;Semantics;Reinforcement learning;Quality control;Transformers;Feature extraction;Mobile communication;Image Captioning;Deep Learning;Transformers;GPT;Computer vision},
  doi={10.1109/WINCOM59760.2023.10322923},
  ISSN={2769-9994},
  month={Oct},}@INPROCEEDINGS{10864205,
  author={Kumar, Bharathi Ganesh and Shanthini, E.},
  booktitle={2024 International Conference on Sustainable Communication Networks and Application (ICSCNA)}, 
  title={From Attacks to Insights: XAI and Defense in Network Security}, 
  year={2024},
  volume={},
  number={},
  pages={395-401},
  abstract={Network intrusion poses significant threats to cyber security, as malicious attacks can disrupt systems and compromise sensitive information. Real-world scenarios include unauthorized access to corporate networks, data breaches exposing sensitive customer information, and Distributed Denial of Service (DDoS) attacks that can impair critical infrastructure. This paper addresses these challenges using the UNSW-NB15 dataset, a comprehensive collection of real-world network traffic data. This dataset was chosen for its diversity in capturing contemporary cyber threats, making it ideal for evaluating model performance in detecting intrusions. While numerous classification models exist for this task, the Multi-Layer Perceptron (MLP) classifier is selected due to its ability to capture complex patterns and provide higher accuracy in non-linear datasets. To enhance the interpretability of the model, Explainable AI (XAI) techniques are employed, including SHAP, LIME, and permutation feature importance, which offer insights into model decisions by explaining feature contributions. However, adversarial machine learning introduces an additional layer of threat by exploiting model vulnerabilities. This paper focuses on the Zeroth Order Optimization (ZOO) attack, a black-box method that only requires access to the model's predictions, without needing knowledge of the architecture or gradients, to demonstrate how adversarial examples can drastically reduce model accuracy and compromise network security. Upon generating adversarial examples, a significant drop in accuracy is observed, identifying the features most susceptible to manipulation. Then XAI methods are applied again to analyze the features that contribute most to the misclassification, allowing us to understand the underlying vulnerabilities. Based on these insights, adversarial training is implemented as a defense mechanism, successfully restoring model accuracy and strengthening resilience against attacks. The results underline the importance of combining XAI with robust defenses to build secure, interpretable machine learning models for intrusion detection.},
  keywords={Training;Accuracy;Explainable AI;Network intrusion detection;Telecommunication traffic;Predictive models;Network security;Traffic control;Computer crime;Optimization;Network Intrusion Detection Systems;Explainable Artificial Intelligence;Multi-Layer Perceptron;Adversarial Machine learning;Zeroth Order Optimization attack;SHapley Additive exPlanations;Local Interpretable Model-agnostic Explanations;Adversial Training;Permutation Feature Importance},
  doi={10.1109/ICSCNA63714.2024.10864205},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10479349,
  author={Macedo, André Manuel and Magalhães, João Paulo},
  booktitle={2023 20th ACS/IEEE International Conference on Computer Systems and Applications (AICCSA)}, 
  title={Detection of Network Intrusions Using Anomaly Detection}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The proliferation and widespread use of new technologies has inevitably brought an increase in the occurrence of cyber-attacks. The adoption of cybersecurity technologies and policies are increasingly a central point that requires innovative and appropriate solutions. This paper proposes a solution that aims to help organisations to identify, detect, manage, and respond to security threats assertively and timely. The proposal includes modeling the behavior of network traffic using machine learning and the automatic detection of behavioral deviations that may indicate the occurrence of malicious activity in the network. Two simulations of cyberattacks were conducted, and the results show that is possible to detect anormal network behaviors by means of machine learning analysis. These results are important to improve the visibility of operators and to enable the digital forensic and incident response faster, reducing the potential impacts of cyberattacks.},
  keywords={Machine learning algorithms;Digital forensics;Telecommunication traffic;Machine learning;Traffic control;Data processing;Recording;Security Operations Center;Artificial Intelligence;Security;Incident;Automation;Recovery},
  doi={10.1109/AICCSA59173.2023.10479349},
  ISSN={2161-5330},
  month={Dec},}@ARTICLE{10716635,
  author={Kim, Yunsu and Chun, Junha and Son, Sungwook and Park, Hyunwoo},
  journal={IEEE Access}, 
  title={Toward Generalized Visualization System for Various CNN Models: Module and Layer View}, 
  year={2024},
  volume={12},
  number={},
  pages={158311-158321},
  abstract={We present CNNExplorer, a generalized visualization system designed to assist beginners in understanding Convolutional Neural Networks (CNNs). CNNExplorer provides an intuitive interface and detailed visualizations at both the module and layer levels, enabling users to explore and understand the complex structures and operations of CNN models without requiring extensive coding knowledge. The module view abstracts the complexity by grouping layers into modules, while the layer view shows detailed transformations within each module. Our system supports a wide range of CNN models, including those available on Hugging Face, allowing users to visualize and analyze a variety of pre-trained models. To demonstrate the potential effectiveness of CNNExplorer in practical applications, we proposed specific application scenarios. Furthermore, we conducted a user study with participants and found the system is effective in enhancing their understanding of deep learning models and appreciated the interactive features. In future work, we will focus on supporting the latest vision models and expanding visualization capabilities to other deep learning architectures.},
  keywords={Convolutional neural networks;Analytical models;Visualization;Deep learning;Data visualization;Engines;Solid modeling;Face recognition;Computational modeling;Artificial intelligence;Deep learning;visual analytics;convolutional neural networks;artificial intelligence education},
  doi={10.1109/ACCESS.2024.3480791},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11156083,
  author={Zakkiya, Salsa Arifah and Selviandro, Nungki and Utomo, Rio Guntur},
  booktitle={2025 IEEE International Conference on Artificial Intelligence for Learning and Optimization (ICoAILO)}, 
  title={A Guideline for the Adoption of Generative AI to Support Secure Software Development Life Cycle (SSDLC): A Case Study of ChatGPT}, 
  year={2025},
  volume={},
  number={},
  pages={62-68},
  abstract={Secure software development using generative AI is gaining traction, particularly in academic environments where undergraduate teams often lack structured guidance. A key challenge is aligning documentation outputs with formal standards such as OWASP ASVS when using large language models (LLMs) like ChatGPT-4o. This study proposes a Secure SDLC guideline incorporating a six-element prompting framework Context, Task, Instruction, Clarify, Refine, and Warning combined with OWASP ASVS principles. A case study involving a student-developed village information system applied the guideline from Project Charter to Secure Design phases. Results demonstrated improved completeness and standard alignment in early phases, though limitations were found in traceability during Business Requirements and Threat Modeling.},
  keywords={Threat modeling;Documentation;Reliability engineering;Software reliability;Security;Prompt engineering;Standards;Guidelines;Software development management;Software engineering;secure SDLC;OWASP ASVS;security documentation;generative AI;chatGPT-4o;prompt engineering},
  doi={10.1109/ICoAILO66760.2025.11156083},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10803251,
  author={Boopalan, Sunil},
  booktitle={2024 International Conference on Cybernation and Computation (CYBERCOM)}, 
  title={Synergistic Solutions for Cloud Cybersecurity and Financial Operations using AI, Blockchain and Quantum Computing}, 
  year={2024},
  volume={},
  number={},
  pages={109-115},
  abstract={This research paper further builds on previous research by proposing a combination of AI and blockchain in the context of integration of quantum computing to improve the cybersecurity of cloud and financial operations, especially for India's UPI and digital rupee platforms. This is especially the case when digital transactions are on the rise and their security against rampant cyber threats and overall soundness of operations must be guaranteed. The following is a novel framework that embellishes AI, blockchain, and quantum computing to meet these challenges outlined in this paper. Machine learning and pattern recognition will be implemented to scope out and prevent security threats, while blockchain is to ensure a secure and open system of transactions; quantum computing will help to provide extraordinary features for data security and data encryption. The research also seeks to examine the current implementation approaches, advantages, and disbursement issues of this integration and subsequently makes recommendations that can help policymakers and practitioners make improvements for the improvement of trust and security in the implementation of financial solutions on the cloud.},
  keywords={Technological innovation;Quantum computing;Stability criteria;Open systems;Machine learning;Blockchains;Pattern recognition;Encryption;Standards;Guidelines;Artificial Intelligence;Blockchain;Quantum Computing;Cloud Cybersecurity;Financial Operations;Unified Payments Interface;Digital Rupee;Machine Learning;Data Encryption;Fraud Detection},
  doi={10.1109/CYBERCOM63683.2024.10803251},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11166985,
  author={Soni, Gaurav and Sharma, Ankur and Singh, Charanjit},
  booktitle={2025 5th International Conference on Intelligent Technologies (CONIT)}, 
  title={Classification of Breast Cancer and its Diagnosis Using Machine Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Breast cancer is the one of the most prevalent and deadly type of rare cancer among the women of all ages. Improving patient outcomes requires accurate diagnosis and timely detection. To enable the precise detection of breast cancer, several categorization approaches have been developed over time. This study offers an extensive examination of contemporary breast cancer classification techniques, including deep learning, machine learning, and image processing methodologies. The document delineates the merits and drawbacks of each method and provides avenues for subsequent investigation. Traditional/Conventional machine learning methods, like Support Vector Machines (SVM), Decision Trees, and Random Forests, are juxtaposed with contemporary deep learning models, such as Convolutional Neural Networks (CNNs), emphasizing their distinct advantages and drawbacks. The discussion encompasses the significance of feature selection, data preparation, and imaging methods. The paper closes by highlighting existing obstacles, including data imbalance and model interpretability, and proposes future research avenues to improve diagnostic accuracy and dependability.},
  keywords={Support vector machines;Deep learning;Accuracy;Computational modeling;Training data;Breast cancer;Data models;Convolutional neural networks;Decision trees;Random forests;Breast cancer;Convolutional Neural Network (CNN);Artificial Neural Networks;Machine Learning},
  doi={10.1109/CONIT65521.2025.11166985},
  ISSN={},
  month={June},}@INPROCEEDINGS{10659951,
  author={Hongwei, Wang and Chuang, Kong and Shuaitao, Ren and Hua, Zhou},
  booktitle={2024 2nd International Conference on Mechatronics, IoT and Industrial Informatics (ICMIII)}, 
  title={Visual Analytic Study on Image Restoration Research Driven by CiteSpace}, 
  year={2024},
  volume={},
  number={},
  pages={111-115},
  abstract={As a pivotal issue in the field of image processing, image restoration plays a vital role in enhancing image quality and information extraction, directly impacting applications in medical imaging, remote sensing, security surveillance, among others. This study employs CiteSpace software to conduct an in-depth visual analytic examination of 3,123 publications related to image restoration indexed in the Web of Science Core Collection, spanning from 2019 to 2024. Throughout the research, we systematically analyze the trends, hot topics, and author collaboration networks within the field through keyword co-occurrence, clustering analysis, timeline analysis, and emerging keyword detection. The findings reveal that deep learning, feature extraction and image reconstruction, as well as unsupervised learning and matrix decomposition, have emerged as core focuses of image restoration research, indicating a progression towards more intelligent, efficient, and interdisciplinary approaches in the discipline. This study not only uncovers the current active research fronts in image restoration but also forecasts potential directions for technological innovation, thereby furnishing researchers and practitioners with valuable strategic insights.},
  keywords={Image quality;Technological innovation;Visual analytics;Feature extraction;Image restoration;Trajectory;Security;Image Restoration;Image Inpainting;Machine Learning;Artificial Intelligence;Image Processing;Image Denoising;Feature Extraction;Deep Learning},
  doi={10.1109/ICMIII62623.2024.00027},
  ISSN={},
  month={June},}@INPROCEEDINGS{11035747,
  author={Saxena, Aaditya and Nandanwar, Himanshu and Katarya, Rahul},
  booktitle={2025 4th International Conference on Distributed Computing and Electrical Circuits and Electronics (ICDCECE)}, 
  title={Advancing Intrusion Detection Systems for IoT: Techniques, Challenges, and Future Directions}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={In recent times, a significant rise is observed in the usage of IoT devices, as a repercussion of which threats of cyberattacks have increased. Intrusion Detection system play an important role in identifying malicious activities in networks. This study examines various IDS approaches including hybrid approaches, and highlights key challenges such as heavy reliance on labelled data, constraints in identifying complex attack patterns and explainability in real time, as well as better solutions discussed in section two of this paper. This research derives potential enhancements such as integration of XAI with various models like CNN, Random Forest and federated learning aiming to enhance performance, generalization and adaptability in order to make IDS more scalable and prone to various types of attacks.},
  keywords={Explainable AI;Federated learning;Computational modeling;Intrusion detection;Real-time systems;Internet of Things;Integrated circuit modeling;Distributed computing;Computer crime;Random forests;intrusion detection systems (IDS);internet of things (IoT);machine learning;explainable AI (XAI);federated learning (FL);machine learning (ML);artificial intelligence (AI)},
  doi={10.1109/ICDCECE65353.2025.11035747},
  ISSN={},
  month={April},}@INPROCEEDINGS{11064064,
  author={Pandey, Riya and Singh, Shikha and Singh, Vineet and Hazela, Bramah and Asthana, Pallavi and Singh, Kamlesh Kumar},
  booktitle={2025 3rd International Conference on Communication, Security, and Artificial Intelligence (ICCSAI)}, 
  title={Dynamic Neural Network Training for Self-Driving Cars in Generative Virtual Environments}, 
  year={2025},
  volume={3},
  number={},
  pages={1267-1272},
  abstract={Neural networks have been seen as a robust means to tackle difficult issues across many fields, including autonomous driving. Training neural networks to drive vehicles autonomously in the real world is a major challenge, including safety concerns, cost, and the uncertainty of dynamic environments. This research employs generative virtual environments based on OpenStreetMap data to provide a novel means of mitigating the problems described above. These environments, with intricate traffic patterns, multiple weather conditions, and diverse road infrastructures, closely represent real-world conditions. To further improve autonomous neural networks' decision-making ability, a dynamic training model with adaptive learning mechanisms is proposed. Iterative learning and conditional adaptation are enabled by virtual sensors that mimic real-world data streams. Experimental results indicate a 25 % increase in navigation accuracy, a 30% decrease in collision rates, and an 85% success rate in transferring to new situations. This research illustrates the promise of virtual simulations as a low-cost, scalable, and secure substitute for physical testing, which could accelerate the development of autonomous car technologies.},
  keywords={Training;Adaptation models;Adaptive learning;Uncertainty;Soft sensors;Neural networks;Virtual environments;Traffic control;Autonomous automobiles;Vehicle dynamics;Autonomous vehicles;neural network training;generative virtual environments;OpenStreetMap;adaptive learning;self-driving cars;virtual sensors;real-world simulation},
  doi={10.1109/ICCSAI64074.2025.11064064},
  ISSN={},
  month={April},}@INPROCEEDINGS{10739246,
  author={Gupta, Sajal and Yadav, Akash and Kashyap, Lavesh and Gupta, Anant and Aeri, Manisha and Dhondiyal, Shiv Ashish},
  booktitle={2024 International Conference on Electrical Electronics and Computing Technologies (ICEECT)}, 
  title={Next-Generation Content Development: The Impact of AI Augmentation Technologies}, 
  year={2024},
  volume={1},
  number={},
  pages={1-6},
  abstract={In the era of information abundance, navigating through extensive content within files presents a significant challenge for various users seeking specific information. This paper minimizes the difficulties a user faces in efficiently extracting relevant information from voluminous documents. Harnessing the capabilities of powerful generative AI models, particularly those developed by OpenAI, our research formulates intuitive methods to alleviate the burden of exhaustive document perusal. By leveraging state-of-the-art generative AI, this research presents innovative approaches that allow users to streamline their information retrieval processes. Our methods aim to enhance a user’s productivity by minimizing the need for strenuous manual reading, ultimately enabling a more efficient and targeted exploration of document content along with its inherent capabilities. Through the integration of OpenAI’s advancements in natural language processing, our proposed techniques pave the way for a user-friendly and efficient means of accessing crucial information within documents. This research contributes to the evolving landscape of informationprocessing, dedicating practical solutions to optimize a user’s interactions with extensive textual data.},
  keywords={Productivity;Industries;Generative AI;Navigation;Manuals;Solids;Information retrieval;Natural language processing;Next generation networking;Faces;PDF-integration;Next.js;React;TypeScript;Tailwind CSS;Clerk;Drizzle ORM;PostgreSQL;AWS SDK;OpenAIAPI;Stripe;Axios;Pinecone},
  doi={10.1109/ICEECT61758.2024.10739246},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10104718,
  author={Patil, Atharva and Suwalka, Divyansh and Kumar, Aryan and Rai, Gaurav and Saha, Jayita},
  booktitle={2023 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)}, 
  title={A Survey on Artificial Intelligence (AI) based Job Recommendation Systems}, 
  year={2023},
  volume={},
  number={},
  pages={730-737},
  abstract={Job recommendation systems are AI-powered platforms that aim to provide job seekers with personalized job recommendations based on their skills, experience, and preferences. However, these systems face several challenges such as dealing with sparse data, maintaining data privacy and security, overcoming bias and discrimination, and ensuring transparency and interpretability. Recent techniques used in job recommendation systems include deep learning, reinforcement learning, and knowledge graphs. These techniques help to address the challenges such as dealing with sparse data, improving the accuracy of recommendations, and ensuring transparency as well as interpretability. The results of this study also helps to improve the job search experience for job seekers, reduces the time taken to find suitable job opportunities, and increase job satisfaction. Consequently, the job recommender architecture serves as a mediator. Accordingly, this work presents a detailed comprehensive survey of several filtering, machine learning and deep learning techniques that has revolutionised job recommendation system. Multiple applications and the associated challenges with existing job recommendation system are also discussed briefly.},
  keywords={Deep learning;Representation learning;Differential privacy;Filtering;Reinforcement learning;Knowledge graphs;Security;Job Recommendation System;Content Based Filtering;Knowledge Graph;Machine Learning},
  doi={10.1109/ICSCDS56580.2023.10104718},
  ISSN={},
  month={March},}@INPROCEEDINGS{9815626,
  author={Mahmud, ASM Ashraf},
  booktitle={2022 4th Global Power, Energy and Communication Conference (GPECOM)}, 
  title={Artificial Intelligence (AI)-based identification of appliances in households through NILM}, 
  year={2022},
  volume={},
  number={},
  pages={414-426},
  abstract={The Smart Grid (SG) technologies greatly enhance the electrical grid by providing more energy security, increasing efficiency, reliability and economically benefitting the supplier which translates to reduce prices to the end customer. This is significant, as most of the current available energy comes from non-renewable sources. Economic development of nations result in increased demand for energy resources and as the world moves forward, the rate at which these resources are being spent is increasing. The SG poses numerous challenges in the fields of communication, engineering and policymaking. An aspect of the SG Technologies like Non-Intrusive Load Monitoring (NILM) enables the collection of valuable information that can be used to increase energy efficiency and gain deep insight on energy statistics. Novel software approaches like Deep Neural Networks, Markov models and Support Vector Machines play an important role for solving the NILM problem. In addition, researchers are delving into other aspects of the implementation such as privacy, price, and resource usage that coming from the paradigms of cloud and edge computing. Expert analysis on all of these topics is essential for the adoption of SG technology. In this paper, the merits of the various AI/ML techniques are expanded upon in a literature review. Then the previous and current state-of-the-art methods in the field of Deep Learning are evaluated and a conclusion is reached on their performance and viability. Furthermore, a case is made about relevant computing paradigms and how they may impact fundamental areas of the technology.},
  keywords={Deep learning;Support vector machines;Privacy;Neural networks;Software;Real-time systems;Smart grids;NILM;AI;ML;Smart Grid;Deep Learning;Markov Model;SVM;Deep Neural Network},
  doi={10.1109/GPECOM55404.2022.9815626},
  ISSN={},
  month={June},}@ARTICLE{11091282,
  author={Choi, Hyun-Tae and Nakamura, Kensuke and Hong, Byung-Woo},
  journal={IEEE Access}, 
  title={Decoupled Latent Diffusion Model for Enhancing Image Generation}, 
  year={2025},
  volume={13},
  number={},
  pages={130505-130516},
  abstract={Latent Diffusion Models have emerged as an efficient alternative to conventional diffusion approaches by compressing high-dimensional images into a lower-dimensional latent space using a Variational Autoencoder (VAE) and performing diffusion in that space. In standard Latent Diffusion Model (LDM), the latent code is formed by sampling from a Gaussian distribution (i.e., combining both the mean and the standard deviation), which helps regularize the latent space but appears to contribute little beyond the deterministic component. Motivated by recent empirical observations that the decoder relies primarily on the latent mean, our work reexamines this paradigm and proposes a decoupled latent diffusion model that focuses on a simplified latent representation. Specifically, we compare three configurations: (i) the standard latent code, (ii) a concatenated representation that explicitly preserves both mean and variance, and (iii) a deterministic mean-only representation. Our extensive experiments on multiple benchmark datasets demonstrate that, when compared to the standard approach, the mean-only configuration not only maintains but in many cases improves synthesis quality by producing sharper and more coherent images while reducing unnecessary noise. These findings suggest that a simplified, deterministic latent representation can yield more stable and efficient generative models, challenging the conventional reliance on latent sampling in diffusion-based image synthesis.},
  keywords={Diffusion models;Image synthesis;Stochastic processes;Codes;Standards;Noise;Training;Image reconstruction;Noise reduction;Decoding;Denoising diffusion model;latent representation;image generation},
  doi={10.1109/ACCESS.2025.3592163},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10940152,
  author={Hossain, Mohammad Alamgir and Shahi, Fazal Imam and Husain, Sadia and Suliman, Abdelrazig and Kamal, Mohammad Shahid and Ahmad, Yasir and Talukdar, Mohammad Mazedul Huq and Martin, R. John},
  booktitle={2025 International Conference on Computer, Electrical & Communication Engineering (ICCECE)}, 
  title={IALS: Innovative Approach for Lung Segmentation Applying Artificial Intelligence and Deep Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={The automated segmentation of lungs within chest CT scans remains crucial for many medical applications that require disease diagnosis and treatment design. The presented deep incremental learning (DIL) system addresses fundamental limitations that arise during lung segmentation processes. The exceptional segmentation outcomes result from the neural network structure which includes masked RCNN+UNet for tissue segmentation and GAN+VARMA for classification. Medical literature identifies lung tissue structures as difficult to study because they present irregular forms and complex structures. The task of obtaining precise segmentation proves very challenging. The application of masked RCNN+UNet enables shape control and improves segmentation precision of the lung system. The DIL function helps maintain improved features within segmented images. The applied framework enables improved performance through DSC and MAE and JI metrics evaluation. Experimental evidence shows that the new framework achieves superior performance compared to current top-ranking methods for lung segmentation. The proposed framework exhibits excellent precision and detection efficiency with a DSC value of 0.96 and JI value of 0.93 and a low MAE $\lt 0.01$. The new extraction method could advance medical image examination systems within healthcare settings.},
  keywords={Deep learning;Image segmentation;Shape control;Lungs;Pulmonary diseases;Computed tomography;Predictive models;Real-time systems;Medical diagnostic imaging;Electronics packaging;lung segmentation;chest CT scan;GAN;RCNN;VARMA;deep learning},
  doi={10.1109/ICCECE61355.2025.10940152},
  ISSN={2768-0576},
  month={Feb},}@ARTICLE{9524697,
  author={Yadav, Pooja and Menon, Neeraj and Ravi, Vinayakumar and Vishvanathan, Sowmya},
  journal={IEEE Transactions on Engineering Management}, 
  title={Lung-GANs: Unsupervised Representation Learning for Lung Disease Classification Using Chest CT and X-Ray Images}, 
  year={2023},
  volume={70},
  number={8},
  pages={2774-2786},
  abstract={Lung diseases are a tremendous challenge to the health and life of people globally, accounting for 5 out of 30 most common causes of death. Early diagnosis is crucial to help in faster recovery and improve long-term survival rates. Deep learning techniques offer a great promise for automated, fast, and reliable detection of lung diseases from medical images. Specifically, convolutional neural networks have accomplished encouraging results in disease detection. In spite of that, the performance of such supervised models depends heavily on the availability of large labeled data, the collection of which is an expensive and tedious task, specially for a novel disease. Therefore, in this article, we propose a deep unsupervised framework to classify lung diseases from chest CT and X-ray images. Our framework introduces multiple-layer generative adversarial networks called Lung-GANs that learn interpretable representations of lung disease images using only unlabeled data. We use the lung features learned by the model to train a support vector machine and a stacking classifier. We demonstrate through experiments that the proposed method outperforms the current state-of-the-art unsupervised models in lung disease classification. Our model obtained an accuracy of 94%–99.5% on all the six large-scale publicly available lung disease datasets used in this study. Hence, the proposed framework will simplify lung disease detection by reducing the time for diagnosis and increasing the convenience of diagnostics.},
  keywords={Pulmonary diseases;X-ray imaging;Computed tomography;Generators;Feature extraction;COVID-19;Training;COVID-19;CT scan;generative adversarial networks;lung disease;pediatric pneumonia;pneumonia;tuberculosis;unsupervised representation learning;X-ray},
  doi={10.1109/TEM.2021.3103334},
  ISSN={1558-0040},
  month={Aug},}@ARTICLE{9849422,
  author={Xian, Weizhi and Zhou, Mingliang and Fang, Bin and Liao, Xingran and Ji, Cheng and Xiang, Tao and Jia, Weijia},
  journal={IEEE Transactions on Broadcasting}, 
  title={Spatiotemporal Feature Hierarchy-Based Blind Prediction of Natural Video Quality via Transfer Learning}, 
  year={2023},
  volume={69},
  number={1},
  pages={130-143},
  abstract={In this paper, we propose a pyramidal spatiotemporal feature hierarchy (PSFH)-based no-reference (NR) video quality assessment (VQA) method using transfer learning. First, we generate simulated videos by a generative adversarial network (GAN)-based image restoration model. The residual maps between the distorted frames and simulated frames, which can capture rich information, are utilized as one input of the quality regression network. Second, we use 3D convolution operations to construct a PSFH network with five stages. The spatiotemporal features incorporating the shared features transferred from the pretrained image restoration model are fused stage by stage. Third, with the guidance of the transferred knowledge, each stage generates multiple feature mapping layers that encode different semantics and degradation information using 3D convolution layers and gated recurrent units (GRUs). Finally, five approximate perceptual quality scores and a precise prediction score are obtained by fully connected (FC) networks. The whole model is trained under a finely designed loss function that combines pseudo-Huber loss and Pearson linear correlation coefficient (PLCC) loss to improve the robustness and prediction accuracy. According to the extensive experiments, outstanding results can be obtained compared with other state-of-the-art methods. Both the source code and models are available online.1},
  keywords={Three-dimensional displays;Spatiotemporal phenomena;Quality assessment;Transfer learning;Distortion;Image restoration;Feature extraction;Video quality assessment;pyramidal spatiotemporal feature;transfer learning;3D convolution;generative adversarial network},
  doi={10.1109/TBC.2022.3192997},
  ISSN={1557-9611},
  month={March},}@ARTICLE{10227351,
  author={Zheng, Yi and Wang, Ji and Li, Xingwang and Li, Jiping and Liu, Shouyin},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Cell-Level RSRP Estimation With the Image-to-Image Wireless Propagation Model Based on Measured Data}, 
  year={2023},
  volume={9},
  number={6},
  pages={1412-1423},
  abstract={Wireless propagation models play a significant role in the deployments of base stations that are used to the reference signal receiving power (RSRP) of signal receivers in a cell. However, the existing models predict the RSRP of one receiver point in a cell at a time, which cannot be generalized to other cells. Motivated by this, a cell-level RSRP estimation method is proposed to directly predict the whole-cell RSRP by converting the RSRP estimation into an image-to-image translation. First, an environment map of each cell and measured RSRP for each cell is transformed into an image. Second, a cell-level image-to-image wireless propagation model based on conditional generative adversarial networks is proposed, which can directly predict the whole-cell RSRP at a time. In particular, a residual estimation method is proposed for the measurement RSRP data in the real world. The proposed method employs an empirical model to reveal the wireless propagation law as a priori knowledge and guide the training steps of the deep learning model. Finally, the experimental results verify the accuracy and generalization performance of the proposed image-to-image wireless propagation model.},
  keywords={Estimation;Predictive models;Wireless communication;Data models;Computational modeling;Buildings;Training;Reference signal receiving power;wireless propagation model;conditional generative adversarial networks},
  doi={10.1109/TCCN.2023.3307945},
  ISSN={2332-7731},
  month={Dec},}@ARTICLE{9537922,
  author={Nabeel, Muhammad and Hashmi, Umair Sajid and Ekin, Sabit and Refai, Hazem and Abu-Dayya, Adnan and Imran, Ali},
  journal={IEEE Network}, 
  title={SpiderNet: Spectrally Efficient and Energy Efficient Data Aided Demand Driven Elastic Architecture for 6G}, 
  year={2021},
  volume={35},
  number={5},
  pages={256-263},
  abstract={Legacy base station (BS) centric cellular architecture is marked by tight interlock between spectral efficiency (SE) and energy efficiency (EE). That means, unless new degrees of freedom and intelligent dynamic adaptability is added, any significant gain in SE must come at the cost of EE. Even the most predominant approaches for capacity enhancement such as network densification yield gains in SE at the cost of increased energy consumption. Moreover, in future mobile networks, the key challenge is not only the rampantly growing volume of traffic, but also the spatiotemporal variability of the traffic. These observations call for a paradigm shift in the way cellular networks are designed and operated. Therefore, in this work, we propose a new cellular architecture called SpiderNet: Spectrally Efficient and Energy Efficient Data Aided Demand Driven Elastic Architecture for 6G Wireless Networks. The key idea behind SpiderNet is to introduce additional degrees of freedom to relax the tight coupling between the SE and EE and database-aided intelligence to enable dynamic adaptive operation for simultaneous enhancement of both SE and EE. This goal is achieved by shifting the pivot of operation from the rigid always ON BS centric cells to user centric (UC) on demand cells. The SpiderNet architecture consists of a layer of low-density large footprint and database aided control BS underlayed by high-density switchable data BS. This database enables artificial intelligence (AI) powered proactive dynamic orchestration of UC cells to maximize not only SE and EE, but quality of experience (QoE) as well. We also identify the challenges that arise in the practical realization of SpiderNet and propose solutions. Finally, we present a case study that compares SpiderNet performance with legacy HetNets. The results show that compared to current BS centric cellular architecture, SpiderNet can substantially enhance both SE and EE without compromising QoE.},
  keywords={Computer architecture;Satellite broadcasting;Microprocessors;Switches;6G mobile communication;Base stations;Artificial intelligence},
  doi={10.1109/MNET.101.2000635},
  ISSN={1558-156X},
  month={Sep.},}@INPROCEEDINGS{9624383,
  author={Song, Sifan and Huang, Daiyun and Hu, Yalun and Yang, Chunxiao and Meng, Jia and Ma, Fei and Coenen, Frans and Zhang, Jiaming and Su, Jionglong},
  booktitle={2021 14th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)}, 
  title={A Novel Application of Image-to-Image Translation: Chromosome Straightening Framework by Learning from a Single Image}, 
  year={2021},
  volume={},
  number={},
  pages={1-9},
  abstract={In medical imaging, chromosome straightening plays a significant role in the pathological study of chromosomes and in the development of cytogenetic maps. Whereas different approaches exist for the straightening task, typically geometric algorithms are used whose outputs are characterized by jagged edges or fragments with discontinued banding patterns. To address the flaws in the geometric algorithms, we propose a novel framework based on image-to-image translation to learn a pertinent mapping dependence for synthesizing straightened chromosomes with uninterrupted banding patterns and preserved details. In addition, to avoid the pitfall of deficient input chromosomes, we construct an augmented dataset using only one single curved chromosome image for training models. Based on this framework, we apply two popular image-to-image translation architectures, U-shape networks and conditional generative adversarial networks, to assess its efficacy. Experiments on a dataset comprised of 642 real-world chromosomes demonstrate the superiority of our framework, as compared to the geometric method in straightening performance, by rendering realistic and continued chromosome details. Furthermore, our straightened results improve the chromosome classification by 0.98%-1.39 % mean accuracy.},
  keywords={Training;Pathology;Computational modeling;Computer architecture;Transforms;Signal processing;Rendering (computer graphics);Conditional Generative Adversarial Networks;Curved Chromosomes;Image-to-Image Translation;Straightening Framework},
  doi={10.1109/CISP-BMEI53629.2021.9624383},
  ISSN={},
  month={Oct},}@ARTICLE{9769916,
  author={Liu, Si and Bao, Renda and Zhu, Defa and Huang, Shaofei and Yan, Qiong and Lin, Liang and Dong, Chao},
  journal={IEEE Transactions on Multimedia}, 
  title={Fine-Grained Face Editing via Personalized Spatial-Aware Affine Modulation}, 
  year={2023},
  volume={25},
  number={},
  pages={4213-4224},
  abstract={Fine-grained face editing, as a special case of image translation task, aims at modifying face attributes according to users’ preference. Although generative adversarial networks (GANs) have achieved great success in general image translation tasks, these models cannot be directly applied in the face editing problem. Ideal face editing is challenging as it has two special requirements – personalization and spatial-awareness. To address these issues, we propose a novel Personalized Spatial-aware Affine Modulation (PSAM) method based on a general GAN structure. The key idea is to modulate the intermediate features in a personalized and spatial-aware manner, which corresponds to the face editing procedure. Specifically, for personalization, we adopt both the face image and the desired attribute as input to generate the modulation tensors. For spatial-aware, we set these tensors to be of the same size as the input image, allowing pixel-wise modulation. Extensive experiments in four fine-grained face editing tasks, i.e., makeup, expression, illumination and aging, demonstrate the effectiveness of the proposed PSAM method. The synthesis results of PSAM can be further boosted by a new transferable training strategy.},
  keywords={Faces;Modulation;Task analysis;Tensors;Training;Generators;Lighting;Fine-grained;face editing;generative adversarial networks},
  doi={10.1109/TMM.2022.3172548},
  ISSN={1941-0077},
  month={},}@ARTICLE{10375493,
  author={Chen, Fangjie and Bai, Jingpeng and Gao, Weihan},
  journal={IEEE Access}, 
  title={Research on Encrypted Traffic Detection Based on Key Features}, 
  year={2024},
  volume={12},
  number={},
  pages={1786-1793},
  abstract={Most of the traffic on the Internet is encrypted traffic, and the detection of encrypted traffic is the current difficulty, because the internal features of the data are destroyed after encryption, and it is difficult to detect. Most of the existing detection of encrypted traffic is based on the external features of encrypted traffic, which requires the extraction of full-cycle information of traffic, and has poor real-time performance. Therefore, based on the internal features of encrypted traffic, this paper proposes a Key Feature Fusion Detection (KFFD) method based on generative adversarial network, which restores the destroyed internal features by encryption key and generative adversarial network, and then improves the internal feature recognition effect of encrypted traffic. Experiments using the Kaggle dataset show that the KFFD method can improve the detection performance of encrypted traffic to a certain extent.},
  keywords={Feature extraction;Cryptography;Data mining;Fingerprint recognition;Generative adversarial networks;Deep learning;Data models;Network security;intrusion detection systems;encrypted traffic detection;GAN;key features;artificial intelligence;machine learning;deep learning},
  doi={10.1109/ACCESS.2023.3347806},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10968991,
  author={Rao Bittla, Srinivasa and Riadhusin, Rame and Malathi, M. and TL, Nethravathi and Aravindh, S.},
  booktitle={2025 3rd International Conference on Integrated Circuits and Communication Systems (ICICACS)}, 
  title={Fault Detection in Transmission Lines via Transfer Functions Based on Multi-Agent Reinforcement Learning}, 
  year={2025},
  volume={},
  number={},
  pages={01-06},
  abstract={In recent years, fault detection addresses high-impedance faults in transmission lines which is crucial for creating reliability and safety in distributed system. The improvements in power system fault detection have employed intelligent techniques like Deep Learning (DL) and Reinforcement Learning (RL) models to improve accuracy and reliability. The existing methods struggled with exact fault detection under varying fault conditions such as changing network topologies, high impedance, and power swings. This research proposed a Multi-Agent Reinforcement Learning (MARL) framework integrated with Transfer Function (TF) analysis to convert the voltage and current signals into the frequency domain, capturing changes caused by faults. The features are extracted through Convolution Neural Network (CNN) to learn automatically and extract complex patterns from TF, and effective detection of faults. MARL employs multiple agents distributed across the power network for detecting and localizing faults through independent learning and decision-making, improving accuracy, adaptability in fault detection tasks. Finally, results of proposed MARL frame work shows that fault detection achieved high performance better outcomes compared to existing Conditional Tabular Generative Adversarial Network (CTGAN) in terms of precision, recall and F1 score by achieving 0.95%, 0.85% and 0.88% respectively.},
  keywords={Accuracy;Power transmission lines;Fault detection;Transfer functions;Reinforcement learning;Voltage;Feature extraction;Electrical fault detection;Power system reliability;Reliability;convolution neural network;conditional tabular;fault detection;generative adversarial network;multi-agent reinforcement learning;transfer function},
  doi={10.1109/ICICACS65178.2025.10968991},
  ISSN={},
  month={Feb},}@ARTICLE{10935704,
  author={Ali, Abdelhay and Abdelrahman, Amr N. and Celik, Abdulkadir and Fouda, Mohammed E. and Eltawil, Ahmed M.},
  journal={IEEE Sensors Journal}, 
  title={A Robust Autoencoder HBC Transceiver With CGAN-Based Channel Modeling}, 
  year={2025},
  volume={25},
  number={9},
  pages={15935-15949},
  abstract={Human body communication (HBC) offers a promising alternative for efficient and secure data transmission in wearable healthcare systems by leveraging the body’s conductive properties. Using the conductive properties of the human body, HBC offers significant advantages over conventional radio frequency wireless communication methods, including ultralow power consumption and minimal interference. However, HBC systems face key challenges in energy efficiency, data rate optimization, channel adaptability, and accurate body channel modeling. In this article, we present a novel dual-mode HBC transceiver architecture designed to overcome these challenges by integrating autoencoder-based signal processing with generative adversarial network (GAN)-driven channel modeling framework to enhance communication reliability. Operating in both broadband and narrowband modes, the transceiver dynamically adjusts its data rate and power efficiency based on application-specific demands. The design process involves first developing a conditional GAN (CGAN)-based channel model from real HBC measurements, and then using this model to train an autoencoder-based transceiver architecture. Our CGAN framework generates realistic synthetic channel responses for training, enabling the autoencoder to learn optimal encoding and decoding strategies that are robust to channel variations. Subsequently, we developed a low-power hardware architecture that supports flexible data rates of the proposed design while ensuring robust performance in diverse scenarios. This systematic approach provides key advantages: improved channel modeling accuracy achieving a 0.9 correlation coefficient between generated and real channels and mean squared error (mse) of 0.0071, reduced hardware complexity through elimination of digital-to-analog converter (DAC)/analog-to-digital converter (ADC), and flexible operation with dual-mode support. Operating at a clock speed of 42 MHz in the narrowband mode, the transceiver achieves an energy efficiency of 349 pJ/bit at a data rate of 262.5 kb/s with a sensitivity of −64 dBm, appealing for long-range and low-power applications. In broadband mode, the transceiver achieves an energy efficiency of 16 pJ/bit at a data rate of 5.25 Mb/s, suitable for applications demanding high data rates over shorter distances.},
  keywords={Transceivers;Autoencoders;Electrodes;Biosensors;Energy efficiency;Training;Narrowband;Hardware;Broadband communication;Wireless communication;Conditional generative adversarial network (CGAN) channel modeling;deep learning;end-to-end communication;human body communication (HBC);Internet of bodies (IoBs)},
  doi={10.1109/JSEN.2025.3551539},
  ISSN={1558-1748},
  month={May},}@ARTICLE{10787142,
  author={Huang, Kun and Gao, Mengmeng and Antonecchia, Emanuele and Zhang, Li and Zhou, Ziling and Zou, Xianghui and Li, Zhen and Cao, Wei and Liu, Yuqing and D’Ascenzo, Nicola},
  journal={IEEE Transactions on Radiation and Plasma Medical Sciences}, 
  title={Enhanced Risk Stratification of Gastrointestinal Stromal Tumors Through Cross-Modality Synthesis from CT to [¹⁸F]-FDG PET Images}, 
  year={2025},
  volume={9},
  number={4},
  pages={487-496},
  abstract={Risk stratification algorithms for gastrointestinal stromal tumors (GISTs) are mainly based on computed tomography (CT) data. Though [18F]-fluorodeoxyglucose positron emission tomography ([18F]-FDG PET) imaging may improve their performance, challenges in image interpretation in the gastrointestinal tract still limit the widespread integration of PET into routine clinical protocols, causing a poor availability of PET data to develop and train stratification models. To solve this issue, we propose to enrich existing [18F]-FDG PET GIST datasets with pseudo-images generated with a novel conditional PET generative adversarial network (CPGAN), which employs a weighted fusion of CT images and tumor masks, embedding also clinical data. As for GIST assessment, we propose the transformer-based multimodal network for GIST risk stratification (TMGRS), which is trained on the enriched dataset and exploits the properties of transformers to process simultaneously PET and CT images. The training and validation of the models were conducted on a multicenter dataset comprising 208 patients. In comparison with the existing stratification methods, CPGAN-synthesized PET images show a peak signal-to-noise ratio increased on average by 18% and improve risk stratification, which achieves a remarkable accuracy of 0.937 when TMGRS network is used. Results underscore the potential of CPGAN network in providing more reliable GIST predictions.},
  keywords={Tumors;Computed tomography;Transformers;Feature extraction;Medical diagnostic imaging;Generators;Positron emission tomography;Plasmas;Training;Image reconstruction;Computed tomography (CT);gastrointestinal stromal tumor (GIST);generative adversarial network (GAN);PET;risk stratification;Transformer},
  doi={10.1109/TRPMS.2024.3514779},
  ISSN={2469-7303},
  month={April},}@INPROCEEDINGS{10889299,
  author={Lin, Kai and Zhao, Caidan and Chen, Jingqian and Xiao, Liang},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={RF Distillation Diffusion Model: An Efficient RFF Data Augmentation Method}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Radio Frequency Fingerprint (RFF) based physical layer authentication technology provides enhanced security for wireless communications. However, the spatiotemporal overlap of wireless signals makes it challenging to label wireless device samples. Moreover, generative networks, such as Generative Adversarial Networks (GANs) struggle to retain the subtle signal features. Utilizing existing unlabeled samples poses a significant challenge for RFF data augmentation. This paper proposes the RF Distillation Diffusion (RFDD) model, an efficient method for RFF data augmentation. RFDD employs a conditional diffusion model to generate high-quality RF signals, which fully utilizes existing unlabeled samples to learn the data distribution of signals, and labeled samples are used to enhance the capability of RFF feature extraction. Additionally, knowledge distillation is utilized to improve sampling efficiency. Experimental results show that the RFDD can fully use 20% unlabeled samples to generate high-quality synthetic RF signals within only 0.45 seconds and improve RFF identification accuracy by 25.63% with 40% synthetic signals under SNRs from -5 to 5 dB. The code is available at https://github.com/XMU-Kai/RFDD},
  keywords={Wireless communication;Radio frequency;Training;Accuracy;RF signals;Fingerprint recognition;Data augmentation;Diffusion models;Communication system security;Speech processing;radio frequency fingerprinting;guided diffusion models;knowledge distillation;data augmentation},
  doi={10.1109/ICASSP49660.2025.10889299},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{9936506,
  author={Jain, Sapna and Alam, M. Afshar},
  booktitle={2022 Second International Conference on Computer Science, Engineering and Applications (ICCSEA)}, 
  title={Development of Application Software for Generating Music Composition Inspired by Nature Using Deep Learning}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Music composition for small-scale gaming companies to generate theme music to generate unique notes for each level of the game demands the requirement of machine learning-based automated nature-inspired music composition. It is worth mentioning that even great musicians usually get inspired by nature to compose the musical notes for the film. In this paper, an attempt is planned to develop the application software to generate musical notes using Deep learning. Deep learning algorithm can help to get predictions, classifications, and decisions based on the data without extracting the features from the data. We propose to use a Deep learning algorithm to hunt tunes from nature.},
  keywords={Deep learning;Software algorithms;Music;Ocean waves;Prediction algorithms;Feature extraction;Mobile applications;Deep learning;Machine learning;Computational intelligence;Mobile application software;Artificial intelligence},
  doi={10.1109/ICCSEA54677.2022.9936506},
  ISSN={},
  month={Sep.},}@INBOOK{10745049,
  author={Arellano, Karen Chappell},
  booktitle={Collaborative Intelligence: How Humans and AI Are Transforming Our World}, 
  title={11 When Artificial Intelligence Meets the Metaverse: An AI-Fueled Immersive Cyberspace}, 
  year={2024},
  volume={},
  number={},
  pages={237-261},
  abstract={In 1992, Neal Stephenson&#x0027;s science fiction book Snow Crash introduced the term &#x201C;metaverse.&#x201D; As the story unfolds, we see the main protagonists and their avatars navigating a hybrid virtual-physical environment that is filled with virtual creatures on top of their physical surroundings. People can carry out a variety of immersive activities in such a mixed environment. The most prominent instances include socializing with their friends online, working together with their coworkers, and sharing virtual activities on a massive scale (e.g., concerts and shopping). To put it another way, digital or virtual material from cyberspace (i.e., the next generation of the Internet) will eventually permeate our physical surroundings, going significantly beyond our present cyberspace&#x0027;s primary 2D user interfaces. To enable such a vision for the metaverse, we foresee that human users will be surrounded by enormous numbers of sensors and intelligent objects to support seamless interaction between human users and immersive 3D environments.},
  keywords={},
  doi={},
  ISSN={},
  publisher={MIT Press},
  isbn={9780262381178},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10745049},}@ARTICLE{9395437,
  author={Massaoudi, Mohamed and Abu-Rub, Haitham and Refaat, Shady S. and Chihi, Ines and Oueslati, Fakhreddine S.},
  journal={IEEE Access}, 
  title={Deep Learning in Smart Grid Technology: A Review of Recent Advancements and Future Prospects}, 
  year={2021},
  volume={9},
  number={},
  pages={54558-54578},
  abstract={The current electric power system witnesses a significant transition into Smart Grids (SG) as a promising landscape for high grid reliability and efficient energy management. This ongoing transition undergoes rapid changes, requiring a plethora of advanced methodologies to process the big data generated by various units. In this context, SG stands tied very closely to Deep Learning (DL) as an emerging technology for creating a more decentralized and intelligent energy paradigm while integrating high intelligence in supervisory and operational decision-making. Motivated by the outstanding success of DL-based prediction methods, this article attempts to provide a thorough review from a broad perspective on the state-of-the-art advances of DL in SG systems. Firstly, a bibliometric analysis has been conducted to categorize this review's methodology. Further, we taxonomically delve into the mechanism behind some of the trending DL algorithms. We then showcase the DL enabling technologies in SG, such as federated learning, edge intelligence, and distributed computing. Finally, challenges and research frontiers are provided to serve as guidelines for future work in the futuristic power grid domain. This study's core objective is to foster the synergy between these two fields for decision-makers and researchers to accelerate DL's practical deployment for SG systems.},
  keywords={Forecasting;Deep learning;Artificial intelligence;Smart grids;Collaborative work;Predictive models;Renewable energy sources;Smart grid;deep learning;deep neural networks;edge computing;distributed and federated learning;power systems},
  doi={10.1109/ACCESS.2021.3071269},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10795392,
  author={Rao, Kunal and Coviello, Giuseppe and Chakradhar, Srimat},
  booktitle={2024 IEEE Conference on Pervasive and Intelligent Computing (PICom)}, 
  title={DiCE: Distributed Code Generation and Execution}, 
  year={2024},
  volume={},
  number={},
  pages={8-15},
  abstract={Generative artificial intelligence (GenAI), specifically, Large Language Models (LLMs), have shown tremendous potential in automating several tasks and improving human productivity. Recent works have shown them to be quite useful in writing and summarizing text (articles, blogs, poems, stories, songs, etc.), answering questions, brainstorming ideas, and even writing code. Several LLMs have emerged specifically targeting code generation. Given a prompt, these LLMs can generate code in any desired programming language. Many tools like ChatGPT, CoPilot, CodeWhisperer, Cody, DeepSeek Coder, StarCoder, etc. are now routinely being used by software developers. However, most of the prior work in automatic code generation using LLMs is focused on obtaining “correct” and working code, and mainly runs on a single computer (serial code). In this paper, we take this to the next level, where LLMs are leveraged to generate code for execution on a distributed infrastructure. We propose a novel system called DiCE, which takes serial code as input and automatically generates distributed version of the code and efficiently executes it on a distributed setup. DiCE consists of two main components (a) LLM-based tool (Synthia) to understand dependencies in serial code and automatically generate distributed version of the code using specialized programming model and semantics, and (b) Runtime (Hermod) to understand the semantics in the distributed code and realize efficient execution on a cluster of machines (distributed infrastructure). DiCE currently focuses on visual programs synthesized by tools like ViperGPT [1] and VisReP [2] (serial code), automatically identifies higher-level task parallelism opportunities (e.g., parallel object detection), transforms the code to exploit the parallelism, and finally efficiently executes it on a cluster of machines. Through our experiments using 100 examples from the GQA dataset [3], we show that the serial codes generated by ViperGPT are successfully transformed into distributed codes which are then efficiently executed on a cluster of machines by DiCE. We note that DiCE correctly identifies opportunities for parallelism and distributes tasks on separate GPUs within the cluster. We observe an average speed-up of 2X, 2.95X, and 3.7X, and an average efficiency of 1, 0.74 and 0.48 for a cluster of 2 nodes, 4 nodes, and 8 nodes, respectively.},
  keywords={Visualization;Codes;Runtime;Generative AI;Semantics;Transforms;Parallel processing;Writing;Programming;Software;Generative Artificial Intelligence (GenAI);Large Language Models (LLM);code generation;code optimization;parallel computing;distributed computing;distributed systems;distributed runtime},
  doi={10.1109/PICom64201.2024.00008},
  ISSN={},
  month={Nov},}@ARTICLE{10843783,
  author={Guo, Shuaishuai and Wang, Yanhu and Ye, Jia and Zhang, Anbang and Zhang, Peng and Xu, Kun},
  journal={IEEE Transactions on Machine Learning in Communications and Networking}, 
  title={Semantic Importance-Aware Communications With Semantic Correction Using Large Language Models}, 
  year={2025},
  volume={3},
  number={},
  pages={232-245},
  abstract={Semantic communications, a promising approach for agent-human and agent-agent interactions, typically operate at a feature level, lacking true semantic understanding. This paper explores understanding-level semantic communications (ULSC), transforming visual data into human-intelligible semantic content. We employ an image caption neural network (ICNN) to derive semantic representations from visual data, expressed as natural language descriptions. These are further refined using a pre-trained large language model (LLM) for importance quantification and semantic error correction. The subsequent semantic importance-aware communications (SIAC) aim to minimize semantic loss while respecting transmission delay constraints, exemplified through adaptive modulation and coding strategies. At the receiving end, LLM-based semantic error correction is utilized. If visual data recreation is desired, a pre-trained generative artificial intelligence (AI) model can regenerate it using the corrected descriptions. We assess semantic similarities between transmitted and recovered content, demonstrating ULSC’s superior ability to convey semantic understanding compared to feature-level semantic communications (FLSC). ULSC’s conversion of visual data to natural language facilitates various cognitive tasks, leveraging human knowledge bases. Additionally, this method enhances privacy, as neither original data nor features are directly transmitted.},
  keywords={Semantics;Visualization;Natural languages;Error correction;Receivers;Generative AI;Semantic communication;Channel coding;Vectors;Transmitters;Semantic communications;semantic error correction;large language models;generative artificial intelligence},
  doi={10.1109/TMLCN.2025.3530875},
  ISSN={2831-316X},
  month={},}@INPROCEEDINGS{10713958,
  author={Gonzalez-Barahona, Jesus M.},
  booktitle={2024 IEEE/ACM First IDE Workshop (IDE)}, 
  title={Software Development in the Age of LLMs and XR}, 
  year={2024},
  volume={},
  number={},
  pages={66-69},
  abstract={Let's imagine that in a few years generative AI has changed software development dramatically, taking charge of most of the programming tasks. Let's also assume that extended reality devices became ubiquitous, being the preferred interface for interacting with computers. This paper proposes how this situation would impact IDEs, by exploring how the development process would be affected, and analyzing which tools would be needed for supporting developers.},
  keywords={Training;Codes;Extended reality;Speech coding;Production;User interfaces;Programming;Software;Speech processing;Software development management;XR;VR;AR;extended reality;LLM;generative AI;IDE;software development},
  doi={10.1145/3643796.3648457},
  ISSN={},
  month={April},}@INPROCEEDINGS{10868064,
  author={Chen, Ziqi and Xiong, Zhaoyang and Ruan, Xinli and Jiang, Shujing and Wei, Wei and Fang, Ke},
  booktitle={2024 4th International Conference on Educational Technology (ICET)}, 
  title={Exploring Learners' Interactions with GenAI Agents in Educational Games: Typologies and Emotional Factors in Human-Computer Interaction}, 
  year={2024},
  volume={},
  number={},
  pages={136-140},
  abstract={This study explores and compares learners' interactions with Generative Artificial Intelligence (GenAI) within an educational game context. Data from 365 dialogues were collected from 76 K12 students at a middle school in Suzhou, China, who had conversations with GenAI agents in an educational game environment. Drawing upon a framework adapted from the classification system of learners' online asynchronous discussions, six categories were utilized: social and affective (ES), information (Inf), questions (Q&A), ideas (ID), agency (EA), and meta-recapitulation (MA). The study revealed several important findings. Firstly, students' responses contained less information (Inf) and meta-recapitulation (MA) due to the limitations of GenAI in providing authoritative and external resources of information. Secondly, players’ social and affective outputs (ES) were associated with mixed emotions, with the majority of emotions experienced by the students being negative (82.02%), and the reasons behind these negative emotions include mistrust of GenAI during or prior to the game, GenAI misinterpreting players’ ideas, a mismatch with players’ expectations, and GenAI repeatedly outputting the same text. Overall, this study sheds light on the complex dynamics of learners' dialogues with GenAI in educational environment, highlighting the learning opportunities and challenges for improving AI-driven educational experiences.},
  keywords={Human computer interaction;Generative AI;Games;Oral communication;Educational technology;generative artificial intelligence (GenAI);educational game;human-computer interaction (HCI);interactive typology;emotion},
  doi={10.1109/ICET62460.2024.10868064},
  ISSN={},
  month={Sep.},}@ARTICLE{10965859,
  author={Liu, Chenxi and Sun, Gan and Liang, Wenqi and Dong, Jiahua and Qin, Can and Cong, Yang},
  journal={IEEE Transactions on Image Processing}, 
  title={MuseumMaker: Continual Style Customization Without Catastrophic Forgetting}, 
  year={2025},
  volume={34},
  number={},
  pages={2499-2512},
  abstract={Pre-trainedlarge text-to-image (T2I) models with an appropriate text prompt has attracted growing interests in customized image generation fields. However, catastrophic forgetting issue makes it hard to continually synthesize new user-provided styles while retaining the satisfying results amongst learned styles. In this paper, we propose MuseumMaker, a method that enables the synthesis of images by following a set of customized styles in a never-end manner, and gradually accumulates these creative artistic works as a Museum. When facing with a new customization style, we develop a style distillation loss module to extract and learn the styles of the training data for new image generation task. It can minimize the learning biases caused by content of new training images, and address the catastrophic overfitting issue induced by few-shot images. To deal with catastrophic forgetting issue amongst past learned styles, we devise a dual regularization for shared-LoRA module to optimize the direction of model update, which could regularize the diffusion model from both weight and feature aspects, respectively. Meanwhile, to further preserve historical knowledge from past styles and address the limited representability of LoRA, we design a task-wise token learning module where a unique token embedding is learned to denote a new style. As any new user-provided style come, our MuseumMaker can capture the nuances of the new styles while maintaining the details of learned styles. Experimental results on diverse style datasets validate the effectiveness of our proposed MuseumMaker method, showcasing its robustness and versatility across various scenarios.},
  keywords={Diffusion models;Continuing education;Text to image;Training;Overfitting;Image synthesis;Electronic mail;Training data;Sun;Generative adversarial networks;Text-to-image model;image generation;style customization;continual learning},
  doi={10.1109/TIP.2025.3553024},
  ISSN={1941-0042},
  month={},}@INPROCEEDINGS{11050326,
  author={Hornek, Timothée and Sartipi, Amir and Tchappi, Igor and Fridgen, Gilbert},
  booktitle={2025 21st International Conference on the European Energy Market (EEM)}, 
  title={Benchmarking Pre-Trained Time Series Models for Electricity Price Forecasting}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Accurate electricity price forecasting (EPF) is crucial for effective decision-making in power trading on the spot market. While recent advances in generative artificial intelligence (GenAI) and pre-trained large language models (LLMs) have inspired the development of numerous time series foundation models (TSFMs) for time series forecasting, their effectiveness in EPF remains uncertain. To address this gap, we benchmark several state-of-the-art pretrained models—Chronos-Bolt, Chronos-T5, TimesFM, Moirai, Time-MoE, and TimeGPT—against established statistical and machine learning (ML) methods for EPF. Using 2024 day-ahead auction (DAA) electricity prices from Germany, France, the Netherlands, Austria, and Belgium, we generate daily forecasts with a one-day horizon. Chronos-Bolt and Time-MoE emerge as the strongest among the TSFMs, performing on par with traditional models. However, the biseasonal MSTL model, which captures daily and weekly seasonality, stands out for its consistent performance across countries and evaluation metrics, with no TSFM statistically outperforming it.},
  keywords={Measurement;Training;Generative AI;Electricity;Time series analysis;Europe;Predictive models;Benchmark testing;Power markets;Forecasting;electricity price forecasting;generative artificial intelligence;benchmark;pre-trained time-series models},
  doi={10.1109/EEM64765.2025.11050326},
  ISSN={2165-4093},
  month={May},}@INPROCEEDINGS{10846743,
  author={Chen, Yi and Li, Yanshan and Yang, Jiahao},
  booktitle={2024 IEEE 17th International Conference on Signal Processing (ICSP)}, 
  title={The design of prompts driven by Chain of Thought in multicultural teaching}, 
  year={2024},
  volume={},
  number={},
  pages={258-262},
  abstract={Generative large language models (LLMs) show promise in multicultural teaching, but existing methods rely heavily on labeled data and resources, struggling to capture cultural nuances and generalize across various teaching contexts. To address the above issues, the paper introduces an innovative method called Multicultural Prompt Learning (MPL), which applies Chain of Thought (CoT) to prompt design. By gradually refining prompts, multicultural elements are integrated step by step, enabling AI to better understand and handle cultural nuances. This approach produces richer, more accurate, and diverse outputs, specifically aimed at enhancing students’ understanding of different cultures in multicultural teaching contexts. The experiment used a questionnaire, including image quality evaluation and a blind content comprehension, to compare Chain of Thought and traditional prompts. Results show Chain of Thought prompts outperform traditional methods in all dimensions, offering greater practical and educational value.},
  keywords={Surveys;Multiprotocol label switching;Design methodology;Education;Refining;Signal processing;Cultural differences;Prompt engineering;Standards;Optimization;Generative large language models(LLMs);Multicultural prompt learning;chain-of-thought(CoT)},
  doi={10.1109/ICSP62129.2024.10846743},
  ISSN={2164-5221},
  month={Oct},}@INPROCEEDINGS{10604929,
  author={Navas-González, Rafael and Vidal-Verdú, Fernando},
  booktitle={2024 XVI Congreso de Tecnología, Aprendizaje y Enseñanza de la Electrónica (TAEE)}, 
  title={Exploring Chat-GPT for its use in Electronic and Biomedical Instrumentation Courses}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={This paper explores the use of Generative Artificial Intelligence (Chat-GPT) in the subjects of Electronic Instrumentation and Biomedical Instrumentation as a tool to introduce and reinforce theoretical concepts, and to develop transversal competencies: reading and writing in the context of engineering.},
  keywords={Training;Accuracy;Generative AI;Instruments;Bibliographies;Focusing;Collaboration;Palabras clave—Chat-GPT;transversal skills;reading and writing in engineering;teaching in electronics;generative artificial intelligence},
  doi={10.1109/TAEE59541.2024.10604929},
  ISSN={2766-2616},
  month={June},}@INPROCEEDINGS{10391696,
  author={Singh, Tanmay and Rai, Parijat and Sood, Saumil and Nigam, Siddhant and Kumari, Suchi},
  booktitle={2023 Second International Conference On Smart Technologies For Smart Nation (SmartTechCon)}, 
  title={Adversarial Attacks and Defences of Various Artificial Intelligent Models}, 
  year={2023},
  volume={},
  number={},
  pages={210-215},
  abstract={Adversarial attacks are becoming increasingly common and sophisticated as time passes and new defenses are being researched and developed. Adversarial machine learning is one of the techniques used to attack artificial intelligence models by feeding deceptive data. Therefore, in this paper, adversarial attacks against machine learning and deep learning are studied, and some defense strategies are also proposed against them. Two attack strategies; Evasion and Poison are used to attack the Support Vector Machine (SVM) model and Convolution Neural Network (CNN) model, respectively. Some defense mechanisms are applied to safeguard the models from such attacks. The models are applied and tested on the MNIST dataset. The results obtained from the models, before and after the defenses are applied are compared.},
  keywords={Support vector machines;Deep learning;Toxicology;Convolution;Neural networks;Data models;Adversarial machine learning;Adversarial attack;machine learning;deep learning;Evasion attack;and Poison attack},
  doi={10.1109/SmartTechCon57526.2023.10391696},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10773838,
  author={Nathanson, Samuel and Yoo, Yungjun and Na, David and Cao, Yinzhi and Watkins, Lanier},
  booktitle={MILCOM 2024 - 2024 IEEE Military Communications Conference (MILCOM)}, 
  title={A Step Towards Modern Disinformation Detection: Novel Methods for Detecting LLM-Generated Text}, 
  year={2024},
  volume={},
  number={},
  pages={615-620},
  abstract={New generative artificial intelligence (GenAI) technology could have devastating consequences on our democracy because it can be easily used to spread disinformation at scale while simultaneously personalizing propaganda to demographics or individuals. The threat is significant – Large-scale GenAI-based disinformation campaigns can sway public opinion, shape political events, or even compromise the integrity of elections. One method for defending against large-scale GenAI disinformation is to build tools for autonomously detecting AI-generated content. In this article, we evaluate state-of-the-art AI detection tools. Additionally, we propose a novel AI content detection method which demonstrates up to a 48% improvement in accuracy (over existing tools) for autonomously detecting AI-generated content.},
  keywords={Military communication;Accuracy;Shape;Generative AI;Voting;Fake news;Generative AI;machine learning;Artificial Intelligence;cybersecurity;disinformation;Large Language Model},
  doi={10.1109/MILCOM61039.2024.10773838},
  ISSN={2155-7586},
  month={Oct},}@INPROCEEDINGS{10638907,
  author={Fadhl, Ayyah Abdulhafith Mahmoud and Shareif, Hanein Omar Mohamed and Ali, Malak Ahmed Elsherif and Elmangoush, Abdullah Mohammad Abdullah},
  booktitle={2024 IEEE 7th International Conference on Advanced Technologies, Signal and Image Processing (ATSIP)}, 
  title={Adaptive Image Steganography: A Review and Research Directions*}, 
  year={2024},
  volume={1},
  number={},
  pages={494-499},
  abstract={Steganography involves concealing secret information in an appropriate multimedia carrier, such as text, image, audio, and video files, in such a way that only the sender and receiver suspect the existence of the secret information. Images are the most popular multimedia carriers. Adaptive image steganography is a promising new trend in the steganographic field. It basically means that the embedding locations are altered adaptively depending on the image content. The primary objective of this paper is to investigate and discuss various approaches to adaptive image steganography. The approaches can be broadly categorized as CNN-based, end_to_end GAN-based, and minimizing additive distortion function-based, both huristically and automatically designed. In addition to discussing the four categorized approaches, this paper provides an overview of image steganography including its characteristics or properties, and evaluation metrics. A summary table of all the details is also provided for convenience. The purpose of this paper is to assist fellow researchers by compiling current trends, their advantages and disadvantages, and identifying improvement gaps},
  keywords={Training;Steganography;Additives;Reviews;Streaming media;Market research;Generative adversarial networks;Adaptive Image Steganography;Content Adaptive Image Steganography;CNN-based;end_to_end GAN-based;minimizing additive distortion function-based},
  doi={10.1109/ATSIP62566.2024.10638907},
  ISSN={2687-878X},
  month={July},}@ARTICLE{11030258,
  author={Yu, Peng and Zhang, Xin and Ma, Liang and Liang, Yikai},
  journal={IEEE Transactions on Engineering Management}, 
  title={How Challenge Stressors Affect GenAI-Enabled Employee Innovation? Based on Transactional Theory of Stress and Coping Model}, 
  year={2025},
  volume={72},
  number={},
  pages={2600-2610},
  abstract={The rapid development of generative artificial intelligence (GenAI) presents new opportunities to address challenge stressors and enable employee innovation. However, research on how challenge stressors affect employee innovation in the context of GenAI remains limited. Based on the transactional theory of stress and coping, this study explores how challenge stressors (time pressure and learning demand) affect GenAI-enabled employee innovation through the mediating role of ambidextrous GenAI use (exploitative use and exploratory use) and the boundary role of perceived GenAI feedback quality. By analyzing questionnaire data collected from 330 employees across various industries, this study found that challenge stressors positively influence both exploitative GenAI use and exploratory GenAI use, which in turn enhance GenAI-enabled employee innovation. In addition, perceived GenAI feedback quality weakens the positive effect of time pressure on exploitative GenAI use but strengthens the positive impact of learning demand on exploitative GenAI use. These results contribute significantly to the literature by exploring the mechanisms and boundary conditions under which challenge stressors influence employee innovation in the context of GenAI. In practice, this study provides valuable insights for policymakers and technology managers to manage employee stress, develop employee innovation, and optimize GenAI implementation to fully realize the long-term value of GenAI.},
  keywords={Technological innovation;Stress;Training;Data mining;Boundary conditions;Employment;Transforms;Industries;Generative AI;Surveys;Challenge stressors (CSs);employee innovation;exploitative use;exploratory use;generative artificial intelligence (GenAI)},
  doi={10.1109/TEM.2025.3578623},
  ISSN={1558-0040},
  month={},}@ARTICLE{10964397,
  author={Ma, Wanlun and Wang, Derui and Song, Yiliao and Xue, Minhui and Wen, Sheng and Li, Zhengdao and Xiang, Yang},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={TrapNet: Model Inversion Defense via Trapdoor}, 
  year={2025},
  volume={20},
  number={},
  pages={4469-4483},
  abstract={Model inversion (MI) attacks, for which effective defense strategies are still lacking, pose significant risks to privacy by reconstructing private training data through access to well-trained classifiers. Addressing this concern, this study introduces TrapNet, designed to defend against advanced MI attacks while maintaining good model utility. TrapNet intentionally injects trapdoors into the classification manifold of the protected target model. In this way, TrapNet can effectively mislead MI attack optimization. Specifically, TrapNet leverages a conditional GAN (cGAN) trained on the private dataset to generate diverse and realistic trapdoor samples. In addition, we propose a graph-matching self-obfuscation strategy and an entropy regularization technique to optimize trapdoor injection while preserving model utility. Compared to the existing defense, TrapNet can provide universal protection to all target classes without access to any auxiliary public data. Extensive experiments on CelebA, VGG-Face, and VGG-Face2 datasets demonstrate TrapNet’s superior performance over existing defenses, including the most advanced NetGuard and BiDO, against state-of-the-art model inversion attacks, i.e., PLG-MI, LOMMA, and Plug&Play.},
  keywords={Data models;Training data;Optimization;Training;Image reconstruction;Manifolds;Generative adversarial networks;Threat modeling;Protection;Face recognition;Deep neural networks;model inversion;privacy-utility defense},
  doi={10.1109/TIFS.2025.3560557},
  ISSN={1556-6021},
  month={},}@INPROCEEDINGS{10462847,
  author={Kukreja, Sanjay and Kumar, Tarun and Bharate, Vishal and Purohit, Amit and Dasgupta, Abhijit and Guha, Debashis},
  booktitle={2023 International Workshop on Artificial Intelligence and Image Processing (IWAIIP)}, 
  title={Vector Databases and Vector Embeddings-Review}, 
  year={2023},
  volume={},
  number={},
  pages={231-236},
  abstract={This research paper aims to present a comprehensive survey of vector databases and vector embedding techniques. A concise overview of the evolution, architecture, advantages and challenges of vector databases are presented in this paper. To convert unstructured data into vectors, various embedding techniques with their in-depth technical description are also surveyed in this research paper. The existing vector databases’ characteristics and features are described to select an appropriate vector database. The embedding and indexing techniques are thoroughly discussed to help the research community experiment with combining them to develop their application. The challenges of vector databases, like selecting distance metrics, dimensionality, data integrity, cost, etc. are presented. This information on vector database systems will help researchers to exhibit further advancements in their data science applications.},
  keywords={Surveys;Performance evaluation;Costs;Databases;Image processing;Data integrity;Data science;Artificial Intelligence;Computer Vision;Embeddings;Generative AI;Large Language Model},
  doi={10.1109/IWAIIP58158.2023.10462847},
  ISSN={},
  month={Dec},}@BOOK{10769331,
  author={Palmer, Rachelle and Perlmutter, Ben and Gangadhar, Ashwin and Larew, Nicholas and Narváez, Sigfrido and Rueckstiess, Thomas and Weller, Henry and Alake, Richmond and Ranjan, Shubham},
  booktitle={Building AI Intensive Python Applications: Create intelligent apps with LLMs and vector databases},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Master retrieval-augmented generation architecture and fine-tune your AI stack, along with discovering real-world use cases and best practices to create powerful AI appsKey FeaturesGet to grips with the fundamentals of LLMs, vector databases, and Python frameworksImplement effective retrieval-augmented generation strategies with MongoDB AtlasOptimize AI models for performance and accuracy with model compression and deployment optimizationPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionThe era of generative AI is upon us, and this book serves as a roadmap to harness its full potential. With its help, you’ll learn the core components of the AI stack: large language models (LLMs), vector databases, and Python frameworks, and see how these technologies work together to create intelligent applications. The chapters will help you discover best practices for data preparation, model selection, and fine-tuning, and teach you advanced techniques such as retrieval-augmented generation (RAG) to overcome common challenges, such as hallucinations and data leakage. You’ll get a solid understanding of vector databases, implement effective vector search strategies, refine models for accuracy, and optimize performance to achieve impactful results. You’ll also identify and address AI failures to ensure your applications deliver reliable and valuable results. By evaluating and improving the output of LLMs, you’ll be able to enhance their performance and relevance. By the end of this book, you’ll be well-equipped to build sophisticated AI applications that deliver real-world value.What you will learnUnderstand the architecture and components of the generative AI stackExplore the role of vector databases in enhancing AI applicationsMaster Python frameworks for AI developmentImplement Vector Search in AI applicationsFind out how to effectively evaluate LLM outputOvercome common failures and challenges in AI developmentWho this book is forThis book is for software engineers and developers looking to build intelligent applications using generative AI. While the book is suitable for beginners, a basic understanding of Python programming is required to make the most of it.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781836207245},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10769331},}@ARTICLE{1268156,
  author={Chan, S.W.K.},
  journal={IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans}, 
  title={Extraction of salient textual patterns: synergy between lexical cohesion and contextual coherence}, 
  year={2004},
  volume={34},
  number={2},
  pages={205-218},
  abstract={Most current information retrieval systems rely solely on lexical item repetition, which is notorious for its vulnerability. In this research, we propose a novel method for the extraction of salient textual patterns. One of our major objectives is to move away from keywords and their associated limitations in textual information retrieval. How individual sentences in text fit together to be perceived as a salient pattern is identified. A text network that exhibits textual continuity, arising from a connectionist model, is described. The network facilitates a dynamic extraction of salient textual segments by capturing semantics from two different categories of natural language, namely lexical cohesion and contextual coherence. We also present the results of an empirical study designed to compare our model with the performance of human judges in the identification of salient textual patterns. The preliminary results show that our model has the potential for automatic salient patterns discovery in text.},
  keywords={Data mining;Information retrieval;Natural languages;Humans;Coherence;Knowledge engineering;Information analysis;Councils;Artificial intelligence;Psychology},
  doi={10.1109/TSMCA.2003.820570},
  ISSN={1558-2426},
  month={March},}@INPROCEEDINGS{10908341,
  author={Tan, Hung Ngo Luu and Nguyen, Van-Dinh and Huynh-The, Thien and Nguyen, Toan-Van and Vo, Phuong Luu},
  booktitle={2024 International Conference on Advanced Technologies for Communications (ATC)}, 
  title={Security Improvement for Deep Learning-Based Semantic Communication Systems}, 
  year={2024},
  volume={},
  number={},
  pages={717-721},
  abstract={Semantic communication is becoming increasingly popular for wireless image transmission due to its superior communication efficiency. However, current deep learning-based semantic systems designed for semantic communication, though efficient, remain vulnerable to eavesdropping and often overlook security measures at the physical layer. To address this issue, this paper presents a deep learning-based system with joint source-channel coding (JSCC) and cyclical consistent generative adversarial network that enhances the security of semantic communication systems. We also design a convolutional neural network for the encoder and decoder which is trained to extract and transmit semantic features while minimizing the risk of privacy leakage. The artificial noise at the physical layer is employed at the source to degrade the eavesdropping ability of the eavesdropper. We show through experiments that under the artificial noise strategy, the legitimate user achieves a higher structural similarity index measure (SSIM) and peak signal-to-noise ratio (PSNR) than the eavesdropper. Moreover, the semantic system with JSCC offers better SSIM and PSNR than the separated source and channel coding models while preserving the confidentiality of semantic information during wireless transmission. This enhanced security framework opens new opportunities for secure and reliable communication of semantic information in diverse applications.},
  keywords={Wireless communication;PSNR;Noise;Semantic communication;Feature extraction;Physical layer;Decoding;Security;Communication system security;Eavesdropping},
  doi={10.1109/ATC63255.2024.10908341},
  ISSN={2162-1039},
  month={Oct},}@INPROCEEDINGS{10541593,
  author={McDaniel, Steven and Zibran, Minhaz F.},
  booktitle={2024 7th International Conference on Information and Computer Technologies (ICICT)}, 
  title={Improving Source Code with Assistance from AI — A Pilot Case Study with ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={332-337},
  abstract={ChatGPT queries were used to provide feedback on five C++ programs selected from various programming assignments for two graduate-level computer science courses – a scientific programming course and an algorithms course. The evaluated software was written by the first author for those courses within the last two years. ChatGPT was asked to evaluate and provide feedback for each program. Specifically, ChatGPT was asked to evaluate the code for strengths and weaknesses and make recommendations for improving (1) execution speed as well as (2) readability and maintainability. A subjective agreement rating was generated by the authors for each strength, weakness, and recommended change provided by ChatGPT. While the overall agreement with the ChatGPT provided feedback was over 90 percent, at times, ChatGPT’s recommendations were found misleading.},
  keywords={Codes;Generative AI;Source coding;Software algorithms;C++ languages;Software quality;Programming;ChatGPT;Code;Readability;Program;Analysis;Execution Speed;Maintainability},
  doi={10.1109/ICICT62343.2024.00060},
  ISSN={2769-4542},
  month={March},}@INPROCEEDINGS{10212269,
  author={Lyu, Xinli and Ying, Fangli and Onpium, Pintusorn},
  booktitle={2023 2nd International Conference on Edge Computing and Applications (ICECAA)}, 
  title={Scene Style Conversion Algorithm of AI Digital Host: A Deep Learning Approach}, 
  year={2023},
  volume={},
  number={},
  pages={783-787},
  abstract={In the recent years, image diversity generation algorithms based on deep learning have gradually mined feature information that can describe the essential content of images through hierarchical learning, which has become a current research hotspot. In particular, the emergence of GANs has made the qualitative leap in the speed and quality of image data generation due to its good autonomous generation ability and ingenious weakly supervised learning mode. In this study, the focus is deep learning based scene style conversion algorithm of the AI digital host. The proposed model has 2 aspects: (1) Efficient face modelling. In this step, the face features are extracted and combined with deep neural networks to obtain the efficient representations, then, the rough stitching of point cloud data is applied to construct the different perspectives the faces. (2) Efficient style conversion algorithm. This study designs an improved GAN algorithm to create new image conversion scheme to complete the design of the AI host. In the experiment section, the mainstream evaluation methods are adopted to test the performance.},
  keywords={Deep learning;Computational modeling;Scalability;Supervised learning;Process control;Generative adversarial networks;Feature extraction;Deep learning;scene style conversion;image processing;AI digital host;intelligent algorithm},
  doi={10.1109/ICECAA58104.2023.10212269},
  ISSN={},
  month={July},}@ARTICLE{11146939,
  author={Wang, Chenyu and Zhou, Zhi and Xu, Zixin and Wang, Zhijie and Wang, Shaoquan and Chen, Xu},
  journal={IEEE Transactions on Mobile Computing}, 
  title={AIGC-Enhanced Federated Learning: Addressing Data Scarcity in Preference-Based Scenarios}, 
  year={2025},
  volume={},
  number={},
  pages={1-16},
  abstract={Federated learning (FL) is a decentralized machine learning paradigm that enables collaborative model training while preserving data privacy by avoiding sensitive data exfiltration from local storage. Despite its success in various domains, current FL frameworks lack mechanisms to accommodate personalized training objectives, particularly in optimizing performance for specific data classes. Recent advancements in Artificial Intelligence Generated Content (AIGC) present opportunities to address these limitations by supplementing training data for user-preferred classes using generative models. Nonetheless, incorporating AIGC into FL introduces significant challenges, including non-compliant data quality, disorganized data distributions, limited computational resources, and slow data generation speed on edge devices. To address these challenges, we propose AIGC-enhanced Federated Preference Learning (FPL), a novel framework designed to enhance FL performance for user-specified preference classes (PCs). Our approach employs pre-training and fine-tuning of generative models across diverse datasets to improve the quality of synthetic data. Additionally, we optimize FPL efficiency through a client selection strategy that matches tasks involving generated data with suitable clients and a data distribution mechanism that allocates synthetic data to where it is most needed. To further accelerate data supplementation, data augmentation is utilized on local clients. We provide theoretical convergence guarantees for AIGC-enhanced FPL and demonstrate its effectiveness through comprehensive experiments on MNIST and CIFAR-10 datasets, including ablation studies on various data supplementation techniques.},
  keywords={Training;Data models;Computational modeling;Servers;Training data;Data augmentation;Artificial intelligence;Synthetic data;Data collection;Performance evaluation;Federated Learning;Artificial Intelligence Generated Content (AIGC);Data Augmentation;Data Heterogeneity},
  doi={10.1109/TMC.2025.3605397},
  ISSN={1558-0660},
  month={},}@ARTICLE{10568151,
  author={Ravikumar, Aswathy and Sriraman, Harini and Chadha, Chandan and Kumar Chattu, Vijay},
  journal={IEEE Access}, 
  title={Alleviation of Health Data Poverty for Skin Lesions Using ACGAN: Systematic Review}, 
  year={2024},
  volume={12},
  number={},
  pages={122702-122723},
  abstract={Skin-based infections are one of the primary causes of the global disease burden. Digital Health Technologies powered by data science models have the potential to revolutionize global health care. Health data poverty refers to the failure of individual people, teams, or communities to profit in research or development owing to a deficiency of representative data. Generative Adversarial Network-based synthetic images can be viable solutions to health data poverty since timely detection and frequent monitoring are extremely critical for the survival of the patients. This study aims to investigate the possibility of obtaining photo - realistic dermatoscopic images of Skin Lesions via Generative Adversarial Networks (GAN), followed by distributing the images to augment the existing dataset to further enhance the performance of a Convolutional Neural Network for the task of classification. The medical and technological publications in six databases: PubMed, Web of Science, IEEE Xplore, Science Direct, Scopus, and Google Scholar were investigated. A Deep Learning pipeline has been created and a set of deep learning models such as VGG16 (Visual Geometry Group 16), DenseNet, Xception, and Inception-ResNet v2 have been assembled. We have used condition-based generative adversarial networks (GANs) besides the traditional data augmentation approaches such as rotation and scaling. To highlight the image features that eventually lead to classification are highlighted using a Local Interpretable Model-Agnostic Explanation (LIME) strategy. It was inferred from the results of the classification that DenseNet-201 with GAN Augmentation was the best individual model, with an accuracy of around 82%, while models such as VGG-16 and SVM (Support Vector Machine) were unable to compete. It was also observed that starting with the pre-trained ImageNet weights sped up the convergence and prevented models from over fitting in the absence of the regularization effect of augmented data. However, the exploitation of the data was still not perfectly optimal, as over fitting with data augmentation and early stopping was observed, which can be used by more extensive data augmentation techniques. The GAN augmentation showed to reduce the data imbalance and increase the data percentage of the less representative classes. A data augmentation approach based on synthetic data that has been obtained from GAN helps us to classify images of lesions of the skin with high accuracy. We can also infer from the results obtained that, enriching the data with GAN-produced data samples results in a significant performance increase. In the field of medical imaging, where particularly large training datasets are not available, novel data augmentation and generation procedures can be beneficial.},
  keywords={Skin;Generative adversarial networks;Lesions;Data models;Melanoma;Electronic healthcare;Data augmentation;Machine learning;Scalability;Deep learning;Deep learning;health data poverty;machine learning;scalability;digital health;GAN},
  doi={10.1109/ACCESS.2024.3417176},
  ISSN={2169-3536},
  month={},}
