@ARTICLE{10981438,
  author={Li, Baimou and Lu, Qiang and Luo, Jake and Wang, Zhiguang},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Discovering Acoustic Impedance Inversion Equation}, 
  year={2025},
  volume={63},
  number={},
  pages={1-14},
  abstract={Classical acoustic impedance inversion (AII) methods rely on mathematical and physical models to estimate subsurface acoustic impedance distribution. However, these methods face difficulties in accurately fitting complex impedance data. While deep learning (DL) methods have achieved higher accuracy and efficiency in impedance inversion, they remain closed box models, lacking interpretability. Hence, it is difficult to analyze the reason why they are (or are not) effective. To address the limitations of both traditional and DL methods, this article proposes a novel approach, acoustic impedance inversion with symbolic regression (AII-SR), which discovers partial differential equations (PDEs) from impedance data to model AII. To discover these PDEs, AII-SR adopts a dual-learning framework. It employs a forward model based on the Robinson convolution principle to ensure the physical consistency and reliability of predictions. Subsequently, AII-SR creates an inversion model that combines a symbolic regression-based PDE generator with a physics-informed solving neural network (PSNN) to identify PDEs that accurately fit the impedance data. Experiments demonstrate that AII-SR outperforms DL methods, such as SSEI, temporal convolutional network (TCN), and Se-UNet, in terms of accuracy and interpretability. AII-SR generates concise, interpretable mathematical expressions in the form of PDEs, offering profound insights into the physical relationships between seismic and impedance data.},
  keywords={Impedance;Data models;Acoustics;Neural networks;Mathematical models;Accuracy;Computational modeling;Training;Geology;Deep learning;Deep symbolic regression;dual learning;impedance inversion;physical information neural network},
  doi={10.1109/TGRS.2025.3565825},
  ISSN={1558-0644},
  month={},}@ARTICLE{11037524,
  author={Chen, Wei and Yuan, Meng and Zhang, Zhao and Xie, Ruobing and Zhuang, Fuzhen and Wang, Deqing and Liu, Rui},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={FairDgcl: Fairness-Aware Recommendation With Dynamic Graph Contrastive Learning}, 
  year={2025},
  volume={37},
  number={9},
  pages={5230-5242},
  abstract={As trustworthy AI continues to advance, the fairness issue in recommendations has received increasing attention. A recommender system is considered unfair when it produces unequal outcomes for different user groups based on user-sensitive attributes (e.g., age, gender). Some researchers have proposed data augmentation-based methods aiming at alleviating user-level unfairness by altering the skewed distribution of training data among various user groups. Despite yielding promising results, they often rely on fairness-related assumptions that may not align with reality, potentially reducing the data quality and negatively affecting model effectiveness. To tackle this issue, in this paper, we study how to implement high-quality data augmentation to improve recommendation fairness. Specifically, we propose FairDgcl, a dynamic graph adversarial contrastive learning framework aiming at improving fairness in recommender system. First, FairDgcl develops an adversarial contrastive network with a view generator and a view discriminator to learn generating fair augmentation strategies in an adversarial style. Then, we propose two dynamic, learnable models to generate contrastive views within contrastive learning framework, which automatically fine-tune the augmentation strategies. Meanwhile, we theoretically show that FairDgcl can simultaneously generate enhanced representations that possess both fairness and accuracy. Lastly, comprehensive experiments conducted on four datasets demonstrate the effectiveness of the proposed FairDgcl.},
  keywords={Data augmentation;Recommender systems;Contrastive learning;Data models;Accuracy;Generators;Training;Electronic mail;Training data;Collaborative filtering;Fairness;recommender system;graph contrastive learning;adversarial training},
  doi={10.1109/TKDE.2025.3580087},
  ISSN={1558-2191},
  month={Sep.},}@INPROCEEDINGS{10960132,
  author={Kiyawat, Dhruve and Tiwari, Vibha and Dubey, Tijil},
  booktitle={2024 IEEE 2nd International Conference on Innovations in High Speed Communication and Signal Processing (IHCSP)}, 
  title={Enhancing Flower Classification with a Deep Learning Approach Using VGG19 and ImageNet}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper aims to present an analysis on methods and advancements in floral classification techniques. The following research includes several techniques to investigates different approaches that can be used for categorization and picture analysis. Additionally, the main agenda for proposing this paper is to explore hyperparameter tuning and data augmentation techniques to enhance the workability of the model as well as to get to know how to use a reliable and precise image model on large datasets, such as the images of flowers in this case. The VGG19 model serves as the foundation to study architecture, and transfer learning is applied by utilising previously trained weights. Furthermore, the research examines approaches for data augmentation and hyperparameter tuning to improve the robustness and accuracy of the model. The outcome indicates significant improvements in the performance and accuracy, demonstrating the proposed methodology’s efficiency. The report concludes by highlighting drawbacks, which also includes suggestions for further directions and explore potential options to elaborate the scope of floral classification research.},
  keywords={Workability;Technological innovation;Accuracy;Transfer learning;Flowering plants;Signal processing;Data augmentation;Data models;Robustness;Tuning},
  doi={10.1109/IHCSP63227.2024.10960132},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11143484,
  author={Liu, Yu and Li, Xiaocan and Xie, Kun and Wen, Jigang and Chen, Yuxiang and Liang, Wei and Feng, Quan and Xie, Gaogang},
  booktitle={2025 IEEE/ACM 33rd International Symposium on Quality of Service (IWQoS)}, 
  title={HDDI: A Historical Data-Based Diffusion Imputation Method for High-Accuracy Recovery in Sparse Mobile Crowd Sensing with High Missing Rate and Long-Term Gap}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={Mobile crowd sensing (MCS) has become a new paradigm for environment sensing. However, the sensing data often face the challenge of missing values, which can impact the performance of subsequent tasks. Although some deep learning-based imputation methods perform well, they still struggle with insufficient training data due to high missing rate and long-term missing data. To address these challenges, we propose a Historical Data-based Diffusion Imputation (HDDI) method. Unlike existing deep learning-based imputation methods, we design a historical data supplement module to match and fuse historical data to supplement the training data. Additionally, we propose a diffusion imputation module that utilizes the supplement training data to achieve high-accuracy imputation even under high missing rate and long-term missing scenarios. We conduct extensive experiments on four public datasets, the results show that our HDDI outperforms baseline methods across four datasets. Particularly, when the data missing rate is 90%, HDDI improves accuracy by 25.15% compared to the best baseline method in the random missing scenario, and by 13.64% in the long-term missing scenario.},
  keywords={Fuses;Design methodology;Training data;Quality of service;Diffusion models;Imputation;Data models;Sensors;Mobile computing;Faces;Mobile crowd sensing;Data imputation;Diffusion model},
  doi={10.1109/IWQoS65803.2025.11143484},
  ISSN={2766-8568},
  month={July},}@ARTICLE{10980209,
  author={Yang, Bo and Wu, Jinjian and Jiao, Changzhe},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Proxy-Enhanced Prototype Memory Network for Weakly Supervised Hyperspectral Target Detection}, 
  year={2025},
  volume={63},
  number={},
  pages={1-14},
  abstract={Hyperspectral target detection (HTD) holds significant promise in numerous earth vision applications, yet it encounters challenges in acquiring high-quality prior target signatures, capturing target spectral variability, and dealing with sample imbalance. To address these issues, we propose a weakly supervised solution, the proxy-enhanced prototype memory network (PE-PMN), for HTD tasks. It relies solely on region-level weakly labeled data, eliminating the need for strict prior target knowledge (e.g., handcrafted target signatures or pixel-level annotations). To fully describe target variations and background diversity, two memory prototype networks are introduced to extract, store, and retrieve prototypes of targets and backgrounds, providing comprehensive spectral information. Additionally, a proxy-based enhancement approach is incorporated to enrich the prototypes in the memory banks and boost the separation between target and background features. To mitigate sample imbalance in the PE-PMN, we developed the bag mix-up (BMU) strategy based on the unconstrained linear mixture model (ULMM) to construct a sufficient training dataset. Experimental results on three simulated datasets and three real datasets demonstrate that the proposed PE-PMN significantly outperforms other competitive weakly supervised HTD methods.},
  keywords={Prototypes;Training;Detectors;Feature extraction;Hyperspectral imaging;Neural networks;Data mining;Training data;Object detection;Libraries;Hyperspectral;prototype memory network (PMN);target detection;weakly supervised learning (WSL)},
  doi={10.1109/TGRS.2025.3565391},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{10928086,
  author={Babu H, Hemal and D, Yeshwanth. C. and N, Shravan. and Bose, K. Regin},
  booktitle={2025 International Conference on Computational, Communication and Information Technology (ICCCIT)}, 
  title={Gesture Showdown: Rock Paper Scissors with AI Vision}, 
  year={2025},
  volume={},
  number={},
  pages={86-91},
  abstract={This paper presents a gesture-based RockPaper-Scissors game that leverages computer vision and hand gesture recognition to enable intuitive human-computer interaction. Utilizing MediaPipe's pre-trained hand tracking module, the system detects and identifies 21 hand landmarks in real-time to classify gestures as rock, paper or scissors based on angular relationships between key points. OpenCV is used for webcam integration and video frame preprocessing, ensuring seamless interaction. The game compares the recognized gesture with a computer-generated move, dynamically displaying the results and resetting after each round for continuous play. The system identifies gestures through precise angle calculations, differentiating between closed fists, open palms and extended fingers. Sample outputs demonstrate real-time gameplay scenarios, highlighting gesture recognition accuracy and user engagement. Future enhancements include refining recognition accuracy, adding multiplayer functionality, introducing customizable gestures, and deploying the game on web and mobile platforms for broader accessibility. This project showcases the potential of integrating AI and computer vision in creating engaging and user-friendly applications.},
  keywords={Hands;Human computer interaction;Computer vision;Accuracy;Webcams;Tracking;Games;Gesture recognition;Rocks;Real-time systems;Computer Vision;Hand Gesture Recognition;MediaPipe;Real-time Interaction;Rock-Paper-Scissors Game},
  doi={10.1109/ICCCIT62592.2025.10928086},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10934489,
  author={Koshika, Manoj and Kandukuri, Prabhakar and Kumar Moppey, Shyam},
  booktitle={2025 International Conference on Intelligent Systems and Computational Networks (ICISCN)}, 
  title={Enhanced Edge Attention-Based SRCNN for Retinal Image Super-Resolution}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={The early recognition of retinal disorders such as cataracts, glaucoma, and retinal problems is highly dependent on high-resolution retinal imaging, which is a complex issue because of poor image quality and the lack of important features. The proposed Enhanced Edge Attention Super Resolution Convolutional Neural Network (EEASRCNN) is designed to improve the quality of retinal images high precisely. The model preserves important details like blood vessels and the optic disc by using a custom edge loss function, sharpening filters, and combined attention mechanisms. With a high structural similarity index (SSIM) and peak signal-to-noise ratio (PSNR) score and an accuracy of 97.16% in preserving structural details, EEASRCNN outperforms traditional super-resolution methods after being trained on a dataset of diverse retinal images. EEASRCNN offers effective image super resolution in real-time medical image diagnosis.},
  keywords={Training;Image quality;Adaptation models;Attention mechanisms;PSNR;Image edge detection;Computational modeling;Superresolution;Retina;Convolutional neural networks;Medical imaging;Image super-resolution;CNN;Edge-Aware loss;Attention mechanisms},
  doi={10.1109/ICISCN64258.2025.10934489},
  ISSN={},
  month={Jan},}@ARTICLE{10681561,
  author={Qi, Lei and Zhao, Dongjia and Shi, Yinghuan and Geng, Xin},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Patch-Aware Batch Normalization for Improving Cross-Domain Robustness}, 
  year={2025},
  volume={35},
  number={1},
  pages={800-810},
  abstract={Despite the significant success of deep learning in computer vision tasks, cross-domain tasks still present a challenge in which the model’s performance will degrade when the training set and the test set follow different distributions. Most existing methods employ adversarial learning or instance normalization for achieving data augmentation to solve this task. In contrast, considering that the batch normalization (BN) layer may not be robust for unseen domains and there exist the differences between local patches of an image, we propose a novel method called patch-aware batch normalization (PBN). To be specific, we first split feature maps of a batch into non-overlapping patches along the spatial dimension, and then independently normalize each patch to jointly optimize the shared BN parameter at each iteration. By exploiting the differences between local patches of an image, our proposed PBN can effectively enhance the robustness of the model’s parameters. Besides, considering the statistics from each patch may be inaccurate due to their smaller size compared to the global feature maps, we incorporate the globally accumulated statistics with the statistics from each batch to obtain the final statistics for normalizing each patch. Since the proposed PBN can replace the typical BN, it can be integrated into most existing state-of-the-art methods. Extensive experiments and analysis demonstrate the effectiveness of our PBN in multiple computer vision tasks, including classification, object detection, instance retrieval, and semantic segmentation.},
  keywords={Training;Batch normalization;Robustness;Object detection;Adversarial machine learning;Semantics;Standards;Single-source domain generalization;cross-perturbation;MixPatch},
  doi={10.1109/TCSVT.2024.3462501},
  ISSN={1558-2205},
  month={Jan},}@INPROCEEDINGS{10608225,
  author={Zheng, Qiuhong and Wang, Jinghan and Shen, Yun},
  booktitle={2024 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)}, 
  title={Human Model Reconstruction with Facial Region Optimization: A Fusion Nerf Approach}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The existing parameterized model-based 3D human reconstruction methods typically does a global representation of the body, lacking further optimization and design for the facial region, leading to poor representation in facial region during practical use. However, a qualified human model demands detailed facial modeling to fully convey facial information, thus avoiding issues like unclear facial identity expression and inadequate model refinement. This paper proposes a 3D human model reconstruction method based on the fusion of face and body using neural radiation field (NeRF). NeRF is established separately for the 2D image’s face and body parts, followed by fusion to reconstruct a finely detailed facial model. Additionally, a texture resampling model correction mechanism based on RePaint is proposed to ensure the coherence of the body structure and uniformity of texture colors in the fusion region of face and body. Ultimately, a 3D human model with a refined facial region is recon-structed.},
  keywords={Solid modeling;Three-dimensional displays;Image color analysis;Reconstruction algorithms;Neural radiance field;Digital humans;Multimedia communication;3D human model;body;face;NeRF;resampling;SMPL-X},
  doi={10.1109/BMSB62888.2024.10608225},
  ISSN={2155-5052},
  month={June},}@INPROCEEDINGS{9944609,
  author={Chen, Hao and Han, Junhua and Lv, Xiaomeng and Wu, Zhenyu and Guo, Huifeng and Zhan, Zhiqiang},
  booktitle={2022 13th International Conference on Reliability, Maintainability, and Safety (ICRMS)}, 
  title={A Semi-supervised Deep Learning Model with Consistency Regularization of Augmented Samples for Imbalanced Fault Detection}, 
  year={2022},
  volume={},
  number={},
  pages={290-295},
  abstract={With increasing requirements on reliability, maintainability and safety in modern ICT systems, fault detection, as an indispensable part of AIOps, has become essential in cloud computing or communication network environments. However, due to the lack of effective labels and class imbalance on faulty samples, fault detection performance based on the common classification model can't meet the system's operational requirements. Some recent approaches of SSL propose a consistency regularization loss to solve the problem of insufficient labels. However, these approaches are mainly for images based on artificial data augmentations but not feasible for all data types, and class-imbalance problem is not considered simultaneously. So, we propose a semi-supervised method for imbalanced fault detection with few labels, called SSLCR-IFD. In the method, we use a semi-supervised deep classifier based on consistency loss to solve the lack of labels, in which two sample augmentation methods based on clustering and GAN are used. Furthermore, a selective pseudo-labeling self-training strategy is proposed to solve the class-imbalance problem. Compared with the standard data augmentation, our methods alleviates the need for domain knowledge and can be used on multiple types of tasks. Finally, experiment results show that our method outperforms the baseline methods on two different AIOps tasks.},
  keywords={Degradation;Deep learning;Fault detection;Generative adversarial networks;Hard disks;Safety;Information and communication technology;Artificial intelligence in reliability and safety;semi-supervised learning;class-imbalance;data augmentation;consistency regularization},
  doi={10.1109/ICRMS55680.2022.9944609},
  ISSN={2575-2642},
  month={Aug},}@INPROCEEDINGS{10575164,
  author={Manoranjitham, R and Swaroop, Somu Santhi},
  booktitle={2024 3rd International Conference on Applied Artificial Intelligence and Computing (ICAAIC)}, 
  title={A Comparative Study of DenseNet121 and InceptionResNetV2 model for DeepFake Image Detection}, 
  year={2024},
  volume={},
  number={},
  pages={432-438},
  abstract={The rise of deep fake technology poses a significant challenge to societal integrity, necessitating robust detection methods. This research study investigates the effectiveness of DenseNet121 and InceptionResNetV2 deep learning models in detecting deep fake images. The study starts with the curation of the dataset and then applies different preprocessing methods to improve the quality of the dataset like scaling, normalization, and data augmentation. The DenseNet121 and InceptionResNetV2 models are trained to differentiate authentic and manipulated images based on distinctive features. DenseNet121’s dense connectivity facilitates feature reuse, enabling effective extraction of discriminative features crucial for identifying manipulated content. In contrast, InceptionResNetV2’s sophisticated architecture exploits both inception and residual connections, enhancing its ability to capture intricate patterns indicative of deep fake manipulation. The comparative analysis of performance metrics reveals InceptionResNetV2’s superiority, achieving an impressive accuracy rate of 99.78% compared to DenseNet121. These findings underscore the efficacy of leveraging existing architectures for identifying deep fake images, thereby contributing to the ongoing efforts to combat misinformation and safeguard digital content integrity.},
  keywords={Measurement;Deep learning;Deepfakes;Accuracy;Computer architecture;Feature extraction;Data augmentation;DenseNet121;InceptionResNetV2;Deep Learning;Deep Fake;Images},
  doi={10.1109/ICAAIC60222.2024.10575164},
  ISSN={},
  month={June},}@INPROCEEDINGS{10920672,
  author={Alevizos, Vasileios and Gerolimos, Nikitas and Edralin, Sabrina and Xu, Clark and Simasiku, Akebu and Priniotakis, Georgios and Papakostas, George A. and Yue, Zongliang},
  booktitle={2025 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Systematic Review on Sustainable Design Thinking Through Biomimetic Approach}, 
  year={2025},
  volume={},
  number={},
  pages={0219-0223},
  abstract={Biomimetic approaches have emerged as com-pelling instruments in the pursuit of sustainable design. With growing environmental challenges, the responsibility to develop eco-friendly architectural solutions has become critical. A targeted review was conducted to explore the integration of biomimicry into sustainable design thinking, focusing on how natural processes can inform and enhance architectural practices. By analyzing various biomimetic strategies and their applications in architectural contexts, an attempt was made to bridge the gap between biological systems and sustainable design practices. The characteristic features of biomimicry involve the emulation of natural processes, leading to innovative and efficient solutions. It was observed that by mimicking biological strategies, significant improvements in thermal efficiency, daylight optimization, and material adaptability could be achieved. Quantitative measurements indicated a 20% reduction in energy use intensity, with cooling loads decreasing by 36.5% when biomimetic shading skins were applied. Such noticeable improvements highlight the effectiveness of biomimicry in sustainable architecture. However, the process of integrating biomimetic principles into design practices is not without challenges. Complicated by the diversity of natural systems, the task requires careful analysis and adaptation of biological characteristics to suit architectural needs. Despite these complexities, biomimetic approaches introduce adaptive systems into designs that can be developed for efficiency, aesthetics, and environmental harmony.},
  keywords={Technological innovation;Adaptive systems;Biomimetics;Scalability;Focusing;Skin;Organisms;Mirrors;Optimization;Systematic literature review;Design thinking;Biomimicry;Biomimetics;Sustainable architecture},
  doi={10.1109/ICAIIC64266.2025.10920672},
  ISSN={2831-6983},
  month={Feb},}@INPROCEEDINGS{11022305,
  author={Wang, Xuedong and Yang, Xuebing and Tang, Wen and Zhang, Wensheng},
  booktitle={2024 8th Asian Conference on Artificial Intelligence Technology (ACAIT)}, 
  title={Tolerating Missing Values through Submatrix Ensemble for EHR Classification}, 
  year={2024},
  volume={},
  number={},
  pages={1775-1780},
  abstract={With an aging population and increasing demand of healthcare, hospitalized elderly patients with chronic diseases require more attention in case of the incidence of adverse events. To improve the survival rate of patients and optimize the allocation of medical resources, accurately classifying their Electronic Health Records (EHRs) and achieving early warning of adverse events is crucial. Nevertheless, existing EHRs often contain missing values, resulting in an incomplete data matrix, which is difficult to apply most of classification models. In this paper, an EHR classification model, Submatrix Ensemble (SME), which can tolerate incomplete EHRs, is proposed. First, we utilize the symmetrical uncertainty between features and labels as the weighting criteria to construct a feature selector and obtain the relevant features. Second, we generate complete submatrices and derive the corresponding base classifiers to constitute an ensemble of decision tree-like classifiers, of which each decision tree includes multiple base classifiers. Third, we adopt the evidence theory to combine all individual classification probabilities and obtain the final result of the ensemble classifier. Experimental evaluations on a real-world dataset regarding chronic diseases in elderly and two publicly available datasets demonstrate that SME outperforms state-of-the-art competitors on EHR classification at different missing rates.},
  keywords={Symmetric matrices;Evidence theory;Measurement uncertainty;Medical services;Feature extraction;Decision trees;Ensemble learning;Resource management;Older adults;Diseases;Missing value;ensemble learning;EHR classification;evidence theory},
  doi={10.1109/ACAIT63902.2024.11022305},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11042476,
  author={Singh, Shweta and Singhal, Abhishek and Joshi, Rakesh Chandra},
  booktitle={2025 2nd International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)}, 
  title={Design of an Efficient Deep Learning-based Model for Diagnosis of Osteoporosis using Dental Periapical Radiograph Images}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Osteoporosis is a chronic bone disease that tends to make the bone fragile enough to break it, hence its early diagnosis would prove to be helpful for both the patients and the medical practitioners to personalize the treatment. Numerous works have already been done involving deep learning algorithms and pre-trained models to predict osteoporosis via the X-ray datasets of knee etc. while very few research works have explored the diagnosis of osteoporosis using the Dental Periapical Radiograph dataset which is the focus of this work. In this paper, a customized deep learning model with various layers and parameters has been implemented on the Dental Radiograph dataset having three classes— Osteoporosis, Osteopenia, and Normal. Apart from the custom model, transfer learning has also been implemented on the pre-trained models like DenseNet121, DenseNet201, VGG19, and MobileNetV2 for the overall comparison and analysis. The highest test accuracy for the custom models is 95.17% and the highest AUC is 99.59% whereas the highest test accuracy among all the fine-tuned pre-trained models mentioned above is 94.57%, and the highest AUC is 97.68%. It is evident that the custom model’s accuracy and AUC have surpassed the fine-tuned model’s performance, making it seem suitable for deployment in real-world settings and developing other applications.},
  keywords={Deep learning;Osteoporosis;Analytical models;Accuracy;Transfer learning;Predictive models;Prediction algorithms;Dentistry;Diagnostic radiography;Medical diagnostic imaging;Deep Learning;Dense Networks;CNN Model;Clinical Diagnosis;Classification Report;AI-Screening},
  doi={10.1109/RMKMATE64874.2025.11042476},
  ISSN={},
  month={May},}@INPROCEEDINGS{10493374,
  author={A, Lakkshmi Yogesh N and S, Shreyas and B, Rajesh C. and G, Bharathraj and S, Sanjay Prasanth A},
  booktitle={2024 Second International Conference on Emerging Trends in Information Technology and Engineering (ICETITE)}, 
  title={Accuracy Analysis of Various CNN Models with Synthetic and Original Dataset for Cotton leaf}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In this day and age, almost in every field of work Artificial Intelligence has its part to play. Likewise in the field of agriculture, for the early detection of diseases Artificial Intelligence algorithms were used. These algorithms use image classification models to perform this operation. So, to get better result in the early disease detection these models need to be trained with a balance dataset with huge of number of training samples. But finding a balanced dataset is quite impossible so in this manuscript we created a fresh dataset for cotton leaf by combining the images from the original and synthetic dataset. For that first we generated the synthetic dataset for cotton leaf using Deep Convolutional Generative Adversarial Network(DCGAN)algorithm which generates the artificial images like the images present in the original dataset. Then Convolutional Neural Network models like: Inception V3, Visual Geometry Group(VGG) 16, Residual Network(ResNet) 50 and MobileNet V2 are used to implement the accuracy analysis for the original dataset and newly created dataset to show that newly created dataset with synthetic images provides better accuracy rate when compared with the original dataset.},
  keywords={Training;Analytical models;Visualization;Market research;Classification algorithms;Cotton;Convolutional neural networks;Synthetic dataset;DCGAN;CNN;Inception V3;VGG 16;ResNet 50;MobileNet V2},
  doi={10.1109/ic-ETITE58242.2024.10493374},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{9799229,
  author={Mujtaba, Dena F. and Mahapatra, Nihar R.},
  booktitle={2021 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Fish Species Classification with Data Augmentation}, 
  year={2021},
  volume={},
  number={},
  pages={1588-1593},
  abstract={The demand for seafood has grown rapidly over the last few decades. Given this growth, there is an increasing need for more efficient and sustainable fishing practices. A prime challenge in this regard is monitoring fisheries to prevent harmful fishing practices. Therefore, commercial fishing boats have started carrying electronic monitoring (EM) systems to mitigate these practices. However, as the volume of video footage from EM grows, reviewing the footage manually becomes infeasible. Therefore, we seek to address this limitation by developing a convolutional neural network model to classify images of fish in EM footage of fisheries. To make our model efficient and effective, we utilize transfer learning, wherein pre-trained image classification models are built upon to improve model training speed, and data augmentation, wherein images are modified to create a larger training dataset. For evaluation, we utilize the FishNet Open Image Database with over 85,000 images from EM footage of fisheries in the western and central Pacific Ocean. We train two models to classify 10 species of fish: one without and one with data augmentation. Our results show that using data augmentation improves our model’s ability to deal with more difficult fish image classification scenarios. By using deep learning, we can achieve a high classification accuracy and quickly identify species in EM footage.},
  keywords={Training;Deep learning;Transfer learning;Fish;Data models;Convolutional neural networks;Monitoring;convolutional neural networks;fish identification;image classification;species conservation;transfer learning},
  doi={10.1109/CSCI54926.2021.00307},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9407386,
  author={Zhang, Xing and Cui, Xiaotong and Cheng, Kefei and Zhang, Liang},
  booktitle={2020 16th International Conference on Computational Intelligence and Security (CIS)}, 
  title={A Convolutional Encoder Network for Intrusion Detection in Controller Area Networks}, 
  year={2020},
  volume={},
  number={},
  pages={366-369},
  abstract={Integrated with various electronic control units (ECUs), vehicles are becoming more intelligent with the assistance of essential connections. However, the interaction with the outside world raises great concerns on cyber-attacks. As a main standard for in-vehicle network, Controller Area Network (CAN) does not have any built-in security mechanisms to guarantee a secure communication. This increases risks of denial of service, remote control attacks by an attacker, posing serious threats to underlying vehicles, property and human lives. As a result, it is urgent to develop an effective in-vehicle network intrusion detection system (IDS) for better security. In this paper, we propose a Feature-based Sliding Window (FSW) to extract the feature of CAN Data Field and CAN IDs. Then we construct a convolutional encoder network (CEN) to detect network intrusion of CAN networks. The proposed FSW-CEN method is evaluated on real-world datasets. The experimental results show that compared to traditional data processing methods and convolutional neural networks, our method is able to detect attacks with a higher accuracy in terms of detection accuracy and false negative rate.},
  keywords={Training;Computational modeling;Network intrusion detection;Feature extraction;Data processing;Security;Data mining;IDS;controller area network;CNN;false negative rate},
  doi={10.1109/CIS52066.2020.00084},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9975983,
  author={Avanzato, Roberta and Beritelli, Francesco},
  booktitle={2022 IEEE International Conference on Internet of Things and Intelligence Systems (IoTaIS)}, 
  title={Heart disease recognition based on extended ECG sequence database and deep learning techniques}, 
  year={2022},
  volume={},
  number={},
  pages={117-121},
  abstract={Mortality caused by cardiovascular diseases (CVDs) has been steadily increasing over the years. For this reason, numerous studies have addressed this issue, introducing innovative techniques for automatic detection of heart disease using ECG/PCG signals and convolutional neural networks (CNNs). The present paper proposes a system for automatic diagnosis of heart disease (five pathology classes) using electrocardiogram (ECG) signals and CNNs. Specifically, ECG signals are passed directly to an appropriately trained CNN network. The database comprises a combination of two public datasets: MIT-BIH Arrhythmia and MIT-BIH Atrial Fibrillation database. The results obtained from testing the network show average classification accuracy of about 93% when a 2second ECG signal is fed to the network; conversely, applying a post-processing filter results in about 100% accuracy after around 38 seconds.},
  keywords={Heart;Deep learning;Pathology;Databases;Neural networks;Electrocardiography;Information filters;ECG signal detection;cardiovascular diseases;convolutional neural network (CNN);Heart diseases recognition},
  doi={10.1109/IoTaIS56727.2022.9975983},
  ISSN={2832-1383},
  month={Nov},}@INPROCEEDINGS{10216511,
  author={Ojo, Taiwo and Chi, Hongmei and Erskine, Samuel Kofi},
  booktitle={2022 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Unmanned Aerial Vehicle Forensics Investigation Performance under Different Attacks}, 
  year={2022},
  volume={},
  number={},
  pages={958-964},
  abstract={Unmanned Aerial Vehicles (UAVs), also called drones, have grown tremendously in recent years and have been adopted in various sectors. With the continuous development of machine learning algorithms to detect various attacks on UAVs. The attackers also focused on utilizing this machine-learning algorithm to disrupt the UAV's activities by using predictions to generate the attack route. In digital forensics, the forensics experts focus on the communication data between the controller and the drones, the multimedia files, and the flight data to make a complete cybersecurity report. This paper reviews various ways the drone may be compromised and its performance evaluation using the existing machine learning detection algorithm to make the forensics report about the drones. The machine learning algorithms investigated in this study include Multilayer Perceptron (MLP) for the detection technique.},
  keywords={Performance evaluation;Machine learning algorithms;Scientific computing;Digital forensics;Machine learning;Multilayer perceptrons;Autonomous aerial vehicles;Drones;Machine Learning;Cyber-Attacks;Digital forensics},
  doi={10.1109/CSCI58124.2022.00171},
  ISSN={2769-5654},
  month={Dec},}@INPROCEEDINGS{10421467,
  author={Datta, Subrata and Bandyopadhyay, Shaon and Mondal, Bappaditya},
  booktitle={2023 International Conference on Integrated Intelligence and Communication Systems (ICIICS)}, 
  title={Classification of Spam and Ham Emails with Machine Learning Techniques for Cyber Security}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={People often receive spam emails that may cause of cyber threats. Hence, classification of spam and ham emails is necessary for cyber security. Lack of classification accuracy is one of the common problems in this context. This paper proposes a new method of spam and ham classification based on machine learning (ML) techniques. The proposed method considers TF-IDF technique for feature selection. In this concern, flexible threshold based pruning in TF-IDF technique is introduced. In addition, the proposed method takes account of six popular ML techniques to classify the emails. Experimental results reveal that the flexible threshold helps to improve the classification accuracy of the ML techniques. The proposed method declares Support Vector Machine (SVM) as the best classifier with accuracy of 96.22%. Thus, the proposed method helps the users in identification of spam emails to avoid cyber threats.},
  keywords={Support vector machines;Communication systems;Unsolicited e-mail;Machine learning;Feature extraction;Security;Computer crime;spam;ham;email;machine learning;TF-IDF;cyber security},
  doi={10.1109/ICIICS59993.2023.10421467},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10403614,
  author={Srivastava, Rahul S and R, Abhishek and P O, Rahul and Mohammed, J.S.Noor and Kamal, Shoaib and Rao, Trupthi},
  booktitle={2023 International Conference on Computational Intelligence for Information, Security and Communication Applications (CIISCA)}, 
  title={COVID-19 Detection Using Deep Learning}, 
  year={2023},
  volume={},
  number={},
  pages={367-373},
  abstract={COVID-19 has had a global impact with no known cure. COVID-19 can be identified from chest X-rays using CNN models, with augmentation techniques improving accuracy. Chest X-ray scans are used due to RT-PCR's low sensitivity. AI-based automated CT image analysis systems differentiate COVID-19 from pneumonia with high accuracy. COVID-19 can cause permanent lung damage like SARS. Studies have used deep learning and CNN models, including VGG16, DenseNet121, and ResNet50, To recognize COVID-19 from images of chest X-rays. Results varied between studies, with the highest accuracy delineated at 99.1%, while the lowest was 79.01%. DenseNet improves accuracy by preventing vanishing gradients, VGG16 uses convolution and max pool layers with two fully connected layers and a softmax for output, and EfficientNet uses compound scaling and AutoML. The data (Covid19 images) has been collected from the Kaggle UCI repository dataset. This paper uses three models (DenseNet, VGG-16, EfficientNet) for the purpose of diagnosing of COVID-19. DenseNet has the highest accuracy of 94.4%, while VGG-16 and EfficientNet have accuracies of 91.6% and 90.2%, respectively.},
  keywords={COVID-19;Deep learning;Training;Biological system modeling;Computational modeling;X-ray imaging;Biomedical imaging;DenseNet;Efficient Net;VGG-16;Kaggle UCI repository dataset;COVID-19;X-Ray;CNN;ReLU;ResNet;CT Scans;Accuracy},
  doi={10.1109/CIISCA59740.2023.00076},
  ISSN={},
  month={June},}@INPROCEEDINGS{10458470,
  author={Montenegro, Carlos and Navarrete, Rosa},
  booktitle={2023 10th International Conference on Soft Computing & Machine Intelligence (ISCMI)}, 
  title={S&P 500 Index Value Forecasting Using Decision Fusion Regression Model}, 
  year={2023},
  volume={},
  number={},
  pages={22-26},
  abstract={Stock information like the S&P500 index is extensive, intricate, nonlinear, and filled with disturbances. Hence, finding appropriate methods to forecast its value has emerged as a complex task. This study uses a regression approach to explore the potential of a BiLSTM-GRU decision fusion model. The individual models exhibit promising outcomes during training, testing, and validation. A fusion option enhances the forecast accuracy for new extrapolation scenarios. The new model shows good predictive performance for short-term forecasting and improving outcomes compared with studies utilized for benchmarking. This focus offers an avenue for academics to delve into a novel exploration of data prediction. Simultaneously, professionals can leverage this research to refine criteria supporting investment choices within the stock market.},
  keywords={Training;Extrapolation;Predictive models;Benchmark testing;Indexes;Forecasting;Task analysis;Stock Forecasting;S&P500 Index;Decision Fusion Model},
  doi={10.1109/ISCMI59957.2023.10458470},
  ISSN={2640-0146},
  month={Nov},}@INPROCEEDINGS{8781797,
  author={Paniagua, Jose L. and Lopez, Jesus A.},
  booktitle={2019 IEEE Colombian Conference on Applications in Computational Intelligence (ColCACI)}, 
  title={Dimensionality Reduction Applied to Time Response of Linear Systems Using Autoencoders}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={An Autoencoder is a multilayer neural network that is used as a powerful tool to perform dimensionality reduction. Due to its structure, is possible to find low-dimensional representations of high-dimensional data in its most hidden layer. In this paper, a deep autoencoder is used to perform a compact representation of the time response of linear systems. The parameters of deep autoencoder are trained using gradient descent and backpropagation. The proposed method is validated with five different first-order systems and six of second order. Results show that is possible to use a deep autoencoder to capture the dynamical behavior of a dynamical system in its latent layer.},
  keywords={Neurons;Dimensionality reduction;Deep learning;Neural networks;Time factors;Mathematical model;Task analysis;Deep learning;Time response;unsupervised learning;Dimensionality reduction},
  doi={10.1109/ColCACI.2019.8781797},
  ISSN={},
  month={June},}@ARTICLE{8788459,
  author={Su, Xin and Guo, Shangqi and Tan, Tian and Chen, Feng},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Generative Memory for Lifelong Learning}, 
  year={2020},
  volume={31},
  number={6},
  pages={1884-1898},
  abstract={Lifelong learning is a crucial issue in advanced artificial intelligence. It requires the learning system to learn and accumulate knowledge from sequential tasks. The learning system needs to deal with increasingly more domains and tasks. We consider that the key to an effective and efficient lifelong learning system is the ability to memorize and recall the learned knowledge using neural networks. Following this idea, we propose Generative Memory (GM) as a novel memory module, and the resulting lifelong learning system is referred to as the GM Net (GMNet). To make the GMNet feasible, we propose a novel learning mechanism, referred to as P-invariant learning method. It replaces the memory of the real data by a memory of the data distribution, which makes it possible for the learning system to accurately and continuously accumulate the learned experiences. We demonstrate that GMNet achieves the state-of-the-art performance on lifelong learning tasks.},
  keywords={Task analysis;Learning systems;Memory modules;Training;Neural networks;Knowledge engineering;Micromechanical devices;Catastrophic forgetting;generative memory (GM);lifelong learning;neural network},
  doi={10.1109/TNNLS.2019.2927369},
  ISSN={2162-2388},
  month={June},}@INPROCEEDINGS{10361023,
  author={Lv, Chenyang and Wei, Ziling and Qian, Weikang and Ye, Junjie and Feng, Chang and He, Zhezhi},
  booktitle={2023 IEEE 41st International Conference on Computer Design (ICCD)}, 
  title={GPT-LS: Generative Pre-Trained Transformer with Offline Reinforcement Learning for Logic Synthesis}, 
  year={2023},
  volume={},
  number={},
  pages={320-326},
  abstract={Logic synthesis (LS) is a process that transforms a high-level logic circuit description into a gate-level netlist, typically via a heuristic algorithm. Such a process can be decomposed into a series of transformation primitives, where each primitive optimizes the netlist while preserving the functional equivalence. However, identifying a desirable primitive sequence (PS) to achieve design goals is challenging, due to the immense design space. Recent advances in artificial intelligence offer the opportunity to leverage machine learning techniques to tackle the combinatorial optimization problem associated with PS. Unfortunately, the existing works either require time-consuming training for each circuit or incur high computational costs. To address these issues, we redefine the optimization of LS as a sequence generation problem and propose a generative pre-trained transformer (GPT) with offline reinforcement learning, which is named as GPT-LS. Thanks to the OpenABC-D dataset, GPT-LS is pre-trained on diverse circuits and its massive intermediate data during the synthesis, by utilizing the offline reinforcement learning technique of decision transformer. Then, GPT-LS is able to generate PS for unseen circuits to conduct optimized LS. According to our comprehensive experiments, GPT-LS achieves results that match those of previous state-of-the-art methods in a significantly shorter time. It is available at: github.com/Intelligent-Computing-Research-Group/GPT-LS.},
  keywords={Training;Runtime;Logic circuits;Heuristic algorithms;Computational modeling;Reinforcement learning;Transforms;Logic gates;Transformers;Optimization;logic synthesis;offline reinforcement learning;decision transformer;generative pre-trained transformer},
  doi={10.1109/ICCD58817.2023.00056},
  ISSN={2576-6996},
  month={Nov},}@INPROCEEDINGS{8621957,
  author={Akujuobi, Uchenna and Sun, Ke and Zhang, Xiangliang},
  booktitle={2018 IEEE International Conference on Big Data (Big Data)}, 
  title={Mining top-k Popular Datasets via a Deep Generative Model}, 
  year={2018},
  volume={},
  number={},
  pages={584-593},
  abstract={Finding popular datasets to work on is essential for data-driven research domains. In this paper, we focus on the problem of extracting top-k popular datasets that have been used in data mining, machine learning, and artificial intelligence fields. We solve this problem on an attributed citation network, which includes node content information (text of published papers) and paper citation relations. By formulating the problem as a semi-supervised multi-label classification one, we develop an efficient deep generative model for learning from both the document content and citation relations. The evaluation on a real-world dataset shows that our proposed model outperforms baseline methods. We then apply the model further to reveal the top-k frequently cited datasets in selected areas and report interesting findings.},
  keywords={Neural networks;Data models;Data mining;Topology;Cost function;Semisupervised learning;Mathematical model;Deep Generative Models;Semi-supervised Learning;Document Classification;Multi-label Classification;Citation Network},
  doi={10.1109/BigData.2018.8621957},
  ISSN={},
  month={Dec},}@ARTICLE{10709339,
  author={Yang, Ning and Lu, Fei and Tian, Guohui and Liu, Jun},
  journal={IEEE Transactions on Industrial Electronics}, 
  title={Long-Term Active Object Detection for Service Robots: Using Generative Adversarial Imitation Learning With Contextualized Memory Graph}, 
  year={2025},
  volume={72},
  number={5},
  pages={5082-5092},
  abstract={Active object detection (AOD) is a crucial task in embodied artificial intelligence within robotics. Previous works mainly address this challenge through deep reinforcement learning (DRL), characterized by prolonged training cycles and model convergence difficulties. Moreover, they often emphasize whether a single AOD task can be completed, overlooking the reality that robots perform long-term AOD tasks. To this end, this article introduces a new AOD solution utilizing a graph based on generative adversarial imitation learning (GAIL). A new expert strategy is devised using the active vision dataset benchmark (AVDB), generating high-quality expert trajectories. Meanwhile, a new AOD model based on GAIL is proposed to predict the robot's execution actions. Moreover, a contextualized memory graph (CMG) is constructed, providing partial state information for the GAIL model and enabling the robot to directly make decisions based on the humanlike memory function. Experimental validation against existing methods in AVDB demonstrates superior results, achieving an 88.8% action prediction accuracy, reducing average path length (APL) to 12.182 steps, and shortening single-step action prediction time to 0.133 s. The proposed method is further evaluated in a real-world home scene, affirming its efficacy and generalization capabilities.},
  keywords={Robots;Trajectory;Service robots;Feature extraction;Streaming media;Robot kinematics;Imitation learning;Generators;Accuracy;Visualization;Active vision, contextualized memory graph (CMG);generative adversarial imitation learning (GAIL);long-term active object detection (AOD);service robot},
  doi={10.1109/TIE.2024.3468636},
  ISSN={1557-9948},
  month={May},}@INPROCEEDINGS{10566961,
  author={Li, Siyuan and Lin, Xi and Li, Gaolei and Chen, Lixing and Liao, Siyi and Wang, Jing and Li, Jianhua},
  booktitle={2023 19th International Conference on Mobility, Sensing and Networking (MSN)}, 
  title={DPG-DT: Differentially Private Generative Digital Twin for Imbalanced Learning in Industrial IoT}, 
  year={2023},
  volume={},
  number={},
  pages={270-276},
  abstract={The existing Artificial Intelligence (AI)-based industrial defect detection methods have received extensive attention in the industrial Internet of Things (IoT). However, due to the limited defect samples, it is difficult for discriminative models to achieve better performance in imbalanced learning. In addition, the privacy concerns surrounding sensitive information hinder the sharing of synthetic industrial data. In this paper, we propose a novel framework called the Differentially Private Generative AI-empowered Digital Twin (DPG-DT) framework, aiming to synthesize realistic samples while satisfying differential privacy and empowering the construction of digital space and its connection with physical space. Specifically, the core of the DPG-DT framework is the proposed Private Synthetic Industry Energy-guided model (PSIE), in which we privatize the energybased model-empowered Langevin Markov Chain Monte Carlo (MCMC) sampling method with Gaussian noise and random response. Our method could replace the conventional generator while guaranteeing privacy. Extensive experiments on real-world industrial datasets NEU-CLS and DeepPCB demonstrate that the proposed framework is capable of generating synthetic industrial images with both high fidelity and differential privacy. Moreover, the achieved downstream accuracy outperforms baselines by 23.9 % in industrial scenarios.},
  keywords={Industries;Differential privacy;Privacy;Monte Carlo methods;Sampling methods;Generators;Data models;Generative Model;Industrial Internet of Things;Differential Privacy;Digital Twin;Energy-based Model},
  doi={10.1109/MSN60784.2023.00049},
  ISSN={2994-3523},
  month={Dec},}@INPROCEEDINGS{10915323,
  author={Behera, Sagarika and Kalagudi, Varsha and Kumar Reddy B, Sai Manish and Das, Soumya Ranjan},
  booktitle={2025 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)}, 
  title={Generative AI-Based Financial Fraud Detection System}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Financial fraud presents a serious threat to the stability and integrity of global financial systems. Traditional methods of detecting fraud often struggle to keep pace with fraudsters’ evolving tactics. In this study, a new method is presented to combating financial fraud by integrating various machine learning algorithms with generative artificial intelligence techniques. This work uses advanced deep learning techniques, such as convolutional and recurrent neural networks, to enhance financial system security. It focuses on improving fraud detection accuracy and reducing false positives and negatives by analyzing extensive datasets to detect subtle fraud indicators in real time. This initiative seeks to set a new standard in financial security, aiming to significantly reduce financial losses due to fraud. RNN has high accuracy (99.39%) but low precision, recall, and F1 score (40% each). CNN has slightly lower accuracy (99.29%) and relatively lower precision (33.33%) and F1 score (36.36%). FCNN shows high accuracy (99.49%) and precision (98.96%), with perfect recall (100%) and a very high F1 score (99.47%). It was observed that the GRU performs excellently across all metrics, with perfect scores (100%) in accuracy, precision, recall, and F1 score, indicating its strong ability to detect fraud while minimizing false positives and false negatives. This performance suggests that GRUs are highly effective for this type of task.},
  keywords={Measurement;Accuracy;Machine learning algorithms;Finance;Stability analysis;Real-time systems;Fraud;Security;Convolutional neural networks;Standards;Generative Adversarial Networks (GANs);Gated Recurrent Unit (GRU);Recurrent Neural Networks (RNNs);Conditional GANs (CGANs);Convolutional Neural Networks (CNNs);Fully Connected Neural Network (FCNN)},
  doi={10.1109/IITCEE64140.2025.10915323},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{11130010,
  author={Papoutsis, Angelos and Dimitriadis, Athanasios and Koritsas, Ilias and Kavallieros, Dimitrios and Tsikrika, Theodora and Vrochidis, Stefanos and Kompatsiaris, Ioannis},
  booktitle={2025 IEEE International Conference on Cyber Security and Resilience (CSR)}, 
  title={RuleXploit: A Framework for Generating Suricata Rules from Exploits Using Generative AI}, 
  year={2025},
  volume={},
  number={},
  pages={267-274},
  abstract={Intrusion Detection Systems (IDS) are essential for effective cyber-defense. Signature-based IDS operate using specific rules which are difficult to generate due to the evolving cybersecurity landscape. To this end, this work proposes a rule generation framework, called RuleXploit, which uses Large Language Models (LLMs) to generate rules from exploits. The proposed framework is composed of two components: the RuleXploit Generator, which produces rules using structured prompts and examples, and the RuleXploit Refinery, which validates and refines these rules for accuracy and effectiveness. The RuleXploit framework is demonstrated via the GPT-4o model, configured with tailored prompt engineering techniques and settings. RuleXploit successfully generated 100% syntactically valid rules and achieved an effectiveness rate of 76.67% in detecting malicious traffic. This work presents the first approach to generate IDS rules from the exploit code of a vulnerability, offering a novel way towards the successful mitigation of cyber attacks.},
  keywords={Accuracy;Translation;Large language models;Retrieval augmented generation;Intrusion detection;Telecommunication traffic;Syntactics;Generators;Vectors;Cyberattack;Intrusion Detection Systems;Cyber-attacks;Rule Generation;Vulnerabilities;Generative Artificial Intelligence;Large Language Models},
  doi={10.1109/CSR64739.2025.11130010},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9660100,
  author={Iannucci, Stefano and Ables, Jesse and Anderson, William and Abburi, Bhuvanesh and Cardellini, Valeria and Banicescu, Ioana},
  booktitle={2021 IEEE Symposium Series on Computational Intelligence (SSCI)}, 
  title={A Performance-Oriented Comparison of Neural Network Approaches for Anomaly-based Intrusion Detection}, 
  year={2021},
  volume={},
  number={},
  pages={1-7},
  abstract={Intrusion Detection Systems employ anomaly detection algorithms to detect malicious or unauthorized activities in real time. Anomaly detection algorithms that exploit artificial neural networks (ANN) have recently gained particular interest. These algorithms are usually evaluated and compared through effectiveness measures, which aim to quantify how well anomalies are identified based on detection capabilities. However, to the best of our knowledge, the performance characterization from the perspective of computational cost and space, training time, memory consumption, together with a quantitative analysis of the trade-offs between algorithm effectiveness and performance, have not been explored yet. In this work, we select four recently proposed unsupervised anomaly detection algorithms based on ANN, namely: REPresentations for a random nEarest Neighbor (REPEN), DevNet, OmniAnomaly, Multi-Objective Generative Adversarial Active Learning (MO-GAAL); we perform a variety of experiments to evaluate the trade-offs between the effectiveness and performance of the selected algorithms using two reference dataset: NSL-KDD and CIC-IDS-2017. Our results confirm the importance of this study, showing that none of the selected algorithms dominate the others in terms of both, effectiveness and performance. Furthermore, it shows that approaches based on Recurrent Neural Networks, which exploit the temporal dependency of the samples, have a clear advantage over the others in terms of effectiveness, while exhibiting the worst execution time.},
  keywords={Training;Recurrent neural networks;Statistical analysis;Memory management;Intrusion detection;Artificial neural networks;Real-time systems;Performance Assessment;Anomaly Detection;Intrusion Detection},
  doi={10.1109/SSCI50451.2021.9660100},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11029922,
  author={Janecek, Madeline and Ezzati-Jivan, Naser and Hamou-Lhadj, Abdelwahab},
  booktitle={2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE)}, 
  title={Execution Trace Reconstruction Using Diffusion-Based Generative Models}, 
  year={2025},
  volume={},
  number={},
  pages={1077-1088},
  abstract={Execution tracing is essential for understanding system and software behaviour, yet lost trace events can significantly compromise data integrity and analysis. Existing solutions for trace reconstruction often fail to fully leverage available data, particularly in complex and high-dimensional contexts. Recent advancements in generative artificial intelligence, particularly diffusion models, have set new benchmarks in image, audio, and natural language generation. This study conducts the first comprehensive evaluation of diffusion models for reconstructing incomplete trace event sequences. Using nine distinct datasets generated from the Phoronix Test Suite, we rigorously test these models on sequences of varying lengths and missing data ratios. Our results indicate that the SSSDS4 model, in particular, achieves superior performance, in terms of accuracy, perfect rate, and ROUGE-L score across diverse imputation scenarios. These findings underscore the potential of diffusion-based models to accurately reconstruct missing events, thereby maintaining data integrity and enhancing system monitoring and analysis.},
  keywords={Analytical models;Adaptation models;Accuracy;Data integrity;Diffusion models;Data models;Robustness;Imputation;Software;Image reconstruction;Software Analysis;Generative Models;System Call Sequences;Execution Trace Reconstruction},
  doi={10.1109/ICSE55347.2025.00063},
  ISSN={1558-1225},
  month={April},}@ARTICLE{10168141,
  author={Yin, Qilin and Lu, Wei and Li, Bin and Huang, Jiwu},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Dynamic Difference Learning With Spatio–Temporal Correlation for Deepfake Video Detection}, 
  year={2023},
  volume={18},
  number={},
  pages={4046-4058},
  abstract={With the rapid development of face forgery techniques, the existing frame-based deepfake video detection methods have fell into a dilemma that frame-based methods may fail when encountering extremely realistic images. To overcome the above problem, many approaches attempted to model the spatio-temporal inconsistency of videos to distinguish real and fake videos. However, current works model spatio-temporal inconsistency by combining intra-frame and inter-frame information, but ignore the disturbance caused by facial motions that would limit further improvement in detection performance. To address this issue, we investigate into long and short range inter-frame motions and propose a novel dynamic difference learning method to distinguish between the inter-frame differences caused by face manipulation and the inter-frame differences caused by facial motions in order to model precise spatio-temporal inconsistency for deepfake video detection. Moreover, we elaborately design a dynamic fine-grained difference capture module (DFDC-module) and a multi-scale spatio-temporal aggregation module (MSA-module) to collaboratively model spatio-temporal inconsistency. Specifically, the DFDC-module applies self-attention mechanism and fine-grained denoising operation to eliminate the differences caused by facial motions and generates long range difference attention maps. The MSA-module is devised to aggregate multi-direction and multi-scale temporal information to model spatio-temporal inconsistency. The existing 2D CNNs can be extended into dynamic spatio-temporal inconsistency capture networks by integrating the proposed two modules. Extensive experimental results demonstrate that our proposed algorithm steadily outperforms state-of-the-art methods by a clear margin in different benchmark datasets.},
  keywords={Faces;Forgery;Deepfakes;Feature extraction;Face recognition;Dynamics;Correlation;Video forensics;face forgery detection;dynamic differential learning;spatio–temporal correlation;fine-grained denoising operation},
  doi={10.1109/TIFS.2023.3290752},
  ISSN={1556-6021},
  month={},}@ARTICLE{8944028,
  author={Wang, Caiyong and Wang, Yunlong and Liu, Yunfan and He, Zhaofeng and He, Ran and Sun, Zhenan},
  journal={IEEE Transactions on Biometrics, Behavior, and Identity Science}, 
  title={ScleraSegNet: An Attention Assisted U-Net Model for Accurate Sclera Segmentation}, 
  year={2020},
  volume={2},
  number={1},
  pages={40-54},
  abstract={This paper proposes a novel sclera segmentation approach based on an attention assisted U-Net model, named ScleraSegNet. Several off-the-shelf or improved attention modules are incorporated into the central bottleneck part or skip connection part of the original U-Net, helping the new model implicitly learn to suppress irrelevant regions in an input image while highlighting salient features useful for a specific task. This enables us to eliminate the necessity of using an external ROI localization model of cascade frameworks. The proposed approach is evaluated on several public, challenging eye datasets and experimental results show that introduced attention modules consistently improve the segmentation performance over the original U-Net across different datasets, and the best performing ScleraSegNet (CBAM) model achieves state-of-the-art segmentation performance. By utilizing the high stage's semantic information to guide the selection of features from the low stage in channel-wise and spatial-wise, the further improved ScleraSegNet (SSBC) model ranked first in the Sclera Segmentation Benchmarking Competition 2019 (SSBC 2019), part of ICB 2019, with a Precision value of 92.88% and a Recall value of 90.34% on the MASD.v1 dataset, and a Precision value of 83.19% and a Recall value of 80.01% on the MSD dataset, respectively.},
  keywords={Image segmentation;Iris recognition;Blood vessels;Biomedical imaging;Benchmark testing;Image color analysis;Sclera segmentation;sclera recognition;U-net;attention mechanism;SSBC},
  doi={10.1109/TBIOM.2019.2962190},
  ISSN={2637-6407},
  month={Jan},}@ARTICLE{9862976,
  author={Sun, Jiayin and Wang, Hong and Dong, Qiulei},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={MoEP-AE: Autoencoding Mixtures of Exponential Power Distributions for Open-Set Recognition}, 
  year={2023},
  volume={33},
  number={1},
  pages={312-325},
  abstract={Open-set recognition aims to identify unknown classes while maintaining classification performance on known classes and has attracted increasing attention in the pattern recognition field. However, how to learn effective feature representations whose distributions are usually complex for classifying both known-class and unknown-class samples when only the known-class samples are available for training is an ongoing issue in open-set recognition. In contrast to methods implementing a single Gaussian, a mixture of Gaussians (MoG), or multiple MoGs, we propose a novel autoencoder that learns feature representations by modeling them as mixtures of exponential power distributions (MoEPs) in latent spaces called MoEP-AE. The proposed autoencoder considers that many real-world distributions are sub-Gaussian or super-Gaussian and can thus be represented by MoEPs rather than a single Gaussian or an MoG or multiple MoGs. We design a differentiable sampler that can sample from an MoEP to guarantee that the proposed autoencoder is trained effectively. Furthermore, we propose an MoEP-AE-based method for open-set recognition by introducing a discrimination strategy, where the MoEP-AE is used to model the distributions of the features extracted from the input known-class samples by minimizing a designed loss function at the training stage, called MoEP-AE-OSR. Extensive experimental results in both standard-dataset and cross-dataset settings demonstrate that the MoEP-AE-OSR method outperforms 14 existing open-set recognition methods in most cases in both open-set recognition and closed-set recognition tasks.},
  keywords={Feature extraction;Task analysis;Training;Power distribution;Sun;Decoding;Gaussian distribution;Open-set recognition;autoencoder;scale mixture distribution;exponential power distribution},
  doi={10.1109/TCSVT.2022.3200112},
  ISSN={1558-2205},
  month={Jan},}@ARTICLE{10546334,
  author={Połap, Dawid and Jaszcz, Antoni},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Sonar Digital Twin Layer via Multiattention Networks With Feature Transfer}, 
  year={2024},
  volume={62},
  number={},
  pages={1-10},
  abstract={Analysis of the seabed using sonar is a key technology enabling the assessment of the substrate, detection, and classification of objects located there. However, quite often sonar data are processed by users due to the small amount of measurement data. This is due to the need to create large datasets and creating a sonar image is often dependent on atmospheric conditions. In this article, we present a solution based on digital twins that allows the implementation of a digital twin layer for sonar applications. A digital twin layer based on generative and classification network models increases the amount of data and improves the effectiveness of solutions. For this purpose, we propose multiattention models that focus on local and global sonar features and enable their fusion. Moreover, a technique for exchanging weights between networks in such a solution was modeled to reduce the amount of computing power. The proposed approach allows for analyzing images by focusing on different features and increasing the automatization of processing its data. To verify the operation, various sonar data were used and high classification accuracy was achieved as well as the generation of new data.},
  keywords={Sonar;Digital twins;Sonar measurements;Feature extraction;Computer architecture;Image segmentation;Computational modeling;Digital twin;feature exchange;feature fusion;image processing;multiattention;sonar},
  doi={10.1109/TGRS.2024.3408411},
  ISSN={1558-0644},
  month={},}@ARTICLE{10360155,
  author={Liu, Haiqiang and Yao, Meibao and Xiao, Xueming and Zheng, Bo and Cui, Hutao},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={MarsScapes and UDAFormer: A Panorama Dataset and a Transformer-Based Unsupervised Domain Adaptation Framework for Martian Terrain Segmentation}, 
  year={2024},
  volume={62},
  number={},
  pages={1-17},
  abstract={Martian terrain segmentation aims to assign all pixels of an input image with various terrain labels, which provides a firm support for the downstream research on rover traversing and geologic analysis tasks. However, existing studies in this field suffer from limitations in two aspects: one is the lack of large-scale and high-quality Martian terrain datasets, and the other is the over-reliance on purely supervised learning that is very data-hungry and sensitive to domain shifts among different datasets. In this article, we overcome these from the perspective of both data and methodology. First, we publish MarsScapes, a panorama dataset with appreciable data volume and fine-grained annotations for Martian terrain understanding. The dataset contains 195 terrain panoramas composed of 3779 subimages, and all pixels in the panoramas are split into nine semantic categories. Then, we propose the first transformer-based unsupervised domain adaptation (UDA) framework (UDAFormer) for the cross-domain terrain segmentation on Mars, which consists of a teacher–student model and an output-guided biased sampling (OGBS) module. The teacher–student model performs knowledge distillation to explore robust cross-domain features, where a modified augmentation regularization (MAR) is designed to alleviate the interference of undesirable augmentations to domain adaption. The OGBS helps the teacher–student network to emphasize the categories that tend to be ambiguous or submerged during the training, elevating the overall accuracy for the UDA segmentation of Martian terrains. Extensive experiments on the MarsScapes and another dataset called Mars-Seg demonstrate the superiority of UDAFormer over the state-of-the-art methods in UDA Martian terrain segmentation.},
  keywords={Mars;Rocks;Training;Annotations;Task analysis;Image segmentation;Transformers;Extraterrestrial surface understanding;knowledge distillation;Martian terrain segmentation;sampling strategy;transformer;unsupervised domain adaptation (UDA)},
  doi={10.1109/TGRS.2023.3343109},
  ISSN={1558-0644},
  month={},}@ARTICLE{10471901,
  author={Du, Xinqi and Li, Ziyue and Long, Cheng and Xing, Yongheng and Yu, Philip S. and Chen, Hechang},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={FELight: Fairness-Aware Traffic Signal Control via Sample-Efficient Reinforcement Learning}, 
  year={2024},
  volume={36},
  number={9},
  pages={4678-4692},
  abstract={Traffic congestion is becoming an increasingly prominent problem, and intelligent traffic signal control methods can effectively alleviate it. Recently, there has been a growing trend of applying reinforcement learning to traffic signal control for adaptive signal scheduling. However, most existing methods focus on improving traffic performance while neglecting the issue of scheduling fairness, resulting in long waiting time for some vehicles. Some works attempt to address fairness issues but often sacrifice transport performance. Furthermore, existing methods overlook the challenge of sample efficiency, especially when dealing with diversity-limited traffic data. Therefore, we propose a Fairness-aware and sample-Efficient traffic signal control method called FELight. Specifically, we first design a novel fairness metric and integrate it into decision process to penalize cases with high latency by setting a threshold for activating the fairness mechanism. Theoretical comparison with other fairness works proves why and when our fairness could bring advantages. Moreover, counterfactual data augmentation is employed to enrich interaction data, enhancing the sample efficiency of FELight. Self-supervised state representation is introduced to extract informative features from raw states, further improving sample efficiency. Experiments on real traffic datasets demonstrate that FELight provides relatively fairer traffic signal control without compromising performance compared to state-of-the-art approaches.},
  keywords={Reinforcement learning;Throughput;Vehicle dynamics;Schedules;Dynamic scheduling;Data augmentation;Computer science;Traffic signal control;reinforcement learning;fairness-aware scheduling;sample efficiency;multi-intersections},
  doi={10.1109/TKDE.2024.3376745},
  ISSN={1558-2191},
  month={Sep.},}@ARTICLE{10262050,
  author={Song, Xu and Hou, Saihui and Huang, Yan and Cao, Chunshui and Liu, Xu and Huang, Yongzhen and Shan, Caifeng},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Gait Attribute Recognition: A New Benchmark for Learning Richer Attributes From Human Gait Patterns}, 
  year={2024},
  volume={19},
  number={},
  pages={1-14},
  abstract={Compared to gait recognition, Gait Attribute Recognition (GAR) is a seldom-investigated problem. However, since gait attribute recognition can provide richer and finer semantic descriptions, it is an indispensable part of building intelligent gait analysis systems. Nonetheless, the types of attributes considered in the existing datasets are very limited. This paper contributes a new benchmark dataset for gait attribute recognition named Multi-Attribute Gait (MA-Gait). Our MA-Gait contains 95 subjects recorded from 12 camera views, resulting in more than 13000 sequences, with 16 attributes labeled, including six attributes that have never been considered in the literature. Moreover, we propose a Multi-Scale Motion Encoder (MSME) to extract robust motion features, and an Attribute-Guided Feature Selection Module (AGFSM) to adaptively capture the most discriminative attribute features from static appearance features and dynamic motion features for different attributes. Our method achieves the best GAR accuracy on the new dataset. Comprehensive experiments show the effectiveness of the proposed method through both quantitative and qualitative evaluations.},
  keywords={Feature extraction;Emotion recognition;Estimation;Data mining;Legged locomotion;Semantics;Shape;Gait attribute recognition;gait dataset;deep learning},
  doi={10.1109/TIFS.2023.3318934},
  ISSN={1556-6021},
  month={},}@ARTICLE{10363131,
  author={Wang, Guangcheng and Jiang, Kui and Gu, Ke and Liu, Hongyan and Liu, Hantao and Zhang, Wenjun},
  journal={IEEE Transactions on Image Processing}, 
  title={Coarse- and Fine-Grained Fusion Hierarchical Network for Hole Filling in View Synthesis}, 
  year={2024},
  volume={33},
  number={},
  pages={322-337},
  abstract={Depth image-based rendering (DIBR) techniques play an essential role in free-viewpoint videos (FVVs), which generate the virtual views from a reference 2D texture video and its associated depth information. However, the background regions occluded by the foreground in the reference view will be exposed in the synthesized view, resulting in obvious irregular holes in the synthesized view. To this end, this paper proposes a novel coarse and fine-grained fusion hierarchical network (CFFHNet) for hole filling, which fills the irregular holes produced by view synthesis using the spatial contextual correlations between the visible and hole regions. CFFHNet adopts recurrent calculation to learn the spatial contextual correlation, while the hierarchical structure and attention mechanism are introduced to guide the fine-grained fusion of cross-scale contextual features. To promote texture generation while maintaining fidelity, we equip CFFHNet with a two-stage framework involving an inference sub-network to generate the coarse synthetic result and a refinement sub-network for refinement. Meanwhile, to make the learned hole-filling model better adaptable and robust to the “foreground penetration” distortion, we trained CFFHNet by generating a batch of training samples by adding irregular holes to the foreground and background connection regions of high-quality images. Extensive experiments show the superiority of our CFFHNet over the current state-of-the-art DIBR methods. The source code will be available at https://github.com/wgc-vsfm/view-synthesis-CFFHNet.},
  keywords={Videos;Distortion;Rendering (computer graphics);Correlation;Visualization;Training;Real-time systems;Depth image-based rendering;hole filling;coarse and fine-grained fusion;hierarchical network;two-stage framework},
  doi={10.1109/TIP.2023.3341303},
  ISSN={1941-0042},
  month={},}@ARTICLE{10547053,
  author={Han, Ke and Huang, Yan and Wang, Liang and Liu, Zikun},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Self-Supervised Recovery and Guide for Low-Resolution Person Re-Identification}, 
  year={2024},
  volume={19},
  number={},
  pages={6252-6263},
  abstract={Low-resolution person re-identification is a challenging task to match low-resolution (LR) probes with high-resolution (HR) gallery images. To address the resolution gap, existing methods typically recover missing details for LR probes by super-resolution, and then match the recovered HR images (instead of the original LR probes) with gallery images. However, they usually pre-specify fixed scale factors for all LR images, and ignore that choosing a preferable scale factor for each image can recover more discriminative content and accordingly benefit the re-id performance. Moreover, these methods do not focus on learning LR representations themselves and always resort to extra recovery to handle LR probes, which is quite time-consuming during inference. To tackle these problems, we propose a Self-supervised Recovery and Guide (SRG) re-id model in this paper. Given LR images during training, our model first recovers more discriminative HR images by finding out preferable scale factors, and further leverages them as guide to improve original LR representations. By enforcing LR representations to approach the self-recovered HR guide in a self-supervised manner, our model can learn more discriminative representations for LR images. As a result, our model is able to directly handle LR probes without requiring recovery during inference, thereby reducing inference time significantly. Extensive experiments demonstrate the effectiveness of our method on four datasets.},
  keywords={Probes;Image reconstruction;Feature extraction;Superresolution;Measurement;Training;Noise;Low-resolution person re-identification;recovery and guide;scale factor metric},
  doi={10.1109/TIFS.2024.3409066},
  ISSN={1556-6021},
  month={},}@INPROCEEDINGS{9338395,
  author={Guidotti, Riccardo and Monreale, Anna},
  booktitle={2020 IEEE International Conference on Data Mining (ICDM)}, 
  title={Data-Agnostic Local Neighborhood Generation}, 
  year={2020},
  volume={},
  number={},
  pages={1040-1045},
  abstract={Synthetic data generation has been widely adopted in software testing, data privacy, imbalanced learning, machine learning explanation, etc. In such contexts, it is important to generate data samples located within “local” areas surrounding specific instances. Local synthetic data can help the learning phase of predictive models, and it is fundamental for methods explaining the local behavior of obscure classifiers. The contribution of this paper is twofold. First, we introduce a method based on generative operators allowing the synthetic neighborhood generation by applying specific perturbations on a given input instance. The key factor consists in performing a data transformation that makes applicable to any type of data, i.e., data-agnostic. Second, we design a framework for evaluating the goodness of local synthetic neighborhoods exploiting both supervised and unsupervised methodologies. A deep experimentation shows the effectiveness of the proposed method.},
  keywords={Software testing;Perturbation methods;Training data;Genomics;Machine learning;Predictive models;Generators;Synthetic Neighborhood Generation;Explainable Machine Learning;Data-Agnostic Generator;Data Mining},
  doi={10.1109/ICDM50108.2020.00122},
  ISSN={2374-8486},
  month={Nov},}@ARTICLE{11173694,
  author={Wang, Bin and Dai, Song and Song, Dongmei and Chen, Lei and Chen, Weimin and Yu, Jintao},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Annotation-Free, High-Fidelity SAR Oil Spill Image Synthesis via Classification-Guided Diffusion Model}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Synthetic Aperture Radar (SAR) imagery is indispensable for rapid, weather-independent marine oil spill monitoring. Yet the acute shortage of annotated SAR spill imagery severely limits deep learning detectors. While Generative Adversarial Networks (GANs) have been used to generate synthetic data, their inherent limitations—training instability and mode collapse—often result in blurred and semantically inconsistent outputs. To overcome these challenges, we introduce a Classification-Guided Diffusion Model (CG-DM), which integrates the expressive power of diffusion processes with task-specific guidance. CG-DM incorporates three key innovations: (i) Morphology-Aware Classification Guidance: SAR oil spill images are categorized into different morphological categories (blocky, elongated and patchy). This category information conditions every step of the reverse-diffusion process, enabling fine-grained control over the global geometry of generated spills while preserving intra-category diversity. (ii) Label-Synchronized Generation: The model simultaneously generates the SAR image and its corresponding pixel-level annotation mask, which eliminates the need for the time-consuming and error-prone manual labeling process. (iii) Spatial-Aware Attention Mechanism: A lightweight attention mechanism performs localized window self-attention with relative positional offsets, which significantly enhances the sharpness of spill edges and the fidelity of speckle-textured details. Evaluated on the M4D benchmark (ITI/EMSA’s semantic segmentation dataset with Sentinel-1 SAR imagery from 2015–2017), CG-DM achieves a Fréchet Inception Distance (FID) of 203.14 and a Kernel Inception Distance (KID) of 0.124, surpassing state-of-the-art GAN baselines by substantial margins. Besides, ablation studies confirm the critical contributions of each component: spatial-aware attention mechanism significantly enhancing generation quality, while classification guidance effectively preserving morphological feature diversity. Crucially, under extreme data scarcity, training augmentation with CG-DM synthetic samples improves oil-spill detection IoU by up to 81%, demonstrating strong practical utility. This study establishes the first annotation-free paradigm for SAR oil-spill data generation, paving the way for high-accuracy maritime disaster monitoring systems.},
  keywords={Oils;Diffusion models;Noise reduction;Radar polarimetry;Attention mechanisms;Training;Annotations;Synthetic aperture radar;Labeling;Manuals;Marine oil spill;diffusion model;SAR image expansion},
  doi={10.1109/TGRS.2025.3612298},
  ISSN={1558-0644},
  month={},}@ARTICLE{10945355,
  author={Ahn, Jung Su and Kwak, Ki Hoon and Cho, Young-Rae},
  journal={IEEE Access}, 
  title={Explainable Feature-Injected Diffusion Model for Medical Image Translation}, 
  year={2025},
  volume={13},
  number={},
  pages={57255-57265},
  abstract={The integration of computed tomography (CT) and magnetic resonance (MR) imaging is crucial for accurate medical diagnosis and treatment planning. However, translating images between CT and MR remains challenging due to significant differences in imaging modalities. To address this problem, we propose an Explainable Feature-Injected Diffusion Model (EIDM) for unsupervised CT-to-MR image translation. EIDM comprises a feature synthesis module and a diffusion-based latent space learning framework. This model captures frequency representations of the original CT images using the Fast Fourier Transform and applies high-pass filters to restore anatomical structures lost during diffusion. It also integrates weighted heatmaps generated by explainable AI models and utilizes a cross-attention mechanism to achieve unbiased image synthesis. We quantitatively evaluated EIDM and recent approaches using four metrics for comparison. Experimental results demonstrate that EIDM outperforms latest Generative Adversarial Networks (GANs) and diffusion models, generating realistic MR images that preserve anatomical integrity, as evidenced by enhanced scores across evaluation metrics. This work highlights the effectiveness of jointly learning explainable features and contour regions in achieving the goal of translating CT to MR images.},
  keywords={Computed tomography;Translation;Diffusion models;Diffusion processes;Bridges;Magnetic resonance imaging;Anatomical structure;Feature extraction;Training;Gaussian noise;Medical images;image translation;diffusion;cross-attention;feature synthesis},
  doi={10.1109/ACCESS.2025.3555585},
  ISSN={2169-3536},
  month={},}@ARTICLE{11154007,
  author={Li, Boang and Cao, Hui and Chen, Badong and Wang, Tao and Zhang, Jie},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={EveryBrain: Generate EEG Responses From Images For Specified Individuals}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={This paper presents EveryBrain, a method to generate electroencephalographic (EEG) signals of visual stimuli using images. Given that individuals exhibit distinct EEG responses to the same visual stimulus, EveryBrain is capable of capturing these individual characteristics during signal generation. The framework operates in two stages. By leveraging the temporal properties of EEG signals and the spatial features of images, EveryBrain presents a self-supervised framework that simultaneously reconstruct EEG signals and perform contrastive learning between image and EEG features. Furthermore, through additional training focused on individual EEG differences, Stage2 injects an ID number (representing a specific person) into image features via a cross-modal projector. The resulting personalized EEG latent codes, supervised by the Stage1 encoder, are then decoded into vivid, individualized EEG responses. Experiments validate the accuracy of EveryBrain in generating EEG signals for various individuals in response to visual stimuli. Overall, the proposed method tackles challenges in EEG generation from images, such as cross-modal alignment, individual variability, and waveform stability, yielding promising results. Additionally, the novel approach of of joint learning between images and EEG demonstrates positive effects on decoding visual neural representations. Both quantitative and qualitative evaluations demonstrate the effectiveness of methods, marking a significant step toward portable and cost-effective "image-to-thought".},
  keywords={Electroencephalography;Visualization;Brain modeling;Training;Feature extraction;Data models;Decoding;Brain;Computational modeling;Videos;cross-modal learning;self-supervised learning;personalized embedding;visual neural decoding;image–to–EEG generation},
  doi={10.1109/TCSVT.2025.3607971},
  ISSN={1558-2205},
  month={},}@INPROCEEDINGS{10487437,
  author={Mohammad, Atif Farid and Clark, Bryan and Hegde, Ramya},
  booktitle={2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE)}, 
  title={Large Language Model (LLM) & GPT, A Monolithic Study in Generative AI}, 
  year={2023},
  volume={},
  number={},
  pages={383-388},
  abstract={Large Language Models (LLMs) are a branch of computer science and artificial intelligence which is concerned with computer and human language interaction. It is the study of mathematical and computational modeling of various aspects of language and the development of an arsenal of systems. Large Language Models are considered an area of research and application that explores how computers can be used to comprehend and manipulate natural language text or speech to perform useful tasks. It has spread its applications in various areas such as machine translation, email spam detection, information extraction, summarization, medical, and question answering etc. Large Language Models (LLMs) have a greater contribution in the area of text pre-processing as well in the time of ChatGPT as an example. Different pre-processing steps are required to perform, such as stemming, part-of-speech (POS) tagging, chunking, parsing, information extraction, etc. to perform language processing.},
  keywords={Deep learning;Computer science;Planets;Generative AI;Unsolicited e-mail;Tagging;Question answering (information retrieval);LLM;GPT;NLP;ML;Natural Language Generation (NLG);Natural Language Understanding (NLU)},
  doi={10.1109/CSCE60160.2023.00068},
  ISSN={},
  month={July},}@INPROCEEDINGS{11166697,
  author={SN, Prajwalasimha and Shelke, Nilesh and Saini, Dilip Kumar Jang Bahadur and Pimpalkar, Amit and Kumar, G Hemanth and D, Shivamma},
  booktitle={2025 3rd International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)}, 
  title={AI-Powered Defense Against Advanced Persistent Threats (APTs): Techniques, Case Studies, and Future Research Directions}, 
  year={2025},
  volume={},
  number={},
  pages={826-831},
  abstract={Advanced Persistent Threats (APTs) are a formidable and ever-evolving threat to global cyber security, particularly against critical infrastructure, government networks, and cyber-physical systems. Exhibiting high levels of sophistication, persistence, and stealth, APTs have a propensity to bypass traditional defense mechanisms dependent on signatures and pre-defined rules. Recent advances in Artificial Intelligence (AI), such as deep learning, federated learning, graph neural networks, reinforcement learning, and adversarial learning, have introduced novel paradigms for real-time threat detection and proactive defense strategies. This paper presents a comprehensive and organized overview of state-of-the-art AI-based solutions for the detection, attribution, deception, and response to APTs. Illustrative case studies from sectors like financial networks, healthcare networks, cloud infrastructures, and national critical assets are discussed, highlighting realistic challenges, performance metrics, and optimal implementation practices. Emerging challenges are also explored, such as data availability constraints, labeling inconsistencies, risks of model compromise, vulnerability to adversarial attacks, and scalability constraints in real-time. The findings emphasize the supreme necessity of interdisciplinary research, as well as collaborative activities by academia, industry, and government, to create scalable, explainable, and anticipatory cyber security solutions that can effectively address APTs in future digital ecosystems.},
  keywords={Industries;Training;Technological innovation;Explainable AI;Government;Collaboration;Real-time systems;Threat assessment;Zero Trust;Computer crime;Advanced Persistent Threats (APTs);Intrusion Detection;Threat Intelligence;Malware;Lateral Movement;Zero-Day Exploits;Anomaly Detection},
  doi={10.1109/ICSCDS65426.2025.11166697},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10639037,
  author={Mansouri, Dhekra and Echtioui, Amira and Khemakhem, Rafik and Hamida, Ahmed Ben},
  booktitle={2024 IEEE 7th International Conference on Advanced Technologies, Signal and Image Processing (ATSIP)}, 
  title={Explainable AI Framework for Alzheimer’s Diagnosis Using Convolutional Neural Networks}, 
  year={2024},
  volume={1},
  number={},
  pages={93-98},
  abstract={Alzheimer’s disease (AD) stands as a form of dementia characterized by the gradual degeneration of brain cells, resulting in compromised memory, cognitive functions, and the loss of fundamental skills, ultimately leading to fatality. While a definitive cure for AD remains elusive, early detection plays a pivotal role in managing its progression and enhancing the quality of life for patients. This study delves into the realm of Alzheimer’s disease identification through the application of various Neural Network models employing classification techniques. Leveraging a contemporary hybrid dataset, the investigation yielded four distinct classifications. Moreover, the study delved into elucidating the specific brain regions contributing to each classification using the Grad-CAM (Gradient-weighted Class Activation Mappings) based XAI (eXplainable Artificial Intelligence) framework applied to patients’ MRI images. A comprehensive assessment was conducted on pre-trained deep neural networks, particularly focusing on Convolutional Neural Network (CNN) models trained exclusively on authentic MRIs and a combination of authentic and synthetic MRIs. The efficacy of deep learning in disease detection was exemplified, with the CNN model trained on both real and synthetic MRIs outperforming its counterpart trained solely on real MRIs. The former achieved an impressive accuracy of 97.50%, a Balanced Accuracy Score (BA) of $98.58 \%$, and a Matthew’s Correlation Coefficient (MCC) of 95.95%. In contrast, the model trained exclusively on real MRIs exhibited an accuracy of $88.98 \%$, a BA of 94.01%, and an MCC of $83.67 \%$.},
  keywords={Correlation coefficient;Accuracy;Explainable AI;Magnetic resonance imaging;Brain modeling;Data models;Convolutional neural networks;Alzheimer’s disease;Grad-CAM;CNN;XAI framework;Real MRIs;Synthetic MRIs},
  doi={10.1109/ATSIP62566.2024.10639037},
  ISSN={2687-878X},
  month={July},}@INPROCEEDINGS{8322601,
  author={Hu, Hengchang and Liu, Bo and Zhang, Pan},
  booktitle={2017 3rd IEEE International Conference on Computer and Communications (ICCC)}, 
  title={Several models and applications for deep learning}, 
  year={2017},
  volume={},
  number={},
  pages={524-530},
  abstract={As a popular technology in recent years, deep learning has attracted widespread attention from academic research to industrial application. In this paper, we briefly summarize the important concepts and decisive factors in the development of deep learning. Then the representative contemporary algorithms are mentioned. It summarizes the 6 main deep learning models of the current mainstream academic research and expounds their principles, illustrating the concepts and characteristics of different kinds of neural network structure models. Certain industrial applications, including speech recognition, image recognition and artificial intelligence, are presented to analyze the future trends and the main challenges.},
  keywords={Biological neural networks;Logic gates;Training;Graphics processing units;Convolutional neural networks;Computational modeling;deep learning;neural networks;learning models;applications},
  doi={10.1109/CompComm.2017.8322601},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9734157,
  author={Shivkumar, Keshav and Swaminathan, Goutham and Puvvadi, Teja and Shekar, Arjun and Shilpa, S},
  booktitle={2022 12th International Conference on Cloud Computing, Data Science & Engineering (Confluence)}, 
  title={Cloud-Based Model for Detecting Skin Cancer}, 
  year={2022},
  volume={},
  number={},
  pages={106-111},
  abstract={Medicine is a crucial sector in human society and as generations go by, there is the constant strive to improve on healthcare to make diagnoses, cures, treatment, etc. better and easier. With the rise of machine learning and artificial intelligence in several markets, there is the obligatory attempt to use it in healthcare as well, wherein successful use cases have been developed; there have been multiple papers on using deep learning in medicine, and deep learning has shown immense potential in classifying medical images for detecting various diseases. This project aims to use deep learning to train a model to classify images of skin lesions as malignant or benign, and implement it in a marketable manner with a user sided interface. Cloud infrastructures have proven itself to be the go-to solution for hosting online services, because of its business efficiencies, cost savings, data security, interoperability and the redundancy of on-premise hardware. The focus on optimizing the current problem statement of detecting skin cancer is assisted by deploying the neural network model on the cloud service Amazon Web Services (AWS), to outsource data-intensive computing. To complete the planned execution, an Android mobile application was proposed so that the general public can make use of the neural network in a simple and easy-to-use manner.},
  keywords={Deep learning;Web services;Computational modeling;Neural networks;Redundancy;Medical services;Skin},
  doi={10.1109/Confluence52989.2022.9734157},
  ISSN={},
  month={Jan},}@ARTICLE{10858454,
  author={Nadeem, Mohammad and Sohail, Shahab Saquib and Madsen, Dag Øivind and Alzahrani, Ahmed Ibrahim and Ser, Javier Del and Muhammad, Khan},
  journal={IEEE Transactions on Big Data}, 
  title={A Multi-Modal Assessment Framework for Comparison of Specialized Deep Learning and General-Purpose Large Language Models}, 
  year={2025},
  volume={11},
  number={3},
  pages={1001-1012},
  abstract={Recent years have witnessed tremendous advancements in Al tools (e.g., ChatGPT, GPT-4, and Bard), driven by the growing power, reasoning, and efficiency of Large Language Models (LLMs). LLMs have been shown to excel in tasks ranging from poem writing and coding to essay generation and puzzle solving. Despite their proficiency in general queries, specialized tasks such as metaphor understanding and fake news detection often require finely tuned models, posing a comparison challenge with specialized Deep Learning (DL). We propose an assessment framework to compare task-specific intelligence with general-purpose LLMs on suicide and depression tendency identification. For this purpose, we trained two DL models on a suicide and depression detection dataset, followed by testing their performance on a test set. Afterward, the same test dataset is used to evaluate the performance of four LLMs (GPT-3.5, GPT-4, Google Bard, and MS Bing) using four classification metrics. The BERT-based DL model performed the best among all, with a testing accuracy of 94.61%, while GPT-4 was the runner-up with accuracy 92.5%. Results demonstrate that LLMs do not outperform the specialized DL models but are able to achieve comparable performance, making them a decent option for downstream tasks without specialized training. However, LLMs outperformed specialized models on the reduced dataset.},
  keywords={Deep learning;Chatbots;Testing;Depression;Large language models;Internet;Hands;Fake news;Big Data;Data models;Large language models;deep learning;assessment framework;generative artificial intelligence},
  doi={10.1109/TBDATA.2025.3536937},
  ISSN={2332-7790},
  month={June},}@INPROCEEDINGS{10037408,
  author={Bannur, Charvi and Bhat, Chaitra and Goutham, Gagan and Mamatha, H. R.},
  booktitle={2022 IEEE 1st International Conference on Data, Decision and Systems (ICDDS)}, 
  title={General Transit Feed Specification Assisted Effective Traffic Congestion Prediction Using Decision Trees and Recurrent Neural Networks}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Traffic congestion prediction is an open-ended critical problem highlighted by the rapid growth in intra-city transit mobility in recent years fuelling the necessity for an intelligent traffic management system in metropolitan areas. The majority of this research continues to rely on data from electronic devices and mobile signals, which can sometimes be manipulated to mislead the public. Modern state-of-the-art models of predictive analysis of Graph Neural Networks (GNNs), AutoRegressive Integrated Moving Average (ARIMA) and other Hybrid Deep Neural Networks have yielded positive results. However, determining which artificial intelligence model would be able to best address the issue of traffic congestion in densely populated areas. Based on this premise, we focus on using GTFS(General Transit Feed Specification) data and have constructed a meticulous and reflective dataset. We also postulate a study of multifarious models in comparison as well as a novel approach that maps traffic congestion as a classification problem rather than a regression-prediction problem to address the shortcomings of the issue. The highest accuracy metric for the optimised models was using the Decision Tree Classifier which yielded an accuracy of 81%. In this research article, we offer an overview of predicting traffic congestion whilst focusing on the G TFS dataset.},
  keywords={Measurement;Recurrent neural networks;Urban areas;Predictive models;Logic gates;Graph neural networks;Feeds;Traffic Congestion Prediction;Public Transit Systems;GTFS data;LSTMs (Long Short Term Memory);GRUs (Gated Recurrent Unit);GNNs (Graph Neural Network);Decision Trees},
  doi={10.1109/ICDDS56399.2022.10037408},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11065524,
  author={Jiang, Yonglong and Lang, Xun and Wu, Jiande and Zhu, Xiaoxian and Peng, Qingjun},
  booktitle={2025 IEEE 14th Data Driven Control and Learning Systems (DDCLS)}, 
  title={Diffusion-TS Guided Small Sample Data Augmentation for Power Transformer Fault Diagnosis}, 
  year={2025},
  volume={},
  number={},
  pages={2199-2204},
  abstract={The shortage of fault samples remains a significant challenge in artificial intelligence-based fault diagnosis for power transformers. To address this challenge, here we introduce and improve the Diffusion-TS method for generating reliable Dissolved Gas Analysis (DGA) training data for transformer fault diagnosis. Initially, a low-pass filter is incorporated into the deep decomposer to construct a trend-extraction layer, thereby improving the accuracy of trend extraction. Then, a dynamically decaying Exponential Moving Average (EMA) is employed during training to optimize model parameters, mitigating issues of unstable training and limited generalization. Using DGA data collected from power transformers, we conducted three experiments to evaluate the model performance in terms of generation similarity, correlation, and utility. Experimental results demonstrate that the generated data exhibits high similarity and correlation with real-world data, making it highly effective for training classification models for transformer fault diagnosis.},
  keywords={Training;Learning systems;Correlation;Training data;Low-pass filters;Dissolved gas analysis;Data augmentation;Market research;Data models;Power transformers;power transformer;small sample data augmentation;dissolved gas analysis;Diffusion-TS},
  doi={10.1109/DDCLS66240.2025.11065524},
  ISSN={2767-9861},
  month={May},}@INPROCEEDINGS{10821878,
  author={Lin, Yuxin and Ma, Jing and Wang, Wei and Wu, Zhihao and Dong, Suyu and Luo, Gongning and Wang, Kuanquan},
  booktitle={2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Biomedically Informed ECG Synthesis: Customizing Cardiac Cycle Phases with Diffusion Model}, 
  year={2024},
  volume={},
  number={},
  pages={3505-3508},
  abstract={Cardiovascular diseases are a major global health challenge, with electrocardiography (ECG) being critical for diagnosis and monitoring. As artificial intelligence and automated ECG diagnostic technologies rapidly advance, the demand for large-scale ECG databases continues to grow. Generative ECG has become a mainstream method to enhance database size and diversity. However, existing methods typically generate ECG randomly or focus on limited physiological categories, lacking the ability to synthesize ECG with varying physiological features and cardiac cycles, which is crucial for various practical applications. In response to this need, we propose a novel approach introducing a diffusion model called DIFF-ECG to generate precisely customized ECG that accurately reflect diverse cardiac conditions. Segmentation-based quality assessments confirmed that the synthesized ECG accurately followed the specified cardiac cycle information, with our model significantly outperforming baseline diffusion and GAN-based methods. Therefore, our approach addresses the critical need for generating clinically relevant and customizable ECG, contributing significantly to the field of automated cardiac disease diagnosis. By enabling fine-tuning of cardiac cycle phases, our method significantly expands the application range of generative ECG, potentially improving the diagnostic accuracy for rare diseases and advancing personalized medicine.},
  keywords={Databases;Biological system modeling;Precision medicine;Electrocardiography;Diffusion models;Data models;Quality assessment;Biomedical monitoring;Monitoring;Synthetic data;Electrocardiography;generative models;synthetic data;time series},
  doi={10.1109/BIBM62325.2024.10821878},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{10498420,
  author={Pallab, Nafisul Mukit and Mojumdar, Mayen Uddin and Chakraborty, Narayan Ranjan and Vetrivendan, L and Akteri, Sharmin},
  booktitle={2024 11th International Conference on Computing for Sustainable Global Development (INDIACom)}, 
  title={Machine Learning based Diagnosis of Kidney Abnormality Recognition on CT Scan Images}, 
  year={2024},
  volume={},
  number={},
  pages={1283-1289},
  abstract={The healthcare industry has witnessed a surge in the adoption of machine learning due to its capacity to detect and predict diseases. The integration of machine learning and artificial intelligence (AI) is increasingly prevalent in the healthcare industry for problem-solving purposes. Kidney abnormalities (KA) are increasingly prevalent in Bangladesh. The exacerbation of this threat to public health is a lack of information and substandard lifestyle choices. There is an urgent need for effective methods to track and monitor the kidney health of individuals in order to buck this trend. Kidney Abnormality, Monitoring, and Analytics (KAMA) endeavors to resolve this concern by developing a sophisticated machine learning system that can promptly and accurately identify and evaluate kidney conditions, differentiating between normal and abnormal states. In an effort to identify kidney abnormalities with precision, the dataset was partitioned into train and test subsets. Both GoogLeNet and a meticulously designed Convolutional Neural Network (CNN) produced the most favorable results.},
  keywords={Industries;Image recognition;Machine learning;Market research;Convolutional neural networks;Problem-solving;Surges;Kidney Cancer;Diagnosis;Abnormality;Evaluation;Transfer learning},
  doi={10.23919/INDIACom61295.2024.10498420},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10938521,
  author={Byun, Chansup and Reuther, Albert and Anderson, LaToya and Arcand, William and Bergeron, Bill and Bestor, David and Bonn, Alexander and Burrill, Daniel and Gadepally, Vijay and Houle, Michael and Hubbell, Matthew and Jananthan, Hayden and Jones, Michael and Luszczek, Piotr and Michaleas, Peter and Milechin, Lauren and Morales, Guillermo and Mullen, Julie and Prout, Andrew and Rosa, Antonio and Yee, Charles and Kepner, Jeremy},
  booktitle={2024 IEEE High Performance Extreme Computing Conference (HPEC)}, 
  title={GPU Sharing with Triples Mode}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={There is a tremendous amount of interest in AI/ML technologies due to the proliferation of generative AI applications such as ChatGPT. This trend has significantly increased demand on GPUs, which are the workhorses for training AI models. Due to the high costs of GPUs and lacking supply, it has become of interest to optimize GPU usage in HPC centers. MIT Lincoln Laboratory Supercomputing Center (LLSC) has developed an easy-to-use GPU sharing feature supported by LLSC-developed tools including LLsub and LLMapReduce. This approach overcomes some of the limitations with the existing methods for GPU sharing. This allows users to apply GPU sharing whenever possible while they are developing their AI/ML models and/or doing parametric study on their AI models or executing other GPU applications. Based on our initial experimental results with GPU sharing, GPU sharing with triples mode is easy to use and achieved significant improvement in GPU usage and throughput performance for certain types of AI applications.},
  keywords={Training;Costs;Parametric study;Generative AI;Computational modeling;Graphics processing units;Throughput;Market research;Chatbots;GPU;sharing;LLsub;LLMapReduce},
  doi={10.1109/HPEC62836.2024.10938521},
  ISSN={2643-1971},
  month={Sep.},}@ARTICLE{10021249,
  author={Nie, Laisen and Wang, Xiaojie and Zhao, Qinglin and Shang, Zhigang and Feng, Li and Li, Guojun},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Digital Twin for Transportation Big Data: A Reinforcement Learning-Based Network Traffic Prediction Approach}, 
  year={2024},
  volume={25},
  number={1},
  pages={896-906},
  abstract={Vehicular Ad-Hoc Networks (VANETs), as the crucial support of Intelligent Transportation Systems (ITS), have received great attention in recent years. With the rapid development of VANETs, various services have generated a great deal of data that can be used for transportation planning and safe driving. Especially, with the advent of Coronavirus Disease 2019 (COVID-19), the transportation system has been impacted, thus novel modes of transportation planning and intelligent applications are necessary. Digital twins can provide powerful support for artificial intelligence applications in Transportation Big Data (TBD). The features of VANETs are varying, which arises the main challenge of digital twins applying in TBD. Network traffic prediction, as part of digital twins, is useful for network management and security in VANETs, such as network planning and anomaly detection. This paper proposes a network traffic prediction algorithm aiming at time-varying traffic flows with a large number of fluctuations. This algorithm combines Deep Q-Learning (DQN) and Generative Adversarial Networks (GAN) for network traffic feature extraction. DQN is leveraged to carry out network traffic prediction, in which GAN is involved to represent Q-network. Meanwhile, the generative network can increase the number of samples to improve the prediction error. We evaluate the performance of our method by implementing it on three real network traffic data sets. Finally, we compare the two state-of-the-art competing methods with our method.},
  keywords={COVID-19;Predictive models;Neural networks;Feature extraction;Transportation;Generative adversarial networks;Digital twins;Digital twin;transportation big data;deep reinforcement learning;generative adversarial networks},
  doi={10.1109/TITS.2022.3232518},
  ISSN={1558-0016},
  month={Jan},}@INPROCEEDINGS{10074593,
  author={Kaushal, Anukriti and Singh, Sanchit and Negi, Shashank and Chhaukar, Shikhar},
  booktitle={2022 4th International Conference on Advances in Computing, Communication Control and Networking (ICAC3N)}, 
  title={A Comparative Study on Deepfake Detection Algorithms}, 
  year={2022},
  volume={},
  number={},
  pages={854-860},
  abstract={In recent years, the number of images and videos shared online increased and people have easy ways to access such content. “DeepFake” refers to any multimedia content created using deep learning technology in order to make it appear realistic. The creation of deepfake videos and images using deep learning techniques leads to very realistic “DeepFake” videos and images by changing the digital content of images and videos. Deepfake is widely recognized as one of artificial intelligence’s most dangerous uses. Deepfake makes it possible to place a person in a totally imaginary situation since it is used to imitate an activity that the person did not perform. Deepfakes have been becoming increasingly dangerous to democracy, society’s security and people’s privacy. The distribution of such deepfake content on various platforms urged the international community to revaluate the threat to social security posed by such content. It encouraged the researchers around the world to develop effective deepfake detection methods. In this paper we have discussed such approaches of deepfake detection in videos and images that are available in recent studies and have provided comparative review of research on deepfake detection algorithms. It also compares the different detection techniques and examines their limitations and advantages.},
  keywords={Deep learning;Deepfakes;Privacy;Streaming media;Security;Detection algorithms;Deepfake;Deep Learning;Deepfake Detection;Detection Accuracy;Artificial Intelligence;Generative Adversarial Networks},
  doi={10.1109/ICAC3N56670.2022.10074593},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9697318,
  author={G, Devasena and V, Vidhya},
  booktitle={2021 International Conference on Computational Intelligence and Computing Applications (ICCICA)}, 
  title={A Study of Various Algorithms for Facial Expression Recognition: A Review}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={Facial Expression Recognition (FER) is an important thrust area in the field of artificial intelligence and computer vision. The features of various faces and their characteristics are analyzed to achieve the concept of FER. The facial characteristics are retrieved using an automated face detection method which helps to identify the emotions of a person. This study examines in-depth FER investigations using several techniques, such as template, appearance, knowledge-based and feature-based approaches, coupled with a variety of algorithms such as viola jones, Faster RCNN, SSD, MTCNN and Face landmark Detection. These techniques are used to classify the different emotions of the human face such as happiness, wrath, sorrow, disgust, fear, neutrality, surprise and disdain. Moreover, research works based on deep learning based FER models are also examined.},
  keywords={Pain;Face recognition;Knowledge based systems;Lighting;Feature extraction;Classification algorithms;Face detection;Face Expression Recognition;Face Detection;Face Recognition;Emotion Classification},
  doi={10.1109/ICCICA52458.2021.9697318},
  ISSN={},
  month={Nov},}@ARTICLE{11007173,
  author={Haghbin, Yasaman and Badiei, Mohammad Hossein and Tran, Nguyen H. and Piran, Md. Jalil},
  journal={IEEE Transactions on Network and Service Management}, 
  title={Resilient Federated Adversarial Learning With Auxiliary-Classifier GANs and Probabilistic Synthesis for Heterogeneous Environments}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Recently, collaborative learning paradigms like Federated Learning (FL) are gaining significant attention as a means of deploying artificial intelligence (AI)-based Internet of Things (IoT) applications. This is due to the fact that participants keep their heterogeneous data on their local devices and share only model updates with the central server. As a result of FL, new challenges arise, such as vulnerabilities to unknown data and adversarial samples, as well as security risks associated with inference, which may expose the system to potential evasion attacks. In this article, we introduce Auxiliary Federated Adversarial Learning (AuxiFed) as a solution to address these serious challenges. AuxiFed synthesizes data by using pre-trained auxiliary-classifier generative adversarial networks (AC-GANs) and probabilistic logic, enhancing model resilience and promoting accurate predictions while safeguarding against adversarial attacks. By leveraging locally trained models, AuxiFed provides representative and diverse synthetic samples for model updates during FL based on the pre-trained AC-GAN generators of individual clients. By merging these synthetic samples with real data during training, we foster diversity of data and improve the model’s ability to generalize to unknown data. In two distinct environments, with homogeneous and heterogeneous data, we train the model on two datasets, MNIST and EMNIST. Different adversarial evasion attacks are tested, as well as scenarios without attacks. The AuxiFed algorithm is also bolstered using robust adversarial techniques, and subsequently compared with the baseline algorithms. AuxiFed generally outperforms Federated Averaging (FedAvg), FL with Variational Autoencoders (FedAvg+VAEs), and FL with Conditional Generative Adversarial Networks (FedAvg+C-GANs) in terms of accuracy, generalization, and robustness. Comparatively to baseline methods, including FedAvg, FedAvg+VAE, and FedAvg+C-GAN, it shows better convergence during training and better performance on unknown data. Various adversarially trained variants of AuxiFed, such as AuxiFed-PGD and AuxiFed-FGSM, also outperform the previously mentioned baseline methods, along with their robust variants. As a result, AuxiFed enhances the performance of models, provides resilience against adversarial attacks, and can generalize to unknown data.},
  keywords={Data models;Training;Internet of Things;Computational modeling;Servers;Synthetic data;Robustness;Resilience;Probabilistic logic;Generative adversarial networks;Auxiliary Federated learning;Adversarial robustenss;Auxiliary classifier generative adversarial network;Heterogeneous Internet of Things;Probabilistic data synthesis},
  doi={10.1109/TNSM.2025.3571688},
  ISSN={1932-4537},
  month={},}@INPROCEEDINGS{10563353,
  author={Rathi, Preeti and Budhani, Sandeep Kumar and Murari Upadhyay, Govind and Vats, Prashant and Kaur, Ranjeeta and Saini, Ashok Kumar},
  booktitle={2024 4th International Conference on Innovative Practices in Technology and Management (ICIPTM)}, 
  title={Unmasking Deepfakes: Understanding the Technology, Risks, and Countermeasures}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This research explores the transformative role of deepfake technology as a cutting-edge tool in the realm of Visual Effects (VFX) filmmaking. Deepfake, an artificial intelligence-driven technique, has evolved beyond its controversial origins to become an invaluable asset in creating hyper-realistic digital content. This paper delves into the intricacies of deepfake applications, focusing on its utilization as a powerful tool for seamlessly integrating computer-generated imagery (CGI) into live-action sequences. The study investigates the advancements in deepfake algorithms, emphasizing their ability to convincingly replicate human expressions, gestures, and voices. Through a comprehensive analysis of case studies and industry practices, we examine how deepfake technology has transcended traditional limitations, providing filmmakers with a versatile and efficient means of enhancing visual storytelling. Furthermore, the ethical considerations and challenges associated with the use of deepfake in filmmaking are discussed. As technology blurs the lines between reality and fiction, concerns regarding misinformation and the potential for misuse are addressed.},
  keywords={Industries;Deepfakes;Ethics;Machine learning algorithms;Statistical analysis;Focusing;Production;Deepfake;Synthetic media;Artificial intelligence;Machine learning;Neural networks;Generative adversarial networks (GANs);Audio-visual manipulation},
  doi={10.1109/ICIPTM59628.2024.10563353},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{9564379,
  author={Parthasarathy, Dhasarathy and Johansson, Anton},
  booktitle={2021 IEEE International Conference on Artificial Intelligence Testing (AITest)}, 
  title={SilGAN: Generating driving maneuvers for scenario-based software-in-the-loop testing}, 
  year={2021},
  volume={},
  number={},
  pages={65-72},
  abstract={Automotive software testing continues to rely largely upon expensive field tests to ensure quality because alternatives like simulation-based testing are relatively immature. As a step towards lowering reliance on field tests, we present SilGAN, a deep generative model that eases specification, stimulus generation, and automation of automotive software-in-the-loop testing. The model is trained using data recorded from vehicles in the field. Upon training, the model uses a concise specification for a driving scenario to generate realistic vehicle state transitions that can occur during such a scenario. Such authentic emulation of internal vehicle behavior can be used for rapid, systematic and inexpensive testing of vehicle control software. In addition, by presenting a targeted method for searching through the information learned by the model, we show how a test objective like code coverage can be automated. The data driven end-to-end testing pipeline that we present vastly expands the scope and credibility of automotive simulation-based testing. This reduces time to market while helping maintain required standards of quality.},
  keywords={Software testing;Training;Codes;Automation;Systematics;Time to market;Search problems;software-in-the-loop testing;generative adversarial networks;time series generation;latent space search},
  doi={10.1109/AITEST52744.2021.00022},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10489807,
  author={Singh, Kamred Udham and More, Ajit and Verma, Rajeshwar and Jain, Dhananjay kumar and Somasekar, J. and Pandey, Saroj Kumar},
  booktitle={2023 International Conference on Artificial Intelligence for Innovations in Healthcare Industries (ICAIIHI)}, 
  title={Prediction of Alzheimer's Disease Progression Using Longitudinal Brain MRI Data and GANs}, 
  year={2023},
  volume={1},
  number={},
  pages={1-6},
  abstract={This research introduces a new method for predicting the course of Alzheimer's disease by combining longitudinal brain MRI data with Generative Adversarial Networks (GANs). Using additional information from reputable repositories, we carried out a descriptive study by applying a deductive technique and an interpretivist mindset. The GAN exhibited remarkable efficacy in producing lifelike MRI pictures by accurately identifying minute structural alterations that signify the advancement of the disease. The predictive model outperformed previous techniques with its high sensitivity and specificity. Comparison with well-established methods demonstrated our GAN-based approach's greater accuracy. Clinical validation, ethical issues, and multi-modal data integration should be the main areas of future research. This novel approach has the potential to completely transform Alzheimer's disease early detection and treatment programs.},
  keywords={Industries;Technological innovation;Ethics;Magnetic resonance imaging;Transforms;Medical services;Predictive models;Alzheimer's Disease;Generative Adversarial Networks;Longitudinal Brain MRI;Predictive Model;Disease Progression},
  doi={10.1109/ICAIIHI57871.2023.10489807},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9319106,
  author={Ladwig, Philipp and Pech, Alexander and Dörner, Ralf and Geiger, Christian},
  booktitle={2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)}, 
  title={Unmasking Communication Partners: A Low-Cost AI Solution for Digitally Removing Head-Mounted Displays in VR-Based Telepresence}, 
  year={2020},
  volume={},
  number={},
  pages={82-90},
  abstract={Face-to-face conversation in Virtual Reality (VR) is a challenge when participants wear head-mounted displays (HMD). A significant portion of a participant's face is hidden and facial expressions are difficult to perceive. Past research has shown that high-fidelity face reconstruction with personal avatars in VR is possible under laboratory conditions with high-cost hardware. In this paper, we propose one of the first low-cost systems for this task which uses only open source, free software and affordable hardware. Our approach is to track the user's face underneath the HMD utilizing a Convolutional Neural Network (CNN) and generate corresponding expressions with Generative Adversarial Networks (GAN) for producing RGBD images of the person's face. We use commodity hardware with low-cost extensions such as 3Dprinted mounts and miniature cameras. Our approach learns end-to-end without manual intervention, runs in real time, and can be trained and executed on an ordinary gaming computer. We report evaluation results showing that our low-cost system does not achieve the same fidelity of research prototypes using high-end hardware and closed source software, but it is capable of creating individual facial avatars with personspecific characteristics in movements and expressions.},
  keywords={Faces;Avatars;Resists;Image reconstruction;Gallium nitride;Three-dimensional displays;Training;Avatar;Convolutional Neural Network;Commodity Hardware;Face Tracking;Generative Adversarial Networks;Neural Rendering;Telepresence;Virtual Reality},
  doi={10.1109/AIVR50618.2020.00025},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10605578,
  author={Zhou, Jun and Wu, Zhenzhou and Man, Mengren and Wu, Yonghui and Linh, Le Dinh and Dai, Manna and Liu, Yong and Goh, Rick},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Llama-TCR: Generate De Novo TCR with Large Language Model}, 
  year={2024},
  volume={},
  number={},
  pages={845-850},
  abstract={T cell receptor-engineered T cell (TCR-T), where T cells are equipped with engineered antigen-specific receptors, is a promising approach of cancer immunotherapy. However, it is known that naturally occurred TCR is not able to detect some cancer antigens due to negative selection and resulted in the proliferation of cancer cells. This study introduces a novel application of large language models (LLM) in the de novo generation of T cell receptors (TCR). We propose Llama-TCR, a generative model trained on database of antigen and TCR pairs, for diverse and functional candidate TCR sequence generation. Using both sequence based benchmarking and 3D structure inspection, we show that the model is able to generate TCR sequences targeting to given antigens and has great potential in the development of novel TCR-T immunotherapy.},
  keywords={Antigens;Visualization;Solid modeling;Three-dimensional displays;Large language models;Immunotherapy;Benchmark testing;Large Language Model;Generative AI;TCR;Immunotherapy},
  doi={10.1109/CAI59869.2024.00158},
  ISSN={},
  month={June},}@ARTICLE{10620071,
  author={Sortino, Renato and Cecconello, Thomas and De Marco, Andrea and Fiameni, Giuseppe and Pilzer, Andrea and Magro, Daniel and Hopkins, Andrew M. and Riggi, Simone and Sciacca, Eva and Ingallinera, Adriano and Bordiu, Cristobal and Bufano, Filomena and Spampinato, Concetto},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={RADiff: Controllable Diffusion Models for Radio Astronomical Maps Generation}, 
  year={2024},
  volume={5},
  number={12},
  pages={6524-6535},
  abstract={Along with the nearing completion of the square kilometer array (SKA), comes an increasing demand for accurate and reliable automated solutions to extract valuable information from the vast amount of data it will allow acquiring. Automated source finding is a particularly important task in this context, as it enables the detection and classification of astronomical objects. Deep-learning-based object detection and semantic segmentation models have proven to be suitable for this purpose. However, training such deep networks requires a high volume of labeled data, which is not trivial to obtain in the context of radio astronomy. Since data needs to be manually labeled by experts, this process is not scalable to large dataset sizes, limiting the possibilities of leveraging deep networks to address several tasks. In this work, we propose RADiff, a generative approach based on conditional diffusion models trained over an annotated radio dataset to generate synthetic images, containing radio sources of different morphologies, to augment existing datasets and reduce the problems caused by class imbalances. We also show that it is possible to generate fully synthetic image-annotation pairs to automatically augment any annotated dataset. We evaluate the effectiveness of this approach by training a semantic segmentation model on a real dataset augmented in two ways: 1) using synthetic images obtained from real masks; and 2) generating images from synthetic semantic masks. Finally, we also show how the model can be applied to populate background noise maps for simulating radio maps for data challenges.},
  keywords={Data models;Surveys;Diffusion models;Task analysis;Training;Computational modeling;Data augmentation;Data-augmentation;diffusion-models;generative models;radio-astronomy;semantic-image-synthesis},
  doi={10.1109/TAI.2024.3436538},
  ISSN={2691-4581},
  month={Dec},}@INPROCEEDINGS{10551260,
  author={Hai, JiaLi and Chang, Kai and Yuan, Liangzhi and Wang, Run},
  booktitle={2023 4th International Conference on Computer, Big Data and Artificial Intelligence (ICCBD+AI)}, 
  title={FraudNet: A Network-centric Method for Balancing and Detecting Anomalies in Healthcare Insurance}, 
  year={2023},
  volume={},
  number={},
  pages={389-394},
  abstract={Healthcare insurance fraud detection is challenged by the prevalence of class imbalance in transaction datasets, which undermines the accuracy of predictive models. Traditional data balancing methods have been insufficient in addressing the complexity of healthcare fraud. This study proposes a novel framework, FraudNET, which utilizes a hybrid of Generative Adversarial Networks (GANs) and Convolutional AutoEncoders (CAE) to generate a balanced dataset and enhance the detection of healthcare insurance fraud. The performance of FraudNET was evaluated against traditional models using metrics such as Precision, Recall, F1 score. FraudNET significantly improved the balance of the dataset, with the GAN generated synthetic data exhibiting high fidelity. The CAE model demonstrated superior performance in classifying fraudulent transactions, outperforming established methods like Synthetic Minority Over-sampling Technique (SMOTE) and Adaptive Synthetic (ADASYN) in comparative analyses. The integration of GANs and CAE in the FraudNET framework offers a promising solution to the challenge of class imbalance in healthcare insurance fraud detection.},
  keywords={Measurement;Training;Analytical models;Adaptation models;Scalability;Insurance;Medical services;Healthcare Insurance Fraud;Generative Adversarial Networks;Convolutional Auto Encoders;Fraud Detection},
  doi={10.1109/ICCBD-AI62252.2023.00072},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10073664,
  author={Raga Priya, Immadi Dhatri and Sree Ramya, Ponnaluri and Vamshi, Mulugu Veera and Chandana, Bhimavarapu and Rao, M.Kameswara},
  booktitle={2023 Third International Conference on Artificial Intelligence and Smart Energy (ICAIS)}, 
  title={Malpractice Detection in Online Proctoring using Deep Learning}, 
  year={2023},
  volume={},
  number={},
  pages={575-583},
  abstract={One of the most effective image processing applications, face recognition is crucial in the technical world. An ongoing problem with authentication is the ability to recognize a person's face, particularly when it comes to tracking students’ movements in an examination. It is a pupil identification method that employs face biostatistics based on multiple technologies. The creation of this system aims to digitally replace physical invigilation with the digital view. The manual recording makes it harder to concentrate on numerous students. HOG classifiers, CNN, SVM, Generative Adversarial Networks, and Gabor filters are used in the suggested system. Face detection systems have grown over years and the industry has paid close attention to this topic. Numerous studies have been conducted on face and eye identification. Reports will be generated and saved following face recognition. The system is tested under different conditions, which include head movements, and changing distances between the person and the cameras. Overall accuracy is determined after testing. This system is efficient to reduce malpractice in less time. The created system is inexpensive and requires little installation.},
  keywords={Support vector machines;Industries;Tracking;Face recognition;Image processing;Manuals;Magnetic heads;Virtual Proctoring;Histogram of Oriented Gradients;Convolutional Neural Network;Support Vector Machine;Generative Adversarial Networks;Machine Learning;Facial Recognition;Facial Detection;Face Landmark estimation;Open Face},
  doi={10.1109/ICAIS56108.2023.10073664},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10475289,
  author={Moradian, Fatemeh and Azmi, Reza and Darvishi, Hosna and Khademhossein, Mobina},
  booktitle={2024 20th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP)}, 
  title={Text to fashion image synthesis Via CW-ControlGAN}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Text-to-image generation is called the method that translates human textual descriptions in the form of keywords or sentences into images with the same semantic content as text. The generated image in this field should match the meaning and content of the text and also have an acceptable quality. In the last few years, the use of Generative adversarial networks has made significant progress in increasing the visual realism, diversity, and semantic harmony of the generated images with their corresponding texts. Nevertheless, this research field is still facing many challenges. The research done is an attempt to develop a new architecture to compete with the state-of-the-art models. The research about text-to-image generation is done using two approaches: defining a loss function and then changing architecture. In the first approach, to extract more detailed features from the desired text and the generated image by the model, multi-mode transformer models that are trained on both the image and the text are used, and specifically, in this research, the text and image encoders of the CLIP model are used. The second approach deals with adding a wavelet loss function to the objective function to better train and improve the performance of the generator network in generating generated images. The obtained results show that a combination of two approaches produces good-quality images and better-attended text descriptions. The datasets used in this research are FashionGen and CUB Birds.},
  keywords={Wavelet transforms;Training;Visualization;Image edge detection;Semantics;Signal processing;Feature extraction;Text-to-Image Synthesis;Generative Adversarial Network;Transformer;Fashion AI;Wavelet transform;Deep Learning},
  doi={10.1109/AISP61396.2024.10475289},
  ISSN={2640-5768},
  month={Feb},}@INPROCEEDINGS{10490999,
  author={Liu, Jiajun and Wang, Siyuan and Zhu, Guangming and Zhang, Liang and Li, Ning and Gao, Eryang},
  booktitle={2023 International Conference on Sensing, Measurement & Data Analytics in the era of Artificial Intelligence (ICSMD)}, 
  title={Content-Conditioned Generation of Stylized Free-Hand Sketches}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={In recent years, the recognition of free-hand sketches has remained a popular task. However, in some special fields such as the military field, free-hand sketches are difficult to sample on a large scale. Common data augmentation and image generation techniques are difficult to produce images with various free-hand sketching styles. Therefore, the recognition and segmentation tasks in related fields are limited. In this paper, we propose a novel adversarial generative network that can accurately generate realistic free-hand sketches with various styles. We explore the performance of the model, including using styles randomly sampled from a prior normal distribution to generate images with various free-hand sketching styles, disentangling the painters' styles from known free-hand sketches to generate images with specific styles, and generating images of unknown classes that are not in the training set. We further demonstrate with qualitative and quantitative evaluations our advantages in visual quality, content accuracy, and style imitation on SketchIME.},
  keywords={Training;Visualization;Image segmentation;Image synthesis;Gaussian distribution;Data augmentation;Task analysis;Generative adversarial networks;Free-hand Sketches;style imitation},
  doi={10.1109/ICSMD60522.2023.10490999},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10900184,
  author={Liu, Zikang},
  booktitle={2024 4th International Conference on Artificial Intelligence, Robotics, and Communication (ICAIRC)}, 
  title={Enhancing Intrusion Detection with GANs for Class Balancing and Random Forest Classification}, 
  year={2024},
  volume={},
  number={},
  pages={148-153},
  abstract={This study explores how to improve prediction accuracy in network intrusion detection by addressing class imbalance issues. With the rapid development of the Internet, network security threats are increasingly complex, which puts forward higher requirements for traditional intrusion detection systems. This research presents an integration of Generative Adversarial Networks (GANs) with Random Forest Classifiers, and conducts a comparative analysis of the performance of various models, including XGBoost, LightGBM, and H2O AutoML. The findings validate the superiority of the Random Forest model in addressing imbalanced datasets, achieving a prediction accuracy of up to 87.14%, which is approximately 10% higher than that of other models. In addition, the feature importance analysis within the Random Forest model shows that features such as ‘Dst_Host_Srv_Count’ and ‘Srv-Count’ contribute the most in prediction, mainly reflecting anomalies in network traffic patterns and connection frequencies. The research provides a practical solution for the field of intrusion detection, which helps to improve the overall protection capability of network systems. By understanding the importance of key features, network security strategies can optimize resource allocation and implement more targeted monitoring, thereby improving the ability to respond to complex attacks.},
  keywords={Adaptation models;Accuracy;Telecommunication traffic;Network security;Predictive models;Real-time systems;Threat assessment;Resource management;Protection;Random forests;intrusion detection;Generative Adversarial Network;Random Forest;feature importance;machine learning},
  doi={10.1109/ICAIRC64177.2024.10900184},
  ISSN={},
  month={Dec},}@ARTICLE{10400463,
  author={Wang, Ziao and Ren, Yunpeng and Zhang, Xiaofeng and Wang, Yiyuan},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Generating Long Financial Report Using Conditional Variational Autoencoders With Knowledge Distillation}, 
  year={2024},
  volume={5},
  number={4},
  pages={1669-1680},
  abstract={Generating financial reports from a piece of news is a challenging task due to the lack of sufficient background knowledge to effectively generate long financial reports. To address this issue, this article proposes a conditional variational autoencoders (CVAEs)-based approach that distills external knowledge from a set of news–report data. Specifically, we design an encoder–decoder architecture to learn the latent variable distribution from this set of news–report data to provide background knowledge. Next, a teacher–student network is employed to distill knowledge to refine the output of the decoder component. To evaluate the model performance, extensive experiments have been performed on two public datasets using evaluation criteria like BLEU, ROUGE, METEOR, and human evaluation. Our promising experimental results demonstrate that our proposed approach outperforms existing state-of-the-art approaches.},
  keywords={Decoding;Task analysis;Biological system modeling;Generative adversarial networks;Knowledge engineering;Logic gates;Generators;Conditional variational autoencoder (CVAE);financial report generation;knowledge distillation (KD);natural language generation (NLG)},
  doi={10.1109/TAI.2024.3351594},
  ISSN={2691-4581},
  month={April},}@INPROCEEDINGS{10795952,
  author={Martiri, Luca and Meli, Giuseppe and Pasquarelli, Luca and Azzalini, Davide and Cristaldi, Loredana and Amigoni, Francesco},
  booktitle={2024 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)}, 
  title={Domain Adversarial Neural Networks for Remaining Useful Life Estimation of Lithium-Ion Batteries}, 
  year={2024},
  volume={},
  number={},
  pages={640-645},
  abstract={During the last few years, the number of devices powered by lithium-ion batteries has grown exponentially, and so has the number of accidents caused by this kind of batteries. Lithium-ion batteries can assume a completely different behavior from their peers based on usage, charging, and many other factors, leading to potential harm and other major issues depending on the importance and purpose of the specific device being powered. It stems from this the importance of being able to accurately predict the Remaining Useful Life (RUL) of such batteries, and most importantly creating a model that is capable of generalizing across different sets of batteries. This work introduces a Domain Adversarial Neural Network (DANN) architecture which, using the adversarial learning paradigm, aims to transfer the knowledge on a source dataset to a target dataset, reducing the shift between their features distribution. The DANN offers a distinct advantage over traditional transfer learning methods, as it does not rely on explicit labels from source or target domains, making it particularly valuable in scenarios with limited availability of labeled data. Additionally, its flexibility allows seamless integration into various neural architectures, such as the convolutional-LSTM neural network that we used in our work. For empirical evaluation we used the MIT-Toyota 2019 collaboration dataset, which is the largest lithium-ion battery dataset publicly available, showing the goodness of our method when compared to traditional transfer learning methods.},
  keywords={Lithium-ion batteries;Training;Accuracy;Transfer learning;Neural networks;Generative adversarial networks;Data augmentation;Data models;Unsupervised learning;Testing;prognostic;remaining useful life estimation;predictive maintenance;lithium-ion batteries;deep learning;transfer learning;domain adaptation},
  doi={10.1109/MetroXRAINE62247.2024.10795952},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10903689,
  author={Singh, Aditi and Shetty, Akash and Ehtesham, Abul and Kumar, Saket and Khoei, Tala Talaei},
  booktitle={2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC)}, 
  title={A Survey of Large Language Model-Based Generative AI for Text-to-SQL: Benchmarks, Applications, Use Cases, and Challenges}, 
  year={2025},
  volume={},
  number={},
  pages={00015-00021},
  abstract={Text-to-SQL systems facilitate smooth interaction with databases by translating natural language queries into Structured Query Language (SQL), bridging the gap between non-technical users and complex database management systems. This survey provides a comprehensive overview of the evolution of AI-driven text-to-SQL systems, highlighting their foundational components, advancements in large language model (LLM) architectures, and the critical role of datasets such as Spider, WikiSQL, and CoSQL in driving progress. We examine the applications of text-to-SQL in domains like healthcare, education, and finance, emphasizing their transformative potential for improving data accessibility. Additionally, we analyze persistent challenges, including domain generalization, query optimization, support for multi-turn conversational interactions, and the limited availability of datasets tailored for NoSQL databases and dynamic real-world scenarios. To address these challenges, we outline future research directions, such as extending text-to-SQL capabilities to support NoSQL databases, designing datasets for dynamic multi-turn interactions, and optimizing systems for real-world scalability and robustness. By surveying current advancements and identifying key gaps, this paper aims to guide the next generation of research and applications in LLM-based text-to-SQL systems.},
  keywords={Surveys;Structured Query Language;Translation;NoSQL databases;Scalability;Query processing;Medical services;Benchmark testing;Robustness;Next generation networking;LLM;text-to-SQL;natural language processing;artificial intelligence;Gen AI;benchmarks;data sets;schema linking;sql generation},
  doi={10.1109/CCWC62904.2025.10903689},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10137939,
  author={Zhang, Meng and Jiang, Ziyin and Zhao, Zhifang and Lv, Xin and Zhang, Lijin},
  booktitle={2022 6th Asian Conference on Artificial Intelligence Technology (ACAIT)}, 
  title={Spectrogram Generation for Music Game Based on Attention-BiLSTM}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={Music game has been popular among digital entertainment since 1960s, and it is significant for children’s musical interests and the inculcation of music. The most important part of music game, charts, however are rarely created by professional staff. In many music games, charts are created by players themselves, resulting in uneven quality. The tedious and labor-intensive production of charts, and the negative impact it can have on the game experience, make them an important and difficult aspect of music game. Most research on music games has conducted from a sociological or design perspective, and there is little on automatic spectrogram for music games. Moreover, BiLSTM neural network mode has achieved remarkable success in processing temporal problems such as speech recognition. Meanwhile, Attention excels in enabling models the ability to discriminate. In this paper, we proposed an automatic generation model combined Attention mechanism with BiLSTM neural network for music game.},
  keywords={Training;Neural networks;Music;Games;Speech recognition;Production;Generative adversarial networks;neural networks;BiLSTM;Attention mechanism;music game},
  doi={10.1109/ACAIT56212.2022.10137939},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10574605,
  author={Ramasubbu, Senthilnathan and Thangavel, Senthil Kumar and Jeyakumar, G},
  booktitle={2024 3rd International Conference on Artificial Intelligence For Internet of Things (AIIoT)}, 
  title={Cyber Chronicles: Tracking Behavior Patterns for Detecting Threats in Large Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={One of the primary challenges in cybersecurity is that even one un-detected, appropriately unanalyzed malicious security event can hide the attack vectors of a potential hacker. It is essential to detect the data breach at the earliest stage to reduce the impact on the business. The malicious actor’s activities will have higher visibility during the initial attacks to compromises or exploitation at the beginning of the attack cycle. After the initial compromise, the attacker studies the environment and establishes the persistence and covert channel communication. At this successive phase of the attack cycle, the attacker camouflages with the production data flow, access, and noises in the network and application logs. It is essential to detect the attacks during the reconnaissance and initial attacks and should not miss any malicious activities. Most of our security tools focus on reducing false positives; however, reducing false negatives is critical to cyber security. Hence, this paper is focused on suitable deep learning to reduce the False Negatives (FNs) with minimal Type II error to detect the attacks well in advance.},
  keywords={Deep learning;Generative AI;Noise;Production;Reconnaissance;Data breach;Vectors;Cyber Security Analysis;deep learning;Type II Error;Reducing False Negatives},
  doi={10.1109/AIIoT58432.2024.10574605},
  ISSN={},
  month={May},}@ARTICLE{11037746,
  author={Guo, Ruibin and Zhang, Weiting and Yang, Dong and Wang, Hongchao and Zhang, Hongke},
  journal={IEEE Network}, 
  title={6G Enabled Generative AI Services for Secure High-Speed Railway Networks}, 
  year={2025},
  volume={39},
  number={5},
  pages={105-113},
  abstract={Running trains at higher speeds is a crucial trend in railway development. For future ultra-high-speed scenarios, the sixth-generation mobile communication technology (6G) can provide reliable transmission and enable generative artificial intelligence (GAI) services for secure high-speed railway networks. In this paper, we propose a 6G-enabled GAI service architecture for railway networks to enhance train operation safety. This architecture leverages integrated air-ground-train transmission, uncrewed aerial vehicle (UAV), and distributed learning mechanisms to facilitate training and inference of GAI services. By analyzing the massive real-time data of critical equipment and areas with GAI techniques, early warnings and customized guidance for equipment breakdowns and natural disasters can be provided. Specifically, we propose integrating time-sensitive networking into 6G and jointly allocating time-spectrum resources in the air-ground-train integrated transmission to guarantee deterministic end-to-end latency in heterogeneous networks. Secondly, we develop a self-organization mechanism for a UAV cluster to perform various functions. The cluster comprises different types of UAVs and multiple intelligent algorithms are utilized during the self-organization process. Furthermore, a federated learning-based distributed training and inference framework for GAI services is studied, and several parallel computing techniques are proposed to reduce communication overhead. Simulation results demonstrate that learning-based resource allocation promotes the timeliness of model inference. Open research issues on further improving the performance of GAI services are also studied.},
  keywords={6G mobile communication;Training;Maintenance;Rail transportation;Autonomous aerial vehicles;Computer architecture;Sensors;Air to ground communication;Disasters;Servers},
  doi={10.1109/MNET.2025.3580618},
  ISSN={1558-156X},
  month={Sep.},}@INPROCEEDINGS{10873072,
  author={Cui, Haoyi and Li, Kexin and Deng, Yangwu and Wang, Wanguo and Deng, Hua and Wang, Zhenli and Zhang, Ke},
  booktitle={2024 International Seminar on Artificial Intelligence, Computer Technology and Control Engineering (ACTCE)}, 
  title={Enhancing Power Model Performance with Image Augmentation and Denoising Techniques}, 
  year={2024},
  volume={},
  number={},
  pages={424-429},
  abstract={High-quality power transmission business samples are crucial for training and optimizing power-related models. However, the current insufficient number of samples and the influence of various disturbing noises lead to significant differences in the quality of the samples, which triggers the problems of model underfitting, poor robustness and low recognition accuracy. To address the issue of insufficient sample quantity, this paper takes measures to expand the sample size before model training. By employing several common data augmentation methods and Poisson fusion techniques, the sample size has been successfully increased, facilitating better fusion of defect images with transmission line background images. This approach helps the model learn more comprehensively and enhances its generalization ability. Furthermore, to suppress noise in images, this paper has improved the DnCNN model for image denoising to enhance image quality. This step effectively reduces the interference of noise on model training and image analysis, improving the model’s ability to accurately capture image features. Experimental validation of these methods in this paper demonstrates their effectiveness in enhancing the model’s performance and stability. The combined application of these technical approaches is expected to provide more effective solutions for image processing and analysis in the electricity industry, thereby driving further development and innovation in the power sector.},
  keywords={Training;Image quality;Power transmission lines;Computational modeling;Noise;Noise reduction;Interference;Transmission line measurements;Data augmentation;Image denoising;Model Training;Data Augmentation;Image Denoising},
  doi={10.1109/ACTCE65085.2024.00092},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10852474,
  author={Nezafat, Mohammad Vatani and Samet, Saeed},
  booktitle={2024 2nd International Conference on Foundation and Large Language Models (FLLM)}, 
  title={Fake News Detection with Retrieval Augmented Generative Artificial Intelligence}, 
  year={2024},
  volume={},
  number={},
  pages={160-167},
  abstract={The rapid spread of false information on social media has grown to be a serious problem that influences public opinion and decision-making. Fake news spreads rapidly and extensively, often outpacing efforts to debunk or mitigate its effects. Traditional methods for detecting fake news face numerous challenges, including the necessity for extensive model training and the potential for inherent biases. Although Large Language Models (LLMs) have seen substantial improvements recently, their use in fake news detection poses the risk of producing false or misleading information due to their possible hallucinations. This study presents a new strategy to combat fake news by integrating Mixtral-8x7B, a Sparse Mixture of Experts (SMoE) Large Language Model, with a Retrieval-Augmented Generation (RAG) framework. Our framework employs Google’s search API to retrieve relevant articles in real time, harnessing Mixtral’s sophisticated language processing capabilities and RAG’s ability to access current information dynamically. Initial results are promising, indicating that our approach performs comparably to established fake news detection techniques. Our method operates without the need for extensive model training, offering significant cost savings and contributing to developing more efficient tools for detecting misinformation in the digital era, which will help stop the spread of misleading data more efficiently.},
  keywords={Training;Accuracy;Costs;Large language models;Retrieval augmented generation;Data models;Real-time systems;Reliability;Fake news;Testing;Fake News Detection;Sparse Mixture of Experts;Retrieval-Augmented Generation;Large Language Model},
  doi={10.1109/FLLM63129.2024.10852474},
  ISSN={},
  month={Nov},}@ARTICLE{9791853,
  author={Kurukuru, V. S. Bharath and Khan, Mohammed Ali and Sahoo, Subham},
  journal={IEEE Transactions on Power Electronics}, 
  title={Cybersecurity in Power Electronics Using Minimal Data – A Physics-Informed Spline Learning Approach}, 
  year={2022},
  volume={37},
  number={11},
  pages={12938-12943},
  abstract={Cyberattacks can be strategically counterfeited to replicate grid faults, thereby manipulating the protection system and leading to accidental disconnection of grid-tied converters. To prevent such setbacks, we propose a physics-informed spline learning approach-based anomaly diagnosis mechanism to distinguish between both events using minimal data for the first time in the realm of power electronics. This methodology not only provides compelling accuracy with limited data, but also reduces the training and computational resources significantly. We validate its effectiveness and accuracy under experimental conditions to conclude how data availability problem can be handled.},
  keywords={Splines (mathematics);Cyberattack;Voltage measurement;Mathematical models;Physics;Circuit faults;Current measurement;Anomaly diagnosis;artificial intelligence;cyberattacks;photovoltaic inverters},
  doi={10.1109/TPEL.2022.3180943},
  ISSN={1941-0107},
  month={Nov},}@INPROCEEDINGS{9464538,
  author={alsukhni, Batool},
  booktitle={2021 12th International Conference on Information and Communication Systems (ICICS)}, 
  title={Multi-Label Arabic Text Classification Based On Deep Learning}, 
  year={2021},
  volume={},
  number={},
  pages={475-477},
  abstract={Multi-label text classification is a natural extension of text classification in which each document can be assigned with a possible widespread set of labels. Natural Language Processing (NLP) helps to understand and manipulate text in natural language by using the computer. Arabic Text Classification is challenging recently because the Arabic language is under-resourced although it has many users. The aim of this paper is to build a model to classify Arabic news and help users get and display the most relevant news to their interests. In this paper, we demonstrate the efficiency of using deep learning models in solving Arabic multi-label text classification problem. Multilayer Perceptron (MLP) and Recurrent Neural Network (RNN) with Long Short-Term Memory (LSTM) have been used; we build two models via python. All data has been cleaned to improve the quality of experimental data. The result of test data in LSTM was 82.03 whereas in the MLP model was 80.37, and both models were evaluated using F1 score.},
  keywords={Deep learning;Recurrent neural networks;Text categorization;Multilayer perceptrons;Data models;Natural language processing;Labeling;Arabic Multilabel Text Classification;Deep Learning;Artificial Intelligence;Long Short-Term Memory;Multilayer Perceptron},
  doi={10.1109/ICICS52457.2021.9464538},
  ISSN={2573-3346},
  month={May},}@INPROCEEDINGS{9949775,
  author={Wang, Kangkang and Chen, Zhen and Wei, Wei and Sun, Xinwei and Mei, Shengwei and Xu, Yunyang and Zhu, Tong and Liu, Junyong},
  booktitle={2022 IEEE/IAS Industrial and Commercial Power System Asia (I&CPS Asia)}, 
  title={Power System Transient Stability Assessment Based on Deep Bayesian Active Learning}, 
  year={2022},
  volume={},
  number={},
  pages={1692-1696},
  abstract={This paper proposes a deep Bayesian active learning (DBAL)-based scheme for online transient stability assessment in power systems. The Bayesian neural network (BNN) is used to predict the transient stability status while adaptively evaluating the predicting confidence by the posterior probability. The uncertainty-based active learning strategy is used to select the most informative samples to maximize the predicting performance of the BNN-based transient stability predictor while reducing the computational burden of time-domain simulation-based stability assessment for sample labeling. Case study on the IEEE 39-bus system demonstrates that the proposed scheme can achieve both the predicting accuracy and the data efficiency.},
  keywords={Neural networks;Asia;Power system stability;Stability analysis;Bayes methods;Labeling;Transient analysis;transient stability assessment;deep Bayesian learning;active learning;artificial intelligence},
  doi={10.1109/ICPSAsia55496.2022.9949775},
  ISSN={},
  month={July},}@INPROCEEDINGS{9653398,
  author={Le, Huy and Nguyen, Minh and Yan, Wei Qi and Lo, Saide},
  booktitle={2021 36th International Conference on Image and Vision Computing New Zealand (IVCNZ)}, 
  title={Training a convolutional neural network for transportation sign detection using synthetic dataset}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={A sufficient amount of training data must be prepared when training a neural network for transportation signs, which requires extensive time and labour work to complete as it is usually done manually. This paper presents a real-time object detection neural network to predict the transportation signs in different environmental conditions and be sufficiently trained by a synthetic generated dataset. Our proposed method is based on the concept of domain randomisation, where a massive amount of images is generated by randomly orienting the transportation sign objects to a computer graphics rendered virtual scene. The trained model could achieve over 80% precision and over 90% recall and mAP against the real-world test dataset. Our proposed method showed that the generated synthetic dataset is adequate for predicting various transportation signs. Preparing and utilising the synthetic data can be an efficient solution to minimise the labour cost and human error during the manual data annotation step.},
  keywords={Training;Annotations;Computational modeling;Neural networks;Transportation;Graphics processing units;Training data;Artificial intelligence;YOLO;Synthetic dataset generation},
  doi={10.1109/IVCNZ54163.2021.9653398},
  ISSN={2151-2205},
  month={Dec},}@INPROCEEDINGS{10052277,
  author={Sui, Fanping and Yue, Wei and Zhang, Ziqi and Guo, Ruiqi and Lin, Liwei},
  booktitle={2023 IEEE 36th International Conference on Micro Electro Mechanical Systems (MEMS)}, 
  title={Trial-and-Error Learning for MEMS Structural Design Enabled by Deep Reinforcement Learning}, 
  year={2023},
  volume={},
  number={},
  pages={503-506},
  abstract={We present a systematic MEMS structural design approach via a "trial-and-error" learning process by using the deep reinforcement learning framework. This scheme incorporates the feedback from each "trial" to obtain sophisticated strategies for MEMS design optimizations. Disk-shaped MEMS resonators are selected as case studies and three remarkable advancements have been realized: 1) accurate overall performance predictions (97.9%) via supervised learning models; 2) efficient MEMS structural optimizations to guarantee targeted structural properties with an excellent generation accuracy of 97.7%; and 3) superior design explorations to achieve one order of magnitude performance enhancement than the training dataset. As such, the proposed scheme could facilitate a wide spectrum of MEMS applications with this data-driven inverse design methodology.},
  keywords={Micromechanical devices;Deep learning;Training;Systematics;Design methodology;Resonant frequency;Reinforcement learning;Artificial Intelligence;MEMS Design;Design Space Exploration;Deep Reinforcement Learning},
  doi={10.1109/MEMS49605.2023.10052277},
  ISSN={2160-1968},
  month={Jan},}@INPROCEEDINGS{8587694,
  author={Riazi, M. Sadegh and Koushanfar, Farinaz},
  booktitle={2018 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)}, 
  title={Privacy-Preserving Deep Learning and Inference}, 
  year={2018},
  volume={},
  number={},
  pages={1-4},
  abstract={We provide a systemization of knowledge of the recent progress made in addressing the crucial problem of deep learning on encrypted data. The problem is important due to the prevalence of deep learning models across various applications, and privacy concerns over the exposure of deep learning IP and user's data. Our focus is on provably secure methodologies that rely on cryptographic primitives and not trusted third parties/platforms. Computational intensity of the learning models, together with the complexity of realization of the cryptography algorithms hinder the practical implementation a challenge. We provide a summary of the state-of-the-art, comparison of the existing solutions, as well as future challenges and opportunities.},
  keywords={Cryptography;Data models;Protocols;Computational modeling;Training;Servers;Artificial Intelligence;Machine Learning;Deep Learning;Privacy;Security;Privacy-Preserving Deep Learning;Secure Function Evaluation;Homomorphic Encryption;Secret Sharing},
  doi={10.1145/3240765.3274560},
  ISSN={1558-2434},
  month={Nov},}@INPROCEEDINGS{10092221,
  author={Alam, Mohammad R. and Ward, Chris M.},
  booktitle={2022 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)}, 
  title={Adversarial Examples in Self-Driving: A Review of Available Datasets and Attacks}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Autonomous vehicles rely on computer vision models for perception, which have been shown to be vulnerable to adversarial attacks. These attacks pose various risks from reducing user confidence in the technology to directly influencing the technology to make a particular action [1]. Research in adversarial machine learning (ML) has led to increased awareness of ML’s vulnerabilities to such attacks and strategies to mitigate their effects and enhance ML generalizability [1]. Although there exists a dataset for assessing a computer vision model’s efficacy against adversarial attacks in the real-world [2], there is no such dataset for benchmarking computer vision algorithms for autonomous vehicles. This effort is a preliminary study on publicly available datasets for self-driving applications through the lens of adversarial ML. We include a discussion of attacks that have been performed in this space. From black-box to white-box attacks, the more knowledge is available to the adversary, the more they can leverage to employ the attack [1]. Adversaries are fully capable of utilizing the publicly available datasets to test their own black-box attacks [3], [4]. Adversarial examples can be useful in both enhancing algorithm resilience to these attacks through inclusion in training [5] as well as for use in benchmarking current approaches against the attacks [2]. Building resilient autonomy in transportation will require mitigation of any vulnerabilities, especially those from potential adversaries. This survey of datasets and attacks on self-driving vehicles is a first step in developing a dataset of adversarial attacks in this domain. The dataset can assist current and future computer vision research in self-driving to benchmark algorithm effectiveness against such attacks in the real-world.},
  keywords={Training;Computer vision;Computational modeling;Closed box;Transportation;Benchmark testing;Pattern recognition;Adversarial AI;Adversarial ML;Computer Vision;Autonomous Vehicles;Datasets;Artificial Intelligence;Machine Learning},
  doi={10.1109/AIPR57179.2022.10092221},
  ISSN={2332-5615},
  month={Oct},}@INPROCEEDINGS{9128376,
  author={Hamdan, Mutasem Q. and Hamdi, Khairi A.},
  booktitle={2020 IEEE 91st Vehicular Technology Conference (VTC2020-Spring)}, 
  title={Variational Auto-encoders application in wireless Vehicle-to-Everything communications}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={In this paper, a new technique called Embedded Variational Auto Encoder (EVAE) is proposed for Vehicle-to-Everything (V2X) up-link scenario. An innovative method has been proposed for the accurate prediction of the interference at the receiving end of each user which leads to the enhancement of the end-to-end performance of the V2X. The new algorithm infers noise and fading probabilistic models effect using decentralized Probabilistic Neural Networks (PNNs), while a second centralized PNN has been embedded inside the first group of the PNNs. This single PNN will be used to infer the interference effect on each V2X receiver. The performance of EVAE is compared with the recently proposed neural networks (NN) algorithms based on conventional auto-encoders (AE). Numerical and simulation results for the achievable symbol error rates (SER) have shown a significant improvement particularly in the high SINR regime, compared with the classical systems based on maximum likeli-hood detection.},
  keywords={Interference;Receivers;Wireless communication;Fading channels;Transmitters;Mathematical model;Vehicle-to-everything;Deep Learning;Variational Autoencoder;V2X;Interference prediction;Artificial Intelligence;Machine Learning;Wireless Communications},
  doi={10.1109/VTC2020-Spring48590.2020.9128376},
  ISSN={2577-2465},
  month={May},}@INPROCEEDINGS{9553104,
  author={Girard, L. and Roy, V. and Giguère, P. and Eude, T.},
  booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, 
  title={Deep Neural Network Training Using Synthetic Signatures for Rare Target Detection in SWIR Hyperspectral Imagery}, 
  year={2021},
  volume={},
  number={},
  pages={4420-4423},
  abstract={Deep learning techniques have enjoyed tremendous success in the vision community, where large labeled datasets are available for training. This has been problematic for hyperspectral target detection applications, as labeled hyperspectral datasets are scarce, particularly for detection applications involving rarely occurring targets. In this work, we present a deep neural network architecture for hyperspectral detection of rare targets and a technique to train such network based on synthetic signature modeling. Using the proposed approach, our network reaches an accuracy competitive with commonly-used statistical detectors, while improving computation time by over 90 % on a realistic target detection problem. Evaluation is conducted using a large dataset of over 600 airborne short-wave infrared (SWIR) hyperspectral images.},
  keywords={Deep learning;Training;Atmospheric measurements;Atmospheric modeling;Object detection;Detectors;Computer architecture;Hyperspectral target detection;Deep Learning;artificial intelligence},
  doi={10.1109/IGARSS47720.2021.9553104},
  ISSN={2153-7003},
  month={July},}@INPROCEEDINGS{10266277,
  author={Joshi, Sunita and Gupta, Neha and Mitali and Yadav, Gautam},
  booktitle={2023 3rd International Conference on Pervasive Computing and Social Networking (ICPCSN)}, 
  title={A Machine Learning Approached Model to Identify the Object for Visually Impaired Person}, 
  year={2023},
  volume={},
  number={},
  pages={599-604},
  abstract={According to the World Health Organization (WHO), 253 million individuals worldwide are visually impaired, including 36 million who are blind and 217 million who have moderate to severe vision impairment. The objective of this study is to demonstrate an improved approach through a real-time working model that is used for the prediction of objects around a visually impaired person. The proposed model is based on object detection which aids in several aspects of object prediction such as accident reduction and managing daily routines while protecting themselves from hazards or obstacles. The proposed model has an accuracy of 72%. More datasets will be embedded in the future to conduct large-scale object prediction with greater accuracy.},
  keywords={Social networking (online);Computational modeling;Visual impairment;Object detection;Predictive models;Hazards;Object recognition;Machine Learning;Raspberry pi;Object Detection;Visually Blind Person;Artificial Intelligence;Convolution Neural Network;Image Processing;Deep Learning;Ultrasonic Sensor},
  doi={10.1109/ICPCSN58827.2023.00105},
  ISSN={},
  month={June},}@INPROCEEDINGS{10704381,
  author={Xiao, Minheng and Bo, Shi and Wu, Zhizhong},
  booktitle={2024 6th International Conference on Data-driven Optimization of Complex Systems (DOCS)}, 
  title={Multiple Greedy Quasi-Newton Methods for Saddle Point Problems}, 
  year={2024},
  volume={},
  number={},
  pages={749-754},
  abstract={This paper introduces the Multiple Greedy Quasi-Newton (MGSR1-SP) method, a novel approach to solving strongly-convex-strongly-concave (SCSC) saddle point problems. Our method enhances the approximation of the squared indefinite Hessian matrix inherent in these problems, significantly improving both stability and efficiency through iterative greedy updates. We provide a thorough theoretical analysis of MGSR1-SP, demonstrating its linear-quadratic convergence rate. Numerical experiments conducted on AUC maximization and adversarial debiasing problems, compared with state-of-the-art algorithms, underscore our method's enhanced convergence rate. These results affirm the potential of MGSR1-SP to improve performance across a broad spectrum of machine learning applications where efficient and accurate Hessian approximations are crucial.},
  keywords={Machine learning algorithms;Accuracy;Estimation;Machine learning;Approximation algorithms;Stability analysis;Iterative algorithms;Optimization;Numerical stability;Convergence;artificial intelligence;saddle point problems;quasi-Newton methods;optimization},
  doi={10.1109/DOCS63458.2024.10704381},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10630082,
  author={A, Adediran Adeolu and Kayode, Ajewole Joshua B. and Ajisegiri, Emanuel},
  booktitle={2024 International Conference on Science, Engineering and Business for Driving Sustainable Development Goals (SEB4SDG)}, 
  title={Engineering Transformation: From Computer Aided Design to the Cloud}, 
  year={2024},
  volume={},
  number={},
  pages={1-16},
  abstract={This paper delves into the transformative impact of digital evolution on engineering, spotlighting data-driven practices and collaboration. Engineers utilize simulation software, IoT, and digital tools for efficient design processes, reduced time-to-market, and enhanced sustainability. The shift from traditional computer aided design (CAD) to cloud-based solutions is examined, emphasizing global accessibility and cost-effectiveness. It highlights the accelerated innovation cycle and the pivotal role of cloud-based CAD in fostering collaborative and efficient design. Traces CAD software evolution, integrating Cloud Computing, Generative Design, VR/AR, Simulation, and IoT for enhanced collaboration and efficiency. Virtual whiteboards facilitate real-time feedback. In the evolving engineering landscape, digital tools play a vital role, overcoming geographical constraints, with features like instant messaging, video conferencing, and efficient document management. CAD integration with cloud services revolutionizes design processes, incorporating machine learning, virtual reality, IoT, generative design, and simulation. Challenges in data storage and security require robust measures. General Electric (GE) strategically leverages cloud computing for growth, emphasizing operational efficiency, customer experience, and scalable solutions. Integration of AR, VR, and AI enhances digital transformation, with challenges in connectivity and security. Digital Engineering (DE) reshapes practices, focusing on data-driven ecosystems and fostering innovation. The surge in digital tools transforms collaborative engineering, enhancing workflows, efficiency, and teamwork. The CAD and CAM sectors witness a rising trend in adopting cloud-based Software-as-a-Service (SaaS). Organizations embracing digital transformation reap benefits, including improved security, collaboration, speed, innovation velocity, and accessibility. Despite a promising future, widespread adoption of online CAD faces challenges due to unreliable internet connectivity.},
  keywords={Cloud computing;Technological innovation;Design automation;Digital transformation;Software as a service;Transforms;Organizations;Computer aided design;Engineering;Internet of Things;Cloud computing},
  doi={10.1109/SEB4SDG60871.2024.10630082},
  ISSN={},
  month={April},}@INPROCEEDINGS{10727442,
  author={T, Anjali and Abhishek, S and S, Remya},
  booktitle={2023 International Conference on Intelligent Computing, Communication & Convergence (ICI3C)}, 
  title={Transformative AI in Skin Care: The Synergy of Transfer Learning and EfficientNetV2 B0}, 
  year={2023},
  volume={},
  number={},
  pages={525-530},
  abstract={Accurate skin mole categorization is essential for early skin cancer identification and treatment in dermatological diagnostics. This study uses the sophisticated transfer learning approach using the EfficientNet V2 B0 model, a convolutional neural network renowned for its effectiveness and high accuracy in image classification tasks, to provide a novel method of differentiating benign from malignant skin moles. The work’s primary contribution is optimizing the EfficientNet V2 B0 model for high accuracy in a medical setting by tailoring it to the unique characteristics of dermatological images. By incorporating unique layers and using specific training methodologies, we improved the transfer learning model’s capacity to identify minute characteristics that may indicate skin mole malignancy. After a thorough validation, the model showed an incredible 98.7% classification accuracy, outperforming the industry norms. This high degree of accuracy opens the door for more dependable, non-invasive skin cancer screening techniques as well as highlights the possibilities of using cutting-edge deep learning models in medical diagnostics. The results of this study might lessen the need for invasive biopsy procedures and provide prompt therapy, which would impact early identification and intervention tactics.},
  keywords={Industries;Training;Accuracy;Biological system modeling;Transfer learning;Medical treatment;Skin;Medical diagnosis;Convolutional neural networks;Skin cancer;Artificial Intelligence;Benign Moles;Convolutional Neural Networks;Deep Learning;Dermatology;EfficientNet V2 B0;Medical Image Analysis;Skin;Transfer Learning},
  doi={10.1109/ICI3C60830.2023.00105},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10532875,
  author={Alshebli, Shamma and Alshehhi, Muna and Yeun, Chan Yeob},
  booktitle={2024 2nd International Conference on Cyber Resilience (ICCR)}, 
  title={Investigating How Data Poising Attacks Can Impact An EEG-Based Federated Learning Model}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Detecting potential security threats from individuals within an organization can be achieved using an Electroencephalogram (EEG), which captures the brain's electrical activity. The concept is based on the premise that certain brainwave patterns might be associated with malicious intentions or deceptive behaviors. Recent research on insider threat detection has utilized traditional machine learning classifiers to recognize patterns in brainwave data that correlate with malicious intent. However, these methods pose privacy and data security concerns because they require access to all user data. A recently introduced framework, Federated Learning (FL), offers a solution to this problem. FL aims to develop a global model classifier without the need to access users' local data, thus safeguarding their privacy and sensitive information. Thus, we developed an FL-based insider threat detection model trained on a dataset that contains the EEG signals of 17 participants captured from five electrodes across five power bands using the Emotiv Insight. The model's accuracy within our framework attained a rate of (94.71%) for MLP. However, this method faces potential security threats and attacks, as clients could act maliciously, or external malicious actors might disrupt the network. Therefore, we additionally explore the data poisoning attacks, emphasizing label-flipping scenarios within our federated learning system for EEG-based insider threat detection and illustrating how factors such as the number of poisoned clients and the percentage of poisoning affect an FL-based system. Based on our findings, a higher number of poisoned clients is much more damaging to FL-based systems and should thus be a focal point of consideration in the security design process of these systems.},
  keywords={Adaptation models;Analytical models;Power measurement;Federated learning;Brain modeling;Data models;Threat assessment;artificial intelligence;machine learning;deep learning;logistic regression;single feed-forward network;multilayer perceptron;federated learning;data poisoning;label flipping;insider threat;EEG signals},
  doi={10.1109/ICCR61006.2024.10532875},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10725478,
  author={Juneja, Kanishka and N, Lalithamani},
  booktitle={2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Addressing the Challenge of Deepfake Media: Robust Detection for Ensuring Authenticity}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={As fake content gets more sophisticated, there’s a competition between making better fakes and better detectors. In an era where seeing is no longer believing, we must sharpen our commitment to authenticity in the face of technological deception. The study looks closely at how deepfake detection model works, including the different ways researchers have previously described and methods used to detect misleading videos and images that are spread very easily nowadays through various platforms. This research centers on a comparative analysis of prominent predefined models, namely CNN, VGG16, and Xception networks, in the realm of deepfake detection. Employing these models individually and by exploring different combinations of them, our methodology aims to unravel the distinctive strengths of each architecture. By evaluating their performance comprehensively, we seek to identify accuracy, precision and robustness of deepfake detection, making advancements in the ongoing process of safeguarding digital authenticity. By doing so, our research seeks to bridge the gap between theoretical model strengths and practical application, ensuring that the identified methods align with the demands of the digital world.},
  keywords={Training;Deep learning;Deepfakes;Accuracy;Detectors;Computer architecture;Predictive models;Prediction algorithms;Robustness;Faces;Deepfake;DFDC;artificial intelligence;Deep learning;Digital Forensics;Neural Networks},
  doi={10.1109/ICCCNT61001.2024.10725478},
  ISSN={2473-7674},
  month={June},}@INPROCEEDINGS{10435666,
  author={Zhang, Tianshuang and Zhao, Yanlin and Ma, Yunfeng},
  booktitle={2023 3rd International Conference on Communication Technology and Information Technology (ICCTIT)}, 
  title={Research on International UI Graphic Design Color Intelligent Matching System Based on Internet Communication Technology}, 
  year={2023},
  volume={},
  number={},
  pages={64-69},
  abstract={An automatic color matching system for industrial production is introduced. The architecture can be divided into three layers: data access layer, business logic layer and display layer. The system uses spectral color meter, central processing unit, storage device and virtual physical sensing game device. Use the feature color in the image as the weight for each node. The connection between two nodes is based on the number of occurrences on the same image. This paper proposes a color design support method based on color network. Through the analysis of different color combinations, the paper puts forward the color selection method which can embody the connotation of traditional culture to the greatest extent. This paper is an innovative UI graphic design color intelligent matching system that uses a computer algorithm to extract the main tone and auxiliary tone of the network model, and is verified. The experimental results show that the system has a certain deviation from the expected color matching, but this deviation is small, so the resulting color difference will not cause any impact on the user's visual performance.},
  keywords={Image color analysis;Feature extraction;Visual effects;Libraries;Communications technology;Software;Pattern matching;UI design;color matching;artificial intelligence;industrial modeling design},
  doi={10.1109/ICCTIT60726.2023.10435666},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10867582,
  author={Soko, Miroslav and Sokolová, Zuzana and Harahus, Maroš and Jurík, Patrik and Galajda, Pavol},
  booktitle={2024 IEEE Asia-Pacific Microwave Conference (APMC)}, 
  title={Frying Oil Quality Evaluation Using UWB Impedance Spectrometer and Machine Learning Techniques}, 
  year={2024},
  volume={},
  number={},
  pages={1018-1020},
  abstract={This paper aims to streamline and accelerate the quality evaluation of vegetable oil used in fryers. We attempt to train the algorithm using several machine learning methods on the data measured by an M-Sequence Ultra-wideband impedance spectrometer, which enables wideband sensing from almost DC to 6 GHz. Using the machine learning AutoEncoder method, we achieved the best results with an Mean Absolute Error value of around 0.25 compared to other methods.},
  keywords={Training;Vegetable oils;Autoencoders;Machine learning;Data models;Sensors;Impedance;Wideband;Ultra wideband technology;Synthetic data;—artificial intelligence;frying oil;M-Sequence UWB impedance spectrometer;machine learning},
  doi={10.1109/APMC60911.2024.10867582},
  ISSN={2690-3946},
  month={Nov},}@INPROCEEDINGS{9771814,
  author={Maesako, Keisuke and Zhang, Liang},
  booktitle={2022 IEEE Wireless Communications and Networking Conference (WCNC)}, 
  title={AVIS: An Innovative Image Preprocessing Method for Object Detection of Aerial Images}, 
  year={2022},
  volume={},
  number={},
  pages={920-925},
  abstract={Recently, discussions on aerial communication platforms using drones, balloons, and high altitude platform stations (HAPS) have become widespread in the communication industry. Besides providing several aerial wireless communication services, aerial images can be applied in many scenarios, such as object detection. Investigating existing object detection models in aerial image processing shows that they have lesser precision than the ground use case. Therefore, we propose the aerial video image segmentation method (AVIS) to substantially improve the detection precision. The segmentation method is expatiated and evaluated. Furthermore, an additive targeted area masking method (TAM) was proposed to suppress the computation load. Compared to existing methods, the evaluation results show that our proposed method greatly improves the aerial object detection precision.},
  keywords={Wireless communication;Image segmentation;Conferences;Superresolution;Communication industry;Object detection;Cameras;machine learning;artificial intelligence;object detection;image segmentation;aerial image;target area masking},
  doi={10.1109/WCNC51071.2022.9771814},
  ISSN={1558-2612},
  month={April},}@INPROCEEDINGS{10982885,
  author={Belaala, Abir and El Mouméne Zerari, Abd and Tahri, Aya and Belaala, Hana and Namane, Mariya},
  booktitle={2025 International Symposium on iNnovative Informatics of Biskra (ISNIB)}, 
  title={Exploring DeiT Transformers for Dermoscopic Image Classification: A Pilot Study}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Skin cancer is a significant public health concern, with millions of new cases diagnosed annually worldwide. Early and accurate diagnosis is crucial for effective treatment and improved patient outcomes. Convolutional neural networks have shown promising results in skin cancer classification, but their performance can be limited by the availability of large, high-quality datasets. In this work, we present a novel approach for skin cancer diagnosis using the Data-efficient Image Transformer (DIET) architecture, which has demonstrated state-of-the-art performance on various image classification tasks.. The DeiT architecture is distinguished by its ability to capture long-range dependencies and contextual information, rendering it particularly adept at addressing complex visual patterns prevalent in dermatology. Furthermore, the DeiT model is optimized for performance on small datasets and with limited computational resources, owing to its efficient training methodology and knowledge distillation framework. We evaluate the DeiT model on the ISIC2019 dataset, which encompasses various skin lesion types, including melanoma. Our findings reveal an overall accuracy of 85%, accompanied by high precision and recall rates. These results underscore the potential of the DeiT transformer in advancing diagnostic capabilities in skin cancer diagnosis.},
  keywords={Training;Visualization;Accuracy;Computational modeling;Transfer learning;Computer architecture;Transformers;Skin;Lesions;Image classification;Skin Cancer;Deep Learning;Vision Transformer;DeiT;Dermoscopic Images;Image Classification;Artificial Intelligence;ISIC2019 Dataset;Computer Aided Diagnosis},
  doi={10.1109/ISNIB64820.2025.10982885},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10718597,
  author={Prathibanandhi, J. and Annie Grace Vimala, G. S.},
  booktitle={2024 Third International Conference on Electrical, Electronics, Information and Communication Technologies (ICEEICT)}, 
  title={Diagnosis of Polycystic Ovary Syndrome Using Deep Learning Neural Network-based Segmentation Techniques}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Polycystic Ovary Syndrome (PCOS) is a widespread endocrine disorder affecting women of reproductive age, characterized by hormonal imbalances leading to symptoms like irregular menstrual cycles, excessive hair growth, and infertility. Early detection is crucial for effective management and prevention of associated health risks. Our study proposes a comprehensive approach to PCOS detection, utilizing preprocessing and segmentation techniques followed by Convolutional Neural Network (CNN) based classification. The preprocessing phase enhances image quality and features through flipping, rotation, zooming, and rescaling, standardizing inputs for analysis. Segmentation techniques isolate regions of interest, employing size-based filtering, contour detection, density analysis, color-based segmentation, edge detection, texture analysis, location-based segmentation, and watershed transformation to delineate structures effectively. Central to our methodology is CNN-based feature extraction and classification, achieving high accuracy in distinguishing PCOS-positive and PCOS-negative cases. Integrating diverse techniques enables effective preprocessing and segmentation, while CNNs automate feature extraction, enhancing model generalization. Our approach presents a promising strategy for accurate PCOS detection from medical images, aiding clinicians in early diagnosis and management, thereby improving patient outcomes and quality of care.},
  keywords={Image segmentation;Accuracy;Filtering;Prevention and mitigation;Neural networks;Watersheds;Medical services;Feature extraction;Reproducibility of results;Convolutional neural networks;PCOS Detection;Ultrasound Imaging;Deep Learning;Convolutional Neural Networks (CNN);Medical Image Analysis;Artificial Intelligence (AI);Data Augmentation},
  doi={10.1109/ICEEICT61591.2024.10718597},
  ISSN={},
  month={July},}@INPROCEEDINGS{10467600,
  author={Singh, Jasdeep and Oberoi, Ashish and Kumar, Yogesh},
  booktitle={2024 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)}, 
  title={Accurate Prediction of Bacterial Infections using Deep Learning-Based Approaches: A Recent Study and Progress}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Bacterial diseases cause a major threat to the health globally which necessitates to its accurate detection as well as diagnosis. There are various traditional methods like clinical assessments, laboratory techniques, microbiological tests etc which no doubt are effective but consumes a lot of time and relies completely on experienced professionals for validation. Hence, to address such challenges, deep learning models have been termed as game changers as they are capable of analysing the data rapidly, diagnosing the patient on time, and minimizing the human errors. This manuscript provides complete information related to the techniques which have been used for the detection and classification of bacterial diseases. It commences with a concise introduction to bacterial diseases and an exploration of conventional diagnostic methods. Subsequently, it delves into the transformative impact of deep learning models on disease detection and classification. The work of researchers in this domain is examined and compared by highlighting their limitations, which serve as the foundation for the proposed system. In essence, this manuscript offers a detailed examination of research papers that leverage such AI learning models for bacterial disease detection and classification, paving the way for more efficient and accurate healthcare practices.},
  keywords={Deep learning;Microorganisms;Neural networks;Medical services;Transforms;Games;Data models;Index: Bacterial infection;Artificial Intelligence;Deep Learning;CNN},
  doi={10.1109/IITCEE59897.2024.10467600},
  ISSN={},
  month={Jan},}
