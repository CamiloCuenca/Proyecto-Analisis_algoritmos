@ARTICLE{10906057,
  author={Gong, Xinrui and Liu, Xiaofeng and Lu, An-An and Gao, Xiqi and Xia, Xiang-Gen and Wang, Cheng-Xiang and You, Xiaohu},
  journal={IEEE Transactions on Wireless Communications}, 
  title={Digital Twin of Channel: Diffusion Model for Sensing-Assisted Statistical Channel State Information Generation}, 
  year={2025},
  volume={24},
  number={5},
  pages={3805-3821},
  abstract={With the advancement of communication technology and the improvement of localization accuracy, cellular networks are gradually evolving from communication to perception-integrated networks. Addressing the research challenges of sensing-assisted communication, we propose, for the first time, the concept of Digital Twin of Channel (DToC). Specifically, we regard user terminal (UT) positions as physical objects, and statistical channel state information (CSI) as virtual digital objects. Observing the change trend of UTs’ statistical CSI caused by the changes of UT’s physical position enables predictive analytics for subsequent communication tasks. Then, we establish the relationship between physical and virtual digital objects using a Diffusion Model (DM) to achieve the DToC. Indeed, the DM can generate the desired objects by gradually denoising from noisy data using neural networks. Furthermore, we propose a conditional DM utilizing UTs’ positions, which completes the task of generating the corresponding statistical CSI under known user-specific position conditions, thus mapping UT positions to statistical CSI. Simulation results demonstrate that our DToC framework outperforms previous statistical CSI estimation methods. Without the need of pilots, our method can simultaneously generate statistical CSIs from a large number of UTs’ positions, achieving satisfactory results.},
  keywords={Sensors;6G mobile communication;Digital twins;Artificial intelligence;Fingerprint recognition;Location awareness;Diffusion models;Noise;Accuracy;Training;Digital twin;integrated sensing and communication;deep generative model;diffusion model;statistical channel information generation},
  doi={10.1109/TWC.2025.3542429},
  ISSN={1558-2248},
  month={May},}@INPROCEEDINGS{10434123,
  author={M, Komal and Shrimal, Gajendra and Singh, Akhilendra Pratap and Jebaraj, Solomon and Dhingra, Lovish and R, Reena},
  booktitle={2023 International Conference on Emerging Research in Computational Science (ICERCS)}, 
  title={Developing Intelligent AI-Driven Systems for Automated Data Science}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={this article proposes the idea of applying smart synthetic intelligence (AI) structures to the automation of statistics technology. The AI structures are designed to study from records inputs to as it should be identify and procedure patterns, tendencies, and relationships within the statistics. Furthermore, those AI structures can be used to create computerized records technology fashions and practice them to datasets to be able to automate the records analysis procedure. The proposed AI gadget architecture is composed of numerous components, which might be accountable for extracting and extracting records, analyzing the statistics to decide styles and trends, and eventually, building models. The AI device structure contains superior strategies inclusive of deep gaining knowledge of, generative antagonistic networks, and reinforcement gaining knowledge of, so as to learn from a wide variety of records sources. Sooner or later, this newsletter discusses the capability advantages of the use of AI-pushed facts science automation and provides a few viable packages.},
  keywords={Knowledge engineering;Automation;Scientific computing;Computational modeling;Computer architecture;Data science;Market research;architecture;variety;reinforcement;extracting;numerous},
  doi={10.1109/ICERCS57948.2023.10434123},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10730236,
  author={Shivakumar, Aditya},
  booktitle={2024 IEEE International Conference on Artificial Intelligence in Engineering and Technology (IICAIET)}, 
  title={Tackling Marine Pollution with IoT and Conditioned Diffusion}, 
  year={2024},
  volume={},
  number={},
  pages={142-146},
  abstract={Marine litter, 85% of which is plastic, is projected to triple by 2040. Addressing this growing challenge, we utilize the surge of COVID-19 masks in waterways as a case study to develop an innovative framework for adaptive pollution modeling. We leverage two novel systems for marine debris monitoring and origin tracking. Firstly, PROMPTCUE is a novel generative AI pipeline that swiftly generates over 60,000 high-quality marine debris images, accommodating diverse conditions from underwater to aerial perspectives. Secondly, we introduce PiDAR, a Raspberry Pi-based computer-vision sensor that detects marine debris like surgical and N95 masks with high precision (mAP>0.99) in less than 40 milliseconds per image. PiDAR is cost-effective (under $100) and can be reconfigured for new debris types within hours using PROMPTCUE datasets, setting new standards in rapid, adaptable environmental monitoring.},
  keywords={Pollution;Generative AI;Marine pollution;Pipelines;Surgery;Real-time systems;Plastics;Environmental monitoring;Surges;Standards;Marine pollution;PiDAR;PROMPTCUE;IoT;YOLO;Computer Vision;Stable Diffusion;ControlNet},
  doi={10.1109/IICAIET62352.2024.10730236},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{11158539,
  author={Kim, Jinhee and Detrick, Rita and Lee, Sang-Soog and Li, Na},
  booktitle={2025 5th International Conference on Artificial Intelligence and Education (ICAIE)}, 
  title={GenAI in Online Collaborative Argumentation: Comparing Interaction Patterns between High and Low Performers}, 
  year={2025},
  volume={},
  number={},
  pages={393-397},
  abstract={Research is exploring how generative AI (GenAI) can support online collaborative argumentation (OCA), yet little is known about how student characteristics (e.g., domain knowledge) influence their interactions with GenAI and argumentation quality. Examining students-GenAI interactions (SAI) could aid in unpacking the underlying GenAI-empowered OCA mechanisms to open the black box of OCA processes to facilitate learning behavior. To this end, we collected chat histories of 60 graduate students and their final argumentative essays through a ChatGPT-powered OCA system on Discord. We employed epistemic network analysis to reveal SAI patterns during OCA. We conducted the Wilcoxon rank-sum (Mann-Whitney U) test to evaluate the OCA performance differences between different levels of domain knowledge. Findings revealed that high domain knowledge (HD) students engaged in more multifaceted OCA activities, demonstrating higher quality argumentation than low domain knowledge (LD) students. The HD group assessed GenAI's inputs more constructively, synthesizing human and AI contributions. Additionally, GenAI demonstrated a higher frequency of performing phases of OCA when interacting with HD students. Significant differences in argumentation quality across various evaluation criteria were confirmed. This study offers implications for improving the design and implementation of GenAI in OCA.},
  keywords={Generative AI;Federated learning;Education;Collaboration;Network analyzers;History;collaborative argumentation;GenAI for education;GenAI-assisted collaborative learning;students-AI interaction;interaction patterns;epistemic network analysis},
  doi={10.1109/ICAIE64856.2025.11158539},
  ISSN={},
  month={May},}@ARTICLE{8606936,
  author={Deng, Jia and Pang, Gaoyang and Zhang, Zhiyu and Pang, Zhibo and Yang, Huayong and Yang, Geng},
  journal={IEEE Access}, 
  title={cGAN Based Facial Expression Recognition for Human-Robot Interaction}, 
  year={2019},
  volume={7},
  number={},
  pages={9848-9859},
  abstract={As an emerging research topic for proximity service (ProSe), automatic emotion recognition enables the machines to understand the emotional changes of human beings which can not only facilitate natural, effective, seamless, and advanced human–robot interaction or human–computer interface but also promote emotional health. Facial expression recognition (FER) is a vital task for emotion recognition. However, significant gap between human and machine exists in FER task. In this paper, we present a conditional generative adversarial network-based approach to alleviate the intra-class variations by individually controlling the facial expressions and learning the generative and discriminative representations simultaneously. The proposed framework consists of a generator G and three discriminators (Di, Da, and Dexp). The generator G transforms any query face image into another prototypic facial expression image with other factors preserved. Armed with action units condition, the generator G pays more attention to information relevant to facial expression. Three loss functions ( $L_{I}$ , La, and Lexp) corresponding to the three discriminators (Di, Da, and Dexp) were designed to learn generative and discriminative representations. Moreover, after rendering the generated expression back to its original facial expression, cycle consistency loss is also applied to guarantee the identity and produce more constrained visual representations. Optimized by combining both synthesis and classification loss functions, the learnt representation is explicitly disentangled from other variations such as identity, head pose, and illumination. Qualitative and quantitative experimental results demonstrate the proposed FER system is effective for expression recognition.},
  keywords={Generators;Face;Feature extraction;Face recognition;Emotion recognition;Generative adversarial networks;Task analysis;Facial expression recognition;emotion recognition;conditional generative adversarial network;human-robot interaction},
  doi={10.1109/ACCESS.2019.2891668},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10346621,
  author={Routray, Sudhir K. and Javali, Abhishek and Sharmila, K P and Jha, Mahesh K. and Pappa, M. and Singh, Monika},
  booktitle={2023 International Conference on Computer Science and Emerging Technologies (CSET)}, 
  title={Large Language Models (LLMs): Hypes and Realities}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Artificial intelligence (AI) has created a lot of buzz in recent years. Using machine learning and other AI techniques several intelligent initiatives have been tested. The large language model is one of them. A large language model (LLM) normally refers to a type of AI model that is trained on vast amounts of text data to understand and generate human-like language outputs. These models are designed to capture the statistical patterns and structures present in the training data, enabling them to generate coherent and contextually relevant responses. The widely known ChatGPT is one of the LLMs which can do several tasks and answer many questions. It is trained with a huge number of data sets and a large number of parameters. In addition to ChatGPT, many other LLMs such as the Google Bard, Claude v1, Bison 001, Cohere, Falcon, and Guanaco-65B have surfaced in recent times. In this paper, we study the basic principles and features of LLMs. We go through their brief history, abilities, limitations, challenges and future prospects.},
  keywords={Computer science;Ethics;Training data;Machine learning;Chatbots;Data models;Internet;Artificial intelligence;large language model;generative AI;hypes of LLM;realities of LLM},
  doi={10.1109/CSET58993.2023.10346621},
  ISSN={},
  month={Oct},}@ARTICLE{9279318,
  author={Yoo, Byungin and Sylvain, Tristan and Bengio, Yoshua and Kim, Junmo},
  journal={IEEE Access}, 
  title={Joint Learning of Generative Translator and Classifier for Visually Similar Classes}, 
  year={2020},
  volume={8},
  number={},
  pages={219160-219173},
  abstract={In this paper, we propose a Generative Translation Classification Network (GTCN) for improving visual classification accuracy in settings where classes are visually similar and data is scarce. For this purpose, we propose joint learning from a scratch to train a classifier and a generative stochastic translation network end-to-end. The translation network is used to perform on-line data augmentation across classes, whereas previous works have mostly involved domain adaptation. To help the model further benefit from this data-augmentation, we introduce an adaptive fade-in loss and a quadruplet loss. We perform experiments on multiple datasets to demonstrate the proposed method's performance in varied settings. Of particular interest, training on 40% of the dataset is enough for our model to surpass the performance of baselines trained on the full dataset. When our architecture is trained on the full dataset, we achieve comparable performance with state-of-the-art methods despite using a light-weight architecture.},
  keywords={Training;Data models;Training data;Visualization;Adaptation models;Semisupervised learning;Faces;Artificial neural networks;feature extraction;image classification;image generation;pattern analysis;semisupervised learning},
  doi={10.1109/ACCESS.2020.3042302},
  ISSN={2169-3536},
  month={},}@ARTICLE{9260133,
  author={Manoni, Lorenzo and Turchetti, Claudio and Falaschetti, Laura},
  journal={IEEE Access}, 
  title={An Effective Manifold Learning Approach to Parametrize Data for Generative Modeling of Biosignals}, 
  year={2020},
  volume={8},
  number={},
  pages={207112-207133},
  abstract={Modeling data generated by physiological systems is a crucial step in many problems such as classification, signal reconstruction and data augmentation. However finding appropriate models from high-dimensional data sampled from biosignals is in general unpracticable due to the problem known as the “curse of dimensionality”. Dimensionality reduction, that is representing data in some lower-dimensional space, is the commonly adopted technique to handle these data. In this context manifold learning has drawn great interests as a promising nonlinear dimensionality reduction method. Neverthless the main drawback of methods based on manifold learning is that they learn data implicitly, that is with no explicit model of data belonging to the manifold. The aim of this article is to develop a manifold learning approach to parametrize data for generative modeling of biosignals, by deriving an explicit function that represents the local parametrization of the manifold. The approach involves two main stages, i) estimation of the intrinsic dimension of data, that is the dimension of the manifold, and ii) estimation of the function representing the local parametrization of the manifold. Experimental results both on synthetic and real-world data shown the effectiveness of the presented approach. The source code of the algorithm for unsupervised learning of data is available at https://codeocean.com/capsule/6692152/tree/v3.},
  keywords={Data models;Manifolds;Hidden Markov models;Biological system modeling;Time series analysis;Mathematical model;Heuristic algorithms;Biosignal generative modeling;intrinsic dimension;latent variables;manifold learning;nonlinear dynamical systems;regression},
  doi={10.1109/ACCESS.2020.3038314},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11074926,
  author={Loh, Kou-Hung Lawrence},
  booktitle={2025 Symposium on VLSI Technology and Circuits (VLSI Technology and Circuits)}, 
  title={Enabling Generative AI: Innovations and Challenges in Semiconductor Design Technologies}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={In recent years, Generative AI has transformed a wide range of domains, from everyday applications to cutting-edge scientific research. This rapid advancement has driven a substantial increase in the demand for computing, connectivity, communication, and memory/data storage across data centers, infrastructure, and edge devices. As a result, there has been a notable surge in industrial investment in “hard tech,” encompassing advanced materials, packaging, and semiconductor process technologies. These investments are aimed at developing next-generation hardware accelerators, both wired and wireless connectivity solutions, and heterogeneous integration at the chip and system levels, all underpinned by significant research and development efforts. In this paper, we will explore the latest technologies and address the challenges involved in creating high-performance computing and high-speed connectivity solutions, with a particular focus on energy efficiencies to enable Generative AI. We will also examine issues related to power distribution and other engineering complexities that arise in these advanced systems. Our discussion will highlight the critical role of technological challenges and innovations in ensuring the longterm sustainability and continued progress of these technologies in the decades ahead.},
  keywords={Wireless communication;Technological innovation;Data centers;Generative AI;Power distribution;Very large scale integration;Energy efficiency;Sustainable development;Voltage control;Investment},
  doi={10.23919/VLSITechnologyandCir65189.2025.11074926},
  ISSN={2158-9682},
  month={June},}@INPROCEEDINGS{11092472,
  author={Shin, JungKyoo and Kim, Bumsoo and Kim, Eunwoo},
  booktitle={2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Generative Modeling of Class Probability for Multi-Modal Representation Learning}, 
  year={2025},
  volume={},
  number={},
  pages={20737-20746},
  abstract={Multi-modal understanding plays a crucial role in artificial intelligence by enabling models to jointly interpret inputs from different modalities. However, conventional approaches such as contrastive learning often struggle with modality discrepancies, leading to potential misalignments. In this paper, we propose a novel class anchor alignment approach that leverages class probability distributions for multi-modal representation learning. Our method, Class-anchor-ALigned generative Modeling (CALM), encodes class anchors as prompts to generate and align class probability distributions for each modality, enabling more effective alignment. Furthermore, we introduce a cross-modal probabilistic variational autoencoder to model uncertainty in the alignment, enhancing the ability to capture deeper relationships between modalities and data variations. Extensive experiments on four benchmark datasets demonstrate that our approach significantly outperforms state-of-the-art methods, especially in out-of-domain evaluations. This highlights its superior generalization capabilities in multi-modal representation learning.},
  keywords={Representation learning;Uncertainty;Autoencoders;Semantics;Benchmark testing;Probabilistic logic;Probability distribution;Data models;Pattern recognition;Videos;multi-modal learning},
  doi={10.1109/CVPR52734.2025.01931},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{9874652,
  author={Guo, Hui and Hu, Shu and Wang, Xin and Chang, Ming-Ching and Lyu, Siwei},
  booktitle={2022 IEEE 5th International Conference on Multimedia Information Processing and Retrieval (MIPR)}, 
  title={Open-Eye: An Open Platform to Study Human Performance on Identifying AI-Synthesized Faces}, 
  year={2022},
  volume={},
  number={},
  pages={224-227},
  abstract={Al-synthesized faces are visually challenging to discern from real ones. They have been used as profile images for fake social media accounts, which leads to high negative social impacts. Although progress has been made in developing automatic methods to detect Al-synthesized faces. there is no open platform to study the human performance of Al-synthesized faces detection. In this work, we develop an online platform called Open-eye to study the human performance of Al-synthesized faces detection. We describe the design and workflow of the Open-eye in this paper.},
  keywords={Training;Social networking (online);Forensics;Information processing;Face detection;Artificial intelligence;Faces},
  doi={10.1109/MIPR54900.2022.00047},
  ISSN={2770-4319},
  month={Aug},}@INPROCEEDINGS{10371557,
  author={Zambrano, Olger and Senouci, Benaoumeur},
  booktitle={2023 49th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)}, 
  title={Image Classification Improvement: Text-to-Image AI for Synthetic Dataset Approach}, 
  year={2023},
  volume={},
  number={},
  pages={74-77},
  abstract={In this paper, we share our experience in using synthetic image generation through text-to-image AI models with the aim of improving the performance of image classifiers models.The procedure for generating high-quality synthetic images with text-to-image AI models is described, utilizing generic prompts based on proximity in hypernymys to generate 200 images of samples (lions, cats, and monkeys). Two image classifiers were built using the synthetic images alongside with classical image augmentation techniques. Each classifier was evaluated using three different datasets. Stable Diffusion 2.1 was employed as the image generator, and the results demonstrate that our proposed technique of generating synthetic images can indeed enhance image classifier accuracy. The results rely on the proficiency of the AI and the appropriateness of utilized prompts. We think our results can be improved by advances on the Latent Diffusion models.},
  keywords={Training;Productivity;Image synthesis;Refining;Image augmentation;Software;Artificial intelligence;Synthetic dataset;text-to-image AI models;image classifiers;image augmentation techniques},
  doi={10.1109/SEAA60479.2023.00020},
  ISSN={2376-9521},
  month={Sep.},}@INPROCEEDINGS{10663051,
  author={Mead, Nancy R.},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={AI and Software Engineering Education: Riding the Wave of Innovation}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={These days we hear a lot about AI, its rapid development, and the changes that might result. These concerns are not only in the field, but also overflow into the classroom. Generative AI applications are being introduced at all levels of education. Starting in elementary school, students learn to use generative AI applications, causing concern among parents who may be less familiar with such applications than the young students. As students continue their education, they can learn to use AI applications in various situations.},
  keywords={Knowledge engineering;Technological innovation;Generative AI;Education;Software engineering;software engineering education;artificial intelligence;AI;bodies of knowledge},
  doi={10.1109/CSEET62301.2024.10663051},
  ISSN={2377-570X},
  month={July},}@ARTICLE{9795891,
  author={Li, Wei and Chen, Jinlin and Cao, Jiannong and Ma, Chao and Wang, Jia and Cui, Xiaohui and Chen, Ping},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={EID-GAN: Generative Adversarial Nets for Extremely Imbalanced Data Augmentation}, 
  year={2023},
  volume={19},
  number={3},
  pages={3208-3218},
  abstract={Imbalanced data cause deep neural networks to output biased results, and it becomes more serious when facing extremely imbalanced data regarding the outliers with tiny size (the ratio of the outlier size to the image size is around 0.05%). Many data argumentation models are proposed to supplement imbalanced data to alleviate biased results. However, the existing augmentation models cannot synthesize tiny outliers, which make the generated data unavailable. In this article, we propose a new augmentation model named extremely imbalanced data augmentation generative adversarial nets (EID-GANs) to address the extremely imbalanced data augmentation problem. First, we design a new penalty function by subtracting the outliers from the cropped region of generated instance to guide the generator to learn the features of outliers. After this, we combine the output value of the penalty function with the generator loss to jointly update the generator’s parameters with backpropagation. Second, we propose a new evaluation approach that adopts two outlier detectors with k-fold cross-validation to assess the availability of generated instances. We conduct extensive experiments to demonstrate the significant performance improvement of EID-GAN on two extremely imbalanced datasets, which are the industrial Piston and the Fabric datasets, and one general imbalanced dataset, i.e., the public DAGM dataset. The experimental results show that our EID-GAN outperforms the state-of-the-art (SOTA) augmentation models on different imbalanced datasets.},
  keywords={Training;Generators;Detectors;Data models;Pistons;Fabrics;Prototypes;Extremely imbalanced data augmentation;generative adversarial net (GAN);generated data evaluation;norm penalty function},
  doi={10.1109/TII.2022.3182781},
  ISSN={1941-0050},
  month={March},}@ARTICLE{8760356,
  author={Blaiotta, Claudia},
  journal={IEEE Robotics and Automation Letters}, 
  title={Learning Generative Socially Aware Models of Pedestrian Motion}, 
  year={2019},
  volume={4},
  number={4},
  pages={3433-3440},
  abstract={Among the biggest challenges faced when integrating robots and intelligent vehicles in crowded environments is the difficulty encountered by artificial agents in anticipating people's moves, which is indeed a critical machine reasoning task in order to enable safe and comfortable interaction with humans. In general terms, this is a multi-agent prediction problem, whose solution, from a Bayesian perspective, involves on one hand inferring the joint latent dynamical state of all agents conditioned on observed data and on the other hand learning the corresponding system dynamics. Among the advantages of such a probabilistic approach is the fact that it naturally allows to account for the intrinsic stochasticity of both human behavior and sensor data in a principled manner. In this letter, we propose a novel Bayesian generative model, which generalizes a popular class of deterministic multiagent motion models and is capable of encoding traffic agents' interactions in a latent probabilistic space. We demonstrate, using real pedestrian data-sets, how it can be exploited for inference, prediction, and trained for learning of agent interaction dynamics. Our experimental evaluations indicate that the proposed approach outperforms both probabilistic latent variable models that neglect multi-agent interactions as well as deterministic physics-inspired models of human motion in crowds.},
  keywords={Vehicle dynamics;Mathematical model;Probabilistic logic;Predictive models;Bayes methods;Force;Dynamics;Social Human-Robot Interaction;Learning from Demonstration;Pedestrian Motion Prediction},
  doi={10.1109/LRA.2019.2928202},
  ISSN={2377-3766},
  month={Oct},}@ARTICLE{10234219,
  author={Wang, Tiancheng and Guo, Di and Sun, Xi-Ming},
  journal={IEEE Sensors Journal}, 
  title={Contrastive Generative Replay Method of Remaining Useful Life Prediction for Rolling Bearings}, 
  year={2023},
  volume={23},
  number={19},
  pages={23893-23902},
  abstract={Recent research has shown that deep learning algorithms used in prognostics of remaining useful life (RUL) have the potential to greatly benefit industrial automation. However, these algorithms are typically trained on a fixed situation that rarely occurs in engineering applications. When confronted with different working conditions, the model’s performance may unpredictably decrease. To address this issue, continual learning methods allow models to incorporate new knowledge after deployment. Despite being a relatively new field, current research on continual learning for RUL prediction relies on regularization-based methods, which do not perform well in noisy and diverse problems such as RUL prediction in bearings. Moreover, traditional memory-based methods for bearings RUL prediction are also ineffective. As a solution, this article proposes a contrastive generative replay (GR) method for continuous bearings RUL prediction. The proposed method utilizes contrastive learning when training GR models, allowing the model to better learn new and old data features and improve the effectiveness of continual learning. Additionally, the method is verified using the FEMTO-ST dataset and compared to state-of-the-art algorithms. Experimental results demonstrate the effectiveness of the proposed method in the task of continuous RUL prediction for bearings.},
  keywords={Data models;Task analysis;Predictive models;Sensors;Vibrations;Rolling bearings;Deep learning;Bearings;continual learning;deep learning;generative reply;remaining useful life (RUL)},
  doi={10.1109/JSEN.2023.3308092},
  ISSN={1558-1748},
  month={Oct},}@ARTICLE{10592048,
  author={Zhang, Yan and Zhang, Yiming and Dong, Hongli and Song, Liwei},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={STUGAN: An Integrated Swin Transformer-Based Generative Adversarial Networks for Seismic Data Reconstruction and Denoising}, 
  year={2024},
  volume={62},
  number={},
  pages={1-15},
  abstract={The collection process of seismic data is often affected by terrain conditions and human factors, resulting in spatial gaps, undersampling, and random noise in the collected seismic trace set, which hampers the subsequent seismic data processing and interpretation. Existing seismic data reconstruction and denoising algorithms based on deep learning mostly use local similarity learning to obtain the distribution of missing traces or noisy data and lack nonlocal similarity feature mining, which cannot effectively extract effective features of seismic data under the mixed interference of several missing traces and strong noise. This poses challenges to simultaneous reconstruction and denoising tasks. This study introduces swin transformer (ST) into seismic data processing. Combined with the generative adversarial network (GAN) structure, a new simultaneous reconstruction and denoising model, ST-united GAN (STUGAN), is proposed. First, an ST module is used to replace the traditional convolution module in GAN, and its self-attention mechanism captures the correlation between local and nonlocal seismic data features to improve the model feature extraction ability. Second, the generator is constructed based on U-Net, and the event features and texture information features of seismic data are extracted. Conditional constraints are incorporated into the discriminator to guide the gradient optimization direction of the generator. Finally, through synthetic and real data experiments, we demonstrate that STUGAN has a good recovery effect and is robust to missing seismic data in large gaps and strong noise interference.},
  keywords={Feature extraction;Noise reduction;Image reconstruction;Data models;Correlation;Noise;Generators;Deep learning;generative adversarial network (GAN);integrated method of reconstruction and denoising;seismic data processing;swin transformer (ST)},
  doi={10.1109/TGRS.2024.3424502},
  ISSN={1558-0644},
  month={},}@ARTICLE{10937153,
  author={Noori Zadeh, Danial and Elamien, Mohamed B.},
  journal={IEEE Access}, 
  title={Generative AI for Analog Integrated Circuit Design: Methodologies and Applications}, 
  year={2025},
  volume={13},
  number={},
  pages={58043-58059},
  abstract={Electronic Design Automation (EDA) in analog Integrated Circuits (ICs) has been the focus of extensive research; however, unlike its digital counterpart, it has not achieved widespread adoption. In this systematic review, we discuss recent contributions in the last five years, highlighting methods that address data scarcity, topology exploration, process-voltage-temperature (PVT) variations, and layout parasitics. Our goal is to support researchers new to this domain by creating a comprehensive collection of references and practical application guidelines. We provide a methodological review of state-of-the-art machine learning (ML) approaches, including graph neural networks (GNNs), large language models (LLMs), and variational autoencoders (VAEs), which have been successfully applied to analog circuit sizing tasks. To the best of authors’ knowledge, this is the first review to comprehensively explore the application of generative AI models in analog IC circuit design. We conclude that future research could focus on few-shot learning with domain-adaptation training of generative AI methods to simplify the design tasks such as human-tool interaction or guided design space exploration.},
  keywords={Integrated circuit modeling;Automation;Reviews;Layout;Topology;Computational modeling;Data models;Generative AI;Voltage;Training;Analog integrated circuits (ICs);electronic design automation (EDA);layout-aware sizing;machine learning (ML);large language models (LLM);graph neural networks (GNN);variational auto-encoders (VAE);artificial intelligence (AI);machine learning (ML)},
  doi={10.1109/ACCESS.2025.3553743},
  ISSN={2169-3536},
  month={},}@ARTICLE{10224070,
  author={Yao, Jinliang and Zheng, Haonan},
  journal={IEEE Access}, 
  title={LC-VTON: Length Controllable Virtual Try-on Network}, 
  year={2023},
  volume={11},
  number={},
  pages={88451-88461},
  abstract={Image-based virtual try-on provides customers with convenient online clothes selections by transferring garments onto a reference person. Despite the emergence of several solutions to generate photo-realistic images and adapt to complex poses, controlling clothing length remains a challenge. We argue that the clothing reconstruction did not consider clothing length information, which results in clothing length being uncontrollable in most virtual try-on methods. To overcome this limitation, a novel clothing-agnostic person representation is proposed, which eliminates clothing information and quantifies clothing length as a numerical value. A new segmentation generator is designed to predict try-on segmentation maps of any length conditioned on this representation. Moreover, we correct two inaccurate labels, which enables our model to utilize clothing length control to generate a wider range of garment interactions in images, such as the top tucked into or worn over the bottom, as well as the top and bottom worn separately without intersecting. Extensive experiments demonstrate that our method achieves the goal of continuous clothing length control and generates photo-realistic images with fine details that outperform most baseline methods in terms of quantitative and qualitative metrics.},
  keywords={Clothing;Image segmentation;Image reconstruction;Task analysis;Semantics;Solid modeling;Generators;Virtual reality;Semantic segmentation;Clothing industry;Generative adversarial networks;Virtual try-on;clothing length controllable;conditional semantic generation;generative adversarial network},
  doi={10.1109/ACCESS.2023.3306449},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10650634,
  author={Xue, Junsheng and Huang, Hai and Zhou, Zhong and Xu, Shibiao and Chen, Aoran},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={LRGAN: Learnable Weighted Recurrent Generative Adversarial Network for End-to-End Shadow Generation}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={In augmented reality(AR) applications, it is a challenging task to generate virtual object shadows while maintaining the precision and consistency of virtual and real areas. To achieve the above target, we propose a learnable weighted recurrent generative adversarial network(LRGAN) for end-to-end shadow generation. Without any additional computational overhead, LRGAN only needs to analyze the background context to create a bridge between the target shadows and the background. Our model incorporates multiple progressive steps to recurrently compute the precise reference masks, based on which a fine-grained shadow generation module generates the shadows. A learnable weighted fusion module, which can normalize pixel values to deal with pixel overflow, fuses the generated shadows with the original image. In addition, we adopt the combined method of module training and the whole model training. Experimental results show that our proposed LRGAN not only improves the plausibility of shadow location and shape but also achieves color harmony in the shadow areas. In the absence of other prior knowledge or post-processing, it outperforms the State-of-the-Art end-to-end methods.},
  keywords={Training;Bridges;Shape;Image color analysis;Fuses;Computational modeling;Neural networks;virtual shadow generation;augmented reality;generative adversarial network;weighted fusion;recurrent structure},
  doi={10.1109/IJCNN60899.2024.10650634},
  ISSN={2161-4407},
  month={June},}@INPROCEEDINGS{10645560,
  author={Poglitsch, Christian and Pirker, Johanna},
  booktitle={2024 IEEE Conference on Games (CoG)}, 
  title={A Qualitative Investigation to Design Empathetic Agents as Conversation Partners for People with Autism Spectrum Disorder}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Autism Spectrum Disorder (ASD) can profoundly affect reciprocal social communication, resulting in substantial and challenging impairments. One aspect is that for people with ASD conversations in everyday life are challenging due to difficulties in understanding social cues, interpreting emotions, and maintaining social verbal exchanges. To address these challenges and enhance social skills, we propose the development of a learning game centered around social interaction and conversation, featuring Artificial Intelligence agents. Our initial step involves seven expert interviews to gain insight into the requirements for empathetic and conversational agents in the field of improving social skills for people with ASD in a gamified environment. We have identified two distinct use cases: (1) Conversation partners to discuss real-life issues and (2) Training partners to experience various scenarios to improve social skills. In the latter case, users will receive quests for interacting with the agent. Additionally, the agent can assign quests to the user, prompting specific conversations in real life and providing rewards for successful completion of quests.},
  keywords={Training;Autism;Emotion recognition;Oral communication;Games;Learning (artificial intelligence);Interviews;Autism Spectrum Disorder;Game;Gamification;Generative Agents;Learning;Social Skills;Empathy},
  doi={10.1109/CoG60054.2024.10645560},
  ISSN={2325-4289},
  month={Aug},}@INPROCEEDINGS{10823498,
  author={Kim, Bo Min and Park, Ga Eun and Park, Si Eun and Bae, Seong Geon},
  booktitle={2024 International Conference on Electrical, Communication and Computer Engineering (ICECCE)}, 
  title={A Study on the three-dimensional Augmented GAN Algorithm through Object Separation}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Computer vision has been rapidly growing alongside the advancements in artificial intelligence, with particular attention on Generative Adversarial Networks (GANs). Among these, CartoonGAN is a model that transforms real photos into cartoon-style images. This model has a limitation in that the simplification of colors during the process of converting real photos into a cartoon style reduces the sense of depth. To address this issue, this study proposes an algorithm that enhances depth perception by clearly separating elements within the image to expand the sense of distance. Additionally, the algorithm strengthens depth perception by applying shading adjustments and a vignette mask. This approach allows for the creation of vivid and three-dimensional cartoon images by applying 3D information to otherwise flat images. Furthermore, it preserves the edges of objects to maximize the visual experience. Future research will aim to increase the applicability of the proposed algorithm to images with various conditions.},
  keywords={Measurement;Visualization;Computer vision;Three-dimensional displays;Image color analysis;Generative AI;Computational modeling;Image edge detection;Transforms;Generative adversarial networks;CartoonGAN;Depth Estimation;Shading;Vignetting Mask;Three-Dimensionality},
  doi={10.1109/ICECCE63537.2024.10823498},
  ISSN={},
  month={Oct},}@INBOOK{10790446,
  author={Shaik, Nazeer and Sekaran, Chandra and Mahajan, Amit and Singh, Balkeshwar},
  booktitle={Toward Artificial General Intelligence: Deep Learning, Neural Networks, Generative AI}, 
  title={5 Reinforcement learning}, 
  year={2024},
  volume={},
  number={},
  pages={109-124},
  abstract={The field of reinforcement learning (RL) is introduced in this chapter, which also looks at several RL techniques. The main goal of RL is to provide algorithms that let agents discover the best policies through interactions with their surroundings while maximizing cumulative rewards. In the first part of the chapter, Markov decision processes (MDPs), which provide a mathematical foundation for modeling RL problems, are discussed. We look at value iteration and policy iteration as iterative approaches to addressing MDPs. To help you find the ideal action-value function, we present Q-Learning, an off-policy model-free RL algorithm. Deep Q-networks (DQNs), which combine Q-learning with deep neural networks, are also addressed in order to handle high-dimensional state spaces. Policy gradient methods are presented as an alternative approach that directly optimizes policy parameters using gradient ascent. Proximal policy optimization (PPO), a leading policy gradient algorithm, is discussed for its ability to balance stability and policy performance. The chapter concludes by emphasizing the significance of RL methods in training agents to make sequential decisions in complex environments across various domains.},
  keywords={Convergence;Mathematical models;Training;Stability analysis;Q-learning;Optimization;Heuristic algorithms;Estimation;Decision making;Artificial neural networks},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9783111324166},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10790446},}@ARTICLE{9645324,
  author={Spinelli, Indro and Scardapane, Simone and Hussain, Amir and Uncini, Aurelio},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={FairDrop: Biased Edge Dropout for Enhancing Fairness in Graph Representation Learning}, 
  year={2022},
  volume={3},
  number={3},
  pages={344-354},
  abstract={Graph representation learning has become a ubiquitous component in many scenarios, ranging from social network analysis to energy forecasting in smart grids. In several applications, ensuring the fairness of the node (or graph) representations with respect to some protected attributes is crucial for their correct deployment. Yet, fairness in graph deep learning remains underexplored, with few solutions available. In particular, the tendency of similar nodes to cluster on several real-world graphs (i.e., homophily) can dramatically worsen the fairness of these procedures. In this article, we propose a novel biased edge dropout algorithm (FairDrop) to counter-act homophily and improve fairness in graph representation learning. FairDrop can be plugged in easily on many existing algorithms, is efficient, adaptable, and can be combined with other fairness-inducing solutions. After describing the general algorithm, we demonstrate its application on two benchmark tasks, specifically, as a random walk model for producing node embeddings, and to a graph convolutional network for link prediction. We prove that the proposed algorithm can successfully improve the fairness of all models with only a small or negligible drop in accuracy, and compares favourably with existing state-of-the-art solutions. In an ablation study, we demonstrate that our algorithm can flexibly interpolate between biasing towards fairness and an unbiased edge dropout. Furthermore, to better evaluate the gains, we propose a new dyadic group definition to measure the bias of a link prediction task when paired with group-based fairness metrics. In particular, we extend the metric used to measure the bias in node embeddings by taking account of the graph structure.},
  keywords={Task analysis;Measurement;Artificial intelligence;Representation learning;Social networking (online);Prediction algorithms;Topology;Fairness;graph embedding;graph neural network;graph representation learning;link prediction},
  doi={10.1109/TAI.2021.3133818},
  ISSN={2691-4581},
  month={June},}@INPROCEEDINGS{9808794,
  author={Zemouri, Ryad and Lévesque, Mélanie and Boucher, Étienne and Kirouac, Mathieu and Lafleur, François and Bernier, Simon and Merkhouf, Arezki},
  booktitle={2022 Prognostics and Health Management Conference (PHM-2022 London)}, 
  title={Recent Research and Applications in Variational Autoencoders for Industrial Prognosis and Health Management: A Survey}, 
  year={2022},
  volume={},
  number={},
  pages={193-203},
  abstract={Whether in the industrial, medical, or real-world domains, more and more data are being collected. The common particularity of all these application domains is that a great part of this data is mostly unlabeled. Thus, designing a learning model with a minimum of labeled data represents a major challenge in the coming years. A particular emphasis has recently been put on unsupervised learning methods based on the idea of autoencoding. The objective of these methods is twofold: to reduce the dimensionality of the input space and to reconstruct the original observation from this lower dimensional representation space. The variational form of these autoencoders, called the Variational Autoencoders (VAEs), is particularly successful in almost all application areas. This enthusiasm comes from the fact that VAEs allow to take advantage of the theoretical foundations of the Variational Bayesian methods and the learning capabilities of artificial neural networks. This review paper gives to the PHM community a synthesis of the latest publications in the PHM domain using the VAEs related to four topics: 1) Data-Driven Soft Sensors for missing values and data outliers, 2) reconstruction error for fault detection, 3) resampling approach for imbalanced data generation and minority class and 4) the variational embedding as PHM preprocessing pipelines and data transformations. After a review of the theoretical foundations and some practical tricks to succeed the implementation of the VAEs in industrial applications, the four main topics used to exploit the VAEs in the PHM domain are detailed. Finally, a global view of the research done at the research institute of Hydro-Québec regarding the diagnosis and failure detection of hydro-generators with VAEs are presented.},
  keywords={Soft sensors;Fault detection;Pipelines;Learning (artificial intelligence);Artificial neural networks;Data models;Bayes methods;Variational Autoencoders;Deep learning;Prognosis and Health Management},
  doi={10.1109/PHM2022-London52454.2022.00042},
  ISSN={2166-5656},
  month={May},}@ARTICLE{9522031,
  author={Li, Xiang and Jiang, Yuchen and Liu, Chenglin and Liu, Shaochong and Luo, Hao and Yin, Shen},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Playing Against Deep-Neural-Network-Based Object Detectors: A Novel Bidirectional Adversarial Attack Approach}, 
  year={2022},
  volume={3},
  number={1},
  pages={20-28},
  abstract={In the fields of deep learning and computer vision, the security of object detection models has received extensive attention. Revealing the security vulnerabilities resulting from adversarial attacks has become one of the most important research directions. Existing studies show that object detection models can also be threatened by adversarial examples, just like other deep-neural-network-based models, e.g., those for classification. In this article, we propose a bidirectional adversarial attack method. First, the added perturbation pushes the prediction results given by the object detectors far away from the ground-truth class while getting close to the background class. Second, a confidence loss function is designed for the region proposal network to reduce the foreground scores. Third, the adversarial examples are generated by a pretrained autoencoder, and the model is trained using an adversarial approach, which can enhance the similarity between the adversarial examples and the original image and speed up algorithm convergence. The proposed method was verified on the most popular two-stage detection framework (Faster R-CNN), and 55.1% drop in the mean average precision (mAP-drop) was obtained. In addition, the adversarial examples have superior transferability, migrating which to the common one-stage detection framework (YOLOv3) gets a 39.5% mAP-drop.},
  keywords={Perturbation methods;Object detection;Proposals;Generators;Task analysis;Deep learning;Artificial intelligence;Adversarial attack;deep neural network (DNN);object detection},
  doi={10.1109/TAI.2021.3107807},
  ISSN={2691-4581},
  month={Feb},}@ARTICLE{9500215,
  author={Mateja, Deborah and Heinzl, Armin},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Towards Machine Learning as an Enabler of Computational Creativity}, 
  year={2021},
  volume={2},
  number={6},
  pages={460-475},
  abstract={Computational creativity composes a collection of activities that are capable of achieving or simulating behaviors, which can be deemed creative. A frequently articulated criticism for related systems is that the creative capability yet remains with the software designer rather than the computational creative system itself. The rise of machine learning (ML) enables new ways of combining, exploring, and transforming conceptual spaces to achieve creative results. This article demonstrates that the learning occurring within the computational machine through ML enables creative capabilities therein, allowing the computational creative system to be more creative on its own than ever before. Thus, we perceive ML as a key enabler of computational creativity. In this article, we consolidate research from the computer science, computational creativity, and information systems communities, which has been treated separately so far. We build on a framework of human creativity to examine the relationship between creative capabilities and ML mechanisms in ML-based computational creative systems. Specifically, we explicate, which creative capabilities are already established through ML mechanisms in computational creative systems as strengths. Furthermore, we explicate challenges pointing towards further potential of ML-based computational creative systems to enhance the inherent creative capabilities. Our results reveal that ML-based computational creative systems advance the previously static and explicit principles of non-ML-based computational creative systems, yielding creative capabilities on the machine's own, which yet have been in the realm of human actors. Impact Statement—Creativity is a core organizational skill as it enables innovation. With markets becoming increasingly volatile, constant innovation is essential for organizations to create and sustain their economic competitive advantage. Due to the undisputable relevance of creativity for individuals, organizations, and societies, artificial intelligence research has set out to enable creative behavior in computational systems. Especially, ML methods lately became a highly frequented means within computational creative systems. However, while oftentimes applied, ML is seldomly explicitly assessed for its potential to facilitate computational creativity. In this article, we analyze extant computational creative systems relying on ML. The findings serve as a guidance for the design of these systems in various contexts and as pointers for future research to advance the creative capabilities of such systems.},
  keywords={Creativity;Artificial intelligence;Machine learning;Technological innovation;Autonomous agents;Task analysis;Computational modeling;Autonomous agents;computational creativity;machine learning (ML)},
  doi={10.1109/TAI.2021.3100456},
  ISSN={2691-4581},
  month={Dec},}@ARTICLE{11037440,
  author={Kim, Junho and Kim, Eunwoo and Lee, Kyungjae},
  journal={IEEE Access}, 
  title={GODiff: Region-Specific Semantic Editing With CLIP-Guided Diffusion Models}, 
  year={2025},
  volume={13},
  number={},
  pages={112818-112834},
  abstract={Text-based image editing enables intuitive and flexible content creation, but existing methods often suffer from issues such as the loss of original image characteristics within the target area or unintended modifications in irrelevant regions. Additionally, high-quality results often require additional training or fine-tuning, which can cause considerable inconvenience in practical use. To address these limitations, we propose GODiff, a method that offers a more convenient and user-friendly editing experience. It allows immediate and precise modifications of a single image based on dynamically changing text prompts and can be flexibly applied to various diffusion models without additional training. In particular, the editing region is automatically identified, and text-based guidance is focused solely on that area, thereby improving efficiency and minimizing unnecessary changes. Furthermore, by optimizing the guidance in real-time during the generative process, GODiff more accurately reflects the intent of the text prompt and produces more natural and consistent results. It has demonstrated consistent performance across diverse datasets and model architectures, and a human evaluation confirmed that it provides superior editing quality in terms of naturalness and user preference compared to existing methods.},
  keywords={Semantics;Diffusion models;Noise;Training;Real-time systems;Mathematical models;Adaptation models;Accuracy;Visualization;Image quality;Diffusion models;image editing;CLIP-based image manipulation},
  doi={10.1109/ACCESS.2025.3580263},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10837854,
  author={Kumar, Manoj and S, Darshan and Harshavardhan, Sai and Kodipalli, Ashwini and Rao, Trupthi},
  booktitle={2024 4th Asian Conference on Innovation in Technology (ASIANCON)}, 
  title={Enhancing Malware Detection Accuracy: A Comparative Analysis of Machine Learning Models with Explainable AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={The challenge of detecting malware in cybersecurity necessitates the exploration of diverse machine learning models for effective solutions. In this investigation, we assess the performance of several models, including Support Vector Machines (SVM), K-Nearest Neighbors (KNN), Logistic Regression, Decision Trees, Random Forests, Randomized Search CV, Grid Search CV, CatBoost, ADA Boost, XGBoost, and Gradient Boosting, using a comprehensive dataset. Our study reveals that CatBoost emerges as the most effective model, achieving an exceptional 99% accuracy in malware prediction. Furthermore, we utilize Lime and Shap explainability techniques to delve into the decision-making process of CatBoost, shedding light on its predictive mechanisms and enhancing transparency in malware detection. By emphasizing the importance of diverse machine learning models and the significance of explainable AI techniques in cybersecurity, our research contributes to the advancement of malware detection methodologies. It underscores the critical role of transparent and interpretable AI systems in fostering trustworthiness and effectiveness in cybersecurity applications.},
  keywords={Support vector machines;Accuracy;Explainable AI;Decision making;Nearest neighbor methods;Feature extraction;Boosting;Malware;Vectors;Computer security;Malware detection;Cybersecurity;Machine learning;Explainable AI;Lime explainer;Shap explainer;CatBoost;Support Vector Machines (SVM);K-Nearest Neighbors (KNN);Logistic Regression;Decision Trees;Random Forests;Randomized Search CV;Grid Search CV;ADA Boost;XGBoost;Gradient Boosting},
  doi={10.1109/ASIANCON62057.2024.10837854},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10481845,
  author={Rizvi, Nida Afreen and Buchke, Pratik},
  booktitle={2024 IEEE International Students' Conference on Electrical, Electronics and Computer Science (SCEECS)}, 
  title={Hybridization of Apriori Algorithm and Genetic Algorithm for Association Rule Mining in Generative AI Enabled Machine Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Machine learning (ML) is software technology which exploits Generative Artificial Intelligence (GAI) to train sophisticated advance software applications, which are capable to learn from Big Data Analysis for excellent performance, which gets more precise with repetitive training and software experience. Generative AI is a category of artificial intelligence technique that can generates different types of text content, suggestions and idea based images and voice. GAI frequently uses Apriori Algorithm (APAL) for Association Rule Mining in Big Data Investigation, Analysis and Result Generation. Computational Complexity, Noise Sensitivity and Computational time are three major vulnerabilities which Apriori Algorithm inherits in big data applications. Article suggests an advance algorithm, which is hybridization of Apriori Algorithm and Genetic Algorithm to address the noticed vulnerabilities. Test simulation is done in AI Tool Kit of Simulink in MATLAB 7.6 Virtual Simulation Environment.},
  keywords={Training;Machine learning algorithms;Generative AI;Software packages;Simulation;Software algorithms;Machine learning;Apriori Algorithm;Genetic Algorithm;Association Rule Mining;AI Enabled Machine Learning;Generative AI},
  doi={10.1109/SCEECS61402.2024.10481845},
  ISSN={2688-0288},
  month={Feb},}@ARTICLE{10737301,
  author={Park, Jiwon and Jeong, Dasol and Lee, Hyebean and Han, Seunghee and Paik, Joonki},
  journal={IEEE Access}, 
  title={Prompt-Based Learning for Image Variation Using Single Image Multi-Scale Diffusion Models}, 
  year={2024},
  volume={12},
  number={},
  pages={158810-158823},
  abstract={In this paper, we propose a novel technique for a multi-scale framework with text-based learning using a single image to perform variations and text-based editing of the input image. Our approach captures the detailed internal information of a single image, enabling numerous variations while preserving the original features. In addition, text-conditioned learning provides a method to combine text and images to effectively perform text-based editing based on a single image. We propose a technique that integrates the diffusion U-Net structure within a multi-scale framework to accurately capture the quality and internal structure of an image from a single image and perform diverse variations while maintaining the features of the original image. Additionally, we utilized a pre-trained Bootstrapped Language-Image Pretraining (BLIP) model to generate various prompts for effective text-based editing, and we fed the prompts that most closely resembled the input image into the training process using Contrastive Language-Image Pretraining (CLIP)’s prior knowledge. To improve accuracy during the image editing stage, we designed a contrastive loss function to enhance the relevance between the prompt and the image. As a result, we improved the performance of learning between text and images, and through various experiments, we demonstrated its effectiveness on text-based image editing tasks. Our experiments show that the proposed method significantly improves the performance of single-image-based generative models and presents new possibilities in the field of text-based image editing.},
  keywords={Training;Computational modeling;Periodic structures;Diffusion models;Data models;Image synthesis;Adaptation models;Noise reduction;Feature extraction;Context modeling;Single image generation;prompt-based learning;text guided image editing},
  doi={10.1109/ACCESS.2024.3487215},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10318389,
  author={Ye, Lei and Zhong, Chuanchuan and Yi, Fanxiao and Wu, Tao},
  booktitle={2023 IEEE International Conference on Unmanned Systems (ICUS)}, 
  title={Domain Adaptiveness on Lidar Echo Texture in Navigable Areas}, 
  year={2023},
  volume={},
  number={},
  pages={457-465},
  abstract={Unmanned driving technology has extremely important significance and value in multiple fields such as the economy, society, and environment. With the rapid development of artificial intelligence technology, unmanned driving has gained more intelligent support, enabling it to achieve autonomous perception, decision-making, and action. However, there are still many risks and challenges in the large-scale application of unmanned driving technology. Traditional unmanned driving technology requires the support of high-precision maps and has weak adaptability in different environments, which makes the technology application cost high. Therefore, this paper proposes a passable area detection framework based on lidar echo texture information. Combining the framework's high environmental adaptability, unmanned vehicles can have good autonomous navigation capabilities even without high-precision maps and high-precision positioning.},
  keywords={Point cloud compression;Laser radar;Costs;Adaptive systems;Decision making;Data collection;Autonomous vehicles;artificial intelligence;autonomous perception;lidar echo texture;domain Adaptive Study},
  doi={10.1109/ICUS58632.2023.10318389},
  ISSN={2771-7372},
  month={Oct},}@ARTICLE{9484698,
  author={Jeong, Changwook and Myung, Sanghoon and Huh, In and Choi, Byungseon and Kim, Jinwoo and Jang, Hyunjae and Lee, Hojoon and Park, Daeyoung and Lee, Kyuhun and Jang, Wonik and Ryu, Jisu and Cha, Moon-Hyun and Choe, Jae Myung and Shim, Munbo and Kim, Dae Sin},
  journal={IEEE Transactions on Electron Devices}, 
  title={Bridging TCAD and AI: Its Application to Semiconductor Design}, 
  year={2021},
  volume={68},
  number={11},
  pages={5364-5371},
  abstract={There is a growing consensus that the physics-based model needs to be coupled with machine learning (ML) model relying on data or vice versa in order to fully exploit their combined strengths to address scientific or engineering problems that cannot be solved separately. We propose several methodologies of bridging technology computer-aided design (TCAD) simulation and artificial intelligence (AI) with its application to the tasks for which traditional TCAD faces challenges in terms of simulation runtime, coverage, and so on. AI-emulator that learns fine-grained information from rigorous TCAD enables simulation of process technologies and device in real-time as well as large-scale simulation such as full-pattern analysis of stress without high demand on computational resource. To accelerate atomistic molecular dynamics (MD) simulation, we have done a comparison study of descriptor-based and graph-based neural net potential, and also show their capability with large-scale and long-time simulation of silicon oxidation. Finally, we discuss the use of hybrid modeling of AI- and physics-based model for the case where physical equations are either fully or partially unknown.},
  keywords={Semiconductor process modeling;Computational modeling;Predictive models;Mathematical model;Semiconductor device modeling;Numerical models;Analytical models;Artificial intelligence (AI);atomistic simulation;design optimization;device simulation;full-chip level modeling;machine learning;process simulation;semiconductor;technology computer-aided design (TCAD)},
  doi={10.1109/TED.2021.3093844},
  ISSN={1557-9646},
  month={Nov},}@INPROCEEDINGS{9527917,
  author={Mauri, Lara and Damiani, Ernesto},
  booktitle={2021 IEEE International Conference on Cyber Security and Resilience (CSR)}, 
  title={STRIDE-AI: An Approach to Identifying Vulnerabilities of Machine Learning Assets}, 
  year={2021},
  volume={},
  number={},
  pages={147-154},
  abstract={We propose a security methodology for Machine Learning (ML) pipelines, supporting the definition of key security properties of ML assets, the identification of threats to them as well as the selection, test and verification of security controls. Our proposal is based on STRIDE, a widely used approach to threat modeling originally developed by Microsoft. We adapt STRIDE to the Artificial Intelligence domain by taking a security property-driven approach that also provides guidance in selecting the security controls needed to alleviate the identified threats. Our proposal is illustrated via an industrial case study.},
  keywords={Adaptation models;Conferences;Pipelines;Machine learning;Security;Proposals;Computer crime;Artificial Intelligence security;Threat modeling;Vulnerability assessment},
  doi={10.1109/CSR51186.2021.9527917},
  ISSN={},
  month={July},}@INPROCEEDINGS{10621423,
  author={Zhao, Tianya and Wang, Xuyu and Mao, Shiwen},
  booktitle={IEEE INFOCOM 2024 - IEEE Conference on Computer Communications}, 
  title={Cross-domain, Scalable, and Interpretable RF Device Fingerprinting}, 
  year={2024},
  volume={},
  number={},
  pages={2099-2108},
  abstract={In this paper, we propose a cross-domain, scalable, and interpretable radio frequency (RF) fingerprinting system using a modified prototypical network (PTN) and an explanation-guided data augmentation across various domains and datasets with only a few samples. Specifically, a convolutional neural network is employed as the feature extractor of the PTN to extract RF fingerprint features. The predictions are made by comparing the similarity between prototypes and feature embedding vectors. To further improve the system performance, we design a customized loss function and deploy an eXplainable Artificial Intelligence (XAI) method to guide data augmentation during fine-tuning. To evaluate the effectiveness of our system in addressing domain shift and scalability problems, we conducted extensive experiments in both cross-domain and novel-device scenarios. Our study shows that our approach achieves exceptional performance in the cross-domain case, exhibiting an accuracy improvement of approximately 80% compared to convolutional neural networks in the best case. Furthermore, our approach demonstrates promising results in the novel-device case across different datasets. Our customized loss function and XAI-guided data augmentation can further improve authentication accuracy to a certain degree.},
  keywords={Radio frequency;Accuracy;Scalability;System performance;Fingerprint recognition;Feature extraction;Data augmentation;Radio frequency fingerprinting;cross-domain identification;few-shot learning;explainable artificial intelligence},
  doi={10.1109/INFOCOM52122.2024.10621423},
  ISSN={2641-9874},
  month={May},}@INPROCEEDINGS{10617128,
  author={Bouafoud, Chaimaa and Zine-Dine, Khalid and Madani, Abdellah},
  booktitle={2024 International Conference on Circuit, Systems and Communication (ICCSC)}, 
  title={The Evolution of Transformers in Education: A Literature Review}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Chatbots, acting as intermediaries between human users and machines, deliver suitable responses based on human input. The integration of Chatbot systems into education, facilitated by Artificial Intelligence and Machine Learning technologies, has emerged as a promising avenue for delivering personalized services to both institutional staff and students. Despite the increasing adoption of Chatbots in educational contexts, a comprehensive understanding of their implementation remains elusive. The review examines the utilization of Chatbots in education, encompassing insights into existing studies, and categorizing the approaches employed. The findings highlight the diverse applications of Chatbots in education, shedding light on their potential to enhance learning experiences and streamline administrative processes. Additionally, the review identifies key challenges, such as concerns regarding privacy and data security, which warrant further investigation. The implications of these findings underscore the need for continued research to optimize the implementation of Chatbot technology in educational settings, ultimately aiming to improve educational outcomes and foster innovation in the field of education.},
  keywords={Technological innovation;Data privacy;Reviews;Data security;Bibliographies;Education;Machine learning;Artificial intelligence;Chatbot;Education;Transformer;NLP},
  doi={10.1109/ICCSC62074.2024.10617128},
  ISSN={},
  month={June},}@INPROCEEDINGS{10983271,
  author={Hayati, Mohammad Mohsen and Majidi, Hassan and Shahinzadeh, Hossein and Abapour, Mehdi and Fotuhi-Firuzabad, Mahmud and Gharehpetian, Gevork B.},
  booktitle={2024 14th Smart Grid Conference (SGC)}, 
  title={Data-Driven Adequacy and Security Assessment: Machine Learning Trends for Reliable Smart Energy Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-11},
  abstract={Smart energy networks (SENs) face numerous challenges related to security, reliability, operational uncertainties, and increasing penetration of renewable energies (REs), necessitating advanced methodologies for adequacy and security assessment. This study delves into the utilization of machine learning-driven approaches (MLDAs) to quantify reliability and gauge the dependability of future sustainable SENs. By autonomously acquiring knowledge from datasets, MLDAs offer swift and reliable evaluations, surpassing traditional methodologies. The integration of artificial intelligence (AI) in enhancing power system reliability is highlighted, emphasizing the importance of extensive datasets and evolving AI algorithms. Data-driven approaches empower energy network operators to proactively identify and mitigate security risks, enhancing the reliability of critical infrastructure systems. The research underscores the significance of constructing reliable databases, addressing challenges in real-time operations, and ensuring the performance and trustworthiness of machine learning (ML) algorithms. Overall, the study showcases the potential of ML techniques in revolutionizing reliability management and risk assessment in smart energy networks, paving the way for sustainable and reliable power systems.},
  keywords={Uncertainty;Machine learning algorithms;Databases;Machine learning;Power system reliability;Smart grids;Management;Reliability;Security;Risk management;Smart energy networks;Machine learning;Data-driven approaches;Reliability management;Security assessment;Artificial intelligence;Risk assessment;Sustainable energy},
  doi={10.1109/SGC64640.2024.10983271},
  ISSN={2572-6927},
  month={Dec},}@INPROCEEDINGS{11074096,
  author={Badhan, Akash and Sharma, Pooja and Dewangan, Mohit and Singh, Hassandeep},
  booktitle={2025 7th International Conference on Inventive Material Science and Applications (ICIMA)}, 
  title={Enhancing Deepfake Detection Through Facial Pattern Recognition and Transfer Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1286-1291},
  abstract={The swift progress of artificial intelligence and deep learning technologies, detecting deep fake content in such content has been accelerated, while at the same time, great concerns as to the authenticity of digital media have been instilled. Added to this is deep fake technology that enables manufacturing of altered images, videos and sound, which could propagate misinformation or defamatory content about a public figure, including political entity, harmful to their reputation. The increasing threat of deepfakes emphasizes the need for robust detection techniques, the more adept deepfake technology becomes. The input of this study is to offer a complete survey of current deepfake identification approaches, which include machine learning mainly based on convolutional and recurrent neural networks. It evaluates different datasets and detection techniques to give the best performance of separating the real and facial lines content. Moreover, it describes preceding challenges and outlines promising future research directions to positively change approaches to detection accuracy via the combination of hybrid deep learning models. This review serves as the principal attempt to facilitate informed decision making in the quickly advancing area of deepfake identification thus as a contributive measure towards effective risk mitigation strategies.},
  keywords={Deep learning;Deepfakes;Adaptation models;Recurrent neural networks;Accuracy;Reviews;Computational modeling;Transfer learning;Transformer cores;Real-time systems;Deepfake;Deep Learning;Deepfake Identification;Morphing;Content Deepfake;Artificial Intelligence},
  doi={10.1109/ICIMA64861.2025.11074096},
  ISSN={},
  month={May},}@INPROCEEDINGS{10984436,
  author={Rao, B. Devananda and Madhukar, Gadde and Reddy, Bankula Nithin and Voni, Sriyan Kumar and Kumar, N. Snehith Venkata},
  booktitle={2025 International Conference on Intelligent Computing and Control Systems (ICICCS)}, 
  title={Comprehensive AI-Powered Healthcare Management System}, 
  year={2025},
  volume={},
  number={},
  pages={1017-1022},
  abstract={This is the Comprehensive AI-Powered Healthcare Management System intended to revolutionize healthcare delivery, overcoming the shortcomings of present systems by integrating multiple sources of information to predict disease onset and administering personalized care, all based on advanced technologies such as Artificial Intelligence and Machine Learning integrated into Blockchain. The system will have early disease detection and tailor-made treatment plans and holistic patient care. The key algorithms include Random Forest, Support Vector Machine, and Neural Networks. It will deploy Convolutional Neural Networks for the analysis of medical images and Natural Language Processing techniques through the application of transformer models such as BERT. Key Technologies to be used are PyTorch, TensorFlow, DialogFlow, and Ethereum. This project shall be developed in phases starting from collecting and integrating diverse health data. Expected output is a fully functional healthcare management platform for the enhancement of patient outcomes, facilitation of greater efficiency by health providers, and secure health data management. These diverse applications have functionalities in improving diagnostic accuracy and patient management in clinics, remote monitoring of patients with chronic diseases, prediction of mental health crisis incidents, and safe storage of patient data through blockchain integration.},
  keywords={Data privacy;Accuracy;Data security;Medical services;Transforms;Transformers;Natural language processing;Blockchains;Medical diagnostic imaging;Diseases;Healthcare Informatics;Artificial Intelligence in Healthcare;Machine Learning for Disease Prediction;Predictive;Analytics in Healthcare;Medical Image Analysis;Blockchain in Healthcare;Data Security and Privacy in Healthcare},
  doi={10.1109/ICICCS65191.2025.10984436},
  ISSN={},
  month={March},}@INPROCEEDINGS{10732647,
  author={Afolabi, Akindele Segun and Adewale Akinola, Olubunmi},
  booktitle={2024 IEEE International Symposium on Technology and Society (ISTAS)}, 
  title={Vulnerable AI: A Survey}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Nowadays, artificial intelligence (AI) is finding relevance in diverse facets of human existence. For example, AI has been applied in areas such as finance, energy, healthcare, transportation, education, agriculture, and entertainment, just to mention a few. However, technologies that employ AI algorithms such as machine learning algorithms and deep learning algorithms are susceptible to a new challenge known as adversarial machine learning (AML) attacks. An AML attack occurs when a malicious actor crafts adversarial examples (AEs) to introduce perturbation into the original input data of an AI-based classification model to cause the model to misclassify inputs. This paper reviewed how computer vision systems, audio systems, industrial systems, transportation systems, blockchain technologies, and cybersecurity systems may be susceptible to AML attacks. Special attention is given to the discussion on AML attacks on network intrusion detection systems (NIDSs) while also highlighting adversarial defense strategies. The paper concludes with a proposal for future research direction regarding AML attack mitigation.},
  keywords={Surveys;Machine learning algorithms;Computational modeling;Prevention and mitigation;Perturbation methods;Transportation;Data models;Adversarial machine learning;Classification algorithms;Proposals;adversarial machine learning attack;network intrusion detection;artificial intelligence;cybersecurity;adversarial example},
  doi={10.1109/ISTAS61960.2024.10732647},
  ISSN={2158-3412},
  month={Sep.},}@ARTICLE{11022692,
  author={Elgarhy, Islam and Badr, Mahmoud M. and Mahmoud, Mohamed and Ni, Jianbing and Alsabaan, Maazen and Alshawi, Tariq},
  journal={IEEE Internet of Things Journal}, 
  title={Investigation of the Robustness of XAI-Based Federated Learning Against Adversarial Attacks for Smart Grid False Data Detection}, 
  year={2025},
  volume={12},
  number={15},
  pages={32179-32192},
  abstract={Federated learning (FL) enables decentralized training of machine learning (ML) models, making it a valuable approach for detecting false data in smart power grids (SGs) to enhance grid stability while protecting consumers’ privacy. However, FL-based ML models remain vulnerable to adversarial attacks during both training and inference phases, which can compromise data security. To address these vulnerabilities, we first investigate the robustness of a novel FL-based false data detection approach using explainable artificial intelligence (XAI), referred to as XAI-based FL detection. This approach utilizes explanations of consumers’ power consumption data, rather than raw data, during the training process. We assess the robustness of the XAI-based FL detection compared to traditional data-driven FL detection against two types of adversarial attacks: 1) Gradient Inversion attacks in the training phase, where adversaries reconstruct private data from shared gradients, and 2) Evasion attacks in the inference phase, where adversaries subtly modify input data to deceive the detection model. Then, we propose a secure XAI-based FL detector with adversarial training (AT) to defend against both attack types. The key idea is that XAI helps mask model gradients during training because XAI-generated explanations remain nearly identical across different samples. Therefore, attackers struggle to accurately reconstruct the original training data, even if they obtain precise explanations using gradient inversion attacks. Additionally, XAI effectively distinguishes between benign and malicious samples. When combined with AT, XAI strengthens model robustness against evasion attacks without compromising accuracy, effectively resolving the tradeoff between security and performance. Our proposed detector reduced the success rate of evasion attacks from 94.99% to 29.11% with training on explanations, and further to 0% with adding AT. It also increased the mean square error for gradient inversion attacks from 0.01 to 2.60 in the most severe attack scenarios, making such attacks ineffective.},
  keywords={Training;Accuracy;Data models;Computational modeling;Robustness;Explainable AI;Detectors;Data privacy;Security;Privacy;Adversarial Attacks;explainable Artificial Intelligence (XAI);electricity theft;evasion;false data detection;federated learning (FL);gradient inversion;privacy preservation;smart grid},
  doi={10.1109/JIOT.2025.3576225},
  ISSN={2327-4662},
  month={Aug},}@INPROCEEDINGS{10866445,
  author={Zhang, Jieyi and Wu, Zhongxing and Pu, Ninghao and Xu, Yifan and Ding, Zhenyang and Liu, Hao},
  booktitle={2024 4th International Conference on Electronic Information Engineering and Computer (EIECT)}, 
  title={Compact and Accurate Binary Neural Network for Real-Time ECG Classification on AIoT Devices}, 
  year={2024},
  volume={},
  number={},
  pages={897-902},
  abstract={Accurate detection of cardiac arrhythmias through electrocardiogram (ECG) signals is critical for timely medical intervention and improving patient outcomes. Despite the proliferation of deep learning-based ECG classification algorithms, many existing models tend to compromise on resource efficiency, resulting in high storage demands and excessive power consumption. This limits their deployment on wearable Artificial Intelligence-of-Things (AIoT) devices, which are increasingly vital for continuous health monitoring. In contrast to conventional binarization approaches, we propose a novel Binary Neural Network (BNN) tailored for ECG signal classification, incorporating innovative basic blocks that enhance both performance and efficiency. Our approach transforms one-dimensional ECG signals into two-dimensional grayscale images, improving data augmentation for small sample sizes. The model achieves a classification accuracy of 97.85% with a remarkably compact memory footprint of just 14.07 KB, representing a 31.37-fold compression compared to traditional full-precision models. Furthermore, we introduce scaling factors for both weight and activation binarization, while replacing the ReLU function with the sign function during quantization-aware training. This approach effectively balances model complexity and classification performance. The simplified architecture of our BNN is particularly well-suited for real-time applications, paving the way for its implementation in wearable medical devices, particularly for enhancing patient monitoring and management of cardiac conditions.},
  keywords={Performance evaluation;Training;Accuracy;Power demand;Neural networks;Pattern classification;Computer architecture;Electrocardiography;Gray-scale;Real-time systems;ECG classification algorithm;Binary Neural Network(BNN);Two-dimensional grayscale images;Artificial Intelligence-of-Things;Data Augmentation},
  doi={10.1109/EIECT64462.2024.10866445},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11122185,
  author={Golovko, Igor and Savenko, Oleg and Vizhevskyi, Petro and Sachenko, Anatoliy},
  booktitle={2024 14th International Conference on Dependable Systems, Services and Technologies (DESSERT)}, 
  title={Obfuscation process with machine learning module}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={machine learning is leveraged to dynamically optimize obfuscation patterns and predict the most effective techniques tailored to specific software environments, which marks a considerable improvement over traditional methods that often require manual intervention and are prone to errors. The design and implementation of an intelligent system for obfuscating .NET programming languages using artificial intelligence. The proposed system leverages deep learning techniques to enhance code security and complexity. The system's architecture includes components such as preprocessing module, AI-based obfuscation module, quality verification module, data storage system, and reporting module. Detailed implementation strategies using .NET tools.},
  keywords={Deep learning;Computer languages;Codes;Source coding;Manuals;Computer architecture;Software;Security;Protection;Intelligent systems;Code Obfuscation;Software Security;Artificial Intelligence in Security;Machine Learning;ONNX;ML.NET;Source Code Protection Strategies},
  doi={10.1109/DESSERT65323.2024.11122185},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10846333,
  author={Chaudhary, Sneha and Chaurasiya, Komal and Sriram, Suthir and S, Ravikumar and V, Nivethitha and M, Thangavel},
  booktitle={2024 International Conference on Electronic Systems and Intelligent Computing (ICESIC)}, 
  title={Unmasking Digital Deceptions: A Comprehensive Survey of Synthetic Reality Analysis Across Multimedia Domains}, 
  year={2024},
  volume={},
  number={},
  pages={202-207},
  abstract={The general accessibility of social networking sites like Facebook, Myspace and TikTok has transformed the way information is communicated, but it has also made it simpler to spread misleading information, thanks to cutting-edge technologies like deepfakes. The use of artificial intelligence in deepfake technology produces material that is remarkably life- like but fake, making it difficult to identify and remove fraudulent content. The evolution of deepfake technology is reviewed in this study, starting with early breakthroughs like the Video Rewrite Program and continuing with more current developments like the Synthesizing Obama and Face2Face projects. We provide a comprehensive analysis of the state-of-the-art detection strategies, namely Region-based CNNs (RCNNs), Conventional Neural Networks (CNNs), and hybrid approaches that combine various deep learning techniques. Though these methods have advanced, there are still issues with accuracy, integration complexity, and adaptability to new deepfake techniques. This paper suggests a novel approach that integrates image, video, and audio analysis into a single detection framework in order to overcome these difficulties. The new approach is directed towards improvement of detection accuracy and the lowering of the false alarm using advanced and deep learning engines along with the real time processing requirements. Early results indicate that the detection capabilities have significantly improved compared to existing solutions operating in real time environment while having less latency and higher recall and precision rates. This method is more effective for deepfake detection and at the same time helps in augmenting the comprehensiveness and efficiency of the system there by making it suitable for wider uses. The study emphasizes the presence of the need for the evolution of static approaches towards the effective defection of sophisticated false information and the justification of new possibilities in the fight against disinformation and protection of information space in general.},
  keywords={Deep learning;Surveys;Deepfakes;Technological innovation;Accuracy;Video on demand;Social networking (online);Real-time systems;Web sites;Protection;Analysis;Artificial Intelligence;Deepfake;Hoaxes;Neural Networks},
  doi={10.1109/ICESIC61777.2024.10846333},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9975900,
  author={Flores, Cecilia Gabriela Rodriguez and Ortega, Jesus Carlos Pedraza and Salazar-Licea, M.C. Luis Antonio and Fernandez, Marco Antonio Aceves and Osti, Marzela Sanchez},
  booktitle={2022 19th International Conference on Electrical Engineering, Computing Science and Automatic Control (CCE)}, 
  title={A survey of approaches in Deep Learning techniques for the detection and classification of mammography abnormalities}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Mammography is currently the most widely used laboratory study for the early detection of precursor abnormalities of breast cancer, which is one of the main causes of mortality worldwide since this disease generates the appearance of large volumes of cancerous cells in the breast.Thus, Computer-aided detection or diagnosis (CADe and CADx) can help the specialist improve the accuracy of the diagnosis, providing the patient with a better treatment and disease management assessment. Unfortunately, there are several circumstances in which it is possible to obtain an erroneous diagnosis, such as subjectivity on the part of the radiologist due to the size or morphology of the anomalies detected, as well as the fact that mammograms may include embedded noise.For this reason, this manuscript seeks to provide the reader with a more general overview of how this issue has been addressed in recent years (2016 onwards) through the compilation of various scientific research focused on the detection and classification of breast cancer precursor anomalies based on the implementation of artificial intelligence techniques, where it is possible to visualize the performance of each of the proposed models through the implementation of various metrics such as F1 Score, AUC, accuracy, etc. Thus, these studies have been obtained from recognized multidisciplinary scientific sites in the world such as Nature, Springer, IEEE Xplorer, and PubMed, among others.},
  keywords={Measurement;Deep learning;Visualization;Morphology;Electrical engineering computing;Breast cancer;Mammography;Anomalies;breast cancer;Artificial Intelligence;metrics},
  doi={10.1109/CCE56709.2022.9975900},
  ISSN={2642-3766},
  month={Nov},}@INPROCEEDINGS{10712588,
  author={Skoczylas, Artur and Gryncewicz, Wiesława and Rosa, Agnieszka and Nadolny, Michał},
  booktitle={2024 14th International Conference on Advanced Computer Information Technologies (ACIT)}, 
  title={Deep Learning in Undeground Mines - a Review}, 
  year={2024},
  volume={},
  number={},
  pages={710-714},
  abstract={Through the newest advancements in the area of artificial intelligence, the popularity of deep learning has increased in almost every conceivable field. Underground mines are no exception to this trend, and although there is a noticeable delay, new technologies are also being implemented there. In this paper, we present a review of deep learning applications in research concerning underground mines. The aim of this article is to outline the latest trends in this specific area; thus, only articles from recent years (2020-2024) were considered. Utilizing a Scopus query, initially 47 articles were identified, which were subsequently reduced to a final sample of 31. Through a comprehensive review of each article, the authors established five main lines of research in the field: predictive maintenance, efficiency assessment, localization and autonomous operation, object recognition, and early warning and safety. The article provides a broad overview of ongoing activities and future directions in these domains, along with a detailed catalog of individual research works and achievements.},
  keywords={Deep learning;Training;Location awareness;Laser radar;Reviews;Market research;Rocks;Object recognition;Monitoring;Predictive maintenance;deep learning;underground mines;review;artificial intelligence;industry applications},
  doi={10.1109/ACIT62333.2024.10712588},
  ISSN={2770-5226},
  month={Sep.},}@INPROCEEDINGS{10748474,
  author={Tauseef, Md. and K, Vaishnavi R and Ghosh, Tejaswini and Muthyalu, Gagana G and Sumedini, A S and Reddy, R Venkata Siva},
  booktitle={2024 5th International Conference on Circuits, Control, Communication and Computing (I4C)}, 
  title={SmartGuard: A Proactive Surveillance System for Enhancing Security in Transportation Hubs}, 
  year={2024},
  volume={},
  number={},
  pages={249-254},
  abstract={Ensuring security within transportation hubs re-mains a paramount concern in contemporary society. The ever-evolving landscape of security threats necessitates innovative solutions to safeguard public safety effectively. This paper introduces SmartGuard, a proactive surveillance system designed to address the critical challenge of detecting unattended objects in transportation hubs. Leveraging cutting-edge technologies such as advanced sensors and artificial intelligence, SmartGuard aims to provide real-time threat analysis and minimize potential risks, including explosives or hazardous materials. By surpassing the limitations of traditional security systems, SmartGuard heralds a new era of resilient security practices, significantly enhancing the safety of public transit environments.},
  keywords={Hazardous materials;Surveillance;Transportation;Machine learning;Real-time systems;Public security;Security;Predictive analytics;Standards;Intelligent sensors;Transportation security;Surveillance systems;SmartGuard;Unattended object detection;Artificial intelligence},
  doi={10.1109/I4C62240.2024.10748474},
  ISSN={2473-7690},
  month={Oct},}@ARTICLE{8301400,
  author={Li, Yuexiang and Shen, Linlin},
  journal={IEEE Access}, 
  title={cC-GAN: A Robust Transfer-Learning Framework for HEp-2 Specimen Image Segmentation}, 
  year={2018},
  volume={6},
  number={},
  pages={14048-14058},
  abstract={Human epithelial type 2 (HEp-2) cell images play an important role for the detection of antinuclear autoantibodies in autoimmune diseases. As the HEp-2 cell has hundreds of different patterns, none of currently available HEp-2 datasets contain all of the types. Therefore, existing automatic processing systems for HEp-2 cells, e.g., cell segmentation and classification, needs to be transferred between different data sets. However, the performances of transferred system often dramatically decrease, especially when transferring supervised-approaches, e.g., deep learning network, from large dataset to the small but similar ones. In this paper, a novel transfer-learning framework using generative adversarial networks (cC-GAN) is proposed for robust segmentation of different HEp-2 datasets. The proposed cC-GAN tries to solve the overfitting problem of most deep learning networks and improves their transfer-capacity. An improved U-net, so-called Residual U-net (RU-net), is developed to work as the generator for cC-GAN model. The cC-GAN was first trained and tested using I3A dataset and then directly evaluated using MIVIA dataset, which is much smaller than I3A. The segmentation result demonstrates the excellent transferring-capacity of our cC-GAN framework, i.e., a new state-of-the-art segmentation accuracy of 75.27% was achieved on MIVIA without finetuning.},
  keywords={Image segmentation;Gallium nitride;Generators;Computer architecture;Microprocessors;Training;Machine learning;Cell segmentation;generative adversarial networks;fully convolutional network},
  doi={10.1109/ACCESS.2018.2808938},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10982880,
  author={Abhinav, R. and Rohith, S. and Suman, K. and Madhuri, T. and Kiranmaie, P. and Sugamya, K.},
  booktitle={2025 International Conference for Artificial Intelligence, Applications, Innovation and Ethics (AI2E)}, 
  title={Explainable AI for Architectural Design Generation with Few-Shot Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Generative design is transforming the field of architecture by enabling intelligent and adaptable solutions that adhere to both user preferences and traditional design principles. However, existing design approaches often lack interpretability and transparency, limiting their applicability in culturally sensitive domains. To address these limitations, we propose a novel framework that combines Few-Shot Learning (FSL) with Explainable AI (XAI) for generating architectural designs rooted in principles such as Vastu Shastra. Our framework utilizes prompt-engineered fine-tuning of a Stable Diffusion model on a dataset of floor plans which consists of around 50–100 floor plan designs, allowing for rapid adaptation to user-specific design requirements. To ensure interpretability and foster user trust, we incorporate SHAP (SHapley Additive exPlanations) to provide clear, interpretable insights into each design's adherence to predefined architectural guidelines. This approach not only offers personalized and culturally compliant design solutions but also bridges the gap between AI-generated outputs and user understanding, making intelligent design accessible and trustworthy.},
  keywords={Technological innovation;Sensitivity;Explainable AI;Training data;Diffusion models;Cultural differences;Prompt engineering;Few shot learning;Floors;Guidelines;Few-Shot Learning;Explainable AI;Architectural Design;Stable Diffusion;SHAP;Vastu Shastra;Prompt Engineering;ControlNet},
  doi={10.1109/AI2E64943.2025.10982880},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{11050625,
  author={Krishnan, Anoop and Basu, Amit},
  booktitle={2025 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Towards Deepfake Detection for Everyone: A Lightweight Deepfake Detection Algorithm (LiDD)}, 
  year={2025},
  volume={},
  number={},
  pages={1168-1174},
  abstract={Modern AI technologies such as Autoencoders, Generative Adversarial Networks (GANs), and Diffusion Models have advanced Deepfake content generation remarkably over the past few years. The risks associated with malicious deepfakes have motivated significant advances in methods for detecting deepfake content, but the most effective methods require substantial computational resources and processing time. Unfortunately, while deepfake generation does not typically face time constraints, deepfake detection methods are unlikely to be broadly adopted unless they are efficient even on modest computing devices. In this paper, we propose a lightweight algorithm for deepfake detection that achieves impressive performance on various reference deepfaking techniques, even though it utilizes relatively sophisticated deep learning models with over 4 M parameters, and even on modest CPU-based laptop computers. This approach paves the way for integration into public infrastructures like web browsers and multimedia players, advancing global efforts to combat digital disinformation and strengthen the security of online platforms.},
  keywords={Deep learning;Performance evaluation;Deepfakes;Portable computers;Public infrastructure;Vectors;Real-time systems;Multisensory integration;Time factors;Security;Deepfake detection;Lightweight algorithm;Resource-constrained;Deep learning;Public infrastructure},
  doi={10.1109/CAI64502.2025.00293},
  ISSN={},
  month={May},}@ARTICLE{11012667,
  author={Wang, Zi-Ming and Xue, Nan and Lei, Ling and Jörnsten, Rebecka and Xia, Gui-Song},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Partial Distribution Matching via Partial Wasserstein Adversarial Networks}, 
  year={2025},
  volume={47},
  number={9},
  pages={7944-7959},
  abstract={This paper studies the problem of distribution matching (DM), which is a fundamental machine learning problem seeking to robustly align two probability distributions. Our approach is established on a relaxed formulation, called partial distribution matching (PDM), which seeks to match a fraction of the distributions instead of matching them completely. We theoretically derive the Kantorovich-Rubinstein duality for the partial Wasserstein-1 (PW) discrepancy, and develop a partial Wasserstein adversarial network (PWAN) that efficiently approximates the PW discrepancy based on this dual form. Partial matching can then be achieved by optimizing the network using gradient descent. Two practical tasks, point set registration and partial domain adaptation are investigated, where the goals are to partially match distributions in 3D space and high-dimensional feature space respectively. The experiment results confirm that the proposed PWAN effectively produces highly robust matching results, performing better or on par with the state-of-the-art methods.},
  keywords={Three-dimensional displays;Training;Data models;Probability distribution;Probabilistic logic;Generative adversarial networks;Feature extraction;Data mining;Cost function;Benchmark testing;Partial distribution matching;partial Wasserstein adversarial network;point set registration;partial domain adaptation},
  doi={10.1109/TPAMI.2025.3572795},
  ISSN={1939-3539},
  month={Sep.},}@INPROCEEDINGS{9423264,
  author={Luo, Qinxuan and Wang, Lingfeng and Lv, Jingguo and Xiang, Shiming and Pan, Chunhong},
  booktitle={2021 IEEE Winter Conference on Applications of Computer Vision (WACV)}, 
  title={Few-Shot Learning via Feature Hallucination with Variational Inference}, 
  year={2021},
  volume={},
  number={},
  pages={3962-3971},
  abstract={Deep learning has achieved huge success in the field of artificial intelligence, but the performance heavily depends on labeled data. Few-shot learning aims to make a model rapidly adapt to unseen classes with few labeled samples after training on a base dataset, and this is useful for tasks lacking labeled data such as medical image processing. Considering that the core problem of few-shot learning is the lack of samples, a straightforward solution to this issue is data augmentation. This paper proposes a generative model (VI-Net) based on a cosine-classifier baseline. Specifically, we construct a framework to learn to define a generating space for each category in the latent space based on few support samples. In this way, new feature vectors can be generated to help make the decision boundary of classifier sharper during the fine-tuning process. To evaluate the effectiveness of our proposed approach, we perform comparative experiments and ablation studies on mini-ImageNet and CUB. Experimental results show that VI-Net does improve performance compared with the baseline and obtains the state-of-the-art result among other augmentation-based methods.},
  keywords={Training;Deep learning;Computer vision;Conferences;Computational modeling;Gaussian distribution;Data models},
  doi={10.1109/WACV48630.2021.00401},
  ISSN={2642-9381},
  month={Jan},}@ARTICLE{9094665,
  author={Liu, Hong-Bin and Lee, Ickjai},
  journal={IEEE Access}, 
  title={MPL-GAN: Toward Realistic Meteorological Predictive Learning Using Conditional GAN}, 
  year={2020},
  volume={8},
  number={},
  pages={93179-93186},
  abstract={Meteorological imagery prediction is an important and challenging problem for weather forecasting. It can also be seen as a video frame prediction problem that estimates future frames based on observed meteorological imageries. Despite it is a widely-investigated problem, it is still far from being solved. Current state-of-the-art deep learning based approaches mainly optimise the mean square error loss resulting in blurry predictions. We address this problem by introducing a Meteorological Predictive Learning GAN model (in short MPL-GAN) that utilises the conditional GAN along with the predictive learning module in order to handle the uncertainty in future frame prediction. Experiments on a real-world dataset demonstrate the superior performance of our proposed model. Our proposed model is able to map the blurry predictions produced by traditional mean square error loss based predictive learning methods back to their original data distributions, hence it is able to improve and sharpen the prediction. In particular, our MPL-GAN achieves an average sharpness of 52.82, which is 14% better than the baseline method. Furthermore, our model correctly detects the meteorological movement patterns that traditional unconditional GANs fail to do.},
  keywords={Gallium nitride;Predictive models;Atmospheric modeling;Generators;Generative adversarial networks;Radar imaging;Meteorological prediction;spatio-temporal forecasting;GAN;video prediction},
  doi={10.1109/ACCESS.2020.2995187},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10411710,
  author={Woźniak, Stanisław and Kocoń, Jan},
  booktitle={2023 IEEE International Conference on Data Mining Workshops (ICDMW)}, 
  title={From Big to Small Without Losing It All: Text Augmentation with ChatGPT for Efficient Sentiment Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={799-808},
  abstract={In the era of artificial intelligence, data is gold but costly to annotate. The paper demonstrates a groundbreaking solution to this dilemma using ChatGPT for text augmentation in sentiment analysis. We leverage ChatGPT’s generative capabilities to create synthetic training data that significantly improves the performance of smaller models, making them competitive with, or even outperforming, their larger counterparts. This innovation enables models to be both efficient and effective, thereby reducing computational cost, inference time, and memory usage without compromising on quality. Our work marks a key advancement in the cost-effective development and deployment of robust sentiment analysis models.},
  keywords={Sentiment analysis;Technological innovation;Gold;Computational modeling;Memory management;Training data;Chatbots;Text Augmentation;ChatGPT;Sentiment Analysis;Model Efficiency;Data Annotation Cost},
  doi={10.1109/ICDMW60847.2023.00108},
  ISSN={2375-9259},
  month={Dec},}@ARTICLE{9729556,
  author={You, Senrong and Lei, Baiying and Wang, Shuqiang and Chui, Charles K. and Cheung, Albert C. and Liu, Yong and Gan, Min and Wu, Guocheng and Shen, Yanyan},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Fine Perceptive GANs for Brain MR Image Super-Resolution in Wavelet Domain}, 
  year={2023},
  volume={34},
  number={11},
  pages={8802-8814},
  abstract={Magnetic resonance (MR) imaging plays an important role in clinical and brain exploration. However, limited by factors such as imaging hardware, scanning time, and cost, it is challenging to acquire high-resolution MR images clinically. In this article, fine perceptive generative adversarial networks (FP-GANs) are proposed to produce super-resolution (SR) MR images from the low-resolution counterparts. By adopting the divide-and-conquer scheme, FP-GANs are designed to deal with the low-frequency (LF) and high-frequency (HF) components of MR images separately and parallelly. Specifically, FP-GANs first decompose an MR image into LF global approximation and HF anatomical texture subbands in the wavelet domain. Then, each subband generative adversarial network (GAN) simultaneously concentrates on super-resolving the corresponding subband image. In generator, multiple residual-in-residual dense blocks are introduced for better feature extraction. In addition, the texture-enhancing module is designed to trade off the weight between global topology and detailed textures. Finally, the reconstruction of the whole image is considered by integrating inverse discrete wavelet transformation in FP-GANs. Comprehensive experiments on the MultiRes_7T and ADNI datasets demonstrate that the proposed model achieves finer structure recovery and outperforms the competing methods quantitatively and qualitatively. Moreover, FP-GANs further show the value by applying the SR results in classification tasks.},
  keywords={Wavelet domain;Magnetic resonance imaging;Generative adversarial networks;Task analysis;Image reconstruction;Hafnium;Discrete wavelet transforms;Discrete wavelet transformation;generative adversarial network (GAN);magnetic resonance (MR) imaging;super-resolution (SR);textures enhance},
  doi={10.1109/TNNLS.2022.3153088},
  ISSN={2162-2388},
  month={Nov},}@ARTICLE{9633227,
  author={Dong, Yongsheng and Tan, Wei and Tao, Dacheng and Zheng, Lintao and Li, Xuelong},
  journal={IEEE Transactions on Image Processing}, 
  title={CartoonLossGAN: Learning Surface and Coloring of Images for Cartoonization}, 
  year={2022},
  volume={31},
  number={},
  pages={485-498},
  abstract={Cartoonization as a special type of artistic style transfer is a difficult image processing task. The current existing artistic style transfer methods cannot generate satisfactory cartoon-style images due to that artistic style images often have delicate strokes and rich hierarchical color changes while cartoon-style images have smooth surfaces without obvious color changes, and sharp edges. To this end, we propose a cartoon loss based generative adversarial network (CartoonLossGAN) for cartoonization. Particularly, we first reuse the encoder part of the discriminator to build a compact generative adversarial network (GAN) based cartoonization architecture. Then we propose a novel cartoon loss function for the architecture. It can imitate the process of sketching to learn the smooth surface of the cartoon image, and imitate the coloring process to learn the coloring of the cartoon image. Furthermore, we also propose an initialization strategy, which is used in the scenario of reusing the discriminator to make our model training easier and more stable. Extensive experimental results demonstrate that our proposed CartoonLossGAN can generate fantastic cartoon-style images, and outperforms four representative methods.},
  keywords={Training;Generative adversarial networks;Generators;Image color analysis;Training data;Rendering (computer graphics);Feature extraction;Deep learning;generative adversarial networks;cartoonization},
  doi={10.1109/TIP.2021.3130539},
  ISSN={1941-0042},
  month={},}@ARTICLE{9739662,
  author={Park, Minho and Song, Hwa Jeon and Kang, Dong-Oh},
  journal={IEEE Access}, 
  title={Imbalanced Classification via Feature Dictionary-Based Minority Oversampling}, 
  year={2022},
  volume={10},
  number={},
  pages={34236-34245},
  abstract={Image classification research is one of the fields continuously studied in the computer vision domain, and several related studies have been actively conducted until recently. However, a limit exists regarding the prediction performance of real-world datasets due to the data imbalance problem between classes. Data augmentation through artificial sample generation for minority classes is one of the methods used to overcome this limitation. Among the various oversampling methods, we propose the feature dictionary-based generative model for the oversampling method. Feature dictionaries are built through the pretrained feature extractor, and the proposed generative model synthesizes artificial samples based on the dictionary. Class-to-class balanced training can be conducted by fine-tuning the classifier as additional data for the minority class. We experiment by applying the proposed framework to the fashion dataset, which has an extreme class imbalance. The experimental results demonstrate that the proposed model achieved the highest top-1 performance on various public fashion datasets. In addition, we analyze the number of samples in the dictionary and test the effectiveness of the elements that comprise the proposed model using various ablation studies.},
  keywords={Feature extraction;Clothing;Dictionaries;Shape;Training;Generators;Predictive models;Deep learning;imbalanced classification;generative adversarial network},
  doi={10.1109/ACCESS.2022.3161510},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8258273,
  author={Verma, Dinesh C. and Bent, Graham},
  booktitle={2017 IEEE International Conference on Big Data (Big Data)}, 
  title={Policy enabled caching for distributed AI}, 
  year={2017},
  volume={},
  number={},
  pages={3017-3023},
  abstract={Web Caching has established itself as a key enabling technology within the Internet. It enables efficient browsing of websites and web-based services on networks that are bandwidth constrained. However, similar techniques are not available for AI based solutions. Many AI solutions are based on deep neural networks or similar approaches which require creation of machine learning models trained with huge amounts of data. Such models are best created in centralized locations with significant processing power. In many environments, sending the data to a centralized location is infeasible or undesirable. A judicious combination of ideas borrowed from web-caching paradigm, with ideas from AI and machine learning can provide an effective solution for exploitation of deep learning models in bandwidth constrained environments. Allowing such caches to generate their own policies using a generative policy approach can enable the creation of a generic edge caching system which can be used with a wide variety of backend AI systems.},
  keywords={Artificial intelligence;Training;Speech;Data models;Drones;Hospitals;Computational modeling;Edge Computing;Fog Computing;Distributed AI;Semantic Caching;Generative Policy},
  doi={10.1109/BigData.2017.8258273},
  ISSN={},
  month={Dec},}@ARTICLE{11059995,
  author={Shen, Xing and Huang, Hengguan and Nichyporuk, Brennan and Arbel, Tal},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Improving Robustness and Reliability in Medical Image Classification with Latent-Guided Diffusion and Nested-Ensembles}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Once deployed, medical image analysis methods are often faced with unexpected image corruptions and noise perturbations. These unknown covariate shifts present significant challenges to deep learning based methods trained on “clean” images. This often results in unreliable predictions and poorly calibrated confidence, hence hindering clinical applicability. While recent methods have been developed to address specific issues such as confidence calibration or adversarial robustness, no single framework effectively tackles all these challenges simultaneously. To bridge this gap, we propose LaDiNE, a novel ensemble learning method combining the robustness of Vision Transformers with diffusion-based generative models for improved reliability in medical image classification. Specifically, transformer encoder blocks are used as hierarchical feature extractors that learn invariant features from images for each ensemble member, resulting in features that are robust to input perturbations. In addition, diffusion models are used as flexible density estimators to estimate member densities conditioned on the invariant features, leading to improved modeling of complex data distributions while retaining properly calibrated confidence. Extensive experiments on tuberculosis chest X-rays and melanoma skin cancer datasets demonstrate that LaDiNE achieves superior performance compared to a wide range of state-of-the-art methods by simultaneously improving prediction accuracy and confidence calibration under unseen noise, adversarial perturbations, and resolution degradation.},
  keywords={Biomedical imaging;Transformers;Diffusion models;Robustness;Image classification;Artificial intelligence;Feature extraction;Uncertainty;Training;Ensemble learning;Medical Image Classification;Uncertainty Quantification;Diffusion-based Generative Models;Ensemble Methods},
  doi={10.1109/TMI.2025.3583974},
  ISSN={1558-254X},
  month={},}@INPROCEEDINGS{11010527,
  author={Ahi, Kiarash and Wu, Stewart and Sriram, Satya and Fenger, Germain},
  booktitle={2025 36th Annual SEMI Advanced Semiconductor Manufacturing Conference (ASMC)}, 
  title={GPU-Accelerated Feature Extraction for Real-Time Vision AI and LLM Systems Efficiency: Autonomous Image Segmentation, Unsupervised Clustering, and Smart Pattern Recognition for Scalable AI Processing with 6.6× Faster Performance, 2.5× Higher Accuracy, and UX-Centric UI Boosting Human-in-the-Loop Productivity}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={The high computational cost of digital image processing, requiring high-performance hardware and extensive resources, severely limits real-time applications. While advancements in algorithm design and GPU acceleration have significantly improved efficiency, modern AI-driven applications such as large language models (LLMs), Generative AI (GenAI), medical imaging, autonomous vehicle perception, photography, advanced nano-scale semiconductor metrology, satellite image analysis, high-precision manufacturing, robotics, and real-time anomaly detection, still demand further optimization to reduce computational overhead and improve scalability.In this paper, we introduce GPU-Accelerated Feature Extraction to enhance runtime and efficiency in edge-based simulations. Our approach leverages AI-driven clustering, grouping images with similar visual and pattern characteristics to enable adaptive tuning on a small subset before generalizing across the full dataset. This method achieves a 3.78× reduction in runtime.Furthermore, rather than processing an entire image, we recognize and extract a single representative pattern or region of interest (ROI) per image, removing redundant data and background noise. This refinement results in an additional 1.74× runtime improvement, culminating in an overall 6.6× speed boost, enhancing Scalable Real-Time AI Processing. We also demonstrated that with a similar runtime, the accuracy achieved is 2.5× higher.This solution, integrated into Calibre SEMSuite™, supports multicloud and real-time deployment for enhanced scalability, usability, and performance, providing users with a powerful tool for fully automated, AI-driven image classification, making high-throughput image review feasible even at the scale required for cutting-edge applications.Beyond performance gains, this approach introduces autonomous data cleaning, anomaly detection and defect identification mechanism, allowing failed patterns and defective images to be identified without human intervention, boosting the reviewer productivity.As GenAI and LLM systems gain popularity, the computational demands on modern systems have reached unprecedented levels. As we demonstrate, thanks to feature extraction and ROI selection, instead of needing for the entire dataset to be processed, only a fraction of the data could be used. This is crucial for reducing the computational overhead of LLM systems.We demonstrate that our method enables high-precision, real-time AI inference with applications in computer vision, LLMs, autonomous systems, healthcare, and scalable AI computing.},
  keywords={Accuracy;Runtime;Image edge detection;Clustering algorithms;Feature extraction;Real-time systems;Computational efficiency;Artificial intelligence;Anomaly detection;Tuning;GPU-accelerated computing;real-time AI inference;scalable vision systems;LLM Efficiency;Generative AI;GenAI;autonomous image segmentation;deep pattern recognition;anomaly detection;AI clustering;edge deployment},
  doi={10.1109/ASMC64512.2025.11010527},
  ISSN={2376-6697},
  month={May},}@INPROCEEDINGS{10424933,
  author={Ma, Liuzhong},
  booktitle={2023 International Conference on Image Processing, Computer Vision and Machine Learning (ICICML)}, 
  title={Dual Unsupervised Luminance-Space Pyramid-Constrained Network for Image Deraining in Real-World Scenarios}, 
  year={2023},
  volume={},
  number={},
  pages={108-113},
  abstract={In the field of image processing, addressing the deleterious impact of rain streaks on images captured in real-world scenarios poses a formidable challenge. Previously developed deep learning-based deraining methods have demonstrated remarkable effectiveness when assessed using standardized benchmark datasets. Nonetheless, their applicability is often limited to pairwise training samples and domain-specific discrepancies. Moreover, these methods experience significant performance degradation when applied to genuine real-world rainy scenarios. Some researchers have observed the influence of luminance but have not proposed targeted solutions or have even disregarded it. In real rain-incorporated scenes, luminance exerts a noticeable influence on the visual characteristics of the images. The primary aim of this study is to alleviate the challenges related to dataset limitations and performance constraints inherent in real-world image deraining processes. To address this, we introduce a dual unsupervised Luminance-space Pyramid constrained Generative Adversarial Network (LP-GAN) designed to eliminate rain streak artifacts from real-world images. More specifically, the LP-GAN architecture comprises two interrelated loops: the first loop is responsible for mapping rainy input images to their corresponding rain-free counterparts, while the second loop operates in the reverse direction. In addition to the standard generative adversarial network (GAN) structure and the application of consistency constraints that align the initial rainy input with the predicted rainy image, we introduce an innovative luminance constraint. This constraint acts as a guiding mechanism to enhance the synthesis of rain-free images with improved naturalness and heightened contrast. Empirical evaluations conducted on diverse and challenging real-world datasets highlight the superior performance of our proposed model when compared to existing unsupervised deraining methodologies.},
  keywords={Training;Visualization;Computer vision;Rain;Training data;Generative adversarial networks;Task analysis;component;Unpaired Image deraining;Luminance constraint;Generative Adversarial Network},
  doi={10.1109/ICICML60161.2023.10424933},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10985467,
  author={Rathor, Kapil and Ballamwar, Aditya and Selvaraj, Sam and Bhise, Archana},
  booktitle={2025 IEEE International Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation (IATMSI)}, 
  title={Performance analysis of GANs for synthetic histopathology Image generation}, 
  year={2025},
  volume={3},
  number={},
  pages={1-6},
  abstract={The advent of Artificial Intelligence (AI) and Deep Learning (DL) techniques has revolutionized the field of medical image analysis, particularly in histopathology for cancer diagnosis. However, challenges persist, including the scarcity of annotated data for training robust models and the need for stain normalization to mitigate colour variations in histopathological images. This paper proposes a comprehensive approach leveraging Generative Adversarial Networks (GANs) to address these challenges. Specifically, it explores the use of GANs, Conditional GANs (CGANs), and Cyclic GANs for generating synthetic data and performing stain normalization. The study compares traditional methods with GAN-based approaches in terms of image quality metrics such as Fréchet Inception Distance (FID), Structural Similarity Index Metric (SSIM), Peak Signal-to-Noise Ratio (PSNR), Features Similarity Index Matrix (FSIM), and Root Mean Square Error (RMSE). Results indicate that while GANs struggle with unconditional image generation, CGANs and Cyclic GANs offer promising results comparable to traditional methods, even without paired image datasets. This research underscores the efficacy of GAN-based techniques, particularly CGANs, in addressing data scarcity and colour normalization challenges in histopathology image analysis, thus advancing the potential for earlier cancer diagnosis and treatment planning.},
  keywords={Measurement;Deep learning;PSNR;Histopathology;Image synthesis;Planning;Indexes;Medical diagnostic imaging;Cancer;Synthetic data;Deep Learning;Generative Adversial Networks;Conditional GANs;Cycle GANs;Fréchet Inception Distance;Structural Similarity Index Metric;Peak Signal-to-Noise Ratio;Histopathology},
  doi={10.1109/IATMSI64286.2025.10985467},
  ISSN={},
  month={March},}@INPROCEEDINGS{10702235,
  author={Zhao, Feng and Xie, Ke and Wang, Sining and Zhao, Linlin and Wang, Guaiqiang and Wu, Xiaofeng and Cui, Yingbao},
  booktitle={2024 20th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)}, 
  title={Application Prospects of Large-Scale Model Technology in the Power Industry}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Generative lager-scale model technology represented by GPT has become a historic turning point in the development of artificial intelligence, marking the transition of artificial intelligence technology from discriminative to generative. Under the new situation, the human-computer interaction mode has changed from single mode to multi-modal, the application form of artificial intelligence has changed from single to systematic, and the application mode has changed from perceptual intelligence to cognitive intelligence and decision-making intelligence collaboration. The next generation of artificial intelligence led by generative big model technology will have a profound impact on personal life, corporate production and even the entire social operation. Facing the vertical professional field of power grids, using big model technology to achieve a major change in the relationship between human and machine interaction, transform traditional business models, and promote architecture optimization and reshaping can be applied on a large scale in the power industry, becoming a new wave of digital transformation of power grids.},
  keywords={Systematics;Computational modeling;Transforms;Production;Turning;Power industry;Power grids;Artificial intelligence;Optimization;Next generation networking;GPT;Large Model Techniques;Power Industry},
  doi={10.1109/ICNC-FSKD64080.2024.10702235},
  ISSN={},
  month={July},}@ARTICLE{10807136,
  author={Hu, Changhui and Hu, Yin and Xu, Lintao and Guo, Yanyong and Cai, Ziyun and Jing, Xiaoyuan and Liu, Pan},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={JTE-CFlow for Low-Light Enhancement and Zero-Element Pixels Restoration With Application to Night Traffic Monitoring Images}, 
  year={2025},
  volume={26},
  number={3},
  pages={3755-3770},
  abstract={We observe that the low-light RGB images, as well as night traffic monitoring (NTM) images, contain lots of color pixels with zeros caused by the low-light, which means that the low-light images suffer both information weakness and information loss of zero-element pixels. In this paper, we propose a novel flow-based generative method JTE-CFlow for low-light image enhancement, which consists of a joint-attention transformer based conditional encoder (JTE) and a map-wise cross affine coupling flow (CFlow). Specifically, JTE executes short-range and long-range operations by RRDBs (i.e., residual-in-residual dense blocks) and JATs (i.e., joint-attention transformer blocks) in series connection. JAT achieves weak information amplification and information loss restoration of zero-element pixels by the integration of self-attention and specific-attention with sharing the same value vectors, where the query and key vectors of specific-attention are from the zero-map feature of the low-light image. On the other hand, CFlow develops a map-wise cross affine coupling (MCAC) layer to perform cross learning for the flow feature, and a multiplication coupling network (MCN) to learn the transformation parameters of MCAC. JTE-CFlow learns to map the subtraction of outputs of CFlow and JTE (i.e., the residual code) into a standard normal distribution, and the inverse network of CFlow takes the latent feature of the low-light image as its input to infer the enhanced image. Experiments show that JTE-CFlow outperforms most SOTA methods on 7 mainstream low-light datasets with the same architecture, and can be applied to enhance NTM images. The source code and pre-trained models are available at https://github.com/NJUPT-IPR-HuYin/JTE-CFlow.},
  keywords={Couplings;Lighting;Image restoration;Image color analysis;Transformers;Brightness;Image enhancement;Vectors;Training;Signal to noise ratio;Low-light image enhancement;joint-attention transformer;map-wise cross affine coupling;flow-based generative model},
  doi={10.1109/TITS.2024.3510832},
  ISSN={1558-0016},
  month={March},}@ARTICLE{9359495,
  author={Kim, Cheolhyeong and Park, Seungtae and Hwang, Hyung Ju},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Local Stability of Wasserstein GANs With Abstract Gradient Penalty}, 
  year={2022},
  volume={33},
  number={9},
  pages={4527-4537},
  abstract={The convergence of generative adversarial networks (GANs) has been studied substantially in various aspects to achieve successful generative tasks. Ever since it is first proposed, the idea has achieved many theoretical improvements by injecting an instance noise, choosing different divergences, penalizing the discriminator, and so on. In essence, these efforts are to approximate a real-world measure with an idle measure through a learning procedure. In this article, we provide an analysis of GANs in the most general setting to reveal what, in essence, should be satisfied to achieve successful convergence. This work is not trivial since handling a converging sequence of an abstract measure requires a lot more sophisticated concepts. In doing so, we find an interesting fact that the discriminator can be penalized in a more general setting than what has been implemented. Furthermore, our experiment results substantiate our theoretical argument on various generative tasks.},
  keywords={Dynamical systems;Gallium nitride;Optimization;Convergence;Q measurement;Heuristic algorithms;Generators;Abstract measure;gradient penalty;local stability;measure-valued differentiation (MVD);Wasserstein generative adversarial network (WGAN)},
  doi={10.1109/TNNLS.2021.3057885},
  ISSN={2162-2388},
  month={Sep.},}@ARTICLE{10278111,
  author={Romanelli, Fabrizio and Martinelli, Francesco},
  journal={IEEE Access}, 
  title={Synthetic Sensor Measurement Generation With Noise Learning and Multi-Modal Information}, 
  year={2023},
  volume={11},
  number={},
  pages={111765-111788},
  abstract={Deep learning has transformed data generation, particularly in creating synthetic sensor data. This capability is invaluable in fields like autonomous driving, robotics, and computer science. To achieve this, we train models using real data, enabling them to replicate sensor data closely. These models introduce variations and noise, enhancing diversity and realism. Prominent techniques, including generative adversarial networks (GANs), variational autoencoders (VAEs), and recurrent neural networks (RNNs), excel in generating synthetic sensor data. Our paper focuses on Autoregressive Convolutional Recurrent Neural Networks (CRNN) for Multivariate Time Series Prediction. We incorporate Denoising Autoencoders (DAE) to mimic real-world noise characteristics. Our model is trained and validated using Ultra Wide Band (UWB) and Ultra High-Frequency Radio Frequency Identification (UHF-RFID) sensor data. It integrates sensor measurements and diverse information sources to produce synthetic data complementing real-world data. While demonstrated with UHF-RFID and UWB sensors, these techniques extend to industrial automation, healthcare and environmental monitoring. While our methodology exhibits broad potential, we present practical demonstrations with UHF-RFID and UWB sensors. Our deep neural network model allows researchers to construct datasets for algorithm validation, eliminating the need for costly and time-consuming data collection.},
  keywords={Robot sensing systems;Data models;Synthetic data;Deep learning;Recurrent neural networks;Artificial neural networks;Robots;Convolutional neural networks;Artificial neural networks;Long short term memory;Machine learning;Convolutional neural networks (CNNs);deep neural networks (DNNs);denoising autoencoder (DAE);long short-term memory (LSTM);artificial neural networks (ANNs);machine learning (ML)},
  doi={10.1109/ACCESS.2023.3323038},
  ISSN={2169-3536},
  month={},}@INBOOK{10951385,
  author={Rashidi, Sol},
  booktitle={Your AI Survival Guide: Scraped Knees, Bruised Elbows, and Lessons Learned from Real-World AI Deployments}, 
  title={How to Start}, 
  year={2024},
  volume={},
  number={},
  pages={37-103},
  abstract={Summary <p>The success of our AI project has to do with three things: preparation, people, and perseverance. This chapter discusses a six&#x2010;phase operational framework; after introducing each phase, it discusses how to exactly approach each of the six phases and what needs to be done in each phase. To start, our AI strategy is all about mapping our present state to a desired state, using AI as the accelerator in achieving that future state. This serves as a primer to help us and our organization stay focused while helping uncomplicate what may appear complicated. It will connect us to a purpose and align our organization, its current maturity, its mindset, and its momentum to act. For an AI project to be successful, the composition and quality of a stakeholder will really make a difference for us if we're in a highly political or sensitive culture.</p>},
  keywords={Artificial intelligence;Companies;Generative AI;Reviews;Knee;Elbow;Documentation;Sequential analysis;Resilience;Planning},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394272655},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951385},}@INPROCEEDINGS{9671177,
  author={Jayasekera, Dinushe and Alwis, Hasini and Dissanayaka, Harshana and Mudalinayake, Rashmika and Piyawardana, Vijani and Pulasinghe, Koliya},
  booktitle={2021 3rd International Conference on Advancements in Computing (ICAC)}, 
  title={ASD Screening for Toddlers via Physical Interpretation through Advanced AI}, 
  year={2021},
  volume={},
  number={},
  pages={128-133},
  abstract={Autism Spectrum Disorders (ASD) are generally causing challenges for significant communication, social interaction, and behavioral patterns to elderly people and children. Providing early treatments can make a huge advancement in the lives of children. Meanwhile, there is a limited number of systems to screen and identify ASD children. This research project is about developing a set of tools bonding together to one system called "AI - Bot Simon" to screen kids with ASD by filling the gap. In the system development process mainly, Audio, Facial expressions, Gestures, and the Gates of a targeted group of children are considered for screening. Since the target group is 6 months to 4 years, they are in early language development age. On the technical side of view Machine Learning (ML) and Deep Learning (DL) with Neural Networks (NN) are used for advanced screening and monitoring for automation of the process. In the last step of the development, all the outputs or information gathered from each tool or model, processed, analyzed, and provided to the users of the system by an Artificial Intelligence (AI) bot implemented with a web application and a mobile application whether children are suffering from ASD or not.},
  keywords={Autism;Pediatrics;Artificial neural networks;Logic gates;Predictive models;Data models;Mobile applications;Autism Spectrum Disorders (ASD);Machine Learning (ML);Deep Learning (DL);Neural Networks (NN);Artificial Intelligence (AI)},
  doi={10.1109/ICAC54203.2021.9671177},
  ISSN={},
  month={Dec},}@ARTICLE{10731562,
  author={Zhou, Guoliang and Liu, Yijia and Yan, Zheng and Gelenbe, Erol},
  journal={IEEE Consumer Electronics Magazine}, 
  title={Is ChatGPT Trustworthy Enough? A Review}, 
  year={2025},
  volume={14},
  number={5},
  pages={28-39},
  abstract={ChatGPT, as an advanced model that seamlessly integrates into diverse digital interactions, shows great potential to enhance the performance of consumer technology and reshape its landscape. The critical question of its trustworthiness and associated challenges becomes increasingly prominent. However, the literature still lacks a thorough review to study its trust. This comprehensive review explores whether ChatGPT is trustworthy enough by navigating the multifaceted realm of large language models, placing a significant focus on its exemplar model, ChatGPT. Our exploration traverses the complex interplay of factors impacting user trust, including trust in ChatGPT itself and trust in its utilization and dissemination. By delving into insightful perspectives on the ChatGPT trustworthiness regarding a set of evaluation criteria, including fundamental properties, subjective properties, and security and privacy, we find that ChatGPT is far from trustworthy based on related literature review. This article sheds light on the weakness of ChatGPT trust and provides the trajectory of future development in the realm of large language models.},
  keywords={Chatbots;Consumer electronics;Artificial intelligence;Surveys;Reliability;Security;Data models;Accuracy;Ethics;Generative AI;Trusted computing},
  doi={10.1109/MCE.2024.3485257},
  ISSN={2162-2256},
  month={Sep.},}@INBOOK{10954211,
  author={Sharma, Ashok and Singh, Parveen and Dar, Gowhar},
  booktitle={Data Analytics in Bioinformatics: A Machine Learning Perspective}, 
  title={Artificial Intelligence and Machine Learning for Healthcare Solutions}, 
  year={2021},
  volume={},
  number={},
  pages={281-291},
  abstract={Summary <p>Trends of teaching and learning has changed its shape from offline teaching to online teaching as full mode and physical mode of teaching may become substitution of academic keeping in view the pandemic covid&#x2010;19.</p> <p>Data science has become part of parcel of our daily life and most of the technical apps we are using contains machine Learning algorithms and helps us in many ways.</p> <p>With rising conditions, artificial intelligence will be the most prominent transformative technology and enabler for society in the present era. here is no uncertainty that AI and analogous frameworks are built to change global efficiency, working habits, and lifestyles and support healthcare, Pharma Industry and Transformation in diagnosis process, disease treatment and early identification of symptoms has been fuelled machine learning techniques and tools such as Generative Adversarial Networks (GAN), Deep Convolutional Networks, Deep Reinforcement Learning (DRL), Gradient&#x2010;boosted&#x2010;tree models (GBM), etc. MRI and other sophisticated imaging systems immensely used for neural disorders, cancer diagnostics. In this chapter we are discussing various resources of medical datasets which can be used for diagnosis of dementia with the usage of machine learning approaches. We are presenting how various machine learning approaches can be useful in early diagnosis of many diseases and explained where machine learning and deep learning can be used on electronically stored medical data.</p> <p>Recent developments are achieved in what way machine learning can be applicable in multi&#x2010;disciplinary research areas. The main emphasis of this chapter is to elaborate on the applicability of machine learning in the domain of healthcare. In the past, there had been substantial signs of progress in the way where machine learning can apply in innumerable research and industries. This chapter deliberates the prospect of using machine learning technologies in the healthcare sector and sketches several industry ingenuities implementing machine learning initiatives.</p>},
  keywords={Medical services;Machine learning;Costs;Medical diagnostic imaging;Industries;Economic indicators;Bioinformatics;Unsupervised learning;Machine learning algorithms;Hospitals},
  doi={10.1002/9781119785620.ch11},
  ISSN={},
  publisher={Wiley},
  isbn={9781119785613},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10954211},}@INPROCEEDINGS{10203358,
  author={Tao, Ming and Bao, Bing-Kun and Tang, Hao and Xu, Changsheng},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={GALIP: Generative Adversarial CLIPs for Text-to-Image Synthesis}, 
  year={2023},
  volume={},
  number={},
  pages={14214-14223},
  abstract={Synthesizing high-fidelity complex images from text is challenging. Based on large pretraining, the autoregressive and diffusion models can synthesize photo-realistic images. Although these large models have shown notable progress, there remain three flaws. 1) These models require tremendous training data and parameters to achieve good performance. 2) The multi-step generation design slows the image synthesis process heavily. 3) The synthesized visual features are challenging to control and require delicately designed prompts. To enable high-quality, efficient, fast, and controllable text-to-image synthesis, we propose Generative Adversarial CLIPs, namely GALIP. GALIP leverages the powerful pretrained CLIP model both in the discriminator and generator. Specifically, we propose a CLIP-based discriminator. The complex scene understanding ability of CLIP enables the discriminator to accurately assess the image quality. Furthermore, we propose a CLIP-empowered generator that induces the visual concepts from CLIP through bridge features and prompts. The CLIP-integrated generator and discriminator boost training efficiency, and as a result, our model only requires about 3% training data and 6% learnable parameters, achieving comparable results to large pretrained autoregressive and diffusion models. Moreover, our model achieves ~120×faster synthesis speed and inherits the smooth latent space from GAN. The extensive experimental results demonstrate the excellent performance of our GALIP. Code is available at https://github.com/tobran/GALIP.},
  keywords={Training;Visualization;Image synthesis;Computational modeling;Training data;Process control;Generators;Image and video synthesis and generation},
  doi={10.1109/CVPR52729.2023.01366},
  ISSN={2575-7075},
  month={June},}@ARTICLE{10177704,
  author={Crothers, Evan N. and Japkowicz, Nathalie and Viktor, Herna L.},
  journal={IEEE Access}, 
  title={Machine-Generated Text: A Comprehensive Survey of Threat Models and Detection Methods}, 
  year={2023},
  volume={11},
  number={},
  pages={70977-71002},
  abstract={Machine-generated text is increasingly difficult to distinguish from text authored by humans. Powerful open-source models are freely available, and user-friendly tools that democratize access to generative models are proliferating. ChatGPT, which was released shortly after the first edition of this survey, epitomizes these trends. The great potential of state-of-the-art natural language generation (NLG) systems is tempered by the multitude of avenues for abuse. Detection of machine-generated text is a key countermeasure for reducing the abuse of NLG models, and presents significant technical challenges and numerous open problems. We provide a survey that includes 1) an extensive analysis of threat models posed by contemporary NLG systems and 2) the most complete review of machine-generated text detection methods to date. This survey places machine-generated text within its cybersecurity and social context, and provides strong guidance for future work addressing the most critical threat models. While doing so, we highlight the importance that detection systems themselves demonstrate trustworthiness through fairness, robustness, and accountability.},
  keywords={Surveys;Threat modeling;Artificial intelligence;Transformers;Natural languages;Text detection;Information integrity;Artificial intelligence;cybersecurity;disinformation;generative AI;large language models;machine learning;text generation;threat modeling;transformer;trustworthy AI},
  doi={10.1109/ACCESS.2023.3294090},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9878940,
  author={Wang, Wentao and Niu, Li and Zhang, Jianfu and Yang, Xue and Zhang, Liqing},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Dual-path Image Inpainting with Auxiliary GAN Inversion}, 
  year={2022},
  volume={},
  number={},
  pages={11411-11420},
  abstract={Deep image inpainting can inpaint a corrupted image using a feed-forward inference, but still fails to handle large missing area or complex semantics. Recently, GAN inversion based inpainting methods propose to leverage semantic information in pretrained generator (e.g., StyleGAN) to solve the above issues. Different from feed-forward methods, they seek for a closest latent code to the corrupted image and feed it to a pretrained generator. However, inferring the latent code is either time-consuming or inaccurate. In this paper, we develop a dual-path inpainting network with inversion path and feed-forward path, in which inversion path provides auxiliary information to help feed-forward path. We also design a novel deformable fusion module to align the feature maps in two paths. Experiments on FFHQ and LSUN demonstrate that our method is effective in solving the aforementioned problems while producing more realistic results than state-of-the-art methods.},
  keywords={Computer vision;Codes;Semantics;Generative adversarial networks;Generators;Pattern recognition;Feeds;Image and video synthesis and generation},
  doi={10.1109/CVPR52688.2022.01113},
  ISSN={2575-7075},
  month={June},}@ARTICLE{10147285,
  author={Hao, Xiaoyang and Feng, Zhixi and Liu, Ruoyu and Yang, Shuyuan and Jiao, Licheng and Luo, Rong},
  journal={IEEE Internet of Things Journal}, 
  title={Contrastive Self-Supervised Clustering for Specific Emitter Identification}, 
  year={2023},
  volume={10},
  number={23},
  pages={20803-20818},
  abstract={Specific emitter identification (SEI) is crucial for attacking and defending Internet of Things (IoT) devices in untrusted scenarios or battlefield environments. However, existing SEI methods usually require annotation information, which is often unavailable in noncooperative communications and untrusted scenarios. In this article, we propose a signal contrastive self-supervised clustering (SCSC) method for unsupervised SEI applications. First, we propose SCSC with 1-D fingerprint pyramid feature extractor (1D-FPFE) for obtaining hierarchical subtle features of emitter signals. Then, we propose a bit-pulse selection (BPS) strategy and several signal data augmentation methods. By constructing signal positive and negative instance pairs through data augmentation, our approach generates cluster preference representations in a contrastive self-supervised learning manner. Extensive experimental results based on communication burst emitter dataset show that SCSC achieves an accuracy improvement of about 26% over the current best communication signal clustering algorithm. Moreover, SCSC also exhibits good performance and generalization for 30 emitter clustering and few-shot unlabeled signal clustering.},
  keywords={Feature extraction;Internet of Things;Fingerprint recognition;Task analysis;Generative adversarial networks;Support vector machines;Long short term memory;Actual burst emitter;signal clustering;signal contrastive self-supervised clustering (SCSC);signal data augmentation;specific emitter identification (SEI)},
  doi={10.1109/JIOT.2023.3284428},
  ISSN={2327-4662},
  month={Dec},}@ARTICLE{10705335,
  author={Wei, Xiulan and Zhang, Yong and Wang, Shaofan and Zhao, Xia and Hu, Yongli and Yin, Baocai},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Self-Attention Graph Convolution Imputation Network for Spatio-Temporal Traffic Data}, 
  year={2024},
  volume={25},
  number={12},
  pages={19549-19562},
  abstract={Missing data in time series is a pervasive problem that serves as obstacles for subsequent traffic data analysis. Consequently, extensive research works have been conducted on traffic missing data imputation tasks. The state-of-the-art traffic data imputation models are mostly based on recurrent neural networks. However, these methods belong to autoregressive models which are highly susceptible to error propagation. The attention-based methods are non-autoregressive models that can avoid compounding errors and help achieve better imputation quality. Moreover, the attention-based methods in now widely applied and have achieved remarkable results, whereas their application on traffic data imputation is still limited. Thus, this paper proposes Self-Attention Graph Convolution Imputation Network (SAGCIN) for spatio-temporal traffic data. To ensure the accuracy of data imputation, it is necessary to fully capture the spatio-temporal contextual information of traffic data to impute missing values. To this end, the SAGCIN model incorporates self-attention mechanism with diffusion graph convolution network. The SAGCIN model consists of two spatio-temporal blocks with a spatio-temporal encoder and an imputation decoder. The encoder learns spatio-temporal representations specialized for traffic data imputation tasks. Based on the learned representation, the decoder performs two stages of imputation operator for missing data. A joint-optimization training approach of imputation and reconstruction is introduced for SAGCIN to perform missing value imputation for traffic data. Empirical results demonstrate that SAGCIN model outperforms state-of-the-art methods in imputation tasks on relevant real-world benchmarks.},
  keywords={Imputation;Convolutional neural networks;Data models;Time series analysis;Interpolation;Deep learning;Correlation;Learning systems;Transportation;Generative adversarial networks;Traffic data;missing values;imputation model;diagonally-masked self-attention;diffusion graph convolution},
  doi={10.1109/TITS.2024.3461735},
  ISSN={1558-0016},
  month={Dec},}@INPROCEEDINGS{11094900,
  author={Chen, Zilong and Wang, Yikai and Sun, Wenqiang and Wang, Feng and Chen, Yiwen and Liu, Huaping},
  booktitle={2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={MeshGen: Generating PBR Textured Mesh with Render-Enhanced Auto-Encoder and Generative Data Augmentation}, 
  year={2025},
  volume={},
  number={},
  pages={5835-5848},
  abstract={In this paper, we introduce MeshGen, an advanced image-to-3D pipeline that generates high-quality 3D meshes with detailed geometry and physically based rendering (PBR) textures. Addressing the challenges faced by existing 3D native diffusion models, such as suboptimal auto-encoder performance, limited controllability, poor generalization, and inconsistent image-based PBR texturing, Mesh-Gen employs several key innovations to overcome these limitations. We pioneer a render-enhanced point-to-shape auto-encoder that compresses meshes into a compact latent space by designing perceptual optimization with ray-based regularization. This ensures that the 3D shapes are accurately represented and reconstructed to preserve geometric details within the latent space. To address data scarcity and image-shape misalignment, we further propose geometric augmentation and generative rendering augmentation techniques, which enhance the model’s controllability and gen-eralization ability, allowing it to perform well even with limited public datasets. For the texture generation, Mesh-Gen employs a reference attention-based multi-view Con-trolNet for consistent appearance synthesis. This is further complemented by our multi-view PBR decomposer that estimates PBR components and a UV inpainter that fills invisible areas, ensuring a seamless and consistent texture across the 3D mesh. Our extensive experiments demonstrate that MeshGen largely outperforms previous methods in both shape and texture generation, setting a new standard for the quality of 3D meshes generated with PBR textures.},
  keywords={Technological innovation;Three-dimensional displays;Shape;Pipelines;Aerospace electronics;Rendering (computer graphics);Controllability;Pattern recognition;Standards;Optimization},
  doi={10.1109/CVPR52734.2025.00548},
  ISSN={2575-7075},
  month={June},}@ARTICLE{10857960,
  author={Lin, Xuanqi and Zhang, Yong and Wang, Shun and Hu, Yongli and Yin, Baocai},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={OST-HGCN: Optimized Spatial-Temporal Hypergraph Convolution Network for Trajectory Prediction}, 
  year={2025},
  volume={26},
  number={3},
  pages={3056-3070},
  abstract={Pedestrian trajectory prediction is a key component for various applications that involve human and vehicle interactions, such as autonomous driving, traffic management and smart city planning. Existing methods based on graph neural networks have limited ability to capture group interactions and precisely model complex associations among multi-agents. To solve these problems, we propose OST-HGCN, an optimized hypergraph convolutional network. It models multi-agent trajectory interactions from both temporal and spatial perspectives using hypergraph structures, and optimizes the spatio-temporal hypergraph structure to enable fine-grained analysis of multi-agent trajectory motion intentions and high-order interactions. We employ OST-HGCN to a CVAE-based prediction framework, and use the optimized hypergraph structure to predict multi-agent plausible trajectories. We conduct extensive experiments on four real trajectory prediction datasets of NBA, NFL, SDD and ETH-UCY, and verify the effectiveness of the proposed OST-HGCN.},
  keywords={Trajectory;Predictive models;Pedestrians;Optimization;Generative adversarial networks;Convolutional neural networks;Market research;Long short term memory;Data models;Accuracy;Trajectory prediction;multi-agent interaction modeling;hypergraph convolution network;hypergraph structure optimization},
  doi={10.1109/TITS.2025.3529666},
  ISSN={1558-0016},
  month={March},}@INPROCEEDINGS{5354411,
  author={Burbidge, Robert and Walker, Joanne H. and Wilson, Myra S.},
  booktitle={2009 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={Grammatical evolution of a robot controller}, 
  year={2009},
  volume={},
  number={},
  pages={357-362},
  abstract={An autonomous mobile robot requires an onboard controller that allows it to perform its tasks for long periods in isolation. One possibility is for the robot to adapt to its environment using some form of artificial intelligence. Evolutionary techniques such as genetic programming (GP) offer the possibility of automatically programming the controller based on the robot's experience of the world. Grammatical evolution (GE) is a recent evolutionary algorithm that has been successfully applied to various problems, particularly those for which GP has been successful. We present a method for applying GE to autonomous robot control and evaluate it in simulation for the Khepera robot.},
  keywords={Robot control;Genetic programming;Robotics and automation;Automatic control;Mobile robots;Intelligent robots;Artificial intelligence;Automatic programming;Robot programming;Evolutionary computation},
  doi={10.1109/IROS.2009.5354411},
  ISSN={2153-0866},
  month={Oct},}@ARTICLE{10146278,
  author={Osipov, Alexey and Pleshakova, Ekaterina and Bykov, Artem and Kuzichkin, Oleg and Surzhik, Dmitry and Suvorov, Stanislav and Gataullin, Sergey},
  journal={IEEE Access}, 
  title={Machine Learning Methods Based on Geophysical Monitoring Data in Low Time Delay Mode for Drilling Optimization}, 
  year={2023},
  volume={11},
  number={},
  pages={60349-60364},
  abstract={The purpose of the article is to create an effective method to monitor the state of the drill string and the bit without interfering with the drilling process itself in low-time delay mode. For continuous monitoring of the well drilling process, an experimental setup was developed that operates on the basis of the use of the phase-metric method of control. Any movement of the bit causes a change in the electrical characteristics of the probing signal. To obtain a stable signal from a bit immersion depth of up to 250 m, a frequency of probing electrical signals of 166 Hz and an amplitude of up to 500 V were used; sampling rate (analog-to-digital converter) ADC - 10101 Hz. To identify the state of the drill string and the bit according to the graphs of dependences of changes in the electrical characteristics of the probing signal on time, the authors of the article investigated a number of deep learning methods, based on the results of the research, a line of capsule neural network (CapsNet) methods was selected. The authors have developed two modifications of 1D-CapsNet and Windowed Fourier Transform (WFT) - 2D-CapsNet. To identify the transition between two rock layers with different properties, WFT-2D-CapsNet showed an accuracy of 99%, which is 2-3% higher than the results of modern rock studies based on measurement-while-drilling (MWD) and logging-while-drilling (LWD) methods. The WFT-2D-CapsNet method unambiguously detects self-oscillations in the drill string and detects the good condition of the bit with an accuracy of 99%.},
  keywords={Drilling;Vibrations;Robots;Generative adversarial networks;Monitoring;Process control;Three-dimensional displays;Artificial intelligence;Geophysics;Robotics;artificial intelligence;neural networks;engineering;CapsNet;geophysical monitoring;drilling optimization},
  doi={10.1109/ACCESS.2023.3284030},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10890295,
  author={Chen, Zhengyang and Han, Bing and Wang, Shuai and Jiang, Yidi and Qian, Yanmin},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Flow-TSVAD: Target-Speaker Voice Activity Detection via Latent Flow Matching for Speaker Diarization}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Speaker diarization is typically considered as a discriminative task, using discriminative approaches to produce fixed diarization results. In this paper, we explore for the first time the use of neural network-based generative methods for speaker diarization. We implement a Flow-Matching (FM) based generative algorithm within the sequenceto-sequence target speaker voice activity detection (Seq2Seq-TSVAD) diarization system. Our experiments reveal that applying the generative method directly to the original binary label sequence space of the TS-VAD output is ineffective. To address this issue, we propose mapping the binary label sequence into a dense latent space before applying the generative algorithm, and our proposed Flow-TSVAD method can significantly outperform the traditional Seq2Seq-TSVAD system. Additionally, we observe that the FM algorithm converges rapidly during the inference stage, only requiring two inference steps to achieve promising results. Moreover, as a generative model, Flow-TSVAD allows for sampling different diarization results by running the model multiple times, so the ensemble system combining the results from various sampling instances can further boost the diarization performance.},
  keywords={Voice activity detection;Frequency modulation;Computational modeling;Signal processing algorithms;Signal processing;Inference algorithms;Acoustics;Computational efficiency;Speaker Diarization;TSVAD;Generative Method;Flow Matching},
  doi={10.1109/ICASSP49660.2025.10890295},
  ISSN={2379-190X},
  month={April},}@ARTICLE{9631874,
  author={Li, Hongchao and Lin, Xianmin and Zheng, Aihua and Li, Chenglong and Luo, Bin and He, Ran and Hussain, Amir},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, 
  title={Attributes Guided Feature Learning for Vehicle Re-Identification}, 
  year={2022},
  volume={6},
  number={5},
  pages={1211-1221},
  abstract={Vehicle Re-ID has recently attracted enthusiastic attention due to its potential applications in smart city and urban surveillance. However, it suffers from large intra-class variation caused by view variations and illumination changes, and inter-class similarity especially for different identities with a similar appearance. To handle these issues, in this paper, we propose a novel deep network architecture, which guided by meaningful attributes including camera views, vehicle types and colors for vehicle Re-ID. In particular, our network is end-to-end trained and contains three subnetworks of deep features embedded by the corresponding attributes. For network training, we annotate the view labels on the VeRi-776 dataset. Note that one can directly adopt the pre-trained view (as well as type and color) subnetwork on the other datasets with only ID information, which demonstrates the generalization of our model. Extensive experiments on the benchmark datasets VeRi-776 and VehicleID suggest that the proposed approach achieves the promising performance and yields to a new state-of-the-art for vehicle Re-ID.},
  keywords={Feature extraction;Cameras;Color;Image color analysis;Task analysis;Training;Semantics;Attributes;deep features;vehicle re-identification},
  doi={10.1109/TETCI.2021.3127906},
  ISSN={2471-285X},
  month={Oct},}@ARTICLE{9051729,
  author={He, Lianhai and Peng, Bo and Yang, Tianlan and Jiang, Jingfeng},
  journal={IEEE Access}, 
  title={An Application of Super-Resolution Generative Adversary Networks for Quasi-Static Ultrasound Strain Elastography: A Feasibility Study}, 
  year={2020},
  volume={8},
  number={},
  pages={65769-65779},
  abstract={In this work, a super-resolution approach based on generative adversary network (GAN) was used to interpolate (up-sample) ultrasound radio-frequency (RF) echo data along the lateral (perpendicular to the acoustic beam direction) direction before motion estimation. Our primary objective was to investigate the feasibility of using a GAN-based super-solution approach to improve lateral resolution in the RF data as a means of improving strain image quality in quasi-static ultrasound strain elastography (QUSE). Unlike natural scene photographs, axial (parallel to the acoustic beam direction) resolution is significantly higher than that of lateral resolution in ultrasound RF data. To better handle RF data, we first modified a super-resolution generative adversary network (SRGAN) model developed by the computer vision community. We named the modified SRGAN model as super-resolution radio-frequency neural network (SRRFNN) model. Our preliminary experiments showed that, compared with axial strain elastograms obtained using the original ultrasound RF data, axial strain elastograms using ultrasound RF data up-sampled by the proposed SRRFNN model were improved. Based on the Wilcoxon rank-sum tests, such improvements were statistically significant ($p <; 0.05$ ) for large deformation (3-5%). Also, the proposed SRRFNN model outperformed a commonly-used method (i.e. bi-cubic interpolation used in MATLAB [Mathworks Inc., MA, USA]) in terms of improving axial strain elastograms. We concluded that applying the proposed (SRRFNN) model was feasible and good-quality strain elastography data could be obtained in in vivo tumor-bearing breast ultrasound data.},
  keywords={Radio frequency;Ultrasonic imaging;Mathematical model;Strain;Data models;Gallium nitride;Generative adversarial network;motion tracking;super-resolution;quasi-static ultrasound strain elastography},
  doi={10.1109/ACCESS.2020.2984733},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9699339,
  author={Oliveira, Nuno and Sousa, Norberto and Oliveira, Jorge and Praça, Isabel},
  booktitle={2021 14th International Conference on Security of Information and Networks (SIN)}, 
  title={Anomaly Detection in Cyber-Physical Systems: Reconstruction of a Prediction Error Feature Space}, 
  year={2021},
  volume={1},
  number={},
  pages={1-5},
  abstract={Cyber-physical systems are infrastructures that use digital information such as network communications and sensor readings to control entities in the physical world. Many cyber-physical systems in airports, hospitals and nuclear power plants are regarded as critical infrastructures since a disruption of its normal functionality can result in negative consequences for the society. In the last few years, some security solutions for cyber-physical systems based on artificial intelligence have been proposed. Nevertheless, knowledge domain is required to properly setup and train artificial intelligence algorithms. Our work proposes a novel anomaly detection framework based on error space reconstruction, where genetic algorithms are used to perform hyperparameter optimization of machine learning methods. The proposed method achieved an F1-score of 87.89% in the SWaT dataset.},
  keywords={Support vector machines;Machine learning algorithms;Machine learning;Cyber-physical systems;Predictive models;Prediction algorithms;Security;Cyber-physical systems;anomaly detection;security;artificial intelligence;convolutional neural networks},
  doi={10.1109/SIN54109.2021.9699339},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11113078,
  author={Wang, Hanchen and Cheng, Dawei and Zhang, Ying and Zhang, Wenjie},
  booktitle={2025 IEEE 41st International Conference on Data Engineering (ICDE)}, 
  title={AIGC for Graphs: Current Techniques and Future Trends}, 
  year={2025},
  volume={},
  number={},
  pages={4504-4508},
  abstract={As artificial intelligence technology continues to advance, artificial intelligence-generated content (AIGC) has begun to evolve towards generating complex and structured data, particularly graph data. As an important topic in many fields such as database, data mining, and machine learning, graph generation holds significant value for simulating complex relationships between entities and has shown vast potential for applications in fields such as molecular generation, drug design, and material discovery. In this context, AIGC technology for graph generation has received widespread attention. This tutorial outlines the latest developments in AIGC for graph generation. We categorize existing methods into two main types according to their objectives and motivations: similarity-based generation and function-driven generation. We first provide an overview of AIGC models for graph generation. Then, we conduct a thorough review of the existing works. Finally, we explore the current trends and future directions, discussing potential ways to integrate database and machine learning techniques for graph generation.},
  keywords={Drugs;Databases;Reviews;Machine learning;Tutorials;Market research;Data engineering;Data mining;Artificial Intelligence Generated Content;Graph Generation;Graph Analytics},
  doi={10.1109/ICDE65448.2025.00340},
  ISSN={2375-026X},
  month={May},}@INBOOK{10955665,
  author={Siva Kumar, Ram Shankar and Anderson, Hyrum and Schneier, Bruce},
  booktitle={Not with a Bug, But with a Sticker: Attacks on Machine Learning Systems and What To Do About Them}, 
  title={Can You Keep a Secret?}, 
  year={2023},
  volume={},
  number={},
  pages={107-132},
  abstract={Summary <p>This chapter presents an excerpt of a conversation between popular podcaster Lex Fridman and Elon Musk, CEO of Tesla, in 2019. Ethan Burris, management professor at the University of Texas at Austin, wrote in Harvard Business Review that there are two kinds of managers. One type tends to think high level, taking a &#x201c;systems approach.&#x201d; The second type is managers who are &#x201c;prevention&#x2010;focused.&#x201d; This framing also coarsely applies to attackers and defenders. The information asymmetry between attackers and defenders is not a phenomenon unique to artificial intelligence (AI). It is a fundamental issue in cybersecurity. With traditional cybersecurity, attackers target coding errors in code written by humans. The vital direction information revealed by the confidence measure of machine learning systems is key for how adversaries attack AI systems.</p>},
  keywords={Artificial intelligence;Software;Neural networks;Codes;Random access memory;Hands;Computer hacking;Computer bugs;Toxicology;Surgery},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781119884903},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10955665},}@INPROCEEDINGS{10205767,
  author={Kaustubh, Kumar and S, Kushala Kumari and M, Kiran},
  booktitle={2023 3rd International Conference on Intelligent Technologies (CONIT)}, 
  title={Visualization and Creation of Image using Processed Dataset and Python Model Architecture}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Due to high data availability, it is difficult to classify/process images with higher speed and accuracy. The generation of semantic and human-face images has been a very important problem in artificial intelligence and computer vision. This project aims to develop a machine learning-based face generator using sketches as input. The training data consists of thousands of images of faces of different races, ages, and genders. The network is trained to learn the spatial relationship between facial features such as the eyes and the nose. The generator network consists of a feature extraction network and an undersampling and oversampling network, both of which use skip connections to reduce the number of layers without affecting network performance. To determine if the created face has the needed characteristics, the discriminator network is built. Experiments show that it can generate a wide range of faces with high fidelity. This work provides a foundation for further applications in various artificial intelligence and computer vision tasks. Compared to state-of-the-art image translation methods, the performance of the proposed network is excellent.},
  keywords={Industries;Computer vision;Video games;Computational modeling;Training data;Machine learning;Transforms;machine learning;artificial intelligence;network;computer vision;performance},
  doi={10.1109/CONIT59222.2023.10205767},
  ISSN={},
  month={June},}@ARTICLE{8892549,
  author={Xu, Ke and Cao, Jiawei and Xia, Kaijian and Yang, Huan and Zhu, Junqing and Wu, Chunying and Jiang, Yizhang and Qian, Pengjiang},
  journal={IEEE Access}, 
  title={Multichannel Residual Conditional GAN-Leveraged Abdominal Pseudo-CT Generation via Dixon MR Images}, 
  year={2019},
  volume={7},
  number={},
  pages={163823-163830},
  abstract={Magnetic resonance (MR) images have distinctive advantages in radiation treatment (RT) planning due to their superior, anatomic and functional information compared with computed tomography (CT). For the RT dose calculation, MR images cannot be directly used because of the lack of electron density information. To address this issue, we propose to generate pseudo-CT (pCT) in terms of multiple matching Dixon MR images to support MR-only RT, particularly in the challenging body section of the abdomen. To this end, we design the dedicated multichannel residual conditional generative adversarial network (MCRCGAN). The significance of our efforts is three-fold: 1) The MCRCGAN organically incorporates multiple theories and techniques, such as multichannel residual network (ResNet) and conditional generative adversarial network (cGAN), which facilitate its more authentic pCT generation than many existing methods. 2) The usage of residual modules effectively deepens the network without performance degradation, and the multichannel ResNet helps to simultaneously capture the substance of images, as extensively as possible, which is implicitly contained in the multiple different MR images of the same subject. 3) Due to the designed dedicated network structure, the MCRCGAN is capable of generating satisfactory pCTs under the condition of limited training data as well as prompt prediction response. Experimental studies on ten patients' paired MR-CT images demonstrate the effectiveness of our proposed MCRCGAN model on both the pCT generation quality and the performance stability.},
  keywords={Generative adversarial networks;Gallium nitride;Computed tomography;Training;Positron emission tomography;Image segmentation;Abdomen;Generative adversarial network (GAN);pseudo-CT;abdomen;deep learning},
  doi={10.1109/ACCESS.2019.2951924},
  ISSN={2169-3536},
  month={},}@INBOOK{11052422,
  author={Bhattacharya, Tathagata and Meka, Harshavardhan and Ponaganti, Srikanth and Vardhan, Peddi Adithya and Mohammad, Irshad Ali},
  booktitle={Imaging Science: Computer Vision, Image and Signal Processing, Pattern Recognition}, 
  title={Chapter 10 Drishti: a generative AI-based application for gesture recognition and execution}, 
  year={2025},
  volume={},
  number={},
  pages={203-236},
  abstract={This study explores the evolution of the inclusive educational tool, now named “Drishti,” a new release of the preceding “Dishari” project. Drishti integrates current technologies, specifically hand gesture detection, and generative AI, to cater to individuals with hearing and speech impairments. Traditional engines like Google frequently overlook the unique accessibility desires of these users, developing barriers to digital engagement. Drishti bridges this gap by using machine learning algorithms and computer vision to interpret hand gestures captured via web cameras, translating them into both sign language and keyword inputs for search engines like Google and Yahoo. The updated version extends the functionality of Dishari by incorporating not only alphabet inputs but also numerical inputs (0-9), delete button gesture, and space button gesture. Generative AI further complements the quest procedure, permitting seamless query inputs through both textual content and gestures. Through an in-depth literature analysis, we list the advancements in gesture recognition and the role of generative AI in improving accessibility, marking Drishti as an enormous step toward empowering people with hearing and speech impairments, to engage with digital platforms more efficiently.},
  keywords={},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9783111436579},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11052422},}@INPROCEEDINGS{9087510,
  author={Islam, Md Shazid and Rahman, Md Saydur and Amin, M Ashraful},
  booktitle={2019 IEEE International Conference on Robotics, Automation, Artificial-intelligence and Internet-of-Things (RAAICON)}, 
  title={Beat Based Realistic Dance Video Generation using Deep Learning}, 
  year={2019},
  volume={},
  number={},
  pages={43-47},
  abstract={Deep learning based feature extraction has enabled us to synchronize audio and body movements. It is a promising research field which has great applications in generating sign language, computer animations as well as dance. Previously, computer generated choreography was limited to just stick figure representation. This paper adds image translation technique in dance generation which produces realistic dance moves. With this technique it is possible to produce dance video of a amateur person dancing like a professional. The mapping of stick figure to realistic image is done using Generative Adversarial Network (GAN). We created our own dataset and after adversarial training reconstructed images have SSIM mean 0.864 and LPIPS mean 0.0168. This method produces realistic dance video which is beat based. Body movement speed varies according to the tempo of music which makes it more relevant to real life dance movement.},
  keywords={Deep Learning;GAN;Image translation;Beat;OpenPose;Pix2pixHD},
  doi={10.1109/RAAICON48939.2019.22},
  ISSN={},
  month={Nov},}@ARTICLE{10802882,
  author={Choi, Hyeon-Beom and Han, Kwon-Hee and Seo, Jeongwook},
  journal={IEEE Access}, 
  title={Normalized Difference Red-Edge Estimation With Modified DiscoGAN Model}, 
  year={2024},
  volume={12},
  number={},
  pages={191661-191669},
  abstract={Vegetation information is important to study the health and productivity of farmlands and forest ecosystems and investigate the types and severity of threats to them. To obtain vegetation information, Normalized Difference Vegetation Index (NDVI) or Normalized Difference Red-Edge (NDRE) is usually used as a single number quantifying vegetation biomass and plant vigor from satellite remote sensing data. Because they indicate different stages of plant growth and focus on different aspects of plant health, the optimal solution for enhancing vegetation information is to use both of them. However, through satellite remote sensing data containing Red, Green, Blue (RGB) and Near-Infrared (NIR) images, we can only calculate the NDVI, not the NDRE that requires the Red-Edge (RE) images. Therefore, in this paper, we propose an NDRE estimation method using the RE images generated from the RGB images by a modified Discover Cross-Domain Relations with Generative Adversarial Networks (DiscoGAN) model. The modified DiscoGAN model was designed by adding some input and hidden layers in generators and discriminators of the original DiscoGAN model to ingest the RGB images with  $256 \times 256 \times 3$  dimension and improve the average Normalized Mean Square Error (NMSE) performance. Experimental results showed that the modified DiscoGAN model outperformed the original DiscoGAN model, obtaining the average NMSE of 0.018 between the real RE images and the generated RE images. Moreover, the NDRE estimation method achieved the average NMSE of 0.074 between the real NDRE values and the NDRE estimates.},
  keywords={Vegetation mapping;Satellites;Normalized difference vegetation index;Estimation;Generators;Spatial resolution;Remote sensing;Network architecture;Training;Reflectivity;DiscoGAN;NDRE;NDVI;red-edge;remote sensing;satellite image},
  doi={10.1109/ACCESS.2024.3517602},
  ISSN={2169-3536},
  month={},}@ARTICLE{9146686,
  author={Yang, Min and Li, Chengming and Shen, Ying and Wu, Qingyao and Zhao, Zhou and Chen, Xiaojun},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Hierarchical Human-Like Deep Neural Networks for Abstractive Text Summarization}, 
  year={2021},
  volume={32},
  number={6},
  pages={2744-2757},
  abstract={Developing an abstractive text summarization (ATS) system that is capable of generating concise, appropriate, and plausible summaries for the source documents is a long-term goal of artificial intelligence (AI). Recent advances in ATS are overwhelmingly contributed by deep learning techniques, which have taken the state-of-the-art of ATS to a new level. Despite the significant success of previous methods, generating high-quality and human-like abstractive summaries remains a challenge in practice. The human reading cognition, which is essential for reading comprehension and logical thinking, is still relatively new territory and underexplored in deep neural networks. In this article, we propose a novel Hierarchical Human-like deep neural network for ATS (HH-ATS), inspired by the process of how humans comprehend an article and write the corresponding summary. Specifically, HH-ATS is composed of three primary components (i.e., a knowledge-aware hierarchical attention module, a multitask learning module, and a dual discriminator generative adversarial network), which mimic the three stages of human reading cognition (i.e., rough reading, active reading, and postediting). Experimental results on two benchmark data sets (CNN/Daily Mail and Gigaword) demonstrate that HH-ATS consistently and substantially outperforms the compared methods.},
  keywords={Task analysis;Cognition;Generative adversarial networks;Generators;Neural networks;Gallium nitride;Syntactics;Abstractive text summarization (ATS);external knowledge base (KB);generative adversarial network;human reading cognition;multitask learning},
  doi={10.1109/TNNLS.2020.3008037},
  ISSN={2162-2388},
  month={June},}@ARTICLE{10061601,
  author={Shi, Guolong and Shen, Xinyi and Xiao, Fuke and He, Yigang},
  journal={IEEE Internet of Things Journal}, 
  title={DANTD: A Deep Abnormal Network Traffic Detection Model for Security of Industrial Internet of Things Using High-Order Features}, 
  year={2023},
  volume={10},
  number={24},
  pages={21143-21153},
  abstract={With the development of blockchain, artificial intelligence, and data mining technology, abnormal network traffic data has become easy to obtain. The traffic detection model detects the traffic patterns in the network to find abnormal traffic that does not conform to the normal traffic law, which has great security significance for Industrial Internet of Things (IIoT) networks and devices in real scenarios. However, previous abnormal detection models rely on expert experience and cannot cope with real-time changes in IIoT scenarios. The manual features cannot be sufficiently representative and adaptive. Moreover, there are few abnormal traffic data in real scenarios, which makes the model unable to fully learn the potential distribution in abnormal data. Therefore, in this work, we propose a deep abnormal network traffic detection model (DANTD) for the security of IIoT using high-order features and novel data augmentation strategies. The DANTD model first adopts a deep convolutional autoencoder to extract effective high-order features to make it more representative. Then, the DANTD model uses generative adversarial networks as data augmentation strategies to enrich the abnormal data, so that the model can fully consider the information of the data distribution. Comprehensive experiments on real IIoT data sets validate the effectiveness of the DANTD model.},
  keywords={Industrial Internet of Things;Data models;Feature extraction;Brain modeling;Computational modeling;Security;Predictive models;Convolutional neural networks;Detection algorithms;Generative adversarial networks;Convolutional neural networks (CNNs);detection model;generative adversarial networks (GANs);Industrial Internet of Things (IIoT)},
  doi={10.1109/JIOT.2023.3253777},
  ISSN={2327-4662},
  month={Dec},}@ARTICLE{10295380,
  author={Li, Pengfei and Zhang, Zhibo and Al-Sumaiti, Ameena Saad and Werghi, Naoufel and Yeun, Chan Yeob},
  journal={IEEE Sensors Journal}, 
  title={A Robust Adversary Detection-Deactivation Method for Metaverse-Oriented Collaborative Deep Learning}, 
  year={2024},
  volume={24},
  number={14},
  pages={22011-22022},
  abstract={Metaverse is trending to create a digital circumstance that can transfer the real world to an online platform supported by large quantities of real-time interactions. Pretrained artificial intelligence (AI) models are demonstrating their increasing capability in aiding the metaverse to achieve an excellent response with negligible delay, and nowadays, many large models are collaboratively trained by various participants in a manner named collaborative deep learning (CDL). However, several security weaknesses can threaten the safety of the CDL training process, which might result in fatal attacks to either the pretrained large model or the local sensitive datasets possessed by an individual entity. In CDL, malicious participants can hide within the major innocent and silently upload deceptive parameters to degenerate the model performance, or they can abuse the downloaded parameters to construct a generative adversarial network (GAN) to acquire the private information of others illegally. To compensate for these vulnerabilities, this article proposes an adversary detection-deactivation method that can limit and isolate the access of potential malicious participants as well as quarantine and disable the GAN attack or harmful backpropagation (BP) of received threatening gradients. A detailed protection analysis has been conducted on a multiview (MV) CDL case, and results show that the protocol can effectively prevent harmful access by heuristic manner analysis and can protect the existing model by swiftly checking received gradients using only one low-cost branch with an embedded firewall.},
  keywords={Generative adversarial networks;Training;Deep learning;Collaboration;Servers;Protocols;Generators;Adversary deactivation;adversary detection;collaborative deep learning (CDL);generative adversarial network (GAN) attack;metaverse;privacy protection},
  doi={10.1109/JSEN.2023.3325771},
  ISSN={1558-1748},
  month={July},}@ARTICLE{9804707,
  author={Wu, Huihuan and Niu, Shuangxia and Zhang, Yunpeng and Zhao, Xing and Fu, Weinong},
  journal={IEEE Journal of Emerging and Selected Topics in Industrial Electronics}, 
  title={Fast Magnetic Field Approximation Method for Simulation of Coaxial Magnetic Gears Using AI}, 
  year={2023},
  volume={4},
  number={1},
  pages={400-408},
  abstract={Artificial intelligence and deep learning have been widely used in recent years to explore the possibility of accelerating computation. However, it has very few applications in magnetic field calculation. This article employs a conditional generative adversarial network (cGAN) to approximate the magnetic field of a coaxial magnetic gear and calculate the magnetic torque through postprocessing. The working principle of magnetic field approximation using cGAN and the training process is introduced in this study. We adopted conditional image-to-image translation technology in cGAN and compared different loss functions and residual structures combinations. Then, we found the best combination, which can accelerate convergence, reduce errors, and improve the generator's performance. Numerical experiments have verified the effectiveness of the proposed cGAN, and the average numerical error can be as small as 1%. At the same time, its speedup ratio is as high as 200 compared to the finite element method.},
  keywords={Magnetic fields;Magnetic gears;Torque;Generative adversarial networks;Generators;Training;Iron;Deep learning;finite element method (FEM);generative adversarial network (GAN);magnetic gear;neural network},
  doi={10.1109/JESTIE.2022.3185558},
  ISSN={2687-9743},
  month={Jan},}@ARTICLE{9682726,
  author={Rong, Chuitian and Li, Xueyan and Sun, Xuemei and Sun, Huabo},
  journal={IEEE Access}, 
  title={Chinese Medicine Prescription Recommendation Using Generative Adversarial Network}, 
  year={2022},
  volume={10},
  number={},
  pages={12219-12228},
  abstract={The theory of traditional Chinese medicine (TCM) is an important part of Chinese culture. In the long history, there are a large number of excellent prescriptions, whose laws have been explored by many studies, but few works directly studied the generation of prescriptions. With the rapid development of deep learning, many applications of text generation using neural networks have emerged. Prescriptions are the doctors’ clinical experience and the results of neural networks also come from the accumulated experience. So, it is very feasible to apply deep learning techniques to the recommendation on TCM prescriptions. GAN and its variants have been applied in text generation recently. It has advantages in many aspects, such as the rapid speed of computation, the update of parameters by back propagation without Markov chain and more real data generation with two-players game. We attempted to know the important attributes of prescriptions and use these contents as the training data for variants of GAN to generate prescriptions. Specifically, we attempted to apply SeqGAN (Sequence Generative Adversarial Nets) and CGAN (Conditional Generative Adversarial Nets) to prescription generations. By underlying the knowledge of TCM, the prescriptions with different characteristics can be successfully generated. In the experiments, we conducted the comparative evaluations on the original data with other models. The results showed that applications in the innovation of prescription sequence generations have certain feasibility and significance, even can provide some reference values for the innovation of TCM.},
  keywords={Generative adversarial networks;Deep learning;Training;Neural networks;Games;Drugs;Logic gates;TCM;prescription recommendation;GAN;SeqGAN;CGAN},
  doi={10.1109/ACCESS.2022.3143797},
  ISSN={2169-3536},
  month={},}@ARTICLE{10847825,
  author={Wang, Zhihong and Leng, Supeng and Zhang, Hanwen and Yuen, Chau},
  journal={IEEE Internet of Things Journal}, 
  title={Deep Semantic Communication for Knowledge Sharing in Internet of Vehicles}, 
  year={2025},
  volume={12},
  number={12},
  pages={19202-19214},
  abstract={Along with the development of intelligent transportation system (ITS), artificial intelligence (AI)-based machine learning technologies have been widely utilized in Internet of Vehicles (IoV). Neural network (NN)-based knowledge sharing among vehicles and road side units (RSUs) presents considerable benefits for enhancing vehicle intelligence. However, it is challenging to ensure the efficiency of knowledge sharing under unstable connectivity among vehicles with different NN model architectures. In this article, we propose a new deep semantic communication framework for knowledge sharing (SCKS), enabling one-to-many NN model transmission and realizing efficient knowledge sharing in an IoV. Based on this framework, a generative distillation algorithm is designed to extract the semantic features of NN model, which can ensure the efficiency of the transmitter for knowledge sharing across different NN models and reduce communication bandwidth demand. In order to facilitate an effective understanding of semantic information by heterogeneous receivers, we design a generative adversarial networks (GAN)-based semantic decoding algorithm. Numerical results on CIFAR10 and ImageNet datasets show that the proposed SCKS outperforms the baseline, especially in the low-signal-to-noise (SNR) region. In particular, the simulation results demonstrate superiority of proposed SCKS scheme in terms of bandwidth requirements and computational efficiency for knowledge sharing cross different NN architectures than the state-of-art scheme, including DeepJSCC and knowledge distillation (KD).},
  keywords={Artificial neural networks;Semantic communication;Receivers;Computer architecture;Computational modeling;Transmitters;Decoding;Wireless communication;Symbols;Vectors;Dataset distillation (DD);deep generative model;deep semantic communication;Internet of Vehicles (IoV);knowledge sharing},
  doi={10.1109/JIOT.2025.3531910},
  ISSN={2327-4662},
  month={June},}@ARTICLE{10750041,
  author={Zhang, Jiexin and Xu, Shu and Zhang, Zhengming and Li, Chunguo and Yang, Luxi},
  journal={IEEE Internet of Things Journal}, 
  title={A Denoising Diffusion Probabilistic Model-Based Digital Twinning of ISAC MIMO Channel}, 
  year={2025},
  volume={12},
  number={15},
  pages={29121-29134},
  abstract={Deep learning (DL) techniques have been extensively utilized to tackle challenges in the field of wireless communication, overcoming the limitations of traditional methods. However, training DL algorithms often requires large amounts of data, which is difficult to obtain in increasingly complex communication environments. Reducing the amount of data required for DL training is therefore an urgent problem to be solved. In this work, we develop a denoising diffusion probabilistic model (DDPM)-based digital twin (DT) framework of integrated sensing and communication (ISAC) multiple-input-multiple-output (MIMO) channel to address the data scarcity issue commonly found in DL-based scenarios. By sampling a small amount of data, our framework captures and simulates the data distribution, building a virtual data repository that can continuously provide samples to assist in executing control instructions to physical entities, even as the user equipment (UE) and target positions change. Specifically, we formulate the data generation problem as a distribution approximation task guided by the Kullback-Leibler (KL) divergence criterion and optimize it by meticulously designing a DDPM network composed of U-Net structure, time-embedding modules, and attention mechanisms. Moreover, we enhance the framework by formulating a task-driven objective function for two applications: 1) sensing channel estimation and 2) target detection. Numerical results demonstrate the superiority of our proposed DDPM-based DT framework compared with other data augmentation techniques in improving the performance of data-driven DL-based tasks, showcasing its robustness across diverse scenarios.},
  keywords={Integrated sensing and communication;Training;MIMO;Wireless communication;Digital twins;Channel estimation;Generative adversarial networks;Array signal processing;Noise reduction;Internet of Things;Channel generation;denoising diffusion probabilistic model (DDPM);digital twin (DT);generative artificial intelligence (GAI);integrated sensing and communication (ISAC) multiple-input-multiple-output (MIMO)},
  doi={10.1109/JIOT.2024.3495212},
  ISSN={2327-4662},
  month={Aug},}@ARTICLE{9861232,
  author={Nan, Haihan and Zhu, Xiaoyan and Ma, Jianfeng},
  journal={China Communications}, 
  title={An efficient correlation-aware anomaly detection framework in cellular network}, 
  year={2022},
  volume={19},
  number={8},
  pages={168-180},
  abstract={Nowadays, the fifth-generation (5G) mobile communication system has obtained prosperous development and deployment, reshaping our daily lives. However, anomalies of cell outages and congestion in 5G critically influence the quality of experience and significantly increase operational expenditures. Although several big data and artificial intelligence-based anomaly detection methods have been proposed for wireless cellular systems, they change distributions of the data and ignore the relevance among user activities, causing anomaly detection ineffective for some cells. In this paper, we propose a highly effective and accurate anomaly detection framework by utilizing generative adversarial networks (GAN) and long short-term memory (LSTM) neural networks. The framework expands the original dataset while simultaneously keeping the distribution of data unchanged, and explores the relevance among user activities to further improve the system performance. The results demonstrate that our framework can achieve 97.16% accuracy and 2.30% false positive rate by utilizing the correlation of user activities and data expansion.},
  keywords={Computer architecture;Microprocessors;Detectors;Anomaly detection;Generative adversarial networks;Data models;Correlation;cellular network;anomaly detection;generative adversarial networks (GAN);long short-term memory (LSTM);call detail record (CDR)},
  doi={10.23919/JCC.2022.08.013},
  ISSN={1673-5447},
  month={Aug},}@ARTICLE{10816496,
  author={Rostami, Maryam Talebi and Motamedi, Seyed Ahmad},
  journal={IEEE Journal of Selected Topics in Signal Processing}, 
  title={IRAU-Net: Inception Residual Attention U-Net in Adversarial Network for Cardiac MRI Segmentation}, 
  year={2025},
  volume={19},
  number={1},
  pages={260-272},
  abstract={Due to the significant advancements in medical imaging, the application of artificial intelligence for early disease diagnosis has greatly contributed to reducing mortality caused by heart diseases. Cardiac MRI segmentation into the left ventricle (LV), right ventricle (RV) and myocardium (MYO) is a key step towards the early treatment and diagnosis of heart diseases. The proposed method consists of two main components: a localization part to extract the heart organ from other parts of the image, and a GAN model for segmentation. In the generator part of the generative adversarial network (GAN) model, a customized U-Net network is employed to segment the cardiac image. A combination of inception and residual blocks and utilizing an attention mechanism yield an improved version of U-Net. On the other hand, the discriminator part of the GAN model is designed to accurately distinguish between the ground truth image and the segmented image generated by the generator part. Our method is evaluated on two cardiac MRI datasets. The evaluation results on the ACDC 2017 challenge dataset show mean Dice scores of 0.947 for LV, 0.919 for RV, and 0.907 for MYO in cardiac MRI segmentation. The experimental results highlight that our proposed IRAU-Net method outperforms other state-of-the-art methods in terms of accuracy while significantly reducing computational costs.},
  keywords={Image segmentation;Generative adversarial networks;Heart;Accuracy;Magnetic resonance imaging;Detectors;Semantic segmentation;Attention mechanisms;Deep learning;Biomedical imaging;Attention mechanism;cardiac segmentation;deep learning;generative adversarial network;medical image segmentation;U-Net},
  doi={10.1109/JSTSP.2024.3523233},
  ISSN={1941-0484},
  month={Jan},}@INPROCEEDINGS{10094897,
  author={Beroud, Th. and Abry, P. and Malevergne, Y. and Senneret, M. and Perrin, G. and Macq, J.},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Wassertein Gan Synthesis for Time Series with Complex Temporal Dynamics: Frugal Architectures and Arbitrary Sample-Size Generation}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Generating surrogate data using Deep Neural Network (DNN) has become a classic task in image processing, while DNN time series synthesis is less often considered. The present work addresses issues related to the DNN synthesis of time series, with complex, scalefree time nonreversible temporal dynamics, using Wassertein Generative Adversarial Network. Instead of proposing yet another overperforming architecture, it discusses, first, synthesis quality quantitative assessment and, second, architecture designs that both reduce, for the Generator, the number of trainable parameters by a factor of 10000 (compared to state-of-the-art architectures), at no expense in performance cost, and permit to generate time series of size longer than that of the training set, without retraining. This works can thus be considered a contribution towards sustainable Artificial Intelligence.},
  keywords={Training;Deep learning;Image processing;Time series analysis;Neural networks;Signal processing;Generative adversarial networks;Generative Adversarial Network;Wasserstein distance;time series;convolution layer;multifractal;scalefree;time nonreversibility},
  doi={10.1109/ICASSP49357.2023.10094897},
  ISSN={2379-190X},
  month={June},}
