@INPROCEEDINGS{9820158,
  author={Tang, Zehai and Hu, Lun and Pan, Xiangyu},
  booktitle={2022 5th International Conference on Artificial Intelligence and Big Data (ICAIBD)}, 
  title={Detection of Link Communities in Attributed Graphs via an Approximate Bayesian Generative Model}, 
  year={2022},
  volume={},
  number={},
  pages={315-320},
  abstract={Attributed graphs are complex networks with non-trivial topological structures and rich node contents. Recently, a variety of algorithms have been proposed to detect meaningful communities from a given attributed graph by combining these topology and content information. However, few of them is capable of detecting the communities of links, which are better to interpret the node behaviors in forming communities. Furthermore, since nodes are possible to grouped into more than one communities, community detection upon links is natural and parameter-free to incorporate overlap, thus revealing the intrinsic organization of attributed graphs in a more reasonable way. In this work, we propose a novel Bayesian probabilistic model to approximately simulate the generative process of an attributed graph given the prior knowledge regarding the distribution of community labels over links. An efficient variational algorithm, namely VBLCD, is developed to solve the inference problem of the proposed model, thus completing the task of detecting link communities. To evaluate the performance of VBLCD, we have applied it to address two practical applications including document classification and social community detection, and also compared VBLCD with several state-of-the-art algorithms. Experimental results demonstrate the promising performance of VBLCD.},
  keywords={Organizations;Approximation algorithms;Probabilistic logic;Inference algorithms;Data models;Bayes methods;Classification algorithms;attributed graph;Bayesian probabilistic model;approximate generative process;community detection;clustering},
  doi={10.1109/ICAIBD55127.2022.9820158},
  ISSN={},
  month={May},}@ARTICLE{9740494,
  author={Almardeny, Yahya and Benavoli, Alessio and Boujnah, Noureddine and Naredo, Enrique},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={A Reinforcement Learning System for Generating Instantaneous Quality Random Sequences}, 
  year={2023},
  volume={4},
  number={3},
  pages={402-415},
  abstract={Random numbers are essential to most computer applications. Still, producing high-quality random sequences is a big challenge. Inspired by the success of artificial neural networks and reinforcement learning, we propose a novel and effective end-to-end learning system to generate pseudorandom sequences that operates under the upside-down reinforcement learning framework. It is based on manipulating the generalized information entropy metric to derive commands that instantaneously guide the agent toward the optimal random behavior. Using a wide range of evaluation tests, the proposed approach is compared against three state-of-the-art accredited pseudorandom number generators (PRNGs). The experimental results agree with our theoretical study and show that the proposed framework is a promising candidate for a wide range of applications.},
  keywords={Generators;Artificial intelligence;Random sequences;Reinforcement learning;NIST;Generative adversarial networks;Ciphers;Artificial intelligence (AI);pseudorandom number generators (PRNG);provably secure RNG;random;reinforcement learning;upside-down reinforcement learning (RL)},
  doi={10.1109/TAI.2022.3161893},
  ISSN={2691-4581},
  month={June},}@INPROCEEDINGS{9885879,
  author={Xu, Jian and Gao, Qiannan},
  booktitle={2022 4th International Conference on Natural Language Processing (ICNLP)}, 
  title={Image Super-Resolution Based on Frequency Division Generative Adversarial Network}, 
  year={2022},
  volume={},
  number={},
  pages={266-271},
  abstract={Most supervised super-resolution (SR) algorithms require paired high-resolution (HR) and low-resolution (LR) images as training samples. However, the network structures trained by supervised algorithms don’t adapt to different image degradations and it is difficult to find paired HR and LR images in real world. In this paper, a new unsupervised image SR algorithm based on generative adversarial network (GAN) is proposed. (1) A new network that can be trained with unpaired HR and LR images is proposed. (2) An intermediate process is proposed so that network contains two GANs, the first learns LR degradation, and the second performs SR procedure. (3) The idea of frequency division training is adopted in LR degradation and SR procedures: low frequency of image is preserved and only high frequency is learned. Experimental results on different datasets show that proposed algorithm provide a better balance between visual quality of SR reconstructed images and computational cost when compared with the state-of-the-art SR algorithms.},
  keywords={Degradation;Training;Visualization;Adaptation models;Computational modeling;Superresolution;Frequency conversion;image super-resolution;generative adversarial network;unsupervised learning;frequency division training},
  doi={10.1109/ICNLP55136.2022.00048},
  ISSN={},
  month={March},}@ARTICLE{10947318,
  author={Ye, Yilin and Huang, Rong and Zhang, Kang and Zeng, Wei},
  journal={IEEE Computer Graphics and Applications}, 
  title={Unified Visual Comparison Framework for Human and AI Paintings Using Neural Embeddings and Computational Aesthetics}, 
  year={2025},
  volume={45},
  number={2},
  pages={19-30},
  abstract={To facilitate comparative analysis of artificial intelligence (AI) and human paintings, we present a unified computational framework combining neural embedding and computational aesthetic features. We first exploit CLIP embedding to provide a projected overview for human and AI painting datasets, and we next leverage computational aesthetic metrics to obtain explainable features of paintings. On that basis, we design a visual analytics system that involves distribution discrepancy measurement for quantifying dataset differences and evolutionary analysis for comparing artists with AI models. Case studies comparing three AI-generated datasets with three human paintings datasets, and analyzing the evolutionary differences between authentic Picasso paintings and AI-generated ones, show the effectiveness of our framework.},
  keywords={Painting;Artificial intelligence;Feature extraction;Image color analysis;Training;Brightness;Semantics;Computational modeling;Art;Generative AI},
  doi={10.1109/MCG.2025.3555122},
  ISSN={1558-1756},
  month={March},}@INPROCEEDINGS{11158640,
  author={Mishra, Mandakani and Pradhan, Rohit Raj and Agrawalla, Kesab and Bokka, Raveendranadh},
  booktitle={2025 International Conference on Advancements in Smart, Secure and Intelligent Computing (ASSIC)}, 
  title={AI for Cybersecurity Threat Detection: A Machine Enabled Computing Perspective}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={With the increasing sophistication of cyber threats through Advanced Persistent Threats, ransomware, and insider attacks, innovative cybersecurity strategy is required, and AI represents a crucial instrument that uses deep learning and reinforcement learning to determine, analyze, and mitigate risks. This paper discusses AI-based cybersecurity, outlining a new model for AI, which improves on threat detection and response efficiency by increasing explainability. Analyzing large datasets and recognizing attack patterns and vulnerabilities to predict them has significantly improved the anomaly detection system and threat mitigation. The model also ensures that it follows ethical standards, including bias and transparency in AI-driven security. The results of this study show the significant advancements of cybersecurity resilience by integrating AI into modern threat defense. This AI-based approach offers scalable, adaptive, and proactive security. It allows organizations to effectively be prepared to deal with increasingly changing cyber threats.},
  keywords={Deep learning;Explainable AI;Standards organizations;Reinforcement learning;Threat assessment;Real-time systems;Time factors;Computer security;Artificial intelligence;Anomaly detection;AI;Cybersecurity;Threat Detection;Deep Learning;Anomaly Detection;Reinforcement Learning},
  doi={10.1109/ASSIC64892.2025.11158640},
  ISSN={},
  month={May},}@ARTICLE{10597596,
  author={Acharya, Kamal and Velasquez, Alvaro and Song, Houbing Herbert},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={A Survey on Symbolic Knowledge Distillation of Large Language Models}, 
  year={2024},
  volume={5},
  number={12},
  pages={5928-5948},
  abstract={This survey article delves into the emerging and critical area of symbolic knowledge distillation in large language models (LLMs). As LLMs such as generative pretrained transformer-3 (GPT-3) and bidirectional encoder representations from transformers (BERT) continue to expand in scale and complexity, the challenge of effectively harnessing their extensive knowledge becomes paramount. This survey concentrates on the process of distilling the intricate, often implicit knowledge contained within these models into a more symbolic, explicit form. This transformation is crucial for enhancing the interpretability, efficiency, and applicability of LLMs. We categorize the existing research based on methodologies and applications, focusing on how symbolic knowledge distillation can be used to improve the transparency and functionality of smaller, more efficient artificial intelligence (AI) models. The survey discusses the core challenges, including maintaining the depth of knowledge in a comprehensible format, and explores the various approaches and techniques that have been developed in this field. We identify gaps in current research and potential opportunities for future advancements. This survey aims to provide a comprehensive overview of symbolic knowledge distillation in LLMs, spotlighting its significance in the progression toward more accessible and efficient AI systems.},
  keywords={Surveys;Computational modeling;Artificial intelligence;Training;Predictive models;Data models;Transformers;Large language models (LLMs);symbolic knowledge;symbolic knowledge distillation},
  doi={10.1109/TAI.2024.3428519},
  ISSN={2691-4581},
  month={Dec},}@INPROCEEDINGS{10545728,
  author={Cheng, Zitong},
  booktitle={2024 IEEE 2nd International Conference on Control, Electronics and Computer Technology (ICCECT)}, 
  title={Research on Internet of Things Human-Computer Interaction System Based on Computer Artificial Intelligence Technology}, 
  year={2024},
  volume={},
  number={},
  pages={1135-1139},
  abstract={This piece delves into the realm of the Internet of Things and explores the synergy between AI technology and human-machine interaction systems. Specifically, an analysis is conducted on the core of computer AI-driven dialogue processes and associated technologies, such as automated question answering, continuous speech recognition, and text-to-speech systems. Research indicates that AI technology greatly enhances the efficiency and accuracy of these interaction systems, particularly in handling continuous streams of natural language input and output. A deeper analysis of the automated question answering system reveals its reliance on sophisticated natural language processing and knowledge graph technologies, aiming to enhance the quality of problem analysis and response generation. Similarly, the exploration of continuous speech recognition systems demonstrates their pivotal role in converting speech information into text accurately, which is vital for achieving smooth human-machine conversations. Furthermore, the analysis of text-to-speech systems highlights the natural and fluid transformation of textual information into speech output through advanced speech synthesis technology. To ensure practicality and the actual effectiveness of the design, a series of system validation tests are proposed and implemented in this study. These tests evaluate the core performance indicators of the system, with recognition rate tests focusing on the accuracy of speech and text processing, while communication distance tests ensure stable connectivity between base stations and IoT nodes. Through this comprehensive validation, the research findings demonstrate the efficient performance and reliability of this human-machine interaction system in IoT applications.},
  keywords={Human computer interaction;Technological innovation;Text recognition;Speech recognition;Question answering (information retrieval);User experience;Internet of Things;Computer AI;Artificial Intelligence Technology;Internet of Things;Human-Computer Interaction Systems},
  doi={10.1109/ICCECT60629.2024.10545728},
  ISSN={},
  month={April},}@ARTICLE{9328201,
  author={Wang, Jianing and Guo, Siying and Huang, Runhu and Li, Linhao and Zhang, Xiangrong and Jiao, Licheng},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Dual-Channel Capsule Generation Adversarial Network for Hyperspectral Image Classification}, 
  year={2022},
  volume={60},
  number={},
  pages={1-16},
  abstract={Deep learning-based methods have demonstrated significant breakthroughs in the application of hyperspectral image (HSI) classification. However, some challenging issues still exist, such as the overfitting problem caused by the limitation of training size with high-dimensional feature and the efficiency of spectral–spatial (SS) exploitation. Therefore, to efficiently model the relative position of samples within the generative adversarial network (GAN) setting, we proposed a dual-channel SS fusion capsule generative adversarial network (DcCapsGAN) for HSI classification. Dual channels (1-D-CapsGAN and 2-D-CapsGAN) are constructed by integrating the capsule network (CapsNet) with GAN for eliminating the mode collapse and gradient disappearance problem caused by traditional GAN. Meanwhile, octave convolution and multiscale convolution are integrated into the proposed model for further reducing the parameters of the CapsNet and extracting multiscale features. To further boost the classification performance, the SS channel fusion model is constructed to composite and switch the feature information of different channels, thereby facilitating the accuracy and robustness of the whole classification performance. Three commonly used HSI data sets are utilized to investigate the performance of the proposed DcCapsGAN model, and the performance of the experiment demonstrates that the proposed model can efficiently improve the classification accuracy and performance.},
  keywords={Feature extraction;Generative adversarial networks;Training;Generators;Gallium nitride;Convolution;Hyperspectral imaging;Capsule networks (CapsNets);generative adversarial network (GAN);hyperspectral image (HSI);multiscale convolution},
  doi={10.1109/TGRS.2020.3044312},
  ISSN={1558-0644},
  month={},}@ARTICLE{9968292,
  author={Chen, Shuangwu and Jin, Dong and He, Huasen and Yang, Feng and Yang, Jian},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Deep Learning Based Online Nondestructive Defect Detection for Self-Piercing Riveted Joints in Automotive Body Manufacturing}, 
  year={2023},
  volume={19},
  number={8},
  pages={9134-9144},
  abstract={Self-piercing riveting (SPR) is widely used for joining lightweight and dissimilar materials in automotive body manufacturing, the quality of which directly affects the safety of vehicles. However, there is still no reliable method that can be used for SPR quality control without destructive test and manual intervention. This article presents an online nondestructive SPR defect detection method based on deep learning. By learning the temporal dependencies of punch force varying with rivet displacement under different joint combinations, the proposed method can provide real-time defect alarms and avoid the enormous cost of joint dissection. We develop an SPR parameter selection mechanism to rule out the irrelevant parameters, which enhances the learning performance. For the problem of model overfitting caused by the savage imbalance of SPR data, we design a conditional generative adversarial network based data generation model. In order to accommodate the difference in defect patterns between factory and laboratory, we devise a transfer learning based model migration method, which substantially reduces the amount of labeled factory data for model training. The evaluations on real SPR data collected from two car assembly lines of Audi and NIO verify that the proposed method achieves a high detection accuracy and a low missing rate in SPR defect detection.},
  keywords={Force;Automobiles;Manufacturing;Data models;Inspection;Production facilities;Numerical models;Automotive body manufacturing;defect detection;nondestructive test;self-piercing riveting (SPR)},
  doi={10.1109/TII.2022.3226246},
  ISSN={1941-0050},
  month={Aug},}@ARTICLE{10623893,
  author={Wang, Jia and Zheng, Gang and Yu, Jiali and Shao, Jinliang and Zhou, Yinfei},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={Sea Surface Temperature Prediction Method Based on Deep Generative Adversarial Network}, 
  year={2024},
  volume={17},
  number={},
  pages={14704-14711},
  abstract={Sea surface temperature (SST) prediction plays an important role in ocean-related fields. Therefore, it is increasingly important to be able to make more accurate prediction of SST. In this article, we develop a deep generative adversarial network (DGAN) for generating future maps of SSTs, providing a visual method of predicting SSTs. Our DGAN model consists of a generator and a discriminator. The generator is designed to produce more realistic maps of future SSTs, which uses multiple composite layers to capture the changes of SSTs and generates clear maps of future SSTs. The discriminator uses the structure of patchGAN to obtain more SST features, and distinguishes between real and generated SST maps. In addition, we improve the loss function and perform convergence analysis, and then, obtain that minimizing the loss function is equivalent to minimizing Pearson $\chi 2$ divergence, and the relevant explanations are carried out through experiments. The generator and discriminator are training adversarially during the training stage, eventually reaching a relatively balanced state, and the DGAN is able to produce more reliable visual predictions. Finally, the effectiveness of the DGAN in the prediction of SST is verified experimentally, and it is compared with the generative model-DL model and the long short-term memory-GAN model.},
  keywords={Generators;Sea surface;Convergence;Sea surface temperature;Mathematical models;Training;Generative adversarial networks;Deep generative adversarial network (DGAN);future image generation;prediction;sea surface temperature (SST)},
  doi={10.1109/JSTARS.2024.3439022},
  ISSN={2151-1535},
  month={},}@ARTICLE{9585485,
  author={Makhmudkhujaev, Farkhod and Kwon, Junseok and Park, In Kyu},
  journal={IEEE Access}, 
  title={Controllable Image Dataset Construction Using Conditionally Transformed Inputs in Generative Adversarial Networks}, 
  year={2021},
  volume={9},
  number={},
  pages={144699-144712},
  abstract={In this paper, we tackle the well-known problem of dataset construction from the point of its generation using generative adversarial networks (GAN). As semantic information of the dataset should have a proper alignment with images, controlling the image generation process of GAN comes to the first position. Considering this, we focus on conditioning the generative process by solely utilizing conditional information to achieve reliable control over the image generation. Unlike the existing works that consider the input (noise or image) in conjunction with conditions, our work considers transforming the input directly to the conditional space by utilizing the given conditions only. By doing so, we reveal the relations between conditions to determine their distinct and reliable feature space without the impact of input information. To fully leverage the conditional information, we propose a novel architectural framework (i.e., conditional transformation) that aims to learn features only from a set of conditions for guiding a generative model by transforming the input to the generator. Such an approach enables controlling the generator by setting its inputs according to the specific conditions necessary for semantically correct image generation. Given that the framework operates at the initial stage of generation, it can be plugged into any existing generative models and trained in an end-to-end manner together with the generator. Extensive experiments on various tasks, such as novel image synthesis and image-to-image translation, demonstrate that the conditional transformation of inputs facilitates solid control over the image generation process and thus shows its applicability for use in dataset construction.},
  keywords={Generators;Image synthesis;Generative adversarial networks;Task analysis;Process control;Reliability;Transforms;Dataset construction;conditional image generation;generative adversarial networks;conditional transformation},
  doi={10.1109/ACCESS.2021.3122834},
  ISSN={2169-3536},
  month={},}@INBOOK{10790428,
  author={},
  booktitle={Toward Artificial General Intelligence: Deep Learning, Neural Networks, Generative AI}, 
  title={Preface}, 
  year={2024},
  volume={},
  number={},
  pages={V-VI},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9783111324166},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10790428},}@INBOOK{10790363,
  author={},
  booktitle={Toward Artificial General Intelligence: Deep Learning, Neural Networks, Generative AI}, 
  title={Frontmatter}, 
  year={2024},
  volume={},
  number={},
  pages={I-IV},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9783111324166},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10790363},}@INBOOK{10880526,
  author={Mittal, Ayushi and Parul, Parul and Gupta, Charu and Tayal, Devendra K},
  booktitle={Generative Artificial Intelligence for Biomedical and Smart Health Informatics}, 
  title={Use of AI with Optimization Techniques: Case Study, Challenges, and Future Trends}, 
  year={2025},
  volume={},
  number={},
  pages={209-238},
  abstract={Summary <p>From common ailments to more intricate and rare disorders, diseases affect individuals worldwide, impacting their well&#x2010;being and necessitating medical attention. The application of artificial intelligence (AI) to the field of disease prediction is the beginning of a revolution in medical technology. Through the application of AI's predictive capabilities, healthcare practitioners may bring in a new era of proactive healthcare management by improving diagnostic accuracy and implementing quick preventive interventions. Utilizing mathematical algorithms to improve and optimize predictive models is a novel method in the field of disease prediction through the application of optimization techniques. This chapter conducts a thorough study of various optimization techniques like flower pollination, differential evolution, and whale optimization. A detailed case study is also conducted on these techniques when they are combined with machine learning. It also covers the challenges faced while applying these optimization techniques to medical disease datasets. A detailed section on emerging future trends is also included to give direction on what can be done with the models.</p>},
  keywords={Diseases;Predictive models;Prediction algorithms;Medical diagnostic imaging;Navigation;Heuristic algorithms;Accuracy;Stochastic processes;Machine learning algorithms;Linear programming},
  doi={10.1002/9781394280735.ch11},
  ISSN={},
  publisher={IEEE},
  isbn={9781394280728},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10880526},}@INBOOK{10952190,
  author={Musiol, Martin},
  booktitle={Generative AI: Navigating the Course to the Artificial General Intelligence Future}, 
  title={Acknowledgments}, 
  year={2024},
  volume={},
  number={},
  pages={405-406},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394205950},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952190},}@INBOOK{10951024,
  author={Musiol, Martin},
  booktitle={Generative AI: Navigating the Course to the Artificial General Intelligence Future}, 
  title={About the Author}, 
  year={2024},
  volume={},
  number={},
  pages={407-407},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394205950},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951024},}@INPROCEEDINGS{10400626,
  author={Wang, L. and Wang, J. and Wang, Z. and Liu, P.},
  booktitle={5th International Conference on Artificial Intelligence and Advanced Manufacturing (AIAM 2023)}, 
  title={Random noise suppression of seismic data with generative adversarial network}, 
  year={2023},
  volume={2023},
  number={},
  pages={401-406},
  abstract={Due to the complex nature of the seismic exploration environment, there is a significant amount of noise in the data gathering process, resulting in various factors that can affect the quality of the data. Standard denoising techniques and models are often insufficient in meeting the demand for high-quality seismic data. However, with the advancement of artificial intelligence, Generative Adversarial Network (GAN) has emerged as an effective solution for seismic data denoising. The GAN-based algorithm for random noise reduction in seismic data involves a generator and discriminator. The generator uses noisy seismic data as input to produce denoised data, while the discriminator evaluates the authenticity of the data. Through game training between the generator and discriminator, this method has been proven to successfully remove random noise from synthetic seismic data. Furthermore, experiments comparing this method to the conventional CNN method on real seismic data using evaluation indices such as data visualization and signal-to-noise ratio have demonstrated its effectiveness. This method shows great potential for future research and application in seismic data denoising.},
  keywords={},
  doi={10.1049/icp.2023.2968},
  ISSN={},
  month={Oct},}@INBOOK{10790418,
  author={},
  booktitle={Toward Artificial General Intelligence: Deep Learning, Neural Networks, Generative AI}, 
  title={Contents}, 
  year={2024},
  volume={},
  number={},
  pages={VII-VIII},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9783111324166},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10790418},}@INPROCEEDINGS{10219618,
  author={Huang, Yubo and Wang, Jia and Li, Peipei and Xiang, Liuyu and Li, Peigang and He, Zhaofeng},
  booktitle={2023 IEEE International Conference on Multimedia and Expo (ICME)}, 
  title={Generative Iris Prior Embedded Transformer for Iris Restoration}, 
  year={2023},
  volume={},
  number={},
  pages={510-515},
  abstract={Iris restoration from complexly degraded iris images, aiming to improve iris recognition performance, is a challenging problem. Due to the complex degradation, directly training a convolutional neural network (CNN) without prior cannot yield satisfactory results. In this work, we propose a generative iris prior embedded Transformer model (Gformer), in which we build a hierarchical encoder-decoder network employing Transformer block and generative iris prior. First, we tame Transformer blocks to model long-range dependencies in target images. Second, we pretrain an iris generative adversarial network (GAN) to obtain the rich iris prior, and incorporate it into the iris restoration process with our iris feature modulator. Our experiments demonstrate that the proposed Gformer outperforms state-of-the-art methods. Besides, iris recognition performance has been significantly improved after applying Gformer.},
  keywords={Training;Representation learning;Modulation;Transformers;Feature extraction;Generative adversarial networks;Image restoration;Iris restoration;Image restoration;Prior knowledge;Iris recognition},
  doi={10.1109/ICME55011.2023.00094},
  ISSN={1945-788X},
  month={July},}@INPROCEEDINGS{10589960,
  author={Dong, Bingyu and Bai, Jie and Xu, Tao and Zhou, Yun},
  booktitle={2024 6th International Conference on Computer Science and Technologies in Education (CSTE)}, 
  title={Large Language Models in Education: A Systematic Review}, 
  year={2024},
  volume={},
  number={},
  pages={131-134},
  abstract={Large Language Models (LLMs) refer to a type of generative artificial intelligence model that produces responses to natural language input. The purpose of this study is to analyze the current application status of LLMs in the field of education through a systematic review of the literature. Data were sourced from three databases: Web of Science, ERIC, and Google Scholar. The study includes 94 documents, analyzed from both qualitative and quantitative perspectives. The results show that large language models have great potential in the field of education, specifically in generating medical content, serving as an English learning assistant, assisting academic research, and evaluating the quality of tests, etc. However, there are still potential dangers such as hindering the development of critical thinking, creating academic integrity crises, and ethical and moral challenges. These findings showed the current application status of LLMs in education, laying the groundwork to inspire future research.},
  keywords={Ethics;Systematics;Reviews;Generative AI;Large language models;Education;Natural languages;large language model;ChatGPT;artificial intelligence;education;systematic review},
  doi={10.1109/CSTE62025.2024.00031},
  ISSN={},
  month={April},}@INPROCEEDINGS{10538552,
  author={Tian, Geng and Rehman, Amir and Xing, Huanlai and Feng, Li and Gulzar, Nighat and Hussain, Abid},
  booktitle={2023 IEEE 22nd International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)}, 
  title={Automatic Intelligent Chronic Kidney Disease Detection in Healthcare 5.0}, 
  year={2023},
  volume={},
  number={},
  pages={2134-2140},
  abstract={Health systems worldwide have an unprecedented opportunity to enhance healthcare service delivery due to the rapid development of emerging digital technologies. Many advancements have been made in the medical field, with deep learning proving particularly useful when applied to a large enough number of well-defined samples. Although, this aspect may make deep learning harder to implement in settings with limited-size datasets. In this study, we present a new method of chronic kidney disease detection (CKDD) by combining Generative Adversarial Networks (GAN) with Convolutional Neural Networks (CNN). Afterward, synthetic sample data was created using GAN, which enlarged the dataset. Subsequently, processing these synthetic samples, the CNN classifier was applied. According to experimental assessments, the suggested CKDD-GAN methodology accuracy is superior to without the GAN technique. Moreover, the proposed CKDD-GAN-based model outperformed with an accuracy of 98.10%. Even though standard synthetic data samples seemed to improve classification performance, GAN-based enhancements resulted in a 2.91% improvement. GAN implementations for detecting chronic kidney disease are highly beneficial since they also increase awareness about its possible uses in various other diseases.},
  keywords={Deep learning;Privacy;Medical services;Generative adversarial networks;Chronic kidney disease;Convolutional neural networks;Security;Healthcare5.0;Chronic kidney disease;Detection;IoMT;Generative Adversarial Network},
  doi={10.1109/TrustCom60117.2023.00297},
  ISSN={2324-9013},
  month={Nov},}@INPROCEEDINGS{10578788,
  author={Lundström, Oxana and Maleki, Neda and Ahlgren, Fredrik},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Online Course Improvement Through GPT-4: Monitoring Student Engagement and Dynamic FAQ Generation}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Artificial Intelligence (AI), specifically in language processing, is increasingly recognized as an invaluable educational tool. The Large Language Model (LLM) GPT, developed by OpenAI, is an advanced machine learning tool that utilizes deep learning for human-like text comprehension and generation. This study uses OpenAI's GPT-4 to enhance an online Internet of Things (loT) course at Linnaeus University. We analyzed 12,000+ messages on an online communication platform spanning four years. We compare traditional Natural Language Processing (NLP) techniques to Generative AI for understanding student feedback and issues, inspiring project ideas, and promoting student engagement. We provide a combined approach to monitor the sentiment or mood of the students' communications over the timeline of the course. Moreover, we show how to use LLM to refine the FAQ generation and decipher student feedback for course refinement. We demonstrate how to generate optimal prompts and prepare the data to apply LLMs effectively. Our research reinforces that strategic use of LLMs, like GPT-4, can revolutionize remote learning by lessening lecturer workload and boosting student satisfaction and engagement. Our future work aims to further leverage AI models across remote engineering education. One potential direction is developing an AI-powered bot for online platforms to facilitate real-time interaction, manage queries, encourage engagement, maintain FAQs, and enhance course outcomes.},
  keywords={Sentiment analysis;Generative AI;Mood;Distance learning;Large language models;Real-time systems;Internet of Things;Artificial Intelligence (AI);education;Natural Language Processing (NLP);course feedback;FAQs},
  doi={10.1109/EDUCON60312.2024.10578788},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10759962,
  author={Takata, Tomoki and Yamada, Rie and Oliveira Nzinga René, António and Xu, Kuangzhe and Fujimoto, Makoto},
  booktitle={2024 Joint 13th International Conference on Soft Computing and Intelligent Systems and 25th International Symposium on Advanced Intelligent Systems (SCIS&ISIS)}, 
  title={Development of a Virtual Patient Model for Kampo Medical Interview: New Approach for Enhancing Empathy and Understanding of Kampo Medicine Pathological Concepts}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Global interest in complementary and alternative medicine has increased in recent years, with Kampo medicine in Japan gaining greater trust and use. Detailed patient interviews are essential in Kampo medicine, as the physician's empathy is critical to diagnostic precision. Typically, medical students develop empathy and deepen their understanding of Kampo's pathological concepts through clinical practice. However, the COVID-19 pandemic has imposed significant restrictions on clinical training. To address this challenge, we propose a novel educational approach to enhance empathy and understanding of Kampo medicine by developing a virtual patient application. This application leverages generative artificial intelligence to simulate realistic patient interactions, enabling students to practice Kampo medical interviews in a safe, controlled environment. The AI-generated conversations are designed to reflect the emotional nuances of real-life dialogue, with the virtual patients' facial expressions synchronized to these emotions, thus enhancing the realism of the training. The suggested method allows repeated practice at any time and fosters the development of essential diag-nostic and empathetic skills. While promising challenges remain in improving these simulations' accuracy, further refinements are still under consideration.},
  keywords={Training;COVID-19;Pathology;Emotion recognition;Pandemics;Generative AI;Medical services;Synchronization;Interviews;Medical diagnostic imaging;Kampo medical interview;Empathy;Virtual patient;Medical student;Artificial intelligence},
  doi={10.1109/SCISISIS61014.2024.10759962},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10970365,
  author={Pereira, Alexandre and Fernandes, Bruno and Barros, Pablo},
  booktitle={2024 12th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)}, 
  title={There's no Human in Charge: Playing Chef's Hat with a Large Language Model Based Agent}, 
  year={2024},
  volume={},
  number={},
  pages={149-153},
  abstract={Generative artificial intelligence (AI), especially large language models (LLMs), has greatly improved the creation of digital content. This study examines the use of an LLM, specifically Llama-3-8B, in playing Chef's Hat, a multiplayer card game. Traditionally, reinforcement learning (RL) agents used in this game do not perform well against human players. Our goal was to see if the LLM could play the game effectively without additional training. We integrated the Llama-3-8B model into the Chef's Hat game and compared its performance with three existing agents: Random, DQL (Deep Q-Learning), and PPO (Proximal Policy Optimization). Using special instructions, we guided the LLM on how to play the game and make decisions. The results showed that the LLM-based agent performed as well as or better than the RL agents, making smart and strategic moves based on the game rules and current situation. This study highlights the adaptability and potential of LLMs in various competitive settings, suggesting they could be used as effective autonomous agents in human-robot interactions. Future work should explore combining LLMs with other types of agents, testing them in different games, and improving the instructions given to them.},
  keywords={Training;Ethics;Affective computing;Generative AI;Large language models;Human-robot interaction;Games;Real-time systems;Standards;Testing;artificial intelligence;large language models;game playing;human-robot interaction},
  doi={10.1109/ACIIW63320.2024.00030},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11114593,
  author={Bonnet, Severin and Di Francesco Maesa, Damiano and Loporchio, Matteo and Tietze, Frank},
  booktitle={2025 IEEE International Conference on Blockchain and Cryptocurrency (ICBC)}, 
  title={A Fair and Trustworthy Remuneration Framework for AI Model Training Using DLT}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Currently, artificial intelligence (AI) models – particularly those of, but not limited to, Large Language Models – are trained over large amounts of data. Training often happens with little consideration, and even less remuneration, of input data that is content protected by Intellectual Property (IP) rights (e.g., copyrights). The recent rise in sophistication and popularity of generative AI models has further highlighted this issue, as traditional IP licensing models remain largely inadequate. In this paper, we present a proof of concept for an automated, fair, and trustworthy remuneration system for AI model training data contributors leveraging Distributed Ledger Technology. We propose the use of attribution methods for rewarding the most relevant sources for any given request, and smart contracts for the enforcement of the mutually beneficial revenue-sharing agreements between the model creator and training data copyright holders.},
  keywords={Training;Distributed ledger;Generative AI;Large language models;Smart contracts;Training data;Intellectual property;Data models;Blockchains;Remuneration;Intellectual Property;Blockchain;Smart Contract;Artificial Intelligence;Large Language Model;Explainable AI},
  doi={10.1109/ICBC64466.2025.11114593},
  ISSN={2832-8906},
  month={June},}@ARTICLE{10937960,
  author={Owusu, Evans and Mapkar, Mariyam and Rahouti, Mohamed and Verma, Dinesh C.},
  journal={Computer}, 
  title={Robust Intrusion Detection With Combinatorial Fusion and Generative Artificial Intelligence}, 
  year={2025},
  volume={58},
  number={4},
  pages={46-57},
  abstract={This article proposes an advanced intrusion detection system that combines combinatorial fusion analysis with generative artificial intelligence to improve anomaly detection in intelligent systems. It addresses challenges in detecting low-profile and evolving threats, especially in imbalanced datasets.},
  keywords={Generative AI;Computer hacking;Intrusion detection;Intelligent systems;Anomaly detection},
  doi={10.1109/MC.2024.3524302},
  ISSN={1558-0814},
  month={April},}@ARTICLE{10812969,
  author={Xu, Xiaoxia and Mu, Xidong and Liu, Yuanwei and Xing, Hong and Liu, Yue and Nallanathan, Arumugam},
  journal={IEEE Communications Magazine}, 
  title={Generative Artificial Intelligence for Mobile Communications: A Diffusion Model Perspective}, 
  year={2025},
  volume={63},
  number={7},
  pages={98-105},
  abstract={This article highlights the potential of a prominent generative artificial intelligence (GAI) method, namely diffusion model (DM), for mobile communications. First, we propose a DM-driven communication architecture which introduces two key paradigms, that is, conditional DM, and DM-driven deep reinforcement learning (DRL), for wireless data generation and communication management, respectively. Then, we discuss the key advantages of the DM-driven communication paradigms. To elaborate further, we explore DM-driven channel generation mechanisms for channel estimation, extrapolation, and feedback in multiple-input multiple-output (MIMO) systems. We showcase the numerical performance of conditional DM using the accurate DeepMIMO channel datasets, revealing its superiority in generating high-fidelity channels and mitigating unforeseen distribution shifts in sophisticated scenes. Furthermore, several DM-driven communication management designs promising to deal with imperfect channels and task-oriented communications are conceived. To inspire future research developments, we highlight the potential applications and open research challenges of DM-driven communications. Code is available at https://github.com/xiaoxiaxusummer/GAI_CDMM/.},
  keywords={Wireless communication;Noise reduction;Channel estimation;Noise measurement;Data models;Mobile communication;Data collection;Stochastic processes;Extrapolation;Trajectory;Generative AI},
  doi={10.1109/MCOM.001.2400284},
  ISSN={1558-1896},
  month={July},}@INPROCEEDINGS{11108609,
  author={Huang, Ruilong and Li, Bohan and Zhao, Xinzhe and Xu, Mengfei and Wu, Wenlong and Zhu, Qi},
  booktitle={2025 IEEE International Conference on Pattern Recognition, Machine Vision and Artificial Intelligence (PRMVAI)}, 
  title={MCTA4R: Enhancing User Preference Alignment with Meta-CoT and Search Algorithms}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Personalized recommendation systems often struggle with accurately predicting long-term user preferences, particularly in dynamic and sparse environments. Aligning user preferences is a key issue in LLM-driven recommendation systems with generative agents. To address this, we propose the Meta-CoT-Agent4Rec (MCTA4R) framework, which integrates the Meta-CoT reasoning process with $A^{*}$ and Monte Carlo Tree Search (MCTS) algorithms. The $A^{*}$ search algorithm leverages a heuristic strategy to guide the model towards optimal recommendations by expanding nodes based on cost evaluations, ensuring relevance in structured data environments. Meanwhile, the MCTS utilizes random simulations and backpropagation to explore diverse recommendation paths, adapting to dynamic and sparse data scenarios. The framework was evaluated using the MovieLens-1M, MovieLens-10M, Amazon-Book, and Steam datasets with different interaction ratios. Experimental results demonstrate that both $\mathrm{A}^{*}$ Meta-CoT and MCTS Meta-CoT significantly outperform traditional few-shot learning methods in terms of accuracy, recall and F1 score.},
  keywords={Adaptation models;Monte Carlo methods;Heuristic algorithms;Machine vision;Prediction algorithms;Data models;Cognition;Pattern recognition;User preference;Recommender systems;Recommendation System;Generative Agents;User Preference Alignment;Search Algorithm},
  doi={10.1109/PRMVAI65741.2025.11108609},
  ISSN={},
  month={June},}@INPROCEEDINGS{9421640,
  author={Wang, Yan and Wang, Pujia and Sun, Boyang and He, Kai and Huang, Lan},
  booktitle={2020 5th International Conference on Mechanical, Control and Computer Engineering (ICMCCE)}, 
  title={IInfoGAN: Improved Information Maximizing Generative Adversarial Networks}, 
  year={2020},
  volume={},
  number={},
  pages={1487-1490},
  abstract={Generative Adversarial Networks (GANs) have achieved huge success in some unsupervised learning fields. There is no doubt that clustering takes a lot of weight in unsupervised algorithm. And in this paper, we raise the Improved Information Maximizing Generative Adversarial Networks (IInfoGAN) algorithm for learning discriminative classifiers from unlabeled data. The basis of our method is an math function that contains the Mutual Information (MI) and Cross Entropy of the observed examples and their predicted classification category distribution, thus enhancing the robustness of the classifier to adversarial generative models. Experiments show that the interpretable representation learned by IInfoGAN is competitive with the representation learned by existing unsupervised methods.},
  keywords={Training;Time series analysis;Clustering algorithms;Predictive models;Generative adversarial networks;Prediction algorithms;Entropy;component;clustering;GAN;InfoGAN;fashion-mnist},
  doi={10.1109/ICMCCE51767.2020.00326},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10605388,
  author={Zhu, Gaoxia and Sudarshan, Vidya and Kow, Jason Fok and Soon Ong, Yew},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Human-Generative AI Collaborative Problem Solving Who Leads and How Students Perceive the Interactions}, 
  year={2024},
  volume={},
  number={},
  pages={680-686},
  abstract={This research investigates distinct human-generative AI collaboration types and students’ interaction experiences when collaborating with generative AI (i.e., ChatGPT) for problem-solving tasks and how these factors relate to students’ sense of agency and perceived collaborative problem solving. By analyzing the surveys and reflections of 79 undergraduate students, we identified three human-generative AI collaboration types: even contribution, human leads, and AI leads. Notably, our study shows that 77.21% of students perceived they led or had even contributed to collaborative problem-solving when collaborating with ChatGPT. On the other hand, 15.19% of the human participants indicated that the collaborations were led by ChatGPT, indicating a potential tendency for students to rely on ChatGPT. Furthermore, 67.09% of students perceived their interaction experiences with ChatGPT to be positive or mixed. We also found a positive correlation between positive interaction experience and a sense of positive agency. The results of this study contribute to our understanding of the collaboration between students and generative AI and highlight the need to study further why some students let ChatGPT lead collaborative problem-solving and how to enhance their interaction experience through curriculum and technology design.},
  keywords={Surveys;Ethics;Generative AI;Federated learning;Collaboration;Lead;Chatbots;Human-generative AI collaboration;ChatGPT;problem-solving;agency;overreliance;higher education},
  doi={10.1109/CAI59869.2024.00133},
  ISSN={},
  month={June},}@ARTICLE{11008623,
  author={Vice, Jordan and Akhtar, Naveed and Hartley, Richard and Mian, Ajmal},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={Quantifying Bias in Text-to-Image Generative Models}, 
  year={2025},
  volume={22},
  number={5},
  pages={5658-5671},
  abstract={Bias in text-to-image (T2I) generation can propagate unfair social representations and may be exploited to push ulterior agendas. These biases raise concerns on the dependability and fairness of models that have become widely popular and readily available for public consumption. Existing works in T2I bias analysis typically focus on social biases. We look beyond that and instead propose an evaluation methodology to quantify general bias in T2I generative models without any preconceived notion. We introduce a suite of three metrics; namely, distribution bias, Jaccard hallucination and generative miss-rate, to extensively appraise general model bias. To validate the efficacy of these metrics, we also introduce a backdoor-inspired strategy, which provides a convenient handle over the extent of bias in a model for controlled analysis. We assess T2I models implementing six widely used pipelines in this domain. Our extensive analysis covers both general and task-oriented scenarios, employing over 105 K generated images. For prior art comparison, it also encompasses social bias analysis. Moreover, we also extend our technique to analyze bias in seven popular captioned image datasets. Our experiments establish that our approach is objective, domain-agnostic and it consistently measures different forms of T2I model biases. To further research efforts into T2I model biases, we have developed an open-source web application and practical implementation of this work, which is available on HuggingFace. All relevant code is also publicly available on GitHub.},
  keywords={Measurement;Artificial intelligence;Analytical models;Hands;Computational modeling;Training;Text to image;Prevention and mitigation;Pipelines;Data mining;Bias;generative artificial intelligence;generative models;text-to-image generation;backdoor attacks;fairness},
  doi={10.1109/TDSC.2025.3572115},
  ISSN={1941-0018},
  month={Sep.},}@INPROCEEDINGS{11155671,
  author={Hart, Ahren and Shakir, Muhammad Zeeshan},
  booktitle={2025 International Conference on Software, Knowledge, Information Management & Applications (SKIMA)}, 
  title={A Systematic Literature Review Exploring AI’s Role in Enhancing Real-Time Holographic Communication}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={This systematic literature review investigates the pivotal role of artificial intelligence (AI) in enhancing real-time holographic communication and immersive virtual interactions. By critically examining recent advancements in AI-driven body and facial tracking, environment generation, and realistic avatar creation, this review identifies current technological capabilities and persistent limitations within holographic communication systems. Challenges such as latency, computational demand, and seamless integration between tracking technologies and dynamic virtual environments are addressed. The synthesis highlights how AI techniques, including deep learning, reinforcement learning, and generative models, significantly enhance interactivity, responsiveness, and realism in virtual settings. The review concludes by proposing future research directions aimed at overcoming identified gaps through the integration of emerging technologies like 5G and 6G networks, emphasizing the potential transformative impact across sectors including education, healthcare, and entertainment.},
  keywords={Holographic Communication;Artificial Intelligence;Real-Time Body Tracking;Avatar Realism;Dynamic Environment Generation;5G/6G Networks;Immersive Virtual Interaction;Ethical Considerations;Metaverse;AI-driven Virtual Environments;Latency Reduction;Computational Optimization},
  doi={10.1109/SKIMA66621.2025.11155671},
  ISSN={},
  month={June},}@INPROCEEDINGS{10853651,
  author={Jing, Chuanli and Yu, Chenggong},
  booktitle={6th International Conference on Artificial Intelligence and Advanced Manufacturing (AIAM 2024)}, 
  title={Method and implementation of intelligent embedded systems based on deep learning technology}, 
  year={2024},
  volume={2024},
  number={},
  pages={65-69},
  abstract={With the rapid development of the Internet of Things and artificial intelligence technologies, intelligent embedded systems face increasingly complex challenges and demands. This paper proposes an intelligent embedded system approach based on deep learning technology and analyzes its implementation. First, the concept and characteristics of intelligent embedded systems, as well as the development and application of deep learning technology, are introduced. Next, the basic principles of deep neural networks and design optimization strategies for deep learning processors are described. Then, based on the analysis of application scenarios and cases of deep learning in embedded systems, an embedded system model based on Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Reinforcement Learning (RL), and Generative Adversarial Networks (GAN) have been developed. This model is applied to image processing, speech recognition, robot control, and data augmentation, and verified in real-world conditions. Finally, the paper summarizes the advantages and development trends of intelligent embedded systems based on deep learning technology and discusses their potential and challenges in the future. Furthermore, the paper highlights the importance of optimizing hardware-software integration to achieve enhanced performance, energy efficiency, and real-time processing in intelligent embedded systems.},
  keywords={},
  doi={10.1049/icp.2024.4190},
  ISSN={},
  month={Oct},}@ARTICLE{10752923,
  author={Yao, Yinghua and Pan, Yuangang and Tsang, Ivor W. and Yao, Xin},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Generation With Nuanced Changes: Continuous Image-to-Image Translation With Adversarial Preferences}, 
  year={2025},
  volume={6},
  number={4},
  pages={816-828},
  abstract={Most previous methods for continuous image-to-image translation resorted to binary attributes with restrictive description ability and thus cannot achieve satisfactory performance. Some works proposed to use fine-grained semantic information, relative attributes (RAs), preferences over pairs of images on the strength of a specified attribute. However, they still failed to reconcile both goals for smooth translation and for high-quality generation simultaneously. In this work, we propose a new model continuous translation via adversarial preferences (CTAP) to coordinate these two goals for high-quality continuous translation based on RAs. In CTAP, we simultaneously train two modules: a generator that translates an input image to the desired image with smooth nuanced changes w.r.t. the interested attributes; and a ranker that executes adversarial preferences consisting of the input image and the desired image. Particularly, adversarial preferences involve an adversarial ranking process: 1) the ranker thinks no difference between the desired image and the input image in terms of the interested attributes; 2) the generator fools the ranker to believe the attributes of its output image changes as expect compared with the input image. RAs over pairs of real images are introduced to guide the ranker to rank image pairs regarding the interested attributes only. With an effective ranker, the generator would “win” the adversarial game by producing high-quality images that present smooth changes. The experiments on two face datasets and one shoe dataset demonstrate that our CTAP achieves state-of-art results in generating high-fidelity images which exhibit smooth changes over the interested attributes.},
  keywords={Generators;Interpolation;Artificial intelligence;Training;Generative adversarial networks;Games;Faces;Data models;Three-dimensional displays;Semantics;Adversarial preferences;continuous image-to-image translation;generative adversarial network (GAN);relative attributes (RAs)},
  doi={10.1109/TAI.2024.3497915},
  ISSN={2691-4581},
  month={April},}@ARTICLE{10419357,
  author={Lee, Gun Ho and Lee, Kyoung Jun and Jeong, Baek and Kim, Taekyung},
  journal={IEEE Access}, 
  title={Developing Personalized Marketing Service Using Generative AI}, 
  year={2024},
  volume={12},
  number={},
  pages={22394-22402},
  abstract={In today’s world, the development of social network services (SNS) like Facebook and Instagram has enabled consumers to acquire information about products through various channels. The acquisition of diverse information has led to a diversification in consumer preferences and requirements. As consumer preferences diversify and online channels expand, there is an increasing need for companies to provide personalized marketing. Among the means of personalized marketing, personalized marketing messages are a key tool that can enhance customer engagement. However, a limitation of personalized marketing message services is the cost issue associated with manually writing individual marketing messages for personalization. To solve this problem, when developing automated technology for personalized marketing messages, there were concerns about the complexity of model development and the quality of messages generated automatically. In this study, we propose the Persuasive Message Intelligence (PMI) service, which utilizes the recently prominent Large Language Model for automated individual personalized marketing messages. PMI generates marketing messages through prompt engineering based on the theory of persuasion in marketing and prior research on AI-generated messages, and validates the elements of prompts through surveys. The trial and error of researchers presented in this study, along with the know-how and rules of prompt engineering, will serve as guidelines for those who wish to develop services through prompts in the future.},
  keywords={Advertising;Psychology;Social networking (online);Public healthcare;History;Generative AI;Business;Generative adversarial networks;Artificial intelligence;Generative AI;personalized marketing message;persuasion theory;prompt engineering},
  doi={10.1109/ACCESS.2024.3361946},
  ISSN={2169-3536},
  month={},}@ARTICLE{9088157,
  author={Zheng, Aiyu and Cai, Jianghui and Yang, Haifeng and Zhao, Xujun},
  journal={IEEE Access}, 
  title={CPGAN: Curve Clustering Architecture Based on Projected Latent Vector of Generative Adversarial Network}, 
  year={2020},
  volume={8},
  number={},
  pages={86765-86776},
  abstract={Although Generative Adversarial Network(GAN) has obtained remarkable achievements in the image analysis and generation, its exploration in GAN-based curve clustering is still limited. The latent space of curve data is often used for clustering. However, the distance geometry in the latent space does not reflect the inherent clusters. In this paper, we propose CPGAN(Curve Clustering Architecture based on Projected Latent Vector of Generative Adversarial Network) for the clustering of curve dataset. Firstly, a novel GAN network structure, which utilizes a projector P (composed of the transposed convolutional network) to reconstruct the latent space of curve data, is proposed. CPGAN utilizes the concatenation of discrete code and Gaussian noise as a latent vector to preserve the implicit signal and structure of the cluster. Secondly, the loss function with two regularizations for CPGAN is proposed to guarantee the robustness and effectiveness of the model. Based on these, the jointly trained projector P is used to participate in the clustering process, while the generator can be used in the generating process. Finally, the spectral dataset from the LAMOST survey, the UCI dataset, and the UCR dataset are used as experimental data to evaluate clustering performance, the robustness of CPGAN, and further application on anomalous detection. CPGAN presents higher results than other methods.},
  keywords={Generative adversarial networks;Gallium nitride;Generators;Convolution;Task analysis;Data models;Robustness;Machine learning;generative adversarial network;curve data;clustering;anomalous detection},
  doi={10.1109/ACCESS.2020.2992887},
  ISSN={2169-3536},
  month={},}@ARTICLE{9174804,
  author={Guo, Anjing and Fang, Leyuan and Qi, Min and Li, Shutao},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Unsupervised Denoising of Optical Coherence Tomography Images With Nonlocal-Generative Adversarial Network}, 
  year={2021},
  volume={70},
  number={},
  pages={1-12},
  abstract={Deep learning for image denoising has recently attracted considerable attentions due to its excellent performance. Since most of current deep learning-based denoising models require a large number of clean images for training, it is difficult to extend them to the denoising problems when the reference clean images are hard to acquire (e.g., optical coherence tomography (OCT) images). In this article, we propose a novel unsupervised deep learning model called as nonlocal-generative adversarial network (nonlocal-GAN) for OCT image denoising, where the deep model can be trained without reference clean images. Specifically, considering that the background areas of OCT images mainly contain pure real noise samples, we creatively train a discriminator to distinguish background real noise samples from the fake noise samples generated by the denoiser, that is the generator, and then the discriminator will guide the generator for denoising. To further enhance denoising performance, we introduce a nonlocal means layer into the generator of the nonlocal-GAN model. Furthermore, since nearby several OCT B-scans have strong correlations, we also propose a nonlocal-GAN-M model to utilize the high correlations within nearby B-scans. Extensive experimental results on clinical retinal OCT images demonstrate the effectiveness and efficiency of the proposed method.},
  keywords={Noise reduction;Generators;Image denoising;Training;Noise measurement;Gallium nitride;Generative adversarial networks;Deep learning;generative adversarial networks (GANs);image denoising;optical coherence tomography (OCT)},
  doi={10.1109/TIM.2020.3017036},
  ISSN={1557-9662},
  month={},}@ARTICLE{10374245,
  author={Abdrakhmanova, Madina and Unaspekov, Timur and Varol, Huseyin Atakan},
  journal={IEEE Transactions on Biometrics, Behavior, and Identity Science}, 
  title={Multimodal Person Verification With Generative Thermal Data Augmentation}, 
  year={2024},
  volume={6},
  number={1},
  pages={43-53},
  abstract={The fusion of audio, visual, and thermal modalities has proven effective in developing reliable person verification systems. In this study, we enhanced multimodal person verification performance by augmenting training data using domain transfer methods. Specifically, we enriched the audio-visual-thermal SpeakingFaces dataset with a combination of real audio-visual data and synthetic thermal data from the VoxCeleb dataset. We adapted visual images in VoxCeleb to the thermal domain using CycleGAN, trained on SpeakingFaces. Our results demonstrate the positive impact of augmented training data on all unimodal and multimodal models. The score fusion of unimodal audio, unimodal visual, bimodal, and trimodal systems trained on the combined data achieved the best results on both datasets and exhibited robustness in low-illumination and noisy conditions. Our findings emphasize the importance of utilizing synthetic data, produced by generative methods, to improve deep learning model performance. To facilitate reproducibility and further research in multimodal person verification, we have made our code, pretrained models, and preprocessed dataset freely available in our GitHub repository.},
  keywords={Visualization;Training data;Generative adversarial networks;Feature extraction;Deep learning;Data augmentation;Identification of persons;Deep learning;multimodal fusion;multimodal learning;data augmentation;generative adversarial networks;face synthesis;person verification},
  doi={10.1109/TBIOM.2023.3346938},
  ISSN={2637-6407},
  month={Jan},}@INPROCEEDINGS{10489368,
  author={Zhang, Rui and Mariano, Vladimir Y.},
  booktitle={2023 5th International Conference on Robotics, Intelligent Control and Artificial Intelligence (RICAI)}, 
  title={Research on Time Series Data Prediction Based on STP-GAN Algorithm}, 
  year={2023},
  volume={},
  number={},
  pages={819-824},
  abstract={In this paper, we utilize the Sentiment Analysis technique in NLP field to provide the opinion influence factors for the algorithmic model by performing sentiment analysis on the text of the research report, introduce the GAN algorithm which is more compatible with the logic of the temporal data operation, and on the basis of which we add the Text Pathway, and put forward the text-assisted Generative Adversarial Network Prediction Model, STP-GAN. The model combines temporal data prediction with sentiment analysis to reduce the error of model training, and introduces the Transformer structure to improve the learning ability of temporal data features. In addition, STP-GAN utilizes BERT for fine-tuning and incorporates a lexicon to increase model adaptability. And on the basis of the proposed STP-GAN, the optimizer RMSPropW, which is more suitable for this research, is proposed, which uses the exponentially weighted moving average as the decay coefficient and utilizes weight decay to improve the training stability and training speed of the prediction model.},
  keywords={Training;Analytical models;Adaptation models;Sentiment analysis;Time series analysis;Predictive models;Prediction algorithms;temporal data;sentiment propensity analysis;generative adversarial model;BERT;optimizer},
  doi={10.1109/RICAI60863.2023.10489368},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10956665,
  author={Shruthi, N Kavya and Singh Yadav, Ajit Kumar},
  booktitle={2025 International Conference on Intelligent Control, Computing and Communications (IC3)}, 
  title={AI-Based Geo Intelligent System for Attack Prediction and Virtual Simulation}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={One of the blooming technologies of AI is the metaverse, The Metaverse is a virtual environment in which users may interact with virtual things and with one another. The Metaverse can be utilized in Military GeoIntelligent systems to build a virtual training environment, allowing Defence personnel to practice in realistic circumstances without the need for costly physical resources. The military personnel can practice in a virtual training environment using the Metaverse that can be created with realistic scenarios. This can aid in enhancing their abilities, judgment, and quickness of response. For instance, pilots can practice flying in various weather conditions, soldiers can hone their tactical skills, and cyber security officials can practice responding to cyberattacks. In this paper, we have focused on AI-based technologies combined with the geo intelligence and metaverse which can jointly help in defence to model and analyse complex geographic situations, allowing defence specialists to explore numerous situations and evaluate the effectiveness of different strategies before deploying resources, with the goal of improving situational awareness, response times, and decision-making capabilities across all security-related agencies. The satellite images obtained from the geo satellites give a brief description of a variety of different types of maps and visualizations, including topographic maps, vegetation maps, and thermal maps. These types of satellite imagery include infrared images, the locations of water bodies, planes, plateaus and a number of other surface structures of earth. The imagery helps in identifying the loopholes of spotting the enemy hiding locations and the risky regions of exposure of the native soldiers. The AI model can identify such locations and predict the possible threat locations. When this kind of model is deployed in the metaverse, it can help the soldiers in being trained for war zone like situations. The predictive outcome can handle and analyse enormous data more efficiently, detect possible dangers early, and respond to them quickly. This can eventually aid in the prevention of security breaches and the protection of national interests.},
  keywords={Training;Solid modeling;Metaverse;Vegetation mapping;Surface structures;Satellite images;Personnel;Time factors;Intelligent systems;Computer crime;Geographic intelligent system;GeoIntelligent systems;Metaverse;Artificial intelligence},
  doi={10.1109/IC363308.2025.10956665},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10877597,
  author={Singh, Gurpreet and Guleria, Kalpna},
  booktitle={2024 Second International Conference Computational and Characterization Techniques in Engineering & Sciences (IC3TES)}, 
  title={A Dense Residual Network-50 Model for Identification of Real and Fake Images}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The rapid advancement of artificial intelligence has led to the creation of highly realistic synthetic images, posing significant challenges in distinguishing them from real images. This study addresses this issue by employing a ResNet-50-based model to classify AI-generated and real images. The dataset comprises 120,000 images, equally divided between REAL images from the CIFAR-10 dataset and FAKE images generated using Stable Diffusion version 1.4. The model's architecture integrates batch normalization and dropout layers to enhance training stability and reduce overfitting. Results indicate a steady improvement in training accuracy, reaching 98.87% by the 22nd epoch, with a corresponding decrease in training loss to 0.0457. The validation accuracy stabilized at 95.59% from the 11th epoch onwards, while validation loss fluctuated, settling at 0.1887 by the 22nd epoch. These outcomes demonstrate the model's robust capability to distinguish between real and AI-generated images, highlighting its potential for applications in digital forensics, content verification, and intellectual property protection. The integration of explainable AI techniques further enhances the model's transparency and reliability, ensuring user trust in its classifications. This research contributes to the ongoing efforts to develop reliable methods for synthetic image detection and emphasizes the importance of early detection in maintaining content authenticity.},
  keywords={Training;Accuracy;Explainable AI;Digital forensics;Intellectual property;Stability analysis;Reliability;Protection;Batch normalization;Overfitting;Machine learning;Deep learning;Image processing;FAKE Images;REAL Image;ResNet50 Model},
  doi={10.1109/IC3TES62412.2024.10877597},
  ISSN={},
  month={Nov},}@ARTICLE{9381694,
  author={Li, Wei and Liang, Zhixuan and Ma, Ping and Wang, Ruobei and Cui, Xiaohui and Chen, Ping},
  journal={IEEE Transactions on Cybernetics}, 
  title={Hausdorff GAN: Improving GAN Generation Quality With Hausdorff Metric}, 
  year={2022},
  volume={52},
  number={10},
  pages={10407-10419},
  abstract={Data usually resides on a manifold, and the minimal dimension of such a manifold is called its intrinsic dimension. This fundamental data property is not considered in the generative adversarial network (GAN) model along with its its variants; such that original data and generated data often hold different intrinsic dimensions. The different intrinsic dimensions of both generated and original data may cause generated data distribution to not match original data distribution completely, and it certainly will hurt the quality of generated data. In this study, we first show that GAN is often unable to generate simulation data, holding the same intrinsic dimension as the original data with both theoretical analysis and experimental illustration. Next, we propose a new model, called Hausdorff GAN, which removes the issue of different intrinsic dimensions and introduces the Hausdorff metric into GAN training to generate higher quality data. This provides new insights into the success of Hausdorff GAN. Specifically, we utilize a mapping function to map both original and generated data into the same manifold. We then calculate the Hausdorff distance to measure the difference between the mapped original data and the mapped generated data, toward pushing generated data to the side of original data. Finally, we conduct extensive experiments (using MNIST, CIFAR10, and CelebA datasets) to demonstrate the significant performance improvement of the Hausdorff GAN in achieving the largest Inception Score and the smallest Frechet inception distance (FID) score as well as producing diverse generated data at different resolutions.},
  keywords={Gallium nitride;Generative adversarial networks;Generators;Measurement;Training;Manifolds;Data models;Distribution transformation;generative adversarial network (GAN);Hausdorff metric;intrinsic dimension},
  doi={10.1109/TCYB.2021.3062396},
  ISSN={2168-2275},
  month={Oct},}@INPROCEEDINGS{9442206,
  author={Liang, Xin and Liu, Zhenyu and Chang, Haoran and Zhang, Lin},
  booktitle={2020 IEEE 18th International Conference on Industrial Informatics (INDIN)}, 
  title={Wireless Channel Data Augmentation for Artificial Intelligence of Things in Industrial Environment Using Generative Adversarial Networks}, 
  year={2020},
  volume={1},
  number={},
  pages={502-507},
  abstract={The rise of Artificial Intelligence of Things (AIoT) makes everything connected smartly, which can enrich industrial productivity. With the help of learning-based wireless communications, terminals in AIoT can communicate with each other and collaborate intelligently. However, one of the critical issues faced in AIoT deployment is the lack of available large datasets for the training of artificial intelligence algorithms in the industrial environment. In this paper, we propose a channel data augmentation algorithm for the dataset limitation cases in intelligent industrial wireless communication systems using generative adversarial networks (GAN). Specifically, we first show the performance of deep learning-based channel state information (CSI) feedback algorithm trained with different size of datasets. Then we develop a GAN for the channel data augmentation to enhance the performance of CSI feedback algorithm. Finally, we apply the enhanced approach to an insufficient dataset for the performance evaluation. Experimental results show that our method can achieve at most 3dB performance improvement than other traditional data augmentation approaches in increasing the accuracy of CSI feedback algorithm when the size of dataset is limited to 10000.},
  keywords={Wireless communication;Performance evaluation;Training;Productivity;Conferences;Industrial communication;Estimation;Data augmentation;GAN;industrial wireless communication;channel estimation},
  doi={10.1109/INDIN45582.2020.9442206},
  ISSN={2378-363X},
  month={July},}@INPROCEEDINGS{10625113,
  author={Jadhav, Balasaheb and Jain, Manas and Jajoo, Adhip and Kadam, Devika and Kadam, Harshvardhan and Kakkad, Toshish},
  booktitle={2024 2nd International Conference on Sustainable Computing and Smart Systems (ICSCSS)}, 
  title={Imagination Made Real: Stable Diffusion for High-Fidelity Text-to-Image Tasks}, 
  year={2024},
  volume={},
  number={},
  pages={773-779},
  abstract={By utilising the sophisticated features of diffusion models (DMs) for image synthesis, this work presents a novel method for high-fidelity text-to-image generation. Conventional deep learning approaches break down the image production process into a series of sequential denoising autoencoder applications. These applications typically operate in pixel space and result in significant computational costs due to the need for substantial GPU resources for training and inference. By exploiting the latent spaces of potent pretrained autoencoders, this method overcomes these difficulties and permits DM training with minimal computational resources while preserving great quality and adaptability. An ideal trade-off between preserving detail and reducing complexity is struck by using latent representations, which greatly improves visual fidelity over earlier techniques. Furthermore, the incorporation of cross-attention layers in the model converts diffusion models into flexible generators that can process a variety of conditioning inputs, including text and bounding boxes, so enabling convolutional high-resolution synthesis. State-of-the-art performance in image inpainting, class-specific image blending, and other tasks is demonstrated by latent diffusion models (LDMs), which also perform significantly better than pixel-based DMs in text-to-image synthesis, unrestricted image generation, and super-resolution. This research pushes the limits of what is possible in high-fidelity text-to-image applications, showcasing the adaptability and effectiveness of LDMs.},
  keywords={Training;Visualization;Image synthesis;Computational modeling;Superresolution;Noise reduction;Text to image;Image Generation;Deep Learning;Stable Diffusion;Latent Space;Latent Diffusion Model (LDM);Generative Adversarial Network (GAN);Contrastive Language-Image Pre-Training (CLIP)},
  doi={10.1109/ICSCSS60660.2024.10625113},
  ISSN={},
  month={July},}@INPROCEEDINGS{10649956,
  author={Połap, Dawid and Jaszcz, Antoni and Prokop, Katarzyna},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Generating synthetic data using GANs fusion in the digital twins model for sonars}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Digital twins are a technology that allows for a virtual copy of a real object or process. The main goal is to map specific features to prevent problems or monitor conditions and operations. In this work, we propose a framework for a sonar system. Data acquired by sonar are most often sent to an operator or classification network to detect objects on the seabed. However, such a classifier needs a large amount of data to be properly trained. Therefore, we propose a digital twin model that uses generative adversarial networks (GANs) with feature fusion to obtain synthetic data for further processing. The proposed GAN model is based on dual generators with combining results that are passed further. The proposed technique indicates that building an artificial intelligence module by fusing real and synthetic data is important and allows for achieving high augmentation results in sonar applications.},
  keywords={Training;Neural networks;Sonar;Generative adversarial networks;Feature extraction;Data models;Generators;GAN;synthetic data;augmentation;feature fusion;digital twins;sonar},
  doi={10.1109/IJCNN60899.2024.10649956},
  ISSN={2161-4407},
  month={June},}@INPROCEEDINGS{10604540,
  author={Yu, Siqi and Jiang, Yongquan and Yang, Yan},
  booktitle={2024 7th International Conference on Artificial Intelligence and Big Data (ICAIBD)}, 
  title={FWBP: A New Generative Modeling Scheme}, 
  year={2024},
  volume={},
  number={},
  pages={277-282},
  abstract={Generative models are often used to generate differentiated samples for images, audio and video, focusing on the diversity of the generated samples. For materials, molecules and other fields, it is more important to generate samples with targeted properties. More attention should be paid to the accuracy of the generated samples. In the spirit of exploring conditional generative neural networks, this manuscript proposes a new generative modeling scheme-FWBP, i.e., Fixed Weight Backpropagation. FWBP can effectively utilize trained prediction models and generate samples with targeted attributes by fixing the weights in prediction models and then backpropagate the properties. High-entropy alloys (HEAs) are alloys composed of multiple elements. The property design of HEAs is of great significance for practical applications. Firstly, a set of function is used to illustrate the general idea and effectiveness of FWBP. Then, FWBP is applied to the generation of HEAs with targeted properties. The accuracy of FWBP is verified in four datasets with various networks. FWBP's efficiency is also proved in the field of image generation.},
  keywords={Backpropagation;Accuracy;Image synthesis;Neural networks;Metals;Focusing;Predictive models;generative models;HEAs;FWBP},
  doi={10.1109/ICAIBD62003.2024.10604540},
  ISSN={2769-3554},
  month={May},}@INPROCEEDINGS{9402449,
  author={Ravindra Padalkar, Ganesh and Dinkar Patil, Shivani and Mallikarjun Hegadi, Mukta and Kailash Jaybhaye, Nikita},
  booktitle={2021 International Conference on Computer Communication and Informatics (ICCCI)}, 
  title={Drug Discovery using Generative Adversarial Network with Reinforcement Learning}, 
  year={2021},
  volume={},
  number={},
  pages={1-3},
  abstract={A large amount of medical data is available to many of us and along with well-established deep learning algorithms, so the design of automated drug development pipelines has increased. The pipeline speeds up the drug discovery process and helps us better understand the disease. They help in planning pre-clinical lab experiments. This reduces the low productivity rate that the pharmaceutical companies are facing currently. Accurate predictions and insights are obtained by using deep learning techniques. So, this increases the need for deep learning approaches that have the potential to speed up the process, decision making, and reduce failure rates in drug discovery and development. With the fast development of computing power and enormous medical data, the project involving drug discovery have been benefited from artificial intelligence. The deep learning model knows as Generative Adversarial Network (GAN) with reinforcement learning is used to solve the problem.},
  keywords={Drugs;Deep learning;Pipelines;Reinforcement learning;Generative adversarial networks;Data models;Gallium nitride;Convolution Neural Network;Generative Adversarial Network;Recurrent Neural Network;Reinforcement Learning},
  doi={10.1109/ICCCI50826.2021.9402449},
  ISSN={2329-7190},
  month={Jan},}@ARTICLE{10309274,
  author={Broo, Didem Gürdür},
  journal={IEEE Spectrum}, 
  title={How Generative AI Helped Me Imagine a Better Robot: It Didn't Give Me Schematics, But It Did Boost My Creativity}, 
  year={2023},
  volume={60},
  number={11},
  pages={44-50},
  abstract={This year, 2023, will probably be remembered as the year of generative AI. It is still an open question whether generative AI will change our lives for the better. One thing is certain, though: New artificial-intelligence tools are being unveiled rapidly and will continue for some time to come. And engineers have much to gain from experimenting with them and incorporating them into their design process. • That's already happening in certain spheres. For Aston Martin's DBR22 concept car, designers relied on AI that's integrated into Divergent Technologies' digital 3D software to optimize the shape and layout of the rear subframe components. The rear subframe has an organic, skeletal look, enabled by the AI exploration of forms. The actual components were produced through additive manufacturing. Aston Martin says that this method substantially reduced the weight of the components while maintaining their rigidity. The company plans to use this same design and manufacturing process in upcoming low-volume vehicle models. • Other examples of AI-aided design can be found in NASA's space hardware, including planetary instruments, space telescopes, and the Mars Sample Return mission. NASA engineer Ryan McClelland says that the new AI-generated designs may “look somewhat alien and weird,” but they tolerate higher structural loads while weighing less than conventional components do. Also, they take a fraction of the time to design compared to traditional components. McClelland calls these new designs “evolved structures.” The phrase refers to how the AI software iterates through design mutations and converges on high-performing designs.},
  keywords={Artificial intelligence;Generative adversarial networks;Space vehicles;Space missions;Aerospace electronics;Three-dimensional printing;Three-dimensional displays;Rigidity;Design engineering},
  doi={10.1109/MSPEC.2023.10309274},
  ISSN={1939-9340},
  month={November},}@INPROCEEDINGS{11036309,
  author={Shuler, Todd L. and Ostrowski, David Alfred},
  booktitle={2025 19th International Conference on Semantic Computing (ICSC)}, 
  title={Using Generative AI for Neurofeedback Content Personalization}, 
  year={2025},
  volume={},
  number={},
  pages={306-309},
  abstract={This paper presents a comprehensive framework for integrating Large Language Models (LLMs) into neurofeedback systems. By leveraging real-time electroencephalogram (EEG) data processing, advanced machine learning, and multimodal feedback mechanisms, the framework offers a transformative approach to personalized neurofeedback. Technical validation and statistical analysis highlight system scalability and empirical reproducibility, addressing critical performance metrics such as latency, accuracy, and resource efficiency. The framework emphasizes the convergence of traditional neurofeedback principles with modern AI capabilities, demonstrating significant potential for applications in mental health, cognitive enhancement, and neurological rehabilitation.},
  keywords={Generative AI;Statistical analysis;Large language models;Scalability;Semantics;Mental health;Machine learning;Electroencephalography;Reproducibility of results;Neurofeedback;Adaptive Feedback;Artificial Intelligence in Neuroscience;Brain-Computer Interfaces (BCI);Cognitive Enhancement;Electroencephalogram (EEG) Generative AI;Large Language Models (LLM);Machine Learning;Mental Health;Multi-Modal Feedback;Neurofeedback;Optimization Framework},
  doi={10.1109/ICSC64641.2025.00053},
  ISSN={2472-9671},
  month={Feb},}@INPROCEEDINGS{10166608,
  author={Zheng, Yuhang and Miao, Miao and Peng, Xiangjia and Lei, Jiaxing and Feng, Shuang},
  booktitle={2023 IEEE 6th International Electrical and Energy Conference (CIEEC)}, 
  title={A Method for Generating Subsynchronous Oscillation Data of Power System Based on Wasserstein Generative Adversarial Network}, 
  year={2023},
  volume={},
  number={},
  pages={3702-3707},
  abstract={With a large number of power electronic devices connected to the power grid, the problem of subsynchronous oscillation caused by the interaction between the converter and the power grid seriously threatens the safe and stable operation of the power system. The existing research methods of subsynchronous oscillation, especially the artificial intelligence methods, mostly rely on a large amount of oscillation data, but in practice, such data is very scarce. Therefore, this paper proposes a method to generate subsynchronous oscillation data in power systems based on Wasserstein generative adversarial network (WGAN). In order to improve the quality of the generated samples and solve the problem of training instability, the JS distance is replaced by Wasserstein distance. Taking the oscillation data in the direct-driven permanent-magnet wind farm system as a practical example, the generated data are analyzed by dynamic time warping (DTW) and frequency to damping ratio methods. The results show that the data generated by the proposed method is consistent with the characteristics of oscillation data and has certain advantages in data quality.},
  keywords={Training;Time-frequency analysis;Simulation;Power system dynamics;Power system stability;Wind farms;Generative adversarial networks;generative adversarial networks;subsynchronous oscillation;data generation;Wasserstein distance},
  doi={10.1109/CIEEC58067.2023.10166608},
  ISSN={},
  month={May},}@INBOOK{10897060,
  author={Islam, Mohammad Rubyet},
  booktitle={Generative AI, Cybersecurity, and Ethics}, 
  title={The Future of GenAI in Cybersecurity}, 
  year={2025},
  volume={},
  number={},
  pages={273-291},
  abstract={Summary <p>This chapter explores the future of generative artificial intelligence (GenAI) in cybersecurity, emphasizing emerging trends and future challenges. The chapter highlights the promise of GenAI in enhancing digital defenses through advanced predictive models and simulations while addressing complex ethical questions. It concludes with the integration of automated security protocols, deepfake detection, adaptive threat modeling, and artificial intelligence (AI)&#x2010;driven security education. The chapter also delves into ethical considerations, regulatory compliance, and the importance of inclusivity and continuous adaptation in the development and deployment of GenAI technologies. The chapter concludes with a call for ethical stewardship, global cooperation, and a commitment to fostering a secure and ethically sound digital future.</p>},
  keywords={Ethics;Computer security;Security;Deepfakes;Artificial intelligence;Training;Biological system modeling;Adaptation models;Predictive models;Market research},
  doi={10.1002/9781394279326.ch11},
  ISSN={},
  publisher={Wiley},
  isbn={9781394279319},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10897060},}@INPROCEEDINGS{10793762,
  author={Fatima, Noreen and Afrakhteh, Sajjad and Demi, Libertario},
  booktitle={2024 IEEE Ultrasonics, Ferroelectrics, and Frequency Control Joint Symposium (UFFC-JS)}, 
  title={A Novel Approach for Automated Segmentation of Left Ventricle Based on Bidirectional Myocardium to Endocardium Translation Using Generative Adversarial Network}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={In echocardiography, accurate segmentation of cardiac structures, particularly left ventricle (LV), is crucial for clinical diagnosis. However, manual segmentation is user-intensive and prone to variability among experts due to intricate anatomical details and imaging artifacts. Our aim is to propose an artificial intelligence (AI)-based technique to automatically segment the LV structure, enhancing accuracy and reducing segmentation time and subjectivity of manual segmentation. We propose a novel Bidirectional generative adversarial network (Bi-GAN) for automated segmentation of LV structures. Specifically, we utilize Bi-GAN for segmenting the endocardium region from available myocardium region and vice versa. The adversarial training, Bi-GAN minimizes the losses and produces the target domain segmentation. The analysis is conducted on the cardiac acquisitions for the multi-structure ultrasound segmentation (CAMUS) dataset, comprising 900 echocardiographic training images and 100 testing images in 4CH views during both end-diastolic (ED) and end-systolic (ES) phases. Results showed a mean Dice of 0.97 for both the ED and ES phases, along with an MAE of 1.90. Conversely, when generating myocardium segmentations from the endocardium, our method attained a mean Dice of 0.88 and MAE of 5.05. Hence, the proposed technique achieves competitive results comparable to the state-of-the-art in LV segmentation, requiring only one set of LV masks (either endocardium or myocardium) as input.},
  keywords={Training;Image segmentation;Accuracy;Ultrasonic imaging;Translation;Imaging;Manuals;Myocardium;Generative adversarial networks;Testing;Deep Learning;Segmentation;Generative Adversarial Network;Echocardiography},
  doi={10.1109/UFFC-JS60046.2024.10793762},
  ISSN={2375-0448},
  month={Sep.},}@INPROCEEDINGS{10498169,
  author={Li, Jian},
  booktitle={2024 International Conference on Integrated Circuits and Communication Systems (ICICACS)}, 
  title={Dynamic Capturing of Facial Expression and 3D Animation Generation based on Generative Adversarial Network}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In recent years, interaction between human and computer based on the functions of computer software is distant from meeting human needs for computer use through development of computer and Artificial Intelligence (AI). People expect a more convenient and faster human-computer interface. In the mobile network environment, the accuracy of related image matching algorithms is affected by factors such as bandwidth uncertainty and channel interference, resulting in significant limitations in image feature matching. The deep learning approach of Generative Adversarial Network (GAN) is proposed for dynamic capturing of 3D animation effect generation by using facial expressions. The feature extraction approach utilized the histogram (HOG) and utilizes the GAN in classification for dynamic capture of animation effects. OpenGL and C++ are employed for 3D animation to simulate the rendering. The outcomes exhibit that the face detection approach has attained good performance in both accuracy and speed.},
  keywords={Deep learning;Histograms;Three-dimensional displays;Heuristic algorithms;C++ languages;Animation;Generative adversarial networks;Animation effect;Deep Learning;Dynamic Capturing;Generative Adversarial Network;and Histogram},
  doi={10.1109/ICICACS60521.2024.10498169},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{9525515,
  author={Zhong, XinYi and Wang, YiZhong and Cai, AiLong and Liang, NingNing and Li, Lei and Yan, Bin},
  booktitle={2021 International Conference on Artificial Intelligence and Electromechanical Automation (AIEA)}, 
  title={Dual-Energy CT Image Super-resolution via Generative Adversarial Network}, 
  year={2021},
  volume={},
  number={},
  pages={343-347},
  abstract={Photon counting detector obtains CT images from multiple energy bins, and acquires X-ray intensity data of different energy bins through one X-ray exposure. However, the spatial resolution of the reconstructed image will decrease, and the image will be blurred due to the low photon count in the narrow energy box width, quantum noise and the response problem of detector cells. Deep learning is gradually applied to medical images to reduce noise or improve resolution, which has exhibited promising performance in image super-resolution (SR) by learning a nonlinear mapping function from low-resolution (LR) images to high-resolution (HR) images. Inspired by the cycle-GAN, we propose a novel network model which realize the mapping of HR images to LR images for Dual-Energy CT (DECT) reconstruction. Experimental results show that the reconstructed image has significant improvements in peak signal-to-noise ratio (PSNR) and root mean square error (RMSE). Compared with the traditional super-resolution reconstruction method, this method has better experimental results.},
  keywords={PSNR;Computed tomography;Superresolution;Detectors;Reconstruction algorithms;Spatial resolution;Root mean square;Dual-Energy CT;super resolution;deep learning;generative adversarial network},
  doi={10.1109/AIEA53260.2021.00079},
  ISSN={},
  month={May},}@INPROCEEDINGS{10774771,
  author={Lokhande, Meghana and Raut, Prajot and Gawali, Kiran and Ahirrao, Mrudul and Bhande, Abhishek},
  booktitle={2024 8th International Conference on Computing, Communication, Control and Automation (ICCUBEA)}, 
  title={Artificial Intelligence for Detecting Cyber Attacks in Deepfake & Identity Theft}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In today's era of digital world and evolving cyber threats, this research paper presents a unified exploration of innovative techniques harnessing the power of artificial intelligence and blockchain to combat deepfake attacks and identity theft. These intertwined challenges demand holistic solutions that transcend traditional boundaries. As the digital landscape is increasingly infiltrated by deepfake technology, concerns surrounding the authenticity of digital content are reaching a critical juncture. Deepfake attacks, capable of generating persuasive yet false imagery and videos, pose a grave societal threat. They undermine trust in media, perpetuate misinformation, and raise the specter of identity theft. Image processing techniques for deepfake detection aim to distinguish real from manipulated content by leveraging advances in AI. Meanwhile, the application of AI and machine learning in deepfake detection has yielded promising results, enhancing our capacity to discern authentic media from forgeries. The research converges on a proactive approach, introducing a pioneering framework that integrates AI and blockchain technology. This paper proposes an Artificial Intelligence-based protection framework, leveraging unsupervised pre-training techniques and Dense Neural Networks (DNN), to combat identity impersonation attacks, particularly the Clone ID attack directed at the Routing Protocol for Low Power and Lossy Networks (RPL). The research investigates the potential of blockchain, including Smart Contracts to combat the deepfake problem by verifying digital media's history and provenance.},
  keywords={Deep learning;Deepfakes;Identity theft;Prevention and mitigation;Neural networks;Smart contracts;Impersonation attacks;Routing protocols;Blockchains;Protection;Deepfake detection;Convolutional Neural Networks;Blockchain technology;Digital content authenticity;Image and video analysis;Threat detection;Artificial Intelligence;Media integrity},
  doi={10.1109/ICCUBEA61740.2024.10774771},
  ISSN={2771-1358},
  month={Aug},}@INPROCEEDINGS{11005231,
  author={Annadurai, Suganya and Meenakshi, M},
  booktitle={2025 International Conference on Wireless Communications Signal Processing and Networking (WiSPNET)}, 
  title={Artificial Intelligence Assisted Side-Channel Analysis: Security Assessment Challenges}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Side-channel attack exploits the information leakage through physical medium to retrieve the secret key used by the cryptographic module. Hence, resistance to such attack has been brought as a mandate for the cryptographic module that are deployed in critical applications. Various countermeasures are being developed to make cryptographic implementations more robust against side-channel attacks. However, the current security assessment standard, which is based on statistical methods will not estimate the efficacy of these countermeasures. Assessing the efficacy of a countermeasure using Artificial Intelligence (AI) techniques or machine learning will be helpful to evaluate the side-channel resistant implementations and will help to streamline the evaluation process. In this paper we outline the datasets available for deep learning on public domain and the dataset created by us along with the recent advancement in AI assisted side-channel attacks that are explored by the research community. Further, this paper discusses the challenges in the security assessment methods using artificial intelligence techniques.},
  keywords={Deep learning;Training;Resistance;Wireless communication;Statistical analysis;Signal processing algorithms;Side-channel attacks;Optimization;Standards;Testing;side-channel analysis;artificial intelligence;countermeasures;security assessment methods},
  doi={10.1109/WiSPNET64060.2025.11005231},
  ISSN={},
  month={March},}@INPROCEEDINGS{10974319,
  author={Guo, Shijie and Zhu, Ming and Zhang, Jiawei and Min, Hang and Zhu, Wei},
  booktitle={2024 3rd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR)}, 
  title={Vision-and-Language Navigation Generative Pretrained Transformer}, 
  year={2024},
  volume={},
  number={},
  pages={38-42},
  abstract={In the domain of Vision-and-Language Navigation (VLN), agents are given the task of navigating through real-world environments, guided by verbal instructions. This poses a significant challenge in maintaining adherence to the provided linguistic instructions throughout the navigation process. Tra-ditional approaches typically employ encoders to meticulously track previous locations and actions, which, in turn, escalates the complexity of the model and the consumption of resources. Our approach introduces the Vision-and-Language Navigation Gen-erative Pretrained Transformer (VLN-GPT), which leverages a transformer decoder model (GPT2) to capture dependencies in the trajectory sequence, eliminating the requirement for separate modules to encode historical data. This strategy facilitates direct access to historical information via the trajectory sequence, thereby improving efficiency. Evaluations conducted on the VLN dataset demonstrate that our VLN-GPT model outperforms the more complex encoder-dependent models, highlighting its effectiveness in the field.},
  keywords={Human computer interaction;Navigation;Decision making;Reinforcement learning;Linguistics;Transformers;Trajectory;Decoding;History;Robots;Vision-and-Language Navigation;Generative Pretrained Transformer;Reinforcement Learning},
  doi={10.1109/AIHCIR65563.2024.00013},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11108954,
  author={Gomes, Chandima},
  booktitle={2025 13th Asia-Pacific International Conference on Lightning (APL)}, 
  title={Application of AI in Lightning and Thunderstorm Forecasting: A Vision for the Future}, 
  year={2025},
  volume={},
  number={},
  pages={228-233},
  abstract={The application of artificial intelligence (AI) in lightning forecasting and thunderstorm tracking is rapidly transforming atmospheric science by enhancing predictive accuracy and real-time monitoring capabilities. Traditional meteorological models rely on numerical weather prediction (NWP) techniques, which, despite their effectiveness, are computationally expensive and often lack the precision required for high-impact weather events. AI-driven approaches, particularly deep learning, machine learning, and neural networks, offer novel solutions by processing vast datasets from satellites, ground-based lightning detection networks, and radar systems with unparalleled speed and efficiency. This paper explores the integration of AI methodologies with conventional meteorological frameworks to improve short-term lightning forecasts and real-time thunderstorm tracking. We discuss recent advancements in AI-based convective storm prediction, the role of ensemble learning in minimizing forecast uncertainties, and the application of generative models for synthesizing realistic weather scenarios. Additionally, we highlight case studies demonstrating the efficacy of AI-driven nowcasting systems in reducing lightning-related casualties and infrastructure damage. The challenges associated with AI deployment in meteorology, including data biases, model interpretability, and computational constraints, are critically examined. Future research directions emphasize the need for hybrid models that blend AI with physics-based approaches, the potential of edge computing for real-time processing, and the prospects of AI-assisted early warning systems in mitigating lightning hazards. By bridging AI innovations with meteorological science, this study envisions a transformative shift in lightning forecasting, paving the way for more resilient disaster management strategies in a changing climate.},
  keywords={Computational modeling;Lightning;Weather forecasting;Predictive models;Alarm systems;Radar tracking;Real-time systems;Data models;Artificial intelligence;Meteorology;AI in meteorology;lightning prediction models;thunderstorm nowcasting;machine learning in weather forecasting;AI-based early warning systems},
  doi={10.1109/APL65034.2025.11108954},
  ISSN={},
  month={June},}@INPROCEEDINGS{10678704,
  author={Mitra, Modhurita and de Vos, Martine G. and Cortinovis, Nicola and Ometto, Dawa},
  booktitle={2024 IEEE 20th International Conference on e-Science (e-Science)}, 
  title={Generative AI for Research Data Processing: Lessons Learnt From Three Use Cases}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={There has been enormous interest in generative AI since ChatGPT was launched in 2022. However, there are concerns about the accuracy and consistency of the outputs of generative AI. We have carried out an exploratory study on the application of this new technology in research data processing. We identified tasks for which rule-based or traditional machine learning approaches were difficult to apply, and then performed these tasks using generative AI.We demonstrate the feasibility of using the generative AI model Claude 3 Opus in three research projects involving complex data processing tasks:1)Information extraction: We extract plant species names from historical seedlists (catalogues of seeds) published by botanical gardens.2)Natural language understanding: We extract certain data points (name of drug, name of health indication, relative effectiveness, cost-effectiveness, etc.) from documents published by Health Technology Assessment organisations in the EU.3)Text classification: We assign industry codes to projects on the crowdfunding website Kickstarter.We share the lessons we learnt from these use cases: How to determine if generative AI is an appropriate tool for a given data processing task, and if so, how to maximise the accuracy and consistency of the results obtained.},
  keywords={Industries;Drugs;Accuracy;Crowdfunding;Codes;Generative AI;Machine learning;Generative AI;Large Language Models;artificial intelligence;data processing;accuracy of results;consistency of results;reliability of research method},
  doi={10.1109/e-Science62913.2024.10678704},
  ISSN={2325-3703},
  month={Sep.},}@INPROCEEDINGS{11137298,
  author={Murri, Srinivas},
  booktitle={2025 1st International Conference on Secure IoT, Assured and Trusted Computing (SATC)}, 
  title={Data Engineering for Intelligent Systems and Generative AI: Architectures, Pipelines, and Strategy}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Integrating generative AI and data engineering greatly enhances intelligent systems by addressing scalability, effectiveness, and real-time efficiency issues. Data engineering establishes the foundation to handle large and complex datasets, while generative AI streamlines these processes by automating repetitive tasks, detecting anomalies, and optimizing query performance. This paper discusses the essential concepts of data pipelines, including modularity, scalability, and automation, which are necessary to support large-scale data environments. Key components of a data pipeline, such as data sources, data flows, processing, and monitoring, are examined to enhance the data preparation process for analysis. This research contributes to the growing evidence showing how generative AI transforms data workflow optimization, particularly for machine learning (ML) pipelines and natural language processing (NLP). The literature review explores innovative developments in generative AI, NLP, and data engineering technologies, highlighting various use cases. Several studies demonstrate that generative AI can reduce costs, improve data quality, and simplify complex data transformations. Additionally, challenges related to data privacy, ethical considerations, and computational expenses are addressed, with future research directions proposed to enhance data pipeline efficiency and AI-driven processes. The findings of this study provide a clearer understanding of how data engineering practices can be combined with AI technologies to support innovation and create more efficient intelligent systems.},
  keywords={Trusted computing;Generative AI;Scalability;Data integrity;Pipelines;Computer architecture;Transforms;Data engineering;Natural language processing;Intelligent systems;Data Engineering;Generative AI;Intelligent Systems;Artificial Intelligence;Data Pipeline;Architectures;lifecycle;Data Quality},
  doi={10.1109/SATC65530.2025.11137298},
  ISSN={},
  month={Feb},}@ARTICLE{10844093,
  author={Ishak, Mohamad Khairi},
  journal={IEEE Access}, 
  title={Mathematical Modeling of Cyberattack Defense Mechanism Using Hybrid Transfer Learning With Snow Ablation Optimization Algorithm in Critical Infrastructures}, 
  year={2025},
  volume={13},
  number={},
  pages={13329-13340},
  abstract={Cybersecurity is a significant topic that has turned into an efficient one at present owing to the increasing dependency on interconnected methods and technology. As digitalization upsurges, the requirement for cybersecurity measures becomes even more vital for numerous networks. To certify the security of critical infrastructures, numerous cyber security solutions must be taken together and the essential infrastructure must be developed. Industrial control methods are one of the most vital aspects of the cybersecurity of critical infrastructures. It is possible to entirely stop these physically located devices’ operations and do substantial destruction with a cyberattack. Whereas AI solutions are being utilized in numerous fields, cyber security has started to become one of the concentrated fields of artificial intelligence (AI) domain. Consequently, there are many studies on identifying cyberattacks by utilizing AI methods. It is probable to utilize AI to help and support cybersecurity solutions to develop cybersecurity of significant infrastructures. This study develops a Cyberattack Defense Mechanism using Hybrid Transfer Learning with Snow Ablation Optimization Algorithm (CDMHTL-SAOA) technique in Critical infrastructures. The main cause of the CDMHTL-SAOA model is to improve the cyber security maturity level of critical infrastructures and inspect both traditional cyberattack and AI approaches. Primarily, the data normalization process can be implemented to scale the raw data into a uniform format. In addition, the snow ablation optimization (SAO) algorithm can be exploited for the optimum choice of feature subsets. For the cybersecurity classification process, the presented CDMHTL-SAOA technique applies the hybrid of convolutional neural network and bi-directional long short-term memory (CNN-BiLSTM) method. Eventually, the parameter choice of the CNN-BiLSTM technique has been implemented by the design of the hippopotamus optimization algorithm (HOA). To represent the better solution of the CDMHTL-SAOA classifier, a simulation validation can be tested on a benchmark database and the solutions are measured for various aspects. The simulation outcomes certified the improved execution of the CDMHTL-SAOA method over other techniques.},
  keywords={Snow;Computer security;Security;Cyberattack;Artificial intelligence;Optimization;Critical infrastructure;Classification algorithms;Transfer learning;Vectors;Cyberattack;hybrid transfer learning;snow ablation optimization;hyperparameter selection;data normalization},
  doi={10.1109/ACCESS.2025.3530931},
  ISSN={2169-3536},
  month={},}@ARTICLE{10930479,
  author={Guo, Huijie and Xing, Xudong and Zhou, Yongjie and Jiang, Wenjiao and Chen, Xiaoyi and Wang, Ting and Jiang, Zixuan and Wang, Yibing and Hou, Junyan and Jiang, Yukun and Xu, Jianzhen},
  journal={IEEE Access}, 
  title={A Survey of Large Language Model for Drug Research and Development}, 
  year={2025},
  volume={13},
  number={},
  pages={51110-51129},
  abstract={Drug research and development (drug R&D) is a sophisticated, cost-intensive, and time-consuming procedure with historically low success rates. The advent of Artificial Intelligence (AI) technologies has introduced innovative methods into drug R&D, particularly by leveraging AI capabilities. Large language models (LLMs), a breakthrough in generative AI, have revolutionized drug discovery. With their extensive datasets, numerous parameters, and strong multitasking abilities, LLMs have significantly improved efficiency across various related domains, providing unparalleled support to drug R&D. These models have facilitated a deeper understanding of intricate disease mechanisms and the identification of novel therapeutic strategies, ushering in a new era in drug development and clinical applications. As a result, the advancement of LLMs is poised to drive significant transformations in drug R&D, emphasizing the importance of effectively leveraging this technology. This review provides insights into the architecture and characteristics of LLMs, explores their applications in drug R&D, and highlights their research implications in bioinformatics data, including proteins, genes, and chemical compounds. Furthermore, it investigates the practical strategies of LLMs in drug discovery, drug repositioning, and clinical inquiries, presenting an innovative approach to research and future advancements in this field.},
  keywords={Drugs;Research and development;Artificial intelligence;Clinical trials;Costs;Biology;Drug discovery;Safety;Diseases;Speech recognition;Large model;artificial intelligence;transformer;drug research and development},
  doi={10.1109/ACCESS.2025.3552256},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10743442,
  author={Jiang, Benrui and Chen, Kan and Hou, Guanyu and Chen, Xiying and He, Jiaming},
  booktitle={2024 9th International Conference on Intelligent Computing and Signal Processing (ICSP)}, 
  title={Embedding Based Sensitive Element Injection against Text-to-Image Generative Models}, 
  year={2024},
  volume={},
  number={},
  pages={453-456},
  abstract={Text-to-image technique has exploded the research on artificial intelligence, and also deep learning technique has received widespread attentions. This technique is an emerging direction of deep learning. It is becoming increasingly popular among researchers and the public. Unfortunately, we found that text-to-image technique has certain security issues, especially adversarial and backdoor attacks. In our work, we explore a novel attack paradigm for the text-to-image scenarios. By our attack, we will use target embeddings to manipulate the user embeddings to generate malicious images. We designed a framework to verify our attack, and the experimental result shows that the efficiency of our attack is 95%, this data proves the effectiveness of our experiments.},
  keywords={Deep learning;Text to image;Signal processing;Security;Text-to-image;Adversarial Attacks;Text Encoder;Transformer},
  doi={10.1109/ICSP62122.2024.10743442},
  ISSN={},
  month={April},}@INPROCEEDINGS{11025027,
  author={Samudra, Bima Surya and Baihaqi, Imam and Isnaini, Fadila},
  booktitle={2024 IEEE Technology & Engineering Management Conference - Asia Pacific (TEMSCON-ASPAC)}, 
  title={The Use of Generative AI in Workplace: Driving Factors, Barriers, and Benefits}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={This study investigates the intention to use generative artificial intelligence (Gen AI) in the workplace based on the Unified Theory of Acceptance and Use of Technology (UTAUT) model. Survey was conducted using an online platform and randomly distributed amongst office workers in Indonesia, gathered 150 responses. Data were analyzed using Partial Least Squares Structural Equation Modeling (PLS-SEM). The results show that performance expectations and facilitating conditions significantly influence behavioral intentions to adopt Gen AI, while ease of use and social influence show limited impacts. Organizations should focus on developing infrastructure and providing technical support to better use in workplaces, thus increasing the adoption and satisfaction of users or workers with Gen AI technology.},
  keywords={Training;Surveys;Productivity;Adaptation models;Generative AI;Employment;Mathematical models;Regulation;Manufacturing;Artificial intelligence;Artificial Intelligence (AI);UTAUT;Manufacturing;Service},
  doi={10.1109/TEMSCON-ASPAC62480.2024.11025027},
  ISSN={},
  month={Sep.},}@INBOOK{10982345,
  author={Bergeret, Olivier and Abbasi, Asif and Farvault, Joel},
  booktitle={GenAI on AWS: A Practical Approach to Building Generative AI Applications on AWS}, 
  title={Glossary}, 
  year={2025},
  volume={},
  number={},
  pages={323-332},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394281305},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10982345},}@INPROCEEDINGS{10803506,
  author={Teng, Jiayi and Yang, Fan and Zhang, Qingke and Zhao, Yaoyao and Li, Na and Li, Qian},
  booktitle={2024 IEEE International Conference on Medical Artificial Intelligence (MedAI)}, 
  title={Variational Disentangled Generative Model for Individualized Treatment Effect Estimation}, 
  year={2024},
  volume={},
  number={},
  pages={635-644},
  abstract={Estimating individualized treatment effect (ITE) from observational data is a challenging problem due to the lack of counterfactual outcomes and the presence of selection bias. Existing ITE estimation methods, which primarily focus on disentangled representation learning, have achieved significant success in estimating treatment effects. However, precisely learning disentangled latent factors remains an open problem. In this paper, we propose a Variational Disentangled Generative Model (VDGM) based on a collaborative strategy of Variational Auto-Encoder (VAE), Generative Adversarial Net (GAN), and Mutual Information Network Estimation. VDGM infers latent factors from observed covariates by VAE, disentangling factors into three disjoint sets corresponding to the instrumental, confounding, and adjustment factors. The disentangled latent factors can then be used to balance the distribution discrepancy between treatment and control groups, thereby reducing selection bias. Furthermore, VDGM addresses information loss by preserving useful predictive information under the regularization of a mutual information estimator. It also uses mutual information estimators to maintain the independence of disentangled latent factors. Additionally, our model uses the GAN framework to generate counterfactual outcomes for ITE estimation. Experimental results on synthetic and real-world datasets show that the proposed method outperforms the baselines in achieving low errors in ITE estimation.},
  keywords={Instruments;Disentangled representation learning;Estimation;Collaboration;Generative adversarial networks;Artificial intelligence;Mutual information;Individualized treatment effect;Disentangled representation learning;Mutual information network estimation},
  doi={10.1109/MedAI62885.2024.00089},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10968513,
  author={Arora, Manali and Garg, Chirag and Mangla, Deepanshu},
  booktitle={2025 International Conference on Machine Learning and Autonomous Systems (ICMLAS)}, 
  title={Validation of Generative Visual Solutions Using Prompt Engineering and Caption Based Visual Reasoning Models}, 
  year={2025},
  volume={},
  number={},
  pages={537-543},
  abstract={We introduce the novel approach of validation of artificially generated images which helps to validate the images based on the prompt given for the generated image. Existing methods involve generation of images based on the prompts, diffusion of images and modification of images, but fail to determine the correctness of the generated image with respect to the generated content and prompt given at user end. The prompt used for generating the image using generative artificial intelligence solutions can be comprehensive and can hold more than single perspective. To address this issue while validating computer visual solutions, we propose a method for the validation of generative visual solutions using prompt engineering and caption based visual reasoning models. The proposed solution determines the different perspectives and comprehensiveness of the prompts based on entities and attributes and then, multiple test cases are formed considering different perspectives, in more detailed and comprehensive format. Hence, proposed solution validates the generated image based on the text prompt engineered for comprehensive understanding based on the complexity of the prompt suitable for visual reasoning models.},
  keywords={Visualization;Scalability;Computational modeling;Machine learning;Reliability engineering;Distortion;Cognition;Reflection;Prompt engineering;Testing;Visual reasoning;Prompt Engineering;LLM;Generative AI;Validation},
  doi={10.1109/ICMLAS64557.2025.10968513},
  ISSN={},
  month={March},}@INPROCEEDINGS{11100283,
  author={Stojanović, Dimitrije and Vidaković, Luka and Pavković, Bogdan and Četić, Nenad and Krunić, Momčilo},
  booktitle={2025 IEEE Zooming Innovation in Consumer Technologies Conference (ZINC)}, 
  title={Comparison of AWS Architectures for Scalable and Cost-Efficient Retrieval-Augmented Generation}, 
  year={2025},
  volume={},
  number={},
  pages={20-24},
  abstract={Large Language Models (LLMs) require up-to-date and domain-specific knowledge to generate accurate responses. As demand for generative Artificial intelligence (AI) applications grows, there is a need for Retrieval-Augmented Generation (RAG) architectures that can dynamically scale and efficiently manage resources. Conventional deployments on Amazon EC2 face challenges in scalability, cost efficiency, and operational complexity, making it difficult to adapt quickly to unpredictable workloads. Another approach is serverless RAG architecture on AWS that leverages Lambda, Amazon S3, DynamoDB, and API Gateway to automate scaling, reduce management overhead, and implement a cost-effective, pay-per-use model. Our evaluation demonstrates that a serverless approach can give savings of up to 87% for loads of 10000 requests per hour compared to EC2 instances while meeting the performance and efficiency requirements of modern AI applications. Serverless architecture establishes a pathway for developing more resilient and scalable cloud-based generative AI systems.},
  keywords={Technological innovation;Generative AI;Scalability;Large language models;Retrieval augmented generation;Serverless computing;Computer architecture;Logic gates;Zinc;Load modeling;Cloud computing;Serverless computing;Retrieval-Augmented Generation;Scalability;Generative AI},
  doi={10.1109/ZINC65316.2025.11100283},
  ISSN={2995-2689},
  month={May},}@INPROCEEDINGS{10828732,
  author={Juliet, A. Hency},
  booktitle={2024 7th International Conference on Contemporary Computing and Informatics (IC3I)}, 
  title={Deep Learning Model Design for Blood Cancer Prediction through AI-Driven Strategies}, 
  year={2024},
  volume={7},
  number={},
  pages={60-65},
  abstract={The study seeks to create and utilize sophisticated deep learning model namely Convolutional Neural Network (CNN) designed for image classification purposes. It’s a custom CNN architecture tailored for the task, to classify images of blood cells into eight distinct categories. It comprises several layers, starting with convolutional layers followed by max-pooling layers, and fully connected layers empowered by AI technique, aiming to precisely forecast different forms of blood cancer using a dataset comprising images of blood cells. Ensuring the consistency and quality of input data, especially in medical imaging datasets susceptible to variations affecting model performance, poses a significant challenge; improving the interpretability and explainability of deep learning models is crucial for their reliable incorporation into clinical decision-making processes for blood cancer prediction. Utilize sophisticated deep learning model design methodologies guided by Artificial Intelligence approaches, tailored to address the unique characteristics of the blood cell image dataset, in order to surmount the outlined challenges. The suggested system provides improved precision and effectiveness in predicting blood cancer by employing advanced deep learning models guided by customized Artificial Intelligence techniques. Throughout the span of 50 epochs, the model’s performance was assessed based on its training and validation accuracy, gradually enhancing until reaching final rates of about 90.31% for training and 90% for validation.},
  keywords={Deep learning;Training;Accuracy;Cells (biology);Predictive models;Data models;Convolutional neural networks;Artificial intelligence;Blood;Cancer;Deep Learning Model Design;Convolutional Neural Network;Blood Cancer Prediction;AI-Driven Strategies;Image Classification;Custom Architecture;Max-pooling;Clinical Decision-making},
  doi={10.1109/IC3I61595.2024.10828732},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11019305,
  author={Rani, P. Shobha and Neela, K. and Chandanavalli, P. and B, Ashwini and K, Sachin and R, Vijay Sai Raj},
  booktitle={2025 International Conference on Computing and Communication Technologies (ICCCT)}, 
  title={GenAI Workforce Evaluation System}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={A widely used approach in emotional analysis is the BOW model, which is also popular in traditional theme modeling. However, an important limitation to the bow model is that it often considers two contrasting emotional texts as the same due to dependence on individual terms. This results in a change in polarity that the machine learning models struggle to handle effectively. We recommend integrating a semantic analysis program with a relevant dividing line to overcome this challenge to improve accuracy. By taking advantage of a generative AI-based model, we can expand emotions and increase classification. Transformer-based architecture as generic AI models offers advanced abilities in understanding relevant meanings and emotional shades, leading to more accurate emotions and analysis results. Implementation of Generic AI in emotional analysis can revolutionize emotional applications, including the recommended system, customer response evaluation and social media tracking. Applying AI-controlled methods will enable decision-making in different domains and improve user experiences, more accurate in reference-u-extensional emotional classification, reference income-ownable emotion classification.},
  keywords={Analytical models;Accuracy;Social networking (online);Generative AI;Semantics;Decision making;Machine learning;Computer architecture;Transformers;Communications technology;Semantic analysis;Generative AI;Emotional classification;Social media tracking},
  doi={10.1109/ICCCT63501.2025.11019305},
  ISSN={2995-3197},
  month={April},}@INPROCEEDINGS{10274928,
  author={Paroiu, Razvan and Trausan-Matu, Stefan},
  booktitle={2023 22nd RoEduNet Conference: Networking in Education and Research (RoEduNet)}, 
  title={Assisting students to compose music with deep neural networks and aesthetic measurement feedback}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper introduces a novel approach that enables students to compose music using deep neural networks while simultaneously gaining insights into the functionality of various mathematically computed aesthetic measures. While there are existing applications that allow users to compose music with artificial intelligence, they often lack the feedback, which may be provided by newly developed mathematical aesthetic measurement techniques. Our approach bridges this gap by providing users with objective feedback for their generated melodies, fostering a better understanding of the underlying measurement methods. The application was evaluated by multiple participants, which made us aware of both the strengths and limitations of the application.},
  keywords={Bridges;Atmospheric measurements;Education;Music;Artificial neural networks;Measurement techniques;Gain measurement;computer music generation;artificial intelligence;neural networks;aesthetic measurement;deep learning},
  doi={10.1109/RoEduNet60162.2023.10274928},
  ISSN={2247-5443},
  month={Sep.},}@ARTICLE{10879254,
  author={Zhang, Zhihang and Yuan, Xianfeng and Ye, Tianyi and Zhu, Weijie and Zhou, Fengyu},
  journal={IEEE Sensors Journal}, 
  title={Bidirectional Local–Global Interaction-Guided GAN With Discriminator Gradient Gap Regularization for Bearing Fault Diagnosis With Unbalanced Datasets}, 
  year={2025},
  volume={25},
  number={6},
  pages={10498-10511},
  abstract={In complex industrial environments, mechanical devices predominantly operate under normal conditions, resulting in a shortage of available fault samples. This imbalance significantly impedes the effectiveness of intelligent fault diagnosis approaches. To overcome the challenge, an innovative generative adversarial network (GAN) model is proposed in this study, termed the bidirectional local–global interaction-guided GAN with discriminator gradient gap regularization (Bi-Interaction GAN). First, the generator is designed to incorporate a bidirectional interaction mechanism that accounts for the interaction between local and global features of vibration signals, effectively capturing the deep relationships between local and global information in the bearing vibration signals with limited datasets. Subsequently, the stability of the model is enhanced by introducing a novel loss function that integrates discriminator gradient gap regularization with the Wasserstein distance. This approach aims to minimize the gradient discrepancy between real and generated samples in the discriminator, thereby facilitating a more stable training process. Extensive comparative experiments are carried out to validate the proposed approach using a widely utilized dataset and realistic experimental configuration. The results indicate that the Bi-Interaction GAN outperforms existing state-of-the-art (SOTA) GAN models in generating superior-quality samples while achieving high classification accuracy.},
  keywords={Generative adversarial networks;Fault diagnosis;Training;Vibrations;Vectors;Hands;Generators;Costs;Artificial intelligence;Accuracy;Bidirectional local-global interaction;discriminator gradient gap regularization;generative adversarial network (GAN);imbalanced fault diagnosis},
  doi={10.1109/JSEN.2025.3538320},
  ISSN={1558-1748},
  month={March},}@INPROCEEDINGS{9361182,
  author={Chen, Yue and Yang, Xirui and Cheng, Kun and Li, Yi and Liu, Zhiwen and Shi, Yonggang},
  booktitle={2020 International Conference on Artificial Intelligence and Computer Engineering (ICAICE)}, 
  title={Efficient 3D Neural Networks with Support Vector Machine for Hippocampus Segmentation}, 
  year={2020},
  volume={},
  number={},
  pages={337-341},
  abstract={Accurate segmentation of the hippocampal and its subfields from the brain magnetic resonance imaging (MRI), which is a prerequisite for volume measurement, plays a significant role in the clinical diagnosis and treatment of many neurodegenerative diseases. It is of great significance for the precise segmentation of the hippocampus and its sub-regions.In this paper, we proposed a hippocampal subfields segmentation approach based on support vector machine (SVM) combined 3D convolutional neural network (3D CNN) and generative adversarial network (GAN). In the 3D CNN-SVM model, the representative features processed by the 3D CNN are input into the SVM. SVM is trained with the features to achieve the voxel classification of the image, and the segmentation results are obtained. In the 3D GAN-SVM model, we use the generator to segment and use the 3D CNN-SVM network we proposed as the discriminator.The experiments has performed on the dataset obtained from Center for Imaging of Neurodegenerative Diseases (CIND) in San Francisco, USA. The segmentation dice similarity coefficients (DSCs) of the 3D CNN-SVM for CAI, CA2, DG, CA3, Head, Tail, SUB, ERC and PHG in hippocampal subfields are respectively 0.930, 0.926, 0.977, 0.967, 0.931, 0.905, 0.981, 0.870 and 0.911. It demonstrates that combining 3D CNN and SVM achieves a significant improvement in the accuracy of all the hippocampal subfields, and outperforms the existing methods based on the CNN. The DSCs of 3D GAN-SVM are higher, which are respectively 0.989, 0.965, 0.986, 0.977, 0.975, 0.993, 0.818, 0.985 and 0.994. The effect of the GAN-SVM model is also significantly better than that of pure GAN, and the segmentation accuracy has reached the best level on this dataset.Neural network can extract representative features, but it mainly relies on extracting features from a large number of accurately labeled datasets. Most medical datasets are small and difficult to obtain. SVM is more suitable for classification of small datasets, so we combine SVM and neural network to effectively improve the segmentation accuracy of hippocampus in brain MRI images.},
  keywords={Support vector machines;Image segmentation;Three-dimensional displays;Magnetic resonance imaging;Feature extraction;Generative adversarial networks;Hippocampus;hippocampal subfields segmentation;3D convolutional network;support vector machine;generative adversarial},
  doi={10.1109/ICAICE51518.2020.00071},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10108162,
  author={Liao, Junzhe},
  booktitle={2022 2nd International Conference on Big Data, Artificial Intelligence and Risk Management (ICBAR)}, 
  title={A Study on Neural Style Transfer Methods for Images}, 
  year={2022},
  volume={},
  number={},
  pages={60-64},
  abstract={Image style transfer techniques have been around for almost twenty years. In particular, the rise of deep learning has gradually influenced traditional image transfer techniques, eventually giving rise to new neural image transfer techniques. This paper covers an introduction to traditional style transfer techniques, including Stroke-based rendering, image filtering, image analogy and texture synthesis, as well as a categorization of various current classic neural image style transfer methods including slow neural method, fast neural method and generative adversarial networks (GAN) based neural style transfer method. In addition, this paper covers commonly used training datasets for style transfer. Finally, the challenges of neural image style transfer are discussed, and the possible future research directions are contained.},
  keywords={Deep learning;Training;Big Data;Rendering (computer graphics);Generative adversarial networks;Image filtering;Risk management;neural style transfer;deep learning;convolutional neural network;image rendering;generative adversarial nets;texture synthesis},
  doi={10.1109/ICBAR58199.2022.00019},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10760979,
  author={Balasubramani, Jagadesh and Surendran, R},
  booktitle={2024 2nd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS)}, 
  title={Utilizing Hybrid-Deep Learning for Autism Spectrum Disorder Detection in Children via Facial Emotion Recognition}, 
  year={2024},
  volume={},
  number={},
  pages={487-492},
  abstract={Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder that significantly impacts social interaction and communication. Early detection and intervention are crucial for optimal outcomes. This research investigates the use of deep learning techniques to identify ASD based on facial emotion analysis. The proposed approach leverages Self-Attention-Based Progressive Generative Adversarial Networks (SA-PGAN) optimized with the Gorilla Troops Optimizer (GTO) to accurately recognize subtle facial cues associated with ASD. The model is trained on a dataset of facial images from autistic children, undergoing extensive preprocessing to ensure data quality and consistency. The performance of the proposed model is evaluated using various metrics, including accuracy, precision, recall, F1-score, and computational time. The results demonstrate significant improvements over state-of-the-art methods, such as Random Forest (RF), Support Vector Machine (SVM), and Convolutional Neural Networks (CNN). This research contributes to the development of advanced AI-powered tools for early ASD detection, enabling timely interventions and improving the quality of life for individuals with ASD.},
  keywords={Support vector machines;Radio frequency;Measurement;Autism;Accuracy;Computational modeling;Face recognition;Generative adversarial networks;Convolutional neural networks;Random forests;Deep Learning;Autism Spectrum Disorder (ASD);Self-Attention-Based Progressive Generative Adversarial Networks (SA-PGAN);Gorilla Troops Optimizer (GTO);Facial Landmark Analysis},
  doi={10.1109/ICSSAS64001.2024.10760979},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9339146,
  author={Cai, Yuan and Song, Fei and Xu, Yifan and Liu, Xiaodu and Zhang, Xiao and Han, Hao},
  booktitle={2020 IEEE 9th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={Spectrum Waterfall Completion in Jamming Enviroment: A General Adversarial Networks Method}, 
  year={2020},
  volume={9},
  number={},
  pages={1661-1665},
  abstract={It is very important for completing spectrum data in the wireless communication system. The traditional completion method mainly considered the missing completion operation of sparse data. To solve this problem, we proposed an efficient algorithm based on generative adversarial network (GAN), which can automatically mine the relationship of the data and complete the missing data accurately. The proposed method uses the sensing spectrum waterfall as the input sample of the network structure. We adopt a pre-classification module and generation module based on GAN to generate incomplete spectrum data in multiple jamming patterns. Simulation results show that the proposed algorithm can effectively complete the missing data, and its performance is better than that of the data completion algorithm without a clssifier.},
  keywords={Wireless communication;Simulation;Generative adversarial networks;Generators;Sensors;Jamming;Gallium nitride;Spectrum waterfall completion;generative adversarial network;wireless communication},
  doi={10.1109/ITAIC49862.2020.9339146},
  ISSN={2693-2865},
  month={Dec},}@INPROCEEDINGS{10957177,
  author={Liao, Bin and Guo, Zipei and Liao, Maotian and Shen, Xiaonan and Zou, Yu},
  booktitle={2025 International Conference on Electrical Automation and Artificial Intelligence (ICEAAI)}, 
  title={Research on Distribution Grid Line Defect Identification and Classification Methods in UAV Inspection}, 
  year={2025},
  volume={},
  number={},
  pages={144-148},
  abstract={With the development of the power system, the application of UAVs in distribution network inspection is becoming more and more widespread, therefore, this paper carries out research on the algorithms for distribution network line defects, solves the problems of fewer samples for acceptance of line engineering defects, poorer training effect, and lower model recognition accuracy, and researches a method for the identification and categorization of line defects in distribution networks. Firstly, through the sample data enhancement technique, the generalization ability of the model is improved, overfitting is reduced, and the robustness of the model to the input data is enhanced; secondly, the Generative Adversarial Network (GAN) is introduced to generate the antagonistic samples, which significantly reduces the amount of computational effort; finally, in combination with the Transformer architecture, an algorithm applicable to the recognition of line defects of power distribution grids is proposed, which improves the algorithm's performance in the complex scenario. The experimental results show that the method in this paper has significant improvement in the accuracy of defect recognition, computational efficiency and anti-interference ability, which provides a new technical solution for distribution network line defect detection.},
  keywords={Accuracy;Computational modeling;Atmospheric modeling;Distribution networks;Inspection;Generative adversarial networks;Transformers;Autonomous aerial vehicles;Data models;Robustness;unmanned aircraft inspection;distribution network line;defect recognition;generative adversarial network},
  doi={10.1109/ICEAAI64185.2025.10957177},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10920590,
  author={Fan, Zhongding and Liu, Xianzeng and Cao, Zheng and Wang, Hang and Zhou, Yuanyuan and Liu, Yongbin},
  booktitle={2024 International Conference on Sensing, Measurement & Data Analytics in the era of Artificial Intelligence (ICSMD)}, 
  title={Multi-Sensor Data Fusion and Augmentation for Imbalanced Fault Diagnosis of Bearings}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Stable operation of bearing is required, while on the other side, it can lead to insufficient fault data collection and imbalanced data, which further deteriorates the performance of deep learning(DL) methods in the fault diagnosis of bearings. In this paper, a novel method combining multi-sensor data fusion and augmentation for bearing imbalanced fault diagnosis is proposed. First, the limited real fault samples are fed into the one-dimensional Wasserstein generative adversarial network with gradient penalty (1D-WGAN-GP) to generate the fake samples for augmenting the fault data. Then, the features of augmented data from different sensors are extracted and fused by using the proposed multi-branch one-dimensional convolutional neural network (1D-MCNN). Finally, imbalanced fault diagnosis of bearings is achieved based on the fused features. The performance of the proposed method is verified experimentally. The results show that, compared to existing methods the proposed method can be used to fuse fault features from multiple sensors, and effectively enhance the fault data, thereby achieving excellent accuracy and stability under the imbalanced data of bearing.},
  keywords={Fault diagnosis;Vibrations;Accuracy;Data integration;Sensor fusion;Sensor phenomena and characterization;Feature extraction;Generative adversarial networks;Data augmentation;Data mining;Bearing;Imbalanced fault diagnosis;Generative adversarial network;Data augmentation;Features fusion},
  doi={10.1109/ICSMD64214.2024.10920590},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10108310,
  author={Huang, Jiashu},
  booktitle={2022 2nd International Conference on Big Data, Artificial Intelligence and Risk Management (ICBAR)}, 
  title={Multitrack Symbolic Music Composition with LSTM-GAN}, 
  year={2022},
  volume={},
  number={},
  pages={35-40},
  abstract={Music generation is becoming a heated subject in the field of machine learning. Particularly, in the direction of multitrack, sequential, and symbolic music composition, methods based on generative adversarial networks (GAN) such as MuseGAN and BinaryMuseGAN have shown outstanding performance and have been adopted by many researchers. However, there are still issues in musicality and temporal correlation that need to be addressed. In this paper, an LSTM-based GAN is proposed in order to capture more temporal information from real-world music samples. One bar is seen as the smallest unit and fed into the LSTM network in the discriminator. Additionally, a processor is added between the generator and the discriminator to extract important information from the data. This LSTM-GAN scheme helps the discriminator find important differentiators more quickly and hence improves the ability of the generator to fabricate authentic data. The proposed method is validated via experiments, where the generated data shows similarities with the authentic ones.},
  keywords={Heating systems;Correlation;Machine learning;Big Data;Generative adversarial networks;Generators;Risk management;music generation;generative adversarial network;generator;discriminator;LSTM},
  doi={10.1109/ICBAR58199.2022.00014},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10934534,
  author={Jiang, Xinran and Li, Daiwei and Zhang, Haiqing and Zhou, Ying and Liu, Jialing and Xiang, Xiaoming},
  booktitle={2024 4th International Symposium on Artificial Intelligence and Intelligent Manufacturing (AIIM)}, 
  title={Weighted Strategy Optimization Approach for Discrete Sequence Generation}, 
  year={2024},
  volume={},
  number={},
  pages={843-846},
  abstract={Generative Adversarial Networks (GANs) perform well in continuous data generation, but face challenges in discrete sequence generation due to the non-differentiability of backpropagation. SeqGAN addresses this issue by utilizing the policy gradient method; however, it still suffers from limitations such as low efficiency, inadequate reward utilization, and a tendency to converge to local optima. This paper proposes a discrete sequence generation model, W-SeqGAN, which is based on Weighted Policy Optimization (WPO). This model incorporates WPO into the training process of the generator. Its dynamic weighting mechanism ena bles the generator to focus on samples with strong discriminator feedback or those that are difficult to generate, thereby enhancing the generation quality. Experiments were conducted using synthe tic data, and the Negative Log Likelihood (NLL) was adopted as t he evaluation metric. The results indicate that W-SeqGAN outper forms traditional SeqGAN and other baseline models in terms of generation quality and training efficiency.},
  keywords={Training;Measurement;Gradient methods;Data collection;Generative adversarial networks;Generators;Stability analysis;Manufacturing;Optimization;Faces;Generative Adversarial Networks;Sequence Generation;Weighted Policy Optimization},
  doi={10.1109/AIIM64537.2024.10934534},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10575170,
  author={Paroha, Abhay Dutt},
  booktitle={2024 3rd International Conference on Applied Artificial Intelligence and Computing (ICAAIC)}, 
  title={Rate of Penetration Prediction using Batch Normalized Deep Elman Neural Network}, 
  year={2024},
  volume={},
  number={},
  pages={34-40},
  abstract={Exploration, drilling, and extraction are basic components of the upstream process in the oil and gas industry. Rate of Penetration (ROP) is an essential component of the drilling process because it dictates the rate at which materials fracture to enlarge the aperture. For time and money savings, early ROP prediction is critical, but current methods are defective. To enhance ROP prediction, BG-DEL, an innovative method, combines Batch Normalization with a Deep Elman Neural Network based on the Gaussian Error Linear Unit. Following the proper preparation of the data, the subsequent operations are executed: clustering using WFFC, value generation utilizing LRF-GAN, and correlation calculation. To evaluate a classifier that has been trained to predict ROP using database values, this study employs L2CO method for parameter selection. The experimental evaluation yields substantial advantages for the upstream sector of the oil and gas industry. It demonstrates a 98.9% accuracy rate and a correlation coefficient of 0.95. Keywords-Rate of Penetration (ROP), Ward Farthest First Clustering (WFFC), Linear Regression Function based Generative Adversarial Network (LRF-GAN), Laplace Crossover Operator based Coot Optimization (L2CO), Batch Normalized.},
  keywords={Drilling;Correlation coefficient;Accuracy;Databases;Neural networks;Linear regression;Generative adversarial networks;Rate of Penetration (ROP);Ward Farthest First Clustering (WFFC);Linear Regression Function based Generative Adversarial Network (LRF-GAN);Laplace Crossover Operator based Coot Optimization (L2CO);Batch Normalized},
  doi={10.1109/ICAAIC60222.2024.10575170},
  ISSN={},
  month={June},}@INPROCEEDINGS{9797676,
  author={Zhang, Minghao and He, Lingmin and Wang, Xiuhui},
  booktitle={2021 2nd International Conference on Artificial Intelligence and Computer Engineering (ICAICE)}, 
  title={Image Translation based on Attention Residual GAN}, 
  year={2021},
  volume={},
  number={},
  pages={802-805},
  abstract={Using Generative Adversarial Networks (GAN) to translate images is a significant field in computer vision. There are partial distortion, artifacts and detail loss in the images generated by current image translation algorithms. In order to solve this problem, this paper adds attention-based residual neural network to the generator of GAN. Attention-based residual neural network can improve the representation ability of the generator by weighting the channels of the feature map. Experiment results on the Facades dataset show that Attention Residual GAN can translate images with excellent quality.},
  keywords={Training;Degradation;Deep learning;Computer vision;Neural networks;Generative adversarial networks;Distortion;image translation;Generative Adversarial Networks;residual neural network;attention mechanism},
  doi={10.1109/ICAICE54393.2021.00156},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10933659,
  author={Li, Jia and Cheng, Xien and Luan, Wenye},
  booktitle={2024 5th International Conference on Computer, Big Data and Artificial Intelligence (ICCBD+AI)}, 
  title={Color Image Information Hiding Based on Attention GAN}, 
  year={2024},
  volume={},
  number={},
  pages={301-305},
  abstract={Image steganography aims to embed secret information into images to achieve data steganography. Aiming at the problems of insufficient feature expression ability, poor model flexibility, and poor quality of steganographic images in existing methods, this paper proposes an image steganography method based on attention generative adversarial networks. By introducing a combination of global attention mechanism, adaptive convolution module, and deep convolution block, the feature expression ability and the accuracy of image restoration are improved, while a customized discriminator is used to ensure the quality and authenticity of the steganographic image. The adaptive convolution module is able to dynamically adjust the size and number of convolution kernels according to the features of the input image, which effectively improves the flexibility and generalization ability of the model and reduces the consumption of computational resources. In this paper, experimental validation is carried out on COCO, CelebA and ImageNet datasets, and the results show that the method has obvious advantages over existing deep learning steganography techniques in terms of steganographic capacity, security, robustness and imperceptibility.},
  keywords={Steganography;Adaptation models;Visualization;Attention mechanisms;Accuracy;Convolution;Generative adversarial networks;Robustness;Stability analysis;Image restoration;Image Steganography;Generative Adversarial Network;Encoder-Decoder Network;Attention Mechanism},
  doi={10.1109/ICCBD-AI65562.2024.00057},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9904077,
  author={Zhang, Xiao and Chen, Ming and Wu, Dongliu},
  booktitle={2022 5th International Conference on Pattern Recognition and Artificial Intelligence (PRAI)}, 
  title={Industrial Character Image Motion Deblurring and Target Region Dynamic Location Method}, 
  year={2022},
  volume={},
  number={},
  pages={658-663},
  abstract={For one commodity, characters are printed on a specific area of the packing paper, recording the product ID. Because the machine needs to find the particular area for character recognition, we propose an automatic location method of character area. This location method can discover the region of interest more accurately without additional manual operation. Due to subtle camera vibrations and the factory line’s abrupt speed changes, slightly blurred images will be collected in image acquisition in industrial applications. In image motion deblurring, the protection of texture details is often ignored by previous methods, but it is vital for character recognition. Therefore, we propose a variant of Generative Adversarial Networks, which can preserve the texture details better and run faster in motion deblurring. The results of our method are better in terms of texture detail preservation and texture edge clarity. Its resulting images have more apparent details and edges, which is the key to achieving better effect during the character recognization.},
  keywords={Vibrations;Target recognition;Image edge detection;Packaging;Network architecture;Generative adversarial networks;Production facilities;automatic location;motion deblurring;character texture details;channel-recurrent network;generative adversarial networks},
  doi={10.1109/PRAI55851.2022.9904077},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{11160513,
  author={Zhao, Yanli and Xiong, Junna},
  booktitle={2025 6th International Conference on Artificial Intelligence and Electromechanical Automation (AIEA)}, 
  title={Research on Cervical Cell Image Classification Method Based on Convolutional Neural Network}, 
  year={2025},
  volume={},
  number={},
  pages={211-215},
  abstract={Given the scarcity of cervical cell image samples and their low classification accuracy, a deep learning-based intelligent analysis method is proposed for the task of cervical cytopathology image classification. By introducing deep convolutional generative adversarial network (DCGAN) for data enhancement, the problem of insufficient medical image samples is effectively solved, and the generated images significantly outperform the comparison methods in PSNR (23.69) and SSIM (0.939) metrics. Adopting ResNet101 as a classification network and utilizing its residual linkage structure to effectively extract multi-scale features, it achieves $\mathbf{9 9. 1 5 \%}$ precision and $\mathbf{9 9. 3 0 \%}$ recall on the Herlev dataset, which outperforms comparative models such as VGG and ResNet50. The experimental results show that the method performs well in both normal cell (up to 99.97 % recall) and lesion cell (down to 98.17 % precision) classification tasks, providing a reliable technical solution for computer-aided diagnosis of cervical disease screening.},
  keywords={Computational modeling;Data enhancement;Feature extraction;Generative adversarial networks;Data models;Lesions;Convolutional neural networks;Reliability;Image classification;Residual neural networks;Convolutional Neural Networks;Generative Adversarial Networks;Cervical Cell Classification;Deep Learning},
  doi={10.1109/AIEA66061.2025.11160513},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{11022295,
  author={Lu, Ji and Wu, Minjun},
  booktitle={2024 8th Asian Conference on Artificial Intelligence Technology (ACAIT)}, 
  title={Research on Speech Enhancement of Vocal Music Auxiliary Teaching System Based on Time-Frequency Fusion and Multi-Channel Attention Mechanism}, 
  year={2024},
  volume={},
  number={},
  pages={1542-1547},
  abstract={In this paper, the quality of speech signals collected in acoustic teaching scenarios is further improved. A dual-microphone speech enhancement method based on time-frequency fusion and deep learning algorithm is proposed to obtain higher quality speech information. Using dual-microphone speech enhancement algorithm based on general sidelobe canceller as the basic speech enhancement algorithm, time-frequency masking and adversarial generative networks are introduced. Then, the noise removal level of the algorithm is further improved, and the quality of the enhanced speech is further improved. Simulation results prove that compared with other types of speech enhancement algorithms, the constructed speech enhancement algorithm has better performance in different scenarios in terms of mean opinion score, signal-to-noise ratio, perceptual evaluation of speech quality, short-time objective intelligibility and log spectral distance. Therefore, the constructed dual-microphone speech enhancement method based on time-frequency fusion and deep learning algorithm has good performance, can effectively improve the quality of the enhanced speech, and can be applied to the actual vocal music teaching scene to help improve the teaching quality, witch has high feasibility.},
  keywords={Deep learning;Time-frequency analysis;Attention mechanisms;Simulation;Education;Speech enhancement;Generative adversarial networks;Microphone arrays;Optimization;Signal to noise ratio;vocal music teaching;speech enhancement;microphone array;time-frequency masking;generative adversarial network},
  doi={10.1109/ACAIT63902.2024.11022295},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10165280,
  author={Gao, Dequan and Yang, Meng and Feng, Bao and Luo, Wang and Bai, Dongxia},
  booktitle={2023 IEEE 3rd International Conference on Information Technology, Big Data and Artificial Intelligence (ICIBA)}, 
  title={Business systems KPI anomaly detection based on an adversarial variational autoencoder}, 
  year={2023},
  volume={3},
  number={},
  pages={1702-1706},
  abstract={An anomaly KPI detection method is proposed based on an adversarial variational autoencoder (AVAE) for business systems. The proposed AVAE model is a combination of conditional variational autoencoder (CVAE) and generative adversarial network (GAN). Firstly, to effectively extract the periodic characteristics of KPI data, time information is introduced into the CVAE network as the input condition. Secondly, the discriminator of GAN network is introduced on the basis of CVAE to improve the sample inference ability of the generated network. Finally, CVAE, whose encoder can better obtain the mapping from real samples to hidden space, is used as a generator. Experimental results show the effectiveness of the proposed method.},
  keywords={Systems operation;Maintenance engineering;Generative adversarial networks;Generators;Distance measurement;Data models;Information technology;anomaly detection;business system;variational autoencoder;generative adversarial network;KPI},
  doi={10.1109/ICIBA56860.2023.10165280},
  ISSN={},
  month={May},}@INPROCEEDINGS{11064529,
  author={Jain, Shaveta and Kumar, Rajneesh and Agrawal, Kushagra},
  booktitle={2025 3rd International Conference on Communication, Security, and Artificial Intelligence (ICCSAI)}, 
  title={Enhanced Rice Leaf Diseases Diagnosis Using Deep Learning Model with GAN-Based Synthetic Data Augmentation}, 
  year={2025},
  volume={3},
  number={},
  pages={1334-1339},
  abstract={Rice is a widely cultivated crop and a crucial staple food in many South Asian nations. Diseases that affect rice leaves can significantly decrease crop yields, but early identification can help mitigate their effects. Recently, machine learning has been applied to address the issue of disease spread. A major challenge, however, is the scarcity of balanced diseased leaf images compared to healthy ones, which limits the effectiveness of model training due to the need for extensive datasets. To overcome this limitation, Generative Adversarial Networks (GANs) have been increasingly used to generate synthetic images that closely mimic real ones. This approach has gained popularity in identifying leaf diseases, although research focusing specifically on rice diseases is still limited. In this research, GAN is utilized as a data augmentation method to create synthetic images for balancing Paddy doctor dataset. Subsequently, a hybrid model and Modified ResNet50 are employed for paddy disease classification. The experimental findings reveal that with image augmentation deep learning models learns well and performs best, achieving an accuracy of 99.92% by hybrid model and 98.8% by Modified ResNet50 which is 1% – 10% better when compared with existing models.},
  keywords={Deep learning;Training;Accuracy;Computational modeling;Generative adversarial networks;Data augmentation;Data models;Diseases;Residual neural networks;Synthetic data;Rice leaf Disease;Generative AI;GANs;CNN;InceptionV3;Modified ResNet50},
  doi={10.1109/ICCSAI64074.2025.11064529},
  ISSN={},
  month={April},}@INPROCEEDINGS{10475264,
  author={Momen-Tayefeh, Mehrshad and Momen-Tayefeh, Mehrdad and Hasheminasab, Fatemeh Zahra and Ghahramani, S. AmirAli Gh.},
  booktitle={2024 20th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP)}, 
  title={SNRGAN: The Semi Noise Reduction GAN for Image Denoising}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Conventional noise reduction methods often fail to effectively handle high levels of noise, leading to artifacts and distortions. This paper proposes a Generative Adversarial Network (GAN) approach for noise reduction with low complexity. The proposed Semi Noise Reduction GAN (SNRGAN) effectively learns the underlying patterns of noise and generates denoised versions of noisy images, even with different noise levels. Training our model on three diverse datasets yielded admissible results, as evidenced by superior PSNR and NMSE scores. Furthermore, our model excelled in both subjective evaluations and objective metrics and its efficacy in handling elevated noise levels positions it as a promising solution for real-world applications.},
  keywords={Training;Image quality;Quantization (signal);Noise reduction;Neural networks;Generative adversarial networks;Distortion;Generative Adversarial Networks;Noise Reduction;Convolutional Neural Networks},
  doi={10.1109/AISP61396.2024.10475264},
  ISSN={2640-5768},
  month={Feb},}@INPROCEEDINGS{9288175,
  author={Vijay, Malaika and Meghana, Meghana and Aklecha, Nishant and Srinath, Ramamoorthy},
  booktitle={2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Dialog Driven Face Construction using GANs}, 
  year={2020},
  volume={},
  number={},
  pages={647-652},
  abstract={This paper presents an end-to-end pipeline using Generative Adversarial Networks (GANs) for face construction based on speech-based descriptions, and iterative editing of the generated image to arrive at a close approximation of the expected face. We propose a dialog-based interaction with the system where the user and system take turns providing descriptions and generating images respectively. A rule-based Natural Language (NL) Parser is used to extract facial attribute descriptors from textual descriptions, MSG-Style GAN (Multi-Scale Gradient Style GAN) for face generation, and Attribute GAN (AttGAN) for facial attribute manipulation.},
  keywords={Pipelines;Tools;Generative adversarial networks;Feature extraction;Generators;Faces;Facial features;Generative Adversarial Network;Convolutional Neural Network;Face Construction;Image Generation;Natural Language Parser},
  doi={10.1109/ICTAI50040.2020.00104},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{9688141,
  author={Sun, Yifan and Huang, Peng and Jiao, Wentao and Xiaoqiang, Sima and Zhang, Peng and Wang, Li},
  booktitle={2021 IEEE 2nd International Conference on Information Technology, Big Data and Artificial Intelligence (ICIBA)}, 
  title={Estimation of Centroid Position of Silicon Particles Based on GAN and Visual Tracking}, 
  year={2021},
  volume={2},
  number={},
  pages={695-699},
  abstract={In this paper, we used generative adversarial network (GAN) and visual tracking to detect the growth of silicon particles. To solve the problem of fewer data sets, we use the Wasserstein-GAN (WGAN) model to expand the data set. From the loss functions of the generator and discriminator, the quality of the data generated by the model is high. The position of the center of mass of the silica particles during the melting process was determined by the extracted tracking mark results, and the motion trajectory of the center of mass of the silica was given.},
  keywords={Silicon compounds;Visualization;Target tracking;Noise reduction;Generative adversarial networks;Data models;Silicon;generative adversarial networks;visual tracking;silicon particles;mathematical modeling},
  doi={10.1109/ICIBA52610.2021.9688141},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9743093,
  author={Rao, V. Chandra Shekhar and Venkatramulu, S and Phridviraj, M S B and Pratapagiri, Sreenivas and Madugula, Sujatha and Kiran, Siripuri},
  booktitle={2022 Second International Conference on Artificial Intelligence and Smart Energy (ICAIS)}, 
  title={COVID-19 Patterns Identification using Advanced Machine Learning and Deep Neural Network Implementation}, 
  year={2022},
  volume={},
  number={},
  pages={240-243},
  abstract={Predictive analysis and Therapeutic analysis are solitaries in the field of investigation with huge dimensions, which predict a range of diseases. Recently, the effect of the Covid-19 is massive and the virus constantly is mutating. The Generative Adversarial Network (GAN) is the modern efficiency technique used by advanced neural networks to analyze data in cavernous environment. This paper reviews the issues in datasets of Covid, that enables patients to be diagnosed and predicted. The GANs are used to produce, transform, and view datasets profound that trends in medical database. The general prediction research can be highly performing with the incorporation of GANs in comparison with classical neural networks in multiple layers. This research manuscript is projected so that the prediction of mining and the exploration of information can be done more effectively.},
  keywords={COVID-19;Planets;Neural networks;Transforms;Production;Generative adversarial networks;Market research;Data Analytics;Network for Generative Adversarial;GAN;Medical Diagnosis},
  doi={10.1109/ICAIS53314.2022.9743093},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10730244,
  author={Wang, Yuxin and Liu, Qiang},
  booktitle={2024 6th International Conference on Industrial Artificial Intelligence (IAI)}, 
  title={Skip-CBAM Based Unsupervised Anomaly Detection of Fused Magnesia Furnace}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Abnormal ultra-high temperature semi-molten conditions in a fused magnesia furnace (FMF) can lead to furnace leakage. To ensure high detection performance, existing models require sufficient expert-labeled training data for supervised learning. However, the above model has limited ability to identify unknown abnormal working conditions, and label production is time-consuming and expensive. This paper suggests an unsupervised detection method based on skip-connected generative adversarial network (GAN) to address this issue. Specifically, to adapt to the strong interference caused by irregular changes in images caused by irregular water mist and flicker scenes, existing methods remove interference through multi-step processing for detection, which is difficult to apply in practice. In contrast, we use a reconstruction model of convolutional block attention module (CBAM) with skip connections for end-to-end computation, which improves performance while being more concise. This method determines abnormal areas through reconstruction and distinguishes abnormal working conditions by comparing abnormal scores. Finally, this method is compared with existing unsupervised and supervised methods on actual FMF images, and the application results demonstrate the effectiveness of this method.},
  keywords={Employee welfare;Adaptation models;Furnaces;Training data;Interference;Generative adversarial networks;Data models;Magnesium;Image reconstruction;Anomaly detection;Fused magnesia furnace (FMF);unsupervised learning;generative adversarial network (GAN);anomaly detection},
  doi={10.1109/IAI63275.2024.10730244},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10934487,
  author={Zhou, Wei and Cang, Minnan},
  booktitle={2024 4th International Symposium on Artificial Intelligence and Intelligent Manufacturing (AIIM)}, 
  title={A Deep Learning-Based Non-Photorealistic Rendering (NPR) Generation Method}, 
  year={2024},
  volume={},
  number={},
  pages={981-984},
  abstract={With the advancement of deep learning technologies, non-photorealistic rendering (NPR) techniques have made significant breakthroughs in the field of computer graphics. This paper proposes a deep learning-based framework for NPR generation, combining convolutional neural networks (CNNs) and generative adversarial networks (GANs), aimed at automatically generating graphics in various artistic styles, such as sketches, ink paintings, and oil paintings. Through image style transfer and feature learning, the framework optimizes the preservation of details and enhances the artistic effects of the generated images. Experimental results demonstrate that the proposed method significantly outperforms traditional algorithms in terms of style transfer quality, generation efficiency, and adaptability. It shows strong potential for wide applications in animation, game design, and virtual reality, providing robust technical support for digital art creation.},
  keywords={Deep learning;Solid modeling;Digital art;Games;Rendering (computer graphics);Generative adversarial networks;Animation;Convolutional neural networks;Optimization;Painting;Non-Photorealistic Rendering;Deep Learning;Convolutional Neural Networks;Generative Adversarial Networks (GAN)},
  doi={10.1109/AIIM64537.2024.10934487},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10860191,
  author={Liu, Chao and Yang, Tingting and Wang, Yu and Ren, Bin and Wang, Yanzhao},
  booktitle={2024 4th International Conference on Artificial Intelligence, Virtual Reality and Visualization}, 
  title={Research on Anomaly Detection Model for Power Industrial Control Networks Based on Bidirectional Recurrent Neural Networks}, 
  year={2024},
  volume={},
  number={},
  pages={171-175},
  abstract={In response to the current challenges of low accuracy in detecting abnormal data traffic and insufficient sample space in power industrial control networks, we propose a novel approach. Our method involves leveraging bidirectional recurrent neural networks(Bi-RNN) with long short-term memory (LSTM) architecture for anomaly traffic detection. Additionally, we introduce a sample augmentation technique based on generative adversarial networks (GAN) to address the limited sample size issue. We train our model on training datasets with temporal characteristics and evaluate its performance on testing datasets, achieving a prediction accuracy exceeding 99.6%. Moreover, through the sample augmentation model, we expand the dataset by over 100,000 samples.},
  keywords={Training;Solid modeling;Protocols;Accuracy;Recurrent neural networks;Industrial control;Generative adversarial networks;Long short term memory;Streams;Testing;Bidirectional Recurrent Neural Networks;Power Industrial Control Networks;Anomaly Traffic Detection;Generative Adversarial Networks},
  doi={10.1109/AIVRV63595.2024.10860191},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10664887,
  author={Park, Jiyoon},
  booktitle={2024 IEEE Integrated STEM Education Conference (ISEC)}, 
  title={Using the Swin-Transformer for Real & Fake Data Recognition in PC-Model}, 
  year={2024},
  volume={},
  number={},
  pages={01-05},
  abstract={Recently, due to the rapid development of generative AI technologies, the use of AI-generated images has increased significantly, making the distinction between real and fake images crucial. Generative images may be used in various ways such as data training and fast image generation, but a potential for misuse, such as in Deep fake or spreading false information, still exists. This study explores a novel model using the architecture ofSwin-Transformer to distinguish between fake and real images generated based on CNN (Convolutional Neural Networks) and GAN (Generative Adversarial Networks). The Swin-Transformer, a successor model of Vision in Transformer (ViT), applies the structure of the Transformer, which has shown outstanding performance in natural language processing, to the field of images and demonstrates excellent pixel-level segmentation performance. Real and fake images require detailed pixel-level analysis, in which the Swin-Transformer exhibits higher accuracy. Improving the performance of distinguishing between real and fake images is expected to set limits on indiscreet image generation, bringing further effects such as preventing the indiscriminate use of AI images through program-based discrimination/legal sanctions.},
  keywords={Training;Image segmentation;Image synthesis;Face recognition;Transformers;Generative adversarial networks;Natural language processing;Artificial Intelligence;Convolution Neural Network;Generative Adversarial Network;Real&Fake},
  doi={10.1109/ISEC61299.2024.10664887},
  ISSN={2473-7623},
  month={March},}@INPROCEEDINGS{11076342,
  author={Puvvadi, Meghana and Arava, Sai Kumar and Raut, Atharva S and Santoria, Adarsh and Prasanna Chennupati, Sesha Sai and Vardhan Puvvadi, Harsha},
  booktitle={2025 7th International Conference on Intelligent Sustainable Systems (ICISS)}, 
  title={A Comprehensive Survey of Generative AI Agents: Transforming Predictive Demand Forecasting and Supply Chain Optimization Strategies}, 
  year={2025},
  volume={},
  number={},
  pages={546-553},
  abstract={Modern supply chains are increasingly complex, requiring intelligent AI-driven systems to optimize supply allocation dynamically in response to fluctuating demand. This review highlights the significance of AI in supply chain management, examining recent advancements in predictive analytics, machine learning, and optimization techniques for demand forecasting and resource allocation. By critically analyzing AI methodologies—including deep neural networks, reinforcement learning, constraint programming, and hybrid models—we assess their impact on supply chain agility, operational efficiency, and profitability. Through an extensive review of literature and industry case studies, this work benchmarks AI-driven supply chain solutions, demonstrating that AI-based planners enhance order fulfillment rates by 15-20%, increase revenue by 1015%, and improve demand-fluctuation resilience by over 20%, significantly outperforming conventional rule-based methods. Furthermore, AI enables real-time decision-making, reducing computational overhead and response time in dynamic market conditions. Despite these advancements, challenges such as data limitations, computational constraints, model interpretability, and sustainability remain significant barriers to adoption. This survey identifies these limitations and outlines critical research directions, including self-adaptive AI models, scalable parallel computing frameworks, and sustainability-driven optimization strategies, to ensure AI-powered supply chains remain resilient, efficient, and adaptable in evolving market environments.},
  keywords={Surveys;Adaptation models;Supply chain management;Computational modeling;Supply chains;Demand forecasting;Resource management;Artificial intelligence;Sustainable development;Optimization;Large Language Models;Generative AI;AI-driven Supply Chains;Reinforcement Learning;Autonomous Supply Chain Agents;Demand-Supply Optimization;Inventory Forecasting;Deep Learning in Logistics},
  doi={10.1109/ICISS63372.2025.11076342},
  ISSN={},
  month={March},}@ARTICLE{9832721,
  author={He, Ziping and Xia, Kewen and Ghamisi, Pedram and Hu, Yuhen and Fan, Shurui and Zu, Baokai},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={HyperViTGAN: Semisupervised Generative Adversarial Network With Transformer for Hyperspectral Image Classification}, 
  year={2022},
  volume={15},
  number={},
  pages={6053-6068},
  abstract={Generative adversarial networks (GANs) have achieved many excellent results in hyperspectral image (HSI) classification in recent years, as GANs can effectively solve the dilemma of limited training samples in HSI classification. However, due to the class imbalance problem of HSI data, GANs always associate minority-class samples with fake label. To address this issue, we first propose a semisupervised generative adversarial network incorporating a transformer, called HyperViTGAN. The proposed HyperViTGAN is designed with an external semisupervised classifier to avoid self-contradiction when the discriminator performs both classification and discrimination tasks. The generator and discriminator with skip connection are utilized to generate HSI patches by adversarial learning. The proposed HyperViTGAN captures semantic context and low-level textures to reduce the loss of critical information. In addition, the generalization ability of the HyperViTGAN is improved through the use of data augmentation. Experimental results on three well-known HSI datasets, Houston 2013, Indian Pines 2010, and Xuzhou, show that the proposed model achieves competitive HSI classification performance in comparison with the current state-of-the-art classification models.},
  keywords={Generative adversarial networks;Transformers;Task analysis;Data models;Hyperspectral imaging;Generators;Training;Generative adversarial network (GAN);hyperspectral image (HSI) classification;semisupervised learning;transformer},
  doi={10.1109/JSTARS.2022.3192127},
  ISSN={2151-1535},
  month={},}@ARTICLE{10265249,
  author={Huang, Dongxia and Luo, Weiqi and Liu, Minglin and Tang, Weixuan and Huang, Jiwu},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Steganography Embedding Cost Learning With Generative Multi-Adversarial Network}, 
  year={2024},
  volume={19},
  number={},
  pages={15-29},
  abstract={Since the generative adversarial network (GAN) was proposed by Ian Goodfellow et al. in 2014, it has been widely used in various fields. However, there are only a few works related to image steganography so far. Existing GAN-based steganographic methods mainly focus on the design of generator, and just assign a relatively poorer steganalyzer in discriminator, which inevitably limits the performances of their models. In this paper, we propose a novel Steganographic method based on Generative Multi-Adversarial Network (Steg-GMAN) to enhance steganography security. Specifically, we first employ multiple steganalyzers rather than a single steganalyzer like existing methods to enhance the performance of discriminator. Furthermore, in order to balance the capabilities of the generator and the discriminator during training stage, we propose an adaptive way to update the parameters of the proposed GAN model according to the discriminant ability of different steganalyzers. In each iteration, we just update the poorest one among all steganalyzers in discriminator, while update the generator with the gradients derived from the strongest one. In this way, the performance of generator and discriminator can be gradually improved, so as to avoid training failure caused by gradient vanishing. Extensive comparative results show that the proposed method can achieve state-of-the-art results compared with the traditional steganography and the modern GAN-based steganographic methods. In addition, a large number of ablation experiments verify the rationality of the proposed model.},
  keywords={Generators;Generative adversarial networks;Steganography;Costs;Security;Training;Distortion;Steganography;generative adversarial network;steganalysis},
  doi={10.1109/TIFS.2023.3318939},
  ISSN={1556-6021},
  month={},}@ARTICLE{10607852,
  author={Bist, Prem Singh and Tayara, Hilal and Chong, Kil To},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Generative AI in the Advancement of Viral Therapeutics for Predicting and Targeting Immune-Evasive SARS-CoV-2 Mutations}, 
  year={2024},
  volume={28},
  number={11},
  pages={6974-6982},
  abstract={The emergence of immune-evasive mutations in the SARS-CoV-2 spike protein is consistently challenging existing vaccines and therapies, making precise prediction of their escape potential a critical imperative. Artificial Intelligence(AI) holds great promise for deciphering the intricate language of protein. Here, we employed a Generative Adversarial Network to decipher the hidden escape pathways within the spike protein by generating spikes that closely resemble natural ones. Through comprehensive analysis, we demonstrated that generated sequences capture natural escape characteristics. Moreover, incorporating these sequences into an AI-based escape prediction model significantly enhanced its performance, achieving a 7% increase in detecting natural escape mutations on the experimentally validated Greaney dataset. Similar improvements were observed on other datasets, demonstrating the model's generalizability. Precisely predicting immune-evasive spikes not only enables the design of strategically targeted therapies but also has the potential to expedite future viral therapeutics. This breakthrough carries profound implications for shaping a more resilient future against viral threats.},
  keywords={Proteins;Coronaviruses;Protein engineering;Training;Computational modeling;Medical treatment;Vaccines;Immune-evasive mutations;SARS-CoV-2 spike protein;artificial intelligence (AI);generative adversarial network (GAN);escape prediction model},
  doi={10.1109/JBHI.2024.3432649},
  ISSN={2168-2208},
  month={Nov},}
