@ARTICLE{11048361,
  author={Lau, Christina L. and Ding, Shuhan and Xie, Yutong and Law, Edwin R. and Kor, Bahar and Davaji, Benyamin and Lal, Amit and Doerschuk, Peter C.},
  journal={IEEE Transactions on Semiconductor Manufacturing}, 
  title={Process-Aware Digital Twins by Deep Learning for DUV Photolithography and Plasma Etch}, 
  year={2025},
  volume={38},
  number={3},
  pages={634-641},
  abstract={Computer representations of the structure, context, and behavior of physical systems are critical components of computational system optimization. Traditionally, such optimization is done by iterative physical experiments, which can be expensive both in time and resources. In this paper, these computer representations, called digital twins, are developed primarily using SEM images and equipment process parameters. HyperPix2Pix, the proposed methodology of the digital twins, is a deep neural network that uses SEM images of the input structure together with equipment process parameters to predict the output SEM images. We demonstrate HyperPix2Pix on a DUV photolithography stepper and plasma etcher. HyperPix2Pix predicts output images that closely match the experimental output images and have very similar critical dimensions. Compared to previous work, HyperPix2Pix includes the effects of process parameters through multimodal learning, elucidating the role of different parameters in nanofabrication processes and their effects on critical dimensions of the resulting structures.},
  keywords={Lithography;Layout;Plasmas;Generators;Generative adversarial networks;Integrated circuit modeling;Training;Semiconductor device measurement;Digital twins;Translation;DUV photolithography;plasma etch;digital twins;machine learning;generative artificial intelligence;Pix2Pix;critical dimensions;metrology},
  doi={10.1109/TSM.2025.3582194},
  ISSN={1558-2345},
  month={Aug},}@INPROCEEDINGS{11162172,
  author={Omara, Ahmed and Kantarci, Burak},
  booktitle={2025 IEEE International Conference on Communications Workshops (ICC Workshops)}, 
  title={Efficient Adversarial Detection Frameworks for Vehicle-to-Microgrid Services in Edge Computing}, 
  year={2025},
  volume={},
  number={},
  pages={572-577},
  abstract={As Artificial Intelligence (AI) becomes increasingly integrated into microgrid control systems, the risk of malicious actors exploiting vulnerabilities in Machine Learning (ML) algorithms to disrupt power generation and distribution grows. Detection models to identify adversarial attacks need to meet the constraints of edge environments, where computational power and memory are often limited. To address this issue, we propose a novel strategy that optimizes detection models for Vehicle-to-Microgrid (V2M) edge environments without compromising performance against inference and evasion attacks. Our approach integrates model design and compression into a unified process and results in a highly compact detection model that maintains high accuracy. We evaluated our method against four benchmark evasion attacks-Fast Gradient Sign Method (FGSM), Basic Iterative Method (BIM), Carlini & Wagner method (C&W) and Conditional Generative Adversarial Network (CGAN) method—and two knowledge-based attacks, white-box and gray-box. Our optimized model reduces memory usage from 20MB to 1.3MB, inference time from 3.2 seconds to 0.9 seconds, and GPU utilization from 5% to 2.68%.},
  keywords={Performance evaluation;Adaptation models;Accuracy;Computational modeling;Image edge detection;Conferences;Generative adversarial networks;Real-time systems;Smart grids;Optimization;vehicle-to-microgrid (V2M);machine learning;smart microgrids;cybersecurity;generative adversarial network (GAN);evasion attack;inference attack;vehicle-to-home (V2H)},
  doi={10.1109/ICCWorkshops67674.2025.11162172},
  ISSN={2694-2941},
  month={June},}@INPROCEEDINGS{10924943,
  author={Zhang, Jing and Wang, Yuqing and Jia, Zidi and Ren, Lei},
  booktitle={2024 IEEE Smart World Congress (SWC)}, 
  title={A Supply Chain Digital Twins Framework with Generative Knowledge Graph}, 
  year={2024},
  volume={},
  number={},
  pages={2053-2060},
  abstract={With the explosive development of Artificial intelligence generated content(AIGC), generative AI technology has gradually been applied to supply chain optimization and management. However, current research lacks guiding principles and general framework for the application of generative AI in supply chain system optimization and management. To address this issue, this paper designs the supply chain digital twins framework with generative knowledge graph(SCDT-GKG), based on digital twin technology.Firstly, a foundational architecture for supply chain digital twins is proposed based on a five-dimensional model. Secondly, on this foundational architecture, a generative knowledge graph module is introduced to construct SCDT-GKG. Lastly, a general usage guide is provided, detailing the application processes in supply chain scenarios, thereby offering guidance for the construction and use of SCDT-GKG.This research effectively addresses the challenges of applying generative knowledge graph in supply chain systems and the issue of insufficient data. It also aids in achieving real-time collaborative optimization of supply chain system, paving the way for new method.},
  keywords={Generative AI;Supply chains;Collaboration;Knowledge graphs;Real-time systems;Explosives;Digital twins;Optimization;Guidelines;AIGC;digital twin;generative knowledge graph;supply chain;framework},
  doi={10.1109/SWC62898.2024.00315},
  ISSN={2993-396X},
  month={Dec},}@INPROCEEDINGS{9643283,
  author={Guo, Haojie and Guo, Zhe and Pan, Zhaojun and Liu, Xuewen},
  booktitle={2021 IEEE 33rd International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Bilateral Res-Unet for Image Colorization with Limited Data via GANs}, 
  year={2021},
  volume={},
  number={},
  pages={729-735},
  abstract={Recently the method based on deep learning has made progress in automatic colorization using rich training data, but the colorization model for limited training data still performs unsatisfactorily, resulting in mottled colors and coloring errors in some regions of interest. To solve the above problems, we design a novel Bilateral Res-Unet based on GAN, which is used in generator to transfer color features on both sides of the encoder. The residual connections are then used to improve the ability of color feature transmission and image semantics accuracy. In addition, we redefine a multi-feature semantic perception loss, which constrains the image by assigning different weights to the feature distance after multiple convolution layers of the pretrained network to enhance semantic similarity and make the colored image more vivid. We have implemented comprehensive experiments compared with the recent coloring models, using the PSNR, SSIM, and LPIPS metric. Our method has achieved SOTA results on three limited image datasets.},
  keywords={Measurement;Deep learning;Image color analysis;Convolution;Conferences;Semantics;Training data;Image Colorization;Limited data;Generative Adversarial Networks;Unet;Perceptual loss},
  doi={10.1109/ICTAI52525.2021.00116},
  ISSN={2375-0197},
  month={Nov},}@ARTICLE{10130633,
  author={Verma, Ashish and Sen, Debashis},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Generative Augmentation-Driven Prediction of Diverse Visual Scanpaths in Images}, 
  year={2024},
  volume={5},
  number={2},
  pages={940-955},
  abstract={Visual scanpaths of multiple humans on an image represent the process by which they capture the information in it. State-of-the-art models to predict visual scanpaths on images learn directly from recorded human visual scanpaths. However, the generation of multiple visual scanpaths on an image having diversity like human visual scanpaths has not been explicitly considered. In this article, we propose a deep network for predicting multiple diverse visual scanpaths on an image. Image-specific hidden Markov model-based generative data augmentation is performed in the beginning to increase the number of image-visual scanpath training pairs. Considering a similarity between our generative data augmentation process and the use of long short-term memory (LSTM) for prediction, we propose an LSTM-based visual scanpath predictor. A network to predict a single visual scanpath on an image is designed first. The network is then modified to predict multiple diverse visual scanpaths representing different viewer varieties by using a parameter indicating the uniqueness of a viewer. A random vector is also employed for subtle variations within scanpaths of the same viewer variety. Our models are evaluated on three standard datasets using multiple performance measures, which demonstrate the superiority of the proposed approach over the state of the art. Empirical studies are also given indicating the significance of our generative data augmentation method and our multiple scanpath prediction strategy producing diverse visual scanpaths.},
  keywords={Visualization;Hidden Markov models;Predictive models;Computational modeling;Training;Task analysis;Deep learning;Diverse visual scanpath prediction;generative data augmentation;long short-term memory (LSTM)-based prediction},
  doi={10.1109/TAI.2023.3278650},
  ISSN={2691-4581},
  month={Feb},}@INPROCEEDINGS{11012015,
  author={Zakey, Asmath and Bawantha, Dinura and Shehara, Dinuth and Hasara, Nethmi and Abeywardena, Kavinga Yapa and Fernando, Harinda},
  booktitle={2025 13th International Symposium on Digital Forensics and Security (ISDFS)}, 
  title={A Dual-Branch CNN and Metadata Analysis Approach for Robust Image Tampering Detection}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Image tampering has become a widespread issue due to the availability of advanced tools such as Photoshop, GIMP, and AI-powered technologies like Generative Adversarial Networks (GANs). These advancements have made it easier to create deceptive images, undermining their reliability and fueling misinformation. To address this growing problem, we propose a hybrid approach for image forgery detection, combining deep learning with traditional forensic techniques. Our study integrates a dual-branch Convolutional Neural Network (CNN) with handcrafted features derived from Error Level Analysis (ELA), noise residuals from the Spatial Rich Model, and metadata analysis to enhance detection capabilities. Metadata analysis plays a crucial role in identifying inconsistencies in image properties such as timestamps, geotags, and camera details, which often accompany tampered images. The CASIA dataset, a publicly available benchmark for tampered images, was used to train and evaluate the proposed model. After 30 epochs of training, the hybrid method achieved an accuracy of 95%, demonstrating its effectiveness in distinguishing between authentic and tampered images. This research highlights the advantages of combining deep learning models with traditional feature extraction methods and metadata analysis, offering a robust solution for detecting manipulated images. Our findings contribute to advancing image forensics by improving detection accuracy, even in cases involving sophisticated tampering methods driven by AI.},
  keywords={Deep learning;Analytical models;Image forensics;Accuracy;Noise;Metadata;Feature extraction;Forgery;Convolutional neural networks;Artificial intelligence;Image Tampering;Deep Learning;Forgery Detection;Convolutional Neural Network (CNN);Dual-Branch Network;Error Level Analysis (ELA);Noise Residuals;Spatial Rich Model;Artificial Intelligence (AI);Metadata Analysis},
  doi={10.1109/ISDFS65363.2025.11012015},
  ISSN={2768-1831},
  month={April},}@INPROCEEDINGS{10688373,
  author={Li, Yang and Yang, Songlin and Wang, Wei and He, Ziwen and Peng, Bo and Dong, Jing},
  booktitle={2024 IEEE International Conference on Multimedia and Expo (ICME)}, 
  title={Counterfactual Explanations for Face Forgery Detection via Adversarial Removal of Artifacts}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Highly realistic AI generated face forgeries known as deepfakes have raised serious social concerns. Although DNN-based face forgery detection models have achieved good performance, they are vulnerable to latest generative methods that have less forgery traces and adversarial attacks. This limitation of generalization and robustness hinders the credibility of detection results and requires more explanations. In this work, we provide counterfactual explanations for face forgery detection from an artifact removal perspective. Specifically, we first invert the forgery images into the StyleGAN latent space, and then adversarially optimize their latent representations with the discrimination supervision from the target detection model. We verify the effectiveness of the proposed explanations from two aspects: (1) Counterfactual Trace Visualization: the enhanced forgery images are useful to reveal artifacts by visually contrasting the original images and two different visualization methods; (2) Transferable Adversarial Attacks: the adversarial forgery images generated by attacking the detection model are able to mislead other detection models, implying the removed artifacts are general. Extensive experiments demonstrate that our method achieves over 90% attack success rate and superior attack transferability. Compared with naive adversarial noise methods, our method adopts both generative and discriminative model priors, and optimize the latent representations in a synthesis-by-analysis way, which forces the search of counterfactual explanations on the natural face manifold. Thus, more general counterfactual traces can be found and better adversarial attack transferability can be achieved. Our code is available at https://github.com/yangli-lab/Artifact-Eraser/.},
  keywords={Manifolds;Visualization;Deepfakes;Codes;Noise;Object detection;Forgery;Robustness;Artificial intelligence;Faces},
  doi={10.1109/ICME57554.2024.10688373},
  ISSN={1945-788X},
  month={July},}@INPROCEEDINGS{11080630,
  author={Piemonti, Alice and Cianchini, Vito and Danousis, Michail and Skianis, Charalampos},
  booktitle={2025 IEEE 11th International Conference on Network Softwarization (NetSoft)}, 
  title={Organizing and Augmenting Cybersecurity Knowledge Using Generative AI}, 
  year={2025},
  volume={},
  number={},
  pages={585-590},
  abstract={With the rapid advancements in Artificial Intelligence (AI), cybersecurity threats are becoming increasingly sophisticated. Static, human-curated approaches such as MITRE ATT&CK and CAPEC are often insufficient for companies to implement effective countermeasures, and security experts frequently face challenges in integrating these frameworks into their specific architectures. In this paper, we explore the application of generative AI to organize and enhance cybersecurity knowledge bases. We leverage multiple state-of-the-art Large Language Models (LLMs) to augment an initial dataset of attackmitigation pairs, generating new countermeasures along with their prioritized execution order in a reasonable time frame. To evaluate the generated responses, we employ the LLM-as-aJudge technique. Evaluations with Claude 3.5, DeepSeek R1, and human oversight show that top-performing models on general benchmarks also perform well in this specialized task, with more than 70% of responses rated 4 and 5 out of 5 for correctness, and the weaker models tend to perform the worst. Additionally, we discuss the challenges of running LLMs with a larger number of parameters on less powerful hardware, where the performance of such models can degrade significantly, even performing worse than their smaller counterparts. In such cases, advanced prompt engineering becomes necessary to improve results. Our code and dataset are publicly available at “https://github.com/martel-innovate/HORSE-GenAI-CKB”},
  keywords={Knowledge engineering;Codes;Large language models;Knowledge based systems;Companies;Benchmark testing;Hardware;Prompt engineering;Computer security;Faces;Generative AI;LLM;Security;Cybersecurity;MITRE ATT&CK;Knowledge Base},
  doi={10.1109/NetSoft64993.2025.11080630},
  ISSN={2693-9789},
  month={June},}@INBOOK{10834125,
  author={Verma, Nikhil and Sharma, Tripti and Kaur, Bobbinpreet},
  booktitle={AI in Disease Detection: Advancements and Applications}, 
  title={Explanation of Machine Learning Algorithms Used in Disease Detection, Such as Decision Trees and Neural Networks}, 
  year={2025},
  volume={},
  number={},
  pages={27-52},
  abstract={Summary <p>Machine learning (ML) as a tool in disease diagnosis has come of age. However, in voluminous medical data, outclasses in analysis for digging out hidden patterns helpful for early detection. Current methodologies are effective, notwithstanding their limitations. This chapter thus presents a new approach &#x2013; a &#x201c;symphony of innovation&#x201d; &#x2013; by redefining disease detection to integrate the established methods with truly groundbreaking advancements systematically.</p> <p>This symphony goes beyond established, well&#x2010;rehearsed routines of current ML practices. It introduces AI orchestration as a new conductor that would work in harmony with all other components involved in the disease detection workflow and adapt to the workflow. Picture a network of hospitals, each equipped with patient data as if playing a concert together. Federated learning is a way to train ML models on this &#x201c;decentralized data,&#x201d; unlocking its power for improved disease detection, especially in the case of rare or geographically isolated cases, while protecting patient privacy in the process &#x2013; just like each hospital keeping its sheet music confidential. Another innovation in this symphony is active learning. Traditionally, training ML models require massive amounts of meticulously labeled data. Active learning algorithms act as a discerning conductor that identifies the most informative data points, reducing the need for manual labeling. This reduces not only the workload for medical professionals but also enables more efficient and targeted data collection.</p> <p>Static models can become useless with a changing healthcare environment and patient populations. This symphony is introducing algorithms of continuous learning. These algorithms function much like an adaptable maestro, continuously ingesting new data streams and dynamically refining their predictions to provide perpetual improvement in disease detection accuracy from day one &#x2013; to keep up with the evolving landscape in healthcare.</p> <p>Generative adversarial networks will elevate the level of innovation further. Now, imagine having to compose a host of entirely new musical pieces &#x2013; all those that would enhance the repertoire of an orchestra. GANs are capable of generating synthetic, false, anonymous patient data. In this way, researchers can train ML models on more extensive and more diverse datasets without being faced with questions about privacy, which is very useful in case of rare diseases with minimal real&#x2010;world data.</p> <p>This symphony of innovation, however, does not end with technological progress but is also reflected in the harmonious concurrence of man's brain and machine expertise.</p> <p>XAI techniques focused on the medical domain will turn out to be critical. As a model, such techniques are bound to provide transparent and interpretable explanations for their predictions, engendering trust and acceptance among medical professionals. Picture a program accompanying a complex musical piece that lets an audience &#x2013; here, doctors &#x2013; understand the intricacies of the performance. AI&#x2010;empowered clinical decision support systems are real&#x2010;time companions for a doctor in arriving at a diagnosis and instituting treatment. They study patient data, offer possible diagnoses, and suggest treatment options. Picture an AI assistant that can provide insights in real&#x2010;time and help doctors make more learned decisions about the clinical history of their patients. The ultimate goal of this symphony is personalized medicine. Armed with a patient's case history, genomic data, and data related to lifestyle habits, AI can predict their individual disease risk and hence help in the formulation of targeted interventions. Proactive healthcare &#x2013; prevention before manifestation of the actual disease &#x2013; is within reach.</p> <p>This vision in disease detection goes beyond the conventionally adopted methods in disease detection. With AI orchestration, human&#x2010;machine collaboration, and ethical concerns, we can unleash the promise of healthcare with very early diagnoses and a treatment regime that makes a difference &#x2013; leading to a genuinely healthful future for all. Such a symphony of innovation is taking to the streets and on course to rewrite the score relating to disease detection; every advancement within its repertoire seems to act as a note of hope in this fight for global health.</p>},
  keywords={Diseases;Medical diagnostic imaging;Medical services;Technological innovation;Predictive models;Accuracy;Prediction algorithms;Heuristic algorithms;Feature extraction;Decision trees},
  doi={10.1002/9781394278695.ch2},
  ISSN={},
  publisher={IEEE},
  isbn={9781394278688},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10834125},}@INPROCEEDINGS{9824546,
  author={Li, Qi and Li, Ziye and He, Siyuan},
  booktitle={2022 3rd International Conference on Computer Vision, Image and Deep Learning & International Conference on Computer Engineering and Applications (CVIDL & ICCEA)}, 
  title={Segmentation of Intervertebral Disc based on Semi-supervised Conditional Generative Adversarial Network}, 
  year={2022},
  volume={},
  number={},
  pages={891-895},
  abstract={Intervertebral disc herniation has now become a highly prevalent disease among white collars, and commonly, it's preoperative planning as well as rehabilitation protocols are reliant on physicians’ manual reading of spinal magnetic resonance images to accomplish the desired outcomes. With the advancement of computer technology and artificial intelligence in recent years, a growing number of diagnostic algorithms have been developed for the analysis of spinal lesion images and automatical generation of high-precision lesion segmentation areas, which can provide great aid to imaging physicians in clinical diagnosis and preoperative planning. Even so, poor accuracy with few labels in under-annotated background images poses a great challenge for semantic segmentation of the spine. Because of this, we designed a semi-supervised semantic segmentation network for spine images based on conditional adversarial neural networks combined with U-net and Tversky loss to address the above issue. The accuracy reached 0.898 for the optimal network performance. Finally, we verified the feasibility and superiority of the proposed algorithm in the semi-supervised semantic segmentation task of intervertebral disc images.},
  keywords={Image segmentation;Protocols;Magnetic resonance imaging;Semantics;Neural networks;Magnetic resonance;Manuals;semantic segmentation;GAN;semi-supervised;U-net;lack-annotated},
  doi={10.1109/CVIDLICCEA56201.2022.9824546},
  ISSN={},
  month={May},}@ARTICLE{10897993,
  author={Wu, Hanwei and Dong, Zhangkun},
  journal={IEEE Access}, 
  title={What Motivates Second Language Majors to Use Generative AI for Informal Learning? Insights From the Theory of Planned Behavior}, 
  year={2025},
  volume={13},
  number={},
  pages={34877-34886},
  abstract={Generative artificial intelligence (GenAI) holds great promise for enhancing informal second language (L2) learning, but its impact largely depends on how it is used. This study explores the factors influencing L2 majors’ intention to use GenAI for learning, based on the Theory of Planned Behavior (TPB). Data were collected from 668 L2 majors at various Chinese universities through an online questionnaire with six validated scales. Structural equation modeling (SEM) via AMOS 24 revealed several key findings. First, demographic factors (gender and age) did not significantly affect the TPB constructs. Second, subjective norm and attitude positively influenced behavioral intention, while perceived behavioral control did not have a significant effect, contrary to TPB predictions. Additionally, GenAI literacy was found to be a positive predictor of behavioral intention, both directly and indirectly through attitude. External beliefs positively influenced subjective norm, perceived behavioral control, and attitude, which in turn impacted behavioral intention, with mediation effects observed through subjective norm and attitude. However, perceived behavioral control did not mediate the relationship between external beliefs and behavioral intention. This study concludes by discussing implications and future directions.},
  keywords={Attitude control;Writing;Shape;Chatbots;Testing;Technology acceptance model;Surveys;Software;Refining;Psychology;Generative artificial intelligence;second language majors;behavioral intention;informal learning},
  doi={10.1109/ACCESS.2025.3544489},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9172866,
  author={Xing, Kai and Li, Aiping and Jiang, Rong and Jia, Yan},
  booktitle={2020 IEEE Fifth International Conference on Data Science in Cyberspace (DSC)}, 
  title={A Review of APT Attack Detection Methods and Defense Strategies}, 
  year={2020},
  volume={},
  number={},
  pages={67-70},
  abstract={Cyberspace has been threatened by attacks ever since its birth. With the development of the Internet and artificial intelligence, forms of cyberattacks are emerging in endlessly, and technical means are constantly being renovated. In particular, advanced persistent threats are intensifying. How to effectively prevent this type of attack has become the focus, and attack detection and defense technology has made great progress. This article mainly discusses the research progress of APT attack detection and defense strategies at home and abroad, and focuses on the practice of using machine learning to perform attack detection while elaborating on traditional attack detection methods. Defense strategy is about how to use game theory to find the best defense strategy in limited resources, dynamic information flow tracking and cloud platform.},
  keywords={Cloud computing;Reviews;Cyberspace;Machine learning;Diversity methods;Data science;Dynamic scheduling;Game theory;Protection;Monitoring;advanced persistent threat (APT);game theory;machine learning;detection},
  doi={10.1109/DSC50466.2020.00018},
  ISSN={},
  month={July},}@ARTICLE{9713673,
  author={V., Chandrakanth and Murthy, V. S. N. and Channappayya, Sumohana S.},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Siamese Cross-Domain Tracker Design for Seamless Tracking of Targets in RGB and Thermal Videos}, 
  year={2023},
  volume={4},
  number={1},
  pages={161-172},
  abstract={Multimodal (RGB and thermal) applications are swiftly gaining importance in the computer vision community with advancements in self-driving cars, robotics, Internet of Things, and surveillance applications. Both the modalities have complementary performance depending on illumination constraints. Hence, a judicious combination of both modalities will result in robust RGBT systems capable of all-day all-weather applications. Several studies have been proposed in the literature for integrating the multimodal sensor data for object tracking applications. Most of the proposed networks try to delineate the information into modality-specific and modality shared features and attempt to exploit the modality shared features in enhancing the modality specific information. In this work, we propose a novel perspective to this problem using a Siamese inspired network architecture. We design a custom Siamese cross-domain tracker architecture and fuse it with a mean shift tracker to drastically reduce the computational complexity. We also propose a constant false alarm rate inspired coasting architecture to cater for real-time track loss scenarios. The proposed method presents a complete and robust solution for object tracking across domains with seamless track handover for all-day all-weather operation. The algorithm is successfully implemented on a Jetson-Nano, the smallest graphics processing unit (GPU) board offered by NVIDIA Corporation.},
  keywords={Target tracking;Radar tracking;Artificial intelligence;Surveillance;Video tracking;Convolutional neural networks;Costs;Convolutional neural network (CNN);domain translation;generative adversarial network (GAN);mean-shift algorithm;Siamese networks;target tracking},
  doi={10.1109/TAI.2022.3151307},
  ISSN={2691-4581},
  month={Feb},}@INPROCEEDINGS{10808104,
  author={Zhang, Zhenhong and Chen, Jiajing and Shi, Weiyan and Yi, Lingjie and Wang, Chihang and Yu, Qian},
  booktitle={2024 5th International Conference on Intelligent Computing and Human-Computer Interaction (ICHCI)}, 
  title={Contrastive Learning for Knowledge-Based Question Generation in Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={583-587},
  abstract={With the rapid development of artificial intelligence technology, especially the increasingly widespread application of question-and-answer systems, high-quality question generation has become a key component in supporting the development of these systems. This article focuses on knowledge-based question generation technology, which aims to enable computers to simulate the human questioning process based on understanding specific texts or knowledge bases. In light of the issues of hallucination and knowledge gaps present in large-scale language models when applied to knowledge-intensive tasks, this paper proposes an enhanced question generation method that incorporates contrastive learning. This method utilizes multiple models to jointly mine domain knowledge and uses contrastive learning to guide the model in reducing noise and hallucinations in generation. Experimental results show that by designing prompts containing contrasting examples, the model's performance in question generation improves considerably, particularly when contrasting instructions and examples are used simultaneously, leading to the highest quality of generated questions and improved accuracy. These results demonstrate that the method proposed in this study, which combines contrasting context and chain-of-thought prompts, can effectively improve both the quality and the practicality of question generation.},
  keywords={Human computer interaction;Accuracy;Computational modeling;Large language models;Knowledge based systems;Noise;Contrastive learning;Question generation;Reliability;Context modeling;Contrastive learning;question generation;large-scale language models;knowledge-intensive tasks},
  doi={10.1109/ICHCI63580.2024.10808104},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8944462,
  author={Nisha, D and Sivaraman, E and Honnavalli, Prasad B},
  booktitle={2019 10th International Conference on Computing, Communication and Networking Technologies (ICCCNT)}, 
  title={Predicting and Preventing Malware in Machine Learning Model}, 
  year={2019},
  volume={},
  number={},
  pages={1-7},
  abstract={Machine learning is a major area in artificial intelligence, which enables computer to learn itself explicitly without programming. As machine learning is widely used in making decision automatically, attackers have strong intention to manipulate the prediction generated my machine learning model. In this paper we study about the different types of attacks and its countermeasures on machine learning model. By research we found that there are many security threats in various algorithms such as K-nearest-neighbors (KNN) classifier, random forest, AdaBoost, support vector machine (SVM), decision tree, we revisit existing security threads and check what are the possible countermeasures during the training and prediction phase of machine learning model. In machine learning model there are 2 types of attacks that is causative attack which occurs during the training phase and exploratory attack which occurs during the prediction phase, we will also discuss about the countermeasures on machine learning model, the countermeasures are data sanitization, algorithm robustness enhancement, and privacy preserving techniques.},
  keywords={Machine learning;Predictive models;Data models;Training;Machine learning algorithms;Security;Classification algorithms;Causative attack;exploratory attack;Data sanitization;Algorithm robustness enhancement;Privacy preserving technique},
  doi={10.1109/ICCCNT45670.2019.8944462},
  ISSN={},
  month={July},}@INPROCEEDINGS{9824915,
  author={Gao, Xinyi and Wang, Shengzhe and Cui, Yuyong and Wu, Zhongjian},
  booktitle={2022 3rd International Conference on Computer Vision, Image and Deep Learning & International Conference on Computer Engineering and Applications (CVIDL & ICCEA)}, 
  title={Aero-Optical Image and Video Restoration Based on Mean Filter and Adversarial Network}, 
  year={2022},
  volume={},
  number={},
  pages={528-532},
  abstract={Target detection, recognition, and tracking technology has been widely concerned with the development of artificial intelligence. However, images or videos taken from a long distance could be easily affected by atmospheric turbulence so degradation often occur. With the aim of providing reliable data for further processing, a new method is proposed to obtain sharp image and video from those with aero-optical effect. Firstly, both the degradation and reconstruction models are established. Secondly, mean filter is applied to remove the additive noise in the shooting process of infrared camera. Then, combined with the pyramid structure, the generated countermeasure network based on MobileNet-v2 is used to restore the blurred image without noise. Finally, experiments with the evaluation indexes including Peak-Signal to Noise Ratio (PSNR), Structural Similarity (SSIM), and Kernelized Correlation Filters (KCF) are carried out to demonstrate the significant improvements over competitive algorithms.},
  keywords={Degradation;Target tracking;Target recognition;Atmospheric modeling;Object detection;Filtering algorithms;Image restoration;aero-optical effect;image restoration;adversarial network;turbulence degradation;KCF},
  doi={10.1109/CVIDLICCEA56201.2022.9824915},
  ISSN={},
  month={May},}@ARTICLE{9913205,
  author={Ma, Hongyao and Wang, Zhixue and Gao, Hang and Shen, Zhen and Zhang, Hong and Hu, Xueliang and Li, Chuanfu and Xiong, Gang},
  journal={IEEE Journal of Radio Frequency Identification}, 
  title={Parallel Systems for the Bridge Inspection}, 
  year={2022},
  volume={6},
  number={},
  pages={783-786},
  abstract={As the number of bridges grows in China, bridge inspection is necessary to ensure public transport safety. With the development of various technologies in recent years, such as unmanned aerial vehicles, computer vision, advanced sensing, artificial intelligence, intelligent technologies in bridge inspection have developed rapidly and are gradually replacing traditional methods. Here we propose the parallel systems for bridge inspection, which introduces the parallel theory into the field of bridge inspection to solve the problems of data shortage and the special scene prediction. Based on the classification of concrete dataset (CCD) and the parallel classification dataset (PCD), ConvNeXt and other neural networks are trained and compared. The crack detection accuracy reached 99.22%. We believe that the framework proposed in this paper can improve the efficiency and accuracy of bridge inspection significantly.},
  keywords={Bridges;Inspection;Computational modeling;Intelligent systems;Simultaneous localization and mapping;Point cloud compression;Load modeling;Parallel systems;bridge inspection;intelligent technologies},
  doi={10.1109/JRFID.2022.3212598},
  ISSN={2469-7281},
  month={},}@INPROCEEDINGS{10174453,
  author={More, Vaishnavi and Khalil, Mohammad Affan and George, Kiran},
  booktitle={2023 IEEE World AI IoT Congress (AIIoT)}, 
  title={Using Motor Imagery and Deeping Learning for Brain-Computer Interface in Video Games}, 
  year={2023},
  volume={},
  number={},
  pages={0711-0716},
  abstract={This paper proposes a real-time video game that allows users to use bio signals to play the game through implementation of artificial intelligence and deep learning neural networks. A real-time Electroencephalography (EEG) signal processing algorithm was proposed through classification using the MNE-Python library. The game involves navigating a virtual environment while wearing a g. Nautilus headset that detects the player's brainwave activity. The player's brainwave signals were inputted into a neural network in order to classify the player's intended action in the video game. The neural network is trained using a dataset of EEG signals from multiple participants performing specific mental tasks. The game is designed using the pygame library, and classification output serves as input to the game. The game is tested with a group of participants, and the results show that the BCI-controlled avatar effectively controls the game. The model can achieve an accuracy of 66% when the participant is playing a game.},
  keywords={Headphones;Deep learning;Video games;Signal processing algorithms;Games;Brain modeling;Electroencephalography;Electroencephalography (EEG);Convolutional Neural Networks (CNN);motor imagery (MI) techniques;Real-Time},
  doi={10.1109/AIIoT58121.2023.10174453},
  ISSN={},
  month={June},}@INPROCEEDINGS{10080643,
  author={Herman, Jacob and Zewail, Rami and Ogawa, Tetsuji and ElSagheer, Samir},
  booktitle={2023 15th International Conference on Computer Research and Development (ICCRD)}, 
  title={A Lightweight Transfer Learning-Based Model for Building Classification in Aerial Imagery}, 
  year={2023},
  volume={},
  number={},
  pages={181-186},
  abstract={Over the past decade, there has been a growing interest in the potential of artificial intelligence and computerr vision in tackling challenges related to disaster resilience in urban communities. Unmanned aerial imagery has been the focal of a number of initiatives targeting urban planning and aftermath disaster assessment. Within this context, this presents a novel lightweight transfer learning-based model for assessment of building conditions from aerial images. The proposed method is suitable for EDGE-based operations in resource-limited settings. Experiments were conducted to identify post-flooding building conditions in Zanzibar city in Tanzania. Considerable gains in terms of memory and computation time have been achieved while maintaining accuracies that are in line with state-of-art approaches.},
  keywords={Computational modeling;Buildings;Urban planning;Transfer learning;Memory management;Mobile handsets;Iterative methods;building classification;transfer learning},
  doi={10.1109/ICCRD56364.2023.10080643},
  ISSN={2161-0894},
  month={Jan},}@INPROCEEDINGS{10441394,
  author={Arnab, S.M. Rhydh and Uddin, Mohammad Rakin and Jawad, Atik},
  booktitle={2023 26th International Conference on Computer and Information Technology (ICCIT)}, 
  title={Enhancing Parkinson’s Disease Detection Through Handwriting Analysis: A Deep Learning Approach with Segmentation and Transfer Learning}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Parkinson’s disease (PD), a potentially fatal neurological disorder, necessitates early detection to enable appropriate treatment for affected individuals. The application of artificial intelligence in PD detection is gaining focus in this context. In this regard, this research paper introduces a novel deep learning-based approach aimed at classifying PD through the analysis of handwriting images. The proposed model employs a combination of image segmentation and data augmentation techniques, integrated with a modified DenseNet201 architecture, to ensure efficient and precise PD classification, particularly when confronted with a limited dataset. The segmentation process is applied to isolate the region containing pixel data corresponding to the handwriting data points. Additionally, data augmentation is employed prior to model training to address the challenges posed by a relatively small dataset. Evaluating the proposed approach on a dataset comprising 97 handwriting images, the results demonstrate an impressive accuracy rate of 96.67% on the test set. Furthermore, the model exhibits a well-balanced performance across both data classes, as indicated by F1-score and Recall metrics. Furthermore, the proposed handwriting image-based classification approach demonstrates a substantial improvement over tabular dataset-based classification. The findings also show that in the absence of either segmentation or augmentation, the overall model accuracy decreases to 92.9% and 63.3%, respectively. Moreover, in terms of accuracy, the proposed model outperforms several state-of-the-art methods currently in use, thereby validating its efficacy. Consequently, this research has the potential to significantly enhance the accuracy of PD detection, even when working with limited image data.},
  keywords={Deep learning;Training;Image segmentation;Semantic segmentation;Transfer learning;Data augmentation;Data models;Parkinson’s disease;segmentation;DenseNet201;augmentation;handwriting;deep learning},
  doi={10.1109/ICCIT60459.2023.10441394},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9586966,
  author={Ding, Zhengqi and Sun, Gang and Xu, Huanqing},
  booktitle={2021 IEEE 5th Information Technology,Networking,Electronic and Automation Control Conference (ITNEC)}, 
  title={A Tumor Image Feature Agumentation Algorithm based on Improved Convolutional Neural Network}, 
  year={2021},
  volume={5},
  number={},
  pages={1085-1089},
  abstract={Cell image-based disease prediction model is an important research in the field of artificial intelligence, which is based on the assumption of converting tumor images into matrices for classifying and learning matrix features in neural networks. However, the differences in the incidence of different diseases lead to insufficient data from medical samples, making it difficult train efficient and accurate prediction models. Therefore, the small data problem becomes an urgent problem for scientists to solve. In this paper, we propose a feature augmentation algorithm based on an improved visual geometry group (VGG19) neural network, which can augment the size and quality of the medical image dataset and avoid the overfitting problem of disease prediction models due to insufficient medical image dataset. We obtain the feature-augmented dataset for traditional machine learning model. The feature augmentation algorithm set out in the present paper improves in accuracy, f-score, and recall metrics.},
  keywords={Machine learning algorithms;Neural networks;Predictive models;Prediction algorithms;Feature extraction;Convolutional neural networks;Matrix converters;convolutional neural network;feature augmentation;tumor image recognition;machine learning},
  doi={10.1109/ITNEC52019.2021.9586966},
  ISSN={2693-3128},
  month={Oct},}@INPROCEEDINGS{10167194,
  author={Zhang, Haowei},
  booktitle={2023 4th International Conference on Computer Vision, Image and Deep Learning (CVIDL)}, 
  title={Seg-CycleGAN: An Improved CycleGAN For Abstract Painting Generation}, 
  year={2023},
  volume={},
  number={},
  pages={416-421},
  abstract={In modern art, the creation of abstract painting has become a prominent artistic expression with significant aesthetic merit. With the development of artificial intelligence, the abstract paintings generated by AI has gradually been recognized by the public. This paper proposes an abstract painting creation method based on an improved CycleGAN network (Seg-CycleGAN). Our method starts by obtaining a collection of color blocks through clustering and color block reorganization based on the original input image which is then fed into the CycleGAN network for style transfer. In addition, we add a clustering layer on one of the generator of CycleGAN, which can effectively accelerate the convergence speed of the generator and improve the training efficiency and quality of results. This work provides a novel method for AI generation of abstract paintings and demonstrates its effectiveness in experiments.},
  keywords={Training;Technological innovation;Art;Image color analysis;Image synthesis;Clustering algorithms;Generators;AI generation;Abstract paintings;CycleGAN;Cluster;Color and Texture;Image-to-Image Translation},
  doi={10.1109/CVIDL58838.2023.10167194},
  ISSN={},
  month={May},}@INPROCEEDINGS{10765637,
  author={Parra-Ullauri, Juan Marcelo and Dilley, Oscar and Madhukumar, Hari and Simeonidou, Dimitra},
  booktitle={2024 3rd International Conference on 6G Networking (6GNet)}, 
  title={Profiling AI Models: Towards Efficient Computation Offloading in Heterogeneous Edge AI Systems}, 
  year={2024},
  volume={},
  number={},
  pages={164-166},
  abstract={The rapid growth of end-user AI applications, such as computer vision and generative AI, has led to immense data and processing demands often exceeding user devices' capabilities. Edge AI addresses this by offloading computation to the network edge, crucial for future services in 6G networks. However, it faces challenges such as limited resources during simultaneous offloads and the unrealistic assumption of homogeneous system architecture. To address these, we propose a research roadmap focused on profiling AI models, capturing data about model types, hyperparameters, and underlying hardware to predict resource utilisation and task completion time. Initial experiments with over 3,000 runs show promise in optimising resource allocation and enhancing Edge AI performance.},
  keywords={6G mobile communication;Generative AI;Computational modeling;Systems architecture;Edge AI;Predictive models;Data models;Hardware;Resource management;Faces;Edge AI;6G;Task Offloading;Profiling;Distributed AI},
  doi={10.1109/6GNet63182.2024.10765637},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10372644,
  author={Zekovic, Amela},
  booktitle={2023 31st Telecommunications Forum (TELFOR)}, 
  title={Survey of Internet of Things Applications using Raspberry Pi and Computer Vision}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={This paper gives a survey of Internet of Things (IoT) solutions using Raspberry Pi (RPi) Single Board Computer (SBC) and methods of Artificial Intelligence (AI) area – Computer Vision (CV). Solutions for several areas of IoT applications are presented and compared. An overview of the used hardware, software, CV methods, and CV algorithms are given.},
  keywords={Surveys;Computer vision;Economic indicators;Software algorithms;Hardware;Software;Telecommunications;Computer Vision (CV);Raspberry Pi (RPi);Internet of Things (IoT);Edge AI},
  doi={10.1109/TELFOR59449.2023.10372644},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10672910,
  author={Rohinidevi, V. Vasuki and V, Deeban Chakravarthy and Deepak, S. Prem Kumar},
  booktitle={2024 7th International Conference on Circuit Power and Computing Technologies (ICCPCT)}, 
  title={Systematic Review of Emerging Deep Learning approaches for Crop Diseases detection}, 
  year={2024},
  volume={1},
  number={},
  pages={1439-1444},
  abstract={Deep learning, a branch of artificial intelligence, has drawn interest from the academic and corporate realms, especially in areas like speech and image analysis, video processing, and natural language processing. Its use in agricultural plant protection has expanded to include the diagnosis and evaluation of pests and plant diseases. In this situation, there are several benefits to using deep learning. It removes the biases related to manually chosen pathogen properties, improves objectivity when determining disease characteristics, and hastens the advancement of contemporary technology. In order to diagnose agricultural leaf illnesses, this study explores the most recent developments in deep learning methods, including CNN, DENSNET, InceptionV3, VGG16, Resnet50, and MobileNet, in addition to a variety of sensors. This project aims to aid scientists in the field by tackling challenges in merging deep learning and cutting-edge imaging tools to enhance illness identification. It addresses current trends and barriers, shedding light on unresolved issues and paving the way for further research. By clarifying persistent problems and posing new questions, it fosters progress and innovation in the field of medical imaging and diagnosis.},
  keywords={Deep learning;Plant diseases;Technological innovation;Transfer learning;Sensor phenomena and characterization;Stability analysis;Time factors;Deep learning;crop diseases;CNN;Resnet50;sensor;Leaf wetness},
  doi={10.1109/ICCPCT61902.2024.10672910},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10079059,
  author={Wang, Linlin and Wang, Zhongxun and Wang, Jiao and Liu, Peixue},
  booktitle={2022 2nd International Conference on Networking, Communications and Information Technology (NetCIT)}, 
  title={A Survey of Random Noise Suppression Methods for Seismic Data based on Deep Learning}, 
  year={2022},
  volume={},
  number={},
  pages={572-576},
  abstract={Deep learning has increasingly made their way into the seismic exploration industry as a result of the ongoing development of artificial intelligence. The deep learning approach is brought to the field of seismic data denoising with the goal of addressing the issue that standard denoising methods and denoising models cannot effectively suppress random noise with good quality. Deep learning employs multi-layer convolution to extract deep-level data features, and it creates complex denoising models through adaptive learning of linear approximation to achieve end-to-end mapping between noisy seismic data and denoised seismic data, which introduces a novel concept for seismic data denoising. In this paper, the research of depth learning in random noise suppression of seismic data is introduced, analyzed and summarized with the deep learning network framework as the classification standard.},
  keywords={Deep learning;Industries;Adaptation models;Noise reduction;Linear approximation;Feature extraction;Data models;deep learning;seismic data;noise;denoising},
  doi={10.1109/NetCIT57419.2022.00136},
  ISSN={},
  month={Dec},}@ARTICLE{11016031,
  author={Mohammed, Abdulrahim and Hussain, Muhammad},
  journal={IEEE Access}, 
  title={Advances and Challenges in Deep Learning for Automated Welding Defect Detection: A Technical Survey}, 
  year={2025},
  volume={13},
  number={},
  pages={94553-94569},
  abstract={Automated welding defect detection has emerged as a pivotal aspect of quality assurance in high-stakes industries such as aerospace, oil and gas, and construction. This paper presents a comprehensive review of state-of-the-art Deep Learning (DL) models tailored for welding defect detection, segmentation, and classification, emphasizing technical advancements and persistent challenges. A critical analysis of single-stage and two-stage architectures is conducted to evaluate their ability to address issues like small defect sizes, low image contrast, and diverse defect geometries. The study also highlights the integration of advanced preprocessing techniques, such as noise reduction and contrast enhancement, within DL workflows to improve feature extraction and detection accuracy. Persistent challenges, such as the scarcity of large, labeled datasets, lack of real-time applicability, and limited model interpretability, are explored in depth. To address these gaps, the survey proposes future directions, including the use of self-supervised learning, domain adaptation, Generative Adversarial Networks (GANs), and explainable AI techniques to enhance the robustness, scalability, and transparency of welding defect detection systems. By synthesizing insights from more than a decade of research, this paper provides a detailed roadmap for advancing automated welding inspection technologies, enabling reliable deployment in real-world industrial environments.},
  keywords={Welding;Defect detection;Radiography;Surveys;Image enhancement;Filtering;Wiener filters;Inspection;Image edge detection;Accuracy;Artificial intelligence (AI);computer vision;deep learning;radiographic images;image classification;image segmentation;automated welding defect detection;image enhancement},
  doi={10.1109/ACCESS.2025.3574083},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11028675,
  author={Xiang, Zeyu and Wang, Ze and Xie, Jiawen and Wang, Weidong and Xi, Linhui},
  booktitle={2024 International Conference on Virtual Reality and Visualization (ICVRV)}, 
  title={Research on Medical Image Data Enhancement based on Variational Autoencoders}, 
  year={2024},
  volume={},
  number={},
  pages={78-81},
  abstract={At present, artificial intelligence technology is extensively utilized in the domain of medical image processing, having attained considerable success. Despite the fact that deep learning models are capable of performing better than humans in a multitude of tasks, their enhanced performance is frequently contingent upon the availability of extensive training data. The model employs variational autoencoders (VAEs) to discern the intricate data distribution of medical images through the encoder-decoder structure. Firstly, the encoder maps the incoming medical image to a contiguous latent space, thereby capturing its key features and latent variables. Subsequently, the decoder generates new high-quality images by sampling from the latent space, thereby retaining medically relevant information from the original data and producing diverse and authentic images. In this manner, VAEs can generate diverse and realistic medical images during data augmentation, thereby enhancing the performance and robustness of models in downstream tasks such as classification, segmentation, and diagnosis. Experimental analysis demonstrates that the proposed method markedly improves the accuracy of the model in a number of medical imaging tasks.},
  keywords={Solid modeling;Autoencoders;Diversity reception;Training data;Virtual reality;Data augmentation;Data models;Robustness;Biomedical image processing;Medical diagnostic imaging;medical image processing;image enhancement;variational autoencoders;data augmentation},
  doi={10.1109/ICVRV62410.2024.00023},
  ISSN={2473-571X},
  month={Dec},}@INPROCEEDINGS{10008162,
  author={Wan, Xuan and Zhang, Xue-han},
  booktitle={2022 10th International Conference on Orange Technology (ICOT)}, 
  title={Research on Machine Generation and Design of ‘Orchid Calligraphy’}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  abstract={In the era where information changes rapidly, the font design of Chinese character calligraphy library with huge workload has become more challenging. With the help of artificial intelligence algorithms, the Chinese character database with a huge amount of data provides a basic guarantee for the big data processing used in machine learning. Starting from the present situation of calligraphy font design, through the design and creation of “orchid calligraphy” and comparative analysis of “variable orchid calligraphy font” generated by machine learning, this paper studies the differences and connections to explore the feasibility of integration between the two and the possibility of machine-generated fonts instead of designers to design fonts.},
  keywords={Training;Machine learning algorithms;Databases;Design methodology;Machine learning;Big Data;Market research;the font of character library;machine generation;design integration;GAN},
  doi={10.1109/ICOT56925.2022.10008162},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10827434,
  author={Lee, SooHyung and Park, WooSu and Lee, KiSuk},
  booktitle={2024 15th International Conference on Information and Communication Technology Convergence (ICTC)}, 
  title={Building Knowledge Base of 3D Object Assets Using Multimodal LLM AI Model}, 
  year={2024},
  volume={},
  number={},
  pages={416-418},
  abstract={The proliferation of various XR (eXtended Reality) services and the increasing incorporation of visual effects into existing content services have led to an exponential rise in the demand for 3D object assets. This paper describes an LLM (Large Language Model)-based multimodal AI model pipeline that can be applied to a generative AI model for creating new 3D objects or restructuring the asset management system to enhance the reusability of existing 3D objects. By leveraging a multimodal AI model, we derived descriptive text for assets such as 3D object, 2D image at a human-perceptible level, rather than mere data, and subsequently used an LLM to generate knowledge triplets for constructing an asset knowledge base. The applicability of this pipeline was verified using actual 3D objects from a content production company. Future work will focus on improving the quality of the generated knowledge triplets themselves by training the multimodal AI model with real-world content usage assets.},
  keywords={Training;Solid modeling;Three-dimensional displays;Generative AI;Extended reality;Pipelines;Knowledge based systems;Production;Visual effects;Information and communication technology;LLM;Multi-Modal AI;XR;3D Object;Knowledge Base},
  doi={10.1109/ICTC62082.2024.10827434},
  ISSN={2162-1241},
  month={Oct},}@INPROCEEDINGS{11011119,
  author={Cai, Yong and Wang, Xi},
  booktitle={2025 2nd International Conference on Algorithms, Software Engineering and Network Security (ASENS)}, 
  title={An Ontology-Based Framework for Automated Dataset Validation}, 
  year={2025},
  volume={},
  number={},
  pages={19-23},
  abstract={With the rapid development of artificial intelligence, the importance of data quality has become increasingly prominent. The existing data quality assessment methods, such as accuracy, completeness, consistency, effectiveness, timeliness, uniqueness, intelligibility assessment and data quality indicators, lack user perspective and may not accurately reflect the applicability and practicability of the data in practical application, resulting in the evaluation results not matching with the specific needs and expectations of users. In this paper, we propose OmniSense, a framework of data quality assessment based on domain model and knowledge inference. Using domain model as a bridge, the link between the original data set and the user's needs is established, and the automatic data quality assessment from the user's perspective is realized. This approach enables the developer to estimate the support of the dataset for the implementation of the function before starting training, thereby reducing the cost of retraining due to the inapplicability of the dataset.},
  keywords={Training;Knowledge engineering;Data integrity;Software algorithms;Transforms;Ontologies;Network security;Data models;Kernel;Software engineering;data quality;domain model;ontology;coverage;knowledge inference},
  doi={10.1109/ASENS64990.2025.11011119},
  ISSN={},
  month={March},}@INPROCEEDINGS{10757140,
  author={Çakmak, Ebru and Akkaya, Sıtkı},
  booktitle={2024 Innovations in Intelligent Systems and Applications Conference (ASYU)}, 
  title={Generation of Experimental Data for Sag+Transient Disturbance in Smart Grid Systems}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Smart grids are a more efficient and safer electricity grid that includes today's technology. The biggest problem for smart grid systems is power quality disturbances. If power quality disturbances are not monitored and detected, they can cause major problems. For this reason, many researchers use signal processing methods and artificial intelligence tools on power quality disturbance data. Obtaining the data, which is the basis of the studies, is a separate subject of study. Since it is not possible to obtain data from the field, synthetic data or limited experimental data are mostly used in studies. In this study, the data of sag+transient signal, which is one of the complex data of power quality disturbances, was obtained from the experimental setup established in the laboratory environment. The similarity of experimental data associated with synthetic data to real data was compared through error rates. The results gave similarity values of 0.9492, 0.9477 and 0.8358 for Pearson, Spearman and Kendall respectively. It has been a result that will be a source for future studies.},
  keywords={Technological innovation;Power quality;Laboratories;Oscilloscopes;Signal generators;Prediction algorithms;Smart grids;Intelligent systems;Monitoring;Synthetic data;smart grids;power quality disturbances;experimental data;sag+transient},
  doi={10.1109/ASYU62119.2024.10757140},
  ISSN={2770-7946},
  month={Oct},}@INPROCEEDINGS{11016504,
  author={Chen, Xiaohan and Li, Na and Bajaj, Nikesh and Fan, Pengfei},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Enhancing Competition-Based Big Data Analytics Learning Through AI-Driven Distributed Scaffolding}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Competition-Based Learning (CBL) provides an engaging educational approach by combining collaboration with competition. However, learners often struggle with illstructured problems, particularly in fields like Big Data Analytics. This study investigates how Generative AI, specifically ChatGPT, can support CBL through distributed scaffolding, combining both structural and problem-based approaches to enhance learning. Implemented in an undergraduate Big Data Analytics course, the scaffolding utilized Kaggle for practical problem-solving projects. ChatGPT provided personalized feedback, helping students navigate complex tasks and enhance critical thinking. A mixedmethod evaluation involving surveys and interviews showed that the ChatGPT-supported scaffolding significantly improved knowledge construction, problem-solving skills, and student engagement. These findings highlight the potential of integrating AI-driven scaffolding in CBL environments to address learning challenges, ultimately fostering more effective educational experiences.},
  keywords={Surveys;Navigation;Generative AI;Collaboration;Big Data;Chatbots;Real-time systems;Problem-solving;Interviews;Engineering education;Competition-Based Learning;Kaggle;Big Data Analytics;Student Engagement;Distributed Scaffolding;AI in Education;Critical Thinking},
  doi={10.1109/EDUCON62633.2025.11016504},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10959630,
  author={Alqattan, Fatimah H. and Alsubaiey, Rahma A. and Albutaysh, Norah A. and Alnasser, Fatimah A. and Alhumud, Haythem A.},
  booktitle={2025 2nd International Conference on Advanced Innovations in Smart Cities (ICAISC)}, 
  title={Face Recognition Security Against Deepfakes by Using Multimodal Detection: A Survey}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={Technology has become an essential component of daily life, with millions of people placing their trust in it. Security is important, especially in maximizing the optimization of face recognition (FR) technology, since it has been an enormous concern. The process of recognizing people from images or video clips occurs by using algorithms that detect and extract distinctive facial features. This paper provides a comprehensive study of FR security threats, by reviewing multiple algorithms and Deep Learning (DL) approaches in the facial recognition field. The point of this paper is to discuss the challenge posed by facial spoofing attacks, using either 2D or 3D masks. In this paper we demonstrated different implementations of Convolutional Neural Networks (CNNs) and Artificial Neural Networks (ANNs) algorithms to address the complexity of deep fake detection, focusing on their varied methodologies for facial detection and recognition. The paper emphasizes on the importance of the CNNs and ANNs algorithms using the Inception V3 and ResNet-50 models that helps learn, verify, and recognize face images to enhance the results to be more accurate through using the precise models in common areas such as gates surveillance. Furthermore, different models will be discussed in the paper along with Inception V3 which obtained the maximum testing results based on high performance when interacting in various image environments and high reliability in handling complex data.},
  keywords={Deepfakes;Image recognition;Accuracy;Face recognition;Logic gates;Three-dimensional printing;Complexity theory;Security;Artificial intelligence;Testing;Face Recognition;Face Spoofing;CNNs;ANNs;Inception V3;ResNet-50},
  doi={10.1109/ICAISC64594.2025.10959630},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{11083000,
  author={Imai, Ryota and Ishibashi, Atsushi and Takemoto, Takahiro and Yang, Ayoung and Furuya, Tadasuke},
  booktitle={2025 6th International Conference on Machine Learning and Human-Computer Interaction (MLHMI)}, 
  title={Interface Design for Small Vessels in Autonomous Navigation Systems}, 
  year={2025},
  volume={},
  number={},
  pages={102-107},
  abstract={As the development of MASS(Maritime Autonomous Surface Ships) progresses, AI(artificial intelligence)-based systems have become a cornerstone of autonomous navigation technologies. However, the complexity and unpredictability of the marine environment limit the reliability of AI-based decision-making. Consequently, even with the advancement of autonomous ship technologies, interfaces that enable continuous monitoring of AI systems and allow human intervention when necessary remain essential. This study focuses on the design and implementation of a tablet-based interface for small vessels, enabling real-time visualization of AI decisionmaking processes. The interface supports users in monitoring and intervening as required, thereby enhancing the safety and efficiency of autonomous navigation. By addressing these challenges, the proposed interface aims to ensure a reliable operational environment for autonomous ships, even under fully autonomous conditions.},
  keywords={Visualization;Human-machine systems;Machine learning;Real-time systems;Safety;Reliability;Marine vehicles;Monitoring;Autonomous vehicles;Autonomous robots;Autonomous Surface Ships (MASS);Small Vessel;AI Monitoring Interface;Human-Machine Collaboration},
  doi={10.1109/MLHMI66056.2025.00022},
  ISSN={},
  month={March},}@INPROCEEDINGS{10258194,
  author={Tsai, Jih-Wei and Huang, Chao-Chun and Chu, Chen-Hung and Fan, Gong-Da},
  booktitle={2023 24st Asia-Pacific Network Operations and Management Symposium (APNOMS)}, 
  title={The Smart Applications of ICT and IoT with AI Techniques in IMS Network}, 
  year={2023},
  volume={},
  number={},
  pages={290-293},
  abstract={in this paper, the smart applications of Information and Communication Technologies (ICT) and Internet of Things (IoT) with Artificial Intelligence (AI) techniques are introduced. The AI techniques are applied in Speech to Text/Text to Speech (STT/TTS) functions and Semantic Analysis, etc. The converged architecture of the applications in IP Multimedia Subsystem (IMS) network is shown. Based on the architecture and under Intelligent Communication Service Platform (ICSP), there are two smart applications presented for field trial. The first one is the anti-fraud system to avoid fraudulent call. The second one is the call-out chatbot to make reservations for restaurant more conveniently.},
  keywords={Analytical models;Semantics;Network architecture;Chatbots;Information and communication technology;Internet of Things;IP networks;ICT;IoT;AI;IMS},
  doi={},
  ISSN={2576-8565},
  month={Sep.},}@INPROCEEDINGS{10786735,
  author={Srock, Philipp and Tapia, Juan E.},
  booktitle={2024 International Conference of the Biometrics Special Interest Group (BIOSIG)}, 
  title={Classifying Face Beauty Based on Retouched Images}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The use of facial image filters to modify personal facial attractiveness (beauty) has increased over the past decade. The result of this process is called a “retouched image”. So, the perception of what is less/more beautiful was raised as an exciting topic. As an assumption, there could be a correlation between beauty scores and how well a machine-learning binary classifier can detect them. The more a given filter differs in its “beauty score”, the easier it is for an Artificial Intelligence (AI) or Machine Learning (ML) model to recognise it as such. This work seeks to answer these assumptions.},
  keywords={Visualization;Filters;Protocols;Face recognition;Digital images;Machine learning;Inspection;Feature extraction;High frequency;Discrete cosine transforms;Biometrics;Face beauty;Retouching},
  doi={10.1109/BIOSIG61931.2024.10786735},
  ISSN={1617-5468},
  month={Sep.},}@INPROCEEDINGS{9326940,
  author={Jiaxu, Li and Yuling, Hu},
  booktitle={2020 Chinese Automation Congress (CAC)}, 
  title={Research Framework of Risk Assessment in Evacuation Based on Deep Learning}, 
  year={2020},
  volume={},
  number={},
  pages={1860-1864},
  abstract={Aim at the occurrence of security accidents, emergency evacuation has become an important means that cannot be ignored. At present, most of the risk assessment studies are focused on accident analysis, while only a few studies conduct risk assessments on evacuation issues. Without the basis for risk assessment, it is easy to ignore some important factors when formulating an evacuation emergency plan, resulting in lacking of science in the evacuation plan and even a negative impact in actual implementation. Therefore, the research on risk assessment of evacuation is a very significant research direction. In addition, with the advent of the era of big data and the development of artificial intelligence, the data required for risk assessment is also increasing, and traditional risk assessment methods are difficult to deal with these huge amounts of data. Therefore, the use of deep learning methods into risk assessment and deal with this problem is also one trend in future. The major objective of this study was to apply deep learning method to evacuation risk assessment, and give a framework of risk assessment in evacuation based on convolutional neural networks.},
  keywords={Risk management;Accidents;Deep learning;Neurons;Convolutional neural networks;Biological neural networks;Big Data;risk assessment;emergency evacuation;deep learning;convolutional neural network},
  doi={10.1109/CAC51589.2020.9326940},
  ISSN={2688-0938},
  month={Nov},}@INPROCEEDINGS{11136286,
  author={Handaragall, Vijayalaxmi C and Subhash Metan, Jyoti},
  booktitle={2025 International Conference on Intelligent Computing and Knowledge Extraction (ICICKE)}, 
  title={Comprehensive Analysis of Deep Fake Detection Techniques for Images and Videos using Deep Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Deep fake detection is the process of identifying and recognizing manipulated media such as videos or images, which replicate original people through Artificial Intelligence (AI) techniques. AI methods like Machine Learning (ML) and Deep Learning (DL) approaches aim to differentiate among reliable and altered contented to avoid misinformation. Distinguishing between original and forged images is difficult due to the similarity in their features, often leading to misidentification and causing inaccurate detection. This survey aims to analyze deep fake video and image detection methods and highlights the many challenges encountered during the detection of deep fake content. Detection approaches for videos include Dense Swim Transformer Net (DST-Net) and Directional Magnitude Local Hexadecimal Pattern (DMHLP), while image-based detection approaches include Vector Auto Regressive Moving Average (VARMA), and Gated Recurrent Unit (GRU), referred to as VARMA-LSTM-GRU. Performance metrics such as precision, F1-score, and accuracy are utilized to evaluate deep fake detection models.},
  keywords={Surveys;Deep learning;Deepfakes;Image recognition;Accuracy;Computational modeling;Streaming media;Transformers;Vectors;Security;deep fake detection;deep learning;forged images;image-based detection;video detection},
  doi={10.1109/ICICKE65317.2025.11136286},
  ISSN={},
  month={June},}@INPROCEEDINGS{11025240,
  author={Liu, Wenyue and Lian, Denise Koh Choon and Zhang, Zhihao and Qiu, Jianguo},
  booktitle={2024 4th International Conference on Information Technology and Contemporary Sports (TCS)}, 
  title={DSSO: A High-precision Action Recognition Model for Aerobics based on Dynamic Segmentation and Sequence Optimization}, 
  year={2024},
  volume={},
  number={},
  pages={60-64},
  abstract={With the development of artificial intelligence and computer vision technologies, the application of these advanced technologies to the movement analysis of athletes has become a research focus in the field of sports science. Especially in aerobics, a sports activity that requires a high degree of coordination and technical precision, the application of movement recognition technology can significantly enhance training effects and athletic performance. However, due to the rapidity of aerobics movements and the interference of complex backgrounds, existing action recognition systems have obvious limitations in capturing and analyzing continuous action sequences, such as motion occlusion and insufficient detail capture, which seriously affect the application of the technology. In this study, we propose an integrated action recognition system that contains three modules, aiming to solve the above problems. First, an innovative foreground separation technique is used to effectively extract the athlete’s image from a complex or dynamic background to clearly separate the action subject. Next, a super-resolution technique is introduced to enhance the details of the foreground image, a step that significantly improves the system’s accuracy in recognizing fast and small movements. Finally, the recognition process of the entire aerobics action sequence is optimized by means of time series analysis to effectively deal with the recognition challenges brought by action occlusion and rapid changes. Experimental results on HSiPu2 and UESTC RGB-D Varying-view action databases show that the present model can significantly improve the accuracy compared with existing models.},
  keywords={Training;Analytical models;Accuracy;Databases;Computational modeling;Time series analysis;Aerodynamics;Real-time systems;Optimization;Sports;aerobics movements;complex backgrounds;motion occlusion},
  doi={10.1109/TCS64526.2024.11025240},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10908039,
  author={Wang, ShiYun and Song, ZiAn and Deng, ZhengJie},
  booktitle={2024 International Symposium on Digital Home (ISDH)}, 
  title={An Adversarial Examples Defense Method Based on Convolutional Compressed Residual Network}, 
  year={2024},
  volume={},
  number={},
  pages={173-178},
  abstract={With the wide spread application of artificial intelligence technology in various fields, people are increasingly concerned about its security issues. Especially in image recognition systems, there are some potential security risks. Attackers can generate adversarial examples by adding perturbations to the image, which are difficult for the human eye to detect but can cause the image recognition system to produce incorrect classification results. This article proposes a new adversarial examples defense method based on convolutional compression residual networks, which quickly extracts low-frequency information from images through convolutional compression and combines it with the original image to reduce the impact of high-frequency disturbances on the model. This method not only effectively reduces the impact of adversarial examples on the model in the high-frequency range, but also alleviates the model's excessive sensitivity to high-frequency information, thereby improving the model's defense and running speed while maintaining its recognition rate.},
  keywords={Image coding;Image recognition;Sensitivity;Convolution;Perturbation methods;Feature extraction;Data mining;Security;Residual neural networks;Testing;component;adversarial examples defense;image low-frequency information;convolution compression;residual network},
  doi={10.1109/ISDH64927.2024.00036},
  ISSN={2769-8823},
  month={Nov},}@INBOOK{10819715,
  author={Zoha, Ahmed and Ramzan, Naeem and Jamshed, Muhammad Ali and Ur Rehman, Masood},
  booktitle={Multimodal Intelligent Sensing in Modern Applications}, 
  title={Road Ahead for Multi&#x2010;modal Intelligent Sensing in the Deep Learning Era}, 
  year={2025},
  volume={},
  number={},
  pages={275-283},
  abstract={Summary <p>In the field of computing and artificial intelligence (AI), multi&#x2010;modality enables systems to process and integrate information from different sources, such as text, images, video, and audio. This capability enhances perception, allowing machines to understand their environment better and make improved decisions. This chapter explores the opportunities that existing systems present, such as improved accuracy and enhanced insights, as well as the challenges they face. While promising for advancing various fields, multi&#x2010;modal data fusion faces significant challenges in the age of big data and deep learning. Interpretability remains a crucial concern, prompting the exploration of hybrid approaches that combine statistical signal processing with deep learning, as well as incorporating human expertise for decision&#x2010;making. Additionally, ethical considerations surrounding privacy, bias, and transparency must be carefully addressed through clear governance policies, bias mitigation techniques, and explainable AI methods.</p>},
  keywords={Data models;Semantics;Feature extraction;Computational modeling;Training;Deep learning;Data integration;Adaptation models;Parallel processing;Transfer learning},
  doi={10.1002/9781394257744.ch12},
  ISSN={},
  publisher={IEEE},
  isbn={9781394257737},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10819715},}@INPROCEEDINGS{10532780,
  author={Ali, Atif and Razzaque, Abdul and Munir, Usama and Shahid, Hina and Khattak, Furqan Wali and Rajpoot, Zain and Kamran, Muhammad and Farid, Zulqarnain},
  booktitle={2024 2nd International Conference on Cyber Resilience (ICCR)}, 
  title={AI-Driven Approaches to Cybersecurity: The Impact of Machine and Deep Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Computer Security is constantly evolving and dynamic; today, applying Artificial Intelligence techniques becomes indispensable in treating and detecting threats to which organizations are exposed. Developing information and communications technologies requires cybersecurity mechanisms that guarantee confidentiality, integrity, availability of information, and the development of skills to detect and control new threats on time.},
  keywords={Deep learning;Technological innovation;Ecosystems;Organizations;Information and communication technology;Complexity theory;Computer crime;Cybersecurity;Machine Learning;security;cyberattacks;cybercriminals;SQL Injection},
  doi={10.1109/ICCR61006.2024.10532780},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10538567,
  author={Sinha, Arani and Carlo, Stefano Di},
  booktitle={2024 IEEE 42nd VLSI Test Symposium (VTS)}, 
  title={Innovative Practices Track: Session 4 AI Applications in Test}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={Intel uses AI across the entire product life cycle, from design to product ship. In this talk, the speaker will discuss applications of AI for product development that spans post Si work and test manufacturing flows. The talk will focus on traditional ML applications in Intel’s test manufacturing flow that combine ML techniques and innovation in test infrastructure development to deliver personalized unit testing for optimizing test cost, product performance and improving outgoing quality. He will also go over how Intel is deploying generative AI for product development work to accelerate time to market while improving quality.},
  keywords={Technological innovation;Costs;Generative AI;Time to market;Very large scale integration;Silicon;Manufacturing},
  doi={10.1109/VTS60656.2024.10538567},
  ISSN={2375-1053},
  month={April},}@INPROCEEDINGS{10048916,
  author={Jin, Jungha and Park, SangSeon},
  booktitle={2023 International Conference on Information Networking (ICOIN)}, 
  title={Key generation and management method using AI generated Rubik’s cube states}, 
  year={2023},
  volume={},
  number={},
  pages={719-724},
  abstract={The current encryption system operates as a hybrid encryption method that uses a combination of the symmetric-key method and the asymmetric-key method to generate and manage keys for encryption communication. Despite the fast processing speed of symmetric key encryption methods, due to the problem in key exchange, hybrid encryption solves the security problem of key exchange using asymmetric key method. The asymmetric-key method is difficult to provide smooth services due to the decrease in processing speed caused by computational complexity. The hybrid method is designed to take advantage of the fast processing speed of the symmetric-key, and the secure exchange method of the key used in the symmetric-key operates by using the asymmetric-key. However, with the advent of quantum computer technology, encryption techniques using the asymmetric-key method are changing in the same way as increasing the key size used. Therefore, we will explain the AI application method using the state change of Rubik’s cube to generate keys in the latest state in the symmetric-key encryption system. The application of the Rubik’s cube state change algorithm, which operates on the AI base described in this paper, has the advantage of inducing and using the used key without exchanging the pre-shared key. Because of this key induction method, malicious attackers have little information on the keys used for encryption and decryption, so it is judged that the confidentiality and integrity of key generation and management can be secured more safely. We intend to improve the problem of key exchange and management in existing encryption systems by generating and managing keys through the Rubik’s cube state change algorithm, which operates based on AI.},
  keywords={Web and internet services;Focusing;Receivers;Companies;Speech recognition;Encryption;Internet;Artificial intelligence;key generation;symmetric-key encryption method;cryptography;Information security},
  doi={10.1109/ICOIN56518.2023.10048916},
  ISSN={1976-7684},
  month={Jan},}@INPROCEEDINGS{10578820,
  author={He, Zhangying and Nguyen, Thomas and Miari, Tahereh and Aliasgari, Mehrdad and Rafatirad, Setareh and Sayadi, Hossein},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={The AI Companion in Education: Analyzing the Pedagogical Potential of ChatGPT in Computer Science and Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Artificial Intelligence (AI), with ChatGPT as a prominent example, has recently taken center stage in various domains including higher education, particularly in Computer Science and Engineering (CSE). The AI revolution brings both convenience and controversy, offering substantial benefits while lacking formal guidance on their application. The primary objective of this work is to comprehensively analyze the pedagogical potential of ChatGPT in CSE education, understanding its strengths and limitations from the perspectives of educators and learners. We employ a systematic approach, creating a diverse range of educational practice problems within CSE field, focusing on various subjects such as data science, programming, AI, machine learning, networks, and more. According to our examinations, certain question types, like conceptual knowledge queries, typically do not pose significant challenges to ChatGPT, and thus, are excluded from our analysis. Alternatively, we focus our efforts on developing more in-depth and personalized questions and project-based tasks. These questions are presented to ChatGPT, followed by interactions to assess its effectiveness in delivering complete and meaningful responses. To this end, we propose a comprehensive five-factor reliability analysis framework to evaluate the responses. This assessment aims to identify when ChatGPT excels and when it faces challenges. Our study concludes with a correlation analysis, delving into the relationships among subjects, task types, and limiting factors. This analysis offers valuable insights to enhance ChatGPT's utility in CSE education, providing guidance to educators and students regarding its reliability and efficacy.},
  keywords={Systematics;Limiting;Focusing;Machine learning;Chatbots;Reliability;Task analysis;ChatGPT;Computer Science and Engineering;Education;Generative Artificial Intelligence;Reliability Analysis},
  doi={10.1109/EDUCON60312.2024.10578820},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10937567,
  author={Hong, Cherie and Gochuico, Yestin Arvin and Shin, Jiwon and Ha, Chaeyeon and Marquez, Lenin and Yoo, Youngjin and Lee, Jin-Kook},
  booktitle={2024 IEEE MIT Undergraduate Research Technology Conference (URTC)}, 
  title={Improving Architect-Specific Building Image Generation using Reinforced Data Processing}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper investigates the innovative potential of fine-tuning generative Artificial Intelligence (AI) models through Reinforced Data Processing (RDP) for architectural visualization, focusing on the styles of three renowned architects. The study examines how the varying levels of detail in textual descriptions within image-text pairs impact model performance and evaluates these effects using a domain-specific RDP approach. The findings demonstrate that utilizing RDP models outperforms the base model in generating architect-specific images, offering a practical and creative tool for architects. This study underscores the potential of integrating generative AI into architectural design through RDP, offering substantial support for creative work.},
  keywords={Visualization;Generative AI;Image synthesis;Buildings;Data visualization;Data processing;Diffusion models;Data models;Creativity;Testing;Generative AI;Image Generation;Architectural Visualization;Exterior Visualization;Fine-Tuning;Diffusion Model;Low Rank-Adaptation;Reinforced Data Processing},
  doi={10.1109/URTC65039.2024.10937567},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10541763,
  author={Kumar, Abhishek},
  booktitle={2023 5th International Conference on Advances in Computing, Communication Control and Networking (ICAC3N)}, 
  title={Extractive Text Summarization}, 
  year={2023},
  volume={},
  number={},
  pages={1037-1044},
  abstract={The fields of artificial intelligence (AI), machine learning (ML), and data science have grown significantly over the past ten years, opening up a wide range of opportunities in sectors as varied as healthcare, banking, and transportation. Notably, there have been substantial developments in the field of Natural Language Processing (NLP), which is a subfield of AI and ML. NLP involves the machine-based processing and understanding of human language. Among its various applications, text summarization holds prominence as it enables machines to condense lengthy texts into concise summaries. This project highlights the utilization of multiple extractive text summarization techniques, including Word Frequency, Lex, Luhn, Kl Summarizer, GPT-2 and BERT. The resultant extractive summaries are then evaluated against human-generated summaries using three distinct scoring methods: Rouge Score, BERT Score, and Mover Score. Through this project, we demonstrate the efficacy of these techniques in generating summaries and assess their quality by comparing them against summaries produced by humans using the specified scoring metrics.},
  keywords={Performance evaluation;Law;Computational modeling;Process control;Transportation;Bidirectional control;Transformers;Natural Language Processing;Artificial Intelligence;Mover Score;BERT Score;Word Rank;LEX;Luhn;KL-summarizer;GPT-2(Generative Pretrained Transformer);BERT (Bi-directional Encoder Representation from Transformers)},
  doi={10.1109/ICAC3N60023.2023.10541763},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10882556,
  author={Shenoy, Pavithra P.},
  booktitle={2024 13th International Conference on System Modeling & Advancement in Research Trends (SMART)}, 
  title={Large Language Model Virtual Assistants for International Business and Product Marketing}, 
  year={2024},
  volume={},
  number={},
  pages={556-564},
  abstract={In order for emergent and incumbent businesses to establish themselves on the global market, each company needs to navigate the rules, regulations, and policies native to the regions outside of their current area of operation. This is an understandably time-consuming process, and it can be challenging to understand the explicit and implicit compliances of each country for targeted product marketing. The recent development of Artificial Intelligence (AI), Natural Language Processing (NLP) and Large Language Models (LLMs) presents a unique opportunity to solve these challenges and expedite the process in which a company expands their foreign influence. The proposed solution is to retrain a Pre-trained LLM model on datasets which encompass a region's social and legal characteristics, such as its culture, politics, language differences, and ethical norms. Business professionals can leverage the proposed LLM concepts to provide answers for customer behavior and expectation related questions, which can allow them to gain a comprehensive overview of various barriers that need to be considered when introducing a new product in a foreign region or to gain ideas when developing products to meet regional needs. The efficiency of an organization is improved as a result, since the initial steps to launching the successful release of a product can be automated using machine learning processes, and administrative work can be reduced across many levels. During the search for existing work, the author did not find any research paper that constructed and evaluated a specialized LLM, to publicly available models, that supported the demands related to international business and product marketing. The advantages, challenges, and process of implementation for a fine-tuned LLM solution is explored, with the intended users being international business and market analysts as well as product designers.},
  keywords={Navigation;Large language models;Virtual assistants;Companies;Machine learning;Transformers;Market research;Natural language processing;Regulation;Business;International Business (IB);AI-enabled;Product Marketing;Large Language Model (LLM);Artificial Intelligence (AI);Machine Learning;Generative Pretrained Transformers (GPT);Machine Learning (ML)},
  doi={10.1109/SMART63812.2024.10882556},
  ISSN={2767-7362},
  month={Dec},}@ARTICLE{9079476,
  author={Cui, Fuwei and Cui, Qian and Song, Yongduan},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={A Survey on Learning-Based Approaches for Modeling and Classification of Human–Machine Dialog Systems}, 
  year={2021},
  volume={32},
  number={4},
  pages={1418-1432},
  abstract={With the rapid development from traditional machine learning (ML) to deep learning (DL) and reinforcement learning (RL), dialog system equipped with learning mechanism has become the most effective solution to address human–machine interaction problems. The purpose of this article is to provide a comprehensive survey on learning-based human–machine dialog systems with a focus on the various dialog models. More specifically, we first introduce the fundamental process of establishing a dialog model. Second, we examine the features and classifications of the system dialog model, expound some representative models, and also compare the advantages and disadvantages of different dialog models. Third, we comb the commonly used database and evaluation metrics of the dialog model. Furthermore, the evaluation metrics of these dialog models are analyzed in detail. Finally, we briefly analyze the existing issues and point out the potential future direction on the human–machine dialog systems.},
  keywords={Semantics;Analytical models;Data models;Speech recognition;Buildings;Machine learning algorithms;Biological neural networks;Artificial intelligence (AI);deep learning (DL);dialog model;machine learning (ML);reinforcement learning (RL);sequence to sequence (Seq2Seq) model},
  doi={10.1109/TNNLS.2020.2985588},
  ISSN={2162-2388},
  month={April},}@INPROCEEDINGS{9534286,
  author={Zhang, Yukun and Qiu, Shuang and Wei, Wei and Ma, Xuelin and He, Huiguang},
  booktitle={2021 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Filter Bank Adversarial Domain Adaptation For Motor Imagery Brain Computer Interface}, 
  year={2021},
  volume={},
  number={},
  pages={1-7},
  abstract={Motor imagery (MI) based Brain-computer interface (BCI) is a promising BCI paradigm that can help neuromuscular injury patients to recover or replace their motor abilities. However, electroencephalography (EEG) based MI-BCI suffers from its long calibration time and low classification accuracy, which restrict its application. Thus, it is important to reduce the calibration time of MI-BCI and enhance its prediction accuracy. In this study, we propose a filter bank Wasserstein adversarial domain adaptation framework (FBWADA) that uses a short amount of training data from a new target subject, and all collected data from an existing subject. A Convolutional Neural Networks (CNN) based feature extractor is designed to extract feature from EEG data. Filter bank strategy is employed to extract feature from multiple sub bands and integrate predictions from all sub bands. Wasserstein Generative Adversarial Networks (WGAN) based domain adaptation network aligns the marginal and conditional distribution of target and source. We evaluate our method on Data set 2a of BCI competition IV. Experiment results show that our method achieves the best performance among compared methods under different amount of training data. Performance of our method trained with certain blocks of data is similar to or better than the best comparing method trained with one more block. This indicates that our method could reduce the need for training data for at least one block.},
  keywords={Training;Training data;Filter banks;Feature extraction;Electroencephalography;Brain-computer interfaces;Calibration;brain-computer interface;motor imagery;transfer learning;domain adaptation;filter bank;calibration reduction},
  doi={10.1109/IJCNN52387.2021.9534286},
  ISSN={2161-4407},
  month={July},}@INBOOK{10952036,
  author={Vayadande, Kuldeep and Pednekar, Chaitanya B. and Khune, Priya Anup and Prabhavalkar, Vinay Sudhir and Dange, Varsha R.},
  booktitle={How Machine Learning is Innovating Today's World: A Concise Technical Guide}, 
  title={GPT&#x2010;3&#x2010; and DALL&#x2010;E&#x2010;Powered Applications}, 
  year={2024},
  volume={},
  number={},
  pages={329-341},
  abstract={Summary <p>In the new millennium, the advancement of language and image processing technologies has witnessed remarkable progress, and various applications have demonstrated promising results by utilizing sophisticated models such as GPT&#x2010;3 and DALL&#x2010;E. This survey paper presents an overview of the recent research and development in GPT&#x2010;3&#x2010; and DALL&#x2010;E&#x2010;powered applications. The paper first provides a brief introduction to GPT&#x2010;3 and DALL&#x2010;E and their capabilities in language and image processing by Artificial Intelligence. It then explores various applications of GPT&#x2010;3, such as natural language processing, chatbots, question&#x2010;answering systems, and text generation. The paper highlights the significant impact of GPT&#x2010;3 in these applications and discusses various challenges that need to be addressed in the future. Next, the paper focuses on DALL&#x2010;E and its applications in image generation, 3D rendering, and graphics design. The paper highlights how DALL&#x2010;E has revolutionized the field of computer vision and the impact it has made in the creative industry. The paper also discusses several hybrid models that incorporate both GPT&#x2010;3 and DALL&#x2010;E, such as those that generate text and images based on a given prompt. Additionally, the paper discusses ethical considerations related to these advanced models, such as potential biases and misuse of the technology. Finally, the paper concludes by summarizing the current state of research in GPT&#x2010;3&#x2010; and DALL&#x2010;E&#x2010;powered applications and highlighting future research directions. This survey paper serves as a valuable resource for researchers, developers, and practitioners interested in the latest advancements in language and image processing by Artificial Intelligence and Data Science.</p>},
  keywords={Computational modeling;Generative Pre-trainer transformer;Surveys;Chatbots;Industries;Ethics;Generators;Data models;Adaptation models;Transformers},
  doi={10.1002/9781394214167.ch19},
  ISSN={},
  publisher={Wiley},
  isbn={9781394214150},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952036},}@ARTICLE{9459771,
  author={Chen, Lang and Wang, Rangding and Yan, Diqun and Wang, Jie},
  journal={IEEE Access}, 
  title={Learning to Generate Steganographic Cover for Audio Steganography Using GAN}, 
  year={2021},
  volume={9},
  number={},
  pages={88098-88107},
  abstract={Audio steganography aims to exploit the human auditory redundancy to embed the secret message into cover audio, without raising suspicion when hearing it. However, recent studies have shown that the existing audio steganography can be easily exposed with the deep learning based steganalyzers by extracting high-dimensional features of stego audio for classification. The existing GAN-based steganography approaches mainly studied in images cover, less work is conducted on audio cover. In addition, though a few GAN-based audio steganography methods have been proposed, they still have room for improvements in perceptual quality and undetectability. In this work, we propose an audio steganography framework that could automatically learn to generate superior steganographic cover audio for message embedding. Specifically, the training framework of the proposed framework consists of three components, namely, generator, discriminator and trained deep learning based steganalyzer. Then the traditional message embedding algorithm LSBM, is employed to embed the secret message into the steganographic cover audio to obtain stego audio, which is delivered to the trained steganalyzer for misclassifying as cover audio. Once the adversarial training is completed among these three parties, one can obtain a well-trained generator, which could generate steganographic cover audio for subsequent message embedding. In the practice of our proposed method, the stego audio is produced by embedding the secret message into the steganographic cover audio using a traditional steganography method. Experimental results demonstrate that our proposed audio steganography can yield steganographic cover audio that preserves a quite high perception quality for message embedding. We have compared the detection accuracies with the existing audio steganography schemes as presented in our experiment, the proposed method exhibits lower detection accuracies against the state-of-the-art deep learning based steganalyzers, under various embedding rates. Codes are publicly available at https://github.com/Chenlang2018/Audio-Steganography-using-GAN.},
  keywords={Generators;Generative adversarial networks;Training;Deep learning;Distortion;Network architecture;Graphics;Audio steganography;deep learning based steganalysis;generative adversarial network (GAN)},
  doi={10.1109/ACCESS.2021.3090445},
  ISSN={2169-3536},
  month={},}@ARTICLE{10121444,
  author={Ravikumar, Aswathy and Sriraman, Harini},
  journal={IEEE Access}, 
  title={Computationally Efficient Neural Rendering for Generator Adversarial Networks Using a Multi-GPU Cluster in a Cloud Environment}, 
  year={2023},
  volume={11},
  number={},
  pages={45559-45571},
  abstract={Due to its fantastic performance in the quality of the images created, Generator Adversarial Networks have recently become a viable option for image reconstruction. The main problem with employing GAN is how expensive the computations are. Researchers have developed techniques for distributing GANs across multiple nodes. However, these techniques typically do not scale because they frequently separate the components (Discriminator and Generator), leading to high communication overhead or encountering distribution-related problems unique to GAN training. In this study, the training procedure for the GAN is parallelized and carried out over many Graphical Processing Units (GPUs). TensorFlow’s built-in logic and a custom loop were tweaked for more control over the resources allotted to each GPU worker. In this study, GPU image processing improvements and multi-GPU learning are used. The GAN model is accelerated using Distributed TensorFlow with synchronous data-parallel training on a single system and several GPUs. Acceleration was accomplished using the Genesis Cloud Platform and the NVIDIA Ⓡ GeForceTM GTX 108 GPU accelerator. The speed-up of 1.322 for two GPUs, 1.688 for three GPUs, and 1.7792 for four GPUs using multi-GPU acceleration. The parameter server model’s data initialization and image production bottlenecks are removed, but the results’ speed-up is not linear. Increasing the number of GPUs and removing the connectivity constraint will accelerate things even more. The bottlenecks are detected using new network lines and resources, and solutions are suggested. Recomputation and quantization are the two techniques to reduce the amount of GPU acceleration in memory. Deployment and versioning are essential for successfully operating multi-node GAN models in MLflow. Properly deploying and versioning these models can improve scalability, reproducibility, and collaboration across teams working on the same model. MLflow provides built-in tools for versioning and tracking model performance, making it easier to manage multiple versions of the model and reproduce it in different environments.},
  keywords={Training;Computational modeling;Generative adversarial networks;Graphics processing units;Data models;Load modeling;Servers;All reduce;bottleneck;data parallel;fault tolerance;generative adversarial network;GPU;parallel learning;cloud computing},
  doi={10.1109/ACCESS.2023.3274201},
  ISSN={2169-3536},
  month={},}@ARTICLE{10332183,
  author={Lakshmi, L. and Kalyani, A. Naga and Madhuri, D. Krishna and Potluri, Sirisha and Pandey, Geetika Silakari and Ali, Shahid and Khan, Muhammad Ijaz and Awwad, Fuad A. and Ismail, Emad A. A.},
  journal={IEEE Access}, 
  title={Performance Analysis of Cycle GAN in Photo to Portrait Transfiguration Using Deep Learning Optimizers}, 
  year={2023},
  volume={11},
  number={},
  pages={136541-136551},
  abstract={In the realm of computer vision, image transformations play a pivotal role across various domains such as healthcare, image enhancement, artist painting identification, genome sequencing, and more. While supervised learning demands a substantial volume of annotated images for training models, Cycle-GAN emerges as a potent solution for training models with fewer paired sources and target images in an unsupervised manner. This study introduces a novel system aimed at generating Monet-style paintings from realistic images, leveraging the Cycle-GAN methodology. Given the scarcity of Monet paintings, our system employs a combination of generator and discriminator neural networks to produce new Monet-style artworks. The model is trained using Cycle-GAN in conjunction with deep learning optimizers like RMSprop, ADAM, and SGD. The training dataset, Monet2Photo, comprises two distinct image categories: Monet paintings (300 samples) and natural photographs (7028 samples). The Monet-style images are utilized for training the model, while the raw photo images serve as the test set. Notably, the proposed model exhibits commendable performance, particularly when utilizing the SGD optimizer, as evidenced by favorable outcomes in terms of generator and discriminator losses.},
  keywords={Generators;Computer vision;Training;Generative adversarial networks;Deep learning;Computational modeling;Steganography;Cycle-GAN;generator;discriminator;object transfiguration;unsupervised learning;generative adversarial networks;optimizers},
  doi={10.1109/ACCESS.2023.3337430},
  ISSN={2169-3536},
  month={},}@ARTICLE{9146645,
  author={Yang, Nan and Xu, Yuanye and Zheng, Zeyu and Qi, Liang and Guo, Xiwang and Wang, Tianran},
  journal={IEEE Access}, 
  title={Generating and Editing Arbitrary Facial Images by Learning Feature Axis}, 
  year={2020},
  volume={8},
  number={},
  pages={135468-135478},
  abstract={There are mainly three limitations of the traditional facial attribute editing techniques: 1) incapability of generating an arbitrary facial image with high-resolution; 2) being unable to generate and edit new facial images synthesized by the computer and 3) limited diversity of edited images. This paper presents a method for generating and editing images simultaneously. It incorporates a high-resolution facial image generator, a multi-label classifier, and a Generalized Linear Model (GLM). Experimental results show that our method can generate arbitrary high-resolution facial images, edit computer-synthesized images, perform multi-attribute editing, and effectively control the intensity and style of the generated images. Besides, the approach has high efficiency and flexibility, allowing rapid migration of attribute information from the data set. We design a graphical interface program, which can be integrated as a mobile application.},
  keywords={Mathematical model;Gallium nitride;Computational modeling;Training;Generators;Decoding;Generative adversarial networks;Deep learning;generative adversarial networks;image generating;image editing},
  doi={10.1109/ACCESS.2020.3011424},
  ISSN={2169-3536},
  month={},}@ARTICLE{10504113,
  author={Heng, Yang and Yinghua, Ma and Khan, Fiaz Gul and Khan, Ahmad and Hui, Zeng},
  journal={IEEE Access}, 
  title={HLSNC-GAN: Medical Image Synthesis Using Hinge Loss and Switchable Normalization in CycleGAN}, 
  year={2024},
  volume={12},
  number={},
  pages={55448-55464},
  abstract={In the field of medical image analysis, MRI and CT, among other multimodal medical images, play crucial roles. To overcome the limitations of image acquisition, researchers have proposed medical image synthesis techniques, including both traditional methods and deep learning approaches. In this study, we introduce a universal framework based on cycleGAN for generating CT images from MRI data.This framework incorporates a hinge loss function to establish mappings between different modalities and enhance structural consistency between input and output images. We also employ a switchable normalization technique to improve model stability and reduce manual intervention. These enhancements result in the generation of higher-quality synthetic images while avoiding gradient issues and mode collapse.The results of this research demonstrate significant progress in medical image synthesis. Compared to existing methods, our model exhibits superior performance in quantitative evaluation metrics while maintaining better diversity and structural consistency. This indicates that our framework holds promise in medical image synthesis and can provide valuable support in areas such as disease prediction and treatment.},
  keywords={Biomedical imaging;Computed tomography;Magnetic resonance imaging;Generative adversarial networks;Image synthesis;Brain modeling;Image synthesis;CycleGAN;image translation;generative adversarial network;image synthetic;medical images},
  doi={10.1109/ACCESS.2024.3390245},
  ISSN={2169-3536},
  month={},}@ARTICLE{10109094,
  author={Lee, Hanbit and Lee, Sang-Goo and Park, Jaehui and Shim, Junho},
  journal={IEEE Access}, 
  title={Improving Complex Scene Generation by Enhancing Multi-Scale Representations of GAN Discriminators}, 
  year={2023},
  volume={11},
  number={},
  pages={43067-43079},
  abstract={While recent advances of GAN models enabled photo-realistic synthesis of various object images, challenges still remain in modeling more complex image distributions such as scenes with multiple objects. The difficulty lies in the high structural complexity of scene images, where the discriminator carries a heavy burden in discriminating complex structural differences between real and fake scene images. Therefore, enhancing the discriminative capability of the discriminator could be one of the effective strategies to improve the generation performance of GAN models. In this paper, we explore ways to boost the discriminative capability by leveraging two recent paradigms on visual representation learning: self-supervised learning and transfer learning. As the first approach, we propose a self-supervised auxiliary task tailored to enhance the multi-scale representations of the discriminator. In the second approach, we further enhance the discriminator by utilizing pretrained representations from various scene understanding models. To fully utilize knowledge from multiple expert models, we propose a multi-scale feature ensemble to mix multi-sale representations. Empirical results on challenging scene datasets demonstrate that the proposed strategies significantly advance the generation performance, enabling diverse and photo-realistic synthesis of complex scene images.},
  keywords={Image analysis;Generative adversarial networks;Transfer learning;Feature extraction;Self-supervised learning;Generators;Generative adversarial networks;scene generation;self-supervised learning;transfer learning},
  doi={10.1109/ACCESS.2023.3270561},
  ISSN={2169-3536},
  month={},}@ARTICLE{11119659,
  author={Zarif, Sameh and Najjar, Abdalfatah and Mohamed Amin, Khalid and Alharbi, Abdullah and Elkilani, Wail S. and Shawky, Mahmoud A. and Wagdy, Marian},
  journal={IEEE Access}, 
  title={Toward Enhancing LightWeight GAN for Text-Guided Generation of Animated Character Faces}, 
  year={2025},
  volume={13},
  number={},
  pages={139979-139991},
  abstract={Traditional text-guided image generation methods primarily focus on modifying existing images or altering specific elements, which limits their applicability. This paper introduces a significant enhancement to the LightWeight-GAN model, originally designed for image generation from random noise, by transforming it into a text-guided generative system. The proposed approach enables the generation of high-quality animated character faces directly from textual descriptions. To achieve this, we incorporate a mapping network that refines textual inputs before feeding them into the generator, ensuring more precise feature representation. Additionally, we integrate contrastive language-image pretraining (CLIP) to verify the generated images and enforce stronger alignment between textual prompts and visual outputs. The model is trained on a specialized facial dataset, demonstrating its ability to generate semantically accurate and visually compelling character faces. Extensive experiments using the CartoonSet dataset validate the effectiveness of our approach, achieving an FID score of 29.8 across 10 000 generated images. These improvements significantly outperform existing text-to-image generation models, making our system a promising tool for applications in game development, animation, and virtual reality.},
  keywords={Computational modeling;Generative adversarial networks;Computer architecture;Generators;Visualization;Text to image;Solid modeling;Image synthesis;Training;Semantics;Animated faces generation;LightWeight-GAN;text-guided image;text-to-image generation},
  doi={10.1109/ACCESS.2025.3595928},
  ISSN={2169-3536},
  month={},}@ARTICLE{11155072,
  author={Darmawan, Irfan and Rahmatulloh, Alam and Gunawan, Rohmat and Wahjoe Witjaksono, R. and Fauzi Nugraha, Ghatan},
  journal={IEEE Access}, 
  title={ViTRA: Vision Transformer With Relative Position Embedding Attention for Low-Light Image Quality Improvement}, 
  year={2025},
  volume={13},
  number={},
  pages={160588-160601},
  abstract={Image enhancement is a crucial task in computer vision that aims to improve the quality of images and enhance visual elements, making them more informative and aesthetically pleasing. Generative Adversarial Networks (GANs) have emerged as a powerful tool in the field, showing promise in enhancing and restoring image quality. Despite their potential, GAN-based methods often face challenges such as instability, high computational costs, and the risk of generating unwanted visual artifacts that degrade the final image quality. To address these issues, this study introduces a novel architecture called ViTRA, which combines the capabilities of the Vision Transformer (ViT) with a Relative Positional Encoding (RPE)-based attention mechanism. The ViTRA architecture is integrated into the HVI-CIDNet framework, specifically within the Light Cross-Attention Block (LCAB). By incorporating RPE, the architecture is enhanced, leading to the creation of a new attention mechanism known as the Relative Light Cross-Attention Block (RLCAB). This innovation allows for more effective feature extraction and attention distribution across the image, resulting in better image enhancement and fewer artifacts. Additionally, ViTRA implements automatic loss function weight optimization using Comprehensive Learning Particle Swarm Optimization (CLPSO) which is designed to improve stability and efficiency during model training. Experimental results demonstrate that the ViTRA architecture significantly improves image quality in both qualitative and quantitative terms when compared to traditional GAN and transformer-based approaches. On various benchmark datasets, including the LOLv2-Syn dataset, ViTRA outperforms existing models across all test metrics. Specifically, it achieves a Peak Signal-to-Noise Ratio (PSNR) of 25.716, a Structural Similarity Index (SSIM) of 0.946, and a Learned Perceptual Image Patch Similarity (LPIPS) of 0.0446, highlighting its superior performance in producing high-quality images. This work establishes ViTRA as a promising solution for enhancing image quality, overcoming common limitations in GAN and transformer-based models, and providing a robust approach for future image enhancement applications.},
  keywords={Transformers;Training;Image enhancement;Image quality;Generative adversarial networks;Image coding;Computer architecture;Table lookup;Noise;Computational modeling;Attention module;HVI-CIDNet;image enhancement;relative positional encoding;transformer},
  doi={10.1109/ACCESS.2025.3608457},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11166477,
  author={Schickmair, Verena and Rudisch-Sommer, Rimbert and Stöckl, Andreas},
  booktitle={2025 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)}, 
  title={From Words to Conversions: Leveraging Large Language Models for Dynamic Landing Page Generation}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={In modern business, the demand for effective online marketing is undeniable. Nevertheless, creating landing pages for marketing campaigns poses a fundamental question: Should the implementation be the domain of a web developer or a marketing specialist? The interdisciplinary nature of this task, requiring a fusion of coding and marketing skills, underscores a significant gap in current research. Addressing this gap, this paper introduces a specialized AI landing page generator that operates through natural language input, eliminating the need for coding expertise. This empowers individuals without coding knowledge or marketing expertise to create impactful landing pages independently.Usability tests were conducted to evaluate the system, followed by interviews with marketing and web development professionals. The results demonstrated that business specialists perceived the quality of AI-generated content positively. The AI provided a basic structure and introduced new ideas, while human refinement is needed to ensure the uniqueness of the content. In addition, the technical audits revealed high performance, accessibility, and search engine optimization of the landing pages generated. Furthermore, comparisons between GPT-3.5 and GPT-4 revealed that GPT-4 generally produced better quality content and was preferred by the participants for its creativity and code quality. These findings highlight the potential of AI-driven tools to streamline the creation of landing pages, enhancing efficiency in digital marketing and web development.},
  keywords={Knowledge engineering;Generative AI;Large language models;Natural languages;Search engines;Encoding;Generators;Interviews;Optimization;Business;landing pages;online marketing;language models},
  doi={10.1109/ACDSA65407.2025.11166477},
  ISSN={},
  month={Aug},}@ARTICLE{10379639,
  author={Yan, Peng and Abdulkadir, Ahmed and Luley, Paul-Philipp and Rosenthal, Matthias and Schatte, Gerrit A. and Grewe, Benjamin F. and Stadelmann, Thilo},
  journal={IEEE Access}, 
  title={A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series: Methods, Applications, and Directions}, 
  year={2024},
  volume={12},
  number={},
  pages={3768-3789},
  abstract={Automating the monitoring of industrial processes has the potential to enhance efficiency and optimize quality by promptly detecting abnormal events and thus facilitating timely interventions. Deep learning, with its capacity to discern non-trivial patterns within large datasets, plays a pivotal role in this process. Standard deep learning methods are suitable to solve a specific task given a specific type of data. During training, deep learning demands large volumes of labeled data. However, due to the dynamic nature of the industrial processes and environment, it is impractical to acquire large-scale labeled data for standard deep learning training for every slightly different case anew. Deep transfer learning offers a solution to this problem. By leveraging knowledge from related tasks and accounting for variations in data distributions, the transfer learning framework solves new tasks with little or even no additional labeled data. The approach bypasses the need to retrain a model from scratch for every new setup and dramatically reduces the labeled data requirement. This survey first provides an in-depth review of deep transfer learning, examining the problem settings of transfer learning and classifying the prevailing deep transfer learning methods. Moreover, we delve into applications of deep transfer learning in the context of a broad spectrum of time series anomaly detection tasks prevalent in primary industrial domains, e.g., manufacturing process monitoring, predictive maintenance, energy management, and infrastructure facility monitoring. We discuss the challenges and limitations of deep transfer learning in industrial contexts and conclude the survey with practical directions and actionable suggestions to address the need to leverage diverse time series data for anomaly detection in an increasingly dynamic production environment.},
  keywords={Transfer learning;Task analysis;Time series analysis;Production;Anomaly detection;Data models;Surveys;Deep learning;Process monitoring;Predictive maintenance;Deep transfer learning;time series analysis;anomaly detection;manufacturing process monitoring;predictive maintenance},
  doi={10.1109/ACCESS.2023.3349132},
  ISSN={2169-3536},
  month={},}@ARTICLE{10584534,
  author={Malik, Jasmita and Muthalagu, Raja and Pawar, Pranav M.},
  journal={IEEE Access}, 
  title={A Systematic Review of Adversarial Machine Learning Attacks, Defensive Controls, and Technologies}, 
  year={2024},
  volume={12},
  number={},
  pages={99382-99421},
  abstract={Adversarial machine learning (AML) attacks have become a major concern for organizations in recent years, as AI has become the industry’s focal point and GenAI applications have grown in popularity around the world. Organizations are eager to invest in GenAI applications and develop their own large language models, but they face numerous security and data privacy issues, particularly AML attacks. AML attacks have jeopardized numerous large-scale machine learning models. If carried out successfully, AML attacks can significantly reduce the efficiency and precision of machine learning models. They have far-reaching negative consequences in the context of critical healthcare and autonomous transportation systems. In this paper, AML attacks are identified, analyzed, and classified using adversarial tactics and techniques. This research also recommends open-source tools for testing AI and ML models against AML attacks. Furthermore, this research suggests specific mitigating measures against each attack. It aims to serve as a guidance for organizations to defend against AML attacks and gain assurance in the security of ML models.},
  keywords={Artificial intelligence;Security;Organizations;Testing;Reviews;Data models;Computational modeling;Adversarial machine learning;Data privacy;Software development management;Life cycle assessment;Adversarial machine learning;AI assurance;cybersecurity;data privacy;secure software development lifecycle},
  doi={10.1109/ACCESS.2024.3423323},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10075660,
  author={Jaleel, Qasim and Ali, Israa Hadi},
  booktitle={2022 International Conference on Data Science and Intelligent Computing (ICDSIC)}, 
  title={Facial Behavior Analysis-Based Deepfake Video Detection using GAN Discriminator}, 
  year={2022},
  volume={},
  number={},
  pages={36-40},
  abstract={Deepfake is an artificial intelligence-based method for making fake images of people. It works by putting the existing (source) images or videos on the final (destination) images or videos. But recent improvements in deep learning have made it much easier to make fake videos that look real and are convincing with a relatively small amount of data and computing power. As a result of the development of deep learning techniques such as Generative adversarial networks (GAN), Deepfake has become closer to the truth. Many researchers are based on discovering deep fakes that were created by traditional methods. Traditional methods of detection that look for artifacts and pixels that don't match up can't keep up. This paper can detect deepfakes that are perfectly created. It is detected by modifying the GAN algorithm and inverting its function. The discriminator model of a GAN network is used to analyze behavior, facial gestures, and the appearance of an object. The paper is divided into two stages. The first stage is to use a GAN discriminator that has been modified. It is then trained using a deepfake dataset. The second stage is to test the videos by extracting the faces. Next, run it through the GAN discriminator to see if it's a forgery. In comparison to other networks, the GAN discriminator has demonstrated its ability and accuracy in detecting fake videos. The network's accuracy in detecting and distinguishing between real and fake videos is %94.65.},
  keywords={Deep learning;Training;Deepfakes;Analytical models;Image resolution;Network architecture;Generative adversarial networks;GAN;GAN discriminator;Media Forensics;DeepFake Detection;Face Detection},
  doi={10.1109/ICDSIC56987.2022.10075660},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10013052,
  author={Wang, Ziqi and Yang, Chao and Mao, Shiwen},
  booktitle={2022 IEEE 96th Vehicular Technology Conference (VTC2022-Fall)}, 
  title={Data Augmentation for RFID-based 3D Human Pose Tracking}, 
  year={2022},
  volume={},
  number={},
  pages={1-2},
  abstract={Interest in Radio Frequency (RF) based 3D human pose tracking has skyrocketed in the age of Artificial Intelligence of Things (AIoT). Compared to Computer Vision (CV) based methods, RF-based approaches are more resilient to lighting and non-line-of-sight conditions, and can better preserve user privacy. However, the majority of the current RF-based methods rely on a vision-aided multi-modal learning approach. An extensive amount of paired training data, i.e., Radio-Frequency Identification (RFID) data and vision data, must be collected, to achieve an adequate performance with the supervised-learning network. In order to mitigate such time-consuming and costly tasks, we propose a data augmentation method based on Generative Adversarial Network (GAN), named RFPose-GAN, to generate synthesized RFID data to alleviate the complications of using commodity RFID tags and receivers. In this paper, a forward kinematic layer is incorporated to generate simulated vision pose data, thus eliminating the need of using a Kinect 2.0 device in RFPose-GAN. Experiments conducted demonstrate that the synthesized data achieves accurate pose estimation performance.},
  keywords={Radio frequency;Vehicular and wireless technologies;Three-dimensional displays;Training data;Receivers;Generative adversarial networks;Internet of Things},
  doi={10.1109/VTC2022-Fall57202.2022.10013052},
  ISSN={2577-2465},
  month={Sep.},}@ARTICLE{9978614,
  author={Chang, Hyung-Pil and Yoo, In-Chul and Jeong, Changhyeon and Yook, Dongsuk},
  journal={IEEE Access}, 
  title={Zero-Shot Unseen Speaker Anonymization via Voice Conversion}, 
  year={2022},
  volume={10},
  number={},
  pages={130190-130199},
  abstract={Speech-based interfaces provide convenient methods for controlling various smart devices. For these interfaces to work reliably, considerable speech data with various noise and speaker characteristics must be collected to train the associated speech-processing models. Gathering spoken commands from actual users of devices can improve those devices’ performance by familiarizing each device with the individual acoustic characteristic of its particular user’s speech. However, the direct acquisition of spoken commands could threaten the privacy of users, as the spoken data would contain sensitive speaker-specific information. Speaker anonymization algorithms can be applied to suppress such sensitive information, while preserving the linguistic content of a user’s speech. Previous speaker anonymization algorithms could handle only the voice of speakers who contributed to the training datasets. As speaker anonymization algorithms are typically applied to new speakers (who are absent from the training datasets), a method of handling such speakers (commonly referred to as “unseen speakers”) should be developed. In this paper, we propose a novel method that can effectively suppress the individual characteristics in an unseen speaker’s voice, while retaining the linguistic content of the speech. It adopts zero-shot voice conversion methods for the unseen speaker anonymization. Since the proposed method utilizes speaker identity vectors commonly used in many-to-many voice conversion algorithms and does not modify the conversion algorithm itself, it can be easily combined with many other voice conversion algorithms. The proposed method is evaluated using the VCC2018 and VCTK corpora. Speaker identification rate and speech recognition rate are used for quantitative analysis. The experimental results showed that the average speaker identification accuracy was decreased by 92.3% point absolutely and the average speech recognition accuracy was decreased by 17.7% point absolutely after the speaker anonymization by the proposed method.},
  keywords={Data privacy;Information integrity;Information filtering;Speech recognition;Encoding;Linguistics;Training data;Data privacy;speaker anonymization;unseen speakers;variational autoencoder;voice conversion;zero-shot learning},
  doi={10.1109/ACCESS.2022.3227963},
  ISSN={2169-3536},
  month={},}@ARTICLE{9973296,
  author={Huang, Wenli and Deng, Ye and Hui, Siqi and Wang, Jinjun},
  journal={IEEE Access}, 
  title={Multi-Reception and Multi-Gradient Discriminator for Image Inpainting}, 
  year={2022},
  volume={10},
  number={},
  pages={131579-131591},
  abstract={Many deep learning methods for image inpainting rely on the encoder-decoder architecture to estimate missing contents. When guidance information from uncorrupted regions cannot be adequately represented or utilized, the encoder may have difficulty handling the rich surrounding or background pixels, and the decoder could not recover visually sophisticated or realistic content. This paper proposes an effective multi-scale optimization network to alleviate these issues and generate coherent results with fine details. It adaptively encodes multi-receptive fields feature maps and puts multi-scale outputs into a discriminator to guide training. Specifically, we propose a Multi-Receptive feature maps & masks Selective Fusion (MRSF) operator that can adaptively extract features in different receptive fields to handle sophisticated destroyed images. Then a multi-gradient discriminator (MGD) module uses the intermediate features of the discriminator to guide the generator to produce results with natural textures and semantically real contents. Experiments on several benchmark datasets demonstrate that the proposed method can synthesize more realistic and coherent image content.},
  keywords={Feature extraction;Generators;Task analysis;Semantics;Image restoration;Image reconstruction;Image inpainting;multi-receptive feature maps and masks selective fusion;multi-gradient discriminator},
  doi={10.1109/ACCESS.2022.3227387},
  ISSN={2169-3536},
  month={},}@ARTICLE{11015790,
  author={Gu, Xiang and Li, Chao and Yang, Jie and Wang, Jing and Huang, Qiwei},
  journal={IEEE Access}, 
  title={Pedestrian Trajectory Prediction via Window Attention and Spatial Graph Interaction Network}, 
  year={2025},
  volume={13},
  number={},
  pages={100031-100041},
  abstract={The accuracy of pedestrian trajectory prediction is crucial for the safety of autonomous driving systems. However, the task still faces challenges in modeling long-term dependencies, complex spatial interactions, and multi-scale feature fusion. To address these issues, this paper proposes the WAGIN (Windowed Attention Graph Interaction Network) model. First, in the temporal dimension, a window mask mechanism is designed to adjust the attention receptive field at each time step, effectively capturing temporal dependencies. In the spatial dimension, a hierarchical heterogeneous GCN (graph convolutional network) is constructed, combining pedestrian dynamic interaction graphs and scene semantic static graphs. Additionally, an interaction kernel function based on motion consistency is proposed to model the interactions between individual pedestrians. Finally, a multi-scale dilated convolution network is employed for future trajectory generation, capturing multi-scale spatiotemporal features through dilated convolutions to enhance prediction accuracy and robustness. The model is experimentally validated on the public ETH/UCY dataset, and the results demonstrate its effectiveness, achieving improvements of 23% in average displacement error (ADE) and 21% in final displacement error (FDE) over baseline methods. Moreover, qualitative analysis reveals the model’s excellent generalization ability in handling different scenarios.},
  keywords={Pedestrians;Trajectory;Computational modeling;Predictive models;Transformers;Feature extraction;Accuracy;Spatiotemporal phenomena;Convolution;Attention mechanisms;Pedestrian trajectory prediction;autonomous driving;window attention;spatiotemporal feature learning;spatial interaction;multi-scale dilated convolution},
  doi={10.1109/ACCESS.2025.3573782},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10072084,
  author={Shelake, Swapnil and Kondavathini, Rishikesh and Ansari, Mahedin and Sonwadekar, Punit and Kumar, Sunny and Goswami, Prerna and Kazi, Faruk},
  booktitle={2022 IEEE PES 14th Asia-Pacific Power and Energy Engineering Conference (APPEEC)}, 
  title={Forecasting enhancement of Wind Power Generation using Adversarial Networks: A Data Driven Approach}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Wind energy is major contributor in the power system. However, the unpredictability of wind energy will have a substantial impact on the electrical grid, mostly because of the variable wind speed. Wind energy's consistency and dependability may cause instability, however the issue can be solved by scheduling generation and load. For that economical load dispatch planning is carried out by load dispatch centers. Wind power forecasts can be highly helpful for dispatch planning as well as selling and bidding in the energy market. Prediction can be done using different techniques like Numerical Weather Prediction (NWP), Artificial Intelligence and Machine Learning, time series analysis etc. Prediction using machine learning is incredibly accurate and quick compared to other techniques, particularly when employing Generative Adversarial Network. It is inspired by two-player zero-sum, where the Generator and Discriminator compete against each other. Gated recurrent Unit (GRU) based adversarial networks have fewer errors as compared to others.},
  keywords={Wind energy;Wind speed;Machine learning;Wind power generation;Predictive models;Generative adversarial networks;Generators;Deep learning;GAN;GRU;LSTM;Wind power prediction},
  doi={10.1109/APPEEC53445.2022.10072084},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9644369,
  author={Cho, Yin-Ping and Yang, Fu-Rong and Chang, Yung-Chuan and Cheng, Ching-Ting and Wang, Xiao-Han and Liu, Yi-Wen},
  booktitle={2021 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)}, 
  title={A Survey on Recent Deep Learning-driven Singing Voice Synthesis Systems}, 
  year={2021},
  volume={},
  number={},
  pages={319-323},
  abstract={Singing voice synthesis (SVS) is a task that aims to generate audio signals according to musical scores and lyrics. With its multifaceted nature concerning music and language, producing singing voices indistinguishable from that of human singers has always remained an unfulfilled pursuit. Nonetheless, the advancements of deep learning techniques have brought about a substantial leap in the quality and naturalness of synthesized singing voice. This paper aims to review some of the state-of-the-art deep learning-driven SVS systems. We intend to summarize their deployed model architectures and identify the strengths and limitations for each of the introduced systems. Thereby, we picture the recent advancement trajectory of this field and conclude the challenges left to be resolved both in commercial applications and academic research.},
  keywords={Deep learning;Solid modeling;Conferences;Music;Virtual reality;Benchmark testing;Trajectory;sining voice synthesis;deep learning;review paper},
  doi={10.1109/AIVR52153.2021.00067},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10575875,
  author={Prasanna, Kancharla Lakshmi and Rao, Yamarthi Narasimha},
  booktitle={2024 3rd International Conference on Applied Artificial Intelligence and Computing (ICAAIC)}, 
  title={Context-Aware Approaches in IoT-based Healthcare Systems using Deep Learning Techniques: A Study}, 
  year={2024},
  volume={},
  number={},
  pages={567-570},
  abstract={Health-related technologies are starting to make use of context awareness, a pervasive computing field that has begun to impact healthcare infrastructure. People and healthcare professionals are taking steps to use the Context-Aware Healthcare System (CAHS). The continued popularity of these smart healthcare applications have been greatly attributed to contexts, including user place of residence, time, patient demographics, and past medical records. Furthermore, the contextual needs vary throughout applications. The goal of this research study is to properly comprehend the required context-aware methodologies to develop various healthcare applications by utilizing the data from these preliminary implementations. The experts will also be able to use these outcomes to guarantee that the healthcare systems have contexts that were helpful in the initial implementations. This will help experts to get a better knowledge of the critical contexts employed within distinct subdivisions of context-aware systems for healthcare. This stuy has reviewed IoT-enabled medical care systems using context awareness. This study has also analyzed the examples where patients or healthcare practitioners employed context-aware technologies.},
  keywords={Deep learning;Reviews;Medical services;Context awareness;Ubiquitous computing;Software;History;Sensors;Health care;Health Monitoring},
  doi={10.1109/ICAAIC60222.2024.10575875},
  ISSN={},
  month={June},}@INPROCEEDINGS{9515076,
  author={Frăţilă, Ruxandra and Morogan, Luciana},
  booktitle={2021 13th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)}, 
  title={Enhanced models in deep image steganography}, 
  year={2021},
  volume={},
  number={},
  pages={1-4},
  abstract={Seeking to take advantage of the innovations brought by machine learning, a field in a continuous movement and development, the present paper aims to enhance a practice that has been used since ancient times: steganography. Thereby, we targeted the implementation of a system aimed to hide image-type messages with the aid of deep neural networks. We followed a baseline model designed according to the recommendations stated into the state-of-the-art section. Then, we progressively developed three new models, each adding a new improvement on top of the previous one.},
  keywords={Training;Measurement;Deep learning;Technological innovation;Image color analysis;Lead;Gray-scale;Machine Learning;Steganography;Steganalysis;Multimedia},
  doi={10.1109/ECAI52376.2021.9515076},
  ISSN={},
  month={July},}@INPROCEEDINGS{9543229,
  author={Liu, Jingshuo and Zhang, Shu and Ma, Xinrui and Feng, Maoxuan},
  booktitle={2021 IEEE International Conference on Computer Science, Artificial Intelligence and Electronic Engineering (CSAIEE)}, 
  title={CycleGAN -based Cloud2painting Translation}, 
  year={2021},
  volume={},
  number={},
  pages={5-8},
  abstract={Image2image translation is one of the most popular image processing tasks. In this work, we use the powerful CycleGAN model and some traditional image processing technology to transform images of cloud into sketch portraits of specific objects. Precisely, this work extract the outer contour of the cloud and use the trained CycleGAN model to transform the outer contour into a specific image (taking the sketch of fish as an example) and the output of the model shows its good translation effect. Moreover, this work set the images of cloud without contour extraction as the control group, which proves the necessity of our preprocessing technology.},
  keywords={Training;Computer science;Image processing;Conferences;Transforms;Fish;Task analysis;Image2Image translation;CycleGAN;external contour extraction;morphological operation},
  doi={10.1109/CSAIEE54046.2021.9543229},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10165218,
  author={Gao, Dequan and Wang, Yang and Zhao, Ziyan and Feng, Bao and Li, Yutai},
  booktitle={2023 IEEE 3rd International Conference on Information Technology, Big Data and Artificial Intelligence (ICIBA)}, 
  title={Prediction Model of Bursty Network Traffic for Cloud Data Center Based on GAN-TrellisNet}, 
  year={2023},
  volume={3},
  number={},
  pages={1697-1701},
  abstract={Aiming at the nonlinearity and burstiness of network traffic in large cloud data centers, this paper proposes a GAN-TrellisNet model to improve the accuracy of traffic prediction. Firstly, the model uses a multi-layer TrellisNet construction generator to obtain the long-term and local features of traffic data and generate traffic prediction values. Then, the discriminator selects a convolutional neural network (CNN) with strong feature extraction ability to distinguish the difference between the predicted value and the real value. The experiment shows that compared with the XGBoost, LSTM and TCN models, the proposed model is optimal in RMSE, MAE and R2 performance indicators, and has better prediction effects.},
  keywords={Data centers;Telecommunication traffic;Predictive models;Big Data;Feature extraction;Data models;Generators;cloud data center;network traffic prediction;bursty traffic;GAN-TrellisNet;CNN},
  doi={10.1109/ICIBA56860.2023.10165218},
  ISSN={},
  month={May},}@INPROCEEDINGS{9619262,
  author={Wang, Yipeng and Wang, Wei and Li, Shuangshuang},
  booktitle={2021 3rd International Conference on Industrial Artificial Intelligence (IAI)}, 
  title={Application of data generation model in aquaculture water quality monitoring}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={In order to solve the problem of insufficient data in the process of constructing concentration monitoring model of ammonia nitrogen in intensive aquaculture, a new improved data generation model of TableGAN is proposed based on the model optimization algorithm. The method generates synthetic data with the same distribution characteristics as the original data by confrontation training, and makes the generated data more effective in the optimization model by adding classifiers and optimization functions. The field data of a breeding enterprise show that the accuracy of the ammonia nitrogen concentration soft sensing model trained by the synthetic data set is better than that of the model trained by the original data set in terms of root mean square error and maximum absolute error, and the test effect of the model is also improved significantly.},
  keywords={Training;Ammonia;Uncertainty;Soft sensors;Water quality;Data models;Nitrogen;Synthesis data;TableGAN;generation model;ammonia nitrogen monitoring;model optimization},
  doi={10.1109/IAI53119.2021.9619262},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10104404,
  author={Chen, Zhe and Guo, Xiaoyan and Liu, Jianheng and Yu, Pengyuan},
  booktitle={CAIBDA 2022; 2nd International Conference on Artificial Intelligence, Big Data and Algorithms}, 
  title={Skin Cancer Data Augementation Method Based on Color Transfer}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={There are eight common types of skin cancer. Using deep learning is a popular way of helping users to classify whether their lesion is benign or malignant. If they could observe their disease as soon as possible, it can improve patients’ survival chances. However, the datasets for the medical field have joint problems. That is, the size of the datasets is rare. The popular skin cancer dataset that we use frequently has few apparent issues. The amount of the different types is gigantic, and the total amount of the images is not rare. Also, most of the image data are collected from white skin tone patients. Our work put forward a new model that could improve these situations. The most significant contribution of our work is that it let the data not only focus on one type of color skin tone but is able to generate around 42 different skin tones.},
  keywords={},
  doi={},
  ISSN={},
  month={June},}@INPROCEEDINGS{9696088,
  author={Hong, Liang and Wang, Tianqi},
  booktitle={2021 2nd International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE)}, 
  title={COVID-19 Face Mask Restoration Using Pix2pix model}, 
  year={2021},
  volume={},
  number={},
  pages={157-161},
  abstract={Accurate facial recognition can effectively help the population combat the disease by offering risk-free phone usage, access controls, etc. In the era of COVID-19, a mask has become a necessity. However, masks may reduce the accuracy of face recognition to some degree. Thus, it is necessary to use deep learning to increase face recognition accuracy by recovering the face with a mask. For this purpose, this study proposed an AIbased model based on Pix2pix and U-net generator for restoring face mask images using the paired image database. In the training step, we used two adversarial models, including one generator and one discriminator. Then they are extended to a conditional model, which will be piped to the Pix2pix algorithm once again. U-Net was built in the training of the generator. The loss curves of generator and discriminators show that as iteration time increases, the loss of fake discriminator becomes lower stably. In contrast, the loss of real discriminator has the same tendency. In the meantime, the loss of generator shows an increased tendency. The result indicates that our model can help build reliable face mask restoration for daily use, which helps to improve the recognition accuracy of the face with a mask.},
  keywords={COVID-19;Training;Image databases;Face recognition;Sociology;Generators;Image restoration;COVID-19;U-net Generator;Pix2pix;Face mask restoration;Image restoration},
  doi={10.1109/ICBASE53849.2021.00037},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10692373,
  author={Su, Naiquan and Chen, Yidian and Liu, Yang and Zhang, Qinghua and Zhou, Lingmeng and He, Yu and Chang, Xiaoxiao},
  booktitle={2024 6th International Conference on Internet of Things, Automation and Artificial Intelligence (IoTAAI)}, 
  title={Fault Diagnosis of Rotating Machinery under Variable Operating Conditions Based on Multi-Feature and Transfer Learning}, 
  year={2024},
  volume={},
  number={},
  pages={190-194},
  abstract={The reliability of rolling bearings is one of the crucial guarantees for the continuity and safety of industrial production. However, due to the high temperature, high pressure, and long duration characteristics of their operating environment, the vibration signals often exhibit certain non-stationarity and non-linearity. Additionally, the lack of fault samples makes it challenging to apply data-driven diagnostic methods. This paper proposes a fault diagnosis method for rotating machinery under variable operating conditions based on multi-feature and transfer learning. Firstly, dimensionless features of bearing vibrations are extracted to address the non-linearity of bearing information. To tackle the issue of missing fault samples, an improved convolutional neural network transfer model is proposed to transfer large-scale data models to small-sample models. Validation on the bearing experiment platform of Case Western Reserve University shows that the proposed method achieves an average diagnostic accuracy of 95.9%, providing a theoretical basis for the fault diagnosis of rolling bearings.},
  keywords={Fault diagnosis;Vibrations;Training;Accuracy;Transfer learning;Rolling bearings;Feature extraction;Data models;Convolutional neural networks;Machinery;Rotating Machinery;Dimensionless Features;Transfer Learning;Fault Diagnosis},
  doi={10.1109/IoTAAI62601.2024.10692373},
  ISSN={},
  month={July},}@ARTICLE{10994417,
  author={Neha Margret, Issac and Rajakumar, K.},
  journal={IEEE Access}, 
  title={Adaptive Elastic GAN for High-Fidelity Blood Cell Image Hallucination and Classification}, 
  year={2025},
  volume={13},
  number={},
  pages={84897-84910},
  abstract={Automated blood cell classification is crucial for hematological analysis, yet the scarcity of annotated medical datasets challenges deep learning models. This study presents a novel semi-supervised Elastic Generative Adversarial Network that enhances classification accuracy, improves synthetic image generation quality, and reduces computational complexity. The model utilizes image hallucination, which generates artificial but realistic images to supplement datasets, addressing data imbalance and improving model generalization. The generated images exhibit high fidelity, meaning they closely resemble real blood cell images in texture, morphology, and structural details, ensuring their effectiveness in training deep learning models. Compared to the conventional semi-supervised Wasserstein Generative Adversarial Network, the proposed model achieves a 5.5% increase in classification accuracy, a 34.5% reduction in computational complexity, and a 21.0% decrease in training time, demonstrating superior efficiency and scalability. In addition, it greatly enhances Fréchet Inception Distance and Wasserstein distance, which verifies improved realism and diversity of synthetic samples. Complementing pruning-based optimization ensures reduced model deployment size, rendering it appropriate for real-time medical diagnosis. Through image hallucination, the proposed method sufficiently alleviates data deficiency and improves the reliability of automated blood cell classification, qualifying it as a prospective tool for advanced hematological studies and diagnosis purposes.},
  keywords={Blood;Generative adversarial networks;Training;Computer architecture;Computational modeling;Microprocessors;Image synthesis;Accuracy;Morphology;Microscopy;Blood cell classification;generative adversarial network (GAN);image hallucination;medical image processing;peripheral blood smear cells;semi-supervised Wasserstein GAN (SS-WGAN);semi-supervised elastic WGAN (SS-EGAN)},
  doi={10.1109/ACCESS.2025.3568539},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10992532,
  author={Yang, Xixuan and Jia, Tong and Li, Ying and Huang, Gang},
  booktitle={2025 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)}, 
  title={IFKG: An Intelligent Fault Diagnosis Tool with Knowledge Graph and Generative LLM}, 
  year={2025},
  volume={},
  number={},
  pages={839-843},
  abstract={The development of effective diagnostic methodolo-gies for software system failures is of paramount importance. Traditional methods, which rely on specialized terminology and intricate reasoning, require users to have a technical background, resulting in reduced flexibility and decreased user-friendliness. With the rise of generative large language models, optimizing human-computer interaction has become a critical area of focus. Additionally, the inherent intelligence and extensive knowledge of large language models make them both easy and effective to employ for fault diagnosis assistance. We introduce IFKG, an advanced tool for diagnosing software system failures. IFKG integrates generative large language models with knowledge graphs, employing natural language interactions to implement fault detection and deliver solutions. IFKG enables users to upload descriptive problems, retrieve pertinent information from the knowledge graph, and present diagnostic results in natural language. Our accuracy assessments across diverse software system failures indicate that the IFKG provides targeted and actionable recommendations, effectively assisting users in ad-dressing a range of software system issues. The tool is available on GitHub at https://github.com/mako-xxlIFKG, and the demo video can be found on YouTube: https://youtu.belDie2vgZm2hk.},
  keywords={Fault diagnosis;Human computer interaction;Video on demand;Terminology;Large language models;Natural languages;Knowledge graphs;Software systems;Web sites;Software development management;LLM;knowledge graph;software fault diagnosis},
  doi={10.1109/SANER64311.2025.00088},
  ISSN={2640-7574},
  month={March},}@INPROCEEDINGS{10864028,
  author={Zhao, Yuhui and Liu, Zhaoqi and Guo, Ruixin and Li, Wenlong},
  booktitle={2024 5th International Conference on Artificial Intelligence and Computer Engineering (ICAICE)}, 
  title={Exploration of Innovative Imputation Techniques for Missing Data in Multivariate Time Series}, 
  year={2024},
  volume={},
  number={},
  pages={605-609},
  abstract={Currently, when conducting research in the area of time series, the problem of missing data is often encountered, which brings trouble to our research work. In this paper, we propose a Joint Attention Imputation(JAI) model based on the self-attention mechanism, aiming to improve the accuracy of data imputation. JAI learns the feature values through the joint optimization training method of interpolation and reconstruction. On the other hand, through the two-layered attention mechanism, the temporal dependence and feature correlation between steps and the cross-latitude dependence can be explicitly captured. Dependence and feature correlation between steps and cross-latitude dependence. Experiments show that JAI significantly outperforms existing mainstream models in performing data imputation, demonstrating its powerful imputation capability and application potential.},
  keywords={Training;Interpolation;Correlation;Computational modeling;Time series analysis;Predictive models;Imputation;Data models;Root mean square;Optimization;Joint optimization training;Attention;Imputation;Time series},
  doi={10.1109/ICAICE63571.2024.10864028},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11035065,
  author={Ren, Yinan and Di, Ruohai and Wang, Peng and Li, Xiaoyan and Li, Liangliang and Li, Jianheng and Zhang, Huan and Zhang, Xinlan},
  booktitle={2025 IEEE 6th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={Creep Data Generation Method Based on Physically Constrained Variational Self-encoder}, 
  year={2025},
  volume={},
  number={},
  pages={1491-1495},
  abstract={Polyurethane is a commonly used material in the industrial field, which is prone to creep under the action of such mixed stresses as high temperature and high pressure. Thus affecting the stable operation of the equipment and obtaining reliable data to study its creep process has become an important challenge in this field. To address this problem, a combination of material physical characteristics of the condition of the variational self-encoder virtual sample generation method was proposed in this paper. Firstly, the necessary features to increase the diversity of features of the input samples were extracted according to the creep characteristic curve from the original data. Secondly, the loss function in the network was constructed through the physical information. Finally, the encoder was used to generate a specific condition of the creep curve. The experimental validation proved that the creep data under specific conditions are more accurate, which can provide a certain reference for models that need to be trained by a large number of different conditions of creep data.},
  keywords={Seminars;Temperature distribution;Accuracy;Creep;Feature extraction;Data models;Eigenvalues and eigenfunctions;Reliability;Information technology;Stress;Creep;Polyurethane;Variational selfcoder;Physical information;Coupled stresses},
  doi={10.1109/AINIT65432.2025.11035065},
  ISSN={},
  month={April},}@INBOOK{9562706,
  author={Reznik, Leon},
  booktitle={Intelligent Security Systems: How Artificial Intelligence, Machine Learning and Data Science Work For and Against Computer Security}, 
  title={Adversarial Machine Learning}, 
  year={2022},
  volume={},
  number={},
  pages={315-335},
  abstract={The chapter introduces novel adversarial machine learning attacks and the taxonomy of its cases, where machine learning is used against AI‐based classifiers to make them fail. It investigates a possible data corruption and quality decrease influence on the classifier performance. The module proposes data restoration procedures and other measures to protect against adversarial attacks. Generative adversarial networks are introduced, and their use is discussed. Multiple algorithm examples and use cases are included.},
  keywords={Training;Training data;Adversarial machine learning;Testing;Data models;Taxonomy;Privacy},
  doi={10.1002/9781119771579.ch6},
  ISSN={},
  publisher={IEEE},
  isbn={9781119771555},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/9562706},}@INPROCEEDINGS{10659431,
  author={Trouve, Nicolas and Letheule, Nathan and Leveque, Olivier and Rami, Ilias and Colin, Elise},
  booktitle={EUSAR 2024; 15th European Conference on Synthetic Aperture Radar}, 
  title={SAR image synthesis using text conditioned pre-trained generative AI models}, 
  year={2024},
  volume={},
  number={},
  pages={1387-1392},
  abstract={We explore the utilization of artificial intelligence (AI) generative models for creating high-resolution airborne Synthetic Aperture Radar (SAR) images. Our methodology involves the use of a text-conditioned latent diffusion architecture to train a generative model. We use a database of high-resolution SAR images obtained from the SETHI sensor at ONERA for training purposes. This model is capable of generating synthetic images based on textual prompts provided by users. Additionally, we illustrate the model’s versatility for various applications, such as generating SAR images from handdrawn sketches.},
  keywords={},
  doi={},
  ISSN={},
  month={April},}@ARTICLE{9517298,
  author={Zhang, Jiaxin and Fukuda, Tomohiro and Yabuki, Nobuyoshi},
  journal={IEEE Access}, 
  title={Automatic Object Removal With Obstructed Façades Completion Using Semantic Segmentation and Generative Adversarial Inpainting}, 
  year={2021},
  volume={9},
  number={},
  pages={117486-117495},
  abstract={Automatic object removal with obstructed façades completion in the urban environment is essential for many applications such as scene restoration, environmental impact assessment, and urban mapping. However, the previous object removal typically requires a user to manually create a mask around unwanted objects and obtain background façade information in advance, which would be labor-intensive when implementing multitasking projects. Moreover, accurately detecting objects to be removed in the cityscape and inpainting the static obstructed building façade to obtain plausible images are the main challenges for this objective. To overcome these difficulties, this study addresses the object removal with the façade inpainting problem from the following two aspects. First, we proposed an image-based cityscape elimination method for automatic object removal and façade inpainting by applying semantic segmentation to detect several classes, including pedestrians, riders, vegetation, and cars, as well as using generative adversarial networks (GANs) for filling detected regions by background textures and patching information from street-level imagery. Second, we proposed a workflow to filter unoccluded building façades from street view images automatically and tailored a dataset for the GAN-based image inpainting model with original and mask images. Furthermore, several full-reference image quality assessment (IQA) metrics are introduced to evaluate the generated image quality. Validation results demonstrated the feasibility and effectiveness of our proposed method, and the synthetic image is visually realistic and semantically consistent.},
  keywords={Image segmentation;Buildings;Semantics;Urban areas;Task analysis;Object detection;Image restoration;Generative adversarial networks;semantic segmentation;automatic object removal;façade inpainting;street view images},
  doi={10.1109/ACCESS.2021.3106124},
  ISSN={2169-3536},
  month={},}@ARTICLE{8950402,
  author={Wei, Xiaotao and Wei, Xiang and Xing, Weiwei and Lu, Siyang and Lu, Wei},
  journal={IEEE Access}, 
  title={An Incremental Self-Labeling Strategy for Semi-Supervised Deep Learning Based on Generative Adversarial Networks}, 
  year={2020},
  volume={8},
  number={},
  pages={8913-8921},
  abstract={The recent success of deep neural networks is attributed in part to large-scale well-labeled training data. However, with the ever-increasing size of modern datasets, combined with the difficulty of obtaining label information, semi-supervised learning (SSL) has become one of the most remarkable issues in data analysis. In this paper, we propose an Incremental Self-Labeling strategy for SSL based on Generative Adversarial Nets (ISL-GAN), which functions by constantly assigning unlabeled data with virtual labels for promoting the training process. Specifically, during the virtual labeling process, we introduce a temporal-based self-labeling strategy for safe and stable data labeling. Then, to dynamically assign more virtual labels to data during the training, we conduct a phased incremental label screening and updating strategy. Finally, to balance the contribution of samples with different loss during the training process, we further introduce the Balance factor Term (BT). The experimental results show that the proposed method gives rise to state-of-the-art semi-supervised learning results for the MNIST, CIFAR-10, and SVHN datasets. Particularly, our model performs well with fewer labeled conditions. With a dataset of only 1,000 labeled CIFAR-10 images with CONV-Large Net, a test error of 11.2% can be achieved, and nearly the same performance with a 3.5% test error can be achieved with both 500 and 1,000 image-labeled SVHN datasets.},
  keywords={Training;Semisupervised learning;Gallium nitride;Deep learning;Labeling;Data models;Training data;Deep learning;semi-supervised learning;generative adversarial networks;self-labeling},
  doi={10.1109/ACCESS.2020.2964315},
  ISSN={2169-3536},
  month={},}@ARTICLE{10216968,
  author={Zheng, Yongqiang and Wang, Dongqing},
  journal={IEEE Access}, 
  title={An Auxiliary Classifier Generative Adversarial Network Based Fault Diagnosis for Analog Circuit}, 
  year={2023},
  volume={11},
  number={},
  pages={86824-86833},
  abstract={To solve the analog fault diagnosis problem with fewer samples, a transformer based auxiliary classifier generative adversarial network (ACGAN) is investigated for circuit fault diagnosis by constructing both generator and discriminator in ACGAN with pure transformer components. The transformer has high model generality due to its weak inductive bias, but it also increases the risk of overfitting on small datasets. Therefore, we use ACGAN to generate sample data to enrich the dataset and mitigate the overfitting. However, ACGAN is severely unstable during the training period, for this reason, a confidence mechanism for the discriminator is added to improve the classification accuracy and a new layer normalization method for the generator is studied to avoid the loss of conditional information. Take the sallen-key filter circuit and the biquad high-pass filter circuit as the experiment objects. The experiment results indicate that the transformer based ACGAN diagnosis method can effectively improve diagnosis accuracy, reach 96.22% and 95.35%, respectively.},
  keywords={Fault diagnosis;Transformers;Circuit faults;Feature extraction;Analog circuits;Generators;Knowledge based systems;Neural networks;Transformer; analog circuit;neural networks;fault diagnosis;auxiliary classifier generative adversarial network (ACGAN)},
  doi={10.1109/ACCESS.2023.3305261},
  ISSN={2169-3536},
  month={},}@ARTICLE{9669924,
  author={Valencia-Rosado, Luis Oswaldo and Guzman-Zavaleta, Zobeida J. and Starostenko, Oleg},
  journal={IEEE Access}, 
  title={A Modular Generative Approach for Realistic River Deltas: When L-Systems and cGANs Meet}, 
  year={2022},
  volume={10},
  number={},
  pages={5753-5767},
  abstract={Procedural terrain generation aims to create topographically coherent landscapes with realistic terrain features. Realistic landscapes of our blue planet are not complete without river deltas; however, there is an insufficient advancement in the generation of landscapes with this terrain feature. Therefore, this paper presents a modular approach to generate landscapes focused on the river deltas features. The modular proposal initially creates skeletons of deltas using a stochastic L-system grammar; we include the guidelines for the rules design. In the first module, we propose three L-systems that automatically create delta skeletons using these guidelines. The second module constructs the coastline and the sedimentary lands for the delta skeleton. Finally, the third module uses conditional generative adversarial networks (cGANs) to create the corresponding digital elevation models (DEMs) and land surface images. The evaluation of our proposal includes visual comparisons, and image quality metrics: the Frechet Inception Distance (FID), and the Naturalness Image Quality Evaluator (NIQE). The proposed modular integration generates realistic deltas with enough variability to outperform related work.},
  keywords={Rivers;Skeleton;Sea surface;Surface treatment;Land surface;Grammar;Computational modeling;L-system grammar;generative model;procedural terrain generation},
  doi={10.1109/ACCESS.2022.3140226},
  ISSN={2169-3536},
  month={},}@ARTICLE{9268163,
  author={Wang, Wenxiao and Wong, Hon-Cheng and Lo, Sio-Long and Zhang, Guifang},
  journal={IEEE Access}, 
  title={Uncouple Generative Adversarial Networks for Transferring Stylized Portraits to Realistic Faces}, 
  year={2020},
  volume={8},
  number={},
  pages={213825-213839},
  abstract={Stylized portraits widely exist in artwork or paintings. It is interesting to restore the original identity of portrait artworks, but consider that the rarity and the style diversity of these artworks, it is difficult to pair and obtain sufficient training data to restore their original identities by existing methods. Therefore, it is challenging to explore a method to restore a single stylized portrait to its original identity. Although CycleGAN can convert paintings into realistic photographs in unpaired datasets, it was not developed specifically for portraits, and photo-realistic faces require more accurate structures, thus the visual results obtained with CycleGAN are not satisfactory. In this paper, we propose Uncouple-Generative Adversarial Networks (UncGANs) for transferring stylized portraits to realistic faces. Our UncGANs framework is inspired by CariGANs to tackle the visual problem in CycleGAN for obtaining realistic faces from stylized portraits. In addition, we introduce three losses, namely, the semantic style consistency loss and the cycle consistency loss to effectively guide the training of generators and discriminators on unpaired datasets, the global and local adversarial loss ensure the consistency of appearance characteristics before and after translation, and the location consistency loss to establish the precise correspondence between the source domain and the target domain as well as assist the discriminators. Extensive experimental results and comparisons with state-of-the-art methods including Style, Deep-Image-Analogy, UNIT, MUNIT, CycleGAN, CP-GAN, and PS2-MAN demonstrate that our framework is better at generating realistic faces from stylized portraits with accurate structures and features.},
  keywords={Faces;Generators;Task analysis;Image restoration;Semantics;Training;Painting;Stylized portraits;reality;generative adversarial networks (GANs);deep learning},
  doi={10.1109/ACCESS.2020.3039969},
  ISSN={2169-3536},
  month={},}@ARTICLE{9676600,
  author={Raman, Gurupraanesh and O’rourke, Colm J. and Lu, Jerry and Peng, Jimmy Chih-Hsien and Kirtley, James L.},
  journal={IEEE Access}, 
  title={Conditional Generative Adversarial Networks for Dynamic Control-Parameter Selection in Power Systems}, 
  year={2022},
  volume={10},
  number={},
  pages={11236-11247},
  abstract={This paper describes the novel application of conditional Generative Adversarial Networks (cGANs) for real-time stability region determination (SRD) in power systems. As the network configuration changes during the course of operation, the availability of the stability region would enable the operator to suitably tune the control parameters to maintain stability while maximizing the dynamic performance. Here, the implementation of the cGANs-based SRD is described using transmission and microgrid case studies, where it is demonstrated to adaptively estimate the stability region for different network configurations with high accuracy. It is also shown that the cGANs approach has a significantly shorter execution time as compared to the conventional model-based method, demonstrating its value for real-time use in practical power systems.},
  keywords={Power system stability;Training;Generators;Numerical stability;Real-time systems;Power system dynamics;Circuit stability;Control parameter tuning;distributed generation;generative adversarial networks (GANs);model-free approach;real-time control;small-signal stability},
  doi={10.1109/ACCESS.2022.3141804},
  ISSN={2169-3536},
  month={},}@ARTICLE{10950384,
  author={Yang, Jing and Qin, Haoshen and Sun, Yiping and Wang, Hao and Ayub Khan, Abdullah and Yee Por, Lip and Alizadehsani, Roohallah and Pławiak, Paweł},
  journal={IEEE Access}, 
  title={A Generative Adversarial Network-Based Extractive Text Summarization Using Transductive and Reinforcement Learning}, 
  year={2025},
  volume={13},
  number={},
  pages={65490-65509},
  abstract={Text summarization is crucial in various sectors, such as engineering and healthcare, because it enhances efficiency in terms of time and costs. Current extractive text summarization methods struggle with challenges such as greedy selection, model generalization limitations, and high computational demands. To solve these problems, this research introduces a novel extractive text summarization method that uniquely integrates a Generative Adversarial Network (GAN), Transductive Long Short-Term Memory (TLSTM), and DistilBERT for sentence embedding. Our technique uses GANs, which include generator and discriminator components, with the core design based on TLSTM. TLSTM utilizes transductive learning to improve accuracy by focusing on samples geographically closer to the test data. In our model, the generator considers whether to include a sentence in the summary while the discriminator critically reviews the generated summary. This GAN model reduces greedy sentence selection, enhancing summary coherence and quality. We implement a Reinforcement Learning (RL)-based strategy to address an imbalance caused by more fake than real samples in the discriminator. This RL approach, novel in the context of GANs for summarization, views training as a sequence of interconnected decisions, treating each sample as a unique scenario. The network, acting as the decision-making agent, assigns greater rewards or penalties to the minority class to correct the imbalance. The effectiveness of our model was evaluated using the well-regarded CNN/Daily Mail dataset, achieving ROUGE-1, ROUGE-2, and ROUGE-L scores of 52.45, 26.46, and 44.85, respectively. Compared to existing methods, our results demonstrate a significant improvement in summarization quality and operational efficiency, as measured by the ROUGE metric.},
  keywords={Text summarization;Generators;Long short term memory;Encoding;Training;Reinforcement learning;Feature extraction;Computer science;Bidirectional control;Accuracy;Text summarization;transductive learning;generative adversarial network;reinforcement learning;DistilBERT},
  doi={10.1109/ACCESS.2025.3558266},
  ISSN={2169-3536},
  month={},}@ARTICLE{8768363,
  author={Li, Wanyue and He, Yi and Kong, Wen and Gao, Feng and Wang, Jing and Shi, Guohua},
  journal={IEEE Access}, 
  title={Enhancement of Retinal Image From Line-Scanning Ophthalmoscope Using Generative Adversarial Networks}, 
  year={2019},
  volume={7},
  number={},
  pages={99830-99841},
  abstract={A line-scanning ophthalmoscope (LSO) is a retinal imaging technique that has the characteristics of high imaging resolution, wide field of view, and high imaging speed. However, the high-speed imaging with rather short exposure time inevitably reduces the signal intensity, and many factors, such as speckle noise and intraocular scatter, further degrade the signal-to-noise ratio (SNR) of retinal images. To effectively improve the image quality without increasing the LSO system’s complexity, the post-processing method of image super-resolution (SR) is adopted. In this paper, we propose a learning-based multi-frame retinal image SR method that directly learns an end-to-end mapping from low-resolution (LR) image sequences to high-resolution (HR) images. This network was validated on down-sampled and real LSO image sequences. We evaluated the method on a down-sampled dataset with the metrics of peak signal-to-noise ratio (PSNR), structural similarity (SSIM), and perceptual distance. Moreover, the power spectra and full width at half maximum (FWHM) were used as the no-reference image quality assessment (NR-IQA) algorithms to evaluate the reconstruction results of the real LSO image sequences. The experimental results indicate that the proposed method can significantly enhance the SNR of LSO images and efficiently improve the resolution of LSO retinal images, which has great practical significance for clinical diagnosis and analysis.},
  keywords={Retina;Imaging;Spatial resolution;Image sequences;Image reconstruction;Generative adversarial networks;Line-scanning ophthalmoscope;retinal images;multi-frame image super-resolution;learning-based},
  doi={10.1109/ACCESS.2019.2930329},
  ISSN={2169-3536},
  month={},}@ARTICLE{10265158,
  author={Maier, Martin and Hosseini, Nika and Soltanshahi, Minoo},
  journal={IEEE Consumer Electronics Magazine}, 
  title={INTERBEING: On the Symbiosis Between INTERnet and Human BEING}, 
  year={2024},
  volume={13},
  number={3},
  pages={98-106},
  abstract={With the advent of the metaverse, the future 3D spatial Internet will be about being inside the Internet rather than simply looking at it from a 2D computer or smartphone screen. This article aims at exploring the sociality dimension, AI integration in eXtended meta-uni-omni-Verse, and stigmergy principles. It puts a particular focus on the unifying design of virtual, embodied, intelligent cross-reality environments, ranging from our proposed stigmergic Society 5.0 to Interbeing based on the symbiosis between Inter(net) and (human) being—a word that is not in the dictionary yet. In addition to tokenized digital twins, we leverage on hyperintelligent life-like digital organisms that symbiomimic biological superorganisms. In doing so, they lay the foundation for creating a future stigmergic virtual society that benefits from the convergence of digital evolution and biology as well as advanced eXtended Reality wearables for tapping into the entire reality-virtuality continuum of the metaverse's emerging virtual society.},
  keywords={Metaverse;Internet;X reality;Consumer electronics;Artificial intelligence;Symbiosis;Three-dimensional displays;Social factors;Social implications of technology;Virtual reality;Smart phones;Two-dimensional displays;Wearable devices},
  doi={10.1109/MCE.2023.3319849},
  ISSN={2162-2256},
  month={May},}@INPROCEEDINGS{10673956,
  author={Li, Xinmiao and Feng, Shuang and Zhang, Xin},
  booktitle={2024 IEEE/ACIS 27th International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)}, 
  title={A Review of Methods Using Large Language Models in News Recommendation Systems}, 
  year={2024},
  volume={},
  number={},
  pages={81-86},
  abstract={Large Language Models (LLMs) are widely used in natural language processing tasks due to their powerful semantic understanding and knowledge integration capabilities. Numerous existing recommendation studies consider recommendation tasks as a type of natural language processing, and thus LLMs have consequently brought new changes to the recommendation system paradigm. Existing research on recommendations using LLMs partly utilizes their rich data information, fine-grained user profiling, and expanded recommendation content to improve recommendation effectiveness. Additionally, some and partly studies directly uses LLMs to implement a generative recommendation paradigm. This paper adopts the literature review method to systematically sort out the current research status of news recommendation based on LLMs and classifies and summarizes the relevant research. To comprehensively understand the research in the field of news recommendation using LLMs, this paper introduces the current major work in the field of news recommendation from the two categories of generative LLM-assisted recommendation and direct generative recommendation and summarizes the current work as well as the potential future research directions and challenges.},
  keywords={Technological innovation;Accuracy;Reviews;Large language models;Semantics;Natural language processing;User experience;News Recommendation;Large Language Models;Generative News Recommendation},
  doi={10.1109/SNPD61259.2024.10673956},
  ISSN={2693-8421},
  month={July},}@INPROCEEDINGS{10828587,
  author={Meghana, J and Bellad, Harshavardana R and Pardhi, Diya and Magdum, Ishwari and Nagaraj, Chaitra},
  booktitle={2024 International Conference on Artificial Intelligence, Metaverse and Cybersecurity (ICAMAC)}, 
  title={Integrating Tradition and Technology: A Survey of AI Applications in the Design of Temple Architecture}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={This article will delve into the complicated inter-building of artificial intelligence and traditional skill of temple architecture of South India. It meticulously analyzes the historical roots of temple design, explaining in detail the subtle means and methods that have always been used in temple construction. Apart from detailed preparation and skilled craftsmanship, it is the cultural heritage that is demonstrated with these monumental creations. In the sequel, the paper sheds light on how AI technologies are transforming temple architecture through systems analysis and optimization, generative design and other methods. Living examples of Artificial Intelligence work do not only confirm the successful AI implementations but also illustrate the smooth link between tradition and novelty in the modern temple designs.},
  keywords={Surveys;Technological innovation;Metaverse;Design methodology;Cultural differences;Artificial intelligence;Computer security;System analysis and design;Optimization;Guidelines},
  doi={10.1109/ICAMAC62387.2024.10828587},
  ISSN={},
  month={Oct},}@ARTICLE{9268983,
  author={Fang, Dawei and Guan, Xin and Hu, Benran and Peng, Yu and Chen, Min and Hwang, Kai},
  journal={IEEE Internet of Things Journal}, 
  title={Deep Reinforcement Learning for Scenario-Based Robust Economic Dispatch Strategy in Internet of Energy}, 
  year={2021},
  volume={8},
  number={12},
  pages={9654-9663},
  abstract={Currently, the integration of distributed energy generators through virtual power plants in the Internet of Energy is a mainstream method. The complex structure of virtual power plants and the characteristics of distributed energy make it difficult to solve the economic dispatch problems of virtual power plants. In addition, the load of a virtual power plant is unstable and uncertain and thus requires a robust economic dispatch strategy. Because the selection of the set of uncertain conditions is conservative, the traditional robust economic dispatch strategies cannot effectively reduce the cost of virtual power plants. In addition, the traditional methods for solving robust strategies cannot directly solve nonlinear and nonconvex problems. In this article, we propose a scenario-based robust economic dispatch strategy for virtual power plants, aiming to reduce the operational costs of virtual power plants. First, to reduce the conservatism of the strategy, scenario-based data augmentation is adopted for data generation. Through a generative adversarial network, a large amount of scene data are generated to extend the set of uncertain conditions. The scene data cannot only reduce the conservatism but also can be used in the determination of robust strategies. Second, deep reinforcement learning is adopted for historical data training, directly solving nonlinear and nonconvex problems to obtain a robust economic dispatch strategy. As experiments show, with the accurate generation of scene data, the proposed economic dispatch strategy is robust and effectively reduces the cost of virtual power plants.},
  keywords={Economics;Power generation;Generators;Renewable energy sources;Internet of Things;Distribution networks;Energy storage;Deep reinforcement learning;Internet of Energy;robust economic dispatch strategy;scene data generation;virtual power plant},
  doi={10.1109/JIOT.2020.3040294},
  ISSN={2327-4662},
  month={June},}@ARTICLE{7096939,
  author={Wörgötter, Florentin and Geib, Chris and Tamosiunaite, Minija and Aksoy, Eren Erdal and Piater, Justus and Xiong, Hanchen and Ude, Ales and Nemec, Bojan and Kraft, Dirk and Krüger, Norbert and Wächter, Mirko and Asfour, Tamim},
  journal={IEEE Transactions on Autonomous Mental Development}, 
  title={Structural Bootstrapping—A Novel, Generative Mechanism for Faster and More Efficient Acquisition of Action-Knowledge}, 
  year={2015},
  volume={7},
  number={2},
  pages={140-154},
  abstract={Humans, but also robots, learn to improve their behavior. Without existing knowledge, learning either needs to be explorative and, thus, slow or-to be more efficient-it needs to rely on supervision, which may not always be available. However, once some knowledge base exists an agent can make use of it to improve learning efficiency and speed. This happens for our children at the age of around three when they very quickly begin to assimilate new information by making guided guesses how this fits to their prior knowledge. This is a very efficient generative learning mechanism in the sense that the existing knowledge is generalized into as-yet unexplored, novel domains. So far generative learning has not been employed for robots and robot learning remains to be a slow and tedious process. The goal of the current study is to devise for the first time a general framework for a generative process that will improve learning and which can be applied at all different levels of the robot's cognitive architecture. To this end, we introduce the concept of structural bootstrapping-borrowed and modified from child language acquisition-to define a probabilistic process that uses existing knowledge together with new observations to supplement our robot's data-base with missing information about planning-, object-, as well as, action-relevant entities. In a kitchen scenario, we use the example of making batter by pouring and mixing two components and show that the agent can efficiently acquire new knowledge about planning operators, objects as well as required motor pattern for stirring by structural bootstrapping. Some benchmarks are shown, too, that demonstrate how structural bootstrapping improves performance.},
  keywords={Planning;Robot sensing systems;Syntactics;Semantics;Probabilistic logic;Informatics;Fast learning;generative model;knowledge acquisition},
  doi={10.1109/TAMD.2015.2427233},
  ISSN={1943-0612},
  month={June},}@INPROCEEDINGS{10940062,
  author={Sri, L Pooja and Shri R, Rivanthika and Thrisha, R. and S, Varsha},
  booktitle={2025 International Conference on Electronics and Renewable Systems (ICEARS)}, 
  title={MindMend: Explainable GANs for Stimulating Mental Health Scenarios in Therapist Training}, 
  year={2025},
  volume={},
  number={},
  pages={327-333},
  abstract={Mental health disorders pose great challenges to clinicians, which have few training resources, guard privacy in patient data, lack standardized scenarios for training therapists, and validity difficulties when interventions are assessed. Traditional role-playing doesn't seem to portray the richness and diversity associated with mental health conditions due to ethical constraints that generally prohibit direct contact with clients. This paper introduces a novel application of GANs to meet these challenges by simulating realistic scenarios of mental illness. Present implementations of GANs in health care face enormous difficulties due to the lack of interpretability and bias detection capabilities coupled with clinical validation. We address these limitations through Explainable GANs, a novel architecture for model design that involves explainable AI techniques. This framework will make the generation process of scenarios transparent and understandable to clinicians and researchers, with high-fidelity simulation of mental health conditions. Our objectives are the development of privacy-preserving synthetic data generation, ensuring clinical validity through expert validation, and creation of interpretable AI outputs for healthcare professionals. The technical framework includes sophisticated data processing pipelines, robust model architectures, and integrated explainability components that address some of the critical challenges in data privacy, bias mitigation, and clinical reliability. Comprehensive evaluation metrics and clinical validation allow us to demonstrate the effectiveness of the framework in generating realistic, clinically relevant scenarios while maintaining transparency and interpretability.},
  keywords={Training;Ethics;Data privacy;Renewable energy sources;Explainable AI;Mental health;Medical services;Data models;Robustness;Synthetic data;Generative Adversarial Networks;Mental Health Simulation;Explainable AI;Therapist Training;Ethical AI in Healthcare.},
  doi={10.1109/ICEARS64219.2025.10940062},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{9881069,
  author={Qin, Liwen and Yu, Xiaoyong and Luo, Yuteng and Li, Shan and Zhou, Yangjun},
  booktitle={2022 Power System and Green Energy Conference (PSGEC)}, 
  title={Generative Adversarial Networks-based Distribution Network Operation Scenario Generation}, 
  year={2022},
  volume={},
  number={},
  pages={900-906},
  abstract={With the increasing proportion of renewable energy in the distribution network, the uncertainty of renewable energy poses a challenge to the operation analysis and decision-making of distribution network. Scenario is an important tool to control and optimization of the power system under uncertainty. Therefore, how to generate scenarios efficiently and accurately is the focus of power system uncertainty analysis. In order to solve the above problems, this paper uses Generative Adversarial Nets to generate distribution network operation scenarios. By analyzing the operation scenario generation of distribution network and the principle of Generative Adversarial Nets, the structure and training method of Generative Adversarial Nets for time-series power flow data are proposed and verified in an example based on IEEE33 bus system. The results show that the designed network can learn the characteristics and distribution of operation scenarios of distribution network. This paper also proposes a general distribution network operation scenario generation platform, and gives a general method from scenario set construction to network training, testing and application.},
  keywords={Training;Renewable energy sources;Uncertainty;Distribution networks;Power system stability;Data models;Tides;Generative Adversarial Nets;scenario generation;deep learning Introduction},
  doi={10.1109/PSGEC54663.2022.9881069},
  ISSN={},
  month={Aug},}@ARTICLE{10835232,
  author={Duran, Kubra and Shin, Hyundong and Duong, Trung Q. and Canberk, Berk},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={GenTwin: Generative AI-Powered Digital Twinning for Adaptive Management in IoT Networks}, 
  year={2025},
  volume={11},
  number={2},
  pages={1053-1063},
  abstract={The dramatic increase in smart services makes adaptive management of communication networks more critical. Especially for Internet of Things (IoT) networks, adaptive management faces several challenges, like fluctuating network conditions, heterogeneity in data sources, and rapid response capabilities. These challenges lead to performance degradation and data losses in IoT applications if not handled. Even though traditional AI algorithms are applied in most network topologies, they fall short of handling these adaptive management challenges without requiring additional software developments. Therefore, we propose a Generative AI-powered Digital Twinning (GenTwin) framework to create digital twin models with generative AI algorithms. In this framework, we design two novel mechanisms: Priority Pooling and Twin Adapter. Priority Pooling is to extract the dynamic relations within the topology before performing model training. We theoretically formulate the priority levels and corresponding weights with a novel presence parameter to present a modular architecture to increase training efficiency. The Twin Adapter is to interact with the GAI architecture and fine-tune the model for the adaptive twin modelling task in IoT networks. After creating the adaptive twin models, we test the rapid response capabilities of GenTwin with what-if analysis. According to our simulation results, we note that the proposed pooling mechanism extracts the data relations 19% more by enhancing the training accuracy. In addition, we show that GenTwin surpasses the traditional twin performance in terms of rapid response capabilities by reducing the response time 53% when the dynamicity is maximum.},
  keywords={Adaptation models;Internet of Things;Adaptive systems;Digital twins;Topology;Artificial intelligence;Data models;Smart cities;Network topology;Logic gates;Digital twin;IoT;adaptive management;modelling;generative AI},
  doi={10.1109/TCCN.2025.3527719},
  ISSN={2332-7731},
  month={April},}
