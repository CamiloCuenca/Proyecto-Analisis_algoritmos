@ARTICLE{11086546,
  author={Elmqvist, Niklas and Klokmose, Clemens Nylandsted},
  journal={IEEE Computer Graphics and Applications}, 
  title={Automating the Path: An R&D Agenda for Human-Centered AI and Visualization}, 
  year={2025},
  volume={45},
  number={3},
  pages={73-81},
  abstract={The emergence of generative AI, large language models, and foundation models is fundamentally reshaping computer science, and visualization and visual analytics are no exception. We present a systematic framework for understanding how human-centered AI (HCAI) can transform the visualization discipline. Our framework maps four key HCAI tool capabilities—amplify, augment, empower, and enhance—onto the four phases of visual sensemaking: view, explore, schematize, and report. For each combination, we review existing tools, envision future possibilities, identify challenges and pitfalls, and examine ethical considerations. This design space can serve as an R&D agenda for both visualization researchers and practitioners to integrate AI into their work as well as understanding how visualization can support HCAI research.},
  keywords={Visualization;Ethics;Systematics;Generative AI;Foundation models;Visual analytics;Large language models;Transforms;Research and development;Human computer interaction;Artificial intelligence},
  doi={10.1109/MCG.2025.3559374},
  ISSN={1558-1756},
  month={May},}@ARTICLE{10489870,
  author={Cousins, Stephen},
  journal={Engineering & Technology}, 
  title={The rapid rise of AI art: Has humanity unwittingly entered a radical new era of art and artistic expression? That's the suggestion being circulated in creative communities and online forums as a new breed of powerful artificial intelligence emerges from the shadows}, 
  year={2023},
  volume={18},
  number={2},
  pages={20-25},
  abstract={GENERATIVE AI art has exploded onto the scene over the past few months through advanced online platforms like DALL-E2, Midjourney and Stable Diffusion, which enable anyone with access to a smartphone or PC to create highly polished art by typing in simple text instructions.},
  keywords={},
  doi={10.1049/et.2023.0208},
  ISSN={1750-9637},
  month={March},}@ARTICLE{8351916,
  author={Rosman, Guy and Rus, Daniela and Fisher, John W.},
  journal={IEEE Transactions on Computational Imaging}, 
  title={Information-Driven Adaptive Structured-Light Scanners}, 
  year={2018},
  volume={4},
  number={3},
  pages={341-354},
  abstract={Sensor planning and active sensing, long studied in robotics, adapt sensor parameters to maximize a utility function while constraining resource expenditures. Here, we consider information gain as the utility function. While these concepts are often used to reason about 3D sensors, these are usually treated as a predefined black-box component. In this paper, we show how the same principles can be used as part of the 3D sensor. We describe the generative model for structured-light 3D scanning and show how adaptive pattern selection can maximize information gain in an open-loop-feedback manner. We then demonstrate how different choices of relevant variable sets (corresponding to the subproblems of localization and mapping) lead to different criteria for pattern selection and can be computed in an online fashion. We show results for both subproblems with several pattern dictionary choices and demonstrate their usefulness for pose estimation and depth acquisition.},
  keywords={Robot sensing systems;Three-dimensional displays;Task analysis;Estimation;Computational modeling;Planning;Depth sensors;structured-light;information-gain;sensor planning;3D scanners;uncertainty;simultaneous localization and mapping;generative models},
  doi={10.1109/TCI.2018.2830181},
  ISSN={2333-9403},
  month={Sep.},}@ARTICLE{10897635,
  author={Li, Yidi and Xiao, Jun and Wang, Yiqun and Lu, Zhengda},
  journal={Computational Visual Media}, 
  title={DepthGAN: GAN-based depth generation from semantic layouts}, 
  year={2024},
  volume={10},
  number={3},
  pages={505-522},
  abstract={Existing GAN-based generative methods are typically used for semantic image synthesis. We pose the question of whether GAN-based architectures can generate plausible depth maps and find that existing methods have difficulty in generating depth maps which reasonably represent 3D scene structure due to the lack of global geometric correlations. Thus, we propose DepthGAN, a novel method of generating a depth map using a semantic layout as input to aid construction, and manipulation of well-structured 3D scene point clouds. Specifically, we first build a feature generation model with a cascade of semantically-aware transformer blocks to obtain depth features with global structural information. For our semantically aware transformer block, we propose a mixed attention module and a semantically aware layer normalization module to better exploit semantic consistency for depth features generation. Moreover, we present a novel semantically weighted depth synthesis module, which generates adaptive depth intervals for the current scene. We generate the final depth map by using a weighted combination of semantically aware depth weights for different depth ranges. In this manner, we obtain a more accurate depth map. Extensive experiments on indoor and outdoor datasets demonstrate that DepthGAN achieves superior results both quantitatively and visually for the depth generation task.},
  keywords={Semantics;Transformers;Three-dimensional displays;Layout;Computer vision;Visualization;Convolution;Image synthesis;Encoding;Depth measurement;depth map generation;generative model;transformer;scene generation},
  doi={10.1007/s41095-023-0350-8},
  ISSN={2096-0662},
  month={June},}@INPROCEEDINGS{11039864,
  author={Shah, Khushi and Puig, Domenec and Mathukiya, Kush and Bhatt, Chintan},
  booktitle={2024 International Conference on Control, Computing, Communication and Materials (ICCCCM)}, 
  title={Advancements in Deep Learning Techniques for Robust Detection of DeepFakes}, 
  year={2024},
  volume={},
  number={},
  pages={184-189},
  abstract={With tremendous growth in artificial intelligence and machine learning, numerous techniques can be used to distort and manipulate the media. Although many of these techniques are used for scientific or academic purposes, their potential harmful or devious activities are very important to address. One such tool of widespread misuse is the DeepFake technology. A user on Reddit coined the term "DeepFake," which originates from Deep Learning (DL) and is used to generate fake images of people. They are typically used in entertainment and education, but it is important to address the above-mentioned misuse cases. Hence, deepfake detection has received much required attention, and many techniques have been proposed to identify its instances, whether in photos or videos. Various techniques have been implemented to detect deepfakes, such as Convolution Neural Network (CNN), Artificial Neural Network (ANN) and other pre- trained models including ResNet50, VGG16, VGG19, InceptionNet, EfficientNet, Transformer, U-Net and Transfer Learning. The results showed that using MobileNet as a pretrained model in transfer learning outperformed other models by achieving 83% accuracy and the least loss (0.19) among all.},
  keywords={Deep learning;Deepfakes;Social networking (online);Computational modeling;Transfer learning;Education;Entertainment industry;Media;Transformers;Residual neural networks;DeepFake Detection;Deep Learning;Transfer Learning},
  doi={10.1109/ICCCCM61016.2024.11039864},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10115204,
  author={Mikkilineni, Sai Ranganath and Privat, Taylor D. and Totaro, Michael Wayne},
  booktitle={SoutheastCon 2023}, 
  title={PredNet⊕GAN: A Higher-Level Induction of Predictive Coding into Adversarial Setting Leading to a Semi/Pseudo-GAN Perspective at a Lower Level}, 
  year={2023},
  volume={},
  number={},
  pages={150-158},
  abstract={The neurobiological predictive coding model proposed by Rao and Ballard is one of the most well-known and carefully tested models in the current research space. The manifestation of predictive coding in animals’ visual cortices(such as cats and monkeys) has been adequately demonstrated; however, due to the lack of analytical equipment for the nuanced study of the human brain, it has not been demonstrated comparably in humans. Recently there has been an increase in the variety of opinions in neurobiology research about the application of machine learning/artificial intelligence to understand further and investigate predictive coding theory. In this paper, we induce the predictive coding neural network model (PredNet) into an adversarial setting of Wasserstein and the Conditional-Wasserstein nature. Our experiment includes approximately 60 combinatorial variants of the neural networks and two datasets. The results from our experiments seem to substantiate a new perspective on predictive coding theory. In addition to presenting a unique perspective through our research in this paper, we also provide the performance profile of PredNet in conjunction with an adversarial setting through extensive experimentation and analysis.},
  keywords={Visualization;Predictive coding;Predictive models;Brain modeling;Biological neural networks;Unsupervised learning;Wasserstein loss;Conditional-Wasserstein loss;L1-loss;Gradient Difference Loss;GDL;Predictive Coding;Generative Adversarial Networks;Future frame prediction;Videos;GAN;PredNet;KITTI dataset;Something-Something dataset;Combinatorial Experimentation},
  doi={10.1109/SoutheastCon51012.2023.10115204},
  ISSN={1558-058X},
  month={April},}@INPROCEEDINGS{10570804,
  author={Grini, Anass and El Khamlichi, Btissam and El Afia, Abdellatif and El Fallah-Seghrouchni, Amal},
  booktitle={2024 IEEE Wireless Communications and Networking Conference (WCNC)}, 
  title={HPAC-IDS: A Hierarchical Packet Attention Convolution for Intrusion Detection System}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This research introduces a robust detection system against malicious network traffic, leveraging hierarchical structures and self-attention mechanisms. The proposed system includes a Packet Segmenter that divides a given raw network packet into fixed-size segments that are fed to the HPAC-IDS. The experiments performed on CIC-IDS2017 dataset show that the system exhibits high accuracy and low false positive rates while demonstrating resilience against diverse adversarial methods like Fast Gradient Sign Method (FGSM), Projected Gradient Descent (PGD), and Wasserstein GAN (WGAN). The model's ability to withstand adversarial perturbations is attributed to the fusion of hierarchical attention mechanisms and convolutional neural networks, resulting in a 0% to 10% adversarial attack severity under tested adversarial attacks with different segment sizes, surpassing the state-of-the-art model in detection performance and adversarial attack robustness.},
  keywords={Attention mechanisms;Accuracy;Convolution;Perturbation methods;Intrusion detection;Telecommunication traffic;Generative adversarial networks;Robustness;Convolutional neural networks;Resilience},
  doi={10.1109/WCNC57260.2024.10570804},
  ISSN={1558-2612},
  month={April},}@ARTICLE{9536242,
  author={Dewangan, Gaurav and Maurya, Seetaram},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Fault Diagnosis of Machines Using Deep Convolutional Beta-Variational Autoencoder}, 
  year={2022},
  volume={3},
  number={2},
  pages={287-296},
  abstract={Industries are using fault diagnosis methods to prevent any downtime, which eventually led them to make profits and take necessary steps beforehand to avoid any mishaps. In recent years, deep learning methods have shown extraordinary performance in massive data applications with advancement in computing power. In this article, a novel intelligent fault diagnosis scheme based on deep convolutional variable-beta variational autoencoder (VAE) is proposed to extract discriminative features. A new min–max algorithm for data points reduction and a random sampling technique to get 2-D data has been proposed. The proposed fault diagnosis combines all intermediate steps (from preprocessing to classification) in a single framework, and an end-to-end training has been performed. The proposed training method with variable beta uses VAE as a feature extractor and classifier rather than just being a probabilistic generative model, which further improved the performance of the overall model. The proposed scheme reduces the needs of domain/expertise knowledge on time-series data. The proposed method has also been validated in the presence of noise. The proposed approach is validated through two case studies by utilizing rotating machinery datasets: First, on the case western reserve university vibration dataset (VD), and second, on the air compressor acoustic dataset (AD). Highest accuracies obtained are 99.93% and 99.91% on case western reserve university VD and air compressor AD, respectively, using the proposed scheme. Finally, a comparative study has been presented.},
  keywords={Fault diagnosis;Feature extraction;Convolution;Convolutional neural networks;Machinery;Vibrations;Data models;Convolution neural network (CNN);fault diagnosis;variable-beta;variational autoencoder (VAE)},
  doi={10.1109/TAI.2021.3110835},
  ISSN={2691-4581},
  month={April},}@INPROCEEDINGS{10125852,
  author={Hashana, A.M. Jasmine and Brundha, P. and Ahamed Ayoobkhan, Mohamed Uvaze and S, Fazila},
  booktitle={2023 7th International Conference on Trends in Electronics and Informatics (ICOEI)}, 
  title={Deep Learning in ChatGPT - A Survey}, 
  year={2023},
  volume={},
  number={},
  pages={1001-1005},
  abstract={Abstract-As a subset of machine learning, deep learning makes use of multiple-layer neural networks to learn with available data and make decisions or predictions. A large language model called ChatGPT is based on deep learning, specifically a type of neural network called a transformer. ChatGPT's transformer architecture uses attention mechanisms to focus on the most important parts of the input, allowing it to process and comprehend a large amount of text data. In order for the model to comprehend the context and meaning of natural language text, it is trained on a huge database of text, including articles and books. One of the main importance of using deep learning in ChatGPT is its intelligence to understand relationships and patterns from the input text and generate or predict new text that is homogeneous to the input/training data. Because of this, ChatGPT is able to respond to questions and prompts in a manner that is comparable to that of a human, making it useful for a wide scope of natural language processing missions like translating languages, summarizing texts, and responding to questions. It's worth noting that, while deep learning has been highly effective in ChatGPT, it is not without its limitations. To train, deep learning models can be very complex and require a lot of data and computing power.},
  keywords={Deep learning;Training;Adaptation models;Computational modeling;Computer architecture;Chatbots;Transformers;Artificial Intelligence;Convolutional Neural Networks;ChatGPT;Generative Adversarial Networks;Recurrent Neural Networks},
  doi={10.1109/ICOEI56765.2023.10125852},
  ISSN={},
  month={April},}@INPROCEEDINGS{10289846,
  author={Golfe, Alejandro and del Amor, Rocío and Colomer, Adrián and Sales, María A. and Terradez, Liria and Naranjo, Valery},
  booktitle={2023 31st European Signal Processing Conference (EUSIPCO)}, 
  title={Towards the On-Demand Whole Slide Image Generation: Prostate Patch Synthesis Through a Conditional Progressive Growing GAN}, 
  year={2023},
  volume={},
  number={},
  pages={1070-1074},
  abstract={Prostate cancer is a common disease that affects men, and its diagnosis and prognosis rely on the Gleason scoring system. To automate this process, generative deep learning models can be used to synthesize histopathological tissue patches of non-cancerous and malignant patterns. This work proposes a conditional Progressive Growing GAN to generate synthetic samples by selecting the desired pattern. The model is trained using conditional information about the pattern, and minibatch standard deviation and pixel normalization are used to improve performance and stability. The synthetic samples are assessed using the Frechet Inception Distance (FID). Finally, the proposed framework was applied to the SICAPv2 dataset, and the results showed that data augmentation with our method improved the classification accuracy obtained on this dataset. This demonstrates the effectiveness of the proposed framework as a data augmentation method. Overall, this study provides a promising approach to address the issue of insufficient and unbalanced datasets in prostate cancer diagnosis and prognosis, which can improve the accuracy and reliability of clinical decision-making.},
  keywords={Deep learning;Image synthesis;Europe;Signal processing;Data augmentation;Stability analysis;Reliability;Prostate cancer;Progressive Growing GAN;Conditional GAN;Histology image},
  doi={10.23919/EUSIPCO58844.2023.10289846},
  ISSN={2076-1465},
  month={Sep.},}@INPROCEEDINGS{10451579,
  author={Yi, Junbo and He, Xin and Wang, Maolin and Zheng, Xiujuan and Guo, Feng and Zhang, Yong},
  booktitle={2023 China Automation Congress (CAC)}, 
  title={Quality Prediction of Rocket Engine Combustion Chamber Shell Spinning Process Based on CGAN and Hybrid Neural Network}, 
  year={2023},
  volume={},
  number={},
  pages={2323-2328},
  abstract={The combustion chamber shell is one of the main structures of rocket engines, and the quality prediction of its spinning process is crucial to improve the stability of the engine and the subsequent improvement process. In this article, we propose a quality prediction method based on data augmentation and a hybrid neural network model combining feature attention (FA) and temporal convolutional network and long short term memory network (TCN-LSTM). First, the feature multi-collinearity problem is solved by principal component analysis dimensionality reduction of the equipment time series data of the shell machining process. Then, conditional generative adversarial network is used for data augmentation to generate more samples using quality indicators as condition information to solve the problem of insufficient data collection in actual engineering. Finally, the key feature information is enhanced using the FA mechanism, while the dual quality metrics are predicted by TCN-LSTM, and the prediction results are corrected using the least squares method. In this paper, a real rocket engine combustion chamber shell machining dataset is used to validate the model effect, and the experimental results show that the method has higher prediction accuracy by comparing with different machine learning methods.},
  keywords={Rockets;Neural networks;Time series analysis;Machining;Predictive models;Data augmentation;Combustion;Data Augmentation;Hybrid Neural Network;Rocket Engine Combustion Chamber Shell;Spinning Process;Quality Prediction},
  doi={10.1109/CAC59555.2023.10451579},
  ISSN={2688-0938},
  month={Nov},}@INPROCEEDINGS{9931192,
  author={Xiang, Zhonghao and Song, Limei and Xu, Jingwei and Zhu, Xinjun},
  booktitle={2022 5th International Conference on Intelligent Autonomous Systems (ICoIAS)}, 
  title={RDCGAN-based Metal Workpieces Image Data Augmentation for Industrial Identification}, 
  year={2022},
  volume={},
  number={},
  pages={96-101},
  abstract={The application of deep learning algorithms on various automatic equipment can accomplish many tasks of target detection and identification in industry. Obtaining enough metal workpieces image datasets is a challenge in the real industrial environment. In particular, metal workpieces are vulnerable to lights and other factors. To address this problem, we propose a method for generating metal workpieces images using Restoration Deep Convolutional Generative Adversarial Network (RDCGAN). To improve the quality of the generated images, we integrate an image restoration algorithm. We first design and build the machine vision platform for collecting different kinds of workpieces images in different work conditions. Then we use our RDCGAN to generate metal workpieces images. Finally, we demonstrate that our method produces the images with higher quality compared to the existing approaches in data augmentation methods, as measured by the Fréchet Inception Distance (FID). This approach to metal workpieces image data augmentation can be used in other metal objects data augmentation, to promote the performance of the detection system.},
  keywords={Training;Industries;Deep learning;Machine vision;Metals;Training data;Object detection;dataset augmentation;DCGAN;metal workpieces;image restoration},
  doi={10.1109/ICoIAS56028.2022.9931192},
  ISSN={},
  month={Sep.},}@ARTICLE{9875268,
  author={Zheng, Hongling and Li, Xiang and Li, Yongfeng and Yan, Ziqin and Li, Tinghong},
  journal={IEEE Access}, 
  title={GCN-GAN: Integrating Graph Convolutional Network and Generative Adversarial Network for Traffic Flow Prediction}, 
  year={2022},
  volume={10},
  number={},
  pages={94051-94062},
  abstract={As a necessary component in intelligent transportation systems (ITS), traffic flow-based prediction can accurately estimate the traffic flow in a certain period and area in the future. However, despite the success of traditional research and current machine learning methods, traffic flow prediction models have limitations in terms of prediction accuracy and efficiency. In this work, we propose a novel traffic flow prediction model named Graph Convolution and Generative Adversative Neural Network (GCN-GAN), which leverages Graph Convolution Neural Network (GCN) module and Generative Adversative Neural Network (GAN) module to predict urban traffic flow. Firstly, the GCN module extracts historical traffic flow information in the graph structure. Secondly, the GAN module generates reliable traffic flow prediction results by adversative training. Additionally, GCN-GAN can parallelly generate prediction results rather than traditional one by one. Through experiments on the traffic flow dataset at multiple intersections, our GCN-GAN model outperforms the baseline methods by over 30.54% and has apparent advantages in multi-step prediction.},
  keywords={Predictive models;Neural networks;Generative adversarial networks;Convolutional neural networks;Data models;Machine learning;Time series analysis;Intelligent transportation systems;Intelligent transport system;GCN-GAN;graph machine learning;time series prediction},
  doi={10.1109/ACCESS.2022.3204036},
  ISSN={2169-3536},
  month={},}@ARTICLE{9446893,
  author={Chen, Zhiyuan and Soliman, Waleed Mahmoud and Nazir, Amril and Shorfuzzaman, Mohammad},
  journal={IEEE Access}, 
  title={Variational Autoencoders and Wasserstein Generative Adversarial Networks for Improving the Anti-Money Laundering Process}, 
  year={2021},
  volume={9},
  number={},
  pages={83762-83785},
  abstract={There has been much recent work on fraud and Anti Money Laundering (AML) detection using machine learning techniques. However, most algorithms are based on supervised techniques. Studies show that supervised techniques often have the limitation of not adapting well to new irregular fraud patterns when the dataset is highly imbalanced. Instead, unsupervised learning can have a better capability to find anomalous and irregular patterns in new transaction. Despite this, unsupervised techniques also have the disadvantage of not being able to give state-of-the-art detection results. We propose a suite of unsupervised and deep learning techniques to implement an anti-money laundering and fraud detection system to resolve this limitation. The system leverages three deep learning models: autoencoder (AE), variational autoencoder (VAE), and a generative adversarial network. We preprocess the given dataset to separate the Transaction Date attribute into its base components to capture time-related fraud patterns. Also, Wasserstein Generative Adversarial Network (WGAN) is used to generate fraud transactions, which are then mixed with the base dataset to form a more balanced mixed dataset. These two datasets are used to train the AE and VAE models. We built two versions of the AE model (single-loss and multi-loss) besides a novel method of calculating the anomaly score threshold, called Recall-First Threshold (RFT), which helps enhance the model's performance. Experimental results demonstrated that the False Positive Rate (FPR) drops down to as low as 7% in the proposed multi-loss AE model. In comparison, we achieved an accuracy of 93%, with 100% of the fraud transactions recalled successfully.},
  keywords={Support vector machines;Clustering algorithms;Deep learning;Generative adversarial networks;Unsupervised learning;Radio frequency;Decision trees;Anti-money laundering (AML);autoencoders;anomaly detection;deep learning;fraud detection;GANs;unsupervised learning},
  doi={10.1109/ACCESS.2021.3086359},
  ISSN={2169-3536},
  month={},}@ARTICLE{9197608,
  author={Wang, Xinying and Xu, Dikai and Gu, Fangming},
  journal={IEEE Access}, 
  title={3D Model Inpainting Based on 3D Deep Convolutional Generative Adversarial Network}, 
  year={2020},
  volume={8},
  number={},
  pages={170355-170363},
  abstract={In recent years, the problem of hole repairing in the 3D model has been widely concerned in related fields. As the Generative Adversarial Network (GAN) has achieved great success in generating realistic images, a 3D mesh model repair method based on the 3D Deep Convolutional Generative Adversarial Network (3D-DCGAN) is proposed in this paper. The algorithm contains two GANs: a local GAN and a global GAN. Four steps have been used to implement this concept. First, the 3D model is voxelized, and a mask is used to identify the repairing area; Second, the repairing area is generated by training local GAN; Third, the repaired region is combined with the 3D model to be repaired, thereafter, the global GAN is trained with the combined model. Finally, a decent repaired model is obtained with the perfect transition. The experimental results show that this algorithm can effectively generate the repairing area while retaining the details of the area and blend it with the model to be repaired.},
  keywords={Three-dimensional displays;Gallium nitride;Solid modeling;Generators;Maintenance engineering;Generative adversarial networks;Atmospheric modeling;3D model inpainting;GAN;local GAN;global GAN},
  doi={10.1109/ACCESS.2020.3024288},
  ISSN={2169-3536},
  month={},}@ARTICLE{8698864,
  author={Wang, Zhi-Hui and Wang, Ning and Shi, Jian and Li, Jian-Jun and Yang, Hairui},
  journal={IEEE Access}, 
  title={Multi-Instance Sketch to Image Synthesis With Progressive Generative Adversarial Networks}, 
  year={2019},
  volume={7},
  number={},
  pages={56683-56693},
  abstract={Real-world images usually contain multiple objects, as a result, generating an image from a multi-instance sketch is an attractive research topic. However, existing generative networks usually produce a similar texture on different instances for those methods focus on learning the distribution of the whole image. To address this problem, we propose a progressive instance texture reserved generative approach to generate more convincible images by decoupling the generation of the instances and the whole image. Specifically, we create an instance generator to synthesize the primitive color distribution and the detailed texture for each instance. Then, an image generator is designed to combine all of these instances to synthesize an image retaining texture and color. Besides, to generate more significant details, such as eyes, ears, and so on, we propose a novel technique called discriminative sketch augmentation, which can provide structural constraint by obtaining the sketch of the discriminative region. The extensive experiments demonstrate that our model not only generates convincing images but also achieves higher inception score and lower Fréchet Inception Distance on the MS-COCO dataset.},
  keywords={Generators;Image generation;Image color analysis;Task analysis;Generative adversarial networks;Software;Semantics;Multi-instance sketch to image;image processing;image generation},
  doi={10.1109/ACCESS.2019.2913178},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9883131,
  author={Xiang, Jiajun and Gou, Shuiping and Li, Ruimin and Zheng, Zhihui},
  booktitle={IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium}, 
  title={RGB-Thermal based Pedestrian Detection with Single-Modal Augmentation and ROI Pooling Multiscale Fusion}, 
  year={2022},
  volume={},
  number={},
  pages={3532-3535},
  abstract={RGB-Thermal based pedestrian detection has received more extensive attention due to the provided detailed information and thermal sensitivity of pedestrians. In this paper, a single-modal feature augmentation network (SMA-Net) is proposed. Firstly, two single-modal branches are trained separately to optimize the feature extraction of each branch in addition to the training of pedestrian detection based on fused features. Secondly, a lightweight ROI pooling multiscale fusion module (PMSF) is proposed to obtain more fine-grained and abundant features, in which pooling features of different scales are integrated by adaptively weighting. Finally, a generative constraint strategy is designed to constrain fusion by minimizing the loss function between the generated fusion image and RGB-Thermal pairs. Experimental result on the challenging dataset KAIST demonstrates that the proposed SMA-Net achieves great performance in terms of accuracy and computational efficiency.},
  keywords={Training;Sensitivity;Geoscience and remote sensing;Feature extraction;Computational efficiency;Pedestrian detection;single-modal augmentation;ROI pooling multiscale fusion;generative constraint;multispectral datasets},
  doi={10.1109/IGARSS46834.2022.9883131},
  ISSN={2153-7003},
  month={July},}@ARTICLE{10777302,
  author={Xu, Juncong and Yang, Yang and Fang, Han and Liu, Honggu and Zhang, Weiming},
  journal={IEEE Signal Processing Letters}, 
  title={FAMSeC: A Few-Shot-Sample-Based General AI-Generated Image Detection Method}, 
  year={2025},
  volume={32},
  number={},
  pages={226-230},
  abstract={The explosive growth of generative AI has saturated the internet with AI-generated images, raising security concerns and increasing the need for reliable detection methods. The primary requirement for such detection is generalizability, typically achieved by training on numerous fake images from various models. However, practical limitations, such as closed-source models and restricted access, often result in limited training samples. Therefore, training a general detector with few-shot samples is essential for modern detection mechanisms. To address this challenge, we propose FAMSeC, a general AI-generated image detection method based on LoRA-based Forgery Awareness Module and Semantic feature-guided Contrastive learning strategy. To effectively learn from limited samples and prevent overfitting, we developed a forgery awareness module (FAM) based on LoRA, maintaining the generalization of pre-trained features. Additionally, to cooperate with FAM, we designed a semantic feature-guided contrastive learning strategy (SeC), making the FAM focus more on the differences between real/fake image than on the features of the samples themselves. Experiments show that FAMSeC outperforms state-of-the-art method, enhancing classification accuracy by 14.55% with just 0.56% of the training samples.},
  keywords={Feature extraction;Training;Contrastive learning;Accuracy;Forgery;Semantics;Detectors;Testing;Overfitting;Training data;AI-generated image detection;contrastive learning;diffusion model;generative adversarial network},
  doi={10.1109/LSP.2024.3511421},
  ISSN={1558-2361},
  month={},}@INPROCEEDINGS{10622695,
  author={Lai, Bingkun and He, Jiayi and Kang, Jiawen and Li, Gaolei and Xu, Minrui and zhang, Tao and Xie, Shengli},
  booktitle={ICC 2024 - IEEE International Conference on Communications}, 
  title={On-demand Quantization for Green Federated Generative Diffusion in Mobile Edge Networks}, 
  year={2024},
  volume={},
  number={},
  pages={2883-2888},
  abstract={Generative Artificial Intelligence (GAI) shows remarkable productivity and creativity in Mobile Edge Networks, such as the metaverse and the Industrial Internet of Things. Federated learning is a promising technique for effectively training GAI models in mobile edge networks due to its data distribution. However, there is a notable issue with communication consumption when training large GAI models like generative diffusion models in mobile edge networks. Additionally, the substantial energy consumption associated with training diffusion-based models, along with the limited resources of edge devices and complexities of network environments, pose challenges for improving the training efficiency of GAI models. To address this challenge, we propose an on-demand quantized energy-efficient federated diffusion approach for mobile edge networks. Specifically, we first design a dynamic quantized federated diffusion training scheme considering various demands from the edge devices. Then, we study an energy efficiency problem based on specific quantization requirements. Numerical results show that our proposed method significantly reduces system energy consumption and transmitted model size compared to both baseline federated diffusion and fixed quantized federated diffusion methods while effectively maintaining reasonable quality and diversity of generated data.},
  keywords={Training;Productivity;Energy consumption;Quantization (signal);Metaverse;Green products;Energy efficiency;Federated Diffusion;Energy Efficient;Generative AI;Generative Diffusion;On-demand Quantization},
  doi={10.1109/ICC51166.2024.10622695},
  ISSN={1938-1883},
  month={June},}@ARTICLE{10620276,
  author={Huang, Xi and Tang, Yinxu and Li, Junling and Zhang, Ning and Shen, Xuemin},
  journal={IEEE Network}, 
  title={Toward Effective Retrieval Augmented Generative Services in 6G Networks}, 
  year={2024},
  volume={38},
  number={6},
  pages={459-467},
  abstract={Retrieval augmented generation (RAG) empowers generative language services by integrating extensive context from external data sources (a.k.a. knowledge bases). The current RAG-enhanced generative services are predominantly hosted in cloud environments, relying on static knowledge bases without real-time sensory information which may lead to constrained scalability, responsiveness, and overall service quality. One promising opportunity is to extend the deployment of such services to the network edge, leveraging the anticipated capabilities of 6G networks. In this article, we propose a deployment framework for RAG-enhanced generative services in 6G. We address the key challenges at the convergence of service deployment, 6G networks, and user interactions. Additionally, we explore potential techniques to enhance RAG-based services through data fusion, dynamic knowledge base deployment, service customization, and interactive user experiences. Lastly, we shed light on future paths toward the effective deployment and delivery of RAG-enhanced generative services.},
  keywords={6G mobile communication;Servers;Data integration;Knowledge based systems;Cloud computing;Streams;Real-time systems;Edge AI;Service-oriented systems engineering;6G;retrieval augmented generation;knowledge base deployment;edge intelligence;service customization},
  doi={10.1109/MNET.2024.3436670},
  ISSN={1558-156X},
  month={Nov},}@ARTICLE{11146559,
  author={Heng, Yang and Khan, Fiaz Gul and Yinghua, Ma and Khan, Ahmad and Ali, Farman and Khan, Nasrullah and Kwak, Daehan},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Integrating GANs, Contrastive Learning, and Transformers for Robust Medical Image Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={1-15},
  abstract={Despite the widespread success of convolutional neural networks (CNNs) in general computer vision tasks, their application to complex medical image analysis faces persistent challenges. These include limited labeled data availability, which restricts model generalization; class imbalance, where minority classes are underrepresented and lead to biased predictions; and inadequate feature representation, since conventional CNNs often struggle to capture subtle patterns and intricate dependencies characteristic of medical imaging. To address these limitations, we propose CTNGAN, a unified framework that integrates generative modeling with Generative Adversarial Networks (GANs), contrastive learning, and Transformer architectures to enhance the robustness and accuracy of medical image analysis. Each component is designed to tackle a specific challenge: the GAN model mitigates data scarcity and imbalance, contrastive learning strengthens feature robustness against domain shifts, and the Transformer captures long-range spatial patterns. This tripartite integration not only overcomes the limitations of conventional CNNs but also achieves superior generalizability, as demonstrated by classification experiments on benchmark medical imaging datasets, with up to 98.5% accuracy and an F1-score of 0.968, outperforming existing methods. The framework's ability to jointly optimize data generation, feature discrimination, and contextual modeling establishes a new paradigm for accurate and reliable medical image diagnosis.},
  keywords={Medical diagnostic imaging;Feature extraction;Image classification;Accuracy;Data models;Contrastive learning;Deep learning;Transformers;Training;Robustness;Generative adversarial networks;Contrastive learning;Transformers;Medical image classification},
  doi={10.1109/JBHI.2025.3604845},
  ISSN={2168-2208},
  month={},}@ARTICLE{9343766,
  author={Wang, Yaxiong and Wei, Yunchao and Qian, Xueming and Zhu, Li and Yang, Yi},
  journal={IEEE Transactions on Image Processing}, 
  title={Sketch-Guided Scenery Image Outpainting}, 
  year={2021},
  volume={30},
  number={},
  pages={2643-2655},
  abstract={The outpainting results produced by existing approaches are often too random to meet users' requirements. In this work, we take the image outpainting one step forward by allowing users to harvest personal custom outpainting results using sketches as the guidance. To this end, we propose an encoder-decoder based network to conduct sketch-guided outpainting, where two alignment modules are adopted to impose the generated content to be realistic and consistent with the provided sketches. First, we apply a holistic alignment module to make the synthesized part be similar to the real one from the global view. Second, we reversely produce the sketches from the synthesized part and encourage them be consistent with the ground-truth ones using a sketch alignment module. In this way, the learned generator will be imposed to pay more attention to fine details and be sensitive to the guiding sketches. To our knowledge, this work is the first attempt to explore the challenging yet meaningful conditional scenery image outpainting. We conduct extensive experiments on two collected benchmarks to qualitatively and quantitatively validate the effectiveness of our approach compared with the other state-of-the-art generative models.},
  keywords={Task analysis;Generators;Decoding;Image reconstruction;Shape;Semantics;Toy manufacturing industry;Image outpainting;generation model;adversarial learning},
  doi={10.1109/TIP.2021.3054477},
  ISSN={1941-0042},
  month={},}@ARTICLE{10504108,
  author={Liu, Jianhua},
  journal={Journal of Web Engineering}, 
  title={Enhancing English Language Education Through Big Data Analytics and Generative AI}, 
  year={2024},
  volume={23},
  number={2},
  pages={227-249},
  abstract={This research paper provides a comprehensive examination of the significant impact of big data analytics and generative artificial intelligence (GAI) on the field of English language education. Utilizing a meticulous framework rooted in the evolutionary network influence of big data, our study critically analyzes several aspects of student engagement, learning motivation, self-efficacy, and the existing disparities among learners. Our primary objective is to enhance students' active participation, intrinsic interest, and self-confidence in the context of English language learning, thus advancing their overall linguistic competence. To achieve these objectives, our study systematically integrates the concept of practice education with a multidisciplinary approach, leveraging the power of big data analysis and GAI, and reveals profound insights into student learning behaviors, preferences, and personalized educational needs. We employ advanced techniques for meticulous data processing and interpretation, empowering educators to make data-informed decisions and tailor pedagogical strategies to meet the unique requirements of each student. This data-driven pedagogical approach not only facilitates the implementation of effective teaching methodologies but also effectively addresses the disparities stemming from diverse student backgrounds, thereby fostering a more inclusive and personalized learning environment.},
  keywords={Surveys;Feedback loop;Ethics;Generative AI;Federated learning;Education;Decision making;Big data analysis;generative AI;language education;learning English},
  doi={10.13052/jwe1540-9589.2322},
  ISSN={1544-5976},
  month={March},}@INPROCEEDINGS{11016406,
  author={Wang, Karen D. and Wu, Zhangyang and Tufts, L'Nard and Wieman, Carl and Salehi, Shima and Haber, Nick},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Scaffold or Crutch? Examining College Students' Use and Views of Generative AI Tools for STEM Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={Developing problem-solving competency is central to Science, Technology, Engineering, and Mathematics (STEM) education, yet translating this priority into effective approaches to problem-solving instruction and assessment has been a significant challenge. The recent proliferation of generative artificial intelligence (genAI) tools like ChatGPT in higher education introduces new considerations: how to define problem-solving competency in a genAI era, and how these tools can help or hinder students' development of STEM problem-solving competency. Our research takes steps in examining these considerations by studying how and why college students are currently using genAI tools in their STEM coursework, with a specific focus on how they employ these tools to support their problem-solving. We conducted an online survey of 40 STEM college students from diverse institutions across the US. In addition, we surveyed 28 STEM faculty to understand instructor views on effective and ineffective genAI tool use in STEM courses and their guidance for students. Our findings reveal high adoption rates and diverse applications of genAI tools among STEM students. The most common use cases of genAI tools in STEM coursework include finding explanations, exploring related topics, summarizing readings, and helping with problem-set questions. The primary motivation for using genAI tools in STEM coursework was to save time. Moreover, we found that over half of the student participants reported simply inputting a problem for AI to generate solutions, potentially bypassing their own problem-solving processes. These findings indicate that despite high adoption rates, students' current approaches to utilizing genAI tools often fall short in enhancing their own STEM problem-solving competencies. The study also explored students' and STEM instructors' perceptions of the benefits and risks associated with using genAI tools in STEM education. Our findings provide insights into how to guide students on appropriate genAI use in STEM courses and how to design genAI-based tools to foster students' problem-solving competency.},
  keywords={Surveys;Generative AI;Educational technology;Chatbots;Problem-solving;Engineering education;STEM;Generative AI;Educational Technology;STEM},
  doi={10.1109/EDUCON62633.2025.11016406},
  ISSN={2165-9567},
  month={April},}@ARTICLE{10504107,
  author={Yongli, Gao and Qi, Dong and Zhipeng, Chen},
  journal={Journal of Web Engineering}, 
  title={Leveraging the Synergy of IPv6, Generative AI, and Web Engineering to Create a Big Data-Driven Education Platform}, 
  year={2024},
  volume={23},
  number={2},
  pages={197-226},
  abstract={The rapid advancement of network technology in China has significantly accelerated the implementation of information technology in higher education. Through the utilization of computer technology, multimedia technology, big data technology, artificial intelligence technology, and network communication technology, the integration of these technologies in university teaching has become widespread. This paper presents an analysis and discussion on the utilization of the latest IPv6 network transmission protocol technology to enhance the application of data collection in university education, with a specific focus on gathering information related to university faculties. By leveraging web engineering and multimedia technology as fundamental components, the network facilitates the sharing of educational resources among students, thereby enabling the reform of management approaches, fostering educational progress in China, and establishing a comprehensive big data-driven education platform specifically tailored to colleges and universities. Additionally, the incorporation of big data visualization and analysis tools allows for easy retrieval of existing university educational information, facilitates the creation of data charts, and expedites the utilization of data for its inherent value. Finally, the proposed approach employs generative AI to collect and analyze feedback from students and educators, followed by the application of web engineering techniques to continuously enhance the online education platform based on this feedback.},
  keywords={Technological innovation;Visualization;Generative AI;Education;Ecosystems;Decision making;Data visualization;Web engineering;IPv6;generative AI;education informatization;big data platform},
  doi={10.13052/jwe1540-9589.2321},
  ISSN={1544-5976},
  month={March},}@INPROCEEDINGS{10685837,
  author={Kadel, Rajan and Mishra, Bhupesh Kumar and Shailendra, Samar and Abid, Samia and Rani, Maneeha and Mahato, Shiva Prasad},
  booktitle={2024 International Symposium on Educational Technology (ISET)}, 
  title={Crafting Tomorrow’s Evaluations: Assessment Design Strategies in the Era of Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={13-17},
  abstract={In recent years, no other technology has revolutionised our life as Generative Artificial Intelligence (GenAI). GenAI has gained the attention of a myriad of users in almost every profession. Its advancement has had an intense impact on education, significantly disrupting the assessment design and evaluation methodologies. Despite the potential benefits and possibilities of GenAI in the education sector, there are several concerns primarily centred around academic integrity, authenticity, equity of access, assessment evaluation methodology, and feedback. Consequently, academia is encountering challenges in assessment design that are essential to retaining academic integrity in the age of GenAI. In this article, we discuss the challenges, and opportunities that need to be addressed for the assessment design and evaluation. The article also highlights the importance of clear policy about the usage of GenAI in completing assessment tasks, and also in design approaches to ensure academic integrity and subject learning. Additionally, this article also provides assessment categorisation based on the use of GenAI to cultivate students’ and academic professionals’ knowledge. It also provides information on the skills necessary to formulate and articulate problems and evaluate the task, enabling students and academics to effectively utilise GenAI tools.},
  keywords={Generative AI;Design methodology;Educational technology;Assessment Design;Assessment Evaluation;Generative AI (GenAI)},
  doi={10.1109/ISET61814.2024.00012},
  ISSN={2766-2144},
  month={July},}@INPROCEEDINGS{10798728,
  author={Mirtaheri, Seyedeh Leili and Pugliese, Andrea},
  booktitle={2024 IEEE Conference on Dependable, Autonomic and Secure Computing (DASC)}, 
  title={Leveraging Generative AI to Enhance Automated Vulnerability Scoring}, 
  year={2024},
  volume={},
  number={},
  pages={57-64},
  abstract={Vulnerability assessment is an important and well-studied subject in software security. Traditional methods use expert knowledge, which is time-consuming. Considering the constantly increasing number of vulnerabilities, automated machine learning (ML)-based solutions have been proposed to assess the severity of vulnerabilities. Existing methods concentrate on predicting the Common Vulnerability Scoring System (CVSS) score or its vector metrics using available vulnerability information. The quality and diversity of the vulnerability description data can greatly affect the accuracy of these predictions. Studies report that less than 60% of such descriptions follow the formal template. On the other hand, the performance of ML-based vulnerability scoring approaches is highly dependent on the quality of the data and the model’s architecture. In this paper, we aim to improve the performance of existing ML-based solutions in vulnerability assessment. We use generative artificial intelligence (AI) and feed the CVSS descriptions to a large-language model. We use GPT3.5Turbo to generate descriptions and propose a fine-tuned BERT-CNN model to predict the CVSS vector metrics. We conduct several experiments to assess the performance of the proposed method against the state-of-the-art. We use both the original dataset (6,370 descriptions) and the descriptions generated by GPT3.5Turbo. Our experiments show that our proposed architecture considerably improves accuracy.},
  keywords={Measurement;Hands;Accuracy;Generative AI;Computer architecture;Predictive models;Vectors;Software;Security;Long short term memory;Vulnerability;Severity;Prediction;Generative AI;Convolutional Neural Networks(CNN);ChatGPT;Bert;Long Short-term Memory (LSTM);TextRNN-ATT},
  doi={10.1109/DASC64200.2024.00014},
  ISSN={2837-0740},
  month={Nov},}@INPROCEEDINGS{10978225,
  author={Liu, Zhang and Du, Hongyang and Huang, Lianfen and Gao, Zhibin and Niyato, Dusit},
  booktitle={2025 IEEE Wireless Communications and Networking Conference (WCNC)}, 
  title={Joint Model Caching and Resource Allocation in Generative AI - Enabled Wireless Edge Networks}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={With the rapid advancement of artificial intelligence (AI), generative AI (GenAI) has emerged as a transformative tool, enabling customized and personalized AI-generated content (AIGC) services. However, GenAI models with billions of parameters require substantial memory capacity and computational power for deployment and execution, presenting significant challenges to resource-limited edge networks. In this paper, we address the joint model caching and resource allocation problem in GenAI-enabled wireless edge networks. Our objective is to balance the trade-off between delivering high-quality AIGC and minimizing the delay in AI GC service provisioning. To tackle this problem, we employ a deep deterministic policy gradient (DDPG)-based reinforcement learning approach, capable of efficiently determining optimal model caching and resource allocation decisions for AIGC services in response to user mobility and time-varying channel conditions. Numerical results demonstrate that DDPG achieves a higher model hit ratio and provides superior-quality, lower-latency AIGC services compared to other benchmark solutions.},
  keywords={Wireless communication;Generative AI;Computational modeling;Noise reduction;Memory management;Reinforcement learning;Time-varying channels;Numerical models;Resource management;Low latency communication;AI-generated contents;generative AI;model caching;resource allocation;wireless edge networks},
  doi={10.1109/WCNC61545.2025.10978225},
  ISSN={1558-2612},
  month={March},}@INPROCEEDINGS{11129352,
  author={Felipe, Anna Lyza and Khwakhali, Ushik Shrestha and Nguyen, Thanh Ngoc},
  booktitle={2025 10th International STEM Education Conference (iSTEM-Ed)}, 
  title={A Framework for Assessment Design in the Era of Generative AI: Case Study of Take-Home Assignment in Software-related Courses}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The use of Generative Artificial Intelligence (Gen-AI) in education has introduced various challenges, especially in assessment design, particularly concerning academic integrity. A major concern is plagiarism, as students can easily use AI-generated content to cheat on assignments, undermining the credibility and reliability of assessment results. This paper proposes a framework for designing take-home assignments in software-related courses incorporating Gen-AI while promoting academic integrity. The research employs an experimental approach and provides qualitative analysis by focusing on three carefully selected courses from the BIT and BSE programs. The framework offers guidelines for creating assignments that curtail plagiarism and ensure alignment with course learning objectives. The proposed framework suggests designing assessments between 3-6 levels of Bloom’s taxonomy to integrate Gen-AI into assessments while preserving its academic integrity.},
  keywords={Generative AI;Plagiarism;Education;Taxonomy;Focusing;Reliability;Guidelines;AI Education;Bloom Taxonomy;Computing Education;Generative AI;Assessment Design},
  doi={10.1109/iSTEM-Ed65612.2025.11129352},
  ISSN={},
  month={July},}@INPROCEEDINGS{10721790,
  author={Filho, Raimir Holanda and Colares, Daniel},
  booktitle={2024 International Conference on Software, Telecommunications and Computer Networks (SoftCOM)}, 
  title={A Methodology for Risk Management of Generative AI based Systems}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper addresses cybersecurity challenges in integrating Generative Artificial Intelligence (GenAI) into applications. It proposes a risk analysis approach that focuses on identifying threats and vulnerabilities exploited by malicious actors, which is validated through a case study on prompt injection attacks. The results demonstrated the efficacy of our approach in identifying and quantifying vulnerabilities in Large Language Models (LLMs).},
  keywords={Generative AI;Computational modeling;Large language models;Software;Computer networks;Telecommunications;Risk management;Computer crime;Best practices;Cyber Security;Risk Management;Generative AI;Large Language Models},
  doi={10.23919/SoftCOM62040.2024.10721790},
  ISSN={1847-358X},
  month={Sep.},}@INPROCEEDINGS{11124027,
  author={Iatrellis, Omiros and Kosmopoulou, Ioanna and Samaras, Nicholas and Kokkinos, Konstantinos},
  booktitle={2025 6th International Conference of the Portuguese Society for Engineering Education (CISPEE)}, 
  title={Educators' Adoption and Perceptions of Generative AI Tools in Higher Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Since the introduction of ChatGPT in late 2022, the role of artificial intelligence-driven chatbots in higher education has garnered widespread attention. However, the perspectives of faculty and academic staff regarding these tools remain insufficiently examined. This study explores how educators integrate and perceive generative AI in instructional activities, administrative processes, and student support services. A web-based survey incorporating both structured and open-ended questions was conducted among faculty members associated with a European university network. The findings indicate that nearly half of the participants have utilized AI-powered platforms, such as OpenAI's GPT models, for tasks like course planning, assessment grading, and student guidance. Many respondents acknowledged that AI enhances efficiency in routine academic operations, with two-thirds recognizing its role in optimizing administrative workflows. Furthermore, a significant proportion emphasized the need for institutional policies and targeted training programs to facilitate the responsible adoption of AI in academic environments. Nonetheless, the qualitative responses reflected diverse viewpoints, particularly regarding concerns related to data security, the reliability of AI-generated content, and its potential influence on the future landscape of teaching. These insights underscore both the advantages and challenges associated with incorporating large-scale AI chatbots into university settings.},
  keywords={Training;Surveys;Technological innovation;Generative AI;Transforms;Chatbots;Regulation;Planning;Reliability;Standards;Generative AI;Educators' Attitudes;Large Language Models;Chatbot Integration},
  doi={10.1109/CISPEE64787.2025.11124027},
  ISSN={},
  month={July},}@INPROCEEDINGS{11126578,
  author={Shetgaonkar, Ankit and Pradhan, Dipen and Arora, Lakshit and Girija, Sanjay Surendranath and Raj, Aman and Kapoor, Shashank},
  booktitle={2025 IEEE 49th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Mitigating Clinician Information Overload: Generative AI for Integrated EHR and RPM Data Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={2032-2039},
  abstract={Generative Artificial Intelligence (GenAI), particularly Large Language Models (LLMs), offer powerful capabilities for interpreting the complex data landscape in healthcare. In this paper, we present a comprehensive overview of the capabilities, requirements and applications of GenAI for deriving clinical insights and improving clinical efficiency. We first provide some background on the forms and sources of patient data, namely real-time Remote Patient Monitoring (RPM) streams and traditional Electronic Health Records (EHRs). The sheer volume and heterogeneity of this combined data present significant challenges to clinicians and contribute to information overload.In addition, we explore the potential of LLM-powered applications for improving clinical efficiency. These applications can enhance navigation of longitudinal patient data and provide actionable clinical decision support through natural language dialogue. We discuss the opportunities this presents for streamlining clinician workflows and personalizing care, alongside critical challenges such as data integration complexity, ensuring data quality and RPM data reliability, maintaining patient privacy, validating AI outputs for clinical safety, mitigating bias, and ensuring clinical acceptance. We believe this work represents the first summarization of GenAI techniques for managing clinician data overload due to combined RPM / EHR data complexities.},
  keywords={Patient monitoring;Data privacy;Data analysis;Generative AI;Large language models;Data integration;Medical services;Real-time systems;Complexity theory;Electronic medical records;Generative AI;Large Language Models;Healthcare;Clinical Decision Support;Conversational Agent;Electronic Health Records;Remote Patient Monitoring;Wearable Biosensor Technology;Data Integration;Data Privacy},
  doi={10.1109/COMPSAC65507.2025.00284},
  ISSN={2836-3795},
  month={July},}@INPROCEEDINGS{10975835,
  author={Oraño, Jannie Fleur V. and Nogra, James Arnold and Mangmang, Geraldine B.},
  booktitle={2025 14th International Conference on Educational and Information Technology (ICEIT)}, 
  title={Analyzing the Landscape of Generative and Open AI in Education: A Text Analytics Exploration of Scopus Publications}, 
  year={2025},
  volume={},
  number={},
  pages={84-90},
  abstract={Generative artificial intelligence (GAI) fundamentally reshaped the educational landscape by introducing innovative tools that enhanced learning outcomes and experiences. In this paper, a thorough examination of key terms surrounding GAI in education was undertaken from Scopus literature through sophisticated text analytics techniques such as word cloud generation and semantic analysis. The most used terms in the findings were “learning,” “ChatGPT,” and “language models,” representing the growing prominence of AI-driven educational solutions. Sentiment analysis revealed that authors had positive opinions about GAI and its potential benefits in developing individual learning paths and automating routines. However, concerns regarding ethics and job displacement were also highlighted. The study outlined important academic centers for GAI research, with significant contributions from Stanford University and publications in outlets such as “Lecture Notes in Computer Science.” Geographically, countries like China and India emerged as relevant in GAI research. Further thematic exploration demonstrated a predominantly positive attitude toward GAI's capability to transform pedagogical methodologies. Therefore, this research underscored the importance of text analytics in understanding GAI's role in education and called for strategic partnerships to advance innovation and equity in the global educational landscape.},
  keywords={Text mining;Sentiment analysis;Ethics;Technological innovation;Generative AI;Semantics;Transforms;Tag clouds;Stakeholders;Next generation networking;text analytics;generative ai;sentiment analysis;academia},
  doi={10.1109/ICEIT64364.2025.10975835},
  ISSN={},
  month={March},}@ARTICLE{9655700,
  author={Liu, Haoqiang and Zhao, Hongbo and Wang, Jiayue and Yuan, Shuai and Feng, Wenquan},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={LSTM-GAN-AE: A Promising Approach for Fault Diagnosis in Machine Health Monitoring}, 
  year={2022},
  volume={71},
  number={},
  pages={1-13},
  abstract={Recent years have witnessed that real-time health monitoring for machine gains more and more importance with the goal of achieving fault diagnosis (FD) and predictive maintenance. Conventional diagnosis methods face formidable challenges imposed by the high requirement for expert knowledge and extensive labor. The diagnosis scheme based on deep learning (DL) models has served as a promising solution and achieved great success. However, many of these DL-based models are fail to extract critical temporal information thoroughly. In addition, it is difficult to apply them to machine health monitoring (MHM) in real time as those methods take long time for diagnosis in practice. To address the aforementioned issues, this article introduces a novel intelligent FD algorithm with three stages for MHM. It is a hybrid framework that combines generative adversarial networks (GANs) and autoencoder (AE) based on the bidirectional long short-term memory (bi-LSTM). First, GAN is employed to obtain the reconstruction residual and learn the discriminative representation. Then, AE is used to perform the critical temporal features extraction and dimension reduction. Finally, the supervised learning model is constructed to integrate feature information and predict diagnosis results. To verify the effectiveness of the proposed algorithm, typical rolling bearing datasets are taken as trial data. Preliminary simulation results demonstrate that the proposed algorithm achieves superior performance compared to the competing methods.},
  keywords={Feature extraction;Fault diagnosis;Monitoring;Logic gates;Data mining;Support vector machines;Generative adversarial networks;Deep learning (DL);fault diagnosis (FD);long short-term memory (LSTM);machine health monitoring (MHM)},
  doi={10.1109/TIM.2021.3135328},
  ISSN={1557-9662},
  month={},}@ARTICLE{9573328,
  author={Hou, Haodi and Huo, Jing and Wu, Jing and Lai, Yu-Kun and Gao, Yang},
  journal={IEEE Transactions on Image Processing}, 
  title={MW-GAN: Multi-Warping GAN for Caricature Generation With Multi-Style Geometric Exaggeration}, 
  year={2021},
  volume={30},
  number={},
  pages={8644-8657},
  abstract={Given an input face photo, the goal of caricature generation is to produce stylized, exaggerated caricatures that share the same identity as the photo. It requires simultaneous style transfer and shape exaggeration with rich diversity, and meanwhile preserving the identity of the input. To address this challenging problem, we propose a novel framework called Multi-Warping GAN (MW-GAN), including a style network and a geometric network that are designed to conduct style transfer and geometric exaggeration respectively. We bridge the gap between the style/landmark space and their corresponding latent code spaces by a dual way design, so as to generate caricatures with arbitrary styles and geometric exaggeration, which can be specified either through random sampling of latent code or from a given caricature sample. Besides, we apply identity preserving loss to both image space and landmark space, leading to a great improvement in quality of generated caricatures. Experiments show that caricatures generated by MW-GAN have better quality than existing methods.},
  keywords={Shape;Generative adversarial networks;Codes;Faces;Semantics;Training;Strain;Caricature generation;generative adversarial nets;multiple styles;warping},
  doi={10.1109/TIP.2021.3118984},
  ISSN={1941-0042},
  month={},}@ARTICLE{10304374,
  author={Chen, Junbin and Yu, Tao and Pan, Zhenning and Zhang, Mengyue and Lu, Guanhua and Zhu, Kedong},
  journal={IEEE Transactions on Smart Grid}, 
  title={Stochastic Dynamic Power Dispatch With Human Knowledge Transfer Using Graph-GAN Assisted Inverse Reinforcement Learning}, 
  year={2024},
  volume={15},
  number={3},
  pages={3303-3315},
  abstract={This paper proposes a novel approach for dynamic economic dispatch (DED) of distribution networks, based on graph-generative adversarial network (Graph-GAN) assisted inverse reinforcement learning (IRL) with human knowledge transfer via demonstration. Firstly, the proposed method utilizes graph convolutional network (GCN) to capture the complex and nonlinear relationships between dispatch decision and system state. Secondly, a GAN-based approach is proposed to imitate the reward function from expert demonstration data, which avoids the need for manually designed reward functions. The trained policy network is then used for decision-making in real-time optimal dispatch of distribution networks. Experimental results demonstrate that the proposed approach outperforms traditional IRL methods and achieves supply-demand balance. Computation efficiency of the proposed method is thoroughly analyzed and shows that it is practically scalable to large-scale distribution networks. Overall, the proposed approach presents a promising alternative by incorporating human knowledge into reinforcement learning for DED of distribution networks.},
  keywords={Reinforcement learning;Distribution networks;Power systems;Generative adversarial networks;Convolutional neural networks;Dispatching;Task analysis;Dynamic economic dispatch;inverse reinforcement learning;human knowledge transfer;reward function;graph convolutional network},
  doi={10.1109/TSG.2023.3329459},
  ISSN={1949-3061},
  month={May},}@ARTICLE{10508385,
  author={Ali Raza, Syed and Habib, Usman and Usman, Muhammad and Ashraf Cheema, Adeel and Sajid Khan, Muhammad},
  journal={IEEE Access}, 
  title={MMGANGuard: A Robust Approach for Detecting Fake Images Generated by GANs Using Multi-Model Techniques}, 
  year={2024},
  volume={12},
  number={},
  pages={104153-104164},
  abstract={Recent advances in Generative Adversarial Networks (GANs) have produced synthetic images with high visual fidelity, making them nearly indistinguishable from human-created images. These synthetic images referred to as deepfakes, have become a major source of misinformation due to social media. Technology is advancing rapidly, so reliable methods for distinguishing real from fake images are needed. The current detection mechanisms require image forensics tools such as error level analysis (ELA), and clone detection to detect manipulated images. These approaches are limited because they require forensics expertise to use, are manual in application nature, and are unscalable, creating a need for a framework for a scalable tool that experts and non-experts can use to combat the spread of manipulated images and preserve digital visual information authenticity. We approach this problem with a multi-model ensemble framework using the transfer learning method to effectively detect fake images. The proposed approach named Multi-Model GAN Guard (MMGANGuard)integrates four models into an ensemble framework to identify GAN-generated image characteristics to improve deepfake detection. The Gram-Net architecture, ResNet50V2, and DenseNet201 models are used with co-occurrence matrices using transfer learning for MMGANGuard. Through comprehensive experiments, the proposed model demonstrates promising results in detecting the deepfake with high accuracy on the StyleGAN dataset. For automated detection of deepfake-generated images, the proposed model exceeded 97% accuracy, 98.5% TPR, 98.4% TPR, and 95.6% TPR in these evaluations, eliminating the need for manual assessment which is promising for future research in this domain.},
  keywords={Deepfakes;Predictive models;Social networking (online);Neurons;Image coding;Computer architecture;Data analysis;Deep learning;Generative adversarial networks;Deep fake;data analytics;deep learning;GANs;StyleGAN;detection;multi-model},
  doi={10.1109/ACCESS.2024.3393842},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10550666,
  author={Arachchi, H.A. Dimuthu Maduranga and Samarasinghe, G. D.},
  booktitle={2024 International Research Conference on Smart Computing and Systems Engineering (SCSE)}, 
  title={Impact of Deepfake Advertising Attributes on Consumers’ Hedonic & Utilitarian Values and Brand Credibility}, 
  year={2024},
  volume={7},
  number={},
  pages={1-6},
  abstract={Creative AI technologies, like deepfakes and generative adversarial networks, are making it possible to make and edit audio and video material in advertising in new ways. These new tools make it easy to make big changes to ads and create brand related positive consequences in the mind of target consumers. From a marketing paradigm, this study focused on explaining the relationship between the deepfakes Advertising attributes and brand credibility via hedonic and utilitarian value, which is underexploited empirically in an AI driven Advertising space. Thus, in order to address this empirical knowledge void, an extensive literature review was undertaken and four hypotheses were derived to explain the potential relationships. Quantitative methodology with a survey strategy was undertaken drawing an effective sample size of 229 young undergraduate consumers of Sri Lankan public universities. Furthermore, analysis was carried out using Smart partial least squares (PLS)-structural equation modelling. The study first finds a significant direct relationship between the deepfake Advertising, hedonic value and utilitarian value. It also finds significant relationships between hedonic value, utilitarian value and brand credibility. The findings shed the light on improving Advertising and marketing effectiveness through branding applications.},
  keywords={Surveys;Deepfakes;Analytical models;Brand management;Bibliographies;Generative adversarial networks;Mathematical models;deepfakes advertising;hedonic value;utilitarian value;brand credibility},
  doi={10.1109/SCSE61872.2024.10550666},
  ISSN={2613-8662},
  month={April},}@INPROCEEDINGS{10222379,
  author={Qi, Song and Shi, Wu and Ge, Guojing and Chang, Liang},
  booktitle={2023 IEEE International Conference on Image Processing (ICIP)}, 
  title={Degradation Conditioned GAN for Degradation Generalization of Face Restoration Models}, 
  year={2023},
  volume={},
  number={},
  pages={520-524},
  abstract={Face restoration models are usually trained on synthetic degraded data to output an image that matches the clean version of itself. Most previous methods use a single model to deal with all the degradation levels, resulting in a domain generalization problem. We explore the value of degradation information and propose a Degradation Conditioned GAN (DeCGAN). The architecture consists of modulated convolution, bias, and fusion modules, inspired by deblurring, denoising and super-resolution. The whole network can be modulated by the degradation levels to achieve delicate and precise restoration effects. Experiments are conducted on conventional and modulated face restoration tasks. DeCGAN can achieve more faithful restoration and better metrics (FID, LPIPS, etc.) than previous methods do. Moreover, our model performs well on real-world low-quality face images.},
  keywords={Degradation;Measurement;Convolution;Superresolution;Noise reduction;Generative adversarial networks;Data models;Face Restoration;Distribution Shift;Modulation Modules;GAN},
  doi={10.1109/ICIP49359.2023.10222379},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11095087,
  author={Liu, Yikun and Zhang, Yajie and Cai, Jiayin and Jiang, Xiaolong and Hu, Yao and Yao, Jiangchao and Wang, Yanfeng and Xie, Weidi},
  booktitle={2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={LamRA: Large Multimodal Model as Your Advanced Retrieval Assistant}, 
  year={2025},
  volume={},
  number={},
  pages={4015-4025},
  abstract={With the rapid advancement of multimodal information retrieval, increasingly complex retrieval tasks have emerged. Existing methods predominately rely on task-specific fine-tuning of vision-language models, often those trained with image-text contrastive learning. In this paper, we explore the possibility of re-purposing generative Large Multimodal Models (LMMs) for retrieval. This approach enables unifying all retrieval tasks under the same formulation and, more importantly, allows for extrapolation towards unseen retrieval tasks without additional training. Our contributions can be summarised in the following aspects: (i) We introduce LamRA, a versatile framework designed to empower LMMs with sophisticated retrieval and reranking capabilities. (ii) For retrieval, we adopt a two-stage training strategy comprising language-only pre-training and multimodal instruction tuning to progressively enhance LMM’s retrieval performance. (iii) For reranking, we employ joint training of both pointwise and listwise reranking, offering two distinct ways to further boost the retrieval performance. (iv) Extensive experiments underscore the efficacy of our method in handling more than ten retrieval tasks, demonstrating robust performance in both supervised and zero-shot settings, including scenarios involving previously unseen retrieval tasks. Project page: https://code-kunkun.github.io/LamRA/.},
  keywords={Training;Extrapolation;Computer vision;Contrastive learning;Information retrieval;Pattern recognition;Tuning},
  doi={10.1109/CVPR52734.2025.00380},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{10069761,
  author={Parri, Srihari and Kosana, Vishalteja and Teeparthi, Kiran},
  booktitle={2022 22nd National Power Systems Conference (NPSC)}, 
  title={A hybrid GAN based autoencoder approach with attention mechanism for wind speed prediction}, 
  year={2022},
  volume={},
  number={},
  pages={224-229},
  abstract={Accurate forecasting of wind speed is essential for the effective utilization of wind power. For forecasting algorithms to produce accurate results, high-dimensional input is necessary. The method of obtaining wind speed data, however, runs into a number of issues since data measurement equipment fails. Accurate imputation and effective feature extraction are required for precise wind speed forecasting (WSF). Thus, this paper proposed a hybrid wind speed prediction model consisting of a generative adversarial network (GAN), and an attention mechanism-based convolutional long short-term memory network autoencoder (AM-CLSTMAE). The GAN is used for the effective missing data imputation (MDI) of wind speed values based on the data distribution, and AM-CLSTMAE extracts the spatio-temporal characteristics to accurately predict the wind speed. The proposed model is evaluated using two test cases comprehensively for the MDI, and WSF. The 5-minute wind speed data for the two test cases is collected from the wind farms located in Leicester, and Portland. Different comparison models are used to evaluate the proposed model using various evaluation indices. The two test cases indicated that the proposed model achieved an improvement of 60%, and 63% in the MDI, 42%, and 40% in the WSF for two test cases, respectively.},
  keywords={Wind speed;Optimization methods;Wind farms;Predictive models;Wind power generation;Generative adversarial networks;Prediction algorithms;Wind speed;GAN;attention;forecasting;imputation},
  doi={10.1109/NPSC57038.2022.10069761},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10814607,
  author={Camerota, Chiara and Pappone, Lorenzo and Pecorella, Tommaso and Esposito, Flavio},
  booktitle={2024 20th International Conference on Network and Service Management (CNSM)}, 
  title={Addressing Data Security in IoT: Minimum Sample Size and Denoising Diffusion Models for Improved Malware Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Machine learning (ML) has emerged as a compelling approach to identify attacks in network traffic security. Existing malware detection strategies often concentrate on specific facets, such as efficient data collection, particular types of malware, or handling data scarcity. While valid, these strategies typically overlook the potential for minimizing sample size, focusing instead on data augmentation. This work introduces a novel method to determine the minimum sample size necessary to achieve a specified accuracy level, measured by the F1 score derived from the confusion matrix. We focus on TCP header traffic data transformed into images through flow-splitting techniques for multi-class traffic classification. In addition, we introduce a diffusion model to generate new synthetic traffic images and show that our method outperforms existing techniques in terms of stability and predictability. This study also compares the effectiveness of synthetic image augmentation using Generative Adversarial Networks (GANs) and Denoising Diffusion Probabilistic Models (DDPM) in improving image recognition and classification accuracy.},
  keywords={Accuracy;Noise reduction;Training data;Telecommunication traffic;Data collection;Generative adversarial networks;Diffusion models;Malware;Stability analysis;Synthetic data;malware detection;traffic classification;deep learning},
  doi={10.23919/CNSM62983.2024.10814607},
  ISSN={2165-963X},
  month={Oct},}@INPROCEEDINGS{10788188,
  author={Sha, Liao},
  booktitle={2024 International Conference on Computers, Information Processing and Advanced Education (CIPAE)}, 
  title={Algorithm-Driven Brand Design Strategy and Implementation Path Research}, 
  year={2024},
  volume={},
  number={},
  pages={436-441},
  abstract={This paper systematically expounds the implementation path and case application of algorithm-driven brand design. Firstly, it introduces the process of establishing a multi-channel data collection mechanism to obtain massive user behavior data and preprocess it to form a high-quality dataset. Secondly, it illustrates the key technologies for designing generation and optimization based on preprocessed data, such as dual-path convolutional neural networks, generative adversarial networks, etc. Furthermore, it elaborates on the method of integrating algorithms with existing design processes to achieve human-machine collaboration and enhance decision-making efficiency. Finally, it discusses the importance of continuously optimizing algorithm models through “online learning” mechanisms to ensure their up-to-dateness. The paper inserts multiple real cases and supplements them with chart data, comprehensively demonstrating the innovative applications of algorithm-driven brand design in multiple fields. Overall, algorithms are reshaping a new paradigm of brand design, providing unprecedented personalized experiences for consumers.},
  keywords={Reviews;Human-machine systems;Force;Education;Decision making;Information processing;Generative adversarial networks;Data models;Convolutional neural networks;Optimization;algorithm-driven design;brand design;data collection;algorithm model;human-machine collaboration;online learning},
  doi={10.1109/CIPAE64326.2024.00085},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10546004,
  author={Qu, Hedi and Liu, Deyuan and Yang, Huichao and Fu, Yune and Zhu, Ni},
  booktitle={2024 IEEE 2nd International Conference on Control, Electronics and Computer Technology (ICCECT)}, 
  title={Research Algorithm for Neural Network Computing Based on Chip Acceleration}, 
  year={2024},
  volume={},
  number={},
  pages={794-798},
  abstract={With the rapid development of artificial intelligence technology, neural networks have become a core component in machine learning and deep learning. Neural networks simulate the connections between neurons in the human brain and can process complex data for pattern recognition. However, to deploy and run neural networks in practical applications, it is necessary to rely on the support of high-performance chips. Therefore, the design of neural network architecture has a significant impact on chip design. The architecture of neural networks determines characteristics such as computational complexity, number of parameters, and memory usage, which directly affect key indicators such as power consumption, area, and performance of chips. In various practical application scenarios, deep convolutional neural networks have been widely used. However, trained model parameters are usually saved in floating-point format, which leads to high computational complexity, high memory consumption, and long inference time. Therefore, deploying high-precision models on edge devices with limited computing and memory resources becomes difficult. To address this issue, this study proposes an innovative dynamic pruning model algorithm. Unlike traditional neural network pruning algorithms that mainly prune fixed models after offline training, dynamic pruning algorithms prune by dynamically adjusting the network structure according to real-time requirements, which has a certain degree of innovation. This algorithm can automatically prune redundant connections and nodes based on the characteristics of the current task and the limitations of computing resources, thereby reducing computation and memory usage. Through dynamic pruning, high-precision models can be effectively deployed on edge devices, improving computational efficiency and memory utilization.},
  keywords={Training;Technological innovation;Heuristic algorithms;Computational modeling;Memory management;Inference algorithms;Real-time systems;parameter quantification;deep learning;acceleration chip},
  doi={10.1109/ICCECT60629.2024.10546004},
  ISSN={},
  month={April},}@INPROCEEDINGS{10908265,
  author={Hoang Hao, Truong Thi and Hoang Hao, Truong Thi and Duong, Nguyen Thai and Duong, Nguyen Thai and Khoa, Nghi Hoang and Khoa, Nghi Hoang and Pham, Van-Hau and Pham, Van-Hau and Duy, Phan The and Duy, Phan The},
  booktitle={2024 International Conference on Advanced Technologies for Communications (ATC)}, 
  title={A Trustworthy and Robust Model for Mutated Malware Detection Via Explainable Ai and GANs}, 
  year={2024},
  volume={},
  number={},
  pages={945-950},
  abstract={In recent years, researchers have continuously im-proved malware detection systems and successfully integrated machine learning (ML) and deep learning (DL) models into the detection and classification of malware samples. However, along with these improvements, adversarial attack techniques have also become more sophisticated. To combat the ever-evolving adversarial attack forms, many studies have been proposed and implemented. Adversarial training is one of the most common approaches. While it has been experimentally shown to mitigate some adversarial attacks, its effectiveness remains limited, hindering user confidence in its reliability. In this paper, we introduce RMMD, a robust model for detecting mutated malware, including packed and adversarial variants. This approach leverages Explainable AI (XAI) and Generative Adversarial Networks (GANs) in conjunction with adversarial training techniques. Our proposed model, RMMD, achieves a 90% accuracy rate across all models, indicating a significant leap forward in detecting packed and adversarial malware.},
  keywords={Training;Deep learning;Accuracy;Explainable AI;Generative adversarial networks;Malware;Reliability;Deep Learning;Explainable AI;PE Windows;Malware},
  doi={10.1109/ATC63255.2024.10908265},
  ISSN={2162-1039},
  month={Oct},}@ARTICLE{10234399,
  author={Chen, Junxin and Wang, Wei and Fang, Bo and Liu, Yu and Yu, Keping and Leung, Victor C. M. and Hu, Xiping},
  journal={IEEE Journal on Selected Areas in Communications}, 
  title={Digital Twin Empowered Wireless Healthcare Monitoring for Smart Home}, 
  year={2023},
  volume={41},
  number={11},
  pages={3662-3676},
  abstract={The dramatic progresses of wireless technologies and wearable devices have significantly promoted the development and popularity of smart home, while digital twin (DT) emerges as a game changer benefiting from its enhanced capabilities of visualization and interaction. The DT is able to build a realtime and continuous visual replica of a physical object or process, and to provide realtime monitoring, anomaly prediction, smart interaction, and lifecycle management. This paper presents a DT model to empower healthcare monitoring in the smart home with the goals of graphical monitoring, healthcare prediction, and intelligent control. High fidelity DT of the house and its equipments is created for visualized monitoring, and two suites of devices are deployed for continuously acquiring the users’ electrocardiograph (ECG) waves and the WiFi signals in the house. Two intelligent algorithms are then developed to perform fall detection from WiFi signals and to screen atrial fibrillation from ECG waves collected by wearable devices. Experimental results well validate the proposed model’s effectiveness for smart home monitoring, and the advantages of the developed smart algorithms for healthcare prediction over counterparts.},
  keywords={Monitoring;Medical services;Smart homes;Cloud computing;Biomedical monitoring;Digital twins;Visualization;Digital twin;healthcare monitoring;smart home;artificial intelligence},
  doi={10.1109/JSAC.2023.3310097},
  ISSN={1558-0008},
  month={Nov},}@INPROCEEDINGS{10574658,
  author={Balasubramanian, Prasasthy and Seby, Justin and Kostakos, Panos},
  booktitle={2024 3rd International Conference on Artificial Intelligence For Internet of Things (AIIoT)}, 
  title={CYGENT: A cybersecurity conversational agent with log summarization powered by GPT-3}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In response to the escalating cyber-attacks in the modern IT and IoT landscape, we developed CYGENT, a conversational agent framework powered by GPT-3.5 turbo model, designed to aid system administrators in ensuring optimal performance and uninterrupted resource availability. This study focuses on fine-tuning GPT-3 models for cybersecurity tasks, including conversational AI and generative AI tailored specifically for cybersecurity operations. CYGENT assists users by providing cybersecurity information, analyzing and summarizing uploaded log files, detecting specific events, and delivering essential instructions. The conversational agent was developed based on the GPT-3.5 turbo model. We fine-tuned and validated summarizer models (GPT3) using manually generated data points. Using this approach, we achieved a BERTscore of over 97%, indicating GPT-3’s enhanced capability in summarizing log files into human-readable formats and providing necessary information to users. Furthermore, we conducted a comparative analysis of GPT-3 models with other Large Language Models (LLMs), including CodeT5-small, CodeT5-base, and CodeT5-base-multi-sum, with the objective of analyzing log analysis techniques. Our analysis consistently demonstrated that Davinci (GPT-3) model outperformed all other LLMs, showcasing higher performance. These findings are crucial for improving human comprehension of logs, particularly in light of the increasing numbers of IoT devices. Additionally, our research suggests that the CodeT5-base-multi-sum model exhibits comparable performance to Davinci to some extent in summarizing logs, indicating its potential as an offline model for this task.},
  keywords={Performance evaluation;Analytical models;Generative AI;Data models;Internet of Things;Task analysis;Cyberattack;AI chatbot;Cybersecurity;GPT-3;CodeT5;Conversational AI;Generative AI;Log summarizing},
  doi={10.1109/AIIoT58432.2024.10574658},
  ISSN={},
  month={May},}@INPROCEEDINGS{11108844,
  author={Wang, Xiaoyin and Xiao, Yuting},
  booktitle={2025 IEEE 5th International Conference on Software Engineering and Artificial Intelligence (SEAI)}, 
  title={An Effective Framework for Cross-Site Scripting Payload Generation}, 
  year={2025},
  volume={},
  number={},
  pages={253-258},
  abstract={In the field of cybersecurity, machine learning techniques are being increasingly utilized for cross-site scripting (XSS) vulnerability detection. These techniques playa crucial role in facilitating the identification process and reducing the heavy reliance on human analytics. This paper puts forward a novel approach for generating the payload of cross-site attack scripts. Initially, datasets are gathered for model training, and positional coding is incorporated into the input data to enhance the model's understanding of the structure. The generative AI model conducts an in-depth analysis of the dataset and then further combines the syntactic features of cross-site scripting with common bypass methods to formulate adaptive mutation strategies. Based on the attack response results, the model parameters are updated, and the payload generation process is iteratively optimized. The experimental results demonstrate that this method can generate highly deceptive malicious scripts with a notably high success rate.},
  keywords={Training;Adaptation models;Generative AI;Cross-site scripting;Machine learning;Syntactics;Data models;Vectors;Payloads;Software engineering;network security;Machine Learning;cross-site scripting;generative AI Model;XSS Payload Generation},
  doi={10.1109/SEAI65851.2025.11108844},
  ISSN={},
  month={June},}@INPROCEEDINGS{10947978,
  author={Singh, Deepanshu and Singh, Prabhdeep and Bhandari, Rahul},
  booktitle={2024 International Conference on Artificial Intelligence and Emerging Technology (Global AI Summit)}, 
  title={A Comprehensive Review of Deepfake Detection In Advanced Neural Network Architectures and Deep Learning Strategies}, 
  year={2024},
  volume={},
  number={},
  pages={1147-1152},
  abstract={The proliferation of deepfakes, facilitated by advancements in machine learning and artificial intelligence, poses a significant challenge to online security and information integrity. This study reviews current deep fake detection techniques, focusing on methodologies for identifying manipulated content in images, audio, and video. 17 articles were selected for this study using Prisma guidelines. The function of sophisticated machine learning models, such as Long Short-Term Memory (LSTM) networks and (CNNs), is highlighted for automating detection processes. The review also examines notable algorithms and datasets, including FaceForensics++, MesoNet, and XceptionNet, and their effectiveness in enhancing detection accuracy. A case study using frame extraction and resizing techniques demonstrates a detection accuracy of 62%, with precision at 61 %, recall at 63%, and an F1 score of 62% is also included. The findings underscore the need for ongoing refinement and adaptation of detection systems to counteract the evolving nature of deepfake technologies. The study providing thorough overview of the state-of-the-art in deepfake detection, offering insights into effective methodologies and future research directions.},
  keywords={Deepfakes;Accuracy;Machine learning algorithms;Reviews;Neural networks;Focusing;Security;Long short term memory;Information integrity;Guidelines;CNNs;Generative adversarial networks(GAN);Deepfake detection;DL;Misinformation detection;Video analysis;Spatial-temporal features;Machine learning;Neural network fusion;LSTMs;Introduction;Digital media integrity},
  doi={10.1109/GlobalAISummit62156.2024.10947978},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11030042,
  author={Vonderhaar, Lynn and Elvira, Timothy and Ochoa, Omar},
  booktitle={2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN)}, 
  title={Generating and Verifying Synthetic Datasets with Requirements Engineering}, 
  year={2025},
  volume={},
  number={},
  pages={212-221},
  abstract={With the rise of generative Artificial Intelligence (AI), Machine Learning (ML) developers are becoming less reliant on real data to train their models. Data insufficiency can be resolved by using synthetic data generated by a diffusion model. However, beyond ad hoc interpretation of a generative model's outputs, there is little assurance of the synthetic data's adherence to the data requirement specifications. Adherence of synthetic data to these specifications is critical given that they describe desired downstream model behavior. Therefore, without proper verification methods for this synthetic data, ML developers cannot be confident in the behavior of the downstream model. This paper presents a verification method for generating synthetic data to train downstream ML models by prompting the generative model using requirement specifications and tracing elements of the output back to the prompt. The purpose of this research is to embed requirements engineering into the data augmentation process to increase the rigor and acceptance of these generative AI models to train downstream ML models. This improves the transparency of the data augmentation process, potentially increasing the trust of stakeholders in the generated data, and the use of generative models for data augmentation in a wider range of applications. This also provides a more traditional approach to synthetic data generation to guide ML developers in augmenting their datasets, thus incorporating a more rigorous engineering process into the ML development, i.e., ML Engineering.},
  keywords={Training;Reviews;Generative AI;Diffusion models;Data augmentation;Data models;Requirements engineering;Stakeholders;Synthetic data;Software engineering;machine learning;synthetic data;verification;data augmentation;machine learning engineering;diffusion model},
  doi={10.1109/CAIN66642.2025.00032},
  ISSN={},
  month={April},}@INPROCEEDINGS{10762585,
  author={Brar, Jiwan Harmit Singh and Setioko, Wahyu},
  booktitle={2024 International Seminar on Application for Technology of Information and Communication (iSemantic)}, 
  title={ChatGPT and Local Wisdom: An Exploratory Study of AI-assisted Ethnoscience Lesson Plan}, 
  year={2024},
  volume={},
  number={},
  pages={294-299},
  abstract={ChatGPT is an artificial intelligence generative tool that has many uses, especially in the field of writing. In education, technology can be applied in many ways, one of which is in creating a good learning design. This research aims to explore the advantages and limitations of ChatGPT in designing ethnoscience-based learning and how this technology can integrate local wisdom in the science curriculum. Using a qualitative approach, this research examines how ChatGPT can assist teachers in creating engaging and meaningful lesson designs for students, while maintaining local and cultural excellence. The results show that ChatGPT has great potential in supporting character education and learning quality through the integration of technology and local wisdom. However, it requires a deep understanding of local culture and the ability to integrate it with the existing curriculum.},
  keywords={Seminars;Education;Writing;Chatbots;Complexity theory;Cultural differences;Global communication;Artificial intelligence;chatgpt;ethnoscience;science education;artificial intelligence},
  doi={10.1109/iSemantic63362.2024.10762585},
  ISSN={},
  month={Sep.},}@ARTICLE{9670681,
  author={Wei, Wei and Li, Daheng and Wang, Peng and Li, Yiming and Li, Wanyi and Luo, Yongkang and Zhong, Jun},
  journal={IEEE Robotics and Automation Letters}, 
  title={DVGG: Deep Variational Grasp Generation for Dextrous Manipulation}, 
  year={2022},
  volume={7},
  number={2},
  pages={1659-1666},
  abstract={Grasping with anthropomorphic robotic hands involves much more hand-object interactions compared to parallel-jaw grippers. Modeling hand-object interactions is essential to the study of multi-finger hand dextrous manipulation. This work presents DVGG, an efficient grasp generation network that takes single-view observation as input and predicts high-quality grasp configurations for unknown objects. In general, our generative model consists of three components: 1) Point cloud completion for the target object based on the partial observation; 2) Diverse sets of grasps generation given the complete point cloud; 3) Iterative grasp pose refinement for physically plausible grasp optimization. To train our model, we build a large-scale grasping dataset that contains about 300 common object models with 1.5 M annotated grasps in simulation. Experiments in simulation show that our model can predict robust grasp poses with a wide variety and high success rate. Real robot platform experiments demonstrate that the model trained on our dataset performs well in the real world. Remarkably, our method achieves a grasp success rate of 70.7% for novel objects in the real robot platform, which is a significant improvement over the baseline methods.},
  keywords={Point cloud compression;Grasping;Robots;Grippers;Generators;Predictive models;Feature extraction;Deep learning in grasping and manipulation;multifingered hands;computer vision for automation;point cloud completion;iterative refinement},
  doi={10.1109/LRA.2022.3140424},
  ISSN={2377-3766},
  month={April},}@INBOOK{10953233,
  author={Lopez-Lira, Alejandro},
  booktitle={The Predictive Edge: Outsmart the Market using Generative AI and ChatGPT in Financial Forecasting}, 
  title={Large Language Models: A Game Changer}, 
  year={2024},
  volume={},
  number={},
  pages={51-69},
  abstract={Summary <p>Large language models (LLMs) are the most sophisticated form of artificial intelligence (AI) we have so far. As LLMs become more advanced, their disruptive impact on quantitative analysis and algorithmic trading seems imminent. This chapter explores the transformative role of large language models. The first section, natural language processing (NLP), lays the foundation by explaining how computers understand and process human language. The second section, generative AI, expands on the capabilities of AI systems to create new, original content, a leap forward from traditional, rule&#x2010;based approaches. Finally, the third section, LLMs, focuses on these sophisticated models at the forefront of NLP and generative AI. LLMs like GPT&#x2010;3 have revolutionized the field by demonstrating an unprecedented ability to generate human&#x2010;like text, pushing the boundaries of what is possible in machine&#x2010;generated language and content creation.</p>},
  keywords={Natural language processing;Large language models;Tokenization;Translation;Syntactics;Linguistics;Investment;Generative AI;Computers;Chatbots},
  doi={10.1002/9781394308286.ch3},
  ISSN={},
  publisher={Wiley},
  isbn={9781394242733},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10953233},}@ARTICLE{1608037,
  author={Moriyama, T. and Kanade, T. and Jing Xiao and Cohn, J.F.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Meticulously detailed eye region model and its application to analysis of facial images}, 
  year={2006},
  volume={28},
  number={5},
  pages={738-752},
  abstract={We propose a system that is capable of detailed analysis of eye region images in terms of the position of the iris, degree of eyelid opening, and the shape, complexity, and texture of the eyelids. The system uses a generative eye region model that parameterizes the fine structure and motion of an eye. The structure parameters represent structural individuality of the eye, including the size and color of the iris, the width, boldness, and complexity of the eyelids, the width of the bulge below the eye, and the width of the illumination reflection on the bulge. The motion parameters represent movement of the eye, including the up-down position of the upper and lower eyelids and the 2D position of the iris. The system first registers the eye model to the input in a particular frame and individualizes it by adjusting the structure parameters. The system then tracks motion of the eye by estimating the motion parameters across the entire image sequence. Combined with image stabilization to compensate for appearance changes due to head motion, the system achieves accurate registration and motion recovery of eyes.},
  keywords={Image analysis;Eyelids;Iris;Image texture analysis;Shape;Lighting;Reflection;Tracking;Motion estimation;Parameter estimation;Computer vision;facial image analysis;facial expression analysis;generative eye region model;motion tracking;texture modeling;gradient descent.},
  doi={10.1109/TPAMI.2006.98},
  ISSN={1939-3539},
  month={May},}@ARTICLE{1512056,
  author={Todorovic, S. and Nechyba, M.C.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Dynamic trees for unsupervised segmentation and matching of image regions}, 
  year={2005},
  volume={27},
  number={11},
  pages={1762-1777},
  abstract={We present a probabilistic framework namely, multiscale generative models known as dynamic trees (DT), for unsupervised image segmentation and subsequent matching of segmented regions in a given set of images. Beyond these novel applications of DTs, we propose important additions for this modeling paradigm. First, we introduce a novel DT architecture, where multilayered observable data are incorporated at all scales of the model. Second, we derive a novel probabilistic inference algorithm for DTs, structured variational approximation (SVA), which explicitly accounts for the statistical dependence of node positions and model structure in the approximate posterior distribution, thereby relaxing poorly justified independence assumptions in previous work. Finally, we propose a similarity measure for matching dynamic-tree models, representing segmented image regions, across images. Our results for several data sets show that DTs are capable of capturing important component-subcomponent relationships among objects and their parts, and that DTs perform well in segmenting images into plausible pixel clusters. We demonstrate the significantly improved properties of the SVA algorithm, both in terms of substantially faster convergence rates and larger approximate posteriors for the inferred models, when compared with competing inference algorithms. Furthermore, results on unsupervised object recognition demonstrate the viability of the proposed similarity measure for matching dynamic-structure statistical models.},
  keywords={Image segmentation;Inference algorithms;Pixel;Object recognition;Clustering algorithms;Bayesian methods;Object detection;Approximation algorithms;Convergence;Image matching;Index Terms- Generative models;Bayesian networks;dynamic trees;variational inference;image segmentation;image matching;object recognition.},
  doi={10.1109/TPAMI.2005.219},
  ISSN={1939-3539},
  month={Nov},}@ARTICLE{10897745,
  author={Iwata, Kazunori},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Mixture Density Function Estimation in Shape Clustering}, 
  year={2025},
  volume={6},
  number={8},
  pages={2178-2192},
  abstract={Recent developments in measurement tools have made it easier to obtain shape data, a collection of point coordinates in vector space that are meaningful when some of them are gathered together. As a result, clustering of shape data becomes increasingly important. However, few studies still perform applicable clustering in various cases because some studies rely on their specific shape representations. Thus, we apply a simple and widely recognized representation and generative model to shape. A configuration matrix of the point coordinates is used for the representation, and it is the simplest and most well-accepted representation in conventional shape analysis. As a generative model, we consider the mixture density function, a well-known model in statistics for expressing a population density function, which is a linear combination of subpopulation density functions. The aim of this article is to present a mixture density-based model that will be useful for clustering shape data. The clustering of shapes involves estimating the parameters of the model, and this estimation is derived using an EM algorithm based on the model. As examples of promising shape-data applications, the computational analyses of ape skulls, American football formations, and baseball pitches were performed. In addition, we evaluated the performance of the EM algorithm by comparing it with other typical clustering methods. The theoretical results not only contribute to statistical estimation for shape data but also extend the clustering of nonvector shape data. The experimental results show that the derived EM algorithm performs well in shape clustering.},
  keywords={Shape;Density functional theory;Clustering algorithms;Artificial intelligence;Sports;Data models;Shape measurement;Maximum likelihood estimation;Clustering methods;Mixture models;Clustering;expectation–maximization algorithm;maximum likelihood estimation;mixture density function},
  doi={10.1109/TAI.2025.3543815},
  ISSN={2691-4581},
  month={Aug},}@ARTICLE{11124548,
  author={Jiang, Yifan and Lemaréchal, Yannick and Bafaro, Josée and Abi-Rjeile, Jessica and Joubert, Philippe and Després, Philippe and Manem, Venkata},
  journal={IEEE Transactions on Biomedical Engineering}, 
  title={Lung-DDPM: Semantic Layout-guided Diffusion Models for Thoracic CT Image Synthesis}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={With the rapid development of artificial intelligence (AI), AI-assisted medical imaging analysis demonstrates remarkable performance in early lung cancer screening. However, the costly annotation process and privacy concerns limit the construction of large-scale medical datasets, hampering the further application of AI in healthcare. To address the data scarcity in lung cancer screening, we propose Lung-DDPM, a thoracic CT image synthesis approach that effectively generates high-fidelity 3D synthetic CT images, which prove helpful in downstream lung nodule segmentation tasks. Our method is based on semantic layout-guided denoising diffusion probabilistic models (DDPM), enabling anatomically reasonable, seamless, and consistent sample generation even from incomplete semantic layouts. Our results suggest that the proposed method outperforms other state-of-the-art (SOTA) generative models in image quality evaluation and downstream lung nodule segmentation tasks. Specifically, Lung-DDPM achieved superior performance on our large validation cohort, with a Fréchet inception distance (FID) of 0.0047, maximum mean discrepancy (MMD) of 0.0070, and mean squared error (MSE) of 0.0024. These results were 7.4×, 3.1×, and 29.5× better than the second-best competitors, respectively. Furthermore, the lung nodule segmentation model, trained on a dataset combining real and Lung-DDPM-generated synthetic samples, attained a Dice Coefficient (Dice) of 0.3914 and sensitivity of 0.4393. This represents 8.8% and 18.6% improvements in Dice and sensitivity compared to the model trained solely on real samples. The experimental results highlight Lung-DDPM's potential for a broader range of medical imaging applications, such as general tumor segmentation, cancer survival estimation, and risk prediction. The code and pretrained models are available at https://github.com/Manem-Lab/Lung-DDPM/.},
  keywords={Lungs;Computed tomography;Semantics;Biomedical imaging;Layout;Image synthesis;Annotations;Training;Three-dimensional displays;Lung cancer;Thoracic computed tomography;denoising diffusion probabilistic models;image synthesis;lung nodule segmentation},
  doi={10.1109/TBME.2025.3599011},
  ISSN={1558-2531},
  month={},}@INPROCEEDINGS{9092227,
  author={Malolan, Badhrinarayan and Parekh, Ankit and Kazi, Faruk},
  booktitle={2020 3rd International Conference on Information and Computer Technologies (ICICT)}, 
  title={Explainable Deep-Fake Detection Using Visual Interpretability Methods}, 
  year={2020},
  volume={},
  number={},
  pages={289-293},
  abstract={Deep-Fakes have sparked concerns throughout the world because of their potentially explosive consequences. A dystopian future where all forms of digital media are potentially compromised and public trust in Government is scarce doesn't seem far off. If not dealt with the requisite seriousness, the situation could easily spiral out of control. Current methods of Deep-Fake detection aim to accurately solve the issue at hand but may fail to convince a lay-person of its reliability and thus, lack the trust of the general public. Since the fundamental issue revolves around earning the trust of human agents, the construction of interpretable and also easily explainable models is imperative. We propose a framework to detect these Deep-Fake videos using a Deep Learning Approach: we have trained a Convolutional Neural Network architecture on a database of extracted faces from FaceForensics' DeepFakeDetection Dataset. Furthermore, we have tested the model on various Explainable AI techniques such as LRP and LIME to provide crisp visualizations of the salient regions of the image focused on by the model. The prospective and elusive goal is to localize the facial manipulations caused by Faceswaps. We hope to use this approach to build trust between AI and Human agents and to demonstrate the applicability of XAI in various real-life scenarios.},
  keywords={Videos;Neurons;Predictive models;Machine learning;Feature extraction;Visualization;Data models;deep-fakes;deep-fake detection;faceswap;interpretability;explainable AI (XAI);LRP;LIME},
  doi={10.1109/ICICT50521.2020.00051},
  ISSN={},
  month={March},}@INPROCEEDINGS{9668489,
  author={BOUIJIJ, Habiba and BERQIA, Amine},
  booktitle={2021 4th International Symposium on Advanced Electrical and Communication Technologies (ISAECT)}, 
  title={Machine Learning Algorithms Evaluation for Phishing URLs Classification}, 
  year={2021},
  volume={},
  number={},
  pages={01-05},
  abstract={Phishing URL is a type of cyberattack, based on falsified URLs. The number of phishing URL attacks continues to increase despite cybersecurity efforts. According to the Anti-Phishing Working Group (APWG), the number of phishing websites observed in 2020 is 1 520 832, doubling over the course of a year. Various algorithms, techniques and methods can be used to build models for phishing URL detection and classification. From our reading, we observed that Machine Learning (ML) is one of the recent approaches used to detect and classify phishing URL in an efficient and proactive way. In this paper, we evaluate eleven of the most adopted ML algorithms such as Decision Tree (DT), Nearest Neighbours (KNN), Gradient Boosting (GB), Logistic Regression (LR), Naïve Bayes (NB), Random Forest (RF), Support Vector Machines (SVM), Neural Network (NN), Ex-tra_Tree (ET), Ada_Boost (AB) and Bagging (B). To do that, we compute detection accuracy metric for each algorithm and we use lexical analysis to extract the URL features.},
  keywords={Uniform resource locators;Support vector machines;Measurement;Radio frequency;Machine learning algorithms;Phishing;Feature extraction;Machine Learning;cyberattack;cybersecurity;Phishing;Phishing-URL;lexical analysis;features;accuracy metric},
  doi={10.1109/ISAECT53699.2021.9668489},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{675226,
  author={Altmann, J. and Varaiya, P.},
  booktitle={1998 Sixth International Workshop on Quality of Service (IWQoS'98) (Cat. No.98EX136)}, 
  title={INDEX project: user support for buying QoS with regard to user's preferences}, 
  year={1998},
  volume={},
  number={},
  pages={101-104},
  abstract={Shows that the selection of a quality of service (QoS) becomes a difficult task for the user when he is faced with different prices for different QoSs. Even if the user is only facing a best-effort service, he might be unable to determine the minimal-cost selection of bandwidth. This article shows that the user needs support to get the best service regarding his personal situation. The mechanisms we use for such a personalized support tool (intelligent agent) are described. In addition, the concept of a QoS architecture focusing on this problem is developed in order to show how the agent fits into a QoS framework. The context where this investigation takes place is the INDEX (INternet Demand EXperiment) project, a testbed for examining the user's demand and willingness to pay for different QoSs.},
  keywords={Web and internet services;Costs;Bandwidth;Pricing;Quality of service;High-speed networks;Intelligent agent;Context-aware services;IP networks;Testing},
  doi={10.1109/IWQOS.1998.675226},
  ISSN={},
  month={May},}@INPROCEEDINGS{9813960,
  author={Sugunaraj, Niroop and Ramchandra, Akshay Ram and Ranganathan, Prakash},
  booktitle={2022 IEEE International Conference on Electro Information Technology (eIT)}, 
  title={Cyber Fraud Economics, Scam Types, and Potential Measures to Protect U.S. Seniors: A Short Review}, 
  year={2022},
  volume={},
  number={},
  pages={623-627},
  abstract={Cyber fraud has become increasingly common as it can be easily carried out with relative ease through multiple mediums. Particularly, the elderly population aged 60 and above seniors, are more vulnerable to such fraud/scams as they generally lack the know-how for such fraudulent activities. This paper briefly addresses the various types of fraud/scams, apparent early warning signs, and potential preventive tips before falling victim of cyber fraud. Additionally, sophisticated scam methods are also highlighted, and resources available to report/inform the general public is documented.},
  keywords={Economics;Phishing;Conferences;Sociology;Electronic mail;Statistics;Older adults;cyber fraud;exploitation;scams;resources},
  doi={10.1109/eIT53891.2022.9813960},
  ISSN={2154-0373},
  month={May},}@INPROCEEDINGS{9035236,
  author={Nassar, Mohamed and Itani, Abdallah and Karout, Mahmoud and El Baba, Mohamad and Kaakaji, Omar Al Samman},
  booktitle={2019 IEEE/ACS 16th International Conference on Computer Systems and Applications (AICCSA)}, 
  title={Shoplifting Smart Stores using Adversarial Machine Learning}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={Smart stores cashier-less technology is partially based on camera-equipped object detection systems. Powerful machine learning algorithms are deployed at the back-end for classification. In this paper, we explore the usage of adversarial machine learning techniques to deceive the smart stores' classifiers. In particular, we experiment with printable adversarial patches and target making an expensive item classified as a cheaper one. By sticking patches to the objects and lifting them, a customer can make her customized discounts and alter the machine learning prediction. We discuss experiments, results, and possible countermeasures.},
  keywords={Adversarial machine learning;Neural networks;Machine learning algorithms;Deep learning;Cameras;Training;Smart Stores;Adversarial Machine Learning;Adversarial Patch;Deep Learning;Classification;Convolutional Neural Networks;Object Recognition},
  doi={10.1109/AICCSA47632.2019.9035236},
  ISSN={2161-5330},
  month={Nov},}@INPROCEEDINGS{10685766,
  author={Chan, Venus and Tang, William Ko-Wai},
  booktitle={2024 International Symposium on Educational Technology (ISET)}, 
  title={GPT and Translation: A Systematic Review}, 
  year={2024},
  volume={},
  number={},
  pages={59-63},
  abstract={Despite the growing use of GPT for translation, little research has analyzed studies on GPT and translation. This paper aims to provide a systematic literature review to explore the overall trend and summarize the major benefits and limitations of using GPT for translation based on 16 reviewed papers. The results demonstrate that there has been a significant increase in the number of publications, particularly in the field of translation quality of the European languages. Most studies used a quantitative method, and the findings mostly suggest that GPT-generated translations are on par with human translations and perform better than neutral machine translation outputs. GPT can accurately translate cultural texts, complex structures, and advanced linguistic features, such as poetry, humor, and pun. It is also found that GPT can be effectively used not only for translation but also for post-editing and translation evaluation, leading to new challenges and ethical concerns. This research highlights the changing roles of the key stakeholders and concludes with some direction for future studies.},
  keywords={Training;Ethics;Plagiarism;Europe;Linguistics;Stakeholders;Machine translation;AI;ChatGPT;GPT;translation;neural machine translation (NMT)},
  doi={10.1109/ISET61814.2024.00021},
  ISSN={2766-2144},
  month={July},}@INPROCEEDINGS{9175685,
  author={Chun, Ji Ye and Sendi, Mohammad S. E. and Sui, Jing and Zhi, Dongmei and Calhoun, Vince D.},
  booktitle={2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)}, 
  title={Visualizing Functional Network Connectivity Difference between Healthy Control and Major Depressive Disorder Using an Explainable Machine-learning Method}, 
  year={2020},
  volume={},
  number={},
  pages={1424-1427},
  abstract={Major depressive disorder (MDD) is a complex mental disorder characterized by a persistent sad feeling and depressed mood. Recent studies reported differences between healthy control (HC) and MDD by looking to brain networks including default mode and cognitive control networks. More recently there has been interest in studying the brain using advanced machine learning-based classification approaches. However, interpreting the model used in the classification between MDD and HC has not been explored yet. In the current study, we classified MDD from HC by estimating whole-brain connectivity using several classification methods including support vector machine, random forest, XGBoost, and convolutional neural network. In addition, we leveraged the SHapley Additive exPlanations (SHAP) approach as a feature learning method to model the difference between these two groups. We found a consistent result among all classification method in regard of the classification accuracy and feature learning. Also, we highlighted the role of other brain networks particularly visual and sensory motor network in the classification between MDD and HC subjects.},
  keywords={Radio frequency;Support vector machines;Visualization;Functional magnetic resonance imaging;Machine learning;Hospitals;Brain modeling},
  doi={10.1109/EMBC44109.2020.9175685},
  ISSN={2694-0604},
  month={July},}@INPROCEEDINGS{9953662,
  author={Espinoza, Luis and Carreño, Angel and Vinces, Leonardo},
  booktitle={2022 Congreso Internacional de Innovación y Tendencias en Ingeniería (CONIITI)}, 
  title={Development of a tray transplanting machine using a matrix placement process}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={Manual transplanting of small blueberry seedlings from tray to tray is a slow and low-production activity because it requires previously trained or specialized people for this labor. In Perú, the transplanting machines have not been very well received by the farming industry, because they do not ensure the grip of all the seedlings and represent a high investment. The objective of this project was to develop a tray-to-tray blueberry seedling transplanter to include a gripper matrix system, which was responsible for increasing the number of seedlings transplanted by displacement. The need to treat small seedlings with the proper care was taken into consideration, which is why it was decided to include a pneumatic thrust system prior to extraction, in order to decrease mechanical stress on the seedling as well. This system included the use of air pressure injected by nozzles directed to the lower structure of the seedling, so as to avoid any damage to it.},
  keywords={Vibrations;Force;Process control;Manuals;Organ transplantation;Clamps;Printers;Transplanter of vegetables;seedling trasplanter;trasplantadora de bandejas;CNC;3D printer},
  doi={10.1109/CONIITI57704.2022.9953662},
  ISSN={2539-4320},
  month={Oct},}@INPROCEEDINGS{10441026,
  author={Mahmud, Faysal and Abdullah, Yusha and Islam, Minhajul and Aziz, Tahsin},
  booktitle={2023 26th International Conference on Computer and Information Technology (ICCIT)}, 
  title={Unmasking Deepfake Faces from Videos Using An Explainable Cost-Sensitive Deep Learning Approach}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Deepfake technology is widely used, which has led to serious worries about the authenticity of digital media, making the need for trustworthy deepfake face recognition techniques more urgent than ever. This study employs a resource-effective and transparent cost-sensitive deep learning method to effectively detect deepfake faces in videos. To create a reliable deepfake detection system, four pre-trained Convolutional Neural Network (CNN) models: XceptionNet, InceptionResNetV2, EfficientNetV2S, and EfficientNetV2M were used. FaceForensics++ and CelebDf-V2 as benchmark datasets were used to assess the performance of our method. To efficiently process video data, key frame extraction was used as a feature extraction technique. Our main contribution is to show the model’s adaptability and effectiveness in correctly identifying deepfake faces in videos. Furthermore, a cost-sensitive neural network method was applied to solve the dataset imbalance issue that arises frequently in deepfake detection. The XceptionNet model on the CelebDf-V2 dataset gave the proposed methodology a 98% accuracy, which was the highest possible whereas, the InceptionResNetV2 model, achieves an accuracy of 94% on the FaceForensics++ dataset. Source Code: https://github.com/Faysal-MD/Unmasking-Deepfake-Faces-from-Videos-An-Explainable-Cost-Sensitive-Deep-Learning-Approach-IEEE2023},
  keywords={Deep learning;Deepfakes;Adaptation models;Face recognition;Computational modeling;Feature extraction;Convolutional neural networks;Deepfake video;Keyframe;Explainable AI (XAI);Cost-sensitive;Face Detection;CelebDf;FaceForensics++;CNN},
  doi={10.1109/ICCIT60459.2023.10441026},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10522260,
  author={Khan, Seher and Singh, Krishna Kumar},
  booktitle={2024 11th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)}, 
  title={Leveraging AI-Generated Image for Scene Classification: A transfer Learning Approach}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={When it comes to scene classification, the lack of labelled data is a significant obstacle that forces researchers to think about innovative solutions. This work presents a revolutionary method to strengthen scene classification models by combining transfer learning with AI-generated images. A key component of this project is the construction of a carefully curated dataset of 3672 augmented AI-generated photos in a total of 6 scenes. This database not only serves as a helpful resource for additional research but also makes a substantial contribution to this area of research. Using this dataset, a VGG16 model is trained, demonstrating the usefulness of synthetic data with a notable increase in accuracy. The model's performance is further improved through subsequent training using realistic photos through transfer learning, thereby surpassing the initial baseline. This work demonstrates the transformative effect of transfer learning on scene categorization accuracy and verifies its effectiveness using synthetic data through rigorous testing and evaluation. The results open the door for AI-generated photos to be used as an effective approach to address data scarcity issues in scene classification, which will help real-world applications improve.},
  keywords={Training;Scene classification;Computer vision;Adaptation models;Databases;Computational modeling;Transfer learning;Scene Classification;AI-generated Images;Transfer Learning;VGG16 Model;Computer Vision;CNN},
  doi={10.1109/ICRITO61523.2024.10522260},
  ISSN={2769-2884},
  month={March},}@INPROCEEDINGS{9689784,
  author={Islam, Md Nazmul and Hasan, Mehedi and Masum, Abdul Kadar Muhammad and Uddin, Md Zia and Alam, Md. Golam Rabiul},
  booktitle={2021 24th International Conference on Computer and Information Technology (ICCIT)}, 
  title={Demystify the Black-box of Deep Learning Models for COVID-19 Detection from Chest CT Radiographs}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Covid 19 continues to have a catastrpoic effect on the world, causing terrible spots to appear all over the place. Due to global epidemics and doctor and healthcare personel shortages, developing an AI-based system to detect COVID in a timely and cost-effective method has become a requirement. It is also essential to detect covid from chest X-ray and CT radiographs due to their accuracy in detecting lung infection and as well as to understand the severity. Moreover, though the number of infected people around the globe is enormous, the amount of covid data set to build an AI system is scarce and scattered. In this letter, we presented a Chest CT scan data (HRCT) set for Covid and healthy patients considering a varying range of severity of COVID, which we published on kaggle, that can assist other researchers to contribute to healthcare AI. We also developed three deep learning approaches for detecting covid quickly and cheaply. Our three transfer learning-based approaches, Inception v3, Resnet 50, and VGG16, achieve accuracy of 99.8%, 91.3%, and 99.3%, respectively on unseen data. We delve deeper into the black boxes of those models to demonstrate how our model comes to a certain conclusion, and we found that, despite the low accuracy of the model based on VGG16, it detects the covid spot of images well, which we believe may further assist doctors in visualizing which regions are affected.},
  keywords={COVID-19;Deep learning;Radiography;Computed tomography;Computational modeling;Medical services;Data models;COVID-19;transfer learning;explainable AI;CT Imaging},
  doi={10.1109/ICCIT54785.2021.9689784},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10465486,
  author={Ittannavar, S. S. and Khot, B. P. and Mahadevaswamy, Mahadevaswamy and Havaldar, R. H.},
  booktitle={2023 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES)}, 
  title={Deep Learning for Computer Vision: Recent Breakthroughs and Emerging Trends}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Significant strides have been achieved in the use of deep learning to computer vision, which has changed the way that computers process and respond to visual data. The authors of this study apply a thorough approach that includes data collecting, model construction, training, assessment, and ethical concerns in their investigation of the many facets of picture categorization using Convolutional Neural Networks (CNNs). The study shows how these techniques might be used in the actual world, namely in the fields of healthcare and autonomous systems. Ethical concerns highlight the significance of justice and accountability, and transfer learning emerges as a beneficial technique for optimizing model performance. Future prospects include researching advanced architectures and multimodal fusion, tackling real-world difficulties, and enhancing ethical and explainable AI, as well as reinforcing models against adversarial assaults. In a future when computer vision not only pushes the boundaries of technology but also molds a more inclusive, educated, and responsible society, this article will serve as a stepping stone for academics, practitioners, and the community.},
  keywords={Deep learning;Training;Ethics;Computer vision;Visualization;Computational modeling;Transfer learning;Computer vision;Deep learning;Convolutional Neural Networks (CNNs);Future directions;Real-world applications;Robustness;Adversarial attacks},
  doi={10.1109/ICSES60034.2023.10465486},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8998077,
  author={Ye, Peiwen and Jia, Xiangdong and Yang, Xiaorong and Hu, Haixia},
  booktitle={2019 IEEE 4th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)}, 
  title={End-to-end Physical Layer Optimization Scheme Based on Deep Learning Autoencoder}, 
  year={2019},
  volume={1},
  number={},
  pages={135-139},
  abstract={5G large-scale commercial enterprises will provide high-speed and low-latency communication services, but it also challenges optimization of system. In particular, the conventional block-by-block design communication model has less interpretability and increases the complexity of physical layer optimization. Fortunately, deep learning has an inherent advantage in structured information representation and data extraction. Therefore, in this paper, based on deep learning autoencoder scheme is proposed to perform end-to-end physical layer optimization. Firstly, a two-stage training mode is proposed to improve the generalization of the neural network. Secondly, in order to decrease the system overhead caused by channel state information (CSI) feedback, utilizing autoencoder to reconstruct CSI by its compression feature. The simulation results show that the phased training can effectively improve the convergence rate, the compression and quantization of CSI alleviates the system loads.},
  keywords={Training;Optimization;Machine learning;Receivers;Physical layer;Wireless communication;Neural networks;deep learning;neural network;autoencoder;physical layer optimization;compression sense},
  doi={10.1109/IAEAC47372.2019.8998077},
  ISSN={2381-0947},
  month={Dec},}@INPROCEEDINGS{10394928,
  author={Praveena, M. and Madhumitha, S and Menakadevi, J and Lalith Akkash, V},
  booktitle={2023 7th International Conference on Electronics, Communication and Aerospace Technology (ICECA)}, 
  title={A Comprehensive Taxonomy of Adversarial Attacks on Machine Learning in IoT Application}, 
  year={2023},
  volume={},
  number={},
  pages={1398-1403},
  abstract={This research is a comprehensive taxonomy of threats against Internet of Things (loT-)based Machine Learning (ML) systems. As the number of IoT applications continues to surge, protecting machine learning models from malicious attacks is more essential than ever. This study categorizes various attack techniques, ranging from white-box to black-box, evasion to poisoning, and beyond, to provide an overview of the evolving security environment within IoT systems. The proposed study will provide attack techniques, evaluation metrics, defense mechanisms, and case studies to shed additional light on securing Internet of Things (IoT) devices. This research contributes to understanding how to use machine learning safely in the Internet of Things by analyzing the prevalence and severity of attacks, the effectiveness of countermeasures, and the effect on system performance.},
  keywords={Training;System performance;Biological system modeling;Taxonomy;Internet of Things;Security;Testing;Adversarial Attacks;Machine Learning;Internet of Things (IoT);Threat Landscape;Attack Scenarios},
  doi={10.1109/ICECA58529.2023.10394928},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9282629,
  author={Wang, Pu and Zhang, Zhiyi and Zhou, Yuqian and Huang, Zhiqiu},
  booktitle={2020 IEEE 20th International Conference on Software Quality, Reliability and Security Companion (QRS-C)}, 
  title={Test Data Augmentation for Image Recognition Software}, 
  year={2020},
  volume={},
  number={},
  pages={280-284},
  abstract={Image recognition software has been widely used in many vital areas, so it needs to be thoroughly tested with images as test data. However, for some special areas, such as medical treatment, there are only a few sufficient and credible test data. Some test data still depends on the training data, which results in the defect detection ability of the testing is not high. In this paper, we propose a new test data augmentation approach with combing domain knowledge and data mutation. Given an image, our approach extracts the features of the recognition targets in this image based on domain knowledge, then mutates these features to generate new images. In theory, our approach could generate high-quality test data, which helps testing image recognition software adequately, and improving the accuracy of image recognition software.},
  keywords={Image segmentation;Image recognition;Target recognition;Training data;Feature extraction;Software;Testing;image recognition software;data augmentation;data mutation;domain knowledge},
  doi={10.1109/QRS-C51114.2020.00054},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10499038,
  author={Dar, Mohammad Amin and Khursheed, Tabinda and Ahmad, Adeel and Fayaz, Roma},
  booktitle={2024 11th International Conference on Computing for Sustainable Global Development (INDIACom)}, 
  title={Unveiling Chat GPT’s Educational Prospects: A SWOT Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1419-1423},
  abstract={This research article endeavors to investigate the utilization of ChatGPT within educational contexts. Employing a review methodology, the investigators scrutinized existing research on this topic. The study then employed a SWOT analysis to systematically delineate the strengths, weaknesses, opportunities, and threats associated with the integration of ChatGPT in education. The findings underscore the transformative potential of ChatGPT within the education sector, particularly in enhancing the experiences of teachers, students, and researchers. However, concurrent with these benefits, the research highlights emerging ethical considerations that warrant careful examination. It is imperative for educational institutions to develop equitable policies that govern the utilization of ChatGPT by all stakeholders, ensuring responsible and ethical engagement with this technology.},
  keywords={Training;Ethics;Visualization;Education;Chatbots;Problem-solving;Digital divide;ChatGPT;SWOT Analysis;Ethical Engagement;Educational Prospects;Examination},
  doi={10.23919/INDIACom61295.2024.10499038},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10969021,
  author={Li, Yancai and Du, Chunlei},
  booktitle={2025 3rd International Conference on Integrated Circuits and Communication Systems (ICICACS)}, 
  title={Intelligent Layout of Interior Design Using CenterNet Algorithm with 3D Modelling Interface}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Nowadays, the interior space planning is an essential technique to effectively build an intelligent layout of interior design. This approach enabled the automatic generation of functional, efficient and visual appealed interior layouts. However, the traditional interior design methods heavily relied on manual planning and expertise. To overcome this issue, CenterNet algorithm with 3D Modelling Interface (CenterNet-3D modelling) is proposed. Initially, input data is collected from indoor space dataset and then preprocessed with horizontal flip, gaussian noise techniques. The horizontal flip maintains the structural integrity and gaussian noise adds random variations to expand input images. After that, the CenterNet algorithm is employed to detect objects in indoor images and further fed into Convolutional Neural Network with Gated Recurrent Unit (CNN-GRU) to capture long-range spatial relationships. Finally, the captured relationships are converted into vector formats to create 3D with transformation matrix for effective layout design. From the results, the proposed CenterNet-3D modelling attained better results in terms of accuracy (98.4%), precision (97.6%), recall (96.8%) and F1-score (97.5%) when compared to existing Deep Computer Aided Design (CAD).},
  keywords={Solid modeling;Three-dimensional displays;Gaussian noise;Layout;Vectors;Planning;Convolutional neural networks;Matrix converters;Integrated circuit modeling;Optimization;3d modelling interface;centernet algorithm;convolutional neural network;intelligent layout of interior design;gated recurrent unit},
  doi={10.1109/ICICACS65178.2025.10969021},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10647504,
  author={Abdelli, Khouloud and Lonardi, Matteo and Gripp, Jurgen and Olsson, Samuel and Boitier, Fabien and Layec, Patricia},
  booktitle={2024 24th International Conference on Transparent Optical Networks (ICTON)}, 
  title={Computer Vision for Anomaly Detection in Optical Networks with State of Polarization Image Data: Opportunities and Challenges}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Anomaly detection in optical networks is vital for network reliability. We investigate leveraging state of polarization (SOP) data and computer vision for this task, despite challenges like scarce anomaly data. Our study explores using deep learning to identify anomalies in optical networks, focusing on SOP time series derived images data. Challenges such as anomaly rarity are addressed through innovative approaches. Our research sheds light on the potential of combining SOP data and computer vision for robust anomaly detection in optical networks, while also highlighting the ongoing efforts to overcome associated challenges and propel the field forward.},
  keywords={Computer vision;Image coding;Time series analysis;Focusing;Self-supervised learning;Optical fiber networks;Propulsion;Anomaly detection;computer vision;state of polarization (SOP);machine learning;optical networks},
  doi={10.1109/ICTON62926.2024.10647504},
  ISSN={2161-2064},
  month={July},}@INPROCEEDINGS{10307823,
  author={Jhajaria, Shubham and Kaur, Damandeep},
  booktitle={2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Study and Comparative Analysis of ChatGPT, GPT and DAll-E2}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Natural Language Processing (NLP) has evolved greatly over the years, resulting in the introduction of sophisticated models such as GPT, ChatGPT, and Dall-E2 that employ deep learning approaches to evaluate and create humanlike replies to textual material. As a result, they have become indispensable tool for a variety of applications such as language translation, question answering, and text condensation. This research paper compares the aforementioned models. Secondly, the configuration of each model is explained, stressing its particular elements and discrepancies. Second, the study examines the training data which is further used for training the models, examining the dimensions and quality of the data. Lastly, the performance of each model is compared based on its capacity to create reactions similar to those of people. According to the findings, the ChatGPT, GPT, and Dall-E2 models have various strengths and drawbacks when it comes to creating human-like answers to text inputs. Yet, given the enormous quantity of conversational data required to train it, ChatGPT excels GPT and Dall-E2 in providing natural and realistic replies. Furthermore, ChatGPT's design is optimized for dialogue production, giving it an advantage over competing models.},
  keywords={Training;Computer vision;Analytical models;Visualization;Computational modeling;Training data;Chatbots;Natural language processing;GPT;ChatGPT;Dall-E2;comparative Analysis},
  doi={10.1109/ICCCNT56998.2023.10307823},
  ISSN={2473-7674},
  month={July},}@INPROCEEDINGS{10042887,
  author={Adi, L. C. and Cheng, T. M.},
  booktitle={2022 IEEE 4th Eurasia Conference on IOT, Communication and Engineering (ECICE)}, 
  title={Analysis of Impact of Synthetic Image Data with Multiple Randomization Strategies on Object Detection Performance}, 
  year={2022},
  volume={},
  number={},
  pages={206-210},
  abstract={Real-time object detection is a smart tool in assisting in-field human workers. In order to achieve a better performance out of object detection deep learning models, tremendously larger quantities of data are needed to train the models’ network. However, obtaining data is expensive in terms of cost, extremely time-consuming, and prone to errors in the annotated part which reduces the detection performance. Hence, in recent years, many research has been focusing on developing alternatives to supplement real data with synthetic data. One of the most popular techniques to generate them is called domain randomization. In this research, an extensive analysis of the impact of various domain randomization strategies was conducted to discover the impact on object detection among the strategies to generate synthetic data from the example industrial objects. The strategies of object orientation and rendering randomization were comprehensively inspected. Insights on the usage of better synthetic data generation were given to improve object detection performance in selected aspects. The method is especially efficient when extremely limited real data were available, and the delicate employment of synthetic data has strengthened the object detection performance by up to 37% of improvement.},
  keywords={Measurement;Image color analysis;Computational modeling;Lighting;Object detection;Rendering (computer graphics);Data models;Object Detection;Domain Randomization;Deep Learning;Synthetic Data},
  doi={10.1109/ECICE55674.2022.10042887},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10315659,
  author={Masayuki, Ueno and Tomoyuki, Takami},
  booktitle={2023 IEEE 12th Global Conference on Consumer Electronics (GCCE)}, 
  title={Visualization of Game Strategies from Imitation Learning Agents}, 
  year={2023},
  volume={},
  number={},
  pages={616-617},
  abstract={It is possible to use the agent as an agent that behaves like a human by machine learning how a human learner behaves in a certain situation. Such an imitation learning agent can be used for various educational purposes. It can be used to learn its own strategies and those of others by using XAI technology to visualize how the imitation learning agent evaluates the board.},
  keywords={Visualization;Machine learning;Games;Consumer electronics;Imitation Learning;Logical Board Game;Game Strategy Learning;XAI;explainable AI},
  doi={10.1109/GCCE59613.2023.10315659},
  ISSN={2693-0854},
  month={Oct},}@BOOK{10280681,
  author={Keydana, Sigrid and Chollet, Francois and Kalinowski, Tomasz and Allaire, J.J.},
  booktitle={Deep Learning with R, Second Edition},
  year={2022},
  volume={},
  number={},
  pages={},
  abstract={Deep learning from the ground up using R and the powerful Keras library! In Deep Learning with R, Second Edition you will learn:  Deep learning from first principles Image classification and image segmentation Time series forecasting Text classification and machine translation Text generation, neural style transfer, and image generation  Deep Learning with R, Second Edition shows you how to put deep learning into action. It’s based on the revised new edition of François Chollet’s bestselling Deep Learning with Python. All code and examples have been expertly translated to the R language by Tomasz Kalinowski, who maintains the Keras and Tensorflow R packages at RStudio. Novices and experienced ML practitioners will love the expert insights, practical techniques, and important theory for building neural networks.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Manning},
  isbn={9781633439849},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10280681},}@INPROCEEDINGS{9885304,
  author={Correa, Swebert and Sawant, Suraj and Joshi, Amit},
  booktitle={2022 International Conference on Computing, Communication, Security and Intelligent Systems (IC3SIS)}, 
  title={Human-Computer Music Co-Production Using Genetic Algorithms}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={In this paper, the analysis of generating appealing musical hooks is discussed. Songs generally possess a particular musical piece called the hook. It is that part of the song which helps people quickly recognise the song just by hearing it. However, creating captivating musical hooks is a very tiresome and time-consuming process. Even a few musical notes can generate vast quantities of permutations and combinations of musical pieces! The assistance of genetic algorithms can be used to ease out the process of a musician finding a catchy hook. Humans have a great perception of music, while computers can efficiently crunch many data. The main objective of this project is to combine the best of both worlds, i.e., human-computer music co-production. The user will provide their initial musical notes as input via the provided interface. Then in a cycle of the model’s output generation and the user’s relevance feedback, newer musical hooks will be created. The proposed system can be used by musicians to discover new possibilities that might have otherwise been possibly hidden.},
  keywords={Industries;Computers;Computational modeling;Bibliographies;Music;Auditory system;Security;genetic algorithms;musical hooks;evolutionary computation;metaheuristics},
  doi={10.1109/IC3SIS54991.2022.9885304},
  ISSN={},
  month={June},}@INPROCEEDINGS{8758634,
  author={Sokar, Ghada and Zakaria, Yassien and Rabie, Asmaa and Madkour, Kareem and Leventhal, Ira and Rivoir, Jochen and Gu, Xinli and Stratigopoulos, Haralampos-G.},
  booktitle={2019 IEEE 37th VLSI Test Symposium (VTS)}, 
  title={IP Session on Machine Learning Applications in IC Test-Related Tasks}, 
  year={2019},
  volume={},
  number={},
  pages={1-1},
  abstract={Over the last decade there has been a surge of activity in employing advanced statistical analysis and machine learning methods to various test-related tasks. The topic is no longer simply a matter of academic curiosity but, rather, a pressing need of the industry as it seeks to address various challenges. In this session, three industry experts have been invited to give their perspective, describe machine learning use cases, and discuss challenges and future work ideas. The three talks will cover the use of deep learning for hotspot detection, the challenge of rendering machine learning-based decisions in the semiconductor industry trustable and explainable, and data analytics across the the complete product cycle towards improved product reliability.},
  keywords={Blockchain;Broadcasting;Real-time systems;Bitcoin;Peer-to-peer computing;Internet;TCPIP},
  doi={10.1109/VTS.2019.8758634},
  ISSN={2375-1053},
  month={April},}@INPROCEEDINGS{10393675,
  author={Moon, SungWon and Nam, Dowon and Lee, Jiwon and Yoo, Wonyoung and Lee, Jungsoo},
  booktitle={2023 14th International Conference on Information and Communication Technology Convergence (ICTC)}, 
  title={A Study on Few-shot Object Detection for Warships Based on Data Generation Using Image Outpainting}, 
  year={2023},
  volume={},
  number={},
  pages={1855-1857},
  abstract={With the advent of hyperscale AI based on large amounts of data and supercomputing infrastructure to process them, AI has made remarkable progress in many areas. Among them, AI-based image generation technology has recently developed rapidly, and research on the use of AI training data is also active. Augmenting training data with synthetic image generation can be of great help in AI training for defense and medical applications, where data collection is difficult. In particular, in marine environments, where data collection is more difficult than on land, it is difficult to collect data on various weather conditions, so the application of AI-based image generation technology is very effective. In this paper, several images are generated by image outpainting based on objects in a real image, and the generated images are intended to be used as training data for an object detector.},
  keywords={Training;Image synthesis;Training data;Detectors;Object detection;Medical services;Data collection;object detection;data augmentation;synthetic image generation},
  doi={10.1109/ICTC58733.2023.10393675},
  ISSN={2162-1241},
  month={Oct},}@INPROCEEDINGS{10389393,
  author={Shanbhag, Aakash Dhananjay and Chinara, Chinmay},
  booktitle={2023 International Conference on Electrical, Computer and Energy Technologies (ICECET)}, 
  title={Face to Face Augmented Reality - Broadening the Horizons of AR Communication}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={When users wear Augmented Reality (AR) Head Mounted Displays (HMDs), they occlude most parts of the face. While body language is crucial in effective team communication and negotiation tactics, the effect of eye contact and facial expressions cannot be neglected. However, the degree to which users in AR environments can expressively interact with each other is hindered by HMDs which occlude a large portion of the face and do not realistically blend with the terrain surroundings. Recent developments generate highly photorealistic avatars in Virtual Reality (VR) but they do not solve a multitude of questions which include blending of the virtual model in an AR setting, real-time performance along with high fidelity of temporal coherence as well estimation of high-resolution outputs. We propose to develop a technique for enabling natural and expressive face-to-face communication between subjects in AR environments by removing the HMD barrier where the virtual environments blend seamlessly with a photorealistic face model.},
  keywords={Solid modeling;Three-dimensional displays;Avatars;Computational modeling;Virtual environments;Estimation;Resists;Augmented Reality;Microsoft HoloLens;Deep Learning;image synthesis;inpainting},
  doi={10.1109/ICECET58911.2023.10389393},
  ISSN={},
  month={Nov},}@INBOOK{10952436,
  author={Chaubard, Francois},
  booktitle={AI for Retail: A Practical Guide to Modernize Your Retail Business with AI and Automation}, 
  title={Index}, 
  year={2023},
  volume={},
  number={},
  pages={311-324},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394184712},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952436},}@INPROCEEDINGS{11034642,
  author={Manikandan, Swetha and Haq, Qazi Mazhar Ul and Islam, Faiz Ul},
  booktitle={2025 International Conference on Communication Technologies (ComTech)}, 
  title={A Multimodal Framework For Robust Propaganda Detection in Digital News Media}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The proliferation of propaganda in multimedia content has grown to be a serious issue in the current digital landscape, as false information quickly shapes the public opinion. This study uses the N24News dataset, which blends text and image data, to present a novel method for identifying propaganda. Using convolutional neural networks (CNNs) for visual feature extraction and natural language processing (NLP) techniques for text analysis, the suggested structure allows for a comprehensive multimodel detection system. The technology efficiently combines textual and visual elements using sophisticated fusion techniques, making it possible to accurately identify a wide range of propaganda tactics across categories. The framework performs better on assessment metrics including F1-score, precision, and recall demonstrating its effectiveness in experimental results. These results demonstrate how complex propaganda patterns may be found using multimodal approaches in greater dependability and resilience for identifying inaccurate information. Future work will concentrate on extending this framework to include media forms such as video and audio to adapt to evolving propaganda techniques.},
  keywords={Measurement;Deep learning;Visualization;Text analysis;Shape;Feature extraction;Natural language processing;Convolutional neural networks;Fake news;Resilience;Propaganda detection;multimodal framework;text-image fusion;deep learning;N24News data set},
  doi={10.1109/ComTech65062.2025.11034642},
  ISSN={2996-3621},
  month={April},}@INPROCEEDINGS{11022922,
  author={Yahyaei, Katayoon and Khan, M Shafkat M and Asadizanjani, Navid},
  booktitle={2025 IEEE 43rd VLSI Test Symposium (VTS)}, 
  title={From Design to Inspection: Can Inspection-aware Design Enhance Reliability in Advanced Packaging?}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Heterogeneous integration and advanced packaging technologies present significant challenges for physical inspection, which is crucial for device reliability. The miniature and intricate transistors, interconnects, and dense stacked structures in advanced packages make defect detection difficult in the manufacturing process. To address these challenges, we introduce the concept of updating designs to improve inspection efficiency and discuss potential research directions for its implementation. Additionally, we present a case study on X-ray inspection challenges and propose solutions to address them.},
  keywords={Manufacturing processes;Multichip modules;Inspection;Very large scale integration;Reliability engineering;Transistors;Object recognition;Integrated circuit reliability;X-ray imaging;Testing;Advanced packaging;physical inspection;non-destructive testing;X-ray imaging;design for inspection},
  doi={10.1109/VTS65138.2025.11022922},
  ISSN={2375-1053},
  month={April},}@INBOOK{10345799,
  author={Nandi, Gypsy},
  booktitle={Principles of Soft Computing Using Python Programming: Learn How to Deploy Soft Computing Models in Real World Applications}, 
  title={Front Matter}, 
  year={2024},
  volume={},
  number={},
  pages={i-xiv},
  abstract={The prelims comprise: <list style="bulleted"> <listItem>Half&#x2010;Title Page</listItem> <listItem>Series Page</listItem> <listItem>Title Page</listItem> <listItem>Copyright Page</listItem> <listItem>Contents</listItem> <listItem>About the Authors</listItem> <listItem>Preface</listItem> </list>},
  keywords={},
  doi={10.1002/9781394173167.fmatter},
  ISSN={},
  publisher={IEEE},
  isbn={9781394173143},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10345799},}@INPROCEEDINGS{10968954,
  author={Mishra, Ashish and Choubey, Niyati and Jumde, Parnavi and Samiya, Ananya and Garg, Abhilasha and Kale, Ashlesha},
  booktitle={2025 IEEE 14th International Conference on Communication Systems and Network Technologies (CSNT)}, 
  title={Early Eye Disease Detection Using Machine Learning}, 
  year={2025},
  volume={},
  number={},
  pages={134-139},
  abstract={Early detection of eye diseases such as diabetic retinopathy, glaucoma, and cataracts is crucial in preventing severe vision impairment and blindness. This study explores the application of machine learning (ML) techniques, particularly Convolutional Neural Networks (CNNs), for the automated diagnosis of eye diseases. A deep learning model was trained on a labeled dataset of retinal images, utilizing CNNs for feature extraction and classification. The Tkinter-based Graphical User Interface (GUI) facilitates easy user interaction, enabling real-time diagnosis from uploaded eye images. Experimental results demonstrate a high accuracy rate of 91%, outperforming traditional diagnostic techniques. Additionally, explainable AI (XAI) methodologies were incorporated to enhance model interpretability, improving trust and usability in clinical settings. In the proposed methodology the findings highlight the potential of ML in ophthalmology, paving the way for cost-effective and scalable screening solutions.},
  keywords={Glaucoma;Cataracts;Visual impairment;Retina;Software;Real-time systems;Ophthalmology;Convolutional neural networks;Usability;Graphical user interfaces;Machine Learning;CNN;Ophthalmology;Neural Networks;Uveitis;Cataract;Glaucoma},
  doi={10.1109/CSNT64827.2025.10968954},
  ISSN={2473-5655},
  month={March},}@INPROCEEDINGS{10110830,
  author={Karmanova, Ekaterina V. and Gavrilova, Irina V. and Maslennikova, Olga E.},
  booktitle={2023 International Russian Smart Industry Conference (SmartIndustryCon)}, 
  title={Deep Learning in Automation of Checking Homework Assignments}, 
  year={2023},
  volume={},
  number={},
  pages={207-212},
  abstract={The article deals with the current issues of knowledge management automation. The authors describe the possibilities of deep learning methods for checking homework and control tasks in such school subjects as Russian language, literature, social studies, history. As a rule, the main form of presenting answers to tasks is text. In this regard, it is proposed to automate the process of recognizing handwritten students texts and checking for compliance of the student’s response with the template document proposed by the teacher for this task. The main process of the service is handwritten text recognition technology, which is implemented on the basis of convolutional and recurrent neural network architecture using a decoding algorithm based on connective time classification. The article also provides a description of the online service, which implements the ability to download the answer to the task by students, recognition of the answer, determination and output of the answer similarity percentage with the attached answer from the teacher. According to the authors, this service will automate the teachers routine operations to check homework. It will be especially useful during the implementation of distance learning during pandemics, quarantines, etc.},
  keywords={Deep learning;Handwriting recognition;Automation;Text recognition;Biological system modeling;Transformers;Data models;handwritten text recognition;Russian language;control automation;neural network technologies;online service},
  doi={10.1109/SmartIndustryCon57312.2023.10110830},
  ISSN={},
  month={March},}@INPROCEEDINGS{10474653,
  author={Rajagopal, Sneha and Gaur, Avanthika and Vinod, P.},
  booktitle={2023 16th International Conference on Security of Information and Networks (SIN)}, 
  title={Interpretable PDF Malware Detector}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The Portable Document Format (PDF) has gained widespread popularity due to its adaptable structure. As PDF usage continues to grow, so does the potential for it to be exploited as a platform for attacks. Malicious actors seek to compromise users' confidential information and exploit system vulnerabilities by implanting harmful content within PDF files. This paper presents an approach for detecting malicious PDF files by extracting features using the PDFiD tool. Furthermore, we employ explainable AI techniques, including tools like ELI5, SHAP, LIME, Partial Dependency Plot, and Counterfactual explanations. Through the use of explainable AI, we interpret the classifier's predictions and determine the significance of each feature in classifying PDF files as either malicious or benign. Lastly, we assess the robustness of the classification model by generating adversarial attacks to simulate a black-box approach.},
  keywords={Explainable AI;Closed box;Detectors;Portable document format;Feature extraction;Robustness;Malware;PDFiD;Feature Extraction;Malicious PDF De-tection;Machine Learning;Feature Importance;Explainable AI},
  doi={10.1109/SIN60469.2023.10474653},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10923956,
  author={Singh, Gurpreet and Guleria, Kalpna and Sharma, Shagun},
  booktitle={2024 5th IEEE Global Conference for Advancement in Technology (GCAT)}, 
  title={A Pre-trained Visual Geometry Group-16 Model for the Identification of Fake Images}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This research presents a method for identifying real and AI-generated (fake) images using the VGG16 model, a widely recognized convolutional neural network. Our approach leverages the powerful feature extraction capabilities of VGG16, combined with additional custom layers, to effectively distinguish between authentic and synthetic images. The model was trained and validated on a dataset consisting of both real and AI-generated images. Throughout the training process, we observed a consistent improvement in training and validation accuracy, with training accuracy reaching 99.49% and validation accuracy peaking at 96.40% by epoch 19. Despite minor fluctuations in validation loss, the model demonstrated robust performance and strong generalization capabilities. The results indicate that the VGG16-based model is highly effective in detecting AI-generated images, making it a valuable tool for applications requiring reliable image authenticity verification. Our findings underscore the potential of advanced deep learning techniques in enhancing digital image forensics, contributing to the broader field of AI and cybersecurity. This research highlights the importance of continual model refinement to address challenges such as overfitting and validation variability, ensuring sustained accuracy and reliability in real-world applications.},
  keywords={Training;Deep learning;Geometry;Visualization;Accuracy;Image recognition;Fluctuations;Forensics;Feature extraction;Overfitting;Machine learning;Deep learning;Image processing;Real vs Fake Images;Digital Content Verification;VGG16 Model},
  doi={10.1109/GCAT62922.2024.10923956},
  ISSN={},
  month={Oct},}@INBOOK{11049711,
  author={Campesato, Oswald},
  booktitle={Large Language Models for Developers: A Prompt-based Exploration of LLMs}, 
  title={Index}, 
  year={2024},
  volume={},
  number={},
  pages={999-1012},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9781501520952},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11049711},}@INPROCEEDINGS{10386169,
  author={An, Zichong and Zhu, Xuemei and Fu, Xiangling and Ma, Junqi and Guo, Chenyi and Zhang, Zheng},
  booktitle={2023 IEEE International Conference on Big Data (BigData)}, 
  title={An iterative sinogram metal artifact reducdion based on UNet}, 
  year={2023},
  volume={},
  number={},
  pages={2518-2522},
  abstract={In the practice of dentistry, oral dental CT images are frequently used to assist doctors in diagnosis. Filtered back projection (FBP) technique is widely employed in practice for the reconstruction of CT images obtained from X-ray calculations. However, when metal objects occur in a patient’s oral cavity, the CT images would show density discontinuities due to the metals’ “X-ray absorption coefficient is much larger than human tissues. When the FBP algorithm is applied to CT images with metals, severe metal artifacts would be obtained, which significantly reconstructed images. Therefore, metal artifact reduction (MAR) work is becoming an important problem in dentistry image processing. In this paper, we propose a novel iterative sinogram metal artifact reduction model (IS-MARM) to solve the problem. Inspired by the Diffusion model, we propose a new method to reduce metal artifacts and interpolate new data in sinogram of dentistry images iteratively. This approach reduces the difficulty of model learning and achieves good results. Secondly, we proposed a new simple method of iterative data generating to simulate real-world metals in CT sinogram images. Finally, we have demonstrated the effectiveness of our method through experiments on dental CT MAR work.},
  keywords={Training;Computed tomography;Computational modeling;Metals;Training data;Data models;Dentistry;metal artifact reduction (MAR);X-ray computed tomography (CT);image inpainting;UNet},
  doi={10.1109/BigData59044.2023.10386169},
  ISSN={},
  month={Dec},}@INBOOK{10952456,
  author={Sanford, Jacob J. and Windischman, Woodrow W. and Willard, Dustin and Dennis, Ryan and McNulty, Chris},
  booktitle={Microsoft SharePoint Premium in the Real World: Bringing Practical Cloud AI to Content Management}, 
  title={Index}, 
  year={2024},
  volume={},
  number={},
  pages={387-402},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394197163},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952456},}@INPROCEEDINGS{10557844,
  author={Sharma, Richa and Sharma, G. K. and Pattanaik, Manisha},
  booktitle={2024 IEEE International Symposium on Circuits and Systems (ISCAS)}, 
  title={Adversarial Label Flipping Attack on Supervised Machine Learning-Based HT Detection Systems}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In the semiconductor landscape, safeguarding integrated circuits against Hardware Trojans (HT) is critical.To address this pressing concern, supervised machine learning (ML) has emerged as a promising defense mechanism for HT detection. However, the vulnerability of supervised ML-based defense mechanisms to adversarial attacks poses a substantial challenge, potentially compromising model prediction performance. This paper presents a label flipping poisoning attack, strategically targeting supervised ML-based HT detection systems during the pre-silicon IC design phase. Leveraging the power of the Isolation Forest, our method first identifies potential Trojan nets through a process of random partitioning, flips their labels, and perturbs the model training process. Further, random subsampling is applied to select a subset of Trojan-free samples, whose labels are also flipped. This model-independent, untargeted, and black-box attack is evaluated against Trust-Hub & DeTrust Benchmarks, resulting in a substantial reduction in model recall, challenging the reliability of ML-based HT detection systems.},
  keywords={Training;Semiconductor device modeling;Closed box;Forestry;Benchmark testing;Hardware;Trojan horses;Hardware Security;Hardware Trojan;Supervised Machine Learning;Label Flipping Poisoning Attack},
  doi={10.1109/ISCAS58744.2024.10557844},
  ISSN={2158-1525},
  month={May},}@INPROCEEDINGS{10760517,
  author={Sabitha, R. and Sundar, D.},
  booktitle={2024 2nd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS)}, 
  title={Performance Management in Business Organizations using Optimal and Attention-based Recurrent Neural Network for Enhancing the Productivity}, 
  year={2024},
  volume={},
  number={},
  pages={56-64},
  abstract={The management by goals acts as a primary component of action for analyzing the performance of the organization’s demand of the employees in any bound of organization territory. The intelligence of the organization supports collecting significant data from a huge variety of unstructured data and changes them into useful data that enables the organizations to make illuminated policy decisions and enhance the organization’s productivity and efficiency. The complexities facing any enterprise in decision-making and business intelligence include risk-taking capability, resource failure, poor preparation, and plan failure. Deep learning has not attained much attention due to the efficacy has not been clearly examined in the decision-making within the organization. Hence in this proposed model, an efficient deep learning-aided system is developed for making decisions to improve production growth, where the data needed for the analysis is gathered from different business sectors. The collected data is applied to the Optimized and Attention Recurrent Neural Network (OAtt-RNN) for providing suggestions, which helps to boost up the productivity of the business. The decision-making efficiency of the proposed model is boosted by fine-tuning the attributes from OAtt-RNN using the Botox Optimization Algorithm (BOA). Effective business management generates a positive work environment and motivates employees to concentrate more on their work. The obtained outcome of the designed system is contrasted with other conventional models using different performance metrics to ensure the efficiency of our model.},
  keywords={Productivity;Deep learning;Measurement;Recurrent neural networks;Decision making;Organizations;Data models;Organizational aspects;Optimization;Long short term memory;Business Organizations;Performance Management;Productivity Enhancement;Optimized and Attention Recurrent Neural Network;Botox Optimization Algorithm},
  doi={10.1109/ICSSAS64001.2024.10760517},
  ISSN={},
  month={Oct},}@INBOOK{10942531,
  author={Prasad, Ramjee and Koren, Ana},
  booktitle={Safeguarding 6G: Security and Privacy for the Next Generation}, 
  title={1 Introduction}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={This book provides a comprehensive overview of security and privacy challenges in 6G networks, addressing the urgent need for advanced security frameworks as the next generation of wireless technology emerges. The rapid advancements in quantum computing, AI, and IoT are transforming the digital landscape, introducing both unprecedented opportunities and significant security threats. From AI-driven cyberattacks to the vulnerabilities of IoT devices, this book explores cutting-edge technologies such as quantum key distribution (QKD), post-quantum cryptography, and AI-enabled security systems. Designed for professionals and researchers, this resource outlines real-world applications of 6G security techniques, offering practical insights into protecting critical infrastructures, autonomous vehicles, smart cities, and more. By emphasizing a proactive approach to cybersecurity and fostering collaboration across industries, academia, and policymakers, the book lays out a roadmap for ensuring the resilience and trustworthiness of 6G networks in the future.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770047937},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10942531},}@INPROCEEDINGS{10856013,
  author={Wu, Minghao and Wu, Lifeng},
  booktitle={14th International Conference on Quality, Reliability, Risk, Maintenance, and Safety Engineering (QR2MSE 2024)}, 
  title={Few shot fault diagnosis method of rolling bearing based on CSML}, 
  year={2024},
  volume={2024},
  number={},
  pages={1231-1236},
  abstract={Currently, neural network models have seen widespread adoption in the sphere of fault diagnosis. In the training process of the model there are still problems such as high demand for training data and insufficient generalisation of the model under different working conditions. In order to solve the above problems, in this paper, an algorithm named Cosine Annealing-Sgd-Meta-Learning (CSML) is proposed, which combines the cosine annealing method with the principles of stochastic gradient descent meta-learning. The method uses the cosine annealing algorithm to adjust the learning rate in the outer loop so as to better help the meta-learning task to find the initialisation parameters. In the inner loop, the learning rate is updated using the SGD optimisation algorithm and a wide convolutional network is used to improve the model's ability to extract fault information from the meta-task under known operating conditions, and then the basic learner is updated. High diagnostic accuracy was obtained on the Western Reserve University bearing dataset, which verified its feasibility and effectiveness.},
  keywords={},
  doi={10.1049/icp.2024.3607},
  ISSN={},
  month={July},}@INPROCEEDINGS{10865573,
  author={Xu, Zhenquan and Zou, Juncheng and Long, Dafeng and Wei, Xiaohui and Yang, Guangyu},
  booktitle={2024 China Automation Congress (CAC)}, 
  title={Blood Cell Detection: Enhanced YOLOv9 Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={4415-4420},
  abstract={Blood cell examination is a vital diagnostic tool in medicine, yet traditional methods suffer from low efficiency and accuracy due to overlapping cells, varying sizes, and high densities. To address these challenges, we present an enhanced version of the real-time object detection algorithm YOLOv9, incorporating a novel AKELAN4 module for improved blood cell recognition. Unlike previous approaches, AKELAN4 uniquely integrates Adaptive Kernel Convolution (AKConv) with Inverted Residual Multi-Branch Attention (IRMB), enabling simultaneous dynamic kernel shape adjustments and multi-scale feature extraction. This synergistic combination excels in detecting early-stage abnormalities and irregular shapes. To optimize model efficiency, we introduce the DySample sampling operator and Space-to-depth Convolution (SPDConv) module, reducing redundant calculations and enhancing feature learning efficiency. Our improved YOLOv9 algorithm achieved state-of-the-art performance on the Blood Cell Classification Dataset (BCCD), with 87.2% precision and 93.4% mean average precision, outperforming the recent YOLO-BC model by +6.3% and +3.4%, respectively. This work marks a significant advancement in blood cell detection research, with potential clinical applications.},
  keywords={Representation learning;Adaptation models;Accuracy;Shape;Computational modeling;Heuristic algorithms;Feature extraction;Kernel;Blood;Medical diagnostic imaging;cell detection;YOLOv9;attention mechanism;feature extraction},
  doi={10.1109/CAC63892.2024.10865573},
  ISSN={2688-0938},
  month={Nov},}@INPROCEEDINGS{10873183,
  author={Li, Chuang and Liang, Guojian and Qin, Baozhen and Wei, Xiaobin},
  booktitle={2024 International Conference on Industrial IoT, Big Data and Supply Chain (IIoTBDSC)}, 
  title={Application of Deep Learning Algorithm in Virtual Reality Interactive Product Design}, 
  year={2024},
  volume={},
  number={},
  pages={385-390},
  abstract={In order to improve the design effect of virtual reality interactive products, this paper combines deep learning algorithms and intelligent interaction models to build a system model. In the design of interactive modes, this paper focuses on the design principles and technical implementation of gesture, speech and tactile feedback, and highlights the role of these interactive modes in enhancing user experience. In addition, the virtual environment design part, this paper focuses on scene simulation and role interaction. Finally, this paper provides a comprehensive and in-depth design framework for multimedia interactive system based on virtual reality technology. It covers all aspects from hardware selection to software implementation, from interactive technology to virtual environment design, and provides important guidance for the development of efficient and interactive virtual reality system, and also provides rich thinking and inspiration for future technological innovation and application expansion.},
  keywords={Deep learning;Somatosensory;Solid modeling;Technological innovation;Supply chains;Virtual environments;Tactile sensors;Object detection;Cameras;User experience;deep learning;virtual reality;interactive;product design},
  doi={10.1109/IIoTBDSC64371.2024.00076},
  ISSN={},
  month={Sep.},}
