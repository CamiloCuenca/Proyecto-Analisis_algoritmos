@ARTICLE{8901150,
  author={Zhang, Long and Liu, Li and Zhang, Huaxiang and Chen, Xiuxiu and Wang, Tianshi and Wang, Chunjing},
  journal={IEEE Access}, 
  title={Matching of 3D Model and Semantic Description via Multi-Modal Auxiliary Classifier Generative Adversarial Network With Autoencoder}, 
  year={2019},
  volume={7},
  number={},
  pages={177585-177594},
  abstract={To facilitate the management of 3D content in applications, some researchers add semantics to the geometric description of 3D models. However, the insurmountable semantic gap between 3D model and semantic description is the biggest obstacle to the matching of them. This paper proposes a novel network framework named Multi-modal Auxiliary Classifier Generative Adversarial Network with autoencoder (MACGAN-AE) for the matching of 3D model and its semantic description. Firstly, the Multi-modal Auxiliary Classifier Generative Adversarial Network is presented to solve the multi-modal classification. It captures the latent correlated representation between multi-modes and bridges the semantic gap of them. Then, the autoencoder is introduced to construct MACGAN-AE to further enhance the correlation between 3D model and its semantic description. The framework is expected to minimize the semantic gap between 3D model and its corresponding semantic description. In addition, to preserve the relationships between data after feature projection, this paper also defines a structure-preserving loss to reduce the intra-class distance and increase the inter-class distance. Experimental results on XMediaNet dataset demonstrate that our method significantly outperforms other methods.},
  keywords={Semantics;Three-dimensional displays;Solid modeling;Generative adversarial networks;Data models;Correlation;Generators;Matching;3D model;semantic description;MACGAN-AE},
  doi={10.1109/ACCESS.2019.2953516},
  ISSN={2169-3536},
  month={},}@ARTICLE{8867875,
  author={Ding, Yu and Ma, Liang and Ma, Jian and Wang, Chao and Lu, Chen},
  journal={IEEE Access}, 
  title={A Generative Adversarial Network-Based Intelligent Fault Diagnosis Method for Rotating Machinery Under Small Sample Size Conditions}, 
  year={2019},
  volume={7},
  number={},
  pages={149736-149749},
  abstract={Rotating machinery plays a key role in mechanical equipment, and the fault diagnosis of rotating machinery is a popular research topic. To overcome the dependency on expert knowledge regarding conventional time-frequency analysis diagnosis methods, machine learning (ML) and artificial intelligence (AI)-based methods are commonly studied. Although these methods can achieve high-accuracy diagnosis results, they are based on a large number of training samples. A generative adversarial network (GAN) is an algorithm with the capability of generating realistic samples that are similar to the real samples, and it can be applied to solve fault diagnosis problems with insufficient training data, which is called the small sample size condition in this study. However, a single-GAN model cannot achieve a good diagnostic result. To achieve adaptive feature extraction and high diagnosis accuracy, this study proposes an intelligent fault diagnosis method for rotating machinery based on GANs under small sample size conditions. The effectiveness and performance of the proposed method are validated using rolling bearing and gearbox datasets. In these datasets, only 10% and 20% of the samples are selected as the training data. Samples associated with different health conditions and various working conditions are included in the datasets. Compared with those of other diagnosis methods, the high-accuracy and low-volatility diagnosis results indicate that the proposed method can stably distinguish fault modes under different working conditions in an adaptive way, even though few training samples are available.},
  keywords={Fault diagnosis;Gallium nitride;Training;Generative adversarial networks;Feature extraction;Generators;Fault diagnosis;rotating machinery;generative adversarial network;small sample size conditions},
  doi={10.1109/ACCESS.2019.2947194},
  ISSN={2169-3536},
  month={},}@ARTICLE{10454003,
  author={Li, Peichun and Zhang, Hanwen and Wu, Yuan and Qian, Liping and Yu, Rong and Niyato, Dusit and Shen, Xuemin},
  journal={IEEE Transactions on Mobile Computing}, 
  title={Filling the Missing: Exploring Generative AI for Enhanced Federated Learning Over Heterogeneous Mobile Edge Devices}, 
  year={2024},
  volume={23},
  number={10},
  pages={10001-10015},
  abstract={Distributed Artificial Intelligence (AI) model training over mobile edge networks encounters significant challenges due to the data and resource heterogeneity of edge devices. The former hampers the convergence rate of the global model, while the latter diminishes the devices’ resource utilization efficiency. In this paper, we propose a generative AI-empowered federated learning to address these challenges by leveraging the idea of FIlling the MIssing (FIMI) portion of local data. Specifically, FIMI can be considered as a resource-aware data augmentation method that effectively mitigates the data heterogeneity while ensuring efficient FL training. We first quantify the relationship between the training data amount and the learning performance. We then study the FIMI optimization problem with the objective of minimizing the device-side overall energy consumption subject to required learning performance constraints. The decomposition-based analysis and the cross-entropy searching method are leveraged to derive the solution, where each device is assigned suitable AI-synthetic data and resource utilization policy. Experiment results demonstrate that FIMI can save up to 50% of the device-side energy to achieve the target global test accuracy in comparison with the existing methods. Meanwhile, FIMI can significantly enhance the converged global accuracy under the non-independently-and-identically distribution (non-IID) data.},
  keywords={Training;Data models;Performance evaluation;Generative AI;Optimization;Energy consumption;Convergence;Federated learning;generative AI;data compensation;resource management},
  doi={10.1109/TMC.2024.3371772},
  ISSN={1558-0660},
  month={Oct},}@ARTICLE{10818633,
  author={Huang, Xinyu and Yang, Haojun and Zhou, Conghao and He, Mingcheng and Shen, Xuemin and Zhuang, Weihua},
  journal={IEEE Network}, 
  title={When Digital Twin Meets Generative AI: Intelligent Closed-Loop Network Management}, 
  year={2025},
  volume={39},
  number={5},
  pages={272-279},
  abstract={Generative artificial intelligence (GAI) and digital twin (DT) are advanced data processing and virtualization technologies to revolutionize communication networks. Thanks to the powerful data processing capabilities of GAI, integrating it into DT is a potential approach to construct an intelligent holistic virtualized network for better network management performance. To this end, we propose a GAI-driven DT (GDT) network architecture to enable intelligent closed-loop network management. In the architecture, various GAI models can empower DT status emulation, feature abstraction, and network decision-making. The interaction between GAI-based and model-based data processing can facilitate intelligent external and internal closed-loop network management. To further enhance network management performance, three potential approaches are proposed, i.e., model light-weighting, adaptive model selection, and data-model-driven network management. We present a case study pertaining to data-model-driven network management for the GDT network, followed by some open research issues.},
  keywords={Emulation;Decision making;Computational modeling;Data models;Adaptation models;Mobile communication;Data processing;Network architecture;Servers;Generative adversarial networks;Digital twin;generative AI;closed-loop network management;quality of experience (QoE)},
  doi={10.1109/MNET.2024.3524474},
  ISSN={1558-156X},
  month={Sep.},}@INPROCEEDINGS{10449663,
  author={Aleti, Aldeida},
  booktitle={2023 IEEE/ACM International Conference on Software Engineering: Future of Software Engineering (ICSE-FoSE)}, 
  title={Software Testing of Generative AI Systems: Challenges and Opportunities}, 
  year={2023},
  volume={},
  number={},
  pages={4-14},
  abstract={Software Testing is a well-established area in software engineering, encompassing various techniques and methodologies to ensure the quality of software systems. However, with the arrival of generative artificial intelligence (GenAI) systems, new challenges arise in the testing domain. These systems, capable of generating novel and creative outputs, introduce unique complexities that require novel testing approaches. In this paper, I aim to explore the challenges posed by GenAI systems and discuss potential opportunities for future research in the area of testing. I will touch on the specific characteristics of GenAI systems that make traditional testing techniques inadequate or insufficient. By addressing these challenges and pursuing further research, we can enhance our understanding of how to safeguard GenAI and pave the way for improved quality assurance in this rapidly evolving area.},
  keywords={Software testing;Training;Uncertainty;Systematics;Generative AI;Complexity theory;Software engineering;Generative AI;Software testing;oracle;test suite adequacy},
  doi={10.1109/ICSE-FoSE59343.2023.00009},
  ISSN={},
  month={May},}@ARTICLE{9717263,
  author={Meng, Fan and Song, Tao and Xu, Danya},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={Simulating Tropical Cyclone Passive Microwave Rainfall Imagery Using Infrared Imagery via Generative Adversarial Networks}, 
  year={2022},
  volume={19},
  number={},
  pages={1-5},
  abstract={Tropical cyclones (TCs) generally carry large amounts of water vapor and can cause large-scale extreme rainfall. Passive microwave (PMW) rainfall (PMR) estimation of TC with high spatial and temporal resolution is crucial for disaster warning of TC, but remains a challenging problem due to low temporal resolution of microwave sensors. This study attempts to solve this problem by directly predicting PMW rainfall images (PMRIs) from satellite infrared (IR) images of TC. We develop a generative adversarial network (GAN) to simulate PMRI using IR images and establish the mapping relationship between TC cloud-top brightness temperature and PMR, and the algorithm is named tropical cyclone rainfall (TCR)-GAN. Meanwhile, a new dataset that is available as a benchmark, Dataset of TC IR-to-Rainfall Prediction (TCIRRP), was established, which is expected to advance the development of artificial intelligence in this direction. The experimental results show that the algorithm can effectively extract key features from IR. The end-to-end deep learning approach shows potential as a technique that can be applied globally and provides a new perspective TC precipitation prediction via satellite, which is expected to provide important insights for real-time visualization of TC rainfall globally in operations.},
  keywords={Magnetic resonance imaging;Clouds;Generative adversarial networks;Microwave imaging;Generators;Spatial resolution;Microwave theory and techniques;Deep learning;generative adversarial networks (GANs);passive microwave~(PMW) rainfall;remote sensing;tropical cyclones (TCs)},
  doi={10.1109/LGRS.2022.3152847},
  ISSN={1558-0571},
  month={},}@INPROCEEDINGS{9631541,
  author={Wan, Yichen and Qu, Youyang and Gao, Longxiang and Xiang, Yong},
  booktitle={2021 IEEE Symposium on Computers and Communications (ISCC)}, 
  title={Differentially Privacy-Preserving Federated Learning Using Wasserstein Generative Adversarial Network}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Artificial intelligence (AI) requires a large amount of data to train high-quality machine learning (ML) models. However, due to privacy issues, individuals or organizations are not willing to share data with others, which results in “data islands”. This motivates the emergence of Federated Learning (FL), a novel ML framework allowing clients to exchange model parameters rather than the raw data. Unfortunately, the private data may be reconstructed by malicious participants by exploiting the context of model parameters in FL. This poses further challenges to privacy protection. To address this issue, we propose to integrate Wasserstein Generative Adversarial Network (WGAN) and differential privacy (DP) to protect the model parameters. WGAN is used to generate controllable random noise, which is then injected into model parameters. The new mechanism satisfies DP requirements while the data utility is highly improved. We experimentally demonstrate superior performances from aspects of convergence, accuracy, and data utility.},
  keywords={Training;Differential privacy;Distributed databases;Organizations;Machine learning;Generative adversarial networks;Collaborative work;Federated learning;Privacy Protection;Differential Privacy;Wasserstein Generative Adversarial Nets},
  doi={10.1109/ISCC53001.2021.9631541},
  ISSN={2642-7389},
  month={Sep.},}@INPROCEEDINGS{10956507,
  author={Ganguly, Santanu and Liang, Xing and Makris, Dimitrios},
  booktitle={2025 International Conference on Intelligent Control, Computing and Communications (IC3)}, 
  title={Hybrid Classical-Quantum Generative Algorithms for Financial Modelling and Prediction}, 
  year={2025},
  volume={},
  number={},
  pages={1366-1376},
  abstract={Quantum machine learning (QML) is a cross-disciplinary subject made up of two of the most exciting research areas: quantum computing and classical machine learning (ML), with ML and artificial intelligence (AI) being projected as the first fields that will be impacted by the rise of quantum machines. Quantum computers are being used today in drug discovery, material & molecular modelling and finance. In this work, we explore emerging research areas in the application of hybrid classical quantum machine learning (QML) in finance. We focus on hybrid classical-quantum models that have gained significant interest in the financial world for various applications. We utilise a real-world cryptocurrency dataset to train a quantum generative adversarial networks (qGAN), and implement the real-life NVIDIA stock price data on quantum LSTM (QLSTM), comparing its performance with classical Long Short Term Memory (LSTM) model. Additionally, we investigate the application of quantum circuit Born machine (QCBM) using a toy dataset for applications in finance. For the qGAN, we define quantum circuits for generators and showcase the potential for future quantum advantage in finance through QML, possibly in combination with QLSTM and QCBM. Our findings suggest that, while training classical data is more efficient on LSTM, the test predictions of QLSTM is slightly superior to its classical counterpart making it a promising candidate for financial forecasting and analysis for timeseries type data.},
  keywords={Training;Toy manufacturing industry;Time series analysis;Finance;Machine learning;Prediction algorithms;Generative adversarial networks;Data models;Long short term memory;Financial industry;Quantum Generative Adversarial Network (qGAN);QLSTM;QCBM;QML},
  doi={10.1109/IC363308.2025.10956507},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10570127,
  author={Kashyap, Priyank and Deroo, Andries and Baron, Dror and Wong, Chau-Wai and Wu, Tianfu and Franzon, Paul D.},
  booktitle={2024 IEEE 33rd Microelectronics Design & Test Symposium (MDTS)}, 
  title={High-Speed Receiver Transient Modeling with Generative Adversarial Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Data-intensive applications such as artificial intelligence and graph processing are becoming commonplace, requiring high-speed IO to enable the deployment of these critical applications. To accommodate the increasing data requirements Serializer/Deserializer (SerDes) receivers have become increasingly complex, with different equalization schemes to mitigate channel impairments. It has become increasingly important to model this receiver as they are performance-critical.This paper shows an approach to modeling the transient of a high-speed receiver with fixed and varying equalization through generative networks. The method considers the receiver as a black box, with its inputs and outputs as two different domains, framing the problem as a domain translation task. The proposed approach uses an intermediate representation of the time series to model the receiver successfully. We demonstrate that the proposed method is invariant to the input waveform, receiver configuration, and channel. In a fixed equalization setting, the proposed approach has a root-mean-squared error of 0.016 in a [0, 1] range and an error of 0.054 in the same range for a variable redriver. The approach can predict a batched set of results under 250ms, faster than an equivalent spice model for the same time steps.},
  keywords={Training;Accuracy;Computational modeling;Time series analysis;Receivers;Predictive models;Generative adversarial networks;Data-Driven;Generative;Macro-model;SerDes;Transient},
  doi={10.1109/MDTS61600.2024.10570127},
  ISSN={2573-7600},
  month={May},}@INPROCEEDINGS{10698619,
  author={Torres, Martha and Errapotu, Sai Mounika and Gonzalez, Virgilio},
  booktitle={2024 International Conference on Electrical, Computer and Energy Technologies (ICECET}, 
  title={Cyberattack Risk Classification for Detecting Intrusions through N euro- Fuzzy Inference based Generative Adversarial Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Intrusion detection systems playa significant role in securing the communication networks from adversarial attacks. Recent trends have seen an increase in the exploitation of network vulnerabilities to gain access to network. To address these issues Machine Learning/Artificial Intelligence based frameworks are being integrated into network defense techniques to build intrusion prevention/detection systems capable of scaling with network size while ensuring strong security against cyber-attacks. However, such intrusion detection systems' training procedure is becoming challenging due to the diversity in cyber and cyber physical attack vectors, as well as due to the lack of data, patterns, and parameters. In many applications, the primary challenge in developing an effective AI based intrusion detection system is the lack of adequate cyber-attack data needed for training, which directly affects the accuracy of alerts generated since the training attack dataset is not a full representative of network dynamics. To address these challenges, we focus on Generative Adversarial Networks (GANs) based Intrusion Detection System (IDS) capable of creating realistic attack samples needed for training as well as augmenting missing data. This work specifically focuses on the classification problem in the discriminator side of the GANs based IDS to improve accuracy in training. This paper presents an innovative neuro fuzzy inference injection technique based on the Mamdani approach. The proposed three phase approach that includes data preprocessing, fuzzy inference-based training, and rule evaluation procedure for GAN s based IDS is validated and tested for improving model performance, reliability, and efficiency on IEEE loT dataset.},
  keywords={Training;Fuzzy logic;Accuracy;Intrusion detection;Text to image;Generative adversarial networks;Generators;Vectors;Cyberattack;Testing;Cybersecurity;Intrusion detection system;Fuzzy Inference System;Generative Adversarial Network},
  doi={10.1109/ICECET61485.2024.10698619},
  ISSN={},
  month={July},}@INPROCEEDINGS{10581901,
  author={Nguyen, Dang-Khanh and Paudel, Prabesh and Kim, Seung-Won and Shin, Ji-Eun and Kim, Soo-Hyung and Yang, Hyung-Jeong},
  booktitle={2024 IEEE 18th International Conference on Automatic Face and Gesture Recognition (FG)}, 
  title={Multiple Facial Reaction Generation Using Gaussian Mixture of Models and Multimodal Bottleneck Transformer}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Facial reaction generation has gained prominence in recent years. However, while there has been extensive research on synthesizing facial expressions from the perspective of the speaker, the generation of reactions from the listener's standpoint remains relatively unexplored. Predicting the facial reactions of the listener in a conversational setting presents a challenge due to the diverse range of reactions that can be elicited by the behavior of a single speaker. In this study, we introduce a Multimodal Transformer-based Variational Autoencoder designed to learn the distribution of listener facial reactions based on speaker audiovisual cues. Our proposed approach incorporates the Multimodal Bottleneck Token mechanism to capture interactions between acoustic and visual speaker features and utilizes the Variational Au-to encoder framework to generate latent representations of multiple listener reactions. Additionally, we employ Gaussian Mixture Models to enhance the generative capabilities of the Autoencoder. Experimental results demonstrate that our method surpasses baseline models and previous approaches on the REACT24 benchmark dataset.},
  keywords={Training;Visualization;Face recognition;Oral communication;Gesture recognition;Benchmark testing;Transformers},
  doi={10.1109/FG59268.2024.10581901},
  ISSN={2770-8330},
  month={May},}@INPROCEEDINGS{10888326,
  author={Zhang, Yibo and Gao, Dahua and Xie, Feng and Yang, Minxi and Wang, Wenlong and Liu, Ruichao},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={FreeAlign: Superior Text-Image Alignment by Modulating Prompt Attention}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={In recent years, Text-to-Image (T2I) models have made remarkable advancements, yet accurate accurate association of attributes remains a key challenge. This paper presents FreeAlign, a novel training-free framework designed to enhance attribute alignment in T2I generation. By modulating attention and adapting U-Net components, FreeAlign achieves precise alignment between image attributes and textual descriptions. It strengthens attribute-target associations through refining attention maps, adjusts U-Net’s backbone and skip connections based on energy ratios, and reorders prompts to balance attribute focus. Large Language Models (LLMs) enrich prompts with diverse, contextually relevant text, enhancing diffusion models’ generative power and quality. Extensive experiments show that FreeAlign delivers superior alignment for diverse prompts while preserving intricate details and ensuring structural integrity, establishing a new benchmark for attribute precision in T2I generation.},
  keywords={Training;Accuracy;Large language models;Refining;Text to image;Signal processing;Benchmark testing;Diffusion models;Speech processing;Context modeling;Image generation;training-free;attention modulation;precise text-image binding;diffusion model},
  doi={10.1109/ICASSP49660.2025.10888326},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10696746,
  author={Janani, N and Raman, Valliappan},
  booktitle={2024 Second International Conference on Intelligent Cyber Physical Systems and Internet of Things (ICoICI)}, 
  title={ATheoretical Study on Prenatal Hydronephrosis: Image Segmentation Techniques and CNN Model}, 
  year={2024},
  volume={},
  number={},
  pages={1254-1259},
  abstract={Prenatal Hydronephrosis (PNH) is caused in fetal infants identified by obstruction in the urine production, it leads to the enlargement of the kidney in fetal infants. Hydronephrosis is a common inherited defect that causes dilatation of the renal pelvis and calyces in newborns. The hydronephrosis disease grading is developed by the society for fetal urology (SFU) to get the accurate diagnosis for the decision making. This method involves the diverse population of ultrasound images of patients. Preprocessing methods in the images are used to enhance the visual quality of the image and reduce noise in the ultrasound images. This research study involves the filtering algorithms to segment the ultrasound images and it includes the convolutional neural network for classification. The severity of the hydronephrosis is measured by the extent of renal pelvis and calyceal dilation. The outcome of the study is to predict the prenatal hydronephrosis in the early stage by using the network model, the segmentation of the image shows the predictive capability of the model in distinguishing mild, moderate, and severe cases of hydronephrosis.},
  keywords={Image segmentation;Pediatrics;Ultrasonic imaging;Accuracy;Ultrasonic variables measurement;Predictive models;Filtering algorithms;Convolutional neural networks;Urology;Diseases;Society for Fetal Urology (SFU);Convolutional Neural Network (CNN);Prenatal Hydronephrosis (PNH)},
  doi={10.1109/ICoICI62503.2024.10696746},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{11090249,
  author={Xu, Kai and Dai, Erhan and Yang, Hangen},
  booktitle={2025 37th Chinese Control and Decision Conference (CCDC)}, 
  title={A Deep Learning-Based REBA Assessment Method}, 
  year={2025},
  volume={},
  number={},
  pages={4185-4190},
  abstract={Work-related musculoskeletal disorders (MSDs) are a significant issue in both industrial and healthcare sectors, often resulting from improper working postures. The Rapid Entire Body Assessment (REBA) is a well-established ergonomic tool used to assess the risk associated with whole-body postures, including both upper and lower limbs. However, traditional REBA assessments are time-consuming and prone to subjective bias. This study proposes a real-time REBA evaluation method based on deep learning, which automatically predicts REBA scores using two-dimensional (2D) joint data. The model is trained on posture data from 17 key joints and achieves an accuracy of 77.2% on the validation set, demonstrating strong predictive performance, particularly in complex postures involving the legs and lower back.},
  keywords={Legged locomotion;Deep learning;Musculoskeletal system;Accuracy;Ergonomics;Two-dimensional displays;Predictive models;Real-time systems;Data models;Robustness;REBA;Deep learning;Ergonomic assessment;Musculoskeletal disorders;Posture evaluation},
  doi={10.1109/CCDC65474.2025.11090249},
  ISSN={1948-9447},
  month={May},}@ARTICLE{9777677,
  author={Kanwal, Neel and Pérez-Bueno, Fernando and Schmidt, Arne and Engan, Kjersti and Molina, Rafael},
  journal={IEEE Access}, 
  title={The Devil is in the Details: Whole Slide Image Acquisition and Processing for Artifacts Detection, Color Variation, and Data Augmentation: A Review}, 
  year={2022},
  volume={10},
  number={},
  pages={58821-58844},
  abstract={Whole Slide Images (WSI) are widely used in histopathology for research and the diagnosis of different types of cancer. The preparation and digitization of histological tissues leads to the introduction of artifacts and variations that need to be addressed before the tissues are analyzed. WSI preprocessing can significantly improve the performance of computational pathology systems and is often used to facilitate human or machine analysis. Color preprocessing techniques are frequently mentioned in the literature, while other areas are usually ignored. In this paper, we present a detailed study of the state-of-the-art in three different areas of WSI preprocessing: Artifacts detection, color variation, and the emerging field of pathology-specific data augmentation. We include a summary of evaluation techniques along with a discussion of possible limitations and future research directions for new methods.},
  keywords={Image color analysis;Cancer;Task analysis;Pathology;Laboratories;Image segmentation;Hospitals;Artifacts detection;computational pathology;histopathological images;image augmentation;preprocessing;stain normalization},
  doi={10.1109/ACCESS.2022.3176091},
  ISSN={2169-3536},
  month={},}@ARTICLE{10637270,
  author={Wang, Xin and Wan, Zhongwei and Hekmati, Arvin and Zong, Mingyu and Alam, Samiul and Zhang, Mi and Krishnamachari, Bhaskar},
  journal={IEEE Internet Computing}, 
  title={The Internet of Things in the Era of Generative AI: Vision and Challenges}, 
  year={2024},
  volume={28},
  number={5},
  pages={57-64},
  abstract={Advancements in generative AI hold immense promise to push the Internet of Things (IoT) to the next level. In this article, we share our vision on the IoT in the era of generative AI. We discuss some of the most important applications of generative AI in IoT-related domains. We also identify some of the most critical challenges and discuss current gaps as well as promising opportunities on enabling generative AI for the IoT. We hope this article can inspire new research on the IoT in the era of generative AI.},
  keywords={Internet of Things;Generative AI;Data models;Adaptation models;Robots;Computational modeling;Autonomous vehicles;Social implications of technology},
  doi={10.1109/MIC.2024.3443169},
  ISSN={1941-0131},
  month={Sep.},}@ARTICLE{9718080,
  author={Lee, Sungjin and Yun, Jun Seok and Yoo, Seok Bong},
  journal={IEEE Access}, 
  title={Alternative Collaborative Learning for Character Recognition in Low-Resolution Images}, 
  year={2022},
  volume={10},
  number={},
  pages={22003-22017},
  abstract={Character recognition in a single image is a technology utilized in various sensor platforms, such as smart parking and text-to-speech systems, and numerous studies are being conducted to improve its performance by experimenting with novel approaches. However, when low-quality images were inputted to a character recognition neural network for recognition, a difference in the resolution of the training image and low-quality image results in poor accuracy. To resolve this problem, this study proposes a collaborative trainable mechanism that integrates a global image feature extraction-based super-resolution neural network with a character recognition neural network. This collaborative trainable mechanism helps the character recognizer to be robust to inputs with varying quality in the real world. The alternative collaborative learning and character recognition performance test was conducted using the license plate image dataset among various character images, and the effectiveness of the proposed algorithm was verified using a performance test.},
  keywords={Character recognition;Neural networks;Training data;Collaborative work;Image recognition;Feature extraction;Collaborative learning;image super-resolution;character recognition;global image feature extraction},
  doi={10.1109/ACCESS.2022.3153116},
  ISSN={2169-3536},
  month={},}@ARTICLE{11000123,
  author={Shin, Minkyoung and Jeong, Seonggyun and Heo, Yong Seok},
  journal={IEEE Access}, 
  title={Anodapter: A Unified Framework for Generating Aligned Anomaly Images and Masks Using Diffusion Models}, 
  year={2025},
  volume={13},
  number={},
  pages={83483-83504},
  abstract={In industrial manufacturing, anomaly inspection performance is frequently hampered by the scarcity of anomaly data. To address this issue, synthetic anomaly masks and corresponding images are generated using various methods. These methods typically employ separate branches within a single backbone or distinct models for generating anomaly masks and images. However, such approaches frequently result in misalignment between the anomaly mask and image, and a reduction in realism, which adversely affects the performance of downstream tasks. To address these challenges, we introduce Anodapter, a unified few-shot anomaly generation model that utilizes a single diffusion model to sequentially generate well-aligned anomaly masks and images. Unlike earlier models such as AnomalyDiffusion, which use separate models for mask and image generation, Anodapter integrates both tasks into a single diffusion model through its proposed Switch Adapter, eliminating misalignment and improving realism. This unified approach not only enables the alternating generation of masks and images within a single model, but also significantly enhances both precision and realism. The model is designed to facilitate the generation of anomaly images either from generated or user-specified masks, ensuring precise alignment and high-quality results. To achieve this, Anodapter efficiently separates anomaly information into appearance and spatial components. For spatial control, we introduce a Switch Adapter that manages the spatial arrangements of anomalies. This adapter provides targeted conditioning to the backbone diffusion model to generate well-aligned anomaly masks and images. For appearance control, the model employs specialized prompts with unique identifiers, enabling selective generation of anomaly images or masks. These identifiers assist the model in learning the features of anomalous regions and the overall structure of the image. Through extensive experiments with various datasets, including MVTec AD, MVTec LOCO, and BTAD, we demonstrate that our model can generate realistic and diverse anomaly datasets. It significantly outperforms existing methods in downstream tasks such as anomaly detection, localization, and classification, both quantitatively and qualitatively. Specifically, our model achieved state-of-the-art performance, with an image-level AUROC of 98.48% in anomaly detection, a pixel-level AUROC of 98.82% in anomaly localization, and an anomaly classification accuracy of 71.11% on the MVTec AD dataset, surpassing previous approaches.},
  keywords={Inspection;Image synthesis;Anomaly detection;Adaptation models;Feature extraction;Diffusion models;Training;Location awareness;Image reconstruction;Switches;Anomaly generation;anomaly inspection;few-shot image generation},
  doi={10.1109/ACCESS.2025.3568866},
  ISSN={2169-3536},
  month={},}@ARTICLE{11037631,
  author={Wang, Zixin and Shi, Yuanming and Letaief, Khaled. B.},
  journal={IEEE Internet of Things Magazine}, 
  title={Edge Large AI Models: Collaborative Deployment and IoT Applications}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Large artificial intelligence models (LAMs) emulate human-like problem-solving capabilities across diverse domains, modalities, and tasks. By leveraging the communication and computation resources of geographically distributed edge devices, edge LAMs enable real-time intelligent services at the network edge. Unlike conventional edge AI, which relies on small or moderate-sized models for direct feature-to-prediction mappings, edge LAMs leverage the intricate coordination of modular components to enable context-aware generative tasks and multi-modal inference. We shall propose a collaborative deployment framework for edge LAM by characterizing the LAM intelligent capabilities and limited edge network resources. Specifically, we propose a collaborative training framework over heterogeneous edge networks that adaptively decomposes LAMs according to computation resources, data modalities, and training objectives, reducing communication and computation overheads during the fine-tuning process. Furthermore, we introduce a microservice-based inference framework that virtualizes the functional modules of edge LAMs according to their architectural characteristics, thereby improving resource utilization and reducing inference latency. The developed edge LAM will provide actionable solutions to enable diversified Internet-of-Things (IoT) applications, facilitated by constructing mappings from diverse sensor data to token representations and fine-tuning based on domain knowledge.},
  keywords={Training;Internet of Things;Computational modeling;Servers;Resource management;Microservice architectures;LoRa;Collaboration;Artificial intelligence;Wireless communication},
  doi={10.1109/MIOT.2025.3575766},
  ISSN={2576-3199},
  month={},}@ARTICLE{10924295,
  author={Yuan, Hao and Li, Yuan and Zhou, Kai and Fu, Yao and Zhou, Hao and Li, Zerui},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={A PDC-Based Moisture and Swelling Determination Method for Silicone Rubber Insulation}, 
  year={2025},
  volume={74},
  number={},
  pages={1-12},
  abstract={The determination of the moisture content and swelling rate of silicone rubber (SiR) insulation within fluid-filled cable terminations is crucial for gaining insights into termination insulation conditions. For this reason, this study develops an evaluation method that utilizes data augmentation and feature selection to process dielectric parameters extracted based on the polarization and depolarization current (PDC) method. First, PDC measurements on prepared SiR samples with varying moisture and swelling gradients yield dielectric fingerprint parameters identified via the extended Debye model (EDM). Then, to address the challenge of simultaneously determining two synergistic degradation factors of moisture and swelling with a limited experimental sample size, we employ the Wasserstein generative adversarial network with gradient penalty (WGAN-GP) model to generate augmented data, enhancing evaluation effectiveness. Moreover, recognizing the potential impact of redundant dielectric parameters on the evaluation model’s performance, we conduct feature selection through Shapley additive explanation (SHAP), identifying multiple charge quantity parameters as suitable inputs for the evaluation models. Finally, validation across multiple models confirms the efficacy of our proposed method.},
  keywords={Dielectrics;Moisture;Feature extraction;Training;Partial discharges;Generative adversarial networks;Cable insulation;Degradation;Data augmentation;Rubber;Data augmentation;feature selection;insulation evaluation;moisture;polarization and depolarization current (PDC);silicone oil (SO);silicone rubber (SiR);swelling},
  doi={10.1109/TIM.2025.3550637},
  ISSN={1557-9662},
  month={},}@ARTICLE{10976441,
  author={Bao, Huan and Wei, Kaimin and Wu, Yongdong and Qian, Jin and Deng, Robert H.},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Distributional Black-Box Model Inversion Attack With Multi-Agent Reinforcement Learning}, 
  year={2025},
  volume={20},
  number={},
  pages={5425-5437},
  abstract={Model Inversion (MI) attacks based on Generative Adversarial Networks (GAN) aim to recover private training data from complex deep learning models by searching codes in the latent space. However, this method merely searches in a deterministic latent space, resulting in suboptimal latent codes. Additionally, existing distributional MI schemes assume that an attacker can access the structures and parameters of the target model, which is not always feasible in practice. To address these limitations, this paper proposes a novel Distributional Black-Box Model Inversion (DBB-MI) attack by constructing a probabilistic latent space for searching private data. Specifically, DBB-MI does not require the target model’s parameters or specialized GAN training. Instead, it identifies the latent probability distribution by integrating the output of the target model with multi-agent reinforcement learning techniques. Then, it randomly selects latent codes from the latent probability distribution to uncover private data. As the latent probability distribution closely mirrors the target privacy data in the latent space, the recovered data effectively leaks the privacy of the target model’s training samples. Extensive experiments conducted on diverse datasets and networks demonstrate that our DBB-MI outperforms state-of-the-art MI attacks in terms of attack accuracy, K-nearest neighbor feature distance, and peak signal-to-noise ratio.},
  keywords={Generative adversarial networks;Closed box;Training;Codes;Data models;Data privacy;Glass box;Image reconstruction;Training data;Probability distribution;Distributional model inversion (MI) attack;deep learning;multi-agent reinforcement learning (MARL);black-box attack},
  doi={10.1109/TIFS.2025.3564043},
  ISSN={1556-6021},
  month={},}@ARTICLE{11175521,
  author={Ding, Hongwei and Huang, Nana and Wu, Yaoxin and Cui, Xiaohui},
  journal={IEEE Transactions on Multimedia}, 
  title={Improving Infrared Small Target Detection With GAN-Driven Data Augmentation}, 
  year={2025},
  volume={},
  number={},
  pages={1-16},
  abstract={Infrared small target detection (IRSTD) based on deep learning has received extensive research and application. However, deep learning models require a large amount of data to perform well, and the collection and standardization of infrared small target data is challenging, limiting the applicability of such models. To address this issue, this study proposes a data augmentation scheme for infrared small targets based on Generative Adversarial Networks (GANs). The proposed method is a two-step approach: the first step is the generation of clean backgrounds, and the second is the adaptive fusion of targets and backgrounds. In the background generation stage, we first use the Fast Marching Method (FMM) to fill background targets and obtain clean backgrounds. Then, we design a multi-generator and multi-discriminator GAN model (MGD-GAN) to generate high-quality and diverse background images. In the adaptive target-background fusion stage, we propose a dual-discriminator GAN network (FusionGAN), which allows the target mask to be adaptively fused with the background pixels. By combining real targets with generated backgrounds, new infrared small target images are generated, achieving the goal of data augmentation. Experiments conducted across three different scenarios demonstrate that the proposed data augmentation scheme effectively enhances the performance of both traditional and advanced detection models.},
  keywords={Generative adversarial networks;Data models;Data augmentation;Training;Feature extraction;Adaptation models;Object detection;Deep learning;Generators;Superresolution;Infrared small target detection;Deep learning;Data augmentation;GANs},
  doi={10.1109/TMM.2025.3613079},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{11139959,
  author={Singh, Rahul and Lande, Jayapal and Gupta, Sheifali and Saxena, Mohit and Mahajan, Shubham and Goel, Mohit Kumar},
  booktitle={2025 6th International Conference for Emerging Technology (INCET)}, 
  title={Detecting Apple Leaf Disease with EfficientNet B0 Transfer Learning Model}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Apple farming is a key aspect of global agriculture, significantly contributing to both economies and nutrition on a global level. However, apple tree farming faces numerous challenges, and the major challenge is the existence of diseases that negatively impact the overall health and productivity of the trees. Leaf diseases are a serious issue since they can potentially inflict significant damage by interfering with essential physiological processes like photosynthesis and nutrient absorption. The timely and accurate detection of diseases is of critical importance to facilitate effective control and conservation of crops. While they have been found to be useful, the traditional methods of manual examination are defined by their time-consuming nature and vulnerability to mistakes. This research explores the possibility of employing EfficientNet B0, a convolutional neural network variant, in automatically detecting apple leaf diseases, by leveraging recent advances in artificial intelligence and machine learning. This research seeks to contribute to scholarship in creating an automated system capable of detecting and classifying various diseases that target apple leaves accurately. This work gives a general overview of the methodology, experiment setup, and results achieved with EfficientNet B0. The research brings to light the capacity of EfficientNet B0 in revolutionizing apple orchard disease management practices.},
  keywords={Deep learning;Analytical models;Accuracy;Transfer learning;Manuals;Agriculture;Convolutional neural networks;Sustainable development;Diseases;Farming;Apple Leaf Diseases;classification;deep learning;convolutional neural networks;EfficientNet B0;image recognition},
  doi={10.1109/INCET64471.2025.11139959},
  ISSN={2996-4490},
  month={May},}@ARTICLE{9925992,
  author={Bi, Xia-An and Wang, Yu and Luo, Sheng and Chen, Ke and Xing, Zhaoxu and Xu, Luyun},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Hypergraph Structural Information Aggregation Generative Adversarial Networks for Diagnosis and Pathogenetic Factors Identification of Alzheimer’s Disease With Imaging Genetic Data}, 
  year={2024},
  volume={35},
  number={6},
  pages={7420-7434},
  abstract={Alzheimer’s disease (AD) is a neurodegenerative disease with profound pathogenetic causes. Imaging genetic data analysis can provide comprehensive insights into its causes. To fully utilize the multi-level information in the data, this article proposes a hypergraph structural information aggregation model, and constructs a novel deep learning method named hypergraph structural information aggregation generative adversarial networks (HSIA-GANs) for the automatic sample classification and accurate feature extraction. Specifically, HSIA-GAN is composed of generator and discriminator. The generator has three main functions. First, vertex graph and edge graph are constructed based on the input hypergraph to present the low-order relations. Second, the low-order structural information of hypergraph is extracted by the designed vertex convolution layers and edge convolution layers. Finally, the synthetic hypergraph is generated as the input of the discriminator. The discriminator can extract the high-order structural information directly from hypergraph through vertex-edge convolution, fuse the high and low-order structural information, and finalize the results through the full connection (FC) layers. Based on the data acquired from AD neuroimaging initiative, HSIA-GAN shows significant advantages in three classification tasks, and extracts discriminant features conducive to better disease classification.},
  keywords={Feature extraction;Genetics;Correlation;Data mining;Deep learning;Generators;Convolutional neural networks;Alzheimer’s disease (AD);deep learning;hypergraph structural information aggregation generative adversarial networks (HSIA-GANs);imaging genetics},
  doi={10.1109/TNNLS.2022.3212700},
  ISSN={2162-2388},
  month={June},}@INPROCEEDINGS{9005597,
  author={Liu, Ling},
  booktitle={2019 IEEE International Conference on Big Data (Big Data)}, 
  title={Deception, Robustness and Trust in Big Data Fueled Deep Learning Systems}, 
  year={2019},
  volume={},
  number={},
  pages={3-3},
  abstract={We are entering an exciting era where human intelligence is being enhanced by machine intelligence through big data fueled artificial intelligence (AI) and machine learning (ML). However, recent work shows that DNN models trained privately are vulnerable to adversarial inputs. Such adversarial inputs inject small amount of perturbations to the input data to fool machine learning models to misbehave, turning a deep neural network against itself. As new defense methods are proposed, more sophisticated attack algorithms are surfaced. This arms race has been ongoing since the rise of adversarial machine learning. This keynote provides a comprehensive analysis and characterization of the most representative attacks and their defenses. As more and more mission critical systems are incorporating machine learning and AI as an essential component in their real-world big data applications and their big data service provisioning platforms or products, understanding and ensuring the verifiable robustness of deep learning becomes a pressing challenge in the presence of adversarial attacks. This includes (1) the development of formal metrics to quantitatively evaluate and measure the robustness of a DNN prediction with respect of intentional and unintentional artifacts and deceptions, (2) the comprehensive understanding of the blind spots and the invariants in the DNN trained models and the DNN training process, and (3) the statistical measurement of trust and distrust that we can place on a deep learning algorithm to perform reliably and truthfully. In this keynote talk, I will use empirical analysis and evaluation of our cross-layer strategic teaming defense framework and techniques to illustrate the feasibility of ensuring robust deep learning.},
  keywords={Machine learning;Big Data;Robustness;Distributed databases;Conferences;Computer science},
  doi={10.1109/BigData47090.2019.9005597},
  ISSN={},
  month={Dec},}@ARTICLE{11175426,
  author={Wang, Qinghe and Jia, Xu and Li, Xiaomin and Li, Taiqing and Ma, Liqian and Zhuge, Yunzhi and Lu, Huchuan},
  journal={IEEE Transactions on Multimedia}, 
  title={StableIdentity: Inserting Anybody into Anywhere at First Sight}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={Recent advances in large pretrained text-to-image generation models have shown unprecedented capabilities for high-quality human-centric generation, however, customizing face identity is still an intractable problem. Existing methods cannot ensure stable identity preservation and flexible editability, even with several images for each subject during training. In this work, we propose StableIdentity, which allows identity-consistent recontextualization with just one face image from a person seen for the first time. More specifically, we employ a face encoder with the identity prior to encode the input face, and then calibrate the face representation to align the distribution of a space with the editability prior, which is constructed from celeb names. By incorporating identity prior and editability prior, the learned identity can be injected anywhere with various contexts. In addition, we design a masked two-phase diffusion loss to boost the pixel-level perception of the input face and maintain the diversity of generation. Extensive experiments demonstrate our method outperforms previous customization methods. In addition, the learned identity can be flexibly combined with the off-theshelf modules such as ControlNet. Notably, to the best of our knowledge, we are the first to directly inject the identity learned from a single image into video/3D generation without finetuning. We believe that the proposed StableIdentity is an important step to unify image, video, and 3D customized generation models. The code is available: https://github.com/qinghew/StableIdentity.},
  keywords={Diffusion models;Training;Faces;Text to image;Hands;Predictive models;Noise reduction;Image synthesis;Image reconstruction;Electronic mail;Text-to-image generation;diffusion models;customized generation;identity and editability prior},
  doi={10.1109/TMM.2025.3613113},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{6511940,
  author={Zhang, Wenping and Lau, Raymond Y.K. and Xia, Yunqing and Li, Chunping and Li, Wenjie Maggie},
  booktitle={2012 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology}, 
  title={Latent Business Networks Mining: A Probabilistic Generative Model}, 
  year={2012},
  volume={1},
  number={},
  pages={558-562},
  abstract={Though numerous research has been devoted to social network discovery and analysis, relatively little research has been conducted on business network discovery. The main contribution of our research is the development of a novel probabilistic generative model for latent business networks mining. Our experimental results confirm that the proposed method outperforms the well-known vector space based model by 24% in terms of AUC value.},
  keywords={Business;Companies;Collaboration;Vectors;Tablet computers;Semantics;Probabilistic logic;Electronic publishing;Computational modeling;Resource management;Latent Dirichlet Allocation;Business Networks Mining;Semi-supervised Machine Learning;Web Intelligence},
  doi={10.1109/WI-IAT.2012.195},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9965183,
  author={Gao, Yunlong and Lu, Liping and Xu, Bingrong and Chu, Duanfeng},
  booktitle={2022 6th CAA International Conference on Vehicular Control and Intelligence (CVCI)}, 
  title={Multi-dimensional Attention Network for Vehicle Re-identification}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={Vehicle re-identification (vehicle ReID) is the key point in intelligent transportation systems, which mainly focus on extracting global features by a network of surveillance cameras with non-overlapping fields of view. However, vehicle ReID becomes a more difficult task when taking several aspects into account, e.g. inter-class similarity, intra-class variability, point-of-view variability, and Spatio-temporal uncertainty, which makes feature extraction very difficult. To solve such a problem, we introduce the attention mechanism into the Convolutional Neural Network (CNN) to improve the re-recognition ability of the module. A novel attention based CNN is proposed to calculate the attention weights of multi-channels by crosss-dimensional interaction to strengthen the connection between channel attention and spatial force, which enables the network to better extract the features of vehicles. We evaluate the performance of our network on VeRi-776 and VeRi-Wild datasets currently available. The experimental results demonstrate the effectiveness of our proposed method in vehicle re- recognition tasks.},
  keywords={Uncertainty;Surveillance;Semantics;Force;Feature extraction;Cameras;Convolutional neural networks;Vehicle Re-identification;Intelligent Traffic;Attention},
  doi={10.1109/CVCI56766.2022.9965183},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10820435,
  author={Rezaei, Mohammadamin and Mosavi, Amir and Kalinin, Alexey},
  booktitle={2024 IEEE 6th International Symposium on Logistics and Industrial Informatics (LINDI)}, 
  title={Deep Learning for Reliability Prediction of Fault Tolerant Multilevel Inverter}, 
  year={2024},
  volume={},
  number={},
  pages={000057-000064},
  abstract={The summation of multiple DC low-voltage sources in series results in higher power and a higher output voltage across the load, and this type of inverter is known as a cascaded multilevel inverter (CMLI). Using a larger number of switches is one of the drawbacks of multilevel inverters (MLls) in comparison with the conventional inverters, which affects the reliability of MLI. Proper fault detection, reducing the number of switches and predicting the lifetime of components may help to compensate for the mentioned disadvantages. This paper presents a new fault tolerant MLI including an analog fault detection prioritized by lifetime of components method which is adapted to Long Short-Term Memory (LSTM) deep learning method to forecast the fault and lifetime of MLI capacitors. The experimental findings demonstrate the practicability of the proposed techniques.},
  keywords={Deep learning;Fault diagnosis;Fault tolerance;Fault detection;Fault tolerant systems;Capacitors;Multilevel inverters;Sensors;Software measurement;Long short term memory;reliability;multilevel;inverter;deep learning;LSTM;power electronics;electronics;electrical engineering;artificial intelligence;machine learning;generative AI;energy;soft computing;mathematics;applied mathematics;XAI;power supply;mechatronics;model;data science;big data;applied informatics;information systems;data mining;generative artificial intelligence;fault tolerant control;fault tolerant systems;fault tolerant computing;fault diagnosis;fault tolerance;fault detection;sustainable development;sustainable energy;SDGs},
  doi={10.1109/LINDI63813.2024.10820435},
  ISSN={2156-8804},
  month={Oct},}@INPROCEEDINGS{10820384,
  author={Jalali, Mohammad and Abghari, Hirad and Choubin, Bahram and Mosavi, Amir},
  booktitle={2024 IEEE 6th International Symposium on Logistics and Industrial Informatics (LINDI)}, 
  title={Analytic Network Process and Fuzzy Value Functions for Modeling Vulnerability of River Plain Aquifer}, 
  year={2024},
  volume={},
  number={},
  pages={151-156},
  abstract={The aim of this study is to present a modeling strategy for the vulnerability of a plain aquifer considering groundwater contamination. The model is structured based on the analytic network process (ANP) combined with fuzzy value functions. The output of the ANP model is used for developing the layers of the vulnerability map which were generated in the ArcGIS software environment. The vulnerability map provides a visual representation of the vulnerability of the aquifer. The study indicates that approximately half of the region falls under the vulnerable classes which are at risk of groundwater contamination.},
  keywords={Analytical models;Visualization;Groundwater;Water conservation;Soil;Water pollution;Software;Rivers;Contamination;Aquifers;artificial intelligence;aquifer vulnerability;analytic network process;fuzzy value function;applied mathematics;deep learning;mathematics;computer science;applied machine learning;machine learning;big data;data mining;soft computing;hydrological model;hydrology;water;data science;XAI;model;data;applied informatics;information systems;generative artificial intelligence;generative AI;sustainable development;SDGs;groundwater contamination;clean water},
  doi={10.1109/LINDI63813.2024.10820384},
  ISSN={2156-8804},
  month={Oct},}@INPROCEEDINGS{10877197,
  author={Mohd, Bassam J. and Ahmad Yousef, Khalil M. and Abu Ghalyon, Salah G.},
  booktitle={2024 25th International Arab Conference on Information Technology (ACIT)}, 
  title={A Comparative Evaluation of Retrieval-Augmented Generation For Arabic Documents}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Generative AI creates new content using AI models (i.e., LLMs) trained on large datasets. However, LLMs lack specific sources and can produce inaccurate or misleading information. Retrieval-augmented generation (RAG) improves accuracy by combining LLMs with a content store, providing evidence for responses and making the model more adaptable to changing information. This paper introduces a comparative evaluation of various generative AI models—LLama 3, LLama 3.1, Gemma, Gemma 2, Phi 3, Phi 3.5, and Phi 3.5 Mini based on their performance in answering questions derived from Arabic and English documents using the RAG locally. The models were evaluated based on their ability to answer questions of varying difficulty levels. Questions were categorized as easy, moderate, or complex. The models’ performance was measured in terms of two key metrics: response time to answer each question and the accuracy of their responses (or quality of the answer). Using RAG method, the results show that LLaMA 3.1 consistently outperformed other models in both Arabic and English languages, whereas Gemma 2 demonstrated decent results. Additionally, response time can be misleading indicators of model performance because less accurate responses require less effort and are generated more rapidly than highly accurate ones.},
  keywords={Adaptation models;Accuracy;Generative AI;Computational modeling;Retrieval augmented generation;Focusing;Time measurement;Time factors;Information technology;Testing;Generative AI;Generative Models;Machine Learning;Artificial Intelligence;Retrieval-augmented generation;large language models;Natural Language Processing;Neural Networks},
  doi={10.1109/ACIT62805.2024.10877197},
  ISSN={2831-4948},
  month={Dec},}@INPROCEEDINGS{10250591,
  author={Thaseen, Aliya and D, Kothandaraman},
  booktitle={2023 Second International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)}, 
  title={A Brief Survey on Multi Dimensional Feature Subset Based Lung Tumor Identification Model using Machine Learning Techniques}, 
  year={2023},
  volume={},
  number={},
  pages={632-637},
  abstract={Identifying malignant lung nodules from Computed Tomography (CT) scans is a complex and time-consuming task for radiologists. To ease this burden, Computer-Aided Diagnostic (CAD) systems have been developed. Over the past few years, approaches to deep learning have demonstrated excellent outcomes, often beating classical methods. Researchers are currently experimenting with a variety of deep learning strategies to boost the efficiency of CAD systems used in CT-based lung cancer detection. Each year, India sees around 75,000 new cases. The disease has a potential to be asymptomatic largely in its initial stages thus making it practically impossible to detect. In addition, the elements such as respiration nodules can generate blurry photos and introduce other noises in the images. Many researchers have recommended alternative strategies based on their studies for lung tumor detection. Several CAD techniques and systems have been proposed, developed, and introduced recently in an effort to leverage computer technology to address this issue. Machine learning and deep learning are used by these systems, and there are also other ways based on image processing that can be used to gauge the cancer's malignancy. In this research, numerous techniques for lung cancer detection is analyzed and the limitations are identified that helps the researchers for designing efficient and accurate models for lung cancer detection},
  keywords={Deep learning;Solid modeling;Analytical models;Computed tomography;Biological system modeling;Lung cancer;Lung;Lung Cancer;Computer Tomography;Image Processing;Feature Extraction;Machine Learning Lung Tumor Region},
  doi={10.1109/ICAISS58487.2023.10250591},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10820415,
  author={Kulikov, Anatoliy and Kaverin, Vladimir and Ardabili, Sina and Mosavi, Amir and Nabipour, Narjes and Kalinin, Alexey},
  booktitle={2024 IEEE 6th International Symposium on Logistics and Industrial Informatics (LINDI)}, 
  title={Machine Learning Modeling and Simulation of Asynchronous Electric Drive}, 
  year={2024},
  volume={},
  number={},
  pages={000095-000102},
  abstract={This study focuses on simulating and modeling the behavior of a frequency-controlled asynchronous electric drive using MATLAB/Simulink. The control system is designed using the root locus method along with the Vyshnegradsky diagram. The research examines the system's dynamic response during startup under normal load. The results indicate that the electromagnetic torque can be optimized, with minimal overshot, by selecting specific Vyshnegradsky parameters. Experimental validation shows that the control system achieves an acceptable level of accuracy. Additionally, machine learning techniques such as support vector machine (SVM), random forest (RF), and k-nearest neighbor (k-NN) are used to predict the behavior of key system variables. Evaluation of the models was conducted using two frequently used criteria. i.e., root mean square error and correlation coefficient. RF provided lower RMSE and higher CC in comparison with SVM and k-NN. On the other hand, k-NN provided higher CC, but it generated higher RMSE in comparison with RF. Accordingly, in the training phase, RF was selected for the optimum modeling.},
  keywords={Support vector machines;Radio frequency;Training;Torque;PI control;System dynamics;Simulation;Electromagnetics;Root mean square;Random forests;asynchronous electric motor;energy efficiency;frequency converter;induction motor;asynchronous motor;ensemble;power electronics;electronics;electrical engineering;artificial intelligence;machine learning;generative AI;energy;soft computing;mathematics;applied mathematics;XAI;mechatronics;model;data science;big data;applied informatics;information systems;data mining;generative artificial intelligence;fault tolerant control;fault tolerant systems;fault tolerance;electric machines;fault detection;sustainable development;sustainable energy;SDGs;electric drive;mining industry},
  doi={10.1109/LINDI63813.2024.10820415},
  ISSN={2156-8804},
  month={Oct},}@ARTICLE{9984938,
  author={Chundawat, Vikram S and Tarun, Ayush K and Mandal, Murari and Lahoti, Mukund and Narang, Pratik},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={A Universal Metric for Robust Evaluation of Synthetic Tabular Data}, 
  year={2024},
  volume={5},
  number={1},
  pages={300-309},
  abstract={Synthetic tabular data generation becomes crucial when real data are limited, expensive to collect, or simply cannot be used due to privacy concerns. However, producing good quality synthetic data is challenging. Several probabilistic, statistical, generative adversarial networks and variational autoencoder-based approaches have been presented for synthetic tabular data generation. Once generated, evaluating the quality of the synthetic data is quite challenging. Some of the traditional metrics have been used in the literature, but there is lack of a common, robust, and single metric. This makes it difficult to properly compare the effectiveness of different synthetic tabular data generation methods. In this article, we propose a new universal metric, TabSynDex, for the robust evaluation of synthetic data. The proposed metric assesses the similarity of synthetic data with real data through different component scores, which evaluate the characteristics that are desirable for “high-quality” synthetic data. Being a single score metric and having an implicit bound, TabSynDex can also be used to observe and evaluate the training of neural network-based approaches. This would help in obtaining insights that was not possible earlier. We present several baseline models for comparative analysis of the proposed evaluation metric with existing generative models. We also give a comparative analysis between TabSynDex and existing synthetic tabular data evaluation metrics. This shows the effectiveness and universality of our metric over the existing metrics.},
  keywords={Measurement;Synthetic data;Data models;Training;Data privacy;Evaluation metrics;generative adversarial networks (GANs);generative models;tabular data synthesis},
  doi={10.1109/TAI.2022.3229289},
  ISSN={2691-4581},
  month={Jan},}@INPROCEEDINGS{10083340,
  author={Das, Athirasree and Sebastian, Linda},
  booktitle={2023 Advanced Computing and Communication Technologies for High Performance Applications (ACCTHPA)}, 
  title={A Comparative Analysis and Study of a Fast Parallel CNN Based Deepfake Video Detection Model with Feature Selection (FPC-DFM)}, 
  year={2023},
  volume={},
  number={},
  pages={1-9},
  abstract={Deep learning is an efficient and practical method that has been widely applied in numerous fields. Videos created with swapped faces in a video, altered facial emotions, changed genders, fraudulent video content generation, and altered facial features are referred to as “DeepFake” videos. These videos are created utilizing deep learning technology called generative adversarial networks. Fake videos are used to stir up political agitation, commit acts of terrorism, and demand money. A fast Parallel CNN-based deepfake video detection model with feature selection is the new model we presented in this project (FPC-DFM). In order to identify Deepfake videos, the FPC DFM architecture uses feature extraction, feature selection, and prediction. The FPC-DFM model extracted features using three convolutional models: EfficientN et, VGG16, and ResNet as well as Principal Component Analysis (PCA)-based feature selection and Support Vector Machine-based classification. We offer a new architecture for capturing the video frame features that will be utilized to determine if the video is real or fake by utilizing deep learning techniques. In comparison to other pre-trained models like VGG16-TL, EfficientNet-TL and Resnet50-TL and our results demonstrated that FPC-DFM has the best performance and the highest accuracy of 96.50%.},
  keywords={Deep learning;Deepfakes;Analytical models;Computational modeling;Terrorism;Neural networks;Support vector machine classification;Deepfake video detection;Convolutional neural network (CNN);Principal Component Analysis;Support vector machine (SVM)},
  doi={10.1109/ACCTHPA57160.2023.10083340},
  ISSN={},
  month={Jan},}@ARTICLE{10918977,
  author={Noor Asmat, Bibi and Bilal, Hafiz Syed Muhammad and Uddin, M. Irfan and Karim, Faten Khalid and Mostafa, Samih M.},
  journal={IEEE Access}, 
  title={Utilizing Conditional GANs for Synthesis of Equilibrated Hyperspectral Data to Enhance Classification and Mitigate Majority Class Bias}, 
  year={2025},
  volume={13},
  number={},
  pages={49271-49289},
  abstract={A land cover scene is described by vegetation, urban infrastructure, water bodies, bare soil, and many other physical materials. Satellite imagery and remote sensing techniques analyze the scene for the management of natural resources and environmental changes. Hyperspectral Imaging (HSI) plays a vital role in land cover classification due to its rich spectral information, which captures a broader range of wavelengths. This enhanced spectral data allows for more precise identification and differentiation of land cover types. Imbalanced class distributions in HSI classification hinder rare class performance, as these critical classes are often underrepresented in training data. GANs offer a solution by generating synthetic samples to address this scarcity. However, current GAN-based methods use a static up-sampling mechanism for minority classes and generate samples for even larger classes. Furthermore, these models use the largest class as the scaling factor for minority classes, leading to excessive synthetic sample generation for smaller classes. Although these methods achieve class balance, but often suffer from synthetic bias due to over-reliance on generated samples, especially for minority classes. As a result, this can cause dataset inflation, compromise the authenticity of minority class representations, and potentially degrade the model’s performance on real-world data. To overcome this limitation, we introduce a novel approach that dynamically balances class distributions by leveraging the smallest class size as a scaling factor. Our proposed model, Spectra Balance GAN (SB-GAN), ensures efficient and adaptive sample generation, producing only the necessary synthetic samples while preserving the integrity of the dataset and maintaining a manageable size. The primary novelty of this model lies in its adaptive nature of class balancing mechanism and an integrated conditional GAN to generate only the required samples, ensuring efficient and balanced hyperspectral image classification. The efficacy of the SB-GAN approach has been evaluated using three publicly available datasets: Indian Pines, Pavia University, and Salinas. The approach achieved an average classification accuracy of 99% across these datasets, demonstrating its potential to significantly improve the classification of rare classes in HSI scenes.},
  keywords={Land surface;Accuracy;Hyperspectral imaging;Data models;Generative adversarial networks;Generators;Environmental monitoring;Deep learning;Adaptation models;Urban planning;Hyperspectral imaging;HSI;GAN;cGAN;generative adversarial network;conditional generative adversarial network;down sampling;up sampling;synthetic;augmentation;imbalance class;land cover scene},
  doi={10.1109/ACCESS.2025.3550057},
  ISSN={2169-3536},
  month={},}@ARTICLE{10937314,
  author={Zhang, Shutao and Xue, Ye and Tang, Zhiwei and Wang, Hao and Shen, Chao and Shi, Qingjiang and Chang, Tsung-Hui},
  journal={IEEE Transactions on Wireless Communications}, 
  title={Robust Network Optimization by Deep Generative Models and Stochastic Optimization}, 
  year={2025},
  volume={24},
  number={7},
  pages={6069-6084},
  abstract={Wireless network optimization is essential for improving the network performance in mobile communications. However, due to the stochastic nature of wireless networks, existing schemes based on analytical models and deterministic optimization are less reliable. To this end, we design a framework for robust network optimization based on deep generative models and stochastic optimization. Inspired by the powerful diffusion process, we propose a deep generative simulator to capture the statistical distribution of the network performance. By sampling from the deep generative simulator, we can alleviate the inherent uncertainty related to the network performance and devise an innovative expectation-quantile-based stochastic objective function. The inner expectation is designed for the temporal statistics, while the outer quantile is developed for the spatial statistics. This designated two-tier objective function is capable of mitigating temporal fluctuations and ensuring satisfactory network performance across most geographical grids, thereby achieving robustness. To solve this stochastic optimization problem, a smooth zeroth-order approach is introduced by taking advantage of the unique structure of quantile functions. Through theoretical performance analysis and simulation experiments with real-world datasets, we demonstrate the superiority of our approach over other baseline schemes, highlighting its practical utility in robust network optimization.},
  keywords={Optimization;Wireless networks;Stochastic processes;Uncertainty;Linear programming;Mathematical models;Big Data;Diffusion processes;Predictive models;Fluctuations;Generative diffusion model;quantile function;robust approach;wireless network optimization},
  doi={10.1109/TWC.2025.3551316},
  ISSN={1558-2248},
  month={July},}@INPROCEEDINGS{10927222,
  author={Chukwu, Chikodili Mary-Zita and Abiola, Oluwatoyin Bunmi and Saka-Balogun, Olaide Yetunde and Chukwu, Patrick Chisom and Chukwu, Chibuzor Emmanuel and Oyelami, Funmilayo Helen and Babalola, Gbemisola and Sanya, Oluwafemi Akindele and Atachin, Aondoaseer James},
  booktitle={2024 IEEE 5th International Conference on Electro-Computing Technologies for Humanity (NIGERCON)}, 
  title={Development of a Machine Learning Based Predictive Model for Event Management}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Event management is crucial for the success of any event, as a well-managed event leads to high attendee and client satisfaction. Traditional event management systems emphasize efficient tracking of user data and electronic booking but often lack the ability to provide clients with pre-visualization experience of their event venue based on their specifications. This study addresses this gap by proposing an event management system capable of generating wedding event design styles based on user inputs using a deep learning model. The system leverages a dataset of diverse wedding decoration images, undergoing preprocessing, feature extraction, and image labeling to facilitate the deep learning model, Stable Diffusion, in understanding and predicting new decoration styles from user inputs. Stable Diffusion, an image generative deep learning model, learns from past datasets to create images from text prompts. The system features a web application with a Graphical User Interface (GUI) for user input, generating images based on these inputs. After 500 epochs, the system achieved an accuracy of 0.9765 using precision metrics. The system offers a predictive modeling approach to provide clients with pre-visualization experience, creating decoration images tailored to their preferences. Future work includes enhancing the model's performance by training with larger datasets and expanding the application to other event types such as birthdays and funerals.},
  keywords={Deep learning;Measurement;Training;Humanities;Accuracy;Image synthesis;Predictive models;Feature extraction;Labeling;Graphical user interfaces;event;event management;design;image generation;user specification},
  doi={10.1109/NIGERCON62786.2024.10927222},
  ISSN={2377-2697},
  month={Nov},}@ARTICLE{10582783,
  author={Jiang, Zihan and Ma, Yiqun and Shi, Bingyu and Lu, Xin and Xing, Jian and Gonçalves, Nuno and Jin, Bo},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Social NSTransformers: Low-Quality Pedestrian Trajectory Prediction}, 
  year={2024},
  volume={5},
  number={11},
  pages={5575-5588},
  abstract={This article introduces a novel model for low-quality pedestrian trajectory prediction, the social nonstationary transformers (NSTransformers), that merges the strengths of NSTransformers and spatiotemporal graph transformer (STAR). The model can capture social interaction cues among pedestrians and integrate features across spatial and temporal dimensions to enhance the precision and resilience of trajectory predictions. We also propose an enhanced loss function that combines diversity loss with logarithmic root mean squared error (log-RMSE) to guarantee the reasonableness and diversity of the generated trajectories. This design adapts well to complex pedestrian interaction scenarios, thereby improving the reliability and accuracy of trajectory prediction. Furthermore, we integrate a generative adversarial network (GAN) to model the randomness inherent in pedestrian trajectories. Compared to the conventional standard Gaussian distribution, our GAN approach better simulates the intricate distribution found in pedestrian trajectories, enhancing the trajectory prediction's diversity and robustness. Experimental results reveal that our model outperforms several state-of-the-art methods. This research opens the avenue for future exploration in low-quality pedestrian trajectory prediction.},
  keywords={Pedestrians;Trajectory;Transformers;Predictive models;Generative adversarial networks;Enhanced loss function;generative adversarial network (GAN);nonstationary transformers (NSTransformers);pedestrian trajectory prediction},
  doi={10.1109/TAI.2024.3421175},
  ISSN={2691-4581},
  month={Nov},}@ARTICLE{10078231,
  author={Li, Tianyi and Yang, Genke and Chu, Jian},
  journal={IEEE Transactions on Cybernetics}, 
  title={Implicit Posteriori Parameter Distribution Optimization in Reinforcement Learning}, 
  year={2024},
  volume={54},
  number={5},
  pages={3051-3064},
  abstract={Efficient and intelligent exploration remains a major challenge in the field of deep reinforcement learning (DRL). Bayesian inference with a distributional representation is usually an effective way to improve the exploration ability of the RL agent. However, when optimizing Bayesian neural networks (BNNs), most algorithms need to specify an explicit parameter distribution such as a multivariate Gaussian distribution. This may reduce the flexibility of model representation and affect the algorithm performance. Therefore, to improve sample efficiency and exploration based on Bayesian methods, we propose a novel implicit posteriori parameter distribution optimization (IPPDO) algorithm. First, we adopt a distributional perspective on the parameter and model it with an implicit distribution, which is approximated by generative models. Each model corresponds to a learned latent space, providing structured stochasticity for each layer in the network. Next, to make it possible to optimize an implicit posteriori parameter distribution, we build an energy-based model (EBM) with value function to represent the implicit distribution which is not constrained by any analytic density function. Then, we design a training algorithm based on amortized Stein variational gradient descent (SVGD) to improve the model learning efficiency. We compare IPPDO with other prevailing DRL algorithms on the OpenAI Gym, MuJoCo, and Box2D platforms. Experiments on various tasks demonstrate that the proposed algorithm can represent the parameter uncertainty implicitly for a learned policy and can consistently outperform competing approaches.},
  keywords={Bayes methods;Uncertainty;Artificial neural networks;Mathematical models;Inference algorithms;Generators;Reinforcement learning;Bayesian inference;exploration;parameter distribution;reinforcement learning (RL)},
  doi={10.1109/TCYB.2023.3254596},
  ISSN={2168-2275},
  month={May},}@ARTICLE{9811392,
  author={Zhang, Yiwen and Zhong, Liming and Shu, Hai and Dai, Zhenhui and Zheng, Kaiyi and Chen, Zefeiyun and Feng, Qianjin and Wang, Xuetao and Yang, Wei},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Cross-Task Feedback Fusion GAN for Joint MR-CT Synthesis and Segmentation of Target and Organs-at-Risk}, 
  year={2023},
  volume={4},
  number={5},
  pages={1246-1257},
  abstract={The synthesis of computed tomography (CT) images from magnetic resonance imaging (MR) images and segmentation of target and organs-at-risk (OARs) are two important tasks in MR-only radiotherapy treatment planning (RTP). Some methods have been proposed to utilize the paired MR and CT images for MR-CT synthesis or target and OARs segmentation. However, these methods usually handle synthesis and segmentation as two separate tasks, and ignore the inevitable registration errors in paired images after standard registration. In this article, we propose a cross-task feedback fusion generative adversarial network (CTFF-GAN) for joint MR-CT synthesis and segmentation of target and OARs to enhance each task’s performance. Specifically, we propose a cross-task feedback fusion (CTFF) module to feedback the semantic information from the segmentation task to the synthesis task for the anatomical structure correction in synthetic CT images. Besides, we use CT images synthesized from MR images for multimodal segmentation to eliminate the registration errors. Moreover, we develop a multitask discriminator to urge the generator to devote more attention to the organ boundaries. Experiments on our nasopharyngeal carcinoma dataset show that CTFF-GAN achieves impressive performance with MAE of 70.69 $\pm$ 10.50 HU, SSIM of 0.755 $\pm$ 0.03, and PSNR of 27.44 $\pm$ 1.20 dB in synthetic CT, and the mean dice of 0.783 $\pm$ 0.075 in target and OARs segmentation. Our CTFF-GAN outperforms state-of-the-art methods in both the synthesis and segmentation tasks.},
  keywords={Image segmentation;Computed tomography;Task analysis;Training;Standards;Generative adversarial networks;Image edge detection;Feedback fusion mechanism;generative adversarial network;joint synthesis and segmentation;MR-only radiotherapy treatment planning (RTP)},
  doi={10.1109/TAI.2022.3187388},
  ISSN={2691-4581},
  month={Oct},}@INPROCEEDINGS{10483780,
  author={Lu, Zeyu and Wu, Chengyue and Chen, Xinyuan and Wang, Yaohui and Bai, Lei and Qiao, Yu and Liu, Xihui},
  booktitle={2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, 
  title={Hierarchical Diffusion Autoencoders and Disentangled Image Manipulation}, 
  year={2024},
  volume={},
  number={},
  pages={5362-5371},
  abstract={Diffusion models have attained impressive visual quality for image synthesis. However, how to probe and manipulate the latent space of diffusion models has not been extensively explored. Prior work diffusion autoencoders encode the semantic representations with a single latent code, neglecting the low-level details and leading to entangled representations. To mitigate those limitations, we propose Hierarchical Diffusion Autoencoders (HDAE) that exploits the coarse-to-fine feature hierarchy for the latent space of diffusion models. Our HDAE converges 2+ times faster and encodes richer and more comprehensive coarse-to-fine representations of images. The hierarchical latent space inherently disentangles different semantic levels of features. Furthermore, we propose a truncated feature based approach for disentangled image manipulation. We demonstrate the effectiveness of our proposed HDAE with extensive experiments and applications on image reconstruction, style mixing, controllable interpolation, image editing, and multi-modal semantic image synthesis. The code will be released upon acceptance.},
  keywords={Interpolation;Visualization;Computer vision;Codes;Image synthesis;Semantics;Aerospace electronics;Algorithms;Generative models for image;video;3D;etc.;Applications;Arts / games / social media},
  doi={10.1109/WACV57701.2024.00529},
  ISSN={2642-9381},
  month={Jan},}@INPROCEEDINGS{9724900,
  author={Shang, Qiqi and Hu, Lingxi and Li, Quanfeng and Long, Wei and Jiang, Linhua},
  booktitle={2021 3rd International Conference on Artificial Intelligence and Advanced Manufacture (AIAM)}, 
  title={A Survey of Research on Image Style Transfer Based on Deep Learning}, 
  year={2021},
  volume={},
  number={},
  pages={386-391},
  abstract={The explosive growth of graphics card computing power is accompanied by the rise of deep learning, and the development of style transfer has also ushered in a new stage. And this technology is widely used in all aspects of life. This paper firstly introduces the traditional image style transfer method, and then focuses on the image style transfer method based on deep learning that has emerged in recent years. These image style transfer methods, based on convolutional neural network and generative adversarial network, are introduced respectively. Finally, some problems that exist in the current image style transfer and future development trends are discussed.},
  keywords={Deep learning;Graphics;Neural networks;Market research;Generative adversarial networks;Explosives;Convolutional neural networks;deep learning;style transfer;convolutional neural network;generative adversarial network},
  doi={10.1109/AIAM54119.2021.00084},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10356420,
  author={Li, Xiangjuan and Li, Feifan and Li, Yang and Pan, Quan},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={PGN: A Perturbation Generation Network Against Deep Reinforcement Learning}, 
  year={2023},
  volume={},
  number={},
  pages={611-618},
  abstract={Deep reinforcement learning has advanced greatly and applied in many areas. In this paper, we explore the vulnerability of deep reinforcement learning by proposing a novel generative model for creating effective adversarial examples to attack the agent. Our proposed model can achieve both targeted attacks and untargeted attacks. Considering the specificity of deep reinforcement learning, we propose the action consistency ratio as a measure of stealthiness, and a new measurement index of effectiveness and stealthiness. Experiment results show that our method can ensure the effectiveness and stealthiness of attack compared with other algorithms. Moreover, our methods are considerably faster and thus can achieve rapid and efficient verification of the vulnerability of deep reinforcement learning.},
  keywords={Deep learning;Perturbation methods;Reinforcement learning;Generative adversarial networks;Robustness;Indexes;Time complexity;Deep reinforcement learning;adversarial attack;generative network},
  doi={10.1109/ICTAI59109.2023.00096},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{10933705,
  author={Zheng, Xintao and Wu, Chenyang and Sun, Jian and He, Haiquan and Wu, Chunsheng},
  booktitle={2024 5th International Conference on Computer, Big Data and Artificial Intelligence (ICCBD+AI)}, 
  title={Research on Commutation Failure Fault Diagnosis in HVDC Transmission Systems Based on WGAN and DT-SVM}, 
  year={2024},
  volume={},
  number={},
  pages={513-519},
  abstract={Commutation failure is a typical fault in high-voltage direct current (HVDC) transmission systems. It can lead to drastic changes in a series of electrical parameters, such as the voltage on the inverter side and the direct current, significantly impacting the safety and stability of the receiving AC system. Therefore, accurate and timely diagnosis of commutation failure is crucial for implementing subsequent control measures to prevent maloperation of protection devices. To tackle the difficulty in accurately diagnosing commutation failure faults under the influence of multiple factors, a fault diagnosis method based on a combination of Wasserstein Generative Adversarial Network (WGAN) and Decision Tree Support Vector Machine (DT-SVM) is proposed. Firstly, the WGAN is employed to augment the sample data of commutation failure faults. Then, a DT-SVM-based fault diagnosis model is constructed. Finally, the augmented sample data is analyzed for fault diagnosis. Experimental results demonstrate that the proposed method can accurately identify the types of commutation failure faults in HVDC transmission systems.},
  keywords={Fault diagnosis;Support vector machines;Commutation;HVDC transmission;High-voltage techniques;Generative adversarial networks;Stability analysis;Inverters;Decision trees;Protection;commutation failure;fault diagnosis;wasserstein generative adversarial network;support vector machine;decision tree},
  doi={10.1109/ICCBD-AI65562.2024.00091},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10873237,
  author={Yang, Ye and Wang, Wen and Zhong, Yulu and Jin, Chunhua and Zhao, Chenfang and Qiu, Baomin and Jia, Wenjie},
  booktitle={2024 International Seminar on Artificial Intelligence, Computer Technology and Control Engineering (ACTCE)}, 
  title={Short-Term EVs Charging Load Prediction Under Low-quality Data Environment Based on GRU-GAN-GOA-MKELM Framework}, 
  year={2024},
  volume={},
  number={},
  pages={145-152},
  abstract={The precise forecasting of electric vehicles (EVs) load can provide reference for assessing the influence of EVs on the electricity network and optimizing the operation and allocation of the electricity network. Nevertheless, as the recorded dataset of the EV battery charging stations are difficult to collect, obtaining accurate prediction results with scarce EVs load data is challenging. On the one hand, the missing data exert great influence on forecasting values. On the other hand, a forecasting framework with superior precision should be trained with large amount of data. Aiming at realizing high accuracy EVs load prediction results utilizing scarce data, a data generation approach in terms of a generative adversarial network (GAN) is put forward. This method can generate high quality data from the scarce initial data to enhance prediction precision. Additionally, the prediction framework is established on the basis of the multi-kernel extreme learning machine (MKELM) combining poly and RBF kernel functions, parameters of which are optimally chosen via the grasshopper optimization algorithm (GOA). Through comparing with the five comparison models and three data generation methods, the validity and feasibility of the established EVs load prediction framework is verified.},
  keywords={Hands;Predictive models;Data collection;Prediction algorithms;Generative adversarial networks;Data models;Forecasting;Kernel;Optimization;Load modeling;EV load prediction;Data generation;Generative adversarial networks;Grasshopper optimization algorithm;Multi-kernel extreme learning machine},
  doi={10.1109/ACTCE65085.2024.00037},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10574538,
  author={Richter, Anna and Ijaradar, Jyotirmaya and Wetzker, Ulf},
  booktitle={2024 3rd International Conference on Artificial Intelligence For Internet of Things (AIIoT)}, 
  title={Iterative Imputation of Incomplete Wireless Network Traffic using Adversarial Learning and a Two-Stage Approach}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In modern industries, wireless communication technologies are the driver of flexible information transfer. To meet certain communication requirements like reliability, low latency and a specific data rate, constant monitoring and analysis of the captured data is necessary. Passive monitoring is a technique for tracking the communication between devices on link-level. Under certain conditions, the monitoring device loses information (data packets) from time to time. To avoid erroneous data analysis results, incomplete traces have to be reconstructed by imputation. In the present work, we propose a deep learning based imputation approach, using the concept of Generative Adversarial Networks (GANs). For our experiments we created a simulated data set using ns-3. The proposed model could outperform the selected baseline methods. We further improved the result by implementing a second stage of imputation based on the Expectation Maximization (EM) algorithm.},
  keywords={Industries;Deep learning;Data analysis;Wireless networks;Generative adversarial networks;Reliability;Iterative methods;imputation;multivariate time series;wireless networks;WiFi;Generative Adversarial Networks},
  doi={10.1109/AIIoT58432.2024.10574538},
  ISSN={},
  month={May},}@INPROCEEDINGS{10605254,
  author={Sintunata, Vicky and Liu, Siying and Nguyen Van, Dinh and Lim, Zhao Yong and Zhikuan, Ryan Lee and Wang, Yue and Feng, Jack Ho Jun and Leman, Karianto},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Unsupervised Latent Regression through Information Maximization - Contrastive Regularized GAN}, 
  year={2024},
  volume={},
  number={},
  pages={1468-1473},
  abstract={Most of labelled image public datasets are discrete in nature, e.g. cat vs dog, human, car, etc. With the growing complexity of tasks, fine-grained label data is needed. Fine-grained labels are costly because there is a need for experts to label them. Generative Adversarial Network (GAN) has been gaining a lot of attentions due to its ability to not only generate realistic images but also to disentangle the attributes of the images. Unfortunately, GAN’s disentanglement methods usually lack the ability to quantify such attributes. The objective of this work is to quantify the attributes of the target (object/image) based on the disentangled properties without supervision. In order to get the (disentangled) attributes, we leverage GAN with information maximization and contrastive regularizer. Regression is done by adding additional layer to the contrastive networks of the model. The regression quality of the proposed method is quantified by order quality measured using normalized Kendall’s Tau. Furthermore, an application in denoising image is also presented.},
  keywords={Noise reduction;Dogs;White noise;Generative adversarial networks;Complexity theory;Automobiles;Task analysis;Generative Adversarial Network;Regression;Disentanglement;Gaussian White Noise Denoising},
  doi={10.1109/CAI59869.2024.00264},
  ISSN={},
  month={June},}@INPROCEEDINGS{11041153,
  author={V, Banupriya and L, Rakesh and T, Seventheesh and M, Gowdameshwar},
  booktitle={2025 3rd International Conference on Artificial Intelligence and Machine Learning Applications Theme: Healthcare and Internet of Things (AIMLA)}, 
  title={Forensic Face Sketching and Recognition using Deep Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The research proposes a new forensic face sketching and recognition system built on deep learning techniques to improve criminal identification capabilities. The method uses a mix of Convolutional Neural Networks (CNNs) and also Generative Adversarial Networks (GANs) to produce accurate facial drawings from text descriptions that can then be compared to real-world face photos. This method resolves traditional sketch recognition issues through automation which results in improved precision and more consistent outcome generation. A real and synthesized facial image dataset provides foundation for training as the system implements both augmentation and normalization methods. thrown results show that sketch-to-photograph matching provides accurate outcomes which support reliable forensic investigation output. The new system drives substantial improvements to forensic technology by executing more precise identifications together with reduced human mistakes.},
  keywords={Deep learning;Training;Accuracy;Face recognition;Forensics;Generative adversarial networks;Reliability;Convolutional neural networks;Security;Standards;Forensics;Recognition system;Face Recognition;Convolutional Neural Networks;Generative Adversarial Networks;Facial sketches;Deep learning},
  doi={10.1109/AIMLA63829.2025.11041153},
  ISSN={},
  month={April},}@INPROCEEDINGS{11081065,
  author={Zhao, Huafei and Abisado, Mideth},
  booktitle={2025 3rd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS)}, 
  title={A Survey of Low-light Image Enhancement Algorithms based on Deep Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1191-1196},
  abstract={Low-light image enhancement (LLIE) represents a critical challenge in computer vision, focusing on improving image visibility while preserving fine details and natural color fidelity. While traditional approaches like histogram equalization and Retinex-based methods have been widely used, they often suffer from noise amplification and color distortion artifacts. Recent advances in deep learning have revolutionized this field, achieving unprecedented performance. However, the rapid proliferation and diverse nature of these deep learning techniques necessitate a comprehensive and systematic review to consolidate current knowledge, structure the evolving landscape, and identify key trends and challenges. This paper systematically reviews state-of-the-art deep learning methods for LLIE, including convolutional neural network (CNN)-based architectures, generative adversarial networks (GANs), and Transformer models. Furthermore, we comprehensively analyze benchmark datasets, standardized evaluation metrics, and persistent challenges in the field, while also outlining promising directions for future research.},
  keywords={Deep learning;Surveys;Measurement;Adaptation models;Image color analysis;Lighting;Generative adversarial networks;Convolutional neural networks;Image enhancement;Systematic literature review;Low-light image enhancement;survey;Convolutional Neural Network;Generative Adversarial Networks;Deep Learning},
  doi={10.1109/ICSSAS66150.2025.11081065},
  ISSN={},
  month={June},}@INPROCEEDINGS{10963119,
  author={Upeksha, Sanduni and Samarasinghe, Dumindu T. and Sanochana, Mithun and Samarathunga, Sapni S. and Rajamanthri, Lochana and Samarakkody, Takshila and Aluthwala, Chathuni},
  booktitle={2025 5th International Conference on Advanced Research in Computing (ICARC)}, 
  title={The Influence of Generative AI on work-life balance among female software professionals in Sri Lanka}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={This study explores the role of generative artificial intelligence on work-life balance among female software professionals in Sri Lanka's software industry. This qualitative study explores the influence of Generative Artificial Intelligence (GenAI) tools on workload, productivity, and overall well-being to show how these technologies uniquely shape professional and personal lives within this demographic group. Data were gathered through semi-structured interviews with 15 female software professionals from various job roles, including software engineers, quality assurance engineers, system engineers, Development and Operations (DevOps) engineers, and project managers. Using thematic analysis, findings disclose that generative AI is mostly utilized for automation, communication and collaboration, creativity and innovation, and decision support, with ChatGPT being the most widely used tool. These tools will enable professionals to streamline the workload, increase efficiency, reduce overtime, and maintain healthy working conditions. The insights of this study yield important implications for employers and government organizations such as the Department of Labor, explicitly pointing out how generative AI can be instrumented to create a favorable work environment. Thus, by applying generative AI solutions, the key stakeholders of the Sri Lankan software industry can create work conditions crucial for the work-life balance of women to enhance organizational performance as well as the work-related well-being of female software professionals.},
  keywords={Industries;Productivity;Employee welfare;Training;Technological innovation;Generative AI;Software;Teamwork;Stakeholders;Creativity;Female Software Professionals;Generative AI;Software Industry;Work-Life Balance},
  doi={10.1109/ICARC64760.2025.10963119},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10803287,
  author={Shi, Zixin and Huang, Linjun and Wang, Haolin},
  booktitle={2024 IEEE International Conference on Medical Artificial Intelligence (MedAI)}, 
  title={Predicting Complications of Cirrhosis using Synthetic Data Generation Enhanced Dynamic Classifier Selection}, 
  year={2024},
  volume={},
  number={},
  pages={260-267},
  abstract={Early identification of the risk of complications in cirrhosis is essential for facilitating timely interventions, personalized treatment plans and better patient management. However, developing data-driven models using real-world Electronic Health Records (EHRs) data is often hindered by challenges related to data accessibility, integrity, sparsity and class imbalance. Synthetic data that captures the characteristics and patterns of real-world EHRs data can be used for model development and evaluation that effectively addresses these data-related issues. In this study, we propose a dynamic classifier selection-based framework that incorporates both real-world EHRs data and synthetic data generated by generative adversarial networks. The framework trains a diverse set of heterogeneous classifiers, leveraging the benefits of both data sources. By utilizing dynamic classifier selection, the framework adaptively selects the best classifier based on the specific characteristics of the input data. The proposed framework was assessed through experiments to evaluate its effectiveness in the early prediction of the prevalence of acute on chronic liver failure and hepatic encephalopathy. The experimental results consistently demonstrate the superior performance of the proposed framework compared to baseline approaches. This study showcases the potential of the framework to improve clinical predictions and contribute to advancing our understanding of disease progression.},
  keywords={Soft sensors;Decision making;Liver;Data collection;Generative adversarial networks;Data models;Electronic medical records;Synthetic data;Diseases;Context modeling;Electronic Health Records;Complications;Synthetic Data;Generative Adversarial Networks;Dynamic Classifier Selection},
  doi={10.1109/MedAI62885.2024.00040},
  ISSN={},
  month={Nov},}@ARTICLE{10564147,
  author={Li, Min and Zhang, Ying and Tian, Yanping and Wang, Junyin and Du, Chenghu},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={HUMOD: High-Quality Human Modeling From Monocular Virtual Try-On Image}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={Monocular human modeling is a complex task involving fitting in-shop clothing onto a reference person while reconstructing its 3D model. However, previous methods face inherent challenges, including unpaired clothing-person images, unnatural clothing formations, and inaccurate 3D modeling. To tackle these challenges, we propose a new monocular HUman MODeling pipeline, HUMOD, which consists of two key parts, i.e. an image-based virtual try-on and a monocular human modeling. In our design, we introduce the Semantic Map Prediction Network to infer predictable "after-try-on" semantic maps by leveraging spatial prior information. Additionally, we design a spatial-aware clothing alignment network with a first proposed bidirectional feature matching to accurately align the shape of the clothing with the pose of the human body. Finally, we propose a novel multi-scale perception attention network to carve the human mesh by feeding image-based try-on results from try-on synthesis network. Notably, the multi-scale perception attention network is the first lightweight structure that integrates an edge detection operator and a texture feature description operator for double-depth maps estimating of human mesh. Our experimental results demonstrate that our approach outperforms state-of-the-art methods in both qualitative and quantitative evaluations with better-preserved details and more accurate 3D meshes.},
  keywords={Clothing;Three-dimensional displays;Semantics;Solid modeling;Computational modeling;Deformation;Predictive models;Human modeling;virtual try-on;depth map;generative model},
  doi={10.1109/TCE.2024.3416835},
  ISSN={1558-4127},
  month={},}@INPROCEEDINGS{9509685,
  author={Rath, Tanvi and Preethi, N},
  booktitle={2021 10th IEEE International Conference on Communication Systems and Network Technologies (CSNT)}, 
  title={Application of AI in Video Games to Improve Game Building}, 
  year={2021},
  volume={},
  number={},
  pages={821-824},
  abstract={Video Games Industry has been welcoming AI like any other industry for various tasks, AI in gaming helps to convey a much more realistic gaming experience, amplify player interaction and satisfaction over extensive periods. Additionally, the gaming industry is utilizing Artificial Intelligence to liberate its staff by making game development automated, quicker, and less expensive. In this work an experiment is described using Deep Neural Network and Statistical techniques for forecasting the location of an object in future frames of a video, it focuses on the engineering phase of the game, the proposed model combines future prediction of object location which helps to build the infinite universe in the videogame without any additional videos frames of the input video or hard coding any scenes to build the scenes further.},
  keywords={Deep learning;Industries;Analytical models;Games;Predictive models;Data models;Motion detection;Image Analytics;Video Analytics;Future Frame Prediction},
  doi={10.1109/CSNT51715.2021.9509685},
  ISSN={2329-7182},
  month={June},}@INPROCEEDINGS{9276003,
  author={Ge, Fei},
  booktitle={2020 International Conference on Computing and Data Science (CDS)}, 
  title={Brief Review of Recent Researches in Speech Enhancement from Filters to Neural Networks}, 
  year={2020},
  volume={},
  number={},
  pages={260-264},
  abstract={According to the World Health Organization, more and more people will suffer from hearing loss in the future. Therefore, there will be greater demand for the output and technology of hearing aids. Under the help of artificial intelligence, the technology of smart hearing aids will also become more intelligent, so that the wearer can get a better experience. This paper mainly studies the related problems of speech signal processing in intelligent digital hearing aids. This article focuses on the speech enhancement in digital hearing aids. First, this work studies the application of filter in speech enhancement technology, mainly introduces the Wiener filter algorithm using the minimum mean square error criterion; the Kalman filter algorithm that can solve discrete signals; spectral subtraction based on multi-window spectrum estimation. Secondly, this paper studies some specific methods of deep learning technology in speech enhancement, mainly introduces DNN-based speech enhancement method, deep learning-based auditory cepstrum coefficient speech enhancement algorithm, and AE-CGAN-based speech enhancement algorithm. Finally, this paper studies the related problems of acoustic scene classification, divides the listening environment into Gaussian white noise, impact noise, and music noise, and explains the solutions for each listening environment.},
  keywords={FCC;Data science;component;formatting;style;styling;insert},
  doi={10.1109/CDS49703.2020.00059},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10134485,
  author={Ramesh, Dhivyashri and Sriram, Ishwarya and Sridhar, Kavya and Dunston, Snofy D and V, Mary Anita Rajam},
  booktitle={2023 International Conference on Wireless Communications Signal Processing and Networking (WiSPNET)}, 
  title={Understanding DeepFool Adversarial Attack and Defense with Skater Interpretations}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={With the incorporation of artificial intelligence in businesses, particularly features like computer vision, it has become increasingly important to ensure the robustness of the models being used. A popular technique used to exploit machine learning models is an adversarial attack. Adversarial attacks mis-lead a predictive model by providing it with perturbed input. In the context of computer vision, it involves creating perturbations in an image to deceive a model. One such adversarial attack is the DeepFool attack, which aims to create the most minimal perturbations to an image to deceive the model. These attacks can also affect the way in which interpretations are made. In this paper, we analyze the DeepFool attack and its countermeasures on the ResNet-50 model running on the NIH malarial dataset. To assess the efficiency of the attack and subsequent adversarial training, we have used accuracy and loss. The nature and impact of the attack and adversarial training are analysed using skater, a model interpretation framework. The variations in the interpretations when adversarial attacks are in place are also analysed.},
  keywords={Training;Wireless communication;Computer vision;Analytical models;Computational modeling;Perturbation methods;Machine learning},
  doi={10.1109/WiSPNET57748.2023.10134485},
  ISSN={},
  month={March},}@INBOOK{10952656,
  author={LeGrande, Craig and Lakshminarayanan, Venky},
  booktitle={AI-Driven Value Management: How AI Can Help Bridge the Gap Across the Enterprise to Achieve Customer Success}, 
  title={Introduction to AI&#x2010;Driven Value Management}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={Summary <p>This chapter briefly explores how value management came to be as a successful enterprise selling strategy and then more recently as a driver of marketing campaigns, customer loyalty programs, and partner ecosystems. It looks at how more companies today are demanding better returns from their business investments, and examines the tectonic shift in customer relationships that is forcing sellers in nearly every industry to deliver tangible and recurring business value to the buyers of their products. Finally, the chapter introduces the game&#x2010;changer: Artificial intelligence (AI) in all its forms and its potential for bringing the selling power of value management to more parts of the business, at lower cost, and at unprecedented speed and scale. Combining the power of AI with a state&#x2010;of&#x2010;the&#x2010;art value management approach can empower businesses to realize 8X revenue outcomes.</p>},
  keywords={Business;Artificial intelligence;Companies;Investment;Costs;Industries;Videos;Translation;Germanium;Generative AI},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394288847},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952656},}@INBOOK{10952230,
  author={McGeorge, Donna},
  booktitle={The ChatGPT Revolution: Get Curious, Get Productive and Get Creative with AI}, 
  title={There's an AI for that}, 
  year={2024},
  volume={},
  number={},
  pages={49-63},
  abstract={Summary <p>ChatGPT can handle a huge and varied number of tasks. But there are some other big players giving it a run for its money in the artificial intelligence (AI) space. Many of the AI applications use OpenAI's GPT&#x2010;4, meaning all the prompts, results and capability is not different compared with going directly to ChatGPT. Some of the challenges of crafting prompts for specific needs have been eliminated with the GPT store in ChatGPT. The chapter looks at prompts, which are the key to unlocking the productivity potential of ChatGPT. Most mainstream apps used on a day&#x2010;to&#x2010;day basis now have some kind of AI assistance: think Adobe, Microsoft, Google. These AI assistants can help the users with tasks like writing, editing, designing or researching, without they having to leave the app or switch to another tool.</p>},
  keywords={Artificial intelligence;Chatbots;Internet;Generators;Smart phones;Windows;Productivity;Operating systems;Generative AI;Biological system modeling},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394283149},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952230},}@INBOOK{10952562,
  author={Mladjenovic, Paul},
  booktitle={AI Investing For Dummies}, 
  title={A Primer on ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={13-22},
  abstract={Summary <p>ChatGPT hit one million users in record time and much more quickly than any prior tech launch. This chapter introduces us to using ChatGPT and lists some alternatives to consider. ChatGPT was created and launched by Open artificial intelligence (AI). There are two versions at the time of this writing: the free version (GPT version 3.5) and the premium version GPT Plus ($20 per month for version 4). Our part in using ChatGPT is to enter our question or request, and this is referred to as the &#x201c;prompt,&#x201d; which makes sense; we're prompting it to generate a response we're seeking. Using AI to go in&#x2010;depth will ultimately mean making choices that will make our path going forward less stressful. The chapter provides a simple two&#x2010;step formula for creating a useful prompt. It discusses limits and negatives of ChatGPT and ChatGPT Alternatives.</p>},
  keywords={Chatbots;Artificial intelligence;Generative Pre-trainer transformer;Virtual assistants;Financial management;Writing;Transformers;Telephone sets;Radar applications;Portfolios},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394237043},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952562},}@INPROCEEDINGS{10339427,
  author={Teng, Haoran and Yu, Yin and Wei, Jinghe and Liu, Guozhu},
  booktitle={2023 2nd International Conference on Machine Learning, Cloud Computing and Intelligent Mining (MLCCIM)}, 
  title={A STDP Rules-Based Spiking Neural Network Implementation for Image Recognition}, 
  year={2023},
  volume={},
  number={},
  pages={71-76},
  abstract={With the progress and development of artificial intelligence, the concept of neuromorphic computing has been widely observed since its proposed. The biological neural system can use sparse electrical spikes for information transfer, has powerful memory-learning functions, and perform complex tasks with extremely low power consumption. As the third generation neural network, spiking neural network has higher level of bionic characteristics than the traditional neural network. It can simulate the information processing mechanism of human brain to a greater extent, which is the focus of the research of brain-like computing. In this work, a two-layer SNN composed of Leaky-Integrate-Fire neurons was implemented in the BindsNET simulation environment. The network was learned and trained by the time-dependent plasticity of spike rule, and achieves 92% recognition accuracy on the MNIST handwritten digit set.},
  keywords={Training;Image recognition;Power demand;Neuromorphic engineering;Software algorithms;Neurons;Hardware;Neuromorphic computing;Spiking Neural Networks;LIF neurons;STDP rules;Image recognition},
  doi={10.1109/MLCCIM60412.2023.00016},
  ISSN={},
  month={July},}@INBOOK{10952954,
  author={Blount, Jeb and Iannarino, Anthony},
  booktitle={The AI Edge: Sales Strategies for Unleashing the Power of AI to Save Time, Sell More, and Crush the Competition}, 
  title={Beware of the Authority Bias}, 
  year={2024},
  volume={},
  number={},
  pages={34-36},
  abstract={Summary <p>Authority bias is the human inclination to accept and value the views, information, or recommendations from authoritative sources, without critically evaluating their validity or accuracy. Similar to anthropomorphism, the human authority bias can fool us into believing that, since artificial intelligence (AI) seems to span the breadth and depth of human knowledge, anything it produces is fact, irrefutably true, and trustworthy. As our reliance on digital sources&#x2014;especially AI&#x2014;for knowledge grows exponentially, this bias will become an increasing danger, across society. First, it's essential to understand the mechanics behind AI. Even the most advanced AI is only as good as the data it's trained on. It is right and essential to approach AI outputs with a healthy dose of skepticism&#x2014;just like any other source of information.</p>},
  keywords={Artificial intelligence;Machine learning algorithms;Cognition;Generative AI;Faces;Accuracy;Weapons;Subject matter experts;Presses;Machine learning},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394244492},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952954},}@INPROCEEDINGS{10204183,
  author={Li, Jianan and Dong, Qiulei},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Open-set Semantic Segmentation for Point Clouds via Adversarial Prototype Framework}, 
  year={2023},
  volume={},
  number={},
  pages={9425-9434},
  abstract={Recently, point cloud semantic segmentation has attracted much attention in computer vision. Most of the existing works in literature assume that the training and testing point clouds have the same object classes, but they are generally invalid in many real-world scenarios for identifying the 3D objects whose classes are not seen in the training set. To address this problem, we propose an Adversarial Prototype Framework (APF) for handling the open-set 3D semantic segmentation task, which aims to identify 3D unseen-class points while maintaining the segmentation performance on seen-class points. The proposed APF consists of a feature extraction module for extracting point features, a prototypical constraint module, and a feature adversarial module. The prototypical constraint module is designed to learn prototypes for each seen class from point features. The feature adversarial module utilizes generative adversarial networks to estimate the distribution of unseenclass features implicitly, and the synthetic unseen-class features are utilized to prompt the model to learn more effective point features and prototypes for discriminating unseen-class samples from the seen-class ones. Experimental results on two public datasets demonstrate that the proposed APF outperforms the comparative methods by a large margin in most cases.},
  keywords={Point cloud compression;Training;Computer vision;Three-dimensional displays;Semantic segmentation;Prototypes;Feature extraction;Segmentation;grouping and shape analysis},
  doi={10.1109/CVPR52729.2023.00909},
  ISSN={2575-7075},
  month={June},}@ARTICLE{10415463,
  author={Gao, Mengyu and Dong, Qiulei},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Adaptive Conditional Denoising Diffusion Model With Hybrid Affinity Regularizer for Generalized Zero-Shot Learning}, 
  year={2024},
  volume={34},
  number={7},
  pages={5641-5652},
  abstract={Generalized zero-shot learning (GZSL) is a challenging topic in both computer vision and machine learning. Recently, generative models (e.g., GAN and VAE) have attracted much attention for handling the GZSL task, however, they are sometimes prone to either model collapse or ambiguous distribution modeling. Inspired by the feature generation ability of denoising diffusion models in other visual tasks, we propose an Adaptive Conditional Denoising Diffusion Model to synthesize unseen-class visual features for GZSL on condition of a set of semantic features in this paper, called AC-DDM. Unlike traditional denoising diffusion models whose reverse process has both a fixed time interval and a fixed number of total denoising time steps, the proposed AC-DDM has a learnable distribution-constrained predictor which could adaptively learn the time interval and the number of total denoising time steps for each unseen class, so that it could synthesize more discriminative features for sample classification. In order to improve the discrimination ability of the synthesized visual features further, we also explore a hybrid affinity regularizer under the proposed AC-DDM, which forces the differences among the affinity matrices of the real and synthesized visual features to be small. Extensive experimental results on four public benchmark datasets demonstrate the superiority of the proposed model over 20 state-of-the-art models in both the ZSL and GZSL tasks.},
  keywords={Visualization;Noise reduction;Adaptation models;Semantics;Task analysis;Circuits and systems;Zero-shot learning;Denoising diffusion model;adaptive feature synthesis;generalized zero-shot learning},
  doi={10.1109/TCSVT.2024.3359238},
  ISSN={1558-2205},
  month={July},}@ARTICLE{9099288,
  author={Shinagawa, Seitaro and Yoshino, Koichiro and Alavi, Seyed Hossein and Georgila, Kallirroi and Traum, David and Sakti, Sakriani and Nakamura, Satoshi},
  journal={IEEE Access}, 
  title={An Interactive Image Editing System Using an Uncertainty-Based Confirmation Strategy}, 
  year={2020},
  volume={8},
  number={},
  pages={98471-98480},
  abstract={We propose an interactive image editing system that has a confirmation dialogue strategy using an entropy-based uncertainty calculation on its generated images with Deep Convolutional Generative Adversarial Networks (DCGAN). DCGAN is an image generative model that learns an image manifold of a given dataset and enables continuous change of an image. Our proposed image editing system combines DCGAN with a natural language interface that accepts image editing requests in natural language. Although such a system is helpful for human users, it often faces uncertain requests to generate acceptable images. A promising approach to solve this problem is introducing a dialogue process that shows multiple candidates and confirms the user's intention. However, confirming every editing request creates redundant dialogues. To achieve more efficient dialogues, we propose an entropy-based dialogue strategy that decides when the system should confirm, and enables effective image editing through a dialogue that reduces redundant confirmations. We conducted image editing dialogue experiments using an avatar face illustration dataset for editing by natural language requests. Through quantitative and qualitative analysis, our results show that our entropy-based confirmation strategy achieved an effective dialogue by generating images desired by users.},
  keywords={Natural languages;Generators;Generative adversarial networks;Task analysis;Training;Hair;Image generation;Confirmation;generative adversarial networks;image editing;natural language interface},
  doi={10.1109/ACCESS.2020.2997012},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11126829,
  author={Oomoto, Shiori and Enoki, Miki and Oguchi, Masato},
  booktitle={2025 IEEE 49th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Optimization of Prompt Segmentation for Improving Event Recommendation Accuracy Using Generative Artificial Intelligence}, 
  year={2025},
  volume={},
  number={},
  pages={295-300},
  abstract={As demand grows for event recommendation systems capable of accommodating users with diverse backgrounds and preferences, recent advancements in Large Language Models (LLMs) have attracted significant attention. LLMs offer the ability to flexibly integrate multiple conditions, enabling highly personalized recommendations. However, this flexibility often results in longer prompts, which can degrade response accuracy. Additionally, optimal prompt structures may vary across LLM versions, leading to inconsistent performance.To address these issues, we propose a dynamic prompt optimization method that segments prompts based on LLM evaluations. We conducted experiments using ChatGPT-4o and evaluated the effectiveness of prompt segmentation to verify the feasibility of the proposed method. The experimental results demonstrate that prompt segmentation improves recommendation accuracy but that its effectiveness saturates beyond a certain threshold. These findings suggest that determining the optimal number of prompt segments maximizes output quality while preventing unnecessary segmentation.},
  keywords={Accuracy;Generative AI;Large language models;Optimization methods;Software;Recommender systems;Large Language Models;Event Recommendation;Prompt Optimization},
  doi={10.1109/COMPSAC65507.2025.00047},
  ISSN={2836-3795},
  month={July},}@ARTICLE{10772168,
  author={Tang, Hao and He, Hui and Feng, Yuming and Meng, Junxiong and Zhang, Weizhe},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Response Generation Honeypot with Anti-Detection Capabilities for IoT Botnet Lifecycle Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1-15},
  abstract={With the widespread use of edge computing, the security issues on the edge side of IoT within the cloud-edge-device architecture are becoming increasingly severe, particularly with the growing threat posed by botnets. Existing research on IoT botnet detection primarily focuses on identifying infected devices, with significantly less emphasis on detecting the botnet scanning and propagation phases. Recognizing the importance of early detection to protect devices and networks, this paper introduces RGPot-a novel honeypot based on a generative response model designed to detect the lifecycle of IoT botnets. RGPot consists of two core components: an interaction response module and a lifecycle detection module. In the Interaction Response Module, Generative Adversarial Networks (GANs) are employed to train models capable of generating responses to various types of request data. This enables RGPot to effectively simulate real IoT devices and provide tailored responses to deceive potential attackers. In the Lifecycle Detection Module, a multi-layer Long Short-Term Memory (LSTM) network is utilized to comprehensively detect the stages of an IoT botnet’s lifecycle, facilitating the precise identification of the stage at which the detected traffic data is located. To evaluate the efficacy of RGPot, we created a controlled experimental environment to assess its ability to capture IoT botnets and detect traffic data. The experimental results validate RGPot’s capability in botnet capture and anti-detection, with an accuracy of 98.81% in detecting botnet lifecycles and a reduction in false positives of approximately 5%.},
  keywords={Botnet;Fingerprint recognition;Internet of Things;Long short term memory;Artificial intelligence;Protocols;Edge computing;Computational modeling;Adaptation models;Data models;Edge Computing;IoT Security;Botnet Lifecycle Detection;RGPot;GANs;LSTM},
  doi={10.1109/TAI.2024.3509812},
  ISSN={2691-4581},
  month={},}@INPROCEEDINGS{10913930,
  author={Yuan, Hongye and Yan, Xin and Li, Chunlin},
  booktitle={2024 International Conference on Engineering and Emerging Technologies (ICEET)}, 
  title={A Semantic-Driven Data Generative Traffic Modeling Method for Digital Twin Networks}, 
  year={2024},
  volume={},
  number={},
  pages={01-06},
  abstract={Digital Twin Networks (DTN) create synchronized virtual replicas of physical networks to enable real-time monitoring, prediction, and optimization of network performance, facilitating efficient management in complex environments. However, existing DTN modeling often face challenges in accuracy, efficiency, and high communication costs. This paper proposes a novel semantic-driven traffic generation method that integrates diffusion models, network simulation, and semantic communication for constructing DTN. Our approach first extracts semantic information from real network data and inputs it into Mininet for initial traffic simulation. Then, to reduce discrepancies with real-world data, we introduce a Transformer-based diffusion model, DiffNTG, which refines Mininet-generated traffic to achieve high fidelity. Experimental results demonstrate that our model reduces error metrics between simulated and real networks by up to 96% and decreases computational costs by approximately 83%, showing strong potential for DTN applications.},
  keywords={Costs;Accuracy;Computational modeling;Traffic control;Diffusion models;Transformers;Semantic communication;Real-time systems;Data models;Digital twins;Digital Twin Networks;Diffusion Models;Net-work Traffic Generation;Semantic Communications;High-Fidelity Simulation},
  doi={10.1109/ICEET65156.2024.10913930},
  ISSN={2831-3682},
  month={Dec},}@ARTICLE{1629097,
  author={Hsin Chen and Fleury, P.C.D. and Murray, A.F.},
  journal={IEEE Transactions on Neural Networks}, 
  title={Continuous-valued probabilistic behavior in a VLSI generative model}, 
  year={2006},
  volume={17},
  number={3},
  pages={755-770},
  abstract={This paper presents the VLSI implementation of the continuous restricted Boltzmann machine (CRBM), a probabilistic generative model that is able to model continuous-valued data with a simple and hardware-amenable training algorithm. The full CRBM system consists of stochastic neurons whose continuous-valued probabilistic behavior is mediated by injected noise. Integrating on-chip training circuits, the full CRBM system provides a platform for exploring computation with continuous-valued probabilistic behavior in VLSI. The VLSI CRBM's ability both to model and to regenerate continuous-valued data distributions is examined and limitations on its performance are highlighted and discussed.},
  keywords={Very large scale integration;Neurons;Stochastic resonance;Circuit noise;Embedded system;Working environment noise;Intelligent systems;Bioelectric phenomena;Embedded computing;Power system modeling;Boltzmann machine;continuous-valued probabilistic VLSI;noise;on-chip training;probabilistic generative model;stochastic computation},
  doi={10.1109/TNN.2006.873278},
  ISSN={1941-0093},
  month={May},}@ARTICLE{11168475,
  author={Boutouta, Hanane and Lakhfif, Abdelaziz and Senator, Ferial and Mediani, Chahrazed},
  journal={IEEE Access}, 
  title={Enhancement of Implicit Emotion Recognition in Arabic Text: Annotated dataset and baseline models}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Emotion recognition in textual data has emerged as a rapidly advancing task within the field of Natural Language Processing (NLP). Implicit Emotion Recognition (IER), which involves identifying emotions primarily through contextual cues rather than overt or explicit emotional expressions, remains in its early stages. Despite significant progress in recognizing explicit emotions, current research has largely overlooked IER, particularly for low-resource languages such as Arabic. This study aims to comprehensively address this task for the Arabic language, including dataset construction, annotation, modeling, and evaluation. Specifically, the study (1) presents the first annotated dataset for Arabic Implicit Emotion Recognition (AIER); (2) annotates the dataset with emotion, cue, and cause using a semi-automatic annotation tool, validated by four native Arabic speakers and linguists; (3) investigates the potential of two categories of transformer-based models: masked language models, exemplified by pre-trained Bidirectional Encoder Representations from Transformers (BERT)-based architecture, through a series of fine-tuning experiments, and causal-based models, such as generative Large Language Models (LLMs), via a zero-shot prompting approach; and (4) evaluates the performance of four distinct algorithmic models on the proposed dataset :classical Machine Learning (ML), Deep Learning (DL), BERT-based, and generative LLMs. The experimental results demonstrate that BERT-based models outperform ML, DL models, and generative LLMs. Notably, the fine-tuned MARBERTv2 model achieves superior performance compared to other pre-trained models, obtaining an impressive F1-score of 79.83% on the AIER dataset.},
  keywords={Emotion recognition;Natural language processing;Encoding;Context modeling;Blogs;Bidirectional control;Annotations;Linguistics;Transformers;Social networking (online);Arabic NLP;BERT;Deep Learning;Implicit Emotion Recognition;Generative LLMs;Machine Learning;Masked Language Modeling},
  doi={10.1109/ACCESS.2025.3611337},
  ISSN={2169-3536},
  month={},}@ARTICLE{10884737,
  author={Tang, Xin and Chen, Qian and Weng, Wenjie and Liao, Binhan and Wang, Jiacheng and Cao, Xianbin and Li, Xiaohuan},
  journal={IEEE Internet of Things Journal}, 
  title={DNN Task Assignment in UAV Networks: A Generative AI Enhanced Multiagent Reinforcement Learning Approach}, 
  year={2025},
  volume={12},
  number={10},
  pages={13340-13352},
  abstract={uncrewed aerial vehicles (UAVs) offer high mobility and flexible deployment capabilities, making them ideal for Internet of Things (IoT) applications. However, the substantial amount of data generated by various applications within the existing low-altitude network requires processing through deep neural networks (DNN) on UAVs, which is challenging due to their limited computational resources. To address this issue, we propose a two-stage optimization method for flight path planning and task allocation based on a mother-child UAV swarm system. In the first stage, we employ a greedy algorithm to solve the path planning problem by considering the task size of the target area to be inspected and the shortest flight path as constraints. The goal is to minimize both the flight path of the UAV and the overall cost of the system. In the second stage, we introduce a novel DNN task assignment algorithm that combines multiagent deep deterministic policy gradient (MADDPG) and generative diffusion models (GDMs), named GDM-MADDPG. This algorithm takes advantage of the reverse denoising process of GDM to replace the actor network in MADDPG. It enables UAVs to generate specific DNN task assignment actions based on agents’ observations in a dynamic environment, thereby improving the efficiency of task assignment and overall system performance. The simulation results demonstrate that our algorithm outperforms the benchmarks in terms of path planning, Age of Information (AoI), task completion rate, and system utility, demonstrating its effectiveness.},
  keywords={Autonomous aerial vehicles;Collaboration;Artificial neural networks;Internet of Things;Computational modeling;Servers;Heuristic algorithms;Cloud computing;Real-time systems;Energy consumption;Deep neural network;generative artificial intelligence (AI);mobile edge computing;multiagent reinforcement learning (MARL);path planning;task assignment;uncrewed aerial vehicle (UAV) network},
  doi={10.1109/JIOT.2025.3541715},
  ISSN={2327-4662},
  month={May},}@INPROCEEDINGS{10972630,
  author={Ma, Yunsheng and Ye, Wenqian and Cui, Can and Zhang, Haiming and Xing, Shuo and Ke, Fucai and Wang, Jinhong and Miao, Chenglin and Chen, Jintai and Rezatofighi, Hamid and Li, Zhen and Zheng, Guangtao and Zheng, Chao and He, Tianjiao and Chandraker, Manmohan and Yaman, Burhaneddin and Ye, Xin and Zhao, Hang and Cao, Xu},
  booktitle={2025 IEEE/CVF Winter Conference on Applications of Computer Vision Workshops (WACVW)}, 
  title={Position: Prospective of Autonomous Driving - Multimodal LLMs, World Models, Embodied Intelligence, AI Alignment, and Mamba}, 
  year={2025},
  volume={},
  number={},
  pages={920-936},
  abstract={With the emergence of Generative AI, multimodal AI systems that leverage foundation models are beginning to demonstrate enormous potential for perceiving the real world, collecting new data, making decisions, and using tools like humans. In recent years, the use of Large Language Models and World Models in autonomous driving has received widespread attention. However, despite their enormous potential, there is still a lack of comprehensive understanding regarding the key challenges, opportunities, and future applications of these new foundation models in driving systems. In this paper, we provide an outlook on this field, summarizing existing methods and exploring their limitations. In addition, we further discuss the applicability of emerging approaches, such as Reinforcement Learning from Human Feedback and Mamba for applications in autonomous driving. Finally, we highlight open questions and offer insights into promising directions for future research. This paper is part of a living document that will be updated based on the LLVM-AD workshop series to reflect the latest developments in the field.},
  keywords={Computer vision;Foundation models;Generative AI;Large language models;Conferences;Computational modeling;Reinforcement learning;Autonomous vehicles;autonomous driving;multimodal large language model;world model;embodied ai;mamba},
  doi={10.1109/WACVW65960.2025.00114},
  ISSN={2690-621X},
  month={Feb},}@INPROCEEDINGS{9660045,
  author={Doboli, Alex and Doboli, Simona},
  booktitle={2021 IEEE Symposium Series on Computational Intelligence (SSCI)}, 
  title={A Novel Learning and Response Generating Agent-based Model for Symbolic - Numeric Knowledge Modeling and Combination}, 
  year={2021},
  volume={},
  number={},
  pages={01-09},
  abstract={Many modern applications require both modeling and generative capabilities, so that they can produce novel outcomes that address requirements beyond the solutions used in model training. Current AI approaches arguably emphasize modeling but pay much less attention to generative capabilities. This paper presents a new learning and response generating (LRG) agent-based model, in which interacting agents continuously learn symbolic - numeric knowledge and create new outcomes (responses) using a set of five ways to combine concepts. Each way has both fast, reactive and a slow, planned versions. Experiments present the characteristics of an agent's modeling and generating capabilities.},
  keywords={Training;Computational modeling;Semantics;Extraterrestrial measurements;Numerical models;Artificial intelligence;Computational intelligence;modeling;generating;knowledge representation;agents;learning;generation through combination},
  doi={10.1109/SSCI50451.2021.9660045},
  ISSN={},
  month={Dec},}@INBOOK{10880600,
  author={Nair, Ardra and Devaser, Virrat and Arora, Komal},
  booktitle={Generative Artificial Intelligence for Biomedical and Smart Health Informatics}, 
  title={Machine Learning Applications in the Prediction of Polycystic Ovarian Syndrome}, 
  year={2025},
  volume={},
  number={},
  pages={565-589},
  abstract={Summary <p>Machine learning (ML) has emerged as a powerful tool in disease detection, revolutionizing the landscape of healthcare diagnostics. This chapter explores the advancements in ML and artificial intelligence (AI), specifically tailored for the early detection of polycystic ovary syndrome (PCOS). The integration of ML and AI technologies has sparked a transformative shift in healthcare, particularly in addressing the challenges posed by PCOS. This chapter introduces ML&#x2010;based approaches and integration into the Flask web application the seamlessly incorporating K&#x2010;Nearest Neighbors (KNN) predictive model. This platform empowers users to effortlessly input diagnostic responses and obtain instant risk assessments, reshaping the landscape of PCOS screening. Timely detection holds immense significance in mitigating severe complications associated with PCOS, such as obesity, insulin resistance, infertility, and cardiovascular issues. Through the fusion of ML and AI management and healthcare, this chapter delves into accessible PCOS screening tools, heralding a new era of proactive healthcare management, and fostering enhanced patient outcomes.</p>},
  keywords={Medical diagnostic imaging;Diseases;Biochemistry;Ultrasonic imaging;Accuracy;Predictive models;Hair;Data collection;Blood;Ultrasonic variables measurement},
  doi={10.1002/9781394280735.ch27},
  ISSN={},
  publisher={IEEE},
  isbn={9781394280728},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10880600},}@INPROCEEDINGS{9065262,
  author={Zhang, Jianguang and Zhang, Xuyang and Yang, Jianfeng and Wang, Zhaoxu and Zhang, Yufan and Ai, Qian and Li, Zhaoyu and Sun, Ziru and Yin, Shuangrui},
  booktitle={2020 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Deep LSTM and GAN based Short-term Load Forecasting Method at the Zone Level}, 
  year={2020},
  volume={},
  number={},
  pages={613-618},
  abstract={Accurate short-term load forecasting (STLF) with time horizon ranging from seconds to hour is essential to revealing the deviation of day-ahead load forecasting. Especially, under the competitive market environment, accurate forecasting result can reduce the expensive cost on the activation of spinning reserve. Method based on deep long short-term memory RNN (LSTM) is promising to implement STLF. However, over-fitting is a common problem capping such model's generalization ability. To cope with it, generative adversarial networks (GAN) and deep LSTM based model is proposed in this paper. The deep LSTM is concatenated with the generator whose parameters are initialized by the pre-trained GAN. Essentially, the model aims to address the overfitting issue by the synthetic load produced by the generator. It has the effect of the regularization and thus the deep LSTM can make better forecasting on the unseen data. The results demonstrate that the proposed algorithm has better generalization ability.},
  keywords={Generators;Gallium nitride;Load modeling;Autoregressive processes;Forecasting;Training;Generative adversarial networks;Deep LSTM;GAN;Over-fitting;Regularization;Short-term load forecasting},
  doi={10.1109/ICAIIC48513.2020.9065262},
  ISSN={},
  month={Feb},}@INBOOK{10953020,
  author={Baker, Pam},
  booktitle={Generative AI For Dummies}, 
  title={Creating Short&#x2010;Form Content}, 
  year={2025},
  volume={},
  number={},
  pages={133-156},
  abstract={Summary <p>GenAI opens new possibilities for content creators looking to produce high&#x2010;quality, engaging short&#x2010;form content in a single piece or a multitude of them at scale. This chapter explores practical strategies for leveraging GenAI to create short&#x2010;form content and streamline workflows. It presents various techniques to generate disparate forms of short content. These include: AI aggregation, output stitching, and AI chaining. GenAI is uniquely equipped to support bloggers in every phase of the content creation process. GenAI such as ChatGPT and Claude can spot trending topics and make blog post suggestions accordingly. GenAI can be used in numerous ways to speed up the processes involved in news writing. GenAI can be an invaluable asset in crafting memorable speeches by providing assistance in several key areas. The chapter explores how GenAI can help the readers with website design and content, streamlining the process from conceptualization to execution.</p>},
  keywords={Artificial intelligence;Chatbots;Videos;Social networking (online);Generative AI;Blogs;Aggregates;Web sites;Manuals;Computational modeling},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394270767},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10953020},}@INPROCEEDINGS{11031727,
  author={Sharma, Anjali and Rani, Ritu and Sharma, Arun},
  booktitle={2025 International Conference on Data Science and Business Systems (ICDSBS)}, 
  title={Exploring the Role of Loss Functions in Deepfake Detection}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={With deepfakes becoming more common, it's increasingly difficult to separate real content from manipulated ones. As vast amounts of data are generated daily, the need for effective deepfake detection becomes increasingly critical. We aim to apply a basic CNN model to check if an image is real or fake. We examine how various loss functions, including binary cross-entropy, focal loss, and hinge loss, impact training and detection performance. The models were evaluated on a dataset of 190,335 images with a focus on accuracy and loss. Binary Cross-Entropy performs well on balanced datasets, Focal Loss shows superior performance in imbalanced datasets, and Hinge Loss provides robust margin-based classification. Our findings provide insights into the optimal loss functions for enhancing the performance of deepfake detection models. At 92.70% training accuracy and a 0.0118 training loss, the Focal Loss model emerged as the best, providing a solid foundation for future advancements in deepfake detection.},
  keywords={Training;Deepfakes;Solid modeling;Accuracy;Detectors;Fasteners;Solids;Generative adversarial networks;Entropy;Convolutional neural networks;CNN;GAN;AI;Deepfakes},
  doi={10.1109/ICDSBS63635.2025.11031727},
  ISSN={},
  month={April},}@INPROCEEDINGS{10204994,
  author={Hu, Tie and Lin, Mingbao and You, Lizhou and Chao, Fei and Ji, Rongrong},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Discriminator-Cooperated Feature Map Distillation for GAN Compression}, 
  year={2023},
  volume={},
  number={},
  pages={20351-20360},
  abstract={Despite excellent performance in image generation, Generative Adversarial Networks (GANs) are notorious for its requirements of enormous storage and intensive computation. As an awesome “performance maker”, knowledge distillation is demonstrated to be particularly efficacious in exploring low-priced GANs. In this paper, we investigate the irreplaceability of teacher discriminator and present an inventive discriminator-cooperated distillation, abbreviated as DCD, towards refining better feature maps from the generator. In contrast to conventional pixel-to-pixel match methods in feature map distillation, our DCD utilizes teacher discriminator as a transformation to drive intermediate results of the student generator to be perceptually close to corresponding outputs of the teacher generator. Furthermore, in order to mitigate mode collapse in GAN compression, we construct a collaborative adversarial training paradigm where the teacher discriminator is from scratch established to co-train with student generator in company with our DCD. Our DCD shows superior results compared with existing GAN compression methods. For instance, after reducing over $40\times MACs$ and $80\times$ parameters of CycleGAN, we well decrease FID metric from 61.53 to 48.24 while the current SoTA method merely has 51.92. This work's source code has been made accessible at https://github.com/poopit/DCD-official.},
  keywords={Training;Measurement;Image coding;Source coding;Refining;Collaboration;Generative adversarial networks;Efficient and scalable vision},
  doi={10.1109/CVPR52729.2023.01949},
  ISSN={2575-7075},
  month={June},}@ARTICLE{10461106,
  author={Zheng, Xiaolong and Yang, Kun and Xiong, Jie and Liu, Liang and Ma, Huadong},
  journal={IEEE Transactions on Mobile Computing}, 
  title={Pushing the Limits of WiFi Sensing With Low Transmission Rates}, 
  year={2024},
  volume={23},
  number={11},
  pages={10265-10279},
  abstract={Existing WiFi sensing systems transmit dedicated high-rate packets for accurate sensing. These “sensing packets” greatly affect the main data communication function of WiFi and significantly counteract the promised benefit of reusing WiFi communication for sensing. In this work, we propose WiImg2.0, a lightweight system which involves machine learning techniques to enable WiFi sensing under low packet rate, pushing WiFi sensing one step towards real-life adoption. The key idea is to convert the WiFi CSI samples into images and employ the Generative Adversarial Network (GAN) for CSI image inpainting, relaxing the requirement of high sample rate for sensing. We first recover the sensing data from the antenna spatial domain and then from the sample time domain. To avoid the large training overhead of GAN, we design a lightweight GAN that leverages samples of only three rates in a fixed window to recover the CSI traces of arbitrary rates and varying duration. Experiments show that with just 25 packets per second, WiImg2.0 is able to increase the recognition accuracy for hand gesture recognition and daily activity tracking from the state-of-the-art 59.1% and 65.9% to 86.7% and 96.4%, respectively.},
  keywords={Sensors;Wireless fidelity;Generative adversarial networks;Machine learning;Mobile computing;Time-domain analysis;Gesture recognition;Channel state information;activity recognition;low transmission rates;GAN;WiFi},
  doi={10.1109/TMC.2024.3374046},
  ISSN={1558-0660},
  month={Nov},}@ARTICLE{10413212,
  author={Fu, Kui and Dang, Xuanju},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Light-Weight Convolutional Neural Networks for Generative Robotic Grasping}, 
  year={2024},
  volume={20},
  number={4},
  pages={6696-6707},
  abstract={Grasp planning with high-performance and efficiency in unstructured environments is a critical problem that intelligent robots need to solve urgently to complete picking tasks. To solve this problem, a quantized grasp quality generative neural network is proposed to generate pixel-level grasps. A light-weight convolutional neural network is first used to generate initial grasp configurations. Aiming at the degradation of grasping performance caused by the light-weight design, a decoupled grasp quality network is designed to generate a pixel-wise grasp quality. To improve the robustness and generalization of the model, an adaptive filtering method is proposed to filter the grasp configurations. Then, an ellipse fitting-based grasp pose optimization method is proposed to obtain the final grasp configuration. On the public Cornell dataset, the state-of-the-art grasp accuracy of 98.9% and the efficiency of 15 ms are achieved, with approximately 564× fewer parameters compared to comparable performance. In the grasping experiments on the robotic platform, grasp success rates of 99% and 93.4% can be achieved in single object and cluttered scenes, respectively. Finally, the model is deployed on an embedded artificial intelligence (AI) computing device to verify its practicality.},
  keywords={Planning;Grasping;Robot kinematics;Grippers;Computational modeling;Deep learning;Artificial intelligence;Deep learning;embedded AI;multifeature weighting (MFW);robotic grasping},
  doi={10.1109/TII.2024.3353841},
  ISSN={1941-0050},
  month={April},}@INPROCEEDINGS{10178496,
  author={Ashrafi, Navid and Schmitt, Vera and Spang, Robert P. and Möller, Sebastian and Voigt-Antons, Jan-Niklas},
  booktitle={2023 15th International Conference on Quality of Multimedia Experience (QoMEX)}, 
  title={Protect and Extend - Using GANs for Synthetic Data Generation of Time-Series Medical Records}, 
  year={2023},
  volume={},
  number={},
  pages={171-176},
  abstract={Preservation of private user data is of paramount importance for high Quality of Experience (QoE) and acceptability, particularly with services treating sensitive data, such as IT-based health services. Whereas anonymization techniques were shown to be prone to data re-identification, synthetic data generation has gradually replaced anonymization since it is relatively less time and resource-consuming and more robust to data leakage. Generative Adversarial Networks (GANs) have been used for generating synthetic datasets, especially GAN frameworks adhering to the differential privacy phenomena. This research compares state-of-the-art GAN-based models for synthetic data generation to generate time-series synthetic medical records of dementia patients which can be distributed without privacy concerns. Predictive modeling, autocorrelation, and distribution analysis are used to assess the Quality of Generating (QoG) of the generated data. The privacy preservation of the respective models is assessed by applying membership inference attacks to determine potential data leakage risks. Our experiments indicate the superiority of the privacy-preserving GAN (PPGAN) model over other models regarding privacy preservation while maintaining an acceptable level of QoG. The presented results can support better data protection for medical use cases in the future.},
  keywords={Data privacy;Privacy;Predictive models;Generative adversarial networks;Data models;Information filtering;Quality of experience;Synthetic data generation;differential privacy;medical data privacy;GAN-based models},
  doi={10.1109/QoMEX58391.2023.10178496},
  ISSN={2472-7814},
  month={June},}@INPROCEEDINGS{8462601,
  author={Zhang, Xinyi and Wang, Fei and Dong, Hang and Guo, Yu},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={A Deep Encoder-Decoder Networks for Joint Deblurring and Super-Resolution}, 
  year={2018},
  volume={},
  number={},
  pages={1448-1452},
  abstract={In this paper, we propose an end-to-end convolution neural network (CNN) to restore a clear high-resolution image from a severely blurry image. It's a highly ill-posed problem and brings tremendous challenges to state-of-art deblurring or super-resolution (SR) methods. A straightforward way to solve this problem is to concatenate two types of networks directly. However, experiments show that the concatenation of independent networks increases computation complexity instead of generating satisfying high-resolution images. Consequently, we focus on designing a single deep network to solve the deblurring and SR problems in parallel. Our method, called ED-DSRN, extends the traditional Super-Resolution network by adding a deblurring branch that shares the same feature maps extracted from an encoder-decoder module with the original SR branch. Extensive experiments show that our method produces remarkable deblurred and super-resolved images simultaneously with high efficiency.},
  keywords={Image resolution;Image restoration;Task analysis;Kernel;Training;Feature extraction;Convolution;Super-Resolution;Blind deblurring;Joint tasks;Encoder-Decoder networks;Parallel branches},
  doi={10.1109/ICASSP.2018.8462601},
  ISSN={2379-190X},
  month={April},}@ARTICLE{9383217,
  author={Kuo, Chia-Hsuan and Chen, Chiao-Ting and Lin, Sin-Jing and Huang, Szu-Hao},
  journal={IEEE Access}, 
  title={Improving Generalization in Reinforcement Learning–Based Trading by Using a Generative Adversarial Market Model}, 
  year={2021},
  volume={9},
  number={},
  pages={50738-50754},
  abstract={With the increasing sophistication of artificial intelligence, reinforcement learning (RL) has been widely applied to portfolio management. However, shortcomings remain. Specifically, because the training environment of an RL-based portfolio optimization framework is usually constructed based on historical price data in the literature, the agent potentially 1) violates the definition of a Markov decision process (MDP), 2) ignores their own market impact, or 3) fails to account for causal relationships within interaction processes; these ultimately lead the agent to make poor generalizations. To surmount these problems-specifically, to help the RL-based portfolio agent make better generalizations-we introduce an interactive training environment that leverages a generative model, called the limit order book-generative adversarial model (LOB-GAN), to simulate a financial market. Specifically, the LOB-GAN models market ordering behavior, and LOB-GAN's generator is utilized as a market behavior simulator. A simulated financial market, called Virtual Market, is constructed by the market behavior simulator in conjunction with a realistic security matching system. Virtual Market is then leveraged as an interactive training environment for the RL-based portfolio agent. The experimental results demonstrate that our framework improves out-of-sample portfolio performance by 4%, which is superior to other generalization strategies.},
  keywords={Portfolios;Training;Optimization;Topology;Data models;Stock markets;Network topology;Artificial market simulation;portfolio management;reinforcement learning},
  doi={10.1109/ACCESS.2021.3068269},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9053905,
  author={Chen, Zhengyang and Wang, Shuai and Qian, Yanmin and Yu, Kai},
  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Channel Invariant Speaker Embedding Learning with Joint Multi-Task and Adversarial Training}, 
  year={2020},
  volume={},
  number={},
  pages={6574-6578},
  abstract={Using deep neural network to extract speaker embedding has significantly improved the speaker verification task. However, such embeddings are still vulnerable to channel variability. Previous works have used adversarial training to suppress channel information to extract channel-invariant embedding and achieved a significant improvement. Inspired by the successful joint multi-task and adversarial training with phonetic information for phonetic-invariant speaker embedding learning, in this paper, a similar methodology is developed to suppress the channel variability. By treating the recording devices or environments as the channel variability, two individual experiments are carried out, and consistent performance improvement is observed in both cases. The best performance is obtained by sequentially applying multi-task training at the statistics pooling layer and adversarial training at the embedding layer, achieving 10.77% and 9.37% relative improvements in terms of EER compared to the baselines, for the recording environments or devices level, respectively.},
  keywords={Training;Performance evaluation;Neural networks;Signal processing;Phonetics;Task analysis;Speech processing;channel information;adversarial training;multitask learning;text-dependent speaker verification},
  doi={10.1109/ICASSP40776.2020.9053905},
  ISSN={2379-190X},
  month={May},}@INPROCEEDINGS{10037802,
  author={Wang, Wei and Zhang, Wangyou and Lin, Shaoxiong and Qian, Yanmin},
  booktitle={2022 13th International Symposium on Chinese Spoken Language Processing (ISCSLP)}, 
  title={Text-Informed Knowledge Distillation for Robust Speech Enhancement and Recognition}, 
  year={2022},
  volume={},
  number={},
  pages={334-338},
  abstract={Most existing speech enhancement (SE) approaches heavily depend on simulated data for training, leading to performance degradation on realistic data and subsequent speech recognition task. One of the main reasons is that SE models cannot be trained on real data due to the absence of reference signals. In this paper, we aim to tackle this problem by exploiting transcribed real data to mitigate the mismatch between training and evaluation. A text-informed SE teacher is first trained to provide “reference” signals for the transcribed real data. Then a SE student is trained on both simulated and real data, where the supervision comes from the simulated ground truth and the teacher, respectively. Finally, a speech recognition model is trained on enhanced signals from the SE student. Our experimental results show that the proposed method can not only improve the speech enhancement performance, but also reduce the word error rate on the downstream speech recognition task.},
  keywords={Training;Degradation;Error analysis;Speech recognition;Speech enhancement;Performance gain;Data models;robust speech recognition;speech enhancement;knowledge distillation;multi-modality},
  doi={10.1109/ISCSLP57327.2022.10037802},
  ISSN={},
  month={Dec},}@ARTICLE{9889707,
  author={Catak, Ferhat Ozgur and Kuzlu, Murat and Tang, Haolin and Catak, Evren and Zhao, Yanxiao},
  journal={IEEE Access}, 
  title={Security Hardening of Intelligent Reflecting Surfaces Against Adversarial Machine Learning Attacks}, 
  year={2022},
  volume={10},
  number={},
  pages={100267-100275},
  abstract={Next-generation communication networks, also known as NextG or 5G and beyond, are the future data transmission systems that aim to connect a large amount of Internet of Things (IoT) devices, systems, applications, and consumers at high-speed data transmission and low latency. Fortunately, NextG networks can achieve these goals with advanced telecommunication, computing, and Artificial Intelligence (AI) technologies in the last decades and support a wide range of new applications. Among advanced technologies, AI has a significant and unique contribution to achieving these goals for beamforming, channel estimation, and Intelligent Reflecting Surfaces (IRS) applications of 5G and beyond networks. However, the security threats and mitigation for AI-powered applications in NextG networks have not been investigated deeply in academia and industry due to being new and more complicated. This paper focuses on an AI-powered IRS implementation in NextG networks along with its vulnerability against adversarial machine learning attacks. This paper also proposes the defensive distillation mitigation method to defend and improve the robustness of the AI-powered IRS model, i.e., reduce the vulnerability. The results indicate that the defensive distillation mitigation method can significantly improve the robustness of AI-powered models and their performance under an adversarial attack.},
  keywords={Data models;Computational modeling;Artificial intelligence;Security;Solid modeling;Receivers;Neural networks;Next generation networking;Adversarial machine learning;Security;next-generation networks;adversarial machine learning;model poisoning;intelligent reflecting surfaces},
  doi={10.1109/ACCESS.2022.3206012},
  ISSN={2169-3536},
  month={},}@ARTICLE{10847859,
  author={Saffari, Seyedeh Fatemeh and Kim, Daeho and Choi, Byungjoo},
  journal={IEEE Access}, 
  title={Robotization of Miniature-Scale Radio-Controlled Excavator: A New Medium for Construction- Specific DNN Data Generation}, 
  year={2025},
  volume={13},
  number={},
  pages={17054-17067},
  abstract={Digital management of excavators has seen limited progress due to challenges in artificial intelligence (AI) training. The AI required for digital twinning of excavators necessitates a large volume of diverse imagery data, currently scarce in the construction domain. Moreover, the absence of deployable robot agents hinders reinforcement learning, impeding task-oriented AI development. In response, we introduce an innovative approach utilizing a miniature-scale, radio-controlled excavator (RC-excavator). This presents a cost-effective method for automated data collection and labeling, as well as interactive reinforcement learning. The RC-excavator’s electric circuit was modified, its motion dynamics were modeled, and it was fully robotized for precise computer-directed motion control. Statistical validation of its motions achieved a Normalized Range Adjusted Accuracy (NRAA) of 99.14% for the bucket, 97.97% for the main arm, and 98.63% for the cabin. This confirms its adequacy for image labeling and task-oriented automation research.},
  keywords={Excavation;Artificial intelligence;Robots;Training;Labeling;Three-dimensional displays;Reinforcement learning;Synthetic data;Computational modeling;Receivers;Automated labeling;construction equipment;digital twinning;interactive reinforcement learning},
  doi={10.1109/ACCESS.2025.3532203},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10200962,
  author={Yu, Hao and Zhang, Jian and Guo, Yuenan and Qu, Shunke and Gong, Mingchen and Zeng, Xuanyu and Chen, Hao and He, Tianyuan and Xiao, Kejiang},
  booktitle={2023 IEEE 13th International Conference on Electronics Information and Emergency Communication (ICEIEC)}, 
  title={Attention-based BiLSTM Model for Rainfall Prediction}, 
  year={2023},
  volume={},
  number={},
  pages={176-180},
  abstract={In order to further improve the accuracy of rainfall prediction, this paper proposes a Bi-LSTM prediction model incorporating an attention mechanism. The model splits the input sequence into a spatio-temporal sequence and a feature sequence, and introduces an attention mechanism before the Bi-LSTM network model to calculate the attention of the two sequences separately before fusion. The Bi-LSTM network can adaptively select the most important input features according to their importance, and the parameters of the attention layer are obtained by a competitive random search algorithm, which further enhances the robustness of the model. Finally, the prediction experiments are conducted on real data, and the results show that the Bi-LSTM model based on attention mechanism has better prediction accuracy compared with support vector regression (SVR) and LSTM models, which can provide technical support for precipitation prediction.},
  keywords={Support vector machines;Adaptation models;Precipitation;Predictive models;Prediction algorithms;Transformers;Data models;rainfall prediction;Attention;Bi-LSTM},
  doi={10.1109/ICEIEC58029.2023.10200962},
  ISSN={2377-844X},
  month={July},}@INPROCEEDINGS{10472378,
  author={Hu, Yan and Chaddad, Ahmad},
  booktitle={2023 IEEE International Conference on E-health Networking, Application & Services (Healthcom)}, 
  title={Potential of Federated Learning in Healthcare}, 
  year={2023},
  volume={},
  number={},
  pages={1-2},
  abstract={Federated learning (FL) has emerged as a promising approach for training machine learning models on distributed data while preserving privacy specifically in the field of medical diagnosis. This paper provides a review of the applications of FL in healthcare, presents the standard FL training process, and suggests future research directions. Our analysis indicates that while FL has shown great potential, more work is needed to optimize its implementation in healthcare settings and ensure the reliability of FL models. Further investigation is necessary to fully realize the potential of FL to improve medical diagnosis.},
  keywords={Training;Federated learning;Reviews;Distributed databases;Market research;Medical diagnosis;Reliability;Federated Learning;AI;Healthcare},
  doi={10.1109/Healthcom56612.2023.10472378},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10248457,
  author={Liu, Kun and Wang, Ding and Yang, Ying and Wang, Jingkai and Mao, Jingkun},
  booktitle={2023 8th International Conference on Intelligent Computing and Signal Processing (ICSP)}, 
  title={A Domain Generalization Model Based on Multilevel Domain Adversarial Invariant Representation Learning}, 
  year={2023},
  volume={},
  number={},
  pages={2106-2110},
  abstract={Due to the influence of various factors such as cross-scene shooting height, shooting time, imaging angle of view, weather, etc., the performance of the defect detection model degrades in cross-scene situations. In this paper, we proposed a domain generalization model based on multilevel domain adversarial invariant representation learning, which included the designed defect space feature and channel feature enhancement modules. Among them, the defect space feature enhancement module uses the shallow feature invariance score to guide the model to extract cross-scene invariant representations, and at the same time, design and use the defect importance information in the shallow features to enhance the representation of defects in the shallow features. The channel feature enhancement module assigns learning weights to different channels of each sample according to the similarity between the sample and the whole, and the importance of different feature channels to defects, so as to better guide the model to extract cross-scene invariant representations. The experimental verification on the photovoltaic cell data set collected in outdoor natural scenes shows that, proposed model has stronger generalization ability than existed domain generalization methods.},
  keywords={Representation learning;Photovoltaic cells;Computational modeling;Imaging;Signal processing;Feature extraction;Data models;domain generalization;invariant feature;defect detection;photovoltaic cell},
  doi={10.1109/ICSP58490.2023.10248457},
  ISSN={},
  month={April},}@INPROCEEDINGS{9455950,
  author={Zhang, Jiacheng and Liu, Weishuo and Zhao, Zhicheng and Su, Fei},
  booktitle={2021 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)}, 
  title={Distribution Estimation Based Pseudo-Feature Library Generation For Few-Shot Image Classification}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Due to the high cost of labeled data acquisition, few-shot learning has attracted great attention in recent years. The biased estimation of class distribution from a few labeled samples hinders the model’s performance. Some existing methods generate samples or features by a learning module or network. In this paper, a distribution-based pseudo-feature library generation method is proposed, and it follows a simple distribution modeling hypothesis. The base class features is introduced to better estimate the novel class distribution. Furthermore, a patch-level pseudo-feature library is adversarially generated to reinforce the training of the classifier. The proposed method significantly improves the model performance for the few-shot image classification task without introducing additional training parameters. Our method ranks first in the ICME 2021 Few-Shot Learning for Vehicle Footprint Recognition Challenge, demonstrating its effectiveness.},
  keywords={Training;Conferences;Data acquisition;Estimation;Libraries;Task analysis;Image classification;Few-shot learning;fine-grained classification;pseudo-feature generation},
  doi={10.1109/ICMEW53276.2021.9455950},
  ISSN={},
  month={July},}@INPROCEEDINGS{8803111,
  author={Ma, Leiyuan and Liu, Ziyi and Zheng, Nanning and Wang, Jianji},
  booktitle={2019 IEEE International Conference on Image Processing (ICIP)}, 
  title={Har Enhanced Weakly-Supervised Semantic Segmentation Coupled with Adversarial Learning}, 
  year={2019},
  volume={},
  number={},
  pages={1845-1849},
  abstract={Semantic segmentation is a challenging computer visual task which needs enormous pixel-level annotation data. But collecting a large amount of pixel-level annotation data is labor intensive. To address this issue, our work focuses on weakly-supervised learning approach which combines the adversarial learning and localization ability of classification model together, in this way, data with different annotations can be fully utilized. Specifically, the adversarial learning encourages the high order spatial consistences thus offers a relatively reliable initial confidence map. And we find that the hybrid atrous rate (HAR) can improve the localization ability of the classification model, thus indicate more precise object-related regions, which serves as strong supervision information. We conduct experiments with different settings to demonstrate the effectiveness of this weakly-supervised learning approach. The results show that our approach can improve the performance of baseline adversarial learning from 73.2 to 75.1 (mIOU), which is pretty effective.},
  keywords={Image segmentation;Semantics;Training;Cams;Task analysis;Visualization;Data models;semantic segmentation;weakly-supervised;adversarial learning;atrous rate},
  doi={10.1109/ICIP.2019.8803111},
  ISSN={2381-8549},
  month={Sep.},}@INPROCEEDINGS{8803293,
  author={Zhang, Zheng and Xu, Yi and Wang, He and Ni, Bingbing and Xu, Hongteng},
  booktitle={2019 IEEE International Conference on Image Processing (ICIP)}, 
  title={Single-Image Rain Removal Via Multi-Scale Cascading Image Generation}, 
  year={2019},
  volume={},
  number={},
  pages={2771-2775},
  abstract={A novel single-image rain removal method is proposed based on multi-scale cascading image generation (MSCG). In particular, the proposed method consists of an encoder extracting multi-scale features from images and a decoder generating de-rained images with a cascading mechanism. The encoder ensembles the convolution neural networks using the kernels with different sizes, and integrates their outputs across different scales. The decoder implements a coarse-to-fine image generation framework, adding fine details incrementally to the final de-rained images according to the spatial contextual information on different scales. We test the proposed method on both synthetic and real-world datasets. Experimental results show that the proposed method is robust to the changes of scene, e.g., the viewpoint and the depth, the heaviness of rain, etc., which suppresses the blurring problem of de-rained image and outperforms state-of-the-art methods consistently.},
  keywords={Rain;Feature extraction;Loss measurement;Image synthesis;Decoding;Kernel;Periodic structures;Single-image de-raining;multi-scale;cascading image generation},
  doi={10.1109/ICIP.2019.8803293},
  ISSN={2381-8549},
  month={Sep.},}@INPROCEEDINGS{10445885,
  author={Yang, Guoxing and Lu, Haoyu and Li, Chongxuan and Zhou, Guang and Wu, Haoran and Lu, Zhiwu},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Progressive Image Synthesis from Semantics to Details with Denoising Diffusion GAN}, 
  year={2024},
  volume={},
  number={},
  pages={7495-7499},
  abstract={Although denoising diffusion probabilistic models (DDPMs) have shown remarkable progress in image generation, they typically face two main challenges: the time-expensive sampling process and the semantically meaningless latent space, which are often addressed separately in previous works. In particular, the latest representative work Denoising Diffusion GAN reduces the sampling steps to as few as two but ignores the semantics of the latent space. To address the two challenges simultaneously, we propose a two-stage framework to make the latent space of Denoising Diffusion GAN more semantically meaningful while enjoying its efficiency. Extensive results on three benchmark datasets demonstrate that our proposed diffusion model achieves competitive results with only two sampling steps in unconditional image generation. More importantly, the latent space of our diffusion model trained for unconditional image generation is shown to be semantically meaningful, which can be exploited on various downstream tasks (e.g., attribute editing) without further training.},
  keywords={Training;Image synthesis;Noise reduction;Semantics;Space exploration;Task analysis;Speech processing;Diffusion model;GAN;Latent space;Semantics},
  doi={10.1109/ICASSP48485.2024.10445885},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10400312,
  author={Kang, Yang and Haiyan, Wang and Yiwen, Zeng and Haiyang, Yao},
  booktitle={2023 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)}, 
  title={Underwater Monocular Vision 3D Reconstruction Based on Cascaded Epipolar}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Addressing the challenges of low accuracy in image depth prediction and significant disparity between reconstructed edges and reality in underwater monocular 3D reconstruction, this paper conducts an in-depth analysis of a deep learning network based on Cascaded Epipolar geometry. By employing model pre-training, camera pose inversion, adjusting the format of cascaded convolutions, and modifying the epipolar direction, the model gains the ability to perform 3D reconstruction of underwater monocular visual images. Experiment results on the public dataset Flsea indicates that the Cascaded Epipolar-based method for underwater monocular vision 3D reconstruction offers clearer depth prediction edges and 3D depth information. However, its performance in terms of Mean Squared Error (MSE) shows some deviation comparing to the state-of-the-art UW -GAN.},
  keywords={Solid modeling;Visualization;Three-dimensional displays;Convolution;Image edge detection;Cameras;Image reconstruction;underwater optical images;underwater monocular visual images;underwater 3D reconstruction;depth prediction},
  doi={10.1109/ICSPCC59353.2023.10400312},
  ISSN={2837-116X},
  month={Nov},}@INPROCEEDINGS{11086724,
  author={Zhang, Bo and Zhao, Kaixin and Wang, Shuailing and Ye, Yangdong},
  booktitle={2025 10th International Conference on Intelligent Computing and Signal Processing (ICSP)}, 
  title={Empowering Top-N Recommendation with Graph Adversarial Contrastive Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1143-1146},
  abstract={Graph neural networks (GNN) have demonstrated impressive performance on personalized recommendation. However, several challenges such as interaction noise and data sparsity hinder the learning of high-quality user and item representations. Recently, supervised learning combined with Contrastive Learning(CL) is a mainstream paradigm to optimize GNN-based recommenders when dealing with such challenges. Despite effectiveness, we argue that it still suffers from two crucial defects: (1) when integrating CL with GNNs, they usually perform stochastic perturbations on the user-item bipartite graph and node embedding, which may result in the vulnerable representations of users and items; meanwhile, the accuracy of the embedding is heavily rely on the design of the perturbation strategy; (2) in the supervised learning period, they generally employ a ranking-oriented loss (e.g., Bayesian personalized ranking, BPR) and treat each training instance equally, forgoing the subtle difference of different examples. To settle such limitations, we contribute a novel training paradigm, named Graph Adversarial Contrastive Learning (GAGL), to improve the generality and robustness of GNN-based recommenders. Specifically, we devise an adversarial contrastive learning principle, which adds adversarial perturbations on node embeddings to enhance model robustness. Furthermore, we design an instance-sensitive BPR to dynamically learn the contribution ratio of each training instance and formulate the entire training process as a bi-level optimization problem. Extensive experiments on four real-world datasets demonstrate the superiority of GACL over recent state-of-the-art methods.},
  keywords={Training;Perturbation methods;Computational modeling;Supervised learning;Stochastic processes;Contrastive learning;Robustness;Graph neural networks;Optimization;Recommender systems;recommendation systems;graph neural networks;contrastive learning;adversarial learning},
  doi={10.1109/ICSP65755.2025.11086724},
  ISSN={},
  month={May},}@INPROCEEDINGS{10448122,
  author={Lim, Heunseung and Shin, Jungkyoo and Choi, Hyoungki and Kim, Dohoon and Kim, Eunwoo and Paik, Joonki},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Gravitated Latent Space Loss Generated by Metric Tensor for High-Dynamic Range Imaging}, 
  year={2024},
  volume={},
  number={},
  pages={3300-3304},
  abstract={High Dynamic Range (HDR) imaging seeks to enhance image quality by combining multiple Low Dynamic Range (LDR) images captured at varying exposure levels. Traditional deep learning approaches often employ reconstruction loss, but this method can lead to ambiguities in feature space during training. To address this issue, we present a new loss function, termed Gravitated Latent Space (GLS) loss, that leverages a metric tensor to introduce a form of virtual gravity within the latent space. This feature helps the model in overcoming saddle points more effectively. Easy to integrate, the GLS loss function fosters stable learning within a convex environment and demonstrates its performance in improving HDR image quality. Experimental data confirms that the proposed method outperforms existing state-of-the-art techniques in quantitative evaluations.},
  keywords={Image quality;Training;Tensors;Imaging;Performance gain;Extraterrestrial measurements;Speech processing;metric tensor;high dynamic range;gravitated latent space},
  doi={10.1109/ICASSP48485.2024.10448122},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{11099833,
  author={N, Mathivanan and S, Aswath and S, Adithya and N, Ranjith Kumar},
  booktitle={2025 International Conference on Emerging Technologies in Engineering Applications (ICETEA)}, 
  title={RetroWinAug: A Lightweight Browser-Based Image Augmentation Tool with Privacy-Preserving Client-Side Processing}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Image augmentation is a key step towards the quality and diversity of datasets to be used in applications such as in computer vision, machine learning, and deep learning. As traditional image augmentation tools often require software installations on the local machine, server-side processing or remove thcloud-based systems, issues relating to compatibility with the local system, computational resource demand, latency and data privacy are common. In this paper, RetroWinAug, a browser based lightweight image augmentation tool is introduced to overcome these constraints through client-side processing with keeping user's privacy and usability intact. With a retro inspired user-friendly interface, RetroWinAug enables users to do several important image augmentations such as grayscale conversion, rotation, flipping, sepia filtering, brightness variation, blurring, etc, in their browser. It displays the original and augmented image side by side, and allows to view the results instantly as visual feedback to improve workflow. Since RetroWinAug is implemented in HTML, CSS, JavaScript, and OpenCV.js, it all runs on the client side, thus no user's sensitive data, e.g. medical or proprietary images, need be transmitted to a server. It is cross platform and does not require any additional software, plugins or high-performance hardware and works on desktops, tablets and mobile devices smoothly. There are a number of applications that RetroWinAug is well suited for, including medical imaging, autonomous vehicles, satellite imagery, agriculture, academic research, educational environment, and so on. By combining all the usability, privacy protection and accessibility, RetroWinAug proposed a very efficient solution to the image pre-processing task across different domains.},
  keywords={Performance evaluation;Deep learning;Privacy;Data privacy;Computer vision;Filtering;Image augmentation;Software;Usability;Biomedical imaging;Image Augmentation;Client-Side Processing;Web-Based Tool;Data Privacy;Computer Vision;Deep Learning;Cross-Platform;Medical Imaging;Autonomous Vehicles;OpenCV.js},
  doi={10.1109/ICETEA64585.2025.11099833},
  ISSN={},
  month={June},}@INPROCEEDINGS{10889308,
  author={Liang, Jun and Luo, Rui and Peng, Yang and Su, Hai},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={DuCol: Text-Tag Adaptive Colorization of Dual-Character Line Art}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Automatic colorization techniques often struggle with dual-character line art, particularly in areas such as color coordination between characters, handling complex scenes and interactions, and meeting personalized colorization requirements. To address these challenges, we introduce DuCol, a novel framework specifically designed for the colorization of dual-character line art. DuCol leverages text-based inputs to accommodate personalized color preferences and integrates a Text-Labeled Adaptive Colorization (TAC) Module to ensure global color assignment, effectively harmonizing colors between characters. Furthermore, the model utilizes detailed segmentation information from a skeleton graph to enable precise boundary detection, resolving interactions between characters and preventing color bleeding or ambiguity. Extensive experiments on a large-scale illustration dataset demonstrate that DuCol’s superiority in dual-character line art colorization, establishing it as a leading solution in this domain.},
  keywords={Adaptation models;Art;Color;Signal processing;Skeleton;Acoustics;Speech processing;Hemorrhaging;multiple characters;Line art;Colorization},
  doi={10.1109/ICASSP49660.2025.10889308},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{11158367,
  author={Sai Kiran, Chintha Reddy and S, Hariharasitaraman and Ahmed, Sajjad and Phulre, Ajay Kumar},
  booktitle={2025 International Conference on Advancements in Smart, Secure and Intelligent Computing (ASSIC)}, 
  title={Zero-Day Malware Detection Using Autoencoder and Hybrid Deep Learning Model}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Malware continues to pose a serious threat to cybersecurity, especially with the rise of unknown or zero day attacks that bypass the traditional antivirus tools. This study proposes a hybrid detection framework that combines machine learning and deep learning for more effective threat identification. Known malware is classified using an RNN-LSTM model, while an Autoencoder detects unfamiliar threats by learning typical benign behavior and flagging anomalies. To improve accuracy, XGBoost is used to select the most relevant features for analysis. Experimental results show that the model achieves 99% accuracy in detecting known malware and reliably identifies previously unseen attacks. This approach demonstrates strong potential for enhancing proactive and scalable cybersecurity defenses.},
  keywords={Deep learning;Adaptation models;Accuracy;Computational modeling;Autoencoders;Malware;Real-time systems;Data models;Reliability;Computer security;zero day attack;deep learning;machine learning},
  doi={10.1109/ASSIC64892.2025.11158367},
  ISSN={},
  month={May},}@INPROCEEDINGS{10722747,
  author={Deva Sundar, M and Ansgar, V and Atchaya, S and Ananthi, S},
  booktitle={2024 5th International Conference on Smart Electronics and Communication (ICOSEC)}, 
  title={Altered Image Detection in E-commerce Products Using Feature Fusion Model}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={In today’s world, e-commerce websites have become the go-to choice for shoppers. Unfortunately, scammers exploit this by using altered or filtered photos to deceive customers, leading to dissatisfaction and financial losses. This study addresses this issue by introducing a novel approach for detecting altered images on e-commerce platforms. The proposed model employs a feature-level fusion method that combines traditional feature extraction with a Convolutional Neural Network (CNN)-based model to identify manipulated images effectively. This approach leverages the strengths of both traditional image processing techniques and modern deep learning architectures. Extensive experimentation has shown that this model significantly enhances accuracy, achieving a $\mathbf{9 5 \%}$ improvement over standalone CNN models. The model’s robustness and accuracy have been validated across various product categories, confirming its suitability for different types of e-commerce images. The primary objective is to increase the reliability of product images, thereby boosting customer satisfaction and reducing return rates.},
  keywords={Industries;Accuracy;Customer satisfaction;Deep architecture;Switches;Feature extraction;Information filters;Robustness;Electronic commerce;Convolutional neural networks;CNN;image classification;filters;feature extraction},
  doi={10.1109/ICOSEC61587.2024.10722747},
  ISSN={},
  month={Sep.},}
