@INBOOK{10952738,
  author={Jay, Rabi},
  booktitle={Enterprise AI in the Cloud: A Practical Guide to Deploying End-to-End Machine Learning and ChatGPT Solutions}, 
  title={Implementing Generative AI Use Cases with ChatGPT for the Enterprise}, 
  year={2024},
  volume={},
  number={},
  pages={433-464},
  abstract={Summary <p>This chapter discusses the role that generative artificial intelligence (AI) and ChatGPT can play in businesses, products, services, and relationships. The story of generative AI is one of resilience and continuous innovation, starting all the way from small statistical models to deep learning to large language models. Generative AI is a type of AI that uses techniques to generate new, realistic artifacts based on its learning from existing artifacts. Large language models are those that can understand, generate, and work with human language. ChatGPT is a conversational chatbot application that uses an OpenAI service to create new content. The ChatGPT OpenAI service serves the output from a large language model that is trained on billions of words from multiple sources. The chapter also discusses some best practices to follow when implementing Generative AI and reviews the generative AI cloud platform tools offered by Azure.</p>},
  keywords={Generative AI;Data models;Artificial intelligence;Deep learning;Predictive models;Business;Machine learning;Chatbots;Drugs;Biological neural networks},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394213078},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952738},}@INPROCEEDINGS{9396839,
  author={Sargar, Omkar and Kinger, Shakti},
  booktitle={2021 International Conference on Emerging Smart Computing and Informatics (ESCI)}, 
  title={Image Captioning Methods and Metrics}, 
  year={2021},
  volume={},
  number={},
  pages={522-526},
  abstract={Image Captioning is one of the emerging topics of research in the field of AI. It uses a combination of Computer Vision (CV) and Natural Language Processing (NLP) to derive features from the image, use this information to identify objects, actions, their relationships, and generate a description for the image. It is most important concept in artificial intelligence applied in the fields like aid to the blind, self-driving cars, and many more. This paper we demonstrates a concise state of art image captioning and its method for caption generation using deep learning concepts. We also determine the approach for image caption generation using Convolutional Neural Network (CNN) and Generative Adversarial Network (GAN) model in deep learning framework. Using this approach system intelligent enough to create sentences for images. It uses the encoder-decoder architecture, where CNN is used for image vector generation and LSTM is used for the generation of a logical sentence using the NLP concepts. Finally, we evaluate the proposed system experimental analysis with numerous existing systems and show the effeteness of system.},
  keywords={Deep learning;Measurement;Computational modeling;Generative adversarial networks;Natural language processing;Gallium nitride;Artificial intelligence;Deep learning;AI;natural language processing;computer vision},
  doi={10.1109/ESCI50559.2021.9396839},
  ISSN={},
  month={March},}@INPROCEEDINGS{10111118,
  author={Zhai, Chunpeng and Wibowo, Santoso and Cowling, Michael},
  booktitle={2023 11th International Conference on Information and Education Technology (ICIET)}, 
  title={An Innovative Tool for Education: An Adversarial Dialogue System Embedded with Humor, Empathy and Culture}, 
  year={2023},
  volume={},
  number={},
  pages={163-166},
  abstract={Artificial intelligence (AI) dialogue systems are gaining popularity in education for enhancing user experience and achieving learning outcomes. However, there is a limited study on AI dialogue systems can dynamically generate humorous interactions and empathetic responses to learners' emotions while considering their cultural diversity. This work-in-progress paper presents an interactive adversarial learning system, the MACHE-Bot, based on Wasserstein's generative adversarial network (WGAN) that uses user input to determine whether the generated responses entail humor, empathy, and culture in learning. The significance of the MACHE-Bot is: (1) it can trigger humorous and empathetic interactions and consider learners' cultural varieties, (2) it is able to capture the subtleties of user emotion, (3) it is capable of expressing multimodal humorous responses by recalling prior context and external knowledge, and (4) it is embedded with a corpus of cultural contexts, semantic properties, and language editions to enhance learning experience and outcomes. This study is useful because the ability of the MACHE-Bot to generate responses that are tailored to the user's emotions and cultural background can greatly enhance the learning experience and lead to better learning outcomes. Additionally, the use of a WGAN and the incorporation of external knowledge and cultural context makes the MACHE-Bot a unique and innovative system that has the potential to improve the overall effectiveness of AI-powered educational systems.},
  keywords={Emotion recognition;Education;Semantics;Oral communication;Learning (artificial intelligence);Generative adversarial networks;Adversarial machine learning;WGAN;humorous interactions;empathetic responses;cultural diversity},
  doi={10.1109/ICIET56899.2023.10111118},
  ISSN={},
  month={March},}@INPROCEEDINGS{10456422,
  author={Sarkar, Indrojit and Rabbi, Fazle and Azim, Md. Ayenul and Chowdhury, Md. Ashiqul Haider and Ferdous, Maliha and Ali, Mohammad},
  booktitle={2023 IEEE 9th International Women in Engineering (WIE) Conference on Electrical and Computer Engineering (WIECON-ECE)}, 
  title={SmartFire Car: An Image Processing and Artificial Intelligence-Based Fire Detection and Extinguishing System}, 
  year={2023},
  volume={},
  number={},
  pages={40-45},
  abstract={In this work, we present a novel image processing and artificial intelligence-based autonomous vehicle system for swift fire detection and suppression. The suggested approach offers a unique and economical option, especially for developing nations, to properly tackle fire-related threats in crowded residential spaces and outdoors. The algorithm used by the system, the Haar cascade, is effective in spotting fire in real-time video feeds. After detecting and determining the ideal stopping distance from the fire, the SmartFire car begins to effectively and efficiently extinguish it. To put the proposed theoretical system to the test in actual practical settings, we developed our prototype. The capacity of the SmartFire prototype to measure distances from the fire source and continue operating amid several fire sources has been used to evaluate its effectiveness. To make the system reliable and efficient, its limitations, such as the smallest fire size needed for detection, have also been examined. This work has the potential to significantly contribute to the modernization of the traditional fire-fighting system, particularly in developing countries, leading to more effective fire-handling capabilities.},
  keywords={Image processing;Prototypes;Streaming media;Reliability theory;Generative adversarial networks;Real-time systems;Sensors;SmartFire car;Artificial Intelligence;Image Processing;Cost-effective;Haar Cascade Algorithm;Prototype},
  doi={10.1109/WIECON-ECE60392.2023.10456422},
  ISSN={2837-8245},
  month={Nov},}@INPROCEEDINGS{10028941,
  author={Menaka, S and Shivani, B and Malavikka, S and Ganesh, B S and Saravanan, V},
  booktitle={2022 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI)}, 
  title={A Reliable and Fast Automatic Combination of Deep Features and Species Categorization Using Unified Ensemble Layer}, 
  year={2022},
  volume={01},
  number={},
  pages={1-6},
  abstract={Plant species detection objectives is to automatically identify the type of plant. Despite the fact that a number of components like leaf, plants, culmination, seeds could make a contribution to the selection, leaf functions are the most popular. Since leaves of different plant species are accessible in comparison to different elements of the plants, this becomes obvious that we the study with the help of leaf. This paper delivers plant species -classifier novel based which is dependent on extracting morphological capabilities Firstly, 2 -layers of plant taxonomy are built for arranging huge counts of different species of plants with its genus orderly. Secondly, framework of deep learning been built for allowing tree classifiers that is path-based. Here the plant taxonomy over tree classifier is used to in the place of flat soft-max portion in deep CNNs conventional. function based on path have been described for enhancing this method for learning tree classifiers and deep CNN, in which backpropagation to upgrade each of the parameter classifier and the community weights concurrently. From the proposed system, we present a multi-path multi-deep convolutional network for the identity of plant species which feeds specific versions of plant photographs, for this reason the resultant model has higher image presentation than traditional Ensemble learning. complete experimental evaluation on benchmark plant datasets confirmed that without the usage of any pre-educated fashions, our proposed shallow network demonstrates very competitive performance for plant species identification.},
  keywords={Deep learning;Taxonomy;Vegetation;Learning (artificial intelligence);Seeds (agriculture);Reliability;Object recognition;morphological;plant taxonomy;SoftMax layer;CNN;Ensemble learning},
  doi={10.1109/ICDSAAI55433.2022.10028941},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9573657,
  author={Teow, Matthew Y. W.},
  booktitle={2021 IEEE International Conference on Artificial Intelligence in Engineering and Technology (IICAIET)}, 
  title={Convolutional Autoencoder for Image Denoising: A Compositional Subspace Representation Perspective}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={This study explores a convolutional autoencoder for image denoising with a proposed compositional subspace method. This modeling approach presents a structural and rigorous mathematical abstraction to understand a convolutional autoencoder's functional computation layers. The theoretical basis is that the best way to model a complex learning function is by using a composition of simple functions to form a multilayer successive cascaded function for complex representation. The proposed method has experimented with the Fashion-MNIST dataset. Experimental results are discussed and were consistent with the theoretical expectation.},
  keywords={Computational modeling;Conferences;Learning (artificial intelligence);Nonhomogeneous media;Mathematical models;Image reconstruction;Image denoising;Convolutional Autoencoders;Deep Learning;Computer Vision;Image Denoising;Compositional Subspace Representations},
  doi={10.1109/IICAIET51634.2021.9573657},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10365033,
  author={Lakmal, H.K.I.S. and Dissanayake, Maheshi B. and Aramvith, Supavadee},
  booktitle={2023 7th SLAAI International Conference on Artificial Intelligence (SLAAI-ICAI)}, 
  title={Enhancing Visual Fidelity in Unpaired Night-to-Day Image Translation through a Perceptual Quality Focused Training Objective}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Nighttime driving poses visibility challenges, but image translation methods can help by transforming night images into day-like scenes. The Cycle-GAN is a versatile unpaired image translation model which can easily be adept to night-to-day image translation tasks. However, it generates unnatural and unrealistic outcomes in these cases. This study is focused on addressing this with a novel training strategy for the Cycle-GAN, employing a tailored training objective that incorporates perceptual quality optimization. This training objective aims to boost the naturalness and perceptual quality of the generated images by preserving high-level image features. The optimization process involves minimizing Euclidean distances between synthesized and target image feature maps, which are derived from the pre-trained VGG19 network. Experimental findings attest to the effectiveness of this method, revealing noteworthy improvements of 8% in Inception Score, 2% in NIQE Score, and 13% in BRISQUE Score.},
  keywords={Training;Visualization;Adaptation models;Safety;Task analysis;Artificial intelligence;Optimization;night driving;image translation;perceptual quality;night-to-day;cycle-GAN},
  doi={10.1109/SLAAI-ICAI59257.2023.10365033},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10899966,
  author={Li, Yongzhi and Jia, Chunyang and Lv, Jianing and Ma, Xiaodong and Zhang, Jianguo and Weng, Xiaolong},
  booktitle={2024 4th International Conference on Artificial Intelligence, Robotics, and Communication (ICAIRC)}, 
  title={Dynamic camouflage generation using online learning in conditional GANs}, 
  year={2024},
  volume={},
  number={},
  pages={370-373},
  abstract={Traditional camouflage designs rely mainly on manual experience and fail to integrate environmental textures effectively, nor do they adequately consider the complexity and diversity of battlefield backgrounds. In light of this, this paper introduces a dynamic camouflage generation method based on an online learning with conditional GANs. This method uses online learning algorithm to train the model and combines style loss, pixel loss, color distribution loss, adversarial loss, and patch discriminator to ensure the generation effect, which can produce high-quality camouflage patterns from background images. To assess the effectiveness of the generated images, we calculated the Fréchet Inception Distance (FID) between them and real samples, achieving a score of 11.08. Additionally, we measured the Structural Similarity Index (SSIM) between the generated camouflage patterns and their corresponding backgrounds, which resulted in a value of 0.89. It indicates the successful camouflage effect of the generated patterns. Moreover, by integrating these camouflage patterns into background images and analyzing their blending with the backgrounds using the Canny detector, we further validate the efficacy of the generated camouflage patterns produced by this model.},
  keywords={Analytical models;Image color analysis;Heuristic algorithms;Learning (artificial intelligence);Manuals;Detectors;Complexity theory;Indexes;Robots;Camouflage pattern;Conditional GANs;Dynamic camouflage generation;Online learning},
  doi={10.1109/ICAIRC64177.2024.10899966},
  ISSN={},
  month={Dec},}@ARTICLE{10768939,
  author={Yu, Zhiping and Liu, Chenyang and Liu, Liqin and Shi, Zhenwei and Zou, Zhengxia},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={MetaEarth: A Generative Foundation Model for Global-Scale Remote Sensing Image Generation}, 
  year={2025},
  volume={47},
  number={3},
  pages={1764-1781},
  abstract={The recent advancement of generative foundational models has ushered in a new era of image generation in the realm of natural images, revolutionizing art design, entertainment, environment simulation, and beyond. Despite producing high-quality samples, existing methods are constrained to generating images of scenes at a limited scale. In this paper, we present MetaEarth - a generative foundation model that breaks the barrier by scaling image generation to a global level, exploring the creation of worldwide, multi-resolution, unbounded, and virtually limitless remote sensing images. In MetaEarth, we propose a resolution-guided self-cascading generative framework, which enables the generating of images at any region with a wide range of geographical resolutions. To achieve unbounded and arbitrary-sized image generation, we design a novel noise sampling strategy for denoising diffusion models by analyzing the generation conditions and initial noise. To train MetaEarth, we construct a large dataset comprising multi-resolution optical remote sensing images with geographical information. Experiments have demonstrated the powerful capabilities of our method in generating global-scale images. Additionally, the MetaEarth serves as a data engine that can provide high-quality and rich training data for downstream tasks. Our model opens up new possibilities for constructing generative world models by simulating Earthâs visuals from an innovative overhead perspective.},
  keywords={Remote sensing;Image synthesis;Image resolution;Noise;Diffusion models;Training;Noise reduction;Computational modeling;Solid modeling;Visualization;Diffusion model;generative foundation model;remote sensing;self-cascading generation;unbounded generation},
  doi={10.1109/TPAMI.2024.3507010},
  ISSN={1939-3539},
  month={March},}@ARTICLE{9351918,
  author={Lee, Yun Kyung and Kim, Hyun Woo and Park, Jeon Gue},
  journal={IEEE Access}, 
  title={Many-to-Many Unsupervised Speech Conversion From Nonparallel Corpora}, 
  year={2021},
  volume={9},
  number={},
  pages={27278-27286},
  abstract={We address a nonparallel data-driven many-to-many speech modeling and multimodal style conversion method. In this work, we train a speech conversion model for multiple domains rather than a specific source and target domain pair, and we generate diverse output speech signals from a given source domain speech by transferring some speech style-related characteristics while preserving its linguistic content information. The proposed method comprises a variational autoencoder (VAE)-based many-to-many speech conversion network with a Wasserstein generative adversarial network (WGAN) and a skip-connected autoencoder-based self-supervised learning network. The proposed conversion network trains the models by decomposing the spectral features of the input speech signal into a content factor that represents domain-invariant information and a style factor that represents domain-related information to automatically estimate the various speech styles of each domain, and the network converts the input speech signal to another domain using the computed content factor with the target style factor we want to change. Diverse and multimodal outputs can be generated by sampling different style factors. We also train models in a stable manner and improve the quality of generated outputs by sharing the discriminator of the VAE-based speech conversion network and that of the self-supervised learning network. We apply the proposed method to speaker conversion and perform the perceptual evaluations. Experimental results revealed that the proposed method obtained high accuracy of converted spectra, significantly improved the sound quality and speaker similarity of the converted speech, and contributed to stable model training.},
  keywords={Decoding;Generative adversarial networks;Gallium nitride;Training;Data models;Speech;Speech conversion (SC);non-parallel SC;many-to-many SC;Wasserstein generative adversarial network (WGAN);variational auto-encoder (VAE);self-supervised learning},
  doi={10.1109/ACCESS.2021.3058382},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8784069,
  author={Salapura, Valentina and Wood, David and Witherspoon, Shonda Adena and Grueneberg, Keith and Bertino, Elisa and Jabal, Amani Abu and Calo, Seraphin},
  booktitle={2019 IEEE International Conference on Smart Computing (SMARTCOMP)}, 
  title={Generative Policy Framework for AI Training Data Curation}, 
  year={2019},
  volume={},
  number={},
  pages={475-477},
  abstract={Policy-based mechanisms are used to implement desired autonomic behavior of a managed system in a distributed environment. For modern dynamically changing systems, policy-based mechanisms tend to be too rigid, and quickly lose their efficacy when conditions of the autonomous system change during its operation. In this paper, we propose a generative policy framework that can generate policies for an autonomous system when conditions change. For changed conditions, the policy generation manager dynamically generates new set of policies optimized for the new situation. As a use case, we demonstrate how our generative policy framework generates policies for selecting optimal data for an AI model training. The policies are dynamically generated based on the availability and trustworthiness of data in a coalition environment.},
  keywords={Conferences;Business;generative policy framework, context aware policies, automatic policy generation, autonomous managed systems},
  doi={10.1109/SMARTCOMP.2019.00092},
  ISSN={},
  month={June},}@INPROCEEDINGS{10137955,
  author={Shao, Guifang and Chen, Hongrong and Gao, Fengqiang},
  booktitle={2022 6th Asian Conference on Artificial Intelligence Technology (ACAIT)}, 
  title={An Improved GAN Model Based on Positive Samples for LED Die Defect Detection}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={The positive sample learning for defect detection can be applied to avoid the deficiency of deep learning networks. But there still exist the problems of simple defect generation and low detective accuracy. Thus, we put forward an improved GAN model for light emitting diode (LED) die defect detection. Firstly, we use GAN and the artificially generated defects to train the generator for fixing defects. Here, the real defect datasets and a random function are utilized in the defect generation module to generate multiple defects. An attention module is added to the discriminator to help the model detecting minor defects. Then, SSIM is used to compare the difference between the repaired image and the original image, and Otsu is utilized to detect and segment defects. What’s more, to improve the quality of the generated image, the SSIMLoss and NormalLoss are introduced into the original reconstruction loss function. Experiments on DAGM 2007 public dataset and the LEDWP dataset verify the efficiency of our proposed method compared to the one with no improvement introduction.},
  keywords={Training;Deep learning;Image segmentation;Learning (artificial intelligence);Maintenance engineering;Light emitting diodes;Generative adversarial networks;LED die;defect detection;GAN;positive sample learning},
  doi={10.1109/ACAIT56212.2022.10137955},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10581772,
  author={Wang, Sheng and Zhao, Ying and Zhang, Yan and Dai, Tingting and Ji, Qing},
  booktitle={2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={Sketch Face Expression Recognition under Simulated Prosthetic Vision}, 
  year={2024},
  volume={},
  number={},
  pages={1667-1670},
  abstract={For patients with severe retinitis pigmentosa (RP) or age-related macular degeneration (AMD), retinal prostheses could be the most effective means of visual rehabilitation at present. Facial perception is an ability that potential subjects of prostheses are eager to regain, and expression recognition is one of the important components of facial perception. However, limited by the number of available retinal prosthesis stimulation electrodes currently, only low resolution perception can be generated. Thus, it becomes an important task to investigating and applying different image processing strategies to optimize the perceptual effects presented to prosthesis implant recipients. To achieve accurate recognition of expressions, a lightweight image style conversion method was proposed to realize the conversion of original images to sketch images, and the expression recognition effect after pixelating the sketch images and original images at three resolutions: 24×24, 32×32 and 48×48 was investigated. The results of psychophysical experiments showed that the sketch images at low resolution, i.e., 24×24, were more conducive to expression recognition compared to directly pixelating the original image. Furthermore, the expression recognition effect of original image and sketch image under normal human vision were also studied, the results showed an accuracy of 70.41 % and 59.18%, respectively and could provide a reference for subsequent related research.},
  keywords={Image quality;Seminars;Visualization;Image recognition;Image resolution;Accuracy;Face recognition;retinal prostheses;simulated prosthetic vision;style migration;sketching;expression recognition},
  doi={10.1109/AINIT61980.2024.10581772},
  ISSN={},
  month={March},}@ARTICLE{10946701,
  author={Tang, Zecheng and Wu, Xiaolong and Han, Honggui},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Robust Reconstructed Neural Network Based on Spectral Elastic Activation}, 
  year={2025},
  volume={36},
  number={8},
  pages={15322-15336},
  abstract={The presence of sparse samples poses a formidable challenge for neural networks (NNs) in shaping representative patterns due to the limited coverage of concentrative activation range in NNs. To address this issue, a robust reconstructed NN, based on spectral elastic activation (SEA-RRNN), is developed in this article. Primarily, a spectral elastic activation (SEA) is designed to broaden the original activation of NNs, which embeds a spectral increment scaled by the estimated outlier degree on the activation boundary. It enables SEA-RRNN to stretch the boundary of SEA to cover the features of sparse samples. Then, an adaptive robust gradient descent (ARGD) algorithm is introduced to update the parameters of SEA. By tuning the loss between error and correntropy with the estimated outlier degree, the ARGD algorithm establishes two loss functions with complementary distance sensitivity for different parameters of SEA, which alleviates the construction conflict of robust center and precise boundary in SEA-RRNN. Furthermore, the theoretical analysis of SEA-RRNN is provided to validate its convergence and robustness. Finally, the experimental results demonstrate that SEA-RRNN exhibits superior robustness compared to other NN models.},
  keywords={Artificial neural networks;Robustness;Heuristic algorithms;Training;Sensitivity;Market research;Feature extraction;Standards;Neurons;Generative adversarial networks;Neural networks (NNs);robust gradient descent;robustness;sparse samples;spectral elastic activation (SEA)},
  doi={10.1109/TNNLS.2025.3548439},
  ISSN={2162-2388},
  month={Aug},}@ARTICLE{10639254,
  author={Gnanha, Aurele Tohokantche and Cao, Wenming and Mao, Xudong and Wu, Si and Wong, Hau-San and Li, Qing},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={EviD-GAN: Improving GAN With an Infinite Set of Discriminators at Negligible Cost}, 
  year={2025},
  volume={36},
  number={4},
  pages={6422-6436},
  abstract={Ensemble learning improves the capability of convolutional neural network (CNN)-based discriminators, whose performance is crucial to the quality of generated samples in generative adversarial network (GAN). However, this learning strategy results in a significant increase in the number of parameters along with computational overhead. Meanwhile, the suitable number of discriminators required to enhance GAN performance is still being investigated. To mitigate these issues, we propose an evidential discriminator for GAN (EviD-GAN)—code is available at https://github.com/Tohokantche/EviD-GAN—to learn both the model (epistemic) and data (aleatoric) uncertainties. Specifically, by analyzing three GAN models, the relation between the distribution of discriminator’s output and the generator performance has been discovered yielding a general formulation of GAN framework. With the above analysis, the evidential discriminator learns the degree of aleatoric and epistemic uncertainties via imposing a higher order distribution constraint over the likelihood as expressed in the discriminator’s output. This constraint can learn an ensemble of likelihood functions corresponding to an infinite set of discriminators. Thus, EviD-GAN aggregates knowledge through the ensemble learning of discriminator that allows the generator to benefit from an informative gradient flow at a negligible computational cost. Furthermore, inspired by the gradient direction in maximum mean discrepancy (MMD)-repulsive GAN, we design an asymmetric regularization scheme for EviD-GAN. Unlike MMD-repulsive GAN that performs at the distribution level, our regularization scheme is based on a pairwise loss function, performs at the sample level, and is characterized by an asymmetric behavior during the training of generator and discriminator. Experimental results show that the proposed evidential discriminator is cost-effective, consistently improves GAN in terms of Frechet inception distance (FID) and inception score (IS), and performs better than other competing models that use multiple discriminators.},
  keywords={Generative adversarial networks;Training;Uncertainty;Generators;Computational modeling;Data models;Ensemble learning;Deep learning;evidential learning;generative adversarial networks (GANs);generative modeling},
  doi={10.1109/TNNLS.2024.3388197},
  ISSN={2162-2388},
  month={April},}@INPROCEEDINGS{10692671,
  author={Li, Yulong and Wang, Boqian and Su, Jionglong},
  booktitle={2024 IEEE 7th International Conference on Big Data and Artificial Intelligence (BDAI)}, 
  title={GP-PAIL: Generative Adversarial Imitation Learning in Massive-Agent Environments}, 
  year={2024},
  volume={},
  number={},
  pages={314-322},
  abstract={Traditional multi-agent reinforcement learning algorithms are unsuitable for massive-agent environments where the problems of credit allocation, dense reward function design and stage course design become pronounced. Since massive-agent environments can only give sparse rewards to the agents, these algorithms face difficulty in learning effective actions. While specially designed dense reward functions can help the agents to obtain more reward signals, the algorithms face a trade-off between convergence speed and generalization ability. Although a hand-crafted reward function can provide frequent feedback that accelerates the learning of the agents, excessively detailed rewards may cause the agents to focus on short-term rewards and overlook long-term goals, resulting in a sub-optimal strategy. To address this, we propose GP-PAIL (Generative Pixel-to-Pixel Adversarial Imitation Learning), a novel generative adversarial imitation learning algorithm that uses a pixel-to-pixel policy structure for centralized control. It mitigates the issues of fixed behavioral patterns and credit allocation inherent in the specially designed of dense reward functions and staged curricula, enhancing imitation learning in massive-agent environments. Experimental results demonstrate the efficacy of GP-PAIL, with a 92% win rate compared to the best12 algorithm. Furthermore, in terms of early skill learning speed, it improves nearly 3.25 times faster on number of episodes compared to the current state-of-the-art best32 algorithm.},
  keywords={Imitation learning;Accelerated aging;Cloning;Reinforcement learning;Big Data;Resource management;Artificial intelligence;Faces;Convergence;Centralized control;Generative Adversarial Imitation Learning;LUX;Massive-Agent Reinforcement Learning Environments;Pixel-To-Pixel Policy Architecture;Behavioral Cloning},
  doi={10.1109/BDAI62182.2024.10692671},
  ISSN={},
  month={July},}@INPROCEEDINGS{10981046,
  author={Xun, Tianwang and Li, Ruiyu and Su, Lei and Wu, Junxian and Dong, Di and Shang, Wenting and Shao, Lizhi},
  booktitle={2025 IEEE 22nd International Symposium on Biomedical Imaging (ISBI)}, 
  title={MIHCGENER: A Framework for Multiple Immunohistochemical Image Generation Based on the Combination of Pathological Foundation Model and Generative Model}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={The tumor microenvironment (TME) is important to the treatment and prognosis of cancer. Multiplex Immunohistochemical (mIHC) images can display the expression of multiple biomolecular markers while maintaining spatial location, making it an effective tool for TME analysis. However, acquiring mlHC images demands stringent laboratory conditions, extensive time and resources. In this study, we proposed an end-to-end generative framework to transform hematoxylin and eosin (H&E) images into mIHC images. In addition, we introduced a pathological foundation model into the feature encoding of pathological image generation to enhance the performance of our framework and proved the superiority and necessity of the foundation model. Our method successfully generated mIHC images, achieved state-of-the-art (SOTA) performance against popular methods and maintained robustness on cross-cancer. The framework we proposed is expected to provide a more efficient and cheaper tool for the observation and evaluation of TME in pathology.},
  keywords={Multiplexing;Pathology;Foundation models;Image synthesis;Biological system modeling;Transforms;Immune system;Cancer;Biomedical imaging;Tumors;Multiplex Immunohistochemical image;Generative model;Pathology;Foundation model},
  doi={10.1109/ISBI60581.2025.10981046},
  ISSN={1945-8452},
  month={April},}@INPROCEEDINGS{10703969,
  author={Nataraj, Vidhya and Liao, Wen-Hsuan and Chang, Yue-Shan and Chiang, Chen-Yu and Lin, Chao-Yin and Lin, Yu-An and Day, Min-Yuh},
  booktitle={2024 IEEE International Conference on Information Reuse and Integration for Data Science (IRI)}, 
  title={Generative AI in Multimodal Cross-Lingual Dialogue System for Inclusive Communication Support}, 
  year={2024},
  volume={},
  number={},
  pages={204-209},
  abstract={Advancements in natural language processing have enhanced dialogue systems, making them vital for inclusive technology that facilitates accessible interactions across diverse user needs. However, existing systems often struggle with multimodal inputs, multilingual support, and generating contextually appropriate responses in data-scarce environments. This research addresses these gaps by developing an integrated dialogue system leveraging generative AI models like ChatGPT and multimodal inputs like text, audio, and image. The system utilizes transfer learning and large language models (LLMs) to process multilingual data, generating comprehensive responses tailored to user context. The proposed approach constructs a multimodal cross-lingual task-oriented dialogue system capable of understanding and responding to users in multiple languages and modalities. The proposed multimodal cross-lingual task-oriented dialogue system will enhance functionality and inclusivity compared to traditional unimodal or single-language dialogue systems in providing inclusive communication support. The major research contribution of this study highlights the potential of generative AI in developing accessible dialogue systems that cater to diverse user needs to advance inclusive technology. Practitioner implications of this paper highlight the potential of multimodal cross-lingual dialogue system to foster digital inclusion and inclusive communication support, improving accessibility and equity in human-computer interactions for diverse users.},
  keywords={Generative AI;Large language models;Computational modeling;Transfer learning;Training data;Data science;Chatbots;Data models;Rough surfaces;Digital divide;Generative AI;Large Language Models (LLMs);Multimodal;Cross-lingual;Dialogue System;Inclusive Communication Support},
  doi={10.1109/IRI62200.2024.00051},
  ISSN={2835-5776},
  month={Aug},}@INPROCEEDINGS{10837605,
  author={Boubakri, Meryem and Nafil, Khalid},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Enhancing Student Learning in Scrum Projects with Generative AI Assistance}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This article focuses on integrating generative AI tools, particularly ChatGPT and Bard, into Scrum framework education to enhance student learning and collaboration. Drawing from feedback obtained from students, the study compares the effectiveness of these tools, highlighting ChatGPT's detailed responses and Bard's conciseness. Despite students' overall satisfaction with GAI integration, they highlighted the irreplaceable role of human educators. Areas for improvement include addressing technical issues and enhancing GAI adaptability. The students' recommendations include utilizing GAI for various tasks and providing clearer prompts and training. Moving forward, the focus should be on improving GAI tools to better comprehend context and adaptability, and exploring collaborative learning approaches. To evaluate the impact of GAI integration on student outcomes, long-term studies must be conducted. In summary, while generative AI has potential to enhance Scrum education, its incorporation should be balanced with human guidance to create dynamic and effective learning environments.},
  keywords={Training;Surveys;Technological innovation;Generative AI;Federated learning;Reviews;Instruments;Collaboration;Project management;Chatbots;Education;Scrum;ChatGPT;Bard;Generative AI;Prompting},
  doi={10.1109/ITHET61869.2024.10837605},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{10981337,
  author={Munar, Leonardo Saavedra and Astrid González Jiménez, Dulfay and López Sotelo, Jesús Alfonso and Vicente Pradilla Cerón, Juan},
  booktitle={2025 IEEE Engineering Education World Conference (EDUNINE)}, 
  title={Opportunities for Integrating Generative AI, Service-Learning and Maker Movement for Transformative Learning in Engineering Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={This article explores the possibilities of integrating Generative AI, the maker movement, and service learning in engineering education to promote transformative learning. Empirical data from first-year engineering students identified three key outcomes: increased ability to solve complex problems through creative and collaborative approaches; enhanced social skills such as teamwork and community engagement; and greater personalization and effectiveness of learning via generative tools. Lessons learned emphasize the importance of flexible curriculum planning for smooth integration of these methodologies and the necessity of teacher training to manage interdisciplinary projects. The study highlights the need for a holistic approach that links learning outcomes to the social and technological context. Ultimately, this integrative methodology offers opportunities to innovate engineering education by creating more active and meaningful educational experiences, preparing future engineers for the challenges of today's world by fostering the technical, critical, and social competencies essential to their professional education.},
  keywords={Training;Generative AI;Teamwork;Planning;Engineering students;Generative AI (Gen AI);maker movement;service learning;transformative learning;engineering education.},
  doi={10.1109/EDUNINE62377.2025.10981337},
  ISSN={},
  month={March},}@INPROCEEDINGS{11129301,
  author={Gumulya, Devanny},
  booktitle={2025 10th International STEM Education Conference (iSTEM-Ed)}, 
  title={Generative Artifical Inteligence (GAI) Assisted Product Design Process}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Generative Artificial Intelligence (GAI) has emerged as a powerful tool in various creative fields, including product design. This study investigates how GAI can enhance the product design process, especially in the development stage of the design thinking process, by boosting creativity, efficiency, and ideation. The study is project-based learning on product design 1 subject, in which 12 groups of students work in pairs to create new shoe designs using GAI. The students were guided through design thinking approaches and used GAI during the development stage, which required them to sketch and improve their sketches before submitting them to GAI. Surveys, feedback forms, and project assessments were utilized to determine the effect of GAI on creativity and design outputs. The findings show that GAI substantially raised students’ creative output, allowing for more diverse idea exploration and improved efficiency in developing design concepts. To help the GAI generate useable designs, the study identified specific prompts that can improve design outcomes: product category, descriptive phrases for shoe shape, material type, color, and features. In addition, hyper-realistic, hyper-detailed, UHD, and 8 K prompts were found effective to ensure that the designs were realistic and detailed. While GAI aided in the quick generation of novel concepts, several of the designs produced were deemed impractical or impossible to manufacture. Hence, Students’ design knowledge in manufacturing and material played a critical role in evaluating the feasibility of GAI-generated concepts. But overall, the integration of GAI in the product design process provides new perspectives, allowing designers to overcome creative blocks and generate ideas more rapidly. This research supports the integration of GAI into the design thinking process, particularly in the development stage. By understanding both the capabilities and limitations of GAI, product designers can enhance their creative and innovative potential, contributing to a more innovative and forwardthinking design industry.},
  keywords={Surveys;Shape;Generative AI;Footwear;Color;Product design;Manufacturing;Stakeholders;Creativity;Testing;Product Design Process;Design Thinking;Generative Artifical Intelligence;Project Based Learning;Design Development},
  doi={10.1109/iSTEM-Ed65612.2025.11129301},
  ISSN={},
  month={July},}@INPROCEEDINGS{9198575,
  author={Örs, Evrim and Schmidt, Robin and Mighani, Moein and Shalaby, Marwan},
  booktitle={2020 IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC)}, 
  title={A Conceptual Framework for AI-based Operational Digital Twin in Chemical Process Engineering}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={As digitalization is becoming more and more an integral part of business in all sectors, the digital twin paradigm starts to play a more crucial role. This paper primarily aims at describing a generic framework for digital twin development in chemical process industry from an operational perspective. The main building blocks of the operational digital twin are presented, namely data management, process modeling, process optimization, production scheduling, and process control, as well as the deployment. Strong emphasis is put on the advanced process control hierarchy. Additionally, the role of artificial intelligence in the development and deployment of operational digital twin in process industry is presented, particularly regarding surrogate modeling, predictive modeling and AI supported optimization and control. Consequently the potential for new business models induced by digitalization is discussed, and an outlook for prospective research topics is provided.},
  keywords={Industries;Process control;Artificial intelligence;Optimization;Modeling;Production;Chemical processes;Digital twin;process industry;artificial intelligence;advanced process control;predictive modeling},
  doi={10.1109/ICE/ITMC49519.2020.9198575},
  ISSN={},
  month={June},}@INPROCEEDINGS{9733699,
  author={Häring, Ivo and Lüttner, Florian and Frorath, Andreas and Fehling-Kaschek, Miriam and Ross, Katharina and Schamm, Thomas and Knoop, Steffen and Schmidt, Daniel and Schmidt, Andreas and Ji, Yang and Yang, Zhengxiong and Rupalla, Armin and Hantschel, Frank and Frey, Michael and Wiechowski, Norbert and Schyr, Christian and Grimm, Daniel and Zofka, Marc René and Viehl, Alexander},
  booktitle={2021 IEEE 17th International Conference on Intelligent Computer Communication and Processing (ICCP)}, 
  title={Framework for safety assessment of autonomous driving functions up to SAE level 5 by self-learning iteratively improving control loops between development, safety and field life cycle phases}, 
  year={2021},
  volume={},
  number={},
  pages={33-40},
  abstract={Safety verification and validation of autonomous driving functions up to SAE level 5 pose enormous challenges for car manufacturers. The paper argues that efficient improvement opportunities arise by suitably combining iterative development and verification processes that use self-learning approaches and well-defined quality and convergence criteria within a conceptual framework. The following cycles are used: development cycle, safety life cycle and field life cycle. For these cycles, suitable phases are first identified and defined. Then linkages are given that enable criteria-based iterative execution and improvement of selected combined phases. For this purpose, the selected phases are further resolved. It is distinguished between local loops within one cycle and loops between several cycles as well as with respect to the time horizon they cover. Suitable sample machine learning (ML) and artificial intelligence (AI) methods for the improvement loops are proposed in order to improve safety assessment of autonomous driving (AD) functions. The article presents three different types of ML/AI approaches regarding their usage within the development process of AD functions as well as identifies further improvement potentials. The approach is illustrated by ML/AI approach examples for the efficient provision of relevant and critical scenarios for the training and assessment of AD functions.},
  keywords={Training;Couplings;Conferences;Process control;Machine learning;Learning (artificial intelligence);Safety;Verification and validation of autonomous driving;iterative self-learning improvement loop;machine learning and artificial intelligence;selection of training data;development;safety and life cycle},
  doi={10.1109/ICCP53602.2021.9733699},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10605559,
  author={Nabian, Mohsen and Eftekhari, Zahra and Wong, Chi Wah},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={CI-VAE: a Generative Deep Learning Model for Class-Specific Data Interpolation}, 
  year={2024},
  volume={},
  number={},
  pages={313-319},
  abstract={We propose a new variant of Variational Autoencoder (VAE), Class-Informed VAE (CI-VAE), that enables interpolation between arbitrary pairs of observations of the same class. CI-VAE combines the general VAE architecture with a linear discriminator layer on the latent space to enforce the construction of a latent space where observations from different classes are linearly separable. This allows for robust latent-space linear traversal and data generation between two arbitrary observations of the same class, which has potential applications in science and engineering. One specific application is to enhance understanding of the biological processes involving the development of diseases or cancer from healthy cells. We demonstrate the effectiveness of CI-VAE on the MNIST dataset of handwritten digits, showing that it significantly improves class-specific linear traversal and data augmentation compared to VAE while maintaining comparable reconstruction error. We also apply CI-VAE to a study of colon cancer single-cell genomics data, showing that interpolation between normal cells and tumor cells using CI-VAE may enhance our understanding of the mechanism of cancer development.},
  keywords={Interpolation;Neural networks;Genomics;Semisupervised learning;Data augmentation;Probabilistic logic;Data models;Deep Learning;Generative Models;Class-Specific Interpolation},
  doi={10.1109/CAI59869.2024.00067},
  ISSN={},
  month={June},}@INPROCEEDINGS{10375461,
  author={Salameh, Haythem Bany and Mohawesh, Rami and Maqsood, Sumbal and Jararweh, Yaser and Alshuqayran, Nuha},
  booktitle={2023 Tenth International Conference on Social Networks Analysis, Management and Security (SNAMS)}, 
  title={Generative Adversarial Network (GAN) in Social Network: Introduction, Applications, Challenges and Future Directions}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={Generative adversarial networks are now a hot topic in the field of artificial intelligence. GANs take their cue by including a generator and a discriminator learned using the adversarial learning concept. Specifically, GANs seek to anticipate the distribution of the information samples from the real world and then generate a new response based on this prediction. Since their inception, GANs have been the subject of extensive research in different fields of social networks, such as image, vision, speech processing, and language processing. This survey paper summarises GAN-based models' theoretic concept, applications, advantages, and disadvantages with development trends and potential future directions. We elaborate on the topic by discussing the applications of GAN and the challenges that must be addressed. In particular, we discuss speech and language processing, image processing, face detection, texture-transferring, and communication-based GAN applications. We conclude our findings with a discussion of potential future directions.},
  keywords={Deep learning;Surveys;Social networking (online);Image processing;Reinforcement learning;Generative adversarial networks;Market research;GAN;Deep Learning;GAN Applications;Social Networks},
  doi={10.1109/SNAMS60348.2023.10375461},
  ISSN={2831-7343},
  month={Nov},}@INPROCEEDINGS{11030130,
  author={Csanky, Bálint Antal and Laczi, Szandra Anna and Póser, Valéria},
  booktitle={2025 IEEE 19th International Symposium on Applied Computational Intelligence and Informatics (SACI)}, 
  title={AI-Manipulated Reality: Generation and Detection of Deepfake Content}, 
  year={2025},
  volume={},
  number={},
  pages={571-576},
  abstract={The development of artificial intelligence (AI) has fundamentally reshaped various applications in computer vision and deep learning. Alongside these benefits, however, it has also introduced significant challenges, particularly with the emergence of deepfake technology. Deepfakes leverage neural networks to manipulate audio and visual content, producing hyper-realistic yet fake images and videos that pose threats in areas such as manipulation, extortion, and disinformation. This review provides an overview of the fundamental methods behind deepfake creation, including autoencoders, generative adversarial networks (GANs), and audio manipulations. It also addresses the technology's harmful uses and the related societal challenges. Furthermore, it offers a detailed discussion of potential defense strategies against deepfake content, such as traditional visual and physiological analyses, as well as deep learning-based detection methods that rely on identifying temporal inconsistencies, visual anomalies, and characteristic patterns of generative networks. The analysis aims to highlight the dangers of deepfake technology and the necessity for developing reliable detection tools, thereby contributing to the reduction of manipulated content proliferation.},
  keywords={Deep learning;Deepfakes;Visualization;Accuracy;Reviews;Semisupervised learning;Reliability theory;Generative adversarial networks;Physiology;Artificial intelligence;Deepfake;Face and voice manipulation;GAN;Deepfake content detection},
  doi={10.1109/SACI66288.2025.11030130},
  ISSN={2765-818X},
  month={May},}@INBOOK{11104976,
  author={Nag, Anindya and Hassan, Md. Mehedi and Karim, Asif and Kumar Reddy C, Kishor},
  booktitle={Generative AI in Neurodegenerative Disorders: Innovations, Views, and Obstacles}, 
  title={6 Exploring the Promises and Perils of Implementing Generative AI into Mental Healthcare and Emotional Well-being Support of General Public: A Comprehensive Overview}, 
  year={2025},
  volume={},
  number={},
  pages={147-164},
  abstract={This book delves into the transformative power of AI in the realm of neurodegenerative diseases, covering topics such as ALS, Huntington's, Parkinson's, and Alzheimer's. Generative AI provides new opportunities for early diagnosis, precise therapy, and individualized rehabilitation, which are crucial as these conditions remain major obstacles for healthcare providers and researchers. Researchers, physicians, AI developers, and healthcare professionals will find this book an invaluable resource for understanding how AI is influencing the development of treatments for neurodegenerative diseases. It describes important obstacles and future directions while providing insights into the newest breakthroughs, thus bridging the gap between technology and practical clinical applications. Anyone involved in neurodegenerative healthcare, from scientists conducting AI-driven medical research to physicians seeking to incorporate AI into patient care or AI professionals investigating new healthcare applications, will find the information and insights they need in this comprehensive book. Predictive analytics, biomarker identification, and drug discovery are being transformed by AI-driven models, such as deep neural networks, generative adversarial networks (GANs), and variational autoencoders (VAEs). This book offers a comprehensive examination of these developments. Robots, wearable sensors, and cognitive therapy platforms are some of the AI-enhanced rehabilitation tools covered, as are AI-integrated cutting-edge technologies like fMRI and MRI, gene-editing methods like CRISPR, and more. In addition to discussing recent technical developments, this book takes a close look at the data privacy, ethics, and regulatory issues that arise when using AI to study neurodegenerative disorders. Issues like algorithmic bias, model explainability, and fair AI-driven healthcare are thoroughly investigated in light of the growing usage of AI models in clinical decision-making, mental health applications, and cognitive rehabilitation.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788743801740},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11104976},}@INPROCEEDINGS{10893895,
  author={Kaur, Jashanpreet and Singh, Gurpreet},
  booktitle={2025 International Conference on Multi-Agent Systems for Collaborative Intelligence (ICMSCI)}, 
  title={AI Meets Astronomy: EfficientB0- Powered Classification of AI-Synthesized Celestial Objects Using SpaceNet}, 
  year={2025},
  volume={},
  number={},
  pages={870-875},
  abstract={The problem with astronomical images classification generated by artificial intelligence is that the data comes from synthetic sources. The paper developed the first large dataset named SpaceNet with 4,099 AI-generated images of five different classes of astronomy, namely: Asteroid, Black Hole, Comet, Con-stellation, and Nebula. This dataset has been used in testing the performance of a deep learning (DL) model optimized for image classification called EfficientBO. By numerous experiments, it has been demonstrated that the model provides 96.44%. The authors also reported such key performance metrics like precision, recall, Fl-score, where most of the classes received near-perfect scores. Therefore, Fl-scores equal to 1.00 are observed in the case of the Asteroid, Black Hole, and Nebula classes, thereby showing good efficiency of the model when it comes to AI -generated image classification. The model appears to be quite general with minimal overfitting on synthetic data, though the results may differ for the real scenes. Future work will aim at increasing the dataset through more diverse synthetic images and possibly add more architecture in DL to add to the classification performance.},
  keywords={Deep learning;Comets;Accuracy;Data models;Solar system;Artificial intelligence;Image classification;Synthetic data;Overfitting;Testing;SpaceNet;Artificial Intelligence (AI)-generated images;EfficientBO;astronomical image classification;DL},
  doi={10.1109/ICMSCI62561.2025.10893895},
  ISSN={},
  month={Jan},}@ARTICLE{9763075,
  author={Li, Wei and Chen, Jinlin and Wang, Zhenyu and Shen, Zhidong and Ma, Chao and Cui, Xiaohui},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={IFL-GAN: Improved Federated Learning Generative Adversarial Network With Maximum Mean Discrepancy Model Aggregation}, 
  year={2023},
  volume={34},
  number={12},
  pages={10502-10515},
  abstract={The generative adversarial network (GAN) is usually built from the centralized, independent identically distributed (i.i.d.) training data to generate realistic-like instances. In real-world applications, however, the data may be distributed over multiple clients and hard to be gathered due to bandwidth, departmental coordination, or storage concerns. Although existing works, such as federated learning GAN (FL-GAN), adopt different distributed strategies to train GAN models, there are still limitations when data are distributed in a non-i.i.d. manner. These studies suffer from convergence difficulty, producing generated data with low quality. Fortunately, we found that these challenges are often due to the use of a federated averaging strategy to aggregate local GAN models’ updates. In this article, we propose an alternative approach to tackling this problem, which learns a globally shared GAN model by aggregating locally trained generators’ updates with maximum mean discrepancy (MMD). In this way, we term our approach improved FL-GAN (IFL-GAN). The MMD score helps each local GAN hold different weights, making the global GAN in IFL-GAN getting converged more rapidly than federated averaging. Extensive experiments on MNIST, CIFAR10, and SVHN datasets demonstrate the significant improvement of our IFL-GAN in both achieving the highest inception score and producing high-quality instances.},
  keywords={Generative adversarial networks;Collaborative work;Data models;Training;Computational modeling;Distributed databases;Training data;Federated learning;Federated learning;generative adversarial network (GAN);maximum mean discrepancy (MMD);non-independent identically distributed (i.i.d.) training data},
  doi={10.1109/TNNLS.2022.3167482},
  ISSN={2162-2388},
  month={Dec},}@ARTICLE{9627629,
  author={Das, Asha and Devarampati, Vinod Kumar and Nair, Madhu S.},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={NAS-SGAN: A Semi-Supervised Generative Adversarial Network Model for Atypia Scoring of Breast Cancer Histopathological Images}, 
  year={2022},
  volume={26},
  number={5},
  pages={2276-2287},
  abstract={Nuclear atypia scoring (NAS), forms a significant factor in determining individualized treatment plans and also for the prognosis of the disease. Automation of cancer grading using quantitative image-based analysis of histopathological images can circumvent the shortcomings of the prevailing manual grading and can assist the pathologists in cancer diagnosis. However, developing such a robust classifier model require sufficient amount of annotated data, while the labeled histopathological images are scarce and expensive to procure as annotation forms a time-consuming and laborious task. Hence, a semi-supervised learning framework combined with the deep neural network based generative adversarial training, that can improve the performance of the classification model with limited annotated data, is proposed in this paper. The proposed NAS-SGAN model consists of discriminator and generator models that are trained in an adversarial manner using both labeled and unlabeled samples. The discriminator model is designed as an unsupervised model stacked over the supervised model sharing the model parameters and learns the data distribution by extracting the discriminative features. The generator model is trained over a stable feature matching objective function following a composite GAN architecture, and its for the first time the semi-supervised GAN model is explored for the grading of breast cancer. Experimental analysis shows that the proposed model could better discriminate different cancer grades thereby improving the robustness and accuracy of the system, even with limited amount of labeled samples.},
  keywords={Data models;Generative adversarial networks;Training;Deep learning;Breast cancer;Semisupervised learning;Feature extraction;Breast cancer;generative adversarial network;histopathology;nuclear atypia scoring;semi-supervised learning},
  doi={10.1109/JBHI.2021.3131103},
  ISSN={2168-2208},
  month={May},}@INPROCEEDINGS{10649965,
  author={Singh, Gaurav and Bali, Kavitesh Kumar},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Enhancing Decision-Making in Optimization through LLM-Assisted Inference: A Neural Networks Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={This paper explores the seamless integration of Generative AI (GenAI) and Evolutionary Algorithms (EAs) within the domain of large-scale multi-objective optimization. Focusing on the transformative role of Large Language Models (LLMs), our study investigates the potential of LLM-Assisted Inference to automate and enhance decision-making processes. Specifically, we highlight its effectiveness in illuminating key decision variables in evolutionarily optimized solutions while articulating contextual trade-offs. Tailored to address the challenges inherent in inferring complex multi-objective optimization solutions at scale, our approach emphasizes the adaptive nature of LLMs, allowing them to provide nuanced explanations and align their language with diverse stakeholder expertise levels and domain preferences. Empirical studies underscore the practical applicability and impact of LLM-Assisted Inference in real-world decision-making scenarios.},
  keywords={Symbiosis;Generative AI;Large language models;Decision making;Neural networks;Inference algorithms;Planning;Generative Artificial Intelligence;large language models;evolutionary algorithms;multi-objective optimization;LLM-Assisted inference;automated decision making;nuanced explanations},
  doi={10.1109/IJCNN60899.2024.10649965},
  ISSN={2161-4407},
  month={June},}@INPROCEEDINGS{10338904,
  author={Rawlins, Charles and Jagannathan, S. and Wunsch, Donald},
  booktitle={2023 Fifth International Conference on Blockchain Computing and Applications (BCCA)}, 
  title={Prediction of Blockchain Transaction Fraud Using a Lightweight Generative Adversarial Network}, 
  year={2023},
  volume={},
  number={},
  pages={116-121},
  abstract={Classic blockchain protocol design is centered around a computationally-intense cryptographic scheme, such as Bitcoin's Proof-of-Work (PoW). Network scalability and efficiency are stifled with the computational resources necessary to approve new transactions, thus rendering PoW unsuitable with limited devices like Internet of Things (IoT). As a first step towards alleviating this, a novel lightweight Generative Adversarial Network (GAN) called Vector GAN (VecGAN) is introduced wherein its weights are tuned through a direct error-driven learning approach with a Bayesian estimator for the selection of random noise matrices, called Bayesian Feedback Alignment (BFA), to augment data for improved fraud prediction. The augmented data is subsequently processed by a classifier for prediction. This combination of VecGAN with a classifier is treated as a novel method of blockchain ledger decision-making to approve ground-truth data. By using the two-step process, prediction accuracy using a classifier was improved up to 8% for real-world datasets. Resource consumption comparison to existing IoT blockchain protocols in a realistic simulation environment is also provided, where lightweight approaches for VecGAN in training and noise modeling reduce computation compared to other techniques.},
  keywords={Training;Scalability;Generative adversarial networks;Rendering (computer graphics);Proof of Work;Blockchains;Fraud;Blockchain and Machine Learning/Artificial Intelligence;Blockchain for Internet of Things;Transaction Monitoring and Analysis},
  doi={10.1109/BCCA58897.2023.10338904},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11131016,
  author={Chuang, Cheng-Hung and Chen, Yu-Jie and Chen, Hung-Yu and Yu, Qi-Rui and Lian, Zhen-You},
  booktitle={2025 Seventh International Symposium on Computer, Consumer and Control (IS3C)}, 
  title={Generation of Multi-Vertebrae Using 3D Deep Learning Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={In the field of medical image processing, the application of 3D deep learning technology has received increasing attention. This study explores a composite 3D deep learning architecture for generating images of single vertebrae and multiple vertebrae. First, we build on Generative Adversarial Nets (GAN) and expand it into a 3D GAN architecture. By training the generator and discriminator, we use it to generate 3D images of a single vertebra. However, 3D single-vertebrae limits practical usability. We hope to further explore another challenge in vertebrae image generation, namely generating 3D images of multiple vertebrae. The biggest problem with multiple vertebrae is the continuity between vertebrae. To this end, we created a composite architecture called 3D U-Net+GAN, which combines the advantages of U-Net and GAN. This architecture can not only generate high-quality multi-vertebral images, but also maintain the continuity and consistency of the images. We use two publicly available datasets, xVertSeg.v1 and VerSe2020, to conduct experiments to demonstrate the superiority of the 3D U-Net + GAN architecture in generating multi-vertebral images. The two 3D deep learning architectures proposed in this study provide effective solutions for single-segment and multi-segment vertebral image generation, which are of great significance for improving medical image processing technology.},
  keywords={Deep learning;Solid modeling;Three-dimensional displays;Image synthesis;Computational modeling;Computer architecture;Feature extraction;Thorax;Hardware;Biomedical imaging;medical imaging;3D deep learning;3D U-Net;Generative Adversarial Networks},
  doi={10.1109/IS3C65361.2025.11131016},
  ISSN={2770-0496},
  month={June},}@INPROCEEDINGS{1640937,
  author={Sy Bor Wang and Quattoni, A. and Morency, L.-P. and Demirdjian, D. and Darrell, T.},
  booktitle={2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)}, 
  title={Hidden Conditional Random Fields for Gesture Recognition}, 
  year={2006},
  volume={2},
  number={},
  pages={1521-1527},
  abstract={We introduce a discriminative hidden-state approach for the recognition of human gestures. Gesture sequences often have a complex underlying structure, and models that can incorporate hidden structures have proven to be advantageous for recognition tasks. Most existing approaches to gesture recognition with hidden states employ a Hidden Markov Model or suitable variant (e.g., a factored or coupled state model) to model gesture streams; a significant limitation of these models is the requirement of conditional independence of observations. In addition, hidden states in a generative model are selected to maximize the likelihood of generating all the examples of a given gesture class, which is not necessarily optimal for discriminating the gesture class against other gestures. Previous discriminative approaches to gesture sequence recognition have shown promising results, but have not incorporated hidden states nor addressed the problem of predicting the label of an entire sequence. In this paper, we derive a discriminative sequence model with a hidden state structure, and demonstrate its utility both in a detection and in a multi-way classification formulation. We evaluate our method on the task of recognizing human arm and head gestures, and compare the performance of our method to both generative hidden state and discriminative fully-observable models.},
  keywords={Hidden Markov models;Pattern recognition;Humans;Computer vision;State estimation;Computer science;Artificial intelligence;Laboratories;Application software;Power generation},
  doi={10.1109/CVPR.2006.132},
  ISSN={1063-6919},
  month={June},}@ARTICLE{11015756,
  author={Ma, Hao and Chen, Rujin and Zhang, Xiao-Lei and Liu, Ju and Li, Xuelong},
  journal={IEEE Signal Processing Letters}, 
  title={Enhancing Intelligibility for Generative Target Speech Extraction via Joint Optimization With Target Speaker ASR}, 
  year={2025},
  volume={32},
  number={},
  pages={2309-2313},
  abstract={Target speech extraction (TSE) isolates the speech of a specific speaker from a multi-talker overlapped speech mixture. Most existing TSE models rely on discriminative methods, typically predicting a time-frequency spectrogram mask for the target speech. However, imperfections in these masks often result in over-/under-suppression of target/non-target speech, degrading perceptual quality. Generative methods, by contrast, re-synthesize target speech based on the mixture and target speaker cues, achieving superior perceptual quality. Nevertheless, these methods often overlook speech intelligibility, leading to alterations or loss of semantic content in the re-synthesized speech. Inspired by the Whisper model’s success in target speaker ASR, we propose a generative TSE framework based on the pre-trained Whisper model to address the above issues. This framework integrates semantic modeling with flow-based acoustic modeling to achieve both high intelligibility and perceptual quality. Results from multiple benchmarks demonstrate that the proposed method outperforms existing generative and discriminative baselines.},
  keywords={Speech enhancement;Training;Decoding;Spectrogram;Measurement;Semantics;Predictive models;Computational modeling;Vectors;Signal to noise ratio;Generative target speech extraction;target speaker extraction (TSE);Whisper;optimal transport conditional flow matching;multi-task joint learning},
  doi={10.1109/LSP.2025.3573951},
  ISSN={1558-2361},
  month={},}@INPROCEEDINGS{9288323,
  author={Chen, Donglin and Gao, Xiang and Xu, Chuanfu and Chen, Shizhao and Fang, Jianbin and Wang, Zhenghua and Wang, Zheng},
  booktitle={2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={FlowGAN: A Conditional Generative Adversarial Network for Flow Prediction in Various Conditions}, 
  year={2020},
  volume={},
  number={},
  pages={315-322},
  abstract={Many flow-related design optimization problems like aircraft and automobile aerodynamic design are solved via computational fluid dynamics (CFD) simulations. However, CFD simulations are known to be resource-demanding and time-consuming. Deep learning (DL) is emerging as a viable means to accelerate CFD simulations by directly predicting the outcomes of multiple simulation iterations. While promising, existing DL-based models have to be re-trained whenever the flow condition changes, which incurs significant training overhead for real-life scenarios with a wide range of flow conditions. This paper presents FLOWGAN, a novel conditional generative adversarial network for accurate prediction of flow fields in various conditions. FlowGAN is designed to directly obtain the generation of solutions to flow fields in various conditions based on observations rather than re-training. As FlowGAN does not rely on knowledge of the underlying governing equations, it can quickly adapt to various flow conditions and avoid the need for expensive re-training. We evaluate FlowGAN by applying it to scenarios of simulating both the whole flow field and selected regions of interest (RoI). Compared to the state-of-the-art DL based methods, FlowGAN significantly reduces the prediction errors by 2.27% while exhibiting a better generalization ability.},
  keywords={Training;Computational modeling;Atmospheric modeling;Computational fluid dynamics;Predictive models;Tools;Generative adversarial networks;Flow fields prediction;Multi-source data processing;GAN;Predictive performance},
  doi={10.1109/ICTAI50040.2020.00057},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{9462062,
  author={Thambawita, Vajira and Hicks, Steven A. and Isaksen, Jonas and Stensen, Mette Haug and Haugen, Trine B. and Kanters, JØrgen and Parasa, Sravanthi and de Lange, Thomas and Johansen, Håvard D. and Johansen, Dag and Hammer, Hugo L. and Halvorsen, Pål and Riegler, Michael A.},
  booktitle={2021 International Conference on Applied Artificial Intelligence (ICAPAI)}, 
  title={DeepSynthBody: the beginning of the end for data deficiency in medicine}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={Limited access to medical data is a barrier on developing new and efficient machine learning solutions in medicine such as computer-aided diagnosis, risk assessments, predicting optimal treatments and home-based personal healthcare systems. This paper presents DeepSynthBody: a novel framework that overcomes some of the inherent restrictions and limitations of medical data by using deep generative adversarial networks to produce synthetic data with characteristics similar to the real data, so-called DeepSynth (deep synthetic) data. We show that DeepSynthBody can address two key issues commonly associated with medical data, namely privacy concerns (as a result of data protection rules and regulations) and the high costs of annotations. To demonstrate the full pipeline of applying DeepSynthBody concepts and user-friendly functionalities, we also describe a synthetic medical dataset generated and published using our framework. DeepSynthBody opens a new era of machine learning applications in medicine with a synthetic model of the human body.},
  keywords={Biological system modeling;Pipelines;Data protection;Machine learning;Medical services;Generative adversarial networks;Regulation;DeepSynthBody;synthetic medical data;deep synthetic human body;synthetic data;GAN;DeepSynth augmentation;privacy issue;medical data privacy;multi-model DeepSynth;DeepSynth explainable AI;explainable DeepSynth},
  doi={10.1109/ICAPAI49758.2021.9462062},
  ISSN={},
  month={May},}@INPROCEEDINGS{9178896,
  author={Wu, Junbin and Li, Mengru and Chen, Zhe and Chen, Wenjun and Wu, Xuanquan and Xi, Ying},
  booktitle={2020 11th International Conference on Mechanical and Aerospace Engineering (ICMAE)}, 
  title={Generative Design of the Roller Seat of the Wind Turbine Blade Turnover Machine Based on Cloud Computing}, 
  year={2020},
  volume={},
  number={},
  pages={212-217},
  abstract={Generative design is a design exploration technology based on an artificial intelligence algorithm. By constraining the manufacturing process and product performance requirements, generative design can generate a variety of feasible models in cloud computing. In this paper, according to the load condition of the roller seat of the wind turbine blade turnover machine, several models that meet the design requirements are generated by using the generative design. After analyzing and comparing several models, the best model is obtained. Next, the structural strength and stiffness of the new model are simulated and analyzed. Compared with the parameters of the original model, the stress distribution of the new model generated by the generative design is uniform, the maximum displacement is reduced from 0.138mm to 0.126mm, and the mass is only 44.4% of the original model.},
  keywords={Blades;Mathematical model;Stress;Wind turbines;Computational modeling;Analytical models;Cloud computing;generative design;wind turbine blade;turnover machine;roller seat;cloud computing},
  doi={10.1109/ICMAE50897.2020.9178896},
  ISSN={},
  month={July},}@ARTICLE{10305193,
  author={Yan, Han and Zhang, Haijun and Shi, Jianyang and Ma, Jianghong},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={Mixing and Matching Elements for Intelligent Fashion Design: A Generative Adversarial Network With Structure and Texture Disentanglement}, 
  year={2024},
  volume={70},
  number={1},
  pages={358-370},
  abstract={Mixing and matching design elements from different fashion items to automatically create new textures or structures is desirable for fashion designers in order to facilitate the repetitive drawing process, and this mixing and matching process may also inspire them. In this research, we propose a structure and texture disentanglement generative adversarial network (STD-GAN) to create automated mix-and-match designs. Our model is trained to disentangle fashion items into different style elements and to integrate these elements to create a new design in an unsupervised manner. More specifically, a fashion attribute encoder is developed to disentangle the features of fashion items into two representations based on structure and texture. A texture mapping network is then applied to encode the texture representation in the form of different spatial features. A fashion fusion decoder is also developed that can generate mixed-style fashion items by utilizing the structure representation and the different texture features. In addition, a multi-discriminator framework is proposed to determine the authenticity and texture similarity of the reconstructed and mixed fashion items. Extensive experimental results demonstrate the effectiveness of our STD-GAN and its potential to facilitate the fashion design process by creating different textures and structures in a mix-and-match manner.},
  keywords={Semantics;Codes;Generative adversarial networks;Training;Representation learning;Feature extraction;Artificial intelligence;Intelligent design;fashion intelligence;generative adversarial network;disentanglement},
  doi={10.1109/TCE.2023.3329574},
  ISSN={1558-4127},
  month={Feb},}@INPROCEEDINGS{10607286,
  author={Chen, Chiung-Hui},
  booktitle={2024 9th International Conference on Big Data Analytics (ICBDA)}, 
  title={Web3.0 Generative Art- A Co-Creation System in Environmental Sustainability Concept Form}, 
  year={2024},
  volume={},
  number={},
  pages={264-269},
  abstract={In 2021, the first year of Metaverse, Web3.0 ecosystems emerged as a result of the Internet's de-centralized evolution. In the Web3.0 space, there has been a very active advancement of the generative art non-fungible token, which is a special asset stored on a blockchain that allows creators to buy and sell assets and verify ownership. In other words, as it reconstructs the interpersonal relationship, the generative art non-fungible token must carry cultural values to be meaningful, and waiting to observe artificial intelligence generative art in the future requires a new mindset and posture. Design thinking is a design-based approach to solve today's complex problems. This study thus addresses the new Web3.0 ecosystem and introduces environmental sustain ability issues and computational thinking in the form of generative art to discuss the possibilities of future design thinking. By linking with social information, this study also creates an intersection with heterogeneous knowledge and stimulates a new thinking pattern that is different from previous ones. This project of design and research in the Metaverse virtual environment is still a novel topic. Reviewing past literature indicates that relevant papers are very scarce, and more resources are urgently needed for research in this field.},
  keywords={Art;Metaverse;Ecosystems;Green products;Big Data;Internet;Nonfungible tokens;blockchain;Web3.0;generative art;collaboration;sustainability},
  doi={10.1109/ICBDA61153.2024.10607286},
  ISSN={},
  month={March},}@INPROCEEDINGS{11034830,
  author={Shukla, Vinit Kumar and Merikapudi, Seshaiah},
  booktitle={2025 International Conference on Knowledge Engineering and Communication Systems (ICKECS)}, 
  title={Adaptive Learning Revolution with AI-Driven Personalization and Gamified Real-Time Interaction}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={As cutting-edge technologies like artificial intelligence, machine learning, cloud computing, OpenAI, LLM, generative AI, augmented reality (AR), virtual reality (VR), mixed reality (MR), extended reality (XR), and big data become more prevalent, it is helpful from an educational point of view to analyze the AI-enabled Adaptive Learning Platform with Gamified Personalized System and Real-Time Recommendations. This will allow learners to take full advantage of these new technologies. The literature review and their research on the Adaptive Learning Model are conducted from this point of view. This study assesses the potential of cutting-edge technologies for adaptive learning platforms, addressing the proliferation of personalized with recommendations & gamified educational approaches. Since 2012, numerous studies have been conducted to this extent. Also, the perspective of current going on studies is crucial to provide advanced and accurate solutions in the realm of education which can transform the complete educational & research field. This paper synthesizes the guide for future research and studies on how to better platforms design AI-Based Adaptive Learning Platform with Dynamic Content Delivery, Real-Time Feedback, Student Engagement, Competency-Based Education, Supervised Association Rules, Dynamic System Models, Open Educational Resources (OERs), Reinforcement Learning, Advanced Analytics & Visualization, Scalability, Low Latency. These advancements highlight the potential for AI and machine learning to strengthen personalized learning & gamification, improve student engagement and optimize educational results.},
  keywords={Adaptive learning;Adaptation models;Solid modeling;Generative AI;Scalability;Reinforcement learning;Transforms;Open Educational Resources;Real-time systems;Systematic literature review;Adaptive Learning;Gamification;Personalized Learning;Real-Time Feedback;Reinforcement Learning},
  doi={10.1109/ICKECS65700.2025.11034830},
  ISSN={},
  month={April},}@ARTICLE{10254204,
  author={Rani, Gundala Jhansi and Hashmi, Mohammad Farukh and Gupta, Aditya},
  journal={IEEE Access}, 
  title={Surface Electromyography and Artificial Intelligence for Human Activity Recognition—A Systematic Review on Methods, Emerging Trends Applications, Challenges, and Future Implementation}, 
  year={2023},
  volume={11},
  number={},
  pages={105140-105169},
  abstract={Human activity recognition (HAR) has become increasingly popular in recent years due to its potential to meet the growing needs of various industries. Electromyography (EMG) is essential in various clinical and biological settings. It is a metric that helps doctors diagnose conditions that affect muscle activation patterns and monitor patients’ progress in rehabilitation, disease diagnosis, motion intention recognition, etc. This review summarizes the various research papers based on HAR with EMG. Over recent years, the integration of Artificial Intelligence (AI) has catalyzed remarkable advancements in the classification of biomedical signals, with a particular focus on EMG data. Firstly, this review meticulously curates a wide array of research papers that have contributed significantly to the evolution of EMG-based activity recognition. By surveying the existing literature, we provide an insightful overview of the key findings and innovations that have propelled this field forward. It explore the various approaches utilized for preprocessing EMG signals, including noise reduction, baseline correction, filtering, and normalization, ensure that the EMG data is suitably prepared for subsequent analysis. In addition, we unravel the multitude of techniques employed to extract meaningful features from raw EMG data, encompassing both time-domain and frequency-domain features. These techniques are fundamental to achieving a comprehensive characterization of muscle activity patterns. Furthermore, we provide an extensive overview of both Machine Learning (ML) and Deep Learning (DL) classification methods, showcasing their respective strengths, limitations, and real-world applications in recognizing diverse human activities from EMG signals. In examining the hardware infrastructure for HAR with EMG, the synergy between hardware and software is underscored as paramount for enabling real-time monitoring. Finally, we also discovered open issues and future research direction that may point to new lines of inquiry for ongoing research toward EMG-based detection.},
  keywords={Human activity recognition;Electromyography;Artificial intelligence;Feature extraction;Wearable sensors;Surveys;Behavioral sciences;Machine learning;Real-time systems;Machine learning (ML);human activity recognition (HAR);deep learning (DL);electromyography (EMG);real-time systems;artificial intelligence (AI)},
  doi={10.1109/ACCESS.2023.3316509},
  ISSN={2169-3536},
  month={},}@ARTICLE{9521554,
  author={Fu, Yabo and Zhang, Hao and Morris, Eric D. and Glide-Hurst, Carri K. and Pai, Suraj and Traverso, Alberto and Wee, Leonard and Hadzic, Ibrahim and Lønne, Per-Ivar and Shen, Chenyang and Liu, Tian and Yang, Xiaofeng},
  journal={IEEE Transactions on Radiation and Plasma Medical Sciences}, 
  title={Artificial Intelligence in Radiation Therapy}, 
  year={2022},
  volume={6},
  number={2},
  pages={158-181},
  abstract={Artificial intelligence (AI) has great potential to transform the clinical workflow of radiotherapy. Since the introduction of deep neural networks (DNNs), many AI-based methods have been proposed to address challenges in different aspects of radiotherapy. Commercial vendors have started to release AI-based tools that can be readily integrated to the established clinical workflow. To show the recent progress in AI-aided radiotherapy, we have reviewed AI-based studies in five major aspects of radiotherapy, including image reconstruction, image registration, image segmentation, image synthesis, and automatic treatment planning. In each section, we summarized and categorized the recently published methods, followed by a discussion of the challenges, concerns, and future development. Given the rapid development of AI-aided radiotherapy, the efficiency and effectiveness of radiotherapy in the future could be substantially improved through intelligent automation of various aspects of radiotherapy.},
  keywords={Image reconstruction;Computed tomography;Artificial intelligence;Tumors;Planning;Magnetic resonance imaging;Imaging;Artificial intelligence (AI);image reconstruction;image registration;image segmentation;image synthesis;radiotherapy;treatment planning},
  doi={10.1109/TRPMS.2021.3107454},
  ISSN={2469-7303},
  month={Feb},}@INPROCEEDINGS{10370540,
  author={Balakrishnan, D. and Mariappan, Umasree and Narasimharao, Chunduri Mohan and Krishna, Darvemula Sreeram and Kamalesh, Damarouthu and Balaji, Chavidi},
  booktitle={2023 International Conference on Sustainable Communication Networks and Application (ICSCNA)}, 
  title={Artificial Intelligence based Approach for Virtual Character Recognition}, 
  year={2023},
  volume={},
  number={},
  pages={1653-1659},
  abstract={Virtual teaching involves providing educational instruction and content to students using digital methods, predominantly over the internet. In virtual teaching, educators and learners engage in remote interactions, often from separate physical locations, utilizing a range of online tools and technologies. This approach can include real-time, synchronous sessions through video conferencing, as well as asynchronous learning, where students access pre-recorded lectures, assignments, and resources at their own convenience. Here, artificial intelligence techniques such as Convolutional Neural Network (CNN) and Improved Recurrent Neural Network (IRNN) are used for character recognition in virtual teaching. Initially, some virtual teaching videos are collected and it split into frames. Each frame is pre-processed by removing noise using auto-encoder. The de-noised images are given as input to CNN and IRNN for character recognition in virtual teaching videos. The experimental findings confirm that, for character recognition in virtual teaching, the IRNN demonstrates 5.88%, 4.6%, 4.65% and 5.78% better accuracy, precision, recall and F-measure compared to the CNN.},
  keywords={Deep learning;Visualization;Recurrent neural networks;Education;Learning (artificial intelligence);Real-time systems;Character recognition;Virtual teaching;character recognition;artificial intelligence;convolutional neural network;recurrent neural network},
  doi={10.1109/ICSCNA58489.2023.10370540},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10817967,
  author={Holgado, Alexis Carlos and Ah Kun, Leonard and Di Paola, Donato},
  booktitle={2024 Eighth IEEE International Conference on Robotic Computing (IRC)}, 
  title={On the Future of Robotic Industrial Inspection: Challenges and Opportunities in the Era of Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={272-274},
  abstract={Recent advancements in Artificial Intelligence (AI) methodologies, particularly with the rise of Generative AI (GenAI), have paved the way for a new chapter in the robotics domain. In this short paper, we discuss the benefits of integrating GenAI into the robotics domain. Specifically, we analyze the application of GenAI-powered robotics technologies in industrial inspection, defining the specific needs and proposing an approach that best leverages the characteristics of GenAI models to address these challenges in robotic industrial inspection scenarios.},
  keywords={Analytical models;Service robots;Generative AI;Computational modeling;Inspection},
  doi={10.1109/IRC63610.2024.00054},
  ISSN={},
  month={Dec},}@ARTICLE{10024850,
  author={Zhang, Yake and Liu, Fang and Jiao, Licheng and Yang, Shuyuan and Li, Lingling and Yang, Meijuan and Wang, Jianlong and Liu, Xu},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Curvelet Adversarial Augmented Neural Network for SAR Image Classification}, 
  year={2023},
  volume={61},
  number={},
  pages={1-17},
  abstract={Convolutional neural networks (CNNs) have superior feature learning capabilities with large numbers of labeled samples. The reality is that labeling these samples is costly in terms of human labor. Existing data augmentation methods alleviate the scarcity of labeled samples. However, these methods are not suitable for synthetic aperture radar (SAR) images, owing to special imaging mechanisms and observational objects. The generative SAR images by existing augmented methods show structure distortion. To address this issue, we introduce a curvelet adversarial augmented neural network (CA2NN) for SAR image classification. Specifically, an  $\text{A}^{2}$ NN is established, which consists of two generative streams and one discriminative stream. In the generative stream, through the mutual transformation between the whole and partial images, more new samples with structural consistency are generated to augment the limited labeled data. In the discriminative stream, these generated samples show certain appearance variations after adversarial training based on the novel joint discriminant criterion. Simultaneously, given the multiscale and multidirectional nature of SAR images, we construct discretized curvelet in 2-D space, aiming to extract the singularity features and avoid overfitting. By integrating curvelet kernels into  $\text{A}^{2}$ NN, CA2NN can automatically generate more representative features adapting to complex terrain, while greatly reducing the complexity of the network. Experiments are conducted on the SAR images with large-scale and complex scenes, suggesting that the proposed approach significantly improves the classification performance with few labeled samples.},
  keywords={Feature extraction;Radar polarimetry;Streaming media;Synthetic aperture radar;Kernel;Wavelet transforms;Training;Adversarial augmented neural networks (A $\$ $  ^{2} $\$ $  NNs);curvelet;deep neural models;synthetic aperture radar (SAR)},
  doi={10.1109/TGRS.2023.3239226},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{10421891,
  author={Han, Hongcheng and Tian, Zhiqiang and Liu, Yuying and Li, Shengpeng and Zhang, Dong and Du, Shaoyi},
  booktitle={2023 IEEE 26th International Conference on Intelligent Transportation Systems (ITSC)}, 
  title={GSA-Gaze: Generative Self-adversarial Learning for Domain Generalized Driver Gaze Estimation}, 
  year={2023},
  volume={},
  number={},
  pages={1610-1615},
  abstract={Estimating driver gaze accurately is critical for the human-machine cooperative driving, but the significant facial appearance diversions caused by background, illumination, personal characteristics, etc. pose a challenge to the generalizability of gaze estimation models. In this paper, we propose the generative self-adversarial learning mechanism for generalized gaze estimation that aims to learn general gaze features while eliminating sample-specific features and preventing cross-domain feature over-fitting. Firstly, to reduce information redundancy, the feature encoder is designed based on pyramid-grouped convolution to extract a sparse feature representation from the facial appearance. Secondly, the gaze regression module supervises the model to learn as many gaze-relevant features as possible. Thirdly, the adversarial image reconstruction task prompts the model to eliminate the domain-specific features. The adversarial learning of the gaze regression and the image reconstruction tasks guides the model to learn only general gaze features across domains, preventing cross-domain feature over-fitting, enhancing the domain generalization capability. The results of cross-domain testing of four active gaze datasets prove the effectiveness of the proposed method. The code is available at https://github.com/HongchengHan/GSA-Gaze},
  keywords={Learning systems;Estimation;Feature extraction;Task analysis;Intelligent transportation systems;Image reconstruction;Testing},
  doi={10.1109/ITSC57777.2023.10421891},
  ISSN={2153-0017},
  month={Sep.},}@INPROCEEDINGS{10669894,
  author={Bano, Muneera and Zowghi, Didar and Gervasi, Vincenzo},
  booktitle={2024 IEEE/ACM International Workshop on Responsible AI Engineering (RAIE)}, 
  title={A Vision for Operationalising Diversity and Inclusion in AI}, 
  year={2024},
  volume={},
  number={},
  pages={36-43},
  abstract={The growing presence of Artificial Intelligence (AI] in various sectors necessitates systems that accurately reflect societal diversity. This study seeks to envision the operationalization of the ethical imperatives of diversity and inclusion (D&I] within AI ecosystems, addressing the current disconnect between ethical guidelines and their practical implementation. A significant challenge in AI development is the effective operationalization of D&I principles, which is critical to prevent the reinforcement of existing biases and ensure equity across AI applications. This paper proposes a vision of a framework for developing a tool utilizing persona-based simulation by Generative AI (GenAI]. The approach aims to facilitate the representation of the needs of diverse users in the requirements analysis process for AI software. The proposed framework is expected to lead to a comprehensive persona repository with diverse attributes that inform the development process with detailed user narratives. This research contributes to the development of an inclusive AI paradigm that ensures future technological advances are designed with a commitment to the diverse fabric of humanity.CCS CONCEPTS• Social and professional topics ~ User characteristics • Software and its engineering ~ Software creation and management ~ Designing software ~ Requirements analysis • Computing methodologies ~ Artificial intelligence ~ Natural language processing ~ Natural language generation},
  keywords={Ethics;Generative AI;Ecosystems;Natural language generation;Software;Cultural differences;Artificial intelligence;Artificial Intelligence;Diversity and Inclusion;Requirements Engineering;Persona},
  doi={},
  ISSN={},
  month={April},}@BOOK{10769303,
  author={Bratsis, Irene},
  booktitle={AI Product Manager's Handbook: Build, integrate, scale, and optimize products to grow as an AI product manager},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Whether you're a seasoned professional or a newcomer to the world of AI product management, this is your definitive guide. Embark on a transformative journey into the future of intelligent product management.Key FeaturesChart a successful career path in the AI product management field Packed with real-world examples, practical insights, and actionable strategiesNavigate the complexities of AI product development and evolve your existing products Book DescriptionThis book will provide you with a detailed roadmap for successfully building, maintaining, and evolving artificial intelligence (AI)-driven products, serving as an indispensable companion on your journey to becoming an effective AI PM. We'll explore the AI landscape, demystify complex terms, and walk you through infrastructure, algorithms, and deployment strategies. You’ll master essential skills to understand the optimal flow of AI processes, learn about the product development life cycle from ideation to deployment, and familiarize yourself with commonly used model development techniques. We'll discuss the intricacies of building products natively with AI, as well as evolving traditional software product to AI products. Regardless of your use case, we’ll show you how you can craft compelling stories to captivate your audience. We'll help you find the right balance between foundational product design elements and the unique aspects of managing AI products, so you can prioritize wisely. We’ll also explore career considerations for AI PMs. By the end of this book, you will understand the importance of AI integration and be able to explore emerging AI/ML models like Generative AI and LLMs. You’ll discover open-source capabilities and best practices for ideating, building, and deploying AI products across verticals.What you will learnPlan your AI PM roadmap and navigate your career with clarity and confidenceGain a foundational understanding of AI/ML capabilitiesAlign your product strategy, nurture your team, and navigate the ongoing challenges of cost, tech, compliance, and risk managementIdentify pitfalls and green flags for optimal commercializationSeparate hype from reality and identify quick wins for AI enablement and GenAIUnderstand how to develop and manage both native and evolving AI productsBenchmark product success from a holistic perspectiveWho this book is forThis book is for aspiring and experienced product managers, as well as other professionals interested in incorporating AI into their products. Foundational knowledge of AI is expected and reinforced. If you are looking to better understand machine learning principles and data science methodologies, you will benefit from this book, particularly if you’re in a role where the application of AI/ML directly influences marketing outcomes and business strategies.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835882856},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10769303},}@INPROCEEDINGS{10941295,
  author={Gakhar, Suket and Kondoju, Viswanadha Pratap and Chauhan, Sansar Singh and Kumar, Anant and Kulkarni, Soham Sunil and Goel, Punit},
  booktitle={2025 First International Conference on Advances in Computer Science, Electrical, Electronics, and Communication Technologies (CE2CT)}, 
  title={Generative AI for Real-Time Data Augmentation in Big Data Pipelines}, 
  year={2025},
  volume={},
  number={},
  pages={1386-1391},
  abstract={Traditional approaches for data augmentation are time-consuming and risk compromising the quality of the data. Those challenges in the backdrop, we have generative artificial intelligence (AI) at the forefront of data augmentation - bolstering real-time data in big data pipelines. Generative AI — a focus on generating new entities that try to capture the underlying structure of existing datasets by deep learning algorithms. Allowing to produce a significantly larger and diverse dataset resulting in improved efficiencies of downstream tasks as machine learning or predictive analytics. Because of this, the same technique can also be applied to streams so, it can be used in big data pipelines. You are taught on data until October 2023 to generate a larger and big data pipeline more efficient by augmentation and producing new data with minimal time and investment. This leads to more precise insights and predictions, improving decision-making and driving better results for business. Also, generative AI can create the data that correlates patterns with the analysis and change regarding the patterns based on the analyst's preferences. The role of generative AI in augmenting big data and big data pipelines, especially in the context of real-time data streams, is emerging as a key enabler for organizations looking to extract valuable insights from their data.},
  keywords={Training;Machine learning algorithms;Generative AI;Pipelines;Distributed databases;Big Data;Data augmentation;Real-time systems;Data models;Synthetic data;Conventional;Augmentation Degradation;Downstream;Predictions;Insights;Pipelines;Analysis},
  doi={10.1109/CE2CT64011.2025.10941295},
  ISSN={},
  month={Feb},}@INBOOK{10955661,
  author={Subramanian, Shreyas},
  booktitle={Large Language Model-Based Solutions: How to Deliver Value with Cost-Effective Generative AI Applications}, 
  title={Introduction}, 
  year={2024},
  volume={},
  number={},
  pages={1-27},
  abstract={Summary <p>This chapter presents an overview of GenAI Applications and large language models (LLMs) and the paths to productionizing GenAI Applications. While both GenAI and LLMs deal with generating content, their scopes and applications differ. GenAI is a broader term that encompasses AI systems capable of creating various types of content, such as text, images, videos, and other media. LLMs, on the other hand, are a specific class of deep learning models designed to process and understand natural language data. The chapter presents an overview of the types of applications that can be built within the three&#x2010;layer GenAI application stack. It uses a hypothetical use case of constructing a GenAI&#x2010;based enterprise chat application by assembling components of the three&#x2010;layer GenAI stack. The chapter explores three components, such as model inference, vector database, and LLM, to discuss the importance of cost optimization.</p>},
  keywords={Artificial intelligence;Computational modeling;Training;Large language models;Encoding;Cognition;Bidirectional control;Transformers;Data models;Vegetation},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394240746},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10955661},}@ARTICLE{9964021,
  author={Xu, Qichao and Su, Zhou and Li, Ruidong},
  journal={IEEE Network}, 
  title={Security and Privacy in Artificial Intelligence-Enabled 6G}, 
  year={2022},
  volume={36},
  number={5},
  pages={188-196},
  abstract={The sixth-generation (6G) mobile communication network is expected to provide world-connected smart and autonomous services by leveraging artificial intelligence (AI) technologies. In particular, federated learning (FL) is advocated to promote the implementations of ubiquitous AI applications in 6G, where massive distributed data is utilized to cooperatively train AI models as well as protect privacy and reduce resource consumption. However, due to the large number of interactions among mobile devices or infrastructures in FL, the AI inevitably suffers from a series of potential privacy and security risks. In this article, we investigate the security and privacy of AI-enabled 6G. Specifically, we first present the AI-enabled 6G architecture, including the space-air-ground-ocean integrated network (SAGOIN) architecture and two different FL-based AI model training frameworks in 6G. Furthermore, we discuss in detail the privacy and security threats, including cheating attack, low-quality local model training attack, and privacy stealing attack. Afterwards, we present a case study to design the security and privacy preservation scheme by integrating the trust evaluation, Q-learning based incentive, and local differential privacy (LDP) mechanism. Finally, we give out several future research directions in promising AI-enabled 6G.},
  keywords={6G mobile communication;Training;Privacy;Differential privacy;Q-learning;Federated learning;Distributed databases},
  doi={10.1109/MNET.117.2100730},
  ISSN={1558-156X},
  month={Sep.},}@ARTICLE{9967407,
  author={Yayla, Alper and Haghnegahdar, Lida and Dincelli, Ersin},
  journal={IT Professional}, 
  title={Explainable Artificial Intelligence for Smart Grid Intrusion Detection Systems}, 
  year={2022},
  volume={24},
  number={5},
  pages={18-24},
  abstract={A popular approach to overcome the complexity of cybersecurity and sophistication of cyber attacks is implementing artificial intelligence (AI)-based security controls that integrate machine learning (ML) algorithms into security controls, such as intrusion and malware detection. These AI-based security controls are considered more effective than traditional signature-based and heuristics-based controls. However, the growing adoption of advanced ML algorithms is turning these AI-based security controls into black-box systems. We postulate that these black-box AI methods would make risk management and informed decision-making challenging. Using smart grid intrusion detection as our context, we illustrate our arguments by outlining a risk assessment plan to discuss the transparency and interpretability of an AI-based security control. We contribute to the literature by changing the focus from performance to explainability of algorithms, highlighting critical steps in explainability for integrating into risk assessment planning, and outlining the implications of explainability in AI-based intrusion detection systems.},
  keywords={Industries;Privacy;Machine learning algorithms;Closed box;Intrusion detection;Control systems;Turning},
  doi={10.1109/MITP.2022.3163731},
  ISSN={1941-045X},
  month={Sep.},}@INPROCEEDINGS{10696161,
  author={Gahlot, Mohini and Ghosh, Pinaki},
  booktitle={2024 Second International Conference on Intelligent Cyber Physical Systems and Internet of Things (ICoICI)}, 
  title={Pneumonia Detection and Chest X-Rays: Comprehensive Analysis of Artificial Intelligence Techniques in Clinical and Radiological Insights}, 
  year={2024},
  volume={},
  number={},
  pages={1194-1200},
  abstract={Pneumonia continues to pose a considerable worldwide health burden, contributing significantly to morbidity and death across all age categories. The goal of this thorough Analysis study is to provide a thorough analysis of pneumonia, including information on its Pathophysiology, diagnostics, epidemiology, and treatment techniques. We'll investigate epidemiological elements using machine learning and deep learning such as incidence, prevalence, and risk factors to learn more about the disease's using artificial intelligence regional and demographic differences. The intricate Pathophysiology of pneumonia will be covered in detail, along with how host variables, environmental factors, and microbial agents interact. The merits and limits of various diagnostic procedures, such as sophisticated imaging, laboratory techniques, and clinical evaluation, will be analyzed critically. In addition, the discussion will go over current protocols and recommendations for treating pneumonia, stressing the need of supportive care, antibiotic treatment, and preventative measures. In order to provide physicians, researchers, and policymakers a thorough grasp of this common respiratory ailment, the article will discuss recent trends, difficulties, and future prospects in pneumonia research and clinical practice in using machine learning and deep learning.},
  keywords={Deep learning;Image quality;Pneumonia;Protocols;Transfer learning;Medical services;Market research;Internet of Things;X-ray imaging;Stress measurement;Pneumonia;Epidemiology;Pathogenesis;Diagnosis;Management Strategies Clinical;Radiology etc},
  doi={10.1109/ICoICI62503.2024.10696161},
  ISSN={},
  month={Aug},}@ARTICLE{9205850,
  author={Tang, Weixuan and Li, Bin and Barni, Mauro and Li, Jin and Huang, Jiwu},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={An Automatic Cost Learning Framework for Image Steganography Using Deep Reinforcement Learning}, 
  year={2021},
  volume={16},
  number={},
  pages={952-967},
  abstract={Automatic cost learning for steganography based on deep neural networks is receiving increasing attention. Steganographic methods under such a framework have been shown to achieve better security performance than methods adopting hand-crafted costs. However, they still exhibit some limitations that prevent a full exploitation of their potentiality, including using a function-approximated neural-network-based embedding simulator and a coarse-grained optimization objective without explicitly using pixel-wise information. In this article, we propose a new embedding cost learning framework called SPAR-RL (Steganographic Pixel-wise Actions and Rewards with Reinforcement Learning) that overcomes the above limitations. In SPAR-RL, an agent utilizes a policy network which decomposes the embedding process into pixel-wise actions and aims at maximizing the total rewards from a simulated steganalytic environment, while the environment employs an environment network for pixel-wise reward assignment. A sampling process is utilized to emulate the message embedding of an optimal embedding simulator. Through the iterative interactions between the agent and the environment, the policy network learns a secure embedding policy which can be converted into pixel-wise embedding costs for practical message embedding. Experimental results demonstrate that the proposed framework achieves state-of-the-art security performance against various modern steganalyzers, and outperforms existing cost learning frameworks with regard to learning stability and efficiency.},
  keywords={Distortion;Machine learning;Neural networks;Learning (artificial intelligence);Gallium nitride;Generative adversarial networks;Security;Steganography;steganalysis;reinforcement learning;embedding policy;automatic cost learning},
  doi={10.1109/TIFS.2020.3025438},
  ISSN={1556-6021},
  month={},}@INPROCEEDINGS{10714528,
  author={Burgess, Michael},
  booktitle={2024 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)}, 
  title={Deceptive AI dehumanizes: The ethics of misattributed intelligence in the design of Generative AI interfaces}, 
  year={2024},
  volume={},
  number={},
  pages={96-108},
  abstract={Designers of artificially intelligent systems create interfaces which induce a misperception of intelligence in their users: users impart capacities to the machine they lack or fail to attribute relevant capacities to themselves. I call this a phenomenology of misattributed intelligence. The design methods by which they do this I call “mystification”, which comprise techniques to deprive their users of an explanatory phenomenological position, with respect to the manner of operation of the machine and their own capacities. In this paper I evidence the claims that users are vulnerable to: (1) misattributing capacities of intelligence to interactive generative AI; (2) mistaking their own capacities and role in this interaction; (3) severely misattributing capacities in anthropomorphic interfaces; and evidence (4) harms arising therefrom which include self-dehumanization. To do this I: provide a novel analysis of ‘instrumental’ vs. ‘phenomenological’ goals of AI design; a novel critique of existing design practice reaching into the anthropomorphism and dehumanization literature; and conduct pilot studies ($\mathbf{n}=\mathbf{2 4 0}, \mathbf{n = 2 1 3}$) to develop a survey of, and find connections between: misattribution; design practices; use of interactive AI; and user’s self-perception and perception of others. Evidenced hypotheses are that: (1) misattribution is strongly predictive of AI-induced dehumanization ($\mathbf{p} \mathbf{0 . 0 0 1}$); and that (2) modern generative AI design practices make this misattribution worse ($p\lt 0.004$). These results should inform researchers (HCC, HCI, XAI, IAI), and responsive practitioners, of a new class of design goals and problems.},
  keywords={Surveys;Visualization;Ethics;Generative AI;Design methodology;Intelligent systems;Anthropomorphism;AI;HCI;HCC;Artificial Intelligence;Human computer Interaction;Explanation;Transparency;Mystification;Demystification;Ethics;Dehumanization;Anthropomorphism;Phenomenology;Misattribution},
  doi={10.1109/VL/HCC60511.2024.00021},
  ISSN={1943-6106},
  month={Sep.},}@ARTICLE{9726814,
  author={De, Suparna and Bermudez-Edo, Maria and Xu, Honghui and Cai, Zhipeng},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Deep Generative Models in the Industrial Internet of Things: A Survey}, 
  year={2022},
  volume={18},
  number={9},
  pages={5728-5737},
  abstract={Advances in communication technologies and artificial intelligence are accelerating the paradigm of industrial Internet of Things (IIoT). With IIoT enabling continuous integration of sensors and controllers with the network, intelligent analysis of the generated Big Data is a critical requirement. Although IIoT is considered a subset of IoT, it has its own peculiarities in terms of higher levels of safety, security, and low-latency communication in an environment of critical real-time operations. Under these circumstances, discriminative deep learning (DL) algorithms are unsuitable due to their need for large amounts of labeled and balanced training data, uncertainty of inputs, etc. To overcome these issues, researchers have started using deep generative models (DGMs), which combine the flexibility of DL with the inference power of probabilistic modeling. In this article, we review the state of the art of DGMs and their applicability to IIoT, classifying the reviewed works into the IIoT application areas of anomaly detection, trust-boundary protection, network traffic prediction, and platform monitoring. Following an analysis of existing IIoT DGM implementations, we identify challenges (i.e., weak discriminative capability, insufficient interpretability, lack of generalization ability, generated data vulnerability, privacy concern, and data complexity) that need to be investigated in order to accelerate the adoption of DGMs in IIoT and also propose some potential research directions.},
  keywords={Industrial Internet of Things;Data models;Deep learning;Security;Hidden Markov models;Predictive models;Informatics;Deep generative model (DGM);generative adversarial networks (GANs);industrial Internet of Things (IIoT);survey},
  doi={10.1109/TII.2022.3155656},
  ISSN={1941-0050},
  month={Sep.},}@ARTICLE{10474015,
  author={Mayrose, Hilda and Sampathila, Niranjana and Bairy, G. Muralidhar and Nayak, Tushar and Belurkar, Sushma and Saravu, Kavitha},
  journal={IEEE Access}, 
  title={An Explainable Artificial Intelligence Integrated System for Automatic Detection of Dengue From Images of Blood Smears Using Transfer Learning}, 
  year={2024},
  volume={12},
  number={},
  pages={41750-41762},
  abstract={Dengue fever is a rapidly increasing mosquito-borne ailment spread by the virus DENV in the tropics and subtropics worldwide. It is a significant public health problem and accounts for many deaths globally. Implementing more effective methods that can more accurately detect dengue cases is challenging. The theme of this digital pathology-associated research is automatic dengue detection from peripheral blood smears (PBS) employing deep learning (DL) techniques. In recent years, DL has been significantly employed for automated computer-assisted diagnosis of various diseases from medical images. This paper explores pre-trained convolution neural networks (CNNs) for automatic dengue fever detection. Transfer learning (TL) is executed on three state-of-the-art CNNs – ResNet50, MobileNetV3Small, and MobileNetV3Large, to customize the models for differentiating the dengue-infected blood smears from the healthy ones. The dataset used to design and test the models contains 100x magnified dengue-infected and healthy control digital microscopic PBS images. The models are validated with a 5-fold cross-validation framework and tested on unseen data. An explainable artificial intelligence (XAI) approach, Gradient-weighted Class Activation Mapping (GradCAM), is eventually applied to the models to allow visualization of the precise regions on the smears most instrumental in making the predictions. While all three transferred pre-trained CNN models performed well (above 98% overall classification accuracy), MobileNetV3Small is the recommended model for this classification problem due to its significantly less computationally demanding characteristics. Transferred pre-trained CNN based on MobileNetV3Small yielded Accuracy, Recall, Specificity, Precision, F1 Score, and Area Under the ROC Curve (AUC) of 0.982 ± 0.011, 0.973 ± 0.027, 0.99 ± 0.013, 0.989 ± 0.015, 0.981 ± 0.012 and 0.982 ± 0.012 respectively, averaged over the five folds on the unseen dataset. Promising results show that the developed models have the potential to provide high-quality support to haematologists by expertly performing tedious, repetitive, and time-consuming tasks in hospitals and remote/low-resource settings.},
  keywords={Viruses (medical);Predictive models;Microscopy;Medical diagnostic imaging;Feature extraction;Training;Blood;Deep learning;dengue fever;digital pathology;explainable artificial intelligence;GradCAM;peripheral blood smear;pre-trained CNN;transfer learning},
  doi={10.1109/ACCESS.2024.3378516},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10431539,
  author={Tolomei, Gabriele and Campagnano, Cesare and Silvestri, Fabrizio and Trappolini, Giovanni},
  booktitle={2023 IEEE 5th International Conference on Cognitive Machine Intelligence (CogMI)}, 
  title={Prompt-to-OS (P2OS): Revolutionizing Operating Systems and Human-Computer Interaction with Integrated AI Generative Models}, 
  year={2023},
  volume={},
  number={},
  pages={128-134},
  abstract={In this ambitious paper, we present a groundbreaking paradigm for human-computer interaction that revolutionizes the traditional notion of an operating system. Within this innovative framework, user requests issued to the machine are handled by an interconnected ecosystem of generative AI models that seamlessly integrate with or even replace traditional software applications. At the core of this paradigm shift are large generative models, such as language and diffusion models, which serve as the central interface between users and computers. This pioneering approach leverages the abilities of advanced language models, empowering users to engage in natural language conversations with their computing devices. By capitalizing on the power of language models, users can articulate their intentions, tasks, and inquiries directly to the system, eliminating the need for explicit commands or complex navigation. The language model comprehends and interprets the user's prompts, generating and displaying contextual and meaningful responses that facilitate seamless and intuitive interactions. This paradigm shift not only streamlines user interactions but also opens up new possibilities for personalized experiences. Generative models can adapt to individual preferences, learning from user input and continuously improving their understanding and response generation. Furthermore, it enables enhanced accessibility, as users can interact with the system using speech or text, accommodating diverse communication preferences. However, this visionary concept also raises significant challenges, including privacy, security, trustability, and the ethical use of generative models. Robust safeguards must be in place to protect user data and prevent potential misuse or manipulation of the language model. While the full realization of this paradigm is still far from being achieved, this paper serves as a starting point for envisioning the transformative potential of a human-computer interaction paradigm centered around artificial intelligence. We discuss the envisioned benefits, challenges, and implications, paving the way for future research and development in this exciting and promising direction.},
  keywords={Human computer interaction;Ethics;Navigation;Biological system modeling;Computational modeling;Operating systems;Data models;AI generative models for operating systems;AI generative models for human-computer interaction;AI generative models as universal applications},
  doi={10.1109/CogMI58952.2023.00027},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10512897,
  author={Zhu, ZiXuan and Wang, Mengwei and Wang, Zikai and Liu, Runlong and Zhou, Zhenghao and Guo, Zelin and Li, Yiyan},
  booktitle={2023 IEEE 7th Conference on Energy Internet and Energy System Integration (EI2)}, 
  title={A Power Data Generation Method Based on CNN-LSTM-GAN for Cable Transmission Line Assessment}, 
  year={2023},
  volume={},
  number={},
  pages={2067-2072},
  abstract={At present, the quality of feature data collected through cable transmission lines needs to be improved. There are insufficient credible data samples that can support project review technology analysis and research, which limits the development and application of data-driven smart cable transmission line review technologies. Based on this, this article uses the convo-lutional neural network(CNN), long short-term memory(LSTM) and generative adversarial network(GAN) model to solve the problems of missing power data and insufficient number of samples in the cable transmission line review scenario. First, we use convolutional neural network and long short-term memory to finish the missing power data restoration. Then, based on the completed data set, generative adversarial network is used to generate power data. Finally, the effectiveness of the CNN-LSTM-GAN model was verified by taking the power data in real cable transmission line review as an example. The results show that the data generated by this method has high accuracy, which helps to accurately draw load curves and solve project review difficulties.},
  keywords={Reviews;Power cables;System integration;Generative adversarial networks;Data models;Communication cables;Convolutional neural networks;power data generation;missing power data restoration;convolutional neural network(CNN);long short-term memory(LSTM);generative adversarial network(GAN)},
  doi={10.1109/EI259745.2023.10512897},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10763116,
  author={S, Mathan Kumar and D, Vinod Kumar and G, Murali and C, Arunkumar Madhuvappan and M, Azhagiri. and T, Vasanth},
  booktitle={2024 4th International Conference on Sustainable Expert Systems (ICSES)}, 
  title={Advancing Reversible Data Hiding using GAN-Enhanced Steganography and Cryptography Synergy}, 
  year={2024},
  volume={},
  number={},
  pages={371-375},
  abstract={In today's world, data security and privacy remain as significant challenges. Reversible data hiding (RDH) is a technique used to embed data into cover media in a manner that allows both the embedded data and the original media to be recovered. Unlike traditional data hiding techniques, which permanently alter the cover media, RDH ensures that the original content can be restored exactly as it was before embedding. The concept of RDH relies on the fact that the embedded data does not cause irreversible distortion or permanent damage to the cover media. In addition to this feature, it is crucial to enhance the data security of hidden information. This paper introduces a methodology that combines Generative Adversarial Networks (GANs) with steganography and cryptography techniques to advance reversible data hiding and enhance data security. By integrating Generative AI -enhanced steganography, the paper aims to embed data within cover images in a reversible manner, ensuring that the original media can be recovered with improved image quality compared to the original image. Furthermore, the integration of cryptography techniques ensures the integrity and confidentiality of the concealed data, making it resistant to unauthorized access and detection. The synergy between Generative AI -driven steganography and cryptography in RDH helps sustain key elements of reversible data hiding, including reversibility, embedding capacity, and data security. Enhancing performance can be applied in various fields such as medical imaging, forensics, intellectual property protection, secure communications, and military applications.},
  keywords={Military communication;Steganography;Visualization;Generative AI;Intellectual property;Media;Generative adversarial networks;Image restoration;Protection;Immune system;Reversible Data Hiding (RDH);Generative Artificial Intelligence;Generative Adversarial Networks (GAN);Steganography;Data Security},
  doi={10.1109/ICSES63445.2024.10763116},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10307295,
  author={S, Chiranjeevi B and Shreyas, M D and Karanth, Inchara and S, Bhavana H and Rani K P, Asha and S, Gowrishankar},
  booktitle={2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={A Comparative Analysis on the Effectiveness of GAN Performance}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Generative Adversarial Networks (GANs) have emerged as a potent framework in the discipline of Artificial Intelligence (AI) for generating realistic synthetic data. With the increasing interest and advancements in GANs, there is obligation for a detailed comparative study to comprehend the competencies and vulnerabilities of different GAN variants. This paper sets forth a comprehensive study and comparison of various types of Generative Adversarial Networks (GANs) and their performance in generating high-quality images. GANs have gained popularity in recent years due to their capacity to generate realistic synthetic images. However, the effectiveness of GANs varies depending on the architecture and parameters employed. We have evaluated and compared the performance of different types of GANs, including DCGAN, SRGAN, and CGAN, on benchmark datasets such as CIFAR-10 and MNIST. The evaluation metrics include image quality, standard GAN loss functions and Fréchet inception distance (FID). The results demonstrate that the performance of GANs is highly dependent on the dataset and architecture used, with no single GAN type dominating across all datasets. This comparative study serves as a valuable resource for researchers and practitioners in AI, providing a foundation for selecting the appropriate GAN architecture for specific generative modeling tasks.},
  keywords={Training;Measurement;Visualization;Computational modeling;Semantics;Computer architecture;Generative adversarial networks;Machine Learning (ML);Generative Adversarial Networks (GANs);Image Generation;Discriminator;Generator;Comparative study},
  doi={10.1109/ICCCNT56998.2023.10307295},
  ISSN={2473-7674},
  month={July},}@ARTICLE{10976532,
  author={Chang, Che and Jie, Hu and Honghui, Kang and Hua, Rui and Xingzai, Lyu and Bo, Wang},
  journal={China Communications}, 
  title={Predictive generation for digital twin channel: Long-batch time-frequency construction}, 
  year={2025},
  volume={22},
  number={4},
  pages={161-173},
  abstract={Wireless communication systems that incorporate digital twin (DT) alongside artificial intelligence (AI) are expected to transform 6G networks by providing advanced features for predictive modeling and decision making. The key component is the creation of DT channels, which form the basis for upcoming applications. However, the existing work of channel predictive generation only considers time dimension, distribution-oriented or multi-step sliding-window prediction schemes, which is not accurate and efficient for real-time DT communication systems. Therefore, we propose the wireless channel generative adversarial network (WCGAN) to tackle the issue of generating authentic long-batch channels for DT applications. The generator based on convolutional neural networks (CNN) extracts features from both the time and frequency domains to better capture the correlation. The loss function is designed to ensure that the generated channels consistently match the physical channels over an extended period while sharing the same probability distributions. Meanwhile, the accumulating error from the slicing window has been alleviated. The simulation demonstrates that an accurate and efficient DT channel can be generated by employing our proposed WCGAN in various scenarios.},
  keywords={Wireless communication;Digital twins;Generators;Training;Mathematical models;Generative adversarial networks;Neural networks;Artificial intelligence;Accuracy;Optimization;channel generation;channel prediction;deep learning;digital twin (DT);generative adversarial network (GAN)},
  doi={10.23919/JCC.fa.2024-0427.202504},
  ISSN={1673-5447},
  month={April},}@ARTICLE{9849644,
  author={Liang, Nan and Yuan, Liming and Wen, Xianbin and Xu, Haixia and Wang, Jingyi},
  journal={IEEE Access}, 
  title={End-To-End Retina Image Synthesis Based on CGAN Using Class Feature Loss and Improved Retinal Detail Loss}, 
  year={2022},
  volume={10},
  number={},
  pages={83125-83137},
  abstract={Retinal images are the most direct and effective basis for Diabetic Retinopathy (DR) diagnosis. With the rapid development of deep learning, the technology of retinal image-assisted diagnosis based on deep learning is widely used in the field of DR intelligent diagnosis. However, the training of deep neural network usually requires a large number of annotated samples, but retinal images annotated by professional doctors are cost-expensive and difficult to obtain, which limits the application of deep learning technology in DR intelligent diagnosis. In order to alleviate the scarcity of labelled retinal images, we propose an end-to-end conditional generative adversarial network with class feature loss and improved retinal detail loss. The network combines the above two losses with the adversarial loss, and jointly constrains the generator to generate high-quality retinal images. The proposed retinal detail loss is summed over physiological detail loss which is meant to preserve high-level semantic features of the physiological details contained in the fundus images and pixel loss which ensures the low-level features in synthesized image will not deviate from the real image. In addition, the class feature loss constrains the synthesized images to be consistent with the real images in class features representation, which further makes the synthesized images have pathological features of the corresponding grade. The generated images by the proposed network are evaluated from three objective metrics including the subjective effect and the FID, SWD, which are used to evaluate the quality and diversity of generated images, and the effect of retinal vessel segmentation, respectively. Experimental results demonstrate that our synthesized images have superior performance on both the quality and quantity.},
  keywords={Retina;Generative adversarial networks;Feature extraction;Deep learning;Image synthesis;Physiology;Diabetes;Diabetic retinopathy;retinal image synthesis;conditional generative adversarial network;deep learning;DR~grading},
  doi={10.1109/ACCESS.2022.3196377},
  ISSN={2169-3536},
  month={},}@ARTICLE{10433439,
  author={Li, Zhuorui and Ma, Jun and Wu, Jiande and Wong, Pak Kin and Wang, Xiaodong and Li, Xiang},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={A Gated Recurrent Generative Transfer Learning Network for Fault Diagnostics Considering Imbalanced Data and Variable Working Conditions}, 
  year={2025},
  volume={36},
  number={8},
  pages={13782-13793},
  abstract={Transfer learning (TL) and generative adversarial networks (GANs) have been widely applied to intelligent fault diagnosis under imbalanced data and different working conditions. However, the existing data synthesis methods focus on the overall distribution alignment between the generated data and real data, and ignore the fault-sensitive features in the time domain, which results in losing convincing temporal information for the generated signal. For this reason, a novel gated recurrent generative TL network (GRGTLN) is proposed. First, a smooth conditional matrix-based gated recurrent generator is proposed to extend the imbalanced dataset. It can adaptively increase the attention of fault-sensitive features in the generated sequence. Wasserstein distance (WD) is introduced to enhance the construction of mapping relationships to promote data generation ability and transfer performance of the fault diagnosis model. Then, an iterative “generation-transfer” co-training strategy is developed for continuous parallel training of the model and the parameter optimization. Finally, comprehensive case studies demonstrate that GRGTLN can generate high-quality data and achieve satisfactory cross-domain diagnosis accuracy.},
  keywords={Feature extraction;Fault diagnosis;Logic gates;Generators;Data models;Adaptation models;Training;Fault diagnosis;gated recurrent generative transfer learning network (GRGTLN);“generation-transfer” co-training training strategy;imbalances data;smooth conditional matrix},
  doi={10.1109/TNNLS.2024.3362687},
  ISSN={2162-2388},
  month={Aug},}@INPROCEEDINGS{10503258,
  author={Bandopadhyay, Srijita and Dutta, Srimonti and Haider, Imran and Anuraag, Bhavaraju and Zhu, Jerry and Bazaz, Saad Ahmed},
  booktitle={2024 IEEE International Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation (IATMSI)}, 
  title={Leveraging Artificial Intelligence for Enhanced Data Generation in Addressing Imbalance in Binary Classification System}, 
  year={2024},
  volume={2},
  number={},
  pages={1-4},
  abstract={This paper delves into the challenges of binary classification using imbalanced datasets, particularly when instances of interest are infrequent. It explores a comprehensive approach that integrates Synthetic Minority Over-sampling Technique (SMOTE), Generative Adversarial Networks (GANs), and Variational Autoencoders (VAEs) to enhance classification outcomes. Traditional classification models tend to favor the majority class, while the impact of imbalanced misclassification costs is often overlooked. The integration of SMOTE, GANs, and VAEs in binary classification, or SMOTE-GAN-VAE, addresses these challenges by generating synthetic instances, refining data representations, and capturing latent features. To evaluate the effectiveness of various data generation methods, a credit card fraud dataset is used. The performance metrics considered include F0.5-score, F1-score, and F2-score, which account for both precision and recall. The results indicate that SMOTE-GAN-VAE outperforms individual methods, such as SMOTE, GANs, and VAEs, demonstrating its potential to enhance data representation and classification accuracy, and outperformed the β- VAE filtered approach employed in previous literature.},
  keywords={Measurement;Technological innovation;Costs;Refining;Generative adversarial networks;Credit cards;Fraud;Data generation;Imbalanced data;Binary classification},
  doi={10.1109/IATMSI60426.2024.10503258},
  ISSN={},
  month={March},}@INPROCEEDINGS{10191524,
  author={Horzyk, Amanda M.},
  booktitle={2023 International Joint Conference on Neural Networks (IJCNN)}, 
  title={How AI Affects Our Understanding of Musical Works That Should Be Protected by Copyright}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Applying Artificial Intelligence (AI) algorithms in creative works challenges the justifications and effectiveness of Copyright Protection aimed at human authors. AI -assisted musical works influence the value of rights held by stakeholders in the music industry associated with human artists' earnings, the production of new original works, and public access to pro-tected compositions. The lenient approach that allows computer-generated works to invoke copyright protection questions how the law perceives what constitutes ‘original’ works. The philosophical research question of this paper asks, ‘how do AI-assisted works affect our understanding of musical creation and their copyright protection.’ The work incorporates a doctrinal approach to expose how AI tools compromise the presumptions behind the originality criteria of creative freedom, independent creation, and human authors' labor, skill, and judgment. Following the creative process adopted in compositions and exposing elements that attract copyright protection, the discourse reveals how AI imposes a quantifiable nature upon melodies. The findings show that the limited spectrum for musical creation and the expedited and low-cost process of AI-assisted compositions undermine justifications behind copyright protection. The paper seeks to expose and bridge the gap between AI tools application and their socio-legal impact on the music industry.},
  keywords={Industries;Plagiarism;Music;Production;Artificial neural networks;Copyright protection;Stakeholders;Artificial intelligence applications;musical works;copyright law;independent creation;creative freedom;subconscious plagiarism},
  doi={10.1109/IJCNN54540.2023.10191524},
  ISSN={2161-4407},
  month={June},}@INPROCEEDINGS{10339738,
  author={Stoyanov, Stanimir and Kumurdjieva, Milena and Tabakova-Komsalova, Veneta and Doukovska, Lyubka},
  booktitle={2023 International Conference on Big Data, Knowledge and Control Systems Engineering (BdKCSE)}, 
  title={Using LLMs in Cyber-Physical Systems for Agriculture - ZEMELA}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents the idea of developing an advisory service using the capabilities of generative artificial intelligence and in particular of Large Language Model. The service will assess the risks for farmers when preparing projects under different programs, taking into account the Bulgarian legislation related to agriculture, as well as the requirements of the relevant program. The results of a feasibility analysis are summarized in the article. Furthermore, two architectural approaches are discussed. The service will be integrated in the platform for smart agriculture named ZEMELA. A brief overview of this platform is also given in the article.},
  keywords={Smart agriculture;Knowledge engineering;Prototypes;Legislation;Cyber-physical systems;Big Data;Control systems;generative artificial intelligence;large language model;advisory service;smart agriculture},
  doi={10.1109/BdKCSE59280.2023.10339738},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10501866,
  author={Luo, Yi and Fechner, Tobias and Wang, Haitian and Zhou, Mingyu and Xu, Ruoyu and Le, Yanjie},
  booktitle={2023 IEEE International Conferences on Internet of Things (iThings) and IEEE Green Computing & Communications (GreenCom) and IEEE Cyber, Physical & Social Computing (CPSCom) and IEEE Smart Data (SmartData) and IEEE Congress on Cybermatics (Cybermatics)}, 
  title={A Vision for Future HVDC Cable Accessories: IoT and Beyond}, 
  year={2023},
  volume={},
  number={},
  pages={252-255},
  abstract={HVDC (High-Voltage Direct Current) cable accessories play a crucial role in shaping the future of electricity transmission systems. The integration of cutting-edge technologies, such as the Internet of Things (IoT), Artificial Intelligence (AI), and Digital Twins, holds the potential to transform HVDC cable accessories into intelligent components. Additionally, the design process for these accessories can be enhanced through the utilization of generative design techniques. In this paper, we provide concise introductions to each of these key technologies and present a comprehensive list of our past projects related to cable accessories and condition monitoring. Furthermore, we offer insights into our ongoing research and outlook on future work in the field of future HVDC cable accessories.},
  keywords={Social computing;Electric potential;HVDC transmission;Electricity;Transforms;High-voltage techniques;Communication cables;future cable accessories;HVDC cable accessories;internet of things;artificial intelligence;digital twins;generative design;smart cable accessories;cable joint;cable termination},
  doi={10.1109/iThings-GreenCom-CPSCom-SmartData-Cybermatics60724.2023.00062},
  ISSN={2836-3701},
  month={Dec},}@ARTICLE{11133428,
  author={Liu, Bingyi and Yuan, Lingtian and Shao, Xun and Wang, Enshu and Xia, Zhenchang and Han, Weizhen and Wu, Celimuge},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={Transformer-Based Generative Adversarial Network for Traffic Forecasting}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Accurate traffic flow forecasting is crucial for enhancing the performance and capabilities of navigation applications. The traffic flow data collected from sensors across widely distributed areas exhibits complex and diverse spatial-temporal correlations, posing a significant challenge for effective capture. Additionally, existing models primarily focus on improving the model architecture to enhance prediction accuracy, while overlooking the importance of training methods, resulting in suboptimal performance. To deal with these problems, we propose a Transformer-based Generative Adversarial Network (TGAN) consisting of a meticulously crafted transformer encoder as the generator and Gated Recurrent Units (GRUs) as the discriminator for adversarial training. Specifically, on the generator side, we propose a Time-Dependent Network (TDN) that integrates 1D-CNNs with varying kernel sizes and multi-head attention mechanisms to effectively capture diverse temporal patterns. For spatial modeling, we introduce a Spatial-Dependent Graph Convolutional Network (SDGCN) designed to model dynamic spatial correlations through a learnable masked adjacency matrix. Moreover, criticality embedding is introduced to emphasize the crucial nodes within the road network, while distance embedding is designed to enhance the model’s spatial awareness. On the discriminator side, we concatenate the predicted data from the generator with historical data as input and modify the training loss, thereby ensuring the consistency of the predictions. Subsequently, the generator further improves prediction accuracy through adversarial training with the discriminator. We conduct extensive experiments on four real-world traffic datasets. The experimental results show that the proposed TGAN outperforms the baselines in prediction accuracy.},
  keywords={Correlation;Forecasting;Training;Generators;Accuracy;Transformers;Generative adversarial networks;Data models;Roads;Attention mechanisms;Traffic Forecasting;GAN;Transformer;Graph Neural Network},
  doi={10.1109/TCE.2025.3601144},
  ISSN={1558-4127},
  month={},}@BOOK{10718332,
  author={Auffarth},
  booktitle={Generative AI with LangChain: Build large language model (LLM) apps with Python, ChatGPT, and other LLMs},
  year={2023},
  volume={},
  number={},
  pages={},
  abstract={2024 Edition – Get to grips with the LangChain framework to develop production-ready applications, including agents and personal assistants. The 2024 edition features updated code examples and an improved GitHub repository. Purchase of the print or Kindle book includes a free PDF eBook. Key FeaturesLearn how to leverage LangChain to work around LLMs’ inherent weaknessesDelve into LLMs with LangChain and explore their fundamentals, ethical dimensions, and application challengesGet better at using ChatGPT and GPT models, from heuristics and training to scalable deployment, empowering you to transform ideas into realityBook DescriptionChatGPT and the GPT models by OpenAI have brought about a revolution not only in how we write and research but also in how we can process information. This book discusses the functioning, capabilities, and limitations of LLMs underlying chat systems, including ChatGPT and Gemini. It demonstrates, in a series of practical examples, how to use the LangChain framework to build production-ready and responsive LLM applications for tasks ranging from customer support to software development assistance and data analysis – illustrating the expansive utility of LLMs in real-world applications. Unlock the full potential of LLMs within your projects as you navigate through guidance on fine-tuning, prompt engineering, and best practices for deployment and monitoring in production environments. Whether you're building creative writing tools, developing sophisticated chatbots, or crafting cutting-edge software development aids, this book will be your roadmap to mastering the transformative power of generative AI with confidence and creativity.What you will learnCreate LLM apps with LangChain, like question-answering systems and chatbotsUnderstand transformer models and attention mechanismsAutomate data analysis and visualization using pandas and PythonGrasp prompt engineering to improve performanceFine-tune LLMs and get to know the tools to unleash their powerDeploy LLMs as a service with LangChain and apply evaluation strategiesPrivately interact with documents using open-source LLMs to prevent data leaksWho this book is forThe book is for developers, researchers, and anyone interested in learning more about LangChain. Whether you are a beginner or an experienced developer, this book will serve as a valuable resource if you want to get the most out of LLMs using LangChain. Basic knowledge of Python is a prerequisite, while prior exposure to machine learning will help you follow along more easily.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835088364},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10718332},}@INPROCEEDINGS{9952762,
  author={Jin, Kyohoon and Lee, Junho and Choi, Juhwan and Jang, Soojin and Kim, Youngbin},
  booktitle={2022 13th International Conference on Information and Communication Technology Convergence (ICTC)}, 
  title={Generative Data Augmentation via Wasserstein Autoencoder for Text Classification}, 
  year={2022},
  volume={},
  number={},
  pages={603-607},
  abstract={Generative latent variable models are commonly used in text generation and augmentation. However generative latent variable models such as the variational autoencoder(VAE) experience a posterior collapse problem ignoring learning for a subset of latent variables during training. In particular, this phenomenon frequently occurs when the VAE is applied to natural language processing, which may degrade the reconstruction performance. In this paper, we propose a data augmentation method based on the pre-trained language model (PLM) using the Wasserstein autoencoder (WAE) structure. The WAE was used to prevent a posterior collapse in the generative model, and the PLM was placed in the encoder and decoder to improve the augmentation performance. We evaluated the proposed method on seven benchmark datasets and proved the augmentation effect.},
  keywords={Training;Degradation;Scalability;Text categorization;Diversity reception;Benchmark testing;Natural language processing;Text augmentation;Generative model;Text classification},
  doi={10.1109/ICTC55196.2022.9952762},
  ISSN={2162-1241},
  month={Oct},}@INPROCEEDINGS{10463281,
  author={Wyawahare, Medha and Nagdekar, Rutuja and Naik, Atharva},
  booktitle={2024 14th International Conference on Cloud Computing, Data Science & Engineering (Confluence)}, 
  title={CyberGuard - Guarding Against Deceptive Websites}, 
  year={2024},
  volume={},
  number={},
  pages={320-325},
  abstract={Phishing attacks pose a growing threat to online security, necessitating the development of highly accurate detection tools. Traditional methods reliant on webpage content features and third-party services often result in high false positives. This paper presents CyberGuard, a pioneering phishing detection model that exclusively leverages website URLs, mitigating the need for third-party services. The model harnesses deep learning, employing a Generative Adversarial Network (GAN) framework with LSTM for URL generation and CNN for discrimination.},
  keywords={Uniform resource locators;Deep learning;Phishing;Generative adversarial networks;Security;Long short term memory;Zero-hour attacks;Generative Adversial Networks (GAN);Neural networks;Phishing Detection},
  doi={10.1109/Confluence60223.2024.10463281},
  ISSN={2766-421X},
  month={Jan},}@INPROCEEDINGS{9924077,
  author={Remya Revi, K and Isaac, Meera Mary and Antony, Rahul and Wilscy, M.},
  booktitle={2022 International Conference on Connected Systems & Intelligence (CSI)}, 
  title={GAN-generated Fake Face Image Detection using Opponent Color Local Binary Pattern and Deep Learning Technique}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={Advancements in AI techniques like Generative Adversarial Network (GAN) facilitate the creation of realistic-looking fake face images and these images are used to create fake profiles on various social media platforms. In this work, we develop deep learning-based binary classification models to distinguish GAN-generated fake face images from camera-captured real face images. The classification models are developed by fine-tuning three lightweight state-of-the-art pre-trained Convolutional Neural Networks (CNNs) - GoogLeNet, ResNet-18, and MobileNet-v2 -using the transfer learning approach. In this method, instead of RGB images, joint color texture feature maps of the images obtained using Opponent Color-Local Binary Pattern (OC-LBP) are used as input to the CNN. For the experimental analysis, we use datasets that contain fake face images generated by Progressive Growing GAN (PGGAN) and Style-based GAN (StyleGAN2), and camera-captured real face images from CelebFaces Attributes- High Quality (CelebA-HQ) and Flickr Faces High Quality (FFHQ) datasets. The proposed method shows remarkable performance in terms of test accuracy, generalization capability, and robustness against JPEG compression. Also, the method exhibits excellent performance when compared with state-of-the-art methods.},
  keywords={Deep learning;Image coding;Image color analysis;Social networking (online);Transfer learning;Transform coding;Generative adversarial networks;Generative adversarial network;convolutional neural network;deep learning;joint color texture feature;fake face images;social media},
  doi={10.1109/CSI54720.2022.9924077},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10531571,
  author={Yadav, Rashmi and Bhat, Aruna},
  booktitle={2024 2nd International Conference on Artificial Intelligence and Machine Learning Applications Theme: Healthcare and Internet of Things (AIMLA)}, 
  title={A Survey on Skin Lesion Detection and Classification using Machine Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The research explores how dermatologists use machine learning to quickly and accurately identify and classify skin injury. Conventional diagnosis techniques depend on visual examination, but are subjective and have different interpretations. The ability to analyze data and recognize patterns is a possible remedy for ML. The paper examines the current technology of machine learning, focusing on validation in the real world, and deals with data set variability. Although the research acknowledges the fruitfulness of deep learning (DL), the research emphasizes the benefits of traditional ML techniques regarding interpretation and processing performance. Methods for automating the analysis of skin lesions, such as feature engineering, rule-based techniques and traditional ML algorithms, have been studied. The study suggests using advanced transfer learning techniques, integrating genetic and clinical data, and refining the way artificial intelligence (AI) is explained in order to get over barriers. Intending to enhance the accessibility and correctness of skin lesion identification, the future requires collaboration between dermatology and machine learning to develop real-time diagnostic tools. By offering scalable solutions for rapid diagnosis of lesions and improved patient outcomes, this combination of medical expertise and ML capabilities has the power to revolutionize dermatology. The future of automated dermatological diagnosis is expected to be shaped by collaboration between machine learning experts and dermatologists, enabling more personalized treatment for patients.},
  keywords={Machine learning algorithms;Dermatology;Transfer learning;Collaboration;Machine learning;Genetics;Skin;skin lesion;machine learning;survey;deep learning;CNN},
  doi={10.1109/AIMLA59606.2024.10531571},
  ISSN={},
  month={March},}@INPROCEEDINGS{10092954,
  author={Nakazawa, Ryo and Premachandra, Chinthaka},
  booktitle={2022 2nd International Conference on Robotics, Automation and Artificial Intelligence (RAAI)}, 
  title={AI Based Biometrics Recognition with a Hyperspectral Image Sensor}, 
  year={2022},
  volume={},
  number={},
  pages={240-243},
  abstract={In information security, facial recognition technology is one of the most familiar authentication technologies in our daily life. However, the recent development in the field of Artificial Intelligence has made it easy to generate a human face image from a small number of images, which poses a threat to individual information security. This is known as deep faking, and is a problem for future information security. As a solution for this issue, we develop a face recognition technique based on highdimensional images using a hyperspectral sensor (HSI). Unlike ordinary two-dimensional sensors, the high-dimensional data acquired here is a huge cube-shaped data with spectral wavelength information. In order to perform authentication using highdimensional images, we generated images for each wavelength band by dividing the wavelength information into pseudo-bands and created classification models for each band. Inference is performed on a single high-dimensional image using multiple trained classification models, and authentication is based on the majority vote of the models. We confirmed the effectiveness of these methods through validation experiments.},
  keywords={Support vector machines;Image segmentation;Image recognition;Face recognition;Biological system modeling;Information security;Authentication;biometrics recognition;hyper spectral image;image segmentation;multiclass classification},
  doi={10.1109/RAAI56146.2022.10092954},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10803468,
  author={Khan, Yousef and Hamed, Ahmed Abdeen},
  booktitle={2024 IEEE International Conference on Medical Artificial Intelligence (MedAI)}, 
  title={Reinforcement Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses}, 
  year={2024},
  volume={},
  number={},
  pages={392-397},
  abstract={Addressing the global challenge of breast cancer, this research explores the fusion of generative AI and the intricacies of breast cancer risk assessment. This study seeks to bridge the technology gap between intelligent machines and clinicians by demonstrating ChatGPT's proficiency in reasoning. The methodology employs a supervised prompt-engineering approach to enforce detailed explanations for ChatGPT's recom-mendations. Synthetic use cases, generated algorithmi-cally, serve as the testing ground for the encoded rules, evaluating the model's processing prowess. Findings highlight ChatGPT's promising capacity in processing rules comparable to Expert System Shells, with a focus on natural language reasoning. The research introduces the concept of reinforcement explainability, showcasing its potential in elucidating outcomes and facilitating user-friendly interfaces for breast cancer risk assessment.},
  keywords={Bridges;Generative AI;Natural languages;Chatbots;Breast cancer;Cognition;Risk management;Expert systems;Testing;Reinforcement Explainability;Chat-GPT;Prompt Engineering;Breast Cancer},
  doi={10.1109/MedAI62885.2024.00059},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11146337,
  author={Townsend, Jake and Karabacak, Bilge and Clark, Ulku and Miller, Kasey and Alamleh, Hosam},
  booktitle={2025 IEEE 50th Conference on Local Computer Networks (LCN)}, 
  title={Designing a Maritime Cybersecurity Risk Intelligence Model with Generative AI and Real-Time Interviews}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={AI has disrupted all sectors, and the maritime industry is undergoing its own transformation. After reviewing 48 academic papers, the authors showed the need for a holistic and engaging cybersecurity risk analysis method and suggested a survey-based method called Cyber Risk Analysis Method for Maritime Transportation Systems (CRAMMTS). This study presents an AI-powered system for conducting risk analysis interviews with maritime entities, developed using LangChain, LangGraph and OpenAI’s GPT-4o in Python. The system uses external sources, such as Maritime Attack Database and CRAMMTS survey results, as a data source, evaluates each question/response pair in real-time, determining the necessity of follow-up questions and ensuring thorough risk coverage. The system stores the interview results, applies basic analysis, and generates recommendation statements for the entity. Retrieval augmented generation is employed to integrate current incidents and risk data into the analysis. Future expansion opportunities include automated analysis and the generation of comprehensive risk analysis documents with actionable recommendations. This approach not only aims to streamline and standardize the maritime risk analysis process but also reduce the cost barrier to cybersecurity resources using advanced language models.},
  keywords={Surveys;Text analysis;Generative AI;Computational modeling;Soft sensors;Transportation;Real-time systems;Risk analysis;Interviews;Computer security;Maritime Cybersecurity;Large Language Models;Risk Intelligence;Generative AI;Real-Time Interviews},
  doi={10.1109/LCN65610.2025.11146337},
  ISSN={2832-1421},
  month={Oct},}@INBOOK{10953150,
  author={Savoie, Christopher},
  booktitle={Convergence: Artificial Intelligence and Quantum Computing: Social, Economic, and Policy Impacts}, 
  title={Quantum Computing's Beautiful Accidents}, 
  year={2023},
  volume={},
  number={},
  pages={213-220},
  abstract={Summary <p>Quantum computation has the great potential to revolutionize business and life in myriad ways, and at a level that civilization has yet to experience. In the next decade&#x2014;even the next several years&#x2014;we will likely see quantum computing's impact unfold first in the fields of artificial intelligence (AI) and machine learning (ML). Though quantum computing continues to evolve, the actual devices are not yet faster than their classical counterparts. The important takeaway is that quantum's main role will be as a force multiplier to existing AI and ML solutions. In fact, we have already entered a regime in which quantum devices, in certain, extreme edge case circumstances, can outperform their classical counterparts. This is referred to as quantum supremacy. Quantum computing will give us the computing horsepower to address the dimensionality of this interconnectedness of myriad variables in intertwined complex systems.</p>},
  keywords={Quantum computing;Computers;Accuracy;Computational modeling;Machine learning;Force;Complexity theory;Pandemics;Convergence;Accidents},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394174126},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10953150},}@INPROCEEDINGS{9754643,
  author={Liu, Zirong and Lai, Zhihui and Gao, Can},
  booktitle={2021 IEEE 7th International Conference on Cloud Computing and Intelligent Systems (CCIS)}, 
  title={Multi-scale Defective Samples Synthesis for Surface Defect Detection}, 
  year={2021},
  volume={},
  number={},
  pages={224-229},
  abstract={Surface defect detection has received both academic and industrial attention in recent years. In real-world applications, it is usually difficult to collect defective samples since manual labeling is time-consuming and defective samples rarely appear. In this paper, we propose a novel method for multi-scale defective sample synthesis and detection. First, a Pairs Generative Adversarial Network (PairsGAN) is proposed for generating defects and their labels. To improve the generated quality of the defective area, we design a defect discriminator in PairsGAN to focuses on distinguishing the defective area. Then, a Multi-Scale Defect Fusion (MSDF) module is presented to diversify the generated defects with various scales and styles, which fuses them into normal samples in different locations, so as to obtain naturally defective samples and corresponding labels. Finally, generated samples are used as the inputs of the semantic segmentation network for defect detection. Experimental results demonstrate that our method achieves more stable and better segmentation results comparing to recent methods.},
  keywords={Cloud computing;Fuses;Conferences;Semantics;Manuals;Generative adversarial networks;Labeling;Surface defect detection;Deep learning;Generative adversarial network;Semantic Segmentation},
  doi={10.1109/CCIS53392.2021.9754643},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10607431,
  author={Gherghina, Ion-Stelian and Bizon, Nicu},
  booktitle={2024 16th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)}, 
  title={Detection, Prevention, and Monitoring Techniques for Industrial Equipment – a brief review}, 
  year={2024},
  volume={},
  number={},
  pages={1-14},
  abstract={Within the modern industry, the analysis and critical evaluation of existing techniques for the detection, prevention, and monitoring of industrial equipment are essential aspects for improving performance and operational efficiency. This study investigates innovative methods designed to enhance the reliability and accuracy of defect detection, with the main goal of optimizing maintenance programs and preventing failures within production processes. The analysis will focus on a diverse range of techniques, including methods based on signal acquisition and analysis, artificial intelligence, audio analyses, and image processing, as well as vibration analyses and other relevant techniques. Through comparison and critical evaluation of these techniques, this paper aims to provide a deep understanding of the advantages and limitations of each approach, as well as the context in which they are applicable in industrial practice. Through this study, a series of methods and technologies are pursued that contribute to the strengthening of knowledge in the field of monitoring industrial equipment and identifying future directions for research and development, aimed at the continuous improvement of performance and reliability.},
  keywords={Prevention and mitigation;Noise;Signal processing algorithms;Machine learning;Prediction algorithms;Data models;Maintenance;Detection;Prevention;Monitoring;Predictive Maintenance;Industrial Equipment;Signal Processing;Artificial Intelligence},
  doi={10.1109/ECAI61503.2024.10607431},
  ISSN={},
  month={June},}@INPROCEEDINGS{11058718,
  author={Guarrasi, Valerio and Di Feola, Francesco and Restivo, Rebecca and Tronchin, Lorenzo and Soda, Paolo},
  booktitle={2025 IEEE 38th International Symposium on Computer-Based Medical Systems (CBMS)}, 
  title={Whole-Body Image-to-Image Translation for a Virtual Scanner in a Healthcare Digital Twin}, 
  year={2025},
  volume={},
  number={},
  pages={528-534},
  abstract={Generating positron emission tomography (PET) images from computed tomography (CT) scans via deep learning offers a promising pathway to reduce radiation exposure and costs associated with PET imaging, improving patient care and accessibility to functional imaging. Whole-body image translation presents challenges due to anatomical heterogeneity, often limiting generalized models. We propose a framework that segments whole-body CT images into four regions, i.e., head, trunk, arms, and legs, and uses district-specific Generative Adversarial Networks (GANs) for tailored CT-to-PET translation. Synthetic PET images from each region are stitched together to reconstruct the whole-body scan. Comparisons with a baseline non-segmented GAN and experiments with Pix2Pix and CycleGAN architectures tested paired and unpaired scenarios. Quantitative evaluations at district, whole-body, and lesion levels demonstrated significant improvements with our district-specific GANs. Pix2Pix yielded superior metrics, ensuring precise, high-quality image synthesis. By addressing anatomical heterogeneity, this approach achieves state-of-the-art results in whole-body CT-to-PET translation. This methodology supports healthcare Digital Twins by enabling accurate virtual PET scans from CT data, creating virtual imaging representations to monitor, predict, and optimize health outcomes.},
  keywords={Measurement;Legged locomotion;Image segmentation;Translation;Computed tomography;Medical services;Generative adversarial networks;Digital twins;Positron emission tomography;Biomedical imaging;GANs;Digital Twins;Virtual Scanning;CT;PET;Image Translation},
  doi={10.1109/CBMS65348.2025.00114},
  ISSN={2372-9198},
  month={June},}@INPROCEEDINGS{10326358,
  author={Jo, Jinhoon and Lee, Sangho and Yun, Ghangmin and Lee, Kyuho},
  booktitle={2023 IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia)}, 
  title={An Energy-Efficient GAN Processor for Mobile Image Translation}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={An energy-efficient generative adversarial network (GAN) accelerator is proposed for mobile image-to-image translation. In image translation, low precision bits below 8 were not employed due to significant output image quality degradation. In addition, due to the zero injection of transposed convolution, effective PE utilization decreased up to 89%. To address these problems, this paper proposes two key features: 1) we apply layer-wise dynamic fixed-point quantization and implement bit-combined PE to increase throughput by 2×; 2) By analyzing the matching pattern of transposed convolution, data remapping for transposed convolution that simultaneously computes 4 outputs is proposed. The proposed processor is implemented on ZCU 104 FPGA, achieving energy efficiency of 76.38 GOPS/W while consuming 6.08 W of power for mobile image-to-image translation.},
  keywords={Image quality;Quantization (signal);Power demand;Convolution;Generative adversarial networks;Throughput;Energy efficiency;generative adversarial network (GAN);Image-to-image translation;FPGA},
  doi={10.1109/ICCE-Asia59966.2023.10326358},
  ISSN={},
  month={Oct},}@ARTICLE{9513560,
  author={Xu, Yiming and Liu, Xiaohong and Pan, Liyan and Mao, Xiaojian and Liang, Huiying and Wang, Guangyu and Chen, Ting},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Explainable Dynamic Multimodal Variational Autoencoder for the Prediction of Patients With Suspected Central Precocious Puberty}, 
  year={2022},
  volume={26},
  number={3},
  pages={1362-1373},
  abstract={Central precocious puberty (CPP) is the most common type of precocious puberty and has a significant effect on children. A gonadotropin-releasing hormone (GnRH)-stimulation test is the gold standard for confirming CPP. This test, however, is costly and unpleasant for patients. Therefore, it is critical to developing alternative methods for CPP diagnosis in order to alleviate patient suffering. This study aims to develop an artificial intelligence (AI) diagnostic system for predicting response to the GnRH-stimulation test using data from laboratory tests, electronic health records (EHRs), and pelvic ultrasonography and left-hand radiography reports. The challenges are in integrating these multimodal features into a comprehensive deep learning model in order to achieve an accurate diagnosis while also accounting for the missing or incomplete modalities. To begin, we developed a dynamic multimodal variational autoencoder (DMVAE) that can exploit intrinsic correlations between different modalities to impute features for missing modalities. Next, we combined features from all modalities to predict the outcome of a CPP diagnosis. The experimental results (AUROC 0.9086) demonstrate that our DMVAE model is superior to standard methods. Additionally, we showed that by setting appropriate operating thresholds, clinicians could diagnose about two-thirds of patients with confidence (1.0 specificity). Only about one-third of patients require confirmation of their diagnoses using GnRH (or GnRH analog)-stimulation tests. To interpret the results, we implemented an explainer Shapley additive explanation (SHAP) to analyze the local and global feature attributions.},
  keywords={Feature extraction;Biochemistry;Breast;Medical diagnostic imaging;Ultrasonography;Diagnostic radiography;Machine learning;Central precious puberty;dynamic multimodal variational autoencoder;generative model;deep learning;Shapley additive explanations},
  doi={10.1109/JBHI.2021.3103271},
  ISSN={2168-2208},
  month={March},}@ARTICLE{10502181,
  author={Zabeehullah and Arif, Fahim and Khan, Nauman Ali and Haq, Qazi Mazhar ul and Asim, Muhammad and Ahmad, Sadique},
  journal={IEEE Consumer Electronics Magazine}, 
  title={An SDN-AI-Based Approach for Detecting Anomalies in Imbalance Data Within a Network of Smart Medical Devices}, 
  year={2024},
  volume={13},
  number={6},
  pages={28-36},
  abstract={The Internet of Medical Things (IoMT) has become a novel paradigm for real-time healthcare applications. Artificial intelligence (AI) based efforts have been made to address the security challenges of IoMT, the problem of imbalance data still exists, due to which AI algorithms cannot sufficiently learn malicious traffic behavior and fail to identify rare anomalies in imbalance data accurately. Therefore, in this article, we propose an intelligent model based on software defined networking and deep learning (DL) to handle the heterogeneous, complex, and distributed architecture. To tackle the imbalance challenge, the proposed model utilizes generative adversarial network (GAN) to generate plausible synthetic data for minor class traffic. It combines autoencoder-driven DL models with reconstruction error and Wasserstein distance-based GAN. When compared to naive and advanced techniques, the proposed model produced noticeably better results on an imbalance dataset and outperformed these techniques by 4.78% and 4.54% in terms of accuracy and F1-score values, respectively.},
  keywords={Training;Data models;Long short term memory;Convolutional neural networks;Artificial intelligence;Synthetic data;Generative adversarial networks;Internet of Medical Things;Medical services;Software defined networking},
  doi={10.1109/MCE.2024.3389292},
  ISSN={2162-2256},
  month={Nov},}@ARTICLE{10564107,
  author={Nam, SangGyu and Hsueh, Chu-Hsuan and Rerkjirattikal, Pavinee and Ikeda, Kokolo},
  journal={IEEE Transactions on Games}, 
  title={Using Reinforcement Learning to Generate Levels of Super Mario Bros. With Quality and Diversity}, 
  year={2024},
  volume={16},
  number={4},
  pages={807-820},
  abstract={Procedural content generation (PCG) is essential in game development, automating content creation to meet various criteria such as playability, diversity, and quality. This article leverages reinforcement learning (RL) for PCG to generate Super Mario Bros. levels. We formulate the problem into a Markov decision process (MDP), with rewards defined using player enjoyment-based evaluation functions. Challenges in level representation and difficulty assessment are addressed by conditional generative adversarial networks and human-like artificial intelligence agents that mimic aspects of human input inaccuracies. This ensures that the generated levels are appropriately challenging from human perspectives. Furthermore, we enhance content quality through virtual simulation, which assigns rewards to intermediate actions to address a credit assignment problem. We also ensure diversity through a diversity-aware greedy policy, which chooses not-bad-but-distant actions based on $Q$-values. These processes ensure the production of diverse and high-quality Super Mario levels. Human subject evaluations revealed that levels generated from our approach exhibit natural connection, appropriate difficulty, nonmonotony, and diversity, highlighting the effectiveness of our proposed methods. The novelty of our work lies in the innovative solutions we propose to address challenges encountered in employing the PCG via RL method in Super Mario Bros., contributing to the field of PCG for game development.},
  keywords={Games;Artificial intelligence;Genetic algorithms;Entertainment industry;Reinforcement learning;Layout;Generative adversarial networks;Procedural content generation (PCG);quality and diversity;reinforcement learning (RL);Super Mario Bros},
  doi={10.1109/TG.2024.3416472},
  ISSN={2475-1510},
  month={Dec},}@INPROCEEDINGS{10245906,
  author={Luo, Qing and Zeng, Wei and Chen, Manni and Peng, Gang and Yuan, Xiaofeng and Yin, Qiang},
  booktitle={2023 IEEE 6th International Conference on Electronic Information and Communication Technology (ICEICT)}, 
  title={Self-Attention and Transformers: Driving the Evolution of Large Language Models}, 
  year={2023},
  volume={},
  number={},
  pages={401-405},
  abstract={Transformers, originally introduced for machine translation, and built upon the Self-Attention mechanism, have undergone a remarkable evolution, establishing themselves as the bedrock of large language models (LLMs). Their unparalleled capacity to model intricate relationships and capture extensive dependencies within sequences has propelled their prominence. This article, presented in a popular science format, serves as an introduction to the transformer architecture, elucidating its innovative structure that enables efficient processing of long sequences and capturing dependencies over extended distances. We believe that this resource will prove valuable to college students or youth researchers aspiring to delve into the study and research of modern Artificial Intelligence (AI) domains.},
  keywords={Computer vision;Visualization;Technological innovation;Computational modeling;Transformers;Artificial intelligence;Task analysis;Self-Attention;transformer;large language model (LLM);natural language processing (NLP);generative pretrained transformer (GPT)},
  doi={10.1109/ICEICT57916.2023.10245906},
  ISSN={2836-7782},
  month={July},}@INPROCEEDINGS{10578884,
  author={Ambikairajah, Eliathamby and Sirojan, Tharmakulasingam and Thiruvaran, Tharmarajah and Sethu, Vidhyasaharan},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={ChatGPT in the Classroom: A Shift in Engineering Design Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Artificial intelligence tools like ChatGPT are increasingly being incorporated into our education paradigm. This paper explores how ChatGPT was used in an Electrical Engineering Design Proficiency course at the University of New South Wales in Sydney. The course is a term-long laboratory-based class that centres on independent student work in system design, implementation, and validation. Students were encouraged to consult ChatGPT for design solutions, explanations, and suggestions, with the requirement that they declare any use of AI tools. The assessment process was carefully designed to determine whether responses originated from AI tools or the students' own understanding. Notably, 70% of the fifty students in the class utilised ChatGPT to enhance their understanding of the subject. The paper will also discuss the specific design tasks given to students, the assessment process, and explore ChatGPT's potential as a supportive educational tool in other courses.},
  keywords={Industries;Electrical engineering;Codes;Debugging;Chatbots;Artificial intelligence;Task analysis;Generative AI;ChatGPT;Engineering Education;Engineering Design;Learning and Teaching},
  doi={10.1109/EDUCON60312.2024.10578884},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10260766,
  author={Nguyen-Duc, Anh and Arora, Chetan and Abrahamsson, Pekka},
  booktitle={2023 IEEE 31st International Requirements Engineering Conference Workshops (REW)}, 
  title={Preface of RESET 2023: 2nd International Workshop on Requirement Engineering for Software Startups and Emerging Technologies}, 
  year={2023},
  volume={},
  number={},
  pages={365-366},
  abstract={The Second International Workshop on Requirement Engineering for Software startups and Emerging Technologies (RESET) is a part of the 31st IEEE International Requirements Engineering Conference 2023, held on 4 September 2023. The workshop brought together requirements engineering researchers and practitioners to discuss the need for adapting conventional requirement engineering artifacts (i.e., requirement definition, metrics), processes and practices in developing and operating emerging technologies, including Software Startups, Artificial Intelligence (AI), Blockchain, and Quantum Computing. Participants gained insights into the RE practices, tools, techniques, and frameworks that can help them build scalable, robust, and innovative software-intensive systems. The workshop included a keynote presentation and four paper presentations.},
  keywords={Measurement;Quantum computing;Conferences;Software;Blockchains;Requirements engineering;Artificial intelligence;workshop summary;software startups;generative AI;blockhain;requirement engineering},
  doi={10.1109/REW57809.2023.00070},
  ISSN={2770-6834},
  month={Sep.},}@INPROCEEDINGS{10540818,
  author={Ranasinghe, Sajani and De Silva, Daswin and Mills, Nishan and Alahakoon, Damminda and Manic, Milos and Lim, Yen and Ranasinghe, Weranja},
  booktitle={2024 IEEE International Conference on Industrial Technology (ICIT)}, 
  title={Addressing the Productivity Paradox in Healthcare with Retrieval Augmented Generative AI Chatbots}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Artificial Intelligence (AI) is reshaping the health-care landscape through diverse innovations, personalisations and decision-making capabilities. The human-like intelligence of Generative AI has been fundamental in driving this transformation across the sector. Despite large investments and some early successes, several studies have signalled the emergence of a productivity paradox due to inherent limitations of Generative AI that disintegrate within the complexity of healthcare systems and operations. In this study, we investigate the capabilities of Retrieval Augmented Generation (RAG) and Generative AI chatbots in addressing some of these challenges. We present the design and development of a Retrieval Augmented Generative AI Chatbot framework for consultation summaries, diagnostic insights, and emotional assessments of patients. We further demonstrate the technical value of this framework in service innovation, patient engagement and workflow efficiencies that collectively move to address the productivity paradox of AI in healthcare.},
  keywords={Productivity;Technological innovation;Image resolution;Generative AI;Decision making;Medical services;Information processing;Artifical Intelligence;Generative AI;Retrieval Augmented Generation;Chatbot;Healthcare;Productivity Paradox;Digital Health},
  doi={10.1109/ICIT58233.2024.10540818},
  ISSN={2643-2978},
  month={March},}@INPROCEEDINGS{11100722,
  author={Jiang, Yihan and Xiang, Xinyu and Zhang, Xiurong},
  booktitle={2025 IEEE International Symposium on the Application of Artificial Intelligence in Electrical Engineering (AAIEE)}, 
  title={Review and Outlook on Deep Learning for High-Resolution Power Time Series Reconstruction}, 
  year={2025},
  volume={},
  number={},
  pages={256-260},
  abstract={High-resolution time series reconstruction is crucial for enhancing the utility of sparse or low-quality data, with broad applications in industrial monitoring, signal processing, and energy management. Advances in deep learning and physical modeling have propelled computer science and electrical engineering to develop diverse reconstruction techniques, yet their progress and paradigmatic differences remain unsystematically compared. This review contrasts these fields through methodological innovations and application scenarios, analyzing their technical characteristics and integration trends. By investigating the current state of interdisciplinary research, this study offers methodological guidance and practical insights for advancing high-resolution reconstruction of power time series, focusing on photovoltaic and grid-related data, with emphasis on improving computational efficiency and real-time applicability.},
  keywords={Electrical engineering;Deep learning;Computer science;Technological innovation;Reviews;Computational modeling;Time series analysis;Signal processing;Propulsion;Real-time systems;time series reconstruction;deep learning;generative models;computer science;electrical engineering},
  doi={10.1109/AAIEE64965.2025.11100722},
  ISSN={},
  month={April},}@ARTICLE{10298233,
  author={Pandey, Chandrasen and Tiwari, Vaibhav and Imoize, Agbotiname Lucky and Li, Chun-Ta and Lee, Cheng-Chi and Roy, Diptendu Sinha},
  journal={IEEE Access}, 
  title={5GT-GAN: Enhancing Data Augmentation for 5G-Enabled Mobile Edge Computing in Smart Cities}, 
  year={2023},
  volume={11},
  number={},
  pages={120983-120996},
  abstract={This paper introduces 5GT-GAN, a novel approach leveraging generative adversarial networks (GANs) to create synthetic mobile Internet traffic data, particularly tailored to smart city applications. Given the challenges of data scarcity and privacy concerns in the context of 5G, generating synthetic data becomes a crucial aspect for effectively deploying AI-driven systems in real-world scenarios. 5GT-GAN integrates unsupervised GAN schemes with the ability to manage temporal dynamics through supervised autoregressive models, successfully generating large-scale synthetic mobile Internet traffic data. Our experimental results illustrate the superior performance of 5GT-GAN in terms of mean squared error (MSE) and mean absolute error (MAE) compared to traditional models. The use of “Train Synthetic Test Real” (TSTR) and “Train Real Test Synthetic” (TRTS) methodologies affirmed the model’s effectiveness with (0.0023 MAE, 0.0074 MSE) and (0.0045 MAE, 0.0092 MSE) respectively. Moreover, the model’s runtime complexity of O(n log n) emphasized its efficiency in handling larger datasets, an edge over traditional models. The study also identifies potential future work in augmenting data for traffic prediction and integrating self-attention mechanisms to enhance the capabilities of the model further.},
  keywords={Synthetic data;Data models;5G mobile communication;Generative adversarial networks;Data privacy;Artificial intelligence;Edge computing;Internet of Things;5GT-GAN;smart city;multi-access edge computing (MEC);Internet of Things (IoT);generative adversarial networks;synthetic data},
  doi={10.1109/ACCESS.2023.3328170},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9696103,
  author={Du, Yinjie and Jip Yau, Cin},
  booktitle={2021 2nd International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE)}, 
  title={Handwriting Image Recognition Based on a GAN Model}, 
  year={2021},
  volume={},
  number={},
  pages={487-491},
  abstract={Big data is a new driver of world economic and societal changes. However, our research is based on using the GAN to solve the real application Deepfakes, which are created by artificial intelligence programmed to replace one person’s likeness with another in recorded video, photo, pr audio. To tackle this issue, this paper proposed a GAN model based handwriting image recognition which can be generated new celebrities after showing it pictures of many real celebrities. Typically, Deepfakes are made using a neural network-based architecture, the most capable of which utilizes generative adversarial networks (GANs). This involves placing two neural networks in contest with one another: the first new data from the same statistical distribution as the training set, and the second attempts to discriminate data produced by the first from data in the original training set. The experimental results demonstrated that using the GAN model to solve Deepfakes can give individuals new tools for self-expression and integration in the online world.},
  keywords={Training;Handwriting recognition;Image recognition;Computational modeling;Graphics processing units;Generative adversarial networks;Cost function;Handwriting image recognition;GAN model;Deepfake},
  doi={10.1109/ICBASE53849.2021.00097},
  ISSN={},
  month={Sep.},}@BOOK{10769333,
  author={Weaver-Lambert, Lisa},
  booktitle={The AI Value Playbook: How to make AI work in the real world},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Learn from real-world examples how leveraging AI, including machine learning and generative AI, is imperative for businesses to navigate risk, drive value, and gain a competitive advantageKey FeaturesUnderstand machine learning and generative AI terminology, concepts, and the AI technology stack.Learn from diverse real-world case studies narrated by business leaders in their own voice.Apply a value-driven approach to AI applications across multiple business sectors.Book DescriptionBusiness leaders are challenged by the speed of AI innovation and how to navigate disruption and uncertainty. This book is a crucial resource for those who want to understand how to leverage AI to drive business value, drawn from the firsthand experience of those who have been implementing this technology successfully. The AI Value Playbook focuses on questions frequently posed by leaders and boards. How can businesses adapt to these emerging technologies? How can they start building and deploying AI as a strategic asset to drive efficiency? What risks or threats need to be considered? How quickly can value be created? This book is a response to those demands. In a series of in-depth and wide-ranging conversations with practitioners, from CEOs leading new generative AI-based companies to Data Scientists and CFOs working in more traditional companies. Our experts share their hard-earned wisdom, talking candidly about their successes and failures, and what excites them about the future. These interviews offer unique insights for business leaders to apply to their own organizations. The book distils a value-driven playbook for how AI can be put to work today.What you will learnFundamentals of AI concepts and the tech stackHow AI works with real-world practical applicationsHow to integrate into your company's overall strategyHow to incorporate generative AI in your processesHow to drive value with sector-wide examplesHow to organize an AI-driven operating modelHow to use AI for competitive advantageThe dos and don'ts of AI applicationWho this book is forThe AI Value Playbook is aimed at supporting non-technical executives and board members to quickly formulate a perspective on how to integrate AI. This book addresses the gap in data and AI knowledge in leadership teams that have an appetite for nuanced, targeted and practical solutions. It includes which levers and processes to consider to future-proof their business. It speaks to an audience interested in understanding how AI can drive value for their organisations.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835467596},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10769333},}@INPROCEEDINGS{9715407,
  author={Barra Montevechi, José Arnaldo and Campos, Afonso Teberga and Gabriel, Gustavo Teodoro and dos Santos, Carlos Henrique},
  booktitle={2021 Winter Simulation Conference (WSC)}, 
  title={Input Data Modeling: An Approach Using Generative Adversarial Networks}, 
  year={2021},
  volume={},
  number={},
  pages={1-12},
  abstract={Input data modeling varies according to the modeler's objectives and may be a simple or complex task. Despite great advances in data collection techniques, the input data analysis remains a challenge, especially when the input data is complex and cannot be modeled by standard solutions offered by commercial simulation software. Therefore, this paper focuses on how Generative Adversarial Networks (GANs) may support input data modeling, especially when traditional approaches are insufficient or inefficient. We evaluate the adoption of GANs for modeling correlated data as well as independent and identically distributed data. As results, GAN input models were able to generate highly accurate synthetic samples (average accuracies> 97.0%). For univariate distributions, we found no significant difference between standard and GAN input models performances. On the other hand, for correlated data, GAN input models outperformed standard ones. The most relevant accuracy gain was observed for the bivariate normal.},
  keywords={Training;Analytical models;Data analysis;Fitting;Distributed databases;Data collection;Generative adversarial networks},
  doi={10.1109/WSC52266.2021.9715407},
  ISSN={1558-4305},
  month={Dec},}@ARTICLE{10729262,
  author={Jiang, Xingguo and Zhang, Yuchao and Lin, Guojun and Yu, Ling},
  journal={IEEE Access}, 
  title={Music Emotion Recognition Based on Deep Learning: A Review}, 
  year={2024},
  volume={12},
  number={},
  pages={157716-157745},
  abstract={In recent years, with the development of the digital era, music emotion recognition technology has been widely used in the fields of music recommendation system, music classification, psychotherapy, music visualization, background music generation, smart home, and other applications of music emotion recognition, and has received attention from all walks of life. Especially the rapid development of artificial intelligence and deep learning, the music emotion recognition model using efficient deep neural network composition has become the mainstream model. This paper provides a more detailed overview of music emotion recognition, first introducing the background of music and emotion, and briefly summarizing the content of related works as well as the content framework. In the process, we also compare the similarities and differences in the content of other researchers’ reviews of related research areas. And in the middle section, we provide a detailed account of datasets, emotion models, feature extraction, and emotion recognition algorithms. Finally, we discuss the current challenges in music emotion recognition and explore future research priorities.},
  keywords={Emotion recognition;Reviews;Music;Feature extraction;Deep learning;Brain modeling;Speech recognition;Machine learning algorithms;Visualization;Support vector machines;Artificial intelligence;Music emotion recognition;deep learning;artificial intelligence;music emotion datasets},
  doi={10.1109/ACCESS.2024.3484470},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10939855,
  author={Madunuri, Ram and Yellepeddi, Sai Manoj and Ravi, Chetan Sasidhar and Chitta, Subrahmanyasarma and Bonam, Venkata Sri Manoj and Vangoor, Vinay Kumar Reddy},
  booktitle={2024 Asian Conference on Intelligent Technologies (ACOIT)}, 
  title={AI-Enhanced Drug Discovery Accelerating the Identification of Potential Therapeutic Compounds}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper aims to propose the Enhanced Artificial Intelligence (EAI) approach to improve the speed of the identification of possible therapeutic agents in the process of drug discovery. Pharmacophore based methods are proven to have certain drawbacks like very high cost, huge time consumption and low hit rates. To overcome with these challenges the proposed system employs the sophisticated technologies of machine learning and deep learning. The general approach entails vast data gathering, preprocessing, and efficient feature extraction techniques and the use of various machine learning models such as Support Vector Machines (SVM), Random Forest (RF), Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN). The main advantage of the presented approach is the ability to compare it with traditional ones and highlight the advantages in terms of data processing, higher accuracy and less time consumption, as well as predictive accuracy. The experimental results presented also establish CNN with an accuracy of $92 \%$, the effectiveness of computational methods and blowing superiority in the experimental verifications. Such study also implies that the proposed approach with EAI integration has a huge potential of cutting on the cost and time taken in the overall process of drug discovery. This paper also discusses the possibilities for application of improved AI methods and enlargement of the existing data sets to improve the functionality of the system in the future.},
  keywords={Support vector machines;Accuracy;Recurrent neural networks;Costs;Feature extraction;Data models;Drug discovery;Convolutional neural networks;Compounds;Random forests;EAI (Enhanced Artificial Intelligence);Drug discovery;Therapeutic compounds;Machine learning;Computational biology;Pharmacology;Predictive modelling;Data preprocessing;Algorithm development;Biomedical research},
  doi={10.1109/ACOIT62457.2024.10939855},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11135299,
  author={Nejari, Aya and Badaoui, Abdelmounaim and Elmounadi, Abdelali and Berbiche, Naoual},
  booktitle={2025 International Conference on Circuit, Systems and Communication (ICCSC)}, 
  title={AI-Driven IoT Security: A Comprehensive Review on Current Trends and Future Perspectives}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The rapid expansion of Internet of Things (IoT) usage has introduced multiple security challenges, necessitating strong protection strategies. Artificial Intelligence (AI) has emerged as a powerful solution to strengthen IoT network security through intelligent threat management. This paper aims to present an in-depth review of recent research on AI-driven IoT security, with a particular emphasis on the latest developments and techniques. Through the analysis of Intrusion Detection Systems (IDS) and AI-based security approaches, we show how they can be applied to detect and counter cyberattacks. Furthermore, we assess the advantages and limitations of these approaches by examining performance indicators such as accuracy, precision, recall, and Fl-score. From our findings, we suggest that it is crucial to combine advanced techniques like autoencoders and hybrid learning strategies to improve the security features of IoT environments. At last, we discuss the future research perspectives, and underline the importance of the design of adaptive and lightweight AI models for IoT security.},
  keywords={Deep learning;Reviews;Intrusion detection;Network security;Market research;Security;Internet of Things;Hybrid learning;Protection;Integrated circuit modeling;Artificial Intelligence;Machine Learning;Deep Learning;Internet of Things;Cybersecurity;Intrusion Detection Systems},
  doi={10.1109/ICCSC66714.2025.11135299},
  ISSN={},
  month={June},}
