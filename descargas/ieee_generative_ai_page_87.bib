@INPROCEEDINGS{11163044,
  author={Lv, Chunhong and Yue, Hu and Liu, Jianguo and Xie, Yixun and Cao, Zeding and Zhou, Rong and Wan, Juan},
  booktitle={2025 IEEE 12th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={Fault Diagnosis and State Prediction of Power Transformer Based on Deep Learning Methods}, 
  year={2025},
  volume={12},
  number={},
  pages={817-821},
  abstract={This study proposes an integrated framework for fault diagnosis and state prediction of power transformers by leveraging deep learning methods. The framework combines a Transformer-Based model for time-series forecasting of oil chromatography data and a multilayer perceptron (MLP) classifier for fault diagnosis. To address data imbalance in chromatography datasets, GANs synthesize realistic minority-class samples, enhancing the classifier’s generalization capability. Experimental results demonstrate the Transformer’s superiority in predicting gas concentrations, achieving a mean squared error (MSE) of 5.69 × 10−6 for 5-day forecasts and 7.34 × 10−6 for 10-day forecasts. For fault classification, GAN-augmented MLP attains 94.10% accuracy. This work underscores the potential of data-driven approaches in advancing transformer states monitoring, offering scalable solutions for predictive maintenance in power systems.},
  keywords={Fault diagnosis;Deep learning;Accuracy;Oils;Oil insulation;Predictive models;Data models;Real-time systems;Power transformers;Monitoring;Power Transformer;Fault diagnosis;State pre-diction;Deep learning;Transformer;GAN},
  doi={10.1109/ITAIC64559.2025.11163044},
  ISSN={2693-2865},
  month={May},}@INPROCEEDINGS{10827452,
  author={He, Zijin and Zeng, Xiaodong},
  booktitle={2024 7th International Conference on Pattern Recognition and Artificial Intelligence (PRAI)}, 
  title={Advanced Modulation Recognition with CResNet for Mining Complex Information}, 
  year={2024},
  volume={},
  number={},
  pages={973-976},
  abstract={Automatic modulation recognition is a key technology in the field of cognitive radio, which plays an important role in civil and military fields. In recent years, the increasing number of signal modulation types and the increasing complexity of the communication electromagnetic environment have brought great challenges to automatic modulation identification. In this paper, we introduce a novel automatic modulation recognition (AMR) system, the Complex-convolution Residual Network (CResNet), tailored for accurately identifying modulation modes in challenging low signal-to-noise ratio (SNR) conditions. This model incorporates a complex module at the input layer to capture the key comple features of radio signals, including signal phase and amplitude nuances. Key enhancements include the use of complex Adam optimizer, which bolster feature discernment of the complex radio signal. Our evaluation on the RadioML2016.10a dataset demonstrates robust performance across SNR levels, achieving a notable 0.59 average all-SNR accuracy and over 0.82 accuracy in >0 dB environment. It shows superior performance compared to traditional and contemporary AMR models, particularly in challenging low SNR conditions, highlighting the model's robustness and adaptability in complex electromagnetic environments, providing a solid foundation for future research and applications in advanced complex signal processing and recognition tasks.},
  keywords={Solid modeling;Adaptation models;Technological innovation;Accuracy;Modulation;Solids;Robustness;Electromagnetics;Signal to noise ratio;Residual neural networks;AMR;Complex Convolution;ResNet;Complex Adam optimizer},
  doi={10.1109/PRAI62207.2024.10827452},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9836728,
  author={Hao, Xu and Shoucheng, Shen and Yujie, Jiang},
  booktitle={2022 IEEE 10th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={Pollen texture migration deblurring method based on self-coding generator}, 
  year={2022},
  volume={10},
  number={},
  pages={1269-1273},
  abstract={Image deblurring is a classical problem in the field of computer vision. The purpose of this paper is to restore the multi-layer pollen image into an image with clear texture when the fuzzy kernel is unknown. In this paper, a pollen texture migration deblurring network based on self-coding generator is designed, which uses the maximum similar texture information between adjacent layers of pollen to recover clear pollen layer by layer. A pollen image deblurring method based on texture migration DeblurGAN of countermeasure generation network is proposed. The texture migration network is used as the recovery network, and the residual pair information is extracted by the residual block in the encoder to simplify the training. Secondly, the jump connection layer is used to retain the information to remove the color offset, and the deconvolution layer of the generator is improved into the alternating layer of nearest neighbor interpolation and convolution, which can help to remove the checkerboard error. Finally, a layer of convolution is used to reconstruct the feature image. The algorithm is evaluated on multi-layer pollen data sets. From the evaluation index and subjective effect, it can be seen that the method proposed in this paper has stronger image restoration ability, retains rich texture information, and can effectively improve the image deblurring effect.},
  keywords={Training;Convolution;Stability criteria;Feature extraction;Generators;Image restoration;Indexes;multi-layer pollen image deblurring;Texture migration;Alternately connecting the residual layer},
  doi={10.1109/ITAIC54216.2022.9836728},
  ISSN={2693-2865},
  month={June},}@INPROCEEDINGS{9544189,
  author={Ma, XinNa and Qi, Lin and Zhao, Meng},
  booktitle={2021 International Conference on Computer Engineering and Artificial Intelligence (ICCEAI)}, 
  title={Bearing fault diagnosis based on attention mechanism and deep residual network}, 
  year={2021},
  volume={},
  number={},
  pages={286-290},
  abstract={A bearing fault diagnosis model based on the deep residual network is proposed for the situation that the model recognition rate is low and the classification effect is poor due to the large difference of fault sample distribution in the actual working condition. Firstly the collected bearing fault signals are constructed as fault samples, reconstructs the one-dimensional time series signals into grayscale maps, and initially obtains the input data which is suitable for the deep residual network. To solve the situation of insufficient effective samples, data augmentation by sliding sampling is used to expand the bearing vibration dataset; the samples are further divided into training and testing sets as the input of ResNet101, and data normalization is used to make the training and testing sets learn the same distribution to shorten the training time; then a hybrid attention mechanism is introduced at the appropriate parts to effectively suppress the redundant features and enhance the feature extraction capability of the model. And then a softmax classifier is used for fault classification to achieve intelligent fault diagnosis of rolling bearings. Finally, the Western Reserve University bearing dataset (CWRU) is used to verify the effectiveness of the model. The experimental results show that the proposed bearing fault diagnosis method based on hybrid attention mechanism and residual network can achieve more than 99 % diagnostic accuracy, and it achieves good generalization performance on the high-speed rail wheel pair dataset with an accuracy above 94 %.},
  keywords={Training;Fault diagnosis;Vibrations;Wheels;Gray-scale;Feature extraction;Rail transportation;deep learning;deep residual networks;fault diagnosis;rolling bearings;grayscale map},
  doi={10.1109/ICCEAI52939.2021.00057},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9459085,
  author={Wang, Siqing and Li, Deqi and Zhang, Xin and Zhang, Shutao},
  booktitle={2021 4th International Conference on Artificial Intelligence and Big Data (ICAIBD)}, 
  title={Weighted Cross-Product Constraint Transformation to Optimize Spatial Structure of Data}, 
  year={2021},
  volume={},
  number={},
  pages={27-31},
  abstract={The research of data spatial structure optimization is significant in data mining. Many methods optimize the space based on a specific criterion, which in a certain extent destroys the original spatial distribution of data with uncertain optimization effects. Based on the heterogeneous distribution spatial structure of the data and the importance of the data attributes to distinguish categories, we proposed the weighted cross-product constraint transformation (WCCT) method to improve the accuracy of data analysis. This method retains the spatial distribution of the original data and maps the data to a limited high-dimensional space with constraints, which increases the proximity between the same data category and the discrimination between different data categories. Moreover, we established a statistical evaluation system of spatial structure to prove the effectiveness of this method in optimizing the spatial structure of data attributes. Experimental analysis on real data demonstrates that the proposed method obtains excellent classification performance with different machine learning classifiers.},
  keywords={Graphical models;Data analysis;Machine learning;Big Data;Spatial databases;Data mining;Optimization;cross-product constraint transformation;attribute importance;optimization of spatial structure;data mining},
  doi={10.1109/ICAIBD51990.2021.9459085},
  ISSN={},
  month={May},}@INPROCEEDINGS{10281212,
  author={Jin, Mingxin and Li, Huifang},
  booktitle={2023 4th International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)}, 
  title={Feature-Aligned Feature Pyramid Network and Center-Assisted Anchor Matching for Small Face Detection}, 
  year={2023},
  volume={},
  number={},
  pages={198-204},
  abstract={The performance of face detection has made great progress with the rapid development of deep learning. However, small faces only contain an extremely limited number of pixels, which makes them suffer from poor feature representation and low-quality positive anchors. These problems make small face detection still a highly challenging task In this paper, we conduct an in-depth study from the perspective of feature learning and anchor matching and present a small-scale aware face detector (SFDet), which can accurately detect small faces. Specifically, we first propose a feature alignment module (FAM), which learns the semantic transformation offset and adaptively upsamples features using it as a guide. FAM can construct a powerful feature pyramid to learn more discriminative and robust feature representation of small faces. Then, we design an IoU-and-center based anchor matching strategy (ICAMS), which introduces center point information as a new matching metric to complement the traditional intersection over union (IoU) metric and simultaneously uses these two metrics in the anchor matching stage. ICAMS can ensure the generation of high-quality positive anchors of small faces. Comprehensive experiments are conducted on two challenging face detection datasets, and the results demonstrate the effectiveness of our method.},
  keywords={Measurement;Representation learning;Fuses;Semantics;Detectors;Feature extraction;Face detection;small face detection;feature alignment;anchor matching},
  doi={10.1109/ICBAIE59714.2023.10281212},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10920598,
  author={Chen, Tianming and Wang, Manyi and Wang, Daye},
  booktitle={2024 International Conference on Sensing, Measurement & Data Analytics in the era of Artificial Intelligence (ICSMD)}, 
  title={Application of Edge Computing Based on MultiScale Convolutional Neural Networks in Gear Fault Diagnosis}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Gear fault diagnosis plays a crucial role in detecting gear faults promptly, enabling timely repairs or replacements to minimize potential losses. While deep learning-based methods have been widely used for gear fault diagnosis, their effective application in real-world industrial environments remains a challenge. In this paper, we introduce a novel approach that combines a multi-scale convolutional neural network with multiknowledge distillation (MSCNN-MKD). This approach is deployed on edge computing nodes for online gear fault diagnosis. Experiments results validate the effectiveness of our proposed methodology. The proposed method achieves an accuracy of 98.76% in recognizing 7 fault categories. Additionally, the number of parameters is 18.54K, the floating-point operations are 41.54M, and the average inference time is 1.07ms. The methodology has great potential for practical industrial applications in gear faults diagnosis.},
  keywords={Fault diagnosis;Learning systems;Accuracy;Data analysis;Gears;Computational modeling;Computer architecture;Maintenance engineering;Convolutional neural networks;Edge computing;gear fault diagnosis;multi-scale feature;edge computing;convolutional neural networks (CNN)},
  doi={10.1109/ICSMD64214.2024.10920598},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10421670,
  author={K, Suresh and Radha, J and T, Thilagaraj and R, Subramani and Lakineni, Prasanna Kumar and Taqui, Syed Noeman},
  booktitle={2023 International Conference on Communication, Security and Artificial Intelligence (ICCSAI)}, 
  title={Leveraging Model Distillation as a Defense Against Adversarial Attacks Based on Deep Learning}, 
  year={2023},
  volume={},
  number={},
  pages={921-925},
  abstract={Adversarial attacks on deep learning models threaten machine learning system security and reliability. The above attacks use modest data alterations to produce erroneous model results while being undetected by humans. This work suggests model distillation to prevent adversarial perturbations. The student model is taught to emulate the teacher model in model distillation. This is done using teacher model soft outputs. Our idea is that this strategy organically strengthens the student model against adversarial assaults by keeping the teacher model's essential knowledge and generalization capabilities while reducing weaknesses. Distilled models are more resilient to adversarial assaults than non-distilled models, according to experiments. These models also perform similarly on undamaged, uncorrupted data. The results show that model distillation may be a powerful defense against machine learning adversaries. This method protects model resilience and performance.},
  keywords={Deep learning;Adaptation models;Technological innovation;Data models;Robustness;Safety;Security;Model Distillation;Adversarial Attacks;Deep Learning;Defensive Approach;Machine Learning},
  doi={10.1109/ICCSAI59793.2023.10421670},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9338817,
  author={Xu, Huanhuan and Li, Hongmei and Sun, Xuemei and Li, Fuyu},
  booktitle={2020 IEEE 9th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={A Method based on Spatial and Temporal Multi Grained Information for Gait Recognition}, 
  year={2020},
  volume={9},
  number={},
  pages={1316-1320},
  abstract={Gait recognition is one of the new biometric techniques. However, gait recognition is easily affected by external factors, resulting in a decrease in the accuracy. Therefore, this paper proposes a gait recognition method based on spatial and temporal multi grained information. This method uses hierarchical network to obtain different receptive fields, focusing on both shallow and deep features of gait. In addition, more spatial and temporal information can be saved to improve the accuracy of gait recognition. Finally, the proposed method is experimentally verified on the CASIA-B dataset. the experimental results show that the accuracy of the proposed method is greatly improved under normal walking, carrying bags and wearing coats.},
  keywords={Legged locomotion;Visualization;Conferences;Focusing;Feature extraction;Information technology;Gait recognition;gait recognition;multi grained;hierarchical;spatial and temporal information},
  doi={10.1109/ITAIC49862.2020.9338817},
  ISSN={2693-2865},
  month={Dec},}@INPROCEEDINGS{10581580,
  author={Yang, Junkang and Liu, Hongqing and Li, Xing and Jia, Jie},
  booktitle={2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={Speech Super Resolution and Noise Suppression System Using a Two-Stage Neural Network}, 
  year={2024},
  volume={},
  number={},
  pages={1171-1175},
  abstract={Super-resolution (SR) and noise suppression have been a hot research topic in the field of speech processing. Speech super-resolution, also named bandwidth extension (BWE), aims to extend the bandwidth of narrowband speech and improve its clarity, and noise suppression focuses on removing background noise from speech. Most of the past researches have performed these two tasks separately, while in the real world, bandwidth loss and noise exist almost simultaneously. Therefore, it is important to treat super-resolution and noise suppression jointly. In recent years, deep learning has made a big splash in the field of speech processing, and we see the promise of using deep learning techniques to solve this problem. In this paper, we propose a joint speech super-resolution and noise suppression method based on deep learning methods. Specifically, we use two networks to handle these two single tasks separately and then cascade them, we use multiple loss functions as well as multiplexing of the spectrogram, and the experiments show that our method outperforms the baselines.},
  keywords={Deep learning;Seminars;Superresolution;Noise reduction;Noise;Neural networks;Noise measurement;speech super-resolution;noise suppression;deep learning;multi-stage network},
  doi={10.1109/AINIT61980.2024.10581580},
  ISSN={},
  month={March},}@INPROCEEDINGS{11137824,
  author={Nie, Linhai and Wang, Jin and Hu, Naixuan},
  booktitle={2025 7th International Conference on Artificial Intelligence Technologies and Applications (ICAITA)}, 
  title={Feature Partitioning for Federated Learning with Momentum-Guided Aggregation}, 
  year={2025},
  volume={},
  number={},
  pages={439-443},
  abstract={Federated learning allows edge devices to collaboratively train deep models without uploading raw data, but one of its main challenges is the presence of non-independent and identically distributed (non-IID) data. Specifically, the varying data distributions across different clients result in slower convergence and reduced model accuracy during training. To confront this challenge, this paper proposes a method that partitions the features of raw data into sensitive and robust features. The sensitive features are used to generate noisy shared data, which is then uploaded to the server. The server trains on these pseudo images, while clients perform local training using the original data. Model parameters are aggregated and exchanged between the server and clients at predefined communication intervals. In addition, we adopt a momentum-guided initialization strategy for parameter aggregation. The experimental results show that the proposed method outperforms the state-of-the-art methods by $\mathbf{5. 3 1 \%}$ in terms of performance.},
  keywords={Training;Performance evaluation;Accuracy;Federated learning;Distributed databases;Data models;Servers;Noise measurement;Convergence;Testing;Federated Learning;Non-IID Data;Feature Partitioning;Gradient Momentum},
  doi={10.1109/ICAITA67588.2025.11137824},
  ISSN={},
  month={June},}@INPROCEEDINGS{10168597,
  author={Dong, Mengchuan and Zhou, Wei and Pang, Cong and Zhang, Xiangyu and Lou, Xin},
  booktitle={2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS)}, 
  title={Image Frequency Separation Residual Network for End-to-end RAW to RGB Mapping}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Due to the limitations of hardware specification of smartphones' camera system, there is still a visible gap in imaging quality between smartphones and digital singlelens reflex (DSLR) cameras. Sophisticated learning-based image processing becomes a promising solution to close this gap. In this paper, we propose an Image Frequency Separation Residual Network (IFS Net) to perform the end-to-end RAW to RGB image mapping. Different from existing methods that directly train the input image and the ground truth image one-to-one as a whole, our proposed method first divides the input image and the ground truth into high-frequency and low-frequency parts by discrete wavelet transform (DWT). These two parts are then trained separately using different networks for details and global information, and finally synthesized into the output image using inverse DWT. Experimental results show that the proposed IFS Net outperforms other existing algorithms in both PSNR and SSIM. Visual comparison shows that the images produces by IFS Net preserves more details and look close to that captured by DSLR cameras.},
  keywords={Visualization;Image color analysis;Neural networks;Signal processing algorithms;Transforms;Signal processing;Cameras;Image Signal Processing (ISP);learning-based ISP;smartphone camera;imaging},
  doi={10.1109/AICAS57966.2023.10168597},
  ISSN={2834-9857},
  month={June},}@INPROCEEDINGS{10067087,
  author={Moon, Jiwon and Song, Seunghwan and Baek, Jun-Geol},
  booktitle={2023 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Multivariate Time Series Anomaly Detection via Temporal Encoder with Normalizing Flow}, 
  year={2023},
  volume={},
  number={},
  pages={620-624},
  abstract={In the recent manufacturing process, as the introduction of smart factories spreads, high-dimensional data are being collected in real-time from various sensors of production facilities. However, existing anomaly detection models often do not reflect temporal factors, and even if they do, models that reflect temporal information are separately trained, resulting in a problem of falling into local optima. Therefore, it is very difficult to detect process anomalies in real-time by reflecting both correlations between high-dimensional variables and temporary dependency. This study proposes Temporal Encoder with Normalizing Flow (TENF), which can reflect both the correlation between variables and the time dependency in real-time using a relatively simple structure model. TENF consists of a Temporal Encoder for reflecting temporal dependencies and a NF Module for learning the distribution of high-dimensional data and is learned in an end-to-end manner. Experiments on multivariate time series data with similar characteristics to those generated in the manufacturing process demonstrate experimentally superior anomaly detection performance compared to existing models.},
  keywords={Manufacturing processes;Correlation;Time series analysis;Real-time systems;Production facilities;Data models;Noise measurement;Anomaly detection;long short term memory;normalizing flow;smart factory},
  doi={10.1109/ICAIIC57133.2023.10067087},
  ISSN={2831-6983},
  month={Feb},}@INPROCEEDINGS{8785558,
  author={Ke, Xianxin and Bai, Jiaojiao and Wen, Lei and Cao, Bin},
  booktitle={2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={Multi-index dialogue data cleaning model}, 
  year={2019},
  volume={},
  number={},
  pages={672-676},
  abstract={We proposed a multi-index dialogue data cleaning model. Our model has two distinctive characteristics: (1) it fuses multiple indices to build the model; (2) it applies two attention mechanisms when dealing with information of questions and answers, making the model's cleaning process more in line with human thinking process. The comparison experiment with the dual encoder model shows that the proposed architecture has higher accuracy. Moreover, the weight of the attention mechanism is in line with the human intuitive understanding and can highlight the key information of the sentence.},
  keywords={Data models;Training;Cleaning;Task analysis;Predictive models;Data mining;Indexes;NLP;dialogue data cleaning;multi-index;Data Purification Framework},
  doi={10.1109/ITAIC.2019.8785558},
  ISSN={},
  month={May},}@INPROCEEDINGS{10934613,
  author={Tu, Linfeng and Gu, Yuliang and Huang, Xiaobing and Wu, Xinchun},
  booktitle={2024 4th International Symposium on Artificial Intelligence and Intelligent Manufacturing (AIIM)}, 
  title={Lightweight Design of Image Denoising based on TNet mini}, 
  year={2024},
  volume={},
  number={},
  pages={646-649},
  abstract={Image denoising is vital in fields like autonomous driving and medical imaging to reduce noise while preserving quality. Traditional methods blur edges, and deep learning is computationally costly. This paper proposes TNet mini, a convolutional neural network based on denoising algorithm that balances denoising performance and efficiency. The algorithm introduces a network model that can be adapted to different application scenarios by selecting models of varying sizes. After training, the model is quantized from 32-bit to 8-bit, reducing storage requirements by 73% with only a slight decrease in denoising quality (PSNR drops by 0.215). The algorithm outperforms typical deep learning models in both performance and speed, making it suitable for deployment on edge devices. To address the high power consumption issues of commonly used convolutional neural network inference hardware, this paper designs a dedicated hardware accelerator for TNet mini network inference. The accelerator achieves 38.5135 GOPS/W energy efficiency, outperforming both the 2080Ti GPU (7.1429 GOPS/W) and i5-12400f CPU (2.5281 GOPS/W), offering up to 15.23 times better efficiency than the i5-12400f and 5.39 times better than the 2080Ti.},
  keywords={Training;Adaptation models;Convolution;Computational modeling;Noise reduction;Graphics processing units;Energy efficiency;Convolutional neural networks;Hardware acceleration;Image denoising;Image denoising;Convolutional Neural Network;Hardware Accelerator;FPGA},
  doi={10.1109/AIIM64537.2024.10934613},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11137832,
  author={Pears, Jack and Golcarenarenji, Gelayol},
  booktitle={2025 International Conference Automatics, Robotics and Artificial Intelligence (ICARAI)}, 
  title={An Explainable CNN-Based Approach for Classifying Desert Lions from Camera Trap Images}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The Desert Lion population plays a significant role in promoting tourism and is of considerable ecological interest. Camera traps are used to monitor the lions; however, manually evaluating this data is labor-intensive and time-consuming for conservationists. Hence, this study developed a computer vision system that improves upon the InceptionV3 architecture to classify Desert Lions from camera trap data, with a final accuracy of 97.7 percent on the Desert Lion dataset. The final system is validated on unseen data, achieving an accuracy of 85.9 percent. Grad-CAM was also included for explainability of the model output.},
  keywords={Deep learning;Computer vision;Accuracy;Biological system modeling;Robot vision systems;Wildlife;Computer architecture;Cameras;Deserts;Monitoring;Camera trap;Desert lion;Explainability;Wildlife conservation;Deep learning},
  doi={10.1109/ICARAI67046.2025.11137832},
  ISSN={},
  month={June},}@INPROCEEDINGS{11108727,
  author={Chen, Jianqing and Liu, Genggeng},
  booktitle={2025 IEEE 5th International Conference on Software Engineering and Artificial Intelligence (SEAI)}, 
  title={Multi-Task Learning for Routability Prediction}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={The rapid development of Very-Large-Scale-Integration (VLSI) has raised challenges to the scalability and reliability of Electronic Design Automation. Early-stage routability prediction can significantly accelerate the design process by assessing routing congestion and Design Rule Check (DRC) violations. While machine learning has become the mainstream approach, existing studies often focus on task-specific models, overlooking the correlation between congestion and DR C violations, and lacking cross-task generalization. To address these limitations, this work proposes a unified framework that combines a U-Net architecture with multi-task learning, enhanced by residual networks and attention mechanisms. Using shared chip features, the framework simultaneously predicts congestion and DRC violations, significantly reducing prediction time. Experimental results on the CircuitNet dataset show that the proposed method achieves competitive performance across both tasks, demonstrating its capability in capturing complex physical design characteristics.},
  keywords={Design automation;Correlation;Scalability;Computer architecture;Very large scale integration;Multitasking;Routing;Physical design;Software engineering;Residual neural networks;Machine learning;VLSI;Physical design;Routability prediction;Multi-task prediction},
  doi={10.1109/SEAI65851.2025.11108727},
  ISSN={},
  month={June},}@INPROCEEDINGS{9976817,
  author={Dai, Yun and Zhang, Ying and Yao, Yuan and Liu, Yi},
  booktitle={2022 4th International Conference on Industrial Artificial Intelligence (IAI)}, 
  title={Variational Adversarial Active Learning Assisted Process Soft Sensor Method}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={Soft sensor methods have been widely applied in process industries to predict key quality variables that cannot be measured online. However, labeled samples to construct models are often limited because quality variables are difficult to be obtained. Additionally, due to the instrument of redundant sensors, the process data is high-dimensional with strong correlations. In this paper, an active learning soft sensor framework named variational adversarial active learning (VAAL) is developed to select informative unlabeled samples to enhance prediction performance. The sampling strategy of VAAL learns a latent space using a variational autoencoder (VAE) and an adversarial network trained in a way of minimax game. The VAE tries to trick the adversarial network into predicting that all samples are from the labeled pool, while the adversarial network learns how to discriminate between dissimilarities in the latent space. The Gaussian process regression model is adopted in VAAL as a base soft sensor. The prediction results of an industrial debutanizer column demonstrate the advantages of VAAL as compared to the existing active learning strategies.},
  keywords={Industries;Correlation;Annotations;Soft sensors;Instruments;Gaussian processes;Games;active learning;soft sensor;variational autoencoder;Gaussian process regression},
  doi={10.1109/IAI55780.2022.9976817},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{11064046,
  author={Mishra, Aditya Dev and Singh, Youddha Beer and Dixit, Mayank and Pandey, Mahima Shanker},
  booktitle={2025 3rd International Conference on Communication, Security, and Artificial Intelligence (ICCSAI)}, 
  title={A Prescriptive Deep Leaning-Based Architecture for Deepfake Detection}, 
  year={2025},
  volume={3},
  number={},
  pages={177-180},
  abstract={Over the past few years, detecting and creating deepfakes has emerged as a prominent research challenge within the realm of deep learning. This technology enables the manipulation of audio, video, and facial features with remarkable realism, often disseminated on the internet for various purposes, including tarnishing individuals' reputations. Numerous studies have been conducted on both detecting and generating deepfake content generated by deep learning. This study aims to provide an overview of deepfake detection approaches, available datasets, and research obstacles within this domain. The objective of this study is to propose a deep-learning-based architecture for detecting deepfake images. Although several architectures are capable of detecting deepfakes, deep learning models demonstrate a significant advantage over traditional methods. This study offers a thorough overview of deepfake approaches, aiding in the development of new and more robust architecture to tackle the growing challenges posed by deepfakes.},
  keywords={Deep learning;Deepfakes;Explainable AI;Blockchains;Security;Facial features;Audio-visual systems;Deepfakes;Deep learning models;Ensemble model;Fake detection;Machine Learning},
  doi={10.1109/ICCSAI64074.2025.11064046},
  ISSN={},
  month={April},}@INPROCEEDINGS{9820049,
  author={Pan, Liwei and Gao, Yi and Zhou, Shixing and Chen, Jianxia},
  booktitle={2022 5th International Conference on Artificial Intelligence and Big Data (ICAIBD)}, 
  title={APRSR: Adversarial Personalized Ranking Modeling for Sequential Recommendation}, 
  year={2022},
  volume={},
  number={},
  pages={211-216},
  abstract={In recent years, the sequential recommendation achieves excellent results. But it also meets many challenges. For example, when we add adversarial perturbations to the input, the model’s performance might be weakened. To solve this problem, we propose a novel model named APRSR, Adversarial Personalized Ranking Modeling for Sequential Recommendation in short. APRSR model is designed based on a self-attention sequential recommendation model by adding adversarial perturbations. First, APRSR can learn local representation and the global representation respectively, then it can get the final representation by balancing the local representation and the global representation. In the meantime, it considers the influence of candidate items on user’s intent. To enhance the robustness and learn more expressive features, APRSR utilizes the idea of the adversarial matrix factorization which can generate the adversarial perturbations. Extensive experiments on five public real-world datasets demonstrate the effectiveness of APRSR and outperform those of other state-of-the-art models.},
  keywords={Perturbation methods;Machine learning;Big Data;Robustness;Data models;sequential recommendation;adversarial perturbations;adversarial machine learning},
  doi={10.1109/ICAIBD55127.2022.9820049},
  ISSN={},
  month={May},}@INPROCEEDINGS{10760574,
  author={Malathi, M. and Fernandez, F. Mary Harin},
  booktitle={2024 2nd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS)}, 
  title={Image Enhancment Hair Removal in Dermoscopy Images Using Dual Swin Autoencoder}, 
  year={2024},
  volume={},
  number={},
  pages={854-858},
  abstract={Skin cancer requires effective treatment for better survival rates especially in the case of melanoma. To reduce the image noise and removing hair the conventional method takes high computational complexity and decayed accuracy. In order to tackle this issue, an innovative dual Swin autoencoder has been proposed in this paper. This autoencoder utilizes Swin Transformer blocks to effectively eliminate noise from images and get rid of unwanted hair, all while maintaining important characteristics of the skin and lesions. Experimental results demonstrate that our model outperforms conventional techniques, with PSNR values up to 81.71 dB and SSIM up to 0.99, effectively eliminating hair and retaining important skin features. This approach enhances the accuracy of melanoma diagnosis in dermoscopy images.},
  keywords={Hair;Reflectivity;Accuracy;Optical microscopy;Optical coherence tomography;Melanoma;Transformers;Skin;Quality assessment;Lesions;Skin Cancer;Image Denoising;Dual Swin Autoencoder;Hair Removal;Image Quality Assessments},
  doi={10.1109/ICSSAS64001.2024.10760574},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9302741,
  author={Mu-Chien Hsu, Michael and Jui-Chun Shyur, Richard},
  booktitle={2020 International Conference on Pervasive Artificial Intelligence (ICPAI)}, 
  title={Using Segmentation to Enhance Frame Prediction in a Multi-Scale Spatial-Temporal Feature Extraction Network}, 
  year={2020},
  volume={},
  number={},
  pages={164-169},
  abstract={Designing a machine to predict future events is a challenging problem to even existing state-of-the-art approaches. It require great computation power either in adversarial training and in segmentation and optical flow. By combining conventional segmentation and the DNN we proposed in this paper, we have a simpler architecture which effectively and efficiently predicts both future frames and semantics more precise than the previous approaches. The input is a raw image sequence, and each frame of it is segmented for semantics, extracted for spatial features, analyzed for temporal features at different scales in a top down path; and then the prediction of frames and segmentation are synthesized in the bottom-up path. Results of our model show superiority of prediction to other state-of-the-art ones in (1) precision of frames, and (2) accuracy of segmentation masks.},
  keywords={Feature extraction;Image segmentation;Predictive models;Videos;Motion segmentation;Semantics;Training;Frame Prediction;Segmentation Prediction;Multi-Scale;Spatial Features;Temporal Analysis;Spatial- Temporal},
  doi={10.1109/ICPAI51961.2020.00038},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10762650,
  author={Yao, Guilin and Chang, Junjie},
  booktitle={2024 5th International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE)}, 
  title={A robust double-layer affinity based matting method}, 
  year={2024},
  volume={},
  number={},
  pages={357-360},
  abstract={In traditional matting algorithms, sampling and affine methods are the primary approaches. The sampling method provides initial alpha values for each pixel but often results in discontinuities and noise, necessitating affine methods for smoothing. Affine methods, which involve both short- and long-range searches, enhance alpha value continuity between neighboring pixels but have varying effects on different regions. To address this, we propose a dual-layer post-processing matting algorithm that combines robust priors with long-range and shortrange modeling. The robust prior step independently samples each unknown pixel, selecting optimal foreground and background samples to compute initial alpha values. Then, a dual-layer affine framework, utilizing the KNN method and a color linear model, further refines these alpha values. Experiments show that this dual-layer algorithm improves both the visual quality and the accuracy of alpha values for foreground, background, and mixed regions.},
  keywords={Visualization;Solid modeling;Smoothing methods;Computational modeling;Software algorithms;Color;Nearest neighbor methods;Solids;Sampling methods;Software engineering;traditional matting algorithms;sampling and affine methods;dual-layer post-processing matting},
  doi={10.1109/ICBASE63199.2024.10762650},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11040971,
  author={N, Karthicrajan and R, Boomika and S, Vadivel},
  booktitle={2025 3rd International Conference on Artificial Intelligence and Machine Learning Applications Theme: Healthcare and Internet of Things (AIMLA)}, 
  title={Deep Learning Based Deep-Sea Image Enhancement and Animal Species Classification}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Marine research and biodiversity conservation relies crucially on underwater image analysis. Despite being an important asset for oceanographic work, the effective use of underwater imagery for various tasks remains inhibited by challenges like poor visibility, low contrast and color distortion. In this paper, I introduce a novel framework that uses FunieGAN for underwater image enhancement followed by Yolov8 for sea creature detection and classification. To improve the visual quality of underwater images the proposed approach makes use of FunieGAN's capabilities aimed to combat the haze and color inconsistency problems. Extra images are then generated using Yolov8, which are then used to detect and classify marine species with high accuracy and precision. The framework also includes a real time deployment component including a Streamlit based application to process time series underwater images in an accessible and efficient manner. The combined methodology yields significant improvements in image quality and detection accuracy that have been validated through results. This work presents a scalable and practical approach for underwater image analysis that has applications in marine biology, environmental monitoring, and fisheries management.},
  keywords={Deep learning;Visualization;Accuracy;Image color analysis;Streaming media;Fisheries;Real-time systems;Biodiversity;Environmental management;Image enhancement;Marine biodiversity;sea creature detection;deep learning;underwater image enhancement;FunieGAN;Streamlit application;YOLOv8},
  doi={10.1109/AIMLA63829.2025.11040971},
  ISSN={},
  month={April},}@INPROCEEDINGS{10748252,
  author={Zhang, Shao and Xu, Huahu and Fang, Dikai and Xu, Jingkun and Shen, Jun},
  booktitle={2024 3rd International Conference on Artificial Intelligence, Internet of Things and Cloud Computing Technology (AIoTC)}, 
  title={Enhancing Single Image De-raining with a Sparse Spatial Transformer}, 
  year={2024},
  volume={},
  number={},
  pages={318-322},
  abstract={The paper proposes an innovative Transformerbased architecture for rain removal, called the Sparse Spatial Transformer (DRMformer), aimed at effectively enhancing the performance of single image de-raining. DRMformer is a model designed to improve the quality of image reconstruction in single image de-raining tasks. The model introduces two core modules: the Multi-branch Top-k Attention (MTKA) and the Multi-scale Spatial Attention Feed-forward Network (MSAFN). MTKA combines local and global attention mechanisms, using a Top-k selection strategy to effectively filter out interfering information, thereby improving the efficiency of feature aggregation. MSAFN employs multi-scale convolution and spatial attention mechanisms to capture image features at different scales, enhancing the retention of detail in image reconstruction. Experimental results show that DRMformer performs exceptionally well on multiple benchmark datasets, such as Rain200L, Rain200H, DID-Data, and DDN-Data, outperforming current state-of-the-art de-raining methods. Ablation studies further verify the significant contribution of the MTKA and MSAFN modules to the model's performance. DRMformer provides a new solution to the single image de-raining problem, offering significant benefits for applications requiring image processing in rainy conditions and paving the way for future research and application in image processing tasks.},
  keywords={Attention mechanisms;Rain;Convolution;Transformer cores;Benchmark testing;Transformers;Feature extraction;Robustness;Internet of Things;Image reconstruction;Single Image De-raining;Image Restoration;SparseSpatial Transformer;Feature Aggregation},
  doi={10.1109/AIoTC63215.2024.10748252},
  ISSN={},
  month={Sep.},}@INBOOK{11164824,
  author={Gillain, Emmanuel},
  booktitle={Demystifying Artificial Intelligence: Symbolic, Data-Driven, Statistical and Ethical AI}, 
  title={11 Conclusion – Moving forward}, 
  year={2024},
  volume={},
  number={},
  pages={445-452},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9783111426303},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11164824},}@INPROCEEDINGS{9498128,
  author={Yoshikawa, Hiroki and Uchiyama, Akira and Higashino, Teruo},
  booktitle={2021 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)}, 
  title={Time-Series Physiological Data Balancing for Regression}, 
  year={2021},
  volume={},
  number={},
  pages={393-398},
  abstract={Many studies have shown the effectiveness of machine learning in estimating psychological or physiological states using physiological data as input. However, it is ethically and physically difficult to collect a large amount of data without bias in an uncontrolled environment. Specifically, the amount of data in rare cases is especially small compared to common data. Therefore, the distribution bias may cause overfitting in machine learning. In this paper, we propose a SMOTE-based method to alleviate the distribution bias by data augmentation in the regression problem using a dataset containing time-series physiological data. The effectiveness of the proposed method was confirmed for datasets of thermal sensation and core body temperature collected in uncontrolled environments. The results show that our method improves the performance of regression models for minor cases with a bit of decline in the mean average error.},
  keywords={Temperature sensors;Conferences;Psychology;Estimation;Machine learning;Computer applications;Feature extraction;Machine learning;Data preprocessing;Health care;Time-series;Regression},
  doi={10.1109/ICAICA52286.2021.9498128},
  ISSN={},
  month={June},}@INPROCEEDINGS{10603148,
  author={Du, Lin and Qi, Jiancheng and Gao, Tianyun and Gao, Yan and Liu, Dianxiong},
  booktitle={2024 4th International Conference on Computer Communication and Artificial Intelligence (CCAI)}, 
  title={A Cooperative Network for Low-Resolution Person Re-Identification}, 
  year={2024},
  volume={},
  number={},
  pages={70-74},
  abstract={Affected by the location of the camera and its own resolution, the pedestrian images collected in the surveillance system often have different resolution. When the pedestrian is far away from the camera, the image resolution will become lower. It is still a challenge for person re-identification (Re-ID) of low resolution images. In this paper, we propose a Low-to-High Multi-Resolution Cooperative Network (LtH-MRCN) for low resolution Re-ID. LtH-MRCN is consisted of two parts, including Low-to-High Resolution Auto-Encoder (LtH-RAE) and Multi-Resolution Collaborative Network (MRCN). LtH-RAE is designed based on HRN et to generate high resolution images from low resolution images, while MRCN utilizes a pair of low and high resolution images to do Re- Id cooperatively. We evaluate our method on two public datasets, including vr-Market1501 and vr-msmt17. LtH- MRCN achieves Rank-1 accuracy of 71.4% and 70.4% on two datasets respectively.},
  keywords={Image resolution;Pedestrians;Accuracy;Federated learning;Surveillance;Collaboration;Cooperative systems;low resolution;low-to-high;auto-encoder;cooperative network},
  doi={10.1109/CCAI61966.2024.10603148},
  ISSN={},
  month={May},}@INPROCEEDINGS{9853337,
  author={Huang, Shuying and Ren, Mingyang and Yang, Yong},
  booktitle={2022 International Conference on Computer Engineering and Artificial Intelligence (ICCEAI)}, 
  title={AMSNet: Attention-based Multi-Scale Network for Image SR Reconstruction}, 
  year={2022},
  volume={},
  number={},
  pages={566-570},
  abstract={Image super-resolution reconstruction (SR) aims to find the mapping relationship between a low-resolution (LR) image and the corresponding high-resolution (HR) image. At present, the SR methods based on deep learning still has the problem of blurred edges and loss of details in the reconstruction results. To address these issues, we propose an attention-based multi-scale SR network (AMSNet), In order to better learn the global and local features of images, a multi-scale network structure is designed to reconstruct richer image features. In the multi-scale structure, cascaded residual blocks (CRB) are used to extract image features. Additionally, a Squeeze-and-Excitation-based residual upsampling block (SERUB) is designed to enhance important features that are beneficial to image reconstruction. Extensive experiments show that our network has better performance in image reconstruction compared to some other state-of-the-art models and is able to reconstruct image texture details better.},
  keywords={Deep learning;Image texture;Analytical models;Computational modeling;Image edge detection;Superresolution;Feature extraction;image super-resolution;Deep Learning;Attention Mechanism;Multi-scale},
  doi={10.1109/ICCEAI55464.2022.00121},
  ISSN={},
  month={July},}@INPROCEEDINGS{11160541,
  author={Zhang, Ximing and Zhao, Jiguang and Zhao, Liang and Xu, Huan and Tian, Bing and Huang, Chuwei},
  booktitle={2025 6th International Conference on Artificial Intelligence and Electromechanical Automation (AIEA)}, 
  title={Efficient Graph Neural Network for Power Transmission Line Detection}, 
  year={2025},
  volume={},
  number={},
  pages={87-91},
  abstract={To supply uninterrupted electric power is extremely crucial for the economy and daily life. The traditional manual inspection method for power transmission line fault detection has many disadvantages. Although deep learning has been applied in power transmission line detection, existing schemes have deficiencies in complex environment with low-resolution images, and small target. To solve this problem, this paper proposes a visual feature modeling method based on graph convolution and constructs a graph neural network model, SCAN-GNN (Graph Neural Network based on SPD-Conv and NAM), which combines graph convolution and convolution operations. We build a novel SCAN-GNN model. The proposed Space-to-depth Convolution (SPD-Conv) solves the detection problems in small target and lowresolution scenarios and the Normalization-based Attention Module (NAM) enhances the detection performance. Experiments have shown that the SCAN-GNN model can achieve efficient and accurate target detection of transmission lines.},
  keywords={Visualization;Power transmission lines;Convolution;Computational modeling;Fault detection;Feature extraction;Electrical fault detection;Graph neural networks;Real-time systems;Power systems;Power transmission line detection;SPD-Conv;NAM},
  doi={10.1109/AIEA66061.2025.11160541},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{11009438,
  author={He, Bangwei and Wang, Feng and Li, Jianxiu and Hang, Min and Wen, Xiangyu and Wu, Ying and Song, Yufei},
  booktitle={2025 2nd International Conference on Smart Grid and Artificial Intelligence (SGAI)}, 
  title={Cyber Risk Detection for IEC 60870-5-104 Operation Commands in Distribution Systems}, 
  year={2025},
  volume={},
  number={},
  pages={145-149},
  abstract={To address the increasing cybersecurity challenges in distribution automation systems, this paper proposes a modeling method for International Electrotechnical Commission (IE C) 60870-5-104 protocol that integrates network layer traffic features and application layer protocol features. Through improved ARIMA (Auto-Regressive Integrated Moving Average) time series modeling and wavelet packet analysis, precise modeling of communication traffic is achieved. Based on information entropy theory, a protocol field correlation model is constructed, and combined with random forest and improved deep autoencoder to achieve efficient monitoring of remote control command anomalies. Experimental results demonstrate that this method shows significant advantages in both accuracy and real-time performance of anomaly detection.},
  keywords={Analytical models;Protocols;Time series analysis;Autoencoders;Feature extraction;Wavelet packets;IEC Standards;Anomaly detection;Remote control;Monitoring;component;Distribution System;Anomaly Detection;Cyber Security;Deep Learning},
  doi={10.1109/SGAI64825.2025.11009438},
  ISSN={},
  month={March},}@INPROCEEDINGS{10920825,
  author={Nanya, Daisuke and Yonezawa, Kouki},
  booktitle={2025 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Reference-Based Anime Line Art Colorization by Region Correspondence Using Region Features}, 
  year={2025},
  volume={},
  number={},
  pages={0718-0722},
  abstract={The coloring process in anime (Japanese animation) production is a critical yet labor- and time-intensive phase in creating animated content. Reducing time and effort required for this step could significantly lower the time, cost, and effort required for anime production. Various body parts of anime characters are assigned corresponding colors in advance, and these colors often differ from character to character. Therefore, the characters in the line art need to be colored with these predetermined colors. However, as line art lacks information about the appropriate coloring, it becomes difficult to automatically color based solely on the line drawing. This study introduces a colorization system for anime line art based on region estimation using a reference colored image to address this issue. Through interviews with a Japanese animation studio, we identified that anime images are typically segmented into numerous distinct regions. The proposed system inputs a line art and reference colored image of the same cut as the line art and outputs the colored line art based on the features of corresponding regions in the two images. Experimental results using a dataset of real anime works confirm the effectiveness of our system.},
  keywords={Image segmentation;Art;Image color analysis;Neural networks;Estimation;Production;Machine learning;Animation;Interviews;Painting;anime;colorization;neural network},
  doi={10.1109/ICAIIC64266.2025.10920825},
  ISSN={2831-6983},
  month={Feb},}@INPROCEEDINGS{11158472,
  author={Wu, Yao and Zou, Xiaowen and Su, Henghua and Lau, Kim},
  booktitle={2025 5th International Conference on Artificial Intelligence and Education (ICAIE)}, 
  title={Performance Analysis of General and Custom GPTs in L2 Personalized Interaction}, 
  year={2025},
  volume={},
  number={},
  pages={236-240},
  abstract={The emergence of custom GPTs has opened new prospects for various disciplines in higher education, as these models can enhance output relevance through targeted instructions and specialized knowledge bases. This study compares chat logs from both general and custom GPTs in terms of linguistic output, prompt execution, and user operation, based on data collected from a beginner-level Chinese language course. The research shows that the general GPT can only achieve appropriate vocabulary choices with an average of six rounds of interaction, whereas the custom GPT maintain effectiveness for an average of 13 rounds. Furthermore, over 80% of students expressed a clear preference for using custom GPTs due to their convenience, appropriateness in vocabulary selection, and accuracy in language feedback, citing their personalized interaction capabilities as a valuable supplement to classroom instruction. These findings provide strong evidence for the effective integration of GPTs into educational contexts, demonstrating their potential to enhance learning outcomes and support personalized educational experiences.},
  keywords={Vocabulary;Accuracy;Education;Knowledge based systems;Linguistics;Performance analysis;custom GPTs;AI agent;L2 Chinese (second Language);Beginner-level;personalized education},
  doi={10.1109/ICAIE64856.2025.11158472},
  ISSN={},
  month={May},}@INPROCEEDINGS{10070331,
  author={Mao, Xiangyu and Zhang, Zhida and Zhang, Kewei and Jia, Xiqiang and Shao, Huiqin},
  booktitle={2022 International Conference on Artificial Intelligence, Information Processing and Cloud Computing (AIIPCC)}, 
  title={Anomaly Detection based on Teacher-Student Network in the field of Security Document Production}, 
  year={2022},
  volume={},
  number={},
  pages={422-425},
  abstract={Our paper proposes an unsupervised learning framework for knowledge distillation based on teacher-student networks for anomaly detection and classification in secure document images. The teacher network uses Wide-ResNet-50 as the backbone network and is pre-trained on large datasets of secure document images and ImageNet. We use a multi-scale feature pyramid matching strategy, so that the student network can receive multi-scale feature maps to better detect anomalies of various sizes. We introduce an attention mechanism to transfer the attention map of the middle layer of the teacher model to the student model as knowledge, hoping that the student model will focus on the region that the teacher model focuses on, thereby distinguishing the difference between normal regions and abnormal regions, and improving the accuracy of detecting anomalies. Our method is applied in the field of Security document to achieve accurate and fast anomaly detection.},
  keywords={Knowledge engineering;Cloud computing;Production;Information processing;Feature extraction;Security;Anomaly detection;Knowledge distillation;Anomaly detection;Teacher-student pyramid matching;Visual inspection;Attention mechanism},
  doi={10.1109/AIIPCC57291.2022.00095},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10826626,
  author={Ma, Yanjin and Rao, Yunbo and Xue, Junmin and He, Qixue},
  booktitle={2024 7th International Conference on Pattern Recognition and Artificial Intelligence (PRAI)}, 
  title={A Comprehensive Data Augmentation Method for Modern Cigarette Packaging Defect Detection}, 
  year={2024},
  volume={},
  number={},
  pages={700-706},
  abstract={This study addresses the issue of insufficient quantity and incomplete types of defect detection datasets for cigarette packages in modern industrial production line scenarios. We propose a cigarette packaging defect data augmentation method. The method consists of three components: preprocessing for obtaining cigarette package defect data through segmentation and cropping based on Segment Anything Model(SAM), generation of cigarette package defects using Cigarette Box Defect-Improved Denoising Diffusion Probabilistic Model (CBD-IDDPM), and We expanded the original dataset by utilizing 600 generated images and trained different defect detection models using the augmented dataset. The experimental results validate the effectiveness of our dataset augmentation method for cigarette package defect detection. The mAP50-95 of YOLOv8n has increased from 73% to 75.2%.},
  keywords={Image segmentation;Image synthesis;Noise reduction;Production;Packaging;Diffusion models;Data augmentation;Data models;Pattern recognition;Defect detection;defect detection;image generation;data augmentation;CBD-IDDPM},
  doi={10.1109/PRAI62207.2024.10826626},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10405533,
  author={Li, Xiuwen and Chen, Chong and Chen, Jie},
  booktitle={2023 5th International Conference on Artificial Intelligence and Computer Applications (ICAICA)}, 
  title={A Lightweight Network-Based Approach for Cross-View Drone Image Matching}, 
  year={2023},
  volume={},
  number={},
  pages={91-96},
  abstract={Aiming at the existing problem of cross view drone image matching, that is, the amount of parameters is too large when using the large backbone network (ResNet-50) to extract features, and it is not easy to deploy on embedded devices, this paper proposed a lightweight network cross view drone image matching method. This method introduced the multi head attention mechanism, which enables LNet to effectively capture the interaction between features. At the same time, the triple loss function is introduced to ensure that the model can effectively distinguish the feature representation of positive and negative samples. Through the verification experiment on the dataset university-1652, the LNet network contains only 16.8M parameters. Experimental results show that the recall rate of this method in drone positioning task (Recall@K, R@K) and average precision (AP) reached 87.02% and 88.93%; The recall rate and average accuracy of drone navigation mission reached 89.91% and 84.79%.},
  keywords={Navigation;Image matching;Computational modeling;Feature extraction;Computational complexity;Task analysis;Drones;lightweight network;embedded network;drone navigation},
  doi={10.1109/ICAICA58456.2023.10405533},
  ISSN={2833-8413},
  month={Nov},}@INPROCEEDINGS{9742723,
  author={Tephila, M.Benedict and Shankar, B. Maruthi and Abhinandhan, S. and Arjun, K.K. and Aswini, P.M. and Priya, C.Divya},
  booktitle={2022 Second International Conference on Artificial Intelligence and Smart Energy (ICAIS)}, 
  title={An Experimental Approach in Colour Correction and Contrast Improvement for Underwater Images}, 
  year={2022},
  volume={},
  number={},
  pages={607-613},
  abstract={Underwater captured images often face low visibility and low colour cast because of the light absorbed and scattered when traveling in water. In the marine environment, it is difficult to view an image clearly and with proper details as compared to other environments. This is primarily due to the factors such as pollution, light, depth etc. It becomes an arduous task to produce a clear image in such situations. However, with the help of advanced technology, it has become easier to solve such issues using the appropriate algorithm or methodology. In this paper, a Bi-interval contrast enhancement and color correction is recommended to improve the image quality underwater. The technology or the process adopted here is such that it makes sure that the quality of the image is being restored and an enhanced image is produced as a result. Here the first step involves subinterval linear transformation with effective and simple color correction methodology to address color distortion. Color correcting strategy ensures the quality of the image restoration and hence a single image is produced by information from multiple images. This process is followed by the application of a Gaussian low-pass filter in the L-Channel in order to segregate the high and low frequency components. The last step of the process involves use of Bi-interval histogram using S-shaped function and optimal equalization threshold strategy for high and low frequency components. A comparison of the proposed work with other traditional methodologies indicates that this work shows high-quality underwater images with quantitative and qualitative evaluation.},
  keywords={Image quality;Histograms;Image color analysis;Low-pass filters;Distortion;Water pollution;Image restoration;Image processing;Underwater images;Contrast enhancement;Color correction;Image restoration},
  doi={10.1109/ICAIS53314.2022.9742723},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{9288327,
  author={Wang, Menglan and Yu, Yue and Li, Benyuan},
  booktitle={2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Joint Embedding based Text-to-Image Synthesis}, 
  year={2020},
  volume={},
  number={},
  pages={432-436},
  abstract={Learning joint embedding between image and text is significant for text-to-image synthesis as it bridges the semantic gap between image and text. Most existing text-to-image generation methods depend on the quality of the text embedding. If the text features are not be extracted well, it is difficult for subsequent processes to generate satisfactory images. However, these methods are disturbed by the text expression form in the process of extracting text features, resulting in the ideal text features cannot be generated well. In this paper, we propose a new text encoder that learns joint embedding to capture semantic information shared by the real images and the input text, and eliminates the interference of textual expression forms. The main difference with existing works is that for different texts describing the same image, although their expressions are different, because they contain the same semantic information, the proposed text encoder extracts the similar semantic features from these different texts. Meanwhile, a special auxiliary classifier for discriminator is adopted to retain low-level features to generate fine-detailed images. We evaluate this work on the Caltech-UCSD Birds 200 (CUB) and the Oxford-102 flower dataset, experiments show that our work has better performance than the state-of-the-art works.},
  keywords={Semantics;Interference;Tools;Feature extraction;Generators;Data mining;Task analysis;joint embedding;special auxiliary classifier;text-to-image synthesis},
  doi={10.1109/ICTAI50040.2020.00074},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{10604637,
  author={Huang, Zhencong},
  booktitle={2024 7th International Conference on Artificial Intelligence and Big Data (ICAIBD)}, 
  title={Research on Super-Resolution Processing of Improved RCAN on SMT Blurred Images}, 
  year={2024},
  volume={},
  number={},
  pages={478-483},
  abstract={Surface mounted technology (SMT) of electronic motherboards is a key technology for assembling advanced circuit boards, and quality inspection is crucial for SMT assembled chips. Some blurred images in our data set cannot be directly used for training to obtain ideal detection results, so super-resolution processing needs to be performed first. We find that convolutional neural network depth and image feature correlation in training are critical for super-resolution. Therefore, we proposed the RCAN-CBAM network. The backbone network adopts the residual-in-residual structure of residual channel attention networks (RCAN) and builds a deep network through a combination of long and short residual connections to focus on high-frequency information learning. The original RCAN architecture only considers channel correlation and ignores spatial correlation. We introduce a spatial attention mechanism to form a convolutional block attention module (CBAM) to achieve comprehensive attention to channel and spatial features. Experiments show that our method shows better performance and visual effects than existing advanced methods on the SMT data set.},
  keywords={Training;Correlation;Attention mechanisms;Superresolution;Surface mount technology;Inspection;Big Data;SMT;super-resolution;RCAN;spatial attention},
  doi={10.1109/ICAIBD62003.2024.10604637},
  ISSN={2769-3554},
  month={May},}@INPROCEEDINGS{8679044,
  author={Ibrahim, Mariam and Alsheikh, Ahmad},
  booktitle={2018 10th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)}, 
  title={Assessing Level of Resilience Using Attack Graphs}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={Cyber-Physical-Systems are subject to cyber-attacks due to existing vulnerabilities in the various components constituting them. System Resiliency is concerned with the extent the system is able to bounce back to a normal state under attacks. In this paper, two communication Networks are analyzed, formally described, and modeled using Architecture Analysis & Design Language (AADL), identifying their architecture, connections, vulnerabilities, resources, possible attack instances as well as their pre-and post-conditions. The generated network models are then verified against a security property using JKind model checker integrated tool. The union of the generated attack sequences/scenarios resulting in overall network compromise (given by its loss of stability) is the Attack graph. The generated Attack graph is visualized graphically using Unity software, and then used to assess the worst Level of Resilience for both networks.},
  keywords={Resilience;Tools;Security;Stability analysis;Communication networks;Local area networks;Analytical models;Resiliency;Attack Graph;Faults;Stability},
  doi={10.1109/ECAI.2018.8679044},
  ISSN={},
  month={June},}@INPROCEEDINGS{11048123,
  author={Wang, Ziyi and Liu, Yong},
  booktitle={2025 5th International Conference on Artificial Intelligence and Industrial Technology Applications (AIITA)}, 
  title={Quantitative Evaluation of Intangible Cultural Heritage Inheritance: Stroke Trajectory Analysis and Machine Learning Model Construction for Paper-Cutting Craftsmanship}, 
  year={2025},
  volume={},
  number={},
  pages={1332-1336},
  abstract={With the acceleration of globalization, intangible cultural heritage (ICH) faces new challenges, particularly in the crisis of craftsmanship inheritance. Effectively quantifying and assessing artisans' skills is crucial for preserving traditional craftsmanship. Therefore, this study proposes an innovative approach based on papercutting art, utilizing stroke trajectory analysis combined with machine learning models to quantitatively evaluate the skills of papercutting inheritors. Specifically, high-quality stroke trajectory images of papercutting art are collected using web crawling techniques. Degraded images are then generated through threshold processing and pixel swapping, followed by the use of a diffusion model to synthesize defective stroke trajectory images. Based on these data, we design the BruNet model, which extracts multi-space features through convolutional neural networks (CNNs) and multi-layer perceptrons (MLPs). These features are then fused using a feature fusion module and trained with cross-entropy and contrastive learning losses. Experimental results demonstrate that BruNet achieves significant performance improvements over state-of-the-art models, providing novel insights and technical support for ICH preservation.},
  keywords={Analytical models;Image segmentation;Art;Merging;Globalization;Contrastive learning;Feature extraction;Diffusion models;Trajectory;Cultural differences;ICH;Paper-cutting;AIGC;Machine learning;Contrastive learning},
  doi={10.1109/AIITA65135.2025.11048123},
  ISSN={},
  month={March},}@INPROCEEDINGS{10331952,
  author={Liu, Qianyu and Zhao, Yaling and Ma, Zhong and Li, Liuhui},
  booktitle={2023 IEEE 6th International Conference on Pattern Recognition and Artificial Intelligence (PRAI)}, 
  title={Automatic Soldering Defect Detection for Tantalum Capacitors in Printed Circuit Boards}, 
  year={2023},
  volume={},
  number={},
  pages={272-278},
  abstract={The automatic detection system proposed in this paper mainly focuses on automatic welding errors detection for tantalum capacitors. Without manual labeling standard PCBs, it can automatically determine the positions and directions of the tantalum capacitors in PCBs and implement automatic labeling by means of segmentation, coarse-fine positioning, direction detection. In the test, the positions and directions of the tantalum capacitors in the PCBs under test can be automatically detected and matched with those in the corresponding standard PCBs, further finding the tantalum capacitors those are missing or in wrong directions in the PCBs under test. On one hand, this method does not need a lot of experienced workers to detect the soldering defects of tantalum capacitors, reducing the probability of defective PCBs being categorized as non-defective due to workers' fatigue or carelessness. It reduces economic cost a lot. On the other hand, unlike deep learning algorithms, it does not need a lot of training examples and performs well on a lot of PCBs whose sizes, shapes and densities of components are unknown before. This improves the productivity and ensures rapid PCB images collection and rapid detection of welding errors. The application shows that the average speed can reach 15 frames per second, and the accuracy is greater than 98%.},
  keywords={Training;Deep learning;Tantalum;Costs;Software design;Welding;Capacitors;tantalum capacitors;automatic labeling;automatic welding defects detection},
  doi={10.1109/PRAI59366.2023.10331952},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10729951,
  author={Zheng, Youkang and Liu, Jun and Zhou, Sai},
  booktitle={2024 3rd International Conference on Artificial Intelligence and Computer Information Technology (AICIT)}, 
  title={DocTrKan: Document Image Enhancement Based on KAN-Enhanced Transformer Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Document images serve as a medium for transmitting information; however, they are influenced by numerous environmental factors during capture, complicating the identification and processing of their content. In the digital era, it is crucial to eliminate noise from document images to enhance readability. To address this challenge, we propose a novel transformer-based document image enhancement algorithm utilizing KAN enhancement, designed to improve both machine-printed and handwritten document images in an end-to-end manner. The encoder operates directly on pixel blocks with positional information, bypassing traditional convolutional layers for feature extraction. A KAN network is incorporated into the encoder to enhance the model's expressive power, reduce parameter count, and improve optimization efficiency. A decoder is employed to reconstruct the clean image. In testing on the DIBCO dataset, DocTrKan surpasses traditional transformer and threshold-based methods in enhancement performance.},
  keywords={Scalability;Noise;Computer architecture;Transformers;Feature extraction;Information technology;Image enhancement;Optimization;Image reconstruction;Testing;document image;image enhancement;KAN;transformer},
  doi={10.1109/AICIT62434.2024.10729951},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10403139,
  author={Song, Rihui and Zhang, Hengfei and Zhao, Baoze and Tan, Zhidong and Liu, Liwen and Zhou, Xiaomei and Zhang, Yuling and Huang, Kai},
  booktitle={2023 IEEE International Conference on Medical Artificial Intelligence (MedAI)}, 
  title={An Electrocardiogram Augmentation Method for Automatic Detection of ST-Segment Elevation Myocardial Infarction and Culprit Vessel}, 
  year={2023},
  volume={},
  number={},
  pages={366-371},
  abstract={With the development of deep learning, neural networks have been applied to detect myocardial infarction or culprit vessels using electrocardiograms. Although data augmentation is a widely used technique to improve the performance of neural networks, few augmentation methods are designed for the detection of ST-segment elevation myocardial infarction and culprit vessels. The main purpose of this paper is to improve the accuracy in detecting ST-segment elevation myocardial infarction and culprit vessels with a novel ECG data augmentation algorithm. We propose an augmentation scheme, which synthesizes new samples by splicing and transforming heartbeats. To splice heartbeats without manually labeled segmentation points, we design an automatic detection algorithm for a splicing point. We applied our augmentation method to four neural networks to demonstrate its effectiveness. The experimental results show that the largest increases in accuracy and macro-Fl scores of the models are 6.41% and 5.73%, respectively.},
  keywords={Heart beat;Splicing;Neural networks;Myocardium;Electrocardiography;Data augmentation;Diseases;ECG Augmentation;Myocardial Infarction De-tection;Neural Networks},
  doi={10.1109/MedAI59581.2023.00055},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11042656,
  author={Senthil Kumar, L. T. and Kalaiyarasi, M. and Hemalatha, L. T. and Saravanan, S.},
  booktitle={2025 2nd International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)}, 
  title={Enhanced U-Net with Boundary Aware Modules for Waterbody Area Segmentation of Satellite Images}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Satellite imaging is essential for environmental monitoring, resource management, and disaster response, especially in the identification and analysis of waterbody regions. However, challenges such as uneven waterbody configurations, low contrast with adjacent terrain, and fluctuating spectral characteristics due to environmental influences hinder accurate segmentation. This study presents an enhanced U-Net architecture, attaining notable performance enhancements with average metrics of 96.1% recall, 97.2% F1 score, 94.3% Jaccard index, 97.7% accuracy, 99.0% specificity, and 97.2% Dice coefficient. The proposed method integrates preprocessing, and sophisticated edge-detection techniques to enhance segmentation precision. Boundary refinement blocks and dense connections augment the network's capacity to identify and outline complex waterbody edges. Experiments using publicly accessible datasets illustrate the model's resilience and versatility across many environmental situations, affirming its reliability as a tool for water resource management and conservation.},
  keywords={Image segmentation;Accuracy;Satellites;Satellite images;Indexes;Environmental monitoring;Telecommunication network reliability;Resource management;Water resources;Resilience;Satellite Image;Environmental Monitoring;Waterbody Segmentation;U-Net;Boundary-Aware Modules},
  doi={10.1109/RMKMATE64874.2025.11042656},
  ISSN={},
  month={May},}@INPROCEEDINGS{11158300,
  author={Hwang, Sherlyn and Sivakumar, Saaveethya and Chiong, Choo W.R.},
  booktitle={2025 5th International Conference on Artificial Intelligence and Education (ICAIE)}, 
  title={Comparative Analysis of GPT and BERT for Automated Open-Ended Question Scoring}, 
  year={2025},
  volume={},
  number={},
  pages={20-25},
  abstract={Automated scoring systems based on machine learning are well-established, significantly reducing educators' grading workload. Unlike closed-ended questions, scoring open-ended questions requires analysing and evaluating students' answers, which is time-consuming and tedious. Especially in having a large student population, educators cannot give timely feedback. A reliable automated scoring of open-ended question systems can reduce the workload and consistency of the grading process, allowing them to focus more on teaching and supporting students. The automated scoring system is built in machine learning models, learning human decisions from the provided dataset. The state-of-the-art models in automated grading involve the GPT and BERT models, performing well on NLP tasks. This paper benchmarked the performance of the GPT-3.5 model against existing BERT models in scoring short answer questions using Mohler dataset.},
  keywords={Training;Computer science;Accuracy;Computational modeling;Machine learning;Benchmark testing;Robustness;Computational efficiency;Automated Scoring;Machine Learning;NLP;Open-ended question},
  doi={10.1109/ICAIE64856.2025.11158300},
  ISSN={},
  month={May},}@INPROCEEDINGS{11144614,
  author={Chu, Xinjian and He, Dan},
  booktitle={2025 2nd International Conference on Artificial Intelligence and Digital Technology (ICAIDT)}, 
  title={Research on Deep Forged Image Detection Based on Deep Learning Fusion of Multidimensional Recognition Features}, 
  year={2025},
  volume={},
  number={},
  pages={140-143},
  abstract={This study relies on deep learning to develop a deep forgery image detection model that integrates multidimensional recognition features. The use of deep learning techniques to extract and explore visual and semantic features of forged images covers a comprehensive coverage from pixel level distribution, texture construction to high-order semantic content. By designing a feature fusion mechanism that integrates multiple recognition features into the detection algorithm, the accuracy and stability of the detection are enhanced. Tests on multiple fake image detection standard datasets have shown excellent monitoring capabilities, strong practical potential, and broad application prospects. The research has opened up new technological means for deep forgery technology, which plays an important role in ensuring the authenticity of images and maintaining information security.},
  keywords={Deep learning;Deepfakes;Visualization;Image recognition;Accuracy;Semantics;Information security;Feature extraction;Forgery;Character recognition;deep learning;Deepfake images;Multidimensional recognition features;image detection},
  doi={10.1109/ICAIDT66272.2025.00033},
  ISSN={},
  month={April},}@INPROCEEDINGS{9403762,
  author={Xue, WanRu},
  booktitle={2020 International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE)}, 
  title={Application research of digital fractal image technology in intelligent art design}, 
  year={2020},
  volume={},
  number={},
  pages={296-300},
  abstract={Digital fractal image technology relies on the computing power of computers to display the results in the way of graphics rendering. The research purpose of this paper is to explore an innovative intelligent artistic creation way and absorb digital fractal image technology through the continuous exploration of the realization way of automatic design, so as to bring new topics and creative fields for the development of art. From the point of view of automatic design, taking the fractal graphics generated by digital fractal image technology theory as the research object, a modeling method of self-combination nonlinear transformation is proposed to realize the batch generation of fractal graphics. In order to further explore the artistic value of fractal graphics, neural style transfer algorithm is adopted to transfer the artistic elements of other excellent works to fractal graphics, and the secondary development of fractal graphics is realized.},
  keywords={Training;Computers;Art;Rendering (computer graphics);Fractals;Convolutional neural networks;Software engineering;Digital fractal image technology;Intelligent art;Self-combination nonlinear transformation modeling},
  doi={10.1109/ICBASE51474.2020.00069},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9415231,
  author={Kang, Ju-Mi and Yoon, Ju Hong and Lee, Minho and Kim, Jewoo and Park, Min-Gyu},
  booktitle={2021 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Volumetric Human Reconstruction from a Single Depth Map}, 
  year={2021},
  volume={},
  number={},
  pages={325-328},
  abstract={We present an efficient approach to reconstruct a human body from a single depth map, captured by a commercial depth camera or a stereo depth sensor. The underlying idea is to predict the rear side depth map through the deep network because the rear side depth map tends to symmetric to the front depth map and the shape variation is lesser than the front. One the rear side depth map is predicted, we construct a signed distance volume and extract a human as the form of 3D meshes through the Marching Cubes method. We experimentally show that the proposed method can effectively predict the rear side depth map.},
  keywords={Solid modeling;Three-dimensional displays;Image recognition;Shape;Predictive models;Cameras;Complexity theory;3D Reconstruction;Single Image;Occupancy Volume;Volume Loss},
  doi={10.1109/ICAIIC51459.2021.9415231},
  ISSN={},
  month={April},}@INPROCEEDINGS{11106172,
  author={Sheelavantmath, Khushi Kiran and Isloor, Vaibhav and Sheetal, B and Bhuvisha, N and Sandesh, B J},
  booktitle={2025 11th International Conference on Computing and Artificial Intelligence (ICCAI)}, 
  title={Localization of Deepfake Facial Images Through U-NET Architecture}, 
  year={2025},
  volume={},
  number={},
  pages={102-107},
  abstract={Traditional deep fake detection methods predominantly rely on binary classification, categorizing images as either real or fake, which often limits their transparency and interpretability for real-world applications. To address this, we propose a novel approach that integrates Histogram of Oriented Gradients (HOG) features into a U-Net architecture, enabling the capture of both fine-grained texture patterns and highlevel contextual information in deep fake regions. For enhanced interpretability, Class Activation Maps (CAM) are transformed into the HSV color space, facilitating intuitive color-based analysis. Contour detection is then employed to localize manipulated regions, and bounding boxes are generated using Dlib to precisely identify these features. By iterating through 68 facial landmarks, textual descriptions are generated to highlight alterations in facial features, providing a detailed understanding of the modifications. To further quantify the extent of manipulation, the resulting feature map undergoes a quantitative assessment by calculating the percentage of contour-detected areas. This method offers a comprehensive framework for identifying and analyzing subtle differences between genuine and modified images, advancing the transparency and accuracy of deep fake detection.},
  keywords={Location awareness;Deepfakes;Histograms;Attention mechanisms;Image color analysis;Data visualization;Computer architecture;Feature extraction;Real-time systems;Facial features;Deepfake Detection;Histogram of Oriented Gradients (HOG);U-Net Architecture;Class Activation Maps (CAM);HSV Color Space;Contour Detection;Dlib;Facial Landmark Analysis},
  doi={10.1109/ICCAI66501.2025.00023},
  ISSN={},
  month={March},}@INPROCEEDINGS{10900108,
  author={Wang, Yiyang and Zeng, Weiyu and Qin, Bin},
  booktitle={2024 4th International Conference on Artificial Intelligence, Robotics, and Communication (ICAIRC)}, 
  title={AD-Gaussian: an Audio Driven Face Synthesis Method Leveraging Differential Attention and 3D Gaussian Splatting}, 
  year={2024},
  volume={},
  number={},
  pages={1054-1057},
  abstract={This paper presents AD-Gaussian, a novel audio-driven face synthesis method. It efficiently integrates multiple input modalities—audio, blinking, and head movements, while employing differential attention to guide specific spatial regions to focus on the critical features that drive their visual changes. By dynamically predicting the deformation of 3D Gaussians, the method enables visually coherent face animations synchronized with speech. Experimental results show that AD-Gaussian outperforms existing methods on key metrics for rendering quality and synchronization accuracy while maintaining real-time performance.},
  keywords={Measurement;Visualization;Three-dimensional displays;Attention mechanisms;Lips;Rendering (computer graphics);Real-time systems;Synchronization;Faces;Robots;Audio Driven Face Synthesis;3D Gaussian Splatting;Differential Attention},
  doi={10.1109/ICAIRC64177.2024.10900108},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10934560,
  author={Hu, Huifeng and Liu, Jicheng and Gao, Hongyue and Wang, Xinglin},
  booktitle={2024 4th International Symposium on Artificial Intelligence and Intelligent Manufacturing (AIIM)}, 
  title={Research on Image Depth Estimation Based on PatchMatchNet in the Field of Holographic 3D Display}, 
  year={2024},
  volume={},
  number={},
  pages={650-654},
  abstract={The display effect of real objects in holographic 3D displays primarily depends on the accuracy of their depth and detail information. However, existing methods face challenges such as insufficient precision, high computational cost, and limitations on mobile devices. To address these issues, this paper proposes a multi-view depth estimation method based on PatchMatchNet(PMN). The method extracts image features using a feature extraction network and optimizes depth estimation through an adaptive propagation and evaluation mechanism, thereby enhancing the accuracy of object depth estimation. The obtained depth map is used to generate a hologram via tomography, which is then displayed as a holographic 3D image using a Spatial Light Modulator (SLM). Comparative analysis with openMVS and MVSNet demonstrates that PMN outperforms in terms of both depth estimation accuracy and computational efficiency, validating its practical application in holographic displays.},
  keywords={Deep learning;Visualization;Three-dimensional displays;Accuracy;Depth measurement;Modulation;Tomography;Feature extraction;Mobile handsets;Computational efficiency;depth estimation;fresnel diffraction;feature pyramid network;holographic 3D display;multi-scale feature fusion},
  doi={10.1109/AIIM64537.2024.10934560},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10854003,
  author={Xi, Qian and Tang, Jie and Qian, Siqi and An, Mengsheng},
  booktitle={6th International Conference on Artificial Intelligence and Advanced Manufacturing (AIAM 2024)}, 
  title={Development of a leaf recognition system based on convolutional neural networks}, 
  year={2024},
  volume={2024},
  number={},
  pages={214-219},
  abstract={Plant leaves are crucial for plant classification, and their automatic recognition has broad applications in botany and agriculture. However, traditional leaf classification methods are often inefficient and inaccurate. This study proposes a leaf recognition system based on Convolutional Neural Networks (CNNs). Utilizing MobileNetV2 as the base model, the system accurately classifies different types of leaves through extensive training on leaf image data. Specifically, the system preprocesses the dataset and leverages CNN's powerful feature extraction capabilities to identify patterns like texture and shape. Validation on a test set achieved an average recognition accuracy of 96%, indicating high reliability. Additionally, the system features a visualizati on interface for users to access detailed recognition results. This research provides an effective solution for the rapid and accurate identification of plant leaves, with significant theoretical and practical implications.},
  keywords={},
  doi={10.1049/icp.2024.4228},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10064907,
  author={Pandey, Pooja and Gupta, Rashmi and Goel, Nidhi},
  booktitle={2022 4th International Conference on Artificial Intelligence and Speech Technology (AIST)}, 
  title={Vision Enhancement of Single Foggy Image using CNN}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  abstract={Fog removal from a single foggy scene is a tedious piece of work. Some of the existing methodologies are based on various constraints and assumptions to evaluate fog free image or defog image. Recent researchers have applied deep neural network algorithms to calculate defog image. Motivated by the recent works, this paper aims to estimate fog free image entrenched on Convolutional Neural Network (CNN). Different haze relevant features are learned using deep architecture of CNN. Using these extracted features, final defog image has been estimated. Results are compared with the existing methodologies for analysis purpose as well.},
  keywords={Deep learning;Image quality;Rain;Image color analysis;Neural networks;Feature extraction;Real-time systems;Defogging;CNN;Restoration;Atmospheric light},
  doi={10.1109/AIST55798.2022.10064907},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11077479,
  author={Ahmed, Sajid and Yoshiura, Noriaki},
  booktitle={2025 6th International Conference on Artificial Intelligence, Robotics and Control (AIRC)}, 
  title={Selective and Enhanced Privacy-Preserving Surveillance: Real-Time Face Anonymization Using Gaussian Blur and Pixelation}, 
  year={2025},
  volume={},
  number={},
  pages={407-412},
  abstract={Public surveillance networks are significant for surveillance and security but are hugely privacy-intrusive due to the widespread usage of facial recognition technologies. Traditional privacy-preserving methods of homomorphic encryption and face blurring either compromise on usability or require high computational effort, making them inappropriate for real-time processing. This paper proposes a novel selective anonymization scheme that is both privacy-preserving and functional-integrity-preserving for surveillance videos. Our approach fuses YOLOv8 nano facial detection with facial matching algorithm to determine target and non-target individuals. Non-target faces are anonymized by a combination of pixelation and Gaussian blurring to render full privacy safeguards. Experimental evaluations using the WIDERFACE dataset and Face detection dataset confirm our methodology to achieve 98.7% privacy preservation, 92.3% target recognition accuracy, and process frames on ordinary CPU, making it highly efficient for real-time applications. The work contributes to the development of privacy-aware surveillance systems that are data protection law-compliant without sacrificing security effectiveness.},
  keywords={Image quality;Privacy;Surveillance;Face recognition;Real-time systems;Information filtering;Security;Face detection;Information integrity;Videos;Privacy-Preserving Surveillance;Selective Anonymization;YOLOv8 nano;Real Time video Processing;Facial Privacy Protection},
  doi={10.1109/AIRC64931.2025.11077479},
  ISSN={},
  month={May},}@INPROCEEDINGS{10581711,
  author={Zhai, Wankang and Wang, Yuhan and Tang, Feng and Chen, Boyang},
  booktitle={2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={A Closer Look at Deep Learning Survival Prediction for High-Throughout Data}, 
  year={2024},
  volume={},
  number={},
  pages={995-999},
  abstract={Research on survival prediction with deep learning has recently emerged. We found that deep learning has great advantages in the process of survival prediction. In this article, we compare traditional deep learning with two baseline models. They are Cox-nnet and DeepSurv. To summarize: When mining TCGA (The Cancer Genome Atlas) high-throughput genetic data sets for analysis: the results obtained by the simple and easy-to-use model are more credible, and its concordance index (evaluation of survival prediction model indicators) is also higher. We compare the loss curves of the two models and give our analysis.},
  keywords={Deep learning;Training;Seminars;Metalearning;Analytical models;Transfer learning;Predictive models;Deep Learning;High-Throughout Data;Survival Prediction;Cox Model},
  doi={10.1109/AINIT61980.2024.10581711},
  ISSN={},
  month={March},}@INBOOK{10710391,
  author={Martinez, David R. and Kifle, Bruke M.},
  booktitle={Artificial Intelligence: A Systems Approach from Architecture Principles to Deployment}, 
  title={Abbreviations}, 
  year={2024},
  volume={},
  number={},
  pages={525-527},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={MIT Press},
  isbn={9780262378703},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10710391},}@INPROCEEDINGS{10982904,
  author={Ansari, Abdullah and El-Hussain, Issa and Ansari, Anas and Rao, KS and Jain, AK},
  booktitle={2025 International Conference for Artificial Intelligence, Applications, Innovation and Ethics (AI2E)}, 
  title={AI-Driven Seismic Tunnel Damage Prediction: A Robust Model for Risk Assessment and Mitigation in Earthquake-Prone Region}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={In the heart of the tectonically dynamic Himalayas, Jammu and Kashmir faces the relentless threat of moderate to large earthquakes, endangering vital tunnel infrastructure. This study pioneers a cutting-edge Seismic Tunnel Damage Prediction (STDP) model that harnesses the power of deep learning to revolutionize risk assessment in these earthquake-prone regions. By meticulously examining historical tunnel damage from significant seismic events, the model integrated a range of critical parameters that influence tunnel vulnerability and damage potential. The model developed in this study outperformed previous models. The STD multiple-graphs serve as a ready-to-use tool for efficient damage assessment.},
  keywords={Deep learning;Heart;Visualization;Technological innovation;Ethics;Prevention and mitigation;Predictive models;Jamming;Faces;Resilience;damage prediction;deep learning;risk assessment;infrastructure resilience;damage visualization;mitigation strategies},
  doi={10.1109/AI2E64943.2025.10982904},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{11077560,
  author={Kumar, Vimlesh},
  booktitle={2025 6th International Conference on Artificial Intelligence, Robotics and Control (AIRC)}, 
  title={QwinSR: A Simplified MLP-Based Super-Resolution Model Integrating Swin-Mixer and SwinIR Architectures}, 
  year={2025},
  volume={},
  number={},
  pages={457-462},
  abstract={Despite advances in image processing, resolution loss remains a common challenge, creating a demand for superresolution (SR) techniques that reconstruct high-fidelity images from lower-resolution sources. This paper introduces QwinSR, a novel hybrid model for single-image super-resolution, which leverages the shifted window approach from Swin Transformer and the all-MLP design philosophy. QwinSR combines the shallow feature extraction capabilities of convolutional layers with the deep feature extraction of Swin-Mixer blocks, a derivative of the Swin Transformer that substitutes self-attention with multilayer perceptrons (MLPs). While focusing on simplicity and efficiency, QwinSR aims to achieve competitive performance with state-of-the-art SR models by utilizing residual connections and convolutional layers in its architecture. Our proposed model is evaluated through a series of ablation studies, where we analyze the impact of various hyperparameters, such as channel numbers, patch sizes, and the presence of residual connections, on the peak signal-to-noise ratio (PSNR) of upscaled images. Due to resource constraints, a full experimental benchmark was not conducted; however, the potential of QwinSR is discussed in relation to existing benchmarks in SR literature. We conclude by outlining future work, including formal testing on larger GPU clusters and further architectural enhancements, to refine the performance and efficiency of QwinSR in real-world applications.},
  keywords={PSNR;Philosophical considerations;Convolution;Superresolution;Benchmark testing;Multilayer perceptrons;Transformers;Feature extraction;Robots;Image reconstruction;Super-resolution;Swin Transformer;MLPbased architecture;image enhancement;deep learning},
  doi={10.1109/AIRC64931.2025.11077560},
  ISSN={},
  month={May},}@INPROCEEDINGS{10956791,
  author={Feng, Shimin and Zhou, Xinye and Xie, Weiyi and Li, Zishan and Peng, Xuanzhi and Yu, Xinran},
  booktitle={2025 International Conference on Electrical Automation and Artificial Intelligence (ICEAAI)}, 
  title={A U-Net-Based Approach for Fundus Retinal Image Segmentation}, 
  year={2025},
  volume={},
  number={},
  pages={1325-1329},
  abstract={In this paper, the problem of fundus retinal image segmentation is investigated. The U-Net which is based on convolutional neural networks is used to explore the fundus retinal image segmentation. The U -Net structure includes a contraction path and an expansion path, and the U-Net can effectively combine the context information and position information of an image to achieve accurate segmentation. The data augmentation techniques including gray scale conversion, standardization, histogram equalization, and gamma transformation are employed to preprocess images to enhance the image features and improve the segmentation accuracy. The experimental results on the DRIVE dataset show that the proposed U-Net-based approach achieves excellent segmentation performance with an accuracy of as high as 95.6%.},
  keywords={Deep learning;Image segmentation;Histograms;Accuracy;Standardization;Retina;Data augmentation;Data models;Convolutional neural networks;Biomedical imaging;U-Net;image segmentation;fundus retinal image;deep learning},
  doi={10.1109/ICEAAI64185.2025.10956791},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9832294,
  author={Yang, Bin and Jiang, Juhao and Chen, Guannan},
  booktitle={2022 IEEE 2nd International Conference on Software Engineering and Artificial Intelligence (SEAI)}, 
  title={Multi-frame Video Super-resolution Based on Efficient and Parallel Network}, 
  year={2022},
  volume={},
  number={},
  pages={69-73},
  abstract={Multi-frame video super-resolution(VSR) aims to restore a high-resolution video from both its corresponding low-resolution frame and multiple neighboring frames, in order to make full use of the inter-frame information. However, vast computation complexity hinders the inference speed of video super-resolution. In order to increase the inference speed while ensuring the accuracy of the model, we proposed an efficient and parallel multi-frame VSR network, termed EPVSR. The proposed EPVSR is based on spatio-temporal adversarial learning to achieve temporal consistency and uses TecoGAN as the baseline model. By adding an improved non-deep network, which is composed of parallel subnetworks with multi-resolution streams, these streams are fused together at regular intervals to exchange information. we reduced the number of parameters and make the model lighter. Besides, we implement structural re-parameterization network acceleration technique to optimize the inference process of EPVSR network. Finally, our EPVSR achieves the real-time processing capacity of 4K@36.45FPS. compared with TecoGAN, we achieve 9.75 × performance speedups, but the effect is not reduced. the PSNR of EGVSR are increased by 3.36%. The experimental results show that the non-deep network can effectively speed up the model inference, and the proposed EPVSR has a good super-resolution effect.},
  keywords={Visualization;Conferences;Computational modeling;Superresolution;Feature extraction;Real-time systems;Image restoration;multi-frame video super-resolution;TecoGAN;PaeNet;real-time system;non-deep network},
  doi={10.1109/SEAI55746.2022.9832294},
  ISSN={},
  month={June},}@INPROCEEDINGS{11163041,
  author={Zhao, Fanhua and Ren, Hui},
  booktitle={2025 IEEE 12th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={Adaptive Structural-Frequency Modeling for Mural Image Restoration}, 
  year={2025},
  volume={12},
  number={},
  pages={564-569},
  abstract={Ancient murals have suffered from cracks, peeling, and fading due to prolonged natural erosion and human impact, diminishing their artistic value and historical significance. To address the issues of detail loss and structural inconsistency in mural restoration, this study proposes a novel Adaptive Structural-Frequency Modeling (ASFM) approach. ASFM integrates feature modeling and frequency optimization, enhancing structural coherence in the spatial domain while preserving fine-grained texture details in the frequency domain. Experiments conducted on the Dunhuang mural dataset demonstrate that the proposed method outperforms state-of-the-art approaches in terms of PSNR, SSIM, and LPIPS, while achieving more visually natural restoration results. Ablation studies further verify the contributions of the feature modeling and frequency optimization modules, highlighting their effectiveness in improving both overall consistency and local detail restoration. This research provides an effective solution for computer-aided mural restoration and can be extended to other digital preservation tasks for cultural heritage.},
  keywords={Representation learning;Adaptation models;PSNR;Frequency-domain analysis;Computational modeling;Stability criteria;Image restoration;Information technology;Optimization;Visual perception;Mural Image Restoration;Deep Learning;Fast Fourier Transform;Attention Mechanism},
  doi={10.1109/ITAIC64559.2025.11163041},
  ISSN={2693-2865},
  month={May},}@INPROCEEDINGS{11083240,
  author={Hu, Nan and Cheng, Le and Wang, Botao and Xu, Jiwei and Tang, Keke and Zhu, Peican},
  booktitle={2024 IEEE International Conference on High Performance Computing and Communications (HPCC)}, 
  title={GAA-BD: Graph Adversarial Augmentation-based Social Bot Detection}, 
  year={2024},
  volume={},
  number={},
  pages={944-951},
  abstract={Online social networks are crucial for information acquisition nowadays, yet they are increasingly jeopardized by malicious attacks from social bots. This underscores the urgent need for robust social bot detection methods. To address the significant challenge posed by the imbalance in the number of human and bot users, we introduce a Graph Adversarial Augmentation-based method for social Bot Detection (GAA-BD) to improve detection efficacy. Our method incorporates a graph convolutional neural network as its core architecture and enhances it with adversarial augmentation applied to both the dataset and the training process. By strategically generating synthetic samples and employing targeted adversarial training, our approach effectively resolves sample size imbalances and bolsters model robustness. Comprehensive experimental results demonstrate that our proposed method outperforms existing baselines, establishing its effectiveness in combatting social bot infiltration in online networks.},
  keywords={Training;Social networking (online);Perturbation methods;High performance computing;Generative adversarial networks;Robustness;Graph neural networks;Stability analysis;Generators;Convolutional neural networks;Bot Detection;Graph Neural Networks;Oversampling;Adversarial Training},
  doi={10.1109/HPCC64274.2024.00128},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9722660,
  author={Rahman, Md. Habibur and Shahjalal, Md. and Ali, Md. Osman and Deok Chung, Byung and Jang, Yeong Min},
  booktitle={2022 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={FFDNet Based Channel Estimation for Multiuser Massive MIMO System with One-Bit ADCs}, 
  year={2022},
  volume={},
  number={},
  pages={023-026},
  abstract={Low-resolution analog-to-digital converters (ADCs) in massive multiple-input multiple-output (m-MIMO) systems offer significant throughput increase for wireless communication. The low-resolution ADC part limits the performance of the transceiver, especially estimating the channels from highly quantized measurements. Mapping from quantized received signals to channel is very challenging. Since the channel response has the characteristic of sparsity, we have leveraged a fast and flexible denoising convolutional neural network (FFDNet) based channel estimation scheme for the m-MIMO system with one-bit ADCs treating the channel matrix as a 2D natural image in this letter. FFDNet can effectively learn from sufficiently large training datasets and is exploited to estimate the channel in the m-MIMO system equipped with one-bit ADCs. We have investigated the exhibited performance of the FFDNet based channel estimation through simulation results. A significantly reduced normalized mean square error has been achieved in our proposed scheme.},
  keywords={Training;Wireless communication;Simulation;Noise reduction;Channel estimation;Mean square error methods;Network architecture;Massive MIMO;channel estimation;one-bit ADC;FFDNet;deep learning},
  doi={10.1109/ICAIIC54071.2022.9722660},
  ISSN={},
  month={Feb},}@ARTICLE{8954698,
  author={Zhang, Xueqin and Zhou, Yue and Pei, Songwen and Zhuge, Jingjing and Chen, Jiahao},
  journal={IEEE Access}, 
  title={Adversarial Examples Detection for XSS Attacks Based on Generative Adversarial Networks}, 
  year={2020},
  volume={8},
  number={},
  pages={10989-10996},
  abstract={Models based on deep learning are prone to misjudging the results when faced with adversarial examples. In this paper, we propose an MCTS-T algorithm for generating adversarial examples of cross-site scripting (XSS) attacks based on Monte Carlo tree search (MCTS) algorithm. The MCTS algorithm enables the generation model to provide a reward value that reflects the probability of generative examples bypassing the detector. To guarantee the antagonism and feasibility of the generative adversarial examples, the bypassing rules are restricted. The experimental results indicate that the missed detection rate of adversarial examples is significantly improved after the MCTS-T generation algorithm. Additionally, we construct a generative adversarial network (GAN) to optimize the detector and improve the detection rate when dealing with adversarial examples. After several epochs of adversarial training, the accuracy of detecting adversarial examples is significantly improved.},
  keywords={Deep learning;Training;Feature extraction;Gallium nitride;Encoding;Detectors;Malware;Network intrusion detection;generative adversarial network;Monte Carlo tree;convolutional neural networks},
  doi={10.1109/ACCESS.2020.2965184},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8461771,
  author={Yi, Jiangyan and Tao, Jianhua and Wen, Zhengqi and Bai, Ye},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Adversarial Multilingual Training for Low-Resource Speech Recognition}, 
  year={2018},
  volume={},
  number={},
  pages={4899-4903},
  abstract={This paper proposes an adversarial multilingual training to train bottleneck (BN) networks for the target language. A parallel shared-exclusive model is also proposed to train the BN network. Adversarial training is used to ensure that the shared layers can learn language-invariant features. Experiments are conducted on IARPA Babel datasets. The results show that the proposed adversarial multilingual BN model outperforms the baseline BN model by up to 8.9% relative word error rate (WER) reduction. The results also show that the proposed parallel shared-exclusive model achieves up to 1.7% relative WER reduction when compared with the stacked share-exclusive model.},
  keywords={Feature extraction;Training;Hidden Markov models;Data models;Task analysis;Speech recognition;Error analysis;Speech recognition;low-resource;deep neural networks;bottleneck features;adversarial multilingual training},
  doi={10.1109/ICASSP.2018.8461771},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{9257746,
  author={Xu, Ming-Chao and Yin, Fei and Liu, Cheng-Lin},
  booktitle={2020 17th International Conference on Frontiers in Handwriting Recognition (ICFHR)}, 
  title={SRR-GAN: Super-Resolution based Recognition with GAN for Low-Resolved Text Images}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={Text images convey important information for various applications, while the recognition of low-resolution text images is a challenge. Most existing methods solve this problem using a cascaded scheme in two steps: image super-resolution and high-resolution text recognition. In this paper, we propose a novel framework, called SRR-GAN, which integrates text recognition with super-resolution via adversarial learning. By joint training of recognition and super-resolution models, more generic features for images of various quality can be learned, so as to yield high recognition performance for both high-resolution and low-resolution images. Experiments on natural scene and handwritten texts demonstrate that SRR-GAN outperforms the cascaded scheme on low-resolution images. The results show that SRR-GAN can improve recognition accuracies by 10%-20% relatively on five datasets of scene/handwritten texts. Meanwhile, SRR-GAN maintains high performance on high-resolution images.},
  keywords={Text recognition;Image recognition;Training;Image restoration;Feature extraction;Handwriting recognition;Image segmentation;Super-Resolution;Adversarial Learning;Text Recognition},
  doi={10.1109/ICFHR2020.2020.00012},
  ISSN={},
  month={Sep.},}@ARTICLE{10583942,
  author={Lin, Ling and Wang, Tao and Liu, Hao and Zhu, Congcong and Chen, Jingrun},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Toward Quantifiable Face Age Transformation Under Attribute Unbias}, 
  year={2024},
  volume={34},
  number={11},
  pages={11768-11782},
  abstract={Previous works condition aging patterns utilizing one-hot or artificial predefined distributions. Nevertheless, different age groups show different intraclass variations. This property made it challenging to express differences in apparent age across all age groups discriminately. Adaptive aging feature distribution by learning the target age group in training data is a promising solution. Unfortunately, existing datasets commonly suffer from diverse degrees of semantic-level attribute imbalance, which leads to the tendency for previous approaches to generate paradoxical appearances. To address the aforementioned issues, we propose a novel framework containing three modules: the Causal Aging (CA) module, the Shapley Value Quantization (SVQ) module, and the Differentiated Age Embedding Transformation (DAT) module. Specifically, to eliminate the effect of attribute imbalance on the adaptive distribution of learning target age groups, we design the CA module, which controls the effect of momentum on aging features by De-confound training. Meanwhile, the influence of the aging-independent attribute, which appears abundantly in training data, on the target aging feature is eliminated by counterfactual inference subtraction. Subsequently, the SVQ module quantifies the contribution of different attributes to age based on the results of the CA module. This operation allows us to obtain adaptive age distributions for different age groups. Eventually, the DAT module takes a target age vector, sampled from the target age distribution quantized by SVQ, and modulates the age representation of the generated image. Extensive experimental results on four face aging datasets show that our model achieves convincing performance compared to the current state-of-the-art methods.},
  keywords={Aging;Training;Image color analysis;Circuits and systems;Face recognition;Data models;Cause effect analysis;Face aging;shapely value;style transfer;causal learning},
  doi={10.1109/TCSVT.2024.3422661},
  ISSN={1558-2205},
  month={Nov},}@ARTICLE{11036686,
  author={Wang, Kan and Wang, Xingjie and Zhao, Nan and Yang, Xu and Fang, Hai and Niyato, Dusit},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={Uplink RSMA in LEO Satellite Communications: A Perspective From Generative Artificial Intelligence}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Consider an uplink rate splitting multiple access (RSMA) transmission in low earth orbit (LEO) terrestrial-satellite networks, by jointly optimizing the user access, transmit power splitting and receive beamforming. Despite advantages of deep reinforcement learning in online optimization, some issues still remain, i.e., the hybrid nature of discrete and continuous actions, low sample quality, and intractable representation of irregular environments. To circumvent these issues, we first formulate a parameterized Markov decision process (PAMDP) to represent the environment evolution, by parameterizing each discrete action as a continuous real vector, upon which the hybrid proximal policy optimization (PPO) is applied. Then, generative diffusion models (GDMs) are embedded into hybrid PPO to output the optimal action distribution, by adding the pure Gaussian noise with states into denoising networks. Experiments results corroborate that GDMs-assisted hybrid PPO achieves larger rewards with stability and faster convergence. Further, the proposed method dominates other benchmarks, under different terminal numbers, transmit power budgets and noise levels.},
  keywords={Satellite broadcasting;Satellites;Low earth orbit satellites;Uplink;Streams;Decoding;Array signal processing;Spectral efficiency;Hybrid power systems;Vectors;LEO satellite networks;RSMA;GDM;PPO},
  doi={10.1109/TVT.2025.3579713},
  ISSN={1939-9359},
  month={},}@INPROCEEDINGS{7398384,
  author={Seaman, Bill},
  booktitle={2015 International Conference on Cyberworlds (CW)}, 
  title={Neosentient Architecture Generator}, 
  year={2015},
  volume={},
  number={},
  pages={8-13},
  abstract={This paper outlines an approach to a series of "open" purpose "architecture" generators and related systems. The word "architecture" is here defined in the broadest of linguistic manners. This paper outlines the long-term goals for the facilitation of the functional components of this 'system of systems', although the system will be designed to be extensible as a large-scale open source project. Three major components make up the system: 1) one or more databases, 2) a means to generate intelligent queries, and 3) a virtual media space to display media elements and processes as derived from the queries/interaction. I will begin by discussing precursors and historical problems related to computational creativity and symbiotic creative systems. Given the non-linear nature of the subject matter, the following text will progress in a modular manner, where much of the paper could we read in differing orders. Thus, it will not unfold in the linear manner of other more traditional IEEE papers, and should be explored with this intentionality by the reader. The project takes a multi-perspective approach to the subject matter in which no overarching hierarchy can be given, suggesting the need for such a form. Thus I will draw on the IEEE formatting related to "Component Heads" -- "components of your paper and are not topically subordinate to each other." This structure also mirrors the functionality of the system itself which seeks to explore dynamic heterarchical combinatorics as its overarching methodology as an intelligent system. Thus the reader may need to work harder at making the creative jumps that enable this analogue "system" to function by reading each of these different component heads in relation to each other and articulating their own connections between the components. This is a Koestler-like bisociational approach[1]. Thus the paper itself becomes an analogue combinatoric "architecture" used to discuss this project.},
  keywords={Computer architecture;Media;Artificial intelligence;Architecture;Context;Generators;Sensors;Generative Architecture;Generative Art;Recombinant Poetics;Recombinant Informatics;Generative Systems;Cybernetics;Systems Approach},
  doi={10.1109/CW.2015.55},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10707809,
  author={Wang, Haohong and Smith, Daniel and Kudelska, Malgorzata},
  booktitle={2024 IEEE 7th International Conference on Multimedia Information Processing and Retrieval (MIPR)}, 
  title={10x Future of Filmmaking Empowered by AIGC}, 
  year={2024},
  volume={},
  number={},
  pages={68-74},
  abstract={In this position paper, we present a vision for the future of filmmaking, driven by the emergence of generative AI technology. While the AI workflow for filmmaking remains in its infancy, recent advancements in diffusion models and the emergence of AI tools such as Midjourney, Runway, Pika, SORA, and LUMA are profoundly inspiring. The integration of AI into filmmaking endeavors, exemplified by projects like Our T2 Remake and Next Stop Paris, has yielded unprecedented impacts. This paper meticulously examines the challenges currently confronting AI models and proposes temporary solutions to surmount these obstacles in the filmmaking process. Furthermore, it demonstrates the workflow of the film “Next Stop Paris,” illustrating how these integrated AI modules can collaborate efficiently to produce short films despite technical limitations in the early days. We foresee a future akin to Silicon Valley's technology incubation, where intellectual property (IP) incubation thrives in Hollywood. This initiative supports our vision of catalyzing 10x growth in the filmmaking industry.},
  keywords={Productivity;TV;Generative AI;Pipelines;Entertainment industry;Intellectual property;Information processing;Motion pictures;Artificial intelligence;Standards;AI;generative AI;AIGC;diffusion model;filmmaking;Next Stop Paris},
  doi={10.1109/MIPR62202.2024.00018},
  ISSN={2770-4319},
  month={Aug},}@INBOOK{10614285,
  author={Ojanperä, Tero},
  booktitle={AI Revolution: Mastering AI for Personal and Organizational Growth}, 
  title={2 Prompting &#x2013; Learn to Use ChatGPT and Other AI Applications}, 
  year={2024},
  volume={},
  number={},
  pages={23-66},
  abstract={"The AI Revolution" is a practical guide to using new AI tools, such as ChatGPT, DALLE and Midjourney. Learn how to multiply your productivity by guiding or prompting AI in various ways. The book also introduces Microsoft Copilot, Google Bard, and Adobe Photoshop Generative Fill, among other new applications. ChatGPT reached a hundred million users in just two months after its release, faster than any other application before. This marked the advent of the generative AI era. Generative AI models generate text, images, music, videos, and even 3D models in ways previously thought impossible for machines. The book explains in an understandable manner how these AI models work. The book provides examples of how AI increases productivity, which professions are changing or disappearing, and how job markets will evolve in the coming years. With this book, you'll learn to recognize the opportunities and risks AI offers. Understand what this change demands from individuals and companies and what strategic skills are required. The book also covers legal questions caused by generative AI, like copyrights, data protection, and AI regulation. It also ponders societal impacts. AI produces content, thus influencing language, culture, and even worldviews. Therefore, it's crucial to understand by whom and how AI is trained. The AI revolution started by ChatGPT is just the beginning. This handbook is for you if you want to keep up with the rapid development of AI.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770042314},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10614285},}@ARTICLE{11006143,
  author={Liang, Ruihuai and Yang, Bo and Chen, Pengyu and Cao, Xuelin and Yu, Zhiwen and Debbah, Mérouane and Niyato, Dusit and Poor, H. Vincent and Yuen, Chau},
  journal={IEEE Transactions on Mobile Computing}, 
  title={GDSG: Graph Diffusion-Based Solution Generator for Optimization Problems in MEC Networks}, 
  year={2025},
  volume={24},
  number={10},
  pages={10264-10277},
  abstract={Optimization is crucial for the efficiency and reliability of multi-access edge computing (MEC) networks. Many optimization problems in this field are NP-hard and do not have effective approximation algorithms. Consequently, there is often a lack of optimal (ground-truth) data, which limits the effectiveness of traditional deep learning approaches. Most existing learning-based methods require a large amount of optimal data and do not leverage the potential advantages of using suboptimal data, which can be obtained more efficiently. To illustrate this point, we focus on the multi-server multi-user computation offloading (MSCO) problem, a common issue in MEC networks that lacks efficient optimal solution methods. In this paper, we introduce the graph diffusion-based solution generator (GDSG), designed to work with suboptimal datasets while still achieving convergence to the optimal solution with high probability. We reformulate the network optimization challenge as a distribution-learning problem and provide a clear explanation of how to learn from suboptimal training datasets. We develop GDSG, a multi-task diffusion generative model that employs a graph neural network (GNN) to capture the distribution of high-quality solutions. Our approach includes a straightforward and efficient heuristic method to generate a sufficient amount of training data composed entirely of suboptimal solutions. In our implementation, we enhance the GNN architecture to achieve better generalization. Moreover, the proposed GDSG can achieve nearly 100% task orthogonality, which helps prevent negative interference between the discrete and continuous solution generation training objectives. We demonstrate that this orthogonality arises from the diffusion-related training loss in GDSG, rather than from the GNN architecture itself. Finally, our experiments show that the proposed GDSG outperforms other benchmark methods on both optimal and suboptimal training datasets. Regarding the minimization of computation offloading costs, GDSG achieves savings of up to 56.62% on the ground-truth training set and 41.06% on the suboptimal training set compared to existing discriminative methods.},
  keywords={Optimization;Training;Servers;Artificial intelligence;Training data;Graph neural networks;Diffusion models;Generators;Generative AI;Costs;Multi-access edge computing;network optimization;computation offloading;generative AI;graph diffusion},
  doi={10.1109/TMC.2025.3568248},
  ISSN={1558-0660},
  month={Oct},}@INPROCEEDINGS{10184233,
  author={Hamid, Oussama H.},
  booktitle={2023 9th International Conference on Information Technology Trends (ITT)}, 
  title={ChatGPT and the Chinese Room Argument: An Eloquent AI Conversationalist Lacking True Understanding and Consciousness}, 
  year={2023},
  volume={},
  number={},
  pages={238-241},
  abstract={This paper explores the cognitive implications of recent advancements in large language models (LLMs), with a specific focus on ChatGPT. We contribute to the ongoing debate about the cognitive significance of current LLMs by drawing an analogy to the Chinese Room Argument, a thought experiment that questions the genuine understanding of language in machines (computer programs). Our argument posits that current LLMs, including ChatGPT, generate text resembling human-like responses, akin to the process depicted in the Chinese Room Argument. In both cases, the responses are provided without a deep understanding of the language, thus lacking true signs of consciousness.},
  keywords={Computational modeling;Assistive technologies;Chatbots;Transformers;Market research;Artificial intelligence;Information technology;AI language models;ChatGPT;consciousness;Chinese room argument;generative pre-trained transformer (GPT)},
  doi={10.1109/ITT59889.2023.10184233},
  ISSN={},
  month={May},}@INPROCEEDINGS{10386018,
  author={Zadeh, Pooya Moradian and Sattler, Deborah},
  booktitle={2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Improving Accessibility and Readability of Survey Reports in Digital Health Platforms using Conversational AI}, 
  year={2023},
  volume={},
  number={},
  pages={4987-4989},
  abstract={This study proposes the integration of conversational AI in community-based survey platforms to generate personalized narratives for vulnerable patients such as the elderly, those with palliative care needs, or from diverse language communities. The study emphasizes the capabilities of AI-driven analysis and proposes the use of this technology to analyze health survey data and produce personalized narratives that address the specific needs of each individual. The proposed approach aims to enhance patient engagement by providing compassionate assistance and insightful guidance derived directly from the survey responses.},
  keywords={Surveys;Mood;Biological system modeling;Sociology;Chatbots;Electronic healthcare;Artificial intelligence;Compassionate Care;Conversational AI;Generative AI;Palliative Care;Community-Health;Value-based Health},
  doi={10.1109/BIBM58861.2023.10386018},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{10602875,
  author={Vella, Salvatore and Shariah, Salah},
  booktitle={2024 4th Interdisciplinary Conference on Electrics and Computer (INTCEC)}, 
  title={All You Need is Knowledge, Experience and Tools: A Framework for Integrating Digital Labour With White Collar Work}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={This paper proposes a framework for using digital labour to augment white-collar professions. We define a White Collar employee as one who performs administrative and managerial work, uses knowledge and experience, and works with others in a set of workflows. Starting with simple questions and answers, AI can help to augment white-collar roles. In this paper, we look at how AI agents, Digital Labour, can be defined with knowledge, made better through experience, and given skills, tools, and personality for the role. By describing a set of Digital Labour and an appropriate workflow, we can illustrate how Digital Labour can augment and improve many white-collar workflows. It offers insights into the future of professional work environments where human employees and Digital Labour will collaborate.},
  keywords={Loans and mortgages;Economic indicators;Automobiles;Artificial intelligence;Generative AI;agents;White Collar;autonomous;finance},
  doi={10.1109/INTCEC61833.2024.10602875},
  ISSN={},
  month={June},}@INPROCEEDINGS{10725758,
  author={Bal, Advait and Anjana, P and Gayathri Devi, K T and Upot, Vishaal S and Anjali, T},
  booktitle={2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Exploring the Integration of GPT-Powered Navigation and Book Reader Glasses for the Visually Impaired}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper presents a comprehensive exploration of the implementation details and functionalities of an AI-Enabled Vision Assistance System tailored for the visually impaired. The system integrates a smart camera within spectacles, leveraging GPT’s natural language processing capabilities for real-time object recognition and navigation assistance. We delve into the intricacies of both image analysis and language generation models, addressing potential challenges and proposing solutions to ensure robustness and user-friendliness. Through rigorous analysis, we demonstrate the effectiveness and feasibility of this approach, highlighting its potential to significantly improve the lives of millions of visually impaired individuals by promoting accessibility and fostering greater independence.The paper delves into the implementation details, outlining the functionalities of image analysis. We address potential challenges and propose solutions to ensure robustness and user-friendliness. Through rigorous analysis, we demonstrate the effectiveness and feasibility of this approach. This research has the potential to significantly improve the lives of millions of visually impaired individuals by promoting accessibility and fostering greater independence.},
  keywords={Image analysis;Navigation;Smart cameras;Glass;Transformers;Real-time systems;Robustness;Natural language processing;Object recognition;Artificial intelligence;AI-Enabled Vision Assistance System;Visually Impaired;GPT (Generative Pre-trained Transformer);Real-time Object Recognition;Navigation Assistance;Accessibility},
  doi={10.1109/ICCCNT61001.2024.10725758},
  ISSN={2473-7674},
  month={June},}@INPROCEEDINGS{8404567,
  author={Halici, Eren and Alatan, A. Aydin},
  booktitle={2018 26th Signal Processing and Communications Applications Conference (SIU)}, 
  title={Object localization with reinforcement learning}, 
  year={2018},
  volume={},
  number={},
  pages={1-4},
  abstract={Reinforcement Learning, which has recently started to be used more and more in computer vision applications, is mostly utilized in solving object tracking and object localization problems. Most of the time, training these problems makes use of bounding box information; however, producing bounding box information requires meticulous human effort. In this work, a framework for solving the object localization problem without using bounding boxes is proposed. Instead of bounding boxes; a database of tightly cropped images and a database of uncropped scenes is required. The framework consists of two parts: A reinforcement learning agent that tries to produce tightly cropped images from uncropped scenes and a discriminator which aims to determine whether an image is generated by the reinforcement learning agent or it belongs to the distribution of the tightly cropped image database. The experiment results indicate that achieving a promising localization performance is possible without using explicit bounding box information.},
  keywords={Dogs;Learning (artificial intelligence);Computer vision;Object tracking;Training;Image databases;Object Localization;Reinforcement Learning;Generative Adversarial Networks},
  doi={10.1109/SIU.2018.8404567},
  ISSN={},
  month={May},}@INPROCEEDINGS{9621905,
  author={Jia, Hao and Thawonmas, Ruck and Paliyawan, Pujana},
  booktitle={2021 IEEE 10th Global Conference on Consumer Electronics (GCCE)}, 
  title={An Aerial Cinematographer AI for Settlements in Minecraft–Toward Their Crowd Assessment}, 
  year={2021},
  volume={},
  number={},
  pages={853-854},
  abstract={This paper proposes an aerial cinematographer AI for shooting videos of settlements in Minecraft worlds. A supervised learning approach is adopted to train the AI using a decision tree with movement behavior data of a target player. Results on unseen data show the effectiveness of the proposed AI when its position is close to the settlement center.},
  keywords={Conferences;Supervised learning;Decision trees;Artificial intelligence;Consumer electronics;Videos;Aerial Cinematographer;Decision Tree;Generative Design in Minecraft Competition},
  doi={10.1109/GCCE53005.2021.9621905},
  ISSN={2378-8143},
  month={Oct},}@INPROCEEDINGS{9175496,
  author={Chen, Kang and Yi, Fuwang and Jia, Jun and Zhai, Guangtao},
  booktitle={2020 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)}, 
  title={Real time Robust Invisible Hyperlinks in Physical Photographs Based on Embodied AI Platform}, 
  year={2020},
  volume={},
  number={},
  pages={271-274},
  abstract={Quick Response (QR) Code plays an important role in connecting the physical world where we live in and the digital world that contains information. However, the pictures made up of black and white color blocks really affect people's moods. This paper designs a visual appealing two-dimensional code to help people access information from offline to online. A Deep Neural Network (DNN) based encoder hides information into natural images and a DNN based decoder recovers it. A novel finder pattern is designed to help the decoding device to locate our codes quickly. We design a decoding device. It consists of an AI chip, camera, and LCD screen. The information is invisible in our generated hidden images but detectable by our device. With the help of powerful edge computing, the device can recover the hidden information from the pictures in real time.},
  keywords={Decoding;Artificial intelligence;Cameras;Robustness;Computational modeling;Training;Real-time systems;Information Hiding and Recovery;Generative Adversarial Network;Edge Computing},
  doi={10.1109/MIPR49039.2020.00063},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{11076943,
  author={K, Carolin Joanna Sheryl and Ramalakshmi, K and Jemima, N Cinthia and Venkatesan, R},
  booktitle={2025 Global Conference in Emerging Technology (GINOTECH)}, 
  title={Classification of AI- Generated vs. Human Voices Using Convolutional Neural Networks(CNNs) and Sprectrogram Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The rapid development of AI technologies mainly in voice synthesis and cloning areas has caused considerable difficulties in distinguishing AI-generated and human voices. This brought huge risks to security, media authentications, and fraud detections. This paper presents a deep learning-based methodology for classifying AI-generated and human voices based on CNNs. We transform audio signals into their time-frequency representations, so-called spectrograms. The pre-trained CNN architectures to be fine-tuned for binary classification are VGG16 and ResNet50. The experiments show that the proposed models have high accuracy; ResNet50 outperforms VGG16 due to its deeper architecture. It provides a dogged means of differentiating AI-generated voices from human voices and gives another key tool in mitigating the risks connected to the malicious utilization of AI-driven voice technologies.},
  keywords={Deep learning;Authentication;Media;Fraud;Human voice;Convolutional neural networks;Security;Artificial intelligence;Spectrogram;Residual neural networks;Neural Network;Voice Synthesis;Deep Learning;Generative Adversarial Networks},
  doi={10.1109/GINOTECH63460.2025.11076943},
  ISSN={},
  month={May},}@INPROCEEDINGS{10691329,
  author={Miyamoto, Takumi and Wang, Yuanyuan},
  booktitle={2024 International Conference on Future Technologies for Smart Society (ICFTSS)}, 
  title={Generating Appreciation Contents of Artworks for Creativity with Paintings and Music}, 
  year={2024},
  volume={},
  number={},
  pages={132-135},
  abstract={Art appreciation in the digital realm often falls short of the immersive depth found in physical museum visits. To address this gap, we propose a system designed to enhance the online art experience. Our system seamlessly integrates the user’s chosen artwork with music that matches the mood of the artwork, enhancing sensory engagement. This interactive platform not only pairs artwork with harmonious music but also adapts over time through user feedback, generating personalized content that reflects individual emotional and cognitive responses. By digitally enhancing interest in and appreciation of art, our approach aims to enrich cultural experiences and promote overall well-being.},
  keywords={Art;Mood;Museums;Cultural differences;Artificial intelligence;Creativity;Painting;online art appreciation;appreciation content generation;music-image fusion;digital art experience;generative AI},
  doi={10.1109/ICFTSS61109.2024.10691329},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10990639,
  author={Devi, M. Vasumathi and Priyanka, Rupireddy and Kumar, V.N.S. Vijay and SAGAR, M. and Swapnapriya, Cheekatla and Kumar, Kopparty Vinay},
  booktitle={2024 2nd International Conference on Signal Processing, Communication, Power and Embedded System (SCOPES)}, 
  title={Fusion Methods of Deep Learning for Surveillance and Harvest Prediction of Plants}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Farmers have the opportunity to make harvest for 4–5 times more farm output per acre. Today, more than ever, technology is enabling farmers to make significant progress, greatly enhancing their quality of life. Seen through the eyes of a farmer, it is a significant miracle occurring on their modest farm land. In order to evaluate data and improve farming techniques, Technologies- based rooftop farming models can include AI and machine learning algorithms. We may anticipate the development of even more sophisticated algorithms in the future, which will enable farming to become more productive and efficient. AI algorithms play apivotal role in converting this data into actionable insights. AI introduces a level of sophistication and efficiency to agriculture that was previously unattainable, from the creation of decision support systems to predictive modeling for estimating crop harvest. Conventional methods of crop monitoring, which typically depend on visual assessments or basic remote sensing techniques, may fail to detect the subtle variations in plant health that indicate stress or potential harvest problems. Recent advancements in remote sensing technology, especially hyper-spectral imaging, have facilitated the acquisition of intricate spectral data, enabling more precise evaluations of crop health.},
  keywords={Deep learning;Visualization;Machine learning algorithms;Surveillance;Crops;Signal processing algorithms;Prediction algorithms;Artificial intelligence;Remote sensing;Farming;Deep learning;UNet;Feature extraction;Generative learning;Classification;Harvest Predection},
  doi={10.1109/SCOPES64467.2024.10990639},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10890225,
  author={Swami, Kunal and Chittersu, Raghu and Adlinge, Pranav and Irny, Rajeev and Doodekula, Shashavali and Shukla, Alok},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={PromptArtisan: Multi-instruction Image Editing in Single Pass with Complete Attention Control}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={We present PromptArtisan, a groundbreaking approach to multi-instruction image editing that achieves remarkable results in a single pass, eliminating the need for time-consuming iterative refinement. Our method empowers users to provide multiple editing instructions, each associated with a specific mask within the image. This flexibility allows for complex edits involving mask intersections or overlaps, enabling the realization of intricate and nuanced image transformations. PromptArtisan leverages a pre-trained InstructPix2Pix model in conjunction with a novel Complete Attention Control Mechanism (CACM). This mechanism ensures precise adherence to user instructions, granting fine-grained control over the editing process. Furthermore, our approach is zero-shot, requiring no additional training, and boasts improved processing complexity compared to traditional iterative methods. By seamlessly integrating multi-instruction capabilities, single-pass efficiency, and complete attention control, PromptArtisan unlocks new possibilities for creative and efficient image editing workflows, catering to both novice and expert users alike.},
  keywords={Training;Image transformation;Process control;Signal processing;Acoustics;Complexity theory;Iterative methods;Speech processing;Artificial intelligence;Multi-instruction Editing;Single Pass Editing;Diffusion Models;Generative AI},
  doi={10.1109/ICASSP49660.2025.10890225},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10663037,
  author={Wei, Zhengyuan and Lee, Albert T.L. and Lee, Victor C.S. and Chan, Wing-Kwong},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Toward AI-facilitated Learning Cycle in Integration Course Through Pair Programming with AI Agents}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={We propose a new methodology that harnesses recent advancements in AI techniques to formulate an AI-facilitating code learning cycle for students. The approach builds on an existing learning process and innovatively incorporates pair programming into the learning cycle. It first transforms the example code into scaffold code as exercises through an instructor-AI pairing. The scaffold code serves as an exercise for students to complete and debug on a hardware platform iteratively with an expert AI assistant. This design alleviates instructors' burden of crafting new exercises for new scenarios and offers students the advantage of interactive learning with scenario diversity. We evaluate the methodology using a suite of example codes and assess the semantic similarity among different code versions produced by AI assistants. The case study shows promising results of the methodology. We further discuss our findings and outline future work for the proposed methodology.},
  keywords={Codes;Semantics;Transforms;Programming;Hardware;Artificial intelligence;Generative AI;pair programming;learning process},
  doi={10.1109/CSEET62301.2024.10663037},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10641535,
  author={Bugbee, Kaylin and Acharya, Ashish and Foshee, Emily and Ramasubramanian, Muthukumaran and Davis, Carson and Praveen, Bishwas and Nagaraja, Kartik and Misra, Tarun and Vishwanathan, Shravan and Wingo, Stephanie and Balsara, Nikita and Li, Xiang and Okhade, Meghna and John, Justin},
  booktitle={IGARSS 2024 - 2024 IEEE International Geoscience and Remote Sensing Symposium}, 
  title={The Science Discovery Engine: Leveraging an Insight Engine Capability to Enable Scientific Search}, 
  year={2024},
  volume={},
  number={},
  pages={4055-4057},
  abstract={NASA has created the Science Discovery Engine, a search capability built using insight engine technology, to enable discovery of NASA’s open science data and information. In this paper, we present the SDE architecture and curation methodology developed using an insight engine capability. We also share our progress to date, lessons learned implementing an insight engine capability and planned future work.},
  keywords={NASA;Geoscience and remote sensing;Artificial intelligence;Engines;Open science;insight engines;scientific curation;data search;generative AI},
  doi={10.1109/IGARSS53475.2024.10641535},
  ISSN={2153-7003},
  month={July},}@INPROCEEDINGS{10663012,
  author={DesLauriers, James and Michalickova, Katerina and Pinney, John and Gao, Liam and Cooling, Chris},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={You & AI: A Research Computing Hackathon: Poster Abstract}, 
  year={2024},
  volume={},
  number={},
  pages={1-2},
  abstract={In June 2023, the Imperial College London Graduate School's Research Computing and Data Science group invited thirty PhD students for a one-day Hackathon on AI-assisted programming. This poster abstract presents our experiences in planning and running the event, and shares student and organiser reflections on the event and where it might lead.},
  keywords={Programming;Lead;Data science;Reflection;Planning;Artificial intelligence;generative ai;training;ai-assisted programming},
  doi={10.1109/CSEET62301.2024.10663012},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10819226,
  author={Suárez-Pizzarello, Marianella and De Los Angeles SáNchez-Trujillo, María and Rodráguez Flores, Eduar Antonio},
  booktitle={2024 IEEE 4th International Conference on Advanced Learning Technologies on Education & Research (ICALTER)}, 
  title={Exploring ChatGPT-4 as an Academic Assistant in Thesis Development: A Case Study on Postgraduate Higher Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={The objective of this study is to assess the effectiveness of ChatGPT-4 in assisting postgraduate students with structuring research problems, conducting literature reviews, and formulating research objectives, while also examining the benefits and limitations of integrating AI into academic writing support. Using a qualitative case study approach, 13 students from a Digital Education program participated, guided by structured prompts to align ChatGPT-4's responses with academic standards. Data were collected through structured reflective statements and a focus group, providing insights into the students' experiences and satisfaction with AI support. Findings indicate that ChatGPT-4 helps students clarify complex academic concepts and organize their work, enhancing their confidence in academic writing. However, concerns about potential dependency on AI and content accuracy highlight the need for responsible AI literacy. The study concludes that AI support should be adapted to meet evolving academic demands, with an emphasis on ethical considerations to ensure students use AI as a supportive tool rather than a substitute for critical engagement in research.},
  keywords={Ethics;Accuracy;Bibliographies;Education;Artificial intelligence;Standards;Generative AI;Academic writing support;Research development;Ethical literacy},
  doi={10.1109/ICALTER65499.2024.10819226},
  ISSN={},
  month={Dec},}@ARTICLE{9500220,
  author={Wang, Yuehui and Cai, Liyan and Zhang, Dongyu and Huang, Sibo},
  journal={IEEE Access}, 
  title={The Frequency Discrepancy Between Real and Generated Images}, 
  year={2021},
  volume={9},
  number={},
  pages={115205-115216},
  abstract={Despite the success of Generative Adversarial Networks (GANs), little work has focused on the discrepancy between real and generated images in frequency domain. In this work, we provide a systematic analysis on this topic. We first demonstrate the general existence of the frequency discrepancy and further perform extensive experiments both on datasets with various frequency distributions and models with different upsampling methods to reveal the sources of the discrepancy. Experimental results show that: resize-convolution is not a perfect alternative to deconvolution, and natural images and unnatural images should be treated separately during training. Based on these studies, we provide some novel solutions to reduce the discrepancy. Finally, we further show the effectiveness of our solutions on Variational Auto Encoders (VAEs). We hope that the community should pay equal attention to the performance of generative models both in spatial and frequency domain.},
  keywords={Frequency-domain analysis;Tools;High frequency;Visualization;Generative adversarial networks;Training;Deep learning;computer vision;generative adversarial network;image generation;frequency discrepancy},
  doi={10.1109/ACCESS.2021.3100891},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{687214,
  author={Kiviluoto, K. and Oja, E.},
  booktitle={1998 IEEE International Joint Conference on Neural Networks Proceedings. IEEE World Congress on Computational Intelligence (Cat. No.98CH36227)}, 
  title={Softmax-network and S-Map-models for density-generating topographic mappings}, 
  year={1998},
  volume={3},
  number={},
  pages={2268-2272 vol.3},
  abstract={We propose a neural network model for density-generating topographic mappings. The model consists of two parts: the Softmax-network, and the S-Map. The Softmax-network implements the softmax function, so that each neuron's output is a softmax of the weighted sum of the input to that neuron and to its neighbors. The S-Map, based on the Softmax-network, utilises a Hebbian-like learning scheme for the input-to-neuron weights to minimize the negative log likelihood error function; simulations show that a simplified version of the S-Map with fully Hebbian learning yields qualitatively similar results. The model is related both to the generative topographic mapping (GTM) and the self-organizing map (SOM).},
  keywords={Neurons;Biological system modeling;Artificial neural networks;Neural networks;Lattices;Output feedback;Neurofeedback;Error correction;Information processing;Computer networks},
  doi={10.1109/IJCNN.1998.687214},
  ISSN={1098-7576},
  month={May},}@ARTICLE{11020580,
  author={Li, Siyuan and Lin, Xi and Liu, Yaju and Chen, Xiang and Li, Jianhua},
  journal={IEEE Communications Magazine}, 
  title={Trustworthy AI-Generative Content for Intelligent Network Service: Robustness, Security, and Fairness}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={AI-generated content (AIGC) models, represented by large language models (LLM), have revolutionized content creation. High-speed next-generation communication technology is an ideal platform for providing powerful AIGC network services. At the same time, advanced AIGC techniques can also make future network services more intelligent, especially various online content generation services. However, the significant untrustworthiness concerns of current AIGC models, such as robustness, security, and fairness, greatly affect the credibility of intelligent network services, especially in ensuring secure AIGC services. This article proposes TrustGAIN, a trustworthy AIGC framework that incorporates robust, secure, and fair network services. We first discuss the robustness to adversarial attacks faced by AIGC models in network systems and the corresponding protection issues. Subsequently, we emphasize the importance of avoiding unsafe and illegal services and ensuring the fairness of the AIGC network services. Then, as a case study, we propose a novel sentiment analysis-based detection method to guide the robust detection of unsafe content in network services. We conduct our experiments on fake news, malicious code, and unsafe review datasets to represent LLM application scenarios. Our results indicate that TrustGAIN is an exploration of future networks that can support trustworthy AIGC network services.},
  keywords={Security;Robustness;Intelligent networks;Data models;Solid modeling;Artificial intelligence;Metaverse;Biological system modeling;Training;Reliability},
  doi={10.1109/MCOM.004.2400646},
  ISSN={1558-1896},
  month={},}@INPROCEEDINGS{10410334,
  author={Hoogendoorn, Tjalling and Arachchige, Jeewanie Jayasinghe and Bukhsh, Faiza A.},
  booktitle={2023 International Conference on Frontiers of Information Technology (FIT)}, 
  title={Survey of Explainability within Process Mining: A case study of BPI challenge 2020}, 
  year={2023},
  volume={},
  number={},
  pages={43-48},
  abstract={The need for explainability in Business process management is tremendously increasing, especially in the age of generative AI. The number of published articles on explainable AI (XAI) has skyrocketed for five years. AI impacts the decision-making process in business analytics. Process mining as a sub-discipline of data science can play a role in explainable business decision-making. Process mining exhibits its intention in process discovery, performance measures of processes, and process improvements based on the event logs. Although the accuracy of the outcome of process mining models has been investigated at a certain level, the explainability of those is possible through the discretization of the analytic steps. As an initial step in exploring the explainability of process mining, this research conducts a technical analysis of 37 research papers submitted to the Business Process Intelligence (BPI) Challenge 2020. The main focus of this analysis aims to answer the question, "How and why a process model is produced? " To make a foundation for the research question, the notion of explainability is explored based on an Explainable AI ontology. Due to the small sample size, the study cannot identify clear trends of explainability in process mining. However, the results conclude that explainability depends on the process model’s transparency and reproducibility. Moreover, further research with a large sample size is required to understand the discrete factors impacting decision-making in business process management.},
  keywords={Analytical models;Explainable AI;Decision making;Market research;Business process management;Data mining;Business;Data Science;Process Mining;Explainability;Transparency},
  doi={10.1109/FIT60620.2023.00018},
  ISSN={2473-7569},
  month={Dec},}@INPROCEEDINGS{10884515,
  author={Duell, Jamie and Seisenberger, Monika and Fu, Hsuan and Fan, Xiuyi},
  booktitle={2024 IEEE International Conference on Data Mining (ICDM)}, 
  title={QUCE: The Minimisation and Quantification of Path-Based Uncertainty for Generative Counterfactual Explanations}, 
  year={2024},
  volume={},
  number={},
  pages={693-698},
  abstract={Deep Neural Networks (DNNs) stand out as one of the most prominent approaches within the Machine Learning (ML) domain. The efficacy of DNNs has surged alongside recent increases in computational capacity, allowing these approaches to scale to significant complexities for addressing predictive challenges in big data. However, as the complexity of the DNN models increases, interpretability diminishes. In response to this challenge, explainable models such as Adversarial Gradient Integration (AGI) leverage path-based gradients provided by DNNs to elucidate their decisions. Yet, the performance of path-based explainers can be compromised when gradients exhibit irregularities during out-of-distribution path traversal. In this context, we introduce Quantified Uncertainty Counterfactual Explanations (QUCE), a method designed to mitigate out-of-distribution traversal by minimizing path uncertainty. QUCE not only quantifies uncertainty when presenting explanations but also generates more certain counterfactual examples. We showcase the performance of the QUCE method by comparing it with competing methods for both path-based explanations and generative counterfactual examples. The code repository for the QUCE method is available at: https://github.com/jamie-duell/QUCE_ICDM.},
  keywords={Measurement;Uncertainty;Computational modeling;Artificial neural networks;Machine learning;Feature extraction;Minimization;Complexity theory;Reliability;Data mining;Explainable Artificial Intelligence;Deep Learning;Counterfactual;Uncertainty},
  doi={10.1109/ICDM59182.2024.00078},
  ISSN={2374-8486},
  month={Dec},}@INPROCEEDINGS{11019696,
  author={Sivamurugan, S and Susila Sakthy, S},
  booktitle={2025 International Conference on Computing and Communication Technologies (ICCCT)}, 
  title={Framework for Quick Visuals Insight Discovery in the Data Workflows}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Data-driven decision-making growth demands rapid frameworks to discover visual insights which bring value to data pipelines. Decision-making processes require time-sensitive visualization and interpretation because standard data analysis approaches handle limited amounts of data effectively. The survey investigates multiple frameworks and methodologies that improve visual analytics through interactive visualization methods and automated insights generation as well as large-scale data processing platforms. The research investigates modern visualization methods based on deep learning models as well as explainable AI (XAI) systems that produce insights and adaptive dashboards which are evaluated for their advantages and barriers. The survey analyses the problems that stem from handling large-scale data dimensions as well as maintaining interpretability and achieving optimal computation speeds. Future research focuses on generative AI as a tool to improve visualization methods and federated learning to maintain confidential analytics while edge computing provides immediate results. This paper gathers recent innovation progress to deliver researchers and practitioners complete understanding about developing visual insight discovery trends and innovations in data workflow applications.},
  keywords={Deep learning;Surveys;Technological innovation;Accuracy;Data analysis;Explainable AI;Visual analytics;Decision making;Data visualization;Real-time systems;Data Visualization;Insight Discovery;Visual Analytics;Exploratory Data Analysis;Real-Time Analytics;Automated Data Summarization;Interactive Dashboards;Explainable AI},
  doi={10.1109/ICCCT63501.2025.11019696},
  ISSN={2995-3197},
  month={April},}@INBOOK{9111451,
  author={Lee, Mark H.},
  booktitle={How to Grow a Robot: Developing Human-Friendly, Social AI}, 
  title={9 BUILDING GIANT BRAINS}, 
  year={2020},
  volume={},
  number={},
  pages={125-144},
  abstract={If you want to build an artificially intelligent machine, why not build an artificial brain? This is an obvious plan: The human brain is the source of human intelligence, and so if we could copy it somehow, we would expect to reproduce at least some aspects of intelligence. This attractive approach has been tried before, and there are several ongoing projects in this area. The big snag with "copying the brain somehow" is that no one has yet figured out how the brain actually works. Modern neuroscience has made rapid progress in recent years, but despite gaining much understanding of specific detail, the big picture remains elusive. We still can't answer questions such as, "How is thought generated and held in the brain?" or "How did I store that memory or make that decision?"},
  keywords={},
  doi={},
  ISSN={},
  publisher={MIT Press},
  isbn={9780262357852},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/9111451},}@INBOOK{10834092,
  author={Iqbal, Mohammed Ismail and Kaushik, Priyanka},
  booktitle={AI in Disease Detection: Advancements and Applications}, 
  title={Deep Learning for Disease Detection &#x2014; A Deep Dive into Deep Learning Techniques Such as Convolutional Neural Networks (CNNs) and Their Use in Disease Detection}, 
  year={2025},
  volume={},
  number={},
  pages={99-122},
  abstract={Summary <p>The mixing of superior deep learning strategies has deeply affected the sector of disease identification, promising sizeable advancements in diagnostic accuracy and performance. This chapter explores the utilization of multiscale convolutional layers, interest mechanisms, switch learning, generative adverse networks (GANs), and self&#x2010;supervised learning in the healthcare domain. These techniques collectively beautify the capability of convolutional neural networks (CNNs) to discover and diagnose diseases from medical pix with extraordinary precision. Multiscale convolutional layers allow the models to capture features at numerous scales, improving the sensitivity and specificity of ailment detection, mainly in situations like most cancers. Attention mechanisms similarly refine this process by allowing models to focus on the most applicable components of an image, mirroring the meticulous examination by human professionals.</p> <p>The chapter discusses deep learning, leveraging pre&#x2010;educated models, which extensively reduces the reliance on tremendous, categorized datasets, thereby expediting the development process and enhancing version accuracy. This approach has shown outstanding success throughout distinctive imaging modalities, from X&#x2010;rays to CT scans, improving the adaptability and robustness of diagnostic models. GANs contribute via producing artificial records to augment schooling datasets, addressing the challenge of limited data availability and enhancing model performance, specifically in uncommon disease scenarios. Self&#x2010;supervised learning, which trains models on unlabeled records via proxy duties, has demonstrated comparable performance to absolutely supervised models while requiring fewer categorized samples, therefore lowering the need for luxurious and time&#x2010;eating data annotation.</p> <p>Innovations in these areas have not only enhanced the technical performance of disease detection models but also expanded their potential applications. Future studies instructions consist of the exploration of multimodal learning, which mixes data from various assets including genomic information and digital health data, imparting a more complete diagnostic perspective. The implementation of federated learning guarantees data privacy while enhancing version training via decentralized records assets. Explainable AI (XAI) techniques enhance version interpretability, fostering more consideration and popularity amongst healthcare professionals. Moreover, the integration of AI with wearable devices for continuous fitness tracking, and the improvement of real&#x2010;time adaptive knowledge of models, hold tremendous promise for revolutionizing patient care and disease control.</p> <p>This comprehensive method to leveraging superior deep learning methodologies in disorder identification underscores the transformative potential of AI in healthcare. With the aid of addressing modern&#x2010;day demanding situations and exploring progressive answers, we can pave the way for greater accurate, efficient, and personalized diagnostic systems, in the end enhancing patient outcomes by using advanced AI and deep learning to enhance diagnostic accuracy, treatment efficiency, and patient outcomes, ultimately setting a new benchmark for best practices in healthcare.</p>},
  keywords={Diseases;Medical diagnostic imaging;Deep learning;Accuracy;Data models;Transfer learning;Training;Magnetic resonance imaging;Explainable AI;Data augmentation},
  doi={10.1002/9781394278695.ch5},
  ISSN={},
  publisher={IEEE},
  isbn={9781394278688},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10834092},}@INPROCEEDINGS{6966273,
  author={Kotteeswaran, C. and Rajesh, A.},
  booktitle={Second International Conference on Current Trends In Engineering and Technology - ICCTET 2014}, 
  title={A survey of diverse nature bio-inspired computing models}, 
  year={2014},
  volume={},
  number={},
  pages={120-124},
  abstract={Natural computing, also called Natural computation, is a recent emerging field of research that introduces three classes of methods: 1) a division of techniques which can be used to solve novel problems by retrieving inspiration from the nature; 2) a division that concentrates on the use of computers to synthesize natural observable fact; and 3) a division that employ natural materials (e.g., molecules) to compute. The main scheme of research that compose these three branches are artificial neural networks, evolutionary algorithms, swarm intelligence, artificial immune systems, fractal geometry, artificial life, DNA computing, and quantum computing, among others. In this paper, we make an attempt to investigate the working nature, applications, variants and generative power of various bio-inspired computing models such as membrane computing, splicing circular words, Bidirectional sticker system.},
  keywords={Biomembranes;Splicing;Automata;Computational modeling;Conferences;Biological system modeling;Bio-inspired Computing;Membrane Computing;Watson crick two-way finite Automata;Splicing Circular words},
  doi={10.1109/ICCTET.2014.6966273},
  ISSN={},
  month={July},}@INPROCEEDINGS{11047663,
  author={Li, Meng and Kong, Xianguang and Li, Hong and Gao, Bo and Wang, Pengfei},
  booktitle={2025 5th International Conference on Artificial Intelligence and Industrial Technology Applications (AIITA)}, 
  title={Research on Process Quality Prediction and Optimization Techniques for Solid Fuel Rocket Engine Integrated with Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={163-169},
  abstract={Solid fuel rocket engines serve as a crucial technological foundation for rapid space launch capabilities and are a significant indicator of national strategic weapon delivery capabilities. With the continuous advancement of industrial manufacturing systems, particularly the explosive growth of generative artificial intelligence technologies in recent years, the ability to collect and analyze vast amounts of industrial big data has been greatly enhanced. Consequently, exploring the deep correlations between production parameters and product quality has become a key aspect of the manufacturing process for solid fuel rocket engines. This paper, set against the backdrop of solid fuel rocket engine manufacturing, leverages machine learning, large model technologies, and other AI algorithms to study the relationship between quality data and quality issues in the production process. By identifying potential quality problems in advance, the research aims to provide timely recommendations for process parameter optimization, thereby reducing material waste, rework, and scrap. This approach holds significant practical value in reducing component quality issues and enhancing the controllability of the production process.},
  keywords={Rockets;Adaptation models;Solid modeling;Machine learning algorithms;Large language models;Production;Solids;Fuels;Engines;Optimization;Solid Rocket Engine;Component Machining;Machine Learning;Large Language Models;Quality Prediction;Optimization Algorithms},
  doi={10.1109/AIITA65135.2025.11047663},
  ISSN={},
  month={March},}@ARTICLE{10382545,
  author={Liu, Fangfang and Sun, Zhengfen and Yang, Yang and Guo, Caili and Zhao, Shan},
  journal={IEEE Internet of Things Journal}, 
  title={Rate-Adaptable Multitask-Oriented Semantic Communication: An Extended Rate–Distortion Theory-Based Scheme}, 
  year={2024},
  volume={11},
  number={9},
  pages={15557-15570},
  abstract={Semantic communication, as a new paradigm for next-generation communication, aims to transmit semantic symbols for artificial intelligence (AI) tasks. Existing research typically requires extracting and transmitting specialized semantics for each AI task when multiple target AI tasks exist. Considering that each AI task may share common semantics, this article proposes a joint source–channel coding scheme for a multitask semantic communication (MTSC) system, which can extract the common semantics required by multiple AI tasks, and thus reduce the overall semantic transmission. To this end, we first formulate the MTSC problem as a rate–distortion problem that simultaneously considers the rate of extracted semantics and the distortion of multiple AI tasks. Then, we derive a new form of rate–distortion, called extended rate–distortion, which can guide the compact semantics extraction of multiple AI tasks simultaneously. Additionally, we derive a self-consistent equation for this extended rate–distortion form, theoretically proving the effectiveness of this approach. To ensure proper tradeoff between the rates and distortions of multiple AI tasks, we further propose a rate adjustment module that can dynamically adjust the rate according to channel conditions. We validate our experimental results on multiple data sets, which show that the proposed method can reduce transmission overhead by 40%–50% and achieve a 7.6% improvement in multitask performance.},
  keywords={Semantics;Task analysis;Multitasking;Artificial intelligence;Rate-distortion;Distortion;Communication systems;Adaptive networks;extended rate–distortion theory;multitask semantic communication (MTSC);selfconsistent equation},
  doi={10.1109/JIOT.2024.3350656},
  ISSN={2327-4662},
  month={May},}@ARTICLE{10492795,
  author={},
  journal={Engineering & Technology}, 
  title={Comment: Artificial intelligence: Are your AI-based software platforms becoming a legal liability?}, 
  year={2023},
  volume={18},
  number={5},
  pages={21-21},
  abstract={WHEN CHATGPT launched last year, it took the tech world by storm due to the role it can play both as a smart coding assistant and, more generally, to help speed up the writing process for people in almost any walk of life. Since then, generative AI systems for a variety of uses have gained fans the world over. However, there are some potential legal issues on the horizon.},
  keywords={},
  doi={10.1049/et.2023.0503},
  ISSN={1750-9637},
  month={June},}
