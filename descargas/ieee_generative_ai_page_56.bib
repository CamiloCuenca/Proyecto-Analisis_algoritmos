@INPROCEEDINGS{8695407,
  author={Huang, Dou and Song, Xuan and Fan, Zipei and Jiang, Renhe and Shibasaki, Ryosuke and Zhang, Yu and Wang, Haizhong and Kato, Yugo},
  booktitle={2019 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)}, 
  title={A Variational Autoencoder Based Generative Model of Urban Human Mobility}, 
  year={2019},
  volume={},
  number={},
  pages={425-430},
  abstract={Recently, big and heterogeneous human mobility data inspires many revolutionary ideas of implementing machine learning algorithms for solving some traditional social issues, such as zone regulation, air pollution, and disaster evacuation el at.. However, incomplete datasets were provided owing to both the concerns of violation of privacy and some technique issues in many practical applications, which leads to some limitations of the utility of collected data. Variational Autoencoder (VAE), which uses a well-constructed latent space to capture salient features of the training data, shows a significant excellent performance in not only image processing, but also Natural Language Processing domain. By combining VAE and sequence-to-sequence (seq2seq) model, a Sequential Variational Autoencoder (SVAE) is built for the task of human mobility reconstruction. It is the first time that this kind of SVAE model is implemented for solving the issues about human mobility reconstruction. We use navigation GPS data of selected greater Tokyo area to evaluate the performance of the SVAE model. Experimental results demonstrate that the SVAE model can efficiently capture the salient features of human mobility data and generate more reasonable trajectories.},
  keywords={Trajectory;Hidden Markov models;Global Positioning System;Data models;Gaussian distribution;Data privacy;human mobility;generative model;machine learning},
  doi={10.1109/MIPR.2019.00086},
  ISSN={},
  month={March},}@INPROCEEDINGS{10648013,
  author={Pontorno, Orazio and Guarnera, Luca and Battiato, Sebastiano},
  booktitle={2024 IEEE International Conference on Image Processing (ICIP)}, 
  title={On the Exploitation of DCT-Traces in the Generative-AI Domain}, 
  year={2024},
  volume={},
  number={},
  pages={3806-3812},
  abstract={Deepfakes represent one of the toughest challenges in the world of Cybersecurity and Digital Forensics, especially considering the high-quality results obtained with recent generative AI-based solutions. Almost all generative models leave unique traces in synthetic data that, if analyzed and identified in detail, can be exploited to improve the generalization limitations of existing deepfake detectors. In this paper we analyzed deepfake images in the frequency domain generated by both GAN and Diffusion Model engines, examining in detail the underlying statistical distribution of Discrete Cosine Transform (DCT) coefficients. Recognizing that not all coefficients contribute equally to image detection, we hypothesize the existence of a unique “discriminative fingerprint”, embedded in specific combinations of coefficients. To identify them, Machine Learning classifiers were trained on various combinations of coefficients. In addition, the Explainable AI (XAI) LIME algorithm was used to search for intrinsic discriminative combinations of coefficients. Finally, we performed a robustness test to analyze the persistence of traces by applying JPEG compression. The experimental results reveal the existence of traces left by the generative models that are more discriminative and persistent at JPEG attacks. Code and dataset are available at github/opontorno/dcts_analysis_deepfakes.},
  keywords={Deepfakes;Machine learning algorithms;Image recognition;Image coding;Transform coding;Statistical distributions;Fingerprint recognition;Synthetic Traces;Deepfakes;Multimedia Forensics},
  doi={10.1109/ICIP51287.2024.10648013},
  ISSN={2381-8549},
  month={Oct},}@ARTICLE{10792879,
  author={Ihsan, Imran and Imran, Azhar and Sher, Tahir and Al-Rawi, Mahmood Basil A. and Elmeligy, Mohammed A. and Pathan, Muhammad Salman},
  journal={IEEE Access}, 
  title={Graph-Based COVID-19 Detection Using Conditional Generative Adversarial Network}, 
  year={2024},
  volume={12},
  number={},
  pages={191323-191344},
  abstract={Coronavirus (SARS-CoV-2) is a novel global pandemic, which requires rapid and accurate identification techniques to curb its spread. COVID-19, the disease induced by the virus, causes severe respiratory complications, necessitating advanced diagnostic tools for early detection. Recent research indicates the potential of radiographic imaging in unravelling critical insights into the characteristics of this formidable pathogen. Leveraging the advancements in Computer Vision (CV) and deep learning methodologies, an automated system can be devised to discern respiratory anomalies from X-ray images, enhancing conventional diagnostic methods. In this study, we propose a pioneering approach for COVID-19 diagnosis utilizing chest radiographs. The proposed methodology encompasses four distinct phases: initial segmentation of raw chest radiographs employing Conditional Generative Adversarial Networks (CGAN), followed by feature extraction through a tailored pipeline integrating both manual computer vision algorithms and pre-trained Deep Neural Network (DNN) models. Subsequently, a graph-based feature reconstruction technique amalgamates these extracted features across the network, culminating in a comprehensive representation. These reconstructed features serve as input to a classification module, comprising a multi-layer neural network, GCN, adept at processing graph-structured data, alongside conventional machine learning classifiers such as Support Vector Machine (SVM), Extreme Gradient Boosting (XGBoost), and Random Forest (RF), facilitating categorization of chest X-ray images into COVID-19, pneumonia, and normal cases. Furthermore, we conduct an exhaustive evaluation of the selected DNN architectures to ascertain the efficacy of our proposed models vis-à-vis existing research, thus ensuring the deployment of the most robust diagnostic framework.},
  keywords={COVID-19;Image segmentation;X-ray imaging;Feature extraction;Generative adversarial networks;Pneumonia;Biomedical imaging;Lungs;Accuracy;Computed tomography;COVID-19;image segmentation;C-GAN;deep neural network (DNN);key point extraction;classification models},
  doi={10.1109/ACCESS.2024.3515160},
  ISSN={2169-3536},
  month={},}@INBOOK{11049769,
  author={HERMAN, ERIK},
  booktitle={Optimizing Prompt Engineering for Generative AI}, 
  title={Chapter 7: Hands-On Exercises and Case Studies}, 
  year={2025},
  volume={},
  number={},
  pages={147-172},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9781501521379},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11049769},}@INBOOK{10952367,
  author={Lewrick, Michael and Hatamleh, Omar},
  booktitle={AI and Innovation: How to Transform Your Business and Outpace the Competition with Generative AI}, 
  title={Front Matter}, 
  year={2025},
  volume={},
  number={},
  pages={1-15},
  abstract={<p>The prelims comprise: <ul> <li>Book Serice Page</li> <li>Copyright Page</li> <li>Title Page</li> <li>Table of Contents</li> <li>About the authors</li> <li>Preface</li> <li>Motivation for the Topic</li> </ul> </p>},
  keywords={},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394254996},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952367},}@INPROCEEDINGS{10900657,
  author={Gujjar, Deepesh and Upadhye, Sanatkumar and Sinha, Sandipan and Khursheed, Taha and Patel, Jigar and Sidhu, Jaswinder and Trivedi, Manish and Abachi, Sagar},
  booktitle={2025 38th International Conference on VLSI Design and 2024 23rd International Conference on Embedded Systems (VLSID)}, 
  title={An Innovative Solution to Improve Ultra Low Voltage Writability and Leakage in GPU SRAMs}, 
  year={2025},
  volume={},
  number={},
  pages={203-207},
  abstract={Increase in the use of Generative AI has led to an increasing demand for state-of-the-art Graphics Processing Unit (GPU) cores for their parallel processing and energy efficiency. GPUs enable training of Large Language Models (LLMs) over millions of matrix operations and new features such as native raytracing and high-resolution video rendering. Thermal efficiency and stand by time are becoming major concerns as handheld computation power is increasing exponentially, to optimize this, GPUs must work at lower voltages. Though new technology nodes promise faster performance at lower power for many IPs, SRAM scaling trends are not on par due to bit cell scaling limitations especially for Ultra Low Voltage (ULV) corners. To overcome these limitations, innovative circuit solutions have been implemented in the below discussed 3nm SRAM to enable successful write operation at Ultra Low Voltage domain while providing significant leakage power gains.},
  keywords={Training;Low voltage;Graphics processing units;Random access memory;Very large scale integration;Parallel processing;Rendering (computer graphics);Market research;Robustness;Energy efficiency;AI;GPU;ULV;bit cell;write;leakage;SRAM;SOC},
  doi={10.1109/VLSID64188.2025.00048},
  ISSN={2380-6923},
  month={Jan},}@INBOOK{11049776,
  author={HERMAN, ERIK},
  booktitle={Optimizing Prompt Engineering for Generative AI}, 
  title={Contents}, 
  year={2025},
  volume={},
  number={},
  pages={v-xx},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9781501521379},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11049776},}@INBOOK{11049708,
  author={HERMAN, ERIK},
  booktitle={Optimizing Prompt Engineering for Generative AI}, 
  title={Chapter 8: Best Practices and Future Directions}, 
  year={2025},
  volume={},
  number={},
  pages={173-188},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9781501521379},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11049708},}@ARTICLE{10815972,
  author={Son, Nguyen Khanh and Sangaiah, Arun Kumar and Medhane, Darshan Vishwasrao and Alenazi, Mohammed J. F. and Aborokbah, Majed},
  journal={IEEE Consumer Electronics Magazine}, 
  title={Enhancing Resilience in Edge IoT Devices Against Adversarial Attacks}, 
  year={2025},
  volume={14},
  number={4},
  pages={48-56},
  abstract={With the rapid growth of consumer electronics devices, the traditional centralized cloud computing paradigm faces significant challenges, including high latency, limited capacity, and susceptibility to network failures. Fog computing, an edge-based computing paradigm, has emerged to address these issues by processing and computing Internet of Things (IoT) data at the device level rather than relying on the cloud. This paradigm shift presents an opportunity to embed artificial intelligence (AI) models directly into edge intelligence devices. However, deploying AI models at edge IoT devices presents several challenges, such as adversarial attacks, due to the increased physical accessibility of IoT devices to attackers, especially it is difficult to identify the specific types of threats that might be injected to the system. In this article, we propose a framework for adversarial training to enhance the robustness of AI models against unknown adversarial attacks by employ SE-GAN, a self-attention conditional generative adversarial network-based model to generate adversarial samples and train the AI model using this adversarial dataset.},
  keywords={Training;Internet of Things;Data models;Servers;Computational modeling;Consumer electronics;Generative adversarial networks;Edge computing;Cloud computing;Security;Resilience},
  doi={10.1109/MCE.2024.3522524},
  ISSN={2162-2256},
  month={July},}@INPROCEEDINGS{10986615,
  author={Rouf, Muntaha and Jadon, Jitendra Singh},
  booktitle={2025 3rd International Conference on Disruptive Technologies (ICDT)}, 
  title={Generative AI for Text to Speech and Sign Language Translation}, 
  year={2025},
  volume={},
  number={},
  pages={1124-1129},
  abstract={This paper presents the development of an AI-powered platform designed to enhance real-time communication for individuals with speech and hearing impairments. The system integrates 3D animation, Natural Language Processing[15] (NLP), and Automatic Speech Recognition [1] [2] (ASR) to convert spoken words into sign language gestures. By utilizing advanced speech recognition models, natural language understanding, and dynamic 3D [6] gesture generation, the platform ensures a smooth and intuitive communication experience. To promote inclusivity, the system supports both multilingual and regional sign languages, making it accessible across diverse linguistic and cultural backgrounds. This solution bridges the gap in real-time communication tools by offering a scalable and accessible platform for both web and mobile applications. Ultimately, the goal is to empower individuals with disabilities, enhance their interaction with digital environments, and foster greater social inclusion.},
  keywords={Sign language;Three-dimensional displays;Translation;Auditory system;Speech enhancement;Real-time systems;Natural language processing;Multilingual;Text to speech;Noise measurement;generative AI;sign language;text to speech;natural language processing},
  doi={10.1109/ICDT63985.2025.10986615},
  ISSN={},
  month={March},}@INBOOK{11049753,
  author={HERMAN, ERIK},
  booktitle={Optimizing Prompt Engineering for Generative AI}, 
  title={Chapter 1: Introduction to Prompt Engineering}, 
  year={2025},
  volume={},
  number={},
  pages={1-16},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9781501521379},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11049753},}@INBOOK{10951764,
  author={Lewrick, Michael and Hatamleh, Omar},
  booktitle={AI and Innovation: How to Transform Your Business and Outpace the Competition with Generative AI}, 
  title={SOURCES}, 
  year={2025},
  volume={},
  number={},
  pages={257-262},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394254996},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951764},}@ARTICLE{9274341,
  author={Park, Sungho and Hwang, Sunhee and Hong, Jongkwang and Byun, Hyeran},
  journal={IEEE Access}, 
  title={Fair-VQA: Fairness-Aware Visual Question Answering Through Sensitive Attribute Prediction}, 
  year={2020},
  volume={8},
  number={},
  pages={215091-215099},
  abstract={Visual Question Answering (VQA) is a task that answers questions on given images. Although previous works achieve a great improvement in VQA performance, they do not consider the fairness of answers in terms of ethically sensitive attributes, such as gender. Therefore, we propose a Fair-VQA model that contains two modules: VQA module and SAP (Sensitive Attribute Prediction) module. On top of VQA module, which predicts various kinds of answers, SAP module predicts only sensitive attributes using the same inputs. The predictions of SAP module are utilized to rectify answers from VQA module to be fairer in terms of the sensitive attributes with graceful performance degradation. To validate the proposed method, we conduct extensive experiments on VQA, GQA, and our proposing VQA-Gender datasets. In all the experiments, our method shows the fairest results in various metrics for fairness. Moreover, we demonstrate that our method works interpretably through the analysis of visualized attention maps.},
  keywords={Visualization;Task analysis;Predictive models;Knowledge discovery;Face recognition;Artificial intelligence;Data models;FAI;fairness;visual question answering;VQA},
  doi={10.1109/ACCESS.2020.3041503},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10991119,
  author={Patil, Ratna and Nikam, Ajinkya and Lichade, Tanush and Patel, Rajat and Maheshwari, Deep and Rajguru, Aryan},
  booktitle={2025 International Conference on Cognitive Computing in Engineering, Communications, Sciences and Biomedical Health Informatics (IC3ECSBHI)}, 
  title={Intelligent PDF Query System for Document Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={665-669},
  abstract={A system based on artificial intelligence has been built to enable readers' interactions with PDF files through queries and responses in regular language. The system also utilizes advanced natural language processing techniques such as document-level contextualized representations to aid in effective document analysis so that users can locate information easily and precisely. The use of such document parsing and the vector storage mechanisms combing with the generative AI models and also the transformer based architecture offers an innovative approach to querying about the content within PDF documents overcoming the hurdles posed by conventional document retrieval systems. From the qualitative approach it is evident that the system improves the accuracy of responses and the level of user satisfaction significantly more than conventional methods of document retrieval. Such system efforts not only augment productivity with source of AI but the intelligent search options also help the general audience attract examine and consume complicated and heavy materials. Such improvements result in ease of information extraction and lessen the amount of attention that would have been used when dealing with large loads of information.},
  keywords={Productivity;Text analysis;Accuracy;Scalability;Organizations;Portable document format;Transformers;Natural language processing;Vectors;Time factors;PDF Document Analysis;NLP;AI-Based Question-Answering System;Google Gemini AI;FAISS},
  doi={10.1109/IC3ECSBHI63591.2025.10991119},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10605440,
  author={Verma, Tanvi and Filho, Ricardo Shirota},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={PLNet: Light Recipe Design for Indoor Farming through Generative Deep Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1092-1097},
  abstract={Indoor farming has emerged as a promising solution for year-round cultivation and efficient resource utilization in crop production. Achieving optimal plant growth and quality in indoor environments requires precise control of light conditions. This study introduces PLNet, a generative deep learning method for the designing the light recipes specifically tailored for indoor farming.Leveraging the power of deep neural networks, our approach establishes complex connections between light spectra and plant growth characteristics. Initially, a biomass estimator model is trained using a diverse dataset encompassing different light recipes and corresponding plant responses. Subsequently, a generative model is trained using the estimator model as a foundation, enabling the generation of optimal light spectra to achieve desired growth outcomes. This novel generative method offers an efficient and effective approach to formulating light recipes for indoor farming. By reducing the reliance on traditional trial-and-error methods, our method saves significant time and resources.The presented generative deep learning method holds great potential for advancing the design of light recipes in indoor farming. Leveraging the capabilities of deep neural networks facilitates more targeted and efficient optimization of light conditions, resulting in improved crop yield and quality for a variety of leafy green crops. The findings of this study contribute to the ongoing efforts in enhancing productivity and sustainability in indoor cultivation practices.},
  keywords={Deep learning;Biological system modeling;Artificial neural networks;Linear programming;Generators;Vectors;Biomass;Indoor farming;Generative deep learning;Light treatment;Light recipe design},
  doi={10.1109/CAI59869.2024.00197},
  ISSN={},
  month={June},}@ARTICLE{9616389,
  author={Liao, Wenlong and Yang, Zhe and Chen, Xinxin and Li, Yaqi},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={WindGMMN: Scenario Forecasting for Wind Power Using Generative Moment Matching Networks}, 
  year={2022},
  volume={3},
  number={5},
  pages={843-850},
  abstract={With the increasing penetration of wind power generation, the fluctuating and intermittent behavior of wind power poses huge challenges to the operation and planning of distribution networks. A popular way to mitigate these challenges is to provide a group of possible wind power forecasting scenarios instead of depending on deterministic point forecasting values, so that system operators can consider the uncertainties. This letter proposes a novel WindGMMN method for wind power scenario forecasting, in which necessary modifications are made on the generative moment matching network (GMMN), and an optimization strategy is designed to find a series of wind power scenarios with similar shapes, probability distributions, and temporal correlations as potential scenarios. Simulations and analyses were performed on a public dataset with 2190 wind power generation curves and their corresponding meteorological features. The results show that the proposed WindGMMN outperforms popular baselines (e.g., variational auto-encoders and generative adversarial networks) for scenario forecasting of wind power, without any restrictions on the time horizon (e.g., times ranging from 10 min to 24 h).},
  keywords={Wind power generation;Forecasting;Optimization;Predictive models;Uncertainty;Machine learning;Deep learning;Deep learning;generative moment matching network (GMMN);machine learning;scenario forecasts;wind power},
  doi={10.1109/TAI.2021.3128368},
  ISSN={2691-4581},
  month={Oct},}@ARTICLE{10869347,
  author={Ivanov, Petr and Shtark, Maria and Kozhevnikov, Alexander and Golyadkin, Maksim and Botov, Dmitry and Makarov, Ilya},
  journal={IEEE Access}, 
  title={SensorDBSCAN: Semi-Supervised Active Learning Powered Method for Anomaly Detection and Diagnosis}, 
  year={2025},
  volume={13},
  number={},
  pages={25186-25197},
  abstract={Fault detection and diagnosis (FDD) is a critical challenge in industrial processes aimed at minimizing risks such as safety hazards, costly downtime, and suboptimal production. Traditional supervised FDD methods offer great performance while heavily relying on large volumes of labeled data, whereas unsupervised methods do not depend on labeled data, though are inferior in performance compared to supervised ones. In this paper, we propose SensorDBSCAN, a novel semi-supervised method for anomaly detection and diagnosis. The key innovation lies in achieving good performance with minimal labeled data - less than 1% of the dataset - by leveraging active and contrastive learning techniques. The proposed approach combines a transformer-based encoder trained with a triplet-based contrastive learning objective and the classical density-based clustering algorithm DBSCAN, enabling strong feature extraction, efficient and interpretable feature space organization and simple clustering algorithm. Unlike existing methods, SensorDBSCAN eliminates the need for manual labeling large amounts of data, cluster analysis, and pre-defining cluster numbers, providing greater usability in real-world cases. We validate the effectiveness of our method on the Tennessee Eastman Process (TEP) and its advanced simulations (TEP Rieth and TEP Rieker). SensorDBSCAN demonstrates better performance on well-known and realistic datasets, reducing labeling requirements while maintaining high accuracy of fault detection and diagnostics. The code is available at https://github.com/K0mp0t/sensordbscan.},
  keywords={Active learning;Training;Fault detection;Labeling;Anomaly detection;Transformers;Feature extraction;Computational modeling;Accuracy;Time series analysis;Active learning;semi-supervised learning;time series anomaly detection and diagnosis},
  doi={10.1109/ACCESS.2025.3537649},
  ISSN={2169-3536},
  month={},}@ARTICLE{11108704,
  author={Zhong, Lanfeng and Huang, Zongyao and Liu, Yang and Liao, Wenjun and Zhang, Shichuan and Wang, Guotai and Zhang, Shaoting},
  journal={IEEE Transactions on Medical Imaging}, 
  title={VLM-CPL: Consensus Pseudo-Labels from Vision-Language Models for Annotation-Free Pathological Image Classification}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Classification of pathological images is the basis for automatic cancer diagnosis. Despite that deep learning methods have achieved remarkable performance, they heavily rely on labeled data, demanding extensive human annotation efforts. In this study, we present a novel human annotation-free method by leveraging pre-trained Vision-Language Models (VLMs). Without human annotation, pseudo-labels of the training set are obtained by utilizing the zero-shot inference capabilities of VLM, which may contain a lot of noise due to the domain gap between the pre-training and target datasets. To address this issue, we introduce VLM-CPL, a novel approach that contains two noisy label filtering techniques with a semi-supervised learning strategy. Specifically, we first obtain prompt-based pseudo-labels with uncertainty estimation by zero-shot inference with the VLM using multiple augmented views of an input. Then, by leveraging the feature representation ability of VLM, we obtain feature-based pseudo-labels via sample clustering in the feature space. Prompt-feature consensus is introduced to select reliable samples based on the consensus between the two types of pseudo-labels. We further propose High-confidence Cross Supervision by to learn from samples with reliable pseudo-labels and the remaining unlabeled samples. Additionally, we present an innovative open-set prompting strategy that filters irrelevant patches from whole slides to enhance the quality of selected patches. Experimental results on five public pathological image datasets for patch-level and slide-level classification showed that our method substantially outperformed zero-shot classification by VLMs, and was superior to existing noisy label learning methods. The code is publicly available at https://github.com/HiLab-git/VLM-CPL.},
  keywords={Training;Pathology;Noise measurement;Image classification;Annotations;Reliability;Cancer;Accuracy;Feature extraction;Noise;Pathological image classification;foundation model;pseudo-label;noisy label learning},
  doi={10.1109/TMI.2025.3595111},
  ISSN={1558-254X},
  month={},}@ARTICLE{11153509,
  author={Tian, Qing and Liu, Xiang and Sun, Jixin and Wan, Jun and Lei, Zhen},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Unsupervised Domain Adaptation Person Re-Identification: Bridged by Feature Fusion Transitional Domain}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={The goal of unsupervised domain adaptation person re-identification (UDA Reid) is to achieve feature space alignment between the source domain and the target domain, so that the Reid model can effectively match pedestrians in the target domain. Creating the transitional domain is an effective approach, but existing models often have difficulty synthesizing transitional domains with sufficiently public features. To tackle this challenge, we propose an innovative approach named feature fusion transitional domain (F2TD-Reid), which comprises two essential components: the dictionary fusion module (DFM) and the transitional domain attention module (TDAM). Among them, the DFM utilizes a feature fusion to extract and reconstruct pedestrian images from instances, focusing on capturing the essential visual elements within the images. For the TDAM, it further refines the feature extraction of instance points through an innovative weighted attention mechanism. These two modules optimize the generation process of scaling factors, thereby facilitating the transfer of knowledge between the source domain and the target domain. Through a series of comparative experiments, we verify the superiority of the F2TD-Reid method in solving UDA Reid. The code is available at https://github.com/1x-x/F2TD-Reid.},
  keywords={Feature extraction;Dictionaries;Training;Semantics;Security;Information science;Image reconstruction;Identification of persons;Adaptation models;Transformers;Person re-identification;unsupervised domain adaptation;feature fusion;transitional domain},
  doi={10.1109/TIFS.2025.3607258},
  ISSN={1556-6021},
  month={},}@INPROCEEDINGS{10390657,
  author={Shao, Hengyi and Li, Lei and Zhang, Lin},
  booktitle={2023 8th IEEE International Conference on Network Intelligence and Digital Content (IC-NIDC)}, 
  title={Unsupervised Domain Adaptation Algorithm Improved with Balanced Sampling}, 
  year={2023},
  volume={},
  number={},
  pages={56-60},
  abstract={Sleep disorders seriously affect human health. Leveraging deep learning methods and Electroencephalography, automatic sleep staging can aid experts in accurately diagnosing patients' sleep disorders. However, the imbalance of the training data undermines the learning of minority class features. Besides, the performance of the automatic sleep staging model obtained on the training data tends to decrease on the practical data due to the difference in data distribution. As a result, an unsupervised domain adaptation algorithm combined with class rebalancing strategy and semi-supervised learning is proposed to solve the above problems. To alleviate data imbalance in sleep staging datasets, our paper devises a balanced sampler. Random logit interpolation and relative confidence threshold are introduced to improve the accuracy of pseudo-labels. Moreover, distribution alignment is introduced to mitigate the dissimilarity in data distribution between the source and target domains. Through experiments, the effectiveness of the proposed method is proved on the SHHS, Sleep-EDF and ISRUC-Sleep datasets. The average improvement in accuracy is around 5.27%. Both the F1 score and recall rate have also been significantly improved.},
  keywords={Deep learning;Interpolation;Adaptation models;Training data;Semisupervised learning;Feature extraction;Brain modeling;Unsupervised Domain Adaptation Algorithm;Balanced sampling;Distribution alignment;Automatic sleep staging},
  doi={10.1109/IC-NIDC59918.2023.10390657},
  ISSN={2575-4955},
  month={Nov},}@INPROCEEDINGS{10390596,
  author={Liang, Xin and Liu, Zhenyu and Zhang, Lin},
  booktitle={2023 8th IEEE International Conference on Network Intelligence and Digital Content (IC-NIDC)}, 
  title={Real-World Wireless Channel Data Augmentation Using Adversarial Autoencoder for DL-Based Massive Mimo CSI Feedback}, 
  year={2023},
  volume={},
  number={},
  pages={232-236},
  abstract={In massive multiple-input multiple-output (MIMO) systems, deep learning (DL)-based channel state information (CSI) feedback can provide high downlink throughput with limited feedback overhead. However, insufficient wireless channel data in the actual situation impairs the reconstruction accuracy of CSI feedback network. In this paper, we propose an adversarial autoencoder (AAE)-based wireless channel data augmentation network named CsiAAE to improve the CSI reconstruction accuracy of DL-based CSI feedback network trained with limited dataset. Experimental results under real-world wireless channel data show that compared with traditional data augmentation methods, CsiAAE can provide higher reconstruction accuracy for the DL-based CSI feedback network trained with insufficient dataset.},
  keywords={Wireless communication;Deep learning;Massive MIMO;Performance gain;Data augmentation;Throughput;Downlink;Deep Learning;CSI Feedback;Data Augmentation;Adversarial Autoencoder;Massive MIMO},
  doi={10.1109/IC-NIDC59918.2023.10390596},
  ISSN={2575-4955},
  month={Nov},}@INPROCEEDINGS{10882386,
  author={Shrivastava, Abhishek and Kumar, Vinesh and Maurya, Jay Prakash},
  booktitle={2024 International Conference on Artificial Intelligence and Quantum Computation-Based Sensor Application (ICAIQSA)}, 
  title={Cutting-Edge Image Recognition Leveraging Deep Learning and Machine Learning for Enhanced Accuracy}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper investigates advanced techniques in image recognition and classification by integrating deep learning and machine learning approaches to achieve higher accuracy. Through the implementation of sophisticated training algorithms, the study demonstrates enhanced performance in recognizing and categorizing images across various data models. A major turning point in the development of image identification technology came in 2012 when deep neural networks were introduced. These networks surpassed earlier cutting-edge algorithms and completely changed the computer vision industry. This progress has brought us closer to achieving human-level accuracy in tasks such as identity verification. The role of large datasets like ImageNet is crucial, as they provide the foundation for the success of deep learning. With continuous research pushing the limits of picture identification and producing major advances in human knowledge, deep learning has a huge influence on business, society, and technology. Additional research in this area might lead to creative uses that revolutionize our relationship with our surroundings. Key topics discussed include data pre-processing, post-processing, model optimization, and accuracy enhancement. The findings highlight the potential of cutting-edge technologies to advance image classification and recognition in various sectors, such as medical imaging and visual analysis. The approach emphasizes scalability and adaptability, ensuring that models can be effectively applied to real-world scenarios. Future research will focus on refining these models to handle even more complex image datasets, further enhancing their practical utility and reliability.},
  keywords={Deep learning;Training;Adaptation models;Visualization;Image recognition;Accuracy;Computational modeling;Visual systems;Data models;Reliability;Education Deep Neural Networks;Image Recognition;Computer Vision;Convolutional Neural Networks (CNNs);Recurrent Neural Networks (RNNs)},
  doi={10.1109/ICAIQSA64000.2024.10882386},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10956639,
  author={Shinde, Ashwini S and Zope, Tejaswini K and Bongulwar, Deepali and Chavan, Manjusha N and Chaudhari, Deepti A. and Sonawane, Atharv},
  booktitle={2024 Third International Conference on Artificial Intelligence, Computational Electronics and Communication System (AICECS)}, 
  title={Hybrid Deep Learning Models for Accurate Early Detection of Lung Cancer from MRI Scans}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Early identification of lung cancer is vital for improving patient outcomes, since it is a major contributor to cancer-related mortality, often resulting from late-stage diagnosis. This study addresses the challenge of accurately identifying early-stage lung cancer from MRI scans, where subtle tumors are often overlooked. Traditional diagnostic methods, reliant on manual interpretation and conventional machine learning models, fall short in handling the complexity of MRI data. In order to address these constraints, we suggest using a hybrid deep learning model that combines Convolutional Neural Networks (CNNs) for spatial feature extraction with Transformer networks for contextual analysis. This innovative approach significantly enhances the accuracy of early-stage lung cancer detection. Performance evaluation on extensive MRI datasets demonstrates that the hybrid model achieves an accuracy of 95%, a sensitivity of 93%, and a specificity of 96%, outperforming traditional diagnostic methods. The results highlight the potential of this hybrid model to revolutionize early detection strategies, ultimately improving treatment outcomes and survival rates for lung cancer patients.},
  keywords={Deep learning;Accuracy;Sensitivity;Magnetic resonance imaging;Lung cancer;Transformers;Feature extraction;Convolutional neural networks;Context modeling;Tumors;Early detection;Lung cancer;MRI;Deep learning;Hybrid model},
  doi={10.1109/AICECS63354.2024.10956639},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10913856,
  author={Omar, Chaieb and Nabil, Kannouf and Benabdellah, Mohammed},
  booktitle={2024 3rd International Conference on Embedded Systems and Artificial Intelligence (ESAI)}, 
  title={A Systematic Review and Taxonomy of Ransomware Detection Based on Artificial Intelligence Algorithms}, 
  year={2024},
  volume={},
  number={},
  pages={1-11},
  abstract={The escalating prevalence of ransomware attacks poses a significant risk to digital infrastructures, data integrity, and essential services worldwide. Traditional signature-based detection methods often struggle to keep pace with the evolving landscape of ransomware variants and stealthy attack techniques. Artificial Intelligence (AI) offers a promising solution, leveraging sophisticated features such as bytecodes, opcodes, API calls, and behavioral analysis to enhance ransomware detection capabilities. This review delves into the latest advancements in ransomware prevention and detection techniques, categorizing ransomware types and examining the intricate lifecycle of ransomware attacks. A comprehensive taxonomy of ransomware analysis techniques, machine/deep learning methods, and feature selection techniques is presented, considering the diverse operating systems targeted by these malicious threats. By conducting a thorough analysis of recent research articles in this field, we identify the key challenges faced by academics and the research community in mitigating the ransomware threat. Moreover, we explore potential future research directions to address these challenges and develop more effective countermeasures.},
  keywords={Learning systems;Machine learning algorithms;Embedded systems;Prevention and mitigation;Data integrity;Taxonomy;Machine learning;Feature extraction;Ransomware;Systematic literature review;Ransomware prevention;Ransomware detection;Machine learning;Ransomware analysis;Feature selection},
  doi={10.1109/ESAI62891.2024.10913856},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10691162,
  author={Kumar, Sachin and B, Deepa and T, Kavitha and M, Tamilselvi and V, Sathiyapriya and B, Natarajan},
  booktitle={2024 International Conference on Data Science and Network Security (ICDSNS)}, 
  title={A Novel Approach for Sign Language Video Generation Using Deep Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Sign language enhances the communication capabilities of the deaf-mute community, allowing for a deeper understanding of their needs and emotions. These languages are highly structured and visual, using gestures and various upper body movements such as those of the hands, face, eyes, and gaze. Researchers face numerous challenges in recognizing and translating the diverse variations in sign movements, which requires specialized expertise in computer vision and artificial intelligence. Sign language recognition and translation research has garnered global attention. This research work introduces a novel methodology for generating sign gesture videos from text inputs by integrating various intelligent techniques. The proposed model employs an enhanced generative adversarial network (GAN) to create sign videos from input sentences. Experiments with the proposed VideoGAN model using diverse sign language datasets from multiple countries have demonstrated its effectiveness. The research outcomes highlight its contribution to high-quality video production, with improved evaluation metrics underscoring the model's superior performance.},
  keywords={Measurement;Training;Sign language;Visualization;Face recognition;Refining;Production;Assistive technologies;Generative adversarial networks;Videos;computer vision;deep learning;sign language;generative adversarial network;video generation;photo realistic video},
  doi={10.1109/ICDSNS62112.2024.10691162},
  ISSN={},
  month={July},}@ARTICLE{9456901,
  author={Zhang, Longhao and Yang, Huihua and Qiu, Tian and Li, Lingqiao},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={AP-GAN: Improving Attribute Preservation in Video Face Swapping}, 
  year={2022},
  volume={32},
  number={4},
  pages={2226-2237},
  abstract={Face swapping is a popular subject in face manipulation, which aims to replace the identity of the target face with that of the source face. Existing methods cannot well preserve facial attributes (e.g., pose, expression, skin color, illumination, make-up, occlusion, etc.) of the target face, causing noticeable temporal discontinuity and instability artifacts for video face swapping. In this paper, we propose a lightweight Generative Adversarial Networks based framework named AP-GAN, which can precisely control the attribute of the generated face to be consistent with that of the target face, achieving efficient and high-fidelity video face swapping. Specifically, we derive a U-Net based generator with ID blocks to translate identity and PE blocks to correct pose and expression. Besides, a PE-aware discriminator is designed to help supervise pose and expression of the synthetic face. Furthermore, we propose a discriminator based perceptual loss leveraging multi-scale features of the discriminator to preserve facial attributes like skin color, illumination, make-up and occlusion. AP-GAN is trained on Flickr-Faces-HQ, CelebA-HQ and VGGFace2 and evaluated on FaceForensics++. Extensive experiments and comparisons to the existing state-of-the-art face swapping methods demonstrate the efficacy of our framework. Comprehensive ablation studies are also carried out to isolate the validity of each proposed component and to contrast with other face manipulation approaches.},
  keywords={Faces;Face recognition;Facial features;Generative adversarial networks;Lighting;Generators;Skin;Generative Adversarial Networks;video face swapping;facial attributes;U-Net;perceptual loss},
  doi={10.1109/TCSVT.2021.3089724},
  ISSN={1558-2205},
  month={April},}@INPROCEEDINGS{9283883,
  author={Ebrahimi, Mohammadreza and Samtani, Sagar and Chai, Yidong and Chen, Hsinchun},
  booktitle={2020 IEEE Security and Privacy Workshops (SPW)}, 
  title={Detecting Cyber Threats in Non-English Hacker Forums: An Adversarial Cross-Lingual Knowledge Transfer Approach}, 
  year={2020},
  volume={},
  number={},
  pages={20-26},
  abstract={The regularity of devastating cyber-attacks has made cybersecurity a grand societal challenge. Many cybersecurity professionals are closely examining the international Dark Web to proactively pinpoint potential cyber threats. Despite its potential, the Dark Web contains hundreds of thousands of non-English posts. While machine translation is the prevailing approach to process non-English text, applying MT on hacker forum text results in mistranslations. In this study, we draw upon Long-Short Term Memory (LSTM), Cross-Lingual Knowledge Transfer (CLKT), and Generative Adversarial Networks (GANs) principles to design a novel Adversarial CLKT (A-CLKT) approach. A-CLKT operates on untranslated text to retain the original semantics of the language and leverages the collective knowledge about cyber threats across languages to create a language invariant representation without any manual feature engineering or external resources. Three experiments demonstrate how A-CLKT outperforms state-of-the-art machine learning, deep learning, and CLKT algorithms in identifying cyber-threats in French and Russian forums.},
  keywords={Knowledge engineering;Privacy;Machine learning algorithms;Computer hacking;Semantics;Generative adversarial networks;Knowledge transfer;adversarial learning;generative adversarial networks;hacker forums;cross-lingual knowledge transfer;long short-term memory},
  doi={10.1109/SPW50608.2020.00021},
  ISSN={},
  month={May},}@INPROCEEDINGS{10626557,
  author={Bajpai, Devesh and Kiran, Mallela Uday and Reddy, Busi Hemanth and Natarajan, Suresh Kumar},
  booktitle={2024 4th International Conference on Intelligent Technologies (CONIT)}, 
  title={Smart AI Voice Assistant through Generative Text Transformer and NLP Implementation in Python}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In our project, we employed Natural Language Processing (NLP), Artificial Intelligence (AI), Generative Text Transformer (GTT), and Speech Recognition technologies. Through the utilization of these advanced technologies, we aimed to enhance the capabilities and functionalities of our system. NLP facilitated improved language understanding and interaction, while AI contributed to the overall intelligence and decision-making processes. GTT played a crucial role in generating coherent and contextually relevant text, adding a layer of sophistication to our applications. Additionally, the integration of speech recognition technology enabled seamless interaction through voice commands, enhancing the overall user experience. By leveraging these cutting-edge technologies synergistically, our project aimed to deliver a more intelligent, efficient, and user-friendly system, showcasing the transformative potential of combining NLP, AI, GTT, and speech recognition in an integrated framework. This potent blend transcends mere functionality, aiming to transform user experience and pave the way for intelligent companions seamlessly integrated into our lives. By leveraging the transformative power of this unified framework, we envision a future where technology not only serves us but also empowers and enriches our interactions with the world around us.},
  keywords={Productivity;Ethics;Privacy;Transforms;Transformers;Natural language processing;User experience;NLP;AI;GTT;Speech Recognition;Contextual Relevance;Unified Framework;Empowerment},
  doi={10.1109/CONIT61985.2024.10626557},
  ISSN={},
  month={June},}@ARTICLE{9868048,
  author={Yao, Yinghua and Pan, Yuangang and Tsang, Ivor W. and Yao, Xin},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Differential-Critic GAN: Generating What You Want by a Cue of Preferences}, 
  year={2024},
  volume={35},
  number={3},
  pages={3754-3768},
  abstract={This article proposes differential-critic generative adversarial network (DiCGAN) to learn the distribution of user-desired data when only partial instead of the entire dataset possesses the desired property. DiCGAN generates desired data that meet the user’s expectations and can assist in designing biological products with desired properties. Existing approaches select the desired samples first and train regular GANs on the selected samples to derive the user-desired data distribution. However, the selection of the desired data relies on global knowledge and supervision over the entire dataset. DiCGAN introduces a differential critic that learns from pairwise preferences, which are local knowledge and can be defined on a part of training data. The critic is built by defining an additional ranking loss over the Wasserstein GAN’s critic. It endows the difference of critic values between each pair of samples with the user preference and guides the generation of the desired data instead of the whole data. For a more efficient solution to ensure data quality, we further reformulate DiCGAN as a constrained optimization problem, based on which we theoretically prove the convergence of our DiCGAN. Extensive experiments on a diverse set of datasets with various applications demonstrate that our DiCGAN achieves state-of-the-art performance in learning the user-desired data distributions, especially in the cases of insufficient desired data and limited supervision.},
  keywords={Generative adversarial networks;Training data;Training;Generators;Robots;Labeling;Knowledge engineering;Desired data generation;generative adversarial network (GAN);pairwise ranking;user preference},
  doi={10.1109/TNNLS.2022.3197313},
  ISSN={2162-2388},
  month={March},}@INPROCEEDINGS{8372069,
  author={Li, Zhaoyu and Nguyen, Son P. and Xu, Dong and Shang, Yi},
  booktitle={2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Protein Loop Modeling Using Deep Generative Adversarial Network}, 
  year={2017},
  volume={},
  number={},
  pages={1085-1091},
  abstract={Biology and medicine have a long-standing interest in computational structure prediction and modeling of proteins. There are often missing regions or regions that need to be remodeled in protein structures. The process of predicting particular missing regions in a protein structure is called loop modeling. In this paper, we propose a generative adversarial network (GAN) in deep learning for loop modeling using the idea of image inpainting. The generative network is to capture the context of the loop region and predict the missing area. The adversarial network is to make the prediction look real and provide gradients to the generative network. The proposed network was evaluated on a common benchmark for loop modeling. Experiments show that our method can successfully predict the loop region and has achieved better performance than the state-of-the-art tools. To our knowledge, this work represents the first attempt of using GAN for any bioinformatics studies.},
  keywords={Proteins;Neural networks;Predictive models;Tools;Computational modeling;Gallium nitride;Machine learning;protein structure prediction;loop modeling;deep learning;generative adversarial network},
  doi={10.1109/ICTAI.2017.00166},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{9869909,
  author={Vitolo, Paola and Licciardo, Gian Domenico and Amendola, Anna Chiara and Di Benedetto, Luigi and Liguori, Rosalba and Rubino, Alfredo and Pau, Danilo},
  booktitle={2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS)}, 
  title={Quantized ID-CNN for a Low-power PDM-to-PCM Conversion in TinyML KWS Applications}, 
  year={2022},
  volume={},
  number={},
  pages={154-157},
  abstract={This paper proposes a novel low-power HW accelerator for audio PDM-to-PCM conversion based on artificial neural network. The system processes samples from a digital MEMS microphone and converts them in PCM format by using a 1-Dimensional Convolutional Neural Network (1D-CNN). The model has been quantized to reduce the computational complexity while preserving its Signal-to-Noise Ratio (SNR) and the HW accelerator has been designed to minimize the physical resources. The SNR achieved is 41.56 dB while the prototyping of the design on a Xilinx Artix-7 FPGA shows a dynamic power consumption of 1 mW and a utilization of 606 LUTs and 410 FFs. These results enable the proposed system to be the first step of a tiny low-power end-to-end neural network-based Keyword Spotting (KWS) system.},
  keywords={Micromechanical devices;Power demand;Filtering;Table lookup;Iterative methods;Convolutional neural networks;Pulse modulation;PDM-to-PCM conversion;neural network;keywork spotting;FPGA;low power},
  doi={10.1109/AICAS54282.2022.9869909},
  ISSN={},
  month={June},}@INPROCEEDINGS{9276900,
  author={Luo, Xinxin and Cai, Ziyun and Wu, Fei and Xiao-Yuan, Jing},
  booktitle={2020 IEEE International Conference on Information Technology,Big Data and Artificial Intelligence (ICIBA)}, 
  title={A Generative Model for Zero-Shot Learning via Wasserstein Auto-encoder}, 
  year={2020},
  volume={1},
  number={},
  pages={757-762},
  abstract={Zero-shot learning aims to use the labeled instances to train the model, and then classifies the instances that belong to a class without labeled instances. However, the training instances and test instances are disjoint. Thus, the description of the classes (e.g. text description or class attribute information) is to establish a connection between the training set and the test set to make the model effective. Since real world image annotation requires a lot of manpower and material resources, this setting is very important in the real world. Zero-shot learning can effectively solve the problem of image annotation. Most of the previous methods explored the mapping between visual space and semantic space. Some recent generative methods attempt to generate image features of unseen classes based on auxiliary information, and have achieved good performances. In this paper, we propose to use Wasserstein Auto-encoder (WAE) as a generative model to establish data distribution. Then the generated samples from the generative model are used to classify unseen classes. We test our model on four benchmark datasets including CUB, SUN, AWA2 and aPY, the results of which demonstrate the effectiveness of our model.},
  keywords={Training;Visualization;Image annotation;Benchmark testing;Data models;Generators;Sun;Zero-Shot Learning;Wasserstein Auto-encoder;Generative Model},
  doi={10.1109/ICIBA50161.2020.9276900},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11060553,
  author={Mwaniki, Susan and Araka, Eric and Kituku, Benson and Maina, Elizaphan},
  booktitle={2025 IST-Africa Conference (IST-Africa)}, 
  title={Students' Perceptions on the Use of Generative AI in Enhancing Teaching and Learning Computer Science Courses}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={This research study examines the perception of third-year computer science students in Kenya towards the use of Generative Artificial Intelligence tools in their studies. The researchers used descriptive research design to understand student attitudes, the perceived usefulness of Generative Artificial Intelligence, and the challenges they face. The study finds that students generally see Generative Artificial Intelligence tools as beneficial for learning, especially in areas like coding and research. However, they also identify concerns about over-reliance on Generative Artificial Intelligence, accuracy of information, and ethical considerations, such as plagiarism. The study concludes that Generative Artificial Intelligence can be valuable in computer science education, however, it should be used reliably and balanced with traditional teaching methods to ensure critical thinking and creativity.},
  keywords={Computer science;Training;Accuracy;Generative AI;Plagiarism;Focusing;Encoding;Computer science education;Reliability;Problem-solving;Generative AI;Active Learning;Computer Science Education;Student Perceptions;Barriers to Adoption;Educational Technology},
  doi={10.23919/IST-Africa67297.2025.11060553},
  ISSN={2576-8581},
  month={May},}@INPROCEEDINGS{10988029,
  author={Srilakshmi, P and Chaganti, Koushik Reddy and Suryam, Talachendri and I, Sweety Julia and Chaithanya, D. and Kavitha, Jami},
  booktitle={2025 5th International Conference on Trends in Material Science and Inventive Materials (ICTMIM)}, 
  title={Real-Time IoT Cybersecurity using Machine Learning-based AI Threat Detection System to Train Generative Robots}, 
  year={2025},
  volume={},
  number={},
  pages={1124-1130},
  abstract={Existing security protocols encounter major cybersecurity difficulties because the online devices' growing popularity continues to spread across networks. These security protocols are ineffective because they do not properly handle current cyber threats. The main goal of this study involves developing enhanced IoT cybersecurity through the development of a threat detection system which brings together adversarial training and deep learning models (CNN-LSTM) and Federated Learning (FL). The system enables distributed Internet of Things devices to work on security model development through Federated Learning while maintaining total privacy of their information. Security procedures controlled by generative artificial intelligence robots alongside real-time attack protection functions decrease security response durations. Through its Federated CNN-LSTM model the system upholds a 1.2% false positive rate alongside a 98.3% accuracy evaluation and 160 milliseconds of exact threat tracking time. The designed system sustains a minimal occurrence of incorrect alarm activations. The developed system provides real-time security for the Internet of Things framework because it enables adaptive protection systems while preserving user privacy in current IoT settings.},
  keywords={Training;Privacy;Protocols;Federated learning;Real-time systems;Threat assessment;Internet of Things;Computer security;Protection;Robots;IoT cybersecurity;Machine learning;Federated learning;Generative AI;AI-driven threat detection;CNN-LSTM;Adversarial training;Real-time security;Edge computing},
  doi={10.1109/ICTMIM65579.2025.10988029},
  ISSN={},
  month={April},}@INPROCEEDINGS{11086338,
  author={Kumar, P. Vinoth and K S, Nandhanaa and S, Lakshmi Praba and K, Bhuvaneshwari and T, Kesavan},
  booktitle={2025 Second International Conference on Cognitive Robotics and Intelligent Systems (ICC - ROBINS)}, 
  title={Leveraging Generative AI in Electric Vehicles for Enhanced Driver Safety and Advanced Communication Systems}, 
  year={2025},
  volume={},
  number={},
  pages={21-27},
  abstract={The fast-evolving developments in Computer Vision and Generative AI have made new possibilities for increasing driver safety and communication in Electric Vehicles (EVs) feasible. This research proposes an AI-powered driving assistant that combines predictive analytics and voice command processing to augment the driving experience. One of the system's most important elements is a computer visionbased drowsiness detection module that constantly tracks the driver's eye closure, blink patterns, head posture, and yawning rate through an in-car camera. Upon detecting the presence of drowsiness, the system sends an alert mechanism in the form of audible alerts, seat vibrations, or dashboard alerts to avoid accidents. In addition, Natural Language Processing and ChatGPT are used to develop a conversational AI assistant that facilitates effortless interaction between the driver and the car. Vehicle diagnostics and predictive safety alerts are made available by the AI assistant, enhancing overall driving situational awareness. By combining computer vision for driver monitoring and generative AI for interactive support, this study seeks to improve driver awareness, vehicle communication, and overall road safety. The system is in line with the future of semi-autonomous and autonomous EVs, making them more responsive to human needs and providing a safer, more engaging driving experience.},
  keywords={Vibrations;Computer vision;Technological innovation;Generative AI;Electric vehicles;Road safety;Safety;Automobiles;Monitoring;Accidents;Computer Vision;Generative AI;Natural Language Processing;Chat GPT;autonomous EVs},
  doi={10.1109/ICC-ROBINS64345.2025.11086338},
  ISSN={},
  month={June},}@ARTICLE{8733810,
  author={Zhang, Yunlei and Wu, Bin and Ning, Nianwen and Song, Chenguang and Lv, Jinna},
  journal={IEEE Access}, 
  title={Dynamic Topical Community Detection in Social Network: A Generative Model Approach}, 
  year={2019},
  volume={7},
  number={},
  pages={74528-74541},
  abstract={Social networks that are dynamic contain rich network structure and content information. In dynamic networks, it is necessary to discover communities and their topical meanings. However, existing methods either only discover communities with ignoring their topical meaning in dynamic networks, or they discover communities and their topics in static networks. In this paper, we identify the problem of dynamic topical community detection and propose a dynamic topical community detection (DTCD) method to detect communities and their topical meanings in dynamic networks. The DTCD is a generative model integrating network structure, text, and time. The DTCD considers a community as a mixture of topics and generates the neighbors and documents of the node and their time stamps at the same time via the community. The latent variables are learned by collapsed Gibbs sampling. The DTCD not only can find communities and their topics, but also capture the temporal variations of communities and topics. The experimental results on two real-world datasets demonstrate the effectiveness of DTCD.},
  keywords={Social networking (online);Image edge detection;Task analysis;Correlation;Semantics;Telecommunications;User-generated content;Social network;dynamic community detection;user generated content;generative model;collapsed Gibbs sampling},
  doi={10.1109/ACCESS.2019.2921824},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{6492586,
  author={Liang Hao-zhe and Huang Kui-hua and Li Guo-hui},
  booktitle={International Conference on Automatic Control and Artificial Intelligence (ACAI 2012)}, 
  title={A surveillance activity recognition model based on Hidden Markov Model}, 
  year={2012},
  volume={},
  number={},
  pages={305-308},
  abstract={In this paper a novel activity recognition model based on Hidden Markov model was proposed. For the HMM parameters learning problem, a two-phase model including a bottom-up process and a top-down process was introduced. Bottom-up used Dirichlet Mixture Model to learn the HMM structure automatically and top-down defined a generative clustering process, which was called HMM-mixture. Both processes were unsupervised. The performance of the proposed model was tested by real surveillance video and an application for classification of activity was also showed. Clusters of HMM-trajectory were successfully recognized by the proposed model and properly classification results were achieved.},
  keywords={Hidden Markov Model;activity recognition;intelligence surveillance;trajectory analysis},
  doi={10.1049/cp.2012.0979},
  ISSN={},
  month={March},}@INPROCEEDINGS{9635559,
  author={Btoush, Eyad and Zhou, Xujuan and Gururaian, Rai and Chan, KC and Tao, XiaoHui},
  booktitle={2021 8th International Conference on Behavioral and Social Computing (BESC)}, 
  title={A Survey on Credit Card Fraud Detection Techniques in Banking Industry for Cyber Security}, 
  year={2021},
  volume={},
  number={},
  pages={1-7},
  abstract={The technological revolution is accelerating due to a number of key enabling technologies, such as Artificial Intelligence (AI)/Machine Learning (ML), big data, blockchain, cloud computing, Internet of Thing (IoT). With the broad adoption of ever-improving internet technology, cyber security is of great importance in the banking industry due to the rising number of cyber attacks and crimes. Credit card fraud is one of the most serious threats facing the banking industry worldwide. Credit card fraud is expanding at an alarming rate and has developed into a significant problem, particularly as the volume of financial transactions involving credit cards continues to expand. In this paper, we have reviewed various credit card fraud detection techniques that can strengthen the defense against a range of frauds. Additionally, we analysed the findings and reported the research challenges. Finally, we compared various techniques and highlighted their advantages and disadvantages. This will help provide guidance for determining the most appropriate techniques for credit card fraud detection.},
  keywords={Industries;Social computing;Cloud computing;Banking;Learning (artificial intelligence);Big Data;Credit cards;Fraud;Credit card;Machine learning;Artificial intelligence;Credit card fraud detection;Banking},
  doi={10.1109/BESC53957.2021.9635559},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10872334,
  author={Valentine C J, Lenin and Ahmed B, Arshad and Raja, Esakki and PA, Udhayadhithan},
  booktitle={2024 International Conference on Smart Electronics and Communication Systems (ISENSE)}, 
  title={Enabling Augmented Intelligence Using Gen AI in Mechanical Ventilators}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Mechanical ventilators, despite their life saving potential, require constant monitoring and manual adjustment that are time consuming and human resource draining. The paper proposes an augmented intelligence approach leveraging existing Generative Artificial Intelligence (Gen AI) such as ChatGPT, Medllama, etc, to enhance the existing patient monitoring systems in place by providing real-time data-driven recommendations for patient diagnosis and ventilators. It uses an ARM Cortex-M7 based microcontroller and FreeRTOS, a real time operating system, to collect vital ventilator data and sends it to cloud for generating actionable insights for clinicians. These Gen AI -enabled recommendations assist healthcare professionals to provide timely adjustments by deciding next course of action based on suggestions to optimize patient care and reduce their monitoring burden.},
  keywords={Ventilators;Technological innovation;Patient monitoring;Microcontrollers;Operating systems;Lungs;Manuals;Real-time systems;Medical diagnosis;Standards;Mechanical Ventilator;Machine Learning;Gen AI;CDSS;ARM based architecture;RTOS;MQTT},
  doi={10.1109/ISENSE63713.2024.10872334},
  ISSN={},
  month={Dec},}@ARTICLE{9372892,
  author={Wang, Guan’An and Hu, Qinghao and Yang, Yang and Cheng, Jian and Hou, Zeng-Guang},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Adversarial Binary Mutual Learning for Semi-Supervised Deep Hashing}, 
  year={2022},
  volume={33},
  number={8},
  pages={4110-4124},
  abstract={Hashing is a popular search algorithm for its compact binary representation and efficient Hamming distance calculation. Benefited from the advance of deep learning, deep hashing methods have achieved promising performance. However, those methods usually learn with expensive labeled data but fail to utilize unlabeled data. Furthermore, the traditional pairwise loss used by those methods cannot explicitly force similar/dissimilar pairs to small/large distances. Both weaknesses limit existing methods’ performance. To solve the first problem, we propose a novel semi-supervised deep hashing model named adversarial binary mutual learning (ABML). Specifically, our ABML consists of a generative model  $G_{H}$  and a discriminative model  $D_{H}$ , where  $D_{H}$  learns labeled data in a supervised way and  $G_{H}$  learns unlabeled data by synthesizing real images. We adopt an adversarial learning (AL) strategy to transfer the knowledge of unlabeled data to  $D_{H}$  by making  $G_{H}$  and  $D_{H}$  mutually learn from each other. To solve the second problem, we propose a novel Weibull cross-entropy loss (WCE) by using the Weibull distribution, which can distinguish tiny differences of distances and explicitly force similar/dissimilar distances as small/large as possible. Thus, the learned features are more discriminative. Finally, by incorporating ABML with WCE loss, our model can acquire more semantic and discriminative features. Extensive experiments on four common data sets (CIFAR-10, large database of handwritten digits (MNIST), ImageNet-10, and NUS-WIDE) and a large-scale data set ImageNet demonstrate that our approach successfully overcomes the two difficulties above and significantly outperforms state-of-the-art hashing methods.},
  keywords={Data models;Semantics;Force;Computational modeling;Hash functions;Binary codes;Training data;Adversarial learning (AL);deep learning;hashing},
  doi={10.1109/TNNLS.2021.3055834},
  ISSN={2162-2388},
  month={Aug},}@INPROCEEDINGS{10402778,
  author={Ghosh, Tanusree and Naskar, Ruchira},
  booktitle={2023 IEEE International Conference on Visual Communications and Image Processing (VCIP)}, 
  title={Leveraging Image Gradients for Robust GAN-Generated Image Detection in OSN context}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Creating hyper-realistic synthetic images has become effortless with tremendous development in Generative Artificial Intelligence technologies. Generative Adversarial Networks (GAN) generated synthetic images, especially non-existent face images that are visually indistinguishable from real faces, pose a severe social threat by enabling misinformation dissemination, often over online social networks and through fake social profiles. In spite of successful solutions being reported in the recent literature for detecting GAN-generated synthetic images, the performance of such schemes degrades considerably with the launch of post-processing attacks. In this work, we employ gradient of an image as the key component to detect synthetic images. According to our results, gradient proves to be a considerably efficient image derivative for synthetic image detection as well as to achieve robustness against post-processing attacks. We explore two different gradient operators and design four unique deep learning-based detection networks utilizing different gradient-based feature sets. Our solution achieves state-of-the-art (SOTA) detection accuracy (above 99%) on the test set consisting of STYLEGAN2 images and outperforms SOTA solutions for detecting post-processed and compressed images.},
  keywords={Image coding;Visual communication;Social networking (online);Detectors;Generative adversarial networks;Feature extraction;Faces;Digital Image Forensics;Fake Image Detection;Generative Adversarial Networks;GAN Face Detection;Image Gradients;Synthetic Image Forensics},
  doi={10.1109/VCIP59821.2023.10402778},
  ISSN={2642-9357},
  month={Dec},}@INPROCEEDINGS{9937639,
  author={Tian, Min and Lu, Jing and Gao, Haoran and Wang, Haibing and Yu, Jianyi and Shi, Cong},
  booktitle={2022 IEEE International Symposium on Circuits and Systems (ISCAS)}, 
  title={A Lightweight Spiking GAN Model for Memristor-centric Silicon Circuit with On-chip Reinforcement Adversarial Learning}, 
  year={2022},
  volume={},
  number={},
  pages={3388-3392},
  abstract={As a powerful generative model, Generative Adversarial Network (GAN) is widely studied to automatically generate high-quality new data to greatly enhances the capabilities of artificial intelligence (AI) technology. However, the unique training process of GAN comes at a very high computational complexity and high cost of memory accesses. In this work, a memristor-based spiking-GAN neuromorphic hardware system is proposed to address the challenges. Both the generator and discriminator of GAN are in the form of spiking neural network (SNN) to improve the computational performance, and the memristor synapse circuit with 1 memristor and 4 transistors (1M4T) is proposed as Computing in Memory (CIM) to avoid the cost of memory accesses. The reinforcement learning rule (i.e., reward-modulated spike-timing dependent plasticity, or R-STDP) is used to train both discriminator and generator networks, with a new backpropagation method for the reward/punishment signal. Tests on the MNIST and Fashion-MNIST datasets showed that the proposed GAN can efficiently generate data samples. The results demonstrate the great potential of this memristor-based spiking-GAN for high-speed energy-efficient data augmentations.},
  keywords={Costs;Computational modeling;Memristors;Generative adversarial networks;Hardware;Generators;Energy efficiency;Spiking neuron;Generative adversarial network;Memristor;Reinforcement learning;Reward-modulated STDP;On-chip learning;Neuromorphic systems},
  doi={10.1109/ISCAS48785.2022.9937639},
  ISSN={2158-1525},
  month={May},}@INPROCEEDINGS{11098362,
  author={Kotov, Georgi and Nakov, Ognyan and Lazarova, Milena and Nakov, Plamen},
  booktitle={2025 60th International Scientific Conference on Information, Communication and Energy Systems and Technologies (ICEST)}, 
  title={Hybrid CNN and Forensic Approach for Detecting AI-Generated Human Faces}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={The rapid development of deep generative models, particularly Generative Adversarial Networks (GANs) and diffusion models, has resulted in generation of synthetic images that closely mimic real human features. This growing realism has serious implications for security, digital identity verification, and misinformation. The paper presents an overview of the technological and scientific challenges related to distinguishing between real human face images and those generated by artificial intelligence. A hybrid detection framework is suggested that integrates deep CNN-based features with handcrafted forensic cues. The experimental results of training the suggested hybrid approach using WhichFaceIsReal dataset show that the hybrid model outperforms both CNN-only and forensic-only baselines achieving an accuracy of 94.8% and demonstrating improved precision, recall, and robustness.},
  keywords={Training;Deepfakes;Visualization;Accuracy;Face recognition;Generative adversarial networks;Feature extraction;Diffusion models;Robustness;Faces;AI-generated faces;deepfakes;Generative Adversarial Networks;face recognition;image forensics},
  doi={10.1109/ICEST66328.2025.11098362},
  ISSN={2603-3267},
  month={June},}@ARTICLE{10177163,
  author={Mejia-Escobar, Christian and Cazorla, Miguel and Martinez-Martin, Ester},
  journal={IEEE Access}, 
  title={Improving Facial Expression Recognition Through Data Preparation and Merging}, 
  year={2023},
  volume={11},
  number={},
  pages={71339-71360},
  abstract={Human emotions present a major challenge for artificial intelligence. Automated emotion recognition based on facial expressions is important to robotics, medicine, psychology, education, security, arts, entertainment and more. Deep learning is promising for capturing complex emotional features. However, there is no training dataset that is large and representative of the full diversity of emotional expressions in all populations and contexts. Current facial datasets are incomplete, biased, unbalanced, error-prone and have different properties. Models learn these limitations and become dependent on specific datasets, hindering their ability to generalize to new data or real-world scenarios. Our work addresses these difficulties and provides the following contributions to improve emotion recognition: 1) a methodology for merging disparate in-the-wild datasets that increases the number of images and enriches the diversity of people, gestures, and attributes of resolution, color, background, lighting and image format; 2) a balanced, unbiased, and well-labeled evaluator dataset, built with a gender, age, and ethnicity predictor and the successful Stable Diffusion model. Single- and cross-dataset experimentation show that our method increases the generalization of the FER2013, NHFI and AffectNet datasets by 13.93%, 24.17% and 7.45%, respectively; and 3) we propose the first and largest artificial emotion dataset, which can complement real datasets in tasks related to facial expression.},
  keywords={Emotion recognition;Face recognition;Training;Artificial intelligence;Merging;Data models;Image recognition;Artificial dataset;deep learning;convolutional neural network;emotion recognition;facial expression recognition;stable diffusion},
  doi={10.1109/ACCESS.2023.3293728},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10810905,
  author={Arshad, Mohammad and Rao, B. Devananda and Sirisha, M. Ratna and Lingaiah, S. and Shekar, Kukunoor and Benarji, T.},
  booktitle={2024 5th International Conference on Data Intelligence and Cognitive Informatics (ICDICI)}, 
  title={Signature Forgery Detection using Convolutional Neural Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1362-1368},
  abstract={Signature of a person can uniquely identify the person and it is widely used in social situations and monetary transactions with individuals and financial entities. Many fraud cases have been appearing in society where signature of a person is forged for financial and other benefits. There is need for detecting forged signatures with technology driven approaches. With the emergence of Artificial Intelligence (AI), there are unprecedented possibilities in solving problems of the real world with responsible usage of AI. Deep learning (DL) is one part of AI which extends neural networks has become very significant in computer vision applications. From the existing approaches, it is observed that there is need for a complete framework for end to end processing of signatures for efficient detection of forgeries. Towards this end, we proposed a DL based framework for automatic detection of signature forgery. The framework is designed to leverage performance of the models. We proposed an algorithm known as Learning based Signature Forgery Detection (LbSFD) which exploits pipeline of multiple DL models such as CNN, VGG16 and Siamese. All the models are CNN variants used to improve efficiency in signature forgery detection. A benchmark signature dataset is used for our empirical study. Our experiments revealed that the CNN based models are highly efficient in signature forgery detection. Highest accuracy with 98.26% is achieved when VGG16 model is employed with transfer learning.},
  keywords={Deep learning;Computer vision;Neural networks;Transfer learning;Pipelines;Forgery;Fraud;Convolutional neural networks;Cognitive informatics;Artificial intelligence;Signature Forgery Detection;Artificial Intelligence;Deep Learning;Convolutional Neural Networks},
  doi={10.1109/ICDICI62993.2024.10810905},
  ISSN={},
  month={Nov},}@ARTICLE{11021344,
  author={Kshirsagar, Jay and Shirmohammadi, Shervin},
  journal={IEEE Instrumentation & Measurement Magazine}, 
  title={Generative AI: Basics and Applications in Biomedical Measurements [Roadmap for Measurement and Applications]}, 
  year={2025},
  volume={28},
  number={4},
  pages={31-39},
  abstract={Artificial Intelligence (AI) and its subset of machine learning, especially Deep Learning (DL), are now prevalent in the field of instrumentation and measurement (I&M) [1]. One particular use case of DL is Generative AI (GenAI): AI that is trained to generate content in the form of text, audio, music, image, video, etc., at a quality that is close to what humans would consider to be realistic. Although architectures such as Hidden Markov Models or Bayesian networks can be used to create GenAI models, today the great majority of GenAI models are based on DL. Table 1 summarizes the types of GenAI, their generation technology, their DL architecture, and example tools.},
  keywords={Deep learning;Generative AI;Hidden Markov models;Bayes methods;Instrumentation and measurement;Content management},
  doi={10.1109/MIM.2025.11021344},
  ISSN={1941-0123},
  month={June},}@INPROCEEDINGS{10271916,
  author={Chen, Yifan and Li, Lei and Hu, Xinyu and Li, Jiahao and Wang, Junyuan and Liu, Fuqiang},
  booktitle={2023 IEEE International Conference on Metaverse Computing, Networking and Applications (MetaCom)}, 
  title={Utilizing Latent Codes for Minting AI-Generated Digital Assets into NFTs}, 
  year={2023},
  volume={},
  number={},
  pages={383-387},
  abstract={The use of Artificial Intelligence (AI) generators to create digital artwork as the content of Non-Fungible Tokens (NFTs) is prevalent. Typically, when minting AI-generated digital artwork into NFTs, the data of digital artwork is stored in the cloud or decentralized storage system, and a Uniform Resource Identifier (URI) or Content Identifier (CID) of the data is stored in the smart contract of NFTs to access the data. This makes AI art NFTs suffer from potential asset loss as conventional NFTs. Can AI be utilized to enhance the availability of AI-generated digital assets as NFT content? In this paper, we propose a new method for minting AI-generated digital assets into NFTs. The key idea of our approach is to store the latent codes of the generated assets on the blockchain instead of URI or CID in conventional NFTs. Here, the latent codes are intermediate variables in the process of generating digital assets by the generator and could restore the assets through the generator. Meanwhile, to be able to restore assets, the universal generator is stored on a distributed system, and its high popularity guarantees its availability. Experiments demonstrate the feasibility of our method. In addition, the integrity and the availability of assets minted by the proposed method and the existing ones are discussed, concluding that our approach has better availability while safeguarding integrity.},
  keywords={Uniform resource locators;Cloud computing;Codes;Metaverse;Smart contracts;Digital art;Generators;non-fungible token;artificial intelligence;generative adversarial network;blockchain;digital asset},
  doi={10.1109/MetaCom57706.2023.00073},
  ISSN={},
  month={June},}@INPROCEEDINGS{10692590,
  author={Li, Qiang and Zhao, Feng and Zhao, Linlin and Qin, Xuhong and Wang, Yubo and Zhu, Yana},
  booktitle={2024 6th International Conference on Internet of Things, Automation and Artificial Intelligence (IoTAAI)}, 
  title={Digital Twin System Based on Swarm Intelligence Scheduling}, 
  year={2024},
  volume={},
  number={},
  pages={319-325},
  abstract={With the large-scale integration of distributed energy resources, issues such as reverse power flow, heavy overloads in both positive and negative directions, and voltage violations have become prominent in scenarios where source-grid-load-storage collaborate and interact, such as source complementarity and source-load complementarity. It is crucial to promptly eliminate power risks and ensure the safe and stable operation of the distribution network. However, due to the complex structure, numerous devices, and large scale of the distribution network, traditional regulation and control models no longer meet the requirements of collaborative scheduling among source, grid, load, and storage. To address these issues, this paper proposes a digital twin technology based on swarm intelligence scheduling, which combines artificial intelligence large-model technology with digital twin technology to establish an interactive simulation and deduction mechanism for the distribution network's source-grid-load-storage interaction, thereby improving the quality and efficiency of collaborative scheduling among source, grid, load, and storage.},
  keywords={Accuracy;Generative AI;Collaboration;Optimal scheduling;Distribution networks;Data models;Power grids;Digital twins;Particle swarm optimization;Load modeling;Distributed Energy;Swarm Intelligence Scheduling;Large Model},
  doi={10.1109/IoTAAI62601.2024.10692590},
  ISSN={},
  month={July},}@ARTICLE{10839316,
  author={Xu, Baoyu and Ruan, Yancheng and Qiu, Chenghu and He, Shuibing and Shu, Feng and Kang, Xiaoyang and Zhang, Lihua},
  journal={IEEE Internet of Things Journal}, 
  title={Multilevel and Energy-Efficient Partial Computation Offloading in Heterogeneous Edge Intelligence}, 
  year={2025},
  volume={12},
  number={11},
  pages={14993-15007},
  abstract={Due to the diversity of edge devices (EDs) and applications, edge systems are heterogeneous and have been applied in artificial intelligence fields, such as smart factories and intelligent transportation, which is called heterogeneous edge intelligence. Many studies employ computation offloading to transfer processing data from resource-scarce EDs to resource-rich edge servers. These studies primarily focus on the overall resource consumption of homogeneous edge systems, neglecting the system heterogeneity and the details of resource consumption. In this article, we construct a system model from a parallel perspective for the heterogeneous edge system with different processors, memory, and applications, which perceives the cost of energy and delay from three levels: system, application, and component. A hybrid metaheuristic algorithm combined with a greedy rule, hybrid mutation, and whale optimization algorithm (GHMWOA) is proposed to realize partial computation offloading. A partial offloading architecture of heterogeneous edge intelligence is proposed to validate our model and algorithm with real-world hardware and software. Experiment results not only show GHMWOA outperforms multiple classical optimization algorithms in minimizing energy consumption, but also discover on which system component energy consumption depends, and how properties of application and system influence the cost of energy.},
  keywords={Delays;Energy consumption;Program processors;Optimization;Edge computing;Computational modeling;Costs;Artificial intelligence;Servers;Heuristic algorithms;Heterogeneous edge intelligence;multilevel energy analysis;parallel processing;partial computation offloading},
  doi={10.1109/JIOT.2025.3529185},
  ISSN={2327-4662},
  month={June},}@INPROCEEDINGS{10585479,
  author={Ryspayeva, Marya and Nishan, Alina},
  booktitle={2024 IEEE AITU: Digital Generation}, 
  title={Enhancing Grayscale Image Synthesis with Deep Conditional GAN and Transfer Learning}, 
  year={2024},
  volume={},
  number={},
  pages={122-127},
  abstract={This study explores using advanced Generative Adversarial Networks (GAN) to create realistic breast ultrasound images. Combining Deep Convolutional GAN with a Wasserstein Gradient-Penalty and integrating Transfer Learning aims to address the lack of diverse datasets in breast cancer diagnosis. The research proposes a new method to generate high-quality images of breast tumors, which involves using state-of-the-art DCGAN-WG-TL models with pre-trained networks like VGG19 to refine the synthetic image generation process. The methodology includes preprocessing the Breast Ultrasound Images dataset, generating synthesized images, and evaluating the results using the Fréchet Inception Distance (FID) metric to assess image quality. The study found that DCGAN-WG-TL with lambda = 5.0 and 500 epochs produced the best results.},
  keywords={Measurement;Image quality;Ultrasonic imaging;Image synthesis;Transfer learning;Neural networks;Medical services;deep convolutional generative adversarial network;GAN;data balance;ultrasound breast cancer;transfer learning;artificial intelligence},
  doi={10.1109/IEEECONF61558.2024.10585479},
  ISSN={},
  month={April},}@INPROCEEDINGS{9837779,
  author={Xu, Mengfei and Chen, Jiejie and Yang, Honggang and Xiao, Tongfei},
  booktitle={2022 14th International Conference on Advanced Computational Intelligence (ICACI)}, 
  title={Combined with Decomposition Algorithm and Generative Adversarial Networks on Landslide Displacement Prediction}, 
  year={2022},
  volume={},
  number={},
  pages={42-48},
  abstract={Landslide displacement prediction is essential to establishing the early warning system (EWS). To better grasp the landslide evolution process, this paper proposes a novel architecture of variational mode decomposition-Generative Adversarial Network (VMD-GAN) for forecasting the landslide displacement. Firstly, VMD was used to decompose the time series into multiple intrinsic mode functions (IMFs) to extract the internal hidden information of the original series and remove the interference of noise to improve the prediction accuracy of the model. Then, GAN predicts each IMFs. Finally, the predicted results for each IMFs component are added to get the final prediction result. The Baishuihe in the Three Gorges Reservoir was made as an example and displacement data from August 2003 to December 2011 were selected for analysis. Compared with empirical mode decomposition-Generative Adversarial Network(EMDGAN), long short-term memory (LSTM), and temporal convolutional networks (TCN) models, the result has shown that the root means square errors (RMSE) of VMD-GAN in landslide prediction was 3.33 and the correlation coefficient R-square was 0.99, which demonstrated the best prediction accuracy and fitting ability.},
  keywords={Fitting;Time series analysis;Predictive models;Generative adversarial networks;Reservoirs;Prediction algorithms;Feature extraction;VMD;GAN;TCN;landslide displacement prediction},
  doi={10.1109/ICACI55529.2022.9837779},
  ISSN={},
  month={July},}@ARTICLE{11048911,
  author={Nakamura, Kensuke and Sohn, Bong-Soo and Korman, Simon and Hong, Byung-Woo},
  journal={IEEE Access}, 
  title={Regularization for Unconditional Image Diffusion Models via Shifted Data Augmentation}, 
  year={2025},
  volume={13},
  number={},
  pages={113258-113273},
  abstract={Diffusion models are a powerful class of techniques in ML for generating realistic data, but they are highly prone to overfitting, especially with limited training data. While data augmentation such as image rotation can mitigate this issue, it often causes leakage, where augmented content appears in generated samples. In this paper, we propose a novel regularization framework, called shifted data-augmentation (SDA), for training unconditional diffusion models. SDA introduces an auxiliary diffusion path using transformed data and the noise-shift technique alongside the standard path with original data. This dual-path structure enables effective regularization while suppressing leakage through a trajectory shift in the diffusion process. We implement SDA with image rotation as its most basic and interpretable configuration. We also conduct synthetic and empirical analyses demonstrating that SDA effectively leverages the regularization benefit of image rotation. In particular, SDA yielded notable performance in training with limited data.},
  keywords={Diffusion models;Training;Data augmentation;Noise;Overfitting;Trajectory;Image synthesis;Diffusion processes;Generative adversarial networks;Data models;Data augmentation;diffusion model;noise-shift;regularization},
  doi={10.1109/ACCESS.2025.3582756},
  ISSN={2169-3536},
  month={},}@ARTICLE{10681321,
  author={Qian, Fulan and Cui, Yan and Chen, Hai and Chen, Wenbin and Yan, Yuanting and Zhao, Shu},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={ReOP: Generating Transferable Fake Users for Recommendation Systems via Reverse Optimization}, 
  year={2024},
  volume={11},
  number={6},
  pages={7830-7845},
  abstract={Recent research has demonstrated that recommendation systems exhibit vulnerability under data poisoning attacks. The primary process of data poisoning attacks involves generating malicious data (i.e., fake users) through surrogate models and injecting the malicious data into the target models’ datasets, thereby manipulating the output results of the target models. However, current methods generating fake users based on gradient descent may cause them to fall into undesired local minimum in the loss landscape and overfitting to the surrogate model, thus limiting the performance of attacking other recommendation models. To address this problem, we propose the reverse optimization algorithm (ReOP), which utilizes the reverse direction of optimization to update fake users, enabling them to steer clear of sharp local minimum in loss landscape and navigate towards the flat local minimum. ReOP makes fake users less sensitive to model changes, alleviates their overfitting to the surrogate model, and thus significantly improves the transferability of fake users. Experimental results demonstrate that ReOP surpasses the state-of-the-art baseline methods, effectively generating fake users with significant attack effects on various target models.},
  keywords={Recommender systems;Optimization;Data models;Closed box;Glass box;Predictive models;Biological system modeling;Data poisoning attack;recommendation systems;reverse optimization;transferability},
  doi={10.1109/TCSS.2024.3451452},
  ISSN={2329-924X},
  month={Dec},}@INPROCEEDINGS{10773642,
  author={Yoo, Yungjun and Na, David and Nathanson, Samuel and Cao, Yinzhi and Watkins, Lanier},
  booktitle={MILCOM 2024 - 2024 IEEE Military Communications Conference (MILCOM)}, 
  title={Disinformation at Scale: Detecting AI-Human Composite Images via Convolution Ensembles}, 
  year={2024},
  volume={},
  number={},
  pages={621-626},
  abstract={Detecting fake news and synthetic content has become increasingly crucial in the cybersecurity community due to the rapid spread of disinformation, which can manipulate public opinion, influence elections, and harm reputations. The rise of advanced image generation models, like diffusion models, has exacerbated this issue by creating highly realistic images that are difficult to distinguish from authentic ones. Additionally, AI-human composite images, images with both human-generated and AI-generated elements, are more difficult to detect for modern detection tools. This paper explores state-of-the-art tools for detecting AI-generated images and introduces a novel detection method using ensembles of convolutional neural networks. Our method outperforms existing techniques when detecting AI-human composite images by dividing images into multiple subsections and evaluating each independently for signs of manipulation or generative signatures. We demonstrate the effectiveness of our approach through rigorous experimentation, showing significant improvements in detecting AI-human composite fake images and enhancing the robustness of detection systems against common evasion techniques like JPEG compression and geometric downsampling.},
  keywords={Military communication;Image coding;Image synthesis;Convolution;Voting;Transform coding;Diffusion models;Robustness;Convolutional neural networks;Fake news;Generative AI;machine learning;Artificial Intelligence;cybersecurity;disinformation;text-to-image model},
  doi={10.1109/MILCOM61039.2024.10773642},
  ISSN={2155-7586},
  month={Oct},}@ARTICLE{10681094,
  author={Ahmed, Zishan and Shanto, Shakib Sadat and Rime, Most. Humayra Khanom and Morol, Md. Kishor and Fahad, Nafiz and Hossen, Md. Jakir and Abdullah-Al-Jubair, Md.},
  journal={IEEE Access}, 
  title={The Generative AI Landscape in Education: Mapping the Terrain of Opportunities, Challenges, and Student Perception}, 
  year={2024},
  volume={12},
  number={},
  pages={147023-147050},
  abstract={Generative AI (GAI) technologies like ChatGPT are permanently changing academic education. Their integration opens up vast opportunities for bespoke learning and better student interaction but also brings about academic honesty issues and the application of real-life educators. This study aims to fill the literature gap regarding the use of multiple GAI tools and their effect on academic outcomes via a comprehensive review. A systematic literature review was performed following PRISMA guidelines to synthesize results on the potential and drawbacks of GAI in educational domains. We included theoretical and empirical papers that used qualitative, quantitative, or mixed-methods study designs. We have also explored conceptual frameworks and the most creative AI applications with a special emphasis on uniqueness and practicability. Experiences, and Perceptions Concerning To compile the information needed we gathered insights into what students were going through by conducting the survey which contains 200 respondents of undergraduate university students gathering insights into the college students’ experiences and perceptions related to GAI used for educational purposes. At the basic level, GAI comprises areas like personalization, task automation, teacher assistance, and efficiency among others, and respective solutions for the immersion of a learner in learning processes to reform directions. However, it generates plenty of challenges such as the question of assessment integrity, the risk that too much automated grading could overwhelm educational value, and relevantly the veracity of AI-generated content as well as the potential disruption to skills like critical thinking, in addition to data privacy and ethical issues. Student Perception Survey the text also indicates that most students, as per the student perception survey found AI systems useful in academic support. However, they also know the other side of the coin and are very familiar with the technology constraints and challenges.},
  keywords={Education;Generative AI;Artificial intelligence;Surveys;Chatbots;Ethics;Market research;Chatbots;education;generative AI;opportunities and challenges;student perception},
  doi={10.1109/ACCESS.2024.3461874},
  ISSN={2169-3536},
  month={},}@ARTICLE{8651511,
  author={Ainam, Jean-Paul and Qin, Ke and Liu, GuiSong and Luo, Guangchun},
  journal={IEEE Access}, 
  title={Sparse Label Smoothing Regularization for Person Re-Identification}, 
  year={2019},
  volume={7},
  number={},
  pages={27899-27910},
  abstract={Person re-identification (re-id) is a cross-camera retrieval task which establishes a correspondence between images of a person from multiple cameras. Deep learning methods have been successfully applied to this problem and have achieved impressive results. However, these methods require a large amount of labeled training data. Currently, the labeled datasets in person re-id are limited in their scale and manual acquisition of such large-scale datasets from surveillance cameras is a tedious and labor-intensive task. In this paper, we propose a framework that performs intelligent data augmentation and assigns the partial smoothing label to generated data. Our approach first exploits the clustering property of existing person re-id datasets to create groups of similar objects that model cross-view variations. Each group is then used to generate realistic images through adversarial training. Our aim is to emphasize the feature similarity between generated samples and the original samples. Finally, we assign a non-uniform label distribution to the generated samples and define a regularized loss function for training. The proposed approach tackles two problems 1) how to efficiently use the generated data and 2) how to address the over-smoothness problem found in current regularization methods. The extensive experiments on four large-scale datasets show that our regularization method significantly improves the re-id accuracy compared to existing methods.},
  keywords={Training;Task analysis;Generative adversarial networks;Gallium nitride;Measurement;Cameras;Smoothing methods;Computational and artificial intelligence;artificial neural network;feature extraction;image retrieval},
  doi={10.1109/ACCESS.2019.2901599},
  ISSN={2169-3536},
  month={},}@ARTICLE{10963975,
  author={Palla, Dominik and Slaby, Antonin},
  journal={IEEE Access}, 
  title={Evaluation of Generative AI Models in Python Code Generation: A Comparative Study}, 
  year={2025},
  volume={13},
  number={},
  pages={65334-65347},
  abstract={This study evaluates leading generative AI models for Python code generation. Evaluation criteria include syntax accuracy, response time, completeness, reliability, and cost. The models tested comprise OpenAI’s GPT series (GPT-4 Turbo, GPT-4o, GPT-4o Mini, GPT-3.5 Turbo), Google’s Gemini (1.0 Pro, 1.5 Flash, 1.5 Pro), Meta’s LLaMA (3.0 8B, 3.1 8B), and Anthropic’s Claude models (3.5 Sonnet, 3 Opus, 3 Sonnet, 3 Haiku). Ten coding tasks of varying complexity were tested across three iterations per model to measure performance and consistency. Claude models, especially Claude 3.5 Sonnet, achieved the highest accuracy and reliability. They outperformed all other models in both simple and complex tasks. Gemini models showed limitations in handling complex code. Cost-effective options like Claude 3 Haiku and Gemini 1.5 Flash were budget-friendly and maintained good accuracy on simpler problems. Unlike earlier single-metric studies, this work introduces a multi-dimensional evaluation framework that considers accuracy, reliability, cost, and exception handling. Future work will explore other programming languages and include metrics such as code optimization and security robustness.},
  keywords={Codes;Generative AI;Costs;Encoding;Accuracy;Python;Artificial intelligence;Internet;Software development management;Reliability;Automatization;generative AI;LLM;python;software development},
  doi={10.1109/ACCESS.2025.3560244},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10603301,
  author={Nukala, Saihemanth and Yuan, Xiaohong and Roy, Kaushik and Odeyomi, Olusola T.},
  booktitle={2024 4th International Conference on Computer Communication and Artificial Intelligence (CCAI)}, 
  title={Face Recognition for Blurry Images Using Deep Learning}, 
  year={2024},
  volume={},
  number={},
  pages={46-52},
  abstract={The rapid growth of visual surveillance and personal identification systems in smart environments has empowered the development of real-time face recognition, even under imperfect conditions. Among these challenges, recognizing faces in blurry images stands as a significant barrier to achieving consistent identification results. In this paper, we combine advanced machine learning algorithms and deep learning frameworks, integrating Generative Adversarial Networks (GANs), specifically the Generative Facial Prior (GFPGAN), to restore clarity to blurred facial images. The primary objective is to enhance the accuracy of face recognition in real-world scenarios where image quality may be compromised. In the proposed approach, the GFPGAN model serves as the primary mechanism for blind face restoration, transforming blurred images into clear and recognizable visuals. Upon achieving clarity in the image, a customized Convolutional Neural Network (CNN) is deployed to perform face recognition tasks. To showcase the efficiency of the proposed system, a comprehensive comparative analysis is carried out, comparing the results of the pretrained models VGG-Face, FaceNet, CNN, and DeepFace. Our experiments showed a high validation accuracy of 83.72% for FaceNet. Our experimental results demonstrate that the combination of GFPGAN preprocessing and deep learning models significantly improves blurry images face recognition accuracy.},
  keywords={Deep learning;Visualization;Accuracy;Image recognition;Face recognition;Surveillance;Authentication;face recognition;computer vision;deep learning;deblur;generative adversarial networks},
  doi={10.1109/CCAI61966.2024.10603301},
  ISSN={},
  month={May},}@INPROCEEDINGS{11013383,
  author={Preethi, C. and Gomathi, S.},
  booktitle={2025 8th International Conference on Trends in Electronics and Informatics (ICOEI)}, 
  title={Enhancing Autism Spectrum Disorder Detection and Classification with GAN-Driven Autoencoder Models}, 
  year={2025},
  volume={},
  number={},
  pages={841-846},
  abstract={Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder of highly variable symptoms, characterized by difficulties in communication, social interaction, and repetitive behaviors. Most current diagnostic approaches are based on behavioral assessments and clinical evaluations, which are rather subjective and may also require much time. Besides, traditional machine learning models fail to grasp the high-dimensional, intricate patterns of data in ASD, therefore seriously undermining the effectiveness in classification. This brings about an avid requirement for more efficient and reliable methodologies of ASD diagnosis. To tackle the above challenges, we propose here a novel method that exploits GAN s, combined with autoencoders (AE), for improved ASD detection and classification. The introduced GAN+AE model works in the feature extraction improvement direction—to learn complicated and high-level data representations. Compared to the conventional diagnostic features of ASD with added generation powers of GAN, our model presents improved performances in the classification of ASD cases to the best of their accuracy. Most significantly, compared with traditional machine-learning models, GAN+AE scored higher in terms of precision, recall, and F1-score; it decreases false negatives and maximizes ASD diagnostic accuracies—a promise for an earlier diagnosis tool for ASD. This article attempts to highlight the effectiveness of the deep learning models in overcoming the limitations of the traditional ASD detection approaches.},
  keywords={Deep learning;Autism;Accuracy;Computational modeling;Autoencoders;Predictive models;Generative adversarial networks;Data models;Robustness;Testing;Autism Spectrum Disorder (ASD);Disease Detection;Deep Learning;Classification;Artificial Intelligence (AI);Prediction},
  doi={10.1109/ICOEI65986.2025.11013383},
  ISSN={},
  month={April},}@INPROCEEDINGS{11012145,
  author={Mouthami, K and T, Elamathi and Ba, Brijesh A and T, Hari P},
  booktitle={2025 3rd International Conference on Advancements in Electrical, Electronics, Communication, Computing and Automation (ICAECA)}, 
  title={Generative AI in Autonomous UAV Systems: Revolutionizing Surveillance and Rescue Missions}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Defense and disaster management requires more advanced and efficient technological solutions for rapid responses. This research work introduces a leading-edge technique that integrates Enhanced Super Resolution Generative Adversarial Network (ESRGAN) and Yolo Only Look Once Version 11 (YOLOv11) for the autonomous drone. This approach marks a significant advancement in aerial monitoring of the environment by increased surveillance capabilities and reduced reaction time improving the overall efficiency. The proposed Artificial Intelligence (AI) model can be added to Unmanned Aerial Vehicles (UAV) which has predefined paths and is autonomous to reduce human interventions in defense and disaster relief operations. Beyond technical implementation, real-world applications, limitations and challenges of the proposed methodology is also discussed.},
  keywords={Disasters;Surveillance;Superresolution;Disaster management;Watches;Autonomous aerial vehicles;Real-time systems;Telecommunication computing;Reliability;Drones;Disaster Management;Defense;ESRGAN;YOLOv11},
  doi={10.1109/ICAECA63854.2025.11012145},
  ISSN={},
  month={April},}@ARTICLE{8889669,
  author={Kustowski, Bogdan and Gaffney, Jim A. and Spears, Brian K. and Anderson, Gemma J. and Thiagarajan, Jayaraman J. and Anirudh, Rushil},
  journal={IEEE Transactions on Plasma Science}, 
  title={Transfer Learning as a Tool for Reducing Simulation Bias: Application to Inertial Confinement Fusion}, 
  year={2020},
  volume={48},
  number={1},
  pages={46-53},
  abstract={We adopt a technique, known in the machine learning community as transfer learning, to reduce the bias of computer simulation using very sparse experimental data. Unlike the Bayesian calibration, which is commonly used to estimate the simulation bias, the transfer learning approach discussed in this article involves calculating an artificial neural network surrogate model of the simulations. Assuming that the simulation code correctly predicts the trends in the experimental data but it is subject to unknown biases, we then partially retrain, or transfer learn, the initial surrogate model to match the experimental data. This process eliminates the bias while still taking advantage of the physics relations learned from the simulation. Transfer learning can be easily adapted to a wide range of problems in science and engineering. In this article, we carry out numerical tests to investigate the applicability of this technique to predict the observable outcomes of inertial confinement fusion (ICF) experiments under new conditions. Using our synthetic validation data set, we demonstrate that an accurate predictive model can be built by retraining an initial surrogate model with experimental data volumes so small that they are relevant to the ICF problem. This opens up new opportunities for knowledge transfer and building predictive models in physics. After implementing transfer learning in a standard neural network, we successfully extended the method to a more complex, generative adversarial network architecture, which will be needed for predicting not only scalars but also diagnostic images in our future work.},
  keywords={Predictive models;Computational modeling;Neural networks;Data models;Numerical models;Physics;Standards;Artificial intelligence;artificial neural networks;calibration;computer simulation;hydrodynamics;inertial confinement;machine learning;neural networks},
  doi={10.1109/TPS.2019.2948339},
  ISSN={1939-9375},
  month={Jan},}@INPROCEEDINGS{9722696,
  author={Rizwan, A. and Abu-Dayya, A. and Filali, F. and Imran, A.},
  booktitle={2022 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Addressing Data Sparsity with GANs for Multi-fault Diagnosing in Emerging Cellular Networks}, 
  year={2022},
  volume={},
  number={},
  pages={318-323},
  abstract={Data-driven machine learning is considered a means to address the paramount challenge of timely fault diagnosis in modern and futuristic ultra-dense and highly complex mobile networks. Whereas diagnosing multiple faults in the network at the same time remains an open challenge. In this context, the data sparsity is hindering the potential of machine learning to address such issues. In this work, we have proposed a data augmentation scheme comprising Pix2Pix Generative Adversarial Network (GAN) and a customized loss function never used before, to address the data sparsity challenge in Minimization of Drive Tests (MDT) data. Our proposed unique augmentation scheme generates images of MDT coverage maps with Peak signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) values of 25 and 0.97 respectively, which are significantly higher than those achieved without our customized loss function. The performance of data augmentation scheme used is further evaluated with a Convolutional Neural Network (CNN) model for simultaneously detecting most commonly occurring network faults, such as antenna up-tilt, antenna down-tilt, transmission power degradation, and cell outage. The CNN applied on the data generated from the 1% of the MDT data with the proposed augmentation scheme has lead to a gain of 550% in the detection of all classes, including the four faults and cell with normal behavior, as compared to when it is applied on the data generated without our customized loss function.},
  keywords={Cellular networks;PSNR;Transmitting antennas;Machine learning;Generative adversarial networks;Minimization;Data models;GAN;ZSM;Fault diagnosis;Automation;Machine Learning;Deep learning;Wireless cellular networks},
  doi={10.1109/ICAIIC54071.2022.9722696},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10201295,
  author={Wang, Zimu and Gan, Hong-Seng},
  booktitle={2023 IEEE 3rd International Conference on Computer Communication and Artificial Intelligence (CCAI)}, 
  title={Multi-level Adversarial Training for Stock Sentiment Prediction}, 
  year={2023},
  volume={},
  number={},
  pages={127-134},
  abstract={Stock sentiment prediction is a task to evaluate whether the investors are expecting or gaining a positive or negative return from a stock, which has a high correlation with investors’ sentiments towards the business. However, as the nature of social media, the textual information posted by ordinary people is usually noisy, inconsistent, and even grammatically incorrect, leading the model to generate unsatisfied predictions. In this paper, we improve the performance of stock sentiment prediction by applying and comparing adversarial training at multiple levels, including character, word, and sentence levels, with the utilization of three novel adversarial attack models: DeepWordBug, BAE, and Generative Adversarial Network (GAN). We also propose an effective pre-processing technique and a novel adversarial examples incorporation method to improve the prediction results. To make an objective evaluation, we select three backbone models: Embedding Bag, BERT, and RoBERTa-Twitter, and validate the models before and after adversarial training on the TweetFinSent dataset. Experimental results demonstrate remarkable improvements in the models after adversarial training, and the RoBERTa-Twitter model with word-level adversarial training performs optimally among the experimented models. We conclude that sentence-level and word-level adversarial training are the most appropriate for deep learning and pre-trained language models, respectively, and we further conduct ablation studies to highlight the usefulness of our data pre-processing and adversarial examples incorporation approaches and a case study to display the adversarial examples generated by the proposed adversarial attack models.},
  keywords={Training;Deep learning;Correlation;Social networking (online);Computational modeling;Predictive models;Generative adversarial networks;Stock Sentiment;Sentiment Analysis;Textual Adversarial Attack;Adversarial Training;Natural Language Processing},
  doi={10.1109/CCAI57533.2023.10201295},
  ISSN={},
  month={May},}@INPROCEEDINGS{10870734,
  author={Kollem, Sreedhar and Peddakrishna, Samineni and Sirigiri, Chandrasekhar},
  booktitle={2024 4th International Conference on Artificial Intelligence and Signal Processing (AISP)}, 
  title={An Optimized GAN Approach for Denoising MRI Brain Tumor Images}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Image denoising is a critical pre-processing step in MRI brain imaging that is intended to improve image quality and clarity by reducing noise. The presence of noise in MRI images can be attributed to multiple factors, including the imaging apparatus, patient motion, and transmission inaccuracies. The presence of this noise might hinder the visibility of crucial anatomical features, hence posing challenges for medical practitioners in effectively diagnosing and interpreting the images. An optimized technique has been presented to tackle the aforementioned problem, which combines the Generative Adversarial Network (GAN) with the Spotted Hyena Optimizer (SHO). This technique is known as an optimized GAN (OGAN). The utilization of the Spotted Hyena Optimizer (SHO) in conjunction with GAN-based denoising presents a sophisticated method for enhancing image quality. The SHO optimizes the GAN's parameters, resulting in high-quality denoised images that retain essential characteristics. The effectiveness of this approach has been evaluated using peak signal-to-noise ratio (PSNR), Universal Image Quality Index (UQI), and Structural Similarity Index (SSIM). This methodology exhibits its superior performance compared to existing techniques.},
  keywords={Image quality;Neuroimaging;PSNR;Magnetic resonance imaging;Optimization models;Noise reduction;Noise;Generative adversarial networks;Indexes;Medical diagnostic imaging;Image denoising;GAN;Optimization;CNN model;Spotted Hyena Optimizer},
  doi={10.1109/AISP61711.2024.10870734},
  ISSN={2640-5768},
  month={Oct},}@INPROCEEDINGS{11022439,
  author={Jahan Suchi, Kazi Nusrat and Jahan, Nusrot and Tasnim, Arpa and Akhter, Nazneen},
  booktitle={2024 27th International Conference on Computer and Information Technology (ICCIT)}, 
  title={Explainable attention based BiLSTM-SVM for Software Requirement Classification: Integrating Generative Artificial Intelligence}, 
  year={2024},
  volume={},
  number={},
  pages={2404-2409},
  abstract={The human classification of software requirements, a difficult subjective process prone to inconsistencies and classification errors, is a major difficulty in software requirement specification (SRS). With an increasing number of requirements, manual classification becomes unfeasible. To address this issue, this work proposes a customized attention layer based BiLSTM-SVM hybrid architecture to implement automation in the categorization of software requirement. The model integrates a pre-trained GPT-Neo model to overcome the limitation of small real-world dataset by augmenting the data. The augmented dataset expands to 6,783 functional and non-functional requirements, seven times larger than the Promise_exp dataset. Experimental results on the augmented dataset are promising, achieving 97% accuracy on the testing set—significantly outperforming the other datasets. These findings demonstrate the effectiveness of data augmentation using the GPT-Neo model. GPT-Neo also enables the generation of balanced datasets, ensuring equal representation of FR and NFR. Additionally, LIME is implemented to ensure transparency in the model’s decision-making process. This approach allows future researchers to experiment with more complex architectures, such as transformers, without concerns of data scarcity or overfitting.},
  keywords={Adaptation models;Accuracy;Automation;Computational modeling;Decision making;Computer architecture;Data augmentation;Transformers;Software;Data models;Software Requirement Specification;GPT-Neo;BiLSTM-SVM;LIME;FRs;NFRs},
  doi={10.1109/ICCIT64611.2024.11022439},
  ISSN={2474-9656},
  month={Dec},}@INPROCEEDINGS{11035086,
  author={Wang, Wentao and Xie, Xiaohua},
  booktitle={2025 IEEE 6th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={HairDiffusion: Designing Your Hair with Diffusion Models}, 
  year={2025},
  volume={},
  number={},
  pages={456-461},
  abstract={Groundbreaking advancements have emerged within the domain of synthetic image creation over the past decade, with cutting-edge innovations like Stable Diffusion redefining the capabilities of text-guided image generation. However, precise image editing tailored to specific requirements has increasingly garnered attention, with hair editing for facial images emerging as a task of great interest, challenge, and practical value in the field of graphics. This task seeks to restructure hair segments through language-guided instructions, ensuring fidelity to the original image's structural and semantic attributes, ensuring that only the hair is altered in the generated target image, with all other content remaining consistent with the source. Although high-quality and controllable hair editing for facial images achieved through Generative Adversarial Networks (GANs) has demonstrated remarkable results, its applicability and accuracy remain constrained by the inherent limitations of GAN models. To address these challenges, this paper proposes a novel method, HairDiffusion, which leverages large-scale pre-trained diffusion models to significantly enhance the applicability of hair editing for real-world facial images. Through lora fine-tuning, attention map optimization, and a dual-guidance control mechanism with source reference, HairDiffusion achieves diversity and generalization in generated images while effectively preserving the original facial attributes.},
  keywords={Hair;Seminars;Technological innovation;Image synthesis;Semantics;Diffusion models;Generative adversarial networks;Stability analysis;Information technology;Optimization;Image generation;hair editing;diffusion model},
  doi={10.1109/AINIT65432.2025.11035086},
  ISSN={},
  month={April},}@INPROCEEDINGS{9414438,
  author={Du, Chenpeng and Han, Bing and Wang, Shuai and Qian, Yanmin and Yu, Kai},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={SynAug: Synthesis-Based Data Augmentation for Text-Dependent Speaker Verification}, 
  year={2021},
  volume={},
  number={},
  pages={5844-5848},
  abstract={Text-dependent speaker verification systems trained on large amount of labelled data exhibit remarkable performance. However, collecting the speech from a lot of speakers with target transcript is a lengthy and expensive process. In this work, we propose a synthesis based data augmentation method (SynAug) to expand the training set with more speakers and text-controlled synthesized speech. The performance of SynAug is evaluated on the RSR2015 dataset. Experimental results show that for i-vector framework, the proposed methods can boost the system performance significantly, especially for the low-resource condition where the amount of genuine speech is extremely limited. Moreover, combined with traditional data augmentation methods such as adding noises and reverberation, the systems could be further strengthened in extremely limited resource situation.},
  keywords={Training;System performance;Conferences;Signal processing;Reverberation;Speech processing;Data augmentation;Speech Synthesis;Text-dependent Speaker verification;i-vector},
  doi={10.1109/ICASSP39728.2021.9414438},
  ISSN={2379-190X},
  month={June},}@ARTICLE{10254267,
  author={Zheng, Shuai and Zhu, Zhenfeng and Liu, Zhizhe and Cheng, Jian and Zhao, Yao},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Adversarial Graph Disentanglement With Component-Specific Aggregation}, 
  year={2024},
  volume={5},
  number={5},
  pages={2204-2216},
  abstract={A real-world graph has a complex topological structure, which is often formed by the interaction of different latent factors. Disentanglement of these latent factors can effectively improve the robustness and expressiveness of the node representation of a graph. However, most existing methods lack consideration of the intrinsic differences in relations between nodes caused by factor entanglement. In this article, we propose an adversarial disentangled graph convolutional network (ADGCN) for disentangled graph representation learning. To begin with, we point out two aspects of graph disentanglement that need to be considered, i.e., microdisentanglement and macrodisentanglement. For them, a component-specific aggregation approach is proposed to achieve microdisentanglement by inferring latent components that caused the links between nodes. On the basis of microdisentanglement, we further propose a macrodisentanglement adversarial regularizer to improve the separability among component distributions, thus restricting the interdependence among components. In addition, to reveal the topological graph structure, a diversity-preserving node sampling approach is proposed, by which the graph structure can be progressively refined in a way of local structure awareness. The experimental results on various real-world graph data verify that our ADGCN obtains more favorable performance over currently available alternatives.},
  keywords={Representation learning;Adversarial machine learning;Artificial intelligence;Task analysis;Semantics;Visualization;Routing;Adversarial learning;graph disentanglement;graph neural networks;graph representation learning},
  doi={10.1109/TAI.2023.3316202},
  ISSN={2691-4581},
  month={May},}@INPROCEEDINGS{10664066,
  author={Jayadharshini, P. and Vasuki, C. and Santhiya, S. and Sathiyaseelan, S. and Chinnappan, D. Pavul and Srinesh, S.},
  booktitle={2024 International Conference on Emerging Innovations and Advanced Computing (INNOCOMP)}, 
  title={A Comparative Analysis of Diverse Classification Techniques in Machine Learning for Predicting Poker Hands}, 
  year={2024},
  volume={},
  number={},
  pages={563-569},
  abstract={This paper introduces an innovative approach to predicting poker hands through the application of machine learning algorithms. In our study, we delve into the realm of predictive analytics, exploring the effectiveness of various classification techniques on a comprehensive dataset of poker hands with known outcomes. The utilized algorithms encompass K-Nearest Neighbors (KNN), Logistic Regression, Adaboost, Decision Trees, Random Forest, LightGBM classifier, XGBoost, and Naive Bayes. Leveraging the inherent capabilities of these algorithms, we conduct an in-depth analysis of features extracted from the cards and their combinations, aiming to enhance predictive accuracy. To facilitate this investigation, we utilize a CSV file containing the pertinent data required for training and testing the models. The wide array of algorithms chosen permits a detailed assessment of their effectiveness in forecasting poker hands, taking into account measures like accuracy, sensitivity, and F1 measure. Integrating KNN, Logistic Regression, Adaboost, Decision Trees, Random Forest, LightGBM_classifier, XGBoost, and Naive Bayes offers a comprehensive understanding of the strengths and weaknesses of these algorithms in predicting poker hands. This research not only advances the field of predictive modeling in poker games but also contributes valuable insights into the optimal choice of algorithms for similar classification tasks.},
  keywords={Logistic regression;Machine learning algorithms;Accuracy;Computational modeling;Nearest neighbor methods;Prediction algorithms;Classification algorithms;Poker Hand;Machine Learning;XGBoost;Naïve Bayes;Logistic Regression},
  doi={10.1109/INNOCOMP63224.2024.00098},
  ISSN={},
  month={May},}@INPROCEEDINGS{10961354,
  author={MI, Thenmozhi and S, Nithya Sree R and J, Mohammed Esa Khan and B, Akshaya R and L, Barath kumar},
  booktitle={2024 First International Conference on Data, Computation and Communication (ICDCC)}, 
  title={Chest X-Ray Analysis Using Machine Learning for Pneumonia Detection}, 
  year={2024},
  volume={},
  number={},
  pages={156-159},
  abstract={A dangerous and potentially fatal respiratory infection is pneumonia., especially for young children and the elderly. With the shortage of radiologists, our automated approach can help fill the gap by providing a quick and reliable diagnosis. By leveraging advanced machine learning techniques, with the ultimate goal of improving patient outcomes by increasing the effectiveness and accuracy of pneumonia detection. Our study proposes an automated approach to detect pneumonia by applying advanced machine learning strategies to chest radiographs. The method is taking relevant information out of the photos and using a robust classification algorithm to distinguish between healthy images and images that show pneumonia. For image processing tasks, the Convolutional Neural Network (CNN) algorithm is selected due to its efficacy. A useful indicator for assessing pneumonia detection systems, the F1 score aids in determining how well machine learning models work. By indicating the model's capacity to precisely detect optimistic cases while reducing false positives, it offers a reasonable valuation of overall performance. The created model is a useful tool to assist healthcare workers in promptly identifying cases of pneumonia, since it demonstrates promising sensitivity and specificity. The findings of this study have implications for respiratory infection treatment that include accelerating diagnosis times, decreasing human error, and eventually increasing patient outcomes.},
  keywords={Pneumonia;Accuracy;Computational modeling;Machine learning;Medical services;Data models;Classification algorithms;Convolutional neural networks;Reliability;X-ray imaging;Pneumonia;Streptococcus pneumonia;Convolutional Neural Network;respiratory infections;X-ray images},
  doi={10.1109/ICDCC62744.2024.10961354},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11113958,
  author={Tadiparthi, Mothilal and Arathi, Vesangi Naga and Sai Vignesh, Vissamsetti and Raju, Talla Krishna and Maneesha, Veerabattina},
  booktitle={2025 5th International Conference on Expert Clouds and Applications (ICOECA)}, 
  title={Gray Scale Image Colorization using Convolutional Neural Network and PyTorch}, 
  year={2025},
  volume={},
  number={},
  pages={701-706},
  abstract={Colorizing grayscale photos is a difficult process that has important uses in the creative industries, media improvement, and historical photo restoration. By utilizing advances in neural networks for image-to-image translation, this project investigates colorization of black-and-white images using PyTorch and deep learning approaches. The technique uses a convolutional neural network (CNN) architecture trained on a range of colourful image datasets to predict chrominance components while maintaining brightness from the input grayscale image. Notably, that the model outperforms in the conventional techniques in terms of evaluation measures like PSNR (Peak Signal-to-Noise Ratio) and SSIM (Structural Similarity Index), achieving the good realistic and brilliant colorization. In addition to advancing automated image improvement, this research offers useful applications for repairing old photos, improving visual media, and supporting the creative industries by colorizing the black and white images.},
  keywords={Deep learning;Industries;Training;Visualization;PSNR;Image color analysis;Media;Gray-scale;Image restoration;Convolutional neural networks;Black-and-white photo colorization;PyTorch;Convolutional Neural Networks;Chrominance prediction;PSNR;SSIM;Automated image enhancement;Photo restoration;Creative industries;Deep learning},
  doi={10.1109/ICOECA66273.2025.00126},
  ISSN={},
  month={March},}@INPROCEEDINGS{10616690,
  author={Anupama, H.S and Pradeep, K.R and Niranjanamurthy, M and Kanthraju, V and Darshan, Cb and Murthy, Svn},
  booktitle={2024 International Conference on Knowledge Engineering and Communication Systems (ICKECS)}, 
  title={Adversarial learning for De-Identification of Medical-Records}, 
  year={2024},
  volume={1},
  number={},
  pages={1-5},
  abstract={Medical records may exclusively be disclosed for the purpose of research. Medical researchers can only access the medical records of patient if they are de-identified because of data protection and privacy laws. De-Identified data means the process of removing or masking protected health information (PHI) in order to reduce the risk that subjects identify be connected with data. Automatic de-identification classifiers The goal is to make it affordable to de-identify large amounts of medical records. Current classifiers are trained on costly manually pseudonymized records from a single source, limiting their applicability to new data sources. To improve this, we need larger, more diverse datasets for training more versatile de-identification tools. We propose a method to convert medical text into a secure format without the need for pseudonymization, making it easier to share training data securely.},
  keywords={Training;Knowledge engineering;Deep learning;Privacy;Limiting;Law;Soft sensors;De-identification;privacy;pseudonymization;neural networks;medical records etc},
  doi={10.1109/ICKECS61492.2024.10616690},
  ISSN={},
  month={April},}@INPROCEEDINGS{11073838,
  author={David, S. Alex and Karthik, Chelli and Abhishek, R S and Kalaingan, S and Shankar, B. Prabhu and M.A.Y, Peer Mohamed Appa},
  booktitle={2025 7th International Conference on Inventive Material Science and Applications (ICIMA)}, 
  title={Industrial Object Anomaly Detection}, 
  year={2025},
  volume={},
  number={},
  pages={1304-1307},
  abstract={Currently, industrial objects are being inspected by methods which are based on labeled datasets and manual overwatch, and this paper addresses the limitations of these methods with an unsupervised anomaly detection framework. To classify images as defective or normal without requiring any training data, this method use a pretrained ViT model from Hugging Face to extract the features and apply KMeans clustering. However, at the same time, this approach greatly reduces the cost and time needed to label the dataset while leaving detection accuracy from highly accurate sets (such as health records) essentially unchanged. Finally, the framework was evaluated in MVTec AD dataset, which gave an average accuracy above 70% on other object classes. Finally, this method deploys the model via a Streamlit interface, and can capture images uploaded by a user in real time, and classify. The system is scalable, capable of being applied to other industrial domains, and is more likely to be suitably useful as a practical quality control technique. However, some more improvements are still needed for real-time processing and localized defect localization in massive scales.},
  keywords={Location awareness;Accuracy;Computational modeling;Quality control;Streaming media;Transformers;Feature extraction;Real-time systems;Anomaly detection;Unsupervised learning;Unsupervised Learning;Anomaly Detection;Deep Learning;MVTec AD;Industrial Quality Control;Streamlit Deployment},
  doi={10.1109/ICIMA64861.2025.11073838},
  ISSN={},
  month={May},}@INPROCEEDINGS{10930025,
  author={Choi, Hyoungki and Kim, Seungwoo and Jang, Jinbeum and Paik, Joonki},
  booktitle={2025 IEEE International Conference on Consumer Electronics (ICCE)}, 
  title={Pose-Guided Person Image Synthesis with Hybrid Appearance Encoding}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={Despite significant advancements in pose-guided image synthesis techniques using diffusion models, many results still appear unrealistic and unnatural due to insufficient semantic understanding of the input person images by the synthesis models. This paper introduces an enhanced deep neural network for pose-guided person image synthesis. The proposed network integrates both global and local information by employing Swin Transformers and a CNN-based Fourier convolution block during the encoding process of a person image. This approach generates more natural and refined images across various poses and appearances. Furthermore, we improve the appearance encoding process by utilizing VQ-VAE (Vector Quantized Variational AutoEncoder) to compress appearance information. Our method demonstrates outstanding results in preserving details and reducing overfitting. Additionally, the generated images can be effectively used as training data for applications such as object detection, object re-identification, and abnormal behavior analysis.},
  keywords={Image coding;Image synthesis;Convolution;Semantics;Training data;Object detection;Transformers;Vectors;Hybrid power systems;Overfitting;pose;person image synthesis;Swin transformer;Fourier convolution;VQ-VAE;image generation},
  doi={10.1109/ICCE63647.2025.10930025},
  ISSN={2158-4001},
  month={Jan},}@INPROCEEDINGS{10895513,
  author={M, Tarun and S, Bairavel and D, Sudha and John, Jobin and G, Vignesh},
  booktitle={2024 International Conference on Emerging Research in Computational Science (ICERCS)}, 
  title={Real - Time Speech Decoding through Advanced lip Reading using Deep Learning Model}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={This research aims to develop a real-time speech decoding system by advanced lip-reading techniques through a deep learning model. The proposed solution integrates cutting-edge advancements in deep learning to make improvement in the efficiency of speech recognition systems. By employing this model will be trained on large datasets of audio-visual speech samples to learn analyzing the patterns of lip movements corresponding to speech phonetics. The system's real-time capability will be achieved through optimized model architectures and efficient computational strategies. The implementation will be validated using diverse datasets and evaluated against standard benchmarks, demonstrating its potential for applications in noisy environments, accessibility for the hearing-impaired, and improved speech recognition in various real-world scenarios. This research contributes to the evolving field of multimodal deep learning, offering a promising avenue for real-time speech decoding through advanced lip reading.},
  keywords={Deep learning;Scientific computing;Lips;Computational modeling;Speech recognition;Phonetics;Real-time systems;Decoding;Noise measurement;Standards;deep learning;Speech recognition;Optimization},
  doi={10.1109/ICERCS63125.2024.10895513},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10822535,
  author={Lee, Hyun Jung and Jo, Eunjung and Lim, Minjoo and Oh, Ji-Hye and Kam, Tae-Eui},
  booktitle={2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Solving Blind Inverse Problem in Microscopy: Diffusion-based Zero-shot Isotropic Reconstruction}, 
  year={2024},
  volume={},
  number={},
  pages={3384-3387},
  abstract={Volumetric fluorescence microscopy is crucial for non-invasive three-dimension (3D) visualization of biological systems but faces challenges due to anisotropic blurring caused by the point spread function (PSF). Previous methods have struggled with adapting to the diverse PSFs and have not effectively addressed their overall impacts of PSF. We propose Isotropic Diffusion Posterior Sampling (IsotropicDPS), solving isotropic reconstruction as a blind inverse problem. Our method employs two specialized score-based diffusion models, each trained on high-resolution lateral images and a diverse set of blurring PSFs. This approach enables the joint estimation of both the clean axial images and the PSF through a conditional posterior sampling strategy with a parallel reverse diffusion process. Remarkably, IsotropicDPS achieves zero-shot reconstruction and PSF estimation without requiring axial images during training. We validated our method through experiments on synthetic and real data, demonstrating superior performance and adaptability to varying PSF scenarios compared to existing methods.},
  keywords={Training;Three-dimensional displays;Inverse problems;Microscopy;Estimation;Reconstruction algorithms;Fluorescence;Diffusion models;Image reconstruction;Faces;Isotropic Reconstruction;Blind Inverse Problem;Diffusion Models;PSF},
  doi={10.1109/BIBM62325.2024.10822535},
  ISSN={2156-1133},
  month={Dec},}@ARTICLE{9296325,
  author={Yang, Hong-Ming and Zhang, Xu-Yao and Yin, Fei and Yang, Qing and Liu, Cheng-Lin},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Convolutional Prototype Network for Open Set Recognition}, 
  year={2022},
  volume={44},
  number={5},
  pages={2358-2370},
  abstract={Despite the success of convolutional neural network (CNN) in conventional closed-set recognition (CSR), it still lacks robustness for dealing with unknowns (those out of known classes) in open environment. To improve the robustness of CNN in open-set recognition (OSR) and meanwhile maintain its high accuracy in CSR, we propose an alternative deep framework called convolutional prototype network (CPN), which keeps CNN for representation learning but replaces the closed-world assumed softmax with an open-world oriented and human-like prototype model. To equip CPN with discriminative ability for classifying known samples, we design several discriminative losses for training. Moreover, to increase the robustness of CPN for unknowns, we interpret CPN from the perspective of generative model and further propose a generative loss, which is essentially maximizing the log-likelihood of known samples and serves as a latent regularization for discriminative learning. The combination of discriminative and generative losses makes CPN a hybrid model with advantages for both CSR and OSR. Under the designed losses, the CPN is trained end-to-end for learning the convolutional network and prototypes jointly. For application of CPN in OSR, we propose two rejection rules for detecting different types of unknowns. Experiments on several datasets demonstrate the efficiency and effectiveness of CPN for both CSR and OSR tasks.},
  keywords={Prototypes;Training;Feature extraction;Robustness;Task analysis;Biological neural networks;Brain modeling;Open-set recognition;CNN;prototype model;unknown detection;discriminative model;generative model},
  doi={10.1109/TPAMI.2020.3045079},
  ISSN={1939-3539},
  month={May},}@INPROCEEDINGS{10750596,
  author={Ali Kazmi, Syed Hussain and Hassan, Rosilah and Qamar, Faizan and Nisar, Kashif and Dahnil, Dahlila Putri},
  booktitle={2024 IEEE 7th International Symposium on Telecommunication Technologies (ISTT)}, 
  title={Threat Intelligence in IoMTs with Federated Learning using Non-IID Data: An Experimental Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={120-125},
  abstract={In the rapidly evolving field of Artificial Intelligence (AI) empowered cyberspace, securing the Internet of Medical Things (IoMTs) demands innovative strategies. Intrusion Detection Systems (IDS) integrated with Deep Learning (DL) have become a transformative approach for threat intelligence in IoMTs. However, centralized data processing in DL-based IDS raises privacy concerns. Therefore, Federated Learning (FL) has gained attention for potentially enhanced intrusion detection with privacy preservation. This study investigates the effectiveness of FL-enabled intrusion detection for IoMTs, particularly focusing on the challenge of Non-IID (Non-Independently and Identically Distributed) data. Utilizing the WUSTL-EHMS-2020 dataset of IoMTs, which includes various attacks such as man-in-the-middle (MitM), spoofing, and data injection attacks, random distribution based Non-IID data have been created and visualized using Principle Components Analysis (PCA). The experimentation is performed using Python based FLOWER federated learning framework. The comparative IDS simulations on centralized data and non-IID data reveal significant variations in the performance of IDS for both centralized learning and FL. Thereby, this study highlights the implications of these findings for future research directions.},
  keywords={Data privacy;Privacy;Medical devices;Federated learning;Intrusion detection;Data visualization;Data processing;Security;Artificial intelligence;Principal component analysis;AI;IoTs;Deep Learning;Privacy;IDS},
  doi={10.1109/ISTT63363.2024.10750596},
  ISSN={2767-9446},
  month={Oct},}@INPROCEEDINGS{10782876,
  author={Meng, Nan and Cheung, Jason P.Y. and Huang, Tao and Zhao, Moxin and Zhang, Yue and Yu, Chenxi and Shi, Chang and Zhang, Teng},
  booktitle={2024 46th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}, 
  title={EUFormer: Learning Driven 3D Spine Deformity Assessment with Orthogonal Optical Images}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={In clinical settings, the screening, diagnosis, and monitoring of adolescent idiopathic scoliosis (AIS) typically involve physical or radiographic examinations. However, physical examinations are subjective, while radiographic examinations expose patients to harmful radiation. Consequently, we propose a pipeline that can accurately determine scoliosis severity. This pipeline utilizes posteroanterior (PA) and lateral (LAT) RGB images as input to generate spine curve maps, which are then used to reconstruct the three-dimensional (3D) spine curve for AIS severity grading. To generate the 2D spine curves accurately and efficiently, we further propose an Efficient U-shape transFormer (EUFormer) as the generator. It can efficiently utilize the learned feature across channels, therefore producing consecutive spine curves from both PA and LAT views. Experimental results demonstrate superior performance of EUFormer on spine curve generation against other classical U-shape models. This finding demonstrates that the proposed method for grading the severity of AIS, based on a 3D spine curve, is more accurate when compared to using a 2D spine curve.},
  keywords={Three-dimensional displays;Sensitivity;Pipelines;Scoliosis;Transformers;Optical sensors;Artificial intelligence;Diagnostic radiography;Image reconstruction;Monitoring;Adolescent Idiopathic Scoliosis;3D spine curve;efficient vision transformer;severity grading;generative adversarial network},
  doi={10.1109/EMBC53108.2024.10782876},
  ISSN={2694-0604},
  month={July},}@INPROCEEDINGS{11065659,
  author={Xu, Zhifei and Tang, Zhiqing and Xie, Xuan and Lou, Jiong and Guo, Jianxiong},
  booktitle={2025 International Conference on Sensor-Cloud and Edge Computing System (SCECS)}, 
  title={Edge-Collaborative Model Reuse for Low-Latency AI Task Scheduling with Attention-based Soft Actor-Critic}, 
  year={2025},
  volume={},
  number={},
  pages={173-178},
  abstract={The increasing use of AI and large language models has driven the deployment of Generative AI (GenAI) in cloud data centers. However, the inherent latency and high resource costs associated with large AI models are problematic for latency-sensitive edge users. While edge server deployment can reduce transmission times, it often leads to underutilized resources and suboptimal trade-offs between inference latency and quality. This paper introduces an Edge-Collaborative AI Task scheduling (CAT) algorithm that combines model reuse to reduce latency. We address AI task scheduling for edge servers by segmenting tasks and distributing patches, considering model distribution and cold starts. We propose a soft actor-critic-based algorithm, CAT, which uses an attention layer to learn complex edge system dynamics. Simulations in a task scheduling environment demonstrate that CAT reduces inference latency by up to 25% compared to baseline methods.},
  keywords={Schedules;System dynamics;Scheduling algorithms;Heuristic algorithms;Quality of service;Dynamic scheduling;Inference algorithms;Servers;Artificial intelligence;Low latency communication;I Task;Low-latency Scheduling;Attention;Soft Actor-CriticI Task;Soft Actor-CriticA},
  doi={10.1109/SCECS65243.2025.11065659},
  ISSN={},
  month={April},}@INPROCEEDINGS{10754689,
  author={Stein, Kyle and Harvey, Alexander and Lopez, Aylanna and Taj, Uzma and Watkins, Shari and Watkins, Lanier},
  booktitle={2024 IEEE 15th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)}, 
  title={Eliciting and Measuring Toxic Bias in Human-to-Machine Interactions in Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={13-19},
  abstract={As Large Language Models (LLMs) continue to advance and be utilized across societal domains, such as finance, healthcare, and the justice system, the need to address the inherent bias and the ability to learn new biases in these models becomes imminent. Concerns regarding these biases are rising, given their potential to perpetuate and even amplify existing social inequalities. This paper explores the multifaceted nature of bias in artificial intelligence (AI), examining the similarities and differences between human and machine bias. We delve into the origins of bias, distinguishing between those introduced by users and those inherent in the AI systems themselves. Our study focuses on the mechanisms by which biases are elicited and amplified through human-to-machine interactions. Through experimentation and analysis, we implement methodologies for eliciting, measuring, and mitigating these biases. Our results suggest that even though LLMs like ChatGPT-4 are equipped with effective content moderators, these chatbots can still learn and exhibit biased responses through human coercion. Further, we have learned that these biases are both inherent and learned through human interaction. Finally, we offer insightful strategies to mitigate these biases in LLMs.},
  keywords={Large language models;Finance;Medical services;Mobile communication;Chatbots;Large Language Models;Generative AI;Bias},
  doi={10.1109/UEMCON62879.2024.10754689},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10541203,
  author={El Houda Dehimi, Nour and Tolba, Zakaria},
  booktitle={2024 6th International Conference on Pattern Analysis and Intelligent Systems (PAIS)}, 
  title={Attention Mechanisms in Deep Learning : Towards Explainable Artificial Intelligence}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Attention mechanisms have revolutionized Machine Learning (ML), particularly in Natural Language Processing (NLP). These mechanisms enable models to selectively focus on crucial parts of the input data, improving performance across tasks like machine translation and sentiment analysis. However, complex ML architectures often remain opaque. This paper explores how attention mechanisms offer a unique path towards Explainable Artificial Intelligence (XAI). By visualizing and analyzing where a model "attends", we can gain insights into which features or data components were most impactful for its predictions. This understanding facilitates model debugging, bias detection, and the development of more transparent AI systems. We discuss different types of attention mechanisms and their potential for explainability in various ML domains.},
  keywords={Analytical models;Technological innovation;Sentiment analysis;Explainable AI;Predictive models;Data models;Trajectory;Attention mechanisms;Deep learning;CNN;RNN;LSTM;GAN;DNN;XAI},
  doi={10.1109/PAIS62114.2024.10541203},
  ISSN={},
  month={April},}@ARTICLE{9953141,
  author={Chiu, Chien-Ching and Chen, Po-Hsiang and Jiang, Hao},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Electromagnetic Imaging of Uniaxial Objects by Artificial Intelligence Technology}, 
  year={2022},
  volume={60},
  number={},
  pages={1-14},
  abstract={The electromagnetic (EM) imaging of uniaxial objects by the artificial intelligence (AI) technology is presented in this article. We study the 2-D inverse scattering problem from uniaxial objects illuminated by the transverse magnetic (TM) and transverse electric (TE) polarized incident waves. As the uniaxial objects have different components of permittivity along different transverse directions, the problem of TE polarization will be more severe than that of TM polarization. We use the dominant current scheme (DCS) and backpropagation scheme (BPS) to calculate the preliminary permittivity distribution. By combining with deep learning and neural networks, the permittivity distribution of those uniaxial objects can be reconstructed more accurately. U-Net is used to reconstruct the permittivity distribution because U-Net has shared the weights and biases, which can effectively reduce the network complexity and is very suitable for solving image processing problems. In the numerical results, we added different noises to compare the reconstruction results of the DCS and BPS initial estimations through the U-Net. Numerical results show that the reconstruction permittivity for the DCS initial estimation is better than that for the BPS initial estimation. Our diversity is that we have reconstructed the uniaxial objects by neural network successfully with less time-consuming effort and real-time imaging.},
  keywords={Image reconstruction;Neural networks;Imaging;Deep learning;Permittivity;Inverse problems;Electromagnetics;Deep learning;dielectric objects;electromagnetic (EM) imaging;inverse scattering;U-Net;uniaxial objects},
  doi={10.1109/TGRS.2022.3222502},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{9862656,
  author={Yang, Wenkao and Zeng, Chenglong},
  booktitle={2022 IEEE 5th International Conference on Big Data and Artificial Intelligence (BDAI)}, 
  title={A Hybrid Anomaly Detection Model Based on GANomaly in Cloud Environment}, 
  year={2022},
  volume={},
  number={},
  pages={51-56},
  abstract={Anomaly detection technology, which analyzes network data in detail and provides strategies for deploying security tools to ensure the integrity, confidentiality, and reliability of computer systems, is an important part of network information security infrastructure. However, in the cloud environment, the massive network traffic data contains many irrelevant or redundant features, which not only consumes many computing resources but also makes the detection accuracy lower. To this end, this paper proposes a hybrid model based on NSGA-III and GANomaly. Among them, NSGA-III can optimize the model in terms of the number of features, accuracy and false positive rate, while GAN omaly is a classifier that can be trained without negative samples. The experimental results show that the model reduces the number of features by nearly 74% on the basis of an accuracy rate of 99.71 % and a false alarm rate of 0.2% on the CSE-CIC-IDS2018 dataset.},
  keywords={Training;Computational modeling;Information security;Telecommunication traffic;Feature extraction;Generative adversarial networks;Robustness;cloud environment;redundant features;NSGA-III;GANomaly},
  doi={10.1109/BDAI56143.2022.9862656},
  ISSN={},
  month={July},}@INPROCEEDINGS{10749007,
  author={Ye, Jiajie and Sheng, Yongji and Wang, Siyu and Ma, Ye and Yang, Zheng and Liu, Xinyu and Xi, Ning},
  booktitle={2024 IEEE 14th International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)}, 
  title={Embodied Generative Method for Scheduling Disinfection Tasks Using Robot}, 
  year={2024},
  volume={},
  number={},
  pages={422-427},
  abstract={Embodied artificial intelligence (AI) systems, which combine AI with physical robots, have recently received significant attention. However, dynamic environments harbor much uncertainty and unknown situations, posing challenges for robot task scheduling and motion planning. This paper presents an approach that integrates language models with robots to achieve embodied generative method for scheduling disinfection task. We propose a framework that enables the zero-shot capability of disinfection robots in real-world environments. The experiments demonstrate that, compared to traditional static or dynamic planning methods, the proposed framework effectively performs in scenarios with randomly distributed objects and zero-shot situations, thereby enhancing the system's robustness in practical applications.},
  keywords={Training;Uncertainty;Large language models;Dynamics;Zero shot learning;Robot sensing systems;Dynamic scheduling;Robustness;Cognition;Planning},
  doi={10.1109/CYBER63482.2024.10749007},
  ISSN={2642-6633},
  month={July},}@INPROCEEDINGS{11035645,
  author={G, Saranya and K S, Krishna Meeraa and S R, Lakshanyasri and Chilukuri, Sriya},
  booktitle={2025 5th International Conference on Pervasive Computing and Social Networking (ICPCSN)}, 
  title={Artificial Intelligence-Driven Ant Colony Optimization for Sustainable Food Delivery and Carbon Footprint Reduction}, 
  year={2025},
  volume={},
  number={},
  pages={1852-1858},
  abstract={The rapidly expanding urban food delivery industry has raised environmental concerns due to carbon emissions, delivery delays, and increased operating expenses. This study proposes an Artificial Intelligence-driven system that integrates Ant Colony Optimization (ACO) with carbon emission tracking to enhance route planning for sustainable food delivery. By developing environmentally friendly and effective delivery routes, the main objective is to decrease fuel usage, reduce delivery delays, and lower the overall carbon footprint. The system uses the Haversine formula and vehicle-specific emission factors to generate optimum routes and predicted carbon emissions based on delivery locations entered by customers through a Streamlit-based web application. ACO, inspired by the foraging behavior of ants, finds the quickest and least polluting routes by dynamically updating pheromone trails based on route distances. Compared to traditional algorithms, the model uses real-time traffic data to dynamically adjust routes, which reduces delivery times by 19%, fuel consumption by 13%, and carbon emissions by 14%. The proposed solution demonstrates how AI, coupled with nature-inspired optimization, may greatly improve urban logistics while advancing environmental sustainability.},
  keywords={Ant colony optimization;Social networking (online);Carbon dioxide;Real-time systems;Planning;Delays;Fuels;Optimization;Carbon footprint;Logistics;Route Planning;Ant Colony Optimization;Sustainable Food Delivery;Route Optimization;Carbon Emission Tracking;Urban Logistics},
  doi={10.1109/ICPCSN65854.2025.11035645},
  ISSN={},
  month={May},}@ARTICLE{7935512,
  author={Li, Liyuan and Xu, Qianli and Gan, Tian and Tan, Cheston and Lim, Joo-Hwee},
  journal={IEEE Transactions on Cybernetics}, 
  title={A Probabilistic Model of Social Working Memory for Information Retrieval in Social Interactions}, 
  year={2018},
  volume={48},
  number={5},
  pages={1540-1552},
  abstract={Social working memory (SWM) plays an important role in navigating social interactions. Inspired by studies in psychology, neuroscience, cognitive science, and machine learning, we propose a probabilistic model of SWM to mimic human social intelligence for personal information retrieval (IR) in social interactions. First, we establish a semantic hierarchy as social long-term memory to encode personal information. Next, we propose a semantic Bayesian network as the SWM, which integrates the cognitive functions of accessibility and self-regulation. One subgraphical model implements the accessibility function to learn the social consensus about IR-based on social information concept, clustering, social context, and similarity between persons. Beyond accessibility, one more layer is added to simulate the function of self-regulation to perform the personal adaptation to the consensus based on human personality. Two learning algorithms are proposed to train the probabilistic SWM model on a raw dataset of high uncertainty and incompleteness. One is an efficient learning algorithm of Newton's method, and the other is a genetic algorithm. Systematic evaluations show that the proposed SWM model is able to learn human social intelligence effectively and outperforms the baseline Bayesian cognitive model. Toward real-world applications, we implement our model on Google Glass as a wearable assistant for social interaction.},
  keywords={Computational modeling;Bayes methods;Cognition;Probabilistic logic;Semantics;Social intelligence;Psychology;Artificial social intelligence (ASI);Bayesian cognitive model (BCM);cognitive modeling;computational social intelligence;generative model;machine learning;personality model;probabilistic model;social working memory (SWM);statistical learning},
  doi={10.1109/TCYB.2017.2706027},
  ISSN={2168-2275},
  month={May},}@ARTICLE{10274069,
  author={Cho, Eunhee and Jeon, Byeonghwan and Park, In Kyu},
  journal={IEEE Access}, 
  title={Synthesizing Industrial Defect Images Under Data Imbalance}, 
  year={2023},
  volume={11},
  number={},
  pages={111335-111346},
  abstract={Defect detection is a crucial technology in the industry that enhances production efficiency within the manufacturing sector. However, obtaining a balanced dataset with sufficient samples of both normal and defect is often challenging and time-consuming. Constructing an unbalanced dataset skewed toward normal samples results in decreased performance and reduced generalization of trained models. Therefore, building an appropriate dataset is essential for effectively training deep models. In this study, we propose a defect image augmentation technique based on generative adversarial networks (GANs), dubbed SyNDGAN, to address the challenges of unbalanced datasets encountered in real-world manufacturing scenarios. Specifically, our SyNDGAN synthesizes defect samples from normal images with given segmentation maps which contain the defect types and location of the defect. We validate our method by utilizing manufacturer data which considers the industrial scenario, with limited data. In our experiments, the proposed method shows superior quality compared to other methods both quantitatively and qualitatively. Furthermore, we demonstrate that synthesized data helps to improve the defect recognition performance, which can be utilized in real-world scenarios.},
  keywords={Generative adversarial networks;Training;Data models;Generators;Inspection;Decoding;Image segmentation;Data augmentation;Classification algorithms;Manufacturing systems;Defect synthesis;generative adversarial networks;augmentation;classification},
  doi={10.1109/ACCESS.2023.3322927},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8857529,
  author={Huang, Dianwen and Feng, Mengling},
  booktitle={2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}, 
  title={Understanding Deep Convolutional Networks for Biomedical Imaging: A Practical Tutorial}, 
  year={2019},
  volume={},
  number={},
  pages={857-863},
  abstract={Medical imaging seeks to unveil the internal structures hidden by the skin and bones to assist disease diagnosis and also treatment optimisation. In the past, processing medical images used to be a laborious task. However, the development of artificial intelligence has allowed the machine to gain a high level of understanding to perceive and extract information from biomedical images. Deep learning models, in particular, the convolutional neural networks (CNNs), were developed and implemented successfully for various biomedical applications. Therefore, it is of paramount importance for healthcare practitioners to understand the mechanisms behind the implemented CNNs to accurately interpret their outcomes. This tutorial summarises the key steps to train a functional CNNs. CNNs are usually constructed in the order of a convolution operation, ReLU, spatial pooling and followed by the fully connected layers. In addition, we have also introduced a number of preprocessing methods that target the image augmentation to combat the sparse data problem. We further explored a generative model as an augmentation method known as the generative adversarial networks (GANs), where GANs may yield new useful information to the dataset as compared to the classical augmentation.},
  keywords={Kernel;Convolution;Feature extraction;Medical diagnostic imaging;Task analysis;Diseases},
  doi={10.1109/EMBC.2019.8857529},
  ISSN={1558-4615},
  month={July},}@INPROCEEDINGS{10311193,
  author={Hogue, Debra and Sharp, Timothy and Karch, Joseph and Dolinger, Geoffrey and Stringer, Alexander and Schley, Lacey and Bowersox, Adam and Weaver, Chris and Hougen, Dean},
  booktitle={2023 IEEE/AIAA 42nd Digital Avionics Systems Conference (DASC)}, 
  title={Using Informative AI to Understand Camouflaged Object Detection and Segmentation}, 
  year={2023},
  volume={},
  number={},
  pages={1-9},
  abstract={Explainable artificial intelligence is crucial for trust-building and gaining insights into machine learning applications, allowing for the identification of improvement opportunities. Recent advances in computer vision have incorporated XAI into object detection, providing explanations to validate system predictions. However, informative artificial intelligence, which focuses on understanding the underlying world behind data, has not been integrated into camouflaged object detection and segmentation research. We propose leveraging the Self-Explaining Decision Architecture alongside localization and ranking techniques to bridge this gap. By combining explainable artificial intelligence with informative artificial intelligence concepts into camouflaged object detection and segmentation, we strive to deepen our understanding of visual cues that undermine camouflage.},
  keywords={Location awareness;Visualization;Systematics;Decision making;Object detection;Machine learning;Feature extraction;Camouflage Object Detection and Segmentation;Informative AI;Self-Explaining AI;Machine Learning;Deep Learning;Computer Vision;Image Segmentation},
  doi={10.1109/DASC58513.2023.10311193},
  ISSN={2155-7209},
  month={Oct},}@ARTICLE{11071380,
  author={Peng, Dandan and Xie, Linhai and Yang, Hong and Zhang, Yanchun},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={scVDM: A Diffusion Model Integrated with Conditional VAE for Generative Single-cell Tasks}, 
  year={2025},
  volume={},
  number={},
  pages={1-15},
  abstract={Single-cell RNA-seq data has become a critical source in revealing cellular activities. However, the developing probing techniques and the fatal damages to the detected cells incur various kinds of noise, e.g. the batch effect and the absence of cellular correspondence between experimental groups. Therefore, many single-cell tasks are better modeled as generative rather than discriminative tasks, since, instead of the exact cell-wise ground truth, only the distribution of cellular profiles under a certain condition is measurable. Considering the highly nonlinear and complex associations between gene expressions, we developed scVDM, a latent diffusion model integrated with a transformer-based conditional denoiser to learn three different generative tasks in single-cell data, including conditional data generation, batch effect correction and drug perturbation prediction. The high dimensional transcriptomic data are firstly projected to the latent space through a conditional VAE and then the complicated relationships between latent dimensions are deeply exploited through self-attentions to generate realistic diffusion noise. Based on the evaluation of five real-world datasets, our method demonstrates outstanding performance through comprehensive experimental results in all generative tasks.},
  keywords={Data models;Diffusion models;Perturbation methods;Drugs;Training;Gene expression;Vectors;Transformers;Predictive models;Computational modeling;scRNA-seq data;generative tasks;diffusion model},
  doi={10.1109/JBHI.2025.3585960},
  ISSN={2168-2208},
  month={},}@ARTICLE{10662891,
  author={Hashmi, Ehtesham and Yildirim Yayilgan, Sule and Hameed, Ibrahim A. and Mudassar Yamin, Muhammad and Ullah, Mohib and Abomhara, Mohamed},
  journal={IEEE Access}, 
  title={Enhancing Multilingual Hate Speech Detection: From Language-Specific Insights to Cross-Linguistic Integration}, 
  year={2024},
  volume={12},
  number={},
  pages={121507-121537},
  abstract={The rise of social media has enabled individuals with biased perspectives to spread hate speech, directing it toward individuals based on characteristics such as race, gender, religion, or sexual orientation. Constructive interactions in varied communities can greatly enhance self-esteem, yet it is vital to consider that adverse comments may affect individuals’ social standing and emotional health. The crucial task of detecting and addressing this type of content is imperative for reducing its negative effects on communities and individuals alike. The rising occurrence highlights the urgency for enhanced methods and robust regulations on digital platforms to protect humans from such prejudicial and damaging conduct. Hate speech typically appears as a deliberate hostile action aimed at a particular group, often with the intent to demean or isolate them based on various facets of their identity. Research on hate speech predominantly targets resource-aware languages like English, German, and Chinese. Conversely, resource-limited languages, including European languages such as Italian, Spanish, and Portuguese, alongside Asian languages like Roman Urdu, Korean, and Indonesian, present obstacles. These challenges arise from a lack of linguistic resources, making the extraction of information a more strenuous task. This study is focused on the detection and improvement of multilingual hate speech detection across 13 different languages. To conduct a thorough analysis, we carried out a series of experiments that ranged from classical machine learning techniques and mainstream deep learning approaches to recent transformer-based methods. Through hyperparameter tuning, optimization techniques, and generative configurations, we achieved robust and generalized performance capable of effectively identifying hate speech across various dialects. Specifically, we achieved a notable enhancement in detection performance, with precision and recall metrics exceeding baseline models by up to 10% across several lesser-studied languages. Additionally, our work extends the capabilities of explainable AI within this context, offering deeper insights into model decisions, which is crucial for regulatory and ethical considerations in AI deployment. Our study presents substantial performance improvements across various datasets and languages through meticulous comparisons. For example, our model significantly outperformed existing benchmarks: it achieved F1-scores of 0.90 in German (GermEval-2018), up from the baseline score of 0.72, and 0.93 in German (GermEval-2021), a substantial increase from 0.58. Additionally, it scored 0.95 in Roman Urdu HS, surpassing the previous peak of 0.91. Furthermore, for mixed-language datasets such as Italian and English (AMI 2018), our accuracy rose dramatically from 0.59 to 0.96. These outcomes emphasize the robustness and versatility of our model, establishing a new standard for hate speech detection systems across diverse linguistic settings.},
  keywords={Transformers;Hate speech;Artificial intelligence;Linguistics;Adaptation models;Machine learning;Deep learning;Natural language processing;Explainable AI;Social networking (online);Multi lingual;Hate speech;word embedding;machine learning;deep learning;transformers;natural language processing;explainable AI},
  doi={10.1109/ACCESS.2024.3452987},
  ISSN={2169-3536},
  month={},}@ARTICLE{11072164,
  author={Akin, Murat and Sir, Gül Didem Batur and Karadağ, Ayyüce Aydemir and Çerçioğlu, Hakan},
  journal={IEEE Access}, 
  title={A Multi-Criteria Comparison of Large Language Model Powered Assistants in Pre-Research Studies for the Academia}, 
  year={2025},
  volume={13},
  number={},
  pages={127086-127099},
  abstract={Large Language Models (LLMs), including Generative Pre-trained Transformers (GPT), a specific type of Large Language Model Powered Assistants (LLM-PA), have emerged as powerful tools in academic research and education. They offer capabilities ranging from language understanding to content generation, and serve as the foundation for LLM-PA-powered assistants, such as ChatGPT, DeepSeek, and Gemini, which facilitate interactive learning, research support, and intelligent tutoring. This study aims to guide researchers in choosing and ranking various LLM-PA alternatives in their preliminary research for academic studies. However, selecting the appropriate alternatives requires considering a large number of distinct criteria. Therefore, we conducted a multi-criteria comparison of different LLM-PAs employed in academic research. These assistants are evaluated based on criteria including performance metrics, user experience, ethical issues, and technical constraints. Examining the strengths and limitations of each tool across these dimensions, it is aimed to provide insights into their performance and suitability for academic applications. Throughout the solution procedure, we first define the criteria and sub-criteria affecting the preferences and sort them by the G1 method. Subsequently, we evaluate nine commonly used LLM-PA using the Simple Additive Weighting Method. According to the results, Gemini 2.0, Claude 3.7 Sonnet and ChatGPT-4o are the most preferred tools.},
  keywords={Chatbots;Writing;Education;Artificial intelligence;Ethics;Accuracy;Publishing;Decision making;User experience;Transformers;LLM-powered assistants;academic studies;multi-criteria decision-making;simple additive weighting method},
  doi={10.1109/ACCESS.2025.3586502},
  ISSN={2169-3536},
  month={},}@ARTICLE{11176145,
  author={Lu, Xinyu and Feng, Zhanbo and Lou, Jiong and Wu, Chentao and Xue, Guangtao and Zhao, Wei and Li, Jie},
  journal={IEEE Transactions on Mobile Computing}, 
  title={Multi-Layer Scheduling in Gig Platforms Using a Generative Diffusion Model With Duality Guidance}, 
  year={2025},
  volume={},
  number={},
  pages={1-14},
  abstract={In recent years, gig platforms have emerged as a new paradigm, seamlessly connecting workers and tasks while leveraging workers' collective intelligence, participation, and shared resources. Traditionally, platforms have operated under the assumption of worker homogeneity, where service capabilities and associated service costs are similar. However, in mobile computing scenarios, such as mobile crowdsensing, the diversity in worker capabilities and costs renders the supply and demand matching into a complex problem characterized by multiple layers of workers possessing distinct attributes. The dynamic nature of incoming task requests requires the continual reallocation of these workers, thereby introducing a time-dependent overhead. In this paper, we introduce a framework, called the Generative Diffusion Model with Duality Guidance, termed Guid, to address the intricate multi-layer scheduling problem. We formalize a time-slotted long-term optimization problem that captures the spatiotemporal dynamics of task requests and worker services, as well as the intricate time-coupled overhead. Our framework employs a generative diffusion model to explore the complex solution space of the problem and generate superior solutions. To effectively manage time coupling, we utilize dual optimization theory to generate time slot-aware information, guiding the generative diffusion model towards solutions that assure long-term performance. We provide a rigorous theoretical analysis demonstrating that our guidance solution ensures a parameterized competitive ratio guarantee relative to the theoretically optimal solution. Our comprehensive experiments further illustrate that the proposed method outperforms benchmark techniques, achieving reduced overhead compared to seven baseline methods.},
  keywords={Diffusion models;Costs;Optimization;Training;Couplings;Mobile computing;Crowdsensing;Supply and demand;Space exploration;Dynamic scheduling;Competitive analysis;generative diffusion model;gig economy},
  doi={10.1109/TMC.2025.3613450},
  ISSN={1558-0660},
  month={},}@ARTICLE{10500419,
  author={Prakash, P. Suman and Rao, P. Kiran and Babu, E. Suresh and Khan, Surbhi Bhatia and Almusharraf, Ahlam and Quasim, Mohammad Tabrez},
  journal={IEEE Access}, 
  title={Decoupled SculptorGAN Framework for 3D Reconstruction and Enhanced Segmentation of Kidney Tumors in CT Images}, 
  year={2024},
  volume={12},
  number={},
  pages={62189-62198},
  abstract={Our proposed work, SculptorGAN, represents a novel advancement in the domain of medical imaging, for the accurate and automatic diagnosis of renal tumors, using the techniques and principles of Generative Adversarial Network (GAN). This dichotomous framework forms a contrast to the normal segmentation models like that of U-Net model but, instead, founded on a strategy that is aimed towards reconstruction and segmentation of CT images, particularly of renal malignancies. The core of the SculptorGAN methodology is a GAN-based approach for precise three-dimensional rendering of renal anatomies from CT scans, followed by a segmentation phase to correctly separate the neoplastic from non-neoplastic tissues. In fact, SculptorGAN was designed to circumvent limitations that come as inherent in the segmentation techniques, and in this case to eliminate them. In fact, by including such an advanced algorithmic architecture, accuracy of diagnosis in SculptorGAN has increased to 96.5%, which is the primary aspect behind early detection and thus proper curing of renal tumors. The better results were ascribed to more accurate and detailed reconstruction of renal structures that the framework allowed, apart from the better segmentation. The performance analyses show quantitative results with respect to the presented datasets, while the validation shows that SculptorGAN outperforms most of the traditional models such as U-Net. In particular, SculptorGAN decreased the time taken for 3D reconstruction by about 35% while increasing the accuracy of segmentation by 20% or more. The outcome, in their turn, may suggest this improvement in efficiency and the level of reliability for renal tumor diagnosis as of having far-reaching implications for the patient treatment and its outcomes. In conclusion, the framework deals with all the challenges with an accurate diagnosis of renal tumors and brings betterment in the overall field of medical image analysis by providing the abilities of GANs for the betterment in image reconstruction and segmentation.},
  keywords={Three-dimensional displays;Image reconstruction;Image segmentation;Tumors;Training;Computed tomography;Computational modeling;Medical diagnostic imaging;Deep learning;Renal tumors;diagnostic imaging;3D reconstruction;artificial intelligence;GAN methodology;healthcare diagnostics;decoupling deep learning},
  doi={10.1109/ACCESS.2024.3389504},
  ISSN={2169-3536},
  month={},}@ARTICLE{9149870,
  author={Zhang, Peng and Hua, Xia and Wang, Xinqing and Rui, Ting and Zhang, Haitao and Shao, Faming and Wang, Dong},
  journal={IEEE Access}, 
  title={VSA-CGAN: An Intelligent Generation Model for Deep Learning Sample Database Construction}, 
  year={2020},
  volume={8},
  number={},
  pages={137986-138003},
  abstract={In order to solve the problem of model accuracy reduction caused by the difficulty of obtaining specific training samples or the insufficient number of samples in the application of existing object detection and recognition model based on deep learning, this article proposes a conditional generative adversarial network model (VSA-CGAN), which integrates the self-attention mechanism of visual perception to optimize the inference of object attention feature maps, so as to learn the global information of the image and the detailed features of the object. It is designed to add conditional features in the generator and the discriminator, associate the specific dimensions of the data with the semantic features, and explicitly indicate the model to generate the corresponding object signature category information, so as to generate the feature representation of the image which is more suitable for the distribution of the original data. The model in this article has completed numerical experiments on several general standard data sets, and compared with several mainstream generative adversarial network models in image data augmentation performance. The experimental results show that the generation model in this article has excellent object simulation ability and strong application prospects.},
  keywords={Generative adversarial networks;Data models;Generators;Gallium nitride;Feature extraction;Numerical models;Machine learning;Generative adversarial network;attention mechanism;visual salience;object simulation;deep learning;data augmentation},
  doi={10.1109/ACCESS.2020.3012185},
  ISSN={2169-3536},
  month={},}@ARTICLE{10107487,
  author={Yin, Xiaolin and Wu, Shaowu and Wang, Ke and Lu, Wei and Zhou, Yicong and Huang, Jiwu},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Anti-Rounding Image Steganography With Separable Fine-Tuned Network}, 
  year={2023},
  volume={33},
  number={11},
  pages={7066-7079},
  abstract={Image steganographic methods based on encoder-decoder model with end-to-end network architecture recently have been proposed. However, in steganographic applications, the feature map (called stego matrix) generated by the encoder needs to be rounded as a real stego image for the receiver. The loss of precision by rounding stego matrix leads to the decline in the accuracy of extracted secret messages. The challenge of using end-to-end network to preserve robustness against rounding operation is that it is non-differentiable. In this paper, we propose an anti-rounding image steganography method with separable fine-tuning network architecture which includes the joint training stage (JT-stage) and the separable fine-tuning stage (SF-stage). Firstly, in JT-stage, an embedded generator and a stego matrix extractor are jointly learned without rounding operation. Utilizing concatenation in embedded generator can realistically fuse cover image and secret messages. And the multi-scale fusion block and residual dense block in stego matrix extractor can make secret messages more correctly decoded. Moreover, the discriminator is constructed by generative adversarial nets (GAN) in JT-stage to effectively improve the authenticity and steganalysis security. Then, in SF-stage, the embedded generator is frozen, and the stego matrix is obtained and rounded as a stego image. A stego image extractor is constructed by fine-tuning the layers of the stego matrix extractor to improve the accuracy of message extraction. As the loss will not backpropagate in the embedded generator, the non-differentiability of rounding operation can be offset. Experiments show that the proposed separation fine-tuning network is robust to rounding operation, and effectively reduces the degradation of the image quality and steganalysis performance.},
  keywords={Steganography;Generators;Training;Feature extraction;Decoding;Generative adversarial networks;Data mining;Image steganography;anti-rounding;separable fine-tuned network;precision loss},
  doi={10.1109/TCSVT.2023.3269468},
  ISSN={1558-2205},
  month={Nov},}@BOOK{10769215,
  author={Meyer, Lucas A.},
  booktitle={Building AI Applications with Microsoft Semantic Kernel: Easily integrate generative AI capabilities and copilot experiences into your applications},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Unlock the power of GenAI by effortlessly linking your C# and Python apps with cutting-edge models, orchestrating diverse AI services with finesse, and crafting bespoke applications through immersive, real-world examplesKey FeaturesLink your C# and Python applications with the latest AI models from OpenAICombine and orchestrate different AI services such as text and image generatorsCreate your own AI apps with real-world use case examples that show you how to use basic generative AI, create images, process documents, use a vector databasePurchase of the print or Kindle book includes a free PDF eBookBook DescriptionIn the fast-paced world of AI, developers are constantly seeking efficient ways to integrate AI capabilities into their apps. Microsoft Semantic Kernel simplifies this process by using the GenAI features from Microsoft and OpenAI. Written by Lucas A. Meyer, a Principal Research Scientist in Microsoft’s AI for Good Lab, this book helps you get hands on with Semantic Kernel. It begins by introducing you to different generative AI services such as GPT-3.5 and GPT-4, demonstrating their integration with Semantic Kernel. You’ll then learn to craft prompt templates for reuse across various AI services and variables. Next, you’ll learn how to add functionality to Semantic Kernel by creating your own plugins. The second part of the book shows you how to combine multiple plugins to execute complex actions, and how to let Semantic Kernel use its own AI to solve complex problems by calling plugins, including the ones made by you. The book concludes by teaching you how to use vector databases to expand the memory of your AI services and how to help AI remember the context of earlier requests. You’ll also be guided through several real-world examples of applications, such as RAG and custom GPT agents. By the end of this book, you'll have gained the knowledge you need to start using Semantic Kernel to add AI capabilities to your applications.What you will learnWrite reusable AI prompts and connect to different AI providersCreate new plugins that extend the capabilities of AI servicesUnderstand how to combine multiple plugins to execute complex actionsOrchestrate multiple AI services to accomplish a taskLeverage the powerful planner to automatically create appropriate AI callsUse vector databases as additional memory for your AI tasksDeploy your application to ChatGPT, making it available to hundreds of millions of usersWho this book is forThis book is for beginner-level to experienced .NET or Python software developers who want to quickly incorporate the latest AI technologies into their applications, without having to learn the details of every new AI service. Product managers with some development experience will find this book helpful while creating proof-of-concept applications. This book requires working knowledge of programming basics.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835469590},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10769215},}@BOOK{10410239,
  author={Barrett, Clark and Boyd, Brad and Bursztein, Elie and Carlini, Nicholas and Chen, Brad and Choi, Jihye and Roy Chowdhury, Amrita and Christodorescu, Mihai and Datta, Anupam and Feizi, Soheil and Fisher, Kathleen and Hashimoto, Tatsunori and Hendrycks, Dan and Jha, Somesh and Kang, Daniel and Kerschbaum, Florian and Mitchell, Eric and Mitchell, John and Ramzan, Zulfikar and Shams, Khawaja and Song, Dawn and Taly, Ankur and Yang, Diyi},
  booktitle={Identifying and Mitigating the Security Risks of Generative AI},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Every major technical invention resurfaces the dual-use dilemma — the new technology has the potential to be used for good as well as for harm. Generative AI (GenAI) techniques, such as large language models (LLMs) and diffusion models, have shown remarkable capabilities (e.g., in-context learning, code-completion, and text-to-image generation and editing). However, GenAI can be used just as well by attackers to generate new attacks and increase the velocity and efficacy of existing attacks. This monograph reports the findings of a workshop held at Google (co-organized by Stanford University and the University of Wisconsin-Madison) on the dual-use dilemma posed by GenAI. This work is not meant to be comprehensive, but is rather an attempt to synthesize some of the interesting findings from the workshop. Short-term and long-term goals for the community on this topic are discussed. This work should provide both a launching point for a discussion on this important topic, as well as interesting problems that the research community can work to address.},
  keywords={Privacy and Security},
  doi={},
  ISSN={},
  publisher={now},
  isbn={9781638283133},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10410239},}@INPROCEEDINGS{9670760,
  author={Xu, Juan and Li, Kang},
  booktitle={2021 International Conference on Sensing, Measurement & Data Analytics in the era of Artificial Intelligence (ICSMD)}, 
  title={Generative Zero-shot Learning Compound Fault Diagnosis of Bearings}, 
  year={2021},
  volume={},
  number={},
  pages={1-7},
  abstract={Diagnosis of compound faults remains a challenge during fault diagnosis of bearings, owing to the different fault parameters coupling, fault characteristics diversity, and the exponential increasement of the number of possible failure modes. Current compound faults diagnostic methods, which are usually based on supervised or semi-supervised learning, require sufficient labeled or unlabeled training data for each compound faults. In industrial scenarios, neither labeled nor unlabeled training data of compound faults are usually difficult to collect and sometimes even inaccessible, whereas single faults samples are easy to obtain. Based on these issues, we construct a novel generative zero-shot learning (ZSL) compound faults diagnosis model identifies unseen compound faults using only single faults samples as training set. This model comprises several modules, namely semantic vector definition, feature extractor, generative adversarial modules. Firstly, we devise a unified semantic vector definition method for expressing single and compound faults based on theoretical correlation of characteristics between single fault and compound faults vibration data. Secondly, a CNN-based feature extractor is designed for extraction the fault features from the time-frequency domain of vibration data. Thirdly, a generative adversarial module performs adversarial training of semantic vectors and fault features of single faults to learn the mapping relationship between the fault features and the fault semantic vectors. Once trained, the generator is able to generate compound fault features using the compound fault semantic vectors, rather than any compound fault samples. Finally, the K-nearest neighbor method is adopted to identify the unseen compound faults by measuring the distance between the extracted feature from the testing compound fault samples and the generated features. The effectiveness of the proposed method is verified on a self-built bearing test stand. The results show that in the absence of compound fault samples, the accuracy of compound fault classification reaches 78.10%.},
  keywords={Fault diagnosis;Vibrations;Training;Time-frequency analysis;Semantics;Training data;Feature extraction;Generative Zero-shot Learning;Semantic Vector;Generative Adversarial Networks;Compound Fault Diagnosis},
  doi={10.1109/ICSMD53520.2021.9670760},
  ISSN={},
  month={Oct},}
