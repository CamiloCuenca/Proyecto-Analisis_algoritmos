@INPROCEEDINGS{11012270,
  author={S, Arun Kumar and S, Sasikala and T, Dhanusha and R, Jamunadevi and B, Aruneshwer and M, Rosan Karthik R},
  booktitle={2025 3rd International Conference on Advancements in Electrical, Electronics, Communication, Computing and Automation (ICAECA)}, 
  title={Explainable AI based Improved Intrusion Detection System in Wireless Sensor Networks}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={To protect computer networks from unauthorized access by users, including insiders, the intrusion detection system (IDS) is used. It monitors network traffic to detect malicious activity and sends alerts immediately when observed. The various challenges posed by the wireless sensor network (WSN) environment require the development of machine learning-based IDS. Adaptive WSN data analysis and anomaly detection are possible with Machine Learning (ML) based IDS. This paper aims to improve the security and reliability of WSN using ML. WSN will generate high-dimensional data due to the increase in user base and network size. In this project, two datasets; WSN DS and KDD CUP 99 are used to detect and classify attacks using different ML algorithms. Furthermore, to improve the interpretability of attack classification, the proposed method also tests explainable AI (XAI) algorithms; LIME (local interpretation that can be interpreted independently of the model) and SHAP (SHapley supplementary interpretation).},
  keywords={Wireless sensor networks;Time division multiple access;Accuracy;Explainable AI;Intrusion detection;Telecommunication traffic;Classification algorithms;Telecommunication computing;Security;Testing;wireless sensor network;machine learning;intrusion detection;accuracy;explainable AI},
  doi={10.1109/ICAECA63854.2025.11012270},
  ISSN={},
  month={April},}@INPROCEEDINGS{10870562,
  author={Yan, Anrong},
  booktitle={2024 IEEE International Conference on Power System Technology (PowerCon)}, 
  title={Analysis of Digital Twin Implementation Technologies for Power Distribution Systems}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Digital twin technology has emerged as a cutting-edge solution, providing virtual representations of physical systems that enable real-time monitoring, analysis, and control of distribution systems affected by uncertainty. However, issues such as data errors and limited real-time measurements pose observability problems, affecting the accuracy and performance of digital twin models in distribution systems. This paper offers a comprehensive analysis of the current research landscape and outlines the key technical requirements for implementing digital twins in distribution systems. The focus is on both data and model aspects, including data imputation and augmentation, topology and line parameter identification, intelligent state estimation methods, and digital twin model construction methods. Future research is encouraged to deepen the understanding of these requirements and develop high-performance digital twins capable of addressing various application scenarios in power distribution systems.},
  keywords={Technical requirements;Parameter estimation;Uncertainty;Power distribution;Data models;Real-time systems;Imputation;Digital twins;Topology;State estimation;power distribution systems;data imputation and augmentation;topology and line parameter identification;intelligent state estimation;digital twin model construction},
  doi={10.1109/PowerCon60995.2024.10870562},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11102826,
  author={Tian, Yanlong and Deng, Zhongxiang and Wang, Nuoran and Zhang, Zhong and Guo, Peng},
  booktitle={2025 11th International Symposium on Sensors, Mechatronics and Automation System (ISSMAS)}, 
  title={Evaluation on Large Language Models for Pedestrian Trajectory Prediction}, 
  year={2025},
  volume={},
  number={},
  pages={264-267},
  abstract={Pedestrian trajectory prediction has significant application value in modern transportation and can improve traffic safety and management efficiency. Recently, large language models (LLMs) have demonstrated impressive capabilities in various fields, raising questions about their potential in trajectory prediction tasks. In this paper, we evaluate the performance of different LLMs architectures in pedestrian trajectory prediction and compare them with traditional methods. Our experiments on the benchmark dataset have revealed the advantages and limitations of LLMs in capturing pedestrian movement patterns and social interactions. The evaluation results indicate that LLMs possess promising capabilities in understanding contextual information.},
  keywords={Pedestrians;Large language models;Transportation;Benchmark testing;Predictive models;Sensor systems;Real-time systems;Trajectory;Sensors;Safety;Pedestrian Trajectory Prediction;Large Language Models;Performance Evaluation},
  doi={10.1109/ISSMAS65783.2025.11102826},
  ISSN={},
  month={June},}@INPROCEEDINGS{10259854,
  author={Wang, Zi and Zhu, Wenqi and Song, Junyeob and Chen, Lu and Koksal, Okan and Agrawal, Amit},
  booktitle={2023 Conference on Lasers and Electro-Optics (CLEO)}, 
  title={Metagrating Design based on Reinforcement Learning}, 
  year={2023},
  volume={},
  number={},
  pages={1-2},
  abstract={We demonstrate an algorithm based on reinforcement learning to realize high efficiency multifunctional metagrating devices without the requirement of a training dataset.},
  keywords={Training;Reinforcement learning;Lasers and electrooptics;Electrooptical waveguides},
  doi={},
  ISSN={2160-8989},
  month={May},}@INPROCEEDINGS{11167306,
  author={Ramya, Pendli and Divya, Kundaram and Kurmala, Bhavya Sri and Poranki, Vaishnavi Maitreyi and Kiran, Medikonda Asha and Nagamani, P.},
  booktitle={2025 5th International Conference on Intelligent Technologies (CONIT)}, 
  title={EvadeSafe-XAI: A Robust Malware Defense System using Explainable AI}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Adopting machine learning (ML) techniques in malware detection has significantly improved the automated identification of malicious software. However, these systems remain susceptible to evasion attacks, where adversaries modify malware to bypass detection mechanisms. The EvadeSafe-XAI framework integrates adversarial training and robust optimization techniques to address this challenge, thereby enhancing detection accuracy and resilience. EvadeSafe-XAI employs deep learning-based malware and adversary detectors to effectively counter sophisticated attacks while maintaining high detection rates for benign and malicious files. This approach strengthens malware detection systems against adversarial threats, ensuring more reliable cybersecurity defenses.},
  keywords={Training;Support vector machines;Accuracy;Refining;Malware;Robustness;Real-time systems;Computer security;Random forests;Resilience;Adversarial malware detection;machine learning;cybersecurity;Support Vector Machines (SVM);Random Forest;deep learning;adversarial training;and evasion attacks},
  doi={10.1109/CONIT65521.2025.11167306},
  ISSN={},
  month={June},}@INPROCEEDINGS{10797106,
  author={He, Ming and Meng, Gege},
  booktitle={2024 First International Conference on Software, Systems and Information Technology (SSITCON)}, 
  title={Intelligent Auditing System Based on Deep Belief Network Density based Spatial Clustering of Applications}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In recent years, as the traditional manual audit systems disposed to errors and frequently focused on compliance, rather than risk valuation the need of advanced audit systems had increased. Additionally, increased complex financial transactions, advanced technologies and regulators requirements in sectors and industry firms have necessitated the developing intelligent audit systems. The existing methods for developing intelligent audit systems failed in providing valuable indicators for audit process. Therefore, this paper proposes Deep Belief Network (DBN) - Density Based Spatial Clustering of Applications with Noise (DBSCAN) for designing an intelligent audit system by detecting fraudulent firms. Initially, audit data dataset is taken which incorporated audit data information of various firms. The collected audit data is preprocessed by utilizing data cleaning and feature engineering, for obtaining efficient financial audit data. Then this financial audit data features are extracted by employed DBN method for revealing hidden patterns. The extracted relevant features are evaluated for detecting the fraudulent firms by utilizing DBSCAN data mining method. The proposed DBN-DBSCAN achieved better results which comprises accuracy (96.58%), Specificity (97.85%), Sensitivity (95.69%), and F1-score $\mathbf{(9 5. 2 0 \%)}$ when compared with existing Long Short-Term Memory (LSTM).},
  keywords={Accuracy;Sensitivity;Regulators;Optimization models;Noise;Feature extraction;Software systems;Cleaning;Data mining;Long short term memory;complex financial transactions;deep belief network;density based spatial clustering of applications with noise;financial fraudulent firms;intelligent audit systems},
  doi={10.1109/SSITCON62437.2024.10797106},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10986642,
  author={Sharma, Navya and Garg, Preeti},
  booktitle={2025 3rd International Conference on Disruptive Technologies (ICDT)}, 
  title={Multimodal Image Fusion for Enhanced Medical Diagnosis}, 
  year={2025},
  volume={},
  number={},
  pages={1108-1112},
  abstract={Nowadays, image fusion has developed a dynamic meadow in image processing, specifically in medical analysis. Multimodal Medical Image Fusion (MMIF) improves medical images by merging two or more images of diverse modalities, resulting in a vibrant, and instructive fused image. Deciding on the utmost operative MMIF technique is decisive for attaining greater image eminence. The study delivers an inclusive assessment of MMIF techniques, leading medical imaging modalities, fusion steps, and valuation methodologies. Fundamental modalities consist of Computed Tomography (CT), Positron Emission Tomography (PET) and Magnetic Resonance Imaging (MRI). MMIF techniques are classified into various transforms such as spatial domain, fuzzy logic, morphological approaches, and sparse representation methods. Furthermore, fusion may befall on pixel-level, feature-level, or decision-level fusion, through valuation alienated into subjective and objective data. The research, moreover, projects MMIF techniques, emphasizing their corresponding assets and flaws, as well as managerial specialists, concerning ideal imaging resolutions.},
  keywords={Deep learning;Magnetic resonance imaging;Computed tomography;Decision making;Transforms;Medical diagnosis;Positron emission tomography;Medical diagnostic imaging;Image fusion;Cost accounting;Image Fusion Levels;Imaging Modalities;Image Fusion Techniques;Deep learning},
  doi={10.1109/ICDT63985.2025.10986642},
  ISSN={},
  month={March},}@INPROCEEDINGS{10601756,
  author={Vikrama, G S and Sujatha, G},
  booktitle={2024 International Conference on Advances in Computing, Communication and Applied Informatics (ACCAI)}, 
  title={Creating Smart Security Along With AI for Cloud-Based Internet of Land Transport}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The Internet of Things is profitable to take a important influence on the transportation sector. Autonomous vehicles, also known as AVs, are being developed with the goal of making everyday tasks easier, such as carrying packages, reducing congestion, and transporting goods. The term “autonomous vehicles” (AVs) refers not only to vehicles that operate on land but also to those that operate in the air and on the water, and these vehicles have a wide variety of uses.. In order to solve this issue, we are working on implementing a Cyber Security created information transfer to automated vehicles. Here, a cloud serves as a mediator, transferring correspondent files to autonomous vehicles. To ensure the highest level of data protection, we employ a CS-based algorithm that is compliant with Advanced Encryption Standard. This algorithm transforms the transferred data into cypher text. In order to decrypt the cypher text, it is necessary to have the caller’s private key for the specific $A V$ being used.},
  keywords={Cloud computing;Ciphers;Transportation;Transforms;Turning;Encryption;Computer crime;Cyber Security;Cipher text;AES;IoT;Cloud AV},
  doi={10.1109/ACCAI61061.2024.10601756},
  ISSN={},
  month={May},}@INPROCEEDINGS{10853007,
  author={Zheng, Zheran and Yuan, Yao and Huang, Kejie and La, Yuan and Wang, Zengchao and Zhao, Linjie},
  booktitle={20th International Conference on AC and DC Power Transmission 2024 (ACDC 2024)}, 
  title={An insulation evaluation method of transformer OIP bushings based on WGAN under unbalanced samples}, 
  year={2024},
  volume={2024},
  number={},
  pages={781-785},
  abstract={Aiming at the problems of poor classification and difficult diagnosis of multi-source information caused by the imbalance between normal and abnormal samples, a method of fault data expansion based on WGAN was proposed. To solve the problem of unbalanced amount of 275 OIP bushings produced from 1990 to 2017 in the southern region of China, WGAN was used to effectively expand the fault data to balance the data set. SVM was used to classify and train the data to test the effect of data expansion. When the fault state casing data is expanded to 125 groups, the classification effect is the best. SVM has a classification accuracy of 91.5% for the expanded data set, which is 22.39% higher than that without expansion. By sample expansion, the problem of low evaluation accuracy of fault casing caused by sample imbalance is effectively solved, which has broad engineering application prospects.},
  keywords={},
  doi={10.1049/icp.2024.2375},
  ISSN={},
  month={July},}@INBOOK{10789073,
  author={Joshi, Yash and Mishra, Sachit and Ponmagal, R. S.},
  booktitle={Internet of Things and Machine Learning in Agriculture: Technological Impacts and Challenges}, 
  title={17 Using deep learning for image-based plant disease detection}, 
  year={2021},
  volume={},
  number={},
  pages={355-368},
  abstract={Crop ailments pose a great threat to us. Crops are a major source of nutrition in the world. It is usually very hard to identify and analyze ailments in a crop through the naked eye. In this chapter, we discuss how different deep learning and machine learning techniques can be used to identify and analyze crop aliments with high accuracy.},
  keywords={Deep learning;Plant diseases;Crops;Computational modeling;Accuracy;Image segmentation;Image edge detection;Image classification;Computers;Visualization},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9783110691283},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10789073},}@INPROCEEDINGS{10908041,
  author={Liu, Hong and Cheng, Manman},
  booktitle={2024 International Symposium on Digital Home (ISDH)}, 
  title={Image Distinction- Image Pressure: A New Mode of Image Dissemination}, 
  year={2024},
  volume={},
  number={},
  pages={115-120},
  abstract={This article proposes a new model for image recognition and dissemination: Image Distinction-Image Pressure. Images are in two states during the dissemination process: one is an image that has already been recognized and remembered by people in the brain—Memory Image, and the other is a new image that has not been recognized temporarily-Ontology Image. There is a natural gap between these two images, called image distinction. With image distinction, there is also image pressure. This kind of image pressure drives the dissemination of images, generating image entropy, which may lead to the generation of positive, negative, or Extraordinary image pressures, promoting the completion of image representation purposes. The dissemination mode of Image Distinction-Image Pressure compensates for some structural defects in current image recognition and dissemination, such as difficulties in image recognition caused by occlusion, deformation, etc., and promotes research on image dissemination.},
  keywords={Image recognition;Deformation;Image representation;Drives;Brain modeling;Entropy;Image Distinction;Image Pressure;Image Entropy;Image Representation;Image Recognition;Image Dissemination},
  doi={10.1109/ISDH64927.2024.00026},
  ISSN={2769-8823},
  month={Nov},}@INBOOK{10834128,
  author={},
  booktitle={AI in Disease Detection: Advancements and Applications}, 
  title={Index}, 
  year={2025},
  volume={},
  number={},
  pages={361-374},
  abstract={},
  keywords={},
  doi={10.1002/9781394278695.index},
  ISSN={},
  publisher={IEEE},
  isbn={9781394278688},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10834128},}@INPROCEEDINGS{10486235,
  author={Surekha, M and Sagar, Anil Kumar and Khemchandani, Vineeta},
  booktitle={2024 IEEE International Conference on Computing, Power and Communication Technologies (IC2PCT)}, 
  title={Adversarial Attack and Defense Mechanisms in Medical Imaging: A Comprehensive Review}, 
  year={2024},
  volume={5},
  number={},
  pages={1657-1661},
  abstract={Medical imaging is essential in modern healthcare, allowing for accurate diagnoses and treatment planning. The practice of machine learning algorithms into clinical imaging uses has significantly enhanced diagnostic abilities. In contrast, as technology has forward-looking, new problems have emerged, main among them existence adversarial assaults. This complete research study investigates the background information of adversarial attacks and its rising defense measures on medical image model. Adversarial assaults involve intelligent alterations of input data to change machine learning algorithms, possibly important to misdiagnosis or inaccurate clinical diagnosis. This paper thoroughly analyses many adversarial assault practices precisely tailored for medical imaging based on division, classification and rebuilding of clinical image with different defensive tactic. Also, the research study provides the better path for collect rising counter measures on adversarial attacks posed by threats. These protective measures contain different types of proposals. For example, adversarial practices, input pre-processing and algorithm understandable strategies.},
  keywords={Threat modeling;Machine learning algorithms;Reviews;Computer architecture;Switches;Reliability engineering;Robustness;Adversarial attack;adversarial defense;medical image analysis;taxonomy;evaluation},
  doi={10.1109/IC2PCT60090.2024.10486235},
  ISSN={},
  month={Feb},}@INBOOK{11164838,
  author={Tabatabaian, Mehrzad},
  booktitle={Prompt Engineering Using ChatGPT: Crafting Effective Interactions and Building GPT Apps}, 
  title={Chapter 11: GPTs and GPT Application Builder}, 
  year={2024},
  volume={},
  number={},
  pages={67-94},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9781501518959},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11164838},}@INPROCEEDINGS{10155024,
  author={Bera, Shagun and Khandeparkar, Kedar},
  booktitle={2023 IEEE International Symposium on Ethics in Engineering, Science, and Technology (ETHICS)}, 
  title={AI Based Real-Time Privacy-Aware Camera Data Processing in Autonomous Vehicles}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={The three V's, namely volume, velocity and variety of sensor data are ubiquitous for decision-making in autonomous self-driving vehicles. The sensor data contain information about living and non-living entities in the neighbourhood of the moving vehicle. While identifying these objects are essential, details such as human faces, vehicle number plates, building names, etc., are not necessary for decision-making. Thus, we consider the following issues related to data collection, 1) the problem of data privacy, and 2) the problem of misuse of data by an adversary having unauthorized access. This paper proposes a method that first locates private objects (non-essential for decision-making) from frames captured by cameras installed on self-driving cars and then augments it with noise and blurring effects to make them unrecognizable. The performance results show that a combination of blurring and noise can hide private data while retaining information essential for the car to drive. Also, as the proposed approach processes within the limits of the interframe capture time, it is feasible for use in real-time. Moreover, results show that the proposed method can defend the adversarial attacks for the reconstruction of image frames from a given augmented frame.},
  keywords={Ethics;Data privacy;Privacy;Decision making;Cameras;Real-time systems;Object recognition;Privacy Protection;Autonomous Vehicles;Computer Vision;Semantic Segmentation},
  doi={10.1109/ETHICS57328.2023.10155024},
  ISSN={},
  month={May},}@INPROCEEDINGS{8058548,
  author={Jackson, Ethan C. and Hughes, James Alexander and Daley, Mark and Winter, Michael},
  booktitle={2017 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)}, 
  title={An algebraic generalization for graph and tensor-based neural networks}, 
  year={2017},
  volume={},
  number={},
  pages={1-8},
  abstract={Despite significant effort, there is currently no formal or de facto standard framework or format for constructing, representing, or manipulating general neural networks. In computational neuroscience, there have been some attempts to formalize connectionist notations and generative operations for neural networks, including Connection Set Algebra, but none are truly formal or general. In computational intelligence (CI), though the use of linear algebra and tensor-based models are widespread, graph-based frameworks are also popular and there is a lack of tools supporting the transfer of information between systems. To address these gaps, we exploited existing results about the connection between linear and relation algebras to define a concise, formal algebraic framework that generalizes graph and tensor-based neural networks. For simplicity and compatibility, this framework is purposefully defined as a minimal extension to linear algebra. We demonstrate the merits of this approach first by defining new operations for network composition along with proofs of their most important properties. An implementation of the algebraic framework is presented and applied to create an instance of an artificial neural network that is compatible with both graph and tensor based CI frameworks. The result is an algebraic framework for neural networks that generalizes the formats used in at least two systems, together with an example implementation.},
  keywords={Biological neural networks;Linear algebra;Finite element analysis;Tools;Computer science;Computational modeling;Neural Networks;Algebraic Methods;Connectomics},
  doi={10.1109/CIBCB.2017.8058548},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9201866,
  author={},
  booktitle={2020 15th International Conference on Computer Science & Education (ICCSE)}, 
  title={Book of Abstracts}, 
  year={2020},
  volume={},
  number={},
  pages={35-65},
  abstract={Presents abstracts for the articles comprising the conference proceedings.},
  keywords={},
  doi={10.1109/ICCSE49874.2020.9201866},
  ISSN={2473-9464},
  month={Aug},}@INBOOK{8858409,
  author={Miller, Arthur I.},
  booktitle={The Artist in the Machine: The World of AI-Powered Creativity}, 
  title={Index}, 
  year={2019},
  volume={},
  number={},
  pages={369-399},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={MIT Press},
  isbn={9780262354592},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/8858409},}@ARTICLE{11124492,
  author={Capparella, Valerio and Nerio Nemmi, Eugenio and Violino, Simona and Costa, Corrado and Figorilli, Simone and Moscovini, Lavinia and Pallottino, Federico and Pane, Catello and Mei, Alessandro and Ortenzi, Luciano},
  journal={IEEE Access}, 
  title={VIE-Net: Regressive U-Net for Vegetation Index Estimation}, 
  year={2025},
  volume={13},
  number={},
  pages={144650-144661},
  abstract={Vegetation indexes (VIs) are important indicators in agriculture, revealing valuable information about the vegetative status of crops through nondestructive evaluation methods. Among these indexes, the Normalized Difference Vegetation Index (NDVI) is a key metric used for assessing plant cover and health by combining Near-Infrared (NIR) and Red reflectance. NDVI calculation is based on multispectral cameras equipped with NIR sensors. However, the presence of this sensor is what makes the device costly and therefore impractical for small-scale farms. To address this limitation, recent works have explored the use of artificial intelligence to build AI-powered RGB cameras as a more affordable alternative for NDVI estimation. This has been done by means of generative artificial intelligence (often prone to hallucinations) or via shallow neural networks (pixel-wise regression) with the drawback of a high computational cost. Here, we introduce an end-to-end non-generative approach for NDVI estimation from calibrated RGB images. The proposed model, called VIE-Net, is a convolutional neural network based on a regressive version of the U-Net architecture. The model is tested on two datasets with images captured at 25 m above ground level (remote sensing) and 1 meter from the subject (proximal sensing), achieving correlation performance up to  $r^{2} = 0.98$  when non-vegetative background is removed. A lightweight version of the model was also tested, achieving  $r^{2} = 0.84$ . This approach not only provides a cost-effective solution for NDVI estimation but also improves the reliability of vegetation health assessment using standard RGB images.},
  keywords={Normalized difference vegetation index;Sensors;Cameras;Vegetation mapping;Indexes;Accuracy;Agriculture;Training;Neural networks;Meters;AI-powered sensors;end-to-end approach;machine learning application;open source;regressive convolutional neural network;remote and proximal sensing;RGB sensor},
  doi={10.1109/ACCESS.2025.3598124},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11050682,
  author={Peci, Fatos and Hamiti, Enver and Khan, Ishtiaq},
  booktitle={2025 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Agentic AI with Chatops for Large Scale Network Operations}, 
  year={2025},
  volume={},
  number={},
  pages={1617-1626},
  abstract={Operating large-scale networks necessitates interaction with numerous tools and dashboards for troubleshooting and analysis. Given the sensitivity of network services, minimizing manual interaction time is crucial for improving Mean Time To Repair (MTTR) and ensuring service availability. Recent developments in generative AI enable the transformation of interactions with diverse APIs and dashboards into intent-driven operations. Agentic AI offers capabilities to translate user intent into automated processes, thereby reducing the time engineers spend interacting with various interfaces and dashboards. This paper presents a novel approach for operating large-scale network infrastructure, wherein AI agents execute tasks involving API and dashboard interactions based on natural language commands. We evaluated the impact of this approach within a major global network environment. Our findings demonstrate significant time savings, consequently improving MTTR and overall service availability in this large-scale network.},
  keywords={Translation;Sensitivity;Generative AI;Large language models;Manuals;Maintenance engineering;Natural language processing;Encoding;History;Service level agreements;service level agreements;mean time to repair;natural language processing;large language models;chatops},
  doi={10.1109/CAI64502.2025.00242},
  ISSN={},
  month={May},}@ARTICLE{9199819,
  author={Sakib, Sadman and Tazrin, Tahrat and Fouda, Mostafa M. and Fadlullah, Zubair Md. and Guizani, Mohsen},
  journal={IEEE Access}, 
  title={DL-CRC: Deep Learning-Based Chest Radiograph Classification for COVID-19 Detection: A Novel Approach}, 
  year={2020},
  volume={8},
  number={},
  pages={171575-171589},
  abstract={With the exponentially growing COVID-19 (coronavirus disease 2019) pandemic, clinicians continue to seek accurate and rapid diagnosis methods in addition to virus and antibody testing modalities. Because radiographs such as X-rays and computed tomography (CT) scans are cost-effective and widely available at public health facilities, hospital emergency rooms (ERs), and even at rural clinics, they could be used for rapid detection of possible COVID-19-induced lung infections. Therefore, toward automating the COVID-19 detection, in this paper, we propose a viable and efficient deep learning-based chest radiograph classification (DL-CRC) framework to distinguish the COVID-19 cases with high accuracy from other abnormal (e.g., pneumonia) and normal cases. A unique dataset is prepared from four publicly available sources containing the posteroanterior (PA) chest view of X-ray data for COVID-19, pneumonia, and normal cases. Our proposed DL-CRC framework leverages a data augmentation of radiograph images (DARI) algorithm for the COVID-19 data by adaptively employing the generative adversarial network (GAN) and generic data augmentation methods to generate synthetic COVID-19 infected chest X-ray images to train a robust model. The training data consisting of actual and synthetic chest X-ray images are fed into our customized convolutional neural network (CNN) model in DL-CRC, which achieves COVID-19 detection accuracy of 93.94% compared to 54.55% for the scenario without data augmentation (i.e., when only a few actual COVID-19 chest X-ray image samples are available in the original dataset). Furthermore, we justify our customized CNN model by extensively comparing it with widely adopted CNN architectures in the literature, namely ResNet, Inception-ResNet v2, and DenseNet that represent depth-based, multi-path-based, and hybrid CNN paradigms. The encouragingly high classification accuracy of our proposal implies that it can efficiently automate COVID-19 detection from radiograph images to provide a fast and reliable evidence of COVID-19 infection in the lung that can complement existing COVID-19 diagnostics modalities.},
  keywords={Radiography;Lung;X-rays;Diseases;Computed tomography;Data models;Hospitals;COVID-19;convolutional neural network (CNN);deep learning;generative adversarial network (GAN);pneumonia},
  doi={10.1109/ACCESS.2020.3025010},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11128597,
  author={Meng, Lingyi and Zheng, Enhao and Li, Xiong and Zhang, Zhong},
  booktitle={2025 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={SRL-Gym: A Morphology and Controller Co-Optimization Framework for Supernumerary Robotic Limbs in Load-Bearing Locomotion}, 
  year={2025},
  volume={},
  number={},
  pages={727-733},
  abstract={Supernumerary Robotic Limbs (SRLs) can assist human motions by providing extra degrees of freedom (DoFs) and body support. The extra DoFs lead to larger design space in structure and control policies, which is complex and time-consuming with the traditional manual design process. In this pilot study, we proposed a novel morphology-controller co-optimization framework to automatically generate and optimize the SRL structure based on the locomotion task input. There are two layers, with the inner layer optimizing the controller to achieve human-robot synchronization, and the outer layer optimizing the morphology parameters for performance enhancement. We validated the proposed framework through simulations using SRLs in a load-bearing locomotion task. The results demonstrate that the controller optimization can automatically generate realistic gait patterns and stable human-robot synchronization, while the SRLs significantly improve the user's load-bearing capability. Additionally, the co-optimization process reduces both the manufacturing cost of the SRL and the torque on the joints. This approach shows potential for exhaustive exploration of the design space and acceleration of the design process. Future works will be done in a more realistic SRL generative design model and achieve Sim2Real for practical uses.},
  keywords={Limbs;Torque;Biological system modeling;Computational modeling;Morphology;Aerospace electronics;Synchronization;Robots;Optimization;Load modeling},
  doi={10.1109/ICRA55743.2025.11128597},
  ISSN={},
  month={May},}@INPROCEEDINGS{11093086,
  author={Wang, Yinuo and Fan, Yanbo and Wang, Xuan and Yu, Guo and Wang, Fei},
  booktitle={2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Diffusion-based Realistic Listening Head Generation via Hybrid Motion Modeling}, 
  year={2025},
  volume={},
  number={},
  pages={15885-15895},
  abstract={Listening head generation aims to synthesize non-verbal responsive listening head videos that naturally react to a certain speaker, for which, both realistic head movements, expressive facial expressions, and high visual qualities are expected. Previous approaches typically follow a two-stage pipeline that first generates intermediate 3D motion signals such as 3DMM coefficients, and then synthesizes the videos by deterministic rendering, suffering from limited motion expressiveness and low visual quality (e.g. 256×256). In this work, we propose a novel listening head generation method that harnesses the generative capabilities of the diffusion model for both motion generation and high-quality rendering. Crucially, we propose an effective hybrid motion modeling module that addresses training difficulties caused by the scarcity of listening head data while preserving the intricate details that may be lost in explicit motion representations. We further develop a tailored control guidance for head pose and facial expression, by integrating their intrinsic motion characteristics. Our method enables high-fidelity video generation with 512 × 512 resolution and delivers vivid listener motion feedback. We conduct comprehensive experiments and obtain superior performance in terms of both visual quality and motion expressiveness compared with existing methods.},
  keywords={Training;Visualization;Three-dimensional displays;Computational modeling;Refining;Pipelines;Process control;Rendering (computer graphics);Hybrid power systems;Videos;listening head generation;diffusion model;video synthesis},
  doi={10.1109/CVPR52734.2025.01481},
  ISSN={2575-7075},
  month={June},}@ARTICLE{9782579,
  author={Zheng, Wenbo and Yan, Lan and Gou, Chao and Wang, Fei-Yue},
  journal={IEEE Transactions on Fuzzy Systems}, 
  title={Fuzzy Deep Forest With Deep Contours Feature for Leaf Cultivar Classification}, 
  year={2022},
  volume={30},
  number={12},
  pages={5431-5444},
  abstract={Deep learning is a compelling technique for feature extraction due to its adaptive capacity of processing and providing deeper image information. However, for the task of leaf cultivar classification, the deep learning-based classifier model is unable to extract contour features of leaf images deeply due to the lack of large specialized datasets and expert knowledge annotations. Also, the scale/size of the current leaf cultivar dataset does not meet the needs of deep neural networks (DNNs). In particular, the high model complexity of DNNs implies that deep-learning-based neural networks seem to must require a large dataset to achieve good performance, but facing the fact that the leaf cultivar dataset often is small, even some classes in this kind of datasets contain less than ten images/examples. To overcome these problems and inspired by the resounding success of fuzzy logic, we propose a novel fuzzy ensemble model for leaf cultivar classification. To extract the contours of leaves, we first propose generative adversarial networks-based methods. Second, to improve the ability of feature representation, we present a data augmentation method to transform our contour features. Third, to get the essential features of leaves, we design a novel generation of the fuzzy random forest. Finally, to achieve accurate classification, we design a novel deep learning strategy, namely deep fuzzy representation learning, integrating and cascading a lot of our fuzzy random forests. Experimental results show that our model outperforms other existing state-of-the-arts on three real-world datasets, and performs much better than the original deep forest and DNN-based algorithms particularly.},
  keywords={Forestry;Random forests;Feature extraction;Deep learning;Neural networks;Task analysis;Representation learning;Contour feature learning;data augmentation;deep forest;fuzzy logic},
  doi={10.1109/TFUZZ.2022.3177764},
  ISSN={1941-0034},
  month={Dec},}@INPROCEEDINGS{11080552,
  author={Sahraoui, Rania and Bannour, Fetia and Houidi, Omar and Jouaber, Badii},
  booktitle={2025 IEEE 11th International Conference on Network Softwarization (NetSoft)}, 
  title={An Intelligent E2e Network Slicing Framework Using Transformer-Enhanced Drl}, 
  year={2025},
  volume={},
  number={},
  pages={7-12},
  abstract={The 5G/6G era has introduced a wide variety of services, including enhanced Mobile Broadband (eMBB), UltraReliable Low-Latency Communications (URLLC), and massive Machine-Type Communications (mMTC). Each service presents unique, highly diversified, and often conflicting requirements, driving the need for more flexible and intelligent solutions. In this context, Network Slicing (NS) has emerged as a prominent technology that allows multiple virtual networks to operate over a shared physical infrastructure, thereby accommodating these diverse service demands. Supported by technologies such as Software-Defined Networking (SDN) and Network Function Virtualization (NFV), network slicing requires the efficient placement of slices to optimize resource utilization and ensure Quality of Service (QoS). We propose a native artificial intelligence (AI) architecture for end-to-end (E2E) slicing that leverages Transformer-based Deep Reinforcement Learning (DRL) to enable zero-touch, automated slice placement in future networks, such as 5 G -and-beyond systems. Our system embeds AI directly into the network fabric, supporting native AI for real-time data processing and decision-making. Results show that integrating the Transformer model with DRL effectively addresses complex optimization challenges in network slicing, outperforming other state-of-the-art learning algorithms by better balancing slice acceptance ratio and energy efficiency. This supports the sustainable management of future networks, aligns with the vision of the Next Generation Mobile Networks (NGMN) Alliance, and illustrates the evolving role of AI in next-generation communication systems.},
  keywords={Network slicing;Quality of service;Transformers;Deep reinforcement learning;Fabrics;Energy efficiency;Network function virtualization;Resource management;Artificial intelligence;Next generation networking;End-to-end slicing;5G-and-beyond;Future networks;VNF-FG embedding;Deep reinforcement learning;Attention mechanisms;Generative models;Transformers;Energy efficiency;NGMN vision;Native AI;Zero-touch networks},
  doi={10.1109/NetSoft64993.2025.11080552},
  ISSN={2693-9789},
  month={June},}@ARTICLE{9729867,
  author={Atwany, Mohammad Z. and Sahyoun, Abdulwahab H. and Yaqub, Mohammad},
  journal={IEEE Access}, 
  title={Deep Learning Techniques for Diabetic Retinopathy Classification: A Survey}, 
  year={2022},
  volume={10},
  number={},
  pages={28642-28655},
  abstract={Diabetic Retinopathy (DR) is a degenerative disease that impacts the eyes and is a consequence of Diabetes mellitus, where high blood glucose levels induce lesions on the eye retina. Diabetic Retinopathy is regarded as the leading cause of blindness for diabetic patients, especially the working-age population in developing nations. Treatment involves sustaining the patient’s current grade of vision since the disease is irreversible. Early detection of Diabetic Retinopathy is crucial in order to sustain the patient’s vision effectively. The main issue involved with DR detection is that the manual diagnosis process is very time, money, and effort consuming and involves an ophthalmologist’s examination of eye retinal fundus images. The latter also proves to be more difficult, particularly in the early stages of the disease when disease features are less prominent in the images. Machine learning-based medical image analysis has proven competency in assessing retinal fundus images, and the utilization of deep learning algorithms has aided the early diagnosis of Diabetic Retinopathy (DR). This paper reviews and analyzes state-of-the-art deep learning methods in supervised, self-supervised, and Vision Transformer setups, proposing retinal fundus image classification and detection. For instance, referable, non-referable, and proliferative classifications of Diabetic Retinopathy are reviewed and summarized. Moreover, the paper discusses the available retinal fundus datasets for Diabetic Retinopathy that are used for tasks such as detection, classification, and segmentation. The paper also assesses research gaps in the area of DR detection/classification and addresses various challenges that need further study and investigation.},
  keywords={Diabetes;Retina;Retinopathy;Lesions;Deep learning;Diseases;Biomedical imaging;Diabetic retinopathy;diabetes mellitus;diabetic macular edema;lesion;microaneurysms;haemorrhages;exudates;classification;supervised learning;self-supervised learning;transformers},
  doi={10.1109/ACCESS.2022.3157632},
  ISSN={2169-3536},
  month={},}@ARTICLE{9449902,
  author={Hashmi, Khurram Azeem and Liwicki, Marcus and Stricker, Didier and Afzal, Muhammad Adnan and Afzal, Muhammad Ahtsham and Afzal, Muhammad Zeshan},
  journal={IEEE Access}, 
  title={Current Status and Performance Analysis of Table Recognition in Document Images With Deep Neural Networks}, 
  year={2021},
  volume={9},
  number={},
  pages={87663-87685},
  abstract={The first phase of table recognition is to detect the tabular area in a document. Subsequently, the tabular structures are recognized in the second phase in order to extract information from the respective cells. Table detection and structural recognition are pivotal problems in the domain of table understanding. However, table analysis is a perplexing task due to the colossal amount of diversity and asymmetry in tables. Therefore, it is an active area of research in document image analysis. Recent advances in the computing capabilities of graphical processing units have enabled the deep neural networks to outperform traditional state-of-the-art machine learning methods. Table understanding has substantially benefited from the recent breakthroughs in deep neural networks. However, there has not been a consolidated description of the deep learning methods for table detection and table structure recognition. This review paper provides a thorough analysis of the modern methodologies that utilize deep neural networks. Moreover, it presents a comprehensive understanding of the current state-of-the-art and related challenges of table understanding in document images. The leading datasets and their intricacies have been elaborated along with the quantitative results. Furthermore, a brief overview is given regarding the promising directions that can further improve table analysis in document images.},
  keywords={Image recognition;Deep learning;Neural networks;Task analysis;Feature extraction;Portable document format;Performance analysis;Deep neural network;document images;deep learning;performance evaluation;table recognition;table detection;table structure recognition;table analysis},
  doi={10.1109/ACCESS.2021.3087865},
  ISSN={2169-3536},
  month={},}@ARTICLE{10063864,
  author={Khan, Muhammad Murtaza and Ilyas, Muhammad U. and Khan, Ishtiaq Rasool and Alshomrani, Saleh M. and Rahardja, Susanto},
  journal={IEEE Access}, 
  title={License Plate Recognition Methods Employing Neural Networks}, 
  year={2023},
  volume={11},
  number={},
  pages={73613-73646},
  abstract={Advances in both parallel processing capabilities because of graphical processing units (GPUs) and computer vision algorithms have led to the development of deep neural networks (DNN) and their utilization in real-world applications. Starting from the LeNet-5 architecture of the 1990s, modern deep neural networks may have tens to hundreds of layers to solve complex problems such as license plate detection or recognition tasks. In this article, we present a review of the state-of-the-art methods related to automatic license plate recognition. Since deep networks have demonstrated a remarkable ability to outperform other machine learning techniques, we focus only on neural network based license plate recognition methods. We highlight the particular types of networks, i.e., convolutional, residual recurrent, or long-short-term-memory, used for the specific tasks of license plate detection, extraction, or recognition in different existing works. The presented summary also highlights some of the most widely used data sets for comparison and shares the results reported in the reviewed papers. We also give an overview of the effects of fog, motion, or the use of synthetic data on license plate recognition. Finally, promising directions for future research in this domain are presented.},
  keywords={License plate recognition;Neural networks;Character recognition;Deep learning;Image recognition;Task analysis;Feature extraction;License plate;detection;recognition;deep learning;neural networks},
  doi={10.1109/ACCESS.2023.3254365},
  ISSN={2169-3536},
  month={},}@ARTICLE{9262856,
  author={Xia, Hongbin and Li, Jing Jing and Liu, Yuan},
  journal={IEEE Access}, 
  title={Collaborative Filtering Recommendation Algorithm Based on Attention GRU and Adversarial Learning}, 
  year={2020},
  volume={8},
  number={},
  pages={208149-208157},
  abstract={Aiming at the problem that the traditional collaborative filtering algorithm using shallow models cannot learn the deep features of users and items, and the recommendation model is very susceptible to the counter-interference of its parameters; this paper proposes a matrix-factorization recommendation model that combines adversarial learning and attention-gated recurrent units (AGAMF). Firstly, the gated recurrent unit based on the attention mechanism is used to extract the user's latent vector from the user's auxiliary side information. Secondly, the convolutional neural network is used to extract the item's latent vector from the item's auxiliary side information. Finally, adversarial disturbances are introduced on the latent factors of users and items to quantify the loss of the model under parameter disturbances, and the latent vectors of users and items are integrated into the probability matrix factorization to predict the user's rating of the item. Experiments were performed on two real data sets MovieLens-1M and MovieLens-10M, and the RMSE, MAE and Recall indicators were used for evaluation. Experiments prove that the model proposed in this paper is robust and can effectively alleviate the problem of data sparsity. Compared with other related recommendation algorithms, our model has a significant improvement in recommendation performance.},
  keywords={Perturbation methods;Feature extraction;Logic gates;Convolutional neural networks;Robustness;Data mining;Context modeling;Adversarial learning;attention mechanism;gated recurrent unit;convolutional neural network;probabilistic matrix factorization;collaborative filtering},
  doi={10.1109/ACCESS.2020.3038770},
  ISSN={2169-3536},
  month={},}@ARTICLE{9443174,
  author={Cho, Hyeon and Kim, Taehoon and Chang, Hyung Jin and Hwang, Wonjun},
  journal={IEEE Access}, 
  title={Self-Supervised Visual Learning by Variable Playback Speeds Prediction of a Video}, 
  year={2021},
  volume={9},
  number={},
  pages={79562-79571},
  abstract={We propose a self-supervised visual learning method by predicting the variable playback speeds of a video. Without semantic labels, we learn the spatio-temporal visual representation of the video by leveraging the variations in the visual appearance according to different playback speeds under the assumption of temporal coherence. To learn the spatio-temporal visual variations in the entire video, we have not only predicted a single playback speed but also generated clips of various playback speeds and directions with randomized starting points. Hence the visual representation can be successfully learned from the meta information (playback speeds and directions) of the video. We also propose a new layer-dependable temporal group normalization method that can be applied to 3D convolutional networks to improve the representation learning performance where we divide the temporal features into several groups and normalize each one using the different corresponding parameters. We validate the effectiveness of our method by fine-tuning it to the action recognition and video retrieval tasks on UCF-101 and HMDB-51. All the source code is released in https://github.com/hyeon-jo/PSPNet.},
  keywords={Three-dimensional displays;Task analysis;Visualization;Feature extraction;Semantics;Coherence;Sorting;Action recognition;representation learning;self-supervised learning},
  doi={10.1109/ACCESS.2021.3084840},
  ISSN={2169-3536},
  month={},}@ARTICLE{8932479,
  author={Goienetxea, Izaro and Mendialdua, Iñigo and Rodríguez, Igor and Sierra, Basilio},
  journal={IEEE Access}, 
  title={Statistics-Based Music Generation Approach Considering Both Rhythm and Melody Coherence}, 
  year={2019},
  volume={7},
  number={},
  pages={183365-183382},
  abstract={This paper presents a music generation method which is an extension of a previously presented method that generates coherent melodies using a melodic coherence structure extracted from a template piece. This extension, which has been applied for generating bertso melodies, adds the generation of the rhythmic content of the melodies, for which a rhythmic coherence structure of the template piece is also created. To do so, a pattern discovery and ranking method is used to discover the rhythmically repeated segments that are interesting, and create a rhythmic coherence structure which can have several levels of nesting. Independent sampling processes have been developed for melodic and rhythmic content, using an adapted optimization method for sampling the rhythmic content of the new pieces. An evaluation process has been carried out to evaluate some of the generated pieces, considering on one hand how the listeners perceive them and on the other hand whether they share the features with bertso melodies. It has been concluded from this evaluation that the method is capable of generating good coherent bertso melodies.},
  keywords={Coherence;Rhythm;Machine learning;Grammar;Computational modeling;Knowledge based systems;Coherence;computer generated music;rhythm generation;statistical models},
  doi={10.1109/ACCESS.2019.2959696},
  ISSN={2169-3536},
  month={},}@ARTICLE{9841560,
  author={Zhu, Gang and Ding, Yuting and Zhao, Lin},
  journal={IEEE Access}, 
  title={A Document Image Generation Scheme Based on Face Swapping and Distortion Generation}, 
  year={2022},
  volume={10},
  number={},
  pages={78827-78837},
  abstract={Nowadays, digital images are widely used in various services. The emergence of more and more image editing algorithms has made image forensic approaches to be severely challenged. Driven by the emergence of forged images, more and more image forensic methods are proposed to evaluate the authenticity of digital images. However, in some privacy-related image forensics areas, the scarcity of data affects their development. In this paper, we investigate a document image generation scheme based on face swapping and distortion generation to generate document image databases at a low cost. First, we propose an IDNet for editing face content and text content in digital document images. Second, we propose a Distortion Simulation Network (DSNet) for simulating print-and-scan distortion, and the generated data can be used to study a novel document attack type called recapture attack. Third, we use the database generated by our proposed method to assist in training document image recapture forensic networks. A qualitative comparison with existing methods illustrates that the image content generated by our proposed method maintains more complete semantic information and higher image quality. Quantitative results have confirmed that with the addition of the generated database, the performance of the model improves by about 8% measured in AUC.},
  keywords={Faces;Distortion;Image synthesis;Semantics;Digital images;Databases;Task analysis;Document image forensics;document image generation;distortion generation;face swapping},
  doi={10.1109/ACCESS.2022.3194117},
  ISSN={2169-3536},
  month={},}@ARTICLE{10136716,
  author={Wang, Yanan and Zeng, Donghuo and Wada, Shinya and Kurihara, Satoshi},
  journal={IEEE Access}, 
  title={VideoAdviser: Video Knowledge Distillation for Multimodal Transfer Learning}, 
  year={2023},
  volume={11},
  number={},
  pages={51229-51240},
  abstract={Multimodal transfer learning aims to transform pretrained representations of diverse modalities into a common domain space for effective multimodal fusion. However, conventional systems are typically built on the assumption that all modalities exist, and the lack of modalities always leads to poor inference performance. Furthermore, extracting pretrained embeddings for all modalities is computationally inefficient for inference. In this work, to achieve high efficiency-performance multimodal transfer learning, we propose VideoAdviser, a video knowledge distillation method to transfer multimodal knowledge of video-enhanced prompts from a multimodal fundamental model (teacher) to a specific modal fundamental model (student). With an intuition that the best learning performance comes with professional advisers and smart students, we use a CLIP-based teacher model to provide expressive multimodal knowledge supervision signals to a RoBERTa-based student model via optimizing a step-distillation objective loss—first step: the teacher distills multimodal knowledge of video-enhanced prompts from classification logits to a regression logit—second step: the multimodal knowledge is distilled from the regression logit of the teacher to the student. We evaluate our method in two challenging multimodal tasks: video-level sentiment analysis (MOSI and MOSEI datasets) and audio-visual retrieval (VEGAS dataset). The student (requiring only the text modality as input) achieves an MAE score improvement of up to 12.3% for MOSI and MOSEI. Our method further enhances the state-of-the-art method by 3.4% mAP score for VEGAS without additional computations for inference. These results suggest the strengths of our method for achieving high efficiency-performance multimodal transfer learning.},
  keywords={Data models;Task analysis;Visualization;Transfer learning;Analytical models;Computational modeling;Sentiment analysis;Multimodal transfer learning;knowledge distillation;fundamental model},
  doi={10.1109/ACCESS.2023.3280187},
  ISSN={2169-3536},
  month={},}@ARTICLE{10510282,
  author={Yang, Jing and Gao, Hu and Dang, Depeng},
  journal={IEEE Access}, 
  title={Graph Convolutional Networks With Syntactic and Semantic Structures for Event Detection}, 
  year={2024},
  volume={12},
  number={},
  pages={64949-64957},
  abstract={Event detection is an important task for information extraction, which seeks to identify instances of specific event types from pieces of text. Recent studies have suggested that incorporating syntactic dependency graphs as feature representations for graph neural networks can significantly boost event detection performance. However, there are still challenges in leveraging multi-hop relationships within dependency parse trees to provide valuable additional information for keywords, as well as in effectively extracting relevant information from subordinate clauses, such as restrictive clauses. In this paper, we propose a novel Graph Convolutional Networks With Syntactic and Semantic (GCNWSS) structures for event detection task. Specifically, we construct a multi-hop matrix as the syntactic structure that calculates the hop distance between each word-pair. Besides, we propose a combination of biaffine attention and trigger-aware attention to generate semantic structures. In which, The biaffine attention mechanism is used to capture the global semantic information in a sentence. The trigger-aware attention mechanism enables the learning of trigger-related local semantics features of the text. Experimental results on benchmark dataset illustrate that our proposed model outperforms state-of-the-art methods.},
  keywords={Syntactics;Semantics;Task analysis;Event detection;Feature extraction;Vectors;Data mining;Graph neural networks;Event detection;graph neural network;attention mechanism;dependency parsing tree},
  doi={10.1109/ACCESS.2024.3395115},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11031881,
  author={R.S., Ponmagal and Deep, Harsh and Yadav, Devesh},
  booktitle={2025 International Conference on Data Science and Business Systems (ICDSBS)}, 
  title={Mental Health Support Using Gen-AI Shot Prompting Technique and Vector Embeddings}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Mental illness has become an issue of concern all over the world, with millions experiencing anxiety, depression, and stress. Chatbots powered by artificial intelligence have proved to be a scalable solution to delivering initial assistance through accessible and instant solutions. This work introduces a chatbot for mental wellness that utilizes generative AI and embedding-based relevance detection to provide contextually relevant and empathic answers. In contrast to rule-based systems, the chatbot utilizes few-shot learning, which enables the system to dynamically adjust according to user queries with a low level of training data. The system uses Sentence Transformer embeddings to determine query relevance and the Google Gemini API to create human-like responses. A series of experiments involving classification accuracy tests, response quality evaluation, and user interaction studies proved the high efficacy of the chatbot in identifying relevant queries while sustaining an empathetic tone of conversation. However, issues like spurious positives to vague inputs and crisis response bottlenecks are still areas that need to be addressed. Areas of future improvement include dataset increase, reinforcement learning, multilinguality, and improving crisis intervention mechanisms to improve the effectiveness of the chatbot in offering mental health support. The chatbot was tested using a curated dataset of mental health dialogues in English, with future work aimed at multilingual expansion.},
  keywords={Generative AI;Training data;Mental health;Reinforcement learning;Chatbots;Transformers;Vectors;Multilingual;Internet;Few shot learning;Mental health chatbot;generative AI;few-shot learning;SentenceTransformer;relevance detection;Google Gemini API;natural language processing;embedding-based filtering;conversational AI;crisis intervention;sentiment analysis;machine learning;user interaction study;mental health support;AI ethics;privacy and security;reinforcement learning;multilingual chatbot;context-aware responses;cognitive behavioral therapy},
  doi={10.1109/ICDSBS63635.2025.11031881},
  ISSN={},
  month={April},}@INPROCEEDINGS{11052805,
  author={Ginde, Gouri},
  booktitle={2025 IEEE/ACM Second International Conference on AI Foundation Models and Software Engineering (Forge)}, 
  title={"So what if I used GenAI?" - Legal Implications of Using Cloud-based GenAI in Software Engineering Research}, 
  year={2025},
  volume={},
  number={},
  pages={241-245},
  abstract={Generative Artificial Intelligence (GenAI) advances have led to new technologies capable of generating high-quality code, textual content, and images. The next step is to integrate GenAI technology into various aspects while conducting research or other related areas, a task typically conducted by researchers. Such research outcomes always come with a certain risk of liability. This vision paper sheds light on the various research aspects in which GenAI is used, thus raising awareness of its legal implications to novice and budding researchers. In particular, there are two risks: data protection and copyright. Both aspects are crucial for GenAI. We summarize key aspects regarding our current knowledge that every software researcher involved in using GenAI should be aware of to avoid critical mistakes that may expose them to liability claims and propose a checklist to guide such awareness.},
  keywords={Ethics;Codes;Law;Generative AI;Foundation models;Data protection;Software;Sparks;Software engineering;generative ai;legal implications;software engineering;research;genai},
  doi={10.1109/Forge66646.2025.00034},
  ISSN={},
  month={April},}@INPROCEEDINGS{10801036,
  author={Samantaray, Laxmipriya and Rautaray, Siddharth Swarup and Pandey, Manjusha and Dalai, Swagatika and Patro, P Aniket and Singh, Aryan},
  booktitle={2024 8th International Conference on Electronics, Communication and Aerospace Technology (ICECA)}, 
  title={Stoic Wisdom Meets Modern AI: Leveraging Large Language Models for Philosophical Guidance}, 
  year={2024},
  volume={},
  number={},
  pages={1387-1390},
  abstract={This research study introduces a novel platform that merges the ancient wisdom of Stoicism with contemporary artificial intelligence to offer personalized philosophical guidance. By harnessing the power of Large Language Models (LLMs) and employing Prompt Engineering techniques, the platform generates customized Stoic advice in response to user inquiries. Utilizing the advanced Generative Pre-trained Transformer (GPT) architecture, the system delivers contextually relevant insights and actionable steps, making Stoic principles more accessible and practical for modern users. This fusion of cutting-edge technology and timeless wisdom provides a unique resource for individuals seeking to apply Stoic teachings in their daily lives, thereby addressing the challenges of personalizing and implementing philosophical concepts in a contemporary context.},
  keywords={Philosophical considerations;Generative Pre-trainer transformer;Computational modeling;Memory management;Knowledge based systems;Education;Oral communication;Aerospace electronics;Transformers;Prompt engineering;Stoicism;Large Language Models;Prompt Engineering;Generative Pre-trained Transformers;Philosophy},
  doi={10.1109/ICECA63461.2024.10801036},
  ISSN={},
  month={Nov},}@ARTICLE{9291381,
  author={Zhi, Tao and Fan, Yingchun and Han, Hong},
  journal={IEEE Access}, 
  title={Cross-Modal Retrieval via Similarity-Preserving Learning and Semantic Average Embedding}, 
  year={2020},
  volume={8},
  number={},
  pages={223918-223930},
  abstract={Cross-modal retrieval takes one modality data as the query to search related data from different modalities (e.g. images vs. texts). As the heterogeneous gap exists between different media data, mainstream methods focus on reducing modality gap using common space learning. However, the heterogeneous media gap is big and it is too hard to be eliminated completely. Besides this, the representations of the same modality are diverse, which is important but is ignored by most existing methods. In this paper, we propose a novel cross-modal retrieval via Similarity-preserving Learning and Semantic Average Embedding (SLSAE) method. There are two key ideas in our method, one is to reduce modality gap by similarity-preserving learning, the other is to use semantic average embedding to weaken the impact of diversity existing in the common space. The similarity-preserving learning process will push embeddings from the same category together and pull embeddings from different categories apart. Eliminating the influence of embeddings diversity can improve performance and robustness, which is more friendly to real-world cross-modal retrieval applications. The model of proposed method is concise, and can be extended to multimodal retrieval situation flexibly. Comprehensive experimental results show that our method significantly outperforms the state-of-the-art methods in bimodal cross-modal retrieval, and it also achieves excellent performance in multimodal retrieval scenarios.},
  keywords={Semantics;Media;Correlation;Task analysis;Learning systems;Robustness;Common space learning;cross-modal retrieval;multimodal retrieval;similarity-preserving learning},
  doi={10.1109/ACCESS.2020.3044169},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10867379,
  author={G., Sutherlin Subitha and C., Seldev Christopher and R, Wilfred Blessing N. and V., Sheeja Kumari},
  booktitle={2024 2nd International Conference on Computing and Data Analytics (ICCDA)}, 
  title={Real-Time Enhanced GAN-Powered Intrusion Prevention System: Safeguarding Networks with Advanced AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In an era of escalating cyber threats and evolving networks, the demand for robust intrusion prevention is paramount. Introducing the Real-Time Enhanced GAN-Powered Intrusion Prevention System (RT-EGAN-IPS), a state-of-the-art solution fortified with advanced AI. RT-EGAN-IPS harnesses the power of Generative Adversarial Networks (GANs) to revolutionize real-time intrusion detection. GANs, renowned for their data synthesis capabilities, excel at uncovering subtle anomalies and emerging threats within network data. Its real-time adaptability enables it to swiftly identify novel attack patterns by continuously learning from incoming network data. Deep reinforcement learning and predictive analytics empower RT-EGAN-IPS to not only detect intrusions but autonomously respond, bolstering network protection. Versatile in handling multi-modal data streams, from text logs to multimedia content, RT-EGAN-IPS thrives on a collaborative approach. Security experts collaborate with the system for real-time validation and feedback. Dynamic thresholding ensures responsiveness to evolving threats, supported by low-latency responses and an ensemble approach. This abstract unveils RT-EGAN-IPS, a holistic AI-driven network security paradigm, promising a new level of protection in the ever-changing realm of cyber threats.},
  keywords={Ethics;Prevention and mitigation;Collaboration;Network security;Real-time systems;Threat assessment;Ensemble learning;Artificial intelligence;Protection;Computer security;intrusion prevention;GAN-powered;network security;threat detection;multi-modal data},
  doi={10.1109/ICCDA64887.2024.10867379},
  ISSN={},
  month={Nov},}@ARTICLE{9484796,
  author={Lu, Bi-Liang and Liu, Zhao-Hua and Wei, Hua-Liang and Chen, Lei and Zhang, Hongqiang and Li, Xiao-Hua},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={A Deep Adversarial Learning Prognostics Model for Remaining Useful Life Prediction of Rolling Bearing}, 
  year={2021},
  volume={2},
  number={4},
  pages={329-340},
  abstract={Remaining useful life (RUL) prediction for condition-based maintenance decision making plays a key role in prognostics and health management (PHM). Accurately predicting RUL of the rotating components of complex machines becomes a challenging task for PHM. For many existing methods, the current prediction error of RUL prediction may be accumulated into the future predictions, and thus can lead to a prediction error superposition problem. In this article, the formation mechanism of prediction error superposition is analyzed, and for the first time a deep adversarial long short-term memory (LSTM) prognostic framework is proposed to overcome the major issue related to prediction error superposition. In the proposed framework, a generative adversarial network (GAN) architecture combining the LSTM network and autoencoder (AE) is investigated for bearing RUL monitoring. In the proposed deep adversarial learning prediction framework, due to the potential involvement of long-term and complex tasks, the LSTM network (generator) is used to predict the degradation process of rolling bearings based on available historical data, and a simple but useful AE (discriminator) is used to determine and refine the accuracy of the prediction. Therefore, the AE plays the adversarial role of the LSTM network, and the prediction accuracy of the LSTM network can be significantly improved. For illustration purpose, two practical case studies, which use a series of bearing degradation data and the IEEE PHM 2012 PRONOSTIA datasets, respectively, are presented to show the prediction performance of the proposed method. Experimental results show that the proposed method works very well for vibration monitoring and performs better in comparison with the reference machine learning and deep learning approaches. Impact Statement—The damage of rolling bearing usually leads to a significant consequence to industrial production process. However, the existing remaining useful life (RUL) prediction methods for rolling bearing have a prediction error superposition problem that can affect the multistep prediction performance. The new adversarial learning prognostics model proposed in this article can overcome the problem. The proposed method uses LSTM network as a generator to predict RUL life for rolling bearing, and uses AE as a discriminator to estimate the prediction accuracy. The method can significantly improve the multistep prediction accuracy of RUL for rolling bearing, and provides reliable and scientific strategy in PHM of mechatronics equipment.},
  keywords={Rolling bearings;Predictive models;Mathematical model;Prognostics and health management;Data models;Deep learning;Natural language processing;Auto-encoder (AE);condition monitoring;deep adversarial learning;deep learning;generative adversarial network (GAN);long short-term memory (LSTM);prediction error superposition;prognostics and health management (PHM);remaining useful life (RUL) prediction;rolling bearings},
  doi={10.1109/TAI.2021.3097311},
  ISSN={2691-4581},
  month={Aug},}@INPROCEEDINGS{10574972,
  author={Joshi, Pankaj and Gupta, Aditya and Kumar, Pankaj and Sisodia, Manas},
  booktitle={2024 3rd International Conference on Applied Artificial Intelligence and Computing (ICAAIC)}, 
  title={Robust Multi Model RAG Pipeline For Documents Containing Text, Table & Images}, 
  year={2024},
  volume={},
  number={},
  pages={993-999},
  abstract={RAG (Retrieval Augmented Generation) is generally used for generating results from the existing knowledge-base. RAG refers to finding references (R), Adding references (A) and improving generation(i.e, answers to the question) (G). MultiModel-RAGs are used for generation of results over the documents which contain images and texts. There exists multiple different Multimodel-RAGs but these are not still efficient in generation of the results from the documents which contain relationships between images and texts. This study has proposed the solution to enable effective retrieval and generation of results, which includes the relationship between images and texts. The comparison of proposed Multimodal RAG with four different datasets (i.e., Short-form-type-QA, Long-form-type-QA, MCQ-type-QA, True-False-type-QA) shows the proposed solution improves the effectiveness of the existing Multimodal RAGs. Testing of proposed Multimodal RAG over two different other multimodal LLM i.e, Open-AI & Gemini helps in deciding whether the proposed solution fits best with LLM in different cases.},
  keywords={Analytical models;Accuracy;Computational modeling;Pipelines;Knowledge based systems;Testing;MuRAG(Multimodal Retrieval Augmented Generation);LLM(Large Language Models);RAG(Retrieval Augmented Generation);GenAI(Generative AI)},
  doi={10.1109/ICAAIC60222.2024.10574972},
  ISSN={},
  month={June},}@INPROCEEDINGS{8613665,
  author={Naritomi, Shu and Tanno, Ryosuke and Ege, Takumi and Yanai, Keiji},
  booktitle={2018 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)}, 
  title={FoodChangeLens: CNN-Based Food Transformation on HoloLens}, 
  year={2018},
  volume={},
  number={},
  pages={197-199},
  abstract={In this demonstration, we implemented food category transformation in mixed reality using both image generation and HoloLens. Our system overlays transformed food images to food objects in the AR space, so that it is possible to convert in consideration of real shape. This system has the potential to make meals more enjoyable. In this work, we use the Conditional CycleGAN trained with a large-scale food image data collected from the Twitter Stream for food category transformation which can transform among ten kinds of foods mutually keeping the shape of a given food. We show the virtual meal experience which is food category transformation among ten kinds of typical Japanese foods: ramen noodle, curry rice, fried rice, beef rice bowl, chilled noodle, spaghetti with meat source, white rice, eel bowl, and fried noodle. Note that additional results including demo videos can be see at https://negi111111.github.io/FoodChangeLensProjectHP/.},
  keywords={Virtual reality;Transforms;Geometry;Image generation;Conferences;Shape;Training;Deep Learning, Convolutional Neural Network, Generative Adversarial Networks, HoloLens, Food Image Transfer},
  doi={10.1109/AIVR.2018.00046},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10206235,
  author={Long, Wenhe and Zhao, Wei and Li, Zhiheng},
  booktitle={2023 6th International Conference on Artificial Intelligence and Big Data (ICAIBD)}, 
  title={Diverse Image Colorization Based on Diffusion Model}, 
  year={2023},
  volume={},
  number={},
  pages={860-865},
  abstract={Image colorization refers to the process of coloring a grayscale image. In the field of computer vision, image colorization is a very crucial task, because it can transform grayscale images into real and natural color images, which can provide better visualization effects and more visual information. This paper proposes a method based on the pre-trained diffusion model and control network, so that the model can obtain coloring results with bright colors, natural textures, and diverse results, and can handle a variety of control input conditions. Furthermore, we innovatively proposes a spatial attention module to process reference map control inputs and improve coloring results. Through the test results of a large number of various types of data, such as validation datasets with GT images and old photos without GT images, we show that the model in this paper has excellent performance in grayscale image colorization and strong versatility, which can adapt to different scenarios and different types of test datasets, demonstrating that our algorithm has practical application value.},
  keywords={Adaptation models;Visualization;Computer vision;Image color analysis;Computational modeling;Process control;Transforms;image colorization;diffusion model;generative model;spatial attention},
  doi={10.1109/ICAIBD57115.2023.10206235},
  ISSN={2769-3554},
  month={May},}@INPROCEEDINGS{9395936,
  author={Jinesh Melvin, Y I and Gawade, Sushopti and Palivela, Hemant},
  booktitle={2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS)}, 
  title={Visual Question Answering using Data Mining Techniques for Skeletal Scintigraphy in medical domain - VQADMSS}, 
  year={2021},
  volume={},
  number={},
  pages={859-863},
  abstract={Understanding about the medical images of patients is a very tedious task. Doctors should convey their patient through the image of the questions asked by the patient. Large amounts of labeled data are required for training in traditional approaches for VQA (Visual Question Answering). Also, the description of clinic trial text in English and in multilingual contexts is one of the challenges in the medical field. To present the clarification about the images, doctors are required to provide the related images. It is better for comparison with the patient's previous report and current report. This paper contributes to solve the problems related to VQA for better description of the image and accuracy related images through the answer of the questions, also to make it easy to convey the users with any kind of images. Question answer process should be more descriptive for easy to understand and traceable. This system helps to identify the types of images which are captured by any scanner. The better accuracy is a visualization method which projects the answers as a baseline that shows the corresponding region with various colors, which is easier to note the answers in visual method for the appropriate questions. This proposed framework focuses on Radiology image for Skeletal Scintigraphy to transform and generate a model using Data Mining Techniques. This system suggests that the effective medical Visual Question answering techniques is better to assist doctors in clinical analysis and diagnosis. This also will help the hospital services to grow the medical domain.},
  keywords={Training;Visualization;Radiology;Knowledge discovery;Feature extraction;Data mining;Medical diagnostic imaging;Radiology images;Classification models;Generative models;Transformer;Visual Question Answering},
  doi={10.1109/ICAIS50930.2021.9395936},
  ISSN={},
  month={March},}@INPROCEEDINGS{10505427,
  author={Wang, ZhiQiang and Joshi, Aryan and Zhang, GuiYing and Ren, WenJia and Jia, Feng and Sun, XiaoHang},
  booktitle={2023 2nd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR)}, 
  title={Elevating Perception: Unified Recognition Framework and Vision-Language Pre-Training Using Three-Dimensional Image Reconstruction}, 
  year={2023},
  volume={},
  number={},
  pages={592-596},
  abstract={This research project explores a paradigm shift in perceptual enhancement by integrating a Unified Recognition Framework and Vision-Language Pre-Training in three-dimensional image reconstruction. Through the synergy of advanced algorithms from computer vision & language processing, the project tries to enhance the precision and depth of perception in reconstructed images. This innovative approach holds the potential to revolutionize fields such as medical imaging, virtual reality, and computer-aided design, providing a comprehensive perspective on the intersection of multimodal data processing and perceptual advancement. The anticipated research outcomes are expected to significantly contribute to the evolution of technologies that rely on accurate and contextually rich three-dimensional reconstructions. Moreover, the research aims to reduce the constant need for new datasets by improving pattern recognition through 3D image patterning on backpropagation. This continuous improvement of vectors is envisioned to enhance the efficiency and accuracy of pattern recognition, contributing to the optimization of perceptual systems over time.},
  keywords={Visualization;Solid modeling;Computer vision;Three-dimensional displays;Image recognition;Navigation;Zero-shot learning;component;Pattern Recognition;3D Model LLM;Reconstructive Training;Image to Text Generation;Generative AI;3D Tech},
  doi={10.1109/AIHCIR61661.2023.00105},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10195070,
  author={Banar, Berker and Colton, Simon},
  booktitle={2023 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Autoregressive Self-Evaluation: A Case Study of Music Generation Using Large Language Models}, 
  year={2023},
  volume={},
  number={},
  pages={264-265},
  abstract={Autoregressive models have shown significant success in many tasks such as natural language generation and music composition. However, generic training mechanisms with off-the-shelf loss functions (e.g. cross-entropy), where not much attention is paid to the specifics of the task, do not necessarily guarantee success as different data modalities (e.g. text, visuals, music) exhibit different natures. In this study, we present a novel autoregressive self-evaluation framework to assess the performance of autoregressive models with both domain-agnostic and domain-specific metrics. We demonstrate this strategy with a case study of music generation using GPT-2 within a transfer learning paradigm. We contrast and compare the effects of fundamental parameters in autoregressive generation such as the temperature in sampling and the length of the generated sequence.},
  keywords={Measurement;Training;Analytical models;Visualization;Transfer learning;Natural languages;Reliability;autoregressive self-evalution;autoregressive models;generative models;large language models;music generation},
  doi={10.1109/CAI54212.2023.00118},
  ISSN={},
  month={June},}@INPROCEEDINGS{9985790,
  author={Zhang, Ge and Peng, Xiao and Zhao, Tao and Liang, Fei},
  booktitle={2022 3rd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)}, 
  title={A GAN-based adaptive embedded digital label information hiding scheme}, 
  year={2022},
  volume={},
  number={},
  pages={355-358},
  abstract={With the development of information technology, digital label technology has entered into people’s life, and is widely used in data tracking, traceability and monitoring. However, with the development of big data, the apperance of more potential attack methods, the existing digital label technology is hard to meet the security requirements. Therefore, this paper proposes a GAN-based adaptive embedded digital label information hiding scheme. This scheme: 1) introduces adversarial samples and using adversarial networks to strengthen the carrier information, improving the anti-hidden analysis ability of secret information; 2) introduces an attention mechanism into the generator network, and improves the extraction accuracy of digital labels. A better embedding probability calculation is realized, and the quality of the dense carrier is guaranteed; 3) designs the analyzer network, improving the anti-hidden analysis ability of digital labels.},
  keywords={Big Data;Probability;Feature extraction;Generators;Data mining;Security;Internet of Things;digital label;adversarial generative network;information hiding},
  doi={10.1109/ICBAIE56435.2022.9985790},
  ISSN={},
  month={July},}@INPROCEEDINGS{9967536,
  author={Foria, Federico and Calicchio, Mario and Miceli, Gabriele and Xie, Aniello and Cuccato, Davide and Allegro, Alessandro},
  booktitle={2022 IEEE International Conference on Metrology for Extended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)}, 
  title={Deep Learning Based Detachment Segmentation: the MIRET Approach}, 
  year={2022},
  volume={},
  number={},
  pages={422-426},
  abstract={Among infrastructure diagnostics, the maintenance of Transportation Tunnel (TT) is of paramount importance. On the one hand, a predictive maintenance process would allow for safety compliance, preventive corrective actions, and increased lifetime for the asset, which results in improved efficiency of the overall infrastructure. On the other hand, existing methods to perform diagnosis and detection of these anomalies are inexpensive and time-consuming. Thus, ETS and RMT foresee the development of deep learning-based methods for the segmentation of defects on TT images. This stands as the technological pillar of two innovative ETS projects: the innovative multi-dimensional survey system (ARCHITA), and a new approach for the Management and Identification of the Risk for Existing Tunnels (MIRET). The focus of this communication is the segmentation of superficial detachments on data of concrete type Transportation Tunnels, using convolutional neural networks trained in an adversarial fashion.},
  keywords={Image segmentation;Visualization;Annotations;Transportation;Neural engineering;Predictive models;Safety;predictive maintenance;convolutional neural network;semantic segmentation;generative adversarial network},
  doi={10.1109/MetroXRAINE54828.2022.9967536},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10730162,
  author={Ng, Jing Ying and Liew, Soung-Yue and Chng, Chee Henn and Teo, Teck Wan and Khoo, Zong Zheng},
  booktitle={2024 5th International Conference on Artificial Intelligence and Data Sciences (AiDAS)}, 
  title={The Discovery and Solution of the Pseudo-Reasoning Issue for Constructing Cost-Effective Multi-Agent Frameworks in Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Large Language Models (LLMs) show exceptional logical reasoning capabilities. Despite these advancements, a significant performance and cost gap remains between smaller and larger models. Various prompting techniques have been developed to enhance LLM performance, but the performance gap remains unresolved. Additionally, multi-agent frameworks have also been introduced, however, there is often insufficient emphasis on token consumption, which impacts cost and time efficiency. This paper presents a comparative analysis of different LLMs and prompting strategies using the Counter-Intuitive AR dataset. Our findings reveal that sophisticated prompt engineering methods often result in diminishing returns and are less cost-effective than simply using larger models. This phenomenon, which we term the “pseudo-reasoning issue”, occurs when models appear to demonstrate genuine reasoning but rely on past learned patterns. We show that GPT-4o, even without additional prompting strategies, achieves 76% accuracy, surpassing all the tested methods in enhancing GPT-3.5- Turbo performance. Conversely, a heterogeneous approach, which combines large and small LLMs in solving complex problems is feasible in terms of cost-effectiveness. Our linear graph shows that increased involvement of GPT-4o in text generation correlates with higher model accuracy. These findings challenge the current trend towards increasingly complex strategies and suggest the crucial need for evaluating cost-effectiveness when designing novel prompting strategies.},
  keywords={Costs;Accuracy;Limiting;Large language models;Focusing;Market research;Cognition;Robustness;Data models;Prompt engineering;Large Language Models;Multi-Agent;Generative AI;Prompting;Cost-Effectiveness},
  doi={10.1109/AiDAS63860.2024.10730162},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10113266,
  author={Cui, Yueshan and Luan, Yizhong and Guo, Junmei},
  booktitle={2022 2nd International Symposium on Artificial Intelligence and its Application on Media (ISAIAM)}, 
  title={Improved CycleGAN for natural scenery images style transfer}, 
  year={2022},
  volume={},
  number={},
  pages={16-22},
  abstract={Natural scenery images style transfer is a technique using computer technology to change the stylization effects of images by processing the high-level features which are extracted by images in neural networks, and is used to improve the diversities and aesthetics of images. Since existing neural network models cannot achieve a good effect when dealing with the style transfer tasks of natural photos, this paper proposes an improved CycleGAN method that has the advantage of changing two unpaired image datasets in style. In order to save more image content and solve the model overfitting problem, we added a channel attention mechanism to the generator and optimized the cycle consistency loss. We defined the developed loss function as MS-SSIM+SmoothL1 in this paper. The method can alleviate the overfitting phenomenon of the model as the epoch increases. The images generated by our proposed method have better performance in detail. Experiments demonstrate that the images generated by our proposed improved network are more correspond with human perception in visual. In the FID score, our proposed method was 42.24% lower in the Summer2winter datasets and 23.76% lower in the Monet2photo datasets than CycleGAN.},
  keywords={Training;Image quality;Computational modeling;Neural networks;Media;Feature extraction;Visual effects;image style transfer;generative adversarial nets;loss function;attention mechanism},
  doi={10.1109/ISAIAM55748.2022.00011},
  ISSN={},
  month={June},}@INPROCEEDINGS{10291437,
  author={Lee, Kin Wai and Yin Chin, Renee Ka},
  booktitle={2023 IEEE International Conference on Artificial Intelligence in Engineering and Technology (IICAIET)}, 
  title={Characterisation of Data Augmentation Techniques Using Visualisation}, 
  year={2023},
  volume={},
  number={},
  pages={393-398},
  abstract={Data Augmentation (DA) alleviates the data-space limitations by generating new instances for training machine learning (ML) models. However, in practice, the effectiveness of the DA techniques adopted in varying downstream tasks lacks analytical explainability, mainly due to its domain-specificity nature. This paper describes a new ideation of characterising DA techniques from a visualisation perspective by explaining feature-space characteristics of augmented and original data in the high-dimensional space. This is accomplished by assessing the feasibility of using principal component analysis (PCA) for capturing the distinctiveness inherited by DA techniques. In a problem setting of COVID-19 CT detection, the proximity analysis suggests that computing PCA using low-dimensional features can contribute significant analytical values for the characterisation of DA techniques. The comparison of the clustering performances using data instances from the image and feature domains further highlights the significance of abstract features for more effective visual analysis and interpretation. Furthermore, the non-trivial connection between feature inputs and image outputs demonstrated in the connectivity analysis also indicates the significance of visualisation in analysing ML decisions, particularly with high-level visual explanations.},
  keywords={COVID-19;Training;Visualization;Computed tomography;Data visualization;Machine learning;Data augmentation;Principal component analysis;data augmentation;data visualisation;COVID-19;generative adversarial network},
  doi={10.1109/IICAIET59451.2023.10291437},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9534580,
  author={Jiaqi, Li},
  booktitle={2021 2nd International Conference on Artificial Intelligence and Education (ICAIE)}, 
  title={Interaction Design and Realization of Sound-controlled Graphics in Decoration Sculpture Based on Modern New Media and Algorithmic Aided Design Technology}, 
  year={2021},
  volume={},
  number={},
  pages={85-88},
  abstract={Based on the current situation that interior furnishings design is mostly static and conveys information by itself, with display sculpture as the carrier, modern new media and algorithmic aided design technology are applied in it, and the interactive mode and realization method of sculpture and human in the indoor environment of architecture are discussed. On the basis of studying the generation rules and rules of inorganic flower works in village, mountain and city, using computer algorithm programming, 80 pieces of centrally symmetrical flower-like decorative graphics were optimized and generated. This paper uses the PATHON language to write the voice recognition program and test it. After the test, the interactive projection technology is used to project the figure on the plaster sculpture. At the same time, the external microphone device is connected to realize the synchronous switch of the sound to the figure. This research aims to strengthen the artistic expression of decorative sculpture design, realize the combination of technology and art, and provide a realizable interactive way for the development of other interior furnishings design in the future.},
  keywords={Visualization;Interactive systems;Urban areas;Education;Switches;Speech recognition;Media;Generative graph;Sound control;Interactive projection technology;Computer programming;Decorative sculpture},
  doi={10.1109/ICAIE53562.2021.00025},
  ISSN={},
  month={June},}@INPROCEEDINGS{10692706,
  author={Peng, Dingwei and Yuan, Xuelin and Ouyang, Mingjun and Weng, Qizhen and Xie, Ting and Zhong, Ningze and Zhu, Xiangwei},
  booktitle={2024 6th International Conference on Internet of Things, Automation and Artificial Intelligence (IoTAAI)}, 
  title={Low Bitrate Codec with Joint Vector Quantization and Hoffman Coding for Internet of Things}, 
  year={2024},
  volume={},
  number={},
  pages={402-406},
  abstract={Tiantong-1 satellite offers voice communication rates of 0.6, 1.2, and 2.4 kbps, playing a crucial role in emergency scenarios like field rescue. In the context of BeiDou 3, the communication rate for short messages is typically below 1 kbps. It is necessary to compress the audio to a bit rate lower than 1 kbps in satellite audio internet of things. For satellite voice transmission, the conventional vocoder MELPE, based on the source-filtering assumption, is commonly used. However, it falls short in delivering high-quality voice. This paper introduces an end-to-end vocoder for satellite voice transmission, employing a single model that generates different bit rates with residual vector quantization technique. To further reduce the coding rate, we propose joint vector quantization that achieves a 50% reduction in bitrate. Experimental results show that this method can improve the audio quality at 0.50kbps while it remains the same RTF score. We also count the probability of tokens for each codebook to reduce the code rate by Hoffman coding. Experimental results show that Hoffman coding can reduce the coding rate by 14% while remain the same RTF score.},
  keywords={Satellites;Codes;Codecs;Speech coding;Vector quantization;Vocoders;Bit rate;Encoding;Vectors;Internet of Things;End-to-End Codec;Generative Adversarial Networks;Joint vector quantization;Hoffman Coding;Internet of Things},
  doi={10.1109/IoTAAI62601.2024.10692706},
  ISSN={},
  month={July},}@INPROCEEDINGS{11105937,
  author={Zhu, Yuanjing and Liu, Yunan},
  booktitle={2025 11th International Conference on Computing and Artificial Intelligence (ICCAI)}, 
  title={LLM-NER: Advancing Named Entity Recognition with LoRA+ Fine-Tuned Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={364-368},
  abstract={Named Entity Recognition (NER) is a crucial task in natural language processing, but it faces persistent challenges in deep learning approaches, such as ambiguity, entity overlap, and domain variability. This study explores the potential of large language models (LLMs) to address these challenges by leveraging LoRA (Low-Rank Adaptation) and LoRA+ fine-tuning techniques. We present a specialized fine-tuned LLM based on Meta-Llama-3-8B-Instruct, optimized for NER tasks. Our model is evaluated against three benchmarks—BERT, RoBERTa, and DeBERTa—and demonstrates competitive performance using prompting alone. Moreover, the fine-tuned model with LoRA+ surpasses benchmark models by $10 \%$ in F1 score, showcasing its ability to distinguish nuanced entities effectively. These findings highlight the potential of LLMs in redefining the state of the art for NER tasks, enabling more robust and adaptable entity recognition solutions.},
  keywords={Deep learning;Adaptation models;Terminology;Large language models;Computational modeling;Memory management;Named entity recognition;Benchmark testing;Robustness;Tuning;Named Entity Recognition (NER);Generative AI;Large Language Model (LLM);Fine Tuning;Low-Rank Adaptation (LoRA);LoRA Plus},
  doi={10.1109/ICCAI66501.2025.00063},
  ISSN={},
  month={March},}@INPROCEEDINGS{11108892,
  author={Lin, Jin- Long and Zheng, Meng-Cong and Chen, Chun-Ching and Zhong, Chen-Rao},
  booktitle={2025 IEEE 5th International Conference on Software Engineering and Artificial Intelligence (SEAI)}, 
  title={A Design Method for Automotive Front Styling Based on AIGC and Kansei Engineering}, 
  year={2025},
  volume={},
  number={},
  pages={128-132},
  abstract={This study proposes a novel automotive front styling design method that integrates Retrieval-Augmented Generation Large Language Models (RAG-LLM) with Kansei Engineering and validates its effectiveness through empirical research. The research is divided into five phases: building the LLM platform, constructing the RAG-LLM platform, conducting knowledge-based question answering testing, evaluating design capabilities, and testing image generation. The test results show that the RAG-LLM model significantly outperforms traditional LLM models in generating Kansei vocabulary, as well as in the accuracy and completeness of design proposals. Additionally, when design proposals generated by RAG-LLM were input into image generation AI, the resulting automotive design images demonstrated improvements in design quality, emotional intent, and consumer preferences. This study also demonstrates that the RAG-LLM framework effectively optimizes the application of Kansei Engineering in automotive styling design, enhancing both design efficiency and quality.},
  keywords={Vocabulary;Technological innovation;Accuracy;Image synthesis;Design methodology;Knowledge based systems;Proposals;Automotive engineering;Testing;Software engineering;Kansei Engineering;Generative AI;Styling Design;Product Development;Design Process},
  doi={10.1109/SEAI65851.2025.11108892},
  ISSN={},
  month={June},}@INPROCEEDINGS{10489092,
  author={Zhang, Zhijun and Yu, Haomin and Wang, Wentong and Luo, Yamei},
  booktitle={2023 5th International Conference on Robotics, Intelligent Control and Artificial Intelligence (RICAI)}, 
  title={Autonomous Conscious Humanoid Robot System}, 
  year={2023},
  volume={},
  number={},
  pages={100-107},
  abstract={In order to enable intelligent robots to have autonomous consciousness and make decisions autonomously, and generate behaviors safely and ethically, an autonomous conscious humanoid robot (ACHR) architecture is proposed and designed in this paper. The ACHR is mainly composed of mental system, environment perception system and behavior generation system. When the robot is stimulated externally in an environmental interaction, or generates an internal motivation due to an internal need, the stimulation is analyzed and goals of the robot are generated. Then goals are decomposed and logically sorted through the mental system, and sent into the behavioral decision-making system. Finally, behavior decision that meet moral ethics and safety principle is transferred to the behavior generation module so that the robot can generate behaviors. Compared with existing humanoid robots, the ACHR proposed in this paper combines large-scale models with generative intelligence technology and it is more autonomous. The framework of autonomous conscious humanoid robot proposed in this paper can promote the development of conscious robot in the future and provide a new idea for the development of intelligent robots.},
  keywords={Ethics;Technological innovation;Decision making;Humanoid robots;Safety;Artificial intelligence;Research and development;Autonomous conscious;mental system;environment perception;behavior generation;moral ethics},
  doi={10.1109/RICAI60863.2023.10489092},
  ISSN={},
  month={Dec},}@ARTICLE{11152601,
  author={Ali, Abid and Xia, Yuanqing and Zia, Muhammad Fahad and Bangyal, Waqas Haider and Iqbal, Muddesar},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={Trustworthy Load Forecasting With Generative AI: A Dual-Attention ConvLSTM and VAE-Based Approach}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Increasing urbanization and the global transition toward sustainable, eco-friendly energy systems require efficient and robust energy predictions for smart grids. The inherently unpredictable, volatile, and intermittent nature of energy demand necessitates an accurate short-term load forecasting model to ensure reliable consumer applications. However, conventional deep learning models often struggle to address complex and dynamic load patterns. To address these challenges, this research presents a novel trustworthy GAI-assisted model comprising i) a variational autoencoder that maps raw energy consumption data to extract meaningful and compact features and ii) a deep learning model utilizing a dual attention mechanism with convolutional long short-term memory (DAConvLSTM), that effectively captures the temporal dependencies of the complex load pattern and optimizes forecasting accuracy. The effectiveness and robustness of the proposed model are extensively evaluated using publicly available comprehensive datasets. The results demonstrate the performance of the proposed model, with an overall improvement of 1.45%81.54% in the mean absolute error, 1.92%78.61% in the root mean square error, and 1.55%81.85% in the mean absolute percentage error compared with other baseline methods. The results validate the effectiveness of the proposed model in predicting peak load demand and have practical implications, thereby enhancing the existing knowledge for creating robust energy management in smart grid applications.},
  keywords={Load modeling;Accuracy;Predictive models;Long short term memory;Feature extraction;Data models;Computational modeling;Adaptation models;Load forecasting;Forecasting;Convolutional long short-term memory;dual attention;generative AI;load forecasting;smart grid;variational autoencoder},
  doi={10.1109/TCE.2025.3606753},
  ISSN={1558-4127},
  month={},}@ARTICLE{11174969,
  author={Zhao, Guodong and Wang, Jingjing and Wang, Ye and Meng, Zhijun and Wang, Zichen and Zhang, Xin and Jiang, Chunxiao},
  journal={IEEE Transactions on Aerospace and Electronic Systems}, 
  title={From Sensors to Rotors: Generative Neural Network Driven Hierarchical Learning for Agile Drone Dynamic Target Tracking}, 
  year={2025},
  volume={},
  number={},
  pages={1-17},
  abstract={Traditional motion planning pipelines for autonomous drones often separate perception, planning, and control into distinct layers, resulting in information loss and reduced agility, particularly in dynamic target tracking within obstacledense environments. End-to-end neural networks offer alternatives but face challenges with data utilization and exploration. This paper introduces a hierarchical learning framework for tracking dynamic targets in complex, cluttered environments, built around a vector quantized variational autoencoder (VQ-VAE) architecture. The framework uniquely enables drones to learn what lowlevel rotor commands achieve expert-demonstrated high-level goals, rather than directly mimicking expert outputs. Our three-stage approach generates high-quality expert trajectories using global SE(3) optimization, employs reinforcement-supervised learning to map perceptions to rotor commands, and uses reinforcement learning with pre-trained VQ-VAE components to surpass initial demonstrations. The VQ-VAE serves as a knowledge bridge between stages, preserving control skills while enabling exploration. Experiments in dense obstacle scenarios with dynamic targets demonstrate sub-second planning cycles regardless of obstacle density, success rates exceeding 90% in moderately complex environments, and velocities 4-5 times higher than comparable approaches, proving the framework's effectiveness for agile navigation in unpredictable, obstacle-rich environments.},
  keywords={Drones;Planning;Rotors;Training;Trajectory;Target tracking;Navigation;Aerodynamics;Sensors;Deep learning;Generative neural networks;quadrotor motion planning;reinforcement learning;imitation Learning;adaptive control},
  doi={10.1109/TAES.2025.3612352},
  ISSN={1557-9603},
  month={},}@INPROCEEDINGS{9619635,
  author={Zhao, Qianmengke and Wang, Ye and Liu, Qun},
  booktitle={2021 7th International Conference on Big Data and Information Analytics (BigDIA)}, 
  title={Multi-Semantic Image Recognition Model and Evaluating Index for Explaining the Deep Learning Models}, 
  year={2021},
  volume={},
  number={},
  pages={25-31},
  abstract={Although deep learning models are powerful among various applications, most deep learning models are still a black box, lacking verifiability and interpretability, which means the decision-making process that human beings cannot understand. Therefore, how to evaluate deep neural networks with explanations is still an urgent task. In this paper, we first propose a multi-semantic image recognition model, which enables human beings to understand the decision-making process of the neural network. Then, we presents a new evaluation index, which can quantitatively assess the model interpretability. We also comprehensively summarize the semantic information that affects the image classification results in the judgment process of neural networks. Finally, this paper also exhibits the relevant baseline performance with current state-of-the-art deep learning models.},
  keywords={Deep learning;Image recognition;Neural networks;Semantics;Decision making;Dogs;Predictive models;Neural network interpretability;Explainable artificial intelligence;Interpretability evaluation index},
  doi={10.1109/BigDIA53151.2021.9619635},
  ISSN={},
  month={Oct},}@ARTICLE{10535163,
  author={Yang, Yulin and Chen, Qingqing and Li, Yinhao and Wang, Fang and Han, Xian-Hua and Iwamoto, Yutaro and Liu, Jing and Lin, Lanfen and Hu, Hongjie and Chen, Yen-Wei},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Segmentation Guided Crossing Dual Decoding Generative Adversarial Network for Synthesizing Contrast-Enhanced Computed Tomography Images}, 
  year={2024},
  volume={28},
  number={8},
  pages={4737-4750},
  abstract={Although contrast-enhanced computed tomography (CE-CT) images significantly improve the accuracy of diagnosing focal liver lesions (FLLs), the administration of contrast agents imposes a considerable physical burden on patients. The utilization of generative models to synthesize CE-CT images from non-contrasted CT images offers a promising solution. However, existing image synthesis models tend to overlook the importance of critical regions, inevitably reducing their effectiveness in downstream tasks. To overcome this challenge, we propose an innovative CE-CT image synthesis model called Segmentation Guided Crossing Dual Decoding Generative Adversarial Network (SGCDD-GAN). Specifically, the SGCDD-GAN involves a crossing dual decoding generator including an attention decoder and an improved transformation decoder. The attention decoder is designed to highlight some critical regions within the abdominal cavity, while the improved transformation decoder is responsible for synthesizing CE-CT images. These two decoders are interconnected using a crossing technique to enhance each other's capabilities. Furthermore, we employ a multi-task learning strategy to guide the generator to focus more on the lesion area. To evaluate the performance of proposed SGCDD-GAN, we test it on an in-house CE-CT dataset. In both CE-CT image synthesis tasks–namely, synthesizing ART images and synthesizing PV images–the proposed SGCDD-GAN demonstrates superior performance metrics across the entire image and liver region, including SSIM, PSNR, MSE, and PCC scores. Furthermore, CE-CT images synthetized from our SGCDD-GAN achieve remarkable accuracy rates of 82.68%, 94.11%, and 94.11% in a deep learning-based FLLs classification task, along with a pilot assessment conducted by two radiologists.},
  keywords={Generators;Image synthesis;Decoding;Task analysis;Frequency locked loops;Lesions;Medical diagnostic imaging;CE-CT image synthesis;crossing dual decoding generator;GANs;multi-task learning},
  doi={10.1109/JBHI.2024.3403199},
  ISSN={2168-2208},
  month={Aug},}@ARTICLE{10736668,
  author={Ribeiro, Rafael and de Carvalho, Alexandre Valle and Rodrigues, Nelson Bilber},
  journal={IEEE Transactions on Games}, 
  title={Image-Based Video Game Asset Generation and Evaluation Using Deep Learning: A Systematic Review of Methods and Applications}, 
  year={2025},
  volume={17},
  number={3},
  pages={622-630},
  abstract={Creating content for digital video game is an expensive segment of the development process, and many techniques have been explored to automate it. Much of the generated content is graphical, ranging from textures and sprites to typographical elements and user interfaces. Numerous techniques have been explored to automate the generation of these assets, with recent advancements incorporating artificial intelligence methodologies, such as deep learning generative models. This study comprehensively surveys the literature from 2016 onward, focusing on using machine learning to generate image-based assets for video game development, reviewing the deep learning approaches employed, and analyzing the specific challenges found. Specifically, the deep learning approaches employed, the problems addressed within the domain, and the metrics used for evaluating the results. The study demonstrates a knowledge gap in generative methods for some types of video game assets. In addition, applicability and effectiveness of the most used evaluation metrics in the literature are studied. As future research prospects, with the increase in popularity of generative AI, the adoption of such techniques will be seen in automation processes.},
  keywords={Video games;Games;Measurement;Libraries;Image synthesis;Deep learning;Generative adversarial networks;Surveys;Sprites (computer);Quality assessment;Diffusion models (DMs);evaluation metrics;generative adversarial network (GAN)},
  doi={10.1109/TG.2024.3487054},
  ISSN={2475-1510},
  month={Sep.},}@INPROCEEDINGS{10680805,
  author={Sewioło, Mateusz and Mystkowski, Arkadiusz},
  booktitle={2024 28th International Conference on Methods and Models in Automation and Robotics (MMAR)}, 
  title={Genetic algorithm for automatic construction, optimization and testing of multi-input forked convolutional neural networks used for diagnostics of rotating agricultural machines}, 
  year={2024},
  volume={},
  number={},
  pages={282-287},
  abstract={The third decade of the 21st century can undoubtedly be called the “smart” decade. Manufacturers of all devices try to integrate the functions of their products with methods based on artificial intelligence as much as possible. This trend has also reached industrial and agricultural machine manufacturers, where neural network diagnostics is no longer just a thing of the future and is becoming something every day. As developing AI methods requires a high degree of expert knowledge and is time-consuming, we propose a method to automate the entire process. Thanks to the use of a three-step genetic algorithm, we managed to create a system that can create the appropriate AI architecture based on neural networks, optimise it, and test it completely autonomously. We confirmed its effectiveness by using our method to develop a multi-input, forked convolutional network capable of recognizing nine different states (healthy and eight different damages) of an agricultural rotary tedder with an accuracy of approximately 98%.},
  keywords={Automation;Neural networks;Market research;Approximation algorithms;Convolutional neural networks;Artificial intelligence;Optimization;convolutional neural network;genetic algorithm;agriculture rotary tedder;vibration analysis;fault diagnosis;neural network optimization},
  doi={10.1109/MMAR62187.2024.10680805},
  ISSN={2835-2807},
  month={Aug},}@INPROCEEDINGS{11131819,
  author={Ribić, S. and Mulahasanović, R. Turčinhodžić and Hodžić, K.},
  booktitle={2025 MIPRO 48th ICT and Electronics Convention}, 
  title={Torturing the Turing Test with Suggestive Anagrams in Slavic Languages}, 
  year={2025},
  volume={},
  number={},
  pages={105-110},
  abstract={The impressive results achieved by language recognition using a generative pre-trained transformer have led to divided opinions on whether or not the Turing test has finally been passed. After understanding the working principles of the GPT programs, it was remarked that the tokenization concept, used by GPT, resulted in the loss of the word-to-letter relationship. Through about 36 specially prepared anagrams with a description of a term in a verse in the languages of the South Slavs, it was shown that ChatGPT and similar programs are far more capable of understanding the semantic connection between words and allusions than in performing the relatively simple task of searching for an adequate word from the offered letters.},
  keywords={Generative Pre-trainer transformer;Semantics;Chatbots;Transformers;Search problems;Tokenization;Continents;Marine vehicles;Artificial intelligence;Natural language processing;GPT;Turing test},
  doi={10.1109/MIPRO65660.2025.11131819},
  ISSN={1847-3938},
  month={June},}@INPROCEEDINGS{9750370,
  author={Cinquini, Martina and Giannotti, Fosca and Guidotti, Riccardo},
  booktitle={2021 IEEE Third International Conference on Cognitive Machine Intelligence (CogMI)}, 
  title={Boosting Synthetic Data Generation with Effective Nonlinear Causal Discovery}, 
  year={2021},
  volume={},
  number={},
  pages={54-63},
  abstract={Synthetic data generation has been widely adopted in software testing, data privacy, imbalanced learning, artificial intelligence explanation, etc. In all such contexts, it is important to generate plausible data samples. A common assumption of approaches widely used for data generation is the independence of the features. However, typically, the variables of a dataset de-pend on one another, and these dependencies are not considered in data generation leading to the creation of implausible records. The main problem is that dependencies among variables are typically unknown. In this paper, we design a synthetic dataset generator for tabular data that is able to discover nonlinear causalities among the variables and use them at generation time. State-of-the-art methods for nonlinear causal discovery are typically inefficient. We boost them by restricting the causal discovery among the features appearing in the frequent patterns efficiently retrieved by a pattern mining algorithm. To validate our proposal, we design a framework for generating synthetic datasets with known causalities. Wide experimentation on many synthetic datasets and real datasets with known causalities shows the effectiveness of the proposed method.},
  keywords={Software testing;Deep learning;Data privacy;Filtering;Neural networks;Learning (artificial intelligence);Generators;Data Generation;Causal Discovery;Pattern Mining;Synthetic Datasets;Explainability},
  doi={10.1109/CogMI52975.2021.00016},
  ISSN={},
  month={Dec},}@ARTICLE{9260146,
  author={Hu, Cong and Song, Xiao-Ning},
  journal={IEEE Access}, 
  title={Graph Regularized Variational Ladder Networks for Semi-Supervised Learning}, 
  year={2020},
  volume={8},
  number={},
  pages={206280-206288},
  abstract={To tackle the problem of semi-supervised learning (SSL), we propose a new autoencoder-based deep model. Ladder networks (LN) is an autoencoder-based method for representation learning which has been successfully applied on unsupervised learning and semi-supervised learning. However, It ignores the manifold information of high-dimensional data and usually achieves unmeaning features which are very difficult to use in the subsequent tasks, such as prediction and recognition. To these issues, we proposed Graph Regularized Variational Ladder Networks (GRVLN), which explicitly and implicitly employs the manifold structure of data. Our contributions can be summarized as two folds: (1) Graph regularization is used to build all decoder layers, which explicitly promotes the manifold learning via graph laplacian matrixs; (2) Variational autoencoder is used as the backbone instead of traditional autoencoder in the encoder layers for implicitly learning the manifold structure of data distribution. Compared with ladder networks and other autoencoder-based methods, GRVLN achieves superior performance in semi-supervised classification tasks. Experimental results show that our method also has a comparable performance with state-of-the-art methods on several benchmark data sets.},
  keywords={Semisupervised learning;Decoding;Manifolds;Deep learning;Data models;Encoding;Training;Semi-supervised learning;ladder network;manifold regularization;graph laplacian;variational autoencoder},
  doi={10.1109/ACCESS.2020.3038276},
  ISSN={2169-3536},
  month={},}@ARTICLE{11084772,
  author={Sridharan, Harinath and Ramsai, Nambala and Vundurthy, Bhaskar},
  journal={IEEE Access}, 
  title={Generative Models, Attention Mechanisms, and Adaptive Methods for Robot Navigation in Complex Environments—A Survey}, 
  year={2025},
  volume={13},
  number={},
  pages={132332-132365},
  abstract={Autonomous mobile robots, equipped with multiple sensors, have been traditionally used to perform search, rescue and other tasks. A number of new scenarios for application of mobile robots have emerged in the last decade. These include automated logistics handling in warehouse-like environments (in the context of e-commerce) and robot-assisted personal care. In these scenarios, there is a need for highly accurate object recognition and semantic knowledge. Also, enhanced safety requirements have come up as robots attempt to interact more with humans and make efforts to recognize their gestures and movements. Mobile robots also increasingly operate in malls and other zones which are pedestrian-rich. Thus, a need has arisen for a relook at navigation strategies for mobile robots. Classical approaches are typically inadequate in these new settings. This survey is aimed at studying the role of contemporary approaches in artificial intelligence in enabling successful robotic navigation in a variety of complex environments. In particular, we discuss how generative models, attention mechanisms and adaptive methods have helped mobile robots navigate in cluttered, uneven and even unknown indoor and outdoor environments. We also point to several interesting possibilities in the future.},
  keywords={Robots;Navigation;Attention mechanisms;Adaptation models;Mobile robots;Surveys;Robot sensing systems;Collision avoidance;Reinforcement learning;Production facilities;Mobile robot navigation;complex environments;generative adversarial networks;variational autoencoders;attention mechanisms;transformers;diffusion models;normalizing flow models;deep reinforcement learning;imitation learning;graph neural networks and knowledge graphs;current trends},
  doi={10.1109/ACCESS.2025.3590587},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10371863,
  author={Babadi, Narges and Karimipour, Hadis and Islam, Anik},
  booktitle={2023 IEEE Symposium Series on Computational Intelligence (SSCI)}, 
  title={An Ensemble Learning to Detect Decision-Based Adversarial Attacks in Industrial Control Systems}, 
  year={2023},
  volume={},
  number={},
  pages={879-884},
  abstract={An increasing number of Intrusion Detection Systems (IDSs) rely on Artificial Intelligence (AI), specifically Ma-chine Learning (ML) algorithms, to distinguish between benign and malicious data and detect cyber attacks. However, using ML algorithms exposes IDSs to Adversarial Machine Learning (AML) attacks during the training and test phase. These AML attacks aim to deceive ML algorithms by misclassifying data, posing significant disruptions to the system and its users. Two critical categories of AML attacks are White-box and Black-box attacks, with Black-box attacks being more practical and representative of real-world scenarios. This paper investigates the impact of adversarial examples on supervised ML models in IDSs and proposes an ensemble learning-based detection approach. The study uses a power system dataset and employs Random Forest, AdaBoost, and Decision Tree classifiers to achieve this. During the test phase, adversarial examples are generated using the decision boundary and HopSkipJump attacks, two types of Black-box decision-based attacks. The research applies a deep neural network to the dataset containing the generated adversarial examples to detect these AML attacks, achieving an accuracy of 98 % to 99 %.},
  keywords={Training;Machine learning algorithms;Industrial control;Closed box;Intrusion detection;Learning (artificial intelligence);Adversarial machine learning;Adversarial Machine Learning attacks;Decision-based attacks;Industrial Control Systems;Intrusion Detection systems},
  doi={10.1109/SSCI52147.2023.10371863},
  ISSN={2472-8322},
  month={Dec},}@INBOOK{11164688,
  author={Rosenthal, Kristina},
  booktitle={Finitely Presented Groups: With Applications in Post-Quantum Cryptography and Artificial Intelligence}, 
  title={Teaching Conceptual Modeling in the Age of Generative Conversational AI: Ideas for a Research Agenda}, 
  year={2024},
  volume={},
  number={},
  pages={199-208},
  abstract={As core activity in software development and organizational analysis, conceptual modeling is a learning task faced by most students of computer science, software engineering, and related programs. Advances in capabilities and increased availability of generative Artificial Intelligence (AI) technologies offer transformative potential for teaching and learning in higher education. Hence, this article elaborates on opportunities and challenges of AI technology for teaching conceptual modeling to initiate further discussion on the topic. Future research can draw upon first ideas for a research agenda to advance our knowledge on teaching conceptual modeling in the age of generative conversational AI.},
  keywords={},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9783111474274},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11164688},}@ARTICLE{10269106,
  author={Zhou, Xiaokang and Zheng, Xuzhe and Cui, Xuesong and Shi, Jiashuai and Liang, Wei and Yan, Zheng and Yang, Laurence T. and Shimizu, Shohei and Wang, Kevin I-Kai},
  journal={IEEE Journal on Selected Areas in Communications}, 
  title={Digital Twin Enhanced Federated Reinforcement Learning With Lightweight Knowledge Distillation in Mobile Networks}, 
  year={2023},
  volume={41},
  number={10},
  pages={3191-3211},
  abstract={The high-speed mobile networks offer great potentials to many future intelligent applications, such as autonomous vehicles in smart transportation systems. Such networks provide the possibility to interconnect mobile devices to achieve fast knowledge sharing for efficient collaborative learning and operations, especially with the help of distributed machine learning, e.g., Federated Learning (FL), and modern digital technologies, e.g., Digital Twin (DT) systems. Typically, FL requires a fixed group of participants that have Independent and Identically Distributed (IID) data for accurate and stable model training, which is highly unlikely in real-world mobile network scenarios. In this paper, in order to facilitate the lightweight model training and real-time processing in high-speed mobile networks, we design and introduce an end-edge-cloud structured three-layer Federated Reinforcement Learning (FRL) framework, incorporated with an edge-cloud structured DT system. A dual-Reinforcement Learning (dual-RL) scheme is devised to support optimizations of client node selection and global aggregation frequency during FL via a cooperative decision-making strategy, which is assisted by a two-layer DT system deployed in the edge-cloud for real-time monitoring of mobile devices and environment changes. A model pruning and federated bidirectional distillation (Bi-distillation) mechanism is then developed locally for the lightweight model training, while a model splitting scheme with a lightweight data augmentation mechanism is developed globally to separately optimize the aggregation weights based on a splitted neural network structure (i.e., the encoder and classifier) in a more targeted manner, which can work together to effectively reduce the overall communication cost and improve the non-IID problem. Experiment and evaluation results compared with three baseline methods using two different real-world datasets demonstrate the usefulness and outstanding performance of our proposed FRL model in communication-efficient model training and non-IID issue alleviation for high-speed mobile network scenarios.},
  keywords={Training;Data models;Real-time systems;Reinforcement learning;Knowledge engineering;Semantics;Mobile handsets;Federated learning;reinforcement learning;digital twin;knowledge distillation;lightweight training;mobile networks},
  doi={10.1109/JSAC.2023.3310046},
  ISSN={1558-0008},
  month={Oct},}@ARTICLE{10909721,
  author={Zhao, Chengjie and Wang, Jun and Peng, Qihang and Huang, Wei and Chen, Xiaonan and Zhao, Zexue and Le-Ngoc, Tho},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Deep Learning Based Transceiver Design for Additive Non-Gaussian Impulsive Noise Channels}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={This paper presents a deep-learning (DL)-based transceiver design on additive non-Gaussian impulsive noise (IN) channels. At first, an impulsive generative adversarial network (IGAN) with specific regularization terms is proposed to capture the IN behaviours and used as the channel noise simulator (CNS). Subsequently, the transmitter and receiver are jointly optimized to develop both optimal transmit signal and detection. Furthermore, to enhance the detection performance, the multi-level wavelet signal recovery network (MWSRN) is applied to construct a preprocessor to combat both IN and channel fading without pilots. Illustrative simulation results show that the proposed scheme can achieve better convergence and bit-error rate (BER) performance under different IN settings than various existing approaches.},
  keywords={Receivers;Detection algorithms;Communication systems;Gaussian noise;Computational modeling;Fading channels;Transceivers;Training;Generative adversarial networks;Discrete wavelet transforms;Non-Gaussian impulsive noise;end-to-end communication;deep learning;impulse generative adversarial net;multi-level wavelet signal recovery network},
  doi={10.1109/TCCN.2025.3547726},
  ISSN={2332-7731},
  month={},}@INPROCEEDINGS{11075322,
  author={Ko, Hsiu-Chia},
  booktitle={2025 16th International Conference on E-Education, E-Business, E-Management and E-Learning (IC4e)}, 
  title={The Impact of ChatGPT’s Interactivity on Creative Workers’ Value Perceptions and Subscription Intentions}, 
  year={2025},
  volume={},
  number={},
  pages={466-470},
  abstract={Given the high training costs of generative AI tools like ChatGPT, understanding the factors driving subscription intentions is crucial. This study examines how ChatGPT’s interactive features—perceived control, responsiveness, and personalization—affect creative workers’ perceptions of usefulness and enjoyment, ultimately shaping their subscription intentions. Grounded in utilitarian and hedonic value perspectives and leveraging ChatGPT’s transcombination capabilities—the ability to link diverse concepts and generate novel ideas—this research explores how ChatGPT addresses the unique functional and emotional needs of creative workers. Data from 148 creative workers reveal that perceived control and responsiveness significantly enhance both usefulness and enjoyment, highlighting the importance of dynamic, real-time interactivity for adaptability and immediate feedback. However, personalization has a weaker impact on usefulness and no measurable effect on enjoyment, likely due to limitations of inadequate conversational memory and difficulty processing nuanced inputs, which hinder its ability to address adaptive needs. Both usefulness and enjoyment strongly drive subscription intentions, emphasizing the need to balance functionality with emotional engagement. Practical recommendations focus on optimizing interactivity and transcombination to meet creative workers’ evolving demands.},
  keywords={Training;Electronic learning;Costs;Generative AI;Chatbots;Real-time systems;generative AI;ChatGPT;creative workers;interactivity;perceived usefulness;perceived enjoyment;subscription intentions;transcombination},
  doi={10.1109/IC4e65071.2025.11075322},
  ISSN={},
  month={April},}@INPROCEEDINGS{11103713,
  author={Russo, Silvio and Zanasi, Claudio and Colajanni, Michele},
  booktitle={2025 17th International Conference on Cyber Conflict: The Next Step (CyCon)}, 
  title={Cyber Defense Through Strategic Dynamic Deception}, 
  year={2025},
  volume={},
  number={},
  pages={227-244},
  abstract={In an interconnected digital world being enriched by smart devices, any passive solution for protecting infrastructure is doomed to fail. No matter how many defenses are implemented, attackers can infiltrate networked systems by exploiting technological or human vulnerabilities. In a scenario where the attackers have all the advantages, deception is a strategy that can slow down and divert attackers from penetrating the real infrastructure. Current platforms do create decoy environments to detect and divert threats, but attackers have developed methods to bypass these static deception systems. We propose a novel approach that is based on strategic dynamic deception where the system deceptor continuously analyzes the architecture and the traffic, and deploys credible decoy components. It leverages a combination of technologies such as virtualization, infrastructure as code, and generative AI to implement different types of decoys, such as similar system components, users, data, and network segments. The generation of small decoys should resemble the slow growth of a credible “ivy,” so that it can attract even attackers who are already circulating in the system. When cyber threats are trapped in the fake portions of the infrastructure, many countermeasures can be activated, although these are outside the scope of this paper. Here we focus on strategies and technologies that can generate and deploy dynamic deception infrastructures. Our solution paves the way toward new approaches to cybersecurity that are based on proactive strategic deception.},
  keywords={Training;Adaptation models;Codes;Generative AI;Context awareness;Complexity theory;Computer security;Virtualization;Smart devices;Context modeling;deception;virtualization;generative AI;infrastructure as code},
  doi={10.23919/CyCon65856.2025.11103713},
  ISSN={2325-5374},
  month={May},}@INPROCEEDINGS{10986494,
  author={Vishwakarma, Aryan and Panchal, Nehal and Dave, Vaibhav and Jethani, Hetal and Parashar, Deepak and Bahadure, Nilesh Bhaskarrao},
  booktitle={2025 3rd International Conference on Disruptive Technologies (ICDT)}, 
  title={Multi-Modal Glaucoma Detection Framework using Explainable AI and LLMs}, 
  year={2025},
  volume={},
  number={},
  pages={793-798},
  abstract={Glaucoma is a group of diseases that can lead to partial or complete blindness due to excessive pressure on the eyes, often caused by anxiety or depression. This pressure damages the optic nerve. The condition requires close, regular cooperation between doctors and patients over time. The increasing number of screenings and time constraints on medical practitioners can lead to errors in disease identification and treatment. Many attempts have been made to automate glaucoma screening and provide interpretability to ensure reliable and accurate solutions. A proposed multi-modal approach combines LIME and Generative AI to help medical practitioners detect glaucoma and provide explanations},
  keywords={Glaucoma;Accuracy;Biomedical optical imaging;Generative AI;Transfer learning;Predictive models;Reliability;Usability;Medical diagnostic imaging;Diseases;Glaucoma detection;Generative AI;LIME;multimodal framework;optic nerve damage},
  doi={10.1109/ICDT63985.2025.10986494},
  ISSN={},
  month={March},}@ARTICLE{10530620,
  author={Zubicueta Portales, Stephanie and Riegler, Michael Alexander},
  journal={IEEE Access}, 
  title={Maleficent Neural Networks, the Embedding of Malware in Neural Networks: A Survey}, 
  year={2024},
  volume={12},
  number={},
  pages={69753-69764},
  abstract={In this study, we address the evolving threat of Maleficent Neural Networks, also known as “Evil” Neural Networks, malicious neural networks embedded with malware. Due to the absence of effective detection mechanisms, these malicious models remain undetected, posing significant challenges to the security of users and systems in the rapidly expanding field of Artificial Intelligence and Machine Learning. This research provides a comprehensive examination of Maleficent Neural Networks, and their detection, mitigation, and security issues, based on recent foundational studies. A discussion of ethical and legal concerns surrounding the deliberate infusion of malware into neural networks is also included, emphasising the need for collaborative efforts among experts in the fields of AI, machine learning, and cyber security. The study shows that this new threat possesses several risks, and the number of works on the topic we identified confirms that more research is needed in this direction. Moreover, we propose promising future directions, including the creation of advanced adversarial defence mechanisms and the development of new methods to detect malware within neural networks.},
  keywords={Malware;Neural networks;Biological neural networks;Neurons;Search problems;Load modeling;Feature extraction;Adversarial machine learning;Computer security;Adversarial machine learning;cyber security;malware detection;neural network security},
  doi={10.1109/ACCESS.2024.3401578},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10404459,
  author={Meena, Divya and Katragadda, Harshit and Narva, Kavitha and Rajesh, Adarsh and Sheela, J},
  booktitle={2023 2nd International Conference on Automation, Computing and Renewable Systems (ICACRS)}, 
  title={Text-Conditioned Image Synthesis using TAC-GAN: A Unique Approach to Text-to-Image Synthesis}, 
  year={2023},
  volume={},
  number={},
  pages={454-462},
  abstract={Text-to-image synthesis has emerged as a pivotal domain within artificial intelligence, enabling the creation of lifelike visuals from textual descriptions. This research work introduces a novel solution to the text-to-image synthesis challenge by leveraging the Text Conditioned Auxiliary Classifier Generative Adversarial Network. The proposed TAC-GAN model is both trained and evaluated using the renowned Oxford flower dataset, a benchmark in image synthesis tasks. Notably, our TAC-GAN integrates an auxiliary classifier to ensure semantic alignment between generated images and input text descriptions. This enhancement significantly elevates the authenticity and coherence of the synthesized images, thereby enriching their overall quality. To gauge the quality and diversity of the generated images, we employ two evaluation metrics: The Inception Score and the Multi-Scale Structural Similarity (MS-SSIM) Score. The combined utilization of these metrics furnishes comprehensive insights into the perceptual excellence and structural consistency of the generated images. This holistic evaluation framework underscores the resilience and effectiveness of our approach in delivering high-quality synthesized images that faithfully correspond to textual descriptions.},
  keywords={Measurement;Visualization;Renewable energy sources;Image synthesis;Semantics;Task analysis;Resilience;Image synthesis;Text descriptor;Generative Adversarial Network;Text Conditioned Auxiliary Classifier},
  doi={10.1109/ICACRS58579.2023.10404459},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10203178,
  author={Bao, Fan and Nie, Shen and Xue, Kaiwen and Cao, Yue and Li, Chongxuan and Su, Hang and Zhu, Jun},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={All are Worth Words: A ViT Backbone for Diffusion Models}, 
  year={2023},
  volume={},
  number={},
  pages={22669-22679},
  abstract={Vision transformers (ViT) have shown promise in various vision tasks while the U-Net based on a convolutional neural network (CNN) remains dominant in diffusion models. We design a simple and general ViT-based architecture (named U-ViT) for image generation with diffusion models. U-ViT is characterized by treating all inputs including the time, condition and noisy image patches as tokens and employing long skip connections between shallow and deep layers. We evaluate U-ViT in unconditional and classconditional image generation, as well as text-to-image generation tasks, where U-ViT is comparable if not superior to a CNN-based U-Net of a similar size. In particular, latent diffusion models with U-ViT achieve record-breaking FID scores of 2.29 in class-conditional image generation on ImageNet 256×256, and 5.48 in text-to-image generation on MS-COCO, among methods without accessing large external datasets during the training of generative models. Our results suggest that, for diffusion-based image modeling, the long skip connection is crucial while the down-sampling and upsampling operators in CNN-based U-Net are not always necessary. We believe that U-ViT can provide insights for future research on backbones in diffusion models and benefit generative modeling on large scale cross-modality datasets.},
  keywords={Training;Computer vision;Image synthesis;Computational modeling;Computer architecture;Transformers;Pattern recognition;Image and video synthesis and generation},
  doi={10.1109/CVPR52729.2023.02171},
  ISSN={2575-7075},
  month={June},}@ARTICLE{10044264,
  author={Sun, Zhongchuan and Wu, Bin and Hu, Shizhe and Zhang, Mingming and Ye, Yangdong},
  journal={IEEE Transactions on Systems, Man, and Cybernetics: Systems}, 
  title={Attentive Adversarial Collaborative Filtering}, 
  year={2023},
  volume={53},
  number={7},
  pages={4064-4076},
  abstract={Generative adversarial nets (GANs) have enjoyed considerable success in computer vision and attracted much attention from recommender systems. However, due to the discrete nature of items, it is infeasible to graft GANs directly onto recommendation models. Although several methods have taken steps forward, their training processes are slow-convergent, time-consuming, or even unstable. This article proposes a novel framework named attentive adversarial collaborative filtering (AACF) and an efficient training strategy to improve GANs in recommender systems. There are two distinct novelties over previous work. First, AACF is a differentiable generative adversarial framework that introduces an attention mechanism and “virtual items” to bridge the gap between the generator and the discriminator. Owing to the intrinsic differentiability, AACF can be stably optimized with gradient descent methods. Second, the efficient training strategy substantially reduces computational complexity. It is capable of efficiently training and scaling up the AACF model to large datasets. Extensive experiments on various datasets demonstrate the effectiveness, fast convergence, stability, and scalability of AACF. Since our ideas are general in nature, they will open a path to stably and efficiently train GANs in the research areas with discrete data. The implementation code is available at https://github.com/zhongchuansun/AACF.},
  keywords={Generators;Training;Recommender systems;Computational modeling;Perturbation methods;Computer vision;Adaptation models;Adversarial training;attention mechanism;collaborative filtering (CF);recommender systems},
  doi={10.1109/TSMC.2023.3241083},
  ISSN={2168-2232},
  month={July},}@INPROCEEDINGS{10654934,
  author={Xu, Liang and Zhou, Yizhou and Yan, Yichao and Jin, Xin and Zhu, Wenhan and Rao, Fengyun and Yang, Xiaokang and Zeng, Wenjun},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={ReGenNet: Towards Human Action-Reaction Synthesis}, 
  year={2024},
  volume={},
  number={},
  pages={1759-1769},
  abstract={Humans constantly interact with their surrounding environments. Current human-centric generative models mainly focus on synthesizing humans plausibly interacting with static scenes and objects, while the dynamic human action-reaction synthesis for ubiquitous causal human-human interactions is less explored. Human-human interactions can be regarded as asymmetric with actors and reactors in atomic interaction periods. In this paper, we compre-hensively analyze the asymmetric, dynamic, synchronous, and detailed nature of human-human interactions and propose the first multi-setting human action-reaction synthe-sis benchmark to generate human reactions conditioned on given human actions. To begin with, we propose to an-notate the actor-reactor order of the interaction sequences for the NTU120, InterHuman, and Chi3D datasets. Based on them, a diffusion-based generative model with a Trans-former decoder architecture called ReGenNet together with an explicit distance-based interaction loss is proposed to predict human reactions in an online manner, where the future states of actors are unavailable to reactors. Quantitative and qualitative results show that our method can gener-ate instant and plausible human reactions compared to the baselines, and can generalize to unseen actor motions and viewpoint changes.},
  keywords={Computer vision;Computer architecture;Predictive models;Benchmark testing;Pattern recognition;Decoding;Inductors;Human Reaction Generation;Human-Human Interaction;Human Motion Generation},
  doi={10.1109/CVPR52733.2024.00173},
  ISSN={2575-7075},
  month={June},}@ARTICLE{11151773,
  author={Ren, Zhongle and Du, Zhe and Hou, Biao and Li, Weibin and Jiao, Licheng},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Self-Supervised Learning of Contrast-Diffusion Models for Land Cover Classification in SAR Images}, 
  year={2025},
  volume={63},
  number={},
  pages={1-20},
  abstract={Deep learning (DL) methods have been widely applied to synthetic aperture radar (SAR) land cover classification. The complexity of SAR data and the limited availability of labeled samples greatly constrain the feature learning and the generalization ability of the model. Inspired by the excellent generative performance of denoising diffusion probabilistic models (DDPMs) on complex data distributions, a self-supervised learning framework based on contrast-diffusion models (CDMs) is proposed to expand the applicability to multiple broad scenarios with complex and varying imaging conditions under limited annotated data conditions. Specially, the proposed framework consists of the upstream CDM pretraining on all unlabeled samples and the downstream land cover classification with few labeled samples in each test scene. Concretely, in the upstream task, the features are captured through the generative learning of the DDPM. Following this, the dimensionality reduction and resolution expansion (DRRE) module is designed and embedded to reduce feature redundancy and align the feature granularity between layers and the input image. Finally, contrastive learning is employed to enforce semantic feature consistency across different steps. In the downstream task, the feature in pretrained CDM is efficiently delivered in a single-step reverse diffusion process and then fine-tuned with few labeled samples from each test scene and finally output the predictions. Compared with several supervised and self-supervised methods, the proposed framework achieves superior classification and generalization performance on multiple broad scenes with complex and varying imaging conditions. For example, based on the average results from six test scenes, CDM shows improvements in overall accuracy (OA) of 41.42%, 34.40%, 7.70%, 8.53%, and 9.60% compared to DeepLabv3+, CCNR, SegFormer, MAE, and DDPM, respectively. The code is available at https://github.com/gosling123456/CDM.git},
  keywords={Radar polarimetry;Land surface;Noise reduction;Feature extraction;Synthetic aperture radar;Diffusion models;Imaging;Semantics;Training;Data models;Contrast learning;diffusion models;land cover classification;self-supervised learning (SSL);synthetic aperture radar (SAR)},
  doi={10.1109/TGRS.2025.3600895},
  ISSN={1558-0644},
  month={},}@ARTICLE{10814670,
  author={Zhou, Guanglin and Han, Zhongyi and Chen, Shiming and Huang, Biwei and Zhu, Liming and Liu, Tongliang and Yao, Lina and Zhang, Kun},
  journal={IEEE Transactions on Multimedia}, 
  title={HCVP: Leveraging Hierarchical Contrastive Visual Prompt for Domain Generalization}, 
  year={2025},
  volume={27},
  number={},
  pages={1142-1152},
  abstract={Domain Generalization (DG) endeavors to create machine learning models that excel in unseen scenarios by learning invariant features. In DG, the prevalent practice of constraining models to a fixed structure or uniform parameterization to encapsulate invariant features can inadvertently blend specific aspects. Such an approach struggles with nuanced differentiation of inter-domain variations and may exhibit bias towards certain domains, hindering the precise learning of domain-invariant features. Recognizing this, we introduce a novel method designed to supplement the model with domain-level and task-specific characteristics. This approach aims to guide the model in more effectively separating invariant features from specific characteristics, thereby boosting the generalization. Building on the emerging trend of visual prompts in the DG paradigm, our work introduces the novel Hierarchical Contrastive Visual Prompt (HCVP) methodology. This represents a significant advancement in the field, setting itself apart with a unique generative approach to prompts, alongside an explicit model structure and specialized loss functions. Differing from traditional visual prompts that are often shared across entire datasets, HCVP utilizes a hierarchical prompt generation network enhanced by prompt contrastive learning. These generative prompts are instance-dependent, catering to the unique characteristics inherent to different domains and tasks. Additionally, we devise a prompt modulation network that serves as a bridge, effectively incorporating the generated visual prompts into the vision transformer backbone. Experiments conducted on five DG datasets demonstrate the effectiveness of HCVP, outperforming both established DG algorithms and adaptation protocols.},
  keywords={Visualization;Tuning;Electronic mail;Contrastive learning;Context modeling;Adaptation models;Skin;Protocols;Mutual information;Modulation;Domain generalization;visual prompt;contrastive learning},
  doi={10.1109/TMM.2024.3521719},
  ISSN={1941-0077},
  month={},}@ARTICLE{9829336,
  author={Zhou, Bo and Lv, Yuqian and Wang, Jinhuan and Zhang, Jian and Xuan, Qi},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Attacking the Core Structure of Complex Network}, 
  year={2023},
  volume={10},
  number={4},
  pages={1428-1442},
  abstract={The concept of  $k$ -core in complex networks plays a key role in many applications, e.g., understanding the global structure or identifying central/critical nodes, of a network. A malicious attacker with a jamming ability can exploit the vulnerability of the  $k$ -core structure to attack the network and invalidate the network analysis methods, e.g., reducing the  $k$ -shell values of nodes can deceive graph algorithms, leading to the wrong decisions. In this article, we investigate the robustness of the  $k$ -core structure under adversarial attacks by deleting edges, for the first time. First, we give the general definition of the targeted  $k$ -core attack, map it to the set cover problem, which is NP-hard, and further introduce a series of evaluation metrics to measure the performance of attack methods. Then, we propose the  $Q$  index theoretically as the probability that the terminal node of an edge does not belong to the innermost core, which is further used to guide the design of our heuristic attack methods, namely, COREATTACK and GreedyCOREATTACK. The experiments on a variety of real-world networks demonstrate that our methods behave much better than a series of baselines, in terms of much smaller edge change rate (ECR) and false attack rate (FAR), achieving state-of-the-art attack performance. More impressively, for certain real-world networks, only deleting one edge from the  $k$ -core may lead to the collapse of the innermost core, even if this core contains dozens of nodes. Such a phenomenon indicates that the  $k$ -core structure could be extremely vulnerable under adversarial attacks, and its robustness, thus, should be carefully addressed to ensure the security of many graph algorithms. An open-source implementation is available at https://github.com/Yocenly/COREATTACCK.},
  keywords={Robustness;Minimization;Security;Complexity theory;COVID-19;Machine learning;Social networking (online);Data mining;Artificial intelligence;Open source software;Network analyzers;Generative adversarial networks;Graph theory;Adversarial attack;AI security;graph data mining;k-core decomposition;network science;social network;structural robustness},
  doi={10.1109/TCSS.2022.3188522},
  ISSN={2329-924X},
  month={Aug},}@INPROCEEDINGS{11092120,
  author={Pan, Feng and Zhou, Qiyun and Guo, Weitong and Yang, Hongwu},
  booktitle={2025 7th International Conference on Computer Science and Technologies in Education (CSTE)}, 
  title={A Survey on Retrieval-Augmented Generation in Applications of Education and Teaching}, 
  year={2025},
  volume={},
  number={},
  pages={803-807},
  abstract={Retrieval-augmented generation (RAG) seamlessly combines information retrieval with generative artificial intelligence, allowing large language models (LLMs) to enhance the accuracy and relevance of responses by dynamically retrieving and integrating contextual knowledge from external databases. In education, RAG holds transformative potential, facilitating personalized learning path recommendations, automated question-answering systems, knowledge retrieval, generation of teaching resources, and adaptive evaluation frameworks. Its strengths, such as efficiency, precision, personalization, and interactivity, streamline the acquisition and utilization of educational resources, ultimately fostering improved pedagogical outcomes. Nonetheless, several challenges remain, such as integrating interdisciplinary knowledge, addressing generative hallucinations, and navigating ethical considerations in data usage. Future advancements are expected to concentrate on precision teaching support, adaptive learning ecosystems, data-driven educational governance, and specialized applications in areas like vocational training and inclusive education. RAG is positioned to reshape educational practices by addressing technical and pedagogical barriers and promoting equitable access and personalized learning experiences in an evolving digital landscape.},
  keywords={Surveys;Ethics;Navigation;Generative AI;Large language models;Education;Retrieval augmented generation;Ecosystems;Vocational training;Information retrieval;Intelligence education;Retrieval-augmented generation;Large language model;Educational application},
  doi={10.1109/CSTE64638.2025.11092120},
  ISSN={},
  month={April},}@INPROCEEDINGS{9308378,
  author={Delarosa, Omar and Soros, L. B.},
  booktitle={2020 IEEE Symposium Series on Computational Intelligence (SSCI)}, 
  title={Growing MIDI Music Files Using Convolutional Cellular Automata}, 
  year={2020},
  volume={},
  number={},
  pages={1187-1194},
  abstract={This paper describes a novel generative system based on cellular automata (CA). The main contribution of this work is CARLA, a Cellular Automata Rule Learning Algorithm that learns CA update rules with lower computational overhead (i.e. a smaller neural architecture) than other current approaches. A formal model is developed, situating the algorithm in terms of machine learning. The algorithm is then validated on the 256 possible elementary cellular automata rules. Next, the CARLA algorithm is incorporated into a larger generative system that learns musical patterns by transforming MIDI-encoded music into cellular automata. A novel postprocessing algorithm called Tendril is then developed and integrated with CARLA. This system is then used to generate a novel MIDI composition based partially on update rules learned from Chopin's Waterfall Étude, demonstrating the utility of this new algorithm for creative applications.},
  keywords={Learning automata;Kernel;Complexity theory;Markov processes;Convolution;Computational modeling;Music;Cellular automata;generative music;convolutional architecture},
  doi={10.1109/SSCI47803.2020.9308378},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9624788,
  author={Yang, Hanxuan and Kong, Qingchao and Mao, Wenji and Wang, Lei},
  booktitle={2021 IEEE International Conference on Intelligence and Security Informatics (ISI)}, 
  title={Boosting Hidden Graph Node Classification for Large Social Networks}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Identifying hidden nodes in social networks is a critical issue in security-related applications. In contrast to the conventional node classification on graphs with all nodes being observable, it is more challenging to classify the hidden nodes that are unobservable during the training process, also known as the “inductive learning” in previous research. Existing approaches for inductive node classification mainly adopt graph neural network models to learn node representations. Although these methods are advantageous to modeling the topology of graph-structured data, they rely heavily on node features which may vary significantly in different specific application scenarios. In addition, the inherently changeable graph structure induced by hidden nodes may cause the over-fitting problem. To address the above issues and boost the performances of hidden node classification, we propose a deep generative model based on variational auto-encoders. Specifically, we design a novel graph neural network to aggregate the multi-hop neighbor information of each node. Meanwhile, to better utilize the graph structure information as a supplement to node features, we consider the heterogeneous node influences and introduce a gated attention mechanism using node degrees. Moreover, our proposed model can be trained by minibatches and thus is applicable to large social networks. We conduct experiments on four real-world datasets, and verify the effectiveness of our method for hidden graph node classification.},
  keywords={Training;Representation learning;Social networking (online);Network topology;Spread spectrum communication;Logic gates;Graph neural networks;hidden node classification;graph representation learning;inductive learning;variational auto-encoder;cross-graph network},
  doi={10.1109/ISI53945.2021.9624788},
  ISSN={},
  month={Nov},}@ARTICLE{10423646,
  author={Ferrag, Mohamed Amine and Ndhlovu, Mthandazo and Tihanyi, Norbert and Cordeiro, Lucas C. and Debbah, Merouane and Lestable, Thierry and Thandi, Narinderjit Singh},
  journal={IEEE Access}, 
  title={Revolutionizing Cyber Threat Detection With Large Language Models: A Privacy-Preserving BERT-Based Lightweight Model for IoT/IIoT Devices}, 
  year={2024},
  volume={12},
  number={},
  pages={23733-23750},
  abstract={The field of Natural Language Processing (NLP) is currently undergoing a revolutionary transformation driven by the power of pre-trained Large Language Models (LLMs) based on groundbreaking Transformer architectures. As the frequency and diversity of cybersecurity attacks continue to rise, the importance of incident detection has significantly increased. IoT devices are expanding rapidly, resulting in a growing need for efficient techniques to autonomously identify network-based attacks in IoT networks with both high precision and minimal computational requirements. This paper presents SecurityBERT, a novel architecture that leverages the Bidirectional Encoder Representations from Transformers (BERT) model for cyber threat detection in IoT networks. During the training of SecurityBERT, we incorporated a novel privacy-preserving encoding technique called Privacy-Preserving Fixed-Length Encoding (PPFLE). We effectively represented network traffic data in a structured format by combining PPFLE with the Byte-level Byte-Pair Encoder (BBPE) Tokenizer. Our research demonstrates that SecurityBERT outperforms traditional Machine Learning (ML) and Deep Learning (DL) methods, such as Convolutional Neural Networks (CNNs) or Recurrent Neural Networks (RNNs), in cyber threat detection. Employing the Edge-IIoTset cybersecurity dataset, our experimental analysis shows that SecurityBERT achieved an impressive 98.2% overall accuracy in identifying fourteen distinct attack types, surpassing previous records set by hybrid solutions such as GAN-Transformer-based architectures and CNN-LSTM models. With an inference time of less than 0.15 seconds on an average CPU and a compact model size of just 16.7MB, SecurityBERT is ideally suited for real-life traffic analysis and a suitable choice for deployment on resource-constrained IoT devices.},
  keywords={Threat assessment;Internet of Things;Encoding;Transformers;Data models;Computer architecture;Natural language processing;Bit error rate;Generative adversarial networks;Artificial intelligence;Cyber threat detection;IoT networks;generative AI;BERT;large language models},
  doi={10.1109/ACCESS.2024.3363469},
  ISSN={2169-3536},
  month={},}@ARTICLE{1629080,
  author={Jiann-Ming Wu and Zheng-Han Lin and Hsu, P.-H.},
  journal={IEEE Transactions on Neural Networks}, 
  title={Function approximation using generalized adalines}, 
  year={2006},
  volume={17},
  number={3},
  pages={541-558},
  abstract={This paper proposes neural organization of generalized adalines (gadalines) for data driven function approximation. By generalizing the threshold function of adalines, we achieve the K-state transfer function of gadalines which responds a unitary vector of K binary values to the projection of a predictor on a receptive field. A generative component that uses the K-state activation of a gadaline to trigger K posterior independent normal variables is employed to emulate stochastic predictor-oriented target generation. The fitness of a generative component to a set of paired data mathematically translates to a mixed integer and linear programming. Since consisting of continuous and discrete variables, the mathematical framework is resolved by a hybrid of the mean field annealing and gradient descent methods. Following the leave-one-out learning strategy, the obtained learning method is extended for optimizing multiple generative components. The learning result leads to parameters of a deterministic gadaline network for function approximation. Numerical simulations further test the proposed learning method with paired data oriented from a variety of target functions. The result shows that the proposed learning method outperforms the MLP and RBF learning methods for data driven function approximation},
  keywords={Function approximation;Transfer functions;Learning systems;Neural networks;Stochastic processes;Annealing;Encoding;Cost function;Design optimization;Computer science;Adalines;generative models;mean field annealing;perceptron;postnonlinear projection;potts encoding;supervised learning},
  doi={10.1109/TNN.2006.873284},
  ISSN={1941-0093},
  month={May},}@ARTICLE{10285546,
  author={Liu, Qi and Yang, Zhiyun and Ji, Ru and Zhang, Yonghong and Bilal, Muhammad and Liu, Xiaodong and Vimal, S. and Xu, Xiaolong},
  journal={IEEE Systems, Man, and Cybernetics Magazine}, 
  title={Deep Vision in Analysis and Recognition of Radar Data: Achievements, Advancements, and Challenges}, 
  year={2023},
  volume={9},
  number={4},
  pages={4-12},
  abstract={Radars are widely used to obtain echo information for effective prediction, such as precipitation nowcasting. In this article, recent relevant scientific investigation and practical efforts using deep learning (DL) models for weather radar data analysis and pattern recognition have been reviewed. In addition, this work presents and discusses recent achievements, as well as recent developments and existing problems, in an attempt to establish plausible potentials and trends in this highly concerned field, particularly, in the fields of beam blockage correction, radar echo extrapolation, and precipitation nowcast. Compared to traditional approaches, present DL methods depict better performance and convenience but suffer from stability and generalization.},
  keywords={Deep learning;Meteorological radar;Extrapolation;Precipitation;Data analysis;Market research;Stability analysis;Artificial intelligence;Weather forecasting;Predictive models;Social Internet of Things},
  doi={10.1109/MSMC.2022.3216943},
  ISSN={2333-942X},
  month={Oct},}@ARTICLE{11080483,
  author={Liu, Fang and Yin, Kanghua and Liu, Jia and Yang, Jingxiang and Tang, Xu and Xiao, Liang},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Box2Change: A Novel Weakly Supervised Way for Change Detection via Consistency Instance Segmentation}, 
  year={2025},
  volume={63},
  number={},
  pages={1-16},
  abstract={Change detection in remote sensing images aims at revealing interesting changes about the Earth surface and has been one of the most important issues in Earth observation. In recent years, lots of fully supervised change detection methods have achieved good performance with the help of deep learning architectures, which rely on large amounts of pixel-level labels. However, obtaining high-quality pixel-level labels is laborious and expensive. To alleviate this problem, we propose a novel weakly supervised change detection way via consistency instance segmentation called Box2Change, which requires only box-level labels and achieves competitive results to a fully supervised change detection method. Compared with pixel-level label, it is much more efficient to get box-level label, which locates the potential changed area by a rectangle box. There are two key components in the proposed method: the changed instance segmentation (CIS) and the self-supervised consistency learning (SSCL) in affine space. The former generates multiscale changed instances, which learns positional information from box-level labels and segment the instance boundaries within a given bounded region. The latter introduces affine transform and employs consistency constraints in a self-supervised manner to increase the robustness to pseudo-change situations caused by light or noise. In experiments, three popular public change detection datasets are tested, and both visual and numerical assessments are discussed, where the proposed method exhibits competitive performance to fully supervised methods and achieves the state-of-the-art results compared with the other weakly supervised change detection methods.},
  keywords={Feature extraction;Annotations;Labeling;Remote sensing;Instance segmentation;Costs;Accuracy;Semantics;Training;Artificial intelligence;Change detection;instance segmentation;remote sensing;self-supervised learning;weakly supervised learning},
  doi={10.1109/TGRS.2025.3589090},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{11084627,
  author={Zhu, Linghui and Li, Yiming and Weng, Haiqin and Liu, Yan and Xia, Shu-Tao and Wang, Zhi},
  booktitle={2025 IEEE International Conference on Image Processing (ICIP)}, 
  title={Anti-FT: Towards Practical Deep Leakage From Gradients}, 
  year={2025},
  volume={},
  number={},
  pages={2606-2611},
  abstract={Federated learning is usually regarded as a privacy-preserving training paradigm for it enables multiple clients to participate in a training task without sharing their private data. However, recent studies revealed that a malicious server can still recover private data from the victim clients based on the shared gradients via deep leakage from gradients (DLG). Currently, almost all DLG attacks are designed based on the average loss, leading to a significant decrease in attack efficiency when the batch size is greater than 1. In this paper, we revisit DLG attacks from the perspective of the loss function. We reveal that not all samples in the target batch are equally susceptible to DLG attacks: the sample with the highest loss value tends to be easily recovered by DLG attacks. Based on these observations, we propose a simple yet effective DLG method under practical FL settings. Specifically, the adversaries can enhance the effectiveness of DLG by perturbing the global model through finetuning it with a few mislabeled samples (dubbed ‘Anti-FT’). Extensive experiments are conducted on benchmark datasets, which verify the effectiveness of our method and its resistance to potential defenses. The codes are available at https://github.com/zlh-thu/anti-finetune.},
  keywords={Training;Resistance;Codes;Federated learning;Image processing;Benchmark testing;Robustness;Servers;Security;Artificial intelligence;Deep Leakage from Gradients;Federated Learning;Trustworthy ML;AI Security},
  doi={10.1109/ICIP55913.2025.11084627},
  ISSN={2381-8549},
  month={Sep.},}@ARTICLE{10965355,
  author={Zhang, Yushu and Yang, Zixuan and Wang, Tao and Hua, Zhongyun and Weng, Jian},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={Tailor-Made Face Privacy Protection via Class-Wise Targeted Universal Adversarial Perturbations}, 
  year={2025},
  volume={22},
  number={5},
  pages={5108-5120},
  abstract={The widespread application of face recognition poses unprecedented threats to individual privacy, as face images can be easily and stealthily analyzed. Efforts have been made to employ adversarial perturbations to disrupt the automatic inference of unauthorized face recognition systems. However, existing schemes fail to satisfy the personalized protection requirements of individuals, which may diminish the user experience. In this article, we propose a novel scheme that provides tailor-made face privacy protection for individuals via class-wise targeted universal adversarial perturbations (CT-UAPs). In our scheme, each individual can utilize a user-specific CT-UAP to exclusively generate protected faces whose identification outputs are a virtual identity predefined by themselves. For the generation of CT-UAPs, we develop an optimization-based method that guides the feature vectors of the protected faces to approach the class-wise feature space of the predefined virtual identity while simultaneously approaching that of the original identity. Extensive experiment results demonstrate the effectiveness of our scheme against five face recognition models. In addition, the interpretability of CT-UAPs is highlighted by the experimental results obtained through two-dimensional principal component analysis.},
  keywords={Face recognition;Protection;Perturbation methods;Privacy;Faces;Vectors;Training;Social networking (online);Artificial intelligence;Threat modeling;Face privacy;adversarial perturbations;tailor-made protection},
  doi={10.1109/TDSC.2025.3561162},
  ISSN={1941-0018},
  month={Sep.},}@INPROCEEDINGS{11101357,
  author={Prakash, Krishna and Mitra, Nimmagaddda Vatsalya and Kumar, Nallamothu Pavan and Babu, Manda Anji and Bansal, Shonak and Kumar, Sandeep},
  booktitle={2025 International Conference on Electronics, AI and Computing (EAIC)}, 
  title={Secure Online Voting System-Based on Facial Recognition by using Deep Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Corporate elections, in general, suffer from limitations of traditional in-person and paper-based voting security vulnerabilities, inefficiencies, and logistical constraints. To counter these limitations, this paper recommends a secure online voting system specially designed for the corporate environment with the integration of advanced technologies, such as computer vision, deep learning, and OTP-based authentication, to make the voter verification process robust and tamper proof. With the use of distinct employee identification, for instance, employee ID, or biometric credentials, this model allows access and participation by only the registered employees to ensure that no fraudulent activities occur as well as unapproved access. Employees can securely vote from anywhere with access being allowed. It has the implementation of Haar Cascades for quick facial detection and Convolutional Neural Networks for accurate facial verification, thus yielding a very high accuracy of 98%. Secure authentication along with real-time vote verification helps improve transparency, trust, and security in corporate governance. It provides a scalable and efficient solution for modern corporate elections while offering a new benchmark in digital voting technology.},
  keywords={Deep learning;Accuracy;Face recognition;Authentication;Real-time systems;Security;Convolutional neural networks;Stakeholders;Electronic voting;Artificial intelligence;Corporate Voting;Security;Computer Vision;Deep Learning;Haar Cascades;CNN},
  doi={10.1109/EAIC66483.2025.11101357},
  ISSN={},
  month={June},}@INPROCEEDINGS{9750464,
  author={Jia, Yetao and Zhuang, Honglin and Lin, Zhechao and Meng, Yangyang},
  booktitle={2021 IEEE Sixth International Conference on Data Science in Cyberspace (DSC)}, 
  title={Machine Learning for Software Vulnerability Analysis: A Survey}, 
  year={2021},
  volume={},
  number={},
  pages={396-402},
  abstract={With the development of artificial intelligence technology, some researchers have tried to apply machine learning, deep learning, and other algorithms in the field of vulnerability analysis, and achieved certain results. This paper reviews the research status of software vulnerability analysis. We summarize the traditional vulnerability analysis methods at first, including dynamic vulnerability analysis and static vulnerability analysis. Then we analyze the research progress of intelligent vulnerability analysis methods based on machine learning, point out the existing problems and future research directions.},
  keywords={Deep learning;Machine learning algorithms;Heuristic algorithms;Conferences;Software algorithms;Cyberspace;Data science;software vulnerability analysis;machine learning;deep learning},
  doi={10.1109/DSC53577.2021.00062},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10925100,
  author={Chen, Zhong and Xie, Anming and Wang, Robert},
  booktitle={2024 IEEE Smart World Congress (SWC)}, 
  title={An Edu-Metaverse Service Platform and its Experiments on Physical Education Class in PKU}, 
  year={2024},
  volume={},
  number={},
  pages={40-46},
  abstract={In the digital era, it is the only way for high-quality education to integrate the new generation of information technology with traditional education, promote the Digital transformation of education, and build a networked, digital, personalized, lifelong education system. This paper firstly introduces the concepts with Metaverse and its involvement toward Web3.0 as well as Generative AI. Then come with an Edu-Metaverse Service and its impact on the future education. Edu-Metaverse service would effectively support the “student-centered” education model, and drive profound changes in education scenes, education content, roles and responsibilities, teaching evaluation and other aspects. Finally, a pilot practice combine Edu-Metaverse Service platform with Physical Education in Peking University was introduced and some issues were discussed.},
  keywords={Training;Solid modeling;Humanities;Metaverse;Generative AI;Digital transformation;Education;Internet;Information technology;Sports;metaverse;Education digital transformation;Edu-Metaverse services;PE class},
  doi={10.1109/SWC62898.2024.00036},
  ISSN={2993-396X},
  month={Dec},}@ARTICLE{10342623,
  author={Bhatia, Himesh and Paul, William and Alajaji, Fady and Gharesifard, Bahman and Burlina, Philippe},
  journal={Neural Computation}, 
  title={Least kth-Order and Rényi Generative Adversarial Networks}, 
  year={2021},
  volume={33},
  number={9},
  pages={2473-2510},
  abstract={We investigate the use of parameterized families of information-theoretic measures to generalize the loss functions of generative adversarial networks (GANs) with the objective of improving performance. A new generator loss function, least kth-order GAN (LkGAN), is introduced, generalizing the least squares GANs (LSGANs) by using a kth-order absolute error distortion measure with k≥1 (which recovers the LSGAN loss function when k=2). It is shown that minimizing this generalized loss function under an (unconstrained) optimal discriminator is equivalent to minimizing the kth-order Pearson-Vajda divergence. Another novel GAN generator loss function is next proposed in terms of Rényi cross-entropy functionals with order α>0, α≠1. It is demonstrated that this Rényi-centric generalized loss function, which provably reduces to the original GAN loss function as α→1, preserves the equilibrium point satisfied by the original GAN based on the Jensen-Rényi divergence, a natural extension of the Jensen-Shannon divergence. Experimental results indicate that the proposed loss functions, applied to the MNIST and CelebA data sets, under both DCGAN and StyleGAN architectures, confer performance benefits by virtue of the extra degrees of freedom provided by the parameters k and α, respectively. More specifically, experiments show improvements with regard to the quality of the generated images as measured by the Fréchet inception distance score and training stability. While it was applied to GANs in this study, the proposed approach is generic and can be used in other applications of information theory to deep learning, for example, the issues of fairness or privacy in artificial intelligence.},
  keywords={},
  doi={10.1162/neco_a_01416},
  ISSN={0899-7667},
  month={Aug},}@ARTICLE{9268942,
  author={Yang, Wonseok and Nam, Woochul},
  journal={IEEE Access}, 
  title={Brainwave Classification Using Covariance-Based Data Augmentation}, 
  year={2020},
  volume={8},
  number={},
  pages={211714-211722},
  abstract={A brain–machine interface (BMI) is a technology that controls machines via brainwaves. In BMI, the performance of brainwave analysis is very important for achieving machine control that reflects the user’s intention. One of the main obstacles in this analysis is an insufficient amount of data points because long-term brain signal experiments tend to reduce data quality. Data augmentation methods can be used to overcome this limitation. Recently, several neural network-based data augmentation methods have been developed. However, those methods have several limitations; first, they require considerable computation time because a very large number of parameters must be obtained. Moreover, the neural network based method can suffer from unstable training, which results in quality degradation of artificial data. To address these problems, this paper introduces a method that generates an artificial dataset which has correlation of feature similar to the original dataset. Specifically, after decomposing the covariance matrix for the features into a lower triangular matrix, an artificial dataset can be generated by multiplying the lower triangular matrix by random variables. This method is computationally fast, and the augmentation is stable. When the brainwave data were augmented using this method, classification performance was improved by 1.08%–6.72%. This method focuses on mean, correlation, and not taking into account the other statistical parameters. Since it rapidly generates a large dataset, it can also be useful in other applications.},
  keywords={Covariance matrices;Training;Classification algorithms;Correlation;Gallium nitride;Tongue;Task analysis;Artificial data;brain–machine interface;classification accuracy;covariance matrix;data augmentation},
  doi={10.1109/ACCESS.2020.3040286},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9879680,
  author={Zaheer, M. Zaigham and Mahmood, Arif and Khan, M. Haris and Segu, Mattia and Yu, Fisher and Lee, Seung-Ik},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Generative Cooperative Learning for Unsupervised Video Anomaly Detection}, 
  year={2022},
  volume={},
  number={},
  pages={14724-14734},
  abstract={Video anomaly detection is well investigated in weakly-supervised and one-class classification (OCC) settings. However, unsupervised video anomaly detection methods are quite sparse, likely because anomalies are less frequent in occurrence and usually not well-defined, which when coupled with the absence of ground truth supervision, could adversely affect the performance of the learning algorithms. This problem is challenging yet rewarding as it can completely eradicate the costs of obtaining laborious annotations and enable such systems to be deployed without human intervention. To this end, we propose a novel unsupervised Generative Cooperative Learning (GCL) approach for video anomaly detection that exploits the low frequency of anomalies towards building a cross-supervision between a generator and a discriminator. In essence, both networks get trained in a cooperative fashion, thereby allowing unsupervised learning. We conduct extensive experiments on two large-scale video anomaly detection datasets, UCF crime and ShanghaiTech. Consistent improvement over the existing state-of-the-art unsupervised and OCC methods corroborate the effectiveness of our approach.},
  keywords={Training;Computer vision;Costs;Annotations;Machine vision;Manuals;Generators;Self-& semi-& meta- Vision applications and systems},
  doi={10.1109/CVPR52688.2022.01433},
  ISSN={2575-7075},
  month={June},}@ARTICLE{10228188,
  author={Qiao, Junfei and Yang, Ruyue and Wang, Ding},
  journal={IEEE Transactions on Automation Science and Engineering}, 
  title={Offline Data-Driven Adaptive Critic Design With Variational Inference for Wastewater Treatment Process Control}, 
  year={2024},
  volume={21},
  number={4},
  pages={4987-4998},
  abstract={Wastewater treatment is indispensable to the functioning of urban society, and its optimal control has enormous social benefits. However, precise modelling of the unstable and complex treatment process is challenging yet crucial to the adaptive dynamic programming method. In this article, an adaptive critic algorithm with variational inference is designed to address the optimal control problem of nonlinear discrete-time systems, along with the convergence analysis. Based on the recorded system trajectory, the variational autoencoder is utilized to approximate the behavior policy of the offline dataset without system modelling and online interaction. Through policy iteration learning, the actor-critic structure can amend the policy generated by the variational autoencoder to achieve the optimal control objective. Simulations on a nonlinear system and the wastewater treatment process have verified that the proposed approach outperformed the behavior policy. Driven by the wastewater treatment process data derived from the incremental proportional-integral-derivative controller, the proposed approach can produce an optimal control policy of less tracking error and cost. Note to Practitioners—When dealing with an unknown system with complex dynamics, it is more feasible to improve the acceptable performance of the existing control policy based on the system’s trajectory than to obtain an excelling policy. Motivated by batch reinforcement learning, learning from offline data can avoid the online interaction between the system and the adaptive dynamic programming algorithm, which could lead to exploratory errors during online learning. Specifically, using a model-free adaptive dynamic programming algorithm, the parameters of the controller are instantly updated based on the experience replay buffer sampled from the online trajectory data. However, online exploration determines the update, and there is no guarantee that the system will converge every time. As a specific type of adaptive dynamic programming algorithm, adaptive critic design uses a critic network to approximate the expected future cost and an actor network to generate a control input that minimizes the expected future cost. In this article, using the converged trajectory as the offline dataset, a revised variational autoencoder is used to approximate the behavior policy of the offline dataset. As a generative model, the variational autoencoder considers a random variable that adheres to a prior distribution while producing outputs. Through offline learning, the actor network can amend the approximated policy based on the evaluation from the critic network while being constrained within the limited variation of the generative model. Finally, the objective of the optimal control task can be achieved by following the designated cost design. However, a dataset containing disturbances could impede offline learning, which needs to be addressed.},
  keywords={Wastewater treatment;Optimal control;Dynamic programming;Trajectory;Reinforcement learning;Adaptive algorithms;Data models;Adaptive dynamic programming;offline reinforcement learning;data-driven control;variational autoencoder;wastewater treatment},
  doi={10.1109/TASE.2023.3305615},
  ISSN={1558-3783},
  month={Oct},}@ARTICLE{10400867,
  author={Yu, Kaiwen and He, Qi and Wu, Gang},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={Two-Way Semantic Communications Without Feedback}, 
  year={2024},
  volume={73},
  number={6},
  pages={9077-9082},
  abstract={Semantic communications can significantly improve transmission efficiency, especially in the low signal-to-noise (SNR) regime. However, two-way semantic communications still remain an unexplored topic, which is a critical issue in many machine communication scenarios. Simply extending existing semantic communication systems to the two-way situation requires bidirectional information feedback during the training process, resulting in significant communication overhead. To fill this gap, we investigate a two-way semantic communication (TW-SC) system, where the information feedback can be omitted by exploiting the weight reciprocity in the transceiver. Particularly, the channel simulator and semantic transceiver are implemented on both TW-SC nodes and the channel distribution is modeled by a conditional generative adversarial network. Simulation results demonstrate that the proposed TW-SC system performs closing to the state-of-the-art one-way semantic communication systems but requiring no feedback between the transceiver in training process.},
  keywords={Semantics;Training;Transmitters;Receivers;Wireless communication;Generators;Artificial neural networks;Semantic communications;deep learning;joint source-channel coding},
  doi={10.1109/TVT.2024.3352666},
  ISSN={1939-9359},
  month={June},}@INPROCEEDINGS{10748883,
  author={Niraula, Nobal and Ayhan, Samet and Chidambaram, Balaguruna and Whyatt, Daniel},
  booktitle={2024 AIAA DATC/IEEE 43rd Digital Avionics Systems Conference (DASC)}, 
  title={Multi-Label Classification with Generative Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Multi-label classification is a supervised Machine Learning problem, which can assign zero or more mutually non-exclusive class labels for an instance. It is different from the multi-class classification which assigns exactly one class label out of many predefined class labels for an instance. In this paper, we explore both proprietary and open-source generative Large Language Models (LLMs) for multi-label classification problems. Specifically, we fine-tune these LLMs and provide insights into their behaviors with different prompts and training constraints such as few-shots settings in Aviation Safety and Autonomy domains. We provide recommendations of choosing LLMs for multi-label classifications.},
  keywords={Training;Large language models;Supervised learning;Training data;Aerospace electronics;Data models;Safety;Multi-label Classification;Natural language pro- cessing;Large Language Models;Machine learning},
  doi={10.1109/DASC62030.2024.10748883},
  ISSN={2155-7209},
  month={Sep.},}@INPROCEEDINGS{10910360,
  author={S, Kanimozhi and YS, Sriker and Vasan, Vinod},
  booktitle={2024 IEEE Silchar Subsection Conference (SILCON 2024)}, 
  title={Explorative Deployment of Fine-Tuned Large Language Model for On-Site Computerized Numeric Control Machine Operator Assistance}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In a dynamic workshop environment focused on optimal machine utilization and minimal downtime, it is imperative that a greater emphasis is laid on the tools required to localize faults in essential equipment on the shop floor. One of the major detractors of productivity is the requirement of repeatedly cross-referencing equipment user manuals, consulting consumer portals, and acquiring trained personnel for assistance. This presents an opportunity to blend the intelligence of AI with an emphasis on simplicity of use in a machine shop. CNCGPT is a fine-tuned LLM (Large Language Model) that aims to address machine specific queries that conventional LLM models currently deployed en masse may not be able to ascertain. This model has been tailored to serve as a companion for operators on the shop floor, providing consistent, high-quality responses without tiring. This study aims to present an overview of the model's architecture and an account of a real-time operational assessment conducted during the deployment of the model for assistance with the operation of a specific CNC machine.},
  keywords={Training;Accuracy;Translation;Computational modeling;Generative Pre-trainer transformer;Transformers;Real-time systems;Numerical models;Time factors;Tuning;Generative Pre-trained Transformer (GPT);Large Language Model (LLM);Model Fine Tuning;Computerized Numeric Control (CNC);Operational Companion;User Assistance},
  doi={10.1109/SILCON63976.2024.10910360},
  ISSN={},
  month={Nov},}
