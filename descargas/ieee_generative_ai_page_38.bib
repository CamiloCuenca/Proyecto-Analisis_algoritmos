@INPROCEEDINGS{10724645,
  author={Karlapalam, Jaithra Sarma and Joshi, Priyam and Khuba, Riya and Bhattacharya, Shourjyo and Lalitha, S.},
  booktitle={2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={An Ethical Framework for Advancing Music Composition through Generative Model}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Navigating the intersection of artificial intelligence and music, this work delves into the application of Generative Adversarial Networks (GANs) for jazz music composition. The GAN architecture, comprising a Generator and a Discriminator, is harnessed to produce original music from a jazz-specific Musical Instrument Digital Interface (MIDI) dataset. The Generator learns intricate patterns within the MIDI note rang, incorporating controlled randomness through noise, The MIDI to audio conversion is facilitated by Timidity, while pre-processing techniques include Interquartile range (IQR), box plots and cumulative distribution plots which contribute to refining the generated samples. This is done to analyze the AI capacity in the domain of music generation. It was observed after 15 epoch iterations that the accuracy turned out to be 92 percent, while still being prone to hyperparameter tuning. This process of hyperparameter tuning was carried out after multiple trial and errors to achieve this accuracy. This works provides a significant potential in the field for future research of AI generated music.},
  keywords={Ethics;Accuracy;Navigation;Musical instrument digital interfaces;Noise;Refining;Generative adversarial networks;Generators;Artificial intelligence;Tuning;Discriminator;Generator;Interquartile range (IQR);Signal to Noise ratio (SNR);Tokenization},
  doi={10.1109/ICCCNT61001.2024.10724645},
  ISSN={2473-7674},
  month={June},}@INPROCEEDINGS{10932524,
  author={Haneef, Farhan and M, Varalakshmi and P U, Peer Mohamed},
  booktitle={2025 2nd International Conference on Computational Intelligence, Communication Technology and Networking (CICTN)}, 
  title={Leveraging RAG for Effective Prompt Engineering in Job Portals}, 
  year={2025},
  volume={},
  number={},
  pages={717-721},
  abstract={Traditional recruitment methods are time-consuming and heavily reliant on manual processes, leading to inefficiencies. This paper explores the integration of AI technologies into a job portal to streamline the hiring process, focusing on AI’s ability to automatically parse and extract information from resumes and job descriptions to match candidates with relevant job opportunities. The platform leverages Large Language Models (LLMs) to extract key information, such as skills, education, and work experience, from both resumes and job descriptions. Fine-tuning through prompt engineering ensures accurate extraction, even when data fields are incomplete or missing. To further enhance matching accuracy, Retrieval-Augmented Generation (RAG) techniques are employed. These mechanisms retrieve relevant information from a structured skills database to provide context, which, combined with the generative capabilities of LLMs, enables more contextually accurate matches. Candidates receive personalized job recommendations based on the information extracted from their resumes, while employers can post job descriptions and use AI-driven tools to match candidates. This approach of using contextual prompts not only improves matching accuracy but also reduces computational time, eliminating the need for custom models tailored specifically to resumes or job descriptions.},
  keywords={Accuracy;Large language models;Resumes;Retrieval augmented generation;Manuals;Real-time systems;Data mining;Prompt engineering;Portals;Recruitment;Retrieval-Augmented Generation (RAG);Large Language Models (LLM);Artificial Intelligence (AI);Job Portal;Prompt Engineering;TF-IDF},
  doi={10.1109/CICTN64563.2025.10932524},
  ISSN={},
  month={Feb},}@ARTICLE{11071695,
  author={Lee, Chae-Eun and Hoon Jung, Sung},
  journal={IEEE Access}, 
  title={Applying Progressive Frequency Bands to Improve Image Quality and Training Stability of GAN}, 
  year={2025},
  volume={13},
  number={},
  pages={116104-116117},
  abstract={Generative Adversarial Networks (GANs) have revolutionized the field of image generations, yet their training instability remains a critical challenge that limits their practical applications. This paper introduces Progressive Frequency Band GAN (PFB-GAN), a novel framework that fundamentally reimagines GAN training through the lens of frequency domain analysis. Unlike conventional approaches that focus on time domain stabilization, our method leverages the inherent structure of frequency components to enable systematic and stable training. By introducing a progressive learning strategy that gradually incorporates frequency bands from low to high, PFB-GAN achieves remarkable stability while preserving fine details that are often lost in existing methods. Our comprehensive experiments across various datasets demonstrate consistent improvements, with performance metrics showing significant enhancements ranging from 10.55% to 21.03% across FID, Inception Score, Density & Coverage, and Precision & Recall metrics. More importantly, PFB-GAN shows exceptional resilience under extreme learning conditions, maintaining stability even at high learning rates where conventional GANs fail completely. This work not only advances the theoretical understanding of GAN training dynamics but also provides a practical solution for developing more reliable and robust generative models.},
  keywords={Frequency-domain analysis;Training;Generative adversarial networks;Thermal stability;Image synthesis;Stability criteria;Technological innovation;Deep learning;Visualization;Training data;GAN;generative models;frequency analysis;signal decomposition;progressive spectral learning},
  doi={10.1109/ACCESS.2025.3585951},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10957803,
  author={Cang, Minnan and Zhang, Meng and Zhou, Wei},
  booktitle={2024 International Conference on Image Processing, Computer Vision and Machine Learning (ICICML)}, 
  title={Research on the Application of Machine Learning in Visual Image Design}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={With the rapid development of artificial intelligence, machine learning applications in visual design have become increasingly widespread, particularly in the field of image processing. This study presents an intelligent image generation platform based on Generative Adversarial Networks (GANs) aimed at improving design efficiency and creative expression. The platform integrates Deep Convolutional GANs (DCGANs) with style transfer techniques to efficiently generate high-quality images with artistic and visual appeal. Experimental results demonstrate that the model outperforms traditional methods in terms of clarity (PSNR of 28.4 dB), realism (Inception Score of 7.5), and style consistency (Style Loss of 0.0025). User experience evaluations indicate that designers rate the platform highly for ease of use and image generation quality. This model not only enhances design efficiency but also serves as a powerful tool for creative visual tasks, advancing the automation and intelligence of the design process.},
  keywords={Visualization;Computer vision;Automation;Image synthesis;Computational modeling;Machine learning;Generative adversarial networks;User experience;Machine Learning;Visual Design;Image Generation;GANs (Generative Adversarial Networks)},
  doi={10.1109/ICICML63543.2024.10957803},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9925768,
  author={Wu, Zhijun and Meng, Shijun},
  booktitle={2022 IEEE/AIAA 41st Digital Avionics Systems Conference (DASC)}, 
  title={An Intelligent Text Processing Method for Civil Aviation Radiotelephony Communication Based on Generative Adversarial Network}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={Civil aviation radiotelephony communication is the main way of voice communication between controllers and pilots. Verifying radiotelephony communication’s read-back, extracting intent information, and making control decisions through artificial intelligence is significant. Training the deep models necessitates a lot of text data. The radiotelephony communication data is not easy to obtain and often requires extensive manual correction, the use of machines to automatically generate standardized text data has become a pressing issue that must be addressed. Aiming at the problems of error accumulation and exposure bias in traditional supervised learning text generation methods, this paper proposes an intelligent text processing method for civil aviation radiotelephony communication based on Generative Adversarial Networks (GAN), which can achieve high-quality command generation and read-back generation. This paper's key contributions are in two areas. Firstly, this paper proposes a text generation method for civil aviation radiotelephone communications by introducing a Long Short-Term Memory (LSTM) network-based sequence-to-sequence (Seq2Seq) model into a GAN model as its generator. It enhances the ability to capture text features and can generate samples that are as close to the actual text as possible to confuse the discriminator's judgment. Secondly, this paper presents a text categorization approach for civil aviation radiotelephony communication based on Convolutional Neural Network (CNN) and cross-entropy function. The discriminator of GAN built with the CNN model strives to distinguish between real text and generated text without being fooled by the generator. At the same time, the concept of policy gradient in reinforcement learning is introduced during adversarial training. The generator and the discriminator achieve a dynamic balance in the alternating adversarial training. According to experimental findings, the designed model outperforms other comparable models and can automatically generate texts that conform to civil aviation radiotelephone communication specifications without supervision. It can provide new ideas for the intelligent feedback system of civil aviation radiotelephony communication, speed up the digitization process of air traffic control, and lay a solid foundation for reducing crew operations.},
  keywords={Training;Atmospheric modeling;Process control;Generative adversarial networks;Solids;Feature extraction;Generators;civil aviation radiotelephony communication;generative adversarial network;text generation;reinforcement learning;sequence-to-sequence model},
  doi={10.1109/DASC55683.2022.9925768},
  ISSN={2155-7209},
  month={Sep.},}@ARTICLE{8572684,
  author={Chu, Phuong Minh and Sung, Yunsick and Cho, Kyungeun},
  journal={IEEE Access}, 
  title={Generative Adversarial Network-Based Method for Transforming Single RGB Image Into 3D Point Cloud}, 
  year={2019},
  volume={7},
  number={},
  pages={1021-1029},
  abstract={Three-dimensional (3D) point clouds are important for many applications, including object tracking and 3D scene reconstruction. Point clouds are usually obtained from laser scanners, but their high cost impedes the widespread adoption of this technology. We propose a method to generate the 3D point cloud corresponding to a single red–green–blue (RGB) image. The method retrieves high-quality 3D data from two-dimensional (2D) images captured by conventional cameras, which are generally less expensive. The proposed method comprises two stages. First, a generative adversarial network generates a depth image estimation from a single RGB image. Then, the 3D point cloud is calculated from the depth image. The estimation relies on the parameters of the depth camera employed to generate the training data. The experimental results verify that the proposed method provides high-quality 3D point clouds from single 2D images. Moreover, the method does not require a PC with outstanding computational resources, further reducing implementation costs, as only a moderate-capacity graphics processing unit can efficiently handle the calculations.},
  keywords={Three-dimensional displays;Gallium nitride;Two dimensional displays;Cameras;Generators;Training;Generative adversarial networks;Artificial intelligence;image processing;sensors;machine learning;neural networks},
  doi={10.1109/ACCESS.2018.2886213},
  ISSN={2169-3536},
  month={},}@ARTICLE{10886981,
  author={Song, Yu-Pei and Wu, Xiao and Li, Wei and He, Ting-Quan and Hu, Dong-Feng and Peng, Qiang},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={HighlightNet: Learning Highlight-Guided Attention Network for Nighttime Vehicle Detection}, 
  year={2025},
  volume={26},
  number={4},
  pages={4491-4503},
  abstract={Vehicle detection at night is a crucial task in Intelligent Transportation Systems. Due to the complex lighting environment, vehicle detection at night remains a challenging task. Headlights and taillights are essential cues to identify vehicles at night. However, existing methods struggle to effectively utilize the light information of the vehicle. This paper proposes a novel highlight-guided framework to identify vehicles, named HighlightNet, by utilizing both the illumination data from the vehicle lights and the reflective properties of vehicles. The framework combines vehicle detection and highlight area recognition via dual-branch joint learning. To ensure that both branches focus on the highlighted regions, Feature Similarity Awareness Attention (FSAA) is introduced to capture the common attention regions of different branches. Highlight Region Perception (HRP) is proposed to exclude streetlights and other reflective illuminations from the FSAA output, which generates a mask map capable of differentiating the foreground from the background of highlighted areas. It improves the allocation of feature weights and adaptively modifies the distribution within the dual-branch configuration. Furthermore, to address the severe pixel imbalance between the highlighted area and the background, Adaptive Spatial Balance (ASB) loss is introduced to allocate the attention towards prospective vehicle regions while diminishing the emphasis on background regions. Extensive experiments conducted on the BDD100K-Night dataset and a newly acquired dataset specifically designed for nighttime surveillance, called the NightVehicle dataset, demonstrate that HighlightNet outperforms the state-of-the-art methods for nighttime vehicle detection.},
  keywords={Vehicle detection;Feature extraction;Lighting;Object detection;Deep learning;Training;Noise;Data mining;Computational modeling;Artificial intelligence;Intelligent transportation system;vehicle detection at night;deep neural network;vehicle highlight information;cross-attention},
  doi={10.1109/TITS.2025.3539095},
  ISSN={1558-0016},
  month={April},}@INPROCEEDINGS{8995389,
  author={Yang, Haote and Tu, Shikui},
  booktitle={2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={GLmser: A GAN-Lmser Network for Image-to-Image Translation}, 
  year={2019},
  volume={},
  number={},
  pages={582-589},
  abstract={We present a GAN-Lmser network for the problem of transforming an image from one domain A to another B. The proposed network is based on CNN-Lmser, a recent further extension to deep convolutional layers from least mean square error reconstruction (Lmser) network, which was originally proposed in 1991. Specifically, in GAN-Lmser, the two directions, A-to-B and B-to-A, share the same architecture and symmetrically the same weights, by following the duality in bidirectional architecture (DBA) and duality connection weights (DCW) of Lmser, and an adversarial loss from GAN(generative adversarial network) was added to Lmser. Compared with the famous image-to-image translation model CycleGAN, the GAN-Lmser is compact with a significantly reduced number of parameters and is able to transfer learning through weight sharing between the two directions. Experiments demonstrate that GAN-Lmser is at least comparable to CycleGAN in benchmark datasets, and is robust when the training sample size is small.},
  keywords={Training;Translation;Transfer learning;Mean square error methods;Learning (artificial intelligence);Benchmark testing;Multitasking;Generative adversarial networks;Image reconstruction;Lmser, GAN, image-to-image translation, multi task learning},
  doi={10.1109/ICTAI.2019.00087},
  ISSN={2375-0197},
  month={Nov},}@ARTICLE{11154064,
  author={Jiang, Han and Yang, Xiaoshan and Chen, Chaofan and Xu, Changsheng},
  journal={IEEE Transactions on Multimedia}, 
  title={SPDQ: Synergetic Prompts as Disentanglement Queries for Compositional Zero-Shot Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-13},
  abstract={Compositional zero-shot learning (CZSL) aims to identify novel compositions formed by known primitives (attributes and objects). Motivated by recent advancements in pre-trained vision-language models such as CLIP, many methods attempt to fine-tune CLIP for CZSL and achieve remarkable performance. However, the existing CLIP-based CZSL methods focus mainly on text prompt tuning, which lacks the flexibility to dynamically adapt both modalities. To solve this issue, an intuitive solution is to additionally introduce visual prompt tuning. This insight is not trivial to achieve because effectively learning prompts for CZSL involves the challenge of entanglement between visual primitives as well as appearance shifts in different compositions. In this paper, we propose a novel Synergetic Prompts as Disentanglement Queries (SPDQ) framework for CZSL. It can disentangle primitive features based on synergetic prompts to jointly alleviate these challenges. Specifically, we first design a low-rank primitive modulator to produce synergetic adaptive attribute and object prompts based on prior knowledge of each instance for model adaptation. Then, we additionally utilize text prefix prompts to construct synergetic prompt queries, which are used to resample corresponding visual features from local visual patches. Comprehensive experiments conducted on three benchmarks demonstrate that our SPDQ approach achieves state-of-the-art results.},
  keywords={Visualization;Tuning;Adaptation models;Zero shot learning;Training;Dogs;Artificial intelligence;Modulation;Data mining;Computational modeling;Compositional Zero-shot Learning;Prompt Tuning},
  doi={10.1109/TMM.2025.3607726},
  ISSN={1941-0077},
  month={},}@ARTICLE{11075930,
  author={Lu, Xianwen and Wang, Chengfu and Sun, Hua and Wang, Yong and Liu, Chunling and Liu, Chao and Su, Ya and Cheng, Ruoxi},
  journal={IEEE Transactions on Industry Applications}, 
  title={Low-carbon Economic Dispatch of Multi-Park-Level Integrated Energy Systems Considering Thermal Network Demand Response and Improved Shapley Value Method}, 
  year={2025},
  volume={},
  number={},
  pages={1-13},
  abstract={This paper proposes an improved Shapley Value method for the economic dispatch of Multi-Park-Level Integrated Energy Systems (PIESs). The method considers carbon emissions, thermal network demand response, and the benefit-sharing problem, aiming to fully exploit the renewable energy scheduling potential and achieve low-carbon operation. Firstly, to address the high randomness and volatility of renewable energy output in PIES, a Generative Adversarial Network is employed to learn the probability distribution of historical data, generating renewable energy output sequences that reflect uncertainty and providing multiple potential scenarios. Secondly, a PIES dispatch strategy is proposed, considering the Emissions Trading System and thermal network user satisfaction. A thermal energy user satisfaction model is established from both energy usage methods and price incentives. Next, based on cooperative game theory with an improved Shapley value for benefit allocation, the errors in the generator and discriminator of the Generative Adversarial Network are quantitatively analyzed. Combining the marginal contributions of each PIES, energy sharing and benefit allocation between PIESs are realized. Finally, in the case studies, the effectiveness of carbon reduction after incorporating demand response in IES is verified for the proposed model and method, while also coordinating the complex benefit allocation among PIESs.},
  keywords={Generative adversarial networks;Carbon dioxide;Costs;Uncertainty;Electricity;Emissions trading;Resistance heating;Carbon;Optimization;Thermal energy;Generative Adversarial Network;Multi-ParkLevel Integrated Energy Systems;Carbon Emission Reduction Benefits;User Satisfaction;Improved Shapley Value Method},
  doi={10.1109/TIA.2025.3587628},
  ISSN={1939-9367},
  month={},}@ARTICLE{10158706,
  author={Liu, Jian and Lin, Tim H.},
  journal={IEEE Access}, 
  title={A Framework for the Synthesis of X-Ray Security Inspection Images Based on Generative Adversarial Networks}, 
  year={2023},
  volume={11},
  number={},
  pages={63751-63760},
  abstract={Object detection of prohibited items in X-ray security inspection is challenging because of serious overlap, disorderly background, and high throughput. In the past few years, a variety of deep learning algorithms have been proposed and achieved satisfactory results. However, the performance of these algorithms relies heavily on the specified datasets. Moreover, establishing a large-scale X-ray image dataset by manually collecting and labeling images is prohibitively expensive and time consuming. In this paper, we propose a text-driven framework for synthesizing X-ray security inspection images based on Generative Adversarial Networks (GAN). First, a conditional GAN is developed to generate natural images of prohibited items from class labels. Second, an improved model based on a pix-to-pix GAN is implemented to convert natural images into X-ray images. Third, another HD pix-to-pixel GAN is responsible for producing high-resolution benign background images, which are subsequently fused with the generated images of prohibited items to create X-ray inspection images. Finally, the proposed method is evaluated using SOTA object detection algorithms, such as YOLO-v5, and achieving 4.6% promotion for  $mAP_{0.5}$  and 15.9% promotion for  $mAP_{0.5-0.95}$ . The experimental results demonstrate that our image synthesis framework can effectively augment the datasets of prohibited items and improve the detection performance of deep learning algorithms during X-ray security screening.},
  keywords={X-ray imaging;Inspection;Generative adversarial networks;Training;Security;Image color analysis;Generators;Image generation;data augmentation;object detection;X-ray security checking;generative adversarial network (GAN)},
  doi={10.1109/ACCESS.2023.3288087},
  ISSN={2169-3536},
  month={},}@ARTICLE{9096308,
  author={Lee, Hyeonseok and Yeom, Sangwoo and Kim, Sungchan},
  journal={IEEE Access}, 
  title={BP-GAN: Interpretable Human Branchpoint Prediction Using Attentive Generative Adversarial Networks}, 
  year={2020},
  volume={8},
  number={},
  pages={97851-97862},
  abstract={Branchpoints (BPs) are essential sequence elements of ribonucleic acids (RNAs) in splicing, which is the process of creating a messenger RNA (mRNA) that is translated into proteins. This study proposes to develop deep neural networks for BP prediction. Extensive previous studies have shown that the existence of BP sites depends on sequence patterns called motifs; hence, the prediction model must accurately explain its decisions in terms of motifs. Existing approaches utilized either handcrafted features for interpretable, though less accurate, predictions or deep neural networks that were accurate but difficult to explain. To address the aforementioned difficulties, the proposed method incorporates 1) generative adversarial networks (GANs) to learn the latent structure of RNA sequences, and 2) an attention mechanism to learn sequence-positional long-term dependency for accurate prediction and interpretation. Our method achieves highly satisfying results in various performance metrics with adequate interpretability. We demonstrated that, without any prior biological knowledge, BP prediction by the proposed method is closely related to three motifs, the consensus sequence surrounding BPs, polypyrimidine tract, and 3’ splice site, that are well-established in molecular biology.},
  keywords={RNA;Gallium nitride;Proteins;Splicing;DNA;Generative adversarial networks;Neural networks;Branchpoint prediction;deep neural networks;generative adversarial networks;interpretability},
  doi={10.1109/ACCESS.2020.2995762},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10956203,
  author={Wang, Hanlong and Jiao, Xintao},
  booktitle={2025 International Conference on Electrical Automation and Artificial Intelligence (ICEAAI)}, 
  title={Phase-Aware Speech Enhancement with Dual-Stream Architecture and MetricGAN}, 
  year={2025},
  volume={},
  number={},
  pages={1178-1184},
  abstract={Many studies have explored how to utilize phase information. However, the extraction of the relationship between magnitude and phase remains inadequate. To bridge this gap, this paper proposes a phase-aware dual-stream architecture model. The model includes an encoder and two downstream decoders. The two decoders are responsible for modeling magnitude and phase information, respectively. Moreover, in order to capture the implicit association between magnitude and phase, the model establishes a fusion module between the two decoders, allowing reference to predicted magnitude information during the process of predicting phase information. To avoid the compensation effect between magnitude and phase, the predicted magnitude spectrum is applied with a stop-gradient operator before magnitude fusion, thereby blocking phase related gradients from flowing into magnitude arguments. To discard the discrepancy between predicted PESQ and calculated PESQ, additional phase input is introduced to the discriminator, enabling discriminator to accurately simulate the PESQ calculation process. We achieves a PESQ score of 3.53 on the VoiceBank+DEMAND datasets, which indicates a certain improvement over previous work.},
  keywords={Bridges;Automation;Neural networks;Speech enhancement;Predictive models;Transformers;Decoding;Artificial intelligence;speech enhancement;MetricGAN;phase-aware;dual-stream},
  doi={10.1109/ICEAAI64185.2025.10956203},
  ISSN={},
  month={Jan},}@ARTICLE{11175002,
  author={Sui, Qingya and Zhong, Lin and Ma, Lianbo and Wang, Ziqian and Lei, Zhenyu and Gao, Shangce},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Inter-class and Intra-class Relationships Incorporated Knowledge Distillation for Continual Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={Continual learning enables models to learn sequentially from a stream of tasks while retaining previously acquired knowledge. However, current methods lack the attention of tasks with different categories, as new task is introduced, models often adjust their internal representations to accommodate the new knowledge, which leads to decision boundary shifts and catastrophic forgetting, limiting the performance of continual learning methods. To address these limitations, this paper proposes continual learning with inter-class and intraclass relationships incorporated knowledge distillation (2ICL). The inter-class ensures stable decision boundaries by capturing the relative positioning between task categories. Intra-class relationships preserve internal coherence within each class to enhance generalization. Furthermore, 2ICL incorporates a dynamically expandable representation, enabling it to expand its feature space as new tasks are added while retaining old and new knowledge. Experiments conducted on CIFAR-10, CIFAR-100, and Pathmnist datasets demonstrate that 2ICL not only significantly alleviates catastrophic forgetting but also maintains high accuracy across tasks.},
  keywords={Continuing education;Stability analysis;Adaptation models;Thermal stability;Training;Knowledge transfer;Artificial intelligence;Feature extraction;Deep learning;Neurons;Continual learning;Stability-Plasticity dilemma;Knowledge distillation;Incremental learning},
  doi={10.1109/TAI.2025.3611366},
  ISSN={2691-4581},
  month={},}@INPROCEEDINGS{8851727,
  author={Yin, Ruiping and Li, Kan and Lu, Jie and Zhang, Guangquan},
  booktitle={2019 International Joint Conference on Neural Networks (IJCNN)}, 
  title={RsyGAN: Generative Adversarial Network for Recommender Systems}, 
  year={2019},
  volume={},
  number={},
  pages={1-7},
  abstract={Many recommender systems rely on the information of user-item interactions to generate recommendations. In real applications, the interaction matrix is usually very sparse, as a result, the model cannot be optimised stably with different initial parameters and the recommendation performance is unsatisfactory. Many works attempted to solve this problem, however, the parameters in their models may not be trained effectively due to the sparse nature of the dataset which results in a lower quality local optimum. In this paper, we propose a generative network for making user recommendations and a discriminative network to guide the training process. An adversarial training strategy is also applied to train the model. Under the guidance of a discriminative network, the generative network converges to an optimal solution and achieves better recommendation performance on a sparse dataset. We also show that the proposed method significantly improves the precision of the recommendation performance on several datasets.},
  keywords={Training;Recommender systems;Collaboration;Task analysis;Generative adversarial networks;Sparse matrices;Optimization;component;formatting;style;styling;insert},
  doi={10.1109/IJCNN.2019.8851727},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{10674621,
  author={Wang, Chi-Hung and Guo, Juan-Ling and Hwang, Yuh-Shyan},
  booktitle={2024 International Conference on Consumer Electronics - Taiwan (ICCE-Taiwan)}, 
  title={Research on Two-factor Authentication of Palm Print Image Recognition and Palm Vein Graphic}, 
  year={2024},
  volume={},
  number={},
  pages={573-574},
  abstract={In recent years, the pandemic has led to the introduction of contactless authentication methods, the most popular of which is facial recognition, but this single biometric method presents the challenge of feature change. Thus, it is proposed to combine the palm print with the palm vein which is not easy to change in the human body, and correct the illumination problem of NIR, the line clustering acquisition method, the limitations of the ResNeSt module and GAN, and then generate high-quality images. The experimental results showed that the accuracy rate of this work was as high as 99.3% compared with other works using hand features.},
  keywords={Accuracy;Image recognition;Pandemics;Lighting;Authentication;Generative adversarial networks;Biometric identification;Palm prints;Palm veins;Convolutional networks;Region of interest;ResNet;Generative adversarial network},
  doi={10.1109/ICCE-Taiwan62264.2024.10674621},
  ISSN={2575-8284},
  month={July},}@INPROCEEDINGS{10420998,
  author={Chintalapati, Akhil and Agarwal, Shaurya and Senapati, Aparajita and Misbah, Mohammed and S, Nithyashree R and Kumar, Sunil},
  booktitle={2023 International Conference on Next Generation Electronics (NEleX)}, 
  title={Textual Alchemy: Transmuting BERT Summaries with GAN Elegance}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={In today's digital era, the need for succinct yet insightful representation of vast amounts of information has never been greater. Text summarization stands at the forefront of this challenge, seeking to distill extensive narratives into compact, understandable portions. However, a pervasive issue with existing summarization methods is their propensity to omit essential context or generate fragmented sentences. The result being summaries that sometimes distort the original message, compromising both its clarity and depth. Generative networks, celebrated for their achievements in various AI disciplines, have seldom been tapped into for mending these summarization gaps. The latent potential of these networks, especially when coupled with advanced models like BERT, could be revolutionary for the field. This research delves into a pioneering approach that intertwines BERT's renowned content extraction capabilities with the adaptive refinement offered by Generative Adversarial Networks (GANs). Instead of merely shortening text, this synergy aims to transform - producing summaries that are not only concise but also resonate with the fluidity and nuance of human language. The presented framework doesn't just truncate, it transmutes. This paper offers a deep dive into the methodology behind this novel technique, the intricacies of its design, and robust empirical evaluations demonstrating its standout performance. By channeling the strength of generative networks and addressing the subtle challenges of textual condensation, this study heralds a new chapter in the saga of AI-powered text summarization.},
  keywords={Adaptation models;Adaptive systems;Transforms;Generative adversarial networks;Artificial intelligence;Next generation networking;Text Summarization;BERT;Generative Adversarial Networks;Context Preservation},
  doi={10.1109/NEleX59773.2023.10420998},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10655928,
  author={Sun, Quan and Cui, Yufeng and Zhang, Xiaosong and Zhang, Fan and Yu, Qiying and Wang, Yueze and Rao, Yongming and Liu, Jingjing and Huang, Tiejun and Wang, Xinlong},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Generative Multimodal Models are In-Context Learners}, 
  year={2024},
  volume={},
  number={},
  pages={14398-14409},
  abstract={The human ability to easily solve multimodal tasks in context (i.e., with only a few demonstrations or simple instructions), is what current multimodal systems have largely struggled to imitate. In this work, we demonstrate that the task-agnostic in-context learning capabilities of large multimodal models can be significantly enhanced by effective scaling-up. We introduce Emu2, a generative multimodal model with 37 billion parameters, trained on large-scale multimodal sequences with a unified autoregressive objective. Emu2 exhibits strong multimodal in-context learning abilities, even emerging to solve tasks that require on-the-fly reasoning, such as visual prompting and object-grounded generation. The model sets a new record on multiple multimodal understanding tasks in few-shot settings. When instruction-tuned to follow specific instructions, Emu2 further achieves new state-of-the-art on challenging tasks such as question answering benchmarks for large multimodal models and open-ended subject-driven generation. These achievements demonstrate that Emu2 can serve as a base model and general-purpose interface for a wide range of multimodal tasks. Code and models are publicly available to facilitate future research.},
  keywords={Visualization;Computer vision;Adaptation models;Codes;Reviews;Computational modeling;Benchmark testing},
  doi={10.1109/CVPR52733.2024.01365},
  ISSN={2575-7075},
  month={June},}@ARTICLE{10943232,
  author={Fatima, Noreen and Mento, Federico and Afrakhteh, Sajjad and Perrone, Tiziano and Smargiassi, Andrea and Inchingolo, Riccardo and Demi, Libertario},
  journal={IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control}, 
  title={Synthetic Lung Ultrasound Data Generation Using Autoencoder With Generative Adversarial Network}, 
  year={2025},
  volume={72},
  number={5},
  pages={624-635},
  abstract={Class imbalance is a significant challenge in medical image analysis, particularly in lung ultrasound (LUS), where severe patterns are often underrepresented. Traditional oversampling techniques, which simply duplicate original data, have limited effectiveness in addressing this issue. To overcome these limitations, this study introduces a novel supervised autoencoder generative adversarial network (SA-GAN) for data augmentation, leveraging advanced generative artificial intelligence (AI) to create high-quality synthetic samples for minority classes. In addition, the traditional data augmentation technique is used for comparison. The SA-GAN incorporates an autoencoder to develop a conditional latent space, effectively addressing weight clipping issues and ensuring higher quality synthetic data. The generated samples are evaluated using similarity metrics and expert analysis to validate their utility. Furthermore, state-of-the-art neural networks are used for multiclass classification, and their performance is compared when trained with GAN-based augmentation versus traditional data augmentation techniques. These contributions enhance the robustness and reliability of AI models in mitigating class imbalance in LUS analysis.},
  keywords={Generative adversarial networks;Ultrasonic imaging;COVID-19;Lungs;Autoencoders;Training;Data augmentation;Pneumonia;Kernel;Hospitals;Data augmentation;deep convolutional (DC) discriminator;generative adversarial network (GAN);lung ultrasound (LUS);multiclass classification;supervised autoencoder (SA)},
  doi={10.1109/TUFFC.2025.3555447},
  ISSN={1525-8955},
  month={May},}@INPROCEEDINGS{10416521,
  author={Striuk, Oleksandr and Kondratenko, Yuriy},
  booktitle={2023 13th International Conference on Dependable Systems, Services and Technologies (DESSERT)}, 
  title={Cross-Domain Reconfigurable GAN with Fuzzy Components for Anomaly Detection}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Anomaly detection remains a critical task in various domains, including cybersecurity and healthcare monitoring. Traditional approaches often rely on low-level machine learning and statistical methods, which may struggle to capture complex, multidimensional data patterns and adapt to evolving anomalies. In recent years, generative adversarial networks (GANs) have demonstrated promising potential for anomaly detection due to their ability to learn the underlying data distribution. This paper presents an anomaly detection system, which leverages a GAN-based model integrated with fuzzy logic components. We explore the integration of the GAN architecture with auxiliary components to enhance the performance and robustness of the anomaly detection system. This approach endeavors to explore the practical potential of GAN-based models in the field of anomaly detection and paves the way for future research in this rapidly evolving domain.},
  keywords={Fuzzy logic;Adaptation models;Uncertainty;Statistical analysis;Generative adversarial networks;Task analysis;Anomaly detection;artificial intelligence;machine learning;deep learning;artificial neural networks;GANs;anomaly detection;fuzzy logic},
  doi={10.1109/DESSERT61349.2023.10416521},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10698605,
  author={Shenoy, Neethu and Mbaziira, Alex V},
  booktitle={2024 International Conference on Electrical, Computer and Energy Technologies (ICECET}, 
  title={An Extended Review: LLM Prompt Engineering in Cyber Defense}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The launch of ChatGPT in November 2022 marked a significant advancement in the field of artificial intelligence, particularly in the realm of generative AI (GAI). ChatGPT is based on the Large Language Model (LLM). Use of AI in Cybersecurity can prove to be beneficial as the security analysts are employing AI models for improved detection of threats and quicker response to incidents. The interaction with LLMs needs to be skillfully and tactfully created to get precise and concise response. This technique of crafting queries to interact with the LLM is called prompt engineering. Prompt engineering in vulnerability detection and management is a new trend in the industry to manage cybersecurity threats and weaknesses proactively and effectively. This paper presents an extensive review of the field of prompt engineering in cybersecurity. It is primarily based on a comprehensive analysis of existing literature, encompassing a wide range of sources to provide a thorough overview of the current state and advancements in AI. The review delves into various aspects of prompt engineering, synthesizing key findings and theories from a multitude of scholarly articles and industry reports. This approach ensures a holistic understanding of the AI models including LLMs and how generative AI, in terms of prompt engineering, can be used for cyber-defense.},
  keywords={Industries;Training;Analytical models;Reviews;Chatbots;Market research;Prompt engineering;Artificial intelligence;Computer security;Monitoring;Artificial Intelligence;Machine Learning;Natural Language Processing;Generative AI;Large Language Models;Prompt Engineering;ChatGPT;Cyber-Defense;Cybersecurity;Vulnerability Management},
  doi={10.1109/ICECET61485.2024.10698605},
  ISSN={},
  month={July},}@INPROCEEDINGS{10835518,
  author={Darzi, Saleh and Yavuz, Attila A.},
  booktitle={2024 IEEE 6th International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (TPS-ISA)}, 
  title={Counter Denial of Service for Next-Generation Networks within the Artificial Intelligence and Post-Quantum Era}, 
  year={2024},
  volume={},
  number={},
  pages={138-147},
  abstract={Given the rise in cyber threats to networked systems, coupled with the proliferation of AI techniques and enhanced processing capabilities, Denial of Service (DoS) attacks are becoming increasingly sophisticated and easily executable. They target system availability, compromising entire systems without breaking underlying security protocols. Consequently, numerous studies have focused on preventing, detecting, and mitigating DoS attacks. However, state-of-the-art systematization efforts have limitations such as isolated DoS countermeasures, shortcomings of AI-based studies, and a lack of DoS integration features like privacy, anonymity, authentication, and transparency. Additionally, the emergence of quantum computers is a game changer for DoS from attack and defense perspectives, yet it has remained largely unexplored. This study aims to address these gaps by examining (counter)-DoS in the AI era while also considering post-quantum (PQ) security when it applies. We highlight the deficiencies in the current literature and provide insights into synergistic techniques to bridge these gaps. We explore AI mechanisms for DoS intrusion detection, evaluate cybersecurity properties in cutting-edge machine learning models, and analyze weaponized AI in the context of DoS. We also investigate collaborative and distributed counter-DoS frameworks via federated learning and blockchains. Finally, we assess proactive approaches such as honeypots, puzzles, and authentication schemes that can be integrated into next-generation network systems for DoS prevention and mitigation.},
  keywords={Bridges;Privacy;Analytical models;Prevention and mitigation;Weapons;Authentication;Collaboration;Artificial intelligence;Next generation networking;Network systems;Counter-DoS;Artificial intelligence (AI);post-quantum security;next-generation networks;deep learning},
  doi={10.1109/TPS-ISA62245.2024.00025},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10605442,
  author={Vardhan, Madhurima and Nathani, Deepak and Vardhan, Swarnima and Aggarwal, Abhinav and Simini, Filippo},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Large language models as synthetic electronic health record data generators}, 
  year={2024},
  volume={},
  number={},
  pages={804-810},
  abstract={Electronic health record (EHR) data consists of a wealth of information that can be used for driving clinical research and improving patient care. However, due to the complex and sensitive nature of EHR data, there are strict data regulations and privacy concerns around data sharing. Generating adequately validated synthetic EHR data from scratch, such that it is representative of real data, is a viable and attractive solution to address such data-sharing bottlenecks. In this work, we investigate the adoption and implementation of large language models (LLMs) as a sustainable and scalable deep learning approach for generating high-fidelity EHR data. The findings of this study demonstrate that LLMs outperform commonly used generative modeling frameworks, such as variational autoencoders and generative adversarial networks, and recently introduced diffusion models.},
  keywords={Data privacy;Protocols;Large language models;Data models;Regulation;Generators;Reliability;Large language models;synthetic data;electronic health record data;generative adversarial network;generative models},
  doi={10.1109/CAI59869.2024.00152},
  ISSN={},
  month={June},}@ARTICLE{9524485,
  author={Wu, Zhongqi and Zhuang, Chuanqing and Shi, Jian and Guo, Jianwei and Xiao, Jun and Zhang, Xiaopeng and Yan, Dong-Ming},
  journal={IEEE Transactions on Multimedia}, 
  title={Single-Image Specular Highlight Removal via Real-World Dataset Construction}, 
  year={2022},
  volume={24},
  number={},
  pages={3782-3793},
  abstract={Specular reflections pose great challenges on various multimedia and computer vision tasks, e.g., image segmentation, detection and matching. In this paper, we build a large-scale Paired Specular-Diffuse (PSD) image dataset, where the images are carefully captured by using real-world objects and the ground-truth specular-free diffuse images are provided. To the best of our knowledge, this is the first real-world benchmark dataset for specular highlight removal task, which is useful for evaluating and encouraging new deep learning-based approaches. Given this dataset, we present a novel Generative Adversarial Network (GAN) for specular highlight removal from a single image by introducing the detection of specular reflection information as a guidance. Our network also makes full use of the attention mechanism and is able to directly model the mapping relation between the diffuse area and the specular highlight area without any explicit estimation of the illumination. Experimental results demonstrate that the proposed network is more effective to remove specular reflection components with the guidance of specular highlight detection than recent state-of-the-art methods.},
  keywords={Lighting;Image color analysis;Training;Task analysis;Light sources;Color;Estimation;Specular highlight removal;PSD-Dataset;deep learning},
  doi={10.1109/TMM.2021.3107688},
  ISSN={1941-0077},
  month={},}@ARTICLE{10643310,
  author={Peng, Jincheng and Xing, Huanlai and Xu, Lexi and Luo, Shouxi and Dai, Penglin and Feng, Li and Song, Jing and Zhao, Bowen and Xiao, Zhiwen},
  journal={IEEE Transactions on Mobile Computing}, 
  title={Adversarial Reinforcement Learning Based Data Poisoning Attacks Defense for Task-Oriented Multi-User Semantic Communication}, 
  year={2024},
  volume={23},
  number={12},
  pages={14834-14851},
  abstract={Multi-user semantic communication (MUSC) has emerged as a promising paradigm for future 6G networks and applications, where massive clients (e.g., mobile devices) collaboratively construct a global semantic decoder without sharing their local data. However, due to the lack of direct access to clients’ data, MUSC is vulnerable to data poisoning attacks (DPAs), wherein malicious participants send updates derived from poisoned training samples. Current defense techniques against DPAs are designed for traditional networks and are not directly applicable to MUSC. In this paper, we propose an effective attack-defense game framework, denoted as DPAD-MUSC, tailored to defend against DPAs during image transmission for MUSC. First, we determine each attack-type's optimal attack policy based on reinforcement learning, with the aim of strengthening the attack while avoiding detection. To generate adversarial samples accordingly, we devise an adversarial samples generator (ADV-Generator) based on conditional generative adversarial network (CGAN). Then, we introduce an attack defender (DPA-Defender) to detect data poisoning attacks and exclude poisoned samples from the target model's learning process, with the adversarial samples generated under the guidance of the optimal attack policy to enhance the detector's robustness. Simulation results demonstrate that the DPAD-MUSC can find optimal attack policies that cause a greater accuracy drop in the target model while maintaining a higher evasion rate. The ADV-Generator can generate effective adversarial samples and the DPA-Defender outperforms five state-of-the-art methods on three widely used image datasets under additive white Gaussian noise (AWGN) channel in terms of Top-1 accuracy.},
  keywords={Semantics;Data models;Task analysis;Training;Noise;Training data;Feature extraction;Adversarial training;data poisoning attacks;reinforcement learning;semantic communication},
  doi={10.1109/TMC.2024.3447087},
  ISSN={1558-0660},
  month={Dec},}@ARTICLE{9194389,
  author={Kang, Qi and Yao, SiYa and Zhou, MengChu and Zhang, Kai and Abusorrah, Abdullah},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Effective Visual Domain Adaptation via Generative Adversarial Distribution Matching}, 
  year={2021},
  volume={32},
  number={9},
  pages={3919-3929},
  abstract={In the field of computer vision, without sufficient labeled images, it is challenging to train an accurate model. However, through visual adaptation from source to target domains, a relevant labeled dataset can help solve such problem. Many methods apply adversarial learning to diminish cross-domain distribution difference. They are able to greatly enhance the performance on target classification tasks. Generative adversarial network (GAN) loss is widely used in adversarial adaptation learning methods to reduce an across-domain distribution difference. However, it becomes difficult to decline such distribution difference if generator or discriminator in GAN fails to work as expected and degrades its performance. To solve such cross-domain classification problems, we put forward a novel adaptation framework called generative adversarial distribution matching (GADM). In GADM, we improve the objective function by taking cross-domain discrepancy distance into consideration and further minimize the difference through the competition between a generator and discriminator, thereby greatly decreasing cross-domain distribution difference. Experimental results and comparison with several state-of-the-art methods verify GADM’s superiority in image classification across domains.},
  keywords={Gallium nitride;Generators;Visualization;Task analysis;Generative adversarial networks;Neural networks;Adaptation models;Adversarial learning;distribution matching;generative adversarial networks (GANs);image classification;visual domain adaptation},
  doi={10.1109/TNNLS.2020.3016180},
  ISSN={2162-2388},
  month={Sep.},}@ARTICLE{10525217,
  author={Zhang, Yuxin and Lin, Limei and Huang, Yanze and Wang, Xiaoding and Hsieh, Sun-Yuan and Gadekallu, Thippa Reddy and JalilPiran, Md.},
  journal={IEEE Internet of Things Journal}, 
  title={A Cooperative Vehicle-Road System for Anomaly Detection on Vehicle Tracks With Augmented Intelligence of Things}, 
  year={2024},
  volume={11},
  number={22},
  pages={35975-35988},
  abstract={The Augmented Intelligence of Things (AIoT) is an emerging technology that combines augmented intelligence with the Internet of Things (IoT) to facilitate advanced decision-making processes. In this article, we focus on the detection of vehicle trajectory anomalies in a vehicle-road collaboration system by AIoT, aiming to improve the traffic safety and road operation efficiency. We transmit collaboration data collected by sensors to an IoT server, which enables the effective data analysis for vehicle trajectory information. We propose a self-supervised learning augmented intelligence algorithm to achieve precise and efficient detection of trajectory anomalies. First, we models the traffic road network as a topology graph. Subsequently, we sample the relevant subgraph contexts for each target node through a random walk algorithm. And the subgraphs with higher intimacy scores are selected as the contextual background to be input along with the target node. After that, the anomaly score of each target node is computed through the generative learning module and the contrastive learning module. To evaluate the effectiveness of our anomaly detection approach, we initially conduct pretraining of the model using four widely utilized graph machine learning data sets. The experimental results reveal that our approach surpasses previous methods in the accuracy of identifying graph anomaly nodes. In addition, we carry out our approach on two real traffic data sets with high accuracies of 86.47% and 85.2%, respectively. This result demonstrates the effectiveness of our proposed approach in detecting trajectory anomalies in real traffic scenarios.},
  keywords={Roads;Internet of Things;Collaboration;Anomaly detection;Trajectory;Artificial intelligence;Topology;Anomaly detection;Augmented Intelligence of Things (AIoT);self-supervised learning (SSL);vehicle road collaboration},
  doi={10.1109/JIOT.2024.3398023},
  ISSN={2327-4662},
  month={Nov},}@INPROCEEDINGS{10959788,
  author={Alwan, Wajid D. and Al-Thahab, Osama Qasim Jumah and Al Abboodi, Hanaa Mohsin},
  booktitle={2024 3rd International Conference on Advances in Engineering Science and Technology (AEST)}, 
  title={Review of Skin Cancer Detection and Diagnosis by Applying Different Models of Artificial Intelligence}, 
  year={2024},
  volume={},
  number={},
  pages={42-47},
  abstract={The use of deep learning and machine learning models for automated skin cancer diagnosis is growing in popularity. Skin conditions that are common and can have life-threatening implications include vascular lesions, actinic keratosis, basal cell carcinoma, melanoma, benign keratosis, and melanocytic nevi. Early identification of skin cancer allows patients to treat the condition and reduces the fatality rate. Skin cancer identification is difficult since diverse skin lesions have many features. Many studies presented a range of advanced models aimed at solving the challenges of automatic skin cancer diagnosis. This article will examine the recently proposed machine learning models developed to identify and categorize skin disorders with different types of skin cancer datasets that have been recently used in many studies and applications, as well as assist readers in understanding the field's limitations and unsolved problems. The performance of many sophisticated machine learning and transfer learning algorithms is assessed in this review study.},
  keywords={Deep learning;Machine learning algorithms;Reviews;Basal cell carcinoma;Transfer learning;Melanoma;Skin;Lesions;Skin cancer;Machine Learning;CNN;Transfer Learning;Skin Cancers},
  doi={10.1109/AEST63017.2024.10959788},
  ISSN={},
  month={Nov},}@ARTICLE{11105784,
  author={Aumentado-Armstrong, Tristan and Tsogkas, Stavros and Dickinson, Sven and Jepson, Allan},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Probabilistic Directed Distance Fields for Ray-Based Shape Representations}, 
  year={2025},
  volume={},
  number={},
  pages={1-18},
  abstract={In modern computer vision, the optimal representation of 3D shape remains task-dependent. One fundamental operation applied to such representations is differentiable rendering, which enables learning-based inverse graphics approaches. Standard explicit representations are often easily rendered, but can suffer from limited geometric fidelity, among other issues. On the other hand, implicit representations generally preserve greater fidelity, but suffer from difficulties with rendering, limiting scalability. In this work, we devise Directed Distance Fields (DDFs), which map a ray or oriented point (position and direction) to surface visibility and depth. This enables efficient differentiable rendering, obtaining depth with a single forward pass per pixel, as well as higher-order geometry with only additional backward passes. Using probabilistic DDFs (PDDFs), we can model the inherent discontinuities in the underlying field. We then apply DDFs to single-shape fitting, generative modelling, and 3D reconstruction, showcasing strong performance with simple architectural components via the versatility of our representation. Finally, since the dimensionality of DDFs permits view-dependent geometric artifacts, we conduct a theoretical investigation of the constraints necessary for view consistency. We find a small set of field properties that are sufficient to guarantee a DDF is consistent, without knowing which shape the field is expressing.},
  keywords={Shape;Rendering (computer graphics);Three-dimensional displays;Geometry;Neural radiance field;Computational modeling;Light fields;Computer vision;Artificial intelligence;Probabilistic logic;3D shape representations;differentiable rendering;implicit shape fields;multiview consistency},
  doi={10.1109/TPAMI.2025.3594225},
  ISSN={1939-3539},
  month={},}@INPROCEEDINGS{11011879,
  author={Sathis Kumar, N R and Baalaji, K and G, Sivagnanasekar and S, Vijayarajan and A R, Shameem Mohamed and Madhavan C, Hari},
  booktitle={2025 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI)}, 
  title={Revolutionizing Cardiovascular Disease Prediction: Stacked Ensemble Models with XGBoost, Neural Networks, and Generative AI Integration}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={cardiovascular disease hence makes a sizable portion of global mortality, further calling for ideal and timely prediction measures. The comparison of four machine learning models, namely, Logistic Regression, Random Forest, XGBoost, and Neural Networks for cardiovascular disease prediction is done in this work. Therefore, to improve the prediction accuracy still further, the present study advocated the use of a new Stacking Model as the augmented learner through Random Forest and XGBoost algorithms. When compared with individual models, the accuracy of the Stacking Model is extraordinary is 90.00% higher than other baselines including Logistic Regression (72.36%), Random Forest (71.41%), XGBoost (73.57%), and Neural Networks (73.18). Within the system setting, there is a Generative AI chatbot where users can ask questions about the predictions and factors behind them. Moreover, a user-oriented feature implemented via an SMTP based Email Notification Service means timely alerting of severe predictions and/or changes. The combination of machine learning, Generative AI, and email notification shows how more prompt and efficient, easy to use diagnostic tools can be created for the future with appeal to personalized health solutions.},
  keywords={Logistic regression;Accuracy;Generative AI;Neural networks;Stacking;Medical services;Predictive models;Chatbots;Cardiovascular diseases;Random forests;cardiovascular disease prediction;ensemble learning;data preprocessing;feature selection;Random Forest (RF)},
  doi={10.1109/ICDSAAI65575.2025.11011879},
  ISSN={},
  month={March},}@INBOOK{11090054,
  author={Tiwari, Raj Gaurang and Abeer, A. Aljohani and Rajat, Bhardwaj and Vishal, Jain},
  booktitle={Security and Privacy in IoMT: Challenges and Solutions}, 
  title={9 Exploring the Potential of Explainable Artificial Intelligence for Medical Diagnosis: A Review of Current Approaches and Future Directions}, 
  year={2025},
  volume={},
  number={},
  pages={209-228},
  abstract={This book explores Internet of Medical Things (IoMT) security and privacy in electronic healthcare, addressing vulnerabilities in medical devices that expose patient data to cyber-attacks. It covers IoMT security challenges, potential attacks, and solutions considering resource constraints, network architecture, and communication protocols. IoMT is revolutionizing the medical sector by providing personalized and targeted treatments and by facilitating seamless communication of medical data. IoMT devices are more trustworthy in monitoring and tracking due to higher accuracy levels, which also minimize human errors and inaccurate reporting. While the merits of IoMT devices are clear, they also pose severe privacy and security risks. Medical systems acquire, process, and perform decision-making based on this sensitive health information. Cyber attackers who exploit the flaws and weaknesses in these IoMT devices might well be able to penetrate the hospital network and gain unauthorized access to private patient data. Attacks on these IoMT devices also have the potential to endanger the patients' lives and cause serious physical harm. In addition to outlining viable solutions that take into account constrained resources at IoMT end-devices, hybrid network architecture, application characteristics, and communication protocols, the book covers the core concepts of IoMT security and privacy. It describes both theoretical and practical aspects for those working in security in the IoMT, emphasizing the most significant potential IoT security issues and challenges.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770041379},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11090054},}@ARTICLE{6571229,
  author={Fernandes, Carlos M. and Mora, Antonio M. and Merelo, Juan J. and Rosa, Agostinho C.},
  journal={IEEE Transactions on Cybernetics}, 
  title={KANTS: A Stigmergic Ant Algorithm for Cluster Analysis and Swarm Art}, 
  year={2014},
  volume={44},
  number={6},
  pages={843-856},
  abstract={KANTS is a swarm intelligence clustering algorithm inspired by the behavior of social insects. It uses stigmergy as a strategy for clustering large datasets and, as a result, displays a typical behavior of complex systems: self-organization and global patterns emerging from the local interaction of simple units. This paper introduces a simplified version of KANTS and describes recent experiments with the algorithm in the context of a contemporary artistic and scientific trend called swarm art, a type of generative art in which swarm intelligence systems are used to create artwork or ornamental objects. KANTS is used here for generating color drawings from the input data that represent real-world phenomena, such as electroencephalogram sleep data. However, the main proposal of this paper is an art project based on well-known abstract paintings, from which the chromatic values are extracted and used as input. Colors and shapes are therefore reorganized by KANTS, which generates its own interpretation of the original artworks. The project won the 2012 Evolutionary Art, Design, and Creativity Competition.},
  keywords={Vectors;Art;Clustering algorithms;Mathematical model;Algorithm design and analysis;Painting;Equations;Ant algorithms;cluster analysis;self-organization;stigmergy;swarm art;swarm intelligence;Ant algorithms;cluster analysis;self-organization;stigmergy;swarm art;swarm intelligence},
  doi={10.1109/TCYB.2013.2273495},
  ISSN={2168-2275},
  month={June},}@ARTICLE{9195865,
  author={Zhai, Junhai and Qi, Jiaxing and Zhang, Sufang},
  journal={IEEE Access}, 
  title={Binary Imbalanced Data Classification Based on Modified D2GAN Oversampling and Classifier Fusion}, 
  year={2020},
  volume={8},
  number={},
  pages={169456-169469},
  abstract={Binary imbalance problem refers to such a classification scenario where one class contains a large number of samples while another class contains only a few samples. When traditional classifiers face with imbalanced datasets, they usually bias towards majority class resulting in poor classification performance. Oversampling is an effective method to address this problem, yet how to conduct diversity oversampling is a challenge. In this article, we proposed a diversity oversampling method based on a modified D2GAN model, and on the basis of diversity oversampling, we also proposed a binary imbalanced data classification approach based on classifier fusion by fuzzy integral. Extensive experiments are conducted on 8 data sets to compare the proposed methods with 7 state-of-the-art methods on 5 aspects: MMD-score, Silhouette-score, F-measure, G-means, and AUC-area. The 7 methods include 4 SMOTE related approaches and 3 GAN related approaches. The experimental results demonstrate that the proposed methods are more effective and efficient than the compared approaches.},
  keywords={Gallium nitride;Generative adversarial networks;Generators;Training;Diversity methods;Data models;Machine learning;Binary class imbalance;diversity oversampling;generative adversarial network;classifier fusion;fuzzy integral},
  doi={10.1109/ACCESS.2020.3023949},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10200392,
  author={Su, Na},
  booktitle={2023 IEEE 13th International Conference on Electronics Information and Emergency Communication (ICEIEC)}, 
  title={Research on Multiparty Participation Collaborative Supervision Strategy of AIGC}, 
  year={2023},
  volume={},
  number={},
  pages={268-272},
  abstract={The emergence and popularity of ChatGPT has sparked a new wave of “artificial intelligence” worldwide. AIGC is a true industrial revolution-level artificial intelligence technology revolution that will bring significant changes to the entire country, the world, and humanity. Like all technologies, the development of AIGC technology not only brings convenience and innovation to people, but also brings many risks and challenges. By studying the principle of AIGC technology and combining with typical cases, this paper analyzes the causes of security problems caused by the model defects and abuse propagation, focusing on the analysis of privacy Data breach, prejudice and discrimination, copyright disputes caused by data collection, processing, output and other links, as well as the impact of controlled, malicious application, abuse, misuse and other propagation on personal privacy, social stability, national security and international order. From the perspective of both security issues inherent to AIGC and those caused by its application, a multi-party collaborative regulatory strategy is proposed to safeguard the innovative development of AIGC technology, provide theoretical support for the healthy and standardized development of related industries, and help with economic and social transformation and development.},
  keywords={Industries;Data privacy;Technological innovation;Humanities;Collaboration;Process control;Stability analysis;AIGC;Regulatory strategy;ChatGPT},
  doi={10.1109/ICEIEC58029.2023.10200392},
  ISSN={2377-844X},
  month={July},}@INPROCEEDINGS{11091925,
  author={Luo, Shanshan and Zhang, Wei and Zheng, Ruicong and Wang, Axi},
  booktitle={2025 7th International Conference on Computer Science and Technologies in Education (CSTE)}, 
  title={The Influence of Procedural Scaffolding on pre-Service Teachers' Questioning Skills in Human-AI Collaborative Environment}, 
  year={2025},
  volume={},
  number={},
  pages={191-195},
  abstract={For pre-service teachers to effectively leverage the potential of Generative Artificial Intelligence (Generative AI), they need to develop questioning skills. However, current research indicated that pre-service teachers lacked awareness of how to utilize Generative AI in their professional practice, leading to several challenges: difficulties in formulating precise instructions, and challenges in discerning potentially inaccurate content generated by Generative AI. To address these issues, this study focused on improving pre-service teachers' abilities in prompt design, result verification, and application within human-computer collaborative environments. Grounded in cognitive apprenticeship theory, the study constructed a procedural scaffolding and employed a quasi-experimental design to verify its impact on pre-service teachers' questioning skills and critical thinking. The results showed a significant enhancement in the questioning skills of pre-service teachers. The findings were analyzed, and recommendations were proposed to further support the integration of Generative AI into teacher education.},
  keywords={Training;Computer science;Systematics;Generative AI;Collaboration;generative artificial intelligence;pre-service teachers;teaching questioning;procedural scaffolding},
  doi={10.1109/CSTE64638.2025.11091925},
  ISSN={},
  month={April},}@ARTICLE{9082609,
  author={Yang, Hang and Wang, Minghui and Yu, Zhenhua and Zhao, Xing-Ming and Li, Ao},
  journal={IEEE Access}, 
  title={GANcon: Protein Contact Map Prediction With Deep Generative Adversarial Network}, 
  year={2020},
  volume={8},
  number={},
  pages={80899-80907},
  abstract={Accurate protein contact map prediction is essential for de novo protein structure prediction. Over the past few years, deep learning has brought a significant breakthrough in protein contact map prediction and optimized deep learning architectures are highly desired for performance improvement. As an emerging deep learning architecture, the generative adversarial network (GAN) has shown the powerful capability of learning intrinsic patterns, which inspires us to comprehensively exploit GAN for predicting accurate protein contact maps. In this study, we present GANcon, a novel GAN-based deep learning architecture for protein contact map prediction, which to the best of our knowledge is the first GAN-based approach in this field. Instead of using a single neural network, GANcon is composed of two competitive networks that are evolving through adversarial learning. The generator network employs a dedicated encoder-decoder architecture that can efficiently capture the underlying contact information from versatile protein features to generate contact maps, while the discriminator network learns the differences between generated contact maps and real ones and promotes the generator network to produce more accurate contact maps. Moreover, to deal with the imbalance problem and take into account the symmetry of contact maps, we also propose a novel symmetrical focal loss, which can further enhance the effectiveness of adversarial learning for better performance. The experimental results on several datasets demonstrate that GANcon outperforms many state-of-the-art methods, indicating the effectiveness of our method for predicting protein contact maps. GANcon is freely available at https://github.com/melissaya/GANcon.},
  keywords={Proteins;Generators;Gallium nitride;Generative adversarial networks;Deep learning;Protein engineering;Computer architecture;Protein contact map prediction;deep learning;generative adversarial network;adversarial learning},
  doi={10.1109/ACCESS.2020.2991605},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11104915,
  author={Daher, Wajeeh and Diab, Hussam and Rayan, Anwar},
  booktitle={2025 International Conference on Smart Learning Courses (SCME)}, 
  title={Potential of Generative AI for Chemistry Problem Solving: Evaluating Effectiveness Across Different AI Model Generations and Linguistic Contexts}, 
  year={2025},
  volume={},
  number={},
  pages={49-56},
  abstract={The increasing prevalence of generative AI in education, exemplified by the multilingual ChatGPT (versions 3.5 and 4.0), necessitates a thorough evaluation of its performance across languages. Our research compared the accuracy of ChatGPT's English and Arabic responses to 39 chemistry problems from the 6th-7th grade level. While ChatGPT 4.0 showed notable improvements, particularly with Arabic, English responses remained more accurate. To bridge this gap, we recommend either enriching ChatGPT's Arabic knowledge base or adopting a translation protocol: process Arabic questions in English and then provide the translated answer to the user. This strategy aims to capitalize on the higher accuracy in English, potentially improving outcomes for Arabic speakers and others encountering similar linguistic limitations in AI-driven science education.},
  keywords={Chemistry;Accuracy;Translation;Protocols;Generative AI;Knowledge based systems;Educational technology;Chatbots;Multilingual;Problem-solving;Artificial intelligence;generative artificial intelligence;chemistry;problem solving;primary school;ChatGPT},
  doi={10.1109/SCME62582.2025.11104915},
  ISSN={},
  month={July},}@INPROCEEDINGS{8850773,
  author={Wang, Yanxia and Li, Kang and Gan, Shaojun and Cameron, Che and Zheng, Min},
  booktitle={2019 1st International Conference on Industrial Artificial Intelligence (IAI)}, 
  title={Data Augmentation for Intelligent Manufacturing with Generative Adversarial Framework}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={The global economy is greatly shaped by the unprecedented booming of ICT and artificial intelligence technologies. Their applications in manufacturing has led to the advent of intelligent manufacturing and industry 4.0. Data has become a precious asset for modern industry. This paper first introduces an energy monitoring and data acquisition system namely the Point Energy Technology, which has been developed by the team and installed in several industrial partners, including a local bakery. The lack of data always exists due to various reasons, such as measurement or transmission errors at data collection and transmission stage, leading to the loss of varied length of data samples that are key for process monitoring and control. To solve this problem, we introduce a generative adversarial framework which is based on a game theory for data augmentation. This framework consists of two multilayer perceptron networks, namely generator and discriminator. An improved framework with Q-net that extracts the latent variables from real data is also proposed, in which the Q-net shares the structure with discriminator except for the last layer. In addition, the two optimization methods, namely mini-batch gradient descent and adaptive moment estimation are adopted to tune the parameters. To evaluate the performance of these algorithms, energy consumption data collected from a bakery process is used in the experiment. The experimental results confirm that the latent generative adversarial framework with adaptive moment estimation could generate good quality data samples to compensate the random loss of samples in time series data.},
  keywords={Generators;Estimation;Monitoring;Industries;Training;Manufacturing;Gallium nitride;monitoring system;data augmentation;generative adversarial framework;optimization algorithm},
  doi={10.1109/ICIAI.2019.8850773},
  ISSN={},
  month={July},}@INPROCEEDINGS{10199001,
  author={González, Gastón García and Casas, Pedro and Fernández, Alicia},
  booktitle={2023 7th Network Traffic Measurement and Analysis Conference (TMA)}, 
  title={Deep Generative Replay for Multivariate Time-Series Monitoring with Variational Autoencoders}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Multivariate time-series (MTS) play a crucial role in network monitoring and analysis problems. We explore the usage of generative AI for MTS data modeling, in particular for the sake of knowledge replay. Knowledge replay mechanisms help in leveraging past experiences to enhance learning, mitigate forgetting, promote generalization, and enable the transfer of knowledge across different tasks or domains. Using a VAE-based deep architecture for data modeling, we incorporate a Deep Generative Replay (DGR) approach to transfer previously learned latent representations into future learning tasks, enabling continual learning in MTS problems. We study the generative characteristics of VAE-based models on top of a multi-dimensional network monitoring dataset collected from an operational mobile Internet Service Provider (ISP), portraying its usage in the context of DGR learning tasks.},
  keywords={Web and internet services;Deep architecture;Telecommunication traffic;Data models;Task analysis;Artificial intelligence;Monitoring;Anomaly Detection;Generative AI;VAE;Multivariate Time-Series;GenDeX},
  doi={10.23919/TMA58422.2023.10199001},
  ISSN={},
  month={June},}@INPROCEEDINGS{10685775,
  author={Wei, Xiaodong and Yan, Haixuan},
  booktitle={2024 International Symposium on Educational Technology (ISET)}, 
  title={Research on Teaching Activities in University Blended Technology Development Courses with Support from Generative Virtual Digital Humans}, 
  year={2024},
  volume={},
  number={},
  pages={230-234},
  abstract={In the current educational environment, blended courses have been widely used in university classrooms. With the advancement of AI technology, generative virtual digital humans are gradually being introduced into the education field. However, there are few studies combining the two. To this end, this study designed an experiment to compare the effects of a blended course based on generative virtual digital humans and a traditional blended course. We selected 60 students, 30 of whom participated in a blended course based on generative virtual digital humans (experimental group), and the other 30 students took a traditional blended course (control group). Before and after the experiment, we conducted tests on the cognitive load, flow state, etc. of the two groups of students, and collected data related to academic achievement. Research results show that students in the experimental group are better than those in the control group in terms of cognitive load, flow state, and academic achievement, indicating that blended courses based on generative virtual digital humans have significant effects on reducing cognitive load and improving learning experience and effects. Advantage. This provides a useful reference for future educational innovation, helps promote the development and improvement of educational technology, and improves the quality and effectiveness of education.},
  keywords={Technological innovation;Educational technology;Cognitive load;Digital humans;Artificial intelligence;Generative Virtual Digital Humans;Blended Courses;Higher Education},
  doi={10.1109/ISET61814.2024.00052},
  ISSN={2766-2144},
  month={July},}@ARTICLE{9782799,
  author={Liu, Wenxuan and Zhao, Junhua and Qiu, Jing and Dong, Zhao Yang},
  journal={IEEE Transactions on Power Systems}, 
  title={Interpretable Hybrid Experimental Learning for Trading Behavior Modeling in Electricity Market}, 
  year={2023},
  volume={38},
  number={2},
  pages={1022-1032},
  abstract={A modern electricity market is essentially a complex network, characterized by complicated interactions among cyber communications, physical systems, and social agents. Trading behavior modeling has always been complicated in the physical system-based market. In this paper, trading behavior modeling in the electricity market is solved by a data-driven method combining experimental economics and machine learning, called Hybrid Experimental Learning (HEL). Based on the historical and experiment simulated data, HEL models the trading behavior by a machine learning generative model which will be interpreted by a post hoc interpretation approach. Taking a simulated electricity market based on the trial spot market rule in Guangdong, China as an example, a generative adversarial network (GAN) is employed to generate the offering strategies of a gas generator. Local interpretable model-agnostic explanation (LIME) as a post hoc interpretation approach is applied to explain the relationship between the output of GAN and some of the inputs of HEL, which can be described as offering mechanisms for the gas generator.},
  keywords={Behavioral sciences;Biological system modeling;Computational modeling;Data models;Generative adversarial networks;Analytical models;Electricity supply industry;Electricity markets;hybrid experimental learning;generative adversarial networks;local interpretable model-agnostic explanations},
  doi={10.1109/TPWRS.2022.3173654},
  ISSN={1558-0679},
  month={March},}@ARTICLE{10328639,
  author={Yuan, Jianjun and Liu, Tong and Xia, Haobo and Zou, Xu},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={A Novel Dense Generative Net Based on Satellite Remote Sensing Images for Vehicle Classification Under Foggy Weather Conditions}, 
  year={2023},
  volume={61},
  number={},
  pages={1-10},
  abstract={Accurate vehicle-type classification plays a crucial role in the development of intelligent transportation systems. Recently, several deep learning models have been proposed to utilize satellite remote sensing images for vehicle-type classification. However, conventional neural network models often have limitations when dealing with remote sensing images, such as adverse weather conditions, as well as the extremely low resolution of remote sensing images containing small objects like vehicles. To enhance the vehicle-type classification capability in complex environments, this article develops a novel deep learning framework called Dense Generative Net (DGNet). DGNet consists of three components: feature layer, generation layer, and dense feature fusion layer. The feature layer employs large convolutions to establish a broader receptive field, enabling it to capture more effective global feature information. The generation layer is based on a super-resolution (SR) network, which is designed to generate high-resolution feature information. The dense feature fusion layer performs the final classification by integrating the outputs from two upstream branches and combines the feature information obtained from the feature layer and the generated high-resolution features information from the generation layer, enabling comprehensive and robust classification of vehicle types. To evaluate recognition capability, vehicle data from multiple regions and diverse environmental conditions are utilized, including four different weather conditions. The experimental results demonstrate that DGNet exhibits remarkable vehicle-type recognition capability, with minimal degradation even under heavy foggy weather conditions. The effectiveness of each module and its impact on the overall performance have been verified through ablation experiments.},
  keywords={Remote sensing;Feature extraction;Convolutional neural networks;Meteorology;Transformers;Task analysis;Kernel;Dense Generative Net (DGNet);Foggy weather conditions;satellite remote sensing;vehicle classification},
  doi={10.1109/TGRS.2023.3336546},
  ISSN={1558-0644},
  month={},}@ARTICLE{10564681,
  author={Kranz, Philipp and Schirmer, Fabian and Kaupp, Tobias and Daun, Marian},
  journal={IEEE Software}, 
  title={Generative AI Copilot to Support Safety Analyses of Human–Robot Collaborations: Hazard Operability Analysis and GPT-4}, 
  year={2024},
  volume={41},
  number={6},
  pages={65-72},
  abstract={This article presents a novel framework that combines the hazard and operability analysis with generative AI to support a safety expert in identifying safety hazards, their causes and consequences, and to propose mitigation strategies.},
  keywords={Safety;Hazards;Generative AI;Robots;Task analysis;Artificial intelligence;Software engineering;Disaster management;Collaboration;Complexity theory;Human-robot interaction;Fourth Industrial Revolution;Risk management},
  doi={10.1109/MS.2024.3414445},
  ISSN={1937-4194},
  month={Nov},}@ARTICLE{10398474,
  author={Xu, Minrui and Du, Hongyang and Niyato, Dusit and Kang, Jiawen and Xiong, Zehui and Mao, Shiwen and Han, Zhu and Jamalipour, Abbas and Kim, Dong In and Shen, Xuemin and Leung, Victor C. M. and Poor, H. Vincent},
  journal={IEEE Communications Surveys & Tutorials}, 
  title={Unleashing the Power of Edge-Cloud Generative AI in Mobile Networks: A Survey of AIGC Services}, 
  year={2024},
  volume={26},
  number={2},
  pages={1127-1170},
  abstract={Artificial Intelligence-Generated Content (AIGC) is an automated method for generating, manipulating, and modifying valuable and diverse data using AI algorithms creatively. This survey paper focuses on the deployment of AIGC applications, e.g., ChatGPT and Dall-E, at mobile edge networks, namely mobile AIGC networks, that provide personalized and customized AIGC services in real time while maintaining user privacy. We begin by introducing the background and fundamentals of generative models and the lifecycle of AIGC services at mobile AIGC networks, which includes data collection, training, fine-tuning, inference, and product management. We then discuss the collaborative cloud-edge-mobile infrastructure and technologies required to support AIGC services and enable users to access AIGC at mobile edge networks. Furthermore, we explore AIGC-driven creative applications and use cases for mobile AIGC networks. Additionally, we discuss the implementation, security, and privacy challenges of deploying mobile AIGC networks. Finally, we highlight some future research directions and open issues for the full realization of mobile AIGC networks.},
  keywords={Computational modeling;Servers;Biological system modeling;Artificial intelligence;Generative AI;Surveys;Mobile handsets;AIGC;generative AI;mobile edge networks;communication and networking;AI training and inference;Internet technology},
  doi={10.1109/COMST.2024.3353265},
  ISSN={1553-877X},
  month={Secondquarter},}@ARTICLE{9424633,
  author={Zhu, Qinsong and Sun, Bintao and Zhou, Yuqing and Sun, Weifang and Xiang, Jiawei},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Sample Augmentation for Intelligent Milling Tool Wear Condition Monitoring Using Numerical Simulation and Generative Adversarial Network}, 
  year={2021},
  volume={70},
  number={},
  pages={1-10},
  abstract={Recent advances in artificial intelligence (AI) technology have led to increasing interest in the development of AI-based tool condition monitoring (TCM) methods. However, achieving good performance using these methods relies heavily on large training samples, which are both expensive and difficult to obtain in practical TCM applications. This article addresses this issue by employing a much smaller training sample composed of a non-exhaustive sampling of experimentally measured cutting force signals in conjunction with a novel data augmentation method that combines numerical simulation with a generative adversarial network (GAN). First, cutting force signal samples not present in the experimental dataset are obtained by numerical simulation using a finite element method simulated based on the Johnson-Cook model. Second, the GAN is employed to synthesize additional samples that are similar to both the simulated samples and the experimentally measured samples. The synthesized samples are combined with the measured and simulated samples to produce an appropriately large dataset necessary for the effective training of an AI classifier. The proposed sample augmentation method is applied in milling TCM experiments, and the classification accuracies obtained with several AI classifiers trained with the augmented dataset were all close to or equal to 100%.},
  keywords={Tools;Artificial intelligence;Numerical models;Milling;Generative adversarial networks;Frequency measurement;Numerical simulation;Generative adversarial network (GAN);Johnson–Cook model;milling tool;numerical simulation;tool condition monitoring (TCM)},
  doi={10.1109/TIM.2021.3077995},
  ISSN={1557-9662},
  month={},}@INPROCEEDINGS{8961501,
  author={Yu, Ying and Tang, Bingying and Lin, Ronglai and Han, Shufa and Tang, Tang and Chen, Ming},
  booktitle={2019 IEEE International Conference on Robotics and Biomimetics (ROBIO)}, 
  title={CWGAN: Conditional Wasserstein Generative Adversarial Nets for Fault Data Generation}, 
  year={2019},
  volume={},
  number={},
  pages={2713-2718},
  abstract={With the rapid development of modern industry and artificial intelligence technology, fault diagnosis technology has become more automated and intelligent. The deep learning based fault diagnosis model has achieved significant advantages over the traditional fault diagnosis method. However, a problem has arisen when deep learning models are applied to actual industrial scenarios. In the actual process of industrial production, there are not enough fault data for deep learning, hence the accuracy will decrease because of overfitting. In this paper, aiming at the problem, the fault data generation based on deep learning is deeply studied.In this paper, the data source is the experimental data from the Fault Data Center of Case Western Reserve University.Aiming at the problem of small amount of fault data, a method of generating fault time-frequency spectrum based on improved conditional generative adversarial networks is proposed. CWGAN (Conditional Wasserstein Generative Adversarial Nets) learns the feature of time-frequency spectrum of rolling bearing fault, and generates time-frequency spectrum of corresponding fault categories according to the input categories. Experiments show that the diversity and fidelity of data generated by CWGAN is better than that of the original generative adversarial networks. The VGG-Net model is used to train the fault data enhanced by CWGAN. It is found that the data generated by CWGAN can effectively supplement the small amount of fault data, improve the training effect of the model and avoid over-fitting.},
  keywords={Deep learning;Fault diagnosis;Training;Time-frequency analysis;Accuracy;Rolling bearings;Data collection;Generative adversarial networks;Data models;Overfitting;Rolling bearing;fault diagnosis;generative adversarial networks;deep learning;CWGAN},
  doi={10.1109/ROBIO49542.2019.8961501},
  ISSN={},
  month={Dec},}@ARTICLE{10643390,
  author={Hu, Xinrong and Yang, Chen and Fang, Fei and Huang, Jin and Li, Ping and Sheng, Bin and Lee, Tong-Yee},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={MSEmbGAN: Multi-Stitch Embroidery Synthesis via Region-Aware Texture Generation}, 
  year={2025},
  volume={31},
  number={9},
  pages={5334-5347},
  abstract={Convolutional neural networks (CNNs) are widely used for embroidery feature synthesis from images. However, they are still unable to predict diverse stitch types, which makes it difficult for the CNNs to effectively extract stitch features. In this paper, we propose a multi-stitch embroidery generative adversarial network (MSEmbGAN) that uses a region-aware texture generation sub-network to predict diverse embroidery features from images. To the best of our knowledge, our work is the first CNN-based generative adversarial network to succeed in this task. Our region-aware texture generation sub-network detects multiple regions in the input image using a stitch classifier and generates a stitch texture for each region based on its shape features. We also propose a colorization network with a color feature extractor, which helps achieve full image color consistency by requiring the color attributes of the output to closely resemble the input image. Because of the current lack of labeled embroidery image datasets, we provide a new multi-stitch embroidery dataset that is annotated with three single-stitch types and one multi-stitch type. Our dataset, which includes more than 30K high-quality multi-stitch embroidery images, more than 13K aligned content-embroidered images, and more than 17K unaligned images, is currently the largest embroidery dataset accessible, as far as we know. Quantitative and qualitative experimental results, including a qualitative user study, show that our MSEmbGAN outperforms current state-of-the-art embroidery synthesis and style-transfer methods on all evaluation indicators.},
  keywords={Image color analysis;Feature extraction;Task analysis;Electronic mail;Needles;Computer science;Training;Generative adversarial networks;multi-stitch embroidery synthesis;region-aware texture generation;style transfer},
  doi={10.1109/TVCG.2024.3447351},
  ISSN={1941-0506},
  month={Sep.},}@ARTICLE{10304153,
  author={Nie, Xinxin and Pu, Jing},
  journal={IEEE Access}, 
  title={Mixed Attention Mechanism Generative Adversarial Network Painting Image Conversion Algorithm Based on Multi-Class Scenes}, 
  year={2023},
  volume={11},
  number={},
  pages={123242-123252},
  abstract={With the rapid development of computer vision and artificial intelligence, image conversion technology has been widely applied in the fields of digital media and art. Based on the Generative adversarial network, this paper proposes a painting image conversion algorithm for multi class scenes. It performs deep feature extraction in the residual module, divides the encoding and decoding parts of the generator into functional parts, and designs them separately. The mixed attention module is inserted into the decoder and encoder to preserve the texture details of the image. The deep network interpolation is incorporated to achieve smooth and continuous conversion of the painting image. The experiment showed that the loss value of the research method decreases to 0.008 after 400 iterations during the loss value testing. Its maximum peak signal-to-noise ratio is 34.9dB when the bit rate increases to 1000kb/s. In the SAR image conversion dataset, the F1 value increases to 97.4 after 200 iterations. The pixel loss when it reaches 100% conversion in outdoor images is 5.38k. The data indicates that the research method has good performance in painting image conversion and can provide effective technical references for image conversion.},
  keywords={Painting;Feature extraction;Generators;Generative adversarial networks;Convolution;Decoding;Semiconductor device modeling;Computer vision;Artificial intelligence;Image conversion;generative adversarial network;mixed attention;deep network interpolation;global discrimination},
  doi={10.1109/ACCESS.2023.3329130},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10308219,
  author={Kumar, Ashish and Dwivedi, Pulkit},
  booktitle={2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={A Conditional Generative Adversarial Network Model for Sketch-to-Image Translation}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The sketch-to-image translation is a challenging task that involves generating realistic photographs from hand-drawn sketches. While Generative Adversarial Networks (GANs) have achieved remarkable success in generating real images, sketch-to-image translation remains difficult due to the limited information in the input sketches. Generative modeling problems can be addressed using GANs, which are a category of artificial intelligence algorithms. The objective of a generative model is to discover the probability distribution by analyzing training samples. This estimated probability distribution is then utilized by GANs to produce additional instances. In this paper, we propose a conditional GAN-based model for sketch-to-image translation tasks. By incorporating a loss function in the training process and learning mappings from input sketches to output images, these networks can handle various problems that previously required separate loss formulations. This approach allows for a versatile problem-solving technique using the same fundamental principles. Our suggested approach involves adversarial training of a generator and a discriminator, both of which are integrated into our model. The generator network takes the sketch and a textual description as input and generates a corresponding image. The discriminator network within our model is trained to distinguish between generated and authentic images. Consequently, the generator network is trained to produce images that can deceive the discriminator network into perceiving them as genuine.},
  keywords={Training;Analytical models;Art;Generative adversarial networks;Animation;Generators;Probability distribution;Computer Vision;Generative Adversarial Networks (GANs);Image Synthesis;Conditional GANs;Deep Learning;Automation},
  doi={10.1109/ICCCNT56998.2023.10308219},
  ISSN={2473-7674},
  month={July},}@ARTICLE{10293175,
  author={Lai, Yi-Wei and Chen, Mu-Yen},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={Using Natural Language Processing With Explainable AI Approach to Construct a Human-Centric Consumer Application for Financial Climate Disclosures}, 
  year={2024},
  volume={70},
  number={1},
  pages={1112-1121},
  abstract={Climate change is becoming an increasingly urgent issue. To encourage firms to include climate-related risk information in regular financial reports, the Task Force on Climate-related Financial Disclosures (TCFD) has developed a report format that provides detailed description of the risks and opportunities that enterprises will face due to climate change. Such information is of great concern for consumers, investors and regulators. However, manually accessing this information through individual financial reports is time-consuming. This research uses pre-trained models such as BERT, RoBERTa, and ClimateBERT to automate the detection and analysis of TCFD-related texts. The generative adversarial network (GAN) model is used to generate data with fewer labels, thereby improving classification performance as measured by accuracy, recall, precision, and F1-score. The detected texts are analyzed using explainable AI (XAI) to confirm which the text variables that will affect whether the paragraphs reflect internal support for climate change remediation efforts or lack of such support. In addition, the relationship between these variables and the final prediction results can be understood through the intensity value provided by XAI which reflects the degree of influence of each feature on the model detection results. The results show that the ClimateBERT model achieves a prediction accuracy rate of 90%, thus potentially helping consumers and investors better access important information to their consumption and investment decisions.},
  keywords={Data models;Climate change;Predictive models;Artificial intelligence;Generative adversarial networks;Text categorization;Deep learning;Explainable AI;Natural language processing;Climate change;text classification;deep learning;explainable AI;consumer systems},
  doi={10.1109/TCE.2023.3326953},
  ISSN={1558-4127},
  month={Feb},}@ARTICLE{11007661,
  author={Liu, Xiao-Yin and Li, Guotao and Zhou, Xiao-Hu and Liang, Xu and Hou, Zeng-Guang},
  journal={IEEE Transactions on Cybernetics}, 
  title={A Weight-Aware-Based Multisource Unsupervised Domain Adaptation Method for Human Motion Intention Recognition}, 
  year={2025},
  volume={55},
  number={7},
  pages={3131-3143},
  abstract={Accurate recognition of human motion intention (HMI) is beneficial for exoskeleton robots to improve the wearing comfort level and achieve natural human-robot interaction. A classifier trained on labeled source subjects (domains) performs poorly on unlabeled target subject since the difference in individual motor characteristics. The unsupervised domain adaptation (UDA) method has become an effective way to this problem. However, the labeled data are collected from multiple source subjects that might be different not only from the target subject but also from each other. The current UDA methods for HMI recognition ignore the difference between each source subject, which reduces the classification accuracy. Therefore, this article considers the differences between source subjects and develops a novel theory and algorithm for UDA to recognize HMI, where the margin disparity discrepancy (MDD) is extended to multisource UDA theory and a novel weight-aware-based multisource UDA algorithm (WMDD) is proposed. The source domain weight, which can be adjusted adaptively by the MDD between each source subject and target subject, is incorporated into UDA to measure the differences between source subjects. The developed multisource UDA theory is theoretical and the generalization error on target subject is guaranteed. The theory can be transformed into an optimization problem for UDA, successfully bridging the gap between theory and algorithm. Moreover, a lightweight network is employed to guarantee the real-time of classification and the adversarial learning between feature generator and ensemble classifiers is utilized to further improve the generalization ability. The extensive experiments verify theoretical analysis and show that WMDD outperforms previous UDA methods on HMI recognition tasks.},
  keywords={Brain modeling;Generators;Classification algorithms;Optimization;Exoskeletons;Accuracy;Training;Target recognition;Robot sensing systems;Feature extraction;Generalization bound;human motion intention recognition;multisource unsupervised domain adaptation},
  doi={10.1109/TCYB.2025.3565754},
  ISSN={2168-2275},
  month={July},}@INPROCEEDINGS{10014718,
  author={Patel, Manavkumar and Fatangare, Sonal and Nasare, Aryaman and Pachpute, Abhijeet},
  booktitle={2022 IEEE Pune Section International Conference (PuneCon)}, 
  title={Image-dev: An Advance Text to Image AI model}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={In the recent years, with the rapid growth of Artificial Intelligence, there is increasing interest in Text-to-Image models. High-quality images can be generated with state-of-art text-to-image AI models such as Imagen, DALL.E-2, Draw-Bench. However, these models struggle with generating well aligned images for conflict category and low database. Therefore, Image-dev is a Text-To-Image model that blends TF-IDF(Term Frequency - Inverse Document Frequency) model along with preposition model, to evaluate the relation between the data object. Proposed model output images have an unparalleled level of artistic finish and an added level of language understanding and interpretation further enhance model to produce conflict category images. Image-dev help user's to generate a high-quality, photorealistic images without any pre-context based on GANs, VAEs and diffusion model. Image-dev is based on diffusion model. Diffusion model is more relevant because of its high quality and realistic output generation capacity.},
  keywords={Inverse problems;Databases;Computational modeling;IEEE Sections;Diffusion processes;Data models;Artificial intelligence;DALL.E-2;Diffusion;Imagen;Preposition model;Photorealism;Text-to-Image;TF-IDF},
  doi={10.1109/PuneCon55413.2022.10014718},
  ISSN={2831-5022},
  month={Dec},}@ARTICLE{10530465,
  author={Muniyandi, Amutha Prabakar and Balusamy, Balamurugan and Dhanaraj, Rajesh Kumar and Ellappan, Vijayan and Murali, S. and Sathyamoorthy, Malathy and Nkenyereye, Lewis},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={Privacy Preserved Reinforcement Learning Model Using Generative AI for Personalized E-Learning}, 
  year={2024},
  volume={70},
  number={3},
  pages={6157-6165},
  abstract={Artificial intelligence algorithms are taking important roleplays in online recommendation models for achieving a high probability of success and these systems are slowly occupying modern learning systems. Modernized learning environments are designed based on personalized E-Learning system, due to the availability of enriched content and flexibility in the learning system. This paper proposed a personalized enriched course recommendation method for an e-learning environment using reinforcement techniques. The proposed method uses an Improved Artificial Bee Colony Optimisation (IABCO) algorithm-based generative AI model for preparing the course recommendations and this recommendation part will act as an Agent in the proposed personalized learning method. The proposed method uses IABCO algorithm for generating enriched course list based on personalized recommendation gather from customers and reinforcement learning model is used to evaluate the suggested course list. The proposed method is experimented with a dataset of online course offering website, which contains 3523 course details and 200 students are taken from various levels of learning maturity. The performance evaluation for the proposed system is measured based on success and accuracy rate of selection from the recommended course list. The average success rate and accuracy for the proposed method is 86.5% and 95.6% compared to the existing AI-based recommendation methods.},
  keywords={Electronic learning;Education;Artificial intelligence;Reinforcement learning;Recommender systems;Consumer electronics;Generative AI;Reinforcement learning;generative AI;artificial bee colony optimisation;privacy preserved learning system;course enriched learning system},
  doi={10.1109/TCE.2024.3398824},
  ISSN={1558-4127},
  month={Aug},}@ARTICLE{10480402,
  author={Ling, Xudong and Li, Chaorong and Qin, Fengqing and Zhu, LiHong and Huang, Yuanyuan},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={Two-Stage Rainfall-Forecasting Diffusion Model}, 
  year={2024},
  volume={21},
  number={},
  pages={1-5},
  abstract={Deep neural networks have made great achievements in rainfall prediction. However, the current forecasting methods have certain limitations, such as with blurry generated images and incorrect spatial positions. To overcome these challenges, we propose a Two-stage Rainfall-Forecasting Diffusion Model (TRDM) aimed at improving the accuracy of long-term rainfall forecasts and addressing the imbalance in performance between temporal and spatial modeling. TRDM is a two-stage method for rainfall prediction tasks. The task of the first stage is to capture robust temporal information while preserving spatial information under low-resolution conditions. The task of the second stage is to reconstruct the low-resolution images generated in the first stage into high-resolution images. We demonstrate the state-of-the-art results on the MRMS and Swedish radar datasets. On the Swedish dataset, our proposed method achieves a 5%–10%-point improvement in CSI compared to the other baseline methods for the 60–80 min prediction range. Our project is open source and available on GitHub at: https://github.com/clearlyzerolxd/TRDM.},
  keywords={Rain;Predictive models;Training;Image reconstruction;Spatial resolution;Computational modeling;Superresolution;Diffusion model;Generative adversarial networks (GANs);rainfall prediction},
  doi={10.1109/LGRS.2024.3382241},
  ISSN={1558-0571},
  month={},}@ARTICLE{10036438,
  author={Han, Sujy and Lee, Tae Bok and Heo, Yong Seok},
  journal={IEEE Access}, 
  title={Semantic-Aware Face Deblurring With Pixel-Wise Projection Discriminator}, 
  year={2023},
  volume={11},
  number={},
  pages={11587-11600},
  abstract={Most recent face deblurring methods have leveraged the distribution modeling ability of generative adversarial networks (GANs) to impose a constraint that the deblurred image should follow the distribution of sharp ground-truth images. However, generating sharp face images with high fidelity and realistic properties from a blurry face image remains challenging under the GAN framework. To this end, we focus on modeling the joint distribution of sharp face images and segmentation label maps for face image deblurring in a GAN framework. We propose a semantic-aware pixel-wise projection (SAPP) discriminator that models pixel-label matching with semantic label map information and generates a pixel-wise probability map of realness for the input image as well as a per-image probability. Moreover, we introduce a prediction-weighted (PW) loss to focus on erroneous pixels in the output of the decoder, using per-pixel real/fake probability map to re-weight the contribution of each pixel in the decoder. Furthermore, we present a coarse-to-fine training technique for the generator, which encourages the generator to focus on global consistency in the early training stages and local details in the later stages. Extensive experimental results show that our method outperforms existing methods both quantitatively and qualitatively in terms of perceptual image quality.},
  keywords={Face recognition;Image restoration;Generative adversarial networks;Predictive methods;Semantics;Face image deblurring;semantic-aware pixel-wise projection discriminator;prediction-weighted loss},
  doi={10.1109/ACCESS.2023.3242326},
  ISSN={2169-3536},
  month={},}@ARTICLE{10163862,
  author={Xie, Weicheng and Lu, Wenya and Peng, Zhibin and Shen, Linlin},
  journal={IEEE Transactions on Multimedia}, 
  title={Consistency Preservation and Feature Entropy Regularization for GAN Based Face Editing}, 
  year={2023},
  volume={25},
  number={},
  pages={8892-8905},
  abstract={Generative Adversarial Network (GAN) has been widely used for image-to-image translation-based facial attribute editing. Existing GAN networks are likely to generate samples with anomalies, which may be caused by the lack of consistency preservation and feature entanglement. For preserving image consistency, many studies resorted to the design of the network framework and loss functions, e.g. cycle-consistency loss. However, the generator with the cycle-consistency loss could not well preserve the attribute-irrelevant features, and its feature-level noises may possibly cause synthesis abnormalities. For feature disentanglement, previous works were devoted to mining the implicit semantics of feature spaces, while these semantics are not stable and intuitive enough. For consistency preservation, we propose a target consistency loss to complement the cycle-consistency loss, and enable the network to learn to preserve features of the image more directly. Meanwhile, we filter out outlier feature maps to reduce the synthesis abnormalities and propose a dynamic dropout to better preserve the attribute-irrelevant features. For feature disentanglement, we encode the image semantics more stably and intuitively and propose an entropy regularization to decouple these semantics to allow independent editing of different attributes. The proposed modules are general and can be easily integrated with available image-to-image-based GAN models like StarGAN, AttGAN, and STGAN. Extensive experiments on CelebA dataset show that the our strategy can largely reduce the artifacts and better preserve the subtle facial features, and thus significantly improve the facial editing performance of these mainstream GAN models, in terms of FID, PSNR and SSIM. Additional experiments on realistic expression editing show that our method outperforms StarGAN on RaFD, and achieves much better generalization performances than the three baselines on datasets of FFHQ, RaFD and LFW.},
  keywords={Generators;Generative adversarial networks;Semantics;Facial features;Training;Faces;Task analysis;GAN;Consistency preservation;Entropy regularization;Self-adaptive dropout},
  doi={10.1109/TMM.2023.3289757},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{10467357,
  author={Rojas, Elisa and Carrascal, David and Lopez-Pajares, Diego and Manso, Nicolas and Arco, Jose M.},
  booktitle={2024 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)}, 
  title={Towards AI-enabled Cloud Continuum for IIoT: Challenges and Opportunities}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The last decade has demonstrated an exponential growth in connected devices, particularly at the network edge, and this marked tendency still foresees a increase of the number of connected Internet-of-Things (IoT) devices. Accordingly, the network intelligence is moving from the core and cloud to the edge, establishing a cloud continuum. In this regard, Artificial Intelligence (AI) promotes that evolution and, at the same time, benefits from networking as well. Since Industrial IoT (IIoT) is one of the main verticals of this AI-enabled cloud continuum, in this article we explore the most recent advances in this area, the current status of standards, practical implementations, industry requirements, and, based on that analysis, we list a set of open challenges and opportunities. Our intention is to provide a summarized overview together with specific departing points for researchers in the field.},
  keywords={Computer science;Technological innovation;Service robots;Hydroponics;Robot sensing systems;Safety;Artificial intelligence;IIoT;edge continuum;cloud continuum;AI-enabled networking;softwarized networks},
  doi={10.1109/ACDSA59508.2024.10467357},
  ISSN={},
  month={Feb},}@ARTICLE{10906630,
  author={Wang, Qiong and Xu, Luyun and Shan, Yinglu and Shen, Wenzhuo and Li, Lou and Bi, Xia-An and Liu, Zhonghua},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={CPST-GAN: Conditional Probabilistic State Transition Generative Adversarial Network With the Biomedical Large Foundation Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-14},
  abstract={The risk prediction of Alzheimer’s disease (AD) is crucial for its early prevention and treatment. However, current risk prediction methods face challenges in effectively extracting and fusing multiomics features, particularly overlooking the multilevel evolutionary mechanisms of AD. This article combines biomedical large foundation models with the conditional generative adversarial network (GAN) to mine the evolutionary patterns of AD by considering the regulatory effect of genes on brain lesions. Specifically, we first use biomedical large foundation models to effectively construct high-quality imaging genetic features. Next, a conditional probabilistic state transition mathematical model is constructed to describe AD progression as state transitions of brain regions under genetic regulations. Based on the mathematical model, a conditional probabilistic state transition GAN (CPST-GAN) is proposed. This algorithm can mine the dynamic evolutionary patterns of AD by fusing brain imaging and genetic features to achieve risk prediction of AD. Finally, experiments on the public imaging genetics datasets validate the effectiveness and superiority of CPST-GAN in evolutionary pattern mining and risk prediction of AD. This article not only provides a reliable intelligence algorithm for early intervention of AD but also offers new insights for future research on AD pathogenesis. The code has been published at github.com/fmri123456/CPST-GAN.},
  keywords={Diseases;Foundation models;Data mining;Mathematical models;Probabilistic logic;Generative adversarial networks;Training;Feature extraction;Bioinformatics;Prediction algorithms;Alzheimer’s disease (AD);biomedical large foundation model;conditional probabilistic state transition (CPST) generative adversarial network (GAN);evolutionary pattern mining;imaging genetics;risk prediction},
  doi={10.1109/TNNLS.2025.3539006},
  ISSN={2162-2388},
  month={},}@INPROCEEDINGS{11076385,
  author={M, Tarunkumar and K R, Sujith and Thangam, M. Shanthi},
  booktitle={2025 7th International Conference on Intelligent Sustainable Systems (ICISS)}, 
  title={AI-Driven Recognition and Optimized Wellness Application [AROWA]}, 
  year={2025},
  volume={},
  number={},
  pages={1059-1065},
  abstract={The AROWA-Voice Assist Diagnostic AI is an advanced parallel leap in the development of healthcare diagnostics, employing Deep Learning (CNNs, RNNs) and Natural Language Processing (NLP) methods such as Transformers. With the utilization of text and voice inputs, the system provides diagnostic results through the analysis of patient queries, symptoms, and additional data such as laboratory results. AROWA is designed with an end-user interface that is easy to engage with, including for those with low technical skills. Experimental evaluations demonstrate AROWA achieves a better diagnostic accuracy rate than traditional conventional methods and significantly reduces misdiagnosis rates. This paper details the technical methodology, empirical findings, and broader implications of deploying AROWA in clinical settings.},
  keywords={Deep learning;Image segmentation;Accuracy;Transformers;Natural language processing;Data models;Satellite images;Environmental monitoring;Medical diagnosis;Artificial intelligence;Index Terms - Diagnostic AI;Voice Assist;Deep Learning;CNN;RNN;NLP;Transformers;Healthcare;Accessibility;Diagnostic Precision},
  doi={10.1109/ICISS63372.2025.11076385},
  ISSN={},
  month={March},}@ARTICLE{10793414,
  author={Liu, Tongfei and Xu, Jianjian and Lei, Tao and Wang, Yingbo and Du, Xiaogang and Zhang, Weichuan and Lv, Zhiyong and Gong, Maoguo},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={AEKAN: Exploring Superpixel-Based AutoEncoder Kolmogorov-Arnold Network for Unsupervised Multimodal Change Detection}, 
  year={2025},
  volume={63},
  number={},
  pages={1-14},
  abstract={Multimodal change detection (MCD) has garnered significant interest due to its capacity to address a variety of emergencies in a timely and effective manner. However, discrepancies in sensors and imaging techniques often hinder the direct comparison of heterogeneous remote sensing images (HRSIs), making it difficult to extract change information. To overcome this challenge, we propose a novel superpixel-based AutoEncoder Kolmogorov-Arnold Network (AEKAN) for unsupervised MCD. The primary objective of AEKAN is to excavate the latent commonality features between HRSIs. Notably, commonality features in unchanged regions are generally more pronounced than those in changed regions, which can be leveraged to assess change magnitude. To achieve this, the proposed method utilizes the Kolmogorov-Arnold Network (KAN), renowned for its capability to model data distributions, to extract these commonality features between HRSIs. Concretely, the proposed AEKAN consists of a Siamese KAN encoder and dual KAN decoders. The Siamese encoder aims to map HRSIs and extract latent commonality features, while the dual decoders reconstruct original bitemporal images from these features. In addition, we incorporate a hierarchical commonality loss function within the Siamese encoder to train AEKAN. This loss function is designed to intentionally guide the network in capturing commonality features by minimizing the discrepancies in features extracted from HRSIs at each layer of the Siamese encoder. The extracted commonality features are then adopted to quantify the change magnitude between images through mean square error (MSE). Extensive experiments on five MCD datasets demonstrate that the proposed AEKAN outperforms existing methods. The source code is available at: https://github.com/TongfeiLiu/AEKAN-for-MCD.},
  keywords={Feature extraction;Sensors;Image sensors;Training;Remote sensing;Sensor phenomena and characterization;Land surface;Analytical models;Sun;Radar imaging;Commonality features;heterogeneous images;Kolmogorov-Arnold Network (KAN);multimodal change detection (MCD)},
  doi={10.1109/TGRS.2024.3515258},
  ISSN={1558-0644},
  month={},}@ARTICLE{10803279,
  author={Zhang, Chengyang and Zhang, Yong and Shao, Qitan and Li, Bo and Lv, Yisheng and Piao, Xinglin and Yin, Baocai},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={ChatTraffic: Text-to-Traffic Generation via Diffusion Model}, 
  year={2025},
  volume={26},
  number={2},
  pages={2656-2668},
  abstract={The analysis of traffic situations under abnormal conditions is one of the bottleneck issues in Intelligent Transportation Systems (ITS). Influenced by the suddenness, randomness, and uncertainty, this issue is challenging to achieve through existing deep learning methods. It needs to be assisted by traffic simulation models for analysis. However, simulation models always require extensive scene modeling and calibration, making it difficult to meet the demands of natural human-machine interaction in the AIGC (Artificial Intelligence Generated Content) era, as well as the need for rapid and flexible implementation of situation analysis. With the accumulation of traffic data, the emergence of diffusion models offers a new entry point for the core method of data-driven analysis, namely Text-to-Traffic Generation (TTG). In this work, we explore how generative models combined with text describing the traffic system can be applied for traffic situation generation, and propose ChatTraffic, the first diffusion model for TTG. To guarantee the consistency between synthetic and real data, we augment a diffusion model with the Graph Convolutional Network (GCN) to extract spatial correlations of traffic data. In addition, we construct a large-scale dataset containing text-traffic pairs for TTG. We benchmarked ChatTraffic qualitatively and quantitatively on the released dataset. The experimental results indicate that ChatTraffic can rapidly and flexibly generate realistic traffic situations from text, which have practical significance in addressing bottlenecks in ITS. Our code and dataset are available at https://github.com/ChyaZhang/ChatTraffic.},
  keywords={Diffusion models;Transportation;Social networking (online);Generative adversarial networks;Predictive models;Training;Traffic control;Roads;Analytical models;Long short term memory;Intelligent transportation systems;traffic situation generation;diffusion models},
  doi={10.1109/TITS.2024.3510402},
  ISSN={1558-0016},
  month={Feb},}@INPROCEEDINGS{11013160,
  author={Hadi, Wael and Alnashashibi, May and Al Authman, Mohammad and Al-Banna, Abedal-Kareem and Arafah, Mohammad},
  booktitle={2025 1st International Conference on Computational Intelligence Approaches and Applications (ICCIAA)}, 
  title={Exploring Data Augmentation Techniques for Enhancing Machine Learning Models in Autism Detection}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Early detection of Autism Spectrum Disorder (ASD), a neurodevelopmental condition that affects social interaction, communication, and behavioural patterns, is imperative for timely intervention and support. This study investigates the application of generative adversarial networks (GANs) to enhance ASD detection through data augmentation of tabular autism datasets. We evaluate three GAN architectures-Conditional GANs (CGANs), Wasserstein GANs (WGANs), and Conditional Table GANs (CTGANs)-for generating synthetic data to supplement existing datasets at varying augmentation ratios (25%, 50%, and 75%). The effectiveness of this approach is assessed using four established machine learning algorithms: Logistic Regression (LR), Naive Bayes (NB), Support Vector Machines (SVM), and K-Nearest Neighbors (KNN). Our findings reveal that SVM maintains consistent performance across all GAN models, demonstrating its reliability for ASD detection. Furthermore, CTGAN-based augmentation at specific ratios yields notable NB and LR performance improvements. These results not only validate the possibility of using data augmentation to improve performance in autism detection models but also serve as a foundation for future work in identifying optimal augmentation techniques for autism datasets. This research makes a substantial and important contribution towards the development of early ASD detection methods that could help to improve intervention outcomes and, thus also, quality of life for people with autism.},
  keywords={Support vector machines;Autism;Computational modeling;Machine learning;Nearest neighbor methods;Generative adversarial networks;Data augmentation;Data models;Reliability;Synthetic data;Autism Spectrum Disorder (ASD);Machine Learning;Data Augmentation;Generative Adversarial Networks (GANs);Conditional GAN (CGAN);Wasserstein GAN (WGAN);Conditional Table GAN (CTGAN)},
  doi={10.1109/ICCIAA65327.2025.11013160},
  ISSN={},
  month={April},}@ARTICLE{10891258,
  author={Song, Zhe and Tao, Yi and Hua, Zizheng and Wang, Shuai and Pan, Gaofeng and An, Jianping},
  journal={IEEE Vehicular Technology Magazine}, 
  title={Generative Artificial Intelligence-Empowered Multidomain Internet of Vehicles Systems: Scalability, Efficiency, and Suitability}, 
  year={2025},
  volume={20},
  number={2},
  pages={53-62},
  abstract={In the rapidly evolving landscape of aerial–terrestrial–marine integrated transportation, vehicular communication systems are confronted with various challenges, including unpredictable signal fading, the scarcity of spectrum resources, and the complexity of network topologies. This article introduces a novel generative artificial intelligence (GAI)-driven model designed to enhance the Internet of Vehicles (IoV) across these domains. The proposed system enhances situational awareness by seamlessly integrating multisource data, offering a real-time and unified environmental view supporting precise predictive analytics. Additionally, the model employs generative diffusion models (GDMs) in cognitive radio (CR), optimizing spectrum utilization through dynamic sensing and adaptive allocation strategies. Furthermore, the system redefines network performance by enabling real-time configuration adjustments and optimizing communication paths to adapt to ever-changing conditions. Our findings demonstrate that GAI has the potential to significantly improve the scalability, efficiency, and suitability of IoV systems, paving the way for smarter and more resilient vehicular communications in complex multidomain environments.},
  keywords={Sensors;Real-time systems;Resource management;Vehicle dynamics;Optimization;Transportation;Wireless communication;Vehicle-to-everything;Satellites;Laser radar;Generative AI;Internet of Vehicles},
  doi={10.1109/MVT.2025.3534973},
  ISSN={1556-6080},
  month={June},}@INPROCEEDINGS{10528477,
  author={Wei, Yujia and Xiao, Hanguang and Shi, Xinyi and Li, Huanqi and Wang, Wei},
  booktitle={2023 7th Asian Conference on Artificial Intelligence Technology (ACAIT)}, 
  title={Deep Learning for Medical Image Super-Resolution: A Review}, 
  year={2023},
  volume={},
  number={},
  pages={463-472},
  abstract={Medical image super-resolution (SR) reconstruction technology has a wide range of scenarios and important values in medical diagnosis. The use of SR reconstruction algorithms can enhance low-resolution (LR) medical images into high-resolution (HR) medical images, thus overcoming the problems of low spatial resolution caused by the limitations of physical equipment conditions of image acquisition and the own limitations of imaging principles, and can present the details of human organs or tissues more clearly, especially making the local feature information of lesion points, thus assisting doctors to make a more accurate diagnosis in the clinic. This paper reviews the research on medical image SR reconstruction methods at home and abroad, firstly introduces the performance indexes for evaluating image SR reconstruction methods, then systematically describes the medical image SR reconstruction technology based on deep learning methods, and finally analyzes the problems that still exist in this field and points out the future research directions.},
  keywords={Deep learning;Reviews;Superresolution;Reconstruction algorithms;Performance analysis;Medical diagnosis;Lesions;Medical images;Super-resolution reconstruction;Deep learning},
  doi={10.1109/ACAIT60137.2023.10528477},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11115816,
  author={Joshi, Rahul and Pandey, Krishna and Kumari, Suman},
  booktitle={2025 12th International Conference on Computing for Sustainable Global Development (INDIACom)}, 
  title={Unlocking the Potential of Deep Learning in Medical Image Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Deep learning has transformed illness detection and is assisting the healthcare industry in overcoming obstacles related to correctness and reliability to develop effective as well as resilient computer-aided diagnostic tools. Deep learning approaches provide automated AI-driven utilities that need minimum human oversight to execute tasks associated with the medical detection of fractures, malignancies, internal bleeding, preoperative planning, and intra-operative guiding. Nonetheless, deep learning encounters significant challenges within the burgeoning healthcare sector. This article analyzes the primary obstacles facing the deep learning (DL) research and engineering community in the medical image diagnosis, specifically balanced annotated medical image datasets deficiency, adversarial attacks on deep neural networks (DNN) as well as architectures stemming from noisy medical images, patients' & users' lack of trust, along with ethical and privacy concerns of medical data. This research investigates potential for AI autonomy in healthcare by addressing societal trust issues about autonomous intelligent systems.},
  keywords={Deep learning;Industries;Image analysis;Medical services;Planning;Reliability;Noise measurement;Intelligent systems;Hemorrhaging;Medical diagnostic imaging;Healthcare;Artificial intelligence;deep learning;diseases;adversarial effect;medical image analysis;convolutional neural network},
  doi={10.23919/INDIACom66777.2025.11115816},
  ISSN={},
  month={April},}@ARTICLE{11113318,
  author={Wang, Nian and Cui, Zhigao and Su, Yanzhao and Lan, Yunwei and Xue, Yuanliang and Zhang, Cong and Li, Aihua},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Weakly Supervised Image Dehazing via Physics-Based Decomposition}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Recent weakly supervised image dehazing (WSID) works have succeeded to improve models’ generalization ability to real scene dehazing by using generative adversarial network (GAN) for unpaired image training. However, it is still difficult for current WSID methods to train one effective dehazing model for various scenes since 1) they always result in residual haze due to insufficient generalization to the feature distribution of real scenes, and 2) they are prone to cause distortions like color shifts, artifacts or halos etc, owing to embedding manual prior or threshold hypothesis for image reconstruction. To solve above problems, in this paper, we propose a novel WSID model via physics-based decomposition (PBD), which estimates atmospheric light, scattering coefficient and scene depth of real haze input to effectively capture the illumination information and haze distribution to recover a preliminary dehazed image by minimizing reconstruction loss. With this constraint, we subtly design a discrete wavelet discriminator (DWD) to effectively improve the generalization to real scene from both spatial and frequency aspect under the supervision of unpaired real clear image. Our PBD is a purely data-driven model freeing from any manual setting or partially correct prior, thus simultaneously ensuring the realness and visibility of dehazed images. Experiments on seven benchmarks verified the strong generalization ability of our PBD, which achieves SOTA dehazing performance with realistic details. Code will be published at https://github.com/NianWang-HJJGCDX/PBD.},
  keywords={Training;Atmospheric modeling;Scattering;Image color analysis;Image dehazing;Image reconstruction;Distortion;Generative adversarial networks;Image restoration;Discrete wavelet transforms;Weakly supervised image dehazing;generative adversarial network;discrete wavelet discriminator},
  doi={10.1109/TCSVT.2025.3596024},
  ISSN={1558-2205},
  month={},}@ARTICLE{9999180,
  author={Tran, Van-Nhan and Kwon, Seong-Geun and Lee, Suk-Hwan and Le, Hoanh-Su and Kwon, Ki-Ryong},
  journal={IEEE Access}, 
  title={Generalization of Forgery Detection With Meta Deepfake Detection Model}, 
  year={2023},
  volume={11},
  number={},
  pages={535-546},
  abstract={Face forgery generating algorithms that produce a range of manipulated videos/images have developed quickly. Consequently, this causes an increase in the production of fake information, making it difficult to identify. Because facial manipulation technologies raise severe concerns, face forgery detection is gaining increasing attention in the area of computer vision. In real-world applications, face forgery detection systems frequently encounter and perform poorly in unseen domains, due to poor generalization. In this paper, we propose a deepfake detection method based on meta-learning called Meta Deepfake Detection (MDD). The goal of the model is to develop a generalized model capable of directly solving new unseen domains without the need for model updates. The MDD algorithm establishes various weights for facial images from various domains. Specifically, MDD uses meta-weight learning to shift information from the source domains to the target domains with meta-optimization steps, which aims for the model to generate effective representations of the source and target domains. We build multi-domain sets using meta splitting strategy to create a meta-train set and meta-test set. Based on these sets, the model determines the gradient descent and obtains backpropagation. The inner and outer loop gradients were aggregated to update the model to enhance generalization. By introducing pair-attention loss and average-center alignment loss, the detection capabilities of the system were substantially enhanced. In addition, we used some evaluation benchmarks established from several popular deepfake datasets to compare the generalization of our proposal in several baselines and assess its effectiveness.},
  keywords={Face recognition;Artificial intelligence;Deepfakes;Forgery;Task analysis;Feature extraction;Computer vision;Deepfake detection;meta-learning;artificial intelligence;computer vision},
  doi={10.1109/ACCESS.2022.3232290},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10867401,
  author={Chohan, Ikhlaq and Khan, Ijaz},
  booktitle={2024 2nd International Conference on Computing and Data Analytics (ICCDA)}, 
  title={Enhancing Mathematics Education with ChatGPT-4 Personalized Problem-Solving and Consistent Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The paper presents AI-MathBot, an innovative AI-driven educational tool designed to address challenges in teaching mathematical concepts, particularly in calculus. AI-MathBot focuses on providing personalized and consistent solutions, aligned with classroom instruction, to enhance students' learning experiences. The tool specifically assists in finding intercepts in linear equations, offering step-by-step guidance, tailored practice problems, and quizzes with immediate feedback. By leveraging Generative AI, such as ChatGPT, AI-MathBot ensures that students receive solutions that mirror the methods taught by their instructors, addressing the common issue of inconsistencies found in online resources. The paper outlines the development process, including the phases of Preliminary Settings, Prompt Design, and Evaluation, and highlights the robot's effectiveness in delivering accurate, reliable, and contextually relevant support, making it a significant advancement in educational technology.},
  keywords={Accuracy;Refining;Learning (artificial intelligence);Chatbots;Reliability engineering;Real-time systems;Mirrors;Problem-solving;Usability;Robots;Generative Artificial Intelligence;ChatGPT;AI-Driven Learning;Mathematical problem-solving;Personalized learning},
  doi={10.1109/ICCDA64887.2024.10867401},
  ISSN={},
  month={Nov},}@ARTICLE{11072807,
  author={Hashima, Sherief and Gendia, Ahmad and Hatano, Kohei and Muta, Osamu and Nada, Mostafa S. and Mohamed, Ehab Mahmoud},
  journal={IEEE Open Journal of Vehicular Technology}, 
  title={Next-Gen UAV-Satellite Communications: AI Innovations and Future Prospects}, 
  year={2025},
  volume={6},
  number={},
  pages={1990-2021},
  abstract={The convergence of sixth-generation (6G) networks with unmanned aerial vehicles (UAVs) and satellites is poised to introduce substantial improvements to the landscape of wireless communication, paving the way for a unified and uninterrupted space-air-ground-sea network that ensures comprehensive global connectivity. At the heart of this transformative paradigm lies artificial intelligence (AI), which drives innovation across diverse sectors by enhancing decision-making autonomy, enabling real-time data processing, and optimizing network performance and coverage. This survey paper explores AI-enabled UAV-satellite communications for 6G applications, focusing on its challenges, potential, and future. This new system combines the strengths of 6G networks, UAVs (advanced drones), and satellites. It opens up new possibilities in precision agriculture, disaster management, enhanced telecommunication services, and remote sensing. Despite its promise, this field faces complex challenges. These include spectrum management, security risks, regulatory barriers, and integrating AI operations seamlessly. This paper comprehensively analyzes these challenges, offering innovative solutions and outlining future research directions to unlock the complete capabilities of 6G-enabled UAV-satellite communications. Furthermore, it includes a case study demonstrating the effectiveness of multi-armed bandit (MAB) algorithms in optimizing resource allocation and decision-making processes for UAV-low Earth orbit (LEO) satellite communication scenarios, showcasing significant improvements in network performance. This work lays the foundation for a new generation of ultra-connected, data-driven applications that will redefine global connectivity and technological advancement by addressing these critical aspects.},
  keywords={6G mobile communication;Autonomous aerial vehicles;Satellites;Artificial intelligence;Satellite communications;Real-time systems;Low latency communication;Low earth orbit satellites;Earth;Technological innovation;Sixth-generation (6G);artificial intelligence (AI);unmanned aerial vehicles (UAVs);satellite communications;multi-armed bandit (MAB);generative adversarial network (GAN);large language model (LLM)},
  doi={10.1109/OJVT.2025.3587028},
  ISSN={2644-1330},
  month={},}@INPROCEEDINGS{10085665,
  author={Narayan, Vipul and Awasthi, Shashank and Fatima, Naushen and Faiz, Mohammad and Srivastava, Swapnita},
  booktitle={2023 International Conference on Artificial Intelligence and Smart Communication (AISC)}, 
  title={Deep Learning Approaches for Human Gait Recognition: A Review}, 
  year={2023},
  volume={},
  number={},
  pages={763-768},
  abstract={Many biometric authentication techniques have been defined over the years; of these techniques, Human Gait recognition has gathered popularity over the years due to its ability to recognize a person from a distance. As the data has grown in size the focus has shifted from basic Machine Learning algorithms to Deep Learning based approaches. This paper aims to review the various deep-learning approaches used in the discipline of gait identification. This review comprises recent trends in these deep learning approaches, Convolutional Neural networks, Capsule Networks, Recurrent Neural Networks, Autoencoders, Deep Belief Networks, and Generative Adversarial Networks.},
  keywords={Deep learning;Recurrent neural networks;Machine learning algorithms;Authentication;Learning (artificial intelligence);Generative adversarial networks;Market research;Gait Recognition;Deep Learning (DL);Convolutional Neural Network (CNN);Recurrent Neural Network (RNN);Capsule Networks;Autoencoders;Deep Belief Networks;Generative Adversarial Networks (GAN)},
  doi={10.1109/AISC56616.2023.10085665},
  ISSN={},
  month={Jan},}@ARTICLE{11148286,
  author={Ren, Lei and Wang, Haiteng and Li, Jinwang and Tang, Yang and Yang, Chunhua},
  journal={IEEE Transactions on Systems, Man, and Cybernetics: Systems}, 
  title={AIGC for Industrial Time Series: From Deep-Generative Models to Large-Generative Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-18},
  abstract={With the remarkable success of generative models like ChatGPT, artificial intelligence generated content (AIGC) is undergoing explosive development. Not limited to text and images, generative models can generate industrial time series data, addressing challenges, such as the difficulty of data collection and data annotation. Due to their outstanding generation ability, they have been widely used in Internet of Things, metaverse, and CPSS to enhance the efficiency of industrial production. In this article, we present a comprehensive overview of generative models for industrial time series from deep-generative models (DGMs) to large-generative models (LGMs). First, a DGM-based AIGC framework is proposed for industrial time series generation. Within this framework, we survey advanced industrial DGMs and present a multiperspective categorization. Then, we systematically propose the roadmap to construct industrial LGMs from four aspects: large-scale industrial dataset, LGMs architecture for complex industrial characteristics, self-supervised training for industrial time series, and fine-tuning of industrial downstream tasks. Furthermore, we introduce an evaluation benchmark that systematically assesses fidelity, diversity, and utility. We include a case study on aircraft engine maintenance, demonstrating the application of DGMs in industrial predictive maintenance. Finally, we conclude the challenges and future directions to enable the development of generative models in industry.},
  keywords={Time series analysis;Data models;Diffusion models;Industries;Surveys;Reviews;Data collection;Atmospheric modeling;Transformers;Predictive models;AIGC;diffusion model;generative model;industrial time series;predictive maintenance},
  doi={10.1109/TSMC.2025.3598252},
  ISSN={2168-2232},
  month={},}@BOOK{10769230,
  author={Bustos, Juan Pablo and Soria, Luis Lopez and Arsanjani, Dr. Ali},
  booktitle={Generative AI Application Integration Patterns: Integrate large language models into your applications},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Unleash the transformative potential of GenAI with this comprehensive guide that serves as an indispensable roadmap for integrating large language models into real-world applications. Gain invaluable insights into identifying compelling use cases, leveraging state-of-the-art models effectively, deploying these models into your applications at scale, and navigating ethical considerations.Key FeaturesGet familiar with the most important tools and concepts used in real scenarios to design GenAI appsInteract with GenAI models to tailor model behavior to minimize hallucinationsGet acquainted with a variety of strategies and an easy to follow 4 step frameworks for integrating GenAI into applicationsBook DescriptionExplore the transformative potential of GenAI in the application development lifecycle. Through concrete examples, you will go through the process of ideation and integration, understanding the tradeoffs and the decision points when integrating GenAI. With recent advances in models like Google Gemini, Anthropic Claude, DALL-E and GPT-4o, this timely resource will help you harness these technologies through proven design patterns. We then delve into the practical applications of GenAI, identifying common use cases and applying design patterns to address real-world challenges. From summarization and metadata extraction to intent classification and question answering, each chapter offers practical examples and blueprints for leveraging GenAI across diverse domains and tasks. You will learn how to fine-tune models for specific applications, progressing from basic prompting to sophisticated strategies such as retrieval augmented generation (RAG) and chain of thought. Additionally, we provide end-to-end guidance on operationalizing models, including data prep, training, deployment, and monitoring. We also focus on responsible and ethical development techniques for transparency, auditing, and governance as crucial design patterns.What you will learnConcepts of GenAI: pre-training, fine-tuning, prompt engineering, and RAGFramework for integrating AI: entry points, prompt pre-processing, inference, post-processing, and presentationPatterns for batch and real-time integrationCode samples for metadata extraction, summarization, intent classification, question-answering with RAG, and moreEthical use: bias mitigation, data privacy, and monitoringDeployment and hosting options for GenAI modelsWho this book is forThis book is not an introduction to AI/ML or Python. It offers practical guides for designing, building, and deploying GenAI applications in production. While all readers are welcome, those who benefit most include: Developer engineers with foundational tech knowledge Software architects seeking best practices and design patterns Professionals using ML for data science, research, etc., who want a deeper understanding of Generative AI Technical product managers with a software development background This concise focus ensures practical, actionable insights for experienced professionals},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835887615},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10769230},}@INPROCEEDINGS{10627567,
  author={Richard, Rohan Paul and Veemaraj, Ebenezer and Thomas, Juanith Mathew and Mathew, Joel and Stephen, Caleb and Koshy, Richie Suresh},
  booktitle={2024 4th International Conference on Intelligent Technologies (CONIT)}, 
  title={A Client-Server Based Educational Chatbot for Academic Institutions}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The use of Generative AI applications in academia, such as ChatGPT, Bard and Perplexity among others is growing at a rapid pace. With its rise, certain ramifications are being felt in regards to the quality and correctness of knowledge and output of these apps. This is detrimental to the process of learning and understanding subject matter in relevant context. In order to stop this issue in its tracks, a solution must be identified, built, tested and deployed so that students will get reliable outputs from trusted sources. This research analyses and describes a sample architecture as well as implementation for such a solution. It incorporates the latest in AI research and development, such as the Large Language Model Mixture of Experts (MoE) architecture as well as a Retrieval Augmented Generation (RAG) with a vector store to use trusted documents such as presentation files, PDF handouts and more from instructors. This is used to add context to the request to the Large Language Model and enrich the understanding as well as response of the model. Apart from this, the application is packaged into a server that can be run on the intranet, as well as deployed for public access. A frontend client page is served to the user, and communicates with the server for all its functioning.},
  keywords={Generative AI;Large language models;Chatbots;Portable document format;Vectors;Servers;Reliability;Generative AI;Large Language Model (LLM);Retrieval Augmented Generation (RAG);Mixture of Experts;LangChain},
  doi={10.1109/CONIT61985.2024.10627567},
  ISSN={},
  month={June},}@ARTICLE{10374256,
  author={Ye, Zipeng and Luo, Wenjian and Zhang, Ruizhuo and Zhang, Hongwei and Shi, Yuhui and Jia, Yan},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={An Evolutionary Attack for Revealing Training Data of DNNs With Higher Feature Fidelity}, 
  year={2024},
  volume={21},
  number={4},
  pages={4193-4205},
  abstract={Model inversion attacks aim to reveal information about sensitive training data of AI models, which may lead to serious privacy leakage. However, existing attack methods have limitations in reconstructing training data with higher feature fidelity. In this article, we propose an evolutionary model inversion attack approach (EvoMI) and empirically demonstrate that combined with the systematic search in the multi-degree-of-freedom latent space of the generative model, the simple use of an evolutionary algorithm can effectively improve the attack performance. Concretely, at first, we search for latent vectors which can generate images close to the attack target in the latent space with low-degree of freedom. Generally, the low-freedom constraint will reduce the probability of getting a local optima compared to existing methods that directly search for latent vectors in the high-freedom space. Consequently, we introduce a mutation operation to expand the search domain, thus further reduce the possibility of obtaining a local optima. Finally, we treat the searched latent vectors as the initial values of the post-processing and relax the constraint to further optimize the latent vectors in a higher-freedom space. Our proposed method is conceptually simple and easy to implement, yet it achieves substantial improvements and outperforms the state-of-the-art methods significantly.},
  keywords={Data models;Image reconstruction;Training data;Predictive models;Manifolds;Training;Artificial intelligence;Artificial intelligence security;privacy protection;model inversion attack},
  doi={10.1109/TDSC.2023.3347225},
  ISSN={1941-0018},
  month={July},}@INPROCEEDINGS{10616855,
  author={Chaudhary, Diwakar and Almusawi, Muntather and Sabr, Abdul Redha Hussein and Aeri, Manisha and Ftaiet, Adnan Allwi and Taaban, Nabaa Kareem and Mudhafar, Mustafa},
  booktitle={2024 4th International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)}, 
  title={The Plant’s Leaf Identification using G-A-N and Using IA Technique}, 
  year={2024},
  volume={},
  number={},
  pages={1376-1380},
  abstract={The identification of the disease of paddy leaves is a very critical issue, as it is quite hard with the naked eye, and even professionals like agricultural scientists may make mistakes in this regard. This is a problem that our approach, which we undertake in this paper, may remedy. In this paper, we present deep learning with the use of generative adversarial networks in leaf disease diagnosis using artificial intelligence. In our experiment, we used a dataset with 12,880 paddy leaf images produced by Cycle GAN, displaying five main disease classifications. GANs should be taken into consideration while data augmentation is performed to prevent overfitting, while a GAN design that uses two networks-a Generator and a Discriminator-is suggested. The generator was taught to produce samples of data that are comparable to the original data. The deep learning proposed approach can be regarded as an important tool for early disease identification in the detection and classification of paddy leaf diseases.},
  keywords={Deep learning;Generative adversarial networks;Data augmentation;Generators;Medical diagnosis;Artificial intelligence;Diseases;Plant leaf disease;Paddy Leaf;Deep learning;Cycle GAN;CNN;Deep Learning},
  doi={10.1109/ICACITE60783.2024.10616855},
  ISSN={},
  month={May},}@INPROCEEDINGS{10816877,
  author={K, Priya and Kamath, Akshatha and K M, Chandan and C, Praveen and S N, Omkar and S J, Aaditya},
  booktitle={2024 8th International Conference on Computational System and Information Technology for Sustainable Solutions (CSITSS)}, 
  title={Enhancing Q&A Systems with Multilingual Text Conversion and Speech Integration: Harnessing the Power of LangChain and Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Searching through URLs and PDFs can be tedious and time-consuming because of the unstructured nature of these documents and the challenge of finding accurate and, relevant information. LangChain addressed these issues using advanced natural language processing algorithms to extract pertinent data from URLs and PDFs. With its user-friendly search interface, customizable filters, and efficient indexing and retrieval mechanisms, LangChain significantly enhances the search experience. Users can annotate important sections, store queries, and create bookmarks, making information retrieval from URLs and PDFs more efficient and improving the overall productivity. Traditional text analysis systems often struggle with interactivity, flexibility, and data integration, making it difficult for users to gain meaningful insights from diverse data sources such as websites and PDFs. Our research combines state-of-the-art technologies, including Dash, LangChain, Google Generative AI, and FAISS, to provide a comprehensive solution for extracting, analysing, and interacting with textual data from various sources. This includes handling both PDFs and the data uploaded via URLs. Our research demonstrates significant improvements in the efficiency and accuracy of information retrieval, paving the way for more complex applications such as text summarization and question-answering. Our system is also capable of converting text into speech and translating it into 10 different languages.},
  keywords={Uniform resource locators;Accuracy;Translation;Generative AI;Large language models;Soft sensors;Text summarization;Probability density function;Speech enhancement;Information retrieval;LangChain;ChatGPT;OpenAI;Deep Learning;Google Generative AI;Vector Embeddings;FAISS;Semantic Search},
  doi={10.1109/CSITSS64042.2024.10816877},
  ISSN={2767-1097},
  month={Nov},}@INPROCEEDINGS{10315503,
  author={Chen, Luyu and Shen, Lin and Yu, Dan and Wang, Zhihua and Qian, Kun and Hu, Bin and Schuller, Björn W. and Yamamoto, Yoshiharu},
  booktitle={2023 IEEE 12th Global Conference on Consumer Electronics (GCCE)}, 
  title={Multi-Track Music Generation with WGAN-GP and Attention Mechanisms}, 
  year={2023},
  volume={},
  number={},
  pages={606-607},
  abstract={Music generation with artificial intelligence is a complex and captivating task. The utilisation of generative adversarial networks (GANs) has exhibited promising outcomes in producing realistic and diverse music compositions. In this paper, we propose a model based on Wasserstein GAN with gradient penalty (WGAN-GP) for multi-track music generation. This model incorporates self-attention and introduces a novel cross-attention mechanism in the generator to enhance its expressive capability. Additionally, we transpose all music to C major in training to ensure data consistency and quality. Experimental results demonstrate that our model can produce multi-track music with enhanced rhythm and sound characteristics, accelerate convergence, and improve generation quality.},
  keywords={Training;Rhythm;Generative adversarial networks;Generators;Task analysis;Artificial intelligence;Consumer electronics},
  doi={10.1109/GCCE59613.2023.10315503},
  ISSN={2693-0854},
  month={Oct},}@INPROCEEDINGS{11137620,
  author={Suwannakan, Thanakorn and Junpeng, Putcharee and Intharah, Thanapong},
  booktitle={2025 International Technical Conference on Circuits/Systems, Computers, and Communications (ITC-CSCC)}, 
  title={Developing Thai Language Communication Competency with Intelligent Prompt through Generative AI}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={This study aimed to analyze the quality of a Thai language communication competency assessment developed using generative AI. A total of 151 students in Grade 5 participated in the study. The results found that The design of the intelligent prompt consists of the following elements: 1. Command goal 2. Situation, event, or condition of the question 3. Suitability for the test taker group 4. Test format 5. Dimension of measurement 6. Learning content and 7. Files necessary for AI to learn. Model fit the items generated by ChatGPT 4o, considering the Chi-square Likelihood values (χ2 = 56.47, df= 5, p = .05), AIC and BIC are suitable as a multidimensional model. The reliability of the AI-generated test is within the acceptable standard, with a separate reliability value of 0.94, an EAP/PV value of 0.87, an alpha coefficient of 0.90, and a standard error of measurement of only 0.25, indicating a high level of test validity. AI can imitate humans so well that experts misidentify 61.11% of responses as human, showing the difficulty of distinguishing between Humans and AI.},
  keywords={Computers;Generative AI;Measurement uncertainty;Reliability engineering;Particle measurements;Chatbots;Indexes;Integrated circuit reliability;Standards;Testing;Thai Language Communication Competency;Intelligent Prompt;Generative AI},
  doi={10.1109/ITC-CSCC66376.2025.11137620},
  ISSN={2997-741X},
  month={July},}@INPROCEEDINGS{10426900,
  author={Kong, De-Hua and Zhang, Wen-Wei and Cao, Jia-Ning and Huang, Wen-Chi and Guo, Xing-Yue and Xia, Ming-Yao},
  booktitle={2023 Cross Strait Radio Science and Wireless Technology Conference (CSRSWTC)}, 
  title={Intelligent Electromagnetic Scattering Analysis Based on Inherent Feature Extraction}, 
  year={2023},
  volume={},
  number={},
  pages={1-3},
  abstract={In this paper, intelligent prediction methods for electromagnetic scattering problems based on inherent feature extraction are presented. The electromagnetic characteristics of a target are expressed by a set of inherent feature parameters (IFPs), which are distinctive to the target itself, and independent of incident and scattering directions. Using IFPs as the output of neural networks is conducive to reducing the network size and training difficulty. The scattered far field and radar cross-section (RCS) can be readily computed using the IFPs. Numerical results show that the proposed approaches are viable for both 2D and 3D metal targets.},
  keywords={Wireless communication;Training;Three-dimensional displays;Electromagnetic scattering;Feature extraction;Structural engineering;Backscatter;artificial intelligence;inherent feature parameter;scattered far field;electromagnetic forward problem},
  doi={10.1109/CSRSWTC60855.2023.10426900},
  ISSN={2377-8512},
  month={Nov},}@INPROCEEDINGS{9415217,
  author={Lim, Jeong-Seon and Astrid, Marcella and Yoon, Hyun-Jin and Lee, Seung-Ik},
  booktitle={2021 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Small Object Detection using Context and Attention}, 
  year={2021},
  volume={},
  number={},
  pages={181-186},
  abstract={There are many limitations applying object detection algorithm on various environments. Specifically, detecting small objects is still challenging because they have low-resolution and limited information. We propose an object detection method using context for improving accuracy of detecting small objects. The proposed method uses additional features from different layers as context by concatenating multi-scale features. We also propose object detection with attention mechanism which can focus on the object in image, and it can include contextual information from target layer. Experimental results shows that proposed method also has higher accuracy than conventional SSD on detecting small objects. Moreover, for $300 \times 300$ input, we achieved 78.1% Mean Average Precision (mAP) on the PASCAL VOC2007 test set.},
  keywords={Image color analysis;Object detection;Detectors;Artificial intelligence;Context modeling;object detection;attention;context},
  doi={10.1109/ICAIIC51459.2021.9415217},
  ISSN={},
  month={April},}@INPROCEEDINGS{9793097,
  author={Kumar, Alok and Shukla, Sandeep Kumar and Sharma, Archana and Yadav, Pranay},
  booktitle={2022 International Conference on Applied Artificial Intelligence and Computing (ICAAIC)}, 
  title={A Robust Approach for Image Super-Resolution using Modified Very Deep Convolution Networks}, 
  year={2022},
  volume={},
  number={},
  pages={259-265},
  abstract={This research presents a Modified Very Deep Convolutional Network (MVDCN) for Single Image Super Resolution (SISR). The proposed method is based on modified CNN, in which different image features for training also apply up-sampling as well as residual images, which is a fundamental step of SISR, and the depth of the network is 20. For the improvement of the presented method, it applies the fusion of the bi-cubic method with the proposed modified residual image attributes with Very Deep Convolutional Networks (VDCN). The presented method shows better results in terms of the two base parameters of the proposed method. These are PSNR and SSIM. These two parameters are major parameters for the result analysis of image super resolution (ISR). There are different data sets available for the training and testing of the presented method, such as test datasets “Set5’ [15] and ‘Set14’ [26]. Both are primarily used as benchmarks by various researchers; however, in other works, the data set “Urban100” is very interesting because it contains many challenging images that fail by many of the existing methods. Final data set ‘B100’, natural images from Berkeley University. The proposed MVDCN shows better results as compared to other previous methods.},
  keywords={Training;Image segmentation;Convolution;Superresolution;Benchmark testing;Artificial intelligence;Single Image Super Resolution (SISR);CNN;bi-cubic;Deep Convolutional Networks (DCN);‘Set5’ and ‘Set14’},
  doi={10.1109/ICAAIC53929.2022.9793097},
  ISSN={},
  month={May},}@INPROCEEDINGS{4410395,
  author={Zhou, Yan and Jorgensen, Zach and Inge, Meador},
  booktitle={19th IEEE International Conference on Tools with Artificial Intelligence(ICTAI 2007)}, 
  title={Combating Good Word Attacks on Statistical Spam Filters with Multiple Instance Learning}, 
  year={2007},
  volume={2},
  number={},
  pages={298-305},
  abstract={Statistical spam filters are known to be vulnerable to adversarial attacks. One such adversarial attack, known as the good word attack, thwarts spam filters by appending to spam messages sets of "good" words, which are common in legitimate e-mail but rare in spam. We present a counter attack strategy that first attempts to differentiate spam from legitimate e-mail in the input space, by transforming each e- mail into a bag of multiple segments, and subsequently applies multiple instance logistic regression on the bags. We treat each segment in the bag as an instance. An e-mail is classified as spam if at least one instance in the corresponding bag is spam, and as legitimate if all the instances in it are legitimate. We show that a spam filter using our multiple instance counter-attack strategy stands up better to good word attacks than its single instance counterpart and the commonly practiced Bayesian filters.},
  keywords={Unsolicited electronic mail;Electronic mail;Drugs;Information filtering;Information filters;Logistics;Artificial intelligence;Learning;Mobile computing;USA Councils},
  doi={10.1109/ICTAI.2007.120},
  ISSN={2375-0197},
  month={Oct},}@INPROCEEDINGS{10814410,
  author={Hollósi, Gergely and Ficzere, Dániel and Varga, Pál},
  booktitle={2024 20th International Conference on Network and Service Management (CNSM)}, 
  title={Generative AI for Low-Level NETCONF Configuration in Network Management Based on YANG Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={The NETCONF protocol, standardized by the IETF, is a cutting-edge solution for configuring network entities and offers an alternative to SNMP in modern network devices. Due to the complexity of configuration protocols and the challenges in creating valid configurations, generative AI solutions are promising for converting textual prompts into configuration descriptors. However, the potential of LLMs to generate NETCONF configurations has not been explored in the literature. This paper addresses this gap by evaluating the performance of five different LLMs – including Llama3, an open-source, on-premises capable model – in creating NETCONF configurations using the widespread YANG data models. In order to create valid network configurations using generative AI, this paper proposes a pipeline for integrating domain knowledge into LLMs without additional training and highlights common shortcomings and errors that prevent the generation of valid configurations. The findings indicate that the use of LLMs is promising for this task, but the current state-of-the-art is not yet mature enough for immediate industrial application in complex cases.},
  keywords={Training;Knowledge engineering;Protocols;Generative AI;Large language models;Pipelines;Knowledge based systems;XML;Data models;Complexity theory;network management;service management;NETCONF;YANG;SNMP;generative AI;LLM;RAG;XML;mib;gpt;llama3},
  doi={10.23919/CNSM62983.2024.10814410},
  ISSN={2165-963X},
  month={Oct},}@INPROCEEDINGS{9722700,
  author={Kim, Donghwan and Joo, Jaehan and Kim, Suk Chan},
  booktitle={2022 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Fake Data Generation for Medical Image Augmentation using GANs}, 
  year={2022},
  volume={},
  number={},
  pages={197-199},
  abstract={This paper uses WGAN-GP to generate fake data that can be used as augmented data for strabismus classification and analyze the results. In the introduction of this paper, the general diagnostic technique for strabismus disease is described and the diagnostic technique using deep learning is described. And the reason for generating fake data is described. Main subject describes the WGAN-GP, data set used for data generation and evaluation metrics of GAN. In the experimental result, the data generated by the GAN is visually checked, and the performance of the fake data is evaluated with the FID that is one of the evaluation metrics of the GAN. And in the conclusion, evaluation of the proposed GAN and future work are described.},
  keywords={Measurement;Deep learning;Learning (artificial intelligence);Medical diagnostic imaging;Diseases;WGAN-GP;strabismus;diagnosis;deep learning},
  doi={10.1109/ICAIIC54071.2022.9722700},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{9797472,
  author={Shuai, Zizhen and Li, Shuaishuai and Gao, Yang and Wu, Fei},
  booktitle={2021 2nd International Conference on Artificial Intelligence and Computer Engineering (ICAICE)}, 
  title={Adversarial Learning Based on Global and Local Features for Cross-Modal Person Re-identification}, 
  year={2021},
  volume={},
  number={},
  pages={01-04},
  abstract={In recent years, a great improvement has been achieved in cross-modal person re-identification (Re-ID) methods based on feature partition. However, many works do not use global and local features jointly to improve the accuracy of person identification. It is an important research topic to fully extract and use global features as well as local features, and effectively reduce modality differences. In this paper, we propose an adversarial learning based on global and local features (ALGL) method. We adopt a two-stream network with partially shared parameters as a feature extraction network to extract visible and infrared feature maps. Local features are obtained through Part-based Convolutional Baseline (PCB) operations on feature maps with the local feature learning module. In the global feature learning module, the average pooling is used to obtain the global features. In order to fully explore the discriminative abilities of local features and global features, hetero-center based triplet loss is designed, which brings features of the same category closer, and features of different categories farther away. At the same time, the adversarial learning module minimizes the modality difference between visible and infrared modalities. Experimental results on the SYSU-MM01 and RegDB datasets show that ALGL outperforms the state-of-the-art solutions.},
  keywords={Representation learning;Feature extraction;Adversarial machine learning;Artificial intelligence;Identification of persons;Cross-Modal Person Re-identification;Global Featu-res;Local Features},
  doi={10.1109/ICAICE54393.2021.00047},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10053171,
  author={Urano, Yuto and Sari, Irawati Nurmala and Du, Weiwei},
  booktitle={2022 23rd ACIS International Summer Virtual Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD-Summer)}, 
  title={Image Inpainting using Automatic Structure Propagation with Auxiliary Line Construction}, 
  year={2022},
  volume={},
  number={},
  pages={107-112},
  abstract={Existing image inpainting methods used traditional and deep learning methods to restore a large missing region in the damaged image. This often leads to color discrepancy and blurriness. Pre-processing of prior line detection by user assistance is usually employed to reduce the blurry of center region by segmenting the large region into more minor. However, it operates manually, which is time-consuming. This paper introduces a technique to generate two-line types: penetrator and interactor in constructing auxiliary lines as guidance. These lines assist structure propagation established automatically, while the remaining small regions are filled by texture propagation. Experiments on large regular masks demonstrate that our proposed approach generates higher-quality results than other methods.},
  keywords={Deep learning;Image segmentation;Image color analysis;Image restoration;Artificial intelligence;Software engineering;image inpainting;vanishing points;auxiliary lines;large missing regions},
  doi={10.1109/SNPD-Summer57817.2022.00026},
  ISSN={},
  month={July},}@INPROCEEDINGS{9545949,
  author={Yicheng, Yan and Wei, Guo and Liwen, Wang},
  booktitle={2021 International Conference on Artificial Intelligence, Big Data and Algorithms (CAIBDA)}, 
  title={Broad learning system based on ensemble learning}, 
  year={2021},
  volume={},
  number={},
  pages={62-67},
  abstract={Aiming at the problem of poor stability of broad learning system (BLS), combining with the idea of ensemble learning, bagging BLS and stacking BLS algorithms are proposed. Firstly, the data set is sampled to get the data subset, and then the base classifier is trained by the broad learning system. Finally, the prediction results of the whole model are obtained by integrating the base classifiers. Through experiments on multiple data sets, the results show that the proposed algorithms achieve ideal results in image classification, and the two models are better than the single broad learning system in classification accuracy and variance, which shows the effectiveness of the proposed algorithm.},
  keywords={Learning systems;Fuses;Stacking;Learning (artificial intelligence);Predictive models;Prediction algorithms;Stability analysis;broad learning system;ensemble learning;image classification},
  doi={10.1109/CAIBDA53561.2021.00021},
  ISSN={},
  month={May},}@INPROCEEDINGS{9544485,
  author={Wan, Weiguo and Yang, Yong and Tu, Wei},
  booktitle={2021 International Conference on Computer Engineering and Artificial Intelligence (ICCEAI)}, 
  title={Residual Enhancement Network for Realistic Face Sketch-Photo Synthesis}, 
  year={2021},
  volume={},
  number={},
  pages={191-195},
  abstract={Face sketch-photo synthesis is a significant challenge task in computer vision area, due to the blurred facial details and color distortion produced by the existing approaches. In this paper, we propose a realistic face sketch-photo synthesis method based on residual enhancement network. In the network, a residual enhancement module is constructed and embedded in U-Net to improve the feature representation capability of the deep network. In addition, a detail loss and a perception loss are adopted to constrain the synthesized image has abundant detail and realistic photo style. Experimental results on multiple face sketch datasets indicate that the proposed method obtains superior performance than the state-of-the-art methods, both in terms of visual perception and objective evaluations.},
  keywords={Computer vision;Image color analysis;Face recognition;Distortion;Task analysis;Artificial intelligence;Visual perception;face sketch-photo synthesis;residual enhancement network;detail loss;perception loss},
  doi={10.1109/ICCEAI52939.2021.00037},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8995386,
  author={Wang, Fangjun and Shen, Liping},
  booktitle={2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Facial Expression Recognition: Residue Learning Using SVM}, 
  year={2019},
  volume={},
  number={},
  pages={1675-1680},
  abstract={Residue learning using SVM is exploited to recognize facial expression in this paper. A facial expression consists of neutral component and expressive one(residue), which contains most of the expression information. Firstly, a cGAN is trained to generate neutral face image from an input face image. The intermediate layers record the information during this procedure. So secondly, kernel PCA and SVMs are exploited to analyze the residue in these intermediate layers. Results of experiments on five facial expression databases including BP4D, CK+, JAFFE, Oulu-CASIA and RAF show considerable performance compared with the latest methods.},
  keywords={Databases;Face recognition;Learning (artificial intelligence);Kernel;Principal component analysis;facial expression recognition;GAN;residue learning},
  doi={10.1109/ICTAI.2019.00246},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{9930313,
  author={Shu, Qidi and Hu, Jiarui and Pan, Jun and Bai, Yuchuan and Zhang, Zhuoer and Li, Zongrui},
  booktitle={2022 International Conference on Artificial Intelligence and Computer Information Technology (AICIT)}, 
  title={TCNet: Temporal Consistency Network for Semisupervised Change Detection}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  abstract={Change detection is a challenging task in earth observation. In recent years, deep learning techniques have been widely applied in change detection and achieved impressive progress. However, deep learning based change detection methods heavily rely on a large amount of annotated samples. Labeling for change detection is a time-consuming and labor-intensive task. In order to solve this problem, we propose a novel temporal consistency network (TCNet) for semisupervised change detection. Motivated by the fact that different input sequences have no effect on the prediction results of change detection, our method learns the distribution of unlabeled data by enforce the consistency of the prediction obtained with different input sequences. Specifically, for labeled samples, two segmentation networks with the same structure are trained with two different input sequences. For the unlabeled samples, we perform the forward prediction on the two segmentation networks with corresponding input sequence to obtain two results of change detection. Then, the supervised signals can be generated by minimizing the difference between two predicted results. In this way, the distribution of unlabeled data can be fully explored thus enhancing the generalization of change detection. Experiments on google dataset show the effectiveness of the proposed method.},
  keywords={Deep learning;Earth;Convolution;Perturbation methods;Learning (artificial intelligence);Internet;Labeling;change detection;deep learning;semisupervised convolutional network;consistency learning},
  doi={10.1109/AICIT55386.2022.9930313},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9302622,
  author={Chen, Ching-Han and Shiu, Ming-Fang},
  booktitle={2020 International Conference on Pervasive Artificial Intelligence (ICPAI)}, 
  title={RNN-based Dialogue Navigation System for Visually Impaired}, 
  year={2020},
  volume={},
  number={},
  pages={140-143},
  abstract={Helping the visually impaired to walk and guiding him to the destination is a challenging task. The difficulty is to use natural language as the only communication method and assist the visually impaired to see the road. We have developed a conversational navigation system that integrates multiple rounds of dialogue to confirm the destination for the visually impaired. Besides, we also use image interpretation technology based on the RNN neural network to describe the scene in front of the user. Finally, in terms of hardware, we use a low-cost, low- power embedded hardware that integrates cameras, Wi-Fi, and microphones to implement this application.},
  keywords={Artificial intelligence;dialogue system;embedded hardware;image captioning;navigation;visually impaired},
  doi={10.1109/ICPAI51961.2020.00033},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10581552,
  author={Han, Jiqun and Liu, Xinyu and Tan, Dongxu and Zhu, Jiehui},
  booktitle={2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={An Improved Semi-Supervised Learning-Based U-Net for Underwater Image Enhancement}, 
  year={2024},
  volume={},
  number={},
  pages={1389-1393},
  abstract={The attenuation and scattering of light in underwater environments often lead to degradation issues such as image blurring, color cast, and low contrast. Due to the lack of high-quality paired datasets, the performance of deep learning-based methods is limited. To address these challenges, we propose an improved U-Net architecture based on semi-supervised learning for underwater image enhancement. First, a multi-scale input-level fusion module is proposed to allow our network to fully exploit global spatial information from input images, natural light fields, and depth maps. Second, a multi-branch hybrid convolutional attention residual block is designed to improve the network's feature extraction capability and focus on important spatial and channel information in underwater images. Finally, a semi-supervised learning approach is used to fully exploit unpaired datasets, improving the generalization ability of the network model. Through qualitative and quantitative analysis, the proposed network achieves satisfactory image enhancement results in various underwater scenarios.},
  keywords={Seminars;Measurement;Image color analysis;Statistical analysis;Scattering;Learning (artificial intelligence);Semisupervised learning;Underwater image enhancement;U-Net;semi-supervised learning},
  doi={10.1109/AINIT61980.2024.10581552},
  ISSN={},
  month={March},}@INPROCEEDINGS{10212817,
  author={Lv, Hongmei and Zhao, Aifang and Wang, Yinmei and Li, Haibo and Li, Yuhang and Zou, Guoping},
  booktitle={2023 4th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={Research on Missing Bolt Sub-Detection Based on Real-ESRGAN Super-Resolution Reconstruction}, 
  year={2023},
  volume={},
  number={},
  pages={520-523},
  abstract={The bolt structure is one of the important accessories in the transmission line. Bolts and their missing pins account for a very small proportion of the image and the image definition is not high, so the detection of missing bolts and pins is extremely difficult. In this study, the YOLOV5 network and Real-ESRGAN super-resolution reconstruction network are integrated to adapt to the target identification job of missing bolts and their pins in intricate transmission line circumstances. The Real-ESRGAN super-resolution reconstruction network is used in this method to perform super-resolution reconstruction on photos that contain bolt targets to improve clarity. The YOLOv5 network is then used to detect the reconstructed photos, greatly improving the detection of missing bolt pins precision. The experimental findings demonstrate that the Real-Esrgan super-resolution reconstruction network in combination with the YOLOV5 network can more precisely recognize targets that were challenging to detect missing bolt pins, thereby resolving the issue of poor detection rate of missing bolt pins.},
  keywords={Seminars;Power transmission lines;Target recognition;Superresolution;Learning (artificial intelligence);Fasteners;Inspection;Super-resolution reconstruction;YOLOv5;Object detection;Transmission lines;Deep learning},
  doi={10.1109/AINIT59027.2023.10212817},
  ISSN={},
  month={June},}@INPROCEEDINGS{9887435,
  author={Zhang, Yan and Gao, Tianhan and Mi, Qingwei},
  booktitle={2022 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT)}, 
  title={A Robust Offline Reinforcement Learning Algorithm Based on Behavior Regularization Methods}, 
  year={2022},
  volume={},
  number={},
  pages={150-154},
  abstract={Offline deep reinforcement learning algorithms are still in developing. Some existing algorithms have shown that it is feasible to learn directly without using environmental interaction under the condition of sufficient datasets. In this paper, we combine an offline reinforcement learning method through behavior regularization with a robust offline reinforcement learning algorithm. Moreover, the algorithm is verified and analyzed with a high-quality but limited dataset. The experimental results show that it is feasible to combine the behavior regularization method with the robust offline reinforcement learning algorithm, to gain better performance under the condition of limited data compared with the baseline algorithms.},
  keywords={Reinforcement learning;Generators;Communications technology;Behavioral sciences;Fourth Industrial Revolution;Artificial intelligence;Standards;offline deep reinforcement learning;limited data;behavior regularization},
  doi={10.1109/IAICT55358.2022.9887435},
  ISSN={},
  month={July},}@INPROCEEDINGS{10617749,
  author={Lin, Chia-Yu and Chen, Yi-Zhen},
  booktitle={2024 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT)}, 
  title={Inpainting-based Anomaly Detection System with Self-Supervised Learning}, 
  year={2024},
  volume={},
  number={},
  pages={124-129},
  abstract={Deep learning for defect detection has become a critical imperative in contemporary electronics manufacturing. We propose an inpainting-based anomaly detection system to identify defects without labeled defects. An image inpainting model, which discerns disparities between the original and restored versions of the defective image, is designed as the core of our methodology. To further address issues related to reconstructing asymmetric images with defects, we incorporate self-supervised learning (SSL) to extract a broader spectrum of features. In experiments, we compare the proposed method to state-of-the-art models based on MVTec open dataset. Our proposed method can achieve a best performance of 97%, and surpasses the SOTA model by a margin of 57%.},
  keywords={Deep learning;Self-supervised learning;Learning (artificial intelligence);Feature extraction;Communications technology;Image restoration;Fourth Industrial Revolution;Anomaly detection;Image reconstruction;Defect detection;Defect detection;image inpainting;self-supervised learning},
  doi={10.1109/IAICT62357.2024.10617749},
  ISSN={2834-8249},
  month={July},}@INPROCEEDINGS{10242649,
  author={Ning, Peirong and Jiang, Wei and Wang, Ronggang},
  booktitle={2023 International Conference on Communications, Computing and Artificial Intelligence (CCCAI)}, 
  title={HFLIC: Human Friendly Perceptual Learned Image Compression with Reinforced Transform}, 
  year={2023},
  volume={},
  number={},
  pages={188-194},
  abstract={In recent years, there has been rapid development in learned image compression techniques that prioritize rate-distortion-perceptual compression, preserving fine details even at lower bit-rates. However, current learning-based image compression methods often sacrifice human-friendly compression and require long decoding times. In this paper, we propose enhancements to the backbone network and loss function of existing image compression model, focusing on improving human perception and efficiency. Our proposed approach achieves competitive subjective results compared to state-of-the-art end-to-end learned image compression methods and classic methods, while requiring less decoding time and offering human-friendly compression. Through empirical evaluation, we demonstrate the effectiveness of our proposed method in achieving outstanding performance, with more than 25% bit-rate saving with comparable perceptual quality.},
  keywords={Image coding;Focusing;Transforms;Decoding;Telecommunication computing;Artificial intelligence;Image Compression;Perceptual Compression},
  doi={10.1109/CCCAI59026.2023.00041},
  ISSN={},
  month={June},}@INPROCEEDINGS{11034991,
  author={Rao, Chengcheng and Zheng, Zhihao and Yuan, Chao and Lin, Junsheng},
  booktitle={2025 IEEE 6th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={Dual Regression-Based Semi-Supervised Infrared Image Instance Segmentation Method for Power Transmission Line Surveillance}, 
  year={2025},
  volume={},
  number={},
  pages={782-785},
  abstract={Instance segmentation of infrared images is a key task for power transmission line surveillance. This paper proposes customized solutions to the following problems. First, for the semantic inconsistency in image translation, based on cycle-consistency concept, this paper presents a Dual-Regression (DR) framework, where forms a closed-loop learning between image translation and instance segmentation, thus improving the discriminative ability of instances. Second, for the data-label dependency in supervised training, this paper presents a semisupervised optimization scheme, which embeds the semantic prior extracted from a large number of unlabeled images into the model. The feature representations are enriched for highaccuracy instance segmentation. Experiments on real-world dataset demonstrate that the proposed method gains state-of-the-art performance compared with existing instance segmentation methods. Benefiting from the fine segmentation outlines and high category confidence, the proposed method is excepted to be invested in fully automatic instance annotation of power transmission line infrared images.},
  keywords={Instance segmentation;Training;Seminars;Power transmission lines;Translation;Annotations;Surveillance;Semantics;Learning (artificial intelligence);Optimization;Industrial surveillance;instance segmentation;cycle-consistency learning;semi-supervised optimization},
  doi={10.1109/AINIT65432.2025.11034991},
  ISSN={},
  month={April},}@INPROCEEDINGS{10551058,
  author={Xi, Zhengjie and Liu, Jin and Hu, Bing and Li, Xingye},
  booktitle={2023 4th International Conference on Computer, Big Data and Artificial Intelligence (ICCBD+AI)}, 
  title={Cross-Modality Pedestrian Re-Identification via Modality Data Homogenization and Cross-layer Feature Aggregation}, 
  year={2023},
  volume={},
  number={},
  pages={261-265},
  abstract={Visible-Infrared Cross-Modality pedestrian Re-identification (CmRe-id) seeks to identify pedestrian photos captured by multiple cameras that show the same pedestrian. However, the challenge of cross-modality feature mismatch caused by data heterogeneity remains. To address this challenge, we propose Modality Data Homogenization and Cross-layer Feature Aggregation Network(MHFA) in this paper. For improved modality alignment, we introduce RGB Modality Data Homogenization (MDH) using grayscale conversion. To enhance feature representations, we develop Cross-Layer Feature Aggregation (CLFA). The findings obtained from our extensive evaluation clearly establish the superiority of our suggested technique over current approaches, effectively addressing the limitations of cross-modality pedestrian re-identification.},
  keywords={Cross layer design;Pedestrians;Gray-scale;Big Data;Cameras;Artificial intelligence;Pedestrian Re-Identification;Cross-Modality;Feature Aggregation;Cross-Layer},
  doi={10.1109/ICCBD-AI62252.2023.00049},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11042635,
  author={Mor, Aakash},
  booktitle={2025 2nd International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)}, 
  title={Forensic AI: A Novel Multi-Granular Approach for Detecting Synthetic Media Manipulation}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={With the rapid evolution of AI-driven synthetic media, deepfake technology has emerged as a potent tool for deception, raising concerns about misinformation, security, and digital authenticity. This study introduces a novel multi-granular artifact detection framework to distinguish between real and AI-generated images with high precision. By leveraging deep learning techniques and a custom convolutional architecture, the approach identifies intrinsic and extrinsic inconsistencies left by synthetic media generation processes. Extensive experiments across diverse datasets validate the robustness of the model, demonstrating superior generalization across both seen and unseen deepfake samples. The research provides a step forward in forensic AI, ensuring enhanced media integrity and mitigating the growing threats posed by deepfake technology.},
  keywords={Deep learning;Deepfakes;Visualization;Adaptation models;Digital forensics;Media;Transformers;Robustness;Convolutional neural networks;Artificial intelligence;Deepfake Detection;Synthetic Media;Digital Forensics;Convolutional Neural Networks;AI-generated Images;Media Integrity;Artifact Detection;Deep Learning},
  doi={10.1109/RMKMATE64874.2025.11042635},
  ISSN={},
  month={May},}@INPROCEEDINGS{11035044,
  author={Zhao, Xinyi and Xu, Huahu},
  booktitle={2025 IEEE 6th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={6Diffsuion-GAN: Diffusion-GAN Based IPv6 Address Generation}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={As the number of Internet devices proliferates, IPv6 becomes the next-generation protocol to address address shortages. However, the large address space of IPv6 brings new challenges to network scanning and management. Existing techniques are deficient in the efficiency and quality of IPv6 address scanning. This study proposes 6Diffusion-GAN, a novel architecture that generates more efficient IPv6 addresses through a diffusion process and a feedback mechanism. Experimental results show that 6Diffusion-GAN outperforms the existing algorithms in both hit rate and generation rate, and significantly improves the nonalias rate of addresses to 92.19 %, providing new ideas and tools for IPv6 network management.},
  keywords={Training;Seminars;Protocols;Diffusion processes;Internet;Resource management;Information technology;Artificial intelligence;Next generation networking;Overfitting;Diffusion-GAN;Scanning;IPv6 Target Generation insert},
  doi={10.1109/AINIT65432.2025.11035044},
  ISSN={},
  month={April},}
