@INPROCEEDINGS{9308361,
  author={Veal, Charlie and Lindsay, Marshall and Kovaleski, Scott D. and Anderson, Derek T. and Price, Stanton R.},
  booktitle={2020 IEEE Symposium Series on Computational Intelligence (SSCI)}, 
  title={Evolutionary Algorithm Driven Explainable Adversarial Artificial Intelligence}, 
  year={2020},
  volume={},
  number={},
  pages={913-920},
  abstract={It is well-known that machine learning algorithms can be susceptible to undesirable effects when exposed to conditions that are not expressed adequately in the training dataset. This leads to a growing interest throughout many communities; where do algorithms and trained models break? Recently, methods such as generative adversarial neural networks and variational autoencoders were proposed to create adversarial examples that challenge algorithms. This results in artificial intelligence having higher false detections or completely losing recognition. The problem is that existing solutions, are for the most part, black boxes. Current gaps include how do we better control and understand adversarial algorithms. Herein, we propose the concept of an adversarial modifier set as an understandable and controlled way to generate adversarial examples. This is achieved by exploiting the improved evolution-constructed algorithm to identify ideal features that a victim algorithm values in imagery. These features are combined to realize a tuple library that preserves spatial relations. Last, a set of algorithmically controlled modifiers that generate the imagery are found by examining the content of the false imagery. Preliminary results are encouraging and demonstrate that this approach has benefits in both generating explainable adversarial examples, as well as shedding some insight into victim algorithm decision making.},
  keywords={Feature extraction;Signal processing algorithms;Libraries;Visualization;Training;Transforms;Correlation;adversarial;artificial intelligence;generative;improved evolution-constructed algorithm;machine learning},
  doi={10.1109/SSCI47803.2020.9308361},
  ISSN={},
  month={Dec},}@ARTICLE{10506327,
  author={Ahn, Sungjun and Yim, Hyun-Jeong and Lee, Youngwan and Park, Sung-Ik},
  journal={IEEE Transactions on Broadcasting}, 
  title={Dynamic and Super-Personalized Media Ecosystem Driven by Generative AI: Unpredictable Plays Never Repeating the Same}, 
  year={2024},
  volume={70},
  number={3},
  pages={980-994},
  abstract={This paper introduces a media service model that exploits artificial intelligence (AI) video generators at the receive end. This proposal deviates from the traditional multimedia ecosystem, completely relying on in-house production, by shifting part of the content creation onto the receiver. We bring a semantic process into the framework, allowing the distribution network to provide service elements that prompt the content generator rather than distributing encoded data of fully finished programs. The service elements include fine-tailored text descriptions, lightweight image data of some objects, or application programming interfaces, comprehensively referred to as semantic sources, and the user terminal translates the received semantic data into video frames. Empowered by the random nature of generative AI, users can experience super-personalized services accordingly. The proposed idea incorporates situations in which the user receives different service providers’ element packages, either in a sequence over time or multiple packages at the same time. Given promised in-context coherence and content integrity, the combinatory dynamics will amplify the service diversity, allowing the users to always chance upon new experiences. This work particularly aims at short-form videos and advertisements, which the users would easily feel fatigued by seeing the same frame sequence every time. In those use cases, the content provider’s role will be recast as scripting semantic sources, transformed from a thorough producer. Overall, this work explores a new form of media ecosystem facilitated by receiver-embedded generative models, featuring both random content dynamics and enhanced delivery efficiency simultaneously.},
  keywords={Media;Semantics;Artificial intelligence;Production;Ecosystems;Task analysis;Streaming media;Generative AI;semantic communications;6G multimedia casting;on-device AI},
  doi={10.1109/TBC.2024.3380474},
  ISSN={1557-9611},
  month={Sep.},}@INPROCEEDINGS{11156209,
  author={B., Daphni Michelle and J., Sree Darshne and Satapathy, Sandeep Kumar and Mishra, Shruti},
  booktitle={2025 International Conference on Innovations in Intelligent Systems: Advancements in Computing, Communication, and Cybersecurity (ISAC3)}, 
  title={Predicting Drug Responses: A Comparative Analysis and Visualization of Machine Learning Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={This study provides a practical solution for predicting the drug response by constructing deep learning algorithms and risk modelling. A suitable data set that is appropriate for building prediction models and follows a systematic approach with multiple preprocessing and feature engineering phases is identified. Hyperparameter tuning improves the accuracy of models trained with various algorithms to predict drug responses, including neural networks. A comprehensive set of model performance metrics, including accuracy, precision, recall, and Receiver Operating Characteristic - Area Under the Curve (ROC-AUC), is utilized to ensure completeness in evaluating the results. The visualization markup comprises the evaluation metrics such as confusion matrices, plots of feature importances, and other visualization figures that enable understanding and explanation of model predictions and behavior. In addition to this, some interpretable techniques are also applied to the output of the models to increase clarity and support the evaluation of predictions. This not only assures an efficient and accurate prediction framework but also helps understand the mechanisms that improve the understanding of factors affecting drug response, which is useful in the development of novel drugs and targeting specific diseases.},
  keywords={Drugs;Analytical models;Technological innovation;Accuracy;Systematics;Computational modeling;Predictive models;Prediction algorithms;Generative adversarial networks;Tuning;Drug response prediction;Generative Adversarial Networks (GAN) Model;Diffusion Model;Hybrid Approach;Generative Artificial Intelligence},
  doi={10.1109/ISAC364032.2025.11156209},
  ISSN={},
  month={July},}@INPROCEEDINGS{10729923,
  author={Li, Dongjin and Chen, Xinyan and Tan, Peiwen and Jia, Jie},
  booktitle={2024 3rd International Conference on Artificial Intelligence and Computer Information Technology (AICIT)}, 
  title={How Deep Learning is Implemented in Manufacturing Quality Control}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={This study aims to explore the application and effect of deep learning technology in manufacturing quality control. The study deployed a convolutional neural network (CNN) model to analyze images and sensor data during the manufacturing process to achieve automatic detection and classification of defects. The experiments were conducted in a simulated high-speed production line environment, and a large amount of production data, including images and sensor readings, were collected and processed. The results showed that the accuracy of the deep learning model in identifying serious, moderate and minor defects reached 98%, 95% and 90% respectively, which was significantly higher than the traditional quality control system. The conclusion shows that deep learning technology can significantly improve the quality control accuracy and efficiency of the manufacturing industry, provide strong technical support for the field of intelligent manufacturing, and indicate broad application prospects in advanced manufacturing systems that require higher levels of automation and intelligence.},
  keywords={Deep learning;Accuracy;Automation;Neural networks;Process control;Quality control;Production;Data models;Convolutional neural networks;Reliability;deep learning;manufacturing;quality control;convolutional neural network},
  doi={10.1109/AICIT62434.2024.10729923},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10960165,
  author={Shrivastava, Aayush and Khan, Nikhat and Tanna, Paresh and Lathigara, Amit},
  booktitle={2024 IEEE 2nd International Conference on Innovations in High Speed Communication and Signal Processing (IHCSP)}, 
  title={Violence Detection on Women using Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Detection, prevention, and intervention strategies that rely on the application of state-of-the-art technology are required in that violence against women continues to threaten people from all walks of life. Through the applications of OpenAI's GPT models coupled with FastAPI for real-time deployment, this work comes to present an innovative solution in recognizing incidences of violence through Generative Artificial Intelligence. Through GPT's natural language capabilities, this system scans digital interactions for abusive language, harassment, and threats through social media and messaging platforms. Fast application programming interface (Fast API) is used by the system to give it scalability, real-time processing, and effective handling of concurrent requests so that it does not take too long in high-pressure situations. The technology is monitored and reports abusive behaviors through real-time alarm signals to the proper authorities or support services. Since it was trained on a wide variety of datasets, the model can both understand overt and subtle kinds of violence and thus be precise in identifying gender-based abuse that encompasses not only verbal manipulations but also psychological manipulations. This paper aims to deal with the ethical issues, problems, and possible impact of using a combination of GPT and FastAPI in relation to violence detection. The paper therefore underlines an integrated effort from AI developers, the legal frameworks, and social services to provide full mechanisms for protection.},
  keywords={Technological innovation;Generative AI;Social networking (online);Scalability;Psychology;Signal processing;Real-time systems;Protection;Usability;Application programming interfaces;component;formatting;style;styling;insert (key words)},
  doi={10.1109/IHCSP63227.2024.10960165},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10866661,
  author={G., Uday Kiran and V., Srilakshmi and G., Padmini and B., Lavanya and A., Tejaswini and G., Vijay and D., Ranveer and B., Priyanka and H., Bhagya Laxmi},
  booktitle={2024 3rd Edition of IEEE Delhi Section Flagship Conference (DELCON)}, 
  title={One-Shot Stylization for Transformative Facial Art using StyloMorph}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Face stylization involves transforming an individual's facial features into a specific artistic style while preserving unique characteristics. Traditional methods often require large datasets and extensive training to achieve high-quality results, typically relying on Generative Adversarial Networks (GANs), a deep learning technique that generates realistic images by training a generator and a discriminator in a competitive framework. However, these approaches can be resource-intensive and slow, demanding significant computational power and time. This study introduces StyloMorph, a streamlined face stylization system, designed to simplify the transformation process while maintaining high-quality outputs. Utilizing StyleGAN2 and e4e models, which are pre-trained on the diverse FFHQ dataset, StyloMorph effectively captures a wide range of facial expressions, lighting conditions, and ethnic variations. This ensures robustness and versatility in capturing various facial features across different demographic profiles. The integration of the DLib Shape Predictor with 68 facial landmarks allows for precise face detection and detailed mapping into latent space using the e4e encoder, preserving essential facial features. StyloMorph then pairs source images with stylistic references by manipulating their latent spaces, enabling the fine-tuned model to apply targeted artistic styles while retaining the original facial characteristics. Findings indicate that StyloMorph facilitates high-quality, real-time face stylizations using significantly fewer computational resources than traditional methods. This efficiency, coupled with the system's ability to provide user-friendly and accessible solutions for artistic transformations, makes StyloMorph an ideal tool for applications in digital art and media. The system democratizes artistic expression and offers substantial advancements in the speed and quality of facial stylization technologies.},
  keywords={Training;Shape;Computational modeling;Lighting;Streaming media;Media;Robustness;Real-time systems;Faces;Facial features;Face Stylization;pretrained models;Generative Adversarial Networks (GANs);Deep Learning},
  doi={10.1109/DELCON64804.2024.10866661},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11135891,
  author={Liu, Wei and Zhu, Zhe},
  booktitle={2025 International Conference on Mechatronics, Robotics, and Artificial Intelligence (MRAI)}, 
  title={A Generative Self-supervised Learning Framework for ECG Signals}, 
  year={2025},
  volume={},
  number={},
  pages={606-609},
  abstract={Electrocardiogram (ECG) is an effective tool for screening cardiovascular diseases, and deep learning-based ECG diagnostic tool has drawn significant attention recently. Existing ECG classification methods generally need a lot of annotated ECG samples, but annotating ECG signals requires time-consuming and costly manual labeling by clinicians. Therefore, we propose a generative self-supervised learning method for ECG classification, aiming to enhance the model’s ability to learn from ECG features by reconstructing the signals. First, our approach randomly masks portions of original ECG signals, dividing them into masked and visible segments. Then, the proposed encoder-decoder network processes these segments separately, generating two complete ECG sequences from the masked and visible portions, respectively. Finally, the model learns effective representations by minimizing the differences between the two generated sequences. Experiments on several public ECG datasets demonstrate that our model outperforms supervised methods as well as SOTA self-supervised methods in downstream tasks.},
  keywords={Representation learning;Mechatronics;Pattern classification;Self-supervised learning;Manuals;Electrocardiography;Robustness;Computational efficiency;Labeling;Robots;Electrocardiogram;self-supervised learning;Deep learning;Representation learning},
  doi={10.1109/MRAI65197.2025.11135891},
  ISSN={},
  month={June},}@INPROCEEDINGS{10193536,
  author={Rajendran, T. and Ramana, T. Venkata and Nalini, M. and Siva Subramanian, R and Chitra Devi, D and Anuradha, M.},
  booktitle={2023 4th International Conference on Electronics and Sustainable Communication Systems (ICESC)}, 
  title={Paddy Plant Leaf Disease Classification based on Artificial Intelligence}, 
  year={2023},
  volume={},
  number={},
  pages={1002-1009},
  abstract={One of the main dangers to food supply security has been paddy leaf disease. Disease diagnosis has shown to be a significant challenge in terms of precision and accuracy. Deep learning enabled recent developments in computer vision to make it possible. The classification of numerous rice leaf diseases has been quite successful when deep learning and CNN is used. A number of neural and layered visualization techniques were used with a convolutional neural network trained on a diseased rice leaf image dataset. Once diagnosed, neural networks have been shown to be able to record the hues and surface of lesions unique to a specific disease. This is similar to human intelligence.},
  keywords={Deep learning;Representation learning;Computer vision;Human intelligence;Neural networks;Convolutional neural networks;Security;Convolutional Neural Network (CNN);Leaf;Plant Disease Detection;Paddy},
  doi={10.1109/ICESC57686.2023.10193536},
  ISSN={},
  month={July},}@INPROCEEDINGS{11071058,
  author={Song, Danni and Li, Yuyi and Bian, Yinghui and Liu, Zizhen and Hao, Yuming and Yao, Jie},
  booktitle={2025 3rd International Conference on Data Science and Information System (ICDSIS)}, 
  title={Multi-Sensor Information Fusion Target using Generative Adversarial Networks for Lidar and Visible Image Fusion}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={In the development of artificial intelligence and autonomous driving technology, multi-sensor information fusion is the key to improve the accuracy of environmental perception. Due to the complexity of the real environment, it is difficult for a single sensor to meet the needs of high-precision perception. The development of deep learning brings new opportunities for sensor fusion. In this paper, a CrossGAN-Detection method based on generative adversarial network ( GAN ) is proposed to fuse lidar and visible light image data. This method realizes the feature transformation and optimization of different modal data by constructing a controllable GAN. Experiments on the KITTI dataset show that the average accuracy of CrossGAN-Detection is better than the existing methods under different difficulties, and the advantages are obvious under complex scenes and low visibility conditions, and the effectiveness of the cross-fusion strategy is verified. However, there are deficiencies in GAN training. In the future, new learning methods and time series modeling optimization can be combined to promote the application of multi-sensor fusion technology in many fields.},
  keywords={Training;Laser radar;Accuracy;Target tracking;Time series analysis;Object detection;Generative adversarial networks;Transformers;Synchronization;Optimization;multi-sensor information fusion;generative adversarial network;target detection;LiDAR;visible light image},
  doi={10.1109/ICDSIS65355.2025.11071058},
  ISSN={},
  month={May},}@INPROCEEDINGS{10116297,
  author={Ma, Yucheng and Wang, Qi and Liu, Zengji and Hong, Chao},
  booktitle={2022 IEEE 6th Conference on Energy Internet and Energy System Integration (EI2)}, 
  title={An Enhanced Adversarial Attacks Method on Power System Based on Model Extraction Algorithm}, 
  year={2022},
  volume={},
  number={},
  pages={1229-1234},
  abstract={Artificial intelligence algorithms fit connections between features and problems from a data-driven perspective. Artificial intelligence algorithms perform iterative training of data through neural network, which provides a new thinking dimension for researchers. The researches on the power grid field are no longer limited to modeling and analysis through traditional physical mechanism methods. However, there are security risks on the neural network model established by artificial intelligence algorithms. Attackers apply model extraction attacks to structure a substitute model of target power system model, which supports other attack algorithms to attack the power system and ultimately affects the normal operation of power system. This paper proposes an enhancement method for adversarial attacks on power system based on model extraction algorithm and tests the promoting effect of adversarial sample attack in various scenarios.},
  keywords={Training;Analytical models;Neural networks;System integration;Power grids;Iterative algorithms;Security;Artificial Intelligence;Model Extraction;Adversarial Sample;critical clearing time},
  doi={10.1109/EI256261.2022.10116297},
  ISSN={},
  month={Nov},}@ARTICLE{10571957,
  author={Gao, Mei and Pu, Pengju},
  journal={IEEE Access}, 
  title={Generative Adversarial Network-Based Experience Design for Visual Communication: An Innovative Exploration in Digital Media Arts}, 
  year={2024},
  volume={12},
  number={},
  pages={92035-92042},
  abstract={In the course of technological advancement, the landscape of artistic media creation has witnessed a proliferation of diversity. The integration of artificial intelligence has infused art media with pioneering elements, giving rise to emerging domains like generative art and algorithmic art, thereby infusing artistic expression with a forward-looking essence. This study delves into the realm of cross-modal artistry within digital media art creation, introducing a TAE-GAN image generation framework built upon GAN architecture. The framework initiates the process by employing TextCNN with self-attention to extract emotional features and embed word vectors from textual data. Subsequently, utilizing the generated feature vectors, the model’s output is realized through the GAN network, facilitating image generation based on textual data. Finally, quantitative metrics such as IS and FID are employed for model evaluation, along with user satisfaction analysis regarding text-image synthesis. Experimental findings underscore the commendable performance of the framework across both publicly available and custom datasets, attributed to its multifaceted network structures. Particularly noteworthy is the satisfaction rate for text-image alignment within the self-built dataset, exceeding 60%, presenting a pioneering methodological framework for future digital media art creation.},
  keywords={Generative adversarial networks;Generators;Media;Image synthesis;Training;Vectors;Emotion recognition;Deep learning;Visualization;Digital art;Emotion analysis;GAN;digital media;deep learning;TextCNN},
  doi={10.1109/ACCESS.2024.3419212},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8802800,
  author={Zhang, Xiaonan and Lv, Yang and Li, Yunjie and Liu, Yu and Luo, Pengcheng},
  booktitle={2019 5th International Conference on Big Data and Information Analytics (BigDIA)}, 
  title={A Modified Image Processing Method for Deblurring Based on GAN Networks}, 
  year={2019},
  volume={},
  number={},
  pages={29-34},
  abstract={In computer vision literature, it is really a challenging issue about removing the images blur resulted from camera shake. As the existing image deblurring methods do not apply to the image degraded by partial motion blur, and the existing partial blur detection approaches only used low -level blur features to measure the blurry degree of an image, the blur regions extracted via these methods usually have misclassification. To solve the imaging deblurring problem, we propose an image deblurring method based on Generative Adversarial Network (GAN) architecture using dual path connection. In comparison with the traditional image deblurring algorithm, this model can avoid the dependence on apriori-knowledge of blurred image. Experimental results show that the proposed method significantly outperforms other state-of-art algorithms on image deblurring.},
  keywords={Generative adversarial networks;Image restoration;Generators;Convolution;Gallium nitride;Kernel;Deconvolution;image processing;imaging deblurring;artificial intelligence;dual path connection;convolutional neural network},
  doi={10.1109/BigDIA.2019.8802800},
  ISSN={},
  month={July},}@INPROCEEDINGS{10906961,
  author={Nguyen, Huy and An, Sensong and Luyen, Hung},
  booktitle={2025 United States National Committee of URSI National Radio Science Meeting (USNC-URSI NRSM)}, 
  title={Reconfigurable Transmitarray Design with Generative Adversarial Network}, 
  year={2025},
  volume={},
  number={},
  pages={347-347},
  abstract={The advent of artificial intelligence (AI) has introduced innovative approaches for the design of metasurfaces, significantly reducing the reliance on traditional iterative analytical methods based on simulations. Numerous studies (e.g., S. An et al., “Deep Convolutional Neural Networks to Predict Mutual Coupling Effects in Metasurfaces”, Advanced Optical Materials, vol. 10, 2022) have demonstrated substantial advancements by leveraging various deep learning networks to address macroscopic-level challenges, such as beam steering, pattern optimization, and aperture efficiency enhancement. Conversely, there is a growing interest in employing generative AI algorithms to address the more intricate task of designing unit cells, which is crucial to achieving the desired electromagnetic (EM) surface properties (C. Niu et al., “A Diffusion Model for Multi-Layered Metasurface Unit Cell Synthesis”, IEEE Open Journal of Antennas and Propagation, vol. 4, 2023). This unit-cell-level design process has long been recognized as one of the most time-intensive aspects of metasurface development, primarily due to the extensive literature review and the iterative nature of the trial-and-error approach conventionally required for achieving optimal designs. At the meta-atom level, AI-based design methodologies are commonly applied to solve the inverse design problem, where the process begins with the desired surface performance and seeks to generate the appropriate unit-cell geometry. A notable example of this is the work of Sensong An et al. in “A Deep Learning Approach for Objective-Driven All-Dielectric Metasurface Design” (ACS Photonics, vol. 6, issue 12, Nov. 2019), which demonstrated the potential of AI to design passive metasurfaces in a matter of seconds by utilizing variants of generative adversarial networks (GANs) for the rapid and efficient creation of multifunctional passive designs. Reconfigurable metasurfaces with beam-steering capabilities, such as transmitarrays or reflectarrays, traditionally time-consuming to design, are also promising candidates for the application of AI-driven methods. However, unlike passive meta-atom designs, reconfigurable metasurfaces pose significant challenges for AI-based approaches. A major limitation is the difficulty in generating high-quality, effective datasets for training. Moreover, the active structures, which retain fixed geometrical configurations while representing different phase states (or electrical connections), introduce an added complexity in terms of dimensionality, further complicating the AI-based modeling and optimization processes. Nevertheless, it is of great interest to conduct a pilot study on the application of AI-based design approaches for reconfigurable transmitarrays/reflectarrays to evaluate any potential advantages they offer over conventional design techniques.},
  keywords={Deep learning;Training;Metasurfaces;Generative adversarial networks;Prediction algorithms;Iterative methods;Surface treatment;Optimization;Systematic literature review;Photonics},
  doi={10.23919/USNC-URSINRSM66067.2025.10906961},
  ISSN={},
  month={Jan},}@ARTICLE{10608135,
  author={Chen, Jiayuan and Shi, You and Yi, Changyan and Du, Hongyang and Kang, Jiawen and Niyato, Dusit},
  journal={IEEE Internet of Things Journal}, 
  title={Generative-AI-Driven Human Digital Twin in IoT Healthcare: A Comprehensive Survey}, 
  year={2024},
  volume={11},
  number={21},
  pages={34749-34773},
  abstract={The Internet of Things (IoT) can significantly enhance the quality of human life, specifically in healthcare, attracting extensive attentions to IoT healthcare services. Meanwhile, the human digital twin (HDT) is proposed as an innovative paradigm that can comprehensively characterize the replication of the individual human body in the digital world and reflect its physical status in real time. Naturally, HDT is envisioned to empower IoT healthcare beyond the application of healthcare monitoring by acting as a versatile and vivid human digital testbed, simulating the outcomes and guiding the practical treatments. However, successfully establishing HDT requires high-fidelity virtual modeling and strong information interactions but possibly with scarce, biased, and noisy data. Fortunately, a recent popular technology called generative artificial intelligence (GAI) may be a promising solution because it can leverage advanced AI algorithms to automatically create, manipulate, and modify valuable while diverse data. This survey particularly focuses on the implementation of GAI-driven HDT in IoT healthcare. We start by introducing the background of IoT healthcare and the potential of GAI-driven HDT. Then, we delve into the fundamental techniques and present the overall framework of GAI-driven HDT. After that, we explore the realization of GAI-driven HDT in detail, including GAI-enabled data acquisition, communication, data management, digital modeling, and data analysis. Besides, we discuss typical IoT healthcare applications that can be revolutionized by GAI-driven HDT, namely, personalized health monitoring and diagnosis, personalized prescription, and personalized rehabilitation. Finally, we conclude this survey by highlighting some future research directions.},
  keywords={Medical services;Monitoring;Surveys;Internet of Things;Data models;Digital twins;Data analysis;Diffusion model;generative adversarial network (GAN);generative artificial intelligence (GAI);human digital twin (HDT);Internet of Things (IoT)-healthcare;transformer;variational autoencoder (VAE)},
  doi={10.1109/JIOT.2024.3421918},
  ISSN={2327-4662},
  month={Nov},}@ARTICLE{9532007,
  author={Kim, Yerin and Hong, Sungwook},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Very Short-Term Rainfall Prediction Using Ground Radar Observations and Conditional Generative Adversarial Networks}, 
  year={2022},
  volume={60},
  number={},
  pages={1-8},
  abstract={Weather radars play an important role in in situ rainfall monitoring owing to their ability to measure instantaneous rain rates and rainfall distributions. Currently, the Korea Meteorological Administration (KMA) provides instantaneous radar observation data and predictions based on the McGill algorithm for precipitation nowcasting by Lagrangian extrapolation (MAPLE) for up to 6 h, for short-term forecasting. This study presents a conditional generative adversarial network (CGAN)-based radar rainfall prediction method for very short-range weather forecasts from 10 min to 4 h. The CGAN-predicted model was trained and tested using KMA’s constant altitude plan position indicator (CAPPI) observation data. The qualitative comparison between the radar observation and the CGAN-predicted rain rates displayed high statistical scores, such as the probability of detection (POD) = 0.8442, false alarm ratio (FAR) = 0.2913, and critical success index (CSI) = 0.6268, in the case of a 1-h prediction for rainfall on September 5, 2019, 15:20 KST. This study demonstrates the capability of the CGAN model for short-term rainfall forecasting. Consequently, the CGAN-generated radar-based rainfall prediction could complement the KMA MAPLE system and be useful in various forecasting applications.},
  keywords={Radar;Rain;Predictive models;Meteorological radar;Radar imaging;Data models;Spaceborne radar;Artificial intelligence;conditional generative adversarial network (CGAN);prediction;radar;rainfall},
  doi={10.1109/TGRS.2021.3108812},
  ISSN={1558-0644},
  month={},}@ARTICLE{10850880,
  author={Dehbozorgi, Mohammad Reza and Rastegar, Mohammad and Arani, Mohammadreza Fakhari Moghaddam},
  journal={IEEE Transactions on Industry Applications}, 
  title={False Data Injection Attack Detection and Localization Framework in Power Distribution Systems Using a Novel Ensemble of CNNs and Explainable Artificial Intelligence}, 
  year={2025},
  volume={61},
  number={3},
  pages={4801-4811},
  abstract={Cyber-physical power systems are vulnerable to cyber-attacks, especially false data injection attacks (FDIAs). FDIAs against distribution system state estimation (DSSE), which alter state estimation (SE) by changing meter readings, have received researchers’ attention in recent years. A common defense against FDIAs in the literature is the use of labeled data to train classifiers as FDIA detectors. However, this approach's performance can be limited by the highly imbalanced nature of FDIA datasets. The black box characteristics of the machine learning models can make them hard to trust and adopt in important applications. Hence, we propose an innovative explainable artificial intelligence (XAI)-enhanced ensemble-based detection and localization model that leverages convolutional neural networks (CNNs) and support vector machine (SVM). The ensemble model uses SVM to merge various spatiotemporal CNNs’ outputs. Training these CNNs on under-sampled subsets of the majority class and using their ensemble addresses class imbalance. This paper leverages XAI to enhance the interpretability of the detection process and improve localization accuracy. The localization process uses the outputs of an XAI technique, gradient-weighted class activation mapping, to aid the majority-voting-based localization ensemble model. Our model can also detect FDIAs during the distribution feeder's topology changes. Extensive simulations on IEEE 13-bus and IEEE 123-bus feeders prove the proposed under-sampling-based detection approach as an alternative to prevalent over-sampling methods like generative adversarial networks (GANs), offering a novel solution to class imbalance challenges. The paper also provides a comprehensive analysis of the proposed spatiotemporal model's performance, demonstrating its superiority over temporal CNNs.},
  keywords={Location awareness;Meters;Training;Support vector machines;Data models;Spatiotemporal phenomena;Vectors;Power distribution;Load modeling;Explainable AI;Convolutional neural network;cyber-security;ensemble model;explainable artificial intelligence;false data injection attacks (FDIAs);Power distribution systems},
  doi={10.1109/TIA.2025.3532917},
  ISSN={1939-9367},
  month={May},}@INPROCEEDINGS{10099362,
  author={Alhartomi, Mohammed},
  booktitle={2023 IEEE 13th Annual Computing and Communication Workshop and Conference (CCWC)}, 
  title={New Reward-Clipping Mechanism in Deep -Learning Enabled Internet of Things in 6G to Improve Intelligent Transmission Scheduling}, 
  year={2023},
  volume={},
  number={},
  pages={1236-1242},
  abstract={Sixth-generation (6G) networks and apps have lately benefited from the use of artificial intelligence (AI) to improve a significant amount of data. The integration of AI with 6G can help support green energy and sustainable system by overcoming the complexity of network flaws. The Internet of Things (IoT) utilizes artificial intelligence (AI) to improve the management of large amounts of data, reduce energy consumption, regulate traffic, and facilitate data storage. The primary difficulty in IoT is creating intelligent agents that can enhance smart packet transmission scheduling for Ultra Reliability Low Latency Connection (URLLC). The best channel to employ for smart packet transmission scheduling in the IoT must have a low estimate Packet Error Rate (PER), as well as minimal packet delays from channel errors, and retransmissions. To improve smart packet transmission scheduling by shortening the interval between the estimated and target action value, we propose a Generative Adversarial Network and Deep Q Network (GAN-DQN). To avoid significant critical fluctuations in the target action value, GAN-DQN training is based on reward correction to evaluate the value of each action for accurate states. The simulation results demonstrate that the proposed GAN-DQN increase IoT system reliability by reducing the packet loss caused by various multiuser arrival at a BS while cutting Transmission Delay (TD) to improve intelligent transmission scheduling and power consumption.},
  keywords={6G mobile communication;Training;Channel estimation;Ultra reliable low latency communication;Generative adversarial networks;Scheduling;Delays;AI;IoT;URLLC;packet error rate;6G;deep-RL},
  doi={10.1109/CCWC57344.2023.10099362},
  ISSN={},
  month={March},}@INPROCEEDINGS{10493063,
  author={Aftabi, Elmira and Shirazi, Badrosadat Nategholeslam and Safavi, Ali Akbar and Salimi, Ghasem and Aftabi, Hamidreza},
  booktitle={2024 11th International and the 17th National Conference on E-Learning and E-Teaching (ICeLeT)}, 
  title={A Framework for Customized Course Design and Personalized Learning with AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The rapid pace of technological advancements and the wide range of subjects present challenges to traditional learning methods. The emergence of artificial intelligence technologies has led to changes and innovations in education, offering a valuable solution that enables the customization of courses to meet individual needs and time constraints. We have proposed a framework for personalized learning aimed at reducing learner confusion amidst an abundance of content and mitigating stress. This framework consists of various steps and provides specific prompts for each learning process, tailored for chatbots. Adaptive steps and prompts help learners create courses tailored to their current educational level, desired achievements, and chosen field of study, ensuring a systematic and personalized learning experience. This paper specifically discusses these approaches using chatbots, such as ChatGPT, with examples including topics like deep learning. Our results demonstrate the method effectively provides personalized access to scientific advancements, encouraging independent and critical thinking, while ensuring proper use of AI tools.},
  keywords={Deep learning;Technological innovation;Systematics;Electronic learning;Generative AI;Education;Chatbots;Artificial Intelligence;Customized Course Educational Framework;Learning Challenges;Prompt Engineering;Technology Advancements},
  doi={10.1109/ICeLeT62507.2024.10493063},
  ISSN={2163-6982},
  month={Feb},}@ARTICLE{11154002,
  author={Lokumarambage, Maheshi and Sivalingam, Thushan and Dong, Feng and Rajatheva, Nandana and Fernando, Anil},
  journal={IEEE Transactions on Machine Learning in Communications and Networking}, 
  title={Generative AI-Based Vector Quantized End-to-End Semantic Communication System for Wireless Image Transmission}, 
  year={2025},
  volume={3},
  number={},
  pages={1050-1074},
  abstract={Semantic communication (SemCom) systems enhance transmission efficiency by conveying semantic information in lieu of raw data. However, challenges arise when designing these systems due to the need for robust semantic source coding for information representation extending beyond the training dataset, maintaining channel-agnostic performance, and ensuring robustness to channel and semantic noise. We propose a novel generative artificial intelligence (AI) based SemCom architecture conditioned on quantized latent. The system reduces the communication overhead of the wireless channel by transmitting the index of the quantized latent over the communication channel by mapping the quantized vector to the learned codebook vectors. The learned codebook is the shared knowledge base. The encoder is designed with a novel spatial attention mechanism based on image energy, focusing on object edges. The critic assesses the realism of generated data relative to the original distribution, with the Wasserstein distance. The model introduces novel contrastive objectives at multiple levels, including pixel, latent, perceptual, and task output, tailored for noisy wireless semantic communication. We validated the proposed model for transmission quality and robustness with low-density parity-check (LDPC), which outperforms the baselines of better portable graphics (BPG), specifically at low signal-to-noise ratio (SNR) levels ( $ {\lt }~ {5}$  dB). Additionally, it shows comparable results with joint source-channel coding (JSCC) with lower complexity and latency. The model is validated for human perception and machine perception-oriented task utility. The model effectively transmits high-resolution images without requiring additional error correction at the receiver. We propose a novel semantic-based matrix to evaluate the robustness to noise and task-specific semantic distortion.},
  keywords={Semantics;Symbols;Encoding;Channel coding;Receivers;Wireless communication;Vectors;Training;Semantic communication;Robustness;Generative adversarial network (GAN);generative artificial intelligence (GenAI);knowledge representation;LDPC code;semantic communication;semantic encoding;vector quantization},
  doi={10.1109/TMLCN.2025.3607891},
  ISSN={2831-316X},
  month={},}@INBOOK{10785706,
  author={Haque, Enamul},
  booktitle={AI Horizons: Shaping a Better Future Through Responsible Innovation and Human Collaboration}, 
  title={Introduction}, 
  year={2024},
  volume={},
  number={},
  pages={xvii-xxxii},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9781501518485},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10785706},}@INPROCEEDINGS{9288197,
  author={Lim, Gilbert and Thombre, Pranav and Lee, Mong Li and Hsu, Wynne},
  booktitle={2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Generative Data Augmentation for Diabetic Retinopathy Classification}, 
  year={2020},
  volume={},
  number={},
  pages={1096-1103},
  abstract={A fundamental factor limiting the effectiveness of classification algorithms, especially in the medical imaging domain, has been an insufficient quantity of relevant class-specific data. In particular, positive examples of disease conditions tend to be rare, and represent a common bottleneck in improving model performance. In this paper, we introduce GAN-based generative data augmentation methods with dynamic input sampling, and compare their performance against an image feature transfer technique, towards improving the performance of real-world diabetic retinopathy classification tasks. Results suggest that generative data augmentation has the potential to significantly improve classification performance over the baseline.},
  keywords={Training;Retinopathy;Tools;Diabetes;Task analysis;Gallium nitride;Biomedical imaging;data augmentation, generative training, diabetic retinopathy, generative adversarial networks},
  doi={10.1109/ICTAI50040.2020.00167},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{10555616,
  author={Zhang, Yue and Meredith, Rachel and Reeves, Wilson and Coriolano, Julia and Babar, Muhammad Ali and Rahman, Akond},
  booktitle={2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR)}, 
  title={Does Generative AI Generate Smells Related to Container Orchestration?: An Exploratory Study with Kubernetes Manifests}, 
  year={2024},
  volume={},
  number={},
  pages={192-196},
  abstract={Generative artificial intelligence (AI) technologies, such as Chat-GPT have shown promise in solving software engineering problems. However, these technologies have also shown to be susceptible to generating software artifacts that contain quality issues. A systematic characterization of quality issues, such as smells in ChatGPT-generated artifacts can help in providing recommendations for practitioners who use generative AI for container orchestration.We conduct an empirical study with 98 Kubernetes manifests to quantify smells in manifests generated by ChatGPT. Our empirical study shows: (i) 35.8% of the 98 Kubernetes manifests generated include at least one instance of smell; (ii) two types of objects Kubernetes namely, Deployment and Service are impacted by identified smells; and (iii) the most frequently occurring smell is unset CPU and memory requirements. Based on our findings, we recommend practitioners to apply quality assurance activities for ChatGPT-generated Kubernetes manifests prior to using these manifests for container orchestration.CCS CONCEPTS• Software and its engineering → Software verification and validation; Software defect analysis.},
  keywords={Systematics;Generative AI;Memory management;Static analysis;Containers;Chatbots;Software;container orchestration;empirical study;kubernetes;quality;smell},
  doi={},
  ISSN={2574-3864},
  month={April},}@INPROCEEDINGS{10968178,
  author={D, Shofia Priyadharshini and Ramesh, G.P.},
  booktitle={2025 3rd International Conference on Integrated Circuits and Communication Systems (ICICACS)}, 
  title={Smart IoT-enabled Water Quality Management using Generative AI and Super-Resolution GAN for Enhanced Monitoring and Prediction}, 
  year={2025},
  volume={},
  number={},
  pages={01-07},
  abstract={An essential component of sustainable development is water quality management, which requires accurate monitoring and forecasting capabilities. Conventional methods for assessing water quality often face challenges such as sparse data, sensor inaccuracies, and real-time processing limitations. To address these challenges, this study proposes a Smart IoT-Enabled Water Quality Management System that integrates Super-Resolution Generative Adversarial Networks (SR-GAN) with artificial intelligence (AI) for enhanced monitoring and prediction. The system utilizes IoT -based smart sensors to collect real-time data on temperature, turbidity, oxygen concentration, pH levels, and other water quality parameters.SR-GAN enhances both the temporal and spatial resolution of low-quality sensor data, enabling better feature extraction and more precise information. Generative AI models are then employed for automated decision-making, anomaly detection, and forecasting, effectively identifying potential water pollution threats. Compared to conventional AI and deep learning methods, the proposed framework achieves superior performance in terms of response time efficiency (30% improvement), data quality, and prediction accuracy (98.7%). The integration of edge computing ensures low latency and real-time data processing. This innovative approach significantly enhances water quality monitoring accuracy, facilitating proactive measures and sustainable water resource management.},
  keywords={Temperature sensors;Accuracy;Generative AI;Superresolution;Water quality;Generative adversarial networks;Real-time systems;Reliability;Monitoring;Anomaly detection;smart IoT;water quality management;generative AI;super-resolution GAN;predictive analytics;edge computing;anomaly detection;environmental monitoring;deep learning;sensor data enhancement},
  doi={10.1109/ICICACS65178.2025.10968178},
  ISSN={},
  month={Feb},}@INBOOK{11104978,
  author={Nag, Anindya and Hassan, Md. Mehedi and Karim, Asif and Kumar Reddy C, Kishor},
  booktitle={Generative AI in Neurodegenerative Disorders: Innovations, Views, and Obstacles}, 
  title={Generative AI in Neurodegenerative Disorders: Innovations, Views, and Obstacles}, 
  year={2025},
  volume={},
  number={},
  pages={i-xl},
  abstract={This book delves into the transformative power of AI in the realm of neurodegenerative diseases, covering topics such as ALS, Huntington's, Parkinson's, and Alzheimer's. Generative AI provides new opportunities for early diagnosis, precise therapy, and individualized rehabilitation, which are crucial as these conditions remain major obstacles for healthcare providers and researchers. Researchers, physicians, AI developers, and healthcare professionals will find this book an invaluable resource for understanding how AI is influencing the development of treatments for neurodegenerative diseases. It describes important obstacles and future directions while providing insights into the newest breakthroughs, thus bridging the gap between technology and practical clinical applications. Anyone involved in neurodegenerative healthcare, from scientists conducting AI-driven medical research to physicians seeking to incorporate AI into patient care or AI professionals investigating new healthcare applications, will find the information and insights they need in this comprehensive book. Predictive analytics, biomarker identification, and drug discovery are being transformed by AI-driven models, such as deep neural networks, generative adversarial networks (GANs), and variational autoencoders (VAEs). This book offers a comprehensive examination of these developments. Robots, wearable sensors, and cognitive therapy platforms are some of the AI-enhanced rehabilitation tools covered, as are AI-integrated cutting-edge technologies like fMRI and MRI, gene-editing methods like CRISPR, and more. In addition to discussing recent technical developments, this book takes a close look at the data privacy, ethics, and regulatory issues that arise when using AI to study neurodegenerative disorders. Issues like algorithmic bias, model explainability, and fair AI-driven healthcare are thoroughly investigated in light of the growing usage of AI models in clinical decision-making, mental health applications, and cognitive rehabilitation.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788743801740},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11104978},}@ARTICLE{10197467,
  author={Yang, Changzhi and Pan, Huihui and Sun, Weichao and Gao, Huijun},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Social Self-Attention Generative Adversarial Networks for Human Trajectory Prediction}, 
  year={2024},
  volume={5},
  number={4},
  pages={1805-1815},
  abstract={Predicting accurate human future trajectories is of critical importance for self-driving vehicles if they are to navigate complex scenarios. Trajectories of humans are not only dependent on the humans themselves, but also the interactions with surrounding agents. Previous works mainly model interactions among agents by using a diversity of polymerization methods that integrate various learned agent states hit or miss. In this article, we propose social self-attention generative adversarial networks (Social SAGAN), which generate socially acceptable multimodal trajectory predictions. Social SAGAN incorporates a generator that predicts future trajectories of pedestrians, a discriminator that classifies trajectory predictions as real or fake, and a social self-attention mechanism that selectively refines the most interactive information and helps the overall model to capture what to pay attention to. Through extensive experiments, we demonstrate that our model achieves competitive prediction accuracy and computational complexity compared with previous state-of-the-art methods on all trajectory forecasting benchmarks.},
  keywords={Trajectory;Predictive models;Pedestrians;Feature extraction;Generative adversarial networks;Semantics;Navigation;Generative adversarial networks (GANs);self-attention;social interactions;trajectory prediction},
  doi={10.1109/TAI.2023.3299899},
  ISSN={2691-4581},
  month={April},}@ARTICLE{9811405,
  author={Huang, Shihua and He, Cheng and Cheng, Ran},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={SoloGAN: Multi-domain Multimodal Unpaired Image-to-Image Translation via a Single Generative Adversarial Network}, 
  year={2022},
  volume={3},
  number={5},
  pages={722-737},
  abstract={Despite significant advances in image-to-image (I2I) translation with generative adversarial networks (GANs), it remains challenging to effectively translate an image to a set of diverse images in multiple target domains using a pair of generator and discriminator. Existing multimodal I2I translation methods adopt multiple domain-specific content encoders for different domains, where each domain-specific content encoder is trained with images from the same domain only. Nevertheless, we argue that the content (domain-invariance) features should be learned from images among all of the domains. Consequently, each domain-specific content encoder of existing schemes fails to extract the domain-invariant features efficiently. To address this issue, we present a flexible and general SoloGAN model for efficient multimodal I2I translation among multiple domains with unpaired data. In contrast to existing methods, the SoloGAN algorithm uses a single projection discriminator with an additional auxiliary classifier and shares the encoder and generator for all domains. As such, the SoloGAN model can be trained effectively with images from all domains so that the domain-invariance content representation can be efficiently extracted. Qualitative and quantitative results over a wide range of datasets against several counterparts and variants of the SoloGAN model demonstrate the merits of the method, especially for challenging I2I translation tasks, i.e., tasks that involve extreme shape variations or need to keep the complex backgrounds unchanged after translations. Furthermore, we demonstrate the contribution of each component using ablation studies.},
  keywords={Generative adversarial networks;Image synthesis;Generative adversarial network (GAN);image synthesis;image-to-image (I2I) translation},
  doi={10.1109/TAI.2022.3187384},
  ISSN={2691-4581},
  month={Oct},}@INPROCEEDINGS{9551033,
  author={Nneji, Grace Ugochi and Cai, Jingye and Jianhua, Deng and Monday, Happy Nkanta and Ejiyi, Chukwuebuka Joseph and James, Edidiong Christopher and Mgbejime, Goodness Temofe and Oluwasanmi, Ariyo},
  booktitle={2021 4th International Conference on Pattern Recognition and Artificial Intelligence (PRAI)}, 
  title={A Super-Resolution Generative Adversarial Network with Siamese CNN Based on Low Quality for Breast Cancer Identification}, 
  year={2021},
  volume={},
  number={},
  pages={218-223},
  abstract={Breast cancer is a chronic illness leading to the death of millions of people yearly. Despite the fact that successful identification of benign and malignant images is dependent on radiologists' long-term knowledge, specialists occasionally disagree with their decisions. An automatic system provides an alternative choice for the image diagnosis, thereby helping the expert to make more reliable decisions efficiently, less prone to errors and make diagnosis more scalable. Another issue based with the diagnosis of breast cancer identification is the poor quality of the image which poses a challenge in identification performance. An enhanced super-resolution generative adversarial network has been implemented in this paper to produce super-resolution images of breast cancer from a low-resolution counterpart with higher quality and finer details using an upscale factor of 4. Additionally, siamese convolutional neural network was utilized for the features extraction and classification of breast cancer. The proposed model provides an effective classification performance in terms of accuracy and ROC-AUC scores of 98.87% and 98.76% respectively as compared to other existing approaches.},
  keywords={Measurement;Superresolution;Generative adversarial networks;Feature extraction;Breast cancer;Pattern recognition;Classification algorithms;breast cancer;deep learning;super-resolution;siamese network;generative adversarial network},
  doi={10.1109/PRAI53619.2021.9551033},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8576043,
  author={Xu, Hao and Cao, Yanan and Jia, Ruipeng and Liu, Yanbing and Tan, Jianlong},
  booktitle={2018 IEEE 30th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Sequence Generative Adversarial Network for Long Text Summarization}, 
  year={2018},
  volume={},
  number={},
  pages={242-248},
  abstract={In this paper, we propose a new adversarial training framework for text summarization task. Although sequence-to-sequence models have achieved state-of-the-art performance in abstractive summarization, the training strategy (MLE) suffers from exposure bias in the inference stage. This discrepancy between training and inference makes generated summaries less coherent and accuracy, which is more prominent in summarizing long articles. To address this issue, we model abstractive summarization using Generative Adversarial Network (GAN), aiming to minimize the gap between generated summaries and the ground-truth ones. This framework consists of two models: a generator that generates summaries, a discriminator that evaluates generated summaries. Reinforcement learning (RL) strategy is used to guarantee the co-training of generator and discriminator. Besides, motivated by the nature of summarization task, we design a novel Triple-RNNs discriminator, and extend the off-the-shelf generator by appending encoder and decoder with attention mechanism. Experimental results showed that our model significantly outperforms the state-of-the-art models, especially on long text corpus.},
  keywords={Generators;Hidden Markov models;Training;Decoding;Task analysis;Gallium nitride;Generative adversarial networks;Sequence Generative Adversarial Network;Text Summarization;Deep learning;Reinforcement learning},
  doi={10.1109/ICTAI.2018.00045},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{10369693,
  author={M, Poongodi and N, Buvaneswari and S, Bose and N, Maheswaran and S, Vijayalakshmi},
  booktitle={2023 International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)}, 
  title={Secure Translation from Sketch to Image Using an Unsupervised Generative Adversarial Network with Het for AI Based Images}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={Sketch to image translation could be a useful tool in identifying person and generating real life-like pictures out of sketches and drawings. Translation of sketches to image can come in handy in comic generation or graphic designing applications. The existing system under perform with the accuracy of the images generated and generating images with desired background image is also an important area to improve on. So, it is essential for a system to produce images with better accuracy and quality with desired background. The sketch to image translation is generally deployed using Convolution Neural networks (CNN) and Generative Adversarial Network (GAN) but the solutions often fall behind and fail to make high quality or a real life like output. While these methods focus on bringing out images resembling the given sketches, they fail to concentrate on quality of images generated. The images generated from existing Sketch to image translators and not real life-like and the generators themselves underperform in terms of accuracy. So, it is essential for a system, which can translate sketches into images without labels with better accuracy. The quality and the integrity of the sensitive images should be protected by using Homomorphic Encryption Technique (HET).},
  keywords={Graphics;Convolution;Neural networks;Generative adversarial networks;Transformers;Knowledge management;Generators;Generative Adversarial Network;Spatial Transformer Network;Convolution Neural Network;Residual Network;Homomorphic Encryption Technique},
  doi={10.1109/RMKMATE59243.2023.10369693},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8873455,
  author={Sun, Yasheng and He, Tao and Hu, Jie and Huang, Haiqing and Chen, Biao},
  booktitle={2019 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)}, 
  title={Intent-Aware Conditional Generative Adversarial Network for Pedestrian Path Prediction}, 
  year={2019},
  volume={},
  number={},
  pages={155-160},
  abstract={Learning to understand human behaviors and forecast their motions is a prerequisite for an automated car to navigate in urban traffic safely and efficiently. When pedestrians interact with a vehicle, they follow specific motion patterns based on their intentions. This work presents a conditional generative adversarial network based architecture that explicitly model human intention as a conditional variable to robustly learn the multi-modal nature of pedestrian motion for accurate future trajectory prediction. The generator in our framework uses a LSTM encoder-decoder conditioned on human intention for motion prediction while the discriminator consisting of a LSTM classifier learns to distinguish whether a predicted trajectory is consistent with a given intention. Through experiments on two real-world datasets, it demonstrates that our proposed architecture outperforms state-of-the-art methods in terms of the average displacement error of predicted positions. Additionally, qualitative analysis shows that our model is capable of predicting a multi-modal distribution with respect to human intentions.},
  keywords={Trajectory;Hidden Markov models;Vehicle dynamics;Mathematical model;Predictive models;Dynamics;Generative adversarial networks;pedestrian path prediction;conditional generative adversarial network;human intention estimation;encoder-decoder},
  doi={10.1109/ICAICA.2019.8873455},
  ISSN={},
  month={March},}@INPROCEEDINGS{10956978,
  author={Babu, Kancharagunta Kishan and Biswas, Saroj Kr. and Nath, Pantha Kanthi and Khan, Atiya and Das, Akhil Kumar},
  booktitle={2024 Third International Conference on Artificial Intelligence, Computational Electronics and Communication System (AICECS)}, 
  title={Paired Face Sketch-to-Photo Synthesis using Generative Adversarial Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Face Sketch-to-Photo Synthesis (FSPS) is a crucial problem to solve nowadays as it is used in many real-time applications like criminal case investigation, law enforcement, and digital entertainment. Earlier solving FSPS has been a challenging task due to the vast domain discrepancies between the face sketch images and photo images. However, with the invention of Generative Adversarial Networks (GANs), various image processing problems, such as image in-painting, image denoising, image colourization, and image draining, have been solved by treating them as Image-to-Image (12I) translation tasks. In this paper, the FSPS problem has been solved by treating it as a paired I2I translation task. Six State-Of-The-Art (SOTA) I2I translation methods named Pix2Pix, CycleGAN, PAN, AttentionGAN, CSA-GAN, and PCSGAN are implemented for FSPS over the four face sketch-photo datasets like AR, XM2VTS, CUHK, and CUFSF. Four famous image quality assessment metrics, Mean Squared Error (MSE) metric, Peak Signal-to-Noise Ratio (PSNR) metric, Structural Similarity Index Measure (SSIM) metric, and Learned Perceptual Image Patch Similarity (LPIPS) metric, have been utilized to evaluate the performance of the SOTA methods to select the best suitable I2I method to address the paired FSPS problem. In addition to the results analysis, a separate comparative analysis of the performance of the methods, along with their merits and demerits for all four datasets, are explained.},
  keywords={Measurement;Visualization;Technological innovation;Translation;PSNR;Attention mechanisms;Noise;Generative adversarial networks;Real-time systems;Faces;Face sketch-to-photo synthesis;Paired image datasets;Generative adversarial networks;and Image-to-image translation},
  doi={10.1109/AICECS63354.2024.10956978},
  ISSN={},
  month={Dec},}@ARTICLE{10726922,
  author={Singh, Anushikha and Hussain, Rukhshanda and Bhattacharya, Rajarshi and Lall, Brejesh and Panigrahi, B.K. and Agrawal, Anjali and Agrawal, Anurag and Thangakunam, Balamugesh and Christopher, D.J.},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={MDA-GAN: Multiscale and Dual Attention Generative Adversarial Network for Bone Suppression in Chest X-Rays}, 
  year={2025},
  volume={6},
  number={3},
  pages={604-613},
  abstract={The bone structure in a chest x-ray creates trouble for a radiologist to examine the organs, manifestation of disease, and hidden tiny abnormalities. Bone suppression in chest x-rays allows better examination of lung fields. This has the potential to improve diagnostic accuracy. Dual-energy subtraction imaging is a standard bone suppression technique that delivers a higher dose of radiation and requires specific hardware. This article proposes a novel multiscale and dual attention-guided generative adversarial network (MDA-GAN) to transform chest x-rays into bone-suppressed x-rays in an unsupervised manner. We incorporate a spatial attention module to generate attention maps that were further concatenated with the coarsely generated bone segmentation mask. This dual attention is introduced to the generator at multiple scales in between the skip connection of the encoder and decoder layer. The proposed dual attention multiscale mechanism helps the generator to learn that only bones need to be removed on the chest x-ray without tempering the remaining parts. The proposed MDA-GAN is trained with adversarial loss combined with deep supervised cycle consistency and structure similarity for unpaired training images. We employ supervision heads in all the decoder layers to convert the activation maps into an output comparable to the scaled-down images and minimize the cycle consistency loss in a deep supervised manner. Experiments are conducted on an unpaired dataset including the public and our in-house Indian dataset and results show that incorporating dual attention at multiple scales and deep cycle consistency in translation networks significantly improves the quality of bone-suppressed images. (https://github.com/rB080/ribsup.git.)},
  keywords={Bones;Biomedical imaging;X-ray imaging;Generators;Generative adversarial networks;Decoding;Lung;X-rays;Ribs;Image segmentation;Bone suppression;chest x-rays;generative adversarial network},
  doi={10.1109/TAI.2024.3483731},
  ISSN={2691-4581},
  month={March},}@INPROCEEDINGS{10539833,
  author={Li, Jiajun and Zhang, Chuhuan and Ma, Xiangcheng},
  booktitle={2024 International Conference on Electrical Drives, Power Electronics & Engineering (EDPEE)}, 
  title={Implementation and Applications of Neural Networks Based on FPGA}, 
  year={2024},
  volume={},
  number={},
  pages={192-194},
  abstract={Deep neural networks have been crucial in several recent developments in artificial intelligence and big data technology, including natural language processing, speech recognition, and computer vision. Given the numerous layers of deep neural network models, the computational complexity, and a large number of parameters, the performance of hardware such as computing power, memory bandwidth, and data storage is highly demanding. Due to their high parallelism, low power consumption, and reconfigurability, Field Programmable Gate Arrays (FPGAs), which are programmable logic devices, are frequently used as an alternative to CPUs and GPUs. Their combination with neural networks has become a current research hotspot in the field of artificial intelligence. This paper briefly describes firstly the current mainstream neural network models and the design ideas of FPGAs. Next, the applications of FPGA-based neural networks are introduced. Finally, this paper concludes with a summary and outlook on the development of FPGA-based applications for deep neural networks.},
  keywords={Computer vision;Power demand;Biological system modeling;Programmable logic devices;Artificial neural networks;Speech recognition;Computer architecture;FPGA;neural networks},
  doi={10.1109/EDPEE61724.2024.00043},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10899591,
  author={Li, Qihui and Kang, Ruixin and Lu, Haodong},
  booktitle={2024 7th International Conference on Algorithms, Computing and Artificial Intelligence (ACAI)}, 
  title={Syntactic-Semantic Graph Fusion Generative Adversarial Network: SSGF-GAN}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={As AI technology continues to advance rapidly, more generative tasks have emerged, with text-to-image (T2I) generation becoming a popular area of research. Numerous studies have demonstrated the impressive capabilities that GANs bring to this field. In this paper, we focus on enhancing GANs by incorporating a novel component called the Syntactic-Semantic Graph Fusion Block, inspired by the Graph Neural Network (GNN). This block effectively captures the semantic and syntactic nuances of different sentences, leading to more detailed and refined image generation. Additionally, we introduce several other innovations to the framework, further boosting the model's performance. Experimental results on the CUB bird dataset demonstrate that our approach outperforms many current advanced models.},
  keywords={Technological innovation;Image synthesis;Computational modeling;Semantics;Text to image;Syntactics;Generative adversarial networks;Feature extraction;Boosting;Graph neural networks;Generative Adversarial Network;Text-to-Image;Computer Vision;Natural Language Processing;Graph Neural Network;CUB dataset},
  doi={10.1109/ACAI63924.2024.10899591},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10457292,
  author={Zhou, Yikui and Wang, Jie and Tang, Junnan and Gou, Chao and Jiang, Zigui and Li, Dan and Ng, See-Kiong},
  booktitle={2023 International Conference on Artificial Intelligence of Things and Systems (AIoTSys)}, 
  title={MP-GAN: Cyber-Attack Detection and Localization for Cyber-Physical Systems with Multi-Process Generative Adversarial Networks*}, 
  year={2023},
  volume={},
  number={},
  pages={186-193},
  abstract={Cyber-Physical System (CPS) integrates sensing, computation, cybernetics, and networking to control a hybrid physical system consisting of different functional subsystems, making the production process more intelligent and controllable. However, cyber-attacks during its operation will lead to abnormal system behaviors or even system breakdowns. In recent years, data-driven anomaly detection methods have been adopted to judge whether the CPS system is under cyber-attacks based on rich sensor measurements to avoid further economic losses or safety issues. However, the multi-process essence of CPS has not been adequately addressed in existing works to locate the processes or points being attacked for in-time actions. In this work, we proposed a Multi-Process Generative Adversarial Network (MP-GAN) framework to detect anomalous CPS statuses and locate cyber-attacks. Specifically, the Long-Short-Term-Memory Recurrent Neural Networks (LSTM-RNN) was adopted as the base model to capture the temporal correlation of time series distributions, and the data was transferred between latent space and data space in a bi-directional manner, which regulated the generator to generate more realistic samples and thus better grasping the underline principles of the system. Moreover, parallel generators were employed to capture system performances at different physical processes, thus localizing the attacked CPS processes. Experiments on three CPS datasets, two collected from the Secure Water Treatment (SWaT) system and one collected from the water Distribution (WADI) system, showed that the proposed MP-GAN framework effectively reported anomalies caused by various cyber-attacks inserted in these complex multiprocess CPSs, which outperforms the state-of-the-art methods and can also locate most of the detected irregularities at the corresponding stages where the attacks were inserted.},
  keywords={Correlation;Time series analysis;Bidirectional control;Cyber-physical systems;Generative adversarial networks;Generators;Loss measurement;Cyber-Attack Detection and Localization;Cyber-Physical System;Generative Adversarial Networks;Multivariate Time Series},
  doi={10.1109/AIoTSys58602.2023.00049},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10677617,
  author={Ajuluchukwu, Melvin and Shalan, Atef and Chen, Lei and Ji, Yiming and Balogun, Emmanuel},
  booktitle={2024 IEEE Annual Congress on Artificial Intelligence of Things (AIoT)}, 
  title={Low-Resolution Image Enhancement using Generative Adversarial Networks}, 
  year={2024},
  volume={},
  number={},
  pages={213-218},
  abstract={Enhancing low-resolution (LR) images is crucial in the field of machine vision science. Improving the quality of LR images captured by security cameras is indispensable for forensic analysis and identification in surveillance applications. Generative Adversarial Networks (GANs) have emerged as a powerful deep-learning technique to address the super-resolution (SR) challenge inherent in long-range surveillance photos. The primary aim of this study is to enhance low-quality images of highway security surveillance using GANs architecture to optimize the image quality by generating high-resolution (HR) equivalents of the real HR images. The desired images were reconstructed using a dataset and employing Red-Green-Blue (RGB) guided thermal SR-GANs and GANs, along with perceptual loss function techniques. These approaches enhance image quality while preserving important LR image features, thereby reducing blur and glitches associated with image upscaling.},
  keywords={Road transportation;Image quality;Surveillance;Machine vision;Superresolution;Generative adversarial networks;Security;blur;forensic analysis;image enhancement;low-resolution image;Super-Resolution Generative Adversarial Network (SRGAN)},
  doi={10.1109/AIoT63253.2024.00049},
  ISSN={},
  month={July},}@INPROCEEDINGS{10800301,
  author={Alevizos, Vasileios and Papakostas, George A. and Simasiku, Akebu and Malliarou, Dimitra and Messinis, Antonis and Edralin, Sabrina and Xu, Clark and Yue, Zongliang},
  booktitle={2024 5th International Conference on Data Analytics for Business and Industry (ICDABI)}, 
  title={Integrating Artificial Open Generative Artificial Intelligence into Software Supply Chain Security}, 
  year={2024},
  volume={},
  number={},
  pages={200-206},
  abstract={While new technologies emerge, human errors always looming. Software supply chain is increasingly complex and intertwined, the security of a service has become paramount to ensuring the integrity of products, safeguarding data privacy, and maintaining operational continuity. In this work, we conducted experiments on the promising open Large Language Models (LLMs) into two main software security challenges: source code language errors and deprecated code, with a focus on their potential to replace conventional static and dynamic security scanners that rely on predefined rules and patterns. Our findings suggest that while LLMs present some unexpected results, they also encounter significant limitations, particularly in memory complexity and the management of new and unfamiliar data patterns. Despite these challenges, the proactive application of LLMs, coupled with extensive security databases and continuous updates, holds the potential to fortify Software Supply Chain (SSC) processes against emerging threats.},
  keywords={Industries;Data privacy;Generative AI;Databases;Large language models;Source coding;Supply chains;Memory management;Software;Security;Large Language Models;Software Supply Chain Security;Vulnerabilities},
  doi={10.1109/ICDABI63787.2024.10800301},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10276634,
  author={Muafy, Muhammad Bagus Izzan and Sthevanie, Febryanti and Ramadhani, Kurniawan Nur},
  booktitle={2023 International Conference on Data Science and Its Applications (ICoDSA)}, 
  title={Generated AI Face Detection using Xception Model}, 
  year={2023},
  volume={},
  number={},
  pages={209-214},
  abstract={Generative Adversarial Networks (GANs) have emerged as a valuable deep learning technique, capable of generating lifelike artificial faces through learned data. However, the proliferation of GAN-generated content raises concerns about detecting artificially created faces. Therefore, it is important to detect artificially generated faces visually to prevent fraud, ensure security and privacy, maintain information credibility, and support law enforcement and public safety. To address this challenge, we present a system designed specifically to detect fake face images generated by AI. Our research contributes to the ongoing efforts in combating the challenges posed by GAN-generated fake content, particularly in the domain of face images. By developing robust detection systems, we can enhance our ability to identify and mitigate the potentially harmful consequences of deceptive or maliciously generated visual content. Our research leverages the Xception model, utilizing depthwise separable convolution as the underlying method for classification. We used a collection of 20.000 images comprising both generated faces from the StyleGAN dataset and real faces from CelebA-HQ. Our system’s performance was evaluated using a testing set and has resulted in an impressive accuracy of 98.77%. The generated class has 98% in precision and f1-score, and 97% in recall. For the real class, it has 97% in precision, 98% in recall and f1-score. This indicates the system is effective in accurately distinguishing between generated fake faces and authentic ones.},
  keywords={Visualization;Privacy;Convolution;Law enforcement;Public security;Security;Artificial intelligence;fake face detection;cnn;xception;deep learning},
  doi={10.1109/ICoDSA58501.2023.10276634},
  ISSN={},
  month={Aug},}@ARTICLE{9506869,
  author={Zhang, Ruixuan and Lu, Wenhuan and Wei, Xi and Zhu, Jialin and Jiang, Han and Liu, Zhiqiang and Gao, Jie and Li, Xuewei and Yu, Jian and Yu, Mei and Yu, Ruiguo},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={A Progressive Generative Adversarial Method for Structurally Inadequate Medical Image Data Augmentation}, 
  year={2022},
  volume={26},
  number={1},
  pages={7-16},
  abstract={The generation-based data augmentation method can overcome the challenge caused by the imbalance of medical image data to a certain extent. However, most of the current research focus on images with unified structure which are easy to learn. What is different is that ultrasound images are structurally inadequate, making it difficult for the structure to be captured by the generative network, resulting in the generated image lacks structural legitimacy. Therefore, a Progressive Generative Adversarial Method for Structurally Inadequate Medical Image Data Augmentation is proposed in this paper, including a network and a strategy. Our Progressive Texture Generative Adversarial Network alleviates the adverse effect of completely truncating the reconstruction of structure and texture during the generation process and enhances the implicit association between structure and texture. The Image Data Augmentation Strategy based on Mask-Reconstruction overcomes data imbalance from a novel perspective, maintains the legitimacy of the structure in the generated data, as well as increases the diversity of disease data interpretably. The experiments prove the effectiveness of our method on data augmentation and image reconstruction on Structurally Inadequate Medical Image both qualitatively and quantitatively. Finally, the weakly supervised segmentation of the lesion is the additional contribution of our method.},
  keywords={Ultrasonic imaging;Lesions;Image reconstruction;Annotations;Task analysis;Generative adversarial networks;Medical diagnostic imaging;Ultrasound images;structural legitimacy;data augmentation},
  doi={10.1109/JBHI.2021.3101551},
  ISSN={2168-2208},
  month={Jan},}@ARTICLE{10770814,
  author={Zhang, Hao and Xu, Jin-Jian and Cui, Hong-Wei and Li, Lin and Yang, Yaowen and Tang, Chao-Sheng and Boers, Niklas},
  journal={IEEE Geoscience and Remote Sensing Magazine}, 
  title={When Geoscience Meets Foundation Models: Toward a general geoscience artificial intelligence system}, 
  year={2024},
  volume={},
  number={},
  pages={2-41},
  abstract={Artificial intelligence (AI) has significantly advanced Earth sciences, yet its full potential in to comprehensively modeling Earth’s complex dynamics remains unrealized. Geoscience foundation models (GFMs) emerge as a paradigm-shifting solution, integrating extensive cross-disciplinary data to enhance the simulation and understanding of Earth system dynamics. These data-centric AI models extract insights from petabytes of structured and unstructured data, effectively addressing the complexities of Earth systems that traditional models struggle to capture. The unique strengths of GFMs include flexible task specification, diverse input-output capabilities, and multimodal knowledge representation, enabling analyses that surpass those of individual data sources or traditional AI methods. This review not only highlights the key advantages of GFMs, but also presents essential techniques for their construction, with a focus on transformers, pre-training, and adaptation strategies. Subsequently, we examine recent advancements in GFMs, including large language models, vision models, vision-language models, and foundation-model-based agents, particularly emphasizing the potential applications in remote sensing. Additionally, the review concludes with a comprehensive analysis of the challenges and future trends in GFMs, addressing five critical aspects: data integration, model complexity, uncertainty quantification, interdisciplinary collaboration, and concerns related to privacy, trust, and security. This review offers a comprehensive overview of emerging geoscientific research paradigms, emphasizing the untapped opportunities at the intersection of advanced AI techniques and geoscience. It examines major methodologies, showcases advances in large-scale models, and discusses the challenges and prospects that will shape the future landscape of GFMs. The paper highlights a dynamic field rich with possibilities, poised to unlock new insights into Earth’s complexities and further advance geoscience exploration.},
  keywords={Geoscience;Artificial intelligence;Frequency modulation;Earth;Reviews;Data models;Adaptation models;Surveys;Analytical models;Computational modeling},
  doi={10.1109/MGRS.2024.3496478},
  ISSN={2168-6831},
  month={},}@INPROCEEDINGS{10788248,
  author={Jixuan, Wang},
  booktitle={2024 International Conference on Computers, Information Processing and Advanced Education (CIPAE)}, 
  title={Application and Design Implementation of Deep Learning Algorithms Based on Artificial Intelligence in Virtual Reality Interaction}, 
  year={2024},
  volume={},
  number={},
  pages={461-467},
  abstract={In recent years, the rapid advancement of virtual reality (VR) technology has greatly enhanced user interaction experiences. Concurrently, artificial intelligence (AI), particularly deep learning algorithms, have shown powerful potential in areas such as gesture recognition, offering new perspectives and methodologies for VR interaction design. This article begins by introducing the fundamental theory of deep learning, encompassing convolutional neural networks (CNN), nonlinear activation functions, loss functions, and the training process. Subsequently, it delves into the application of deep learning in gesture recognition, conducting a detailed analysis of data collection and preprocessing for datasets, network model design, and optimization strategies. Following this, the effectiveness and practicality of the proposed methods are validated through a series of experiments. Furthermore, the performance of the model at different testing stages is assessed. Ultimately, the advantages and challenges of deep learning-based gesture recognition in virtual reality interaction are summarized, accompanied by an outlook on future developmental directions.},
  keywords={Deep learning;Training;Solid modeling;Virtual reality;Gesture recognition;User experience;Convolutional neural networks;Artificial intelligence;Optimization;Testing;Deep learning algorithms;virtual reality;interactive applications;design implementation},
  doi={10.1109/CIPAE64326.2024.00089},
  ISSN={},
  month={Aug},}@ARTICLE{10684453,
  author={Bai, Yu and Li, Jun and Shen, Jun and Zhao, Liang},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Investigating the Efficacy of ChatGPT-3.5 for Tutoring in Chinese Elementary Education Settings}, 
  year={2024},
  volume={17},
  number={},
  pages={2102-2117},
  abstract={The potential of artificial intelligence (AI) in transforming education has received considerable attention. This study aims to explore the potential of large language models (LLMs) in assisting students with studying and passing standardized exams, while many people think it is a hype situation. Using primary education as an example, this research investigates whether ChatGPT-3.5 can achieve satisfactory performance on the Chinese Primary School Exams and whether it can be used as a teaching aid or tutor. We designed an experimental framework and constructed a benchmark that comprises 4800 questions collected from 48 tasks in Chinese elementary education settings. Through automatic and manual evaluations, we observed that ChatGPT-3.5’s pass rate was below the required level of accuracy for most tasks, and the correctness of ChatGPT-3.5’s answer interpretation was unsatisfactory. These results revealed a discrepancy between the findings and our initial expectations. However, the comparative experiments between ChatGPT-3.5 and ChatGPT-4 indicated significant improvements in model performance, demonstrating the potential of using LLMs as a teaching aid. This article also investigates the use of the trans-prompting strategy to reduce the impact of language bias and enhance question understanding. We present a comparison of the models' performance and the improvement under the trans-lingual problem decomposition prompting mechanism. Finally, we discuss the challenges associated with the appropriate application of AI-driven language models, along with future directions and limitations in the field of AI for education.},
  keywords={Education;Artificial intelligence;Benchmark testing;Standards;Training;Question answering (information retrieval);Proposals;ChatGPT-3.5;educational intelligence (EI);large language models (LLMs);primary education},
  doi={10.1109/TLT.2024.3464560},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10754316,
  author={Dahn, Nikolas and Firvida, Miguel Bande and Sharma, Proneet and Christensen, Leif and Geisle, Oliver and Mohrmann, Jochen and Frey, Torsten and Kumar Sanghamreddy, Prithvi and Kirchner, Frank},
  booktitle={OCEANS 2024 - Halifax}, 
  title={An Acoustic and Optical Dataset for the Perception of Underwater Unexploded Ordnance (UXO)}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={During the 20st century, millions of tons of munition were dumped into the oceans worldwide. After decades of decay, the problems these unexploded ordnance (UXO) are causing are starting to become apparent. In order to facilitate more efficient salvage efforts through e.g. autonomous underwater vehicles, access to representative data is paramount. However, so far such data is not publicly available. In this paper we present a dataset of multimodal synchronized data for acoustic and optical sensing of UXO underwater. Using an ARIS 3000 imaging sonar, a GoPro Hero 8 and a custom design gantry crane, we recorded close to 100 trajectories and over 74,000 frames of 3 distinct types of UXO in a controlled environment. Included in this dataset are raw and polar transformed sonar frames, annotated camera frames, sonar and target poses, textured 3D models, calibration matrices, and more. The dataset is publicly available at https://zenodo.org/records/11068046. The code for processing the raw data is available at https://github.com/dfki-ric/uxo-dataset2024.},
  keywords={Solid modeling;Three-dimensional displays;Cranes;Oceans;Weapons;Sonar;Cameras;Acoustics;Calibration;Optical sensors},
  doi={10.1109/OCEANS55160.2024.10754316},
  ISSN={2996-1882},
  month={Sep.},}@ARTICLE{11145168,
  author={Xing, Hantong and Wang, Shuang and Wang, Chenxu and Quan, Dou and Mo, Hanlin and Mei, Luyang and Zhou, Huaji and Jiao, Licheng},
  journal={IEEE Transactions on Communications}, 
  title={AFLNet: Auxiliary Feature Learning-Guided Cross-Channel Automatic Modulation Classification}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={This paper conducted a thorough investigation into the primary difficulty of the cross-channel automatic modulation classification (AMC) task by examining data distribution and feature space of different channel conditions. We concluded that the disruption of the target channel feature space structure breakdown the mapping relationship across channels, serving as the main contributor to model performance degradation. Based on the above conclusion, in order to improve the performance of cross-channel AMC, we introduce the Auxiliary Feature Learning-Guided Network (AFLNet). This network improves the structure of the target feature space through two uniquely designed tasks and facilitates efficient cross-domain alignment via a collaborative alignment mechanism. Specifically, AFLNet integrates similarity-based and confidence-based auxiliary feature learning tasks to enhance the discriminability of the target feature space and maintain the correspondence of category structures across different channels, thereby reducing the difficulty of feature alignment. The collaborative alignment mechanism combines adversarial training-based and self-training-based feature alignment methods, leveraging their mutually reinforcing effect and complementary strengths in global alignment and class-level alignment to enhance overall alignment performance. We carried out extensive experiments across four scenarios characterized by substantial channel variations, verifying that AFLNet achieves state-of-the-art with accuracy improvement of up to 9.71%.},
  keywords={Feature extraction;Modulation;Training;Data visualization;Data models;Collaboration;Rician channels;Research and development;Representation learning;Data mining;Automatic modulation classification;cross-channel;domain adaptation;self-training},
  doi={10.1109/TCOMM.2025.3604324},
  ISSN={1558-0857},
  month={},}@INPROCEEDINGS{10650613,
  author={Wang, Ke and Zhao, Ziqi and Liu, Binghong and Guo, Ping and Hu, Yazhou},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Can We Build a Generative Model without Back Propagation Training?}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Driven by deep learning, the field of content generation has witnessed remarkable progress. However, it still faces several challenges, such as low efficiency and high difficulty in training. To confront these obstacles, we propose an efficient and effective lightweight generative model, termed the pseudoinverse learning based variational autoencoder, within the framework of the synergetic learning system. The proposed learning system in this study comprises a reductive subsystem and a generative subsystem, incorporates a non-gradient learning scheme. The reductive subsystem employs variants of the pseudoinverse learning algorithm and probabilistic principal component analysis to embed the inputs into the latent space which is constrained to follow a standard normal distribution. The generative subsystem performs the inverse reconstruction process of the reductive subsystem, which can be used for content generation after training. The experimental results show that the proposed model significantly speeds up the training while achieving comparable generation quality to the baselines.},
  keywords={Training;Backpropagation;Source coding;Neural networks;Streaming media;Probabilistic logic;Task analysis;Content generation;pseudoinverse learning;generative learning;non-gradient descent learning;deep learning},
  doi={10.1109/IJCNN60899.2024.10650613},
  ISSN={2161-4407},
  month={June},}@ARTICLE{11016229,
  author={Khalid, Uman and Paracha, Usama Inam and Naveed, Zeerak and Duong, Trung Q. and Win, Moe Z. and Shin, Hyundong},
  journal={IEEE Wireless Communications}, 
  title={Quantum Fusion Intelligence for Integrated Satellite-Ground Remote Sensing}, 
  year={2025},
  volume={32},
  number={3},
  pages={46-55},
  abstract={Satellite imagery plays a crucial role in integrated satellite-ground remote sensing (SGRS), particularly in applications such as disaster management and military intelligence, where real-time monitoring and forecasting are essential for effective decision-making. However, narrow artificial intelligence (AI) models often face challenges in processing large-scale high-dimensional data efficiently while maintaining the required accuracy and speed, limiting their effectiveness in time-sensitive scenarios. To address these challenges, we explore the integration of satellite remote sensing with large AI, quantum computing, and quantum communication technologies, focusing on enhancing computational efficiency and data security in integrated SGRS systems. Specifically, we put forth an integrated quantum SGRS framework, which combines quantum fusion intelligence (QFI) with quantum anonymous communication (QAC). By integrating quantum and large AI, the QFI models enhance the efficiency, accuracy, and security of satellite imagery analysis while ensuring that the extracted information is transmitted to ground stations in a privacy-preserving manner using QAC. This approach is particularly effective in time- and privacy-sensitive scenarios. To demonstrate the effectiveness of QFI computing, we present case studies in disaster detection and environmental monitoring. This research highlights the transformative potential of quantum-large AI integration in SGRS and its implications for nonterrestrial-terrestrial quantum networks.},
  keywords={Accuracy;Satellites;Quantum advantage;Computational modeling;Scalability;Disasters;Satellite images;Environmental monitoring;Artificial intelligence;Remote sensing;Space-air-ground integrated networks},
  doi={10.1109/MWC.001.2400425},
  ISSN={1558-0687},
  month={June},}@ARTICLE{11014267,
  author={Nath, Suman and White, Ryen W. and Faisal, Fazle E. and Sharp, Morris E. and Gruen, Robert W. and Sivalingam, Lenin Ravindranath},
  journal={Computer}, 
  title={From Search Engines to Action Engines}, 
  year={2025},
  volume={58},
  number={6},
  pages={59-68},
  abstract={With generative artificial intelligence (AI), there is progress in moving from search results to AI-generated answers that synthesize and summarize content. Research on AI agents and artificial capable intelligence aims to reach the next frontier in information access: task completion.},
  keywords={Generative AI;Search engines;Performance evaluation;Artificial intelligence;Task analysis},
  doi={10.1109/MC.2025.3556643},
  ISSN={1558-0814},
  month={June},}@ARTICLE{8937049,
  author={Liu, Juhua and Wang, Chaoyue and Su, Hai and Du, Bo and Tao, Dacheng},
  journal={IEEE Transactions on Image Processing}, 
  title={Multistage GAN for Fabric Defect Detection}, 
  year={2020},
  volume={29},
  number={},
  pages={3388-3400},
  abstract={Fabric defect detection is an intriguing but challenging topic. Many methods have been proposed for fabric defect detection, but these methods are still suboptimal due to the complex diversity of both fabric textures and defects. In this paper, we propose a generative adversarial network (GAN)-based framework for fabric defect detection. Considering existing challenges in real-world applications, the proposed fabric defect detection system is capable of learning existing fabric defect samples and automatically adapting to different fabric textures during different application periods. Specifically, we customize a deep semantic segmentation network for fabric defect detection that can detect different defect types. Furthermore, we attempted to train a multistage GAN to synthesize reasonable defects in new defect-free samples. First, a texture-conditioned GAN is trained to explore the conditional distribution of defects given different texture backgrounds. Given a novel fabric, we aim to generate reasonable defective patches. Then, a GAN-based fusion network fuses the generated defects to specific locations. Finally, the well-trained multistage GAN continuously updates the existing fabric defect datasets and contributes to the fine-tuning of the semantic segmentation network to better detect defects under different conditions. Comprehensive experiments on various representative fabric samples are conducted to verify the detection performance of our proposed method.},
  keywords={Fabrics;Generative adversarial networks;Semantics;Gallium nitride;Task analysis;Convolution;Image segmentation;Fabric defect detection;deep learning;semantic segmentation;generative adversarial network},
  doi={10.1109/TIP.2019.2959741},
  ISSN={1941-0042},
  month={},}@ARTICLE{9195885,
  author={Kande, Nilesh A. and Dakhane, Rupali and Dukkipati, Ambedkar and Yalavarthy, Phaneendra Kumar},
  journal={IEEE Transactions on Medical Imaging}, 
  title={SiameseGAN: A Generative Model for Denoising of Spectral Domain Optical Coherence Tomography Images}, 
  year={2021},
  volume={40},
  number={1},
  pages={180-192},
  abstract={Optical coherence tomography (OCT) is a standard diagnostic imaging method for assessment of ophthalmic diseases. The speckle noise present in the high-speed OCT images hampers its clinical utility, especially in Spectral-Domain Optical Coherence Tomography (SDOCT). In this work, a new deep generative model, called as SiameseGAN, for denoising Low signal-to-noise ratio (LSNR) B-scans of SDOCT has been developed. SiameseGAN is a Generative Adversarial Network (GAN) equipped with a siamese twin network. The siamese network module of the proposed SiameseGAN model helps the generator to generate denoised images that are closer to groundtruth images in the feature space, while the discriminator helps in making sure they are realistic images. This approach, unlike baseline dictionary learning technique (MSBTD), does not require an apriori high-quality image from the target imaging subject for denoising and takes less time for denoising. Moreover, various deep learning models that have been shown to be effective in performing denoising task in the SDOCT imaging were also deployed in this work. A qualitative and quantitative comparison on the performance of proposed method with these state-of-the-art denoising algorithms has been performed. The experimental results show that the speckle noise can be effectively mitigated using the proposed SiameseGAN along with faster denoising unlike existing approaches.},
  keywords={Noise reduction;Gallium nitride;Feature extraction;Signal to noise ratio;Generators;Generative adversarial networks;Machine learning;SDOCT denoising;deep learning;SiameseGAN;deep generative model},
  doi={10.1109/TMI.2020.3024097},
  ISSN={1558-254X},
  month={Jan},}@ARTICLE{9739848,
  author={Zhang, Xiaoqin and Fan, Chenxiang and Xiao, Zhiheng and Zhao, Li and Chen, Huiling and Chang, Xiaojun},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Random Reconstructed Unpaired Image-to-Image Translation}, 
  year={2023},
  volume={19},
  number={3},
  pages={3144-3154},
  abstract={The goal of unpaired image-to-image translation is to learn a mapping from a source domain to a target domain without using any labeled examples of paired images. This problem can be solved by learning the conditional distribution of source images in the target domain. A major limitation of existing unpaired image-to-image translation algorithms is that they generate untruthful images which are overcolored and lack details, while the translation of realistic images must be rich in details. To address this limitation, in this article, we propose a random reconstructed unpaired image-to-image translation (RRUIT) framework by generative adversarial network, which uses random reconstruction to preserve the high-level features in the source and adopts an adversarial strategy to learn the distribution in the target. We update the proposed objective function with two loss functions. The auxiliary loss guides the generator to create a coarse image, while the coarse-to-fine block next to the generator block produces an image that obeys the distribution of the target domain. The coarse-to-fine block contains two submodules based on the densely connected atrous spatial pyramid pooling, which enriches the details of generated images. We conduct extensive experiments on photorealistic stylization and artistic stylization. The experimental results confirm the superiority of the proposed RRUIT.},
  keywords={Image reconstruction;Generators;Generative adversarial networks;Informatics;Training;Feature extraction;Semantics;Generative adversarial network (GANs);image-to-image translation;random feature reconstruction},
  doi={10.1109/TII.2022.3160705},
  ISSN={1941-0050},
  month={March},}@ARTICLE{10897484,
  author={Bian, Xuewei and Wang, Chaoqun and Quan, Weize and Ye, Juntao and Zhang, Xiaopeng and Yan, Dong-Ming},
  journal={Computational Visual Media}, 
  title={Scene text removal via cascaded text stroke detection and erasing}, 
  year={2022},
  volume={8},
  number={2},
  pages={273-287},
  abstract={Recent learning-based approaches show promising performance improvement for the scene text removal task but usually leave several remnants of text and provide visually unpleasant results. In this work, a novel end-to-end framework is proposed based on accurate text stroke detection. Specifically, the text removal problem is decoupled into text stroke detection and stroke removal; we design separate networks to solve these two subproblems, the latter being a generative network. These two networks are combined as a processing unit, which is cascaded to obtain our final model for text removal. Experimental results demonstrate that the proposed method substantially outperforms the state-of-the-art for locating and erasing scene text. A new large-scale real-world dataset with 12,120 images has been constructed and is being made available to facilitate research, as current publicly available datasets are mainly synthetic so cannot properly measure the performance of different methods.},
  keywords={Generators;Convolutional neural networks;Training;Generative adversarial networks;Text detection;Kernel;Accuracy;Visualization;Translation;Learning systems;scene text removal;text stroke detection;generative adversarial networks;cascaded network design;real-world dataset},
  doi={10.1007/s41095-021-0242-8},
  ISSN={2096-0662},
  month={June},}@ARTICLE{11075744,
  author={Alslman, Yasmeen and Alkasassbeh, Mouhammd and Abdel-Rahman, Mohammad J.},
  journal={IEEE Access}, 
  title={Breaking and Healing: GAN-Based Adversarial Attacks and Post-Adversarial Recovery for 5G IDSs}, 
  year={2025},
  volume={13},
  number={},
  pages={132109-132125},
  abstract={Generative adversarial networks (GANs) have advanced rapidly in data augmentation and generation, and researchers have been exploring their applications in other areas, including adversarial attack generation. GANs have significantly improved the field of adversarial attacks, especially against intrusion detection systems (IDSs). These highly sophisticated GAN-based attacks pose a significant threat to IDS security. Addressing the challenges posed by GAN-based adversarial attacks is crucial for assessing their impact and developing robust defense mechanisms. In this paper, we propose new adversarial attack generation techniques derived from advanced GAN architectures. The effectiveness of these attacks, which are based on sophisticated types of GANs, is evaluated against three multi-class IDSs designed for 5G networks. Comprehensive experiments are conducted to evaluate the effectiveness of each GAN in exploiting IDS vulnerabilities and examine the transferability of adversarial attacks across different IDSs, considering the quality of the adversarial samples generated. Exploring these sophisticated GANs for adversarial attack generation enables us to develop a new post-adversarial recovery mechanism based on reconstructing the adversarial samples. Moreover, to thoroughly assess the capabilities of the proposed techniques, new evaluation metrics are introduced to facilitate a comprehensive analysis of the system’s vulnerabilities. Our results show that the proposed GAN-based adversarial attacks can significantly impact IDSs by achieving a high attack success rate (ASR) and drastically reducing accuracy, recall, precision, and F1 score. However, the proposed post-adversarial recovery process effectively restores the IDSs’ performance while significantly reducing the ASR.},
  keywords={Generative adversarial networks;Threat modeling;5G mobile communication;Robustness;Measurement;Closed box;Training;Glass box;Telecommunication traffic;Perturbation methods;Adversarial attacks;adversarial machine learning;generative adversarial networks;generative adversarial attacks;intrusion detection systems;deep learning},
  doi={10.1109/ACCESS.2025.3587605},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9658454,
  author={Xia, Xuan and Li, Nan and Pang, Xufang and Pan, Xizhou and Wu, Chen and Ding, Ning},
  booktitle={2021 International Conference on High Performance Big Data and Intelligent Systems (HPBD&IS)}, 
  title={Facial Attributes Translation with Attention Consistency and Self-calibration}, 
  year={2021},
  volume={},
  number={},
  pages={236-240},
  abstract={The guidance of attention mask in the facial attributes translation tasks is based on the constraints of attribute categories in supervised learning, which are indirect and weak. Hence we propose a generative adversarial network in this paper, which the attention is constrained by a new loss function named attention consistency loss and guided by self-calibration convolution. Stronger constraints on attention improve the quality of facial attributes translation results and self-calibration convolution effectively improves attention coverage. Experiments demonstrate that with attention consistency loss, attention becomes smoother and more focused. In gender swap, hair color change, and age swap, we obtain 70% vote in favor attention consistency loss in the user study. Meanwhile self-calibration convolution improves the mean intersection over union of hair by more than 6%, and improves the mean intersection over union of hair by more than 11% with skip-connection.},
  keywords={Hair;Training;Convolution;Supervised learning;Color;Generative adversarial networks;Transformers;generative adversarial networks;image-to-image translation;facial attributes;attention;self-calibration},
  doi={10.1109/HPBDIS53214.2021.9658454},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10917505,
  author={Chitra, P and Sridar, K and Govindan, Sudha and S, Britto Raj and J, Akshya. and Choudhry, Mani Deepak and Sundarrajan, M.},
  booktitle={2024 4th International Conference on Soft Computing for Security Applications (ICSCSA)}, 
  title={Autonomous Robot Navigation in Unknown Terrains using Generative Adversarial Networks}, 
  year={2024},
  volume={},
  number={},
  pages={604-609},
  abstract={Autonomous Robot Navigation in unknown and dynamic environments is considered one of the grand challenges in robotics. These motions that guide it span from rescue operations to planetary exploration. Classical methods for path planning, including A*, Dijkstra, and RRT, were unable to balance the efficiency and adaptability of motion planning over complex terrain. This may have a powerful solution using Generative Adversarial Networks (GANs) with advanced machine learning techniques to improve the ability of robotic navigation. This study proposes a GAN-based approach for designing an effective self-adaptive path planning and obstacle avoidance system for autonomous robots. Despite performing well in structured environments, traditional techniques normally fail in analysing the unstructured terrains with real-time adjustments and dynamic changes due to the high computational costs and lack of flexibility involved. In this regard, the proposed GAN-based system resolves these issues by rating navigation paths concerning safety and efficiency. Quantitative analysis demonstrates that within a forest, desert, urban, or off-road environment, the computational times by using the developed strategy turn out to be 0.12 seconds, 0.10 seconds, 0.14 seconds, and 0.13 seconds, respectively, behaving much lower than what can be achieved with other algorithms. This approach proves much superior in terms of computational efficiency path smoothness and adaptability under different environmental conditions in applications related to autonomous robot navigation systems.},
  keywords={Navigation;Statistical analysis;Machine learning;Generative adversarial networks;Path planning;Real-time systems;Generators;Safety;Computational efficiency;Autonomous robots;Autonomous robot navigation;Generative Adversarial Networks;Path Planning;Machine learning;Obstacle Avoidance},
  doi={10.1109/ICSCSA64454.2024.00104},
  ISSN={},
  month={Sep.},}@ARTICLE{10444988,
  author={Lu, Jijian and Zheng, Ruxin and Gong, Zikun and Xu, Huifen},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Supporting Teachers’ Professional Development With Generative AI: The Effects on Higher Order Thinking and Self-Efficacy}, 
  year={2024},
  volume={17},
  number={},
  pages={1267-1277},
  abstract={Generative artificial intelligence (AI) has emerged as a noteworthy milestone and a consequential advancement in the annals of major disciplines within the domains of human science and technology. This study aims to explore the effects of generative AI-assisted preservice teaching skills training on preservice teachers’ self-efficacy and higher order thinking. The participants of this study were 215 preservice mathematics, science, and computer teachers from a university in China. First, a pretest–post-test quasi-experimental design was implemented for an experimental group (teaching skills training by generative AI) and a control group (teaching skills training by traditional methods) by investigating the teacher self-efficacy and higher order thinking of the two groups before and after the experiment. Finally, a semistructured interview comprising open-ended questions was administered to 25 preservice teachers within the experimental group to present their views on generative AI-assisted teaching. The results showed that the scores of preservice teachers in the experimental group, who used generative AI for teachers’ professional development, were considerably higher than those of the control group, both in teacher self-efficacy (F = 8.589, p = 0.0084 < 0.05) and higher order thinking (F = 7.217, p = 0.008 < 0.05). It revealed that generative AI can be effective in supporting teachers’ professional development. This study produced a practical teachers’ professional development method for preservice teachers with generative AI.},
  keywords={Education;Chatbots;Training;Task analysis;Generative AI;Mathematics;Interviews;Generative artificial intelligence (AI);higher order thinking;preservice teachers;teacher self-efficacy;teaching skills training},
  doi={10.1109/TLT.2024.3369690},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10760491,
  author={Reddy, Gogireddy Meghanath and Vasanth, Movva and Reddy, Pasam Chandra Shekara Sai Balaji and Abhishek, Jala and Venkateswarlu, B.},
  booktitle={2024 2nd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS)}, 
  title={From Data to Insight: Hybrid Models for Fake News Detection using Generative AI and Web Comparison}, 
  year={2024},
  volume={},
  number={},
  pages={9-17},
  abstract={The spread of false information in the digital age is a major concern. Traditional machine learning approaches are useful, but they often struggle to deal with the dynamic nature of incorrect information. This project aims to develop a hybrid fake news detection system that combines traditional machine learning, generative AI, and real-time online search comparison. Our approach begins with a logistic regression classifier that uses TF-IDF properties to quickly filter potentially incorrect content. The article’s linguistic and contextual coherence is then evaluated by an advanced analysis that makes use of OpenAI’s generative AI through the LangChain framework. A web search tool cross-references the content of the article with up-to-date online data to further assure accuracy. This multi-layered method increases detection accuracy and provides a comprehensive analysis of news veracity. Our results show significant improvements over existing methods and show the potential of combining web data, machine learning, and generative AI for precise fake news detection.},
  keywords={Accuracy;Text analysis;Generative AI;Social networking (online);Biological system modeling;Machine learning;Real-time systems;Hybrid power systems;Fake news;Web search;Fake News Detection;Generative Artificial Intelligence (AI);Machine Learning (ML);Web Search Comparison;Hybrid Models;Logistic Regression;Term Frequency-Inverse Document Frequency (TF-IDF);LangChain;OpenAI;Text Analysis;Misinformation;Real-Time Verification;AI-Driven Verification;Digital Information;News Authenticity},
  doi={10.1109/ICSSAS64001.2024.10760491},
  ISSN={},
  month={Oct},}@ARTICLE{10948186,
  author={Kim, Junyoung and Kwon, Gihyun and Ryu, Dohoon and Ye, Jong Chul},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={AI-Based Generative Model for Computer-Based X-Ray Inspection Training System}, 
  year={2025},
  volume={74},
  number={},
  pages={1-13},
  abstract={X-ray baggage inspection systems have proven to be indispensable tools for swiftly and efficiently examining passengers’ belongings and inspecting goods during import-export processes at locations, such as airports and seaports. The ability to visualize the contents of bags without opening them streamlines the inspection process, enabling rapid assessments. The reliance on human judgment for interpreting X-ray images requires systematic training program, given the disparities between the actual shapes of items and their representations in X-ray images. In addition, the surge in travel demand and logistics movements necessitates a substantial number of highly trained inspectors. Computer-based training (CBT) systems offer a convenient solution for training inspectors, but current X-ray inspection CBT systems have limitations in data diversity and provide only restricted information, constraining the effectiveness of training. To address this, here we propose a novel AI-based data augmentation scheme for X-ray inspection CBT systems. Specifically, this article focuses on the AI generative model component, which is composed of three parts. First, we employ a latent diffusion model (LDM) to generate high-quality, diverse illicit item X-ray images. Second, by incorporating a novel neural support optimization from frontal and side-view images, a tuned voxel grid is obtained, enabling the creation of 3-D images that offer varied perspectives of items. Finally, the generated images undergo transformations, such as metal material emphasis, organic material emphasis, negative images, and variations in brightness to enhance detection capabilities, making it easier to identify items that were challenging to detect in conventional pseudo-color images. Inspector training with real X-ray data followed by training with generated X-ray data resulted in an increase in inspection accuracy and decrease in inspection time, confirming the effectiveness of training using generated images.},
  keywords={Training;X-ray imaging;Diffusion models;Inspection;Data collection;Artificial intelligence;Pipelines;Three-dimensional displays;Shape;Computational modeling;Computer-based training (CBT) system;generative model;latent diffusion model (LDM);pseudo-color images;view synthesis;X-ray inspection},
  doi={10.1109/TIM.2025.3554859},
  ISSN={1557-9662},
  month={},}@INPROCEEDINGS{10908927,
  author={Thielen, Nils and Braun, Jakob and Rachinger, Ben and Franke, Jörg and Risch, Florian and Reinhardt, Andreas},
  booktitle={2025 Pan Pacific Strategic Electronics Symposium (Pan Pacific)}, 
  title={Improving Data Augmentation in Deep Learning-Based THT Solder Joint Classification with Synthetic Data and Active Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Quality control of through-hole technology (THT) and surface mount technology (SMT) solder joints suffers from a high number of false calls, even when automated optical inspection (AOI) is applied. These false calls lead to extensive manual re-inspection require optimization of the test routine. Besides the reduction of false calls, minimizing error slip is essential. In both, research and the industrial contexts, artificial intelligence (AI) is investigated in order to address this problem. While AI-models, especially deep learning-based models such as convolutional neural networks (CNN) can already perform solder joint classification adequately, performance strongly depends on the model architecture and parameters and especially the dataset for training the model itself. To address the latter, this works investigates the utilization of two different approaches to enhance dataset quality, especially if defect data is scarce. First, the systematic inclusion of synthetic data is investigated. Although sufficient synthetic data can be generated by deep generative models such as generative adversarial networks (GANs), robustly training these models and determining the optimal amount of data remains challenging. Utilization of multiple consecutive trainings of pretrained GAN increases robustness a, with a 100% success rate of convergence in the final GAN training, even if there is only a small amount of defective images. Second, methods of active learning (AL) are applied to perform a systematic data augmentation on the most valuable images. Thus, conventional data augmentation methods can be used without complex preparation of synthetic data. Furthermore, well established model architectures can be trained without small modifications in the training process itself. Directed augmentation of images improves recall by 16.5%, although precision slightly decreases.},
  keywords={Training;Systematics;Generative adversarial networks;Data augmentation;Optical imaging;Data models;Convolutional neural networks;Soldering;Artificial intelligence;Synthetic data;Electronics Production;Automated Optical Inspection;Artificial Intelligence;Active Learning;Synthetic Data},
  doi={10.23919/PanPacific65826.2025.10908927},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9098374,
  author={Zhou, Kang and Gao, Shenghua and Cheng, Jun and Gu, Zaiwang and Fu, Huazhu and Tu, Zhi and Yang, Jianlong and Zhao, Yitian and Liu, Jiang},
  booktitle={2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)}, 
  title={Sparse-Gan: Sparsity-Constrained Generative Adversarial Network for Anomaly Detection in Retinal OCT Image}, 
  year={2020},
  volume={},
  number={},
  pages={1227-1231},
  abstract={With the development of convolutional neural network, deep learning has shown its success for retinal disease detection from optical coherence tomography (OCT) images. However, deep learning often relies on large scale labelled data for training, which is oftentimes challenging especially for disease with low occurrence. Moreover, a deep learning system trained from data-set with one or a few diseases is unable to detect other unseen diseases, which limits the practical usage of the system in disease screening. To address the limitation, we propose a novel anomaly detection framework termed Sparsity-constrained Generative Adversarial Network (Sparse-GAN) for disease screening where only healthy data are available in the training set. The contributions of Sparse-GAN are two-folds: 1) The proposed Sparse-GAN predicts the anomalies in latent space rather than image-level; 2) Sparse-GAN is constrained by a novel Sparsity Regularization Net. Furthermore, in light of the role of lesions for disease screening, we present to leverage on an anomaly activation map to show the heatmap of lesions. We evaluate our proposed Sparse-GAN on a publicly available dataset, and the results show that the proposed method outperforms the state-of-the-art methods.},
  keywords={Lesions;Image reconstruction;Diseases;Generative adversarial networks;Anomaly detection;Gallium nitride;Biomedical imaging;Anomaly Detection;Sparsity-constrained Network;Latent Feature;Adversarial Learning},
  doi={10.1109/ISBI45749.2020.9098374},
  ISSN={1945-8452},
  month={April},}@INPROCEEDINGS{10340586,
  author={Yang, Yulin and Li, Yinhao and Chen, Qingqing and Han, Xian-Hua and Liu, Jing and Lin, Lanfen and Hu, Hongjie and Chen, Yen-Wei},
  booktitle={2023 45th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)}, 
  title={Spatial Attention-Guided Generative Adversarial Network for Synthesizing Contrast-enhanced Computed Tomography Images}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Compared to non-contrast computed tomography (NC-CT) scans, contrast-enhanced (CE) CT scans provide more abundant information about focal liver lesions (FLLs), which play a crucial role in the FLLs diagnosis. However, CE-CT scans require patient to inject contrast agent into the body, which increase the physical and economic burden of the patient. In this paper, we propose a spatial attention-guided generative adversarial network (SAG-GAN), which can directly obtain corresponding CE-CT images from the patient’s NC-CT images. In the SAG-GAN, we devise a spatial attention-guided generator, which utilize a lightweight spatial attention module to highlight synthesis task-related areas in NC-CT image and neglect unrelated areas. To assess the performance of our approach, we test it on two tasks: synthesizing CE-CT images in arterial phase and portal venous phase. Both qualitative and quantitative results demonstrate that SAG-GAN is superior to existing GANs-based image synthesis methods.},
  keywords={Frequency locked loops;Economics;Image synthesis;Computed tomography;Liver;Generative adversarial networks;Generators},
  doi={10.1109/EMBC40787.2023.10340586},
  ISSN={2694-0604},
  month={July},}@ARTICLE{11066262,
  author={Yoon, Jiho and Alkhudary, Rami and Talluri, Srinivas and Féniès, Pierre},
  journal={IEEE Transactions on Engineering Management}, 
  title={Risk Management and Macroeconomic Disruptions in Supply Chains: The Role of Blockchain, Digital Twins, Generative AI, and Quantum Computing}, 
  year={2025},
  volume={72},
  number={},
  pages={2995-3009},
  abstract={The global economy faces increasing vulnerabilities from macroeconomic disruptions, such as regulatory changes, trade tensions, geopolitical conflicts, currency volatility, pandemics, and energy crises that undermine the resilience of operations and supply chain management (OSCM) systems. These disruptions exacerbate risks, including supply chain breakdowns, operational inefficiencies, and systemic weaknesses, with energy challenges emerging as a key concern due to their effects on production costs, inflation, and sustainability goals. Advanced technologies, such as blockchain, digital twins, generative artificial intelligence (AI), and quantum computing, offer transformative potential to enhance transparency, predictive accuracy, and decision-making agility. However, their adoption introduces inherent tradeoffs, as they can lead to energy-intensive operations, cybersecurity risks, and economic burdens. To make sense of these dynamics, this article develops a conceptual framework based on a multilayered information system architecture that links specific disruptions to corresponding digital responses. This framework is grounded in a thorough review of both conceptual and empirical literature, along with extensive discussions among the authors. It explores how these technologies can address the risks stemming from macroeconomic disruptions while also considering their broader economic implications and challenges. It argues that simplistic solutions fail to account for the duality of these technologies’ impacts and highlights the need for a systemic approach to integrate these technologies within OSCM. This article concludes by proposing actionable research directions for OSCM scholars and managers to navigate these complexities.},
  keywords={Supply chains;Macroeconomics;Blockchains;Digital twins;Risk management;Quantum computing;Organizations;Generative AI;Costs;Resilience;Blockchain;digital twins;generative artificial intelligence (AI);information system;macroeconomic disruptions;quantum computing;risk management;supply chain;TEM forum;technology management},
  doi={10.1109/TEM.2025.3585433},
  ISSN={1558-0040},
  month={},}@INPROCEEDINGS{11106522,
  author={Koldewey, Christian and Rohde, Malte Nick and Strobel, Gero and Vehmeyer, Julia Marie and Fichtler, Timm and Dumitrescu, Roman},
  booktitle={2025 IEEE International Conference on Engineering, Technology, and Innovation (ICE/ITMC)}, 
  title={Embedding Generative AI into Products – 10 Design Principles for Building Intelligent Systems}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={Generative Artificial Intelligence (GenAl) has the potential to fundamentally transform products and create new value propositions. Nevertheless, many companies face challenges integrating GenAl into their products. While existing research primarily focuses on general GenAl applications, there is a lack of specific guidelines for product integration. This study addresses this gap by deriving ten design principles to support companies in successfully embedding GenAl into their products. We identify key challenges and provide actionable design knowledge based on an interview study with industry experts. The findings show that a structured approach dealing with organizational, technical, and legal issues is essential for successful GenAl integration. These insights provide valuable guidance for both industry and academia, helping to enhance the adoption and economic viability of GenAl-based products.},
  keywords={Industries;Economics;Technological innovation;Generative AI;Law;Companies;Transforms;Product development;Faces;Guidelines;Generative AI;artificial intelligence;product innovation;design science;product development},
  doi={10.1109/ICE/ITMC65658.2025.11106522},
  ISSN={2693-8855},
  month={June},}@INPROCEEDINGS{10714319,
  author={Fahim Siddiqui, Muhammad Hammad and Inkpen, Diana and Gelbukh, Alexander},
  booktitle={2024 28th International Conference Information Visualisation (IV)}, 
  title={Towards Interpretable Emotion Classification: Evaluating LIME, SHAP, and Generative AI for Decision Explanations}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper explores the classification of multi-label emotions utilizing fine-tuned RoBERTa base and zero-shot GPT4 models, with experiments conducted on the SemEval 2018 E-c dataset encompassing 11 emotions, where more than one label is allowed for a text. Employing SHAP and LIME for RoBERTa explanations and generative AI for GPT4, we assess the sufficiency of explanations using the BERT score metric. We show the explanations generated by LIME and SHAP visually using different plots. The BERT score indicates that generative AI produces better explanations than the statistical models, providing deeper insights into emotion selection, with a BERT score of 59.66% compared to SHAP-RoBERTa's 54.17% and LIME-RoBERTa's 53.22%. This shows the potential of generative AI in revealing the reasoning behind decisions within complex emotional contexts. Though the performance is superior, we also discuss the limitations of these models that hinder wide-scale adoption.},
  keywords={Measurement;Visualization;Generative AI;Cognition;Explainable AI;LLM;XAI;LIME;SHAP;Multi-label Classification;Emotion Classification},
  doi={10.1109/IV64223.2024.00053},
  ISSN={2375-0138},
  month={July},}@INPROCEEDINGS{10513318,
  author={Guo, Kaibin and Liu, Yixian and Yang, Qiang},
  booktitle={2023 IEEE 7th Conference on Energy Internet and Energy System Integration (EI2)}, 
  title={WGAN-GP Based Data Reconstruction for Operational Faults of Power Distribution Networks}, 
  year={2023},
  volume={},
  number={},
  pages={2138-2144},
  abstract={Accurate and rapid fault diagnosis is crucial for the safe and stable operation of distribution networks. Although artificial intelligence gains popularity in fault diagnosis for distribution networks, the imbalance in the proportion of fault data and normal operational data hampers accurate diagnosis. To address this problem, a fault data enhancement model for distribution networks using the Wasserstein generative adversarial network with gradient penalty (WGAN-GP) is proposed. WGAN-GP uses the Wasserstein distance as the training target and introduces a gradient penalty mechanism to make the training process more controllable and efficient. Compared to the GAN-based method, WGAN-GP reduces the average relative error for nine dimensions in the standard deviation from 18.30% to 5.30% and in the mean from 4.03% to 0.48%, Compared with the probabilistic statistical based method, WGAN-GP greatly reduces the Wasserstein distance between real and generated data. Experimental results reveal that WGAN-GP can generate higher-quality data and solve the problem of data imbalance in power fault diagnosis.},
  keywords={Fault diagnosis;Training;Process control;Energy Internet;Distribution networks;System integration;Probabilistic logic;distribution networks;imbalanced data;artificial intelligence;WGAN-GP},
  doi={10.1109/EI259745.2023.10513318},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10605540,
  author={Camacho-Zuñiga, Claudia},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Effective Generative AI Implementation in Developing Country Universities}, 
  year={2024},
  volume={},
  number={},
  pages={460-463},
  abstract={This paper explores the integration of Generative Artificial Intelligence (Gen AI) into the teaching-learning-assessment processes within Higher Education Institutions (HEIs), particularly those located in developing countries. Through a mixed-methods approach, utilizing both qualitative insights from ChatGPT 4.0-generated ‘Personas’ representing international experts and quantitative analysis, this study evaluates the potential risks and delineates strategic pathways for the responsible implementation of Gen AI under limited financial and technological resources. The 'Personas' provided evaluations on a Likert scale, assessing risks, required actions, and resources necessary for Gen AI integration, which were then analyzed through descriptive statistics and visualized for interpretation. The findings highlight the most significant challenges as legal and ethical issues, technological dependence, and student development, echoing concerns noted in existing literature. To mitigate these risks, the study suggests a series of sequential strategies including promoting balanced technology use, investing in mental health initiatives, developing skills for educators, supporting AI literacy, creating culturally responsive AI content, and developing inclusive technology policies. Moreover, creating AI tools to enhance teaching and investing in equitable technological infrastructure are identified as resource-intensive actions, with a special emphasis on the prioritization of human resource investment as a starting point for HEIs with financial constraints. It is crucial to note the limitations of this work, given that the expert 'Personas' are bound by the training data and capabilities of the Large Language Model used. Therefore, the careful evaluation of the advice provided to ensure alignment with each institution's mission and philosophy is mandatory. Despite these limitations, the study offers valuable insights and a call-to-action for HEIs to lead the charge in integrating Gen AI across society.},
  keywords={Ethics;Philosophical considerations;Generative AI;Large language models;Education;Training data;Mental health;Educational Equity;AI Ethics;Academic Integrity;Workforce Disruption;Technological Literacy;Educational Innovation;Higher Education},
  doi={10.1109/CAI59869.2024.00093},
  ISSN={},
  month={June},}@INPROCEEDINGS{10516491,
  author={Xu, Bingfeng and Wang, Bo and Chen, Xinkai and Zhao, Jincheng and He, Gaofeng},
  booktitle={2023 Eleventh International Conference on Advanced Cloud and Big Data (CBD)}, 
  title={A CGAN-based Few-shot Method for Zero-day Attack Detection in the Internet of Vehicles}, 
  year={2023},
  volume={},
  number={},
  pages={98-103},
  abstract={Due to the limited availability of labeled attack data, the detection of zero-day attacks in the Internet of Vehicles domain often relies on an anomaly-based approach. However, this approach frequently leads to a high false positive rate. In practice, we have observed that the principles behind zero-day attacks and known attacks are similar within the Internet of Vehicles environment. Inspired by the observation, this paper proposes a conditional generative adversarial network-based few-shot method for zero-day attack detection in the Internet of Vehicles environment. Primarily, a conditional adversarial generative network model with multiple generators and multiple discriminators is proposed. With this framework, an adaptive sampling data augmentation method is designed to augment data with known attack samples by optimizing the input samples of this model to reduce the false positive rate. Moreover, to alleviate the data imbalance problem caused by a few input attack samples of this model, a collaborative focus loss function is provided in the discriminators, which focuses on discerning challenging-to-classify data. Lastly, the proposed method’s effectiveness is evaluated through comprehensive experiments carried out on the F2MD vehicle network simulation platform. The experimental results demonstrate the superiority of the proposed method compared to existing approaches, both in terms of detection effectiveness and latency. As a result, this paper presents a practical and promising solution for zero-day attack detection in the Internet of Vehicles domain.},
  keywords={Learning systems;Adaptation models;Cloud computing;Collaboration;Big Data;Data augmentation;Generators;Internet of Vehicles;zero-day attack detection;conditional generative adversarial network;transfer learning},
  doi={10.1109/CBD63341.2023.00026},
  ISSN={},
  month={Dec},}@ARTICLE{10273408,
  author={Huang, Yudong and Xu, Minrui and Zhang, Xinyuan and Niyato, Dusit and Xiong, Zehui and Wang, Shuo and Huang, Tao},
  journal={IEEE Network}, 
  title={AI-Generated Network Design: A Diffusion Model-Based Learning Approach}, 
  year={2024},
  volume={38},
  number={3},
  pages={202-209},
  abstract={The future networks pose intense demands for intelligent and customized designs to cope with the surging network scale, dynamically time-varying environments, diverse user requirements, and complicated manual configuration. However, traditional rule-based solutions heavily rely on human efforts and expertise, while data-driven intelligent algorithms still lack interpretability and generalization. In this paper, we propose the AIGN (AI-Generated Network), a novel intention-driven paradigm for network design, which allows operators to quickly generate a variety of customized network solutions and achieve expert-free problem optimization. Driven by the diffusion model-based learning approach, AIGN has great potential to learn the reward-maximizing trajectories, automatically satisfy multiple constraints, adapt to different objectives and scenarios, or even intelligently create novel designs and mechanisms unseen in existing network environments. Finally, we conduct a use case to demonstrate that AIGN can effectively guide the design of transmit power allocation in digital twin-based access networks.},
  keywords={Optimization;Protocols;Decision making;Heuristic algorithms;Computational modeling;Trajectory;Planning;Generative adversarial networks;Artificial intelligence;Reinforcement learning;Future Networks;Generative Artificial Intelligence;Diffusion Model;Reinforcement Learning},
  doi={10.1109/MNET.2023.3321538},
  ISSN={1558-156X},
  month={May},}@INPROCEEDINGS{10988345,
  author={Chavan, Siddhesh and Giri, Sujit and Gornar, Sachin and Kalsapnavar, Amey and Mirajkar, Riddhi and Suryawanshi, Amol},
  booktitle={2025 International Conference on Emerging Smart Computing and Informatics (ESCI)}, 
  title={EduMate: AI-Based Student Support Platform with OCR and Voice Assistance}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Advanced AI technology has been used in a timely and accurate manner to allow the children to get homework assistance through a digital learning platform designed to overcome the challenges in classes 1 to 6. OCR technologies like Tesseract, Keras-OCR, and EasyOCR are used to extract texts from handwritten texts and images on images and PDFs so as to ensure adaptability for diverse students' submissions. Google Gemini is utilized to create responses that will give a fast and accurate answer to the queries of students. It further uses the Naive Bayes with a spam detection mechanism and Nearest Neighbors guiding most relevant questions for deep learning in this personalized recommendation system. In this regard, it guides students through their homework and helps them learn in such ways that are as beneficial as possible. There exists a Decision Tree-based guidance mechanism here. It then applies state-of-the-art image pre-processing techniques such as contrast enhancement and filtering for OCR. The system is also multi-threaded and processes PDFs and images directly instance by instance, even in the most resource- demanding environments. This homework assistant makes AI intuitive, efficient, easily accessible, and enables processing in real time, personalized recommendations, and structured support for betterment of the study experience of young learners overall.},
  keywords={Accuracy;Generative AI;Filtering;Optical character recognition;Natural language processing;Real-time systems;Bayes methods;Internet;Informatics;Recommender systems;OCR (Optical Character Recognition);NLP (Natural Language Processing);Generative AI;A* Algorithm;Naive Bayes;Multi-threaded execution;Spam Detection},
  doi={10.1109/ESCI63694.2025.10988345},
  ISSN={2996-1815},
  month={March},}@INPROCEEDINGS{10429554,
  author={Zhou, Guang-Xia and Yan, Jing-Jing},
  booktitle={2023 9th International Conference on Big Data and Information Analytics (BigDIA)}, 
  title={Exploration of the Application of ChatGPT in Command and Control}, 
  year={2023},
  volume={},
  number={},
  pages={807-811},
  abstract={The formidable content generation capacity exhibited by ChatGPT has catalyzed a novel resurgence in the realm of artificial intelligence applications. Diverse sectors of society are actively delving into the integration of this product within their respective industries to facilitate remarkable advancements, encompassing domains such as Command and Control. This discourse undertakes a concise examination of the evolutionary trajectory of ChatGPT, presents its potential applications within the Command and Control domain, encompassing facets such as document generation, knowledge-based question and answer, intelligence analysis, strategic planning, and battlefield operations control. Moreover, it probes the intricacies encountered in the utilization of ChatGPT as a comprehensive artificial intelligence solution within the ambit of Command and Control, thereby offering a salient reference for the comprehensive exploration and implementation of generative AI technology epitomized by ChatGPT.},
  keywords={Command and control systems;Strategic planning;Chatbots;Transformers;Reliability engineering;Trajectory;Probes;chat generative pre-trained transformer (ChatGPT);reinforcement learning from human feedback (RLHF);command and control},
  doi={10.1109/BigDIA60676.2023.10429554},
  ISSN={2771-6902},
  month={Dec},}@INPROCEEDINGS{11022642,
  author={Wakene, Geda and Chen, Zizhao and Wong, W. Eric and Hsu, Chih-Wei},
  booktitle={2025 11th International Symposium on System Security, Safety, and Reliability (ISSSR)}, 
  title={Analyzing Exposure in Generative Adversarial Networks: Advancing Security Against AI-Synthesized Voice Threats}, 
  year={2025},
  volume={},
  number={},
  pages={106-111},
  abstract={As AI proceeds to continue its inevitable growth, the blossoming of deep fakes and AI-synthesized fake voices are beginning to pose significant challenges to the integrity of both audio and visual content on digital platforms. As technologies such as generative adversarial networks (GANs) become increasingly sophisticated, the demand to identify and mitigate the vulnerabilities within them becomes eminent. This study explores novel methodologies to uncover these vulnerabilities that are present in these fake voices and deep fakes. Through using existing techniques, such as a deep neural network (DNN), this research identifies potential weaknesses in the models underlying these technologies. With the knowledge of these weaknesses, the aim is to enhance the robustness of systems that may be prone to manipulation and deception by giving them the ability to both detect and exploit the vulnerabilities in AI-synthesized content to expose the fake from the real. Ultimately, these findings are for the purpose of contributing towards the ongoing efforts to safeguard the integrity and authenticity of multimedia content in the digital age.},
  keywords={Deepfakes;Visualization;Artificial neural networks;Generative adversarial networks;Information age;Robustness;Safety;Security;Artificial intelligence;deep fakes;AI-synthesized fake voices;generative adversarial networks;vulnerabilities},
  doi={10.1109/ISSSR65654.2025.00026},
  ISSN={2835-2823},
  month={April},}@ARTICLE{9931463,
  author={Zhou, Zhili and Su, Yuecheng and Li, Jin and Yu, Keping and Wu, Q. M. Jonathan and Fu, Zhangjie and Shi, Yunqing},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={Secret-to-Image Reversible Transformation for Generative Steganography}, 
  year={2023},
  volume={20},
  number={5},
  pages={4118-4134},
  abstract={Recently, generative steganography that transforms secret information to a generated image has been a promising technique to resist steganalysis detection. However, due to the inefficiency and irreversibility of the secret-to-image transformation, it is hard to find a good trade-off between the information hiding capacity and extraction accuracy. To address this issue, we propose a secret-to-image reversible transformation (S2IRT) scheme for generative steganography. The proposed S2IRT scheme is based on a generative model, i.e., Glow model, which enables a bijective-mapping between latent space with multivariate Gaussian distribution and image space with a complex distribution. In the process of S2I transformation, guided by a given secret message, we construct a latent vector and then map it to a generated image by the Glow model, so that the secret message is finally transformed to the generated image. Owing to good efficiency and reversibility of S2IRT scheme, the proposed steganographic approach achieves both high hiding capacity and accurate extraction of secret message from generated image. Furthermore, a separate encoding-based S2IRT (SE-S2IRT) scheme is also proposed to improve the robustness to common image attacks. The experiments demonstrate the proposed steganographic approaches can achieve high hiding capacity (up to 4 bpp) and accurate information extraction (almost 100% accuracy rate) simultaneously, while maintaining desirable anti-detectability and imperceptibility.},
  keywords={Steganography;Distortion;Generative adversarial networks;Feature extraction;Encoding;Data mining;Transforms;coverless steganography;digital forensics;generative steganography;information hiding;steganography},
  doi={10.1109/TDSC.2022.3217661},
  ISSN={1941-0018},
  month={Sep.},}@INPROCEEDINGS{9010938,
  author={Liu, Kanglin and Qiu, Guoping and Tang, Wenming and Zhou, Fei},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Spectral Regularization for Combating Mode Collapse in GANs}, 
  year={2019},
  volume={},
  number={},
  pages={6381-6389},
  abstract={Despite excellent progress in recent years, mode collapse remains a major unsolved problem in generative adversarial networks (GANs). In this paper, we present spectral regularization for GANs (SR-GANs), a new and robust method for combating the mode collapse problem in GANs. Theoretical analysis shows that the optimal solution to the discriminator has a strong relationship to the spectral distributions of the weight matrix. Therefore, we monitor the spectral distribution in the discriminator of spectral normalized GANs (SN-GANs), and discover a phenomenon which we refer to as spectral collapse, where a large number of singular values of the weight matrices drop dramatically when mode collapse occurs. We show that there are strong evidence linking mode collapse to spectral collapse; and based on this link, we set out to tackle spectral collapse as a surrogate of mode collapse. We have developed a spectral regularization method where we compensate the spectral distributions of the weight matrices to prevent them from collapsing, which in turn successfully prevents mode collapse in GANs. We provide theoretical explanations for why SR-GANs are more stable and can provide better performances than SN-GANs. We also present extensive experimental results and analysis to show that SR-GANs not only always outperform SN-GANs but also always succeed in combating mode collapse where SN-GANs fail.},
  keywords={Gallium nitride;Training;Robustness;Generative adversarial networks;Generators;Monitoring;Optimization},
  doi={10.1109/ICCV.2019.00648},
  ISSN={2380-7504},
  month={Oct},}@ARTICLE{11141522,
  author={Xiang, Xiang and Ma, Jing and Wu, Dongrui and Zeng, Zhigang and Chen, Xilin},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Aligning Logits Generatively for Principled Black-Box Knowledge Distillation in the Wild}, 
  year={2025},
  volume={},
  number={},
  pages={1-17},
  abstract={Black-Box Knowledge Distillation (B2KD) is a conservative task in cloud-to-edge model compression, emphasizing the protection of data privacy and model copyrights on both the cloud and edge. With invisible data and models hosted on the server, B2KD aims to utilize only the API queries of the teacher model's inference results in the cloud to effectively distill a lightweight student model deployed on edge devices. B2KD faces challenges such as limited Internet exchange and edge-cloud disparity in data distribution. To address these issues, we theoretically provide a new optimization direction from logits to cell boundary, different from direct logits alignment, and formalize a workflow comprising deprivatization, distillation, and adaptation at test time. Guided by this, we propose a method, Mapping-Emulation KD (MEKD), to enhance the robust prediction and anti-interference capabilities of the student model on edge devices for any unknown data distribution in real-world scenarios. Our method does not differentiate between treating soft or hard responses and consists of: 1) deprivatization: emulating the inverse mapping of the teacher function with a generator, 2) distillation: aligning low-dimensional logits of the teacher and student models by reducing the distance of high-dimensional image points, and 3) adaptation: correcting the student's online prediction bias through a graph propagation-based only-forward test-time adaptation algorithm. Our method demonstrates inspiring performance for edge model distillation and adaptation across different teacher-student pairs. We validate the effectiveness of our method on multiple image recognition benchmarks and various Deep Neural Network models, achieving state-of-the-art performance and showcasing its practical value in remote sensing image recognition applications.},
  keywords={Data models;Adaptation models;Cloud computing;Training;Predictive models;Image edge detection;Generators;Computational modeling;Servers;Model compression;Cloud-to-Edge Model Compression;Knowledge Distillation;Generative Adversarial Network;Test-Time Adaptation},
  doi={10.1109/TPAMI.2025.3602663},
  ISSN={1939-3539},
  month={},}@INPROCEEDINGS{10323860,
  author={Basyoni, Lamiaa and Qadir, Junaid},
  booktitle={2023 International Symposium on Networks, Computers and Communications (ISNCC)}, 
  title={AI Generated Content in the Metaverse: Risks and Mitigation Strategies}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={The Metaverse has introduced a vast virtual environment where Artificial Intelligence Generated Content (AIGC) plays a crucial role in content creation. However, the increasing popularity of AIGC has raised concerns regarding its potential misuse and the need for effective detection methods to ensure content integrity. Security and privacy threats in the Metaverse have garnered significant attention, but the specific risks of AIGC in this context remain understudied. This paper aims to analyze the potential risks of AIGC in the Metaverse and explore mitigation techniques. By addressing these challenges, the paper contributes to a comprehensive understanding of AIGC's implications in the Metaverse.},
  keywords={Computers;Privacy;Metaverse;Navigation;Avatars;Security;Artificial intelligence;Metaverse;AI-Generated Content},
  doi={10.1109/ISNCC58260.2023.10323860},
  ISSN={2768-0940},
  month={Oct},}@ARTICLE{8848156,
  author={Campbell, Mark},
  journal={Computer}, 
  title={Synthetic Data: How AI Is Transitioning From Data Consumer to Data Producer... and Why That's Important}, 
  year={2019},
  volume={52},
  number={10},
  pages={89-91},
  abstract={Artificial intelligence (AI) empowers countless applications by consuming data and spotting patterns; however, this paradigm is being flipped. AI is now being used to produce data from patterns, and the resulting "synthetic data" are rapidly enabling a vast range of groundbreaking solutions.},
  keywords={Artificial intelligence;Gallium nitride;Information integrity;Videos;Malware;Generators;Tools},
  doi={10.1109/MC.2019.2930097},
  ISSN={1558-0814},
  month={Oct},}@INPROCEEDINGS{8881842,
  author={Farooq, Salah-Ud-Din and Usama, Muhammad and Qadir, Junaid and Imran, Muhammad Ali},
  booktitle={2019 UK/ China Emerging Technologies (UCET)}, 
  title={Adversarial ML Attack on Self Organizing Cellular Networks}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  abstract={Deep Neural Networks (DNN) have been widely adopted in self-organizing networks (SON) for automating different networking tasks. Recently, it has been shown that DNN lack robustness against adversarial examples where an adversary can fool the DNN model into incorrect classification by introducing a small imperceptible perturbation to the original example. SON is expected to use DNN for multiple fundamental cellular tasks and many DNN-based solutions for performing SON tasks have been proposed in the literature have not been tested against adversarial examples. In this paper, we have tested and explained the robustness of SON against adversarial example and investigated the performance of an important SON use case in the face of adversarial attacks. We have also generated explanations of incorrect classifications by utilizing an explainable artificial intelligence (AI) technique.},
  keywords={Optimization;Task analysis;Artificial intelligence;Key performance indicator;Cellular networks;Perturbation methods;Long Term Evolution;Adversarial machine learning;Self Organizing Cellular Networks},
  doi={10.1109/UCET.2019.8881842},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10500064,
  author={Claiborne, Jesse and Brown, Tivon and Rodriguez, Paul and Bhattacharya, Sambit},
  booktitle={SoutheastCon 2024}, 
  title={Enhancing Rare Object Detection in AI: Leveraging Synthetic Data for Improved Model Training}, 
  year={2024},
  volume={},
  number={},
  pages={56-60},
  abstract={Artificial Intelligence (AI) models for object detection face challenges when tasked with identifying rare objects due to the scarcity of data for these items. This scarcity often leads to mediocre performance, as the model lacks sufficient training examples for these specific objects. Acquiring real-world data for such rare objects can also be a challenging and time-consuming process. To address this issue, we developed a method aimed at improving object detection for rare objects. Our method involves the generation of synthetic data, which is subsequently utilized to train AI models. By incorporating synthetic data into the training process, we augment the available dataset, enabling AI models to better recognize and classify rare objects. The synthetic data production methods of this work can be used to build AI applications in areas such as physical security and surveillance, and self-driving vehicles which need to detect rare objects on roads to navigate safely.},
  keywords={Training;Surveillance;Roads;Object detection;Data models;Security;Artificial intelligence},
  doi={10.1109/SoutheastCon52093.2024.10500064},
  ISSN={1558-058X},
  month={March},}@ARTICLE{10965580,
  author={Thuraisamy, Kannan S. and Baig, Zubair and Zeadally, Sherali},
  journal={IT Professional}, 
  title={Generative Artificial Intelligence in Financial Services: Opportunities, Challenges, and Cyberthreats}, 
  year={2025},
  volume={27},
  number={2},
  pages={35-41},
  abstract={Generative artificial intelligence (GAI) is transforming the financial services sector (FSS), offering innovative solutions and equipping the industry with cutting-edge tools to drive value creation and operational efficiency. While the sector-specific benefits of GAI technology are substantial, effectively harnessing these opportunities depends on addressing key institutional challenges, including systemic consequences, ethical concerns, and security and privacy risks. The highly regulated FSS is one of the critical infrastructures that plays a vital role in a country’s economic stability and national security, with cyberthreats posing significant risk to both. We assess the economic benefits of GAI technology, identify institutional challenges associated with its adoption, examine key regulatory initiatives, and outline a risk-mitigation framework. Our proposed solution to mitigate institutional challenges is twofold: 1) actionable institutional risk management safeguards, and 2) a baseline safety net for GAI implementation in the financial services sector.},
  keywords={Economics;Privacy;Ethics;Generative AI;Security;Protection;Financial services;Risk mitigation},
  doi={10.1109/MITP.2025.3534270},
  ISSN={1941-045X},
  month={March},}@INPROCEEDINGS{10883435,
  author={Kaur, Chitranjanjit and Sharma, Anurag},
  booktitle={2025 6th International Conference on Mobile Computing and Sustainable Informatics (ICMCSI)}, 
  title={Enhancing Predictive Maintenance with AI: Applications and Impact}, 
  year={2025},
  volume={},
  number={},
  pages={1604-1612},
  abstract={Industrial maintenance is crucial for companies due to its significant impact on operational costs and efficiency. Many industrial firms find that a substantial portion of their expenses stems from equipment breakdowns, failures, or suboptimal performance over time. These costs can sometimes account for up to 50% of overall expenditures. Additionally, companies face various losses, including downtime from breakdowns, challenges in inventory and purchase management, and potential risks of injuries. The objective of this writing is to investigate how Predive maintenance is a footstep towards industry 5.0 where automation of predictive maintenance is evolved to autonomy in maintenance. In addition to it various machine learning algorithms are suggested to identify between healthy and poor data of a machine which is first step in Predictive maintenance then Deep learning algorithms to construct XAI (Explainable artificial Intelligence). Predictive maintenance, production scheduling, problem detection, predictive quality, and increased energy efficiency are highlighted in the typical use cases of the selected AI applications. Data from the real environment is transmitted to be virtually recreated. Efficient industrial maintenance helps mitigate these costs by reducing downtime, improving equipment reliability, and lowering the need for emergency repairs. By implementing a well-designed and optimized maintenance strategy, production plants can ensure their equipment operates as reliably as possible, minimizing disruptions and enhancing overall operational efficiency. Machine Learning (ML) methods have been appeared as a crucial tool in Predictive Maintenance (PdM) applications to prevent failures in equipment that make up the production lines. However, the performance of PdM applications depends on the appropriate choice of the ML method. To save expenses, find inefficiencies, duplicate tool tracking systems, and do other tasks, Digital Twin evaluates material utilization. Manufacturers create a digital duplicate of any product or system, set of tools and equipment, proprietary goods or processes, or anything else. Their goal is to make the factory floor better. sensors and additional devices that gather real-time.},
  keywords={Adaptation models;Costs;Machine learning algorithms;Electric breakdown;Stacking;Companies;Writing;Vectors;Maintenance;Predictive maintenance;Predictive Maintenance;Support Vector Machine;Long-Short Term Memory;Random Forests (RF);Gaussian Naive Bayes;Total Productive Maintenance},
  doi={10.1109/ICMCSI64620.2025.10883435},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10771916,
  author={Silva, Jonathan C. F. and Silva, Mateus C. and Amorim, Vicente J. P. and Lazaroni, Pedro S. O. and Oliveira, Ricardo A R},
  booktitle={2024 XIV Brazilian Symposium on Computing Systems Engineering (SBESC)}, 
  title={Wearable Sensors: Improving AI for Walking Activities Through GAN-Based Data Augmentation}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Human Activity Recognition (HAR) with artificial intelligence fosters the development of innovative solutions. However, building AI models often requires a substantial amount of data and can be time-consuming. In this context, our work adopted the TimeGAN technique for data augmentation, facilitating the construction of a more efficient model. We developed a classifier that integrates both synthetic and real data. This strategy significantly reduces the time required for data collection and may accelerate the development of new wearable technologies. This approach represents a promising step in optimizing development processes in AI applications for HAR, enhancing the speed and effectiveness of technological innovation.},
  keywords={Training;Technological innovation;Computational modeling;Data collection;Data augmentation;Data models;Human activity recognition;Artificial intelligence;Wearable sensors;Synthetic data;HAR;SPU;WPU;AI;GAN;TIMEGAN},
  doi={10.1109/SBESC65055.2024.10771916},
  ISSN={2324-7894},
  month={Nov},}@ARTICLE{10726800,
  author={Ko, Kyungdeuk and Lee, Bokyeung and Hong, Jonghwan and Ko, Hanseok},
  journal={IEEE Signal Processing Letters}, 
  title={KFA: Keyword Feature Augmentation for Open Set Keyword Spotting}, 
  year={2024},
  volume={31},
  number={},
  pages={2985-2989},
  abstract={In recent years, with the advancement of deep learning technology and the emergence of smart devices, there has been a growing interest in keyword spotting (KWS), which is used to activate AI systems with automatic speech recognition and text-to-speech. However, smart devices with KWS often encounter false alarm errors when inputting unexpected words. To address this issue, existing KWS methods typically train non-target words as an unknown class. Despite these efforts, there is still a possibility that unseen words not trained as part of the unknown class could be misclassified as one of the target words. To overcome this limitation, we propose a new method named Keyword Feature Augmentation (KFA) for open-set KWS. KFA performs feature augmentation through adversarial learning to increase the loss. The augmented features are constrained within a limited space using label smoothing. Unlike other generative model-based open set recognition (OSR) methods, KFA does not require any additional training parameters or repeated operation for inference. As a result, KFA has achieved a 0.955 AUROC score and 97.34% target class accuracy for Google Speech Commands V1, and a 0.959 AUROC score and 98.17% target class accuracy for Google Speech Commands V2, which is the highest performance when compared to various OSR methods.},
  keywords={Training;Internet;Convolution;Artificial intelligence;Signal processing algorithms;Pattern classification;Inference algorithms;Generative adversarial networks;Classification algorithms;Accuracy;Deep learning;keyword spotting;open set recognition},
  doi={10.1109/LSP.2024.3484932},
  ISSN={1558-2361},
  month={},}@INPROCEEDINGS{11135855,
  author={Rohith, B. and Kumar, N. R. Sathis and Srinivasine, P. Animma and Babu, B. Yaswanth and Prajwin, A. Sai},
  booktitle={2025 4th International Conference on Advances in Computing, Communication, Embedded and Secure Systems (ACCESS)}, 
  title={A Hybrid Approach to Fraud Detection: Integrating Explainable Deep Learning with Blockchain-Based Identity Verification}, 
  year={2025},
  volume={},
  number={},
  pages={493-497},
  abstract={Modern online finance operations create difficult obstacles for detecting fraudulent activity. While deep learning (DL) models effectively identify fraudulent activities, their "black-box" nature raises concerns about trust and interpretability. The research design recommends an XDL-Blockchain solution for fraud detection that enhances transparency and accuracy alongside enhanced security capabilities. SHAP and Grad-CAM methods supply interpretation features that enhance stakeholder confidence and blockchain technologies deliver permanent decentralized identity proofing systems which minimize fraudulent activity. Experimental assessments using genuine financial data show that the proposed model delivers superior outcomes compared to conventional detection systems regarding precision and network security. The framework unites artificial intelligence with blockchain technology to provide banks with a dependable system that delivers reliable detection of contemporary financial fraud.},
  keywords={Deep learning;Accuracy;Smart contracts;Finance;Fraud;Blockchains;Stakeholders;Reliability;Artificial intelligence;Protection;Fraud Detection;Explainable Deep Learning (XDL);Blockchain Technology;SHAP (Shapley Additive Explanations);Grad-CAM (Gradient-weighted Class Activation Mapping)},
  doi={10.1109/ACCESS65134.2025.11135855},
  ISSN={},
  month={June},}@INPROCEEDINGS{10901644,
  author={Zhang, Huiwen and Kumar, Venkataramani and Ye, Feng and Hu, Rose Qingyang and Qian, Yi},
  booktitle={GLOBECOM 2024 - 2024 IEEE Global Communications Conference}, 
  title={Enhancing AI-Supported Channel Estimation in MIMO Systems with Open Set Recognition}, 
  year={2024},
  volume={},
  number={},
  pages={1443-1448},
  abstract={Accurate channel estimation is required for various multiple input multiple output (MIMO) implementations in the next-generation wireless communication systems. Recently, Artificial Intelligence (AI) techniques have been introduced for channel state information (CSI) processing in channel estimation because of their accuracy and relatively low complexity compared to the traditional approaches. However, these AI-supported CSI processing models are usually developed with a fixed training dataset. Therefore, the performance of such approaches cannot be guaranteed in new environments. This paper focuses on enhancing AI-supported channel estimation methods with a 2-stage open set recognition scheme. New environments are detected in the first stage by identifying different characteristics between testing and training data. In the second stage, new data is filtered and further categorized to each individual environment. Simulation results using four different environment settings demonstrate that the proposed method can greatly enhance the usability of AI-supported channel estimation.},
  keywords={Training;Accuracy;Simulation;Channel estimation;Training data;MIMO;Artificial intelligence;Usability;Next generation networking;Testing},
  doi={10.1109/GLOBECOM52923.2024.10901644},
  ISSN={2576-6813},
  month={Dec},}@INPROCEEDINGS{10800682,
  author={Bai, Xuemei and Zhao, Huiyuan and Zhang, Chenjie and Hu, Hanping},
  booktitle={2024 4th International Conference on Electronic Information Engineering and Computer Science (EIECS)}, 
  title={Research on Music Generation Based on Transformer}, 
  year={2024},
  volume={},
  number={},
  pages={291-295},
  abstract={Music generation refers to the use of computers to create music through certain algorithms or processes with minimal human intervention, and is an important research direction in the field of artificial intelligence. However, music generation is an unsolved problem facing many challenges, and how to generate high-quality music samples has always been a research hotspot, for this reason, this paper proposes a music generation model based on improved Transformer. Specifically, this paper firstly preprocesses the music data and converts the music data into sequences for the model to process and learn. Secondly, a gated recurrent unit (GRU) is introduced to improve the Transformer, and the feature extraction capability of the Transformer to capture global dependencies and the time series modelling capability of the GRU are used to better understand the contextual relationships of the sequence data, and to generate high-quality music that is closer to real music. Finally, experimental verification of the music generated by the proposed method is carried out in this paper, and the results prove the effectiveness of the method.},
  keywords={Computers;Computer science;Computational modeling;Time series analysis;Logic gates;Transformers;Feature extraction;Data models;Artificial intelligence;Context modeling;music generation;automatic composition;deep learning;Transformer;attention mechanism},
  doi={10.1109/EIECS63941.2024.10800682},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10859404,
  author={Saranya, T. and S, Subbiah and V, Dhanaseelan},
  booktitle={2024 9th International Conference on Communication and Electronics Systems (ICCES)}, 
  title={AI Based Identification of Plant Health Issues}, 
  year={2024},
  volume={},
  number={},
  pages={1513-1517},
  abstract={The plant diseases detection and classification are Critical in ensuring sustainable agricultural productivity and preventing substantial crop losses. Traditional methods are time consuming and error prone and requires expertise in the field and it is difficult for larger operations. The detection of diseases using models like ResNet, MobileNet and YOLO are the recent advancements in the Artificial Intelligence and Deep Learning, but it also faces Challenges such as dataset imbalances, computational demand and variability in conditions persists. This research is on a deep learning model called Efficientnet to automate plant health diagnostics. The study evaluates the model's performance detecting various plant diseases and comparing it to other deep learning techniques, the results of the study show how Efficientnet can outperform other traditional models by providing accurate, real time plant disease identification.},
  keywords={Deep learning;YOLO;Productivity;Plant diseases;Accuracy;Computational modeling;Crops;Real-time systems;Artificial intelligence;Synthetic data;plant disease detection;Efficientnet;deep learning;agriculture;Convolution Neural Network;image classification},
  doi={10.1109/ICCES63552.2024.10859404},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11024793,
  author={Li, Chunling and Jia, Qiane},
  booktitle={2024 5th International Conference on Intelligent Design (ICID)}, 
  title={Research on the Application of Bronze Drum Pattern Design Based on Aesthetic-Enhanced Style Transfer Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={6-11},
  abstract={To protect and inherit the artistic characteristics of excellent traditional Chinese bronze drum culture and to promote innovation, artificial intelligence technology is utilized for the digital preservation and creative design of bronze drum patterns. By employing style transfer algorithms, the details of the bronze drum patterns are optimized to convey their core concepts, and create more innovative and visually appealing forms of inheritance, thus better adapting to the development of contemporary society and the constantly changing consumer demands. This paper uses style transfer algorithms to extract and collect the pattern features and stylistic elements of the bronze drum patterns, and incorporates aesthetic enhancement algorithms to make the transferred images more aesthetically valuable before applying the experimental results in practical applications. This research provides beneficial exploration for the digital preservation and design of bronze drum patterns, not only increasing creative efficiency but also expanding the channels for broadcasting bronze drum patterns, achieving an innovative integration of excellent traditional culture with technology.},
  keywords={Technological innovation;Art;Broadcasting;Feature extraction;Resonance;Pattern recognition;Digital preservation;Cultural differences;Artificial intelligence;Painting;Bronze drum pattern;style transfer algorithm;pattern design},
  doi={10.1109/ICID64166.2024.11024793},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10780796,
  author={Meilani and Aryuni, Mediana and Candra, Sevenpri},
  booktitle={2024 International Conference on Information Management and Technology (ICIMTech)}, 
  title={Analysis Factors Affecting Student Intention to Use Generative Artificial Intelligence in E-Learning}, 
  year={2024},
  volume={},
  number={},
  pages={117-122},
  abstract={The education sector, particularly e-learning, has experienced the emergence of a variety of AI categories as a result of the advancement of Artificial Intelligence (AI) technology. Today, Generative AI (GAI) is one of the most frequently employed forms of AI due to its ability to facilitate the acquisition of information sources and provide an enjoyable learning experience for students. To be able to facilitate efficient GAI in e-Learning, it is necessary to know the preferences for its adoption. This research aims to analyze what factors can influence the use of GAI to support student e-learning. The SEM method is used to process data with the help of SMARTPLS 3 as a tool to process respondent data. Data collection was done with Google Form and 351 respondents were obtained but only 346 valid data. Respondents consisted of students from universities in Indonesia aged 19–24 years old and using GAI in E- Learning. This research uses UTAUT 2 and Perceived Risk research model and Snowball Sampling method. The study's findings indicate that the factors that influence the use of GAI in e-learning students are facilitating conditions, habits, and perceived risks. The most dominant factor in determining students' behavioral intention in using AI is Habit. The results obtained from this study are expected to contribute to educational institutions and e-learning service providers to help develop more effective strategies and policies in adopting GAI in e-learning.},
  keywords={Analytical models;Electronic learning;Generative AI;Education;Psychology;Aging;Data collection;Sampling methods;Internet;Information management;e-learning;GAI;perceived risk;UTATUT 2;intention to use},
  doi={10.1109/ICIMTech63123.2024.10780796},
  ISSN={2837-2778},
  month={Aug},}@INPROCEEDINGS{10818271,
  author={Xie, Songcheng and Zhu, Shengpeng and He, Qifan and Cui, Zhanqi},
  booktitle={2024 11th International Conference on Dependable Systems and Their Applications (DSA)}, 
  title={Autonomous Driving Software Testing Based on Interpretation Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={432-433},
  abstract={With the development of artificial intelligence, autonomous driving has become a typical use of AI technology, while its safety has received widespread attention. However, current mainstream data-driven automated driving test methods lack interpretability, automation features, and a high degree of realism in generating test images. To solve the above problems, this paper proposes a method ATIA (Autonomous Test based on Interpretation Analysis), which generates gradient heatmaps based on Grad-CAM and uses deep image synthesis network to generate test images by replacing key objects according to the heatmap, and also designs a corresponding automated testing tool. The experimental results show that ATIA has the ability to detect defects, while generating images that are closer to real images.},
  keywords={Heating systems;Software testing;Automation;Image synthesis;Semantics;Software;Safety;Object recognition;Artificial intelligence;Autonomous vehicles;autonomous driving;software testing;interpretation analysis;grad-CAM;deep image synthesis},
  doi={10.1109/DSA63982.2024.00067},
  ISSN={2767-6684},
  month={Nov},}@INPROCEEDINGS{10978254,
  author={Luostari, Riku and Korpi, Dani and Honkala, Mikko and Huttunen, Janne M.J.},
  booktitle={2025 IEEE Wireless Communications and Networking Conference (WCNC)}, 
  title={Adapting to Reality: Over-the-Air Validation of AI - Based Receivers Trained with Simulated Channels}, 
  year={2025},
  volume={},
  number={},
  pages={01-06},
  abstract={Recent research shows that integrating artificial intelligence (AI) into wireless communication systems can significantly improve spectral efficiency. However, most AI-based receiver studies rely on simulated radio channel data for both training and validation, raising concerns about real-world generalization, which is vital for ensuring reliable field performance. In this study, we train DeepRx, a convolutional neural network (CNN)-based OFDM receiver, under various simulated channel scenarios and validate its performance over- the-air (OTA) using software-defined radio (SDR) technology in a small cell-type setup. To enhance receiver training, we investigate a randomized 3GPP TS38.901 channel model to diversify the training data, thereby improving performance over conventional receivers and matching or exceeding the performance of receivers trained on narrowly targeted channel models. These results demonstrate DeepRx's robust generalization capability and suggest that narrowly scoped, individual TS38.901 models can compromise both training and validation, underscoring the need for tailored channel models, careful training strategies, and OTA testing in learned receiver development.},
  keywords={Training;Adaptation models;Uncertainty;OFDM;Wireless networks;Receivers;Data models;Channel models;3GPP;Artificial intelligence},
  doi={10.1109/WCNC61545.2025.10978254},
  ISSN={1558-2612},
  month={March},}@ARTICLE{11029708,
  author={Liao, Man-Ling and Chen, Jiann-Liang and Ahmadi, Candra},
  journal={IT Professional}, 
  title={Detecting AI-Generated Images Using Facial Similarity and Feature Extraction for Digital Security}, 
  year={2025},
  volume={27},
  number={3},
  pages={52-56},
  abstract={Artificial intelligence (AI) has revolutionized digital imagery, enabling the creation of highly realistic AI-generated images. This advancement, however, poses risks, such as fraud and misinformation. A critical gap exists in effectively distinguishing between AI-generated and authentic human images. Here, we propose a robust detection system utilizing facial feature extraction and similarity analysis. Our approach involves a three-stage process, including facial feature extraction, similarity assessment, and final verification using the EfficientNet model. The system achieved an accuracy rate of 96.4%, demonstrating its effectiveness in differentiating between AI-generated and real images. These findings offer significant implications for improving digital security and mitigating the risks posed by AI-generated content.},
  keywords={Accuracy;Social networking (online);Feature extraction;Fraud;Security;Servers;Fake news;Artificial intelligence;Facial features;Standards},
  doi={10.1109/MITP.2025.3561143},
  ISSN={1941-045X},
  month={May},}@ARTICLE{10113226,
  author={Prunella, Michela and Scardigno, Roberto Maria and Buongiorno, Domenico and Brunetti, Antonio and Longo, Nicola and Carli, Raffaele and Dotoli, Mariagrazia and Bevilacqua, Vitoantonio},
  journal={IEEE Access}, 
  title={Deep Learning for Automatic Vision-Based Recognition of Industrial Surface Defects: A Survey}, 
  year={2023},
  volume={11},
  number={},
  pages={43370-43423},
  abstract={Automatic vision-based inspection systems have played a key role in product quality assessment for decades through the segmentation, detection, and classification of defects. Historically, machine learning frameworks, based on hand-crafted feature extraction, selection, and validation, counted on a combined approach of parameterized image processing algorithms and explicated human knowledge. The outstanding performance of deep learning (DL) for vision systems, in automatically discovering a feature representation suitable for the corresponding task, has exponentially increased the number of scientific articles and commercial products aiming at industrial quality assessment. In such a context, this article reviews more than 220 relevant articles from the related literature published until February 2023, covering the recent consolidation and advances in the field of fully-automatic DL-based surface defects inspection systems, deployed in various industrial applications. The analyzed papers have been classified according to a bi-dimensional taxonomy, that considers both the specific defect recognition task and the employed learning paradigm. The dependency on large and high-quality labeled datasets and the different neural architectures employed to achieve an overall perception of both well-visible and subtle defects, through the supervision of fine or/and coarse data annotations have been assessed. The results of our analysis highlight a growing research interest in defect representation power enrichment, especially by transferring pre-trained layers to an optimized network and by explaining the network decisions to suggest trustworthy retention or rejection of the products being evaluated.},
  keywords={Feature extraction;Transfer learning;Deep learning;Artificial intelligence;Inspection;Manuals;Image recognition;Computer vision;Autonomous systems;Generative adversarial networks;Artificial vision;auto-encoder;automatic recognition;feature attention mechanism;convolutional neural network;deep learning;explainable artificial intelligence;generative-adversarial network;industrial surface defects;transfer learning},
  doi={10.1109/ACCESS.2023.3271748},
  ISSN={2169-3536},
  month={},}@ARTICLE{9262005,
  author={Naeem, Faisal and Seifollahi, Sattar and Zhou, Zhenyu and Tariq, Muhammad},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={A Generative Adversarial Network Enabled Deep Distributional Reinforcement Learning for Transmission Scheduling in Internet of Vehicles}, 
  year={2021},
  volume={22},
  number={7},
  pages={4550-4559},
  abstract={The Cognitive Internet of Vehicles (CIoV) is an intelligent network that embeds the cognitive mechanism in the Internet of Vehicles (IoV) to sense the environment and observe the network states to learn the optimal policies adaptively. However, one of the key challenges in CIoV systems is to design a smart agent that can smartly schedule the packet transmission for ultra-reliable low latency communication (URLLC) under extreme random and noisy network conditions. We propose a software defined network (SDN) based scheduling algorithm that leverages generative adversarial network (GAN) based deep distributional Q-network (GAN-DDQN) for learning the action-value distribution for intelligent transmission scheduling. A reward-clipping technique is proposed for stabilizing the training of GAN-DDQN against the effect of broadly spanning utility values. The extensive simulation results verify that GAN-Scheduling achieves higher spectral efficiency (SE), service level agreement (SLA), system throughput, transmission packet rate with lower transmission delay, and power consumption compared to the existing reinforcement learning algorithms.},
  keywords={Generative adversarial networks;Delays;Noise measurement;Internet;Dynamic scheduling;Signal to noise ratio;Vehicle dynamics;Software defined networking;Internet of Things;cognitive internet of vehicles;generative adversarial network;deep distributional Q-network},
  doi={10.1109/TITS.2020.3033577},
  ISSN={1558-0016},
  month={July},}@INPROCEEDINGS{10215001,
  author={Jayatharan, Vithushigan and Alwis, Dileeka},
  booktitle={2023 International Research Conference on Smart Computing and Systems Engineering (SCSE)}, 
  title={Alapana Generation using Finite State Machines and Generative Adversarial Networks}, 
  year={2023},
  volume={6},
  number={},
  pages={1-6},
  abstract={The recent advancements in deep learning techniques and computational power have promoted the development of novel approaches for music generation. In this study, generating alapana, an improvisational form of Carnatic music was proposed, by leveraging Generative Adversarial Networks (GANs) and Finite State Machines (FSM). The goal is to create melodious alapana sequences that follow a given input Raga, ensuring continuity and coherence throughout the generated musical piece. The proposed approach incorporates Carnatic music theory rules into the generation process to enhance the structural coherence of the generated alapana. Additionally, various hyperparameter settings were explored to achieve the best performance. The Fréchet Audio Distance, Percentage of Correct Pitches and the Subjective evaluation through human listeners are the evaluation metrics of this approach. The result of this study demonstrates the potential of using GANs and FSM for generating continuous and pleasing alapana sequences in Carnatic music, contributing to the growing body of research in computational music generation.},
  keywords={Measurement;Deep learning;Technological innovation;Automata;Music;Coherence;Generative adversarial networks;Generative Adversarial Network;Finite State Machine;Carnatic Music;Alapana;Raga},
  doi={10.1109/SCSE59836.2023.10215001},
  ISSN={2613-8662},
  month={June},}@INPROCEEDINGS{10550289,
  author={Kalita, Swagat Subhash and Mahajan, Parag and Sharanya, S.},
  booktitle={2024 International Conference on Communication, Computing and Internet of Things (IC3IoT)}, 
  title={Generative Adversarial Network Art Generator for Sculpture Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This study examines computer-generated sculpture using a hybrid architecture of Generative Adversarial Networks (GANs) and Convolutional Neural Networks (CNNs). CNNs are essential for visual data analysis and processing, while GANs iteratively blur the line between synthesis and authenticity. A dynamically interacting generator and discriminator network form the GAN framework. The discriminator, trained to distinguish authentic sculptures from computer-generated ones, guides the generator toward greater realism and complexity with each iteration. This study analyzes the complicated dynamics of GAN-enabled sculpture production, examining several elements that affect the result. We intend to illuminate the complex relationship between composition, texture, and shape of digitally generated sculptures by analyzing sculptures using GANs and CNNs. We want to understand their formation methods as well as their aesthetic value. We also consider how GAN-generated sculptures may be transformed beyond traditional artistic usage. The sculptures offer unique opportunities for artistic expression, scholarly study, and practical use. They can enhance art, education, architectural design, and historical preservation. This thorough inquiry using GANs and CNNs aims to push the limitations of traditional art creation and explore unknown sculpture interpretation and analysis zones.},
  keywords={Training;Visualization;Art;Shape;Neural networks;Production;Generative adversarial networks;computer-generated sculpture;hybrid architecture;Generative Adversarial Networks (GANs);Convolutional Neural Networks (CNNs);generator network;discriminator network;GAN framework;digitally generated sculptures;artistic expression;sculpture interpretation},
  doi={10.1109/IC3IoT60841.2024.10550289},
  ISSN={},
  month={April},}@INPROCEEDINGS{10092222,
  author={Reale, Michael J. and Nichols, Preston and Schneider, Ethan and Bishop, Morgan and Cornacchia, Maria},
  booktitle={2022 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)}, 
  title={Generative Adversarial Networks for Vehicle Transformation in Overhead and Satellite Imagery}, 
  year={2022},
  volume={},
  number={},
  pages={1-13},
  abstract={The ability to create and detect synthetic video is becoming critically important to scene understanding. Techniques for synthetic manipulation and augmentation of data increases diversity within available datasets, while not requiring laborious labeling efforts. That is, the ability to create synthetic video can enable augmentation of small realistic datasets on which to further train Artificial Intelligence and Machine Learning (AI/ML) algorithms. Thus, it may be desirable to convert images of vehicles in satellite and overhead imagery to other varieties of vehicles. In this work, we leverage generative adversarial networks to transform cars into trucks (and vice versa). We leverage an attention-based masking approach that assists the network in transformation of the object and not background. In addition, we demonstrate the benefits of numerous data augmentation procedures, including presenting a new artificial dataset of vehicles from an aerial perspective and introducing novel augmentation techniques appropriate for our network architectures. Experiments are conducted for this unique application on both real and artificial datasets with state-of-the-art results.},
  keywords={Satellites;Machine learning algorithms;Conferences;Transforms;Machine learning;Network architecture;Generative adversarial networks},
  doi={10.1109/AIPR57179.2022.10092222},
  ISSN={2332-5615},
  month={Oct},}@ARTICLE{10542118,
  author={Bai, Bing and Yue, Haimeng and Chen, Lintao and Li, Xiaozheng},
  journal={IEEE Access}, 
  title={Research on Dataset Generation and Monitoring of Generative AI for Drowning Warning System}, 
  year={2024},
  volume={12},
  number={},
  pages={83589-83599},
  abstract={In order to address the scarcity of images in real-world drowning datasets, this research aims to create an intelligent system that can generate a large number of drowning datasets by optimizing AI image generation algorithms. The system will gradually be used to compensate for the shortage of rare real-world drowning datasets. This method is not only based on traditional AI image generation steps but also optimizes the engine framework to create more drowning datasets. For the key elements of drowning, on the one hand, different filters, especially blue and green filters, will be added to distinguish the color differences between underwater and above water. On the other hand, the framework structure of Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Diffusion Models will be optimized to further reduce system computation. At the same time, the detection of drowning swimmers in the system has become clearer. It can greatly improve the performance and efficiency of drowning monitoring algorithms. The drowning dataset generated by AI can describe different real-world drowning processes and perfectly adapt to different emergency scenarios. This method is also applicable to dangerous behaviors where the process is difficult to record.},
  keywords={Artificial intelligence;Training;Monitoring;Generators;Filters;Sports;Image color analysis;Data models;Generative adversarial networks;Encoding;Drowning datasets;engine framework;generative adversarial networks;variational autoencoders},
  doi={10.1109/ACCESS.2024.3407245},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10959690,
  author={Al-Barhamtoshy, Hassanin M. and Deabes, Rania M. and Baalamash, Fardus A.},
  booktitle={2025 2nd International Conference on Advanced Innovations in Smart Cities (ICAISC)}, 
  title={Interactive AI for Advancing and Generating Women's Traditional Fashion in Saudi Arabia}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={This research sought to safeguard the cultural legacy of women's traditional attire in the Kingdom of Saudi Arabia by developing a comprehensive digital platform for the collection and categorization of these costumes. The emphasis was placed on the Western region of Saudi Arabia, where a dataset of traditional garments was collected, compiled, and generated. Moreover, a specialized website was created to streamline the marketing and purchasing processes for these traditional outfits. The methodology integrated both descriptive-analytical and experimental approaches based on generative AI. Tools utilized in this research included an expert opinion survey aimed at understanding the requirements for implementing an artificial intelligence-based classification system for women's traditional clothing, as well as measuring user perceptions regarding the website's effectiveness in marketing Saudi Arabia's traditional wear. Additionally, questionnaires were distributed to gather input from specialists concerning the classification system and its related website, focusing on advancing production and marketing strategies. Users' feedback on both the AI-driven classification system and the website was also collected. Key findings indicated that it is viable to preserve cultural heritage represented by traditional garments from Saudi Arabia's western region through their collection and organization within an AI-based framework. Furthermore, this study highlighted opportunities for promoting and selling traditional fashion via a website equipped with an AI classification system. The AI-driven classification system demonstrated remarkable accuracy, approaching 97%, with an error rate of around 3.15%. The conclusion includes recommendations for sharing this system with fashion houses interested in producing traditional women's clothing in Saudi Arabia, along with providing access to databases that could assist in designing and manufacturing such apparel.},
  keywords={Surveys;Technological innovation;Accuracy;Smart cities;Clothing;Symbols;Production;Organizations;Cultural differences;Convolutional neural networks;traditional clothing;artificial intelligence;machine learning;e-commerce websites},
  doi={10.1109/ICAISC64594.2025.10959690},
  ISSN={},
  month={Feb},}@ARTICLE{11120454,
  author={Lee, Yejin and Golden, Alicia and Sun, Anna and Hosmer, Basil and Acun, Bilge and Balioglu, Can and Wang, Changhan and Hernandez, Charles David and Puhrsch, Christian and Haziza, Daniel and Guessous, Driss and Massa, Francisco and Kahn, Jacob and Wan, Jeffrey and Reizenstein, Jeremy and Zhai, Jiaqi and Isaacson, Joe and Schlosser, Joel and Pino, Juan and Sadagopan, Kaushik Ram and Shamis, Leonid and Ma, Linjian and Hwang, Min-Jae and Chen, Mingda and Elhoushi, Mostafa and Rodriguez, Pedro and Pasunuru, Ram and Hsia, Samuel and Yih, Scott and Popuri, Sravya and Liu, Xing and Wu, Carole-Jean},
  journal={IEEE Micro}, 
  title={Characterizing and Efficiently Accelerating Multimodal Generation Model Inference}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={Generative artificial intelligence (AI) technology is revolutionizing the computing industry, posing new system design and optimization opportunities. In particular, AI’s ability to understand and respond in multiple modalities comes with significant system resource demands. To sustainably scale generative AI capabilities to billions of users in the world, inference must be fast and efficient. This paper pinpoints key system design and optimization opportunities by characterizing a family of emerging multi-modal generation models on real systems. Auto-regressive token generation is a critical latency performance bottleneck, typically dominated by GPU idle time. In addition to memory-intensive attention across the generative AI models, linear operations constitute significant inference latency due to the feed forward networks in Transformer-based models. We demonstrate that state-of-the-art optimization levers, spanning from applications to system software and hardware, set a 3.88× better baseline.},
  keywords={Generative AI;Computational modeling;Translation;Artificial intelligence;Decoding;Graphics processing units;Codes;Vocoders;Transformers;Memory management},
  doi={10.1109/MM.2025.3596539},
  ISSN={1937-4143},
  month={},}@INPROCEEDINGS{10783645,
  author={Hassan, Hana Ahmed Mohamed and Abouelwafa, Mariam Mohamed and Saber, Amira Alaa and Ibrahim, Ahmed Ehab and Shorim, Nada and AbdElminaam, Diaa Salama},
  booktitle={2024 International Mobile, Intelligent, and Ubiquitous Computing Conference (MIUCC)}, 
  title={Automating Forensic Analysis: Integrating Machine Learning Algorithms for Forensic Evidence and Serial Killer Profiling}, 
  year={2024},
  volume={},
  number={},
  pages={447-454},
  abstract={Serial murder investigations pose significant challenges due to the complexity of criminal patterns and behaviors. This study presents an integrated forensic analysis system using advanced artificial intelligence (AI) techniques to enhance the efficiency and accuracy of criminal investigations, particularly in serial murder cases. By applying various machine learning algorithms, including logistic regression, support vector machines (SVM), K-nearest neighbors (KNN), convolutional neural networks (CNN), and generative adversarial networks (GAN), the system analyzes key forensic evidence such as serial killer patterns, fingerprint recognition, face sketching, bloodstain analysis, and autopsy reports. Each module in the system contributes to narrowing down suspect profiles and linking potential cases using AI-driven pattern recognition and data analysis. The system demonstrated high performance across multiple forensic tasks, with logistic regression and SVM achieving 85% accuracy in serial killer pattern recognition, GAN achieving 99% accuracy in face recognition, and LSTM achieving 99.3% accuracy in bloodstain analysis. The integration of these AI techniques ensures robust, unbiased, and efficient forensic analysis, significantly reducing the time and labor required in traditional investigative methods. The findings of this study underscore the transformative potential of AI in forensic science, providing law enforcement with powerful tools to profile serial killers, analyze crime scenes, and identify critical evidence with precision. This unified AI-based approach holds promise for improving investigative outcomes and enhancing public safety by assisting in the timely resolution of complex murder cases.},
  keywords={Support vector machines;Logistic regression;Accuracy;Machine learning algorithms;Forensics;Face recognition;Fingerprint recognition;Nearest neighbor methods;Generative adversarial networks;Artificial intelligence;Serial killer;Artificial Intelligence;Forensic Analysis;Fingerprint;face sketching;Autopsy Report;Blood-stain;Glass Identification},
  doi={10.1109/MIUCC62295.2024.10783645},
  ISSN={},
  month={Nov},}@ARTICLE{10043696,
  author={Esmaeili, Marzieh and Toosi, Amirhosein and Roshanpoor, Arash and Changizi, Vahid and Ghazisaeedi, Marjan and Rahmim, Arman and Sabokrou, Mohammad},
  journal={IEEE Access}, 
  title={Generative Adversarial Networks for Anomaly Detection in Biomedical Imaging: A Study on Seven Medical Image Datasets}, 
  year={2023},
  volume={11},
  number={},
  pages={17906-17921},
  abstract={Anomaly detection (AD) is a challenging problem in computer vision. Particularly in the field of medical imaging, AD poses even more challenges due to a number of reasons, including insufficient availability of ground truth (annotated) data. In recent years, AD models based on generative adversarial networks (GANs) have made significant progress. However, their effectiveness in biomedical imaging remains underexplored. In this paper, we present an overview of using GANs for AD, as well as an investigation of state-of-the-art GAN-based AD methods for biomedical imaging and the challenges encountered in detail. We have also specifically investigated the advantages and limitations of AD methods on medical image datasets, conducting experiments using 3 AD methods on 7 medical imaging datasets from different modalities and organs/tissues. Given the highly different findings achieved across these experiments, we further analyzed the results from both data-centric and model-centric points of view. The results showed that none of the methods had a reliable performance for detecting abnormalities in medical images. Factors such as the number of training samples, the subtlety of the anomaly, and the dispersion of the anomaly in the images are among the phenomena that highly impact the performance of the AD models. The obtained results were highly variable (AUC: 0.475-0.991; Sensitivity: 0.17-0.98; Specificity: 0.14-0.97). In addition, we provide recommendations for the deployment of AD models in medical imaging and foresee important research directions.},
  keywords={Generators;Generative adversarial networks;Training data;Medical diagnostic imaging;Anomaly detection;Image reconstruction;Feature extraction;Anomaly detection;artificial intelligence;machine learning;deep learning;unsupervised anomaly detection;generative adversarial networks;medical imaging;biomedical image processing},
  doi={10.1109/ACCESS.2023.3244741},
  ISSN={2169-3536},
  month={},}
