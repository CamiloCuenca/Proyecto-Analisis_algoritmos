@ARTICLE{10854655,
  author={Al-kfairy, Mousa},
  journal={IEEE Engineering Management Review}, 
  title={Strategic Integration of Generative AI in Organizational Settings: Applications, Challenges and Adoption Requirements}, 
  year={2025},
  volume={},
  number={},
  pages={1-14},
  abstract={Generative AI is revolutionizing the way organizations operate, offering transformative capabilities that span automated content creation, strategic decision-making, and customer engagement through AI-driven chatbots. This paper conducts a comprehensive literature review to explore the applications, challenges, and strategic requirements for adopting generative AI in organizational contexts, focusing on the distinct needs of Small and Medium Enterprises (SMEs) and large organizations. The findings reveal that generative AI can improve efficiency, drive innovation, and improve customer satisfaction, but its adoption pathways differ significantly between organizational sizes. For SMEs, the emphasis lies on cost-effective and scalable solutions that optimize resource-constrained operations. At the same time, large organizations leverage their extensive resources to scale AI applications, manage complex systems, and address ethical and regulatory challenges. The study highlights critical barriers, including data privacy concerns, integration with legacy systems, and resistance to change, alongside actionable recommendations for overcoming these challenges. By synthesizing insights from 38 high-quality studies, this research bridges the gap between theory and practice. It provides a roadmap for organizations of varying scales to harness generative AI as a cornerstone of their digital transformation journey. It also identifies key areas for future exploration, ensuring relevance in this rapidly evolving field.},
  keywords={Generative AI;Organizations;Systematic literature review;Technological innovation;Market research;Databases;Replicability;Quality assessment;Productivity;Industries;AI-Enabled Operational Efficiency;digital transformation;generative AI integration;literature review;strategic AI adoption;strategic planning},
  doi={10.1109/EMR.2025.3534034},
  ISSN={1937-4178},
  month={},}@ARTICLE{9947048,
  author={Yu, Sung-Nien and Wang, Shao-Wei and Chang, Yu Ping},
  journal={IEEE Access}, 
  title={Improving Distinguishability of Photoplethysmography in Emotion Recognition Using Deep Convolutional Generative Adversarial Networks}, 
  year={2022},
  volume={10},
  number={},
  pages={119630-119640},
  abstract={We propose an emotion recognition framework based on ResNet, bidirectional long- and short-term memory (BiLSTM) modules, and data augmentation using a ResNet deep convolutional generative adversarial network (DCGAN) with photoplethysmography (PPG) signals as input. The emotions identified in this study were classified into two classes (positive and negative) and four classes (neutral, angry, happy, and sad). The framework achieved high recognition rates of 90.34% and 86.32% in two- and four-class emotion recognition tasks, respectively, outperforming other representative methods. Moreover, we show that the ResNet DCGAN module can synthesize samples that do not just look like those in the training set, but also capture discriminative features of the different classes. The distinguishability of the classes was enhanced when these synthetic samples were added to the original samples, which in turn improved the test accuracy of the model when trained using these mixed samples. This effect was evaluated using various quantitative and qualitative methods, including the inception score (IS), Fréchet inception distance (FID), GAN quality index (GQI), linear discriminant analysis (LDA), and Mahalanobis distance (MD).},
  keywords={Emotion recognition;Generators;Generative adversarial networks;Feature extraction;Spectrogram;Convolutional neural networks;Photoplethysmography;Augmentation;DCGAN;emotion recognition;PPG},
  doi={10.1109/ACCESS.2022.3221774},
  ISSN={2169-3536},
  month={},}@ARTICLE{10829825,
  author={Zhang, Kexin and Li, Lixin and Lin, Wensheng and Yan, Yuna and Li, Rui and Cheng, Wenchi and Han, Zhu},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Semantic Successive Refinement: A Generative AI-Aided Semantic Communication Framework}, 
  year={2025},
  volume={11},
  number={2},
  pages={687-699},
  abstract={Semantic Communication (SC) is an emerging technology aiming to surpass the Shannon limit. Traditional SC strategies often minimize signal distortion between the original and reconstructed data, neglecting perceptual quality, especially in low Signal-to-Noise Ratio (SNR) environments. To address this issue, we introduce a novel Generative AI Semantic Communication (GSC) system for single-user scenarios. This system leverages deep generative models to establish a new paradigm in SC. Specifically, At the transmitter end, it employs a joint source-channel coding mechanism based on the Swin Transformer for efficient semantic feature extraction and compression. At the receiver end, an advanced Diffusion Model (DM) reconstructs high-quality images from degraded signals, enhancing perceptual details. Additionally, we present a Multi-User Generative Semantic Communication (MU-GSC) system utilizing an asynchronous processing model. This model effectively manages multiple user requests and optimally utilizes system resources for parallel processing. Simulation results on public datasets demonstrate that our generative AI semantic communication systems achieve superior transmission efficiency and enhanced communication content quality across various channel conditions. Compared to CNN-based DeepJSCC, our methods improve the Peak Signal-to-Noise Ratio (PSNR) by 17.75% in Additive White Gaussian Noise (AWGN) channels and by 20.84% in Rayleigh channels.},
  keywords={Transformers;Semantic communication;Decoding;Generative AI;Image reconstruction;Receivers;Wireless communication;Transmitters;Diffusion models;Feature extraction;Generative AI;semantic communication;multi-user system;swin transformer;diffusion model},
  doi={10.1109/TCCN.2025.3526839},
  ISSN={2332-7731},
  month={April},}@INPROCEEDINGS{11035208,
  author={Agnihotri, Anurag and Saravanakumar, R},
  booktitle={2025 5th International Conference on Pervasive Computing and Social Networking (ICPCSN)}, 
  title={Harnessing Generative AI for Transforming Marketing Strategies: Enhancing Consumer Engagement through Precision and Personalization}, 
  year={2025},
  volume={},
  number={},
  pages={1522-1527},
  abstract={Marketing strategies are in the midst of a fundamental change to keep up with changing needs of personalization, interactivity and relevance among consumers. In this paper, propose a generative AI driven framework for inducing customer engagement by producing customized marketing contents in accordance with the historical data of a campaign process. The proposed framework proposes to achieve this by leveraging the Marketing Campaign Performance dataset and use advanced generative models to generate personalized, real-time content in sync with the individual consumer preferences and behavioral patterns. Also, conversational AI is built for instant and context aware responses and recommendations making the user interaction more enriched. Advanced segmentation techniques are used to cluster consumers based on its similar behavior and more targeted marketing strategies are devised to make campaign more effective. The results of experimental efforts show marked improvements on marketing performance metrics such as: 25% increase in click throughs, 30% increase in conversion and total customer engagements increased by 40%. These are the outcomes of the framework’s ability to optimize the delivery of the content with data driven decision making in marketing. The study lays the groundwork for the use of intelligent, adaptive, marketing strategies made possible by generative AI and provides a scalable solution for increasing consumer engagement in competitive digital environments.},
  keywords={Pervasive computing;Context-aware services;Conversational artificial intelligence;Generative AI;Social networking (online);Decision making;Real-time systems;Synchronization;Conversational AI;Consumer Engagement;Generative AI;Marketing Strategies;Personalization},
  doi={10.1109/ICPCSN65854.2025.11035208},
  ISSN={},
  month={May},}@INPROCEEDINGS{9156882,
  author={Wang, Yaxing and Gonzalez-Garcia, Abel and Berga, David and Herranz, Luis and Khan, Fahad Shahbaz and van de Weijer, Joost},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={MineGAN: Effective Knowledge Transfer From GANs to Target Domains With Few Images}, 
  year={2020},
  volume={},
  number={},
  pages={9329-9338},
  abstract={One of the attractive characteristics of deep neural networks is their ability to transfer knowledge obtained in one domain to other related domains. As a result, high-quality networks can be trained in domains with relatively little training data. This property has been extensively studied for discriminative networks but has received significantly less attention for generative models. Given the often enormous effort required to train GANs, both computationally as well as in the dataset collection, the re-use of pretrained GANs is a desirable objective. We propose a novel knowledge transfer method for generative models based on mining the knowledge that is most beneficial to a specific target domain, either from a single or multiple pretrained GANs. This is done using a miner network that identifies which part of the generative distribution of each pretrained GAN outputs samples closest to the target domain. Mining effectively steers GAN sampling towards suitable regions of the latent space, which facilitates the posterior finetuning and avoids pathologies of other methods such as mode collapse and lack of flexibility. We perform experiments on several complex datasets using various GAN architectures (BigGAN, Progressive GAN) and show that the proposed method, called MineGAN, effectively transfers knowledge to domains with few target images, outperforming existing methods. In addition, MineGAN can successfully transfer knowledge from multiple pretrained GANs. Our code is available at: \url{https://github.com/yaxingwang/MineGAN}.},
  keywords={Gallium nitride;Generators;Generative adversarial networks;Training;Data mining;Knowledge transfer;Computational modeling},
  doi={10.1109/CVPR42600.2020.00935},
  ISSN={2575-7075},
  month={June},}@ARTICLE{10489861,
  author={Chaccour, Christina and Saad, Walid and Debbah, Mérouane and Poor, H. Vincent},
  journal={IEEE Transactions on Wireless Communications}, 
  title={Joint Sensing, Communication, and AI: A Trifecta for Resilient THz User Experiences}, 
  year={2024},
  volume={23},
  number={9},
  pages={11444-11460},
  abstract={In this paper a novel joint sensing, communication, and artificial intelligence (AI) framework is proposed so as to optimize extended reality (XR) experiences over terahertz (THz) wireless systems. Within this framework, active reconfigurable intelligent surfaces (RISs) are incorporated as pivotal elements, serving as enhanced base stations in the THz band to enhance Line-of-Sight (LoS) communication. The proposed framework consists of three main components. First, a tensor decomposition framework is proposed to extract unique sensing parameters for XR users and their environment by exploiting the THz channel sparsity. Essentially, the THz band’s quasi-opticality is exploited and the sensing parameters are extracted from the uplink communication signal, thereby allowing for the use of the same waveform, spectrum, and hardware for both communication and sensing functionalities. Then, the Cramér-Rao lower bound is derived to assess the accuracy of the estimated sensing parameters. Second, a non-autoregressive multi-resolution generative AI framework integrated with an adversarial transformer is proposed to predict missing and future sensing information. The proposed framework offers robust and comprehensive historical sensing information and anticipatory forecasts of future environmental changes, which are generalizable to fluctuations in both known and unforeseen user behaviors and environmental conditions. Third, a multi-agent deep recurrent hysteretic Q-neural network is developed to control the handover policy of RIS subarrays, leveraging the informative nature of sensing information to minimize handover cost, maximize the individual quality of personal experiences (QoPEs), and improve the robustness and resilience of THz links. Simulation results show a high generalizability of the proposed unsupervised generative artificial intelligence (AI) framework to fluctuations in user behavior and velocity, leading to a 61% improvement in instantaneous reliability compared to schemes with known channel state information.},
  keywords={Sensors;Terahertz communications;Wireless communication;X reality;Artificial intelligence;Hardware;Wireless sensor networks;Extended reality (XR);terahertz (THz);artificial intelligence (AI);machine learning (ML);reliability;resilience;joint sensing and communication},
  doi={10.1109/TWC.2024.3382192},
  ISSN={1558-2248},
  month={Sep.},}@INPROCEEDINGS{9412832,
  author={Wang, Shuwei and Wang, Qiuyun and Jiang, Zhengwei and Wang, Xuren and Jing, Rongqi},
  booktitle={2020 25th International Conference on Pattern Recognition (ICPR)}, 
  title={A Weak Coupling of Semi-Supervised Learning with Generative Adversarial Networks for Malware Classification}, 
  year={2021},
  volume={},
  number={},
  pages={3775-3782},
  abstract={Malware classification helps to understand its purpose and is also an important part of attack detection. And it is also an important part of discovering attacks. Due to continuous innovation and development of artificial intelligence, it is a trend to combine deep learning with malware classification. In this paper, we propose an improved malware image rescaling algorithm (IMIR) based on local mean algorithm. Its main goal of IMIR is to reduce the loss of information from samples during the process of converting binary files to image files. Therefore, we construct a neural network structure based on VGG model, which is suitable for image classification. In the real world, a mass of malware family labels are inaccurate or lacking. To deal with this situation, we propose a novel method to train the deep neural network by Semi-supervised Generative Adversarial Network (SGAN), which only needs a small amount of malware that have accurate labels about families. By integrating SGAN with weak coupling, we can retain the weak links of supervised part and unsupervised part of SGAN. It improves the accuracy of malware classification by making classifiers more independent of discriminators. The results of experimental demonstrate that our model achieves exhibiting favorable performance. The recalls of each family in our data set are all higher than 93.75%.},
  keywords={Couplings;Technological innovation;Neural networks;Semisupervised learning;Generative adversarial networks;Market research;Malware;Malware;Deep Learning;Classification},
  doi={10.1109/ICPR48806.2021.9412832},
  ISSN={1051-4651},
  month={Jan},}@INPROCEEDINGS{10582937,
  author={Mosavi, Amir and Imre, Felde and Hung, VO Trung},
  booktitle={2024 IEEE 11th International Conference on Computational Cybernetics and Cyber-Medical Systems (ICCC)}, 
  title={ChatGPT and Large Language Models in Healthcare; a Bibliometrics Analysis and Review}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={ChatGPT and similar large language models (LLMs) are becoming the essential tools in healthcare, offering diverse applications. This article presents a bibliometric analysis for studying the dimension and the role of ChatGPT and major large language models in healthcare. The LLMs’ impact, usage, and growth in medical literature is presented. Through exploring the Scopus database, this article uncovers the trends and contributions of LLMs. Our findings deliver insights into the evolution of the LLMs’ applications highlighting their significance and limitations in shaping future healthcare.},
  keywords={Reviews;Large language models;Virtual assistants;Telemedicine;Surveillance;Bibliometrics;Medical services;healthcare;ChatGPT;large language models;artificial intelligence;deep learning;machine learning;LLMs;big data;data science;mathematics;applied artificial intelligence;XAI;natural-language programming;medical sciences;soft computing;applied machine learning;applied mathematics;applied informatics;generative artificial intelligence;generative AI},
  doi={10.1109/ICCC62278.2024.10582937},
  ISSN={},
  month={April},}@INPROCEEDINGS{10855050,
  author={Bento, Antonio Carlos and Lopez-Alvarez, Carlos Alberto and Rodriguez-Jaramillo, Johanna and Díaz-Bautista, Juan Carlos and Vanegas-Salamanca, Katherine},
  booktitle={2024 IEEE International Humanitarian Technologies Conference (IHTC)}, 
  title={Applied Case of IoT and Generative AI Integration in an Electric Vehicle Charging Station}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Electricity consumption is one of the main causes of climate change. Therefore, it is necessary to develop solutions that allow its use to be optimized. To this end, a prototype of a system for the efficient distribution of electric vehicle (EV) charging was developed, using Internet of Things (IoT) technologies, integrating sensors through a scalable infrastructure. The solution also addresses the challenge of reducing global transport emissions, which represent 13% of total emissions, and anticipates future technological advances, such as the adoption of autonomous vehicles. This platform not only responds to current energy needs, but also offers competitive advantages in the global market, contributing significantly to the fulfillment of the United Nations Sustainable Development Goal 7: Affordable and clean energy. The results present the feasibility of using it in a real system, contributing to global energy efficiency.},
  keywords={Green energy;Generative AI;Prototypes;Globalization;Electric vehicle charging;Sensor systems;Energy efficiency;Sensors;Internet of Things;Sustainable development;internet of things;artificial intelligence;electric vehicles (EV);higher education;professional education},
  doi={10.1109/IHTC61819.2024.10855050},
  ISSN={2837-4800},
  month={Nov},}@ARTICLE{10896740,
  author={Zhao, Runhui and Song, Huanhuan and Wen, Hong and Chen, Zhiwei and Hou, Wenjing and Feng, Xuewei},
  journal={IEEE Network}, 
  title={Wireless Security Enhancement Framework Based on AI and RIS in Industrial IoT Networks}, 
  year={2025},
  volume={39},
  number={4},
  pages={29-36},
  abstract={Reconfigurable Intelligent Surface (RIS) technology, closely integrated with Artificial Intelligence (AI) as one of the Physical Layer (PL) technology approaches, is considered an effective solution for enhancing security in industrial Internet of Things (IIoT) networks. Integrating RIS, AI, and heterogeneous IIoT networks presents a promising approach to improving the security of wireless communications in IIoT. This paper discusses new AI-based Physical Layer Authentication (PLA) approaches and how they can be integrated with RIS to enable identity authentication and malicious node detection, aiming to provide light-weight isolation in IIoT terminals. An anti-jamming and secure communication framework for IIoT is proposed, which leverages Deep Reinforcement Learning (DRL) and RIS to defend against malicious jamming and eavesdropping targeting legitimate users’ channels. Additionally, a foundational framework that employs Quantum Reinforcement Learning (QRL) is presented to improve RIS-assisted secure communication. Furthermore, the threats posed by Generative AI (GAI) to RIS-assisted IIoT communication networks and possible defense schemes are provided. Finally, the paper concludes by discussing research opportunities and future challenges.},
  keywords={Industrial Internet of Things;Artificial intelligence;Wireless communication;Security;Authentication;Physical layer;Feature extraction;Communication system security;Fingerprint recognition;Jamming;Reconfigurable intelligent surfaces;Physical layer authentication;Industrial internet of things (IIoT);Reconfigurable intelligent surface;Artificial intelligence},
  doi={10.1109/MNET.2025.3543829},
  ISSN={1558-156X},
  month={July},}@INPROCEEDINGS{9207717,
  author={Chen, Yingying and Hou, Xinwen},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, 
  title={An Improvement based on Wasserstein GAN for Alleviating Mode Collapsing}, 
  year={2020},
  volume={},
  number={},
  pages={1-7},
  abstract={In the past few years, Generative Adversarial Networks as a deep generative model has received more and more attention. Mode collapsing is one of the challenges in the study of Generative Adversarial Networks. In order to solve this problem, we deduce a new algorithm on the basis of Wasserstein GAN. We add a generated distribution entropy term to the objective function of generator net and maximize the entropy to increase the diversity of fake images. And then Stein Variational Gradient Descent algorithm is used for optimization. We named our method SW-GAN. In order to substantiate our theoretical analysis, we perform experiments on MNIST and CIFAR-10, and the results demonstrate superiority of our method.},
  keywords={Gallium nitride;Generators;Training;Entropy;Linear programming;Computational modeling;Generative adversarial networks},
  doi={10.1109/IJCNN48605.2020.9207717},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{11123923,
  author={Hardia, Shruti},
  booktitle={2025 IEEE 16th International Symposium on Autonomous Decentralized Systems (ISADS)}, 
  title={Synthetic Network Intelligence: Diffusion-Based Data Generation for Secure Communication Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={81-86},
  abstract={The scarcity of high-quality labeled network data poses a significant challenge for machine learning applications in cybersecurity and traffic analysis. This study presents a novel approach leveraging diffusion models to generate high-fidelity synthetic network traces, preserving critical structural and statistical properties of real-world traffic. By employing an optimized fine-tuning pipeline, controlled generation constraints, and automated post-processing techniques, the framework en-sures compliance with network protocols while enhancing model performance in classification tasks. Experimental evaluations demonstrate that the generated data achieves strong statistical alignment with real traces and serves as an effective augmentation tool for AI-driven network analysis. This research highlights the potential of generative AI in improving data availability for secure communications research.},
  keywords={Transport protocols;Training;Visualization;Technological innovation;Pipelines;Telecommunication traffic;Transformer cores;Diffusion models;Transformers;Synthetic data;machine learning;artificial intelligence;synthetic network intelligence;generative adversarial network;cybersecurity},
  doi={10.1109/ISADS66912.2025.00016},
  ISSN={2640-7485},
  month={July},}@INPROCEEDINGS{10889921,
  author={Zhou, Yingjie and Zhang, Zicheng and Wen, Farong and Jia, Jun and Jiang, Yanwei and Liu, Xiaohong and Min, Xiongkuo and Zhai, Guangtao},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={3DGCQA: A Quality Assessment Database for 3D AI-Generated Contents}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Although 3D generated content (3DGC) offers advantages in reducing production costs and accelerating design timelines, its quality often falls short when compared to 3D professionally generated content. Common quality issues frequently affect 3DGC, highlighting the importance of timely and effective quality assessment. Such evaluations not only ensure a higher standard of 3DGCs for end-users but also provide critical insights for advancing generative technologies. To address existing gaps in this domain, this paper introduces a novel 3DGC quality assessment dataset, 3DGCQA, built using 7 representative Text-to-3D generation methods. During the dataset’s construction, 50 fixed prompts are utilized to generate contents across all methods, resulting in the creation of 313 textured meshes that constitute the 3DGCQA dataset. The visualization intuitively reveals the presence of 6 common distortion categories in the generated 3DGCs. To further explore the quality of the 3DGCs, subjective quality assessment is conducted by evaluators, whose ratings reveal significant variation in quality across different generation methods. Additionally, several objective quality assessment algorithms are tested on the 3DGCQA dataset. The results expose limitations in the performance of existing algorithms and underscore the need for developing more specialized quality assessment methods. To provide a valuable resource for future research and development in 3D content generation and quality assessment, the dataset has been open-sourced in https://github.com/zyj-2000/3DGCQA.},
  keywords={Three-dimensional displays;Generative AI;Databases;Signal processing algorithms;Production;Data structures;Quality assessment;Speech processing;Standards;Research and development;Artificial Intelligence Generative Content;Quality Assessment Database;3D Quality Assessment},
  doi={10.1109/ICASSP49660.2025.10889921},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10487634,
  author={Yang, Shih-Yang and Qiu, Yu-Wei and Hung, Ling-Hsiang and Tasi, Ching-Hu},
  booktitle={2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE)}, 
  title={Automated Generation of Health Care Dynamic Recommendation Reports Through GPT-Powered Interoperability in Health Care IoT Environment}, 
  year={2023},
  volume={},
  number={},
  pages={261-265},
  abstract={Due to the global aging population and low birth rates, there is a growing emphasis on improving the living environment for the elderly. In Taiwan, the government has implemented a policy of long-term home care and introduced information and communication technology applications to increase care and services for the elderly. This study focuses on the use of physiological measurements as the main topic of investigation. The intuitive information provided by networked devices may be difficult for the elderly to understand and can be perceived as apathetic. Additionally, the elderly often has weaker information capabilities. Therefore, this study explores the innovative use of AI-generated technology combined with physiological measurements to provide feedback for elderly home care. Based on the development of artificial intelligence applications, machine learning technology has become a widespread information tool, generating multimedia-based care suggestions that are easy to understand and flexible.},
  keywords={Temperature measurement;Medical services;Transforms;Transformers;Data models;Internet of Things;Older adults;Generative pretrained transformer;Healthcare;Artificial intelligence;Internet of Things;Long-term care},
  doi={10.1109/CSCE60160.2023.00046},
  ISSN={},
  month={July},}@INPROCEEDINGS{11019832,
  author={Katurde, Atharva Digamber and Gharge, Samiksha Dnyaneshwar and Shinde, Bhakti Bharat and Kolapkar, Soham Vijay and Nakate, Ashwat Anant and Jadhav, Awantika Anil},
  booktitle={2025 International Conference on Computing and Communication Technologies (ICCCT)}, 
  title={Enhancing Recommendations with Adaptive Multi-Modal Generative Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Recommender systems play a critical role in personalizing content, but integrating multiple data modalities and addressing dynamic user preferences presents significant challenges. This paper introduces the Adaptive Multi-Modal Generative Recommender (AMGR) framework, which combines text, image, and video data to enhance recommendation accuracy. By leveraging advanced generative models such as GANs, VAEs, and transformers, AMGR not only suggests content based on user history but also generates personalized content that aligns with evolving preferences. To address the complexities of real-time adaptation, AMGR utilizes reinforcement learning strategies, balancing exploration and exploitation of content. The framework also tackles key technical and ethical challenges, including computational efficiency, multi-modal data fusion, fairness, and privacy. Potential solutions such as federated learning and bias mitigation techniques are explored to ensure responsible and scalable deployment. This paper outlines the proposed methodology, its applications, and the necessary safeguards for AMGR's real-world implementation, contributing to the development of adaptive, fair, and transparent recommendation systems.},
  keywords={Ethics;Adaptation models;Adaptive systems;Accuracy;Scalability;Data integration;Streaming media;Transformers;Real-time systems;Recommender systems;Recommender Systems;Generative AI;Adaptive Multi-Modal Generative Recommender (AMGR);Personalized Recommendations;Multi-Modal Data Fusion;Cold-Start Problem;Real-Time Adaptation;Ethical AI},
  doi={10.1109/ICCCT63501.2025.11019832},
  ISSN={2995-3197},
  month={April},}@INPROCEEDINGS{11063942,
  author={Wei, Yanghui and Yu, Songsen and Su, Hai and Jian, Zhenwen},
  booktitle={2025 5th International Conference on Neural Networks, Information and Communication Engineering (NNICE)}, 
  title={Regionally Allocation Loss Weights for Image Super-Resolution}, 
  year={2025},
  volume={},
  number={},
  pages={329-332},
  abstract={The single-image super-resolution (SISR) task aims to reconstruct low-resolution (LR) images into larger super-resolution (SR) images. Since the LR image is lack a large amount of information compared to the high-resolution (HR) images as the labelled data, the reconstructed SR image is unsatisfactory in terms of perceptual quality and the peak signal-to-noise ratio (PSNR). In the meanwhile, we find that the reconstruction effect of the SR image is inversely proportional to the pixel frequency (i.e., the gradient of change of this pixel from the surrounding pixels) in images. In order to address this issue, this paper proposes a new SISR framework that is conditioned on the down-sampling gradient map (DSDM) of the HR image, which is fed into the adversarial generative network and participates in the modulation process of the network parameters; on the other hand, we use the DSDM to guide the assignment of weights to the combination of the model's loss functions. Experimental results on a benchmark test set show that the proposed method outperforms the current state-of-the-art SR methods in terms of PSNR, LPIPS and other metrics. Qualitative visual results also prove the effectiveness of our method.},
  keywords={Measurement;Hands;Visualization;PSNR;Superresolution;Modulation;Benchmark testing;Cognition;Resource management;Image reconstruction;Single-Image Super-Resolutio;Information Loss;Condition Network;Weights Distribution},
  doi={10.1109/NNICE64954.2025.11063942},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{11024260,
  author={Chen, Xiang},
  booktitle={2025 IEEE/ACM 47th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)}, 
  title={Exploring GenAI-Driven Innovation in Game Development}, 
  year={2025},
  volume={},
  number={},
  pages={157-159},
  abstract={The game industry, now generating over $200 billion annually, has become a major force in entertainment, yet game development remains underexplored in software engineering research. Generative AI (GenAI) has introduced new opportunities for content automation in game development, offering benefits in testing, design, and player engagement. However, integrating GenAI across game development phases presents unique technical, creative, and collaborative challenges. This study aims to develop an adaptable framework that addresses these challenges by providing practical insights and strategies to enhance collaboration, creativity, and efficiency. Using a mixed-methods approach, including open-source analysis and developer surveys and interviews, we will construct a grounded theory on GenAI adoption. The insights will inform a framework refined with industry feedback, contributing datasets, guidelines, and tools to support sustainable GenAI integration in game development.},
  keywords={Surveys;Technological innovation;Generative AI;Collaboration;Games;Interviews;Open source software;Software engineering;Testing;Guidelines;Generative AI;Game Development;Mining Software Repositories;Empirical Studies;Artificial Intelligence;Open Source;Software Engineering},
  doi={10.1109/ICSE-Companion66252.2025.00046},
  ISSN={2574-1934},
  month={April},}@ARTICLE{9762281,
  author={Zhu, Chen and Xu, Jun and Feng, Donghui and Xie, Rong and Song, Li},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Edge-Based Video Compression Texture Synthesis Using Generative Adversarial Network}, 
  year={2022},
  volume={32},
  number={10},
  pages={7061-7076},
  abstract={It has been recognized that texture patterns with abundant high-frequency components, such as grass and water, produce visual masking effects, and the distortion in textures is hard to be perceived by human eyes than structure regions. However, modern video codecs in a rate-distortion optimized manner usually consume a lot of bits to encode textures, leading to the insufficiency in perceptual coding performance. Nowadays, with the rapid development of deep learning, learning based texture synthesis methods have been proposed to replace the coding process of prediction residuals to reduce the rate cost. In this paper, we present a deep texture synthesizer named edge-based texture synthesis framework (ETSF). At encoder side, the framework detects texture regions by semantic and fidelity classification criteria, and the detected regions are quantized coarsely by the hybrid coding framework. In texture characterization, ETSF extracts low-level edge features representing pixel intensity variation. Feature processing tools are developed to remove the spatiotemporal redundancy of edges. The processed edge information is compressed and transmitted. To effectively recover textures, we design an edge-based texture synthesis generative adversarial network (ETSGAN) at the decoder of ETSF, which can incorporate edge information into convolutional layers and generate realistic textures. Experimental results on a collected texture dataset show that the proposed ETSF can achieve an average of -12.8%, -14.2% and -9.6% MOS BD-rate under lowdelay_B, lowdelay_P and random_access configurations of VVC coding, respectively.},
  keywords={Feature extraction;Image edge detection;Encoding;Video compression;Generative adversarial networks;Visualization;Streaming media;Video coding;texture synthesis;edge;generative adversarial network},
  doi={10.1109/TCSVT.2022.3169951},
  ISSN={1558-2205},
  month={Oct},}@ARTICLE{10035924,
  author={Li, Junwu and Li, Binhua and Jiang, Yaoxi and Tian, Longwei and Cai, Weiwei},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={MrFDDGAN: Multireceptive Field Feature Transfer and Dual Discriminator-Driven Generative Adversarial Network for Infrared and Color Visible Image Fusion}, 
  year={2023},
  volume={72},
  number={},
  pages={1-28},
  abstract={Most of the previous infrared and visible image fusion methods based on deep learning were on the basis of gray-scale images and used the single convolution kernel receptive field to extract deep features, which would inevitably cause information loss in the process of feature transfer. Accordingly, this article proposes a new generative adversarial network fusion architecture based on multireceptive field feature transfer and dual discriminator, which is named MrFDDGAN. It is applied to infrared and color visible image fusion. First, three different receptive fields are used to extract multiscale and multilevel deep features of multimodal images on three channels, so as to obtain significant features of source images from multiview and multiperspective in a more comprehensive way. Second, a feature interaction module is introduced in the encoder to realize the information interaction and information prefusion among the three feature channels. Third, the multilevel features fused in the encoder are cascaded with the deep features in the decoder to enhance feature transfer and feature reuse. Finally, this experiment adopts a dual discriminator adversarial network structure to keep the balance of infrared image intensity and visible image texture preserved by fusion results. Qualitative and quantitative experimental analyses are carried out on two public datasets of gray-scale infrared and visible images, and one dataset of infrared and color visible images. The experimental results prove that the proposed MrFDDGAN algorithm has a better subjective visual effect and objective performance than the existing state-of-the-art fusion methods.},
  keywords={Feature extraction;Image fusion;Generative adversarial networks;Kernel;Data mining;Task analysis;Generators;Dual discriminator generative adversarial network (GAN);feature interaction;feature reuse;infrared and color visible image fusion;MrFDDGAN;multireceptive field feature transfer},
  doi={10.1109/TIM.2023.3241999},
  ISSN={1557-9662},
  month={},}@ARTICLE{10082975,
  author={Zhang, Chuanfang and Peng, Kaixiang and Dong, Jie and Zhang, Xueyi and Yang, Kaixuan},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={A Robust Fault Classification Method for Streaming Industrial Data Based on Wasserstein Generative Adversarial Network and Semi-Supervised Ladder Network}, 
  year={2023},
  volume={72},
  number={},
  pages={1-9},
  abstract={With the development of modern information technology, the collection, storage, and transmission of information in the process industry have been gaining popularity. However, the massive streaming industrial data obtained in real time have some nonideal characteristics, such as lack of labels and missing values, which greatly increase the difficulty of process monitoring in process industry. Therefore, a robust semi-supervised fault classification method is proposed in this article. First, Wasserstein generative adversarial network (WGAN) and enhanced minimal gated unit (EMGU) are integrated to complete the missing data imputation of the incomplete unlabeled streaming industrial data, and then a semi-supervised ladder network (SLN) is trained with the imputed unlabeled data and complete labeled data for fault classification. A case study on the hot rolling process (HRP) demonstrates that the proposed method shows outstanding modeling and classification performance in lack of labeled data and missing data, compared with the other state-of-art deep learning methods.},
  keywords={Logic gates;Generative adversarial networks;Noise reduction;Industries;Cost function;Training;Supervised learning;Enhanced minimal gated unit (EMGU);robust fault classification;semi-supervised ladder network (SLN);streaming industrial data;Wasserstein generative adversarial network (WGAN)},
  doi={10.1109/TIM.2023.3262249},
  ISSN={1557-9662},
  month={},}@ARTICLE{10947471,
  author={Gaber, Tarek and Ali, Tarek and Nicho, Mathew and Torky, Mohamed},
  journal={IEEE Internet of Things Journal}, 
  title={Robust Attacks Detection Model for Internet of Flying Things Based on Generative Adversarial Network (GAN) and Adversarial Training}, 
  year={2025},
  volume={12},
  number={13},
  pages={23961-23974},
  abstract={The Internet of Flying Things (IoFT) holds significant promise in fields like disaster management and surveillance. However, it is increasingly vulnerable to cyberattacks that can compromise the confidentiality, integrity, and availability (CIA) of sensitive data. Despite the growing interest in proposing intrusion detection systems (IDSs) for IoFT networks, current literature faces key limitations, particularly the shortage of publicly available IoFT datasets with diverse attacks, and the fact that existing IDSs lack robustness against sophisticated adversarial machine learning (ML) attacks. This article is the first study to address these limitations by proposing a more resilient and accurate IDS tailored for IoFT networks (RIDS-IoFT). We introduce a novel IDS that leverages generative adversarial networks (GANs) to generate a hybrid dataset that combines real IoFT traffic data with GAN-generated adversarial attacks, addressing the dataset diversity issue. Additionally, we introduce an innovative adversarial training method to enhance the system’s defense against evolving threats, such as fast gradient sign method (FGSM), basic iterative method (BIM), and Carlini & Wagner (C&W) attacks. The proposed RIDS-IoFT was evaluated using four ML models, random forest (RF), decision tree (DT), support vector machine (SVM), and logistic regression (LR), on two datasets: 1) ECU-IoFT and 2) CICIDS2018. The IDS’s performance was assessed based on its ability to detect both traditional and adversarial attacks. The results show that the RF model achieved the highest detection accuracy, up to 96.5%, demonstrating superior performance across both real and hybrid datasets. The proposed RIDS-IoFT not only enhances detection accuracy but also strengthens resilience against adversarial threats, making it suitable for resource-constrained IoFT environments. In conclusion, this study presents a comprehensive approach to securing IoFT networks by combining real and synthetic data, improving IDS robustness and accuracy against both traditional and adversarial attacks.},
  keywords={Drones;Computer crime;Training;Generative adversarial networks;Autonomous aerial vehicles;Internet of Things;Accuracy;Wireless fidelity;Synthetic data;Support vector machines;Attacks detection drones;drones;generative adversarial network (GAN);Internet of Flying Things (IoFT);machine learning (ML)},
  doi={10.1109/JIOT.2025.3555202},
  ISSN={2327-4662},
  month={July},}@INPROCEEDINGS{9722634,
  author={Byun, Yunseon and Baek, Jun-Geol},
  booktitle={2022 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Image Synthesis with Single-type Patterns for Mixed-type Pattern Recognition on Wafer Bin Maps}, 
  year={2022},
  volume={},
  number={},
  pages={039-043},
  abstract={To increase the productivity, it is important to manage yield and reduce defects in the semiconductor industry. One of the efforts is to identify defect patterns and control the cause factors that affects the defects. Many engineers inspect the quality of each chip and check the defect pattern on the wafer bin maps. To get the accurate and consistent classification results regardless of the level for domain knowledge or experience of engineers, deep learning-based models have recently been studied. Since most previous studies aim to classify the single-type defect patterns, it is needed to consider the mixed-type defect patterns together. Also, they require a lot of labeled data to train the deep learning-based classification model. However, defects occur extremely rarely in actual manufacturing process. Therefore, the method securing the higher accuracy in a situation where enough labeled data are not given is needed. This paper proposes a deep convolutional generative adversarial network for wafer map synthesis (DCGAN-WS) which generates the mixed-type patterns by synthesizing the single-type pattern and adding the pixel-wise summation. To maintain the characteristics of the binary pixel of the wafer bin maps, a thresholding technique is added. MixedWM38 dataset is used for the experiments, and it was verified that the mixed-type patterns were synthesized well. It helps to construct more robust model for single-type pattern classification and to generate the mixed-type patterns that have not occurred before. In the future, it is expected that this model addresses the problem of the lack of labeled data for defect pattern classification models.},
  keywords={Semiconductor device modeling;Productivity;Knowledge engineering;Manufacturing processes;Image synthesis;Pattern classification;Semiconductor device manufacture;wafer bin maps;image synthesis;pattern classification;generative adversarial network},
  doi={10.1109/ICAIIC54071.2022.9722634},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{8771623,
  author={Wang, Chia-Ching and Liu, Hsin-Hua and Pei, Soo-Chang and Liu, Kuan-Hsien and Liu, Tsung-Jung},
  booktitle={2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS)}, 
  title={Modern Architecture Style Transfer for Ruin Buildings}, 
  year={2019},
  volume={},
  number={},
  pages={293-294},
  abstract={In this work, we focus on building style transfer, which transforms ruin buildings to modern architecture. Inspired by Gaty's and Goodfellow's style transfer and generative adversarial network (GAN), we use CycleGAN to conquer this type of problem. To avoid the artifacts and generate better images, we add “perception loss” into the network, which is the feature loss extracted by VGG pre-trained model. We also adjust cycle loss by changing the ratio of weighting parameters. Finally, we collect images of both ruin and modern architecture from websites and use unsupervised learning to train the model. The experimental results show our proposed method indeed realize the modern architecture style transfer for ruin buildings.},
  keywords={Architecture;Computer architecture;Generators;Buildings;Conferences;Feature extraction;Training;cycle loss;generative adversarial network (GAN);modern architecture;perception loss;style transfer},
  doi={10.1109/AICAS.2019.8771623},
  ISSN={},
  month={March},}@INPROCEEDINGS{9137462,
  author={Jiang, Luyao and Hao, Yu},
  booktitle={2020 3rd International Conference on Artificial Intelligence and Big Data (ICAIBD)}, 
  title={Applying Machine Learning to Predict Film Daily Audience Data: System and Dataset}, 
  year={2020},
  volume={},
  number={},
  pages={11-16},
  abstract={Audience data is highly correlated with the levels of film viewership, as they can impact on people’s perceptions of films, resulting in whether or not they would watch a film or even recommend to others. Hence, if audience data can be properly analyzed, they can provide important clue to help predicting the trend of daily film statistics, such as box office, attendance rate, etc., which would further help cinemas to make wise marketing decisions. Motivated by this, we propose a novel audience data prediction system based on the recent advance of deep learning. Our approach begins with applying Fourier Transform-based algorithm to encode multi-channel time-series audience data into a set of feature maps. Then, these feature maps are fed to Generative Adversarial Networks (GANs) to predict and generate future audience data. To evaluate the proposed approach, we collected a dataset consisting of 200 films across three years (2017, 2018 and 2019), where 15 different daily attributes of 30 days are provided for each film. To help potential research of other researchers, we made it available online. The experiment results illustrated the superior performance of our algorithm in comparison to the baseline.},
  keywords={Deep learning;Machine learning algorithms;Correlation;Heuristic algorithms;Transforms;Prediction algorithms;Market research;Film audience data analysis;Generative Adversarial Networks;Fourier Transform},
  doi={10.1109/ICAIBD49809.2020.9137462},
  ISSN={},
  month={May},}@INPROCEEDINGS{9338894,
  author={Cheng, Guojian and Zhang, Fulin and Qiang, Xinjian},
  booktitle={2020 IEEE 9th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={Super-resolution Reconstruction of Rock Thin-Section Image based on SinGAN}, 
  year={2020},
  volume={9},
  number={},
  pages={786-790},
  abstract={The rock thin section images are of great significance to the study of petroleum geological characteristics and oil and gas exploration. Due to the limitations of various factors, the obtained images of rock thin-sections often have low resolution, which limits the researchers' grasp of their detailed information to some extent. The traditional super-resolution algorithm of neural network will need a large amount of data as a training set, in order to improve rock thin-section image super-resolution reconstruction algorithm texture detail information reduction ability, the paper using single image generative adversarial network for rock thin-section image super-resolution reconstruction, does not need to input a large number of data sets, of single image super-resolution reconstruction image. Rock cast thin section images from an oil field area in Ordos basin were used for training, and peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) evaluation indexes were used for model evaluation. The experimental results show that the super-resolution image processing based on this method has good visual effects and evaluation indexes.},
  keywords={Training;PSNR;Oils;Superresolution;Rocks;Indexes;Image reconstruction;rock thin-section image;neural network;superresolution reconstruction;single image generative confrontatio n network},
  doi={10.1109/ITAIC49862.2020.9338894},
  ISSN={2693-2865},
  month={Dec},}@INPROCEEDINGS{9719245,
  author={Zhang, YuXia and Che, Jin and He, YuTing},
  booktitle={2021 International Conference on Computer Information Science and Artificial Intelligence (CISAI)}, 
  title={Research on Person Re-identification Based on Pose-Attention-GAN}, 
  year={2021},
  volume={},
  number={},
  pages={261-267},
  abstract={Person re-identification (reID) is a challenging task, with the purpose of matching pedestrian images with the same identity across multiple cameras. With the wide usage of deep learning methods, reID performances by different algorithms increase rapidly. However, in the presence of large pose variations, it faces two major challenges: the lack of cross-view paired training data and learning discriminative identity-sensitive and view-invariant features. To solve the above challenges, this paper proposes an image generation and classification framework for pedestrian arbitrary pose based on the combination of Pose-attention-Generative Adversarial Network(PAGAN) and Resnet50 network. Firstly, the human pose network is used to extract the pose corresponding to the pedestrian image, and the generator and discriminator of the PAGAN network are trained with the pedestrian image and its pose. The generator of the network comprises 9 pose attention transfer blocks that each transfers certain regions it attends to, generating arbitrary pose and high-quality fake images progressively, and discriminator distinguishes whether the input image is real or not. Secondly, the fake images of arbitrary pose are increased as training samples. Finally, the expanded training set is used to train the classification and recognition network to learn features related to identity but not pose, effectively improving the generalization ability of the model. The Rank-1/mAP on the Market1501 and DukeMTMC-reID datasets reach 94.1%/85.2% and 84.7%/72.2% respectively. Experimental results show that the proposed algorithm has certain advantages.},
  keywords={Training;Information science;Image synthesis;Computational modeling;Training data;Generators;Robustness;Person re-identification;generative adversarial network;pose attention;identity feature;pose feature},
  doi={10.1109/CISAI54367.2021.00056},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10403117,
  author={Huang, Xikun and Li, Yangyang and Fei, Chaoqun and Wang, Chuanqing},
  booktitle={2023 IEEE International Conference on Medical Artificial Intelligence (MedAI)}, 
  title={Graph Generation with Recurrent and Graph Neural Networks}, 
  year={2023},
  volume={},
  number={},
  pages={203-208},
  abstract={Graph generation has applications as diverse as drug discovery, materials design, and code completion. In this paper, we propose a novel auto-regressive graph generation model, where graph generation is viewed as a decision process. The proposed model combines the power of graph neural networks (GNNs) with generative modeling techniques, and incorporates both graph topology and node features, allowing the generation of graphs with desired properties. Extensive experiments on molecule datasets demonstrate the effectiveness of our approach, achieving high validity, diversity, and similarity to the target molecules.},
  keywords={Drugs;Network topology;Graph neural networks;Space exploration;Topology;Zinc;Chemicals;graph generative model;graph neural networks;recurrent neural networks;auto-regressive;molecular generation},
  doi={10.1109/MedAI59581.2023.00033},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9459093,
  author={Cao, Pin and Zhang, Jie and Zou, Peng and Li, Donglin and Li, Wuchang and Zhong, Chengli and Ma, Lei and Cui, He},
  booktitle={2021 4th International Conference on Artificial Intelligence and Big Data (ICAIBD)}, 
  title={Removal of Rain Streaks in Air Using GAN}, 
  year={2021},
  volume={},
  number={},
  pages={589-593},
  abstract={Rain streaks in the air can be harmful for the image quality, which makes photograph blur and unaesthetic. Pictures with rain streaks are also bad resource for target detection and recognition. Therefore, we promote a method to remove rain streaks based on generative adversarial networks. We find that the rain streaks exit mainly in high-frequency component of a picture. Therefore, our work focuses on the part contains the rain streaks and avoid affecting details and color information of the picture. We also introduced a quantization method to improve network to make it thinner. Based on experiment, rains in the picture are removed effectively. Images after processing are cleaner than the original ones.},
  keywords={Image quality;Rain;Quantization (signal);Target recognition;Image color analysis;Object detection;Big Data;rainstreak removal;generative adversarial network;quantilization;YUV conversion},
  doi={10.1109/ICAIBD51990.2021.9459093},
  ISSN={},
  month={May},}@INPROCEEDINGS{10748268,
  author={Wang, Xiaoxia and Li, Leixiao},
  booktitle={2024 3rd International Conference on Artificial Intelligence, Internet of Things and Cloud Computing Technology (AIoTC)}, 
  title={Improvement of SMOTE Based on Graph Neighborhood Structure and Latent Feature Learning and Its Application}, 
  year={2024},
  volume={},
  number={},
  pages={367-370},
  abstract={The SMOTE algorithm is a classical method for addressing imbalanced classification problems. In this paper, we improves the SMOTE algorithm by incorporating ideas from transfer learning. Initially, a k-nearest neighbor (kNN) graph of minority class samples is constructed to capture the structural relationships between samples. The graph convolutional network (GCN) is then employed to model the adjacency matrix and sample features jointly, generating node feature representations that include neighborhood information. These are used to generate samples in the first phase within the feature space; Subsequently, the generated samples are input into an Autoencoder-Generative Adversarial Network (AE-GAN) for a second phase of sample regeneration. The AE component extracts latent features to enhance the learning of features in the generated samples. The samples generated through these two phases are made closer to the real sample distribution. Finally, results on five imbalanced datasets indicate that the proposed method achieves the best classification performance, validating the effectiveness of the algorithm.},
  keywords={Representation learning;Computers;Graph convolutional networks;Transfer learning;Nearest neighbor methods;Feature extraction;Data models;Classification algorithms;Internet of Things;Faces;Data imbalance;two-stage generate model;sample enhancement;SMOTE;Autoencoder;Generative Adversarial Networks},
  doi={10.1109/AIoTC63215.2024.10748268},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10551033,
  author={Hu, Bing and Liu, Jin and Xi, Zhengjie and Li, Xingye},
  booktitle={2023 4th International Conference on Computer, Big Data and Artificial Intelligence (ICCBD+AI)}, 
  title={Adaptive Latent Distribution Margin GAN for Imbalanced Data Classification}, 
  year={2023},
  volume={},
  number={},
  pages={100-104},
  abstract={Facial Expression Recognition (FER) has achieved significant development as a result of the development of deep learning. However, the constrained size of FER datasets constrains the generalization capability of expression recognition models, resulting in suboptimal model performance. In addition, the currently available training datasets for FER suffer from imbalances that give preference to certain majority classes, resulting in diminished test accuracy specifically for the minority classes. In this paper, we propose a Adaptive Latent Distribution Margin Generative Adversarial Network (ALDMGAN). It employs a distinct latent distribution model for each class, facilitating a clear demarcation between minority and majority classes. In addition, we propose a objective function that minimizes the distribution disparity between classes, resulting in a closer proximity of their latent distributions. Extensive experiments have demonstrated that ALDMGAN substantially enhances the classification accuracy of unbalanced data.},
  keywords={Training;Deep learning;Adaptation models;Adaptive systems;Face recognition;System performance;Big Data;facial expression recognition;generative adversarial nets;imbalanced data},
  doi={10.1109/ICCBD-AI62252.2023.00025},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10104408,
  author={Li, Jiaxin and Sun, Lei and Mao, Xiuqing and Liu, Lei},
  booktitle={CAIBDA 2022; 2nd International Conference on Artificial Intelligence, Big Data and Algorithms}, 
  title={Data Generation Methods of Generative Adversarial Networks Based on Exponential Adaptive Pool}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={In the case of small sample training, the extraction of image features is crucial to the quality of generated images in Generative Adversarial Network (GAN). To ensure it, convolution and pooling are often used to increase the depth of the network, while inevitably lead to the loss of features. To address the problem above, this paper proposes an innovative model of GAN named EAP-GAN based on exponential adaptive pool. To further improve the stability of training process and the quality of generated images, exponential adaptive pool is introduced to replace the average pooling originally, which calculates the kernel weights in two ways: the distance from the centre vector and the size of neighbouring pixel values in the kernel region and then adaptively fuses the feature maps obtained in these two ways by means of the learnable parameter beta, thus presevering the image details more effectively. Finally, the EAP-FastGAN model is verified to outperform the original FastGAN model by visualizing loss functions and comparing the values of FID (a classical quantitative method) on four datasets, namely Panda, Anime, Dog and Obama.},
  keywords={},
  doi={},
  ISSN={},
  month={June},}@INPROCEEDINGS{10882455,
  author={R, Harshini and N, Prameela Kumari},
  booktitle={2024 International Conference on Artificial Intelligence and Quantum Computation-Based Sensor Application (ICAIQSA)}, 
  title={A Comprehensive Study on Deep Learning Techniques used for SAR and Optical Image Registration}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In this paper reviews recent advancements in deep learning-based remote sensing image processing, focusing on image registration, classification, and segmentation. Remote sensing faces challenges due to geometric, radiometric, and spectral differences between various imaging modalities like Synthetic Aperture Radar (SAR) and optical images. Traditional methods struggle with these discrepancies, especially in multimodal datasets. Recent deep learning techniques, such as Convolutional Neural Networks (CNNs) and Generative Adversarial Networks (GANs), have significantly improved accuracy in image alignment, feature extraction, and data fusion. This review synthesizes key studies that address these challenges and highlights future research opportunities to enhance remote sensing applications through deep learning models.},
  keywords={Deep learning;Integrated optics;Image registration;Accuracy;Optical distortion;Optical imaging;Adaptive optics;Optical sensors;Remote sensing;Synthetic aperture radar;Remote sensing;Deep learning;Image registration;Image classification;Image segmentation;Synthetic Aperture Radar (SAR);Optical images;Convolutional Neural Networks (CNNs);Generative Adversarial Networks (GANs);Multimodal data;Radiometric discrepancies;Geometric distortions},
  doi={10.1109/ICAIQSA64000.2024.10882455},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11135806,
  author={Wei, Zhicheng and Huang, Weijie and Liu, Shuhao and Li, Xingyu and Cheng, Bingxuan and Zhang, Menghua},
  booktitle={2025 International Conference on Mechatronics, Robotics, and Artificial Intelligence (MRAI)}, 
  title={CT-MR Synthesis of Medical Images based on Transformer Fusion}, 
  year={2025},
  volume={},
  number={},
  pages={193-196},
  abstract={In medical imaging, acquiring MR scans is costly and time-consuming, prompting interest in synthesizing MR images from CT using deep learning. To address issues such as detail loss and structural inconsistency in existing methods, we propose a generative adversarial framework incorporating a High-Frequency Feature Mask Fusion Transformer (HF Transformer) for CT-to-MR translation. A high-pass filter is applied to the CT input to extract edge-enhanced features, which, along with the original CT image, are processed through parallel encoders. The extracted features are fused via the HF Transformer and decoded to generate the MR image. Experimental results show that our method outperforms baseline models in MAE, PSNR, and SSIM, and better preserves bone marrow signals and key structures like the lumbar vertebral plate.},
  keywords={Deep learning;Translation;Mechatronics;Computed tomography;Image edge detection;Transformers;Feature extraction;High frequency;Robots;Biomedical imaging;Adversarial Generative Networks;CT to MR;High Frequency Information;Transformer fusion},
  doi={10.1109/MRAI65197.2025.11135806},
  ISSN={},
  month={June},}@INPROCEEDINGS{10786696,
  author={Kontogianni, Aristea and Alepis, Efthimios},
  booktitle={2024 15th International Conference on Information, Intelligence, Systems & Applications (IISA)}, 
  title={AI in Smart Tourism: LLMs & GPTs Leading the Way}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={The rise of Artificial Intelligence (AI) has dramatically transformed various industries, including healthcare, finance, education, and transportation, with Large Language Models (LLMs) playing a pivotal role in this evolution. In the realm of Smart Tourism, LLMs, including Generative Pre-trained Transformers (GPTs), have demonstrated significant potential, providing innovative solutions to enhance tourist experiences and streamline industry operations. This paper provides an overview of the LLMs currently available in the market, with a specific focus on the GPT models in the context of Smart Tourism. It examines their performance, datasets, and potential applications within this sector. The study analyzes the data utilized by these models and their interaction with travelers, emphasizing the need for diverse training data to enhance the cultural and contextual relevance of GPT responses. This concise study offers a comprehensive understanding of the transformative potential of LLMs and GPTs in Smart Tourism, providing valuable insights for researchers and industry professionals and serving as a stepping stone for further research in the field.},
  keywords={Tourism industry;Transportation;Training data;Transforms;Transformers;Data models;Real-time systems;Recommender systems;Context modeling;Testing;smart tourism;LLMs;GPTs;ChatGPT},
  doi={10.1109/IISA62523.2024.10786696},
  ISSN={},
  month={July},}@INPROCEEDINGS{10164924,
  author={Lu, Yurong and Huang, Xianglin and Zhai, Yan and Yang, Lifang and Wang, Yirui},
  booktitle={2023 IEEE 3rd International Conference on Information Technology, Big Data and Artificial Intelligence (ICIBA)}, 
  title={ColorGAN: Automatic Image Colorization with GAN}, 
  year={2023},
  volume={3},
  number={},
  pages={212-218},
  abstract={Colorization has attracted increasing interest in recent years. However, image colorization is an ill-posed problem with multi-modal correct solutions and they still suffer problems of context confusion and object-edge color bleeding. In this paper, we proposed the Color-GAN, a novel auto adversarial learning colorization methods coupled with channel and spatial attention based on residual structure enhanced by feature extractor and skip-connection. Our network learns colorizing in the method of combining perceptual and semantic understanding of color with class distributions. Experimental results show that our network outperformers existing methods on different quality metrics, meanwhile generates state-of-the-art performance on auto image colorization.},
  keywords={Measurement;Visualization;Image color analysis;Semantics;Big Data;Feature extraction;Generative adversarial networks;image colorization;gan;attention;skip-connection},
  doi={10.1109/ICIBA56860.2023.10164924},
  ISSN={},
  month={May},}@INPROCEEDINGS{8669076,
  author={Min, Tae-Hong and Kim, Do-Yun and Choi, Young-June},
  booktitle={2019 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Improving Learning time in Unsupervised Image-to-Image Translation}, 
  year={2019},
  volume={},
  number={},
  pages={455-458},
  abstract={Unsupervised image-to-image translation can map local textures between two domains, but typically fails when the domain requires big shape changes. It is difficult to learn how to make such big change using the basic convolution layer, and furthermore it takes much time to learn. For faster learning and high-quality image generation, we propose to use Cycle GAN that is combined with Resnet in a network that is connected with the residual block for upsampling to make big shape change and construct faster image-to-image translation.},
  keywords={Generators;Gallium nitride;Generative adversarial networks;Shape;Image quality;Decoding;Image generation;GAN;CNN;deep learning;DiscoGAN},
  doi={10.1109/ICAIIC.2019.8669076},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10098013,
  author={Vargas, Kevin Ian Ruiz and Pena, Fidel Alejandro Guerrero and Fernandez, Pedro Diamel Marrero and Lanfranchi, Leonardo and Tsang, Ing Jyh and Ren, Tsang Ing},
  booktitle={2022 IEEE 34th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={U-Net Based Discriminator for Real-World Super-Resolution}, 
  year={2022},
  volume={},
  number={},
  pages={873-880},
  abstract={In recent years, single image super-resolution (SISR) deep learning techniques have achieved remarkable improvements in recovering a high-resolution (HR) image from an observed low-resolution (LR) input. Nevertheless, these proposed methods fail in many real-world scenarios since their models are usually trained using a pre-defined degradation process from HR ground truth images to LR ones. To address this issue, new architectures have been proposed focusing on adopting more complicated degradation models to emulate real-world degradation achieving prominent performance but still limited to certain kinds of inputs and dropping considerably in other cases. In this paper, we present a GAN structure for blind super-resolution tasks, applying a technique that has not been very commonly used in SISR proposals: a U-Net architecture as a discriminator of the GAN network. Adding this structural change will encourage the discriminator to focus more on semantic and structural changes between real and fake images and to attend less to domain-preserving perturbations. In addition, the loss function of the generator was modified by adding the LPIPS loss function for the perceptual loss and a per-pixel consistency regularization technique based on the CutMix data augmentation. Numerous novel solutions that have been proposed recently involve powerful deep learning techniques. The proposed model was trained using the DF2K dataset employing a degradation framework for real-world images by estimating blur kernels and real noise distributions to obtain more realistic LR samples. Finally, we present a benchmark comparing our results with other methods in the state-of-the-art. The commonly-used evaluation metrics for image restoration PSNR, SSIM, and LPIPS were used for this evaluation.},
  keywords={Degradation;Measurement;Deep learning;Training;Superresolution;Generative adversarial networks;Generators;Deep Learning;Degradation Modeling;Image Super-Resolution;Loss Functions;U-Net Discriminator},
  doi={10.1109/ICTAI56018.2022.00134},
  ISSN={2375-0197},
  month={Oct},}@ARTICLE{11089958,
  author={Liu, Qiang and Wang, Yuxin and Yang, Chao and An, Jialin and Cheung, Yiu-ming},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Frequency-Domain Feature Reconstruction Network with Memory Units for Anomaly Detection of Fused Magnesium Furnaces}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={Anomaly detection of smelting process benefits the operation safety of fused magnesium furnaces (FMFs). While generative models that fit well complex data distributions in the latent space offer an effective way to anomaly detection, conventional generative models have difficulties in adapting to visual interferences such as dynamic water mist, dust, and on-site lighting changes. To this end, this paper establishes a new frequency-domain feature reconstruction network with memory units for anomaly detection of fused magnesium furnaces. This network utilizes high-frequency filtering to extract features in the frequency domain to suppress the adverse effects of brightness variations caused by fluctuations in the furnace flame. Using the extracted frequency domain features, wavelet sampling is integrated with memory units for reconstruction to eliminate interferences in the frequency domain while preserving anomalous features, thereby alleviating overgeneralization. Moreover, a new adaptive threshold calculation method is proposed for the anomaly detection of FMFs. Finally, the effectiveness of the proposed method is demonstrated by using the image collected from a real FMF.},
  keywords={Anomaly detection;Furnaces;Feature extraction;Image reconstruction;Frequency-domain analysis;Fires;Smelting;Magnesium;Temperature sensors;Temperature measurement;Anomaly detection;generative model;fused magnesium furnace (FMF)},
  doi={10.1109/TAI.2025.3591089},
  ISSN={2691-4581},
  month={},}@INPROCEEDINGS{11158361,
  author={Lin, Jie and Lin, Jing and Luo, Xin},
  booktitle={2025 5th International Conference on Artificial Intelligence and Education (ICAIE)}, 
  title={Barriers to Generative AI Adoption Among Higher Vocational Students: Understanding Hesitancy and Resistance}, 
  year={2025},
  volume={},
  number={},
  pages={504-508},
  abstract={Generative Artificial Intelligence (Gen AI) presents transformative opportunities for educational environments, yet adoption within higher vocational education remains constrained by multifaceted barriers. While existing research has explored Gen AI applications across educational domains, limited attention has focused on understanding adoption hesitancy among higher vocational students who face unique considerations regarding practical skill development and workplace preparation. This study employed a quantitative approach using a cross-sectional survey of 312 vocational students across three colleges in China, examining concerns related to academic integrity, security risks, privacy, cognitive dependency, and information reliability. Correlation analysis revealed significant associations between key adoption barriers, indicating these concerns function as interconnected constructs rather than isolated factors. Cluster analysis identified three distinct student typologies: Conditional Acceptors, AI Skeptics, and Receptive Potentials, demonstrating heterogeneity in pre-adoption attitudes despite no prior Gen AI experience. Principal component analysis further confirmed Gen AI resistance is structured along two fundamental dimensions: Cognitive-Security concerns and Ethical-Informational integrity. This study illuminates the complex topology of Gen AI resistance prior to actual engagement, providing educational institutions with insights for developing differentiated approaches that address varying levels of student resistance while ensuring implementation occurs within appropriate ethical, cognitive, and security frameworks.},
  keywords={Resistance;Surveys;Ethics;Privacy;Generative AI;Topology;Security;Reliability;Faces;Principal component analysis;Generative AI;Higher Vocational Education;Technology Adoption Barriers;Student Perceptions;Educational Technology},
  doi={10.1109/ICAIE64856.2025.11158361},
  ISSN={},
  month={May},}@INPROCEEDINGS{11165833,
  author={Demir, Kadir Alpaslan and Muppalla, Tarun Narasimha Varma and Liu, Bozhen},
  booktitle={2025 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)}, 
  title={Generative AI Efficiency and Effectiveness in Software Project Documentation Review Process}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={In this research, we report the capabilities of Large Language Model (LLM)-based Generative Artificial Intelligence (GenAI) tools, such as ChatGPT and Gemini, in the software project documentation review process. In software projects, the document artifact review process is an essential part of the quality assurance process. This review process is a human effort-intensive process. Introducing automation in this process will help reduce human effort, speed up the development, and reduce the potential of errors in the documents. With its enhanced natural language processing capabilities, LLM-based GenAI tools provide significant potential in the above process. In this research, we investigate the efficiency and effectiveness of LLM-based GenAI tools (such as ChatGPT and Gemini) for software documentation review process. Our experimental design includes comparing the manual document review process with the automated document review process conducted by LLM-based GenAI tools. The research results indicate that utilizing LLM-based GenAI tools provides significant efficiency in the document review process. However, LLM-based GenAI tools can only reach half the effectiveness and review quality that can be achieved by a human. To the best of our knowledge, this study is one of the first studies investigating the effectiveness and efficiency of utilizing GenAI for the software documentation review process. This research provides significant insights into improving the software document artifact review process utilizing LLM-based GenAI techniques.},
  keywords={Quality assurance;Reviews;Generative AI;Large language models;Documentation;Manuals;Chatbots;Software;Software development management;Software engineering;Generative AI;software documentation;document review;software engineering;software development;software process improvement},
  doi={10.1109/ACDSA65407.2025.11165833},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9403807,
  author={Hou, Xuemei and Gao, Fei and Yu, Lei and Chen, Yufei},
  booktitle={2020 International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE)}, 
  title={Test Data Generation Method Based on Siamese Network in Face Recognition System}, 
  year={2020},
  volume={},
  number={},
  pages={454-457},
  abstract={With the development of AI and big data technology, machine learning system has been widely used in various fields and achieved satisfactory results. However, due to the increasing complexity of machine learning system, there are inevitably a variety of unpredictable problems, errors or failures in machine learning system, which cause fatal damage to the quality and reliability of machine learning system. In order to test machine learning system better, automatic test data generation is the key technology. An improved test data generation method based on GAN and siamese network in face recognition system is proposed. The method focuses on discriminator module composed of siamese network which can better measure the similarity between real and fake images. The results show that the proposed test data generation algorithm can generate images that are very close to the real samples. The test data of machine learning system is enhanced.},
  keywords={Training;Machine learning algorithms;Image recognition;Face recognition;Machine learning;Generative adversarial networks;Feature extraction;Test data generation;Siamese network;Face recognition system;GAN},
  doi={10.1109/ICBASE51474.2020.00102},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11035012,
  author={Sun, KaiJian and Gao, He and Zhang, ShuRui and Zheng, Xuehan and Zheng, Wenjing and Jun, Li},
  booktitle={2025 IEEE 6th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={Multi-Discriminator Driven Enhanced Super-Resolution GAN: Combining Feature Clustering and Region-Based Optimization}, 
  year={2025},
  volume={},
  number={},
  pages={01-05},
  abstract={To address the noise and artifact issues caused by single-discriminator architectures in complex image super-resolution tasks, this paper proposes the Multi-Discriminator Enhanced Super-Resolution GAN (MD-ESRGAN). The model constructs highly discriminative feature subsets through a feature clustering module (ISKM), combined with an image tile splitter (ITS) for localized detail enhancement, and dynamically routes features to dedicated expert sub-networks based on a feature routing mechanism (FRM). The innovative design of Feature Density Loss (LFD) optimizes the compactness of feature space distribution, while the Expert Load Consistency Loss (LELC) balances computational resource allocation. Experimental results show that MD-ESRGAN outperforms SwinIR on multiple datasets, significantly improving the quality of high-frequency detail reconstruction and structural fidelity, while exhibiting superior texture restoration ability in complex scenarios.},
  keywords={Training;Visualization;Superresolution;Computer architecture;Generative adversarial networks;Feature extraction;Stability analysis;Image restoration;Resource management;Image reconstruction;expert networks;texture restoration;feature tiling;super-resolution},
  doi={10.1109/AINIT65432.2025.11035012},
  ISSN={},
  month={April},}@INPROCEEDINGS{11041273,
  author={Rajaprakash, S. and V, Ashok Kumar. and J, Raja. and Vasudha, S. Sai and Karunakar, T. and Pavani, Ch.},
  booktitle={2025 3rd International Conference on Artificial Intelligence and Machine Learning Applications Theme: Healthcare and Internet of Things (AIMLA)}, 
  title={Identification of Fake Human Faces Using DCGAN}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={This project explored the implementation of a Deep Convolutional GAN (DCGAN) to synthesize high-quality, realistic human face images. By leveraging the CelebA dataset for training, the generator network learns to map random noise vectors to human-like faces, whereas the discriminator distinguishes between real and generated images. The architecture employs convolutional and deconvolutional layers to enhance the image fidelity and training stability. Key techniques, including binary cross-entropy loss, Adam optimization, and data normalization, ensure effective learning.},
  keywords={Training;Image resolution;Image synthesis;Noise;Virtual environments;Generative adversarial networks;Generators;Stability analysis;Data models;Faces;Face Generation;DCGANs;Generator;Discriminator},
  doi={10.1109/AIMLA63829.2025.11041273},
  ISSN={},
  month={April},}@INPROCEEDINGS{9836713,
  author={Yuan, Chi and Zou, Hongxia},
  booktitle={2022 IEEE 10th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={Cloud Sample Amplification Method Based on Improved CycleGAN}, 
  year={2022},
  volume={10},
  number={},
  pages={790-794},
  abstract={Cloud is one of the primary noise sources of optical satellite remote sensing images, which can obscure or interfere with ground object information in the image to varying degrees. Remote sensing scenes are complex and changeable, and the accurate labeling of cloud areas directly affects the learning performance of cloud pixel classification and segmentation network model. Aiming at the problem that it is challenging to train an automatic annotation model with good stability due to the small number of remote sensing image samples containing cloud and unbalanced samples of different cloud conditions, this paper constructed a cloud sample augmentation strategy model based on improved CycleGAN network. The generated image is a sample image with high visual consistency with the actual image. This strategy can rapidly expand the limited sample set and solve the training problem of a deep learning network under the condition of a small sample.},
  keywords={Training;Visualization;Satellites;Generative adversarial networks;Data models;Stability analysis;Reliability;remote sensing images;cloud;eycleGAN;generated image},
  doi={10.1109/ITAIC54216.2022.9836713},
  ISSN={2693-2865},
  month={June},}@INPROCEEDINGS{10674809,
  author={Yang, Fan},
  booktitle={2024 5th International Conference on Electronic Communication and Artificial Intelligence (ICECAI)}, 
  title={AttenVGG: Integrating Attention Mechanisms with VGGNet for Facial Expression Recognition}, 
  year={2024},
  volume={},
  number={},
  pages={332-337},
  abstract={Facial expression recognition (FER) is a field of study that focuses on enabling computers to identify human emotions from facial images, a task that has broad applications in areas such as security systems and mental health assessment. This paper investigates FER by testing various classical deep learning models on the FER2013 and CK+ datasets, ultimately improving the performance of the VGG19 model by integrating an attention mechanism. Initial tests with traditional Convolutional Neural Networks (CNNs) on unprocessed data achieved limited accuracy, leading to experiments with different data preprocessing methods and model configurations. The enhanced VGG19 model, with its attention mechanism, showed marked performance gains, achieving a 65.04% accuracy rate on the FER2013 dataset and a remarkable average 99.39% accuracy on the CK+. Despite these advancements, the study acknowledges hurdles such as dataset constraints and the necessity for further validation on newer datasets. The successful application of the attention mechanism to the VGG19 model highlights the efficacy of attention-based approaches in refining FER accuracy. The code and models are publicly available at https://github.com/Fyang-Freddie/AttenVGG.},
  keywords={Deep learning;Accuracy;Attention mechanisms;Face recognition;Computational modeling;Training data;Generative adversarial networks;Deep Learning;Convolutional Neural Networks;Attention Mechanism;Data Augmentation},
  doi={10.1109/ICECAI62591.2024.10674809},
  ISSN={},
  month={May},}@ARTICLE{4648792,
  author={Lei, Yun and Ding, Xiaoqing and Wang, Shengjin},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)}, 
  title={Visual Tracker Using Sequential Bayesian Learning: Discriminative, Generative, and Hybrid}, 
  year={2008},
  volume={38},
  number={6},
  pages={1578-1591},
  abstract={This paper presents a novel solution to track a visual object under changes in illumination, viewpoint, pose, scale, and occlusion. Under the framework of sequential Bayesian learning, we first develop a discriminative model-based tracker with a fast relevance vector machine algorithm, and then, a generative model-based tracker with a novel sequential Gaussian mixture model algorithm. Finally, we present a three-level hierarchy to investigate different schemes to combine the discriminative and generative models for tracking. The presented hierarchical model combination contains the learner combination (at level one), classifier combination (at level two), and decision combination (at level three). The experimental results with quantitative comparisons performed on many realistic video sequences show that the proposed adaptive combination of discriminative and generative models achieves the best overall performance. Qualitative comparison with some state-of-the-art methods demonstrates the effectiveness and efficiency of our method in handling various challenges during tracking.},
  keywords={Bayesian methods;Hybrid power systems;Machine learning;Principal component analysis;Lighting;Video sequences;Filtering;Particle tracking;Motion estimation;State estimation;Discriminative;generative;model combination;particle filtering;sequential learning;visual tracking;Discriminative;generative;model combination;particle filtering;sequential learning;visual tracking},
  doi={10.1109/TSMCB.2008.928226},
  ISSN={1941-0492},
  month={Dec},}@ARTICLE{10458911,
  author={Yeom, Taesun and Gu, Chanhoe and Lee, Minhyeok},
  journal={IEEE Access}, 
  title={DuDGAN: Improving Class-Conditional GANs via Dual-Diffusion}, 
  year={2024},
  volume={12},
  number={},
  pages={39651-39661},
  abstract={Class-conditional image generation using generative adversarial networks (GANs) has been investigated through various techniques; however, it continues to face challenges such as mode collapse, training instability, and low-quality output in cases of datasets with high intra-class variation. Furthermore, most GANs often converge in larger iterations, resulting in poor iteration efficacy in training procedures. While Diffusion-GAN has shown potential in generating realistic samples, it has a critical limitation in generating class-conditional samples. To overcome these limitations, we propose a novel approach for class-conditional image generation using GANs called DuDGAN, which incorporates a dual diffusion-based noise injection process. DuDGAN consists of three unique networks: a discriminator, a generator, and a classifier. During the training process, Gaussian-mixture noises are injected into the two noise-aware networks, the discriminator and the classifier, in distinct ways. This noisy data helps to prevent overfitting by gradually introducing more challenging tasks, leading to improved model performance. As a result, DuDGAN outperforms state-of-the-art conditional GAN models for image generation in terms of performance. We evaluated DuDGAN using the AFHQ, Food-101, CIFAR-10, and BAAT datasets and observed superior results across metrics such as FID, KID, Precision, and Recall score compared with comparison models; FID decreases 12.9% and 5.1% on average for AFHQ and CIFAR-10, respectively, highlighting the effectiveness of the proposed approach.},
  keywords={Training;Image synthesis;Generative adversarial networks;Mathematical models;Generators;Computational modeling;Probabilistic logic;Image synthesis;Deep learning;Conditional image generation;deep learning;diffusion-based probabilistic models;generative adversarial networks},
  doi={10.1109/ACCESS.2024.3372996},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10217468,
  author={Wan, Zhiping and Liu, Shaojiang and Xu, Zhiming and Zou, Jiajun},
  booktitle={2023 IEEE 3rd International Conference on Software Engineering and Artificial Intelligence (SEAI)}, 
  title={A Low Latency Routing for Telematics Combined with Image Semantic Communication}, 
  year={2023},
  volume={},
  number={},
  pages={229-234},
  abstract={Vehicle networking enables real-time, efficient and stable transmission of massive data for various intelligent transportation applications, such as autonomous driving, intelligent intersection management, emergency message broadcasting, etc. However, vehicle networking faces severe challenges in network performance and reliability due to factors such as high-speed mobility of vehicles, dynamic changes of network topology structure, etc. This paper proposes a low-latency routing method for vehicle networking based on image semantic communication, aiming to solve the high latency problem of image data transmission in vehicle networking. For routing planning, this method considers factors such as distance measurement between vehicle nodes, packet loss probability of candidate nodes, residual energy measurement of candidate nodes, current load measurement of candidate nodes, etc. to comprehensively select routing nodes, thereby reducing transmission latency. This method also adopts semantic communication method to transform image data into semantic data and compresses semantic data, thereby further reducing the data volume to be sent by the source vehicle and achieving the purpose of shortening the total data transmission time.},
  keywords={Semantics;Vehicular ad hoc networks;Packet loss;Energy measurement;Transportation;Routing;Delays;vehicular networking;low latency routing;semantic communication;semantic compression},
  doi={10.1109/SEAI59139.2023.10217468},
  ISSN={},
  month={June},}@ARTICLE{10441821,
  author={Wijanto, Eddy and Cheng, Hsu-Chih and Liao, Bo-Hong and Huang, Chun-Ming and Chang, Yao-Tang},
  journal={IEEE Access}, 
  title={Research on Dispersion Compensation of FD-OCT System via Pix2Pix GAN Technique}, 
  year={2024},
  volume={12},
  number={},
  pages={30976-30988},
  abstract={Dispersion in optical coherence tomography (OCT) poses a challenge that is exacerbated by the increased spectral bandwidth, which leads to image blur and feature loss. In this paper, we present a straightforward and cost-effective approach for dispersion compensation in OCT. To achieve this, we employed a pixel-to-pixel (Pix2Pix) generative adversarial network (GAN) architecture customized for image-to-image translation. Two data groups with varying amounts of training image data and epochs were used. The Pix2Pix GAN was trained to generate clear OCT images from the corresponding dispersion-affected OCT images in paired datasets. According to the experimental results, the Pix2Pix GAN technique demonstrated a substantial improvement over the basic GAN. Specifically, it increases the peak signal-to-noise ratio (PSNR) by 159%, structural similarity index (SSIM) by 370%, and Fréchet inception distance (FID) by 274%. These outcomes indicate that the proposed model can generate images with resilience and effectiveness, particularly when dealing with dispersion-affected OCT data.},
  keywords={Dispersion;Spectral analysis;Generative adversarial networks;Image resolution;Biomedical imaging;Optical coherence tomography;Biological tissues;Signal to noise ratio;Generative adversarial network;optical coherence tomography;Pix2Pix},
  doi={10.1109/ACCESS.2024.3368051},
  ISSN={2169-3536},
  month={},}@ARTICLE{9570346,
  author={Adnan, Risman and Saputra, Muchlisin Adi and Fadlil, Junaidillah and Ezerman, Martianus Frederic and Iqbal, Muhamad and Basaruddin, Tjan},
  journal={IEEE Access}, 
  title={Learning GANs in Simultaneous Game Using Sinkhorn With Positive Features}, 
  year={2021},
  volume={9},
  number={},
  pages={144361-144374},
  abstract={Entropy regularized optimal transport (EOT) distance and its symmetric normalization, known as the Sinkhorn divergence, offer smooth and continuous metrized weak-convergence distance metrics. They have excellent geometric properties and are useful to compare probability distributions in some generative adversarial network (GAN) models. Computing them using the original Sinkhorn matrix scaling algorithm is still expensive. The running time is quadratic at  $\mathcal {O}(n^{2})$  in the size  $n$  of the training dataset. This work investigates the problem of accelerating the GAN training when Sinkhorn divergence is used as a minimax objective. Let  $\mathcal {G}$  be a Gaussian map from the ground space onto the positive orthant  $\mathbb {R}_{+}^{r}$  with  $r \ll n $ . To speed up the divergence computation, we propose the use of  $c(x,y)= - \varepsilon \log \left \langle{ \mathcal {G}(x),\mathcal {G}(y) }\right \rangle $  as the ground cost. This approximation, known as Sinkhorn with positive features, brings down the running time of the Sinkhorn matrix scaling algorithm to  $\mathcal {O}(r \, n)$ , which is linear in  $n$ . To solve the minimax optimization in GAN, we put forward a more efficient simultaneous stochastic gradient descent-ascent (SimSGDA) algorithm in place of the standard sequential gradient techniques. Empirical evidence shows that our model, trained using SimSGDA on the DCGAN neural architecture on tiny-coloured Cats and CelebA datasets, converges to stationary points. These are the local Nash equilibrium points. We carried out numerical experiments to confirm that our model is computationally stable. It generates samples of comparable quality to those produced by prior Sinkhorn and Wasserstein GANs. Further simulations, assessed on the similarity index measures (SSIM), show that our model’s empirical convergence rate is comparable to that of WGAN-GP.},
  keywords={Generative adversarial networks;Costs;Optimization;Training;Kernel;Games;Numerical models;Entropy regularized optimal transport;generative adversarial network;Sinkhorn divergence;Sinkhorn with positive features},
  doi={10.1109/ACCESS.2021.3120128},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11047953,
  author={Chen, Minrui and Su, Xiaowen},
  booktitle={2025 5th International Conference on Artificial Intelligence and Industrial Technology Applications (AIITA)}, 
  title={AIGC Technology Driving the Innovative Development of Ethnic Minority Element Design in Guangxi}, 
  year={2025},
  volume={},
  number={},
  pages={1647-1652},
  abstract={Under the background of the rapid development of digitalization, the inheritance and innovation of minority culture in Guangxi is facing new opportunities and challenges. This study focuses on the integration of AIGC technology and ethnic minority design in Guangxi. Through the comprehensive analysis of relevant literature and the study of actual cases, the application status of AIGC technology in the design of ethnic minority elements in Guangxi is systematically expounded. This paper analyzes its mechanism in detail, and reveals how AIGC technology uses advanced algorithms such as deep learning and generative adversarial network to deeply tap the rich cultural elements of Guangxi ethnic minorities, and skillfully integrates them into modern design processes. The key challenges in this integration process are analyzed in depth, including the possible misunderstanding of ethnic culture by AIGC technology, the shortage of high-quality data, the shortage of professional and interdisciplinary talents, and the complex copyright issues. In response to these challenges, a series of targeted and operable coping strategies are proposed, such as building a professional cultural review mechanism, improving the national culture database, strengthening the construction of interdisciplinary personnel training system, and establishing a sound copyright management framework. This study aims to provide comprehensive and in-depth theoretical guidance and practical reference for the application of AIGC technology in the field of ethnic minority element design in Guangxi, effectively promote the inheritance and innovative development of ethnic culture in the modern design context, and make it radiate new vitality and vitality in the digital wave.},
  keywords={Training;Deep learning;Technological innovation;Reviews;Databases;Copyright protection;Generative adversarial networks;Cultural differences;Personnel;Faces;AIGC technology;Guangxi minority elements;Design innovation;Cultural inheritance},
  doi={10.1109/AIITA65135.2025.11047953},
  ISSN={},
  month={March},}@INPROCEEDINGS{10880833,
  author={Mejia, Jose M. Ruiz and Rawat, Danda B.},
  booktitle={2024 IEEE International Conference on E-health Networking, Application & Services (HealthCom)}, 
  title={Exploring the Advancements of AI Enabled Clinical Decision Support Systems for Patient Triage in Healthcare}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={As the demand for medical services grows, the need for an efficient care process becomes increasingly urgent. Recent events have highlighted that the demad for services exceeds the available supply. In response, the focus of heaht information technology has shifted toward advanced clinical decision support systems (CDSS) to addess the critical challenges facing the medical industry. However, many healthcare organiztions lack robust clinical systems and tools. This research presents a comprehensive study of current industry applications, its related works, and provides insights into optimizing current state of the art machine learning (ML) CDSS with newer technologies, such as generative artificial intelligence-based knowledge graphs. This paper offers an overview of CDSS, details the patient treatment process and triage methods, explores the capabilities of knowledge graphs in healthcare, and underscores the need to incorporate machine learning into these processes to increase intelligence, robustness, and personalization.},
  keywords={Decision support systems;Medical treatment;Machine learning;Knowledge graphs;Relational databases;Robustness;Internet;Personnel;Information technology;Medical diagnostic imaging;E-triage;Health Record;Generative AI;Knowledge Graph Databases;E-Health;Remote Triage;Healthcare applications;Patient treatment process;Medical Internet of Things;Healthcare},
  doi={10.1109/HealthCom60970.2024.10880833},
  ISSN={},
  month={Nov},}@ARTICLE{10565979,
  author={Fan, Zichen and Zhang, Qirui and An, Hyochan and Xu, Boxun and Xu, Li and Tseng, Chien-Wei and Peng, Yimai and Bejarano-Carbo, Andrea and Abillama, Pierre and Cao, Ang and Liu, Bowen and Lee, Changwoo and Wang, Zhehong and Kim, Hun-Seok and Blaauw, David and Sylvester, Dennis},
  journal={IEEE Journal of Solid-State Circuits}, 
  title={AIMMI: Audio and Image Multi-Modal Intelligence via a Low-Power SoC With 2-MByte On-Chip MRAM for IoT Devices}, 
  year={2024},
  volume={59},
  number={10},
  pages={3488-3501},
  abstract={In this article, we present an ultra-low-power multi-modal signal processing system on chip (SoC) [audio and image multi-modal intelligence (AIMMI)] that integrates a versatile deep neural network (DNN) engine with audio and image signal processing accelerators for multi-modal Internet-of-Things (IoT) intelligence. In order to get high energy efficiency under resource-constrained IoT scenarios, AIMMI features three efficiency-boosting techniques: 1) 2-MB on-chip non-volatile magnetoresistive RAM (MRAM) to store all DNN weights with MRAM-cache microarchitecture that incorporates dynamic power gating to reduce both leakage and dynamic power consumption; 2) a deliberate power management scheme that enables optimized power modes under different operating situations; and 3) a novel reconfigurable neural engine (NE) with energy-efficient dataflow for comprehensive DNN instructions. Fabricated in TSMC 22-nm ultra-low leakage (ULL) technology with MRAM, AIMMI achieves up to 3–10-TOPS/W peak energy efficiency and consumes only 0.25–3.84 mW. It demonstrates convolutional neural network (CNN), generative adversarial network (GAN), and back-propagation (BP) operations on a single accelerator SoC for multi-modal fusion, outperforming state-of-the-art DNN processors by  $1.4 \times -4.5 \times$  in energy efficiency.},
  keywords={Program processors;Image coding;Generative adversarial networks;System-on-chip;Artificial neural networks;Internet of Things;Face recognition;Machine learning;non-volatile memory;signal processing;system-on-chip (SoC);ultra-low power},
  doi={10.1109/JSSC.2024.3410306},
  ISSN={1558-173X},
  month={Oct},}@INPROCEEDINGS{10413786,
  author={Kang, Shin-Haeng and Lee, Sukhan and Sohn, Kyomin},
  booktitle={2023 International Electron Devices Meeting (IEDM)}, 
  title={The Era of Generative Artificial Intelligence: In-Memory Computing Perspective}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={With the advancement of neural networks, particularly the emergence of large language models, in-memory computing has garnered significant attention as a solution to address memory bottlenecks and improve system energy efficiency. This paper provides an explanation of the key concepts of in-memory computing, including CIM (compute-in-memory), and PIM (processing-in-memory), along with the architectures that have been implemented. Furthermore, we evaluate the performance of PIM technology when applied to the representative large language models, GPT.},
  keywords={Performance evaluation;Computational modeling;Graphics processing units;Bandwidth;In-memory computing;Common Information Model (computing);Field programmable gate arrays},
  doi={10.1109/IEDM45741.2023.10413786},
  ISSN={2156-017X},
  month={Dec},}@ARTICLE{10938538,
  author={Guo, Rui and Herremans, Dorien},
  journal={IEEE Access}, 
  title={An Exploration of Controllability in Symbolic Music Infilling}, 
  year={2025},
  volume={13},
  number={},
  pages={54873-54891},
  abstract={This study uses a transformer model to enhance the controllability of generative symbolic music models, specifically related to the infilling task. We introduce a novel Symbolic Music representation with Explicit Rest notation (SMER) encoding incorporating five basic duration types and explicit rest note tokens similar to standard music notation. We compare this approach with another event-based symbolic music encoding called “REMI” (REvamped MIDI-derived events) regarding controllability over bar-level tension and track-level texture, which refers to how musical elements such as melody and harmony are combined in a musical composition. The SMER encoding is compared with another controllable infilling model, Multi-Track Music Machine (MMM), for track-level density controllability. The findings confirm that the proposed SMER demonstrates superior controllability and generates music stylistically more similar to the original music than that generated by MMM. We propose strategies to further enhance track-level texture control by training two models, controlling each bar’s texture (SMER BAR), and predicting each bar’s texture after each bar’s generation (SMER Pre). Those two models with bar-level texture control effectively increase track-level texture control. To explore the interaction of the controllability of different controls, we thoroughly analyzed the controllability of different types and levels of texture controls. Finally, we implemented an interactive interface to facilitate interactive music composition with AI to help bridge the gap between the AI model and musicians.},
  keywords={Music;Bars;Controllability;Encoding;Artificial intelligence;Predictive models;Transformers;Target tracking;Multiple signal classification;Electronic mail;Symbolic music generation;conditional sequence generation;music encodings;interactions of controls},
  doi={10.1109/ACCESS.2025.3554648},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8576121,
  author={Brunner, Gino and Wang, Yuyi and Wattenhofer, Roger and Zhao, Sumu},
  booktitle={2018 IEEE 30th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Symbolic Music Genre Transfer with CycleGAN}, 
  year={2018},
  volume={},
  number={},
  pages={786-793},
  abstract={Deep generative models such as Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) have recently been applied to style and domain transfer for images, and in the case of VAEs, music. GAN-based models employing several generators and some form of cycle consistency loss have been among the most successful for image domain transfer. In this paper we apply such a model to symbolic music and show the feasibility of our approach for music genre transfer. Evaluations using separate genre classifiers show that the style transfer works well. In order to improve the fidelity of the transformed music, we add additional discriminators that cause the generators to keep the structure of the original music mostly intact, while still achieving strong genre transfer. Visual and audible results further show the potential of our approach. To the best of our knowledge, this paper represents the first application of GANs to symbolic music domain transfer.},
  keywords={Generators;Gallium nitride;Music;Feature extraction;Generative adversarial networks;Neural networks;Standards;deep learning;neural networks;music;midi;style;genre;domain;transfer;cnn;gan;cyclegan},
  doi={10.1109/ICTAI.2018.00123},
  ISSN={2375-0197},
  month={Nov},}@ARTICLE{9306883,
  author={Zhang, Chenyang and Tang, Yongqiang and Zhang, Zhizhong and Li, Ding and Yang, Xuebing and Zhang, Wensheng},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Improving Domain-Adaptive Person Re-Identification by Dual-Alignment Learning With Camera-Aware Image Generation}, 
  year={2021},
  volume={31},
  number={11},
  pages={4334-4346},
  abstract={Domain adaptation in person re-identification (re-ID) has always been challenging, especially for the lack of supervision information on the target domain. Existing methods generally introduced extra supervision by adversarial learning techniques, then added all the augmented data in the training process to optimize the re-ID model. However, the direct utilization of all the generated data not only increases additional computational cost but also ignores the potential correlation between the origin and generated data. In this article, we propose a novel dual-alignment learning framework (DAL) with camera-aware image generation to efficiently and effectively tackle this issue. Specifically, we propose a camera transfer matching module to generate additional training images with different camera styles, and construct the matching pairs with each containing a origin image and one corresponding camera transferred image. To strengthen the correlation of images for each matching pair, we align the pseudo-labels via clustering algorithm to reduce the pseudo-labels distribution discrepancy between the origin and generated images. Besides, to avoid model degeneration affected by some inaccurate pseudo-labels on unlabelled data, we maximize the mutual information to align the image feature representations of matching pair. The DAL allows us to decrease the camera variance and enhance the discrimination ability of re-ID model. Extensive experiments on three large-scale benchmarks demonstrate the superiority of DAL over state-of-the-art methods.},
  keywords={Cameras;Training;Data models;Correlation;Clustering algorithms;Adaptation models;Prediction algorithms;Person re-identification;convolutional neural networks;generative adversarial networks;mutual information},
  doi={10.1109/TCSVT.2020.3047095},
  ISSN={1558-2205},
  month={Nov},}@INPROCEEDINGS{9884330,
  author={Kumar, Advait and Tamboli, Dipesh and Pande, Shivam and Banerjee, Biplab},
  booktitle={IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium}, 
  title={RSINet: Inpainting Remotely Sensed Images Using Triple GAN Framework}, 
  year={2022},
  volume={},
  number={},
  pages={143-146},
  abstract={We tackle the problem of image inpainting in the remote sensing domain. Remote sensing images possess high resolution and geographical variations, that render the conventional inpainting methods less effective. This further entails the requirement of models with high complexity to sufficiently capture the spectral, spatial and textural nuances within an image, emerging from its high spatial variability. To this end, we propose a novel inpainting method that individually focuses on each aspect of an image such as edges, colour and texture using a task specific GAN. Moreover, each individual GAN also incorporates the attention mechanism that explicitly extracts the spectral and spatial features. To ensure consistent gradient flow, the model uses residual learning paradigm, thus simultaneously working with high and low level features. We evaluate our model, alongwith previous state of the art models, on the two well known remote sensing datasets, Open Cities AI and Earth on Canvas, and achieve competitive performance. The code can be referred here: https://github.com/advaitkumar3107/RSINet.},
  keywords={Earth;Image edge detection;Urban areas;Generative adversarial networks;Feature extraction;Sensors;Artificial intelligence;Image inpainting;remote sensing;generative adversarial networks},
  doi={10.1109/IGARSS46834.2022.9884330},
  ISSN={2153-7003},
  month={July},}@INPROCEEDINGS{11030033,
  author={Ayala, Orlando Marquez},
  booktitle={2025 IEEE/ACM 4th International Conference on AI Engineering – Software Engineering for AI (CAIN)}, 
  title={Task Decomposition and RAG as Design Patterns for LLM-Based Systems}, 
  year={2025},
  volume={},
  number={},
  pages={279-280},
  abstract={AI technologies are moving rapidly from research to production. Compared to traditional AI-based software, systems employing Large Language Models (LLMs) are more difficult to design due to their scale and versatility. This makes it necessary to document best practices, known as design patterns in software engineering, that can be used across LLM-based applications. While Task Decomposition and Retrieval-Augmented Generation (RAG) are well-known techniques, their formalization as design patterns for LLM-based systems benefits AI practitioners. These techniques should be considered not only from a scientific perspective, but also from the standpoint of desired software quality attributes such as safety and modularity. This will help bridge the gap between AI and software engineering as those fine-tuning or prompting LLMs will be aware of the impact that modern techniques have on the overall system.},
  keywords={Generative AI;Large language models;Retrieval augmented generation;Software quality;Production;Software systems;Safety;Artificial intelligence;Best practices;Software engineering;llms;rag;task decomposition;generative ai;design patterns},
  doi={10.1109/CAIN66642.2025.00049},
  ISSN={},
  month={April},}@ARTICLE{9318504,
  author={Zhang, Yang and Tsang, Ivor W. and Li, Jun and Liu, Ping and Lu, Xiaobo and Yu, Xin},
  journal={IEEE Transactions on Image Processing}, 
  title={Face Hallucination With Finishing Touches}, 
  year={2021},
  volume={30},
  number={},
  pages={1728-1743},
  abstract={Obtaining a high-quality frontal face image from a low-resolution (LR) non-frontal face image is primarily important for many facial analysis applications. However, mainstreams either focus on super-resolving near-frontal LR faces or frontalizing non-frontal high-resolution (HR) faces. It is desirable to perform both tasks seamlessly for daily-life unconstrained face images. In this paper, we present a novel Vivid Face Hallucination Generative Adversarial Network (VividGAN) for simultaneously super-resolving and frontalizing tiny non-frontal face images. VividGAN consists of coarse-level and fine-level Face Hallucination Networks (FHnet) and two discriminators, i.e., Coarse-D and Fine-D. The coarse-level FHnet generates a frontal coarse HR face and then the fine-level FHnet makes use of the facial component appearance prior, i.e., fine-grained facial components, to attain a frontal HR face image with authentic details. In the fine-level FHnet, we also design a facial component-aware module that adopts the facial geometry guidance as clues to accurately align and merge the frontal coarse HR face and prior information. Meanwhile, two-level discriminators are designed to capture both the global outline of a face image as well as detailed facial characteristics. The Coarse-D enforces the coarsely hallucinated faces to be upright and complete while the Fine-D focuses on the fine hallucinated ones for sharper details. Extensive experiments demonstrate that our VividGAN achieves photo-realistic frontal HR faces, reaching superior performance in downstream tasks, i.e., face recognition and expression classification, compared with other state-of-the-art methods.},
  keywords={Face recognition;Faces;Image resolution;Superresolution;Task analysis;Generative adversarial networks;Deep learning;Face hallucination;super-resolution;face frontalization;generative adversarial network},
  doi={10.1109/TIP.2020.3046918},
  ISSN={1941-0042},
  month={},}@INBOOK{10614288,
  author={Ojanperä, Tero},
  booktitle={AI Revolution: Mastering AI for Personal and Organizational Growth}, 
  title={3 A White-collar Worker&#x2019;s Dream or Nightmare?}, 
  year={2024},
  volume={},
  number={},
  pages={67-82},
  abstract={"The AI Revolution" is a practical guide to using new AI tools, such as ChatGPT, DALLE and Midjourney. Learn how to multiply your productivity by guiding or prompting AI in various ways. The book also introduces Microsoft Copilot, Google Bard, and Adobe Photoshop Generative Fill, among other new applications. ChatGPT reached a hundred million users in just two months after its release, faster than any other application before. This marked the advent of the generative AI era. Generative AI models generate text, images, music, videos, and even 3D models in ways previously thought impossible for machines. The book explains in an understandable manner how these AI models work. The book provides examples of how AI increases productivity, which professions are changing or disappearing, and how job markets will evolve in the coming years. With this book, you'll learn to recognize the opportunities and risks AI offers. Understand what this change demands from individuals and companies and what strategic skills are required. The book also covers legal questions caused by generative AI, like copyrights, data protection, and AI regulation. It also ponders societal impacts. AI produces content, thus influencing language, culture, and even worldviews. Therefore, it's crucial to understand by whom and how AI is trained. The AI revolution started by ChatGPT is just the beginning. This handbook is for you if you want to keep up with the rapid development of AI.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770042314},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10614288},}@INPROCEEDINGS{11165813,
  author={Dildabek, Aizat and Sarsembayeva, Talshyn and Abdiakhmetova, Zukhra},
  booktitle={2025 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)}, 
  title={Comparative Analysis of the Efficiency of Synthetic Data Generation Methods in Classification and Regression Problems}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={The use of synthetic data has become an increasingly relevant approach in machine learning, especially in situations involving limited, imbalanced, or sensitive datasets. This study presents a comparative analysis of two popular data generation methods—CTGAN and TVAE—in the context of both regression and classification tasks. Building on previous work focused on regression, this research expands to include classification by evaluating the impact of synthetic data on models such as Logistic Regression, Random Forest, and XGBoost, using the PIMA Indians Diabetes dataset as a case study. The primary focus is on how the number of training epochs affects the quality of the generated data and, consequently, the performance of downstream models. Results show that synthetic data can significantly improve classification accuracy, particularly in ensemble models, but the benefits are highly dependent on the generation method and training parameters. The study confirms the practical value of synthetic data while also highlighting the need for careful tuning to avoid overfitting and performance degradation.},
  keywords={Training;Logistic regression;Accuracy;Computational modeling;Data collection;Data models;Diabetes;Random forests;Synthetic data;Overfitting;Synthetic data;CTGAN;TVAE;classification;regression;data generation;model performance;PIMA Diabetes;XGBoost;Random Forest;training epochs},
  doi={10.1109/ACDSA65407.2025.11165813},
  ISSN={},
  month={Aug},}@ARTICLE{11123474,
  author={Nie, Zekai and Arshad, Masooma and Khaldoon Khurshid, Syed and Javed, Abqa and Waheed, Talha and Zhang, Qianqian and Farrukh Shahzad, Muhammad},
  journal={IEEE Access}, 
  title={Domain-Specific Multi-Document Political News Summarization Using BART and ACT-GAN}, 
  year={2025},
  volume={13},
  number={},
  pages={143737-143750},
  abstract={The exponential growth of digital content has made it increasingly difficult for users to understand the information, particularly in domains like political news. The study provides a framework for domain-specific multi-document political news summarization by using the transformer-based models that are fine-tuned on the synthetic dataset. The use of a generative Artificial Intelligence (AI) model, specifically the Bidirectional and Autoregressive Transformer (BART) model, for summarizing multi-document political news was explored in this paper. To improve the summarization process, real-world data was augmented, and a synthetic dataset was generated using the Adversarial Contextualized Text - Generative Adversarial Network (ACT-GAN) model to create a diverse and domain-specific training dataset. All four models, including BART, Pegasus, Text-To-Text Transfer Transformer (T5), and Seq2Seq, were fine-tuned and evaluated using a synthetic dataset generated via ACT-GAN and benchmarked using ROUGE metrics. BART performs the best in accuracy, recall, and F1-score, showing it can create clear and logical summaries while keeping the important context and structure intact. The results show that the transformer with the synthetic data helps to improve the quality of the political data summarization. In addition to addressing the challenges of extensive information, this framework also employs generative AI models in text summarization domains.},
  keywords={Text summarization;Data models;Synthetic data;Biological system modeling;Accuracy;Training;Transformers;Semantics;Generative AI;Context modeling;ACT-GAN model;BART large;generative AI;multi-document;political news;ROUGE;synthetic dataset;text summarization},
  doi={10.1109/ACCESS.2025.3598058},
  ISSN={2169-3536},
  month={},}@ARTICLE{9431726,
  author={Zhu, Yongjie and Li, Chen and Li, Si and Shi, Boxin and Tai, Yu-Wing},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Hybrid Face Reflectance, Illumination, and Shape From a Single Image}, 
  year={2022},
  volume={44},
  number={9},
  pages={5002-5015},
  abstract={We propose HyFRIS-Net to jointly estimate the hybrid reflectance and illumination models, as well as the refined face shape from a single unconstrained face image in a pre-defined texture space. The proposed hybrid reflectance and illumination representation ensure photometric face appearance modeling in both parametric and non-parametric spaces for efficient learning. While forcing the reflectance consistency constraint for the same person and face identity constraint for different persons, our approach recovers an occlusion-free face albedo with disambiguated color from the illumination color. Our network is trained in a self-evolving manner to achieve general applicability on real-world data. We conduct comprehensive qualitative and quantitative evaluations with state-of-the-art methods to demonstrate the advantages of HyFRIS-Net in modeling photo-realistic face albedo, illumination, and shape.},
  keywords={Faces;Lighting;Shape;Skin;Image color analysis;Estimation;Data models;Face modeling;intrinsic image decomposition;shading;reflectance;illumination},
  doi={10.1109/TPAMI.2021.3080586},
  ISSN={1939-3539},
  month={Sep.},}@ARTICLE{10495097,
  author={Wei, Zixiang and Mao, Bomin and Guo, Hongzhi and Xun, Yijie and Liu, Jiajia and Kato, Nei},
  journal={IEEE Open Journal of the Computer Society}, 
  title={An Intelligent Path Loss Prediction Approach Based on Integrated Sensing and Communications for Future Vehicular Networks}, 
  year={2024},
  volume={5},
  number={},
  pages={170-180},
  abstract={The developments of communication technologies, Internet of Things (IoT), and Artificial Intelligence (AI) have significantly accelerated the advancement of Intelligent Transportation Systems (ITS) and Autonomous Driving (AD) in recent years. The exchange of sensed information by widely deployed radars, cameras, and other sensors on vehicles and roadside infrastructure can improve the traffic awareness of drivers and pedestrians. However, wireless data transmission in vehicular networks is challenged by highly dynamic path loss due to utilized frequency bands, weather conditions, traffic overheads, and geographical conditions. In this paper, we propose an Integrated Sensing and Communication System (ISAC) based path loss prediction approach to improve the knowledge of wireless data transmissions in vehicular networks, which utilizes multi-modal data collected by millimeter-wave (mmWave) radars, laser radars, and cameras to forecast the end-to-end path loss distribution. By leveraging a generative adversarial network for parameter initialization coupled with fine-tuning through supervised learning, the model's accuracy can be significantly improved. To increase the model's scalability, the effects of weather conditions, geographical conditions, traffic overheads, and frequency bands are all analyzed. According to the simulation results, our model achieves excellent accuracy with Mean Squared Error (MSE) of the predicted path loss distribution below $3e^{-3}$ across five different scenarios.},
  keywords={Predictive models;Sensors;Propagation losses;Data models;Laser radar;Vehicle-to-everything;Feature extraction;Artificial general intelligence (AGI);autonomous driving (AD);integrated sensing and communications (ISAC);vehicle-to-everything (V2X)},
  doi={10.1109/OJCS.2024.3386733},
  ISSN={2644-1268},
  month={},}@ARTICLE{10604878,
  author={Guo, Yike},
  journal={IEEE Access}, 
  title={Design of Improved Artificial Intelligence Generative Dialogue Algorithm and Dialogue System Model Based on Knowledge Graph}, 
  year={2024},
  volume={12},
  number={},
  pages={102637-102648},
  abstract={Dialogue systems are an important research direction in artificial intelligence, with broad application prospects and market value. In order to improve system efficiency and user satisfaction, an open domain generative dialogue system integrating knowledge graphs has been developed, which facilitates the utilization of rich background knowledge during dialogue generation, thereby generating more coherent and meaningful dialogue content. At the same time, based on the sequence to sequence model, a bidirectional gated loop unit is introduced to better capture contextual information and improve the model’s understanding and generation ability. These results confirmed that the average values of the improved model in the training and validation sets were 98.66% and 87.34%, respectively, with loss values of 0.01 and 0.10. Compared to the baseline model, this improved model improved Hits@1 and Hits@3 by 0.09% and 0.25%, respectively. This improved model had the minimum perplexity of 17.62. The security and diversity of this improved system were 0.80 and 0.82, respectively, taking into account the balance of these two types of performance. Its correlation and fluency were 1.44 and 1.56, respectively. This indicates that this improved model is beneficial for improving the efficiency of generating dialogue and has certain effectiveness, better meeting users’ needs and improve user satisfaction. This system can provide users with a better conversation experience and provide technological and innovative features for artificial intelligence dialogue assistants.},
  keywords={Data mining;Accuracy;Oral communication;Knowledge based systems;Training;Task analysis;Data models;Knowledge graphs;Bidirectional control;Dialogue system;generative;knowledge graph;Seq2Seq model;bidirectional GRU},
  doi={10.1109/ACCESS.2024.3430902},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9712968,
  author={Jie, Sheng and Kun, Zhang and Xihui, Wang and Jinhao, Hu and Xinrui, Yao and Hualin, Huang},
  booktitle={2021 IEEE 5th Conference on Energy Internet and Energy System Integration (EI2)}, 
  title={Application and Prospect of Deep Learning in New Energy Power System}, 
  year={2021},
  volume={},
  number={},
  pages={461-465},
  abstract={Building a new power system with new energy as the main body is one of the most important measures to achieve “carbon peak and carbon neutral” in China, which also puts forward higher requirements on the data analysis and processing capacity of the current power system. In recent years, artificial intelligence algorithms represented by deep learning have provided strong support for the realization and development of new energy power system. The paper summarizes the basic characteristics of deep learning algorithm and its five mainstream models. From the aspects of image recognition, power load prediction, fault diagnosis and system optimization scheduling, the application of deep learning in new energy power system is deeply analyzed. The application prospect of deep learning in new energy power system is prospected in order to provide reference for the research and construction of new power system.},
  keywords={Deep learning;Power measurement;System integration;Power system stability;Prediction algorithms;Stability analysis;Internet;Artificial intelligence;Deep learning;New energy power system;Energy Internet},
  doi={10.1109/EI252483.2021.9712968},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10837276,
  author={Krishna, E S Phalguna and Saravanan, T and Saravanakumar, S},
  booktitle={2024 IEEE International Conference on Blockchain and Distributed Systems Security (ICBDS)}, 
  title={An Intelligent Transportation Network for the Brain based on Observed Driving Patterns}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This Connected autonomous vehicle can effectively overcome the perceived limitations of human drivers through the use of communication and artificial intelligence technology. However, due to the high dynamics of the vehicular network and the various disruptions and handovers that occur, providing solid communication lines between cars is still difficult, and this might have disastrous consequences. This work proposes a technique for intelligently grouping vehicles in the heterogeneous Cognitive Internet of Vehicles based on their driving behaviours (CIoVs). The driving mode with numerous feature parameters is analysed in the proposed method to precisely capture driving traits. With the goal of facilitating trustworthy clustering of networked autonomous cars, a method based on neural network pattern recognition and the principles of evolutionary algorithms is developed. The cognitive engines can identify the different driving styles and cluster cars that share that style together. We also study the clustering mechanism's communication performance and construct the stability and life duration of clusters. Data from simulations shows that associated to state-of-the-art methods, the suggested mechanism increases reliable communication throughput by around 14.4% and average cluster lifespan by about 11.5%.},
  keywords={Laser radar;Cameras;Brain modeling;Throughput;Data models;Stability analysis;Automobiles;Security;Vehicle dynamics;Anomaly detection;Artificial intelligence;autonomous driving;cognitive Internet of Vehicles;clustering mechanism;genetic algorithm},
  doi={10.1109/ICBDS61829.2024.10837276},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10939159,
  author={Kunchakuri, Naveen},
  booktitle={2025 First International Conference on Advances in Computer Science, Electrical, Electronics, and Communication Technologies (CE2CT)}, 
  title={MATLAB-Based Simulation of Generative AI-Based Autonomous Vehicle Control for High-Speed Driving and Emergency Maneuvers}, 
  year={2025},
  volume={},
  number={},
  pages={1191-1196},
  abstract={Recently, the automobile industry has been investigating the idea of autonomous vehicles extensively as a means of, for increasing gas mileage or gaining access to areas that are dangerous for human drivers. The autonomous industry has not widely adopted these methods despite the fact that they clearly provide improved control efficiency. This is because their first end-user adoption frequently poses significant obstacles. Although System Predictive Management (SPM) has historically been employed to regulate models with shorter dynamics, it is currently also being utilized in models with significantly quicker dynamics due to the development of stronger processors. A weight adaptable SPM depending on the PSO-BP neural network is developed in this study to enhance the monitoring adaptability of self-driving vehicles beneath varying road shape and vehicle high-speeds. It is composed of an optimum-weight adaptable regulating and a dynamics-oriented SPM. The PSO-BP NN is trained offline using the optimum load beneath various operational circumstances determined by automatic simulation in order to accomplish the online modification of SPM load. This approach depends on the employment of SPM to accomplish high-precision monitoring management. The adaptable management structures outperform the original conventional SPM regulation in terms of monitoring adaption, according to the test outcomes of the Prescan-Carsim-Simulink combined simulated system. The adaptable management approach increased monitoring speed while satisfying the vehicle's needs for real-time management and lateral security, according to the evaluation outcomes from an automated vehicle investigation system where the management method was additionally validated.},
  keywords={Industries;Roads;Decision making;Artificial neural networks;Predictive models;Real-time systems;Safety;Automobiles;Vehicle dynamics;Monitoring;Autonomous vehicle;High-Seed;Artificial intelligence;Neural network;Path tracking management},
  doi={10.1109/CE2CT64011.2025.10939159},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10757219,
  author={Örpek, Zeynep and Tural, Büşra and Destan, Zeynep},
  booktitle={2024 8th International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT)}, 
  title={SWOT Analysis of Open-Source Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Language models have become a rapidly developing and highly popular innovation area in the field of artificial intelligence and natural language processing (NLP) in recent years, and a significant part of this development has accelerated with the use of open-source language models. Open-source language models have increased their capacity to learn the complex structure of the language by being trained with large data sets, and thus have enabled more effective solutions to be produced in many areas. Open-source language models are language models that are open to use with their source code and model features, and that anyone can access, use, modify, and develop on. Their accessibility has made them widespread rapidly. Especially large language models such as GPT (Generative Pretrained Transformer) and BERT (Bidirectional Encoder Representations from Transformers) have been trained and have demonstrated an extraordinary ability to understand texts, answer questions, and even produce content. With these capabilities, they have caused artificial intelligence-based solutions to become widespread rapidly in many industries. They have begun to be used in a wide range of areas, from customer service to content creation processes, from automatic translation systems to data analysis. Especially with the spread of open-source language models, small businesses and independent developers have also become able to benefit from this technology. Participation in the innovation process has increased. However, despite the strong potential of open-source language models, this technology needs to be managed carefully and responsibly considering its weaknesses, opportunities, and possible threats. In this study, the current status of this technology and the challenges it may face in the future are evaluated by conducting a SWOT (Strengths, Weaknesses, Opportunities, and Threats) analysis of open-source language models.},
  keywords={Industries;Analytical models;Technological innovation;Data analysis;Source coding;Large language models;Transformers;Natural language processing;Data models;Faces;Open Source;Language Models;NLP},
  doi={10.1109/ISMSIT63511.2024.10757219},
  ISSN={2770-7962},
  month={Nov},}@INBOOK{10950539,
  author={Khan, Ian},
  booktitle={The Quick Guide to Prompt Engineering: Generative AI Tips and Tricks for ChatGPT, Bard, Dall-E, and Midjourney}, 
  title={Prompt Engineering with OpenAI ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={163-176},
  abstract={Summary <p>Developed by OpenAI, ChatGPT is not just another model in a lineage of advancements; it signifies a paradigm shift in how we interact with and understand AI models. ChatGPT&#x2010;3 is built on the foundation of predicting the next word in a sequence. When ChatGPT&#x2010;3 receives a prompt, its primary goal is to understand the context and the task's intention. This chapter presents some practical examples of ChatGPT&#x2010;3 applications, including content creation, code writing, language translation, creative writing, business analytics, gaming, and health care assistance, as well as limitation and ethical considerations of ChatGPT&#x2010;3. ChatGPT&#x2010;3 could be used to generate real&#x2010;time dialogues or narratives within augmented reality and virtual reality environments. By refining prompt engineering further, ChatGPT&#x2010;3 could be employed to derive deeper insights from vast textual datasets.</p>},
  keywords={Artificial intelligence;Translation;Solid modeling;Prompt engineering;Chatbots;Transformers;Training;Analytical models;Adaptation models;Refining},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394243341},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10950539},}@INBOOK{10950798,
  author={Khan, Ian},
  booktitle={The Quick Guide to Prompt Engineering: Generative AI Tips and Tricks for ChatGPT, Bard, Dall-E, and Midjourney}, 
  title={Transformers in Music with MuseNet}, 
  year={2024},
  volume={},
  number={},
  pages={259-272},
  abstract={Summary <p>As a deep learning model, MuseNet leverages the power of transformers&#x2014;specifically, the generalized transformer architecture&#x2014;to generate music compositions spanning a range of styles and genres. This chapter discusses the role of prompts in MuseNet. At its core, MuseNet uses prompts to derive the initial inspiration for generating pieces of music. Prompts play a vital role in guiding the emotional or thematic tone of the generated music. The chapter delves into some real&#x2010;world examples of the output compositions MuseNet is capable of generating. Like all AI models, MuseNet comes with its own set of limitations and poses various ethical considerations, including over&#x2010;reliance on training data, lack of original creativity, copyright concerns, commercial exploitation, loss of cultural nuance, quality inconsistency, and data privacy. The chapter also discusses key points that might define the future of MuseNet.</p>},
  keywords={Transformers;Iterative methods;Training;Rhythm;Prompt engineering;Cultural differences;Artificial intelligence;Rocks;Instruments;Feedback loop},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394243341},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10950798},}@INBOOK{10950909,
  author={Khan, Ian},
  booktitle={The Quick Guide to Prompt Engineering: Generative AI Tips and Tricks for ChatGPT, Bard, Dall-E, and Midjourney}, 
  title={DeepArt and Artistic Prompts}, 
  year={2024},
  volume={},
  number={},
  pages={319-332},
  abstract={Summary <p>In the realms of digital art and AI, DeepArt stands as a fascinating intersection that offers the promise of transforming ordinary images into masterpieces reminiscent of famous art styles. This chapter discusses how prompts influence DeepArt. At its core, DeepArt uses artistic prompts to infuse digital images with artistic flair, marrying content with style. DeepArt uses convolutional neural networks to decode the essence of the prompt. Through prompts, DeepArt exemplifies the beautiful confluence of human creativity and machine precision. The chapter presents some use cases of DeepArt, including personalized digital art, custom merchandise design, enhanced film and animation, reviving historical photos, digital advertising, and interior design visualization. It also discusses the limitations of DeepArt, such as loss of unique style, over&#x2010;reliance on popular artistic templates, computational demands, lack of consistency, potential for misuse, complexity for novice users, overemphasis on visual aspects, and lack of integration with other media.</p>},
  keywords={Artificial intelligence;Visualization;Prompt engineering;Digital art;Compass;Virtual reality;Training;Image color analysis;Geometry;Economics},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394243341},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10950909},}@INBOOK{10952205,
  author={Lopez-Lira, Alejandro},
  booktitle={The Predictive Edge: Outsmart the Market using Generative AI and ChatGPT in Financial Forecasting}, 
  title={The Future of AI in Financial Forecasting}, 
  year={2024},
  volume={},
  number={},
  pages={177-189},
  abstract={Summary <p>In finance, the emergence of AI has marked a transformative era in forecasting and decision&#x2010;making. This chapter explores the potential future landscape of AI in finance. It explores how AI is poised to redefine the norms of financial analysis and investment strategies. The chapter highlights the most significant upcoming AI technology trends. It examines emerging algorithms, the fusion of AI with blockchain and the internet of things (IoT), and the progress in data&#x2010;processing capabilities. The chapter explores the personalization of financial services through AI, envisioning a future where financial advice and strategies are as unique as the individual investor's profile. It discusses the limitations of current AI technologies in financial forecasting and AI's expected influence on the finance industry's structure. This impact includes its effect on employment, the emergence of new financial entities, and new user interfaces.</p>},
  keywords={Chatbots;Artificial intelligence;Heuristic algorithms;Forecasting;Prediction algorithms;Biological system modeling;Predictive models;Finance;Large language models;Translation},
  doi={10.1002/9781394308286.ch9},
  ISSN={},
  publisher={Wiley},
  isbn={9781394242733},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952205},}@INBOOK{10952853,
  author={Khan, Ian},
  booktitle={The Quick Guide to Prompt Engineering: Generative AI Tips and Tricks for ChatGPT, Bard, Dall-E, and Midjourney}, 
  title={Application&#x2010;Specific Prompt Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={123-141},
  abstract={Summary <p>This chapter delves deeper into the fascinating interplay between prompts and creative writing. By specifying genres within the prompt, writers can utilize AI to generate content tailored to specific themes. In the rapidly evolving landscape of AI, prompt engineering for creative writing represents a confluence of human artistry and machine precision. The meticulous crafting of prompts has the potential to reshape how educators and students interact with AI&#x2010;driven educational tools. Through tailored prompts, developers can delegate, automate, and enhance many of their tasks, making the software development life cycle more efficient and robust. To ensure prompts remain adaptive, systems can be designed to include feedback loops where AI learns from user interactions. Personalized and adaptive prompts represent the future of prompt engineering, merging the vast computational potential of AI with the intricate nuances of individual human experiences.</p>},
  keywords={Artificial intelligence;Prompt engineering;Writing;Ethics;Creativity;Codes;Visualization;Solid modeling;Predictive models;Market research},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394243341},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952853},}@INBOOK{10952930,
  author={Baker, Pam},
  booktitle={Generative AI For Dummies}, 
  title={Leaning on Advanced Tactics to Move Your Content to Another Level}, 
  year={2025},
  volume={},
  number={},
  pages={193-201},
  abstract={Summary <p>The integration capabilities of GenAI models are a key factor for many users and companies. This chapter focuses on critical considerations for choosing the right GenAI model, including performance, scalability, ease of integration, and the specific tasks the readers aim to accomplish. It includes case studies and real&#x2010;world applications to provide the readers with a better understanding of how different models can be leveraged to meet diverse needs. Specialized models deliver higher accuracy and efficiency for particular tasks, aligning closely with specific domain knowledge or styles, making them suitable for niche applications. GenAI models offer a versatile foundation upon which industry&#x2010;specific applications can be built, allowing businesses to adapt these technologies to their unique needs. The market currently features a range of specialized GenAI models. The chapter looks at the various elements and methods that can be used to deal with integration issues.</p>},
  keywords={Retrieval augmented generation;Adaptation models;Artificial intelligence;Data models;Context modeling;Companies;Training data;Software;Accuracy;Writing},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394270767},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952930},}@INBOOK{10954607,
  author={Khan, Ian},
  booktitle={The Quick Guide to Prompt Engineering: Generative AI Tips and Tricks for ChatGPT, Bard, Dall-E, and Midjourney}, 
  title={Text Synthesis with CTRL}, 
  year={2024},
  volume={},
  number={},
  pages={205-216},
  abstract={Summary <p>The burgeoning world of AI has seen several significant developments in recent years, one of which is Salesforce's Conditional Transformer Language Model, popularly known as CTRL. CTRL presents a distinctive approach to this interplay compared to its predecessors and contemporaries. A dive into the nuances of CTRL's handling of prompts reveals a model striving for heightened contextual awareness and specificity, a feature that is quintessential for varied professional environments. CTRL's ability to generate coherent and extensive text makes it an invaluable tool for journalism. In a corporate setting, communication tone and clarity are pivotal. By employing CTRL with a control code such as &#x201c;Formal business email,&#x201d; organizations can draft communications that maintain a professional standard. In the realm of education, CTRL can act as a supplemental tutor. The legal profession, characterized by its specific jargon and format, can harness CTRL for drafting or reviewing documents.</p>},
  keywords={Codes;Adaptation models;Artificial intelligence;Context modeling;Biological system modeling;Computational modeling;Transformers;Training;Prompt engineering;Ethics},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394243341},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10954607},}@INBOOK{10950974,
  author={Khan, Ian},
  booktitle={The Quick Guide to Prompt Engineering: Generative AI Tips and Tricks for ChatGPT, Bard, Dall-E, and Midjourney}, 
  title={Ethical Considerations in Prompt Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={103-122},
  abstract={Summary <p>This chapter delves into the nuances of bias within AI and how it manifests in the world of prompt engineering. Given the potential harm, addressing bias in AI, especially in prompt engineering, is of paramount importance. The chapter explores methods that can be employed to ensure that the prompts used in AI interactions remain as unbiased as possible. Given the significant impact of prompts on AI behavior, there's a pressing need for ethical guidelines in their design. The chapter presents an in&#x2010;depth exploration of ethical standards that should be central to prompt engineering. Prompts have emerged as pivotal tools that help elicit specific responses from AI systems. However, the dynamic interface prompts also introduce privacy considerations that are crucial to acknowledge and address. Automated bias detection represents a promising frontier to tackle the pervasive issue of bias in AI.</p>},
  keywords={Artificial intelligence;Ethics;Prompt engineering;Biological system modeling;Training data;Training;Reviews;Feedback loop;Data privacy;Data models},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394243341},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10950974},}@INBOOK{10951394,
  author={Khan, Ian},
  booktitle={The Quick Guide to Prompt Engineering: Generative AI Tips and Tricks for ChatGPT, Bard, Dall-E, and Midjourney}, 
  title={Advanced Topics in Prompt Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={143-161},
  abstract={Summary <p>This chapter presents a detailed exploration of how user feedback can be integrated into prompt design and why it is essential. Ethical considerations are paramount when incorporating feedback to ensure inclusivity and fairness. At its core, A/B testing involves comparing two versions of a prompt to see which one produces better outcomes. These versions are presented to users at random, and the resulting interactions are monitored to determine which version leads to more desired behaviors or outcomes. As AI becomes more integrated into our daily routines and business processes, the need for multilingual support becomes increasingly evident. The chapter looks at the intricate world of multilingual prompt design. It delves into the world of prompts for multimodal AI models, their importance, and strategies for their optimization. The chapter also explores advanced A/B testing strategies tailored for prompt engineering.</p>},
  keywords={Artificial intelligence;Testing;Ethics;Prompt engineering;Feedback loop;User experience;Libraries;Context modeling;Multilingual;Measurement},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394243341},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951394},}@INBOOK{10951367,
  author={Baker, Pam},
  booktitle={Generative AI For Dummies}, 
  title={Ten Ways GenAI Can Boost Your Creativity}, 
  year={2025},
  volume={},
  number={},
  pages={269-276},
  abstract={Summary <p>This chapter explores ten innovative ways that GenAI can spark the creativity and transform the way readers approach art, writing, music, and more. Experimenting with GenAI models can be a transformative experience, blending the realms of education and inspiration. The process of interacting with GenAI can be deeply educational, providing insights into the mechanics of creativity and the potential of AI as a collaborative tool. By engaging with GenAI, users can learn about different genres and styles, discovering new ways to approach their art. The technology serves as a tool for reflection, as users can see how their input is interpreted and transformed by the AI, leading to a deeper understanding of their own creative process. GenAI models and applications, like ChatGPT, can assist writers by generating creative content, suggesting narrative possibilities, and even refining language and grammar. These tools boost human creativity, and AI's speed and computational power is redefining the boundaries of storytelling.</p>},
  keywords={Artificial intelligence;Creativity;Art;Visualization;Generators;Rhythm;Market research;Technological innovation;Sparks;Particle swarm optimization},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394270767},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951367},}@INBOOK{10951263,
  author={Baker, Pam},
  booktitle={Generative AI For Dummies}, 
  title={Unveiling the Human Element in GenAI}, 
  year={2025},
  volume={},
  number={},
  pages={255-266},
  abstract={Summary <p>The presence of humans in the GenAI loop is indispensable. The integration of advanced GenAI models into our daily lives and decision&#x2010;making processes is becoming increasingly prevalent. This chapter explores the symbiotic relationship between human intuition and machine precision. GenAI models can process vast amounts of data and identify patterns beyond human capability, but they lack the nuanced understanding that humans possess. Quality control in GenAI responses is another critical aspect that ensures the reliability and appropriateness of the content produced. Human moderators can review GenAI responses for accuracy and relevance. Establishing protocols for human&#x2010;AI collaborative reviews is essential to maintain quality controls. The process of integrating domain expertise into GenAI models involves capturing the deep, nuanced knowledge of human experts and translating it into a format that GenAI tools can understand and utilize.</p>},
  keywords={Data models;Biological system modeling;Ethics;Computer crashes;Reviews;Symbiosis;Quality control;Humanities;Creativity;Artificial general intelligence},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394270767},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951263},}@ARTICLE{9264218,
  author={Yan, Ke and Su, Jianye and Huang, Jing and Mo, Yuchang},
  journal={IEEE Transactions on Automation Science and Engineering}, 
  title={Chiller Fault Diagnosis Based on VAE-Enabled Generative Adversarial Networks}, 
  year={2022},
  volume={19},
  number={1},
  pages={387-395},
  abstract={Artificial intelligence (AI)-enhanced automated fault diagnosis (AFD) has become increasingly popular for chiller fault diagnosis with promising classification performance. In practice, a sufficient number of fault samples are required by the AI methods in the training phase. However, faulty training samples are generally much more difficult to be collected than normal training samples. Data augmentation is introduced in these scenarios to enhance the training data set with synthetic data. In this study, a variational autoencoder-based conditional Wasserstein GAN with gradient penalty (CWGAN-GP-VAE) is proposed to diagnose various faults for chillers. A detailed comparative study has been conducted with real-world fault data samples to verify the effectiveness and robustness of the proposed methodology. Note to Practitioners—This work attacks the fact that faulty training samples are usually much harder to be collected than the normal training samples in the practice of chiller automated fault diagnosis (AFD). Modern supervised learning chiller AFD relies on a sufficient number of faulty training samples to train the classifier. When the number of faulty training samples is insufficient, the conventional AFD methods fail to work. This study proposed a variational autoencoder-based conditional Wasserstein GAN with gradient penalty (CWGAN-GP-VAE) framework for generating synthetic faulty training samples to enrich the training data set for machine learning-based AFD methods. The proposed algorithm has been carefully designed, implemented, and practically proved to be more effective than the existing methods in the literature.},
  keywords={Training;Generative adversarial networks;Training data;Gallium nitride;Fault diagnosis;Refrigerants;HVAC;Data augmentation;fault diagnosis;generative adversarial network (GAN);variational autoencoder (VAE)},
  doi={10.1109/TASE.2020.3035620},
  ISSN={1558-3783},
  month={Jan},}@ARTICLE{9093005,
  author={Wu, Ensen and Cui, Hongyan and Welsch, Roy E.},
  journal={IEEE Access}, 
  title={Dual Autoencoders Generative Adversarial Network for Imbalanced Classification Problem}, 
  year={2020},
  volume={8},
  number={},
  pages={91265-91275},
  abstract={The imbalanced classification problem has become greatest issue in many fields, especially in fraud detection. In fraud detection, the transaction datasets available for training are extremely imbalanced, with fraudulent transaction logs considerably less represented. Meanwhile, the feature information of the fraud samples with better classification capabilities cannot be mined directly by feature learning methods due to too few fraud samples. These significantly reduce the effectiveness of fraud detection models. In this paper, we proposed a Dual Autoencoders Generative Adversarial Network, which can balance the majority and minority classes and learn feature representations of normal and fraudulent transactions to improve the accuracy of the fraud detection. The new model firstly trains a Generative Adversarial Networks to output sufficient mimicked fraudulent transactions for autoencoder training. Then, two autoencoders are trained on the normal and fraud dataset, respectively. The samples are encoded by two autoencoders to obtain two sets of features, which are combined to form the dual autoencoding features. Finally, the model detects fraudulent transactions by a Neural Network trained on the augmented training set. Experimental results show that the model outperforms a set of well-known classification methods in experiments, especially the sensitivity and precision, which are effectively improved.},
  keywords={Training;Gallium nitride;Generative adversarial networks;Generators;Mathematical model;Credit cards;Feature extraction;Fraud detection;imbalanced classification;generative adversarial networks;autoencoders},
  doi={10.1109/ACCESS.2020.2994327},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9884456,
  author={Yang, Wei and Ma, ZiQian and Shi, YingRu},
  booktitle={IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium}, 
  title={SAR Image Super-Resolution based on Artificial Intelligence}, 
  year={2022},
  volume={},
  number={},
  pages={4643-4646},
  abstract={High-resolution synthetic aperture radar (SAR) image can provide detailed information of the target, which is a benefit for improving the performance of the following interpretation application. However, the higher the resolution, the more complex the system and the higher the cost. A new challenge is how to obtain high-resolution target images from medium resolution images, by using new technology, such as artificial intelligence. In this paper, a new method is proposed to improve the resolution based on the SRGAN-SSIM. Since SRGAN is developed for nature image super-resolution, which results in a poor performance for SAR image, pre-processing is implemented. A modified Non-Local Means (NLM) is adopted for speckle noise suppression. Then, SRGAN based net is used for super-resolution, and the loss function is optimized according to the SSIM. Finally, the method is verified by Terra-SAR images.},
  keywords={Costs;Superresolution;Noise reduction;Buildings;Geoscience and remote sensing;Speckle;Radar polarimetry;Synthetic aperture radar (SAR);Image;Super-resolution (SR);AI;SRGAN},
  doi={10.1109/IGARSS46834.2022.9884456},
  ISSN={2153-7003},
  month={July},}@ARTICLE{10086635,
  author={Köksal, Ali and Ak, Kenan E. and Sun, Ying and Rajan, Deepu and Lim, Joo Hwee},
  journal={IEEE Transactions on Multimedia}, 
  title={Controllable Video Generation With Text-Based Instructions}, 
  year={2024},
  volume={26},
  number={},
  pages={190-201},
  abstract={Most of the existing studies on controllable video generation either transfer disentangled motion to an appearance without detailed control over motion or generate videos of simple actions such as the movement of arbitrary objects conditioned on a control signal from users. In this study, we introduce Controllable Video Generation with text-based Instructions (CVGI) framework that allows text-based control over action performed on a video. CVGI generates videos where hands interact with objects to perform the desired action by generating hand motions with detailed control through text-based instruction from users. By incorporating the motion estimation layer, we divide the task into two sub-tasks: (1) control signal estimation and (2) action generation. In control signal estimation, an encoder models actions as a set of simple motions by estimating low-level control signals for text-based instructions with given initial frames. In action generation, generative adversarial networks (GANs) generate realistic hand-based action videos as a combination of hand motions conditioned on the estimated low control level signal. Evaluations on several datasets (EPIC-Kitchens-55, BAIR robot pushing, and Atari Breakout) show the effectiveness of CVGI in generating realistic videos and in the control over actions.},
  keywords={Machine-to-machine communications;Estimation;Task analysis;Generative adversarial networks;Faces;Dynamics;Cameras;Controllable video generation;video generation with textual instructions;motion generation;conditional generative models},
  doi={10.1109/TMM.2023.3262972},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{10723995,
  author={Vigenesh, M. and Shalini, M and Mandar, P and Hassan, Inzimam Ul and Dari, Sukhvinder Singh and Annamalai, S.},
  booktitle={2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Applying Machine Learning to Strengthening Cyber Security}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Cyber safety threats have become a central problem in the contemporary world, with hackers constantly finding new approaches to make the most systems and users to gain unauthorized admission. Gadget learning has been determined to be a promising approach to combat these threats, considering the improvement of state-of-the-art algorithms capable of detecting malicious activities in near real-time. Through supervised studying, neural networks, or other sample popularity techniques, these algorithms can learn how to locate malicious conduct and lift an alert to take appropriate countermeasures. Additionally, device getting to know can be used to identify new threats and recognize formerly unknown flaws in present defenses, allowing them to be patched or upgraded promptly. Given the ever-converting nature of the cyber security landscape, gadget studying programs are worthwhile for staying ahead of the curve and retaining information secure.},
  keywords={Security management;Neural networks;Machine learning;Reconnaissance;Real-time systems;Hazards;Object recognition;Computer crime;Protection;Testing;Landscape;Secure;Advance;Curve;Gadget},
  doi={10.1109/ICCCNT61001.2024.10723995},
  ISSN={2473-7674},
  month={June},}@INPROCEEDINGS{11052933,
  author={Sahithi, Chalamala Teja and Pandala, Madhavi Latha and Shaik, Arif Basha},
  booktitle={2025 International Conference on Computational Robotics, Testing and Engineering Evaluation (ICCRTEE)}, 
  title={Enhancing Skin Cancer Detection with a Multi-Model Deep Learning Approach}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The increasing prevalence of skin cancer highlights the critical need for early and accurate detection, as it can significantly influence patient outcomes. In this study, we propose a multi-model deep learning approach for automated skin cancer detection using the HAM10000 dataset. We implemented and evaluated four models: ResNet101 with Soft Attention, CNN with XGBoost (CNN+XGBoost), VGG16, and Vision Transformer (ViT-B/32). ResNet101-SA demonstrated the highest accuracy at 97%, followed by CNN+XGBoost (84.6%), VGG16 (78%), and ViT-B/16 (86.73%). To bridge the gap between research and real-world application, we developed a real-time web application using Flask, React, and Express.js, enabling users to upload images for instant lesion analysis. Additionally, an AI assistant was integrated to provide guidance and insights into skin health. Despite the promising performance of our approach, challenges remain in improving model generalization across diverse skin tones, lesion types, and imaging conditions. Future work will focus on enhancing transfer learning techniques, expanding the dataset with additional samples, and deploying the system on the cloud for scalable real-time detection. Furthermore, integrating clinical metadata and incorporating explainable AI will enhance the system’s credibility, making it a valuable tool for both medical professionals and individuals seeking early skin cancer detection.},
  keywords={Deep learning;Accuracy;Transfer learning;Metadata;Transformers;Real-time systems;Skin;Lesions;Skin cancer;Testing;Skin Cancer Detection;Multi Modal Approach;Real Time Detection;Clinincal Decision Support},
  doi={10.1109/ICCRTEE64519.2025.11052933},
  ISSN={},
  month={May},}@ARTICLE{8994961,
  author={Benzaid, Chafika and Taleb, Tarik},
  journal={IEEE Network}, 
  title={AI-Driven Zero Touch Network and Service Management in 5G and Beyond: Challenges and Research Directions}, 
  year={2020},
  volume={34},
  number={2},
  pages={186-194},
  abstract={The foreseen complexity in operating and managing 5G and beyond networks has propelled the trend toward closed-loop automation of network and service management operations. To this end, the ETSI Zero-touch network and Service Management (ZSM) framework is envisaged as a next-generation management system that aims to have all operational processes and tasks executed automatically, ideally with 100 percent automation. Artificial Intelligence (AI) is envisioned as a key enabler of self-managing capabilities, resulting in lower operational costs, accelerated time-tovalue and reduced risk of human error. Nevertheless, the growing enthusiasm for leveraging AI in a ZSM system should not overlook the potential limitations and risks of using AI techniques. The current paper aims to introduce the ZSM concept and point out the AI-based limitations and risks that need to be addressed in order to make ZSM a reality.},
  keywords={5G mobile communication;Automation;Artificial intelligence;Network slicing;Cognition},
  doi={10.1109/MNET.001.1900252},
  ISSN={1558-156X},
  month={March},}@INPROCEEDINGS{11062057,
  author={Gheibi, Reza and Hougen, Dean},
  booktitle={2025 IEEE International Conference on Prognostics and Health Management (ICPHM)}, 
  title={Improved Cervical Cancer Classification using Generative AI and Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Cervical cancer continues to be a major global health challenge, and early detection is crucial to improve patient outcomes. In this study, we propose an innovative approach that uses a combination of Generative AI and Large and Small Language Models (LLMs and SLMs) to improve cervical cancer classification and patient interaction. Our methodology involves transforming tabular patient data into textual descriptions, enabling the use of Natural Language Processing (NLP) techniques for classification. We employ generative AI for data augmentation, improving the robustness of predictive models. Additionally, we fine-tune various language models, including text classification transformers from the BERT family and specialized medical models such as PubMedBERT and BioBERT, alongside general-purpose models such as Mistral, LlaMA and GPT-2. We also evaluate the performance of the zero-shot and few-shot learning paradigms of larger language models GPt3&4. Experimental results demonstrate that our approach significantly improves the accuracy of cervical cancer classification compared to traditional methods. This work highlights the potential of integrating generative AI and small language models to enhance medical diagnosis, offering a promising direction for patient-friendly AI-assisted healthcare applications.},
  keywords={Generative AI;Biological system modeling;Text categorization;Predictive models;Transformers;Natural language processing;Robustness;Prognostics and health management;Cervical cancer;Medical diagnostic imaging;Machine Learning;Cervical Cancer classification;Text Classification;Language Models;LLMs;SLMs;GenAI;BERT},
  doi={10.1109/ICPHM65385.2025.11062057},
  ISSN={2166-5656},
  month={June},}@ARTICLE{9129779,
  author={Muhammad, Khan and Khan, Salman and Ser, Javier Del and Albuquerque, Victor Hugo C. de},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Deep Learning for Multigrade Brain Tumor Classification in Smart Healthcare Systems: A Prospective Survey}, 
  year={2021},
  volume={32},
  number={2},
  pages={507-522},
  abstract={Brain tumor is one of the most dangerous cancers in people of all ages, and its grade recognition is a challenging problem for radiologists in health monitoring and automated diagnosis. Recently, numerous methods based on deep learning have been presented in the literature for brain tumor classification (BTC) in order to assist radiologists for a better diagnostic analysis. In this overview, we present an in-depth review of the surveys published so far and recent deep learning-based methods for BTC. Our survey covers the main steps of deep learning-based BTC methods, including preprocessing, features extraction, and classification, along with their achievements and limitations. We also investigate the state-of-the-art convolutional neural network models for BTC by performing extensive experiments using transfer learning with and without data augmentation. Furthermore, this overview describes available benchmark data sets used for the evaluation of BTC. Finally, this survey does not only look into the past literature on the topic but also steps on it to delve into the future of this area and enumerates some research directions that should be followed in the future, especially for personalized and smart healthcare.},
  keywords={Tumors;Image segmentation;Deep learning;Feature extraction;Medical diagnostic imaging;Biological system modeling;Artificial intelligence;biomedical data analysis;brain tumor classification (BTC);deep learning;health monitoring;smart healthcare;transfer learning},
  doi={10.1109/TNNLS.2020.2995800},
  ISSN={2162-2388},
  month={Feb},}@INPROCEEDINGS{9746675,
  author={Lee, Sang-Hoon and Kim, Ji-Hoon and Lee, Kang-Eun and Lee, Seong-Whan},
  booktitle={ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={FRE-GAN 2: Fast and Efficient Frequency-Consistent Audio Synthesis}, 
  year={2022},
  volume={},
  number={},
  pages={6192-6196},
  abstract={Although recent advances in neural vocoder have shown significant improvement, most of these models have a trade-off between audio quality and computational complexity. Since the large model has a limitation on the low-resource devices, a more efficient neural vocoder should synthesize high-quality audio for practical applicability. In this paper, we present Fre-GAN 2, a fast and efficient high-quality audio synthesis model. For fast synthesis, Fre-GAN 2 only synthesizes low and high-frequency parts of the audio, and we leverage the inverse discrete wavelet transform to reproduce the target-resolution audio in the generator. Additionally, we also introduce adversarial periodic feature distillation, which makes the model synthesize high-quality audio with only a small parameter. The experimental results show the superiority of Fre-GAN 2 in audio quality. Furthermore, Fre-GAN 2 has a 10.91× generation acceleration, and the parameters are compressed by 21.23× than Fre-GAN.},
  keywords={Frequency synthesizers;Computational modeling;Vocoders;Conferences;Transforms;Signal processing;Generators;audio synthesis;neural vocoder;generative adversarial networks;speech synthesis;test-to-speech},
  doi={10.1109/ICASSP43922.2022.9746675},
  ISSN={2379-190X},
  month={May},}@INPROCEEDINGS{9727687,
  author={Zhan, Jie and Zhang, Tengfei and Yu, Yang},
  booktitle={2021 China Automation Congress (CAC)}, 
  title={Multi-source Heterogeneous Data Aggregation Method Based on Adversarial Domain Adaptation}, 
  year={2021},
  volume={},
  number={},
  pages={4856-4861},
  abstract={In recent years, with the deployment of ubiquitous sensing, the aggregation method of massive multi-source heterogeneous data has become a hot research topic. At present, although the adversarial domain adaptation in transfer learning can achieve effective results in processing tasks such as data classification, there are few methods that can well apply the adversarial domain adaptation network to the scenario of multi-source heterogeneous data aggregation. The existing adversarial domain adaptation methods are mostly applied to the transfer of homogeneous features in single source domain. However, the samples in actual application scenarios are often heterogeneous data from multiple sources. To achieve feature alignment and the aggregation of multi-source heterogeneous data at the same time, a multi-source heterogeneous data aggregation method based on adversarial domain adaptation is proposed in this paper, by embedding a mapping neural network for heterogeneous data in the adversarial network, and adding weight parameters to measure the contribution of multiple source domains’ features and classes. The feasibility of the network structure is analyzed theoretically, and the effectiveness of the method is verified through experiments.},
  keywords={Weight measurement;Automation;Neural networks;Transfer learning;Data visualization;Data aggregation;Time measurement;transfer learning;domain adaptation;generative adversarial network;multi-source heterogeneous data;data aggregation},
  doi={10.1109/CAC53003.2021.9727687},
  ISSN={2688-0938},
  month={Oct},}@ARTICLE{11048470,
  author={Nhung Nguyen, Hong and Kim, Yong-Hwa},
  journal={IEEE Access}, 
  title={GAN-Based Driver’s Head Motion Using Millimeter-Wave Radar Sensor}, 
  year={2025},
  volume={13},
  number={},
  pages={108359-108367},
  abstract={The recognition of driver behavior is critical for enhancing road safety, with a particular focus on monitoring driver attention. Radar-based recognition systems offer distinct advantages over traditional computer vision methods, including enhanced user privacy, reduced power consumption, and greater flexibility in sensor deployment. This study leverages a compact millimeter-wave radar to monitor driver head movements, providing a non-intrusive method to assess driver focus. A frequency-modulated continuous-wave (FMCW) radar sensor is strategically positioned on the vehicle’s steering wheel, capturing reflection patterns that vary with the driver’s head orientation. These patterns are used to identify and classify different head movements, which are indicative of the driver’s attention level. To achieve accurate classification, a deep learning approach is adopted, utilizing a Generative Adversarial Network (GAN) model. This model is particularly effective in scenarios with limited labeled data, as it can generate high-quality synthetic data to augment training. Experimental results demonstrate that the proposed method reliably classifies all relevant head movement scenarios, underscoring its potential for real-world applications in driver monitoring systems.},
  keywords={Radar;Generative adversarial networks;Head;Vehicles;Radar imaging;Generators;Monitoring;Magnetic heads;Deep learning;Labeling;Automotive frequency-modulated continuous wave (FMCW) radar;GAN},
  doi={10.1109/ACCESS.2025.3582079},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11149917,
  author={Hsu, Yu-Jung and Wu, Yi-Chieh},
  booktitle={2025 IEEE International Conference on Advanced Visual and Signal-Based Systems (AVSS)}, 
  title={From Temporal to Spatial: A Transformer-GAN Approach for Fall Prediction}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={The study aims to construct a fall detection system. We propose a Transformer-based Generative Adversarial Network (GAN) trained on human keypoint skeleton features. We arrange temporal information spatially, allowing the attention layers to learn movement details. Moreover, the objective of the GAN is to generate corresponding future motion sequences based on the current data. Consequently, the model can predict the next movement and determine whether an individual in the scene has fallen. Finally, the fall detection process employs distance metrics, including Chebyshev distance and Dynamic Time Warping (DTW), with a threshold determined through Bayesian decision theory. Experimental results demonstrate the model’s robust performance, achieving an F1-score of approximately 0.93 when applied to the evaluation set using the Chebyshev distance threshold. The framework effectively distinguishes fall and non-fall instances, showing particular strength in handling challenging scenarios like transitional movements.},
  keywords={Visualization;Stability criteria;Dynamics;Transforms;Predictive models;Chebyshev approximation;Generative adversarial networks;Transformers;Fall detection;Usability},
  doi={10.1109/AVSS65446.2025.11149917},
  ISSN={2643-6213},
  month={Aug},}@INPROCEEDINGS{10001896,
  author={Akita, Yuto and Nakayama, Ryohei and Hizukuri, Akiyoshi and Kido, Shoji},
  booktitle={2022 Joint 12th International Conference on Soft Computing and Intelligent Systems and 23rd International Symposium on Advanced Intelligent Systems (SCIS&ISIS)}, 
  title={Anomaly Detection for Lung CT image Using Efficient GAN with Learning Stabilizations}, 
  year={2022},
  volume={},
  number={},
  pages={1-2},
  abstract={CT (Computed Tomography) screening for detection of early cancer is becoming widespread. The purpose of this study was to develop a computerized method for detecting any lesion in CT images. Our database consisted of lung CT images for 100 abnormal cases and 300 normal cases. In the proposed method, learning stabilization methods were introduced to Efficient GAN (Generative Adversarial Network). The classification accuracy, sensitivity, specificity, and the area under the receiver operating characteristic curve of the receiver for the proposed method were 61%, 62%, 60%, and 0.66, respectively. Those evaluation indices were greater than a conventional Efficient GAN without learning stabilizations (44%, 46%, 42%, and 0.44).},
  keywords={Sensitivity;Databases;Computed tomography;Lung;Receivers;Generative adversarial networks;Image restoration;Efficient GAN;Learning stabilization;Anomaly detection},
  doi={10.1109/SCISISIS55246.2022.10001896},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9702415,
  author={Srivastava, Mayank and Bhatia, Aditi},
  booktitle={2021 5th International Conference on Information Systems and Computer Networks (ISCON)}, 
  title={City Scene Anomaly Detection: Survey}, 
  year={2021},
  volume={},
  number={},
  pages={1-5},
  abstract={Computer vision has evolved over time and is playing a vital role in many applications reducing the need for human supervision. In today's world, video cameras are installed at every corner producing huge amounts of data every second. This data has the potential to produce valuable insights which can produce beneficiary results for researchers as well as the society. Today artificial intelligence is redefining the lives of millions of people. This paper presents works which are done in the field of detecting anomalies. We have revisited several of the researches and have summarized their works. We have also implemented the code and present our work in this paper.},
  keywords={Computer vision;Codes;Computational modeling;Video sequences;Urban areas;Artificial neural networks;Cameras;Artificial Intelligence;Convolutional Neural Networks;Anomaly Detection},
  doi={10.1109/ISCON52037.2021.9702415},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9857306,
  author={Dravid, Amil and Schiffers, Florian and Gong, Boqing and Katsaggelos, Aggelos K.},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={medXGAN: Visual Explanations for Medical Classifiers through a Generative Latent Space}, 
  year={2022},
  volume={},
  number={},
  pages={2935-2944},
  abstract={Despite the surge of deep learning in the past decade, some users are skeptical to deploy these models in practice due to their black-box nature. Specifically, in the medical space where there are severe potential repercussions, we need to develop methods to gain confidence in the models’ decisions. To this end, we propose a novel medical imaging generative adversarial framework, medXGAN (medical eXplanation GAN), to visually explain what a medical classifier focuses on in its binary predictions. By encoding domain knowledge of medical images, we are able to disentangle anatomical structure and pathology, leading to fine-grained visualization through latent interpolation. Furthermore, we optimize the latent space such that interpolation explains how the features contribute to the classifier’s output. Our method outperforms baselines such as Gradient-Weighted Class Activation Mapping (Grad-CAM) and Integrated Gradients in localization and explanatory ability. Additionally, a combination of the medXGAN with Integrated Gradients can yield explanations more robust to noise. The project page with code is available at: https://avdravid.github.io/medXGANpage/.},
  keywords={Location awareness;Visualization;Interpolation;Pathology;Codes;Neural networks;Anatomical structure},
  doi={10.1109/CVPRW56347.2022.00331},
  ISSN={2160-7516},
  month={June},}@INPROCEEDINGS{9725006,
  author={Chen, Jiangan and Du, Rong},
  booktitle={2021 2nd International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={Music Generation using Deep Learning with Spectrogram Analysis}, 
  year={2021},
  volume={},
  number={},
  pages={589-595},
  abstract={In the popular music market, the music producer takes a large amount of time and effort to produce one piece of decent music. It would be much more productive and efficient if music generation with the machine was made possible, thus our study. LSTM and GAN are implemented in our study. To analyze the generated music, we used spectrogram analysis. We generated several pieces of music using LSTM and GAN. From the loss curves, we see a promising generation of the two models. Analyzed with a spectrogram, we see the music generated by LSTM is more coherent, while music generated by GAN is more rhythmic. The results we have are relatively good, and the spectrogram analysis part is intelligible and clear. Despite our hardware and computing ability limitations, we still have promising results generated from our models. For future works, we might be able to generate undistinguishable music with little effort.},
  keywords={Training;Seminars;Analytical models;Computational modeling;Reinforcement learning;Predictive models;Generative adversarial networks;music generation;LSTM;GAN;spectrogram;deep learning;generative model;MIDI},
  doi={10.1109/AINIT54228.2021.00119},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10541170,
  author={Briggs, Morgan and Cross, Miranda},
  booktitle={2024 4th International Conference on Applied Artificial Intelligence (ICAPAI)}, 
  title={Generative AI: Threatening Established Human Rights Instruments at Scale}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={We assess the impacts of generative AI technologies within the context of rights and freedoms enshrined in two codified international covenants, the International Covenant on Civil and Political Rights (ICCPR) and the International Covenant on Economic, Social, and Cultural Rights (ICESCR). Additionally, the UN Guiding Principles on Business and Human Rights (UNGPs) are explored in tandem to further motivate the requirement for businesses and States to carry out human rights due diligence processes. By providing specific use cases and examples of how generative AI’s cross-sectoral risks threaten established human rights and freedoms, such as the freedom of opinion and expression and the right to privacy, we argue that proper governance and accountability mechanisms for generative AI should be based in codified international human rights instruments and support frameworks such as the UNGPs. This paper is intended to serve as a catalogue of concrete evidence to support the enforcement and uptake of human rights due diligence processes and foster conversations at the policy level.},
  keywords={Economics;Privacy;Ethics;Generative AI;Instruments;Oral communication;Cultural differences;Generative AI;AI Ethics;Human Rights;Human Rights Due Diligence;UN Guiding Principles on Business and Human Rights},
  doi={10.1109/ICAPAI61893.2024.10541170},
  ISSN={},
  month={April},}@INBOOK{10788521,
  author={Chander, Bhanu},
  booktitle={Deep Learning for Personalized Healthcare Services}, 
  title={Advanced deep learning techniques and applications in healthcare services}, 
  year={2021},
  volume={},
  number={},
  pages={37-66},
  abstract={: In recent times, healthcare informatics has become a rising field of interest for researchers worldwide because of its critical outcomes on civilization. The healthcare sector is unique from every other industry. It is a high priority segment; moreover, patients view that it is important to receive the highest intensity of care and despite the cost. In addition, assimilating various kinds of knowledge that emerge from the current biomedical study using body sensors, text and images, electronic health reports, and composite high-dimensional artifacts, which can then be merged with biomedical data, remains a crucial point of discussion in transmuting healthcare. The inclusion of traditional, statistical, data mining, artificial intelligence (AI), and machine learning (ML) appliances in healthcare has good fallouts. However, there are issues with high-dimensional data, where, typically, most data need to be first executed to obtain valuable features, and build forecasts or clustering models based on such data. From historical data, the latest developments in deep learning (DL) methodologies offer novel efficient standards to achieve continuous learning representations from extensive complex data. DL’s success in other real-world applications also offers exciting and useful results in healthcare. It could be a medium for explaining massive biomedical information for better human health. This chapter presents the state-of-the-art deep learning schemes that are applied to healthcare services. Then, factors that impact the operation of DL in healthcare are explained. Besides, we evaluate the potential and feebleness of the existing works and explore the advanced applications of DL in healthcare. We conclude the chapter with known challenges and confer possible future directions.},
  keywords={Medical services;Artificial intelligence;Medical diagnostic imaging;Artificial neural networks;Big Data;Deep learning;Monitoring;Data mining;Computed tomography;Accuracy},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9783110708172},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10788521},}
