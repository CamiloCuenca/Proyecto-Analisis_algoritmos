@INPROCEEDINGS{10903910,
  author={Rivas, Luis and Singh, Varun Kumar and Khandelwal, Vinayak and Watkins, Lanier},
  booktitle={2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC)}, 
  title={Securing QR Codes Infrastructure Using AI to Detect Malicious Activity}, 
  year={2025},
  volume={},
  number={},
  pages={0076-0083},
  abstract={With the advent of QR Codes, mobile devices, and computers, users can exchange information quickly but not se-curely. QR Codes-based attacks are rising rapidly, threatening the trust of this extensively used technology. Whether you use it at a restaurant, conference, or payment station, QR Codes inherently rely on user trust to safeguard transactions. Phishing scams using fake codes have increased by over 50%, while using QR vector malware attacks have increased by over 2400% since 2020 [3]–[5]. These alarming results suggest that integrity protections must be reinstated to restore public trust. This research addresses these challenges by leveraging Artificial intelligence (AI) and third-party services to detect QR Codes-based threats. We propose a Secure QR Codes system employing anomaly detection, risk signaling, and four machine-learning models trained on standard and malicious QR Codes. Using encryption engines, AI-based predictions, Application Programming Interface (API), proxy services, and AI assessment modules, the integrated solution identified over 96% simulated real-world attacks like phishing, exfiltration, injection, and code execution. Our approach detects QR Codes with modified structures. It provides a practical, non-proprietary, web-deployable solution to predict and mitigate these threats, restoring trust in QR Codes systems across various applications.},
  keywords={Codes;Phishing;QR codes;Machine learning;Vectors;Mobile handsets;Malware;Protection;Standards;Application programming interfaces;QR Codes;QR Code Security;Cybersecurity;Anomaly Detection;Secure QR Code Infrastructure;Machine Learning (ML);Artificial Intelligence (AI)},
  doi={10.1109/CCWC62904.2025.10903910},
  ISSN={},
  month={Jan},}@ARTICLE{10114940,
  author={Zhu, Taiyu and Li, Kezhi and Herrero, Pau and Georgiou, Pantelis},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={GluGAN: Generating Personalized Glucose Time Series Using Generative Adversarial Networks}, 
  year={2023},
  volume={27},
  number={10},
  pages={5122-5133},
  abstract={Time series data generated by continuous glucose monitoring sensors offer unparalleled opportunities for developing data-driven approaches, especially deep learning-based models, in diabetes management. Although these approaches have achieved state-of-the-art performance in various fields such as glucose prediction in type 1 diabetes (T1D), challenges remain in the acquisition of large-scale individual data for personalized modeling due to the elevated cost of clinical trials and data privacy regulations. In this work, we introduce GluGAN, a framework specifically designed for generating personalized glucose time series based on generative adversarial networks (GANs). Employing recurrent neural network (RNN) modules, the proposed framework uses a combination of unsupervised and supervised training to learn temporal dynamics in latent spaces. Aiming to assess the quality of synthetic data, we apply clinical metrics, distance scores, and discriminative and predictive scores computed by post-hoc RNNs in evaluation. Across three clinical datasets with 47 T1D subjects (including one publicly available and two proprietary datasets), GluGAN achieved better performance for all the considered metrics when compared with four baseline GAN models. The performance of data augmentation is evaluated by three machine learning-based glucose predictors. Using the training sets augmented by GluGAN significantly reduced the root mean square error for the predictors over 30 and 60-minute horizons. The results suggest that GluGAN is an effective method in generating high-quality synthetic glucose time series and has the potential to be used for evaluating the effectiveness of automated insulin delivery algorithms and as a digital twin to substitute for pre-clinical trials.},
  keywords={Glucose;Time series analysis;Insulin;Generative adversarial networks;Monitoring;Data models;Training;Artificial intelligence (AI);continuous glucose monitoring (CGM);diabetes;generative adversarial network (GAN);glucose time series},
  doi={10.1109/JBHI.2023.3271615},
  ISSN={2168-2208},
  month={Oct},}@INPROCEEDINGS{9418456,
  author={Sangeetha, K N and Singh, Seema and Usha, B A and Anirudh R S IshaanGonnagar, Thrivikram},
  booktitle={2021 5th International Conference on Computing Methodologies and Communication (ICCMC)}, 
  title={Security Enhancement in Image Steganography using Generative Adversarial Networks}, 
  year={2021},
  volume={},
  number={},
  pages={178-185},
  abstract={The technique of concealing information within photos, videos, music etc. is called image steganography. Steganography excels in that it does not disclose the presence of any data as opposed to other methods such as cryptology which only try to prevent reading the said data. A major factor in assessing the steganography algorithms is its security. Steganography has subsequently earned remarkable ground in the drawn-out battle with steganalysis. Steganography must be able to resist identification by steganalysis algorithms in order to boost the reliability of image steganography. Conventional steganography methods embed secret data into an image, which ultimately leaves a mark of alteration that can be detected by increasingly advanced AI-based steganalysis algorithms. Within this study, the authorscompare a method of concealing secret information within photos utilizing generative adversarial networks with conventional cryptography techniques. It is hypothesized that this technique has a clear potential to challenge best-in-class steganalysis measurements by producing high performing and increasingly stable payloads.},
  keywords={Knowledge engineering;Machine learning algorithms;Resists;Machine learning;Tools;Reliability theory;Generative adversarial networks;Security Enhancement;Artificial Intelligence;Image Steganography;Neural Networks;Generative Adversarial Networks;Data Integrity;Extraction Reliability},
  doi={10.1109/ICCMC51019.2021.9418456},
  ISSN={},
  month={April},}@INPROCEEDINGS{11080975,
  author={J, Infant Shervin M and Maity, Avishikta and P, Selvaraj},
  booktitle={2025 3rd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS)}, 
  title={Enhancing Cancer Detection and Prevention using Advanced Deep Learning and AI Techniques}, 
  year={2025},
  volume={},
  number={},
  pages={1797-1801},
  abstract={Accurate and early detection of kidney-related abnormalities such as cysts, stones, and tumors is vital for effective cancer prevention and treatment. The motivation behind this research stems from the urgent need to improve early detection of kidney-related abnormalities, particularly Renal Cell Carcinoma (RCC), which often progresses undetected due to subtle early-stage symptoms. Deep learning, particularly convolutional and transformer-based models, offers immense potential in medical imaging. However, to be clinically viable, such systems must not only deliver high performance but also address concerns like dataset imbalance and lack of model interpretability. This work aims to bridge these gaps by developing a robust, explainable, and efficient classification model—FusionNet—that leverages hybrid architectures and explainable AI to support radiologists in clinical decision-making and ultimately contribute to reducing mortality from late-detected renal diseases. This work also introduces a comprehensive AI-based framework that leverages deep learning techniques to enhance the classification of grayscale kidney CT images. We exploited the traditional data augmentation methods and synthetic image generation to address class imbalance using Deep Convolutional Generative Adversarial Networks (DCGANs). The proposed FusionNet architecture integrates ResNet18 for spatial feature extraction and a Vision Transformer (ViT) for capturing global contextual information, providing a powerful hybrid model for multi-class classification. The proposed system demonstrates improved accuracy and balanced performance across all four classes— Normal, Cyst, Stone, and Tumor—outperforming prior models like Kidney Ensemble-Net and transformer-only approaches. Furthermore, model explainability is ensured using Grad-CAM and LIME, helping clinicians visualize decision-making regions and enhancing trust in the AI system. This approach offers a promising step forward in AI-assisted renal cancer detection and clinical decision support.},
  keywords={Deep learning;Computer vision;Accuracy;Prevention and mitigation;Decision making;Computer architecture;Transformers;Cancer detection;Kidney;Biomedical imaging;Kidney cancer detection;deep learning;class imbalance;DCGAN;ResNet18;Vision Transformer;FusionNet;interpretability;Grad-CAM;LIME;medical imaging},
  doi={10.1109/ICSSAS66150.2025.11080975},
  ISSN={},
  month={June},}@INPROCEEDINGS{9836726,
  author={Lu, Dongzhe and Fei, Jinlong and Liu, Long and Li, Zecun},
  booktitle={2022 IEEE 10th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={A GAN-based Method for Generating SQL Injection Attack Samples}, 
  year={2022},
  volume={10},
  number={},
  pages={1827-1833},
  abstract={Due to the simplicity of implementation and high threat level, SQL injection attacks are one of the oldest, most prevalent, and most destructive types of security attacks on Web-based information systems. With the continuous development and maturity of artificial intelligence technology, it has been a general trend to use AI technology to detect SQL injection. The selection of the sample set is the deciding factor of whether AI algorithms can achieve good results, but dataset with tagged specific category labels are difficult to obtain. This paper focuses on data augmentation to learn similar feature representations from the original data to improve the accuracy of classification models. In this paper, deep convolutional generative adversarial networks combined with genetic algorithms are applied to the field of Web vulnerability attacks, aiming to solve the problem of insufficient number of SQL injection samples. This method is also expected to be applied to sample generation for other types of vulnerability attacks.},
  keywords={SQL injection;Generative adversarial networks;Market research;Data models;Security;Artificial intelligence;Usability;SQL injection;data augmentation;generative adversarial network;genetic algorithm;Web vulnerability},
  doi={10.1109/ITAIC54216.2022.9836726},
  ISSN={2693-2865},
  month={June},}@INPROCEEDINGS{10985162,
  author={M, Jenish and Chandar, J. Praveen},
  booktitle={2025 International Conference on Intelligent Computing and Control Systems (ICICCS)}, 
  title={Spinal Vision CNN-Driven Techniques for Accurate Stenosis Detection}, 
  year={2025},
  volume={},
  number={},
  pages={1302-1307},
  abstract={The need for accurate and efficient detection method of spinal stenosis, a condition that involves the narrowing of the spaces in the spine, so as to avoid serious complications. In this project, SPINAL VISION, we present a deep learn based model with Convolutional Neural Nets (CNNs) to improve spinal stenosis detection accuracy. Based on the advanced image preprocessing and image classification techniques, the system achieves high diagnostic precision and sensitivity for reliable identification of stenotic regions within spinal imaging. This proposed methodology is faster and more accurate than traditional diagnostics leading to early intervention and better patient outcomes. Future work will integrate multimodal data and further investigate the interpretability of models for clinical applicability.},
  keywords={Deep learning;Accuracy;Sensitivity;Spine;Process control;Streaming media;Predictive models;Convolutional neural networks;Reliability;Biomedical imaging;Spinal stenosis;convolutional neural networks;deep learning;image processing;medical imaging;diagnostic accuracy},
  doi={10.1109/ICICCS65191.2025.10985162},
  ISSN={},
  month={March},}@INPROCEEDINGS{10241080,
  author={Sun, Xingyu and Zhao, Daxing and Yuan, Jing},
  booktitle={2023 42nd Chinese Control Conference (CCC)}, 
  title={Image Enhancement of Computational Correlation Imaging Based on Generative Adversarial Network at Low Sampling Rates}, 
  year={2023},
  volume={},
  number={},
  pages={7406-7411},
  abstract={In this paper, a computational correlation imaging (CCI) framework based on a generative adversarial network is proposed to efficiently reconstruct target images. CCI collects the light emitted by the projector through a gray scale camera, and the digital micromirror device (DMD) in the projector modulates the light field. Although traditional correlation imaging can reconstruct the image of an object through multiple correlation operations, the visual quality of the reconstructed image is affected by a lot of noises. To solve this problem, an end-to-end generation adversarial network is designed in the paper to improve the quality of images reconstructed from traditional correlation imaging. It can reconstruct high-quality images at low sampling rates. In the proposed method, A generative adversarial network based on conditional computational correlation imaging (GANC3I) is trained, and the image of the measured object is recovered directly from the two-dimensional light signal. Compared with the traditional methods, its peak signal to noise ratio (PSNR) and structural similarity index method (SSIM) are respectively 5–6 times and 7–8 times higher than the original image, the proposed method has clearer image details and stronger robustness than the methods based on compressed sensing (CS) and convolutional neural network (CNN) network.},
  keywords={Visualization;Correlation;PSNR;Neural networks;Generative adversarial networks;Robustness;Light fields;Image enhancement;computational correlation imaging;generative adversarial network},
  doi={10.23919/CCC58697.2023.10241080},
  ISSN={1934-1768},
  month={July},}@ARTICLE{10557650,
  author={Wang, Jiacheng and Du, Hongyang and Niyato, Dusit and Xiong, Zehui and Kang, Jiawen and Ai, Bo and Han, Zhu and In Kim, Dong},
  journal={IEEE Journal on Selected Areas in Communications}, 
  title={Generative Artificial Intelligence Assisted Wireless Sensing: Human Flow Detection in Practical Communication Environments}, 
  year={2024},
  volume={42},
  number={10},
  pages={2737-2753},
  abstract={Groundbreaking applications such as ChatGPT have heightened research interest in generative artificial intelligence (GAI). Essentially, GAI excels not only in content generation but also signal processing, offering support for wireless sensing. Hence, we introduce a novel GAI-assisted human flow detection system (G-HFD). Rigorously, G-HFD first uses the channel state information (CSI) to estimate the velocity and acceleration of propagation path length change of the human induced reflection (HIR). Then, given the strong inference ability of the diffusion model, we propose a unified weighted conditional diffusion model (UW-CDM) to denoise the estimation results, enabling detection of the number of targets. Next, we use the CSI obtained by a uniform linear array with wavelength spacing to estimate the HIR’s time of flight and direction of arrival (DoA). In this process, UW-CDM solves the problem of ambiguous DoA spectrum, ensuring accurate DoA estimation. Finally, through clustering, G-HFD determines the number of subflows and the number of targets in each subflow, i.e., the subflow size. The evaluation based on practical downlink communication signals shows G-HFD’s accuracy of subflow size detection can reach 91%. This validates its effectiveness and underscores the significant potential of GAI in the context of wireless sensing.},
  keywords={Artificial intelligence;Feature extraction;Direction-of-arrival estimation;Wireless sensor networks;Wireless communication;Estimation;Sensors;Generative AI;wireless sensing;human flow detection},
  doi={10.1109/JSAC.2024.3414628},
  ISSN={1558-0008},
  month={Oct},}@ARTICLE{10903146,
  author={Alimardani, Armin},
  journal={IEEE Transactions on Technology and Society}, 
  title={Borderline Disaster: An Empirical Study on Student Usage of GenAI in a Law Assignment}, 
  year={2025},
  volume={6},
  number={2},
  pages={210-219},
  abstract={This empirical study examines the outcomes of integrating Generative AI (GenAI) into a law assignment at the School of Law, University of Wollongong, Australia. Despite receiving instructions on the importance of verifying GenAI outputs and feedback on their attempts to use these tools effectively, a notable portion of students included fabricated or inaccurate information that had been generated by AI in their assignments. This overreliance on AI outputs suggests that instruction and guided practice alone may not sufficiently mitigate the risks associated with the inappropriate use of GenAI. A particularly concerning issue is the difficulty of identifying AI-generated inaccuracies in assessment tasks, which often requires considerable time and effort. Consequently, such errors may go unnoticed, potentially allowing students to bypass the development of essential skills, such as critical thinking and the ability to independently evaluate the accuracy, credibility, and relevance of information. Addressing overreliance on GenAI will require developing robust strategies that should be implemented for the entire duration of a student’s university degree to ensure they engage with AI tools effectively and responsibly.},
  keywords={Law;Ethics;Artificial intelligence;Australia;Training;Reliability;Government;Engineering profession;Disasters;Cognition;Educational technology;generative AI;higher education;large language models;legal education;legal profession},
  doi={10.1109/TTS.2025.3540978},
  ISSN={2637-6415},
  month={June},}@ARTICLE{11175315,
  author={Sang, Qingbing and Li, Qian and Liu, Lixiong and Deng, Zhaohong and Wu, Xiaojun and Bovik, Alan C.},
  journal={IEEE Transactions on Image Processing}, 
  title={No-Reference Image Quality Assessment Leveraging GenAI Images}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={In recent years, deep learning-based methods have made significant progress on the image quality assessment problem; however, challenges remain arising from the lack of annotated, real-world training data and consequent poor generalization ability. Towards addressing these challenges, we propose a no-reference image quality assessment (NR-IQA) method based on generative AI (GenAI) images. Specifically, we use GenAI images as reference images, employing a cold diffusion model to generate distorted images of four different distortion types, and we label these distorted images using a full-reference model, thereby making it possible to construct a large-scale pre-training dataset. We use this resource generation method to facilitate NR-IQA model building. We deploy a Multi-scale Cross Attention Block (MCAB) and a Scale Simple Attention Module (SSAM) to enhance feature representation by extracting multi-scale feature information from both the channel and spatial dimensions that are predictive of image quality. Extensive experiments on eight public databases demonstrate that the proposed method achieves state-of-the-art (SOTA) performance. A public release of all the codes associated with this work will be made available on GitHub.},
  keywords={Diffusion models;Image quality;Distortion;Training;Feature extraction;Computational modeling;Quality assessment;Degradation;Image synthesis;Accuracy;Image Quality Assessment;Diffusion Model;Artificial Intelligence Generated Images;Self-Supervised Learning},
  doi={10.1109/TIP.2025.3610238},
  ISSN={1941-0042},
  month={},}@ARTICLE{10416322,
  author={de Souza, Cleidson Ronald Botelho and Rodríguez-Pérez, Gema and Basha, Manaal and Yoon, Dongwook and Beschastnikh, Ivan},
  journal={IEEE Software}, 
  title={The Fine Balance Between Helping With Your Job and Taking It: AI Code Assistants Come to the Fore}, 
  year={2024},
  volume={41},
  number={6},
  pages={111-118},
  abstract={AI code generation tools are reshaping the software engineering landscape. We provide recommendations for practitioners interested in these tools based on narratives we have collected regarding two AI code generation tools, GitHub Copilot and Tabnine.},
  keywords={Codes;Blogs;Artificial intelligence;Social networking (online);Software engineering;Software development management;Productivity;Generative AI;Software tools;Software development management;Law;Licenses},
  doi={10.1109/MS.2024.3357787},
  ISSN={1937-4194},
  month={Nov},}@INBOOK{10614280,
  author={Ojanperä, Tero},
  booktitle={AI Revolution: Mastering AI for Personal and Organizational Growth}, 
  title={9 Singularity &#x2013; AI Surpasses Human Understanding}, 
  year={2024},
  volume={},
  number={},
  pages={135-142},
  abstract={"The AI Revolution" is a practical guide to using new AI tools, such as ChatGPT, DALLE and Midjourney. Learn how to multiply your productivity by guiding or prompting AI in various ways. The book also introduces Microsoft Copilot, Google Bard, and Adobe Photoshop Generative Fill, among other new applications. ChatGPT reached a hundred million users in just two months after its release, faster than any other application before. This marked the advent of the generative AI era. Generative AI models generate text, images, music, videos, and even 3D models in ways previously thought impossible for machines. The book explains in an understandable manner how these AI models work. The book provides examples of how AI increases productivity, which professions are changing or disappearing, and how job markets will evolve in the coming years. With this book, you'll learn to recognize the opportunities and risks AI offers. Understand what this change demands from individuals and companies and what strategic skills are required. The book also covers legal questions caused by generative AI, like copyrights, data protection, and AI regulation. It also ponders societal impacts. AI produces content, thus influencing language, culture, and even worldviews. Therefore, it's crucial to understand by whom and how AI is trained. The AI revolution started by ChatGPT is just the beginning. This handbook is for you if you want to keep up with the rapid development of AI.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770042314},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10614280},}@INPROCEEDINGS{10737556,
  author={Shakhatova, Aliya and Tolkyn, Mirgalikyzy and Gulnara, Zhetessova and Ozhigin, Sergey and Amir, Mosavi and Kozhanov, Murat},
  booktitle={2024 IEEE 22nd Jubilee International Symposium on Intelligent Systems and Informatics (SISY)}, 
  title={Applied Machine Learning in Geophysics Taxonomy Review Bibliometrics and Trends in Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={000251-000258},
  abstract={This article presents a methodology to identify key studies using machine learning (ML) in geophysics. We created a comprehensive database of fundamental articles for a systematic review. The main goal is to classify the applications and methods of ML in geophysics through a modified PRISMA approach. The study results offer current insights into the trends and developments of ML applications in geophysics. This article presents a systematic method for identifying and analyzing significant studies that apply ML in geophysics. We created a detailed database of essential articles relevant to this field. Using a modified PRISMA guideline, we conducted a thorough review to evaluate and categorize the literature. The main goal of this review is to provide a clear classification of ML applications and methods in geophysics. We documented how ML techniques are used for various geophysical problems, including data analysis, pattern recognition, and predictive modeling. This classification helps clarify the range of ML applications in geophysics and highlights the specific methods and tools used. Our findings offer an updated view of current trends and developments in ML applications within geophysics. By analyzing the progress of ML and their effectiveness in geophysical applications, this study reveals emerging trends and suggests future research directions.},
  keywords={Surveys;Support vector machines;Technological innovation;Systematics;Databases;Taxonomy;Decision making;Geophysics;Machine learning;Market research;Artificial intelligence;machine learning;geophysics;literature review;mathematics;survey;generative artificial intelligence;deep learning;data science;big data;generative AI;data mining;applied artificial intelligence;applied mathematics;applied informatics;information systems;soft computing;geoscience;earth science;earth systems},
  doi={10.1109/SISY62279.2024.10737556},
  ISSN={1949-0488},
  month={Sep.},}@INPROCEEDINGS{9824835,
  author={Chen, Jiajun and Gao, Yin and Zhou, Yingjun and Liu, Zhuang and Li, Da peng and Zhang, Man},
  booktitle={2022 International Wireless Communications and Mobile Computing (IWCMC)}, 
  title={Machine Learning enabled Wireless Communication Network System}, 
  year={2022},
  volume={},
  number={},
  pages={1285-1289},
  abstract={The 5th generation of mobile communication will support three application scenarios of eMBB, uRLLC and mMTC. To meet the requirements, wireless communication systems needs to continue to develop, with the development of artificial intelligence(AI). Machine learning (ML) is expected to optimize wireless systems by tackling complex problems which cannot be solved using traditional mathematical models. AI/ML techniques, which could extract features from raw data in the wireless access network and predict the future state by the previous features, are useful to network optimization. In this paper, indicative use cases using AI/ML techniques in conjunction with its benefits, and its potential deployment solutions are introduced. Furthermore, this paper provides the consideration on the potential prototype of future wireless communication system.},
  keywords={Wireless communication;Wireless networks;Prototypes;Machine learning;Ultra reliable low latency communication;Feature extraction;Mobile communication;Machine learning;LSTM;Network Energy Saving;Load Balancing;Mobility Optimization;load prediction;trajectory prediction},
  doi={10.1109/IWCMC55113.2022.9824835},
  ISSN={2376-6506},
  month={May},}@INPROCEEDINGS{10884131,
  author={Nguyen, Dang and Gupta, Sunil and Do, Kien and Nguyen, Thin and Venkatesh, Svetha},
  booktitle={2024 IEEE International Conference on Data Mining (ICDM)}, 
  title={Generating Realistic Tabular Data with Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={330-339},
  abstract={While most generative models show achievements in image data generation, few are developed for tabular data generation. Recently, due to success of large language models (LLM) in diverse tasks, they have also been used for tabular data generation. However, these methods do not capture the correct correlation between the features and the target variable, hindering their applications in downstream predictive tasks. To address this problem, we propose a LLM-based method with three important improvements to correctly capture the ground-truth feature-class correlation in the real data. First, we propose a novel permutation strategy for the input data in the fine-tuning phase. Second, we propose a feature-conditional sampling approach to generate synthetic samples. Finally, we generate the labels by constructing prompts based on the generated samples to query our fine-tuned LLM. Our extensive experiments show that our method significantly outperforms 10 SOTA baselines on 20 datasets in downstream tasks. It also produces highly realistic synthetic samples in terms of quality and diversity. More importantly, classifiers trained with our synthetic data can even compete with classifiers trained with the original data on half of the benchmark datasets, which is a significant achievement in tabular data generation.},
  keywords={Correlation;Large language models;Data collection;Benchmark testing;Prediction algorithms;Data models;Data mining;Synthetic data;classification;generative model;large language models;tabular data generation;realistic tabular samples},
  doi={10.1109/ICDM59182.2024.00040},
  ISSN={2374-8486},
  month={Dec},}@INPROCEEDINGS{11050496,
  author={Joshi, Nandan and Guven, Erhan},
  booktitle={2025 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Improved Molecular Generation Through Attribute-Driven Integrative Embeddings and GAN Selectivity}, 
  year={2025},
  volume={},
  number={},
  pages={463-468},
  abstract={The growing demand for molecules with tailored properties in fields such as drug discovery and chemical engineering has driven advancements in computational methods for molecular design. Machine learning based approaches for denovo molecular generation have recently garnered significant attention. This paper introduces a transformer-based vector embedding generator combined with a modified Generative Adversarial Network (GAN) to generate molecules with desired properties. The embedding generator utilizes a novel molecular descriptor, integrating Morgan fingerprints with global molecular attributes, enabling the transformer to capture local functional groups and broader molecular characteristics. Modifying the GAN generator loss function ensures the generation of molecules with specific desired properties. The transformer achieves a reconversion accuracy of 94 % when translating molecular descriptors back to SMILES strings, validating the utility of the proposed embeddings for generative tasks. The approach is validated by generating novel odorant molecules using a labeled dataset of odorant and non-odorant compounds. With the modified rangeloss function, the GAN exclusively generates odorant molecules. This work underscores the potential of combining novel vector embeddings with transformers and modified GAN architectures to accelerate the discovery of tailored molecules, offering a robust tool for diverse molecular design applications.},
  keywords={Design methodology;Diversity reception;Machine learning;Computer architecture;Fingerprint recognition;Generative adversarial networks;Transformers;Generators;Vectors;Drug discovery;de-novo molecular generation;generative adversarial networks;molecular descriptor design;transformer embeddings},
  doi={10.1109/CAI64502.2025.00085},
  ISSN={},
  month={May},}@ARTICLE{9930483,
  author={He, Xiangjie and Chang, Zhengwei and Zhang, Linghao and Xu, Houdong and Chen, Hongbo and Luo, Zhongqiang},
  journal={IEEE Access}, 
  title={A Survey of Defect Detection Applications Based on Generative Adversarial Networks}, 
  year={2022},
  volume={10},
  number={},
  pages={113493-113512},
  abstract={With the development of science and technology and the progress of the times, automation and intelligence have been popularized in manufacturing in all walks of life. With the progress of productivity, product defect detection has become an indispensable part. However, in practical scenarios, the application of supervised deep learning algorithms in the field of defect detection is limited due to the difficulty and unpredictability of obtaining defect samples. In recent years, semi-supervised and unsupervised deep learning algorithms have attracted more and more attention in various defect detection tasks. Generative adversarial networks (GAN), as an unsupervised learning algorithm, has been widely used in defect detection tasks in various fields due to its powerful generation ability. In order to provide some inspiration for the researchers who intend to use GAN for defect detection research. In this paper, the theoretical basis, technical development and practical application of GAN based defect detection are reviewed. This paper also discusses the current outstanding problems of GAN and GAN-based defect detection, and makes a detailed prediction and analysis of the possible future research directions. This paper summarizes the relevant literature on the research progress and application status of GAN based defect detection, which provides certain technical information for researchers who are interested in researching GAN and hope to apply it to defect detection tasks.},
  keywords={Task analysis;Generative adversarial networks;Deep learning;Inspection;Computer vision;Anomaly detection;Object detection;Deep learning;generating adversarial networks;defect detection;adversarial learning},
  doi={10.1109/ACCESS.2022.3217227},
  ISSN={2169-3536},
  month={},}@ARTICLE{10935297,
  author={Zhao, Yikun and Feng, Lei and Zhou, Fanqin and Li, Wenjing and Xiong, Zehui and Du, Hongyang and Wu, Celimuge and Guo, Song and Quek, Tony Q.S. and Han, Zhu},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Energy-Efficient Over-the-Air Computation for Federated Generative Model Fine-Tuning in Unmanned Vehicle-Assisted Disaster Relief}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={The utilization of emergent generative artificial intelligence (GAI) within the realm of unmanned vehicles (UVs) can boost edge intelligence and potentially enhance the efficiency and effectiveness of rescue operations. However, to facilitate specialized generative edge intelligence in dynamic UV networks, GAI models need to tap into local data and conduct online fine-tuning, and the dispersed distribution of UVs makes distributed fine-tuning paradigms crucial. Although the federated generative model fine-tuning brings a potential solution, the large number of parameter transmissions involved in its fine-tuning process are often constrained by communication bottlenecks, which are more pronounced for resource-constrained UV networks. To cope with these challenges, we introduce an energy-efficient GAI model fine-tuning framework for the hierarchical UV networks, which employs over-the-air technology to save computational resource costs for unmanned aerial vehicle (UAV) during federated aggregation within a federated learning paradigm. Thereafter, we study the resource allocation problem in the fine-tuning process of the generative model and formulate a joint optimization problem for the bandwidth allocation, power control, computation resource allocation, and denoising factor control, aiming to minimize the system energy consumption. Then, we decouple the original problem into four tractable subproblems, and propose a block coordinate descent algorithm to solve them iteratively. Particularly, we derive a closed-form solution for the denoising factor to minimize the local model uploading transmission energy consumption under a specific AirComp communication error threshold. Simulation based on the state-of-the-art generative models shows that our AirComp-assisted federated generative model fine-tuning scheme can achieve satisfactory customized field-of-view image generation capability compared with the traditional fine-tuning scheme in an energy-efficient way.},
  keywords={Atmospheric modeling;Computational modeling;Training;Artificial intelligence;Energy consumption;Resource management;Disasters;Autonomous aerial vehicles;Energy efficiency;Data models;Generative artificial intelligence;unmanned vehicle network;federated learning;multi-access computing},
  doi={10.1109/TCCN.2025.3553315},
  ISSN={2332-7731},
  month={},}@INPROCEEDINGS{10591881,
  author={Huang, Yijun and Zhang, Jihan and Chen, Xi and Lam, Alan H. F. and Chen, Ben M.},
  booktitle={2024 IEEE 18th International Conference on Control & Automation (ICCA)}, 
  title={From Simulation to Prediction: Enhancing Digital Twins with Advanced Generative AI Technologies}, 
  year={2024},
  volume={},
  number={},
  pages={490-495},
  abstract={The integration of Generative Artificial Intelli-gence (GAI) into Digital Twins (DTs) marks a revolutionary stride in the evolution of virtual replicas for physical systems. This paper explores the cutting-edge advancements brought about by the incorporation of GAI technologies, specifically Large Language Models (LLMs), into DTs. These technologies herald a significant transformation, propelling DTs beyond their current capabilities to become more dynamic, predictive, and interactive tools that can simulate complex scenarios and anticipate future conditions with remarkable accuracy. By systematically examining the levels of GAI integration within DTs, this study delves into the methodologies and strategies for embedding AI capabilities into these virtual models. It outlines how GAI can enhance the functionality of DTs, enabling them to generate synthetic datasets, simulate unprecedented events, and provide actionable insights with LLM-based agents for decision-making. Furthermore, the paper highlights the extended applications of DTs, enriched by GAI, across various domains such as healthcare, urban planning, and beyond. The implications of this integration for operational efficiency, innovation, and decision-making processes are profound. By offering a comprehensive overview of the current state of technology and projecting future trends, this paper aims to provide stakeholders with a deep understanding of the syner-gistic potential between GAI and DTs. It sets the stage for a new era of DT technologies, where the boundaries of what can be achieved with virtual models are continually expanding.},
  keywords={Technological innovation;Generative AI;Decision making;Urban planning;Medical services;Propulsion;Real-time systems},
  doi={10.1109/ICCA62789.2024.10591881},
  ISSN={1948-3457},
  month={June},}@INPROCEEDINGS{9649890,
  author={Nicodeme, Claire},
  booktitle={2021 21st International Conference on Control, Automation and Systems (ICCAS)}, 
  title={Detection Of Defective Videosurveillance Camera In Train Stations}, 
  year={2021},
  volume={},
  number={},
  pages={1185-1189},
  abstract={In the past decade, imaging sensors have known noteworthy improvements and a growing interest from both academics and industries. In particular, video surveillance cameras have widely spread across the world, and many systems depends on their inputs. Either to provide visual information to human operators or to give input data to Artificial Intelligence algorithms, it is important to be able to assess the proper operation of sensors and the quality of images and videos they record. However, existing methods are either very specific (detect only limited kinds of default) or perform poorly in unpredictable environment. Artificial Intelligence algorithms have proven to be useful to detect anomalies and could be used to highlight a wide range of defaults, including noise, obstruction and intentional tampering such as knocking the camera out of alignment. In this work, the authors present a comparative study for defective camera detection, in the context of video surveillance.},
  keywords={Image sensors;Industries;Deep learning;Visualization;Manuals;Detectors;Cameras;video surveillance;image quality;anomaly detection;camera tampering;artificial intelligence},
  doi={10.23919/ICCAS52745.2021.9649890},
  ISSN={2642-3901},
  month={Oct},}@INPROCEEDINGS{10899657,
  author={Ren, Shiqi and Zhang, Yu},
  booktitle={2024 7th International Conference on Algorithms, Computing and Artificial Intelligence (ACAI)}, 
  title={Terrain Image Classification Based on Vision Transformer Deep Learning Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Terrain image classification is an important research direction in the field of remote sensing and computer vision, aiming to realize automatic recognition and classification of different landform features through the analysis and processing of terrain images. In this paper, a deep learning algorithm based on Vision Transformer (ViT) is used to classify terrain images, and the performance of the algorithm in this task is systematically evaluated. In the process of model construction, we first imported the Vision Transformer model and made corresponding parameter Settings to ensure its adaptability and effectiveness. After training, it is observed that the loss function of the training set decreases from the initial value of 2.84 to 0.35, a decrease of 2.49, indicating that the model tends to converge in continuous optimization. At the same time, the accuracy is also significantly improved, from 55.9% to 86.8%, an increase of 30.9%, showing the enhancement of the model's learning ability. For the validation set, loss also decreased from 0.78 to 0.47, a decrease of 0.31, while accuracy increased from 60.1% to 83.5%, an increase of 23.4%. These results further prove the good performance of the model on different data sets and its convergence trend. In addition, through the evaluation of the test set, we get more specific performance indicators: The accuracy of the terrain image classification model based on Vision Transformer on the test set reaches 89.9%, the Precision is 0.9615, the Recall is 0.9494, and the F1-score is 0.9554. These indicators show that the model not only has high classification accuracy, but also performs well in generalization ability. To sum up, this research demonstrates the effectiveness of Vision Transformer deep learning algorithm in terrain image classification, and provides a new solution idea and method for related fields. Through continuous optimization and adjustment, the algorithm is expected to achieve more extensive promotion in practical applications, and bring positive impact on geographic information system, environmental monitoring and other fields..},
  keywords={Training;Deep learning;Computer vision;Adaptation models;Accuracy;Transformers;Classification algorithms;Numerical models;Optimization;Image classification;Terrain image classification;Vision Transformer;Deep learning},
  doi={10.1109/ACAI63924.2024.10899657},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9823673,
  author={Rawat, Ujjwal and Singh, Surender},
  booktitle={2022 2nd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)}, 
  title={Challenges in Music Generation Using Deep Learning}, 
  year={2022},
  volume={},
  number={},
  pages={553-558},
  abstract={Owing to its massive potential, the field of Artificial Intelligence is booming at an unprecedented rate. With the increase in efficiency and accuracy in prediction, classification, translation, and other traditional tasks, deep learning has also witnessed a surge in applications in various other sectors, one of them being music generation. This paper provides a brief introduction to the process of creating fresh new music from a collection of existing music as the sample, using deep learning architectures and training techniques. The creation of music using automated processes in the absence of human intelligence is not a fresh proposal and has been influencing human curiosity for a long time. Being an innovative and complex venture, it poses certain unorthodox challenges which are needed to be addressed. This paper focuses on the analysis of these challenges and explores the scope of this fascinating pursuit.},
  keywords={Deep learning;Training;Computational modeling;Reinforcement learning;Streaming media;Proposals;Artificial intelligence;Deep learning;Music;Music Generation Systems;Challenges},
  doi={10.1109/ICACITE53722.2022.9823673},
  ISSN={},
  month={April},}@INPROCEEDINGS{11112407,
  author={Kınay, Orkun and Tekdemir, Barış and Gökyılmaz, Göktuğ and Yavuz, Ekmel and Ay, Berk and Balcısoy, Selim and Bilimleri Fakültesi, Doğa},
  booktitle={2025 33rd Signal Processing and Communications Applications Conference (SIU)}, 
  title={DJ-AI: Intelligent Playlist Sorting and Seamless Generative Transitions}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={The music listening experience has improved and become more accessible over time with digital playlists and real-time DJ transitions. However, existing systems do not cover fully amateur DJs and end users. Unlike traditional recommendation algorithms, DJ-AI analyzes songs not only based on user preferences but also their musical features to generate optimal sequences and seamless transitions. Graph-based optimization methods have been used for playlist arrangement, while MusicGen and MERT embeddings have been integrated to enhance transition smoothness. Experimental results show that the proposed method improves the listener experience by increasing transition compatibility.},
  keywords={Music;Signal processing algorithms;Optimization methods;Signal processing;Real-time systems;Multiple signal classification;Artificial intelligence;Sorting;Music Transition;Playlist Optimization;Artificial Intelligence},
  doi={10.1109/SIU66497.2025.11112407},
  ISSN={2165-0608},
  month={June},}@INPROCEEDINGS{11126238,
  author={Jabbour, Jason and Reddi, Vijay Janapa},
  booktitle={2024 ACM/IEEE International Conference On Computer Aided Design (ICCAD)}, 
  title={Generative AI Agents in Autonomous Machines: A Safety Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={1-13},
  abstract={The integration of Generative Artificial Intelligence (AI) into autonomous machines represents a major paradigm shift in how these systems operate and unlocks new solutions to problems once deemed intractable. Although generative AI agents provide unparalleled capabilities, they also have unique safety concerns. These challenges require robust safeguards, especially for autonomous machines that operate in high-stakes environments. This work investigates the evolving safety requirements when generative models are integrated as agents into physical autonomous machines, comparing these to safety considerations in less critical AI applications. We explore the challenges and opportunities to ensure the safe deployment of generative AI-driven autonomous machines. Furthermore, we provide a forward-looking perspective on the future of AI-driven autonomous systems and emphasize the importance of evaluating and communicating safety risks. As an important step towards addressing these concerns, we recommend the development and implementation of comprehensive safety scorecards for the use of generative AI technologies in autonomous machines.},
  keywords={Design automation;Autonomous systems;Generative AI;Large language models;Computational modeling;Transformers;Safety;Machinery;Robots;Generative AI;Embodied AI;Robotics;Diffusion;Transformers;Safety;Autonomous Systems;Large Language Models (LLMs)},
  doi={10.1145/3676536.3698390},
  ISSN={1558-2434},
  month={Oct},}@ARTICLE{11082575,
  author={Ozyilkan, Ezgi and Sangwan, Neha and Chaharsooghi, Farhad Shirani and Rini, Stefano},
  journal={IEEE BITS the Information Theory Magazine}, 
  title={Event Report: Unconference on Generative AI and LLMs Session At ISIT 2023 and ISIT 2024}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={In an era marked by the rapid and transformative rise of generative AI, professionals, researchers, and students alike are compelled to engage in meaningful discussions with their peers to navigate the profound changes and opportunities this technology brings. Reflecting this shared sentiment, the inaugural unconference event on Generative AI and Large Language Models (LLMs) was held at ISIT 2023, followed by its second edition in 2024. Key discussions covered the integration of AI into academic tasks, its transformative effects on education, its influence on research methodologies, and career implications. Reflective conversations highlighted ethical concerns and the evolving academic landscape that accompanies them. The unconference format, characterized by a lack of a strict structure, encouraged participants to engage in free-flowing discussions and share their insights openly. This year's unconference event at ISIT 2024 concluded with a call to action for participants to contribute to the ethical and effective use of generative AI.},
  keywords={Artificial intelligence;Generative AI;Industries;Oral communication;Training;Information theory;Ethics;Engineering profession;Reflection;Navigation},
  doi={10.1109/MBITS.2025.3590010},
  ISSN={2692-4110},
  month={},}@INPROCEEDINGS{10920736,
  author={Kang, Minjae and Cho, Gunhee and Yun, Sungju and Lee, Yeonjoon},
  booktitle={2025 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Differentially Private Synthetic Adversarial Network Traffic Generation Based on Tabular Diffusion Processes}, 
  year={2025},
  volume={},
  number={},
  pages={0620-0626},
  abstract={IDS is becoming increasingly important as networks become more vulnerable to a variety of attacks. However, traditional ML and DL-based IDS have limited accuracy and false positive rates due to the lack of open adversarial network datasets and vendors' concerns regarding potential data leakage during the training process. To address these challenges, VAE and GAN-based network packet generation models have emerged, but they still face issues with low data fidelity. In this context, TabDDPM is a suitable option for generating network packets, as it surpasses VAE and GAN in accurately capturing data distribution characteristics and effectively learning the inherent structure of network packet formats. Despite its potential, research applying TabDDPM to network packet generation has not yet been explored. In this paper, we propose and evaluate DP-NetDDPM, a novel framework that enables adversarial network traffic generation while preserving both fidelity and privacy guarantees. Specifically, we examine the use of diffusion to generate adversarial network packet datasets and compare its performance with baseline models. Our framework focuses on three key criteria: data fidelity, adaptability for machine learning applications, and data privacy. The results show that DP-NetDDPM surpasses traditional models in both fidelity and adaptability, achieving a notable 72% improvement in fidelity and a 45% enhancement in adaptability over baselines.},
  keywords={Training;Adaptation models;Privacy;Telecommunication traffic;Machine learning;Network security;Generative adversarial networks;Data models;Faces;Payloads;Adversarial Network Traffic Generation;Data Synthesis;Tabular Diffusion;Differential Privacy},
  doi={10.1109/ICAIIC64266.2025.10920736},
  ISSN={2831-6983},
  month={Feb},}@ARTICLE{10884873,
  author={He, Wenji and Yao, Haipeng and Ren, Xiaoxu and Liu, Yuanling and Xiong, Zehui and Niyato, Dusit},
  journal={IEEE Network}, 
  title={Advancing End-to-End Programmable Networks: Exploring the Interplay of Generative AI with Opportunities and Challenges}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={The rapid proliferation of Internet of Things (IoT) devices and the continuous evolution of network communications are reshaping the global network landscape, demanding advanced management techniques to address the growing complexity of data and service requirements. Generative Artificial Intelligence (GAI) has emerged as a transformative solution, enabling multi-modal data analytics and decision-making. However, traditional network architectures lack the scalability and flexibility required to accommodate the diverse resources and compute-intensive demands of GAI. To address these challenges, we propose a novel end-to-end programmable network framework that provides scalable, flexible support for enhanced storage, computation, and transmission capabilities. This architecture empowers compute-intensive and data-intensive applications by leveraging specialized GAI models designed for network optimization, dynamically enhancing resource allocation and operational efficiency. Furthermore, we implement a GAI-assisted framework to improve DDoS detection within programmable networks. By using diffusion models for synthetic data generation, the framework addresses data scarcity in privacy-constrained environments and simplifies GAI model deployment through knowledge distillation. Simulation results validate the proposed framework’s effectiveness, demonstrating significant improvements in detection latency and detection accuracy.},
  keywords={Real-time systems;Computational modeling;Resource management;Computer architecture;Adaptation models;Optimization;Data models;Training;Network architecture;Image edge detection;Generative Artificial Intelligence;Programmable Networks;Network Optimization;Network Resource Allocation},
  doi={10.1109/MNET.2025.3541820},
  ISSN={1558-156X},
  month={},}@INBOOK{10950668,
  author={Orange, Erica},
  booktitle={AI + The New Human Frontier: Reimagining the Future of Time, Trust + Truth}, 
  title={Generative AI's Inflection Point}, 
  year={2024},
  volume={},
  number={},
  pages={35-41},
  abstract={Summary <p>One key difference with more recent innovations such as generative AI is that they diffuse much faster than previous disruptive tech. This is templosion at play&#x2014;the collapsing of time horizons from centuries to decades to years to months to weeks. Generative AI very quickly captured the public's imagination. The AI chatbot ChatGPT, created by OpenAI, drew 1 million users after only a few days of its unveiling in November 2023, making it one of the fastest product launches in history. The rise of AI chatbots has also sparked discussions among experts about the impact on search engines like Google. To really understand generative AI's true impact, we must separate out hype from reality. A major limiting factor in AI reaching its full business potential, however, is the availability of individuals with the right skills and capabilities to continue innovating around AI.</p>},
  keywords={Artificial intelligence;Chatbots;Internet;Companies;Generative AI;Business;Technological innovation;Search engines;Visualization;Productivity},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394276998},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10950668},}@ARTICLE{9996183,
  author={Zhao, Chen and Dai, Xingyuan and Lv, Yisheng and Niu, Jinglong and Lin, Yilun},
  journal={IEEE Transactions on Systems, Man, and Cybernetics: Systems}, 
  title={Decentralized Autonomous Operations and Organizations in TransVerse: Federated Intelligence for Smart Mobility}, 
  year={2023},
  volume={53},
  number={4},
  pages={2062-2072},
  abstract={Human and social factors are essential to transportation systems, yet top-down management fails to consider them sufficiently. Consequently, management strategies are not tailored to human needs and are inadequate in providing transportation intelligence. This article investigates a management architecture based on decentralized/distributed autonomous operations/organizations (DAOs) that considers both the technical and societal aspects in our transportation metaverse, TransVerse. This design maps people’s transportation needs in physical space to their digital counterparts in cyberspace, utilizing blockchain technology to guarantee the secure exchange of information and ultimately bring about the Internet of Minds (IoM). With the federated intelligence that emerged in IoM, we can devise reliable and prompt traffic decisions by incorporating consensus, community voting, and smart contracts into the organizational, coordination, and execution structure. Details on operational procedures and key technologies are also covered. To demonstrate the efficacy of DAOs-based management, a case study of world model-driven cooperative signal control is provided, indicating its promising application in future transportation management.},
  keywords={Transportation;Behavioral sciences;Organizations;Cyberspace;Social factors;Roads;Vehicle dynamics;Artificial systems;computational experiments;parallel execution (ACP);blockchain;cyber–physical–social systems (CPSS);decentralized/distributed autonomous operations and organizations (DAOs);intelligent transportation systems (ITS)},
  doi={10.1109/TSMC.2022.3228914},
  ISSN={2168-2232},
  month={April},}@INPROCEEDINGS{4739793,
  author={Fan, Tiantian and Zong, Hua and Yu, Changjun and Liu, Mei and Quan, Taifan},
  booktitle={2008 Second International Symposium on Intelligent Information Technology Application}, 
  title={Research on NFE Model of Multi-Sensor Information Fusion}, 
  year={2008},
  volume={2},
  number={},
  pages={394-398},
  abstract={To study information fusion method under complex environment, a highly intelligent information fusion model is put forward- the NFE model. This model is an organic combination of neural network, fuzzy reasoning and expert system. Considering various factors which influence the performance of sensor, the NFE confidence estimator is presented from the engineering application point of view. This paper presents principles, frameworks as well as key algorithms of the NFE model, and makes a comparison between the NFE model and traditional fuzzy neural network model. Simulation experiments prove that the NFE model can realize target recognition more effectively against sensor failures and strong interference, and the results are more reliable.},
  keywords={Intelligent sensors;Expert systems;Artificial intelligence;Neural networks;Fuzzy neural networks;Sensor systems;Fuzzy reasoning;Humans;State estimation;Sensor phenomena and characterization;information fusion;neural network;fuzzy reasoning;expert system},
  doi={10.1109/IITA.2008.553},
  ISSN={},
  month={Dec},}@ARTICLE{10372211,
  author={Dash, Ankan and Ye, Junyi and Wang, Guiling},
  journal={IEEE Access}, 
  title={A Review of Generative Adversarial Networks (GANs) and Its Applications in a Wide Variety of Disciplines: From Medical to Remote Sensing}, 
  year={2024},
  volume={12},
  number={},
  pages={18330-18357},
  abstract={We look into Generative Adversarial Network (GAN), its prevalent variants and applications in a number of sectors. GANs combine two neural networks that compete against one another using zero-sum game theory, allowing them to create much crisper and discrete outputs. GANs can be used to perform image processing, video generation and prediction, among other computer vision applications. GANs can also be utilised for a variety of science-related activities, including protein engineering, astronomical data processing, remote sensing image dehazing, and crystal structure synthesis. Other notable fields where GANs have made gains include finance, marketing, fashion design, sports, and music. Therefore in this article we provide a comprehensive overview of the applications of GANs in a wide variety of disciplines. We first cover the theory supporting GAN, GAN variants, and the metrics to evaluate GANs. Then we present how GAN and its variants can be applied in twelve domains, ranging from STEM fields, such as astronomy and biology, to business fields, such as marketing and finance, and to arts, such as music. As a result, researchers from other fields may grasp how GANs work and apply them to their own study. To the best of our knowledge, this article provides the most comprehensive survey of GAN’s applications in different field.},
  keywords={Generative adversarial networks;Generators;Training;Measurement;Surveys;Remote sensing;Neural networks;Deep learning;generative adversarial networks;computer vision;time series;applications},
  doi={10.1109/ACCESS.2023.3346273},
  ISSN={2169-3536},
  month={},}@ARTICLE{9426908,
  author={Shin, Heean and Sun, Sukkyu and Lee, Joonnyong and Kim, Hee Chan},
  journal={IEEE Access}, 
  title={Complementary Photoplethysmogram Synthesis From Electrocardiogram Using Generative Adversarial Network}, 
  year={2021},
  volume={9},
  number={},
  pages={70639-70649},
  abstract={Photoplethysmogram (PPG) is one of the most widely measured biosignals alongside electrocardiogram (ECG). Due to the simplicity of measurement and the advent of wearable devices, there have been growing interest in using PPG for a variety of healthcare applications such as cardiac function estimation. However, unlike ECG, there are not many large databases available for clinically significant analyses of PPG. To overcome this issue, a Generative Adversarial Network-based model to generate PPG using ECG as input is proposed. The network was trained using a large open database of biosignals measured from surgical patients and was externally validated using an alternative database sourced from another hospital. The generated PPG was compared with the reference PPG using percent root mean square difference (PRD) and Pearson correlation coefficient to evaluate the morphological similarity. Additionally, heart rate measured from the reference ECG, reference PPG, and generated PPG, and compared through repeated measure analysis of variance to test for any significant differences. The mean PRD was 32± 10% and the mean correlation coefficient was 0.95± 0.05 in the test dataset. The HR from the three biosignals showed no significant difference with a p-value of 0.473. When the optimized GAN model was tested on atrial fibrillation ECG from a third dataset, the mean correlation coefficient between the generated PPG heart rate and the ECG heart rate was 0.94± 0.15, with paired t-test resulting in p-value of 0.64. The results indicate that the proposed method may provide a valuable alternative to augmenting biosignal databases that are abundant in one signal while lacking in another.},
  keywords={Electrocardiography;Generative adversarial networks;Generators;Databases;Heart rate;Training;Optimization;Data augmentation;deep learning;electrocardiogram;generative adversarial networks;photoplethysmogram},
  doi={10.1109/ACCESS.2021.3078534},
  ISSN={2169-3536},
  month={},}@ARTICLE{9475986,
  author={Anaam, Asaad and Bu-Omer, Hani M. and Gofuku, Akio},
  journal={IEEE Access}, 
  title={Studying the Applicability of Generative Adversarial Networks on HEp-2 Cell Image Augmentation}, 
  year={2021},
  volume={9},
  number={},
  pages={98048-98059},
  abstract={The Anti-Nuclear Antibodies (ANAs) testing is the primary serological diagnosis screening test for autoimmune diseases. ANAs testing is conducted mainly by the Indirect Immunofluorescence (IIF) on Human Epithelial cell-substrate (HEp-2) protocol. However, due to its high variability, human-subjectivity, and low throughput, there is an insistent need to develop an efficient Computer-Aided Diagnosis system (CADs) to automate this protocol. Many recently proposed Convolutional Neural Networks (CNNs) demonstrated promising results in HEp-2 cell image classification, which is the main task of the HE-p2 IIF protocol. However, the lack of large labeled datasets is still the main challenge in this field. This work provides a detailed study of the applicability of using generative adversarial networks (GANs) algorithms as an augmentation method. Different types of GANs were employed to synthesize HEp-2 cell images to address the data scarcity problem. For systematic comparison, empirical quantitative metrics were implemented to evaluate different GAN models’ performance of learning the real data representations. The results of this work showed that though the high visual similarity with the real images, GANs’ capacity to generate diverse data is still limited. This deficiency in the generated data diversity is found to be of a crucial impact when used as a standalone method for augmentation. However, combining limited-size GANs-generated data with classic augmentation improves the classification accuracy across different variants of CNNs. Our results demonstrated a competitive performance for the overall classification accuracy and the mean class accuracy of the HEp-2 cell image classification task.},
  keywords={Computer architecture;Task analysis;Microprocessors;Generative adversarial networks;Biomedical imaging;Measurement;Feature extraction;Computer-aided diagnosis systems (CADs);convolutional neural networks (CNNs);data augmentation;data diversity;evaluation metrics;generative adversarial networks (GANs);HEp-2 cell image classification},
  doi={10.1109/ACCESS.2021.3095391},
  ISSN={2169-3536},
  month={},}@ARTICLE{9780264,
  author={Zhou, Qiongyi and Du, Changde and Li, Dan and Wang, Haibao and Liu, Jian K. and He, Huiguang},
  journal={IEEE Transactions on Cognitive and Developmental Systems}, 
  title={Neural Encoding and Decoding With a Flow-Based Invertible Generative Model}, 
  year={2023},
  volume={15},
  number={2},
  pages={724-736},
  abstract={Recent studies on visual neural encoding and decoding have made significant progress, benefiting from the latest advances in deep neural networks having powerful representations. However, two challenges remain. First, the current decoding algorithms based on deep generative models always struggle with information losses, which may cause blurry reconstruction. Second, most studies model the neural encoding and decoding processes separately, neglecting the inherent dual relationship between the two tasks. In this article, we propose a novel neural encoding and decoding method with a two-stage flow-based invertible generative (FLIG) model to tackle the above issues. First, a convolutional autoencoder (CAE) is trained to bridge the stimuli space and the feature space. Second, an adversarial cross-modal normalizing flow is trained to build up a bijective transformation between image features and neural signals, with local and global constraints imposed on the latent space to render cross-modal alignment. The method eventually achieves bidirectional generation of visual stimuli and neural responses with a combination of the flow-based generator and the autoencoder. The FLIG model can minimize information losses and unify neural encoding and decoding into a single framework. Experimental results on different neural signals containing spike signals and functional magnetic resonance imaging demonstrate that our model achieves the best comprehensive performance among the comparison models.},
  keywords={Decoding;Encoding;Visualization;Brain modeling;Feature extraction;Task analysis;Training;Cross-modal generation;neural decoding;neural encoding;normalizing flow},
  doi={10.1109/TCDS.2022.3176977},
  ISSN={2379-8939},
  month={June},}@INPROCEEDINGS{8451685,
  author={Wang, Jidong and Li, Yanan and Pang, Zhangyang and Wang, Donghui},
  booktitle={2018 25th IEEE International Conference on Image Processing (ICIP)}, 
  title={Generating Manifold-Aligned Semantic Feature for Zero-Shot Learning}, 
  year={2018},
  volume={},
  number={},
  pages={1613-1617},
  abstract={Zero-shot learning (ZSL) is a task that requires us to recognize novel classes whose visual instances are not included in training set. Most of the state-of-the-art ZSL methods resort to semantic embeddings to learn a visual-semantic mapping. However, there exists a huge gap between image feature space and the semantic embedding space. The main difficulty lies in how to learn a mapping with strong transfer ability to unseen classes. Motivated by the strong domain transfer ability of Generative Adversarial Networks (GAN), we introduce a new method to generate new semantic embeddings, whose manifold is designed to align with the manifold in the image feature space. These new semantic embeddings can boost the transfer ability of the visual-semantic mapping to unseen classes, thus leading to the improvement of ZSL performance. Experimental results on benchmarks show the superiority over the state-of-the-arts.},
  keywords={Semantics;Visualization;Gallium nitride;Manifolds;Training;Probability distribution;Generators;Zero-shot learning;generative adversarial nets;semantic embedding generation;manifold alignment},
  doi={10.1109/ICIP.2018.8451685},
  ISSN={2381-8549},
  month={Oct},}@INPROCEEDINGS{10240781,
  author={Zhou, Ying and Pei, Shenghu and Chen, Haiyong and Liu, Kun},
  booktitle={2023 42nd Chinese Control Conference (CCC)}, 
  title={Generation of Solar Cell Defect Images Based on Multi-Perceptual Fields and Attention Mechanism}, 
  year={2023},
  volume={},
  number={},
  pages={7484-7489},
  abstract={Aiming at the problem of the small sample size of some defect images in solar cell images, a defect images generation model combining multi-perceptual fields and attention mechanism is proposed. Firstly, a generative adversarial network model with dual discriminators is constructed to improve the quality of the generated images; secondly, for focusing accurately on and extracting defect information of different scales with the interference of complex backgrounds, an improved spatial attention module is integrated into the proposed multi-perceptual fields feature extraction and is used in the generator and discriminators; finally, to enhance the texture detail and clarity of the final generated images, the structural similarity (SSIM) loss and the peak signal-to-noise ratio (PSNR) loss are added to the loss function to train the generator, and the generated defect images are mean filtered. The results of the generation experiments on the solar electroluminescence (EL) dataset for 3 different scales of defect images show that the SSIM and PSNR values are higher compared to the existing optimal generation algorithms.},
  keywords={PSNR;Image synthesis;Photovoltaic cells;Interference;Filtering algorithms;Feature extraction;Information filters;generative adversarial nets;attention mechanism;multi-perceptual fields;dual discriminators;solar cells},
  doi={10.23919/CCC58697.2023.10240781},
  ISSN={1934-1768},
  month={July},}@INPROCEEDINGS{11155751,
  author={Nimal, R. J. Golden Renjith and Sangamaeswaran, R. and Hariharan, R. and Divahar, S. Robin and Selvi, S. Saravana and Ebinraj, S},
  booktitle={2025 IEEE 6th International Conference in Robotics and Manufacturing Automation (ROMA)}, 
  title={AI-Driven Material Design and Discovery: Revolutionizing the Development of Novel Alloys and Composites}, 
  year={2025},
  volume={},
  number={},
  pages={113-118},
  abstract={Artificial intelligence (AI) integration in material science led to fundamental transformations in the discovery process of new alloys and composites which simultaneously accelerated development while reducing expenses. The field of material development relies on excessive experimental practices and computer modeling according to traditional methods. Artificial intelligence methods using deep learning and machine learning (ML) enable accelerated large data set analysis which leads to material quality prediction and optimal material composition discovery and better performing material development. The artificial intelligence methods explore new material compositions through combination of high-throughput simulations and experimental data and generative algorithms to invent materials suitable for aerospace engineering and biomedical applications and renewable energy field. The combination of sustainable substitutes discovery alongside minimized resource consumption enables AI-driven discovery to enhance sustainability. Great as its transforming capabilities may be the method faces challenges such as sparse data and difficulty interpreting models along with lab validation needs. Resolving material discovery for high-performance alloys and composites in the following generation remains the central target of this research that examines AI-driven approaches along with their methods and potential future developments.},
  keywords={Materials science and technology;Machine learning algorithms;Biological system modeling;Computational modeling;Discrete Fourier transforms;Metals;Prediction algorithms;Data models;Sustainable development;Standards;Artificial intelligence (AI);novel Alloy design;machine learning;high entropy alloys;GNNs;CNNs;DFT;MD},
  doi={10.1109/ROMA66616.2025.11155751},
  ISSN={},
  month={Aug},}@ARTICLE{10807241,
  author={Zhang, Fan and Wang, Luyao and Zhang, Xinhong},
  journal={Big Data Mining and Analytics}, 
  title={Desensitized Financial Data Generation Based on Generative Adversarial Network and Differential Privacy}, 
  year={2025},
  volume={8},
  number={1},
  pages={103-117},
  abstract={Artificial intelligence has been widely used in the financial field, such as credit risk assessment, fraud detection, and stock prediction. Training deep learning models requires a significant amount of data, but financial data often contains sensitive information, some of which cannot be disclosed. Acquiring large amounts of financial data for training deep learning models is a pressing issue that needs to be addressed. This paper proposes a Noise Visibility Function-Differential Privacy Generative Adversarial Network (NVF-DPGAN) model, which generates privacy preserving data similar to the original data, and can be applied to data augmentation for deep learning. This study conducts experiments using financial data from China Stock Market & Accounting Research (CSMAR) database. It compares the generated data with real data from various perspectives, including mean, probability density distribution, and correlation. The experimental results show that the two datasets exhibit similar characteristics. A time series forecasting model is trained on the generated data and the real data separately, and their prediction results are closely aligned. NVF-DPGAN model is feasible and practical in terms of financial data enhancement and privacy protection. This method can also be generalized to other fields, such as the privacy protection of medical data.},
  keywords={Deep learning;Training;Differential privacy;Noise;Data enhancement;Time series analysis;Generative adversarial networks;Data models;Protection;Stock markets;data desensitization;Generative Adversarial Network (GAN);differential privacy;noise visibility function},
  doi={10.26599/BDMA.2024.9020047},
  ISSN={2097-406X},
  month={February},}@INPROCEEDINGS{10269895,
  author={D'souza, Jason and Kadam, Vedant and Shinde, Pranali and Saxena, Kumkum},
  booktitle={2023 3rd Asian Conference on Innovation in Technology (ASIANCON)}, 
  title={The Quest for Fairness: A Comparative Study of Accuracy in AI Hiring Systems}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Artificial Intelligence and Machine Learning based models are increasingly being used in developing models for automating recruitment systems in various Multinational Companies as well as small-scale and developing companies and industries. With the advent of Generative Artificial Intelligence models, many companies are turning towards automatic and AI-based hiring software. J.P. Morgan uses HireVue, Deloitte incorporates Hiretual for talent sourcing and engagement, IBM incorporates X.ai for automated interview scheduling and many more. But in all these systems a major factor to consider is the biasness in the models and how to detect them and efficiently mitigate them. Some models unwillingly sometimes amplify the biases in the models and results in faulty and biased predictions which can lead to the inaccurate matching of profiles to the job description and result in wayward hiring processes. The biasness can be based on the parameters such as gender, address, etc., or biasness transferred from the programmer into the model while creating the model which is called unconscious bias. The models implemented in the research are Random Forest, Decision Tree, KNN Tree, AdaBoost, and XGBoost. The accuracies for the models Random Forest, Decision Tree, KNN Tree, AdaBoost, and XGBoost were 0.80, 0.81, 0.81, 0.78, and 0.84 respectively.},
  keywords={Technological innovation;Job shop scheduling;Companies;Predictive models;Turning;Software;Decision trees;Artificial Intelligence;AI-based Hiring Systems;biasness;comparative analysis;AdaBoost;XGBoost;KNN Tree;Random Forest;Decision Tree},
  doi={10.1109/ASIANCON58793.2023.10269895},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{11061235,
  author={Elgalaly, Abdelrahman and Fahmy, Ahmed and Ahmed, Abdllah and Youssif, Mohammed and Essam, Muhammad and Mohamed, Samir A. Elsagheer},
  booktitle={2024 12th International Japan-Africa Conference on Electronics, Communications, and Computations (JAC-ECC)}, 
  title={Blockchain-Driven Defense Against Deepfakes on Social Media Platforms}, 
  year={2024},
  volume={},
  number={},
  pages={170-175},
  abstract={The rapid advancement of Artificial Intelligence (AI) has driven a surge in the spread of falsified digital content, particularly through deepfake technologies that generate highly realistic but fake videos, images, and audio. Such manipulated media can distort reality, damage reputations, and erode public trust. To address these risks, this paper proposes a blockchainbased framework designed to protect the authenticity and integrity of user-generated video content on social media platforms. The framework integrates two AI models: Multi-task Cascaded Convolutional Neural Network (MTCNN) for facial verification and Artificial Neural Network (ANN) for voice recognition, ensuring that both visual and audio identities are authenticated before publication. Once verified, blockchain records consent immutably using smart contracts, creating a secure log of authorization for accountability and transparency. This paper also explores blockchain’s role as a decentralized verification tool, examining deepfake detection methods, benchmarks, and the application of blockchain to enhance media reliability within a landscape increasingly susceptible to sophisticated manipulation.},
  keywords={Deepfakes;Visualization;Social networking (online);Surge protection;Multitasking;Blockchains;Convolutional neural networks;Artificial intelligence;Surges;Standards;Deepfake detection methods;Multi-task cascaded convolutional neural networks;Social Engineering;Social media platforms;Blockchain technology;Decentralized verification},
  doi={10.1109/JAC-ECC64419.2024.11061235},
  ISSN={2690-3385},
  month={Dec},}@INPROCEEDINGS{11011377,
  author={Bansal, Vipin and Malhotra, Manisha},
  booktitle={2025 3rd International Conference on Advancement in Computation & Computer Technologies (InCACCT)}, 
  title={ViT-MAD: A novel generative-AI based architecture for diabetic retinopathy detection}, 
  year={2025},
  volume={},
  number={},
  pages={211-216},
  abstract={Retinal imaging, like fundus photographs, is generally used to analyze eye conditions, where professionals like ophthalmologists review the images to identify signs of nerve damage or leakage, helping determine the severity of the disease. However, manual evaluation of such images can lead to errors due to human factors like fatigue and work stress. With advancements in technology, especially in artificial intelligence (AI), it is possible to reduce human-driven errors. AI-based solutions allow professionals to re-evaluate their analyses and facilitate early and accurate predictions. Computer vision-based AI can detect minute signs of diabetic retinopathy (DR) that humans may miss, thereby improving overall accuracy and guiding the treatment in the right direction. Extensive research has been conducted, and various AI-based solutions have been developed to detect DR using various retinal imaging modalities. Since obtaining data from unhealthy individuals is challenging and expensive, an anomaly detection approach using healthy fundus images has been explored. To address these challenges, proposing a novel solution ViT-MAD (Vision Transformer Masked Anomaly Detector), a Vision Transformer-based method that leverages a similarity score model to accurately detect diabetic retinopathy in fundus images. ViT-MAD has achieved over 94% accuracy across diverse fundus image datasets.},
  keywords={Diabetic retinopathy;Accuracy;Reviews;Computational modeling;Imaging;Training data;Retina;Transformers;Artificial intelligence;Stress;Generative-AI;LVM;Anomaly-Detection;Retinal Image;Diabetic Retinopathy},
  doi={10.1109/InCACCT65424.2025.11011377},
  ISSN={},
  month={April},}@INPROCEEDINGS{10574792,
  author={Bokdia, Akshat and Gunavathi, C},
  booktitle={2024 3rd International Conference on Artificial Intelligence For Internet of Things (AIIoT)}, 
  title={Performance Analysis of Data Augmentation Techniques for Lung Cancer Classification using Microarray Data}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={Cancer gene expression data analysis using microarray technology is a critical domain in understanding the molecular intricacies of malignancy. With an emphasis on the incorporation of data augmentation techniques, this paper offers a thorough investigation into the categorization of binary class Lung cancer gene expression dataset. Effective dimensionality reduction is achieved by using univariate feature selection technique called SelectKBest method. Through the evaluation of performance indicators including accuracy and recall, the study offers detailed insights into the advantages and disadvantages of each augmentation strategy. The study’s findings add to the current conversation in precision medicine and provide information for improving methods for analyzing gene expression data in relation to cancer classification.},
  keywords={Accuracy;Precision medicine;Lung cancer;Generative adversarial networks;Data augmentation;Particle measurements;Stability analysis;Logistic Regression;Data augmentation;Gene Expression Data;Lung Cancer;SelectKBest;Generative adversarial network;SMOTE},
  doi={10.1109/AIIoT58432.2024.10574792},
  ISSN={},
  month={May},}@INPROCEEDINGS{10947958,
  author={Mehta, Shiva and Choudhary, Sunila},
  booktitle={2024 International Conference on Artificial Intelligence and Emerging Technology (Global AI Summit)}, 
  title={Overcoming Class Imbalance in Skin Disease Detection Using CNN-GAN Models}, 
  year={2024},
  volume={},
  number={},
  pages={525-530},
  abstract={Skin disorders' identification and classification is challenging because of the vast number and complex nature of skin diseases. This paper proposes a new approach integrating CNN with GAN to enhance the diagnosis and classification of several dermatological diseases. As described in this study, the CNN-GAN architecture can overcome issues with class imbalance and variations in picture quality due to the feature extraction capability of CNNs and the data augmentation capability of GANs. The CNN-GAN model improved over the average CNN model when applied to the HAM10000 database, containing over 10,000 dermatoscopy images spread across seven skin lesions. This way, the proposed framework achieved an average accuracy of 92%, while the model based solely on the CNN resulted in an accuracy of 85%. The CNN-GAN model obtained accurate, recall, and F1-score of 85%, 86%, and 85%, respectively, and it had better performance than the classical CNN model. The accuracy of the predictive model formed by the AUC-Roc was 0. When subjected to cerebrovascular accidents, 92% of the participants showed a discriminative capacity of high level. By adding the pictures generated by GAN into the training process, the main idea of the model was to overcome the problem of class imbalance: the model learns to adapt to the inputs it has never seen before. The results indicated by the confusion matrix were the reduction of false classifications while correlation heatmap signal increased reduction in predictors bias. The graphs depicting the accuracy and loss during the training and validation process did depict a perfect convergence pattern, and overfitting was sparingly frequent.},
  keywords={Training;Heating systems;Accuracy;Generative adversarial networks;Skin;Data models;Convolutional neural networks;Lesions;Diseases;Overfitting;Skin Lesion Classification;Convolutional Neural Networks (CNN);Generative Adversarial Networks (GAN);Data Augmentation;Deep Learning;Medical Image Analysis;Dermatology},
  doi={10.1109/GlobalAISummit62156.2024.10947958},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9276834,
  author={Li, Mingxuan and Lv, Shichao and Shi, Zhiqiang},
  booktitle={2020 IEEE International Conference on Information Technology,Big Data and Artificial Intelligence (ICIBA)}, 
  title={Malware Detection for Industrial Internet Based on GAN}, 
  year={2020},
  volume={1},
  number={},
  pages={475-481},
  abstract={This thesis focuses on the detection of malware in industrial Internet. The basic flow of the detection of malware contains feature extraction and sample identification. API graph can effectively represent the behavior information of malware. However, due to the high algorithm complexity of solving the problem of subgraph isomorphism, the efficiency of analysis based on graph structure feature is low. Due to the different scales of API graph of different malicious codes, the API graph needs to be normalized. Considering the difficulties of sample collection and manual marking, it is necessary to expand the number of malware samples in industrial Internet. This paper proposes a method that combines PageRank with TF-IDF to process the API graph. Besides, this paper proposes a method to construct the adversarial samples of malwares based on GAN.},
  keywords={Malware;Detectors;Internet;Generative adversarial networks;Generators;Gallium nitride;Training;industrial Internet;malware detection;generative adversarial nets;adversarial sample},
  doi={10.1109/ICIBA50161.2020.9276834},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10867865,
  author={Yan, Jie and Zhou, Zhinan and Yuan, Haijing and Liu, Shan and Huang, Zhiguo},
  booktitle={2024 IEEE 4th International Conference on Information Technology, Big Data and Artificial Intelligence (ICIBA)}, 
  title={Dual-Flow Feature Coupling GAN for Image Inpainting}, 
  year={2024},
  volume={4},
  number={},
  pages={1290-1296},
  abstract={Image inpainting is an significant task in the field of computer vision, which can generate exquisite images from incomplete input images. However, insufficient consideration of the relationship between global and local features during the inpainting process can result in poor consistency or even blurring on the generated image contents. In view of this, a dual-flow feature coupling GAN (DFC-GAN) is proposed, which consists of two encoding and decoding subnetworks, namely the main stream and Transformer stream. The main stream is designed to adopt the fully convolutional network for better capturing features. The Transformer stream is presented to use stacked fast Fourier Transformers (FFTr) to expand the receptive fields effectively. Besides, a space and channel aggregation (SCA) module is introduced to fuse local features extracted by the main stream and global features captured by the Transformer stream to avoid potential domain conflicts. A global feature transfer (GFT) module is designed to couple global features generated by the Transformer stream and features from the main stream layer by layer, which can guide the generation of main stream features. Extensive experiments on two public datasets, including Paris StreetView and CelebA-HQ, demonstrate that the proposed method outperforms the state-of-the-art methods both quantitatively and qualitatively.},
  keywords={Couplings;Correlation;Fuses;Semantics;Streaming media;Transformers;Feature extraction;Generative adversarial networks;Encoding;Information technology;Image inpainting;generative adversarial network;fully convolutional network;fast Fourier Transformer},
  doi={10.1109/ICIBA62489.2024.10867865},
  ISSN={},
  month={Dec},}@ARTICLE{10558823,
  author={Chen, Zihan and Yang, Howard H. and Tay, Y. C. and Chong, Kai Fong Ernest and Quek, Tony Q. S.},
  journal={IEEE Wireless Communications}, 
  title={The Role of Federated Learning in a Wireless World with Foundation Models}, 
  year={2024},
  volume={31},
  number={3},
  pages={42-49},
  abstract={Foundation models (FMs) are general-purpose artificial intelligence (AI) models that have recently enabled multiple brand-new generative AI applications. The rapid advances in FMs serve as an important contextual backdrop for the vision of next-generation wireless networks, where federated learning (FL) is a key enabler of distributed network intelligence. Currently, the exploration of the interplay between FMs and FL is still in its nascent stage. Naturally, FMs are capable of boosting the performance of FL, and FL could also leverage decentralized data and computing resources to assist in the training of FMs. However, the exceptionally high requirements that FMs have for computing resources, storage, and communication overhead, would pose critical challenges to FL-enabled wireless networks. In this article, we explore the extent to which FMs are suitable for FL over wireless networks, including a broad overview of research challenges and opportunities. In particular, we discuss multiple new paradigms for realizing future intelligent networks that integrate FMs and FL. We also consolidate several broad research directions associated with these paradigms.},
  keywords={Training;Intelligent networks;Frequency modulation;Federated learning;Generative AI;Wireless networks;Boosting;Artificial intelligence},
  doi={10.1109/MWC.005.2300481},
  ISSN={1558-0687},
  month={June},}@INPROCEEDINGS{10134474,
  author={Tandon, Shubham and Vig, Aryan and Kartik, Murli and Kumawat, Harish Chandra},
  booktitle={2023 International Conference on Recent Advances in Electrical, Electronics, Ubiquitous Communication, and Computational Intelligence (RAEEUCCI)}, 
  title={Real-Time Face Transition using Deepfake Technology (Gan Model)}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Many machine learning models require huge datasets to get trained, to make correct predictions, or to increase their accuracy, that's where generative adversarial network (GAN) comes into the picture. GAN is a deep learning model, which can be used to create artificial data. It consists of two neural networks that cooperate in a way that resembles a game: a generator network and a discriminator network. Within the suggested model in this work, a dense motion network-based first-order motion model for image animation is developed. Here a trained GAN extracts the face landmarks from the driving video and develops the embedding model to create the synthesis video using the dedicated module to prepare the Deepfakes, employing key point detectors as a baseline. Lastly, an approach that makes use of dense motion networks to increase the effectiveness of a collection of GAN generators is provided. With the help of the sequel driving combination of driving video with the source image, the given results produce the augmented animation video. Hence, it is tried to implement a lighter model which consists of modules, with the approximate same accuracy when compared with other implementations of GAN. This work has a wide range of applications, including doubling dataset counts with a small number of sources, creating real-time backgrounds and characters for the gaming and animation industries using CG platforms, translating clothes, predicting videos, creating 3D objects, etc.},
  keywords={Deepfakes;Solid modeling;Computational modeling;Streaming media;Predictive models;Generative adversarial networks;Animation;Artificial Data;Neural Networks;Deepfakes;GAN;Animation},
  doi={10.1109/RAEEUCCI57140.2023.10134474},
  ISSN={},
  month={April},}@ARTICLE{9153037,
  author={Ozcelik, Furkan and Alganci, Ugur and Sertel, Elif and Unal, Gozde},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Rethinking CNN-Based Pansharpening: Guided Colorization of Panchromatic Images via GANs}, 
  year={2021},
  volume={59},
  number={4},
  pages={3486-3501},
  abstract={Convolutional neural network (CNN)-based approaches have shown promising results in the pansharpening of the satellite images in recent years. However, they still exhibit limitations in producing high-quality pansharpening outputs. To that end, we propose a new self-supervised learning framework, where we treat pansharpening as a colorization problem, which brings an entirely novel perspective and solution to the problem compared with the existing methods that base their solution solely on producing a super-resolution version of the multispectral image. Whereas the CNN-based methods provide a reduced-resolution panchromatic image as the input to their model along with the reduced-resolution multispectral images and, hence, learn to increase their resolution together, we instead provide the grayscale transformed multispectral image as the input and train our model to learn the colorization of the grayscale input. We further address the fixed downscale ratio assumption during training, which does not generalize well to the full-resolution scenario. We introduce a noise injection into the training by randomly varying the downsampling ratios. Those two critical changes, along with the addition of adversarial training in the proposed PanColorization generative adversarial network (PanColorGAN) framework, help overcome the spatial-detail loss and blur problems that are observed in CNN-based pansharpening. The proposed approach outperforms the previous CNN-based and traditional methods, as demonstrated in our experiments.},
  keywords={Task analysis;Spatial resolution;Training;Standards;Sensors;Multiresolution analysis;AI;colorization;convolutional neural networks (CNNs);deep learning;generative adversarial networks (GANs);image fusion;PanColorization generative adversarial network (PanColorGAN);pansharpening;self-supervised learning;super-resolution (SR)},
  doi={10.1109/TGRS.2020.3010441},
  ISSN={1558-0644},
  month={April},}@ARTICLE{9507460,
  author={Wang, Yahang and Song, Xiaoning and Xu, Tianyang and Feng, Zhenhua and Wu, Xiao-Jun},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={From RGB to Depth: Domain Transfer Network for Face Anti-Spoofing}, 
  year={2021},
  volume={16},
  number={},
  pages={4280-4290},
  abstract={With the rapid development in face recognition, most of the existing systems can perform very well in unconstrained scenarios. However, it is still a very challenging task to detect face spoofing attacks, thus face anti-spoofing has become one of the most important research topics in the community. Though various anti-spoofing models have been proposed, the generalisation capability of these models usually degrades for unseen attacks in the presence of challenging appearance variations, e.g., background, illumination, diverse spoofing materials and low image quality. To address this issue, we propose to use a Generative Adversarial Network (GAN) that transfers an input face image from the RGB domain to the depth domain. The generated depth clue enables biometric preservation against challenging appearance variations and diverse image qualities. To be more specific, the proposed method has two main stages. The first one is a GAN-based domain transfer module that converts an input image to its corresponding depth map. By design, a live face image should be transferred to a depth map whereas a spoofing face image should be transferred to a plain (black) image. The aim is to improve the discriminative capability of the proposed system. The second stage is a classification model that determines whether an input face image is live or spoofing. Benefit from the use of the GAN-based domain transfer module, the latent variables can effectively represent the depth information, complementarily enhancing the discrimination of the original RGB features. The experimental results obtained on several benchmarking datasets demonstrate the effectiveness of the proposed method, with superior performance over the state-of-the-art methods. The source code of the proposed method is publicly available at https://github.com/coderwangson/DFA.},
  keywords={Face recognition;Faces;Generative adversarial networks;Feature extraction;Training;Deep learning;Task analysis;Face anti-spoofing;generative adversarial network;domain transfer},
  doi={10.1109/TIFS.2021.3102448},
  ISSN={1556-6021},
  month={},}@INPROCEEDINGS{9624500,
  author={Ma, Yangyang and Hua, Yanling and Zuo, Zhengrong},
  booktitle={2021 International Conference on Control, Automation and Information Sciences (ICCAIS)}, 
  title={Infrared Image Generation By Pix2pix Based on Multi-receptive Field Feature Fusion}, 
  year={2021},
  volume={},
  number={},
  pages={1029-1036},
  abstract={Infrared imaging has the advantages of strong anti-interference capability, long-range imaging, and night imaging, and has important applications in both civilian and military fields. In the development of infrared-related equipment, a large number of infrared images under a variety of conditions are required as verification test data. The field test of infrared images requires huge manpower and material resources, and it is difficult to obtain full-time infrared images. To address the problem of insufficient infrared image samples, the paper introduces generative adversarial networks into the infrared image generation task and investigates the infrared image generation method based on visible images by applying Pix2pix networks to paired visible infrared image datasets. To address the problem of missing detailed information of infrared images generated by the Pix2pix network, the paper proposes a Pix2pix network based on multi-receptive field feature fusion and constructs a multi-receptive field feature extractor based on Unet++ structure; the multi-receptive field feature fusion mechanism of nested pixel level by level is proposed. Experiments show that the Pix2pix network based on multi-receptive field feature fusion achieves finer infrared texture generation.},
  keywords={Automation;Image synthesis;Infrared imaging;Feature extraction;Generative adversarial networks;Data mining;Task analysis;Generative Adversarial Networks;infrared image generation;multi-receptive-field feature fusion},
  doi={10.1109/ICCAIS52680.2021.9624500},
  ISSN={2475-7896},
  month={Oct},}@ARTICLE{8999556,
  author={Liu, Shuang and Li, Dan and Cao, Tianchi and Sun, Yuke and Hu, Yingsong and Ji, Junwen},
  journal={IEEE Access}, 
  title={GAN-Based Face Attribute Editing}, 
  year={2020},
  volume={8},
  number={},
  pages={34854-34867},
  abstract={Recently, a variety of methods using the Generative Adversarial Network (GAN) for face editing have been proposed. However, the existing methods cannot control the editing content of the face elements according to the user-specified attributes or need to train a conditional GAN for editing tasks, which means it is difficult to add new attributes in the future. In this paper, a method to edit face attributes by editing the latent variable with the help of a pre-trained unconditional GAN and a linear classification model is proposed. In particular, face attribute editing is divided into two separate stages: Firstly, based on the optimization function, the generative model does a latent variable search to generate a high-quality face image that is similar to the input image. Secondly, by editing the latent variable of the GAN, the attribute of the generated face image can be modified indirectly, so it is almost unaffected by the training process and network structure of GAN, which means it is a flexible method for nearly all GAN network. Images of the FFHQ dataset are edited by attribute labels defined in Celeba dataset for experiments. These experiments prove that our method can edit a variety of face images that vary with race, gender, age, and camera shooting angle. The overall quality of the edited image is not inferior to the other face attribute editing method, and attribute classification for edited image shows a 92.6% attribute editing success rate of the proposed method.},
  keywords={Face;Gallium nitride;Generative adversarial networks;Training;Optimization;Mouth;Machine learning;Face attribute editing;latent variable search;optimization function;generative adversarial network},
  doi={10.1109/ACCESS.2020.2974043},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10394669,
  author={Oh, Jun-Young and Lee, In-Gyu and Chang, Hyun-Ho and Lee, Euijong and Jeong, Ji-Hoon},
  booktitle={2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={Application of A Dual-Stage Deep Learning Framework to Detect Left Atrial Enlargement for Pet Heart Failure}, 
  year={2023},
  volume={},
  number={},
  pages={2972-2978},
  abstract={Artificial intelligence (AI) has transformed medical diagnosis and improved quality of life. But in the field of veterinary medicine has been limited due to training data and obtaining high-quality data. In this study, we propose a framework for diagnosing left atrial enlargement in dogs using AI techniques. Our framework involves generating X-ray image data and utilizing the UNet model for segmentation. The results of our experiments show excellent performance, with a mean dice score of 0.9186 for segmentation. The highest classification accuracy was achieved in trial 1 for normal and overall cases, with 0.9200 and 0.8478, respectively, while trial 2 had the highest abnormal heart classification accuracy of 0.8095. Our findings indicate that generating data and training the model with a certain percentage of the generated data can lead to high classification accuracy. We conclude that the proposed framework has the potential for clinical application in veterinary medicine.},
  keywords={Training;Image segmentation;Training data;Data models;Medical diagnosis;Artificial intelligence;X-ray imaging;Artificial intelligence;Deep learning;Heart failure detection;Image segmentation;Veterinary medicine},
  doi={10.1109/SMC53992.2023.10394669},
  ISSN={2577-1655},
  month={Oct},}@ARTICLE{9291455,
  author={Zhang, Longhao and Pan, Xipeng and Yang, Huihua and Li, Lingqiao},
  journal={IEEE Access}, 
  title={On Open-Set, High-Fidelity and Identity-Specific Face Transformation}, 
  year={2020},
  volume={8},
  number={},
  pages={224643-224653},
  abstract={In this paper, a Generative Adversarial Networks-based framework has been proposed for identity-specific face transformation with high fidelity in open domains. Specifically, for any face, the pro-posed framework can transform its identity to the target identity, while preserving attributes and details (e.g., pose, gender, age, facial expression, skin tone, illumination and background). To this end, an auto-encoder network is adopted to learn the transformation mapping, which encodes the source image into the latent representation, and reconstruct it with the target identity. In addition, the face parsing pyramid is introduced to help the decoder restore the attributes. Moreover, a novel perceptual constraint is applied to the transformed images to guarantee the correct change of the desired identity and to help retrieve the lost details during face identity transformation. Extensive experiments and comparisons to several open-source approaches demonstrate the efficacy of the proposed framework: it can achieve more realistic identity transformation while better preserving attributes and details.},
  keywords={Faces;Generative adversarial networks;Image reconstruction;Training;Generators;Decoding;Gallium nitride;Auto-encoder;face transformation;generative adversarial networks;perceptual constraint},
  doi={10.1109/ACCESS.2020.3044187},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10278317,
  author={Magdy, Karim and Khoriba, Ghada and Abbas, Hala},
  booktitle={2023 International Mobile, Intelligent, and Ubiquitous Computing Conference (MIUCC)}, 
  title={Efficient Semantic Image Synthesis with Normalization Layers and Depth Estimation}, 
  year={2023},
  volume={},
  number={},
  pages={1-9},
  abstract={One of the most important tasks in image-to-image translation is semantic image synthesis. The success of Generative Adversarial Network (GAN) models for the synthesis of semantic images has increased, but the synthesized images produced by these models are of insufficient quality since they lack structural and spatial information. The unique approach we suggest in this paper is built on normalization layers and depth maps, which provide the textures and structure required for each object on the semantic map. First, we present a depth generator that generates a depth image map from the semantic image and then feeds the generated depth map into the normalization layers. Then, we develop a depth discriminator that distinguishes between the depth map of the real image and the depth-translated image generated by the global generator. We run our experiments on three benchmark datasets and achieve high robustness against state-of-the-art evaluation protocols used in semantic image synthesis tasks.},
  keywords={Training;Visualization;Image synthesis;Semantics;Estimation;Symbols;Generative adversarial networks;Semantic Image Synthesis;Generative Adversarial Networks (GANs);Depth estimation},
  doi={10.1109/MIUCC58832.2023.10278317},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10651295,
  author={Bi, Xiaoyang and Zhang, Yingqian and Goh, Sim Kuan},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={DSD-GAN: Double-Scale Discriminators GAN for Enhanced Chinese Brush Baimiao Painting Colorization}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Transforming Baimiao sketches into full-color Chinese brush paintings is significant in the context of rising market demands and exploring new possibilities in the realm of AI art creation. While several pixel-based works demonstrated the capability of generative adversarial network (GAN) for colorization, several challenges remain, e.g., the inappropriate thickness of lines in sketches and the shortage of local detail. To address the challenges, this paper introduces the double-scale discriminator GAN (DSD-GAN), with double discriminators that target realistic image generation at two scales. The generator of DSD-GAN integrates a Unet-based architecture with a convolutional attention module capable of focusing on critical areas to enhance the painting color and detail accuracy. Moreover, an additional enhancement block, inspired by the perceptual field model, is adopted to improve the precision of local details in the generated artwork. Extensive verification on a diverse dataset of Chinese brush paintings, including two artistic subject matter still life and landscape, demonstrates DSD-GAN’s superiority over state-of-the-art Image-to-Image translation methods across various metrics, including PSNR, SSIM, MSE, and PI. Qualitative visual assessments further confirm its effectiveness. The source code is accessible on GitHub upon paper acceptance.},
  keywords={Convolutional codes;Visualization;Brushes;Art;Accuracy;Image color analysis;Generative adversarial networks;Generative Adversarial Network;Chinese Painting;AI colorization;image-to-image translation},
  doi={10.1109/IJCNN60899.2024.10651295},
  ISSN={2161-4407},
  month={June},}@INPROCEEDINGS{11059066,
  author={Chandramowleeswaran, G. and Prasanth, A. and Khuseynovich, Gafurov Abduvoitjon and Ghosh, Amarjeet Kumar and P.Chandrakala and Keer, Priyameet Kaur},
  booktitle={2024 International Conference on Advances in Computing, Communication and Materials (ICACCM)}, 
  title={Deep Learning in Innovative Product Management: Harnessing AI for Disruption Navigation and Creativity Enhancement}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Deep learning as one of the most advanced forms of AI offers wide opportunities to change the direction for new product management through the guidance of disruption and the encouragement of product invention. Describing how artificial intelligence can be used in the identification of market challenges and opportunities, as well as the encouragement of innovation, this paper examines the use of deep learning in product management. To understand various approaches to the integration of deep learning models into product management systems, with a focus on data acquisition, model training, deployment, and performance assessment, we carry out a literature review evaluation. In this case, it is possible to talk about increased levels of predictive accuracy, customer satisfaction, and innovation rates gained thanks to the results received. However, there are two significant issues inherent with the application of deep learning, namely, data privacy and computational costs, yet the benefits of applying deep learning in product management are hard to ignore. This paper highlights the need to proceed with ethical guidelines and research for effective optimization of the AI in achieving such goals such as in product development and industry competitiveness.},
  keywords={Deep learning;Industries;Technological innovation;Ethics;Data privacy;Navigation;Prediction algorithms;Artificial intelligence;Creativity;Guidelines;deep learning;product management;artificial intelligence;market disruption;creativity enhancement},
  doi={10.1109/ICACCM61117.2024.11059066},
  ISSN={2642-7354},
  month={Nov},}@INPROCEEDINGS{10835040,
  author={Zhang, Shujian},
  booktitle={2024 International Conference on Electronics and Devices, Computational Science (ICEDCS)}, 
  title={Research on AI-Based Target Detection Technology for Sports Images}, 
  year={2024},
  volume={},
  number={},
  pages={741-746},
  abstract={With the rapid development of artificial intelligence, deep learning-based target detection technology has been widely applied in various fields. Sports images, as a special application scenario, present new challenges for target detection due to their complex actions and rapidly changing targets. This paper aims to study AI-based target detection technology for sports images by analyzing and improving existing detection algorithms and proposing an optimized detection algorithm suitable for sports scenarios. First, the paper outlines the basic theories of AI and target detection technology, then analyzes the characteristics of sports images and the current application status of detection algorithms, and finally designs and implements a target detection system for sports images. Experiments validate the proposed algorithm’s effectiveness and superiority in various sports scenarios. This research provides a theoretical foundation and technical support for applications such as sports analysis, intelligent refereeing, and athlete training.},
  keywords={YOLO;Training;Performance evaluation;Scientific computing;Neural networks;Lighting;Reliability;Detection algorithms;Artificial intelligence;Sports;Artificial intelligence;target detection;sports images;deep learning;convolutional neural networks},
  doi={10.1109/ICEDCS64328.2024.00139},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11115608,
  author={Barde, Snehlata and Karan, Arya and Aman},
  booktitle={2025 12th International Conference on Computing for Sustainable Global Development (INDIACom)}, 
  title={Digital Mirage: The Paradox of Virtuality and Reality}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={In this digital age, the rampancy of cyberattacks, ranging from hacking and identity theft to various other more pernicious kinds of cybercrime, has already become a growing concern for the world. Sadly, deepfake technology-one of the most recent developments in this area-is an advanced method of generating hyper-realistic fake videos and images by way of artificial intelligence. It is fast gaining grounds as a powerful tool for misinformation and manipulation of people's view to deceive individuals and corporations. Digital Mirage, is our project that aimed to detection and analysis deepfake video using the latest in AI methods combined with Python-based libraries. This initiative is devised to minimize the unwanted effects of digital deception on society for this we selected the Deepfake Detection Challenge (DFDC) dataset-a publicly available pool of authentic and manipulated media created by Facebook. To evaluate the efficacy of detection framework. At last, our system achieved 86% accuracy, which shows that traditional computer vision techniques can be merged with AI-driven approaches to achieve successful deepfake detection. Though it has progressed significantly, it represents a call to further research and development of more sophisticated tools toward countering the continuing threat that deepfake technologies and digital integrity.},
  keywords={Deepfakes;Accuracy;Social networking (online);Nose;Feature extraction;Libraries;Real-time systems;Computer crime;Artificial intelligence;Research and development;Deepfake Detection;Digital Mirage;Cyber Security;Artificial Intelligence},
  doi={10.23919/INDIACom66777.2025.11115608},
  ISSN={},
  month={April},}@INPROCEEDINGS{10821107,
  author={Peng, Yifeng and Li, Xinyi and Wang, Ying},
  booktitle={2024 IEEE International Conference on Quantum Computing and Engineering (QCE)}, 
  title={QRNG-DDPM: Enhancing Diffusion Models Through Fitting Mixture Noise with Quantum Random Number}, 
  year={2024},
  volume={02},
  number={},
  pages={92-96},
  abstract={Recent research has demonstrated that the denoising diffusion probabilistic model (DDPM) can generate high-quality images in artificial intelligence (AI), showing its distinctive capabilities. However, despite this, the diversity of generated images is often limited by the predictability of traditional pseudo-random number generators in the stochastic process. To address this problem, this paper proposes a new mixed noise model based on quantum random numbers QRNG-DDPM. By operating on single qubits, we generate quantum random numbers and apply a self-developed encoding scheme to convert the quantum random numbers into distributions suitable for noise models. Due to the inherent unpredictability of quantum phenomena, quantum random numbers offer a higher level of randomness and diversity compared to traditional pseudo-random numbers. Our experimental results demonstrate that the proposed method significantly enhances the diversity and unpredictability of the generated images, achieving a 5.4% reduction in the Fréchet Inception Distance (FID) score on the CIFAR-10 dataset.},
  keywords={Computational modeling;Noise;Qubit;Noise reduction;Fitting;Stochastic processes;Diffusion models;Generators;Encoding;Artificial intelligence;Quantum random number;Quantum artificial intelligence;Diffusion models;Gaussian mixture noise},
  doi={10.1109/QCE60285.2024.10259},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10851061,
  author={OUBADI, Soumia and MELLAL, Naçima and BOUCHOUAREB, Rachida and ZERTAL, Soumia},
  booktitle={2024 1st International Conference on Electrical, Computer, Telecommunication and Energy Technologies (ECTE-Tech)}, 
  title={A GAN-LSTM Architecture for ECG Anomaly Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Cardiovascular diseases (CVDs) continue to be a primary cause of global mortality, requiring prompt detection and care to avert serious consequences. Electrocardiograms (ECGs) are vital diagnostic instruments for cardiovascular disorders, yet traditional diagnostic methods encounter considerable obstacles, such as class imbalance and substantial heterogeneity in the available data. This study introduces a novel ECG classification technique utilizing GAN and LSTM. Generative Adversarial Networks (GANs) are employed to produce additional synthetic ECG samples, addressing class imbalance in the training dataset. The suggested design integrates LSTM units into the GAN generator to collect and maintain temporal signal patterns, while anomaly detection is performed using a CNN-LSTM model. Experimental findings indicate a significant enhancement in classification performance, achieving an accuracy of up to 94.74%. The findings indicate that the proposed GAN-LSTM model significantly improves ECG anomaly detection and classification, offering substantial potential for the rapid and precise identification of arrhythmias.},
  keywords={Training;Instruments;Mortality;Computer architecture;Electrocardiography;Generative adversarial networks;Real-time systems;Convolutional neural networks;Anomaly detection;Long short term memory;Cardiovascular diseases;ECG anomaly detection;Generative Adversarial Network (GAN);Long Short-Term Memory (LSTM);CNN-LSTM;class imbalance;arrhythmia classification},
  doi={10.1109/ECTE-Tech62477.2024.10851061},
  ISSN={},
  month={Dec},}@ARTICLE{10711211,
  author={Si, Xiaopeng and Huang, He and Yu, Jiayue and Ming, Dong},
  journal={IEEE Transactions on Affective Computing}, 
  title={The fNIRS-Based Emotion Recognition by Spatial Transformer and WGAN Data Augmentation Toward Developing a Novel Affective BCI}, 
  year={2025},
  volume={16},
  number={2},
  pages={875-890},
  abstract={The affective brain-computer interface (aBCI) facilitates the objective identification or regulation of human emotions. Current aBCI mainly relies on electroencephalography (EEG). However, research shows that emotions involve a large-scale distributed brain network. Compared to electroencephalography (EEG), functional near-infrared spectroscopy (fNIRS) offers a higher spatial resolution. It holds greater potential in capturing emotional spatial information, which may foster the development of new affective Brain-Computer Interfaces (aBCI). We proposed a novel self-attention-based deep-learning transformer language model for fNIRS cross-subject emotion recognition, which could automatically learn the emotion's spatial attention weight information with strong interpretability. Besides, we performed data augmentation by introducing the wasserstein generative adversarial networks (WGAN). Results showed: (1) We achieved 84% three-category cross-subject emotion decoding accuracy. The spatial transformer module and WGAN improved the accuracy by 12.8% and 4.3%, respectively. (2) Compared with cutting-edge fNIRS research, we led by 10% in three-category decoding accuracy. (3) Compared with cutting-edge EEG research, we lead by 28% in arousal decoding accuracy, 10% in valence decoding accuracy, and 2% in three-category decoding accuracy. (4) Besides, our approach holds the potential to uncover the brain's spatial encoding mechanism of human emotion processing, providing a new direction for building interpretable artificial intelligence models.},
  keywords={Emotion recognition;Functional near-infrared spectroscopy;Brain modeling;Transformers;Decoding;Electroencephalography;Spatial resolution;Artificial intelligence;Accuracy;Generative adversarial networks;Affective brain-computer interface (aBCI);emotion recognition;functional near-infrared spectroscopy (fNIRS);transformer;spatial;self-attention;data augmentation;wasserstein generative adversarial networks (WGAN);cross-subject},
  doi={10.1109/TAFFC.2024.3477302},
  ISSN={1949-3045},
  month={April},}@INPROCEEDINGS{10935498,
  author={Jiang, Xue and Liu, PeiYu and Lu, Ran and Liu, Mei},
  booktitle={2024 14th International Conference on Information Technology in Medicine and Education (ITME)}, 
  title={Based on the impact of AIGC on the innovative practical capabilities of students in secondary vocational schools}, 
  year={2024},
  volume={},
  number={},
  pages={376-381},
  abstract={AIGC is leading an unprecedented and profound change in the field of education, and its core value is to significantly enhance students' innovative ability. By promoting immersive, independent and autonomous learning models, AIGC is closely aligned with the fundamental purpose of education and breathes new energy into building a solid framework for innovative thinking. It not only provides students with a rich and diversified case base of innovation practice, urging students to sharpen their skills and enhance their independent innovation ability in practice, but also optimizes the information screening and retrieval mechanism to ensure that students' innovation practice can be accurately, efficiently and accurately focused on the key areas of innovation practice in the flood of massive information. Therefore, the remarkable results and potential value of AIGC in cultivating contemporary students' practical and innovative ability are worthy of in-depth exploration and careful consideration by educators and scholars.},
  keywords={Technological innovation;Solid modeling;Generative AI;Education;Buildings;Learning (artificial intelligence);Solids;Information retrieval;Floods;Information technology;AIGC Generative artificial intelligence;Secondary vocational education;Innovation practice ability},
  doi={10.1109/ITME63426.2024.00081},
  ISSN={2474-3828},
  month={Sep.},}@INPROCEEDINGS{10780252,
  author={E, Priya and E, Dinesh Kumar and K, Jayachandiran and R, Shamprakash},
  booktitle={2024 International Conference on Power, Energy, Control and Transmission Systems (ICPECTS)}, 
  title={Smart Healthcare Assistant with Epidemiological Modelling}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The perpetual threat posed by infectious disease outbreaks necessitates continuous advancements in epidemic modeling and public health interventions. Traditional approaches, while valuable, often face challenges in accurately predicting disease transmission dynamics and informing timely containment strategies. In response, this paper proposes a novel hybrid system that integrates established epidemiological models with cutting-edge Artificial Intelligence (AI) techniques, including ensemble methods and Generative Al for Natural Language Processing (NLP). This extends beyond epidemic modeling to address healthcare accessibility disparities through the development of a chatbot powered by Language Model (LLM) technology. The chatbot, capable of conversing in native languages, offers medical assistance and addresses health-related queries effectively, thereby bridging gaps in healthcare access. Additionally, sophisticated disease dynamic models and endemic simulators are employed to forecast disease spread accurately, ensuring the availability of healthcare information even in remote areas.},
  keywords={Epidemics;Accuracy;Medical services;Predictive models;Chatbots;Ensemble learning;Reliability;Artificial intelligence;Forecasting;Standards},
  doi={10.1109/ICPECTS62210.2024.10780252},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11080571,
  author={Rezaei, Farzam and de Vergara, Jorge E. López},
  booktitle={2025 IEEE 11th International Conference on Network Softwarization (NetSoft)}, 
  title={Real-Time Network Traffic Classification in IoT Networks Using Hybrid AI Techniques}, 
  year={2025},
  volume={},
  number={},
  pages={384-387},
  abstract={The development of IoT across various fields emphasizes the need for real-time network traffic classification to maintain security, simplify resources, and address evolving threats. Traditional methods like port-based and deep packet inspection fail with encrypted traffic, privacy constraints, and slow processing, while deep learning solutions face limitations with insufficient data and latency in IoT environments. To overcome these challenges, this research presents a hybrid AI framework that seamlessly combines AI techniques for fast and accurate classification. Through a five-phase process-data preparation, feature engineering, model design, interpretability and optimization, and deployment and validation-it merges synthetic traffic generation and semi-supervised methods to improve data scarcity. Optimized deep neural networks and GAN networks will be used for classification and anomaly detection. Moreover, the results will be enhanced by applying explainable artificial intelligence for transparency. This framework aims to improve latency and accuracy, outperforming current approaches.},
  keywords={Deep learning;Accuracy;Telecommunication traffic;Inspection;Generative adversarial networks;Feature extraction;Real-time systems;Anomaly detection;Optimization;Faces;IoT Network Traffic Classification;Real-Time Classification;Feature Engineering;Anomaly Detection;Machine Learning},
  doi={10.1109/NetSoft64993.2025.11080571},
  ISSN={2693-9789},
  month={June},}@ARTICLE{10944782,
  author={Zhu, Qingling and Yang, Yeming and Liu, Songbai and Lin, Qiuzhen and Tan, Kay Chen},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, 
  title={SCGAN: Sampling and Clustering-Based Neural Architecture Search for GANs}, 
  year={2025},
  volume={9},
  number={5},
  pages={3626-3637},
  abstract={The evolutionary neural architecture search for generative adversarial networks (GANs) has demonstrated promising performance for generating high-quality images. However, two challenges persist, including the long search times and unstable search results. To alleviate these problems, this paper proposes a sampling and clustering-based neural architecture search algorithm for GANs, named SCGAN, which can significantly improve searching efficiency and enhance generation quality. Two improved strategies are proposed in SCGAN. First, a constraint sampling strategy is designed to limit the parameter capacity of architectures, which calculates their architecture size and discards those exceeding a reasonable parameter threshold. Second, a clustering selection strategy is applied in each architecture iteration, which integrates a decomposition selection mechanism and a hierarchical clustering mechanism to further improve search stability. Extensive experiments on the CIFAR-10 and STL-10 datasets demonstrated that SCGAN only requires 0.4 GPU days to find a promising GAN architecture in a vast search space including approximately 10$^{15}$ networks. Our best-found GAN outperformed those obtained by other neural architecture search methods with performance metric results (IS = 9.68$\pm$ 0.06, FID = 5.54) on CIFAR-10 and (IS = 12.12$\pm$ 0.13, FID = 12.54) on STL-10.},
  keywords={Computer architecture;Generative adversarial networks;Training;Neural architecture search;Generators;Stability analysis;Search problems;Optimization;Network architecture;Graphics processing units;Generative adversarial network;neural architecture search;evolutionary algorithm},
  doi={10.1109/TETCI.2025.3547611},
  ISSN={2471-285X},
  month={Oct},}@ARTICLE{9066829,
  author={Kuang, Yan and Lan, Tian and Peng, Xueqiao and Selasi, Gati Elvis and Liu, Qiao and Zhang, Junyi},
  journal={IEEE Access}, 
  title={Unsupervised Multi-Discriminator Generative Adversarial Network for Lung Nodule Malignancy Classification}, 
  year={2020},
  volume={8},
  number={},
  pages={77725-77734},
  abstract={Computer-aided diagnosis systems with deep learning frameworks have been used to identify benign and malignant pulmonary nodules in lung cancer diagnosis. It's commonly known that a premise of training complex deep neural nets is the large-scale labeled datasets. However, the abundance of labeled datasets is usually unavailable in many medical image domains. This factor can lead to the poor generalization performance of deep learning models. In this paper, we propose a novel multi-discriminator generative adversarial network model combined with an encoder for the classification of benign and malignant pulmonary nodules. To the best of our knowledge, we are the first to apply unsupervised learning to identify benign and malignant lung nodules. Firstly, we use a multi-discriminator generative adversarial network to build a generative model trained with unlabeled benign lung nodule images. Then an encoder is combined with the trained generative model to establish a mapping of benign pulmonary nodule images to the latent space. The benign and malignant lung nodules are scored by calculating the GAN discriminator feature loss and image reconstruction loss. The model yields high anomaly scores on malignant images and low anomaly scores on benign images. Experimental results show that our method with only a small number of unlabeled datasets could achieve more competitive results compared with other supervised deep learning approaches.},
  keywords={Cancer;Lung;Training;Generative adversarial networks;Gallium nitride;Machine learning;Biomedical imaging;Computer-aided diagnosis (CAD);lung nodule;malignancy classification;unsupervised learning;generative adversarial networks},
  doi={10.1109/ACCESS.2020.2987961},
  ISSN={2169-3536},
  month={},}@ARTICLE{9279199,
  author={Hajarolasvadi, Noushin and Ramírez, Miguel Arjona and Beccaro, Wesley and Demirel, Hasan},
  journal={IEEE Access}, 
  title={Generative Adversarial Networks in Human Emotion Synthesis: A Review}, 
  year={2020},
  volume={8},
  number={},
  pages={218499-218529},
  abstract={Deep generative models have become an emerging topic in various research areas like computer vision and signal processing. These models allow synthesizing realistic data samples that are of great value for both academic and industrial communities. Affective computing, a topic of a broad interest in computer vision society, has been no exception and has benefited from this powerful approach. In fact, affective computing observed a rapid derivation of generative models during the last two decades. Applications of such models include but are not limited to emotion recognition and classification, unimodal emotion synthesis, and cross-modal emotion synthesis. As a result, we conducted a comprehensive survey of recent advances in human emotion synthesis by studying available databases, advantages, and disadvantages of the generative models along with the related training strategies considering two principal human communication modalities, namely audio and video. In this context, facial expression synthesis, speech emotion synthesis, and the audio-visual (cross-modal) emotion synthesis are reviewed extensively under different application scenarios. Gradually, we discuss open research problems to push the boundaries of this research area for future works. As conclusions, we indicate common problems that can be explored from the Generative Adversarial Networks (GAN) topologies and applications in emotion synthesis.},
  keywords={Generative adversarial networks;Gallium nitride;Data models;Generators;Training;Computational modeling;Emotion recognition;Machine learning;generative adversarial networks;learning systems;emotion recognition;speech synthesis;image processing},
  doi={10.1109/ACCESS.2020.3042328},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10923983,
  author={Ravikumar, Rajesh Jagadeesan and Ammupriya, A. and Devi.P.P and Pandi, V.Samuthira and Akula, Akhila and Sankar, K.},
  booktitle={2024 5th IEEE Global Conference for Advancement in Technology (GCAT)}, 
  title={Deep Learning: Exploring the Depths of Artificial Neural Networks for Advanced Data Analysis and Pattern Recognition}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This research provides a comprehensive exploration of LSTMs, CNNs, and RNNs, with a focus on their application in advanced data analysis and pattern recognition. We begin by examining the theoretical underpinnings of each architecture, highlighting their unique features and the mechanisms by which they process and learn from data. In the process of collecting long-term relationships in sequential data, LSTMs have been demonstrated to perform exceptionally well, making them an excellent choice for applications such as language modeling and time series prediction. CNNs are discussed in the context of their ability to extract hierarchical features from spatial data, rendering them particularly effective for image and video analysis. RNNs, with their inherent ability to process sequences of varying lengths, are analyzed for their applications in speech recognition and machine translation. Following this, the research begins to conduct a comparative examination of different architectures, examining how well they perform on benchmark datasets as well as challenges that are encountered in the real world. We assess their strengths and limitations, considering factors such as accuracy, computational efficiency, and scalability. Additionally, we explore the challenges associated with training deep neural networks, including the need for extensive data preprocessing, the risk of overfitting, and the importance of hyperparameter tuning. Finally, we discuss the implications of these findings for future research and practical applications in data analysis and pattern recognition. The study concludes that while each architecture has its niche, the combination of LSTMs, CNNs, and RNNs offers a powerful toolkit for tackling complex problems across diverse domains. The research underscores the potential of deep learning to unlock insights from data at unprecedented scales and complexities, paving the way for innovative solutions in fields ranging from healthcare to finance.},
  keywords={Deep learning;Training;Technological innovation;Time series analysis;Computer architecture;Speech recognition;Feature extraction;Computational efficiency;Tuning;Overfitting;CNN;RNN;LSTM;Feature Extraction;Overfitting;Regularization;Data Augmentation},
  doi={10.1109/GCAT62922.2024.10923983},
  ISSN={},
  month={Oct},}@INBOOK{10948923,
  author={Banafa, Ahmed},
  booktitle={Artificial Intelligence in Action: Real-World Applications and Innovations}, 
  title={40 The Dark Side of AI: Risks, Challenges, and the Need for Responsible Development}, 
  year={2025},
  volume={},
  number={},
  pages={261-268},
  abstract={This comprehensive book dives deep into the current landscape of AI, exploring its fundamental principles, development challenges, potential risks, and the cutting-edge breakthroughs that are propelling it forward. Artificial intelligence (AI) is rapidly transforming industries and societies worldwide through groundbreaking innovations and real-world applications. Starting with the core concepts, the book examines the various types of AI systems, generative AI models, and the complexities of machine learning. It delves into the programming languages driving AI development, data pipelines, model creation and deployment processes, while shedding light on issues like AI hallucinations and the intricate path of machine unlearning. The book then showcases the remarkable real-world applications of AI across diverse domains. From preventing job displacement and promoting environmental sustainability, to enhancing disaster response, drone technology, and even nuclear energy innovation, it highlights how AI is tackling complex challenges and driving positive change. The book also explores the double-edged nature of AI, recognizing its tremendous potential while cautioning about the risks of misuse, unintended consequences, and the urgent need for responsible development practices. It examines the intersection of AI and fields like operating system design, warfare, and semiconductor technology, underscoring the wide-ranging implications of this transformative force. As the quest for artificial general intelligence (AGI) and superintelligent AI systems intensifies, the book delves into cutting-edge research, emerging trends, and the pursuit of multimodal, explainable, and causally aware AI systems. It explores the symbiotic relationship between AI and human creativity, the rise of user-friendly "casual AI," and the potential of AI to tackle open-ended tasks. This is an essential guide for understanding the profound impact of AI on our world today and its potential to shape our future. From the frontiers of innovation to the challenges of responsible development, this book offers a comprehensive and insightful exploration of the remarkable real-world applications and innovations driving the AI revolution.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770046190},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10948923},}@INPROCEEDINGS{11144984,
  author={Borjigin, Ailiya and Shen, Zhiqi},
  booktitle={2025 IEEE Region 10 Symposium (TENSYMP)}, 
  title={AI-Powered Meta-Reflection for Self-Learning in STEM: A Middle School Case Study on Smart Home Energy Management}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Emerging generative AI tools offer new opportunities to enhance students' metacognitive skills and self-regulated learning through guided reflection. This paper presents a case study on integrating AI-powered meta-reflection into a middle school STEM curriculum. We focus on a project-based learning (PBL) unit where students design a simple Smart Home Energy Management System, learning basic AI concepts, data analysis, and ethical implications of AI-driven decisions. A mixed-methods experimental design compared an AI-enhanced reflection approach (using OpenAI's ChatGPT) with traditional reflection activities. Quantitative data (pre/post tests, surveys, AI interaction logs) and qualitative data (student interviews, reflection journals, teacher feedback) were analyzed. Results indicate that students who engaged in dynamic AI-driven reflection showed greater gains in problem-solving and conceptual understanding, and demonstrated deeper self-regulated learning behaviors compared to a control group using conventional reflection. The AI prompted learners to analyze failures and iterate on solutions, improving their ability to learn from mistakes. Qualitative analyses suggest the AI reflection partner encouraged more introspective, adaptive thinking and higher engagement. We discuss how real-time conversational prompts from AI can scaffold meta-reflection, making student thinking visible and actionable for both learners and teachers. Key challenges (e.g., avoiding over-reliance or “metacognitive laziness”) are addressed through careful design of AI prompts and teacher oversight. Recommendations are provided for scaling AI-driven meta-reflection in K-12 STEM, including aligning AI tools with curriculum goals and training educators to integrate AI reflection facilitation. The study contributes initial evidence that AI-powered meta-reflection can enhance self-learning skills in middle school STEM, preparing students for more independent and reflective learning in an AI-rich future.},
  keywords={Training;Surveys;Smart homes;Learning (artificial intelligence);Metacognition;Chatbots;Reflection;Real-time systems;Problem-solving;Artificial intelligence;STEM Education;Project-Based Learning;Metacognition;Reflection;Self-Regulated Learning;Artificial Intelligence in Education;ChatGPT;Intelligent Tutoring Systems;Smart Home Energy},
  doi={10.1109/TENSYMP63728.2025.11144984},
  ISSN={2642-6102},
  month={July},}@ARTICLE{10980032,
  author={Wang, Yunke and Xu, Chang and Guo, Tianyu and Du, Bo and Tao, Dacheng},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={On Positive-Unlabeled Classification From Corrupted Data in GANs}, 
  year={2025},
  volume={47},
  number={8},
  pages={6859-6875},
  abstract={This paper defines a positive and unlabeled classification problem for standard GANs, which then leads to a novel technique to stabilize the training of the discriminator in GANs and deal with corrupted data. Traditionally, real data are taken as positive while generated data are negative. This positive-negative classification criterion was kept fixed all through the learning process of the discriminator without considering the gradually improved quality of generated data, even if they could be more realistic than real data at times. In contrast, it is more reasonable to treat the generated data as unlabeled, which could be positive or negative according to their quality. The discriminator is thus a classifier for this positive and unlabeled classification problem, and we derive a new Positive-Unlabeled GAN (PUGAN). We theoretically discuss the global optimality the proposed model will achieve and the equivalent optimization goal. Empirically, we find that PUGAN can achieve comparable or even better performance than those sophisticated discriminator stabilization methods. Considering the potential corrupted data problem in real-world scenarios, we further extend our approach to PUGAN-C, which treats real data as unlabeled that accounts for both clean and corrupted instances, and generated data as positive. The samples from generator could be closer to those corrupted data within unlabeled data at first, but within the framework of adversarial training, the generator will be optimized to cheat the discriminator and produce samples that are similar to those clean data. Experimental results on image generation from several corrupted datasets demonstrate the effectiveness and generalization of PUGAN-C.},
  keywords={Generative adversarial networks;Training;Generators;Image synthesis;Standards;Convergence;Gaussian distribution;Data models;Translation;Reviews;Generative adversarial nets;positive-unlabeled learning;image generation},
  doi={10.1109/TPAMI.2025.3565394},
  ISSN={1939-3539},
  month={Aug},}@ARTICLE{10897680,
  author={Li, Yuxuan and Yang, Lingfeng and Li, Xiang},
  journal={Computational Visual Media}, 
  title={APF-GAN: Exploring asymmetric pre-training and fine-tuning strategy for conditional generative adversarial network}, 
  year={2024},
  volume={10},
  number={1},
  pages={187-192},
  abstract={The use of generative adversarial network (GAN)-based models for the conditional generation of image semantic segmentation has shown promising results in recent years. However, there are still some limitations, including limited diversity of image style, distortion of detailed texture, unbalanced color tone, and lengthy training time. To address these issues, we propose an asymmetric pre-training and fine-tuning (APF)-GAN model. In the pretraining phase, we introduce a progressive growing mechanism for pix2pix conditional GAN frameworks to efficiently generate high-quality images with details. Subsequently, in the fine-tuning phase, we introduce novel semantic spatially-guided noise to improve the robustness of the model and increase style diversity. The proposed algorithm outperformed the high-performance GauGAN model and won the championship of the Second Jittor Artificial Intelligence Challenge. Our model was implemented in the Jittor framework and is available at https://github.com/zcablii/jittor-Torile-PG_SPADE.},
  keywords={Semantics;Noise;Training;Generative adversarial networks;Gaussian noise;Generators;Computational modeling;Visualization;Translation;Measurement},
  doi={10.1007/s41095-023-0357-1},
  ISSN={2096-0662},
  month={Feb},}@INBOOK{10955675,
  author={Siva Kumar, Ram Shankar and Anderson, Hyrum and Schneier, Bruce},
  booktitle={Not with a Bug, But with a Sticker: Attacks on Machine Learning Systems and What To Do About Them}, 
  title={Do You Want to Be Part of the Future?}, 
  year={2023},
  volume={},
  number={},
  pages={1-28},
  abstract={Summary <p>Adopters of artificial intelligence (AI) technology include not only headline grabbers like Google and Tesla but also eyebrow&#x2010;raising ones like McDonald's and Hilton Hotels. AI success story represents a true breakthrough. The capabilities of AI systems today are immensely impressive. The only thing rivaling the astonishing speed of machine learning (ML) systems is their proliferation. In the zeal to capitalize on the advancements, our society has deployed ML systems in sensitive areas such as healthcare ranging from pediatrics to palliative care, personalized finance, housing, and national defense. Researchers quickly turned to AI to sift through the mountains of data being generated by doctors and used state&#x2010;of&#x2010;the&#x2010;art algorithms to help with COVID diagnoses. The United States desperately needed a plan to address the ever&#x2010;increasing progress of AI systems and to decisively secure the advantages reaped by this technology from its adversaries.</p>},
  keywords={Artificial intelligence;Robots;Automobiles;Plasmas;Mobile robots;Machine learning;Internet;Games;Companies;Wheels},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781119884903},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10955675},}@INBOOK{10982320,
  author={Bergeret, Olivier and Abbasi, Asif and Farvault, Joel},
  booktitle={GenAI on AWS: A Practical Approach to Building Generative AI Applications on AWS}, 
  title={Introduction to Amazon SageMaker}, 
  year={2025},
  volume={},
  number={},
  pages={169-190},
  abstract={<p>Along the whole AI model creation cycle, Amazon SageMaker will also support governance requirements with simplified access control and transparency over our ML projects and can help us to ensure the responsible application of machine learning at every stage of the cycle. With the Amazon SageMaker service, we can automate model training and hyperparameter tuning, ensuring top&#x2010;tier performance with minimal manual effort. Amazon SageMaker Clarify helps us mitigate bias by detecting potential bias during data preparation, after model training, and in our deployed model by examining specific attributes. Related to Generative AI, SageMaker introduces a powerful suite of tools that make creating, training, and deploying Generative AI models accessible even to those who might not have a deep background in data science. SageMaker JumpStart simplifies the preliminary work, and for simple use cases it can definitely be replaced by Amazon Bedrock.</p>},
  keywords={Data models;Artificial intelligence;Training;Generative AI;Load modeling;Analytical models;Visualization;Transforms;Soft sensors;Pipelines},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394281305},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10982320},}@ARTICLE{9121981,
  author={Liang, Yunji and Samtani, Sagar and Guo, Bin and Yu, Zhiwen},
  journal={IEEE Internet of Things Journal}, 
  title={Behavioral Biometrics for Continuous Authentication in the Internet-of-Things Era: An Artificial Intelligence Perspective}, 
  year={2020},
  volume={7},
  number={9},
  pages={9128-9143},
  abstract={In the Internet-of-Things (IoT) era, user authentication is essential to ensure the security of connected devices and the customization of passive services. However, conventional knowledge-based and physiological biometric-based authentication systems (e.g., password, face recognition, and fingerprints) are susceptible to shoulder surfing attacks, smudge attacks, and heat attacks. The powerful sensing capabilities of IoT devices, including smartphones, wearables, robots, and autonomous vehicles enable continuous authentication (CA) based on behavioral biometrics. The artificial intelligence (AI) approaches hold significant promise in sifting through large volumes of heterogeneous biometrics data to offer unprecedented user authentication and user identification capabilities. In this survey article, we outline the nature of CA in IoT applications, highlight the key behavioral signals, and summarize the extant solutions from an AI perspective. Based on our systematic and comprehensive analysis, we discuss the challenges and promising future directions to guide the next generation of AI-based CA research.},
  keywords={Authentication;Biometrics (access control);Internet of Things;Sensors;Knowledge based systems;Physiology;Smart phones;Artificial intelligence (AI);behavioral biometric;body area networks;constrained devices;continuous authentication (CA);cyber–physical systems data mining;Internet of Things (IoT)},
  doi={10.1109/JIOT.2020.3004077},
  ISSN={2327-4662},
  month={Sep.},}@ARTICLE{9525164,
  author={Yang, Xiaoxian and Xu, Yueshen and Kuang, Li and Wang, Zhiying and Gao, Honghao and Wang, Xuejie},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={An Information Fusion Approach to Intelligent Traffic Signal Control Using the Joint Methods of Multiagent Reinforcement Learning and Artificial Intelligence of Things}, 
  year={2022},
  volume={23},
  number={7},
  pages={9335-9345},
  abstract={With the development of communication technology and artificial intelligence of things (AIoT), transportation systems have become much smarter than ever before. However, the volume of vehicles and traffic flows have rapidly increased. Optimizing and improving urban traffic signal control is a potential way to relieve traffic congestion. In general, traffic signal control is a sequential decision process that conforms to the characteristics of reinforcement learning, in which an agent constantly interacts with its environment, thus providing strategy for optimizing behavior in accordance with feedback in response. In this paper, we propose multiagent reinforcement learning for traffic signals (MARL4TS) to support the control and deployment of traffic signals. First, information on traffic flows and multiple intersections is formalized as input environments for performing reinforcement learning. Second, we design a new reward function to continuously select the most appropriate strategy as control during multiagent learning to track actions for traffic signals. Finally, we use a supporting tool, Simulation of Urban MObility (SUMO), to simulate the proposed traffic signal control process and compare it with other methods. The experimental results show that our proposed MARL4TS method is superior to the baselines. In particular, our method can reduce vehicle delay.},
  keywords={Reinforcement learning;Computational modeling;Transportation;Vehicle dynamics;Sensors;Roads;Real-time systems;Traffic signal control;artificial intelligence of things;collaborative computing;multiagent reinforcement learning;information fusion},
  doi={10.1109/TITS.2021.3105426},
  ISSN={1558-0016},
  month={July},}@INPROCEEDINGS{10553718,
  author={Hnaien, Ilhem Ben and Gascard, Eric and Simeu-Abazi, Zineb and Dhouibi, Hedi},
  booktitle={2024 International Conference on Control, Automation and Diagnosis (ICCAD)}, 
  title={A Literature Review of Digital Twins and Their Applications in the Internet of Things Based on Artificial Intelligence}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This comprehensive literature review explores the dynamic intersection of Digital Twins, Artificial Intelligence (AI), and the Internet of Things (IoT). Emphasizing the pivotal role of Digital Twins as live representations of real-world systems, the paper delves into their integration with AI for IoT applications. The exploration encompasses Digital Twin structures, classification methods, and the transformative impact of Industry 4.0. The review extends to modeling approaches, challenges faced in the realm of Cyber-Physical Systems, and the application of Machine Learning and Deep Learning techniques in enhancing Digital Twins. The synthesis of diverse perspectives aims to provide a holistic understanding of the evolving landscape and potential future developments in this interdisciplinary field.},
  keywords={Deep learning;Reviews;Bibliographies;Digital twins;Fourth Industrial Revolution;Internet of Things;Digital Twin;Artificial Intelligence;Internet of Things;Cyber-Physical Systems},
  doi={10.1109/ICCAD60883.2024.10553718},
  ISSN={2767-9896},
  month={May},}@INPROCEEDINGS{10932313,
  author={Kolhalkar, Nilesh R. and Pandit, Anupama A. and Kedar, Shridhar Ashok and Yedukondalu, G.},
  booktitle={2025 1st International Conference on AIML-Applications for Engineering & Technology (ICAET)}, 
  title={Artificial Intelligence Algorithms for Robotic Harvesting of Agricultural Produce}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Robotic harvesting of fruits and vegetables is an advanced technology that leverages Robotics, Artificial Intelligence, and Machine Vision to harvest the fruits autonomously from plants or trees. This technology aims to address labor shortages, enhance efficiency, reduce costs, and minimize damage to the fruit during harvesting. AI algorithms for fruit detection and harvesting are increasingly used in agricultural automation to improve efficiency and accuracy. The accuracy of detection algorithms in fruit detection and harvesting can differ reliant on various factors, including the type of algorithm used, the quality and diversity of the training data, the complexity of the environment, and the specific fruits being targeted. Advanced control algorithms integrated with image processing ensure that the robotic arm moves smoothly and accurately, minimizing the risk of bruising or damaging the fruit. Soft robotics and adaptive gripping technologies are discussed in the paper which can handle delicate fruits like grapes, without applying excessive force. Machine vision integrated robot arm with novel gripper and cutter for harvesting cluster fruit like grapes is reported in the paper. Case studies of agricultural robots for Orchards, Greenhouses and Field Crops are discussed with detailed analysis along with challenges, future trends and innovations.},
  keywords={Accuracy;Costs;Automation;Machine vision;Pipelines;Lighting;Training data;Robot sensing systems;Prediction algorithms;Robots;Artificial Intelligence;Agriculture Robots;End effector;Machine Vision;Mechatronics;Precision Agriculture;Robotic Harvesting;Smart Farming;Robotics;Harvesting Robots},
  doi={10.1109/ICAET63349.2025.10932313},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10772826,
  author={Zaernia, Amir and Youseffi, Mansour and Parisi, Luca and Abd-Alhameed, Raed and Ma, Renfei},
  booktitle={2024 12th European Workshop on Visual Information Processing (EUVIP)}, 
  title={A Novel Artificial Intelligence-Driven Technique for Enhancing Medical Imaging Techniques to Detect Non-Small Cell Lung Cancer}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Non-Small Cell Lung Cancer (NSCLC) is a disease wherein malignant cancer cells form in the lung tissue and this accounts for 85% of lung cancers. The five-year survival rate decreases as the NSCLC cancer becomes more advanced, from 40% for stage I to only 1% for stage IV; thus, a vital challenge to overcome is the early and correct detection of NSCLC to achieve a higher chance of survival. Due to radiographers being overworked with many time-consuming duties, new systems that can improve the effectiveness and efficiency of clinical professionals while maintaining appropriate predictive performance levels should be considered. Artificial intelligence (AI)-driven techniques can help provide the tools for radiographers to achieve a more accurate and efficient diagnosis of NSCLC. The deep learning (DL) model presented in this study leverages a novel multi-modal approach of using both Computed Tomography (CT) and Magnetic Resonance Imaging (MRI) scans as inputs to the model. This allows the model to learn from both morphological data from CT scans and also functional, physiological data available from MRI scans. As CT scans are the primary modality used in the structural detection of NSCLC, a higher weight is given to the recommendation made based on the information from the CT scan. One of the most important features analysed by the model is that of the Hounsfield Units (HU) of each pixel within the lung. HU values can be used to pinpoint areas of high density within the lungs that are identified as potential tumours. The model achieved a classification accuracy of 97.1% and an Area Under the Receiver Operating Characteristic Curve (AUC-ROC) of 95.7% on a test dataset of 140 patients.},
  keywords={Visualization;Accuracy;Computed tomography;Magnetic resonance imaging;Lungs;Computational modeling;Lung cancer;Predictive models;Diagnostic radiography;Tumors;Non-Small Cell Lung Cancer;Artificial Intelligence;Hounsfield Units;Computed Tomography;Magnetic Resonance Imaging},
  doi={10.1109/EUVIP61797.2024.10772826},
  ISSN={2471-8963},
  month={Sep.},}@INPROCEEDINGS{10635486,
  author={Du, Shiyi and Wang, Xiaosong and Lu, Yongyi and Zhou, Yuyin and Zhang, Shaoting and Yuille, Alan and Li, Kang and Zhou, Zongwei},
  booktitle={2024 IEEE International Symposium on Biomedical Imaging (ISBI)}, 
  title={Boosting Dermatoscopic Lesion Segmentation Via Diffusion Models With Visual And Textual Prompts}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Image synthesis approaches, e.g., generative adversarial networks, have been popular as a form of data augmentation in medical image analysis tasks. It is primarily beneficial to overcome the shortage of publicly accessible data and associated quality annotations. However, the current techniques often lack control over the detailed contents in generated images, e.g., the type of disease patterns, the location of lesions, and attributes of the diagnosis. In this work, we adapt the latest advance in the generative model, i.e., the diffusion model, with the added control flow using lesion-specific visual and textual prompts for generating dermatoscopic images. We further demonstrate the advantage of our diffusion model-based framework over the classical generation models in both the image quality and boosting the segmentation performance on skin lesions. It can achieve a 9% increase in the SSIM image quality measure and an over 5% increase in Dice coefficients over the prior arts.},
  keywords={Image quality;Image segmentation;Adaptation models;Visualization;Image synthesis;Generative adversarial networks;Diffusion models;Diffusion Model;Controllable Image Generation;Skin Lesion Segmentation},
  doi={10.1109/ISBI56570.2024.10635486},
  ISSN={1945-8452},
  month={May},}@INPROCEEDINGS{9853376,
  author={Shi, Er-Mei and Liu, Jia-Xi and Ji, Yuan-Ming and Chang, Liang},
  booktitle={2022 International Conference on Computer Engineering and Artificial Intelligence (ICCEAI)}, 
  title={DP-BEGAN: A Generative Model of Differential Privacy Algorithm}, 
  year={2022},
  volume={},
  number={},
  pages={168-172},
  abstract={In recent years, differential privacy has gradually become a standard definition in the field of data privacy protection. Differential privacy does not need to make assumptions about the prior knowledge of privacy adversaries, so it has a more stringent effect than existing privacy protection models and definitions. This good feature has been used by researchers to solve the in-depth learning problem restricted by the problem of privacy and security, making an important breakthrough, and promoting its further large-scale application. Combining differential privacy with BEGAN, we propose the DP-BEGAN framework. The differential privacy is realized by adding carefully designed noise to the gradient of Gan model training, so as to ensure that Gan can generate unlimited synthetic data that conforms to the statistical characteristics of source data and does not disclose privacy. At the same time, it is compared with the existing methods on public datasets. The results show that under a certain privacy budget, this method can generate higher quality privacy protection data more efficiently, which can be used in a variety of data analysis tasks. The privacy loss is independent of the amount of synthetic data, so it can be applied to large datasets.},
  keywords={Training;Differential privacy;Privacy;Data analysis;Publishing;Computational modeling;Data models;privacy protection;differential privacy;GANs;BEGAN;privacy data publishing},
  doi={10.1109/ICCEAI55464.2022.00043},
  ISSN={},
  month={July},}@INPROCEEDINGS{10649104,
  author={S, Rakshika and U, Shravya and Rao, Saieesh S and Sawkar, Nithanth Praveen and Devi, M. Sheela},
  booktitle={2024 IEEE International Conference on Contemporary Computing and Communications (InC4)}, 
  title={Image Reconstruction and Facial Feature Extraction for Criminal Identification Using Machine Intelligence (Epic Vision)}, 
  year={2024},
  volume={1},
  number={},
  pages={1-6},
  abstract={Criminal detection continues to face challenges when dealing with blurry, fragmented, or ambiguous visual information from surveillance sources. This paper is devoted to a sophisticated machine intelligence approach that attempts to address these issues. The main objective is to reconstruct and enhance the facial features and to carefully extract unique facial features. This approach is poised to provide more accurate and effective criminal detection methods. To achieve these goals, the project uses extensive facial datasets and state-of-the-art neural network models. By doing so, it seeks to change the way law enforcement agencies interpret and analyze physical evidence. The implemented system not only focuses on improving facial images but also ensures that vital facial landmarks are retained even under harsh conditions This modification of features a environmental image quality changes this is the main strength of the project, with real-world criminals -Promising to increase the efficiency of the investigation This study highlights the power of machine intelligence in law enforcement, and provides actionable insights that can reshape current practices His innovative facial reconstruction and feature extraction techniques are at the forefront of technological advances in this field. Moreover, the results of the project extend beyond the immediate context and have global significance. They have the potential to increase the efficiency and success of global security agencies and, ultimately, to help maintain public safety and preserve justice. This approach not only improves facial images but also ensures the retention of crucial facial landmarks, even in adverse conditions. By leveraging state-of-the-art machine intelligence, this project aims to significantly enhance criminal detection methods, offering tangible benefits to law enforcement agencies worldwide.},
  keywords={Visualization;Law enforcement;Surveillance;Neural networks;Feature extraction;Public security;Security;criminal identification;machine intelligence;facial feature extraction;neural networks},
  doi={10.1109/InC460750.2024.10649104},
  ISSN={},
  month={March},}@INPROCEEDINGS{10581584,
  author={Yu, Haoran and Di, Danyang and Shi, Junyao},
  booktitle={2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={Intelligent Quantification Method of Pipeline Flow Based on “YOLO v5-FCN-AdaBoost”}, 
  year={2024},
  volume={},
  number={},
  pages={241-245},
  abstract={The quantification of underground drainage pipeline flow is an important component of urban flood warning. In response to the high error rate and instability of current flow measurement devices, poor measurement accuracy, and the inability to accurately measure in complex drainage pipeline environments with confined spaces, strong corrosion, and low visibility, we have proposed, for the first time, an improved YOLO v5 algorithm, an Fully Convolutional Networks(FCN) algorithm based on dynamic pixel weighting strategy, and an AdaBoost regression algorithm combined with neural networks and machine learning to develop an intelligent quantification method of drainage pipeline flow. Based on this, the “object recognition + image segmentation + flow regression analysis” steps are taken. Generative Adversarial Networks (GAN) are used to provide more samples for target detection. Through data collection, image enhancement, iterative expansion of the dataset, and continuous updating of the parameters of the neural network and machine learning models, intelligent quantification of drainage pipeline flow is ultimately achieved, ensuring real-time, high-precision, and intelligentization.},
  keywords={YOLO;Weight measurement;Machine learning algorithms;Accuracy;Heuristic algorithms;Current measurement;Pipelines;Underground drainage pipelines;Neural network;Machine learning;Generative Adversarial Networks (GAN)},
  doi={10.1109/AINIT61980.2024.10581584},
  ISSN={},
  month={March},}@ARTICLE{10539998,
  author={Kumar Mohanty, Prasant and Hemant Kumar Reddy, K. and Panigrahy, Saroj Kumar and Sinha Roy, Diptendu},
  journal={IEEE Access}, 
  title={Leveraging Generative and Explainable AI for Electric Vehicle Energy Toward Sustainable, Consumer-Centric Transportation}, 
  year={2024},
  volume={12},
  number={},
  pages={143721-143732},
  abstract={In Industry 5.0, predicting electric vehicle energy usage enhances efficiency and sustainability, optimizes charging infrastructure, and meets consumer demands. Leveraging IoT, AI, and analytics enables smart charging that aligns with renewable energy goals, addresses infrastructure limitations, and promotes sustainable transportation by improving user experience, cutting costs, and boosting trust in electric vehicles. This research aims to create a synthetic data set for electric vehicles using an enhanced Generative adversarial network model and, from that, predict the energy for charging electric vehicles using ensemble Machine Learning algorithms. The importance of more detailed features for the best-performing machine learning model has been done utilizing Explainable Artificial Intelligence, specifically, the Shapley Additive Explanations approach, to provide more understanding and derive the inter-dependency among features. The enhanced TemporalCharge Generative adversarial network model provides Skewness and Kurtosis values as -0.51 and -0.182, respectively, for synthetically generated data for the city of Berhampur, Odisha, India, which is very close to four-wheeler electric vehicle charging data of the city. Several plots illustrate the influence of key features on electric vehicle energy consumption during charging, which enhances user optimization, owner empowerment, and ecosystem sustainability.},
  keywords={Electric vehicle charging;Predictive models;Data models;Electric vehicles;Energy consumption;Urban areas;Planning;Consumer electronics;Generative adversarial networks;Electric vehicles;consumer-centric technology;electric vehicle energy use;generative adversarial network;interpretability;shapley additive explanations},
  doi={10.1109/ACCESS.2024.3405959},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10851649,
  author={Yanev, Nikolay Ivanov and Getova, Iglika Dimitrova and Hristova, Teodora Vassileva and Kostadinova, Iva and Dimitrov, Georgi Petrov and Mihaylova, Elizabet},
  booktitle={2024 International Conference Automatics and Informatics (ICAI)}, 
  title={SWOT Analysis of the Possibility of Using AI for Education}, 
  year={2024},
  volume={},
  number={},
  pages={539-545},
  abstract={The purpose of the article is to make a SWOT analysis of the possibility of using generative algorithms in the education of students. The research was done on the basis of different groups of students who filled out a survey about knowledge and desire to use this cutting-edge technology. Economics, engineering, and computer science students took part in the study. After analysis, the strengths and weaknesses, as well as the opportunities and prospects for the development of social skills for using digital technologies in education, were determined. This will guide us in overcoming the difficulties and weaknesses and strengthen the opportunities to use this innovative tool.},
  keywords={Training;Surveys;Economics;Computer science;Ethics;Law;Plagiarism;Learning (artificial intelligence);Informatics;Guidelines;generative artificial intelligence;pedagogical experiment;survey;analysis;SWOT},
  doi={10.1109/ICAI63388.2024.10851649},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10411522,
  author={Zhang, Xi and Liu, Ziyue and Cheng, Yihang and Wang, Xuyan and Wang, Zhe},
  booktitle={2023 IEEE International Conference on Data Mining Workshops (ICDMW)}, 
  title={The Impact of AIGC on Organizational Knowledge Creation : From the Perspective of Adaptive Structuration Theory}, 
  year={2023},
  volume={},
  number={},
  pages={1469-1476},
  abstract={Artificial Intelligence Generated Content (AIGC), as an emerging content generation method, possesses creative generation characteristics that inherently facilitate the knowledge creation process. However, the specific impact of AIGC technology on the knowledge creation process remains unclear. Based on the Adaptive Structuration Theory, this paper delves into how AIGC influences the process of knowledge creation within organizations, while also shedding light on the far-reaching implications of AIGC technology at both the organizational and individual levels. This study offers a fresh perspective for understanding the potential and challenges posed by AIGC technology, providing valuable insights for organizations seeking to optimize the knowledge creation processes and advance the field of career science in response to the new challenges presented by the era of generative artificial intelligence.},
  keywords={Technological innovation;Generative AI;Engineering profession;Conferences;Organizations;Data mining;Artificial Intelligence Generated Content (AIGC);Adaptive Structuration Theory (AST);Organizational Knowledge Creation},
  doi={10.1109/ICDMW60847.2023.00187},
  ISSN={2375-9259},
  month={Dec},}@ARTICLE{11053145,
  author={Alsuhli, Ghada and Sakellariou, Vasilis and Saleh, Hani and Al-Qutayri, Mahmoud and Mohammad, Baker and Stouraitis, Thanos},
  journal={Proceedings of the IEEE}, 
  title={A Survey and Comparative Analysis of Number Systems for Deep Neural Networks}, 
  year={2025},
  volume={113},
  number={2},
  pages={172-207},
  abstract={Deep neural networks (DNNs) are indispensable in various artificial intelligence (AI) applications. However, their inherent complexity presents significant challenges, particularly when deploying them on resource-constrained devices. To overcome these hurdles, academia and industry are actively seeking ways to accelerate and optimize DNN implementations. A significant area of research revolves around discovering more effective methods to represent the enormous data volumes processed by DNNs. Traditional number systems (NSs) have proven nonoptimal for this task, prompting extensive exploration into alternative and bespoke systems for DNNs. This survey aims to comprehensively discuss various NSs utilized to efficiently represent DNN data. These systems are categorized mainly based on their impact on DNN performance and hardware implementation. This survey offers an overview of these categorized NSs and delves into different subsystems within each, outlining their effect on DNN performance and hardware design. Furthermore, these systems are compared quantitatively and qualitatively concerning their expected quantization error, memory utilization, and computational requirements. This survey also emphasizes the challenges linked with each system and the diverse proposed solutions to address them. Insights into the utilization of these NSs for sophisticated DNNs are also presented in this survey. Readers will acquire a deeper understanding of the importance of efficient NSs for DNNs, explore commonly used systems, comprehend the tradeoffs between these systems, delve into design considerations influencing their impact on DNN performance, and discover recent trends and potential research avenues in this field.},
  keywords={Artificial neural networks;Surveys;Hardware;Artificial intelligence;Accuracy;Dynamic range;Arithmetic;System-on-chip;Standards;Market research;Artificial intelligence (AI) accelerators;block floating point (BFP) number system;deep neural networks;dynamic fixed point (DFXP) number system;fixed point (FXP);floating point (FLP);logarithmic number system (LNS);number systems (NSs);posit number systems (PNSs);residue number system (RNS)},
  doi={10.1109/JPROC.2025.3578756},
  ISSN={1558-2256},
  month={Feb},}@INPROCEEDINGS{9842475,
  author={Tian, Jia–Liang and Zhang, Qin–Yan and Li, Hai–Zhen and Wang, Qing and Lei, Yi and Zang, Lin and Gao, Xue–Mei and Yang, Ji–Jiang},
  booktitle={2022 IEEE 46th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Study of facial generation methods after orthodontic treatment}, 
  year={2022},
  volume={},
  number={},
  pages={1006-1011},
  abstract={As the medical aesthetic market is growing rapidly in China, orthodontic treatment is becoming very common among the adolescent population. However, there are countless doctor-patient disputes due to treatment results that do not meet patients' expectations, so there is an urgent need for a method to predict treatment results. With the development of artificial intelligence technology, generative adversarial network has provided us with a new way of thinking. The purpose of this paper is to accurately predict the face of patients after orthodontic treatment by using generative adversarial network. Therefore, we designed an evaluation index to reflect the difference between the algorithm predicted image and the patient's real image. After that, we designed a network based on Encoder-Decoder architecture to transform the vectors in StyleGAN latent space. Finally, we carried out experiments to verify the effectiveness of the evaluation index design and the advantages of the algorithm.},
  keywords={Measurement;Technological innovation;Medical services;Transforms;Predictive models;Prediction algorithms;Generative adversarial networks;Face Generation;Orthodontic Treatment;StyleGAN;Encoder-Decoder},
  doi={10.1109/COMPSAC54236.2022.00156},
  ISSN={0730-3157},
  month={June},}@INPROCEEDINGS{9238807,
  author={Li, Yiwei and Xu, Guoliang and Li, Wanlin},
  booktitle={2020 IEEE/CIC International Conference on Communications in China (ICCC)}, 
  title={FA: A Fast Method to Attack Real-time Object Detection Systems}, 
  year={2020},
  volume={},
  number={},
  pages={1268-1273},
  abstract={With the development of deep learning, image and video processing plays an important role in the age of 5G communication. However, deep neural networks are vulnerable: subtle perturbations can lead to incorrect classification results. Nowadays, adversarial attacks on artificial intelligence models have seen increasing interest. In this study, we propose a new method named FA to generate adversarial examples of object detection models. Based on the generative adversarial network (GAN), we combine the classification and location information to make the generated image look as real as possible. Experimental results on the PASCAL VOC dataset show that our method efficiently and quickly generates the image. Then, we test the transferability of adversarial samples on different datasets and object detection models such as YOLOv4, which also achieve certain transfer performance. Our work provides a basis for further exploring the defects of deep learning and improving the robustness of the systems.},
  keywords={Deep learning;Object detection;Streaming media;Generative adversarial networks;Robustness;Real-time systems;Security;object detection;adversarial samples;GAN;information security and privacy},
  doi={10.1109/ICCC49849.2020.9238807},
  ISSN={2377-8644},
  month={Aug},}@INBOOK{10461723,
  author={Banafa, Ahmed},
  booktitle={Introduction to Artificial Intelligence (AI)}, 
  title={7 Generative AI: Types, Skills, Opportunities and Challenges}, 
  year={2024},
  volume={},
  number={},
  pages={37-44},
  abstract={Introduction to Artificial Intelligence (AI) provides a comprehensive overview of the latest trends in artificial intelligence. The book covers the state of the art in AI research, including machine learning, natural language processing, computer vision, and robotics. The book offers a forward-looking perspective on the future of AI, exploring the emerging trends and applications that are likely to shape the next decade of AI innovation. It also provides practical guidance for businesses and individuals on how to leverage the power of AI to create new products, services, and opportunities. Overall, the book is an essential read for anyone who wants to stay ahead of the curve in the rapidly evolving field of AI and understand the impact that this transformative technology will have on our lives in the coming years.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770041850},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10461723},}@INPROCEEDINGS{9277303,
  author={Feng, Kai and Wu, Jan and Tian, Min},
  booktitle={2020 IEEE International Conference on Information Technology,Big Data and Artificial Intelligence (ICIBA)}, 
  title={A Detect method for deepfake video based on full face recognition}, 
  year={2020},
  volume={1},
  number={},
  pages={1121-1125},
  abstract={In recent years, with the continuous upgrading of computer hardware and the continuous development of deep learning technology, new multimedia tampering tools can make it easier for people to tamper with faces in videos. Tampered videos produced by these new tools may hardly be detected by human, so we need effective method to detect these face-tampered videos. Current popular video face tampering technologies mainly include Deepfake technology based on self-encoder and Face2face technology based on computer graphics. In this paper, we propose a new method for tamper video detection based on the full faces. Facenet algorithm is used here to compare the similarity between real and fake video faces. Finally, in the experimental part, the results showed a significant effect.},
  keywords={Face recognition;Feature extraction;Videos;Information integrity;Gallium nitride;Training;Faces;deepfake;facenet;convolution network;machine learning},
  doi={10.1109/ICIBA50161.2020.9277303},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10577770,
  author={Taspinar, Yavuz Selim and Cinar, Ilkay},
  booktitle={2024 13th Mediterranean Conference on Embedded Computing (MECO)}, 
  title={Distinguishing Between AI Images and Real Images with Hybrid Image Classification Methods}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Due to the rapid proliferation of artificial intelligence applications, some vulnerabilities in security and ethical issues emerge. With these applications, data such as text, images, audio and video can be easily produced. In order to ensure stability in issues such as security , ethics and quality, it is necessary to identify the data produced by artificial intelligence applications. For this purpose, this study focuses on the classification of images created with artificial intelligence applications and real images. In the study , a dataset containing images produced by artificial intelligence and real images was used. There are a total of 975 images in the dataset. The features of the images in the dataset were extracted with SqueezeNet, InceptionV3 and VGG19 pre-trained CNN (Convolutional Neural Network) models. Classification of features was made with ANN (Artificial Neural Network), KNN (K Nearest Neighbor) and SVM (Support Vector Machine) machine learning methods. The highest classification success was obtained from the InceptionV3+ANN model. It is anticipated that the proposed models can be used to detect images produced with artificial intelligence applications. However, it has been determined that more data is needed to fully solve this challenging task.},
  keywords={Support vector machines;Ethics;Computational modeling;Machine learning;Feature extraction;Stability analysis;Convolutional neural networks;ai images;real images;fake images;cnn;machine learning},
  doi={10.1109/MECO62516.2024.10577770},
  ISSN={2637-9511},
  month={June},}@INPROCEEDINGS{10270302,
  author={Wang, Xiuling and Lu, Xiao and Wang, Yingying and Wang, Haixia and Zhang, Zhiguo},
  booktitle={2023 8th International Conference on Image, Vision and Computing (ICIVC)}, 
  title={Facial Expression Recognition Based on An Improved Data Augmentation Method and A Multichannel Convolutional Neural Network Model}, 
  year={2023},
  volume={},
  number={},
  pages={136-145},
  abstract={With the development of artificial intelligence and human-computer interaction, the recognition and analysis of facial expressions have recently received increasing attention. Considering the excellence of the convolutional neural network (CNN) model in the field of image recognition, this paper applies the CNN model to recognize facial expressions. The deep neural network is inseparable from large-scale data. In the real world, it is expensive to obtain large scale data sets with labels. A reliable method of expanding the number and diversity of the samples must be found. The generative adversarial networks (GAN) model can generate more images and solve the imbalance of data volume. However, the experiments indicated that the image sharpness generated by the traditional GAN model was insufficient. The model was challenging to train stably and prone to over-fitting or under-fitting. Given these situations, this paper optimized the structure of the GAN model by combining the advantages of the DCGAN and StarGAN models, and improved the training strategy. Moreover, a new multichannel CNN model is proposed and applied in this paper to obtain more comprehensive facial expression features. The experimental results reveal that the proposed method significantly improves the performance of the evaluated baseline facial expression recognition methods.},
  keywords={Training;Human computer interaction;Solid modeling;Image recognition;Face recognition;Computational modeling;Generative adversarial networks;Facial expression;generative adversarial networks;convolutional neural network (CNN)},
  doi={10.1109/ICIVC58118.2023.10270302},
  ISSN={},
  month={July},}@INPROCEEDINGS{10436771,
  author={Xu, Minrui and Niyato, Dusit and Zhang, Hongliang and Kang, Jiawen and Xiong, Zehui and Mao, Shiwen and Han, Zhu},
  booktitle={GLOBECOM 2023 - 2023 IEEE Global Communications Conference}, 
  title={Joint Foundation Model Caching and Inference of Generative AI Services for Edge Intelligence}, 
  year={2023},
  volume={},
  number={},
  pages={3548-3553},
  abstract={With the rapid development of artificial general intelligence (AGI), various multimedia services based on pretrained foundation models (PFMs) need to be effectively deployed. With edge servers that have cloud-level computing power, edge intelligence can extend the capabilities of AGI to mobile edge networks. However, compared with cloud data centers, resource-limited edge servers can only cache and execute a small number of PFMs, which typically consist of billions of parameters and require intensive computing power and GPU memory during inference. To address this challenge, in this paper, we propose a joint foundation model caching and inference framework that aims to balance the tradeoff among inference latency, accuracy, and resource consumption by managing cached PFMs and user requests efficiently during the provisioning of generative AI services. Specifically, considering the in-context learning ability of PFMs, a new metric named the Age of Context (AoC), is proposed to model the freshness and relevance between examples in past demonstrations and current service requests. Based on the AoC, we propose a least context caching algorithm to manage cached PFMs at edge servers with historical prompts and inference results. The numerical results demonstrate that the proposed algorithm can reduce system costs compared with existing baselines by effectively utilizing contextual information.},
  keywords={Measurement;Costs;Generative AI;Computational modeling;Inference algorithms;Numerical models;Servers;Mobile edge computing;generative artificial intelligence;pretrained foundation models;joint foundation model caching and inference},
  doi={10.1109/GLOBECOM54140.2023.10436771},
  ISSN={2576-6813},
  month={Dec},}@INPROCEEDINGS{10563470,
  author={Ghosh, Raj Krishan and Sheet, Debdoot},
  booktitle={2024 IEEE South Asian Ultrasonics Symposium (SAUS)}, 
  title={Zero-Shot Multi-Frequency Ultrasound Simulation using Physics Informed GAN}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Ultrasound (US) simulators are safe and cost-effective alternatives to real US systems for education and research. Numerical simulators employ heavy computations and simplifying assumptions of US propagation physics. Deep learning (DL) methods require comparably lesser computations and generalize better compared to numerical solvers, however they require large image datasets acquired at different transducer frequency in order to be optimized. We propose a physics informed DL approach to tackle these challenges. A generative adversarial network (GAN) is trained with an US image dataset imaged with a single transducer frequency. A kernel stretching method is proposed that is used during inference to simulate resolution change associated with varying transducer frequency. The proposed method retains aspects of frequency controllability of numerical simulators while preserving realism and computational simplicity of DL models. This approach has application in medical imaging domains where limited access to datasets and low computational resources handicap training of GANs.},
  keywords={Deep learning;Training;Image resolution;Transducers;Ultrasonic imaging;Generative adversarial networks;Numerical models;generative adversarial network;frequency control;resolution;ultrasound simulation;zero-shot adaptation},
  doi={10.1109/SAUS61785.2024.10563470},
  ISSN={},
  month={March},}@INPROCEEDINGS{11091963,
  author={Du, Jinming},
  booktitle={2025 7th International Conference on Computer Science and Technologies in Education (CSTE)}, 
  title={Learning Analytics in Action: A Mixed-Methods Study of Generative AI – ChatGPT’s Impact on L2 Academic Writing Development in English for Academic Purposes (EAP) Classrooms}, 
  year={2025},
  volume={},
  number={},
  pages={856-859},
  abstract={In the field of English for Academic Purposes (EAP), the role of AI-assisted language learning in developing writing skills has been extensively researched and has yielded positive outcomes. Also, Learning Analytics (LA) can significantly contribute to comprehending and enhancing the responsible and reflective utilisation of AI tools in the educational context. However, its impact on language classroom education, particularly in EAP writing instruction, has not received widespread attention. This study addresses this gap by investigating the descriptions and explanations of preferred EAP writing learning strategies among a group of international students (N=42) engaged in EAP studies at a university, with a particular focus on their utilisation of generative AI-powered chatbot technology- ChatGPT. Results showed that EAP students believed generative AI technology to be user-friendly, simple to grasp, creative, and enjoyable for L2 writing learning. They may ask specific questions and receive immediate answers without waiting for responses or feedback. The quality of the written content they produce has improved significantly, and their opinion output is more novel and relevant, with varying degrees of improvement in grammar and syntax. The study's findings suggest that generative AI, such as ChatGPT, can facilitate the development of EAP writing proficiency and provide instant and constructive feedback within an informal digital language learning context. This research yields pedagogical implications for the development of L2 writing strategies for L2 students in EAP classes, utilising generative AI chatbots like ChatGPT. The findings could be a valuable reference for language researchers or teachers who intend to use generative AI-supported chatbots in EAP writing.},
  keywords={Computer science;Generative AI;Education;Writing;Syntactics;Chatbots;Grammar;Learning Analytics;ChatGPT;Language assessment;English for Academic Purposes;EAP writing},
  doi={10.1109/CSTE64638.2025.11091963},
  ISSN={},
  month={April},}@INPROCEEDINGS{10248283,
  author={Beheshti, Amin and Yang, Jian and Sheng, Quan Z. and Benatallah, Boualem and Casati, Fabio and Dustdar, Schahram and Nezhad, Hamid Reza Motahari and Zhang, Xuyun and Xue, Shan},
  booktitle={2023 IEEE International Conference on Web Services (ICWS)}, 
  title={ProcessGPT: Transforming Business Process Management with Generative Artificial Intelligence}, 
  year={2023},
  volume={},
  number={},
  pages={731-739},
  abstract={Generative Pre-trained Transformer (GPT) is a state-of-the-art machine learning model capable of generating human-like text through natural language processing (NLP). GPT is trained on massive amounts of text data and uses deep learning techniques to learn patterns and relationships within the data, enabling it to generate coherent and contextually appropriate text. This position paper proposes using GPT technology to generate new process models when/if needed. We introduce ProcessGPT as a new technology that has the potential to enhance decision-making in data-centric and knowledge-intensive processes. ProcessGPT can be designed by training a generative pre-trained transformer model on a large dataset of business process data. This model can then be fine-tuned on specific process domains and trained to generate process flows and make decisions based on context and user input. The model can be integrated with NLP and machine learning techniques to provide insights and recommendations for process improvement. Furthermore, the model can automate repetitive tasks and improve process efficiency while enabling knowledge workers to communicate analysis findings, support evidence, and make decisions. ProcessGPT can revolutionize business process management (BPM) by offering a powerful tool for process automation and improvement. Finally, we demonstrate how ProcessGPT can be a powerful tool for augmenting data engineers in maintaining data ecosystem processes within large bank organizations. Our scenario highlights the potential of this approach to improve efficiency, reduce costs, and enhance the quality of business operations through the automation of data-centric and knowledge-intensive processes. These results underscore the promise of ProcessGPT as a transformative technology for organizations looking to improve their process workflows.},
  keywords={Training;Deep learning;Automation;Web services;Ecosystems;Decision making;Organizations;Business Process Management;Generative AI;Generative Pre-trained Transformer;Knowledge-Intensive Processes;Data-Centric Processes},
  doi={10.1109/ICWS60048.2023.00099},
  ISSN={2836-3868},
  month={July},}@ARTICLE{10168240,
  author={Sun, Caihao and Zhang, Xiaohua and Meng, Hongyun and Cao, Xianghai and Zhang, Jinhua and Jiao, Licheng},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={Dual-Branch Spectral–Spatial Adversarial Representation Learning for Hyperspectral Image Classification With Few Labeled Samples}, 
  year={2023},
  volume={16},
  number={},
  pages={1-15},
  abstract={Recently, deep learning methods, particularly the convolutional neural networks, have been extensively employed for extracting spectral–spatial features in hyperspectral image (HSI) classification tasks, yielding promising results. Conventional methods often use small image patches as input and combine spectral and spatial features with fixed strategies. However, the equal treatment of all pixels within heterogeneous patches can negatively impact feature extraction performance. In this article, we propose a semisupervised dual-branch spectral–spatial adversarial representation learning (SSARL) method for HSI classification. SSARL adaptively assigns attention weights to different pixels and adds a spectral constraint to spatial features. Our approach consists of three main components: 1) a dual-branch framework designed to independently extract spectral and spatial information from pixel and patch samples; 2) a class consistency loss that adaptively combines spectral and spatial classification results, mitigating the adverse effects of heterogeneous patches and enabling appropriate feature selection for various situations; and 3) the deep learning model on the labeled sample size by adding the adversarial representation module and conditional entropy to two branches, reducing the deep learning model's reliance on labeled sample size. Experimental results demonstrate that SSARL outperforms competitive methods on small-sized (0.3%–5%) labeled samples and exhibits superior performance for boundary test pixels.},
  keywords={Feature extraction;Hyperspectral imaging;Earth;Data mining;Adaptation models;Sun;Semantics;Deep learning;Generative adversarial networks;Semisupervised learning;Adversarial network;class consistency loss;dual branch;generative adversarial network (GAN);hyperspectral image (HSI) classification;semisupervised;spectral–spatial feature},
  doi={10.1109/JSTARS.2023.3290678},
  ISSN={2151-1535},
  month={},}@INPROCEEDINGS{11022223,
  author={Li, Peng},
  booktitle={2024 8th Asian Conference on Artificial Intelligence Technology (ACAIT)}, 
  title={Research on Animation Character Generation Based on Facial Capture and Memory Enhancement GAN Network}, 
  year={2024},
  volume={},
  number={},
  pages={1431-1435},
  abstract={To further improve the quality of face generation of animation characters, an animation face generation method based on realism enhancement is proposed. Among them, the conditional adversarial generative network is used as the basic image generation method, based on which memory network is introduced to adjust the realism of face image sequences. Then, generator and discriminator in conditional adversarial network are optimized to further improve facial detail quality of the generated face images. Experimental results reveal that compared with other generation methods, quality of images generated by the constructed method is higher. PSNR and SSIM evaluation indicators reaches 31.25 and 0.90 respectively, and the highest score is obtained on the subjective evaluation indicator of MOS, indicating that the face generated by the constructed model is more realistic. In conclusion, the proposed animation face generation method based on realism enhancement has excellent performance, can generate higher-quality face images, and can be applied to actual animation character production scenes to achieve higher quality virtual character modeling, which has high feasibility.},
  keywords={Image quality;Image synthesis;Character generation;Production;Animation;Generative adversarial networks;Generators;Image sequences;Faces;Optimization;animation character;face generation;GAN;memory network;quality optimization},
  doi={10.1109/ACAIT63902.2024.11022223},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10605357,
  author={Rizk, Frederic and Rizk, Rodrigue and Rizk, Dominick and Rizk, Patrick and Chu, Chee-Hung Henry},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={A Unified Approach for Binary-Class and Multi-Class Data Augmented Generation}, 
  year={2024},
  volume={},
  number={},
  pages={69-74},
  abstract={Deep neural networks excel in a wide range of tasks but require diverse datasets to prevent overfitting. Overfitting occurs when a network fits training data too precisely, leading to poor generalization. Data Augmentation is often used to mitigate overfitting aiming at enlarging and improving the quality of training datasets, facilitating the construction of superior deep learning models. MAGAN algorithm emerges as an innovative approach that functions as a Meta-Analysis of Generative Adversarial Networks (GANs). MAGAN harnesses the latent space capabilities of GANs to confront the challenges presented by binary-class, multi-class, grayscale, and RGB images, effectively covering a wide spectrum of scenarios. In this paper, we propose the use of MAGAN algorithm for binary-class and multi-class data augmented generation. We also undertake an in-depth experimental analysis, evaluating the performance of the proposed MAGAN-based approach in comparison to two alternative baseline scenarios: one without any augmentation and another utilizing a conventional augmentation method. To gauge the effectiveness of the proposed technique, we employed diverse classification metrics, including accuracy, loss, precision, recall, F1-score, and the confusion matrix. Our results demonstrate that the proposed approach surpasses the other two scenarios achieving improvements in terms of accuracy by a factor of x1.15 and x1.03, respectively. This underscores the significant advantages of harnessing MAGAN, a meta-analysis of GANs, for data augmentation across a range of image types and classification tasks.},
  keywords={Deep learning;Measurement;Accuracy;Training data;Artificial neural networks;Gray-scale;Data augmentation;machine learning;deep neural networks;overfitting;data augmentation;data augmented generation;generative adversarial networks;latent space},
  doi={10.1109/CAI59869.2024.00022},
  ISSN={},
  month={June},}
