@INPROCEEDINGS{11124017,
  author={Pozek, George and Tripaldelli, Alessia and Butka, Brian},
  booktitle={2025 6th International Conference of the Portuguese Society for Engineering Education (CISPEE)}, 
  title={Harnessing Artificial Intelligence to Formulate Intuitive Instructions for Students}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={In the past year, ChatGPT has surfaced as a formidable and transformative force, challenging, and reshaping conventional paradigms across diverse tasks. This research investigates the potential of ChatGPT 3.5, a Generative Pre-trained Transformer, as an innovative tool in coding education, focusing on the delivery of accurate instructional content. Previous research has led us to investigate more AI capabilities with application to the production of learning resources, evaluating ChatGPT's proficiency in completing a digital circuit design laboratory, with the notable result being that ChatGPT achieved a score of 73% on the laboratory assignments. Further delving into its tutoring capabilities, ChatGPT was utilized as a tutor in a Java coding class, where students were permitted to employ ChatGPT as a learning aid. The outcome was compelling, as after students were able to use ChatGPT as a tutor, the average score was 93.325%. This success not only demonstrated the model's adaptability but also highlighted its potential as a valuable resource for students seeking academic support. Central to this new step on the research is the assessment of ChatGPT 3.5's proficiency in understanding Verilog, a sophisticated programming language used in digital systems design. This research is conducted within the context of the Digital Systems Design in Aerospace (CEC330) course at Embry-Riddle Aeronautical University and involves the use of ChatGPT to create detailed laboratory manuals for the class. In this exploration, ChatGPT was tasked with synthesizing informative laboratory manuals by utilizing a provided Verilog code solution. The findings demonstrate the capability of ChatGPT to accurately interpret code and transform it into coherent laboratory instructions. The implications of this study extend to educators, providing them with a powerful tool for crafting clear and comprehensive laboratory instructions for multiple programming classes. This innovative approach has the potential to significantly enhance the instructional experience, enabling professors and teachers to deliver precise guidance to students undertaking coding-related laboratory assignments.},
  keywords={Digital systems;Heuristic algorithms;Education;Manuals;Chatbots;Encoding;Iterative methods;Artificial intelligence;Hardware design languages;Field programmable gate arrays;Artificial Intelligence;ChatGPT;Engineering Education;Digital Systems Design Laboratory;FPGA},
  doi={10.1109/CISPEE64787.2025.11124017},
  ISSN={},
  month={July},}@INPROCEEDINGS{10741141,
  author={Pan, Fengjunjie and Zolfaghari, Vahid and Wen, Long and Petrovic, Nenad and Lin, Jianjie and Knoll, Alois},
  booktitle={2024 IEEE International Symposium on Systems Engineering (ISSE)}, 
  title={Generative AI for OCL Constraint Generation: Dataset Collection and LLM Fine-tuning}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={The Object Constraint Language (OCL) is a formal specification language in model-based systems and software engineering. It defines complex rules and constraints for model-based system design and verification. Constructing an OCL constraint requires expertise not only in OCL syntax but also in meta-model information, which can hinder its application in the practical industrial scenario despite its broad usage. Recently, generative artificial intelligence has demonstrated remarkable performance in code and text generation. This work discusses the generation of OCL constraints from natural language specifications using large language models (LLMs). Given that the automotive and aviation industries are major consumers of model-based engineering, the use of commercial LLMs raises concerns about data privacy. Therefore, we propose to employ open-source and locally deployed LLMs for OCL generation tasks. In this work, we collected a set of meta-models and OCL constraints, which were syntactically validated to ensure the quality of the OCL dataset. Synthetic natural language specifications were generated and used in the dataset for model fine-tuning. Additionally, we designed a retrieval-augmented approach to incorporate meta-model information during LLM fine-tuning and OCL generation. The proposed fine-tuning and OCL generation approach has been experimented with the state-of-the-art open-source LLM, Llama 3 8B. The locally fine-tuned and deployed language model achieved comparable syntactic accuracy and a higher semantic similarity score for OCL generation compared to the cutting-edge commercial models, GPT-4 Turbo and Gemini 1.5 Pro. The usability of the fine-tuned model has been demonstrated for OCL generation in the context of automotive resource allocation.},
  keywords={Visualization;Generative AI;Semantics;Natural languages;Syntactics;Modeling;Usability;System analysis and design;Automotive engineering;Context modeling},
  doi={10.1109/ISSE63315.2024.10741141},
  ISSN={2687-8828},
  month={Oct},}@INPROCEEDINGS{10987974,
  author={Patil, Bhavesh and Yadav, Gitanjali B and Buchade, Amar and Borkar, Soham and Bhosale, Shreyash and Honbute, Vikrant},
  booktitle={2025 International Conference on Emerging Smart Computing and Informatics (ESCI)}, 
  title={Dynamic StarCraft: Multi-Agent Generative AI for Immersive Experiences}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={The present research reveals a unique educational approach through the use of Generative Artificial Intelligence (GenAI) with the focus on storytelling with children. It is shown that by adding GenAI narrative co-creation, voice-over synthesis, and video audition to the system, the learning process becomes interesting. We understand how the audience creates the stories with which they will perform, how the stories are narrated in audio created with advanced text-to-speech systems, and how images for the narratives are generated with text-to-video. Our assessment is however concerned with the level of the languages used in writing the stories, how the stories written were pronounced and the images that were produced, as we point out the ability of the tool to entertain young learners.},
  keywords={Measurement;Generative AI;Refining;Pipelines;Layout;Media;Writing;Software;Text to speech;Text to video;GenAI;LLM;Text-To-Speech(TTS);Text-to-Video(TTV);TTM},
  doi={10.1109/ESCI63694.2025.10987974},
  ISSN={2996-1815},
  month={March},}@INPROCEEDINGS{10932646,
  author={Singh, Pradum Kumar and Sharma, Sourav and Sachdeva, Ritu},
  booktitle={2025 2nd International Conference on Computational Intelligence, Communication Technology and Networking (CICTN)}, 
  title={Advancing Techniques for Deepfake Detection and Evaluation: Challenges and Innovations}, 
  year={2025},
  volume={},
  number={},
  pages={480-485},
  abstract={The proliferation of deepfakes-also termed artificial intelligence-generated synthetic media poses unprecedented challenges to the digital authenticity of media, for media integrity, and to societies’ trust in its credibility. Despite such significant technological advancements, current methodologies for detecting deepfakes remain somewhat fragmented, reactive, and often unable to keep pace with rapidly evolving technologies in generative AI. This article considers a comprehensive multi-modal approach toward deepfake detection by integrating an advanced machine learning algorithm, novel statistical correlation techniques, and forensic image analysis that would fill in the critical gaps in the existing frameworks. By using an extensive dataset of 10,000 synthetic and authentic media samples from diverse domains, we developed a hybrid neural network architecture that attained 94.3% accuracy on identifying AI-generated content. Our methodology utilized ensemble learning by combining spatial-temporal inconsistency detection, biological signal analysis, and advanced feature extraction algorithms. Key findings demonstrate significant vulnerabilities in current deepfake generation models, with our proposed technique successfully identifying subtle artifacts and inconsistencies across multiple generative AI platforms. This research conclusively demonstrates that proactive, adaptive detection strategies are critical to mitigating the potential risks associated with synthetic media, providing a robust framework for future technological interventions in digital forensics and media authentication.},
  keywords={Deepfakes;Machine learning algorithms;Generative AI;Neural networks;Digital forensics;Signal processing algorithms;Authentication;Media;Feature extraction;Information integrity;Artificial Intelligence;deepfake;hybrid neural network;machine learning},
  doi={10.1109/CICTN64563.2025.10932646},
  ISSN={},
  month={Feb},}@ARTICLE{11025168,
  author={Lotfi, Ismail and Alabbasi, Nouf and Alhussein, Omar},
  journal={IEEE Internet of Things Magazine}, 
  title={Rethinking Strategic Mechanism Design In The Age Of Large Language Models: New Directions For Communication Systems}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={This paper explores the application of large language models (LLMs) in designing strategic mechanisms - including auctions, contracts, and games- for specific purposes in communication networks. Traditionally, strategic mechanism design in telecommunications has relied on human expertise to craft solutions based on game theory, auction theory, and contract theory. However, the evolving landscape of telecom networks, characterized by increasing abstraction, emerging use cases, and novel value creation opportunities, calls for more adaptive and efficient approaches. We propose leveraging LLMs to automate or semi-automate the process of strategic mechanism design, from intent specification to final formulation. This paradigm shift introduces both semi-automated and fully-automated design pipelines, raising crucial questions about faithfulness to intents, incentive compatibility, algorithmic stability, and the balance between human oversight and artificial intelligence (AI) autonomy. The paper discusses potential frameworks, such as retrieval-augmented generation (RAG)-based systems, to implement LLMdriven mechanism design in communication networks contexts. We examine key challenges, including LLM limitations in capturing domain-specific constraints, ensuring strategy proofness, and integrating with evolving telecom standards. By providing an in-depth analysis of the synergies and tensions between LLMs and strategic mechanism design within the IoT ecosystem, this work aims to stimulate discussion on the future of AI-driven information economic mechanisms in telecommunications and their potential to address complex, dynamic network management scenarios.},
  keywords={Mechanism design;Contracts;Game theory;Telecommunications;Biological system modeling;Artificial intelligence;Resource management;Retrieval augmented generation;Generative AI;Heuristic algorithms;Deep learning;generative AI;mechanism design;game theory;computer networks},
  doi={10.1109/MIOT.2025.3576260},
  ISSN={2576-3199},
  month={},}@ARTICLE{9624947,
  author={Zhang, Chi and Lin, Zihang and Xu, Liheng and Li, Zongliang and Tang, Wei and Liu, Yuehu and Meng, Gaofeng and Wang, Le and Li, Li},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Density-Aware Haze Image Synthesis by Self-Supervised Content-Style Disentanglement}, 
  year={2022},
  volume={32},
  number={7},
  pages={4552-4572},
  abstract={The key procedure of haze image synthesis with adversarial training lies in the disentanglement of the feature involved only in haze synthesis, i.e., the style feature, from the feature representing the invariant semantic content, i.e., the content feature. Previous methods introduced a binary classifier to constrain the domain membership from being distinguished through the learned content feature during the training stage, thereby the style information is separated from the content feature. However, we find that these methods cannot achieve complete content-style disentanglement. The entanglement of the flawed style feature with content information inevitably leads to the inferior rendering of haze images. To address this issue, we propose a self-supervised style regression model with stochastic linear interpolation that can suppress the content information in the style feature. Ablative experiments demonstrate the disentangling completeness and its superiority in density-aware haze image synthesis. Moreover, the synthesized haze data are applied to test the generalization ability of vehicle detectors. Further study on the relation between haze density and detection performance shows that haze has an obvious impact on the generalization ability of vehicle detectors and that the degree of performance degradation is linearly correlated to the haze density, which in turn validates the effectiveness of the proposed method.},
  keywords={Feature extraction;Image synthesis;Scattering;Generative adversarial networks;Atmospheric modeling;Training;Testing;Haze synthesis;unsupervised image-to-image translation;self-supervised disentanglement},
  doi={10.1109/TCSVT.2021.3130158},
  ISSN={1558-2205},
  month={July},}@ARTICLE{11155158,
  author={Sung, Mingyu and Gong, Mu-Gyeong and Ham, Seung-Jae and Kim, Il-Min and Yun, Sangseok and Kang, Jae-Mo},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={A Novel VLM-Guided Diffusion Model for Remote Sensing Image Super-Resolution}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Super-resolution (SR) of remote sensing imagery based on generative AI models is vital for practical applications such as urban planning and disaster assessment. However, current approaches suffer from poor performance trade-offs among the pivotal, yet competing, objectives: perceptual quality, factual accuracy, and inference speed. To break through this limitation, we propose a novel and high-performing two-stage SR framework for the remote sensing imagery based on a generative diffusion model. First, in Stage 1, factually grounded base images are generated by employing a guidance-free diffusion process relying solely on the original low-resolution images, such that the risk of semantic hallucination can be effectively mitigated. The generated images are refined subsequently in Stage 2 such that high-frequency details for SR quality can be restored via our customized and innovative guidance mechanism with a vision–language model (VLM) and a ControlNet, and a dynamic inference acceleration technique is applied to ensure efficiency. Extensive experimental results confirm that our proposed framework excels in perceptual quality—achieving top CLIP-IQA scores—and in structural integrity while achieving robust performance. In particular, it enables reliable, high-fidelity SR for large-scale, real-world remote sensing pipelines by surpassing the conventional fidelity–hallucination trade-off at practical inference speed. Source code is available at https://github.com/Bluear7878/Remote-Sensing-Vision-Language-Diffusion-Model.},
  keywords={Remote sensing;Diffusion models;Measurement;Accuracy;Semantics;Image segmentation;Image restoration;Superresolution;Standards;Image synthesis;Diffusion models;DDIM sampling;lightweight architecture;super-resolution;remote sensing imagery;VLM},
  doi={10.1109/LGRS.2025.3608178},
  ISSN={1558-0571},
  month={},}@INPROCEEDINGS{10390280,
  author={Al-Jawahry, Hassan M. and Ramyateja, Oruganti and Reddy, R Archana and Ramadan, Ghazi Mohamad and Maharajan, K.},
  booktitle={2023 International Conference on Ambient Intelligence, Knowledge Informatics and Industrial Electronics (AIKIIE)}, 
  title={Classification of Air Quality Index Using Autoregressive Integrated Moving Average (ARIMA) and Artificial Neural Networks Models}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={One of the negative effects of urbanization and population increase in developing nations is air pollution. As a result, the Air Quality Index (AQI) is assessed in a descriptive system that serves as a medium for informing the public about the danger of pollution. Thus, a deep learning system automates the assessment of air contaminants using time series data. Over the years, one of the most often used linear models in time series forecasting has been the Autoregressive Integrated Moving Average (ARIMA). Artificial neural networks (ANNs) have been the subject of recent study into forecasting, and these studies indicate that ANNs may prove to be a viable substitute for more conventional linear methods. In order to take advantage on the distinct advantages of ARIMA and ANN models in linear and nonlinear modelling, a hybrid methodology combining both models are presented in this study. This study made use of the data from the UCI Machine Learning Repository 2017. The primary objective of the Long Short-Term Model (LSTM), which is used for classification, is to improve accuracy in the vicinity of the test point. Based on the findings, the suggested ARIMA-ANN model outperforms the current model in terms of accuracy. The combined model can be an efficient means of enhancing the predicting accuracy attained by either of the models employed separately, according to the study results with the given data sets.},
  keywords={Deep learning;Atmospheric modeling;Urban areas;Time series analysis;Artificial neural networks;Predictive models;Data models;Air Pollutants;Air Quality Index;Auto Regressive Integrated Moving Average;Long Short-Term Model;Time Series Data},
  doi={10.1109/AIKIIE60097.2023.10390280},
  ISSN={},
  month={Nov},}@ARTICLE{8933080,
  author={Ma, Jie and Zhang, Libao and Zhang, Jue},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={SD-GAN: Saliency-Discriminated GAN for Remote Sensing Image Superresolution}, 
  year={2020},
  volume={17},
  number={11},
  pages={1973-1977},
  abstract={Recently, convolutional neural networks have shown superior performance in single-image superresolution. Although existing mean-square-error-based methods achieve high peak signal-to-noise ratio (PSNR), they tend to generate oversmooth results. Generative adversarial network (GAN)-based methods can provide high-resolution (HR) images with higher perceptual quality, but produce pseudotextures in images, which generally leads to lower PSNR. Besides, different regions in remote sensing images (RSIs) reflect discrepant surface topography and visual characteristics. This means a uniform reconstruction strategy may not be suitable for all targets in RSIs. To solve these problems, we propose a novel saliency-discriminated GAN for RSI superresolution. First, hierarchical weakly supervised saliency analysis is introduced to compute a saliency map, which is subsequently employed to distinguish the diverse demands of regions in the following generator and discriminator part. Different from previous GANs, the proposed residual dense saliency generator takes saliency maps as a supplementary condition in the generator. Simultaneously, combining the characteristic of RSIs, we design a new paired discriminator to enhance the perceptual quality, which measures the distance between generated images and HR images in salient areas and nonsalient areas, respectively. Comprehensive evaluations validate the superiority of the proposed model.},
  keywords={Generators;Gallium nitride;Generative adversarial networks;Image reconstruction;Feature extraction;Visualization;Deep learning;generative adversarial network (GAN);remote sensing;saliency analysis;superresolution},
  doi={10.1109/LGRS.2019.2956969},
  ISSN={1558-0571},
  month={Nov},}@INPROCEEDINGS{9434150,
  author={Zhong, Liqun and Liu, Guole and Yang, Ge},
  booktitle={2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)}, 
  title={Blind Denoising of Fluorescence Microscopy Images Using GAN-Based Global Noise Modeling}, 
  year={2021},
  volume={},
  number={},
  pages={863-867},
  abstract={Fluorescence microscopy is a key driving force behind advances in modern life sciences. However, due to constraints in image formation and acquisition, to obtain high signal-to-noise ratio (SNR) fluorescence images remains difficult. Strong noise negatively affects not only visual observation but also downstream analysis. To address this problem, we propose a blind global noise modeling denoiser (GNMD) that simulates image noise globally using a generative adversarial network (GAN). No prior information on noise properties is required. And no clean training targets need to be provided for noisy inputs. Instead, by simulating real image noise using a GAN, our method synthesizes paired noisy and clean images for training a denoising deep learning network. Experiments on real fluorescence microscopy images show that our method substantially outperforms competing state-of-the-art methods, especially in suppressing background noise. Denoising using our method also facilitates downstream image segmentation.},
  keywords={Training;Visualization;Image segmentation;Microscopy;Noise reduction;Fluorescence;Generative adversarial networks;Fluorescence microscopy;blind denoising;generative adversarial network;global noise modeling},
  doi={10.1109/ISBI48211.2021.9434150},
  ISSN={1945-8452},
  month={April},}@INPROCEEDINGS{10689946,
  author={Gurav, Aryan Sharad and Karanjikar, Yathharth Munesh and Bhikle, Omkar Arun and Deshpande, Himani},
  booktitle={2024 5th International Conference on Electronics and Sustainable Communication Systems (ICESC)}, 
  title={Comparing the Effectiveness of GAN-based Methods for Enhancing EuroSat Satellite Imagery Classification}, 
  year={2024},
  volume={},
  number={},
  pages={1611-1616},
  abstract={Addressing the challenge of limited data in remote sensing, this research investigates the application of Generative Adversarial Networks (GANs) to augment the EuroSat dataset. Four GAN variants (Info-GAN, C-GAN, CDC-GAN, and AC- GAN) were employed to expand a reduced EuroSat dataset by 50%. The augmented datasets were subsequently used to train Convolutional Neural Networks (CNNs) for image classification. Comprehensive evaluation metrics (accuracy, recall, precision, Fl-score, AUC, IS, and FID) were employed to assess the performance of the generated images and the trained models. Results indicate that CDC-GAN exhibited the highest classification accuracy and MCC, while AC-GAN excelled in ROC-AUC, precision, and recall. This study underscores the potential of GAN s as a valuable tool for enhancing remote sensing image datasets and improving classification performance.},
  keywords={Measurement;Accuracy;Lead;Generative adversarial networks;Data augmentation;Robustness;Satellite images;Remote sensing;Optimization;Image classification;GAN;Data Augmentation;EuroSat;Satellite Imagery;CNN},
  doi={10.1109/ICESC60852.2024.10689946},
  ISSN={2996-5357},
  month={Aug},}@INPROCEEDINGS{10174589,
  author={Dubey, Ekaagra and Singh, Neetu and Joshi, Prateek and Prasad, Rahul},
  booktitle={2023 IEEE World AI IoT Congress (AIIoT)}, 
  title={A Conditional GAN Architecture for Colorization of Thermal Infrared Images}, 
  year={2023},
  volume={},
  number={},
  pages={0055-0062},
  abstract={The applicability of visible spectrum cameras is limited to nighttime and extreme weather conditions. To overcome these limitations, infrared (IR) cameras were introduced, but their images lack luminance and representation quality, limiting the analytical ability and response time of humans. To be understandable by humans, image enhancement is not sufficient; conversion to visible RGB format is required, and this process is popularly known as colorization. However, the thermal infrared (TIR) images are low in both luminance and chrominance in comparison to grayscale images, which are only low in chrominance. Therefore, TIR colorization needs image-to-image translation; simple color transfer is not enough. In this paper, we investigated and modified one of the most commonly used conditional generative adversarial networks, known as pix2pixHD GAN for TIR-to-visible RGB translation. We are proposing a new composite loss function with noise augmentation in training. The improvement in the average values of NRMSE, PSNR, LPIPS, and NIQE is observed when compared with the state-of-the-art on the publicly available KAIST dataset. The results of the extensive experiments proved the effectiveness of the proposed method for TIR colorization, which is shown using both subjective (visual) and objective assessments for evaluation of image quality.},
  keywords={Training;Image quality;Visualization;Limiting;Image color analysis;Generative adversarial networks;Cameras;Conditional GANs;EMD loss;infrared images;color loss;noise augmentation;pix2pixHD GAN;TV loss;visible spectrum},
  doi={10.1109/AIIoT58121.2023.10174589},
  ISSN={},
  month={June},}@INPROCEEDINGS{10974900,
  author={Aladl, Miada M. and Gouda, Karam and Hagag, Ahmed and Ahmed, Ayman},
  booktitle={2024 34th International Conference on Computer Theory and Applications (ICCTA)}, 
  title={Stellar Cleanse: Pioneering CosmicNet for Superior Denoising of Space Imagery}, 
  year={2024},
  volume={},
  number={},
  pages={220-225},
  abstract={Space imagery is critical for astronomical research and satellite observations, but it often suffers from noise and artifacts, such as streaks caused by cosmic rays and sensor imperfections. Traditional denoising techniques frequently compromise essential features like stars, leading to a loss of valuable information. This paper introduces Stellar Cleanse, a pioneering framework that leverages CosmicNet for superior denoising of space imagery. CosmicNet integrates several advanced techniques: frequency domain preprocessing with Fourier Transform and low-pass filtering, a customized convolutional neural network (CNN) for residual noise learning, attention mechanisms for streak detection and preservation of stars, Total Variation (TV) Minimization for edge retention, and a Generative Adversarial Network (GAN) for final image refinement. Extensive experimental evaluation demonstrates that CosmicNet significantly outperforms traditional methods in both quantitative metrics (PSNR, SSIM) and qualitative assessments, effectively reducing noise while preserving critical celestial features. This groundbreaking approach not only enhances image clarity but also holds promise for broader applications in astronomical imaging and beyond.},
  keywords={Attention mechanisms;Image edge detection;Frequency-domain analysis;Noise;Noise reduction;Pipelines;Stars;Generative adversarial networks;Minimization;Convolutional neural networks;Denoising;space imagery;deep learning;convolutional neural network;attention mechanism;generative adversarial network},
  doi={10.1109/ICCTA64612.2024.10974900},
  ISSN={2770-6575},
  month={Dec},}@INPROCEEDINGS{11158175,
  author={Xu, Xiuci and Xu, Jihong and Jia, Yu},
  booktitle={2025 5th International Conference on Artificial Intelligence and Education (ICAIE)}, 
  title={Design of a Multi-Agent System for Personalized Training of Normal School Students' Teaching Skills}, 
  year={2025},
  volume={},
  number={},
  pages={123-127},
  abstract={With the development of artificial intelligence technology, especially the emergence of generative AI, new opportunities have arisen for the training of normal school students' teaching skills. This paper discusses the design of intelligent agents and the current status of their application in the training of normal school students' teaching skills. It believes that the application of intelligent agent technology in this field is feasible and has a solid foundation. After analyzing the problems of traditional training modes, a four-layer, three-agent system framework is constructed, which includes the user layer, service layer, tool layer, and knowledge layer. The aim is to provide a comprehensive, personalized teaching skills training environment for normal school students, helping them to better master teaching skills and laying a solid foundation for their future teaching careers.},
  keywords={Training;Generative AI;Engineering profession;Solids;Intelligent agents;Multi-agent systems;normal school students;teaching skills;personalization;multi-agent system},
  doi={10.1109/ICAIE64856.2025.11158175},
  ISSN={},
  month={May},}@INPROCEEDINGS{10282673,
  author={Zhang, Xiushe and Wang, Xinlin and Han, Chunlei and Mu, Jinming and Gou, Shuiping},
  booktitle={IGARSS 2023 - 2023 IEEE International Geoscience and Remote Sensing Symposium}, 
  title={Feature Adversarial Network for Multimodal Template Matching}, 
  year={2023},
  volume={},
  number={},
  pages={612-615},
  abstract={Recently generative adversarial network (GAN) has been explored to multimodal template matching. Existing GAN-based multimodal template matching methods exploit the image generation to transform the multimodal template matching task as the unimodal one. However, image synthesis-based multimodal template matching methods relay on the generated image quality, which is unstable. Towards this end, this paper proposes a feature adversarial network, which maps different modal images into a common subspace and learns the correlation in the subspace. Specifically, the feature mapper is designed to map the multimodal features into intermediate features, and the modality discriminator is proposed to optimize the multimodal intermediate features until they are indistinguishable. Thus, an effective common feature subspace is generated for correlation learning. The experimental results on a public dataset demonstrate the superiority of the proposed method.},
  keywords={Image quality;Correlation;Image synthesis;Geoscience and remote sensing;Transforms;Generative adversarial networks;Adversarial machine learning;generative adversarial network;multi-modal images;template matching},
  doi={10.1109/IGARSS52108.2023.10282673},
  ISSN={2153-7003},
  month={July},}@INPROCEEDINGS{10708916,
  author={Gao, Siming and Jiang, Rongheng},
  booktitle={2024 3rd International Conference on Artificial Intelligence and Autonomous Robot Systems (AIARS)}, 
  title={Optimization and Automatic Generation Algorithm of Mechanical Design Parameters Based on Deep Learning}, 
  year={2024},
  volume={},
  number={},
  pages={374-379},
  abstract={The purpose of this paper is to study the optimization and automatic generation algorithm of mechanical design parameters based on deep learning, and to explore its application in engineering design field. Firstly, the paper introduces the potential application of deep learning technology in mechanical design, and reviews the related research work. Then, a parameter optimization method based on Generative Adversarial Network (GAN) is proposed. By learning the complex design space characteristics, efficient design parameter optimization is realized. Then, the automatic generation algorithm based on the Variable Automatic Encoder (VAE) is discussed, which can generate diverse and innovative design schemes. Through the evaluation and analysis of the experimental results, the effectiveness and performance advantages of the proposed method are verified and compared with the traditional methods. Finally, the future development direction of GAN-based mechanical design optimization and VAE-based generation algorithm is prospected, and its application prospect in engineering practice is discussed. This study provides new ideas and methods for the application of deep learning technology in the field of mechanical design, and is of great significance for promoting the intelligence and automation of engineering design.},
  keywords={Deep learning;Training;Automation;Reviews;Generative adversarial networks;Optimization;Design optimization;Convergence;Autonomous robots;Deep learning;automatic generation;mechanical design;Generative adversarial network;Variational automatic encodert},
  doi={10.1109/AIARS63200.2024.00076},
  ISSN={},
  month={July},}@ARTICLE{10587004,
  author={Sikandar, Misba and Din, Ikram Ud and Almogren, Ahmad},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={Integrating Generative AI and Federated Learning for Privacy Preserved Sequence-Based Stomach Adenocarcinoma Detection}, 
  year={2024},
  volume={70},
  number={3},
  pages={5278-5285},
  abstract={Stomach Adenocarcinoma (STAD) significantly impacts global cancer mortality rates. Recent strides in artificial intelligence (AI), machine learning (ML), and deep learning (DL) have primarily harnessed imaging techniques like CT, X-rays, PET, and MRI for cancer detection. Concurrently, the rapidly growing volume of genomic big data presents an untapped reservoir for identifying genetic mutations characteristic of STAD. Our research explores this avenue by examining gene amino acid sequences altered by STAD. We employ physical properties of amino acids, i.e., Electro-Ion Interaction Pseudopotential (EIIP) values and Kidera factors in feature extraction, a novel strategy in STAD diagnostics. To address the issue of class imbalance, we incorporate generative AI to produce additional data samples. Addressing the privacy and security challenges associated with data centralization in healthcare, we propose Fed_ANN11, an artificial neural network (ANN) model developed in a federated environment following an initial deployment as ANN11. Our model demonstrates remarkable accuracy in both simple and federated environments with extracted feature sets, namely, EIIP-based and Kidera factors-based. We found that EIIP-based features eclipse Kidera factors in performance. In a simple setting, the proposed model achieved a testing accuracy of 86% and a training accuracy of 88% for STAD detection using the EIIP-based feature set. In a federated environment, it achieved an accuracy of 0.94% in testing and 0.99% in training for STAD detection using the EIIP-based feature set. Moreover, our proposed model shows significant performance compared to existing state-of-the-art methods. Fed_ANN11 not only excels in diagnostic precision but also upholds stringent big data security and privacy protocols, heralding a paradigm shift in AI’s role in healthcare.},
  keywords={Amino acids;Medical services;Feature extraction;Cancer;Training;Data privacy;Artificial intelligence;Stomach adenocarcinoma detection;genetic mutations;federated learning;amino acid sequences genomic data analysis},
  doi={10.1109/TCE.2024.3423786},
  ISSN={1558-4127},
  month={Aug},}@ARTICLE{11073781,
  author={Peng, Yubo and Jiang, Feibo and Dong, Li and Wang, Kezhi and Yang, Kun},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Personalized Federated Learning for GAI-Assisted Semantic Communications}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Semantic Communication (SC), which focuses on transmitting meaning rather than raw data, has emerged as the next-generation communication paradigm. However, the performance of SC is heavily influenced by network design and training methodologies. To address these challenges and enhance SC performance at the edge, we first introduce a Generative Artificial Intelligence (GAI)-assisted SC (GSC) model, which improves SC capabilities by optimizing the network architecture. Then, to achieve the efficient learning of GSC models deployed on each user, a Personalized Semantic Federated Learning (PSFL) framework is proposed. Specifically, in the local training phase, a Personalized Local Distillation (PLD) approach is employed, where each user selects a tailored GSC model as a mentor based on local resources. This mentor subsequently distills knowledge to a unified student model, ensuring compliance with the model isomorphism requirements of FL. In the global aggregation phase, an Adaptive Global Pruning (AGP) scheme is applied, dynamically pruning or expanding the aggregated global model based on real-time channel conditions. This mechanism effectively balances accuracy and communication energy efficiency. Finally, numerical results validate the feasibility and efficacy of the proposed PSFL framework, demonstrating its potential to enhance SC performance in edge environments significantly.},
  keywords={Semantics;Data models;Training;Feature extraction;Adaptation models;Artificial intelligence;Decoding;Accuracy;Computational modeling;Numerical models;Semantic communication;federated learning;generative artificial intelligence;network pruning},
  doi={10.1109/TCCN.2025.3586904},
  ISSN={2332-7731},
  month={},}@INPROCEEDINGS{10991070,
  author={Manjunatha and Srimani, Pendyala Shamili and Gupta, Manish and Suman, Bashetty and Mohammed, Mohammed Wael and Divetia, Kanan and Arun, V},
  booktitle={2025 International Conference on Cognitive Computing in Engineering, Communications, Sciences and Biomedical Health Informatics (IC3ECSBHI)}, 
  title={Advanced AI Techniques for Restoring Historical Documents and Photographs with Generative Adversarial and Diffusion Models for Cultural Heritage Preservation}, 
  year={2025},
  volume={},
  number={},
  pages={735-740},
  abstract={It is becoming the leading solution for bringing back the lost or damaged digital images, which are crucial for keeping history and culture alive. In this work, the state-of-art Generative Adversarial Networks (GANs), including CycleGAN and Pix2Pix, as well as diffusion models, have been explored for the first time in the area of historical image enhancement. The datasets are collected from the public domain; they are the Library of Congress and Old Picture repositories for training and testing the models. As illustrated by the framework under consideration, the fine details are reconstructed and noise is minimized when compared to other major approaches, thus the legibility and aesthetic quality of historical items are improved. The approach combines up-to-date machine learning algorithms with conventional image processing techniques thus maximizing the amount of the original content to be restored while at the same time maximizing the restoration quality. TensorFlow and PyTorch significantly help in the building of complex network structures and shorten the time for restoration. Thus, this work is relevant in this context as it discusses a professionally oriented scalable and robust realisation of digital archiving and restoration and opens up future ways to develop an integration of AI-based methodologies into the preservation of cultural heritage.},
  keywords={Training;Machine learning algorithms;Noise;Diffusion models;Generative adversarial networks;Libraries;Image restoration;Cultural differences;Image reconstruction;Testing;Image Restoration;Generative Adversarial Networks;Historical Documents;Diffusion Models;Cultural Heritage Preservation},
  doi={10.1109/IC3ECSBHI63591.2025.10991070},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10176925,
  author={Ni, Shifeng and Wang, Xin and Shang, Yifan and Zhang, Linji},
  booktitle={2023 4th International Conference on Electronic Communication and Artificial Intelligence (ICECAI)}, 
  title={Natural and Imperceptible Backdoor Attack against Deep Neural Networks}, 
  year={2023},
  volume={},
  number={},
  pages={377-381},
  abstract={Over the past few years, deep learning has demonstrated impressive performance across a wide range of applications. As the same time, researchers have become increasingly concerned with ensuring the security of deep learning models. Specifically, backdoor attacks have emerged as a significant threat to Deep Learning Model, whereby attackers control the predictions of model by implanting a concealed backdoor into the model. Under this scenario, the backdoored model will appear to make normal predictions on clean images, but will exhibit abnormal behaviors when the trigger is presented. Many existing backdoor attacks utilize a fixed pattern as the trigger, which can be easily detected by defense methods or even humans. Furthermore, existing backdoor attack methods are rarely targeted specifically at the Vision Transformer (ViT) model. Therefore, in this paper, we propose a novel natural backdoor attack method. We exploit natural phenomena to carry out a backdoor attack called the fog backdoor attack, which can utilize fog in the natural world as a trigger to be seamlessly integrated into clean images without being perceived by humans. The generated fog will diffuse over the image, creating a natural-looking effect. In contrast to the fixed and limited triggers produced by other methods, our triggers are more natural and imperceptible. Experimental results demonstrate the effectiveness and robustness of the proposed backdoor attack on different models. Specifically, the attack success rate of the proposed backdoor attack is 98.85% on VGG-16 model, 99.44% on ResNet-18 model and 9S.56% on ViT model, respectively. Furthermore, the proposed attack does not compromise the clean accuracy of the model.},
  keywords={Deep learning;Strips;Artificial neural networks;Predictive models;Transformers;Robustness;Behavioral sciences;Backdoor attack;Artificial intelligence security;Deep Neural Network;Vision Transformer},
  doi={10.1109/ICECAI58670.2023.10176925},
  ISSN={},
  month={May},}@ARTICLE{11124413,
  author={Li, Zihan and Song, Diping and Yang, Zefeng and Wang, Deming and Li, Fei and Zhang, Xiulan and Kinahan, Paul E. and Qiao, Yu},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={VisionUnite: a Vision-Language Foundation Model for Ophthalmology Enhanced with Clinical Knowledge}, 
  year={2025},
  volume={},
  number={},
  pages={1-14},
  abstract={The need for improved diagnostic methods in ophthalmology is acute, especially in the underdeveloped regions with limited access to specialists and advanced equipment. Therefore, we introduce VisionUnite, a novel vision-language foundation model for ophthalmology enhanced with clinical knowledge. VisionUnite has been pretrained on an extensive dataset comprising 1.24 million image-text pairs, and further refined using our proposed MMFundus dataset, which includes 296,379 high-quality fundus image-text pairs and 889,137 simulated doctor-patient dialogue instances. Our experiments indicate that VisionUnite outperforms existing generative foundation models such as GPT4V and Gemini Pro. It also demonstrates diagnostic capabilities comparable to junior ophthalmologists. VisionUnite performs well in various clinical scenarios including open-ended multidisease diagnosis, clinical explanation, and patient interaction, making it a highly versatile tool for initial ophthalmic disease screening. VisionUnite can also serve as an educational aid for junior ophthalmologists, accelerating their acquisition of knowledge regarding both common and underrepresented ophthalmic conditions. VisionUnite represents a significant advancement in ophthalmology, with broad implications for diagnostics, medical education, and understanding of disease mechanisms. The source code is at https://github.com/HUANGLIZI/VisionUnite.},
  keywords={Visualization;Training;Retina;Ophthalmology;Artificial intelligence;Supervised learning;Medical diagnostic imaging;Hemorrhaging;Transformers;Foundation models;Foundation Model;Generative AI;Multimodal},
  doi={10.1109/TPAMI.2025.3598734},
  ISSN={1939-3539},
  month={},}@ARTICLE{8667290,
  author={Pan, Zhaoqing and Yu, Weijie and Yi, Xiaokai and Khan, Asifullah and Yuan, Feng and Zheng, Yuhui},
  journal={IEEE Access}, 
  title={Recent Progress on Generative Adversarial Networks (GANs): A Survey}, 
  year={2019},
  volume={7},
  number={},
  pages={36322-36333},
  abstract={Generative adversarial network (GANs) is one of the most important research avenues in the field of artificial intelligence, and its outstanding data generation capacity has received wide attention. In this paper, we present the recent progress on GANs. First, the basic theory of GANs and the differences among different generative models in recent years were analyzed and summarized. Then, the derived models of GANs are classified and introduced one by one. Third, the training tricks and evaluation metrics were given. Fourth, the applications of GANs were introduced. Finally, the problem, we need to address, and future directions were discussed.},
  keywords={Gallium nitride;Generators;Generative adversarial networks;Training;Feature extraction;Data models;Unsupervised learning;Deep learning;machine learning;unsupervised learning;generative adversarial networks},
  doi={10.1109/ACCESS.2019.2905015},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10585811,
  author={AbdelRaouf, Hussien and Fouda, Mostafa M. and Ibrahem, Mohamed I.},
  booktitle={2024 IEEE 3rd International Conference on Computing and Machine Intelligence (ICMI)}, 
  title={Secure and Robust User Authentication Using Transfer Learning and CTGAN-based Keystroke Dynamics}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Due to keystroke dynamics's reliability and effi-ciency, it has been widely used in multi-factor authentication schemes by enterprises for robust user authentication, hence enhancing online service security. Therefore, in this paper, we propose a novel methodology designed not only to enhance user authentication but also to detect imposter users who are trying to get unauthorized access. Our methodology uses transfer learning and conditional tabular generative adversarial networks (CTGAN)-based keystroke dynamics, and consists of a four-step process; mitigating outliers that hinder the model's performance through utilizing quantile transformation (QT), employing data augmentation through CTGAN, converting CSV data into 3D images, and concatenating features from three accurate transfer learning models (VGG16, ResNet50, and DenseNet121) followed by dense layers to detecting im-poster users accurately and hence making precise decisions to enhance the user authentication process. We conducted extensive experiments to evaluate our methodology using the Carnegie Mellon University (CMU) keystroke dynamics benchmark dataset that contains real typing patterns, and the results demonstrate superior security performance and robustness using our methodology by achieving an accuracy of 99.99% and equal error rate (EER) of 1 %, thereby, outperforming the state-of-the-art.},
  keywords={Solid modeling;Accuracy;Three-dimensional displays;Keystroke dynamics;Transfer learning;Authentication;Generative adversarial networks;User authentication;keystroke dynamics;conditional tabular generative adversarial networks (CTGAN)},
  doi={10.1109/ICMI60790.2024.10585811},
  ISSN={},
  month={April},}@INPROCEEDINGS{10463241,
  author={Mehrez, Hadil and Chaiani, Mounira and Selouani, Sid Ahmed},
  booktitle={2024 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Using StarGANv2 Voice Conversion to Enhance the Quality of Dysarthric Speech}, 
  year={2024},
  volume={},
  number={},
  pages={738-744},
  abstract={In this paper, we propose to use StarGAN, a pow-erful Generative Adversarial Network (GAN), to improve the quality of dysarthric speech. Through extensive experiments, we demonstrate the effectiveness of StarGANv2-VC in converting dysarthric speech and significantly improving its intelligibility and naturalness. In addition, this research contributes to the field by conducting a comparative study between StarGANv2-VC and MaskCycleGAN-VC, another well-established GAN architecture, recently used in dysarthric speech conversion tasks. The results show that StarGANv2-VC performs the best, making it a promising solution for improving the speech quality of people suffering from dysarthria.},
  keywords={Vocoders;Speech enhancement;Linguistics;Generative adversarial networks;Task analysis;Artificial intelligence;Dysarthric speech;voice conversion;generative adversarial networks},
  doi={10.1109/ICAIIC60209.2024.10463241},
  ISSN={2831-6983},
  month={Feb},}@INPROCEEDINGS{9643179,
  author={Sun, Qian and Yang, Ziman and Li, Pei and Li, Mengmeng and Zhao, Ben},
  booktitle={2021 IEEE 33rd International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={SAdvGAN : Multiple Information Fusion For Adversary Generation}, 
  year={2021},
  volume={},
  number={},
  pages={1287-1294},
  abstract={There are many methods for generating adversarial samples. However, most methods do not achieve considerable performances both in the attack accuracy and image realism. In this paper, we generate adversarial samples based on the improved generative adversarial network SAdvGAN. For generator, multidimensional feature fusion is adopted to generate high-quality noises. For discriminator, self-attention is introduced to encourage model to focus on features which benefit the discrimination process. After training with Relativistic average GANs(RaGANs), it reduces the probability of real samples being identified as true. Compared with the current mainstream attack strategies, adversarial samples generated by SAdvGAN perform well in terms of perceived similarity. Concretely, the success rates of SAdvGAN in the semi-white box setting on MNIST and CIFAR10 is higher than that of AdvGAN by 9.68% and 6.1% respectively.},
  keywords={Training;Conferences;Generative adversarial networks;Generators;Artificial intelligence;adversarial samples;generative adversarial network;multi-dimensional feature fusion;self-attention mechanism;attack success rate},
  doi={10.1109/ICTAI52525.2021.00203},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{11027830,
  author={Zhao, Yijun and Li, Jiayu and Shu, Shiqi},
  booktitle={2024 17th International Symposium on Computational Intelligence and Design (ISCID)}, 
  title={DailyPhysics: Fostering Physics Concept Exploration in Children through a Tangible AI Storytelling Approach}, 
  year={2024},
  volume={},
  number={},
  pages={231-234},
  abstract={In early childhood science education, it is important to engage children in scientific experiences and the exploration of the world. In this study, we have designed a tangible game system called "DailyPhysics," which integrates artificial intelligence (AI) technology with gamified narrative design to enhance preschool children's understanding of physical concepts. This system enables children aged 4 to 7 to participate in learning, discovery, and storytelling, using scientific language flexibly to describe everyday phenomena through interaction with AI. By leveraging generative AI technologies, DailyPhysics creates an immersive learning environment that facilitates the natural integration of real-life experiences with physical concepts. Our user research, involving eight children, revealed that DailyPhysics effectively sparked their curiosity in exploring everyday scientific phenomena and significantly improved their ability to grasp and apply physical concepts.},
  keywords={Visualization;Generative AI;Large language models;Education;Games;User interfaces;Aging;Physics;Computational intelligence;Immersive learning;storytelling;TUI;human-AI interaction;children;physics concept;LLM},
  doi={10.1109/ISCID63852.2024.00059},
  ISSN={2473-3547},
  month={Dec},}@INPROCEEDINGS{11011689,
  author={R, Vasanthi and S, Vishali and K, Zaiba Thabassum},
  booktitle={2025 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI)}, 
  title={Integrated Django Web Interface for Facial Attributes Generation Utilizing Deep Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Imagine a system that takes in a line of text and generates realistic images of faces, the sort of challenge AI researchers have been trying to crack for some time now. In this paper, a new way of achieving this vision has been defined which was never been possible before due to the computational limitations, but that is now feasible due to the advent of deep learning technology. A model that blends Conditional Generative Adversarial Network (CGAN) with Convolutional Neural Network (CNN) is created which is capable of generating very realistic human faces only from textual descriptions. The CGAN takes the textual input and creates rough facial images, and the CNN fine-tune these images to have a more natural appearance while still being faithful to the original text. This model is trained on a dataset of paired facial images and textual descriptions. The model can consequently generate varied, high-quality images that closely match the input text as a result of being trained on this extensive dataset. This method was assessed through both human feedback and quantitative measures. These results show major improvement in generated text-to-face, paving the way for applications in graphics, virtual reality, entertainment and identifying criminal activities in cyberspace. But alongside this powerful new technology comes an ethical responsibility to protect oneself from the misuse of it for cybercrimes.},
  keywords={Deep learning;Solid modeling;Technological innovation;Computational modeling;Entertainment industry;Generative adversarial networks;Convolutional neural networks;Artificial intelligence;Facial features;Faces;Text-to-Face Generation;Conditional Generative Adversarial Network (CGAN);Convolutional Neural Network (CNN);Facial Attribute Classification},
  doi={10.1109/ICDSAAI65575.2025.11011689},
  ISSN={},
  month={March},}@INPROCEEDINGS{10870618,
  author={Padmavathi, A and Lahari, Bongu and Thanuja, Udatha and Dwaram, Harshitha},
  booktitle={2024 4th International Conference on Artificial Intelligence and Signal Processing (AISP)}, 
  title={Unlocking Insights: Generating Synthetic Data with GANs Across Diverse Datasets}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Generative adversarial networks (GANs) are a cutting-edge approach to generative modelling in deep learning. GAN's was proposed in 2014 by Ian Goodfellow. Since then, there has been significant growth in adversarial networks. New break-throughs and innovative approaches in generative adversarial networks can radically elevate and increase the quality of synthetically generated images by extracting patterns from the original datasets. Among the major advancements of GAN, image synthesis is the most prominent and extensively studied appli-cation. The concept of adversarial training, where two neural networks compete against each other, has introduced a novel paradigm for learning complex patterns in the Images. The paper emphasizes the vital role of GANs in strengthening and fine-tuning datasets, honing further research to create GANs capable of producing high quality synthetic samples with constrained practice of data.},
  keywords={Deep learning;Training;Ethics;Neural networks;Reinforcement learning;Signal processing;Generative adversarial networks;Mathematical models;Standards;Synthetic data;adversarial;Generative modelling;Deep learning;Breakthroughs;Extracting patterns;Adversarial training;Novel paradigm;Constrained practice of data},
  doi={10.1109/AISP61711.2024.10870618},
  ISSN={2640-5768},
  month={Oct},}@INPROCEEDINGS{10774908,
  author={Kshirsagar, Vanita G. and Bhosale, Digvijay G. and Suryawanshi, Shubhangi and Mahajan, Anita Sachin and Patil, Pramod and Barpute, Jyotsna Vilas and Ahire, Prashant G. and Patil, Rahul A.},
  booktitle={2024 8th International Conference on Computing, Communication, Control and Automation (ICCUBEA)}, 
  title={Generative AI Powered Forensic Device}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Crime is a dominant concern in contemporary society. It is crucial to prevent it and deliver justice promptly. Forensic science is critical for criminal investigations and maintaining law and order. The traditional tactics utilized in this field are frequently based on manual procedures, which are both time-consuming and prone to error, rendering them ineffectual in providing prompt and dependable justice. Utilizing automation and advanced technologies for forensic science and crime scene investigation is now essential. This paper suggests a portable gadget that utilizes Internet of Things (IOT), Machine Learning and Deep Learning to predict, gain understanding, and possibly recognize offenders. This gadget is designed to reconstruct fingerprints, detect weapons and recognize suspicious activities. It utilizes algorithms and technologies like autoencoders, GANs, SSD and YOLOv8. We talk about the benefits of merging these technologies into one easy-to-use device, which will offer data integration, instant data processing, and improved forensic analysis. The article offers information about automating important areas to improve investigative processes and enhance the criminal justice system's efficiency and effectiveness in the future.},
  keywords={Cloud computing;Automation;Forensics;Weapons;Prevention and mitigation;Fingerprint recognition;Internet of Things;Image reconstruction;Testing;Videos;Forensic Science;IOT;Deep Learning;Artificial Intelligence;Generative AI},
  doi={10.1109/ICCUBEA61740.2024.10774908},
  ISSN={2771-1358},
  month={Aug},}@INPROCEEDINGS{11134914,
  author={Autavia, Verisya and Cahya, Vinisa and Ferdianto},
  booktitle={2025 International Conference on Circuit, Systems and Communication (ICCSC)}, 
  title={Evaluation of Chat Generative AI Usage: What Influences Users' Intention to Continue Using It?}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={As the integration of artificial intelligence (AI) continues to expand into daily life, chat-based generative AI technology is becoming increasingly popular among users in Indonesia. However, various psychological and technological factors continue to influence its ongoing use. This study sought to evaluate the factors that influence the intention to continue using chat-based generative AI in Indonesia. Specifically, it explores the role of user interface (UI) and user experience (UX) elements, data security and privacy concerns, user loyalty, and user perceptions in shaping user behaviour towards these technologies. To examine these influences, this study used a quantitative approach using SmartPLS 4.0 software and Structural Equation Modeling (SEM) techniques with the partial least squares path modeling method. Data was collected through an online survey distributed through Google Forms from February to April 2025. Data collection using Google Forms, with the criteria that respondents who actively use chat generative AI and live in Jakarta, Bogor, Depok, Tangerang, and Bandung (cities in Indonesia), was collected using the purposive sampling method. A total of 440 valid responses were analyzed. In addition, secondary data was also collected from academic journals, articles, and relevant literature to support the findings.},
  keywords={Surveys;Data privacy;Generative AI;Urban areas;User interfaces;Mathematical models;User experience;Software;Internet;Usability;chat generative AI;user experience (UX);user perception;safety and privacy;loyalty;continuance intention},
  doi={10.1109/ICCSC66714.2025.11134914},
  ISSN={},
  month={June},}@ARTICLE{10815717,
  author={Luo, Ling},
  journal={Journal of Web Engineering}, 
  title={A Web Intelligent Hotel Management Framework Based on IoT and Generative AI}, 
  year={2024},
  volume={23},
  number={7},
  pages={885-912},
  abstract={The hotel industry has faced numerous opportunities and challenges due to the advent of the artificial intelligence (AI) and the data-driven era. To address this, a novel augmented online performance analysis model is proposed for hotel management operations. This model seamlessly integrates the Internet of Things (IoT), generative AI technologies, and web engineering, allowing for the collection and analysis of multifaceted operational data. Consequently, real-time insights pertaining to room reservations, occupancy rates, and revenue streams are derived, serving as the basis for data-driven optimization strategies. Moreover, by incorporating generative AI technologies, the proposed model demonstrates the ability to dynamically generate predictive models, simulate scenarios, synthesize actionable insights, and adapt to evolving trends. As a result, it offers adaptive solutions for complex hotel management scenarios that were previously beyond the reach of traditional methods.},
  keywords={Industries;Adaptation models;Analytical models;Ethics;Generative AI;Predictive models;Market research;Real-time systems;Data models;Artificial intelligence;Smart hotel management;IoT;generative AI;web engineering},
  doi={10.13052/jwe1540-9589.2371},
  ISSN={1544-5976},
  month={October},}@INPROCEEDINGS{9684603,
  author={Jaber, Aws Naser and Fritsch, Lothar},
  booktitle={2021 25th International Computer Science and Engineering Conference (ICSEC)}, 
  title={COVID-19 and Global Increases in Cybersecurity Attacks: Review of Possible Adverse Artificial Intelligence Attacks}, 
  year={2021},
  volume={},
  number={},
  pages={434-442},
  abstract={The World Health Organization's (WHO) coronavirus disease dashboard has recorded over 207 million confirmed infections and over 4 million deaths. There has been an increasing vulnerability in cybersecurity amongst businesses, gov- ernments and individuals worldwide because the COVID-19 pandemic has led to additional online activities. Accordingly, many people have turned to online work whilst the world is locked down. Thus, warnings have been issued by cybersecurity agencies that the number of cyber threat actors is increasing, and that they are improving in terms of stealing money, personal information and intellectual property. Opportunities for cybercrimes have increased, and COVID-19 is an effective lure. New methods for adverse artificial intelligence (AI)-empowered cyberattacks have been developed, or will be in the near future, using various weaponisations of AI under the COVID-19 umbrella. For this reason, this study reviewed and summarised how and when the most recent cyberattack trends can successfully exploit COVID-19 as a context for attack. Additionally, a summary of the state of knowledge of adverse AI is given, and its potential within the COVID-themed security threats, including defenses, is discussed.},
  keywords={COVID-19;Uniform resource locators;Pandemics;Phishing;Weapons;Malware;Servers;computer security;artificial intelligence;cyber-attack;COVID-19},
  doi={10.1109/ICSEC53205.2021.9684603},
  ISSN={},
  month={Nov},}@ARTICLE{10571791,
  author={Borges, João and Bastos, Felipe and Correa, Ilan and Batista, Pedro and Klautau, Aldebaro},
  journal={IEEE Internet of Things Journal}, 
  title={CAVIAR: Co-Simulation of 6G Communications, 3-D Scenarios, and AI for Digital Twins}, 
  year={2024},
  volume={11},
  number={19},
  pages={31287-31300},
  abstract={Digital twins are an important technology for advancing mobile communications, specially in use cases that require simultaneously simulating the wireless channel, 3-D scenes and machine learning (ML). Aiming at contributing towards a solution to this demand, this work describes a modular co-simulation methodology called CAVIAR, for implementing the virtual counterpart of a digital twin (DT) system. Here, CAVIAR is upgraded to support a message passing library and facilitate using different 6G-related simulators. The main contributions of this work are the detailed description of different CAVIAR architectures, the implementation of this methodology to assess a 6G use case of unmanned aerial vehicle (UAV)-based search and rescue (SAR), and the generation of benchmarking data about the computational resource usage. For executing the SAR co-simulation we adopt five open-source solutions: 1) the physical and link level network simulator Sionna; 2) the simulator for autonomous vehicles AirSim; 3) scikit-learn for training a decision tree for multiple input–multiple output (MIMO) beam selection; 4) Yolov8 for the detection of rescue targets; and 5) neural autonomic transport system (NATS) for message passing. Results for the implemented SAR use case suggest that the methodology can run in a single machine, with the main demanded resources being the CPU processing and the GPU memory.},
  keywords={Three-dimensional displays;Wireless communication;Software;Artificial intelligence;Ray tracing;Message passing;Internet of Things;6G;artificial intelligence (AI);co-simulation;DT;ray tracing (RT)},
  doi={10.1109/JIOT.2024.3418675},
  ISSN={2327-4662},
  month={Oct},}@INPROCEEDINGS{10537784,
  author={Mohan, G Bharathi and Kumar, R Prasanna and Teja, Bhumaraju Mani},
  booktitle={2023 Seventh International Conference on Image Information Processing (ICIIP)}, 
  title={Neural Currency Guard using Generative Adversarial Networks}, 
  year={2023},
  volume={},
  number={},
  pages={817-821},
  abstract={Counterfeit currency detection remains an ongoing challenge worldwide, as counterfeiters continuously enhance their techniques. This paper provides a comprehensive review of recent advancements in counterfeit currency detection systems, with a specific focus on innovative approaches using Generative Adversarial Networks (GANs). We implement GANs to generate realistic synthetic currency images for training robust counterfeit detectors. By thoroughly analyzing current research, we gain valuable perspectives into GAN-based methodologies for producing diversified fake currency data. Our study also examines the utilization of image processing, machine learning, and spectroscopic techniques in existing counterfeit recognition systems. Additionally, we detail a practical implementation of GANs for generating counterfeit currency images in Indian context, as well as evaluate its effectiveness. This research aims to deliver vital insights into cutting-edge counterfeit currency detection, presenting fresh perspectives on harnessing GANs. It also intends to aid future research by highlighting potential areas for improvement.},
  keywords={Training;Economics;Image recognition;Reviews;Machine learning;Information processing;Detectors;counterfeit currency;GANs;synthetic images;spectroscopic analysis;image processing;machine learning;Indian currency},
  doi={10.1109/ICIIP61524.2023.10537784},
  ISSN={2640-074X},
  month={Nov},}@INBOOK{10950516,
  author={Baker, Pam},
  booktitle={ChatGPT For Dummies}, 
  title={Introducing ChatGPT}, 
  year={2023},
  volume={},
  number={},
  pages={5-25},
  abstract={Summary <p>This chapter helps the readers to learn where and how to access ChatGPT. The number of app integrations seems to grow every day as existing software providers hurry to capitalize on ChatGPT's popularity. ChatGPT is just one example, albeit the most publicly well&#x2010;known, of a generative AI model. ChatGPT's capability to provide a unified answer is poised to affect our thinking and behavior to a far greater degree than ranking systems. The capability to produce a close semblance to human communication is primarily responsible for that skin&#x2010;prickling feeling commonly referred to as the heebie&#x2010;jeebies. ChatGPT can help diagnose illnesses and search for cures. Many people believe that generative AI such as ChatGPT and Bard will eventually replace search engines such as Bing and Google. ChatGPT was built on OpenAI's GPT&#x2010;3 family of large language models, fine&#x2010;tuned by humans and reinforcement learning, and trained to perform conversational tasks.</p>},
  keywords={Chatbots;Software;Search engines;Artificial intelligence;Oral communication;Generative AI;Training;Thumb;Shape;Pattern recognition},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394204649},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10950516},}@ARTICLE{10019593,
  author={Wu, Chen and Du, Bo and Zhang, Liangpei},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Fully Convolutional Change Detection Framework With Generative Adversarial Network for Unsupervised, Weakly Supervised and Regional Supervised Change Detection}, 
  year={2023},
  volume={45},
  number={8},
  pages={9774-9788},
  abstract={Deep learning for change detection is one of the current hot topics in the field of remote sensing. However, most end-to-end networks are proposed for supervised change detection, and unsupervised change detection models depend on traditional pre-detection methods. Therefore, we proposed a fully convolutional change detection framework with generative adversarial network, to unify unsupervised, weakly supervised, regional supervised, and fully supervised change detection tasks into one end-to-end framework. A basic Unet segmentor is used to obtain change detection map, an image-to-image generator is implemented to model the spectral and spatial variation between multi-temporal images, and a discriminator for changed and unchanged is proposed for modeling the semantic changes in weakly and regional supervised change detection task. The iterative optimization of segmentor and generator can build an end-to-end network for unsupervised change detection, the adversarial process between segmentor and discriminator can provide the solutions for weakly and regional supervised change detection, the segmentor itself can be trained for fully supervised task. The experiments indicate the effectiveness of the propsed framework in unsupervised, weakly supervised and regional supervised change detection. This article provides new theorical definitions for unsupervised, weakly supervised and regional supervised change detection tasks with the proposed framework, and shows great potentials in exploring end-to-end network for remote sensing change detection (https://github.com/Cwuwhu/FCD-GAN-pytorch).},
  keywords={Task analysis;Image segmentation;Generators;Remote sensing;Generative adversarial networks;Predictive models;Training;Change detection;fully covolutional network;generative adversarial network;remote sensing;weakly supervised segmentation},
  doi={10.1109/TPAMI.2023.3237896},
  ISSN={1939-3539},
  month={Aug},}@ARTICLE{9507288,
  author={Jahangir, Hamidreza and Gougheri, Saleh Sadeghi and Vatandoust, Behzad and Golkar, Mahsa A. and Golkar, Masoud Aliakbar and Ahmadian, Ali and Hajizadeh, Amin},
  journal={IEEE Transactions on Power Systems}, 
  title={A Novel Cross-Case Electric Vehicle Demand Modeling Based on 3D Convolutional Generative Adversarial Networks}, 
  year={2022},
  volume={37},
  number={2},
  pages={1173-1183},
  abstract={Electric Vehicle (EV) demand modeling constitutes the cornerstone of studies aiming to facilitate the integration of EVs into the power system. The different characteristics of the EV demand (departure time, arrival time, and electric demand), as well as the correlation between thereof, render EV demand modeling a complex task. The Majority of previous methods, which were developed based on the Monte Carlo simulation, are unable to observe and preserve the correlation between EV demand characteristics; because, in these methods, the EV demand characteristics are generated separately in an unsupervised manner. This study proposes a novel semi-supervised EV demand modeling approach by mapping the different EV demand characteristics into a three-dimensional (3D) space as a 3D image. To effectively realize the 3D EV demand modeling, we have employed Generative Adversarial Networks (GANs) with a 3D convolutional structure to develop EV-GANS network—a GANs structure tailored to the needs of EV demand modeling in environments hosting high demand diversity such as EV charging stations. Numerical results confirmed the effectiveness of the proposed EV-GANS in estimating the trend of the actual EV demand on the test day with a small error margin compared to the existing benchmark generation-based methods (Monte Carlo and Copula).},
  keywords={Three-dimensional displays;Artificial neural networks;Correlation;Feature extraction;Artificial intelligence;Task analysis;Solid modeling;Artificial intelligence;deep learning;electric vehicles;generative adversarial networks;energy market;smart charging},
  doi={10.1109/TPWRS.2021.3100994},
  ISSN={1558-0679},
  month={March},}@ARTICLE{10695049,
  author={Almuayqil, Saleh Naif and Fadel, Magdy M. and Hassan, Mohammed K. and Hagras, Esam A. A. and Said, Wael},
  journal={IEEE Access}, 
  title={Stego-Image Synthesis Employing Data-Driven Continuous Variable Representations of Cover Images}, 
  year={2024},
  volume={12},
  number={},
  pages={146749-146770},
  abstract={The security of stego-images is a crucial foundation for analyzing steganography algorithms. Recently, steganography has made significant strides in ongoing conflicts with steganalysis. In order to increase the security of stego-images, steganography must be able to evade detection using steganalysis methods. Secret information is typically hidden using traditional embedding-based steganography, which inevitably leaves traces of the modifications that can be found using more sophisticated machine-learning-based steganalysis techniques. Steganography without embedding (SWE) outperforms machine-learning-based steganalysis techniques because it does not require alteration of the data of the cover image. A novel image SWE method based on deep convolutional generative adversarial networks (GANs) is proposed to synthesize stego-images led by embedded text. The variational autoencoder (VAE) in the GAN model is utilized to synthesize the stego-image, based on interpolating the secret text in a continuous variable representation of the cover image. To further improve the framework’s performance and shorten processing times, the whale optimization algorithm (WOA) is used to identify the optimal VAE structure. When creating a stego-image, no embedding or modification procedures are required, and after training, a different convolutional neural network (CNN) known as the extractor can correctly extract the data from the image. The experimental results revealed that this approach has the advantages of evading detection using innovative deep learning (DL) steganalysis architecture and accurate information extraction.},
  keywords={Steganography;Distortion;Generative adversarial networks;Image synthesis;Generators;Computational modeling;Adaptation models;Training;Decoding;Convolutional neural networks;Convolutional neural network;data hiding;generative adversarial network;generative artificial intelligence;generative image synthesis;steganography;variational autoencoder},
  doi={10.1109/ACCESS.2024.3468886},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11048305,
  author={Sathiyaprasad, B. and L, Kaushik. and B, Shraven.},
  booktitle={2025 International Conference on Recent Advances in Electrical, Electronics, Ubiquitous Communication, and Computational Intelligence (RAEEUCCI)}, 
  title={Enhancing Spina Bifida Detection in Fetal Ultrasound Images using Generative Adversarial Networks}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Spina bifida is a congenital neurological condition caused by the incomplete closure of the spinal cord during fetal development, potentially leading to severe complications such as permanent paralysis if untreated. Early and accurate detection is critical for timely intervention, with ultrasonography serving as the gold standard for fetal monitoring. This research employs a Conditional Generative Adversarial Network (cGAN) to detect spina bifida by utilizing clinical features such as gestational age, maternal age, spinal lesion size, and head circumference. The cGAN architecture comprises a generator that synthesizes realistic feature sets conditioned on spina bifida presence and a discriminator that classifies the condition while distinguishing between real and synthetic data. Adversarial training, combined with careful normalization and preprocessing of the input data, ensures the generation of clinically relevant synthetic datasets that enhance diversity and robustness. This approach augments limited real-world data, facilitating robust classification and underscoring the potential of cGANs in advancing data-driven prenatal diagnostics and improving early spina bifida detection.},
  keywords={Training;Adaptation models;Accuracy;Data preprocessing;Generative adversarial networks;Feature extraction;Robustness;Generators;Lesions;Synthetic data;Spina bifida;Conditional Generative Adversarial Network (cGAN);prenatal diagnostics;synthetic data generation;adversarial training;clinical feature classification;gestational age;maternal age;spinal lesion size;prenatal data augmentation;early detection},
  doi={10.1109/RAEEUCCI63961.2025.11048305},
  ISSN={},
  month={April},}@INPROCEEDINGS{10845511,
  author={S, Sarika. P. and Paul, Arya and Kumar, Ajay and George, Anju},
  booktitle={2024 11th International Conference on Advances in Computing and Communications (ICACC)}, 
  title={AI Meets Cyber Defense: Enhancing Network Security with GAN-Driven NIDS}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The field of cybersecurity has witnessed a growth in the breadth and intricacy of cyber threats due to the advancement of communication technology, which calls for the implementation of strong network intrusion detection systems (NIDS). Regrettably, a wide range of potential hazards might put computer users at risk when using the Internet. Users stand to lose a great deal, including control over machines, private information, and potentially even identity theft. The ongoing problem of inconsistent and changing threat data persists despite notable improvements in NIDS models. As more and more research has realized the need for improved detection skills, artificial intelligence (AI) has become a viable answer. In order to meet the challenges presented by emerging cyber threats, this study presents a thorough investigation into the integration of AI, specifically generative adversarial networks (GANs), into NIDS. GANs are a machine learning breakthrough that provides a fresh method for creating new data instances that closely mimic real data. This skill is especially useful in the context of network intrusion detection systems (NIDS), where identifying anomalies necessitates a sophisticated comprehension of intricate and dynamic threat patterns. Our study expands on earlier research in the field that mostly concentrated on deep learning methods like autoencoders, convolutional neural networks (CNN), and long short-term neural networks (LSTM), as well as conventional machine learning models like decision trees (DT) and support vector machines (SVM). Although these methods have shown potential, there hasn’t been much of a practical use for them in actual NIDS systems. A promising approach to improving NIDS performance is provided by the suggested NIDS makes use of GANs, especially when it comes to anomaly detection. Through the creation of artificial data instances that closely resemble real-world threats, GANs can enhance the resilience and flexibility of NIDS in dynamic threat settings.},
  keywords={Support vector machines;Identity theft;Neural networks;Network intrusion detection;Network security;Hazards;Internet;Convolutional neural networks;Long short term memory;Resilience;Network Intrusion Detection Systems (NIDS);Cybersecurity;Artificial Intelligence (AI);Generative Adversarial Networks (GANs);Anomaly Detection},
  doi={10.1109/ICACC63692.2024.10845511},
  ISSN={2766-2829},
  month={Nov},}@INBOOK{11164743,
  author={Abinaya, M. and Vadivu, G. and Balasubramaniam, S. and Kadry, Seifedine},
  booktitle={Generative AI and LLMs: Natural Language Processing and Generative Adversarial Networks}, 
  title={4 Importance of Prompt Engineering in Generative AI Models}, 
  year={2024},
  volume={},
  number={},
  pages={69-92},
  abstract={For the model effectiveness in generative artificial intelligence, prompt engineering and design play a very important role. For the influence of the model and the behavior prompt engineering the subdomain of machine learning and natural language processing (NLP) plays an important role in determining the model’s output. Robustness, performance interpretability importance, and the way to improve are discussed in this chapter. The first section of the book deals with the techniques, principles, and ideas discussed. Relevance, inventiveness, and coherence are the inputs essentially needed for the function. To meet the tasks and the goals the relationship between the prompt design and the capabilities and the complex relationship are discussed. The chapter also specifies various techniques for the prompt creation and restriction of linguistics methods using templates and specific domain advice. How the model interoperability and the mitigation of bias in prompt engineering are examined is shown in this chapter. Transparency and recognizing the bias in the AI system are also covered in this chapter. In the field of text generation, image synthesis, and conversational agents’ real time and case studies are discussed in this chapter. The challenges and future directions of prompt engineering are discussed in this chapter.},
  keywords={},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9783111425511},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11164743},}@INPROCEEDINGS{10569387,
  author={Krašna, Marjan and Gartner, Smiljana},
  booktitle={2024 47th MIPRO ICT and Electronics Convention (MIPRO)}, 
  title={The Effects of AI Services to the Educational Processes – Survey Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={496-501},
  abstract={The initial hype of the public available generative AI with the Chat GPT is over. The initial emotional perturbation between teachers have calmed and the intellectual reasoning overcome the fear of unknown. In 2023 our survey shows that the teachers correctly recognised the AI systems in the background of their online activities. Our research (survey analysis) has shown that 81% of teachers use Chat GPT and that 66% of the teachers are aware of the AI system behind Office 365. The most problematic feature for the teacher is the recognition of authorship of the text where more than 70% have doubts. Despite most of the teachers feels discomfort about AI the reality is not dark. The teachers know that students do not know to how to evaluate the data. Therefore, AI generated results of the students’ assignments could be easily identified if the students do not understand the text provided by the AI. From the data and the educated reasoning, we can conclude that education processes would need to change in the near future but learning would remain the same. We would need to address the ethical topics of using AI in the education and educate students what is right and what is wrong.},
  keywords={Surveys;Training;Ethics;Text recognition;Perturbation methods;Education;Cognition;education;artificial intelligence;influence;ethics;critical thinking},
  doi={10.1109/MIPRO60963.2024.10569387},
  ISSN={2623-8764},
  month={May},}@INPROCEEDINGS{11147398,
  author={Zolezzi, Daniele and Martini, Luca and Vercelli, Gianni Viardo},
  booktitle={2025 IEEE Integrated STEM Education Conference (ISEC)}, 
  title={Facilitating Learning Through Role Inversion: The Flipped Role Methodology with AI Integration}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper introduces the "Flipped Role" methodology applied in the undergraduate course "Digital Communication", part of the degree program in "Media, Communication, and Society". This approach redefines traditional roles in education, assigning students the responsibility of acting as educators. They develop teaching materials, quizzes, and lessons, leveraging Generative Artificial Intelligence (GenAI) as a supportive and interactive tool. The instructor’s role shifts to that of a facilitator, guiding students through a structured, phase-based process and integrating AI tools to enhance the collaborative and engaging learning experience. The primary objective of this methodology is to explore how role reversal and active engagement with AI can support deeper comprehension, improved knowledge retention, and greater awareness of GenAI’s appropriate and responsible use. By placing students at the center of content creation and decision-making, the "Flipped Role" aims to foster a collaborative and reflective educational environment while demonstrating the practical potential of AI-enhanced active learning.},
  keywords={Generative AI;Education;Active learning;Decision making;Collaboration;Learning (artificial intelligence);Media;Digital communication;Active Learning Strategies;Flipped Role Methodology;Generative Artificial Intelligence},
  doi={10.1109/ISEC64801.2025.11147398},
  ISSN={2473-7623},
  month={March},}@INPROCEEDINGS{10219665,
  author={Zhao, Lanxin and Li, Dengshi and Xiao, Jing and Zhu, Chenyi},
  booktitle={2023 IEEE International Conference on Multimedia and Expo (ICME)}, 
  title={Noise adaptive speech intelligibility enhancement based on improved StarGAN*}, 
  year={2023},
  volume={},
  number={},
  pages={1313-1318},
  abstract={When people communicate in noisy environments with the phone, it is difficult for listeners to obtain information even if the device outputs clear speech. Previous studies have focused on speech intelligibility enhancement (IENH) via normal speech and different levels of Lombard speech conversion. However, these methods often lead to speech distortion and impair the overall speech quality. We propose an IENH framework based on an improved Star Generative Adversarial Network (StarGAN) named D2StarGAN. It has two main advantages: 1) Inspired by the dual-discriminator idea, we add a speech metric discriminator based on StarGAN to optimize multiple intelligibility-related metrics simultaneously; 2) The framework can adapt to different far-and-near-end noise levels and different noise types. Experimental results using both objective measurements and subjective listening tests indicate that the proposed method outperforms the baseline method. It adaptively converts all the mobile communication scenarios with far-and-near-end noise, thus making IENH more widely used in practice.},
  keywords={Stars;Speech enhancement;Telephone sets;Mobile communication;Generative adversarial networks;Distortion;Noise measurement;Intelligibility Enhancement(IENH);Environmental Noise;Lombard Effect;StarGAN;Speech Conversion},
  doi={10.1109/ICME55011.2023.00228},
  ISSN={1945-788X},
  month={July},}@ARTICLE{11151234,
  author={Xie, Fan and Zeng, Dan and Shen, Qiaomu and Tang, Bo},
  journal={Chinese Journal of Electronics}, 
  title={A Comprehensive Survey on Text-to-Video Generation}, 
  year={2025},
  volume={34},
  number={4},
  pages={1009-1036},
  abstract={Since the release of Sora, the text-to-video (T2V) generation has brought profound changes to artificial intelligence-generated content. T2V generation aims to generate high-quality videos based on a given text description, which is challenging due to the lack of large-scale, high-quality text-video pairs for training and the complexity of modeling high-dimensional video data. Although there have been some valuable and impressive surveys on T2V generation, these surveys introduce approaches in a relatively isolated way, lack the development of evaluation metrics, and lack the latest advances in T2V generation since 2023. Due to the rapid expansion of the field of T2V generation, a comprehensive review of the relevant studies is both necessary and challenging. This survey attempts to connect and systematize existing research in a comprehensive way. Unlike previous surveys, this survey reviews nearly one hundred representative T2V generation approaches and includes the latest method published on July 2024 from the perspectives of model, data, evaluation metrics, and available open source. It may help readers better understand the current research status and ideas and have a quick start with accessible open-source models. Finally, the future challenges and method trends of T2V generation are thoroughly discussed.},
  keywords={Surveys;Training;Performance evaluation;Reviews;Generative AI;Market research;Transformers;Data models;Complexity theory;Text to video;Survey;Text-to-video generation;Generative artificial intelligence;Sora model;Artificial intelligence generated content},
  doi={10.23919/cje.2024.00.151},
  ISSN={2075-5597},
  month={July},}@ARTICLE{10036448,
  author={Hou, Hao and Xu, Jun and Hou, Yingkun and Hu, Xiaotao and Wei, Benzheng and Shen, Dinggang},
  journal={IEEE Transactions on Image Processing}, 
  title={Semi-Cycled Generative Adversarial Networks for Real-World Face Super-Resolution}, 
  year={2023},
  volume={32},
  number={},
  pages={1184-1199},
  abstract={Real-world face super-resolution (SR) is a highly ill-posed image restoration task. The fully-cycled Cycle-GAN architecture is widely employed to achieve promising performance on face SR, but is prone to produce artifacts upon challenging cases in real-world scenarios, since joint participation in the same degradation branch will impact final performance due to huge domain gap between real-world and synthetic LR ones obtained by generators. To better exploit the powerful generative capability of GAN for real-world face SR, in this paper, we establish two independent degradation branches in the forward and backward cycle-consistent reconstruction processes, respectively, while the two processes share the same restoration branch. Our Semi-Cycled Generative Adversarial Networks (SCGAN) is able to alleviate the adverse effects of the domain gap between the real-world LR face images and the synthetic LR ones, and to achieve accurate and robust face SR performance by the shared restoration branch regularized by both the forward and backward cycle-consistent learning processes. Experiments on two synthetic and two real-world datasets demonstrate that, our SCGAN outperforms the state-of-the-art methods on recovering the face structures/details and quantitative metrics for real-world face SR. The code will be publicly released at https://github.com/HaoHou-98/SCGAN.},
  keywords={Faces;Face recognition;Image restoration;Degradation;Generative adversarial networks;Superresolution;Task analysis;Real-world face super-resolution;semi-cycled architecture;cycle-consistent generative adversarial networks},
  doi={10.1109/TIP.2023.3240845},
  ISSN={1941-0042},
  month={},}@INPROCEEDINGS{10696569,
  author={Tan, Yue Hern and Chua, Hui Na and Low, Yeh-Ching and Jasser, Muhammed Basheer},
  booktitle={2024 IEEE 14th International Conference on Control System, Computing and Engineering (ICCSCE)}, 
  title={Current Landscape of Generative AI: Models, Applications, Regulations and Challenges}, 
  year={2024},
  volume={},
  number={},
  pages={168-173},
  abstract={Generative AI models have witnessed remarkable advancements, blurring the lines between human creativity and machine generation. This paper concisely reviews the current Generative AI landscape, exploring its diverse applications across various domains. We delve into the capabilities of these models, from creating images and music to generating creative text formats. Furthermore, the paper examines the real-world applications of Generative AI, highlighting its potential to revolutionize industries like design, marketing, education, and scientific discovery. However, while existing research extensively explores specific aspects of Generative AI, an analysis of the technology’s landscape, encompassing its capabilities, applications in content creation, and regulatory considerations, remains limited. This paper strives to bridge this gap by delivering a more holistic landscape of GenAI. Our analysis of the GenAI landscape pinpointed user behavior research and responsible development practices as key to user-centric AI creation. Through this study, we aim to stimulate discussion and collaboration between researchers, developers, and policymakers to ensure this powerful technology is harnessed responsibly for the benefit of industry and society.},
  keywords={Industries;Privacy;Generative AI;Reviews;Law;Explainable AI;Prevention and mitigation;Education;Regulation;Creativity;Generative AI;Deep Learning;Applications;Regulations;Ethics;Content Creation},
  doi={10.1109/ICCSCE61582.2024.10696569},
  ISSN={},
  month={Aug},}@ARTICLE{10897585,
  author={Du, Chenghu and Yu, Feng and Jiang, Minghua and Hua, Ailing and Zhao, Yaxin and Wei, Xiong and Peng, Tao and Hu, Xinrong},
  journal={Computational Visual Media}, 
  title={High fidelity virtual try-on network via semantic adaptation and distributed componentization}, 
  year={2022},
  volume={8},
  number={4},
  pages={649-663},
  abstract={Image-based virtual try-on systems have significant commercial value in online garment shopping. However, prior methods fail to appropriately handle details, so are defective in maintaining the original appearance of organizational items including arms, the neck, and in-shop garments. We propose a novel high fidelity virtual try-on network to generate realistic results. Specifically, a distributed pipeline is used for simultaneous generation of organizational items. First, the in-shop garment is warped using thin plate splines (TPS) to give a coarse shape reference, and then a corresponding target semantic map is generated, which can adaptively respond to the distribution of different items triggered by different garments. Second, organizational items are componentized separately using our novel semantic map-based image adjustment network (SMIAN) to avoid interference between body parts. Finally, all components are integrated to generate the overall result by SMIAN. A priori dual-modal information is incorporated in the tail layers of SMIAN to improve the convergence rate of the network. Experiments demonstrate that the proposed method can retain better details of condition information than current methods. Our method achieves convincing quantitative and qualitative results on existing benchmark datasets.},
  keywords={Clothing;Semantics;Shape;Solid modeling;Three-dimensional displays;Neck;Image reconstruction;Generative adversarial networks;Computational modeling;Adaptation models;virtual try-on;conditional image synthesis;human parsing;thin plate spline;semantic adaptation},
  doi={10.1007/s41095-021-0264-2},
  ISSN={2096-0662},
  month={Dec},}@INPROCEEDINGS{11050586,
  author={Goh, Adison and Chee, Benjamin and Vagnoli, Matteo and Baldassarre, Luca and Narayan, Akshay},
  booktitle={2025 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Scaling Responsible Generative AI: Automating Red Teaming of LLM Applications}, 
  year={2025},
  volume={},
  number={},
  pages={902-905},
  abstract={Large Language Models (LLMs) present both significant business potential and substantial risks. This paper addresses the critical need for robust and scalable red teaming processes to identify and mitigate risks before LLM solution deployment. First, we define a comprehensive set of 48 LLM-associated risks reflecting emerging AI threats. Additionally, we introduce an automated adversarial prompt generation pipeline involving five types of generators that cover diverse AI risks at varying complexity levels. Finally, we implement a LLM-as-a-judge evaluation system to streamline testing. When applied to red-team two finance-based LLM applications, our approach achieved perfect recall in identifying failed outputs while reducing manual evaluation by over 90%. The developed features halved the time required for red teaming exercises, enhancing scalability and thoroughness while maintaining effectiveness. This work enhances LLM safety, accelerates deployment, and adds business value through improved risk management and responsible AI use.},
  keywords={Generative AI;Scalability;Large language models;Pipelines;Manuals;Safety;Reliability;Testing;Business;Risk mitigation;Large Language Models;Generative AI;Red Teaming;Responsible AI;AI Safety;Adversarial testing},
  doi={10.1109/CAI64502.2025.00159},
  ISSN={},
  month={May},}@INPROCEEDINGS{10394432,
  author={Venkataramanan, Revathy and Roy, Kaushik and Raj, Kanak and Prasad, Renjith and Zi, Yuxin and Narayanan, Vignesh and Sheth, Amit},
  booktitle={2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={Cook-Gen: Robust Generative Modeling of Cooking Actions from Recipes}, 
  year={2023},
  volume={},
  number={},
  pages={981-986},
  abstract={As people become more aware of their food choices, food computation models have become increasingly popular in assisting people in maintaining healthy eating habits. For example, food recommendation systems analyze recipe instructions to assess nutritional contents and provide recipe recommendations. The recent and remarkable successes of generative AI methods, such as auto-regressive Large Language Models, can enable robust methods for a more comprehensive understanding of recipes for healthy food recommendations beyond surface-level nutrition content assessments. In this study, we investigate the use of generative AI methods to extend current food computation models, primarily involving the analysis of nutrition and ingredients, to also incorporate cooking actions (e.g., add salt, fry the meat, boil the vegetables, etc.), Cooking actions are notoriously hard to model using statistical learning methods due to irregular data patterns - significantly varying natural language descriptions for the same action (e.g., marinate the meat vs. marinate the meat and leave overnight) and infrequently occurring patterns (e.g., add salt occurs far more frequently than marinating the meat). The prototypical approach to handling irregular data patterns is to increase the volume of data that the model ingests by orders of magnitude. Unfortunately, in the cooking domain, these problems are further compounded with larger data volumes presenting a unique challenge that is not easily handled by simply scaling up. In this work, we propose novel aggregation-based generative AI methods, Cook-Gen, that reliably generate cooking actions from recipes, despite difficulties with irregular data patterns, while also outperforming Large Language Models and other strong baselines.},
  keywords={Analytical models;Solid modeling;Generative AI;Computational modeling;Statistical learning;Data models;Recommender systems},
  doi={10.1109/SMC53992.2023.10394432},
  ISSN={2577-1655},
  month={Oct},}@INPROCEEDINGS{10556082,
  author={Xia, Boming and Lu, Qinghua and Zhu, Liming and Lee, Sung Une and Liu, Yue and Xing, Zhenchang},
  booktitle={2024 IEEE/ACM 3rd International Conference on AI Engineering – Software Engineering for AI (CAIN)}, 
  title={Towards a Responsible AI Metrics Catalogue: A Collection of Metrics for AI Accountability}, 
  year={2024},
  volume={},
  number={},
  pages={100-111},
  abstract={Artificial Intelligence (AI), particularly through the advent of large-scale generative AI (GenAI) models such as Large Language Models (LLMs), has become a transformative element in contemporary technology. While these models have unlocked new possibilities, they simultaneously present significant challenges, such as concerns over data privacy and the propensity to generate misleading or fabricated content. Current frameworks for Responsible AI (RAI) often fall short in providing the granular guidance necessary for tangible application, especially for Accountability—a principle that is pivotal for ensuring transparent and auditable decision-making, bolstering public trust, and meeting increasing regulatory expectations. This study bridges the Accountability gap by introducing our effort towards a comprehensive metrics catalogue, formulated through a systematic multivocal literature review (MLR) that integrates findings from both academic and grey literature. Our catalogue delineates process metrics that underpin procedural integrity, resource metrics that provide necessary tools and frameworks, and product metrics that reflect the outputs of AI systems. This tripartite framework is designed to operationalize Accountability in AI, with a special emphasis on addressing the intricacies of GenAI.CCS CONCEPTS•Software and its engineering;},
  keywords={Measurement;Ethics;Data privacy;Systematics;Law;Generative AI;Decision making;Responsible AI;Accountable AI;Risk assessment;Generative AI},
  doi={},
  ISSN={},
  month={April},}@ARTICLE{10141633,
  author={Ye, Fei and Bors, Adrian G.},
  journal={IEEE Transactions on Cybernetics}, 
  title={Lifelong Dual Generative Adversarial Nets Learning in Tandem}, 
  year={2024},
  volume={54},
  number={3},
  pages={1353-1365},
  abstract={Continually capturing novel concepts without forgetting is one of the most critical functions sought for in artificial intelligence systems. However, even the most advanced deep learning networks are prone to quickly forgetting previously learned knowledge after training with new data. The proposed lifelong dual generative adversarial networks (LD-GANs) consist of two generative adversarial networks (GANs), namely, a Teacher and an Assistant teaching each other in tandem while successively learning a series of tasks. A single discriminator is used to decide the realism of generated images by the dual GANs. A new training algorithm, called the lifelong self knowledge distillation (LSKD) is proposed for training the LD-GAN while learning each new task during lifelong learning (LLL). LSKD enables the transfer of knowledge from one more knowledgeable player to the other jointly with learning the information from a newly given dataset, within an adversarial playing game setting. In contrast to other LLL models, LD-GANs are memory efficient and does not require freezing any parameters after learning each given task. Furthermore, we extend the LD-GANs to being the Teacher module in a Teacher–Student network for assimilating data representations across several domains during LLL. Experimental results indicate a better performance for the proposed framework in unsupervised lifelong representation learning when compared to other methods.},
  keywords={Task analysis;Training;Generators;Generative adversarial networks;Data models;Probabilistic logic;Unsupervised learning;Generative adversarial network (GAN);lifelong learning (LLL);representation learning;Teacher--Student network},
  doi={10.1109/TCYB.2023.3271388},
  ISSN={2168-2275},
  month={March},}@INPROCEEDINGS{9540115,
  author={Yi, Da and Guo, Chao and Bai, Tianxiang},
  booktitle={2021 IEEE 1st International Conference on Digital Twins and Parallel Intelligence (DTPI)}, 
  title={Exploring Painting Synthesis with Diffusion Models}, 
  year={2021},
  volume={},
  number={},
  pages={332-335},
  abstract={As a significant composition of art, fine art painting is becoming a research hotspot in machine learning community. With unique aesthetic value, paintings have quite different representations from natural images, making them irreplaceable. Meanwhile, the lack of training data is common in painting-related machine learning tasks. Therefore, the synthesis of fine art painting is meaningful and challenging work. There are two main types of generative models for image synthesis: generative adversarial networks (GANs) and likelihood-based models. GAN-based models can obtain high-quality samples but usually sacrifice diversity and training stability. Diffusion models are a class of likelihood-based models and have recently been shown to achieve state-of-the-art quality on the image synthesis tasks. In this paper, we explore generating fine art paintings by using diffusion models. We carried out the experiments on the partial impression paintings from the Wikiart dataset. The results demonstrate that the diffusion model can generate high-quality samples, and it is easy to train to cover more target distribution than the GAN-based methods.},
  keywords={Training;Art;Image synthesis;Digital twin;Training data;Machine learning;Generative adversarial networks;painting synthesis;image generation;diffusion models},
  doi={10.1109/DTPI52967.2021.9540115},
  ISSN={},
  month={July},}@INPROCEEDINGS{9379855,
  author={Wang, Xueshu and Jing, Xiaojun and Huang, Hai and Cui, Yuanhao and Kadoch, Michel and Cheriet, Mohamed},
  booktitle={2020 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)}, 
  title={Artifacts Reduction GAN For Enhancing Quality Of Compressed Panoramic Video}, 
  year={2020},
  volume={},
  number={},
  pages={1-5},
  abstract={Panoramic video has the characteristics of high resolution, massive information and high sense of immersion, bringing unprecedented visual sensory enjoyment to us. However, considering the limited capacity of current cellular network, videos transmitted to users are often encoded, e.g. by High Efficiency Video Coding (HEVC), resulting in block artifact problems that significantly affects the visual quality. Thus, it is necessary to enhance the quality of compressed panoramic videos. Inspired by the convolutional networks (CNN) and generative adversarial networks (GAN), the paper proposes a deep GAN model -Artifacts Reduction GAN (ARGAN) which is able to enhance the quality of compressed panoramic videos. ARGAN has the ability of reducing artifacts caused by HEVC. Meanwhile, it can increase the visual realistic of the enhanced videos. We tested the performance of our model under PSNR, SSIM and Perception Index. Qualitative results are also provided to display the visual effects of ARGAN. Experimental results show that our method is superior to other quality enhancement methods in both qualitative and quantitative aspects.},
  keywords={Media;Generative adversarial networks;Visual effects;Encoding;Multimedia communication;Indexes;High efficiency video coding;artificial intelligence in media processing;generative adversarial network;video coding and processing;video quality enhancement},
  doi={10.1109/BMSB49480.2020.9379855},
  ISSN={2155-5052},
  month={Oct},}@INPROCEEDINGS{10775200,
  author={Lokhande, Sharayu and Maity, Ankush and Lenka, Sourabh Kumar and Pious, Roshan and Choudhary, Vishal and Pawar, Shilpa},
  booktitle={2024 8th International Conference on Computing, Communication, Control and Automation (ICCUBEA)}, 
  title={Frame Acceleration and Super Resolution for video Enhancement Using GAN}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Low-resolution (LR) videos are common in various applications, including surveillance and video conferencing, primarily due to bandwidth constraints or older recording technologies. This research introduces a novel approach for enhancing the quality of LR videos by leveraging Generative Adversarial Networks (GANs) equipped with MeanShift loss, perceptual loss, Total Variation (TV) Loss, and a modified VGG19 architecture. By processing each frame of an LR video through our model, we achieve significant improvements in visual quality, detail sharpness, and temporal consistency, resulting in high-resolution (HR) videos that are both visually pleasing and realistic. The conventional approach to video enhancement, particularly when employing deep learning models like GANs, involves processing high volumes of data, which can be computationally intensive and time-consuming. This challenge is compounded in real-time applications or environments lacking powerful graphical processing units (GPUs). Our research proposes a novel solution by extracting frames from low-resolution (LR) videos, enhancing each frame individually, and then recombining them into a high-resolution (HR) video. This method offers a significant reduction in computational requirements, making high-quality video enhancement accessible on less capable hardware and suitable for real-time processing.},
  keywords={Deep learning;Visualization;TV;Computational modeling;Process control;Computer architecture;Generative adversarial networks;Real-time systems;Videos;Videoconferences;Generative Adversarial Networks;artificial intelligence;frame rate;super-resolution;loss functions},
  doi={10.1109/ICCUBEA61740.2024.10775200},
  ISSN={2771-1358},
  month={Aug},}@INPROCEEDINGS{11087975,
  author={Anusha, Sigirisetty and Harini, Rayala and Nikita, Turumella and Priyanka, Vuddagiri Naga and Neethu Priya, Gudisa and Babu, Polinati Vinod},
  booktitle={2025 Seventh International Conference on Computational Intelligence andCommunication Technologies (CCICT)}, 
  title={VISOGEN: AI and APIs Unleashed for Smarter Video Generation}, 
  year={2025},
  volume={},
  number={},
  pages={467-473},
  abstract={The increasing demand for multimedia content in education, media, and information dissemination has created a need for efficient and accessible video production tools. This research presents VisoGen, an AI-driven system designed to automate the video content creation process. A system based on artificial intelligence produces informative videos from one input: a topic name. Upon receiving the topic, the system uses Natural Language Processing (NLP) models to automatically retrieve and summarize key information. This generated text is then converted into speech using Text-to-Speech (TTS) technology. Simultaneously, a visual representation of the text is created in the form of subtitles, which are synchronized with the audio for enhanced accessibility. The system then compiles the audio and visual components into a coherent video output. By automating research, content generation, voiceover, and video editing, the proposed system streamlines content creation, making it an efficient and valuable tool for educational, informational, and media production applications. The system significantly reduces the time and effort typically required for manual video creation, offering a seamless solution for users to generate high-quality, multimodal content tailored to their needs. This approach can be particularly beneficial in various sectors such as online learning, media, marketing, and content creation, enhancing both productivity and accessibility.},
  keywords={Productivity;Visualization;Multimedia systems;Manuals;Streaming media;Media;Natural language processing;Text to speech;Synchronization;Creativity;AI-driven video Creation;Natural Language Processing (NLP);Text-to-Speech (TTS);Automated Content Generation;Edge AI;Generative AI;Multimedia Processing},
  doi={10.1109/CCICT65753.2025.00077},
  ISSN={},
  month={April},}@INPROCEEDINGS{10975343,
  author={Naito, Takeshi and Nishijima, Shota and Nishikawa, Yuichiro and Hirano, Akira},
  booktitle={2024 IEEE Opto-Electronics and Communications Conference (OECC)}, 
  title={GAN-supported Data Augmentation in Real-time Optical Filter Shift Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={We demonstrate successful reproduction of digital coherent constellation data by using Generative Adversarial Network (GAN) for real-time optical filter shift detection for the first time. Based on the actual constellation data, we generated clone data by using GAN. With the help of the data augmentation, we have achieved enhanced sensitivity and reduced the amount of data required for machine learning in real-time optical filter shift detection for sufficient accuracy by 68 %.},
  keywords={Optical filters;Sensitivity;Machine learning;Optical fiber networks;Generative adversarial networks;Data augmentation;Real-time systems;Large scale integration;Optical sensors;Monitoring;machine learning;digital coherent;Whitebox;optical performance monitoring;filter shift detection;artificial intelligence;generative adversarial network},
  doi={10.1109/OECC54135.2024.10975343},
  ISSN={2166-8892},
  month={June},}@INPROCEEDINGS{10822347,
  author={Chakrabarty, Subhajit and Sarda, Devesh},
  booktitle={2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Synthetic Generation of Intermediate MR Images of Lumbar Spine Stenosis for Segmentation}, 
  year={2024},
  volume={},
  number={},
  pages={6356-6361},
  abstract={Lumbar spinal stenosis is a narrowing or constriction in the lumbar spine. Magnetic Resonance Imaging (MRI) is preferred for its diagnosis. Limited research has been conducted with the intent of making synthetic and pseudo in-painting datasets. The objective of this study was to develop a model to create a slice of MR image in the subsequent spinal disc, given an MR image slice from previous disc. To the best of our knowledge, this study is the first to explore the effectiveness of creating pseudo in-painting in the datasets for Lumbar Spine Stenosis. We selected a publicly available dataset, named Lumbar Spine MR images Dataset, for reproducibility. We used 1,545 composite T1 and T2 MR images (combined) in the axial view. The combined images were of 515 patients, each having the lower three levels (L3 to L5) of the lumbar spine. Broadly, our method is Generative Adversarial Network that we modified for our task. Our accuracy metric was the DICE Score. The accuracy was between 88.66 and 90.85%. We claim that our work is significant, as it establishes the ability of GAN to perform in-painting based on a slice for a disc, which indicates possibilities of future research on in-painting of larger stack of MR images and expansive synthetic dataset generation.},
  keywords={Image segmentation;Accuracy;Magnetic resonance imaging;Spine;Generative adversarial networks;Reproducibility of results;Bioinformatics;Synthetic data;Biomedical imaging;Generative Adversarial Network (GAN);Artificial Intelligence (AI);Machine Learning (ML);In-Painting;Lumbar Spine},
  doi={10.1109/BIBM62325.2024.10822347},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{9131717,
  author={Whyte, Christopher},
  booktitle={2020 12th International Conference on Cyber Conflict (CyCon)}, 
  title={Problems of Poison: New Paradigms and "Agreed" Competition in the Era of AI-Enabled Cyber Operations}, 
  year={2020},
  volume={1300},
  number={},
  pages={215-232},
  abstract={Few developments seem as poised to alter the characteristics of security in the digital age as the advent of artificial intelligence (AI) technologies. For national defense establishments, the emergence of AI techniques is particularly worrisome, not least because prototype applications already exist. Cyber attacks augmented by AI portend the tailored manipulation of human vectors within the attack surface of important societal systems at great scale, as well as opportunities for calamity resulting from the secondment of technical skill from the hacker to the algorithm. Arguably most important, however, is the fact that AI-enabled cyber campaigns contain great potential for operational obfuscation and strategic misdirection. At the operational level, techniques for piggybacking onto routine activities and for adaptive evasion of security protocols add uncertainty, complicating the defensive mission particularly where adversarial learning tools are employed in offense. Strategically, AI-enabled cyber operations offer distinct attempts to persistently shape the spectrum of cyber contention may be able to pursue conflict outcomes beyond the expected scope of adversary operation. On the other, AI-augmented cyber defenses incorporated into national defense postures are likely to be vulnerable to "poisoning" attacks that predict, manipulate and subvert the functionality of defensive algorithms. This article takes on two primary tasks. First, it considers and categorizes the primary ways in which AI technologies are likely to augment offensive cyber operations, including the shape of cyber activities designed to target AI systems. Then, it frames a discussion of implications for deterrence in cyberspace by referring to the policy of persistent engagement, agreed competition and forward defense promulgated in 2018 by the United States. Here, it is argued that the centrality of cyberspace to the deployment and operation of soon-to-be-ubiquitous AI systems implies new motivations for operation within the domain, complicating numerous assumptions that underlie current approaches. In particular, AI cyber operations pose unique measurement issues for the policy regime.},
  keywords={Uncertainty;Toxicology;Shape;Cyberspace;Prototypes;Prediction algorithms;Routing protocols;deterrence;persistent engagement;cyber;AI;machine learning},
  doi={10.23919/CyCon49761.2020.9131717},
  ISSN={2325-5374},
  month={May},}@INPROCEEDINGS{9927842,
  author={AL-Essa, Malik and Andresini, Giuseppina and Appice, Annalisa and Malerba, Donato},
  booktitle={2022 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)}, 
  title={An XAI-based adversarial training approach for cyber-threat detection}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Adversarial training is commonly used in the artificial intelligence literature to improve the robustness of deep neural models to adversarial samples. In addition, eXplainable Artificial Intelligence (XAI) has been recently investigated to improve the interpretability and explainability of black-box artificial systems such as deep neural models. In this study, we propose a methodology that combines adversarial training and XAI, in order to increase the accuracy of deep neural models trained for cyber-threat detection. In particular, we use the FGSM technique to generate the adversarial samples for the adversarial training stage, and SHAP to produce the local explanations of decisions made during the adversarial training stage. These local explanations are, subsequently, used to produce a new feature set that describes the effect of the original cyber-data characteristics on the classifications of the examples processed during the adversarial training stage. Leveraging this XAI-based information, we apply a transfer learning strategy, namely fine-tuning, to improve the accuracy performance of the deep neural model. Experiments conducted on two benchmark cybersecurity datasets prove the effectiveness of the proposed methodology in the multi-class classification of cyber-data.},
  keywords={Training;Deep learning;Couplings;Biological system modeling;Transfer learning;Learning (artificial intelligence);Predictive models;Adversarial training;eXplainable Artificial Intelligence;Transfer learning;Cyber-threat detection},
  doi={10.1109/DASC/PiCom/CBDCom/Cy55231.2022.9927842},
  ISSN={},
  month={Sep.},}@ARTICLE{10206435,
  author={Li, Wei and Liu, Wei and Chen, Jinlin and Wu, Libing and Flynn, Patrick D. and Ding, Wei and Chen, Ping},
  journal={IEEE Transactions on Cybernetics}, 
  title={Reducing Mode Collapse With Monge–Kantorovich Optimal Transport for Generative Adversarial Networks}, 
  year={2024},
  volume={54},
  number={8},
  pages={4539-4552},
  abstract={Mode collapse has been a persisting challenge in generative adversarial networks (GANs), and it directly affects the applications of GAN in many domains. Existing works that attempt to solve this problem have some serious limitations: models using optimal transport (OT) strategies (e.g., Wasserstein distance) lead to vanishing or exploding gradients; increasing the number of generators can cause several generators focusing on the same mode; and approaches that modify the loss also do not satisfactorily resolve mode collapse. In this article, we reduce mode collapse by formulating it as a Monge problem of OT map. We show that the Monge problem can be transformed to the distribution transformation problem in GAN, and a rectified affine neural network can be considered as a measurable function. In this way, we propose Monge GAN that uses this measurable function to transform the generated data distribution into the original data distribution. We utilize the Kantorovich formulation to obtain the OT cost, which is regarded as the OT distance between the two distributions. Finally, we conduct extensive experiments on both image and numerical datasets to validate our Monge GAN in reducing model collapse.},
  keywords={Generative adversarial networks;Generators;Costs;Training;Neural networks;Image color analysis;Focusing;Generative adversarial network (GAN);mode collapse;Monge problem;optimal transport (OT) map},
  doi={10.1109/TCYB.2023.3296109},
  ISSN={2168-2275},
  month={Aug},}@INPROCEEDINGS{10774721,
  author={Patil, Ratna and Yeolekar, Suyash and Khade, Omkar and Kadam, Yash and Ingole, Prajwal and Patil, Suraj},
  booktitle={2024 8th International Conference on Computing, Communication, Control and Automation (ICCUBEA)}, 
  title={AyUR-bot: A Revolutionary Ayurvedic Chatbot Empowered by Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This study introduces AyUR-bot, a 24/7 Ayurvedic expert chatbot designed for prompt addressing of user queries on nutrition, remedies, and overall wellness. Project objectives include developing an Ayurvedic chatbot using NLP and deep learning, providing accurate responses, optimizing model efficiency, educating users about Ayurveda, and contributing to health and wellness through interactive conversations. The user-friendly chat interface allows effortless query submission. AyUR-bot leverages NLP tools, integrating the Llama 2 Large Language Model (LLM) and implementing Retrieval Augmented Generation (RAG) for question answering, optimizing Ayurvedic knowledge accessibility. The development process involves curating a specialized Ayurvedic document repository and utilizing the Llama 2 LLM model from Hugging Face. AyUR-bot ensures precise responses with unique stopping conditions. Components like the conversational retrieval chain, recursive character text splitter, and embeddings generator synergize for comprehensive responses. Evaluation with BERT Score validates AyUR-bot's effectiveness in delivering context-aware insights. The user-friendly interface enables interactive engagement, facilitating personalized Ayurvedic guidance. This research converges chatbot technology, NLP, and Ayurveda, aligned with project objectives, catering to the growing interest in traditional wellness, democratizing access to Ayurvedic wisdom. AyUR-bot results in a significant advancement in personalized Ayurvedic assistance.},
  keywords={Adaptation models;Large language models;Process control;Oral communication;Chatbots;Vectors;User experience;Question answering (information retrieval);Faces;Text processing;AyUR-bot;Ayurveda;Natural Language Processing;Hugging Face;Conversational Retrieval Chain;Retrieval Augmented Generation (RAG);Vector Database;FAISS;LangChain},
  doi={10.1109/ICCUBEA61740.2024.10774721},
  ISSN={2771-1358},
  month={Aug},}@ARTICLE{10818854,
  author={Zhang, Zhenju and Ma, Linru and Liu, Mingqian and Chen, Yunfei and Zhao, Nan and Nallanathan, Arumugam},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Robust Generative Defense Against Adversarial Attacks in Intelligent Modulation Recognition}, 
  year={2025},
  volume={11},
  number={2},
  pages={1041-1052},
  abstract={Deep neural network (DNN) greatly improves the efficiency of modulation recognition in wireless communication, but it also suffers from attacks. Generative artificial intelligence (GAI) possesses powerful data generation capabilities, which can be used to defend against attacks in modulation recognition. In practical scenarios, closed box attack can be implemented without information on the model. This is a great security threat. The existing defense methods are difficult to improve the robustness of the model while ensuring the recognition accuracy of the original signals. Therefore, this paper uses GAI to propose an adversarial decoupled defense method to protect modulation recognition. Firstly, for weak adversarial perturbations, the empirical mode decomposition (EMD) is used to highlight the high-frequency features in the signal, and the adversary detector is designed to detect the suspiciousness. Then, the signal is regenerated based on the generative adversarial network (GAN) to weaken the antagonism in the example. Further, the traditional adversarial training is decoupled into an original branch and an adversarial branch, and the outputs of the two branches are fused according to the suspiciousness. Simulation results show that the proposed defense method has high recognition accuracy for both original examples and adversarial examples even under attacks, and can effectively improve the robustness of the intelligent recognition model.},
  keywords={Modulation;Perturbation methods;Generative adversarial networks;Training;Wireless communication;Robustness;Modeling;Feature extraction;Data models;Receivers;Adversarial attack;adversarial defense;generative artificial intelligence;intelligent modulation recognition;generative adversarial network},
  doi={10.1109/TCCN.2024.3524184},
  ISSN={2332-7731},
  month={April},}@INPROCEEDINGS{10760914,
  author={Liao, Yi-Ci and Wang, Sheng-Ming},
  booktitle={2024 IEEE 13th Global Conference on Consumer Electronics (GCCE)}, 
  title={Integrating Text-Analysis to Explore the Application of Generative AI Tools on User Interface Design and Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={948-949},
  abstract={This study investigates collaboration issues between UI designers and engineers and the application of Artificial Intelligence Generated Content tools, such as AI-assisted programming tools, through semi-structured interviews and interactions with LLMs like ChatGPT-4, Claude, and Gemini. Text analysis was conducted on the collected data. LLMs served as exploratory tools, supplementing in-person interviews and addressing participant scale limitations in traditional qualitative data collection by simulating different professional perspectives.The results indicate that AI tools can enhance development efficiency but require users to have basic programming knowledge for effective interaction. Additionally, designers learning front-end programming can improve cross-disciplinary collaboration and competitiveness, promoting better communication with engineers. This study aims to explore the potential of AIGC tools in assisting UI designers and front-end engineers in transitioning towards the UI engineering field, thereby enhancing their career flexibility and adaptability.},
  keywords={Electric potential;Text analysis;Generative AI;Engineering profession;Collaboration;User interfaces;Data collection;Interviews;Programming profession;Consumer electronics;AIGC Tool;Large Language Models;Text Analysis;UI Design;UI Engineering},
  doi={10.1109/GCCE62371.2024.10760914},
  ISSN={2693-0854},
  month={Oct},}@INPROCEEDINGS{8628701,
  author={Boulogne, Luuk and Dijkstra, Klaas and Wiering, Marco},
  booktitle={2018 IEEE Symposium Series on Computational Intelligence (SSCI)}, 
  title={Extra Domain Data Generation with Generative Adversarial Nets}, 
  year={2018},
  volume={},
  number={},
  pages={1403-1410},
  abstract={This study focuses on supplementing data sets with data of absent classes by using other, similar data sets in which these classes are represented. The data is generated using Generative Adversarial Nets (GANs) trained on the CelebA and MNIST datasets. In particular we use and compare Coupled GANs (CoGANs), Auxiliary Classifier GANs (AC-GANs) and novel a combination of the two (CoAC-GANs) to generate image data of domain-class combinations that were removed from the training data. We also train classifiers on the generated data. The results show that AC-GANs and CoAC-GANs can be used successfully to generate labeled data from domain-class combinations that are absent from the training data. Furthermore, they suggest that the preference for one of the two types of generative models depends on training set characteristics. Classifiers trained on the generated data can accurately classify unseen data from the missing domain-class combinations.},
  keywords={Gallium nitride;Generators;Training;Artificial neural networks;Task analysis;Training data;Generative adversarial net;deep neural network;data generation},
  doi={10.1109/SSCI.2018.8628701},
  ISSN={},
  month={Nov},}@ARTICLE{10955131,
  author={Chen, Long and Wang, Yanting and Wang, Qiaojuan and Song, Yanqing and Chen, Jianguo},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={Cybersecurity Multi-Dimensional Few-Shot Data Generation on Malicious Enhancement}, 
  year={2025},
  volume={22},
  number={5},
  pages={4988-4997},
  abstract={Small amounts of malicious logs can confuse and imbalance a large volume of normal logs, leading to a significant drop in model performance. To address the high heterogeneity and imbalance between network security data, we propose a multidimensional few-shot data augmentation framework based on Generative Adversarial Networks (GANs) for generating high-quality malicious samples to balance data distribution. In this framework, several representative GAN models, including PE-GAN, XOR-GAN, and TriNet-GAN, are designed to enhance the performance of deep learning models in network threat detection. Large-scale adversarial generation experiments are conducted on the original imbalanced dataset and security event logs using AC-GAN and Seq-GAN, effectively solving the imbalance and few-shot issues. The experimental results are based on the publicly available NIMS (Network Information Management and Security Group) and KDD99 datasets. The results demonstrate that the proposed method performs well in data augmentation for few-shot, imbalanced, and multidimensional complex data.},
  keywords={Generative adversarial networks;Training;Data augmentation;Data models;Artificial intelligence;Generators;Deep learning;Malware;Threat assessment;Network security;Few-shot;data augmentation;network threats;log data;network traffic;generative adversarial networks},
  doi={10.1109/TDSC.2025.3558545},
  ISSN={1941-0018},
  month={Sep.},}@INPROCEEDINGS{11108364,
  author={Reddy, R Thanuja and U, Lavanya and G, Anusha and S, Ummehani and Rastogi, Vanshika and R, Anand},
  booktitle={2025 International Conference on Emerging Technologies in Computing and Communication (ETCC)}, 
  title={Skin Diseases Classification with Deep Learning Techniques: A Review}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={One major health problem is the frequency of skin disorders. For treatment to be effective, a precise diagnosis is essential. Traditional diagnostic techniques, which frequently rely on dermoscopy and visual inspection, can be laborious and subjective. One possible method for automated skin disease diagnostics is a subset of artificial intelligence. This review explores the use of deep learning methods in this sector by looking at the many kinds of skin conditions. datasets using augmentation and preprocessing methods performance benchmarks and criteria for evaluating model designs We also go into the drawbacks and difficulties, such as interpretability of data quality models and ethical issues. By utilizing deep learning, we can increase the precision and effectiveness of diagnosing skin diseases, which will enhance patient outcomes.},
  keywords={Deep learning;Visualization;Ethics;Reviews;Inspection;Skin;Data models;Medical diagnostic imaging;Diseases;Image classification;skin disease;deep learning;computer vision;image classification;medical image analysis;machine learning},
  doi={10.1109/ETCC65847.2025.11108364},
  ISSN={},
  month={June},}@INPROCEEDINGS{10761290,
  author={Amendi, Roger and Halim, Erwin and Hartono, Hendry},
  booktitle={2024 2nd International Conference on Technology Innovation and Its Applications (ICTIIA)}, 
  title={Exploring Ethical Implications: Unraveling Factors Influencing Data Governance Awareness Behavior in Generative AI Chatbot}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={For employees, generative AI chatbots can encourage productivity and optimize work processes with the specific insights provided. The problem is the ethical implications for the privacy and confidentiality of company data that employees carelessly enter into a generative AI chatbot platform. This research aims to study how employees behave when entering company data using a generative AI chatbot based on behavioral intentions on data governance awareness. This research uses quantitative methods like the Partial Least Squares Structural Equation Modeling (PLS-SEM) statistical method. Purposive sampling determines the number of samples, with data collection from February to April 2024. Based on the data collection results, 402 employees in Indonesia who used generative AI chatbots became valid respondents who answered the online questionnaire using Google Forms. The research results show a significant picture of the factors influencing awareness of data governance behavior and company data usage behavior in generative AI chatbots. The test used nine hypotheses, where the results found that six hypotheses had a significant effect and three hypotheses were not significant. The findings of this research have implications for increasing awareness and data governance practices regarding the role of organizational support and employee training to mitigate risks in the use of generative AI chatbots in corporate environments.},
  keywords={Training;Ethics;Data privacy;Generative AI;Companies;Data collection;Chatbots;Mathematical models;Data governance;Security;generative AI chatbot;data governance awareness;employee in workplace;behavior in use;UTAUT2},
  doi={10.1109/ICTIIA61827.2024.10761290},
  ISSN={},
  month={Sep.},}@ARTICLE{10645216,
  author={Yang, Jiajun and Li, Wenyuan and Chen, Keyan and Liu, Zili and Shi, Zhenwei and Zou, Zhengxia},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={Weakly Supervised Adversarial Training for Remote Sensing Image Cloud and Snow Detection}, 
  year={2024},
  volume={17},
  number={},
  pages={15206-15221},
  abstract={Cloud and snow detection in remote sensing images has advanced significantly with the aid of deep learning methods. However, deep learning methods necessitate a large quantity of labeled data, which consumes a substantial amount of human and material resources. Numerous studies have focused on weakly supervised methods to reduce the workload of annotation, but the majority of these methods concentrate on cloud detection and involve snow detection only infrequently. In this article, we propose a novel weakly supervised cloud and snow detection method. Under the guidance of the remote sensing imaging mechanism, we design generative adversarial networks (GANs) to generate cloud and snow images and pseudolabels for training detection networks. The proposed method can generate clouds of different states and reproduce snow's texture. For both the cloud GAN model and snow GAN model, with only image-level annotation training supervision, the models produce both pixel-level cloud/snow reflectance and cloud opacity to obtain the generated remote sensing images and corresponding pseudolabels. Compared to other weakly supervised methods, our method achieves superior cloud and snow detection performance.},
  keywords={Snow;Cloud computing;Remote sensing;Generative adversarial networks;Feature extraction;Reflectivity;Imaging;Cloud and snow detection;deep learning;generative adversarial networks (GANs);remote sensing images;weakly supervised learning},
  doi={10.1109/JSTARS.2024.3448356},
  ISSN={2151-1535},
  month={},}@ARTICLE{9815204,
  author={An, Yongli and Yue, Jingjing and Chen, Lei and Ji, Zhanlin},
  journal={Journal of Communications and Information Networks}, 
  title={Channel Estimation for One-Bit Massive MIMO Based on Improved CGAN}, 
  year={2022},
  volume={7},
  number={2},
  pages={214-220},
  abstract={In the one-bit massive multiple-input multiple-output (MIMO) channel scenario, the accurate channel estimation becomes more difficult because the signals received by the low-resolution analog-to-digital converters (ADC) are quantized and affected by channel noise. Therefore, a one-bit massive MIMO channel estimation method is proposed in this paper. The channel matrix is regarded as a two-dimensional image. In order to enhance the significance of noise features in the image and remove them, the channel attention mechanism is introduced into the conditional generative adversarial network (CGAN) to generate channel images, and improve the loss function. The simulation results show that the improved network can use a smaller number of pilots to obtain better channel estimation results. Under the same number of pilots and signal-to-noise ratio (SNR), the channel estimation accuracy can be improved by about 7.5 dB, and can adapt to the scenarios with more antennas.},
  keywords={Channel estimation;Generators;Massive MIMO;Generative adversarial networks;Feature extraction;Convolution;Estimation;channel estimation;massive MIMO;conditional generative adversarial network;attention mechanism;denoising},
  doi={10.23919/JCIN.2022.9815204},
  ISSN={2509-3312},
  month={June},}@INPROCEEDINGS{10747930,
  author={Chan, Miguel Morales and Amado-Salvatierra, Hector R. and Hernandez-Rizzardini, Rocael and Rosales, Milvia},
  booktitle={2024 IEEE Digital Education and MOOCS Conference (DEMOcon)}, 
  title={Assessing Student Perceptions of Video Quality and Effectiveness From AI-Enhanced Digital Resources}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In this article, the authors explore the practical application of artificial intelligence-based tools in streamlining the course development process, with a particular emphasis on video production and scriptwriting. The work explores the production process for a MOOC lesson, encompassing activities such as video scripting, graphic design, podcast recording, slide presentation preparation, concept mapping, and the creation of interactive learning activities. The article presents the instrument used to evaluate students’ perceptions of the AI-generated video resources, offering insights into the accessibility of creating avatars without the need for specialized equipment. With basic recording devices and adherence to guidelines like maintaining eye contact and minimizing background noise, users can achieve professional results. Furthermore, the work underscores the potential benefits of integrating AI-based tools in the development of MOOCs and large-scale course production. It is observed that the utilization of such technologies may lead to a more streamlined course creation process, with the first exploration indicating a possible reduction of preparation time by approximately 60%. This notable decrease in development time could offer substantial improvements in the scalability and potential personalization of online education.},
  keywords={Computer aided instruction;Electronic learning;Negative feedback;Avatars;Scalability;Education;Production;Streaming media;Quality assessment;Video recording;Artificial Intelligence;LLMs;Generative AI;Prompt Engineering},
  doi={10.1109/DEMOcon63027.2024.10747930},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10416105,
  author={Ma, Zhengzheng and Luo, Guojie},
  booktitle={2023 International Conference on Field Programmable Technology (ICFPT)}, 
  title={An Efficient Dataflow for Convolutional Generative Models}, 
  year={2023},
  volume={},
  number={},
  pages={53-59},
  abstract={Convolutional generative models have achieved significant success in the field of artificial intelligence in recent years. These models typically rely on numerous convolution and transposed convolution operators, both of which are highly computationally intensive but present distinct computation patterns. As a result, accelerating the convolutional generative models can be challenging, particularly when the transposed convolution is likely to become performance bottleneck. In this paper, we propose a dataflow for overcoming the challenge and effectively accelerating both computation-hungry operators of convolutional generative models in the unified architecture. Additionally, we have devised specific tiling schemes to flexibly map both convolution and transposed convolution and fully reuse hardware resources. To demonstrate the effectiveness of our approach, we implemented DCGAN and ST on the Xilinx ZCU102 platform. Our experiments show that the proposed dataflow can reduce memory cost by up to 36%, achieving comparable performance for both convolution and transposed convolution.},
  keywords={Costs;Convolution;Computational modeling;Computer architecture;Hardware;Artificial intelligence;Convolutional Generative Model;FPGA},
  doi={10.1109/ICFPT59805.2023.00011},
  ISSN={2837-0449},
  month={Dec},}@INPROCEEDINGS{10108357,
  author={Jiang, Lai and Hao, YuJie and Lin, Jie},
  booktitle={2022 2nd International Conference on Big Data, Artificial Intelligence and Risk Management (ICBAR)}, 
  title={Dialogue Text Summarization Method Combined Self-supervised Learning and Neural Architecture Search}, 
  year={2022},
  volume={},
  number={},
  pages={65-69},
  abstract={Dialogue summary generation task aims at generating summary for dialogue. Due to the changing topic and discrete semantic of dialogue, previous summarization methods on article cannot generate satisfactory summary for dialogue. To reduce the impact of discrete topics on dialogue summary generation, this work proposes a topic division method to form topic paragraph sets. In order to generate dialogue summaries according to the divided topic paragraphs, we further propose a dialogue text summarization model based on a Generative Adversarial framework. In this model, we use the differentiable Neural Architecture Search method to implement the entire search process of generative and discriminative network. The generative network is a BART network formed by sharing the Transformer structure obtained by the search, which we call EBART. The effectiveness of this work is verified by experiments on public dialogue datasets.},
  keywords={Search methods;Semantics;Self-supervised learning;Big Data;Transformers;Generative adversarial networks;Risk management;Dialogue Summarization;Self-supervised Learning;Neural Architecture Search;Generative Adversarial Networks},
  doi={10.1109/ICBAR58199.2022.00020},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10323952,
  author={Mohammed, Mickael and Salem, Osman and Mehaoua, Ahmed},
  booktitle={2023 International Symposium on Networks, Computers and Communications (ISNCC)}, 
  title={Artificial Intelligence for Anomaly Detection in IoMTs}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The exponential development and widespread emergence of the Internet of Medical Things (IoMT) have led to a growing need for effective anomaly detection techniques to ensure the reliability and security of healthcare systems. This article provides a review of existing machine learning and deep learning algorithms for anomaly detection in IoMT, followed by the presentation of a novel approach combining ARIMA for predicting health parameter values and a decision tree for anomaly detection. This hybrid approach aims to improve the accuracy and efficiency of anomaly detection in IoMT by leveraging both time series models and the discriminative features of decision trees. The preliminary results of this approach are presented and discussed, highlighting its potential to enhance early detection of anomalies in IoMT and contribute to safer and more reliable healthcare.},
  keywords={Deep learning;Support vector machines;Analytical models;Machine learning algorithms;Time series analysis;Data models;Decision trees;Internet of Medical Things;machine learning;deep learning;ARIMA;decision tree;anomaly detection},
  doi={10.1109/ISNCC58260.2023.10323952},
  ISSN={2768-0940},
  month={Oct},}@INPROCEEDINGS{10710796,
  author={Salıcı, Mustafa and Ölçer, Üyesi Ercan},
  booktitle={2024 8th International Artificial Intelligence and Data Processing Symposium (IDAP)}, 
  title={Impact of Transformer-Based Models in NLP: An In-Depth Study on BERT and GPT}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This article examines in depth the effects of BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pretrained Transformer) models in the field of natural language processing (NLP). NLP, as a sub-branch of computer science and artificial intelligence, has an important place in the processes of understanding, processing and producing human language. Transformer-based models have provided revolutionary advances in many NLP tasks, especially language modeling, sentiment analysis, machine translation and question answering. In this article, the technical structures of BERT and GPT models, their performance in low-resource languages such as Turkish and the difficulties encountered in these languages are discussed in detail. The BERT model stands out with its ability to evaluate the contextual meaning of the language from both directions using bidirectional context and offers high success rates especially in tasks such as text classification, named entity recognition (NER) and sentiment analysis. The GPT model, on the other hand, provides superiority in text production with its autoregressive structure and gives successful results in tasks such as creative writing and chatbots. However, the application of these models to morphologically rich and agglutinative languages such as Turkish poses certain challenges. These challenges arise due to the structural features of the language and the limitations of the datasets. The article also discusses the development of Turkish-specific models such as BERTurk, data augmentation techniques, and the success of modifications appropriate to the characteristics of the language in overcoming these challenges. In conclusion, the development of BERT and GPT models in the field of NLP has been a major step in terms of natural language processing and modeling. However, further research and development is required for these models to perform better in languages such as Turkish. The article predicts that future developments of these models will enable language technologies to reach wider audiences and be used in various applications.},
  keywords={Analytical models;Sentiment analysis;Computational modeling;Bidirectional control;Writing;Transformers;Natural language processing;Encoding;Data models;Artificial intelligence;NLP;BERT;GPT;NER},
  doi={10.1109/IDAP64064.2024.10710796},
  ISSN={},
  month={Sep.},}@INBOOK{10785849,
  author={Tardy, Jean},
  booktitle={The Creation of a Conscious Machine: The Quest for Artificial Intelligence}, 
  title={Chapter 19: The Lucid Self-Transformation of Generative AI}, 
  year={2023},
  volume={},
  number={},
  pages={189-200},
  abstract={},
  keywords={Optimization;Generative AI;Control systems;Actuators;Search problems;Predictive models;Software;Refining;Organisms;Self-aware},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9781501518331},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10785849},}@INPROCEEDINGS{8451714,
  author={Lucas, Alice and Katsaggelos, Aggelos K. and Lopez-Tapuia, Santiago and Molina, Rafael},
  booktitle={2018 25th IEEE International Conference on Image Processing (ICIP)}, 
  title={Generative Adversarial Networks and Perceptual Losses for Video Super-Resolution}, 
  year={2018},
  volume={},
  number={},
  pages={51-55},
  abstract={Recent research on image super-resolution (SR) has shown that the use of perceptual losses such as feature-space loss functions and adversarial training can greatly improve the perceptual quality of the resulting SR output. In this paper, we extend the use of these perceptual-focused approaches for image SR to that of video SR. We design a 15-block residual neural network, VSRResNet, which is pre-trained on a the traditional mean -squared -error (MSE) loss and later fine-tuned with a feature-space loss function in an adversarial setting. We show that our proposed system, VSRRes-FeatGAN, produces super-resolved frames of much higher perceptual quality than those provided by the MSE-based model.},
  keywords={Training;Spatial resolution;Mathematical model;Loss measurement;Gallium nitride;Neural networks;Video;Superresolution;Convolutional Neuronal Networks;Generative Adversarial Networks;Perceptual Loss Functions},
  doi={10.1109/ICIP.2018.8451714},
  ISSN={2381-8549},
  month={Oct},}@ARTICLE{9732473,
  author={Lee, Chang-Ki and Cheon, Yu-Jeong and Hwang, Wook-Yeon},
  journal={IEEE Access}, 
  title={Least Squares Generative Adversarial Networks-Based Anomaly Detection}, 
  year={2022},
  volume={10},
  number={},
  pages={26920-26930},
  abstract={Multivariate statistical process control (MSPC) is a technique for detecting anomalies by monitoring several quality characteristics simultaneously. For the MSPC problem, the Hotelling’s  $T^{2}$  control chart has been widely used as a typical method. Recently, researchers have converted the MSPC problem into a classification problem such as the artificial contrast (AC) and the one-class classification (OCC). Previous studies have shown that these methods outperform the Hotelling’s  $T^{2}$  chart when the data do not follow a multivariate normal distribution. However, unless the size of the process data is enough for the AC and the OCC, they cannot work properly. To tackle this problem, in this paper, we propose a novel anomaly detection (AD) approach. The proposed method adopts the least square generative adversarial network (LS-GAN) to estimate the probability distribution of the training data. It generates new training samples from the learned probability distribution. The classifiers such as the random forests (RF) and the one-class support vector machines (OC-SVM) are considered for tackling the AC and the OCC respectively. The numerical experiments demonstrate that the proposed approach outperforms the existing methods in terms of the area under the receiver operating characteristic (ROC) curve (AUC).},
  keywords={Generative adversarial networks;Process control;Monitoring;Control charts;Anomaly detection;Support vector machines;Data models;Anomaly detection;artificial contrast;one-class classification;least square generative adversarial network;Hotelling’s control boundary;random forests;one-class support vector machines},
  doi={10.1109/ACCESS.2022.3158343},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10956941,
  author={Soni, Aayush and Kaur, Kamalpreet and Sharma, Chriag},
  booktitle={2025 International Conference on Automation and Computation (AUTOCOM)}, 
  title={A Review of Artificial Intelligence in Digital Watermarking Techniques}, 
  year={2025},
  volume={},
  number={},
  pages={1601-1606},
  abstract={In this era, watermarking has been considered to be the emerging technology in the digital world and an asset to various social economics domain which pin-pointing the concern in securing the data, privacy and intellectual property. In this review paper, 35 research papers have been reviewed which were published between 2020 and 2025 highlighting the major takeaways including usage and depth knowledge of watermarking techniques in different domain, its advantages and applications using machine learning. This research broader the vision in various sectors such as healthcare, meeting the challenge of securing and protecting the data. A comprehensive exploration of modern watermarking technologies in enhancing digital security through increased diversity in application and privacy. Consequently, this lesser the chances of illegal usage or distribution of intellectual properties and safeguards one's contribution. Thus, among the techniques of digital watermarking include frequency and spatial methods, with frequency domain offering better robustness. Also performance achieved through the deep learning-based methods considered to be highly adaptive, imperceptible, and highly secure watermarking solutions.},
  keywords={Deep learning;Reviews;Frequency-domain analysis;Data integrity;Watermarking;Medical services;Intellectual property;Robustness;Real-time systems;Socioeconomics;Watermarking techniques;Machine learning;Deep Learning;Artificial Intelligence;Healthcare;Data Integrity;Security},
  doi={10.1109/AUTOCOM64127.2025.10956941},
  ISSN={},
  month={March},}@ARTICLE{9261326,
  author={Salazar-Colores, Sebastián and Jiménez, Hugo Moreno and Ortiz-Echeverri, César Javier and Flores, Gerardo},
  journal={IEEE Access}, 
  title={Desmoking Laparoscopy Surgery Images Using an Image-to-Image Translation Guided by an Embedded Dark Channel}, 
  year={2020},
  volume={8},
  number={},
  pages={208898-208909},
  abstract={In this paper, a method to remove the smoke effects in laparoscopic images is presented. The proposed method is based on an image-to-image conditional generative adversarial network endowed with a dark channel's embedded guide mask. The obtained experimental results were evaluated and quantitatively compared with desmoking state-of-art methods using the Peak Signal-to-Noise Ratio (PSNR) metrics and Structural Similarity (SSIM) index. Those results throw an improved performance compared with relevant works. Also, the processing time required by our method is 92 frames per second; a processing time that sets the foundation for a possible real-time implementation in a more modest embedded system.},
  keywords={Laparoscopes;Generative adversarial networks;Minimally invasive surgery;Generators;Image color analysis;Channel estimation;Neural networks;Laparoscopy;image smoke removal;conditional generative adversarial network;dark channel},
  doi={10.1109/ACCESS.2020.3038437},
  ISSN={2169-3536},
  month={},}@ARTICLE{10934748,
  author={Lu, Jiayi and Yang, Wanting and Xiong, Zehui and Xing, Chengwen and Tafazolli, Rahim and Quek, Tony Q.S. and Debbah, Mérouane},
  journal={IEEE Vehicular Technology Magazine}, 
  title={Generative Artificial intelligence-Enhanced MultiModal Semantic Communication in Internet of Vehicles: System Design and Methodologies}, 
  year={2025},
  volume={20},
  number={2},
  pages={71-82},
  abstract={Vehicle-to-everything (V2X) communication supports numerous tasks, from driving safety to entertainment services. To achieve a holistic view, vehicles are typically equipped with multiple sensors. However, processing large volumes of multimodal data increases transmission load, while the dynamic nature of vehicular networks adds to transmission instability. To address these challenges, we propose a novel framework, generative artificial intelligence (GAI)-enhanced multimodal semantic communication (SemCom), referred to as G-MSC, designed to handle various vehicular network tasks by employing suitable analog or digital transmission. GAI presents a promising opportunity to transform the SemCom framework by significantly enhancing semantic encoding, semantic information transmission, and semantic decoding. It optimizes multimodal information fusion at the transmitter, enhances channel robustness during transmission, and mitigates noise interference at the receiver. To validate the effectiveness of the G-MSC framework, we conduct a case study showcasing its performance in vehicular communication networks for predictive tasks. The experimental results show that the design achieves reliable and efficient communication in V2X networks. In the end, we present future research directions of G-MSC.},
  keywords={Semantics;Training;Autonomous vehicles;Sensors;Decoding;Automation;Generative adversarial networks;Accuracy;Generative AI;Semantic communication;Multisensory integration},
  doi={10.1109/MVT.2025.3545399},
  ISSN={1556-6080},
  month={June},}@INPROCEEDINGS{10894461,
  author={V R, Kiruthika and N, Sangavi and S, Satheeshkumar},
  booktitle={2025 International Conference on Multi-Agent Systems for Collaborative Intelligence (ICMSCI)}, 
  title={Bringing Vintage Video to Life Using Deep Learning Algorithms}, 
  year={2025},
  volume={},
  number={},
  pages={1118-1123},
  abstract={The research presents an innovative methodology for video colorization that leverages advanced AI deep learning techniques to transform monochromatic footage into vivid, realistic color videos. The emergence of artificial intelligence has significantly impacted the media and entertainment sectors, overcoming the constraints associated with conventional colorization techniques, which typically depend on manual processes and rudimentary algorithms. This investigation highlights several critical challenges, such as the effective training of deep neural networks, optimization for color accuracy, and compliance with performance benchmarks. The proposed framework utilizes a multi-phase training approach to enhance resilience, a tailored loss function to improve color precision, and attention mechanisms to effectively capture intricate textures, supported by comprehensive evaluations against established benchmark datasets. Our results not only advance the field of automated colorization but also pave the way for various applications within the media industry, indicating potential improvements in real-time processing and user-centric customization. By revitalizing historical footage, this technology promotes accessibility and engagement, underscoring the pivotal role of AI in visual narrative development.},
  keywords={Deep learning;Training;Visualization;Accuracy;Image color analysis;Transforms;Streaming media;Media;Benchmark testing;Artificial intelligence;Video Colorization;Deep Learning;Neural Networks;grayscale footage;Image Processing;Texture Analysis},
  doi={10.1109/ICMSCI62561.2025.10894461},
  ISSN={},
  month={Jan},}@ARTICLE{9989352,
  author={Cho, Sungha and Choi, Minseok},
  journal={IEEE Access}, 
  title={MGDGAN: Multiple Generator and Discriminator Generative Adversarial Networks for Solving Stochastic Partial Differential Equations}, 
  year={2022},
  volume={10},
  number={},
  pages={130908-130920},
  abstract={We propose novel structures of generator and discriminator in physics-informed generative adversarial networks called multiple-generator-and-discriminator generative adversarial networks (MGDGANs), that are designed to solve stochastic partial differential equations (SPDEs). MGDGANs for SPDEs consist of three steps: a generator that samples a solution to the SPDEs, a physics-informed operator that enforces the governing equation, and a discriminator that distinguishes between samples from the generator and training samples. Inspired by the polynomial chaos, we represent the solution by the inner product of functions in spatial and random variables, and model each function by a separate generator. We show that the proposed multiple generator structure offers huge computational savings in training and prediction. If multiple stochastic processes exist in the system, then a distinct discriminator is used for each of them. We show that the loss function obtained by these distinct discriminators provides an equivalent metric to the Wasserstein distance loss by a single discriminator, and provide numerical examples to demonstrate that these multiple discriminators enhance the training accuracy. Numerical examples are demonstrated to verify that the proposed model is efficient in computation and memory; the model reduces computing time by more than a factor of 10 and relative l2 error by about one-third in the SPDE example.},
  keywords={Generators;Stochastic processes;Computational modeling;Mathematical models;Artificial neural networks;Numerical models;Generative adversarial networks;Computational modeling;deep learning;generative adversarial networks;physics-informed deep generative models;uncertainty quantification},
  doi={10.1109/ACCESS.2022.3229696},
  ISSN={2169-3536},
  month={},}@ARTICLE{9058665,
  author={Liu, Qianjun and Ma, Guijun and Cheng, Cheng},
  journal={IEEE Access}, 
  title={Data Fusion Generative Adversarial Network for Multi-Class Imbalanced Fault Diagnosis of Rotating Machinery}, 
  year={2020},
  volume={8},
  number={},
  pages={70111-70124},
  abstract={For the fault diagnosis problems of rotating machinery in the real industrial practice, measurement data with imbalanced class distributions negatively affect the diagnostic performance of most conventional machine learning classification algorithms since equal cost weights are assigned to different fault classes. Meanwhile, the widely used traditional data generation methods for the imbalanced data problem are limited by data dependencies over time continuity. To fill this research gap, this paper develops a new diagnostic framework based on the adversarial neural networks (GAN) and multi-sensor data fusion technique to generate new synthetic data for data compensation purpose. Two different practice modes are designed based on this framework according to the position logic of the data fusion, namely a Pre-fusion GAN mode and a Post-fusion GAN mode. More concretely, without data pre-processing, the designed generator generates synthetic data to puzzle the discriminator and the synthetic data that out-trick the discriminator can be used to compensate the minor class. To avoid data dependency and to ensure the generality of the proposed framework, the network modelling are trained with a more practical approach where the training and test data are obtained under different rotating speeds. Two imbalanced data sets on the rotating machinery, one benchmark public rolling bearing data set and another gear box data set acquired in our lab, are used to validate the proposed method. The performance is examined through a wide range of data imbalanced ratios (as high as 30:1), and compared with other state-of-the-art methods. The experiment results conclude that the proposed Pre-fusion GAN and Post-fusion GAN frameworks both have good performance on the imbalanced fault diagnosis of rotating machinery.},
  keywords={Gallium nitride;Generative adversarial networks;Data models;Machinery;Fault diagnosis;Data integration;Neural networks;Generative adversarial networks;imbalanced fault diagnosis;data continuity;rotating machinery},
  doi={10.1109/ACCESS.2020.2986356},
  ISSN={2169-3536},
  month={},}@ARTICLE{10632200,
  author={Zhang, Qinnan and Zong, Tianqi and Xiong, Zehui and Sun, Pangbo and Zhu, Jianming and Qiu, Wangjie and Zheng, Zhiming and Poor, H. Vincent},
  journal={IEEE Network}, 
  title={Exploring Edge-Driven Collaborative Fine-Tuning Toward Customized AIGC Services}, 
  year={2025},
  volume={39},
  number={3},
  pages={293-301},
  abstract={With the popularization of artificial intelligence-generated content (AIGC), the explosion of end users is spurring an unprecedented diversity in preferences. To cope with this challenge, the AIGC paradigm is shifting from cloud-driven pre-trained large models to edge-driven personalized customization models. The former are large-scale models with more than 100 billion parameters trained based on massive data, while the latter introduce heterogeneous user preferences or professional knowledge to fine-tune the former. However, such fine-tuning incurs costly resource consumption and privacy disclosure. In this paper, we offer a holistic perspective on the AIGC fine-tuning framework spanning from end user to edge to cloud. Specifically, we first investigate how to deploy an edge-driven collaborative fine-tuning task through federated learning. Then, we discuss a verifiable model consensus protocol and fairness incentive design for edge servers to participate in a collaborative learning task. In addition, a case study focuses on the medical scenario, where we develop a practical X-ray diagnostic demo through collaborative fine-tuning of a multimodal pre-training model, and the diagnostic dialogue and performance results are compared. Finally, potential research directions are identified to advance the edge-driven customized AIGC services.},
  keywords={Computational modeling;Collaboration;Tuning;Phase change materials;Adaptation models;Industries;Artificial intelligence;Content management;Customized AIGC services;edge-driven collaborative fine-tuning;federated learning;edge intelligence},
  doi={10.1109/MNET.2024.3441040},
  ISSN={1558-156X},
  month={May},}@INPROCEEDINGS{9073284,
  author={Sankar, Rahul and Nair, Ashwin and Abhinav, Prince and Mothukuri, Siva Krishna P and Koolagudi, Shashidhar G},
  booktitle={2020 International Conference on Artificial Intelligence and Signal Processing (AISP)}, 
  title={Image Colorization Using GANs and Perceptual Loss}, 
  year={2020},
  volume={},
  number={},
  pages={1-4},
  abstract={Image colorization is of great use for several applications, such as the restoration of old images, as well as enabling the storage of grayscale images, which take up less space, which can later be colorized. But this problem is hard since there exist many possible color combinations for a particular grayscale image. Recent developments have aimed to solve this problem using deep learning. But, for achieving good performance, they require highly processed inputs, along with additional elements, such as semantic maps. In this paper, an attempt has been made for generalizing the procedure of colorization using a conditional Deep Convolutional Generative Adversarial Network (DCGAN) by adding "Perceptual Loss". The network is trained over the CIFAR-100 dataset. The results of the proposed generative model with perceptual loss are compared with the existing state-of-the-art systems normal GAN model and U-Net Convolutional model.},
  keywords={Gallium nitride;Image color analysis;Generators;Generative adversarial networks;Cost function;Training;Convolution;coloring;deep learning;GAN;image;perceptual loss;U-Net model},
  doi={10.1109/AISP48273.2020.9073284},
  ISSN={2640-5768},
  month={Jan},}@INPROCEEDINGS{10465337,
  author={Nyambo, Devotha G. and Ngulumbi, Nguse and Mduma, Neema and Sinde, Ramadhani and Lyimo, Tumaini},
  booktitle={2023 First International Conference on the Advancements of Artificial Intelligence in African Context (AAIAC)}, 
  title={Data Synthesis Technique for Categorical Peste des Petits Ruminants (PPR) Data Using CTGAN Model}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={In the field of machine learning (ML), data scarcity is a serious difficulty because data gathering can be costly, time-consuming, and challenging, especially in poor nations. The complexity of using datasets to forecast livestock diseases enabling intervention and surveillance is overstated. This work provides a data synthesis method that has been applied to produce fresh data samples with accuracy from limited real-world data, in order to meet this difficulty. The ML models are trained on a large amount of data, which eliminates overfitting. We propose the synthesis of categorical data for training machine learning models for the prediction of Peste des Petits Ruminants (PPR) disease using Generative Adversarial Networks, namely the Conditional Tabular Generative Adversarial Network. The training score increased to 0.89 and the cross-validation score to 0.87 when the Random Forest algorithm was applied to the synthesized data, according to the results. The Peste des Petits Ruminants (PPR) disease can be predicted and monitored with the help of the generated dataset. With more data available, the suggested approach can be used in any area with categorical data for data-driven models and may enhance the performance of machine learning models.},
  keywords={Training;Machine learning algorithms;Surveillance;Predictive models;Prediction algorithms;Generative adversarial networks;Data models;Data synthesis;Livestock health;PPR disease;Machine Learning;Prediction},
  doi={10.1109/AAIAC60008.2023.10465337},
  ISSN={},
  month={Nov},}@BOOK{9538834,
  author={Haigh, Karen and Andrusenko, Julia},
  booktitle={Cognitive Electronic Warfare: An Artificial Intelligence Approach},
  year={2021},
  volume={},
  number={},
  pages={},
  abstract={This comprehensive book gives an overview of how cognitive systems and artificial intelligence (AI) can be used in electronic warfare (EW). Readers will learn how EW systems respond more quickly and effectively to battlefield conditions where sophisticated radars and spectrum congestion put a high priority on EW systems that can characterize and classify novel waveforms, discern intent, and devise and test countermeasures. Specific techniques are covered for optimizing a cognitive EW system as well as evaluating its ability to learn new information in real time. The book presents AI for electronic support (ES), including characterization, classification, patterns of life, and intent recognition. Optimization techniques, including temporal tradeoffs and distributed optimization challenges are also discussed. The issues concerning real-time in-mission machine learning and suggests some approaches to address this important challenge are presented and described. The book covers electronic battle management, data management, and knowledge sharing. Evaluation approaches, including how to show that a machine learning system can learn how to handle novel environments, are also discussed. Written by experts with first-hand experience in AI-based EW, this is the first book on in-mission real-time learning and optimization.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Artech},
  isbn={9781630818128},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/9538834},}@INPROCEEDINGS{10774282,
  author={Yi Chan, Elicia Min and Seow, Chee Kiat and Wee Tan, Esther Su and Wang, Min and Yau, Peter Chunyu and Cao, Qi},
  booktitle={2024 IEEE 22nd International Conference on Industrial Informatics (INDIN)}, 
  title={SketchBoard: Sketch-Guided Storyboard Generation for Game Characters in the Game Industry}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Research outcomes have been reported to various industrial applications of Artificial Intelligence generated content (AIGC). This paper explores AI assisted creative production of storyboard and game characters in the game industry, by leveraging Stable Diffusion 1.5 coupled with Control Nets (SD-1.5+CN) for image generations and Generative Pretrained Transformer (GPT) of OpenAI for narrative generations. Experiment evaluations are conducted for visual appeal and narrative flows of the generated contents using SketchBoard. The results illustrate SketchBoard with weighted prompts achieving a higher Contrastive Language-Image Pre-Training (CLIP) score than the baseline models. In addition to reducing the time and effort required for manual creation, it obtains strong alignments between the generated images and provided text prompts. User study is conducted where the user feedback indicates a high level of satisfaction, with 92 % of participants expressing enj oyment and contentment with SketchBoard. Its ability to generate visually appealing storyboard frames with coherent narratives offers opportunities for efficient storyboard creation, paving the way for future advancements in automated storyboard generation.},
  keywords={Industries;Visualization;Image synthesis;Games;Transforms;Transformers;Rendering (computer graphics);Real-time systems;Teamwork;Artificial intelligence;AI assisted content production;storyboard generation;creative process;game character design;generative AI},
  doi={10.1109/INDIN58382.2024.10774282},
  ISSN={2378-363X},
  month={Aug},}@INPROCEEDINGS{10969944,
  author={N, Neela and N, Manjunath T and R, Nishitha and Janavi, P and Bhat, Pratheeksha},
  booktitle={2025 International Conference on Computing for Sustainability and Intelligent Future (COMP-SIF)}, 
  title={Adoption of GenAI for Education Domain}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The rise of GenAI appears to be a turning point in the shaping of the education industry as it brings forth the ability for various civilisations throughout the globe to integrate different personalised forms of teaching and learning principles within themselves. For this purpose, the capabilities of GenAI in educational systems are demonstrated by implementing web-based application called EduFab Course Generator. As for the technologies that were applied for the development of the application, these were Next.js, React, and Tailwind CSS. AI materials for creating course materials are made available by the Gemini API, along with Drizzle for the AI Course Generator database management and Clerk for secure authentication management. According to scale requirements of the course, EduFab Course Generator enables users to teach new lessons and topics which also creates the scene for GenAI powered alternative curriculum innovations. To secure the user, Clerk simplifies user management while making authentication detailed. To enrich and enhance the experience of the user at each point in time, the Gemini API develops various text formats like videos, exams, and vocational experience as learning materials for other courses. For securing the user's customized documents along with the user activity history, Drizzle supports flexible and type compliant backend database operations which enable and enhance end-user experience},
  keywords={Technological innovation;Databases;Education;Authentication;Learning (artificial intelligence);Production;Turning;Generators;Sustainable development;Videos;Generative AI;Education Domain;Personalized Learning;Full Stack Development;Artificial Intelligence (AI);Next.js;React;Tailwind CSS;Drizzle ORM;Secure User Authentication;Clerk;Gemini API;AI-Driven Course Material;Dynamic Curriculum Generation;Scalable Web Application;ELearning Platforms;Educational Technology;Interactive Learning Experience;Future of Learning Systems;AI in Education},
  doi={10.1109/COMP-SIF65618.2025.10969944},
  ISSN={},
  month={March},}@ARTICLE{10908560,
  author={Cui, Yuanhao and Cao, Xiaowen and Zhu, Guangxu and Nie, Jiali and Xu, Jie},
  journal={IEEE Communications Magazine}, 
  title={Edge Perception: Intelligent Wireless Sensing at Network Edge}, 
  year={2025},
  volume={63},
  number={3},
  pages={166-173},
  abstract={Future sixth-generation (6G) networks are envisioned to support intelligent applications across various vertical scenarios which have stringent requirements on high-precision sensing as well as ultra-low-latency data processing and decision making. Toward this end, a new paradigm of edge perception network emerges. This network integrates wireless sensing, communication, computation, and artificial intelligence (AI) capabilities at network edge for intelligent sensing and data processing. This article provides a timely overview on this emerging topic. We commence by discussing wireless edge perception, including physical layer transceiver design, network-wise cooperation, and application-specific data analytics, for which the prospects and challenges are emphasized. Next, we discuss the interplay between edge AI and wireless sensing in edge perception, and present various key techniques for two paradigms, namely edge AI empowered sensing and task-oriented sensing for edge AI, respectively. Finally, we emphasize interesting research directions on edge perception to motivate future works.},
  keywords={Wireless communication;Wireless sensor networks;Translation;Text summarization;Edge AI;Predictive models;Transformers;Question answering (information retrieval);Sensors;Artificial intelligence},
  doi={10.1109/MCOM.001.2300660},
  ISSN={1558-1896},
  month={March},}@INPROCEEDINGS{10910984,
  author={Shen, Weiguo and Xu, Dongwei and Xu, Xinjie and Chen, Zhuangzhi and Xuan, Qi and Wang, Wei and Lin, Yun and Yang, Xiaoniu},
  booktitle={2024 6th International Conference on Robotics, Intelligent Control and Artificial Intelligence (RICAI)}, 
  title={A simple data augmentation method for automatic modulation recognition via mixing signals}, 
  year={2024},
  volume={},
  number={},
  pages={219-229},
  abstract={Automatic Modulation Recognition(AMR) is crucial in cognitive radio, transitioning from traditional methods to deep learning-based classification. However, deep learning requires large datasets for effective training, making data augmentation vital for enhancing model generalization and accuracy. It helps to expand the dataset, thereby improving the models’ generalization ability and accuracy. We proposes a novel data augmentation approach for AMR task based on signal mixing, with four specific methods designed to improve the performance of Mixed Signals. The experimental results demonstrate that the proposed methods lead to a notable improvement in the classification accuracy of deep learning-based AMR models in diverse scenarios. Notably, experiments conducted with datasets at a single signal-to-noise ratio show a significant increase in classification accuracy, confirming the effectiveness of the signal mixing method.},
  keywords={Deep learning;Training;Solid modeling;Accuracy;Modulation;Data augmentation;Data models;Robustness;Robots;Signal to noise ratio;Automatic modulation recognition;Data augmentation;Mixing signals},
  doi={10.1109/RICAI64321.2024.10910984},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10932403,
  author={Neeraj and Nandal, Poonam},
  booktitle={2025 2nd International Conference on Computational Intelligence, Communication Technology and Networking (CICTN)}, 
  title={Continual Learning Techniques to Reduce Forgetting: A Comparative Study}, 
  year={2025},
  volume={},
  number={},
  pages={210-215},
  abstract={A key aspect of artificial intelligence is continual learning. The capacity of a model to incrementally learn from a new task and adapt to it without losing the previous knowledge. A fundamental challenge that comes to successful continual learning is catastrophic forgetting; while learning a new task the model forgets the previously learned tasks. Various approaches to mitigate forgetting and enhance continual learning have been discussed across benchmark datasets such as MNIST, CIFAR- 10, and Permuted MNIST. we focus mainly on replay, regularization, and modular architecture-based methods to prevent forgetting. Regularization methods penalize the significant change in parameters during the learning of new tasks while maintaining crucial parameters of previously completed tasks. Replay-based methods store samples of earlier tasks in explicit memory or generate pseudo-samples with the help of generative models. Modular architecture-based methods partition the neural architecture into task-specific modules to prevent interference between tasks, to effectively address catastrophic forgetting. This paper presents a comparative study of the key continual learning methods that reduce catastrophic forgetting. The findings demonstrate the trade-offs between different methods. We examine the efficiency and effectiveness of each method and propose a hybrid technique to prevent catastrophic forgetting. Our comparative analysis emphasizes the significance of choosing the best method depending on the specific requirement of the learning environment, the task complexity, and resource constraints.},
  keywords={Continuing education;Adaptation models;Interference;Computer architecture;Benchmark testing;Communications technology;Complexity theory;Artificial intelligence;Computational intelligence;artificial intelligence;continual learning;catastrophic forgetting},
  doi={10.1109/CICTN64563.2025.10932403},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{9098409,
  author={Mercan, C. and Mooij, G.C.A.M. and Tellez, D. and Lotz, J. and Weiss, N. and van Gerven, M. and Ciompi, F.},
  booktitle={2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)}, 
  title={Virtual Staining for Mitosis Detection in Breast Histopathology}, 
  year={2020},
  volume={},
  number={},
  pages={1770-1774},
  abstract={We propose a virtual staining methodology based on Generative Adversarial Networks to map histopathology images of breast cancer tissue from H&E stain to PHH3 and vice versa. We use the resulting synthetic images to build Convolutional Neural Networks (CNN) for automatic detection of mitotic figures, a strong prognostic biomarker used in routine breast cancer diagnosis and grading. We propose several scenarios, in which CNN trained with synthetically generated histopathology images perform on par with or even better than the same baseline model trained with real images. We discuss the potential of this application to scale the number of training samples without the need for manual annotations.},
  keywords={Gallium nitride;Feature extraction;Training;Convolution;Breast cancer;Generative adversarial networks;Image color analysis;Computational pathology;Generative Adversarial Networks;Mitosis detection;Breast cancer},
  doi={10.1109/ISBI45749.2020.9098409},
  ISSN={1945-8452},
  month={April},}@INPROCEEDINGS{9769851,
  author={Machín, Benjamín and Nesmachnow, Sergio and Toutouh, Jamal},
  booktitle={2021 IEEE Latin American Conference on Computational Intelligence (LA-CCI)}, 
  title={Evolutionary latent space search for driving human portrait generation}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={This article presents an evolutionary approach for synthetic human portraits generation based on the latent space exploration of a generative adversarial network. The idea is to produce different human face images very similar to a given target portrait. The approach applies StyleGAN2 for portrait generation and FaceNet for face similarity evaluation. The evolutionary search is based on exploring the real-coded latent space of StyleGAN2. The main results over both synthetic and real images indicate that the proposed approach generates accurate and diverse solutions, which represent realistic human portraits. The proposed research can contribute to improving the security of face recognition systems.},
  keywords={Landline;Face recognition;Conferences;Sociology;Generative adversarial networks;Robustness;Space exploration;generative adversarial networks;evolutionary algorithms;latent space exploration;human portraits generation},
  doi={10.1109/LA-CCI48322.2021.9769851},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9413823,
  author={Zhang, Libao and Liu, Yanan},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Image Generation Based on Texture Guided VAE-AGAN for Regions of Interest Detection in Remote Sensing Images}, 
  year={2021},
  volume={},
  number={},
  pages={2310-2314},
  abstract={Deep learning has shown great strength in regions of interest (ROIs) detection for remote sensing images (RSIs). However, for most of RSIs, the unbalanced distribution of positive and negative samples greatly limits the performance of the deep learning-based methods. To cope with this issue, we propose a novel method based on texture guided variational autoencoder-attention wise generative adversarial network (VAE-AGAN) to augment the training data for ROI detection. First, to generate realistic texture details of RSIs, we propose a texture guidance block to embed texture prior information into encoder and decoder networks. Second, we introduce the channel and spatial-wise attention layers in the discriminator construct to adaptively recalibrate the varying importance of different channels and spatial regions of input RSIs. Finally, we apply the RSI dataset balanced by our proposal to the weakly supervised ROI detection method. Experimental results demonstrate that the proposal can not only improve the performance of ROI detection, but also outperform other competing augmentation methods.},
  keywords={Learning systems;Deep learning;Image synthesis;Training data;Signal processing;Generative adversarial networks;Decoding;Image generation;texture guidance;attention;generative adversarial networks},
  doi={10.1109/ICASSP39728.2021.9413823},
  ISSN={2379-190X},
  month={June},}@INPROCEEDINGS{10653701,
  author={Hamza, Muhammad and Siemon, Dominik and Akbar, Muhammad Azeem and Rahman, Tahsinur},
  booktitle={2024 IEEE/ACM International Workshop on Software-Intensive Business (IWSiB)}, 
  title={Human-AI Collaboration in Software Engineering: Lessons Learned from a Hands-On Workshop}, 
  year={2024},
  volume={},
  number={},
  pages={7-14},
  abstract={This paper investigates the dynamics of human-AI collaboration in software engineering, focusing on the use of ChatGPT. Through a thematic analysis of a hands-on workshop in which 22 professional software engineers collaborated for three hours with ChatGPT, we explore the transition of AI from a mere tool to a collaborative partner. The study identifies key themes such as the evolving nature of human-AI interaction, the capabilities of AI in software engineering tasks, and the challenges and limitations of integrating AI in this domain. The findings show that while AI, particularly ChatGPT, improves the efficiency of code generation and optimization, human oversight remains crucial, especially in areas requiring complex problem-solving and security considerations. This research contributes to the theoretical understanding of human-AI collaboration in software engineering and provides practical insights for effectively integrating AI tools into development processes. It highlights the need for clear role allocation, effective communication, and balanced AI-human collaboration to realize the full potential of AI in software engineering.},
  keywords={Conferences;Collaboration;Chatbots;Software;Security;Resource management;Problem-solving;Generative AI;ChatGPT;Software Engineering;Workshop;Empirical Investigation},
  doi={10.1145/3643690.3648236},
  ISSN={},
  month={April},}@INPROCEEDINGS{10511616,
  author={Sharma, Vaishali and Singh, Neetu and Prasad, Rahul},
  booktitle={2024 11th International Conference on Signal Processing and Integrated Networks (SPIN)}, 
  title={Assessing YOLOv8 as a Classifier for Detection of Synthetically Generated Facial Imagery}, 
  year={2024},
  volume={},
  number={},
  pages={99-104},
  abstract={The literature has shown that facial recognition technology has been widely employed in diverse industries, such as consumer and security applications. It played a crucial role in enhancing consumer security measures, facilitating biometric identification processes, and elevating consumer experiences. However, the deployment of this technology also leads to significant privacy and ethical considerations that necessitate meticulous attention and regulation in operations. In recent years, You Only Look Once (YOLO) has also shown promising results as an image classifier. However, an in-depth analysis is required to explore the effectiveness of YOLOv8 in the classification of real and fake facial images. Hence, this research is to build an image classification framework employing the YOLOv8 architecture with the aim of efficiently differentiating between real and fake or synthetic (artificially generated) facial images. The methodology involves training the YOLOv8 model using a publicly accessible dataset containing both real and fake faces generated using generative artificial intelligence (AI). The dataset has been obtained from the Kaggle database, consisting of 140k real and fake images employing AI. The extensive series of experimental findings validates the efficacy of the model, with a notable training and testing accuracy of 99.35% and 98.2%, respectively. These significant results are obtained with training over 20 epochs with a minimal error rate of 0.0065. The aforementioned results are the best among standalone deep learning models trained using transfer learning, highlighting the practical efficiency and resilience of the proposed framework for discerning authentic and AI generated facial images, hence demonstrating its potential for use in diverse practical contexts.},
  keywords={Training;YOLO;Industries;Privacy;Transfer learning;Signal processing;Regulation;Artificial Intelligence;facial images;image forensics;transfer Learning;YOLO},
  doi={10.1109/SPIN60856.2024.10511616},
  ISSN={2688-769X},
  month={March},}@INPROCEEDINGS{10469630,
  author={Zhenyuan, Ma and Fei, Jiao and Fengda, Zhang and Jiannan, Xu},
  booktitle={2023 4th International Conference on Power Engineering (ICPE)}, 
  title={Synthetic Oil Chromatographic Sample Generation for Electric Power Transformer Based on Causal GAN}, 
  year={2023},
  volume={},
  number={},
  pages={44-49},
  abstract={Electric power transformer plays a vital role in ensuring the safe, reliable, and cost-effective electric power system. Researching on fault diagnosis related technology for electric power transformers to accurately identify fault types and characteristics holds immense importance for transformer maintenance and the development of appropriate maintenance strategies. However, in real practice, the lack of oil chromatographic data and the imbalanced percentage of fault case data currently impede the development of the electric power transformer health monitoring. In order to solve the problems, we introduce a generation method using GAN (Generative Adversarial Networks) model combining causal mechanism as conditions. We evaluate our proposed method on the quality of synthetic generated data and the accuracy of fault diagnosis comparing with real data. The results show that the proposed method learns from the data and aligned with real-world data but need further improvement.},
  keywords={Fault diagnosis;Power engineering;Oils;Oil insulation;Maintenance engineering;Generative adversarial networks;Power systems;oil chromatographic;synthetic data generation;electric power transformer;generative adversarial networks},
  doi={10.1109/ICPE59729.2023.10469630},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10808235,
  author={Narne, Venkatagopi and Chinta, Druthiksai and Kataru, Rushieswar and Kamepalli, Sujatha},
  booktitle={2024 First International Conference on Innovations in Communications, Electrical and Computer Engineering (ICICEC)}, 
  title={Advanced Deep Learning Approaches for Detecting Real and Fake Images}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={The rapid use of artificial intelligence has grown over the world. With this, a lot of AI-generated content is being created in the form of photographs, movies, and so on, leading to people being manipulated. Generative AI models are operating effectively and looks realistic to human sight, mostly in the name of generative fake images taking place with these generated images. Many people are experiencing troubles, so early detection of phony photos is required to stop all of these human concerns. This research aims to evaluate various deep-learning Models for detecting real or fake images using a global dataset. The evaluated deep learning models such as conditional generative adversarial networks(CGANs), RESNET 50, Siamese neural networks, Convolution neural networks (CNNs), deep belief networks (DBNs), and Generative Adversarial Networks(GANs). Finally, the study has found that conditional generative adversarial networks(CGANs) are the best model for detecting an image is real or fake, accomplishing an accuracy of 99.67 percentage on our dataset. These findings suggest that generative adversarial networks(CGAN) is helpful for detecting real or fake images. The outcomes of this research can provide a solid starting point for future studies focused on improving the deep learning models for the detection of real and fake images.},
  keywords={Deep learning;Technological innovation;Solid modeling;Accuracy;Generative AI;Neural networks;Solids;Motion pictures;Security;Reliability;DeepLearning;Siamese neural networks;RESNET 50;Real and Fake;CGANs;deep belief networks},
  doi={10.1109/ICICEC62498.2024.10808235},
  ISSN={},
  month={Oct},}
