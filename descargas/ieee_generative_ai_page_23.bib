@INPROCEEDINGS{8995444,
  author={Jin, Di and Li, Zhigang and Yang, Liang and He, Dongxiao and Jiao, Pengfei and Zhai, Lu},
  booktitle={2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Adversarial Capsule Learning for Network Embedding}, 
  year={2019},
  volume={},
  number={},
  pages={214-221},
  abstract={The purpose of network embedding is to learn a low-dimensional representation for each node in the network. One can then use this low-dimensional representation to solve some network analysis tasks, such as node classification and node clustering. At present, there are several network embedding learning methods based on GAN (Generative Adversarial Networks) to enhance the robustness of representations. However, these methods have two drawbacks. First, they are often too difficult to be trained stably. Second, they only learn the robust representations by matching the posterior distribution of the latent representations to the given priors. On the contrary, Capsule Networks can learn a more equivariant representation of images that is more robust to the changes in pose and spatial relationships of parts of objects in images. However, there is still no research using Capsule Network for network embedding since the social network is essentially different from images. For this problem, we propose a new approach of adversarial capsule learning (ACL) for network embedding, which is the first time to use Capsule Network in the network analysis tasks. To be specific, the new model consists of two parts, a generator and discriminator. We use Graph Convolutional Networks (GCN) as the generator to learn the embedding of nodes, and use Capsule Network as the discriminator to distinguish between the real and fake samples as accurately as possible. The experimental results demonstrate the effectiveness of the proposed new method.},
  keywords={Training;Learning systems;Deep learning;Graph convolutional networks;Social networking (online);Network analyzers;Generative adversarial networks;Linear programming;Generators;Robustness;Network Embedding;Generative Adversarial Networks (GAN);Capsule Networks;Graph Convolutional Networks;Deep Learning},
  doi={10.1109/ICTAI.2019.00038},
  ISSN={2375-0197},
  month={Nov},}@ARTICLE{8933156,
  author={Kasem, Hossam M. and Hung, Kwok-Wai and Jiang, Jianmin},
  journal={IEEE Access}, 
  title={Spatial Transformer Generative Adversarial Network for Robust Image Super-Resolution}, 
  year={2019},
  volume={7},
  number={},
  pages={182993-183009},
  abstract={Recently, there have been significant advances in image super-resolution based on generative adversarial networks (GANs) to achieve breakthroughs in generating more images with high subjective quality. However, there are remaining challenges needs to be met, such as simultaneously recovering the finer texture details for large upscaling factors and mitigating the geometric transformation effects. In this paper, we propose a novel robust super-resolution GAN (i.e. namely RSR-GAN) which can simultaneously perform both the geometric transformation and recovering the finer texture details. Specifically, since the performance of the generator depends on the discreminator, we propose a novel discriminator design by incorporating the spatial transformer module with residual learning to improve the discrimination of fake and true images through removing the geometric noise, in order to enhance the super-resolution of geometric corrected images. Finally, to further improve the perceptual quality, we introduce an additional DCT loss term into the existing loss function. Extensive experiments, measured by both PSNR and SSIM measurements, show that our proposed method achieves a high level of robustness against a number of geometric transformations, including rotation, translation, a combination of rotation and scaling effects, and a cobmination of rotaion, transalation and scaling effects. Benchmarked by the existing state-of-the-arts SR methods, our proposed delivers superior performances on a wide range of datasets which are publicly available and widely adopted across research communities.},
  keywords={Generators;Generative adversarial networks;Gallium nitride;Deep learning;Discrete cosine transforms;Super-resolution;generative adversarial networks;spatial transformer network;robust image super-resolution;robust generative adversarial network},
  doi={10.1109/ACCESS.2019.2959940},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10513308,
  author={Purwanto, Agus and Kusrini and Utami, Ema and Agustriawan, David},
  booktitle={2024 IEEE International Conference on Artificial Intelligence and Mechatronics Systems (AIMS)}, 
  title={A Comprehensive Literature Review on Generative Adversarial Networks (GANs) for AI Anime Image Generation}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This literature review explores the evolving landscape of Generative Adversarial Networks (GANs) tailored specifically for the generation of cartoon and anime-style images. The paper delves into the methodologies, advancements, challenges, and future prospects within this niche domain. Various GAN architectures, such as DCGAN, StyleGAN, and CycleGAN, are scrutinized for their efficacy in capturing and reproducing the nuanced aesthetics of cartoons and anime. The review navigates through challenges like stylistic coherence, structural integrity, and ethical considerations, including content ownership and potential misuse. Ethical implications, ranging from copyright concerns to content misuse, are discussed. The paper also highlights the myriad applications and potential trajectories stemming from GAN-based cartoon and anime image generation, spanning entertainment, character design, virtual reality, and artistic expression. In synthesizing existing research and probing into uncharted territories, this review contributes to the intersection of artificial intelligence and artistic expression, aiming to chart the current landscape, analyze challenges, and envision pathways for the advancement of GANs in generating high-fidelity, diverse, and aesthetically faithful cartoon and anime-style images.},
  keywords={Ethics;Reviews;Image synthesis;Bibliographies;Entertainment industry;Production;Coherence;Generative Adversarial Networks (Gans);Cartoon;Anime;Image Generation},
  doi={10.1109/AIMS61812.2024.10513308},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10823021,
  author={Xiao, Weiqiang},
  booktitle={2024 6th International Conference on Artificial Intelligence and Computer Applications (ICAICA)}, 
  title={Battery Life Prediction Model Based on Deep Learning}, 
  year={2024},
  volume={},
  number={},
  pages={326-329},
  abstract={We propose a an innovative battery life prediction method, CBA, which is based on generative adversarial network (GAN) framework. First, the paper extracts key features from the battery data and uses them as input to the model. Then, an improved gated convolution layer is designed, which integrates causal convolution into traditional gated convolution to extract the implicit information of features more efficiently. Following feature extraction, LSTM was estimated the initial battery life. To further refine the prediction accuracy, CNN was introduced to serve as a discriminator, evaluating the prediction outcomes produced by the LSTM. According to the feedback of the discriminator, the training parameters of the combination of LSTM and improved gated convolutional layer are constantly updated to generate higher quality data to train the discriminator's recognition ability. Through comparative experiments, the accuracy of this method in battery life prediction is verified. Furthermore, we conducted ablation experiments to assess how the enhanced gated convolutional layers impact the performance of generative adversarial networks in predicting time series data. The experimental findings indicate that the enhanced gated convolutional layer can effectively augment the performance of GAN in time series prediction, ultimately leading to a higher accuracy in lifetime prediction.},
  keywords={Training;Accuracy;Convolution;Time series analysis;Logic gates;Feature extraction;Generative adversarial networks;Batteries;Data mining;Long short term memory;life prediction;feature extraction;LSTM},
  doi={10.1109/ICAICA63239.2024.10823021},
  ISSN={2833-8413},
  month={Nov},}@INPROCEEDINGS{9395756,
  author={Bushra, S. Nikkath and Shobana, G.},
  booktitle={2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS)}, 
  title={Paediatric Sickle Cell Detection using Deep Learning - A Review}, 
  year={2021},
  volume={},
  number={},
  pages={177-183},
  abstract={Sickle Red blood cells (SRBC) are defective RBC cells due to aberration from regular disc shaped cells to irregular sickle shaped cells inherited from parents. The characteristics of majority RBC cells changes drastically in its nature by becoming gummy, rigid and crescent or C -shaped cells which makes it tough to traverse through very small blood capillaries and restricting the normal flow of blood by blocking or closing the blood vessels. The major function of RBC cell is to carry oxygen to other parts of the body without which a human cannot perform his routine activities. A red blood corpuscle (RBC) becomes Sickle RBC (SRBC), when the quantity of Haemoglobin A (HgbA), usually present in normal RBC cell, becomes less in quantity when compared to another substance called Haemoglobin S (HgbS), which is present abundantly in abnormal RBC cells, makes normal RBC cells to narrow down and sooner gets destroyed. Most of the normal RBC cells changes its structure and making a person anemic as a result of which it shows symptoms like shortness of breath, fatigue, severe pain throughout the body. Sickle cells are more prevalent among children of Africa, where majority of them born with flawed RBC patterns and even die due to this abnormality. This paper outlines about the various state-of-art deep learning models for early detection of sickle cells among children by classifying defective cells from normal cells and finding faulty image patterns of RBC cells in children by using most advanced neural network technique of Artificial Intelligence called Deep Learning. The digital image of a blood sample after pre-processing is given as an input to deep neural network to automatically identify the large population of sickle cell deficient children belonging to a particular geographic location where majority of children with sickle cell disease can be spotted out easily. According to American Society of Haematology (AHS), Sickle cells can be treated with gene editing therapy called CRISPR.},
  keywords={Deep learning;Red blood cells;Neural networks;Sociology;Cells (biology);Artificial intelligence;Statistics;Deep Learning;Artificial Neural Network;RBC Cell;Haemoglobin A;Haemoglobin B;CRISPR;Sickle red blood cell (SRBC)},
  doi={10.1109/ICAIS50930.2021.9395756},
  ISSN={},
  month={March},}@INPROCEEDINGS{9832049,
  author={Zeng, Yiqi and Xue, Dongchi},
  booktitle={2022 IEEE 2nd International Conference on Electronic Technology, Communication and Information (ICETCI)}, 
  title={An Overview of Generative Adversarial Networks}, 
  year={2022},
  volume={},
  number={},
  pages={550-552},
  abstract={Artificial intelligence is still the pervasive topic in the field of science and technology. Scientists have been thinking about how to rely on artificial intelligence to transform traditional industries into auto-industries which could significantly improve efficiency and reduce costs. Some researchers used to think that only humans could create images, text and voice and so on, through the GAN[l] model for sample study, however, AI could replace human beings to do all the art creation. Generating adversarial network (GAN) is a kind of neural network belonging to the category of unsupervised learning, which is suitable to solve the tasks of generating images from text, improving image resolution, drug matching and so on. This article would give an introduction of GAN, its structure, applications and some current drawbacks and issues.},
  keywords={Industries;Drugs;Image resolution;Costs;Neural networks;Transforms;Generative adversarial networks;Generating adversarial network;Structure;Applications;Drawbacks},
  doi={10.1109/ICETCI55101.2022.9832049},
  ISSN={},
  month={May},}@INPROCEEDINGS{10291329,
  author={Agarwal, Parul and Asif, Aisha and Parida, Shantipriya and Sekhar, Sambit and Dash, Satya Ranjan and Panda, Subhadarshi},
  booktitle={2023 1st International Conference on Circuits, Power and Intelligent Systems (CCPIS)}, 
  title={Generative Chatbot Adaptation for Odia Language: A Critical Evaluation}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={Large Language Models (LLMs) have gained significant attention in the field of Natural Language Processing (NLP) and Artificial Intelligence (AI) due to their ability to generate human-like text and facilitate conversational interactions. However, the majority of LLMs are majorly developed for English, limiting their accessibility and effectiveness for non-English speaking populations. In India, where only 10% of the population is proficient in English, the need for LLM models adapted to regional languages becomes crucial. This research paper focuses on the adaptability of LLMs to the Odia language, spoken by approximately 50 million people in India. With a primary objective to cater to the Odia-speaking community, we aim to evaluate existing LLM models such as ChatGPT, and Olive, an instruction following Odia LLM, specifically in the context of generating conversational outputs in Odia. We employ a critical evaluation approach to assess the performance, language understanding, and response generation capabilities of the LLM models for the Odia language. By conducting experiments and comparative analysis, we seek to determine the strengths, weaknesses, and potential areas of improvement for the existing LLM models. Our findings will contribute to the development of more effective and contextually accurate generative chatbots for the Odia language, enabling better communication and accessibility for the Odia-speaking population.},
  keywords={Adaptation models;Analytical models;Limiting;Sociology;Chatbots;Statistics;Integrated circuit modeling;Large Language Models (LLM);ChatGPT;Odia;Generative AI;Natural language Processing (NLP);OdiaGenAI},
  doi={10.1109/CCPIS59145.2023.10291329},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10674327,
  author={Zhang, Xu and Deng, Zhongliang and Zhang, Yao},
  booktitle={2024 IEEE 4th International Conference on Software Engineering and Artificial Intelligence (SEAI)}, 
  title={A Spatial-Channel Multi-Attention Parallel Network for Visible-Infrared Person Re-identification}, 
  year={2024},
  volume={},
  number={},
  pages={43-48},
  abstract={Visible-infrared person re-identification(VI-ReID) aims to narrow the image differences between different modalities to achieve cross-device, full-time retrieval of pedestrians. Due to the differences in imaging principles, VI-ReID needs to overcome significant modal differences. Therefore, this paper proposes an innovative multi-attention parallel network. The model extracts feature from the two dimensions of space-channel through the attention mechanism, and aggregates high- and low-level features. This makes the global features retain multilevel and multidimensional common features, and narrows the feature differences between modalities. Then, the global features are mined by block, and multiple spatial-channel local attention modules are used to simultaneously explore local features in different positions, mining specific features and improving the discrimination of features. At the same time, the aligned local features are used to narrow the feature dislocation caused by the change of person posture. Comprehensive experiments show that the proposed model performs well on the SYSU-MM01 dataset, with Rank-1 reaching 76.35% and map reaching 78.23%.},
  keywords={Training;Pedestrians;Attention mechanisms;Aggregates;Imaging;Learning (artificial intelligence);Feature extraction;VI-ReID;attention mechanism;modal differences},
  doi={10.1109/SEAI62072.2024.10674327},
  ISSN={},
  month={June},}@INPROCEEDINGS{10742729,
  author={Tyagi, Manisha},
  booktitle={2024 First International Conference on Technological Innovations and Advance Computing (TIACOMP)}, 
  title={Exploring the Potency of Neural Networks: A Thorough Examination of Deep Learning Techniques}, 
  year={2024},
  volume={},
  number={},
  pages={327-332},
  abstract={Deep learning stands as a revolutionary paradigm in artificial intelligence (AI), demonstrating its prowess across diverse areas, such as image recognition, natural language processing, and autonomous systems. This review article offers a comprehensive exploration of various deep learning techniques, shedding light on their distinctive features, applications, and recent advancements. From classic architectures to cutting-edge innovations, we delve into the diverse landscape of neural networks that have reshaped the field of artificial intelligence.},
  keywords={Deep learning;Technological innovation;Image recognition;Reviews;Navigation;Neural networks;Computer architecture;Propulsion;Natural language processing;Artificial intelligence;Deep Learning;Artificial Intelligence;Natural Language Processing;Attention;Transfer Learning},
  doi={10.1109/TIACOMP64125.2024.00061},
  ISSN={},
  month={June},}@INPROCEEDINGS{11021219,
  author={Aspra, Nico O. and Chong, Chien Hwa},
  booktitle={2025 Systems and Information Engineering Design Symposium (SIEDS)}, 
  title={Developing an AI-Driven NC Programming Assistant: A Productive Failure Approach in CNC Education}, 
  year={2025},
  volume={},
  number={},
  pages={438-443},
  abstract={The integration of artificial intelligence (AI) into engineering and technology education offers new possibilities for enhancing student learning and feedback delivery. In machining, where accuracy and logic are essential, AI can serve as a powerful support tool. This paper presents the NC Programming Assistant, an application that combines rule-based logic and generative AI to help students write and debug numerical control (NC) programs. The assistant provides real-time, context-specific feedback on errors such as syntax issues and safety violations, enabling students to revise their work and strengthen their programming skills. Grounded in the Productive Failure Model, the assistant is designed not only to correct errors but also to encourage learners to engage in trial, failure, and reflection. The tool was deployed in a machining course, where its impact was evaluated through surveys, usage data, and statistical analysis. Results showed improvements in student confidence, debugging ability, and comprehension. By providing immediate and personalized feedback, the assistant addresses common instructional challenges in technical education and demonstrates how theory-informed AI tools can enhance learning outcomes in skill-based disciplines.},
  keywords={Generative AI;Education;Debugging;Machining;Learning (artificial intelligence);Syntactics;Reflection;Logic;Time factors;Programming profession;Artificial intelligence;Education;CNC Programming;Productive Failure},
  doi={10.1109/SIEDS65500.2025.11021219},
  ISSN={2994-3531},
  month={May},}@INPROCEEDINGS{10892969,
  author={Mason, Sharon and Borasi, Raffaella and Miller, David and Vaughan-Brogan, Patricia and Han, Yu Jung and DeAngelis, Karen},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Avoiding ‘Sinking the Boat’ While not ‘Missing the Boat’: K-12 Leaders' Early-on Perspectives of AI Risks and Benefits and Their Implications for Developers}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This full research to practice paper reports on early perspectives from K-12 leaders regarding AI use in schools. With the advent of generative AI applications, K-12 leaders have a key role in providing (or precluding) access to students and teachers' uses of AI tools - as superintendents, principals and other district and school-level administrators will continue to be making (or at the very least informing) decisions about what AI tools will be made available as well as policies governing their use. These decisions will be informed by what K-12 leaders perceive are the potential risks and benefits of AI - as a key charge for K-12 leaders considering any innovation is to evaluate its potential to support student learning while reducing potentially harmful consequences. It is important to understand these current perceptions, especially for anyone designing applications of AI for K-12 education. While previous work has reported on teachers' views of AI, the perspectives of K-12 leaders, who serve as thought-leaders and decision makers, remain largely unexplored. U sing a semi-structured interview protocol, in late 2023, researchers interviewed 36 K-12 leaders across 23 districts in western New York state in order to gather their early perspectives regarding AI and to answer the research question: How do K-12 leaders perceive the risks and opportunities associated with using artificial intelligence in their school environments? Participants included superintendents, principals and various district and school-level administrators as well as some teacher leaders. These K-12 leaders articulated risks that can be categorized by four themes: (a) concerns regarding the ethical use of AI by both students and teachers (including cheating), (b) concerns around privacy and cybersecurity, (c) concerns around the accuracy or legitimacy of the output from AI systems and (d) concerns about replacing people/jobs. At the same time, these K-12 leaders recognized several important opportunities presented by AI, which should also be taken into consideration when making decisions, including (a) preparing students for the future, (b) improving potential for learning and instructional development and (c) supporting K-12 educators. Collectively, these risks and opportunities can be characterized with the idea that K-12 leaders were aware of the need to balance the risks in order to not “sink the boat” while also using care to not delay actions and potentially “miss the boat,” and which represents a more nuanced view of risk, consistent with what has been identified in the entrepreneurship literature. This work has implications for deliberate and informed decision-making regarding policies for and use of AI in the K-12 domain, and the supports needed for their adoption and effective use. The findings also provide valuable insights for developers of domain specific AI systems for K-12 schools. As computer scientists and engineers continue to train models, develop and select algorithms to serve schools, learners and educators, considering the risks and opportunities articulated by K-12 thought leaders and decision makers can support their work in advancing the technologies and potentially improving adoption.},
  keywords={Technological innovation;Privacy;Ethics;Protocols;Generative AI;Boats;Entrepreneurship;Delays;Artificial intelligence;Interviews;artificial intelligence;K-12 leaders;K-12 schools},
  doi={10.1109/FIE61694.2024.10892969},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10814858,
  author={Sun, Jiaqin and Kwong, Chiew-Foong and Buticchi, Giampaolo},
  booktitle={2024 IEEE 11th International Conference on E-Learning in Industrial Electronics (ICELIE)}, 
  title={The Potential of AI in Electrical and Electronic Engineering Education: A Review}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The rapid advancement of Artificial Intelligence (AI) technologies is transforming education, particularly in Electrical and Electronic Engineering (EEE). This paper explores the potential applications, benefits, and challenges of Generative AI (GenAI) and Large Language Models (LLMs) in EEE education. Key areas include personalized learning, intelligent tutoring systems, automated grading, and predictive analytics. While these technologies offer significant enhancements in teaching and learning, they also present challenges such as data privacy, bias, and the need for human interaction. By examining current implementations and providing recommendations, this paper aims to guide educators and researchers in effectively integrating AI to improve EEE education.},
  keywords={Industrial electronics;Electric potential;Data privacy;Electronic learning;Reviews;Generative AI;Large language models;Education;Predictive analytics;Electronics engineering education},
  doi={10.1109/ICELIE62250.2024.10814858},
  ISSN={2997-7282},
  month={Nov},}@ARTICLE{10494544,
  author={Vice, Jordan and Akhtar, Naveed and Hartley, Richard and Mian, Ajmal},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={BAGM: A Backdoor Attack for Manipulating Text-to-Image Generative Models}, 
  year={2024},
  volume={19},
  number={},
  pages={4865-4880},
  abstract={The rise in popularity of text-to-image generative artificial intelligence (AI) has attracted widespread public interest. We demonstrate that this technology can be attacked to generate content that subtly manipulates its users. We propose a Backdoor Attack on text-to-image Generative Models (BAGM), which upon triggering, infuses the generated images with manipulative details that are naturally blended in the content. Our attack is the first to target three popular text-to-image generative models across three stages of the generative process by modifying the behaviour of the embedded tokenizer, the language model or the image generative model. Based on the penetration level, BAGM takes the form of a suite of attacks that are referred to as surface, shallow and deep attacks in this article. Given the existing gap within this domain, we also contribute a comprehensive set of quantitative metrics designed specifically for assessing the effectiveness of backdoor attacks on text-to-image models. The efficacy of BAGM is established by attacking state-of-the-art generative models, using a marketing scenario as the target domain. To that end, we contribute a dataset of branded product images. Our embedded backdoors increase the bias towards the target outputs by more than five times the usual, without compromising the model robustness or the generated content utility. By exposing generative AI’s vulnerabilities, we encourage researchers to tackle these challenges and practitioners to exercise caution when using pre-trained models. Relevant code and input prompts can be found at https://github.com/JJ-Vice/BAGM, and the dataset is available at: https://ieee-dataport.org/documents/marketable-foods-mf-dataset},
  keywords={Pipelines;Mathematical models;Computational modeling;Image synthesis;Generative AI;Linear programming;Trojan horses;Generative artificial intelligence;generative models;text-to-image generation;backdoor attacks;Trojan;stable diffusion},
  doi={10.1109/TIFS.2024.3386058},
  ISSN={1556-6021},
  month={},}@INPROCEEDINGS{9263181,
  author={Sinaga, Marshal Anjona and Stefanus, Lim Yohanes},
  booktitle={2020 International Conference on Advanced Computer Science and Information Systems (ICACSIS)}, 
  title={Least Square Adversarial Autoencoder}, 
  year={2020},
  volume={},
  number={},
  pages={33-40},
  abstract={This research introduces least square adversarial autoencoder (LSAA)-an autoencoder that is able to reconstruct data and also generate data that has characteristics similar to data distribution from the prior distribution LSAA uses least square generative adversarial network loss function on its discriminator. LSAA minimizes Pearson χ2 divergence between the latent variable distribution and the prior distribution. In this research, a Python program is developed to model LSAA by utilizing MNIST data set and FashionMNIST data set. The program is implemented using PyTarch. All of the programming activities are carried out in the cloud environment provided by the Tokopedia-Universitas Indonesia AI Center, using DGR-1 (GPU Tesla V100) as its computing resource. The experimental results show that the mean squared error of LSAA for MNIST data set and FasbionMNIST data set are 0.0080 and 0.0099, respectively. Furthermore, the Fréchet Inception Distance score of LSAA for MNIST data set and FashionMNIST data set are 11.1280 and 27.5737, respectively. These results indicate that the least square adversarial autoencoder is able to reconstruct the image properly and also able to generate images similar to the training samples.},
  keywords={Computational modeling;Graphics processing units;Generative adversarial networks;Data models;Artificial intelligence;Image reconstruction;Python;artificial neural network;autoencoder;least square generative adversarial network;regularization;generative model},
  doi={10.1109/ICACSIS51025.2020.9263181},
  ISSN={2330-4588},
  month={Oct},}@ARTICLE{10194986,
  author={Liu, Yunfan and Li, Qi and Deng, Qiyao and Sun, Zhenan and Yang, Ming-Hsuan},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={GAN-Based Facial Attribute Manipulation}, 
  year={2023},
  volume={45},
  number={12},
  pages={14590-14610},
  abstract={Facial Attribute Manipulation (FAM) aims to aesthetically modify a given face image to render desired attributes, which has received significant attention due to its broad practical applications ranging from digital entertainment to biometric forensics. In the last decade, with the remarkable success of Generative Adversarial Networks (GANs) in synthesizing realistic images, numerous GAN-based models have been proposed to solve FAM with various problem formulation approaches and guiding information representations. This paper presents a comprehensive survey of GAN-based FAM methods with a focus on summarizing their principal motivations and technical details. The main contents of this survey include: (i) an introduction to the research background and basic concepts related to FAM, (ii) a systematic review of GAN-based FAM methods in three main categories, and (iii) an in-depth discussion of important properties of FAM methods, open issues, and future research directions. This survey not only builds a good starting point for researchers new to this field but also serves as a reference for the vision community.},
  keywords={Faces;Facial features;Face recognition;Semantics;Surveys;Generators;Generative adversarial networks;Generative adversarial networks;image translation;facial attribute manipulation},
  doi={10.1109/TPAMI.2023.3298868},
  ISSN={1939-3539},
  month={Dec},}@ARTICLE{10167807,
  author={Lyu, Yueming and Jiang, Yue and He, Ziwen and Peng, Bo and Liu, Yunfan and Dong, Jing},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={3D-Aware Adversarial Makeup Generation for Facial Privacy Protection}, 
  year={2023},
  volume={45},
  number={11},
  pages={13438-13453},
  abstract={The privacy and security of face data on social media are facing unprecedented challenges as it is vulnerable to unauthorized access and identification. A common practice for solving this problem is to modify the original data so that it could be protected from being recognized by malicious face recognition (FR) systems. However, such “adversarial examples” obtained by existing methods usually suffer from low transferability and poor image quality, which severely limits the application of these methods in real-world scenarios. In this paper, we propose a 3D-Aware Adversarial Makeup Generation GAN (3DAM-GAN). which aims to improve the quality and transferability of synthetic makeup for identity information concealing. Specifically, a UV-based generator consisting of a novel Makeup Adjustment Module (MAM) and Makeup Transfer Module (MTM) is designed to render realistic and robust makeup with the aid of symmetric characteristics of human faces. Moreover, a makeup attack mechanism with an ensemble training strategy is proposed to boost the transferability of black-box models. Extensive experiment results on several benchmark datasets demonstrate that 3DAM-GAN could effectively protect faces against various FR models, including both publicly available state-of-the-art models and commercial face verification APIs, such as Face++, Baidu, and Aliyun.},
  keywords={Faces;Face recognition;Three-dimensional displays;Closed box;Privacy;Solid modeling;Social networking (online);Black-box attack;face recognition;generative adversarial networks;makeup transfer;privacy protection},
  doi={10.1109/TPAMI.2023.3290175},
  ISSN={1939-3539},
  month={Nov},}@ARTICLE{11131398,
  author={Whatmough, Paul N.},
  journal={IEEE Solid-State Circuits Magazine}, 
  title={Generative Artificial Intelligence on Edge Devices: Models, Hardware, and Systems: A tutorial}, 
  year={2025},
  volume={17},
  number={3},
  pages={32-37},
  abstract={Generative artificial intelligence (GenAI) refers to the use of neural networks to produce new output data, which could be in the form of text, image, audio, video, or other modalities. During training, these models learn the underlying distributions of the data such that, during inference, they can generate new output data in response to an input prompt (typically a text prompt). In recent years, we have witnessed a staggeringly rapid progression in capability and sophistication of these generative models, following a major boom in investment in AI research during the 2020s. This article provides a brief tutorial on GenAI for edge devices, as a summary of the tutorial of the same name given at the International Solid State Circuits Conference (ISSCC) this year.},
  keywords={Training;Generative AI;Neural networks;Tutorials;Hardware;Data models;Solid state circuits;Integrated circuit modeling;Testing;Investment},
  doi={10.1109/MSSC.2025.3579704},
  ISSN={1943-0590},
  month={Summer},}@ARTICLE{9296950,
  author={Zhou, Yi and Wang, Boyang and He, Xiaodong and Cui, Shanshan and Shao, Ling},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={DR-GAN: Conditional Generative Adversarial Network for Fine-Grained Lesion Synthesis on Diabetic Retinopathy Images}, 
  year={2022},
  volume={26},
  number={1},
  pages={56-66},
  abstract={Diabetic retinopathy (DR) is a complication of diabetes that severely affects eyes. It can be graded into five levels of severity according to international protocol. However, optimizing a grading model to have strong generalizability requires a large amount of balanced training data, which is difficult to collect, particularly for the high severity levels. Typical data augmentation methods, including random flipping and rotation, cannot generate data with high diversity. In this paper, we propose a diabetic retinopathy generative adversarial network (DR-GAN) to synthesize high-resolution fundus images which can be manipulated with arbitrary grading and lesion information. Thus, large-scale generated data can be used for more meaningful augmentation to train a DR grading and lesion segmentation model. The proposed retina generator is conditioned on the structural and lesion masks, as well as adaptive grading vectors sampled from the latent grading space, which can be adopted to control the synthesized grading severity. Moreover, a multi-scale spatial and channel attention module is devised to improve the generation ability to synthesize small details. Multi-scale discriminators are designed to operate from large to small receptive fields, and joint adversarial losses are adopted to optimize the whole network in an end-to-end manner. With extensive experiments evaluated on the EyePACS dataset connected to Kaggle, as well as the FGADR dataset, we validate the effectiveness of our method, which can both synthesize highly realistic ($1280 \times 1280$) controllable fundus images and contribute to the DR grading task.},
  keywords={Lesions;Generators;Retina;Gallium nitride;Generative adversarial networks;Image synthesis;Image segmentation;Diabetic retinopathy;image synthesis;generative adversarial networks},
  doi={10.1109/JBHI.2020.3045475},
  ISSN={2168-2208},
  month={Jan},}@INPROCEEDINGS{9327061,
  author={Cai, Zhuohao and Yang, Yi and Lin, Lan},
  booktitle={2020 Chinese Automation Congress (CAC)}, 
  title={Human action recognition and art interaction based on convolutional neural network}, 
  year={2020},
  volume={},
  number={},
  pages={6112-6116},
  abstract={Although great efforts and progress have been made in human action classification, there are still some problems that have not been completely solved. In addition, the application of artificial intelligence in art has become a major trend, the development of this field is slow, the research of the art interaction technology has great research value in the field of artificial intelligence. Based on convolutional neural network(CNN), this paper studies the human behavior detection algorithm and its interactive key technology in the art field. Through the important frame extraction, joint point optimization, and the improved bottom-up algorithm, the detection effect is improved. At the same time, a new neural network is designed, which is composed of separable multi branch network and style generation network. Firstly, the human skeleton is identified efficiently and the behavior is judged accurately, then Generative Adversarial Networks(GAN) generate the style AI picture based on this. Through cross validation on MPII data set, Kinect data set and the Martial arts data set, the accuracy can reach 93%, which shows the model effect is very good. In addition, the further interactive application of unity3d is used, which can make virtual characters and follow the change of detection situation effectively. Our work provide the foundation for the future research of AI art field.},
  keywords={Art;Streaming media;Real-time systems;Computer vision;Computational modeling;Training;Convolutional neural networks;human action;CNN;GNN;unity3d},
  doi={10.1109/CAC51589.2020.9327061},
  ISSN={2688-0938},
  month={Nov},}@INPROCEEDINGS{8451788,
  author={Halici, Eren and Aydin Alatan, A.},
  booktitle={2018 25th IEEE International Conference on Image Processing (ICIP)}, 
  title={Object Localization Without Bounding Box Information Using Generative Adversarial Reinforcement Learning}, 
  year={2018},
  volume={},
  number={},
  pages={3728-3732},
  abstract={Object localization can be defined as the task of finding the bounding boxes of objects in a scene. Most of the state-of-the-art approaches utilize meticulously handcrafted training datasets. In this work, we are aiming to create a generative adversarial reinforcement learning framework, which can work without having any explicit bounding box information. Instead of relying on bounding boxes, our framework uses tightly cropped object images as training data. Our image localization framework consists of two parts: a reinforcement learning agent (RL agent) and a discriminator. The RL agent takes input scenes and crops them with the objective of creating a tightly cropped object image. The discriminator tries to distinguish whether the image is generated by the RL agent or it comes from a tightly cropped object database. Experiments indicate that it is possible to achieve a promising localization performance without having explicit bounding box data. It can be concluded that generative adversarial reinforcement learning is an important tool in dealing with other learning problems where explicit input/output paired data is not available.},
  keywords={Agriculture;Learning (artificial intelligence);Automobiles;Training;Image databases;Measurement;Object Localization;Reinforcement Learning;Deep Learning;Generative Adversarial Networks;Generative Adversarial Reinforcement Learning},
  doi={10.1109/ICIP.2018.8451788},
  ISSN={2381-8549},
  month={Oct},}@ARTICLE{9664635,
  author={Gao, Yun and Liu, Xiaoyang and Xiang, Jiawei},
  journal={IEEE/ASME Transactions on Mechatronics}, 
  title={Fault Detection in Gears Using Fault Samples Enlarged by a Combination of Numerical Simulation and a Generative Adversarial Network}, 
  year={2022},
  volume={27},
  number={5},
  pages={3798-3805},
  abstract={It is inevitable for gear to become damaged, which has a profound effect on the performance of gear transmission systems. Solving the problem of gear fault detection using artificial intelligence models depends on sufficient fault samples, though they might not always exist. A new method using numerical simulation and a generative adversarial network (GAN) is proposed to enlarge fault samples for detecting faults in gears. First, to supplement the missing fault samples, numerical simulation is employed to obtain simulation fault samples. Then, simulation and measurement fault samples are input into the GAN to generate synthetic fault samples to enlarge the training samples. Finally, the simulation, measurement and related synthetic fault samples serve as typical classifiers, including convolutional neural network, recurrent neural network, and stacked autoencoder, while the test samples of unknown faults are finally detected. Three experimental groups are designed to classify gear faults. The average classification accuracy is 100, 98.83, and 97.64%, which confirms the feasibility and effectiveness of the method for detecting gear faults using incomplete fault samples. The idea presented herein is expected to apply in any type of mechanical system that has the corresponding well-constructed numerical simulation model.},
  keywords={Gears;Training;Generative adversarial networks;Finite element analysis;Numerical models;Artificial intelligence;Fault detection;Detection;generative adversarial network (GAN);gears;lack of fault samples;numerical simulation},
  doi={10.1109/TMECH.2021.3132459},
  ISSN={1941-014X},
  month={Oct},}@ARTICLE{10891637,
  author={Bovenzi, Giampaolo and Cerasuolo, Francesco and Ciuonzo, Domenico and Di Monda, Davide and Guarino, Idio and Montieri, Antonio and Persico, Valerio and Pescapé, Antonio},
  journal={IEEE Transactions on Network and Service Management}, 
  title={Mapping the Landscape of Generative AI in Network Monitoring and Management}, 
  year={2025},
  volume={22},
  number={3},
  pages={2441-2472},
  abstract={Generative Artificial Intelligence (GenAI) models such as LLMs, GPTs, and Diffusion Models have recently gained widespread attention from both the research and the industrial communities. This survey explores their application in network monitoring and management, focusing on prominent use cases, as well as challenges and opportunities. We discuss how network traffic generation and classification, network intrusion detection, networked system log analysis, and network digital assistance can benefit from the use of GenAI models. Additionally, we provide an overview of the available GenAI models, datasets for large-scale training phases, and platforms for the development of such models. Finally, we discuss research directions that potentially mitigate the roadblocks to the adoption of GenAI for network monitoring and management. Our investigation aims to map the current landscape and pave the way for future research in leveraging GenAI for network monitoring and management.},
  keywords={Surveys;Monitoring;Artificial intelligence;Stakeholders;Organizations;Data models;Training;Analytical models;Generative AI;Biological system modeling;Generative AI;networking;LLM;GPT;diffusion models;traffic classification;intrusion detection},
  doi={10.1109/TNSM.2025.3543022},
  ISSN={1932-4537},
  month={June},}@INPROCEEDINGS{11116041,
  author={Tee, Khek Heng and Hilmi Ismail, Zool},
  booktitle={2024 IEEE 10th International Conference on Underwater System Technology: Theory and Applications (USYS)}, 
  title={ROS Wrapper and ChatGPT for Robot Controlled System}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This project seeks to enhance Human Robot Interaction (HRI) by integrating Chat Generative Pre-Trained Transformer (ChatGPT), an advanced artificial intelligence (AI) technology, into the Pepper robot by utilizing robot operating system (ROS) Indigo and Python. The objective is to resolve the Pepper's limitations in built-in libraries for more significant and engaging interaction. The integration of ChatGPT is necessary since Pepper's current libraries make it difficult to communicate effectively, especially in open-ended conversations. Previous studies showcase Pepper's limitations in understanding human speech, successful integration of ChatGPT into the robots and the importance of HRI. The methodology includes creating a virtual environment using Oracle VM VirtualBox, installing ROS Indigo on Ubuntu 14.04 and utilizing ROS wrapper to enable smooth integration with ChatGPT. Both Python 2.7 and Python 3.7 code are developed and connected via rostopic. To adapt the system into a wide range of users with different backgrounds, the integration framework was tested in both Japanese and English. The results revealed that while there were minor challenges in English integration, changing to Japanese adaptation required necessities in identifying the complexities with Kanji recognition. The successful execution of motion tasks based on ChatGPT's output improved the engagement of the robot's responses. Future work will focus on enhancing its interactive capabilities and widen the language preference to further adapt into diverse user profiles.},
  keywords={Hands;Codes;Human-robot interaction;Virtual environments;Oral communication;Chatbots;Libraries;Artificial intelligence;Robots;Python;Human Robot Interaction;ChatGPT;Pepper robot;ROS Wrapper;Python},
  doi={10.1109/USYS62456.2024.11116041},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9904068,
  author={Song, Lanyu and He, Chunlin and Xu, Liming and Zheng, Bochuan},
  booktitle={2022 5th International Conference on Pattern Recognition and Artificial Intelligence (PRAI)}, 
  title={CapGAN: Medical Image Captioning with Clinical Style and Pathology Preservation Using Conditional Generative Adversarial Nets}, 
  year={2022},
  volume={},
  number={},
  pages={1023-1032},
  abstract={In the process of clinical diagnosis, radiologists are mainly to analyze the obtained medical images and yield corresponding disease diagnosis reports. In order to reduce workload and improve efficiency while generating high-quality diagnostic reports, we proposed a novel method to achieve medical image captioning based on conditional generative adversarial nets, in which language evaluator is introduced to align language styles. The proposed method consists of three modules, i.e., diagnostic report generator, discriminator and language style evaluator. Specially, diagnostic report generator which contains feature extraction, attention mechanism and report output modules is used to generate diagnostic reports which is desired to appropriate clinical reports. Then, RNN-based discriminator is used to determine the authenticity between the generated and true diagnostic report. Besides, language style evaluator is adopted to keep the style consistence between the generated and real diagnostic report. Additionally, we use reinforcement learning mechanism to yield high-quality diagnosis report and overcome discretization problem in adversarial training. Extensive experiments show that our proposed method gains significant improvement over other methods in medical image caption. Objectively, ours achieves average increments of 10.15% BLEU-1 and 13.06% BLEU-2 on Open-i. A similar trend can be found on LGK. Additionally, ours outperforms than other comparisons language style evaluation by clinical radiologists subjectively.},
  keywords={Training;Pathology;Reinforcement learning;Learning (artificial intelligence);Feature extraction;Market research;Generators;diagnostic report generation;language style;conditional generative adversarial networks;reinforcement learning},
  doi={10.1109/PRAI55851.2022.9904068},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{11131911,
  author={Borović, Franjo and Kovačić, Mateja and Aleksić-Maslać, Karmela},
  booktitle={2025 MIPRO 48th ICT and Electronics Convention}, 
  title={The Use of the Gen Ai Tool Brisk Teaching in the Educational Process and Its Impact on Student Motivation}, 
  year={2025},
  volume={},
  number={},
  pages={715-719},
  abstract={Generative AI tools provide great opportunities for personalizing and improving the education process. In this paper, we will analyze the Gen AI tool Brisk Teaching that we used in the courses Information and Communication Technologies (ICT) and E-Business in the academic year 24/25 at the Zagreb School of Economics and Management (ZSEM). After we recognized the weak points in the students' knowledge, we implemented chatbots to help students learn and provide professors with quick feedback on the progress of students. In the paper, we will examine the connection between students' activities in the use of GenAI tools and the results achieved in the knowledge test. The research shows that students are very satisfied with the implementation of the Brisk Teaching tool into the education process and believe it provides additional motivation for learning.},
  keywords={Surveys;Economics;Correlation;Accuracy;Generative AI;Education;Chatbots;Real-time systems;Information and communication technology;Artificial intelligence;artificial intelligence;generative AI tools;Brisk teaching;education;motivation;students},
  doi={10.1109/MIPRO65660.2025.11131911},
  ISSN={1847-3938},
  month={June},}@INPROCEEDINGS{10834386,
  author={Barmada, Bashar and Chitalia, Abha and Kabbar, Eltahir},
  booktitle={2024 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}, 
  title={Assessment Process in the Light of GenAI: Prohibiting Vs Endorsing}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Generative AI has become inevitable technology in the current era. Many businesses have started to rely on it in their daily activities. On the other hand, others are sceptical of allowing a full use of GenAI, especially in the academic sector, as it may jeopardise students achieving the learning outcomes. Many academic providers including ones in New Zealand give their staff the choice of either allow or deny the usage of GenAI in assessment work by their students. This paper analyses these two approaches (allowing or denying), their benefits, and drawbacks. It discusses the redesign of assessment requirements and the evaluation process of students’ work to guarantee the academic integrity of the submitted work and the achievement of learning outcomes. Two examples of assessment types that are commonly used in computing discipline are discussed in detail regarding both approaches: the report, which is considered to be prone to GenAI, and the practical project, which is considered to be more resilient to GenAI. The paper will help academic staff in their decision regarding the use of GenAI in assessment work and provide guidance through each approach to achieve the learning outcomes by students with the emphasis on academic integrity.},
  keywords={Hands;Law enforcement;Generative AI;Education;Learning (artificial intelligence);Reflection;Disruptive technologies;Business;academic integrity;generative artificial intelligence;vocational education},
  doi={10.1109/TALE62452.2024.10834386},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10911316,
  author={Han, Huiwen},
  booktitle={2024 6th International Conference on Robotics, Intelligent Control and Artificial Intelligence (RICAI)}, 
  title={Innovative Research on IoT Architecture and Robotic Operating Platforms: Applications of Large Language Models and Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={881-887},
  abstract={This paper introduces an innovative design for robotic operating platforms, underpinned by a transformative Internet of Things (IoT) architecture, seamlessly integrating cutting-edge technologies such as large language models (LLMs), generative AI, edge computing, and 5G networks. The proposed platform aims to elevate the intelligence and autonomy of IoT systems and robotics, enabling them to make real-time decisions and adapt dynamically to changing environments. Through a series of compelling case studies across industries including smart manufacturing, healthcare, and service sectors, this paper demonstrates the substantial potential of IoT-enabled robotics to optimize operational workflows, enhance productivity, and deliver innovative, scalable solutions. By emphasizing the roles of LLMs and generative AI, the research highlights how these technologies drive the evolution of intelligent robotics and IoT, shaping the future of industry-specific advancements. The findings not only showcase the transformative power of these technologies but also offer a forward-looking perspective on their broader societal and industrial implications, positioning them as catalysts for next-generation automation and technological convergence.},
  keywords={Industries;Service robots;Generative AI;Large language models;Computer architecture;Medical services;Real-time systems;Internet of Things;Robots;Smart manufacturing;IoT;robotic operating platform;large language model;generative AI;smart manufacturing;edge computing},
  doi={10.1109/RICAI64321.2024.10911316},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10900007,
  author={Fu, Zheng},
  booktitle={2024 4th International Conference on Artificial Intelligence, Robotics, and Communication (ICAIRC)}, 
  title={Research on Minecraft Image Generation Method Based on Denoising Diffusion Probabilistic Models}, 
  year={2024},
  volume={},
  number={},
  pages={901-904},
  abstract={Generative models have shown great potential in game image generation, especially for pixel-style games like Minecraft, where automatic content generation can significantly enhance the player experience. This paper investigates the application effects of unconditional DDPM, conditional DDPM, classifier-free DDPM, and guided DDPM in Minecraft image generation based on the Denoising Diffusion Probabilistic Model (DDPM). First, we trained an unconditional DDPM using over 3,000 images extracted from Minecraft videos to demonstrate its basic performance in terms of generation quality and detail retention. Subsequently, through comparative analysis, we found that classifier-free DDPM performed best in terms of detail richness and diversity, while guided DDPM was more suitable for generating consistent style content. Further evaluation of image generation effectiveness using the Fréchet Inception Distance (FID) indicates that classifier-free DDPM has a significant advantage in generation quality.},
  keywords={Image synthesis;Noise reduction;Loading;Layout;Games;Diffusion models;Artificial intelligence;Robots;Videos;Load modeling;Generative models;Pixel-style games;DDPM;Fréchet Inception Distance;Generation quality},
  doi={10.1109/ICAIRC64177.2024.10900007},
  ISSN={},
  month={Dec},}@ARTICLE{11152698,
  author={Xiao, Yong and Shi, Guangming and Zhang, Ping},
  journal={IEEE Communications Magazine}, 
  title={Toward Agentic AI Networking in 6G: A Generative Foundation Model-as-Agent Approach}, 
  year={2025},
  volume={63},
  number={9},
  pages={68-74},
  abstract={The promising potential of AI and network convergence in improving networking performance and enabling new service capabilities has recently attracted significant interest. Existing network AI solutions, while powerful, are mainly built based on the close-loop and passive learning framework, resulting in major limitations in autonomous solution finding and dynamic environmental adaptation. Agentic AI has recently been introduced as a promising solution to address the above limitations and pave the way for true, generally intelligent, and beneficial AI systems. The key idea is to create a networking ecosystem to support a diverse range of autonomous and embodied AI agents in fulfilling their goals. In this article, we focus on the novel challenges and requirements of agentic AI networking. We propose AgentNet, a novel framework for supporting interaction, collaborative learning, and knowledge transfer among AI agents. We introduce a general architectural framework of AgentNet and then propose a generative foundation model (GFM)-based implementation in which multiple GFM-as-agents have been created as an interactive knowledge-base to bootstrap the development of embodied AI agents according to different task requirements and environmental features. We consider two application scenarios, digital-twin-based industrial automation and metaverse-based infotainment system, to describe how to apply AgentNet for supporting efficient task-driven collaboration and interaction among AI agents.},
  keywords={6G mobile communication;Automation;Foundation models;Federated learning;Knowledge based systems;Ecosystems;Collaboration;Artificial intelligence;Knowledge transfer;Convergence},
  doi={10.1109/MCOM.001.2500005},
  ISSN={1558-1896},
  month={Sep.},}@INPROCEEDINGS{10496621,
  author={Hatami, Mahdieh and Chegini, Mehran},
  booktitle={2024 10th International Conference on Artificial Intelligence and Robotics (QICAR)}, 
  title={Enhancing Digital Content Accessibility for the Hearing Impaired through AI-Driven Visual Representations}, 
  year={2024},
  volume={},
  number={},
  pages={322-328},
  abstract={Ensuring inclusivity for individuals with hearing impairments is paramount in an increasingly digital world. This article explores an innovative solution that leverages artificial intelligence (AI) and machine learning to enhance content comprehension for this demographic. We present a system that utilizes deep learning models and natural language processing algorithms to convert spoken language into visual representations, including emojis and images. Our approach empowers the hearing impaired to access and interpret information more effectively by bridging the gap between audio-based content and visual cues. Extensive experiments and user studies confirm the system's effectiveness, significantly improving content understanding and engagement. This novel technology opens new avenues for independent and comprehensive comprehension of audio-based content by individuals with hearing impairments.},
  keywords={Deep learning;Visualization;Machine learning algorithms;Auditory system;Natural language processing;Iterative methods;Robots;Natural Language Processing;Deep Learning;Artificial Intelligence;Image Conversion;Voice-to-Emoji},
  doi={10.1109/QICAR61538.2024.10496621},
  ISSN={},
  month={Feb},}@ARTICLE{9122411,
  author={Wang, Min and Lu, Hancheng and Liu, Siqi and Zhu, Zuqing},
  journal={Journal of Lightwave Technology}, 
  title={How to Mislead AI-Assisted Network Automation in SD-IPoEONs: A Comparison Study of DRL- and GAN-Based Approaches}, 
  year={2020},
  volume={38},
  number={20},
  pages={5574-5585},
  abstract={Recently, the combination of artificial intelligence (AI) and software-defined networking (SDN) has attracted intensive research interests because it realizes and promotes AI-assisted network automation (AIaNA). Despite the initial successes of AIaNA, its vulnerabilities, i.e., the downside of the reduction of human involvement achieved by it, have not been carefully explored. In this work, we use software-defined IP over elastic optical networks (SD-IPoEONs) as the background, and study how to mislead the AIaNA system in them. Specifically, we target our attack on the deep neural network (DNN) based traffic predictor in the AIaNA system, and design an adversarial module (ADVM) that can craft and inject adversarial traffic samples adaptively to disturb its operation. We consider two approaches to design the ADVM, i.e., the deep reinforcement learning (DRL) based on deep deterministic policy gradient (DDPG), and the generative adversarial network (GAN) model. Our proposed ADVM can monitor and interact with a dynamic SD-IPoEON to train itself on-the-fly. This enables it to generate and inject adversarial samples in the most disturbing and hard-to-detect way and to severely affect the AIaNA's performance on multilayer service provisioning. Specifically, IP flows will be served incorrectly to result in unnecessary congestions/under-utilizations on lightpaths, and erroneous network reconfigurations will be invoked frequently. Simulation results confirm the effectiveness of our ADVM designs, and show that the GAN-based ADVM achieves better attack effects with smaller perturbation strength.},
  keywords={IP networks;Optical switches;Optical packet switching;Optical fiber networks;Artificial intelligence;Generative adversarial networks;Adversarial samples;artificial intelligence (ai);deep reinforcement learning (drl);generative adversarial network (gan);network automation;software-defined ip over elastic optical networks (sd-ipoeons)},
  doi={10.1109/JLT.2020.3003905},
  ISSN={1558-2213},
  month={Oct},}@INPROCEEDINGS{10053202,
  author={Masaoka, Kei and Sari, Irawati Nurmala and Du, Weiwei},
  booktitle={2022 23rd ACIS International Summer Virtual Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD-Summer)}, 
  title={Edge-enhanced GAN with Vanishing Points for Image Inpainting}, 
  year={2022},
  volume={},
  number={},
  pages={113-118},
  abstract={Reconstructing the damaged images with perspective views has an extensive range in the field of image inpainting. However, most existing methods generated inadequately realistic restored images. Accomplishing this problem, we propose an edge-enhanced image generation model considering viewpoints. Our method applies edge map information to guide image generation based on the perspective views of an image using vanishing points detection. Texture synthesis will be presented as post-processing to complete the remaining missing regions. Experiment shows that our approach can generate perspective images with convincing details, such as indoor and outdoor facades.},
  keywords={Image synthesis;Image edge detection;Generative adversarial networks;Image restoration;Artificial intelligence;Image reconstruction;Software engineering;image inpainting;gan;edge map;vanishing points},
  doi={10.1109/SNPD-Summer57817.2022.00027},
  ISSN={},
  month={July},}@INPROCEEDINGS{9797518,
  author={Sun, Maojun and Jiang, Anxing and Li, Zixiong},
  booktitle={2021 2nd International Conference on Artificial Intelligence and Computer Engineering (ICAICE)}, 
  title={Data Enhancement for Melanoma Classification}, 
  year={2021},
  volume={},
  number={},
  pages={149-155},
  abstract={Melanoma Classification is a popular question in computer vision, with numerous works are proposed. Recent works focus on Convolutional Neural Networks (CNN) in this task. However, the question of insufficient or unbalanced data has not been paid attention to. In this paper, we aim to solve this problem and improve the accuracy of the model. We first compare the effect of the data-enhancement and sampling method in the modeling and then use two types of CNN to construct the model. Finally, we use ensemble learning to try to balance and improve the prediction. Experiments on data enhancement show our method is capable of handling the unbalance dataset with 97.7% accuracy. Finally, our method has a great improvement on the task of Melanoma Classification, which is from 79.9% to 97.8% using unbias training data. Our model decreases the influence of data imbalance and achieves a satisfying performance without label bias.},
  keywords={Deep learning;Neural networks;Training data;Melanoma;Learning (artificial intelligence);Generative adversarial networks;Sampling methods;Melanoma Classification;Data Enhancement;ResNet;AlexNet;Ensemble Learning},
  doi={10.1109/ICAICE54393.2021.00037},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9644326,
  author={Chen, Shan-Ling and Shih, Kuang-Tsu and Chen, Homer H.},
  booktitle={2021 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)}, 
  title={Unsupervised Learning of 3D Object Reconstruction with Small Dataset}, 
  year={2021},
  volume={},
  number={},
  pages={54-59},
  abstract={We propose an unsupervised learning framework trained with a small dataset for 3D object reconstruction from a single image. Our method utilizes autoencoders to extract 3D knowledge from an image, a differentiable renderer to generate an image from a reconstructed 3D object, and GAN inversion to produce pseudo images with random viewpoints and lighting to enlarge the training dataset. Quantitative and qualitative experimental results prove that our approach can recover 3D shapes with small dataset as accurately as state-of-the-art networks with large dataset.},
  keywords={Training;Three-dimensional displays;Shape;Lighting;Virtual reality;Learning (artificial intelligence);Generative adversarial networks;3D object reconstruction;GAN inversion;data augmentation;unsupervised learning},
  doi={10.1109/AIVR52153.2021.00017},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10864210,
  author={Jiang, Tao and Cai, Qingsong and Jia, Ming and Cai, Xuanzhi},
  booktitle={2024 5th International Conference on Artificial Intelligence and Computer Engineering (ICAICE)}, 
  title={DAG-AVAE: Combining GAN with Adversarial VAE to Enhance Causal Structure Learning}, 
  year={2024},
  volume={},
  number={},
  pages={861-868},
  abstract={The task of uncovering the causal structure underlying observed data has garnered significant interest and posed considerable challenges in recent years. While various methods, such as constraint-based and score-based approaches, have been validated, they often exhibit limitations in terms of time efficiency and flexibility. For instance, certain causal structure learning methods, like NOTEARS, attempt to transform a discrete search problem into a continuous optimization problem. However, these algorithms are typically constrained by the assumption of linear relationships among variables. In this paper, we introduce a novel framework, DAG-AVAE, which integrates variational autoencoders (VAE) with adversarial generative networks. This framework represents a fresh and complementary approach to learning the causal structure of observed data through continuous optimization methods. Notably, it accommodates the presence of nonlinear relationships between variables and leverages the output Kullback-Leibler (KL) divergence as a feedback mechanism. This allows for the automatic adjustment of parameters, such as hidden variables within the VAE objective, during the model training process. This innovation addresses the common issue of low reconstruction quality often associated with posterior collapse in VAE structures. Experimental results on both generated and benchmark datasets demonstrate that the directed acyclic graph (DAG) reconstructed by DAG-AVAE shows significant improvements in evaluation metrics, including structure Hamming distance and true positive rate, when compared to existing methods.},
  keywords={Training;Directed acyclic graph;Technological innovation;Autoencoders;Optimization methods;Transforms;Benchmark testing;Generative adversarial networks;Search problems;Hamming distances;Causal Structure;Variational Autoencoder;Posterior Collapse;Generative Adversarial Network},
  doi={10.1109/ICAICE63571.2024.10864210},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11077516,
  author={Malcontento, Justin and Alampay, Raphael and Abu, Patricia Angela},
  booktitle={2025 6th International Conference on Artificial Intelligence, Robotics and Control (AIRC)}, 
  title={Practicality of Translation-Assisted Monocular Depth Estimation for Rainy Weather}, 
  year={2025},
  volume={},
  number={},
  pages={329-336},
  abstract={Most monocular depth estimation models face difficulties under rainy conditions, and need to be robust for advanced driver-assistance systems. To overcome such issues, proposed works include changes in model architecture, along with further training. In this paper, we demonstrate the independent handling of rainy conditions from depth prediction with the use of our new dataset: NSTRain. Along with the unaltered versions, three sets of images are made: rain-only, neural-style-transferonly, and both. Furthermore, multiple rainfall intensities are created for each scene in the applicable sets for further analysis. Each set is used to calibrate a general adversarial network (GAN) model, and image-to-image translation is used to make depth model inputs with ideal weather and environment. Compared to the images prior to translation, outputs from the various trained GAN models have shown average improvements of up to 3.52 % in mean absolute relative error, 13.75 % in mean squared relative error, and 6.14 % in root mean squared error.},
  keywords={Training;Translation;Rain;Depth measurement;Atmospheric modeling;Generative adversarial networks;Artificial intelligence;Robots;Faces;Meteorology;monocular depth estimation;rain;translation},
  doi={10.1109/AIRC64931.2025.11077516},
  ISSN={},
  month={May},}@INPROCEEDINGS{9185242,
  author={Singh, Rajhans and Garg, Ravi and Patel, Nital S. and Braun, Martin W.},
  booktitle={2020 31st Annual SEMI Advanced Semiconductor Manufacturing Conference (ASMC)}, 
  title={Generative Adversarial Networks for Synthetic Defect Generation in Assembly and Test Manufacturing}, 
  year={2020},
  volume={},
  number={},
  pages={1-5},
  abstract={Defect detection and classification is a critical step in any semiconductor manufacturing process. Most of the time it involves manual creation of defects which is time consuming and includes a high material and labor cost. In this paper we propose Artificial Intelligence-based synthetic defect generation techniques to augment the training image sets for Convolutional Neural Network (CNNs)-based defect detection and classification systems. Specifically, we use Generative Adversarial Networks (GANs) to create various modes of the defects which are difficult to create manually. Our results indicate that the output of our adapted GANs are images of realistic-looking defects for a wide variety of common manufacturing defects including foreign material, misplaced epoxy, scratches, and die chipping defects among others.},
  keywords={Gallium nitride;Generative adversarial networks;Training;Generators;Feature extraction;Visualization;Inspection;synthetic defect generation;generative adversarial networks;defect detection},
  doi={10.1109/ASMC49169.2020.9185242},
  ISSN={2376-6697},
  month={Aug},}@INPROCEEDINGS{9764177,
  author={Park, SeongUk and Lee, Seungeui and Kwak, Nojun},
  booktitle={2022 IEEE Radar Conference (RadarConf22)}, 
  title={Range-Doppler Map Augmentation by Generative Adversarial Network for Deep UAV Classification}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={In this paper, we report a data augmentation technique to alleviate the data shortage for UAV (Unmanned Aerial Vehi-cle) classification problem. The UAV classification problem is modeled on CNN (Deep Convolutional Neural Network), which is prevalent in artificial intelligence, and the training data consists of an RD (Range-Doppler) map of a FMCW (Frequency-Modulated Continuous-Wave) radar for a moving UAV. Getting more training data usually helps a deep CNN better generalize to test data or the real world. Therefore, we introduce a Generative Adversarial Network (GAN)-based data augmentation technique to generate synthetic RD maps used for training of UAV classifiers. By doing so, the UAV classifier was able to achieve better performance on the test dataset, especially when the classifier was trained on a smaller dataset.},
  keywords={Training;Training data;Radar;Performance gain;Autonomous aerial vehicles;Generative adversarial networks;Data models;UAV;classification;data augmentation;synthetic data;convolutional neural network;generative adversarial network;Range-Doppler;FMCW;radar},
  doi={10.1109/RadarConf2248738.2022.9764177},
  ISSN={},
  month={March},}@INPROCEEDINGS{10136664,
  author={Yao, Leethar and Lin, Bo-Yu and Ul Haq, Qazi Mazhar and Ul Islam, Ihtesham},
  booktitle={2023 3rd International Conference on Artificial Intelligence (ICAI)}, 
  title={Unsupervised Cross-Domain Adaptation through Mutual Mean Learning and GANs for Person Re-identification}, 
  year={2023},
  volume={},
  number={},
  pages={122-128},
  abstract={Unsupervised cross-domain adaptation is a challenging task for person re-identification due to the unavailability of target domain labels. Among existing methods, pseudo-Iabels-based methods have considerable performance but most of them use target domain data without labels which are challenging difficult for the target model to learn enough features. In this paper, we use generative based models that generate more target data. In cooperation with the generative model, a mutual learning model is used to transfer knowledge of one model to another model that ultimately improves overall model performance. Ex-tensive experiments are performed on Duke and Market datasets that significantly achieve improved performance in comparison to state-of-the-art methods.},
  keywords={Learning systems;Adaptation models;Image segmentation;Image recognition;Object detection;Learning (artificial intelligence);Generative adversarial networks;Person Re-Identification;generative adversarial network;unsupervised domain adaptation},
  doi={10.1109/ICAI58407.2023.10136664},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{9329612,
  author={Vijayamohanan, Jayakrishnan and Noakoasteen, Oameed and Gupta, Arjun and Martínez-Ramón, Manel and Christodoulou, Christos G.},
  booktitle={2020 IEEE International Symposium on Antennas and Propagation and North American Radio Science Meeting}, 
  title={On Antenna Q-factor Characterization with Generative Adversarial Networks}, 
  year={2020},
  volume={},
  number={},
  pages={1643-1644},
  abstract={This paper introduces a novel way to reproduce antennas with Q-factor within a pre-determined threshold using Generative Adversarial Networks (GAN), a class of artificial intelligence algorithm. Instead of optimizing the Q-factor using a conventional optimization techniques, a GAN is trained to learn the distribution on desirable parameter vectors of the antenna and its Q-factor as obtained from a full wave solver. The trained GAN is subsequently used to generate antenna parameters from the learned distribution with a predicted Q-factor. The predicted antenna parameters are imported to CST and simulated using the parameters generated by GAN and the Q-factors are analyzed. The results obtained provides an unique perspective to learning the correlation between antenna parameter distribution and its Q-factor. Simulation results are provided to explain this approach of reproducing antennas with a low Q-factor.},
  keywords={Q-factor;Correlation;Simulation;Meetings;Generative adversarial networks;Antennas;Optimization;Deep learning;Generative Adversarial Networks;Antenna miniaturization;Neural Nets;Antenna Q-factor},
  doi={10.1109/IEEECONF35879.2020.9329612},
  ISSN={1947-1491},
  month={July},}@INPROCEEDINGS{9957306,
  author={Seoni, Silvia and Salvi, Massimo and Matrone, Giulia and Meiburger, Kristen M.},
  booktitle={2022 IEEE International Ultrasonics Symposium (IUS)}, 
  title={Ultrasound Image Beamforming Optimization Using a Generative Adversarial Network}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  abstract={Recently, research has been focusing on the development of artificial intelligence ultrasound beamforming methods to improve the contrast and resolution of B-mode images. In this work, we propose an innovative beamforming domain transfer method using a generative adversarial network (GAN). The GAN takes as input a plane-wave (PW) delay and sum (DAS) image and generates an image as if it had been acquired using the focused modality and reconstructed with the filtered Delay Multiply and Sum (F-DMAS) beamforming technique. A Verasonics Vantage 256 system (L11-5v linear array) was used to acquire 560 (480 and 80 for train and test set, respectively) in-vivo musculoskeletal US images. Images were acquired on five muscles (gastrocnemius lateralis, gastrocnemius medialis, vastus lateralis, vastus medialis, and biceps) on both sides of 14 healthy volunteers (50% female). RF data were acquired both in plane-wave (PW) and focused mode and beamformed using the UltraSound ToolBox (USTB). The DAS beamforming method was employed for PW data, whereas the focused data were reconstructed using F-DMAS. Various dynamic ranges (dR) were employed to create the final 8-bit PW DAS images (dR = 55, 65, 75, 85 dB) while an automatic dR was employed to optimize focused F-DMAS images. A Pix2Pix GAN architecture was designed to formulate the task of beamforming as the translation from one domain (PW DAS image) to another (focused F-DMAS image). Our GAN employed a UNet as the generator and a 3-layer fully convolutional PatchGAN as the discriminator. The proposed GAN architecture shows promising results, generating a GAN image comparable to the F-DMAS image, i.e., in terms of SSIM (0.5183 ± 0.0437 and 0.5152± 0.0519 for GAN images vs DAS images and F-DMAS images vs DAS images). Overall, our GAN enhances image quality and simulates focused F-DMAS beamforming starting from a PW DAS image without needing to access the raw RF data, which is typically unavailable with clinical ultrasound devices.},
  keywords={Radio frequency;Ultrasonic imaging;Image resolution;Array signal processing;Muscles;Generative adversarial networks;Delays;ultrasound image enhancement;ultrasound beamforming;deep learning;generative adversarial networks;filtered delay multiply and sum beamforming},
  doi={10.1109/IUS54386.2022.9957306},
  ISSN={1948-5727},
  month={Oct},}@INPROCEEDINGS{10295610,
  author={Wei, Zixuan and Ma, Jingbo and Yang, Boyuan},
  booktitle={2023 CAA Symposium on Fault Detection, Supervision and Safety for Technical Processes (SAFEPROCESS)}, 
  title={TF-FDGAN: Unsupervised Bearing Fault Detection Based on Time-Frequency Transform and Generative Adversarial Networks}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={In modern industry, obtaining expert labels for bearing fault data is often difficult, which makes traditional detection methods (e.g., supervised learning) less effective and reduces the detection accuracy. Therefore, this paper proposes an unsupervised bearing fault detection based on Time-Frequency transform and generative adversarial networks (TF-FDGAN), which mainly consists of WGAN and izif encoder and uses the time-frequency map as input. The WGAN uses normal data for unsupervised learning to learn its distribution. Then, the izif structure is used to train the encoder to map the input image to space, and the loss function of the izif structure is used as an anomaly score to evaluate whether the input data is in normal working condition. The experimental results show that the method maintains high accuracy and stability in different datasets, and the detection accuracy is greatly improved compared with traditional unsupervised learning algorithms.},
  keywords={Industries;Employee welfare;Time-frequency analysis;Fault detection;Supervised learning;Transforms;Generative adversarial networks;GAN;Unsupervised learning;Fault detection;CWT},
  doi={10.1109/SAFEPROCESS58597.2023.10295610},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10978320,
  author={Banerjee, Bitan and Nimr, Ahmad and Fettweis, Gerhard},
  booktitle={2025 IEEE Wireless Communications and Networking Conference (WCNC)}, 
  title={Overcoming Hardware Limitations in Massive MIMO: A Generative AI Take}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Recent transition in mobile communication standards suggests massive multiple-input multiple-output (MIMO) to be an integral part of the foreseeable future. However, as antenna elements increase to hundreds in the fifth-generation (5G) and beyond, traditional signal processing methods become prone to significant hardware impairments compound from multiple chains, leading to a substantial performance degradation. This paper explores the effectiveness of generative artificial intelligence (AI) techniques in addressing these challenges within massive MIMO systems. For this purpose, the conditional generative adversarial network (CGAN), a special class of generative AI algorithms, is employed to enhance the accuracy of channel state information (CSI) estimation in a hardware-impaired transceiver setup. This problem is treated as an image-denoising task, where the noise is introduced by the hardware impairments and LS estimation error. Through simulations conducted across various antenna array sizes, the potential of generative AI to improve CSI estimation accuracy under hardware impairments is demon-strated. This highlights its capacity to address critical signal processing challenges in the next-generation wireless systems.},
  keywords={Accuracy;Generative AI;Array signal processing;Massive MIMO;Generative adversarial networks;Throughput;Hardware;Transceivers;Next generation networking;Antenna arrays;Massive MIMO;channel estimation;machine learning (ML);generative AI;conditional generative adversarial networks (CGAN)},
  doi={10.1109/WCNC61545.2025.10978320},
  ISSN={1558-2612},
  month={March},}@ARTICLE{4359332,
  author={Fujino, Akinori and Ueda, Naonori and Saito, Kazumi},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Semisupervised Learning for a Hybrid Generative/Discriminative Classifier based on the Maximum Entropy Principle}, 
  year={2008},
  volume={30},
  number={3},
  pages={424-437},
  abstract={This paper presents a method for designing semisupervised classifiers trained on labeled and unlabeled samples. We focus on a probabilistic semisupervised classifier design for multiclass and single-labeled classification problems and propose a hybrid approach that takes advantage of generative and discriminative approaches. In our approach, we first consider a generative model trained by using labeled samples and introduce a bias correction model, where these models belong to the same model family but have different parameters. Then, we construct a hybrid classifier by combining these models based on the maximum entropy principle. To enable us to apply our hybrid approach to text classification problems, we employed naive Bayes models as the generative and bias correction models. Our experimental results for four text data sets confirmed that the generalization ability of our hybrid classifier was much improved by using a large number of unlabeled samples for training when there were too few labeled samples to obtain good performance. We also confirmed that our hybrid approach significantly outperformed the generative and discriminative approaches when the performance of the generative and discriminative approaches was comparable. Moreover, we examined the performance of our hybrid classifier when the labeled and unlabeled data distributions were different.},
  keywords={Semisupervised learning;Hybrid power systems;Entropy;Hidden Markov models;Text categorization;Design methodology;Pattern recognition;Machine learning;Predictive models;Supervised learning;generative model;maximum entropy principle;bias correction;unlabeled samples;text classification;generative model;maximum entropy principle;bias correction;unlabeled samples;text classification},
  doi={10.1109/TPAMI.2007.70710},
  ISSN={1939-3539},
  month={March},}@ARTICLE{10508749,
  author={Kong, De-Hua and Cao, Jia-Ning and Zhang, Wen-Wei and Huang, Wen-Chi and He, Xiao-Yang and Liu, Lu and Xia, Ming-Yao},
  journal={IEEE Transactions on Antennas and Propagation}, 
  title={An AI Predictor: From Point Clouds to Scattered Far Fields for 3-D PEC Targets}, 
  year={2024},
  volume={72},
  number={6},
  pages={5179-5190},
  abstract={In this article, an artificial intelligence (AI) approach is proposed for the prediction of scattered far fields by 3-D perfect-electrical-conducting (PEC) targets. The conventional computational electromagnetic (CEM) methods are plagued by at least two issues. One is the mesh generation, and the other is the intensive or time-consuming solution of matrix equations which could be unbearable. Machine-learning (ML) methods provide a new perspective to tackle the problems by skipping the two steps. Point clouds can well describe the geometrical information of a radar target. Directly using the point cloud rather than the created mesh with the point data should be workable, so we will take the point cloud as the input of the neural network (NN). As for the output, we will let the NN extract a kind of inherent feature parameters (IFPs) that are distinctive to each target and independent of incident and scattering directions. The characteristic mode theory (CMT) is employed to acquire the IFPs for the generation of datasets. The scattered far-field can be readily computed using the IFPs when the incident and scattering directions are specified. We call the NN constructed to realize the function Electromagnetic PointNet (EMPN). Numerical examples show that the EMPN can achieve remarkable reductions in CPU time and even memory requirements. The proposed approach is convenient to run from the input of a point cloud file that may be obtained by using a cellphone with a depth camera to the output of scattered far-field or radar cross section (RCS).},
  keywords={Point cloud compression;Scattering;Feature extraction;Training;Convolutional neural networks;Surface waves;Radar cross-sections;Artificial intelligence (AI);characteristic mode theory (CMT);electromagnetic forward problem;inherent feature parameter (IFP);point cloud;scattered far-field},
  doi={10.1109/TAP.2024.3390615},
  ISSN={1558-2221},
  month={June},}@ARTICLE{10823390,
  author={Gonzalez de Dios, Oscar and Armingol Robles, Pablo and Roelens, Liesbeth and Muniz-Da-Costa, Alejandro and de Miguel, Ignacio and Duran Barroso, Ramon J. and Fernandez-Palacios, Juan Pedro},
  journal={Journal of Optical Communications and Networking}, 
  title={Automation of multi-layer multi-domain transport networks and the role of AI [Invited]}, 
  year={2025},
  volume={17},
  number={2},
  pages={A124-A133},
  abstract={With increasing demand for customized connectivity, transport networks must evolve towards autonomous and customer-driven network management. This paper presents a comprehensive overview of network autonomy and the challenges associated with evolving toward higher levels of autonomy. Moreover, various use cases of artificial intelligence in network automation in IP-over-DWDM transport networks are also analyzed, in particular related to traffic prediction, quality of transmission, anomaly detection, network planning, and proactive failure management. Additionally, the role of generative AI in network operation is explored. Central to our discussion is a proposed control architecture based on open and standard SDN APIs, which incorporates network slicing for multi-layer transport networks and enables real-time access to normalized data, facilitating autonomous network operation.},
  keywords={Autonomous networks;Artificial intelligence;Real-time systems;Planning;Resource management;Network slicing;Data analysis;Computer architecture;Telemetry;Scalability},
  doi={10.1364/JOCN.537463},
  ISSN={1943-0639},
  month={February},}@ARTICLE{10962250,
  author={Sheth, Amit and Khandelwal, Vedant and Roy, Kaushik and Pallagani, Vishal and Chakraborty, Megha},
  journal={IEEE Intelligent Systems}, 
  title={NeuroSymbolic Knowledge-Grounded Planning and Reasoning in Artificial Intelligence Systems}, 
  year={2025},
  volume={40},
  number={2},
  pages={27-34},
  abstract={Decision-support systems in AI-assisted health care require robust, interpretable, and user-centric processes that effectively handle natural language inputs. While large language models (LLMs) excel at generating coherent text, they struggle with complex reasoning and multistep planning tasks. In response, we propose a neurosymbolic framework that integrates LLMs with symbolic knowledge graphs, graph-based reasoners, and constraint-aware planning modules. This hybrid approach leverages LLMs for initial plan formulation while refining outcomes with structured, domain-specific representations that enforce safety standards, ensure regulatory compliance, and maintain logical consistency. Demonstrated through examples in health care and manufacturing, our method bridges the gap between unstructured language generation and formal reasoning, enhancing reliability in high-stakes applications and supporting dynamic, context-aware decision-making. The framework offers a scalable, trustworthy solution for complex, constraint-driven environments. By combining generative creativity with formal logic, our approach addresses the key limitations of LLMs, making it suitable for diverse, high-impact domains.},
  keywords={Natural languages;Medical services;Cognition;Regulation;Planning;Safety;Standards;Decision support systems;User centered design;Context awareness;Decision making},
  doi={10.1109/MIS.2025.3544943},
  ISSN={1941-1294},
  month={March},}@INPROCEEDINGS{10000726,
  author={Benaddi, Hafsa and Jouhari, Mohammed and Ibrahimi, Khalil and Benslimane, Abderrahim and Amhoud, El Mehdi},
  booktitle={GLOBECOM 2022 - 2022 IEEE Global Communications Conference}, 
  title={Adversarial Attacks Against IoT Networks using Conditional GAN based Learning}, 
  year={2022},
  volume={},
  number={},
  pages={2788-2793},
  abstract={During the last decade, the integration of artificial intelligence (AI) and the use of intrusion detection systems (IDSs) in the Internet of Things(IoT) networks have brought a new dimension to technological progress. Deep learning (DL) and machine learning (ML)-based IDS are vulnerable to adversarial perturbations. However, anomaly detection methods suffer from unbalanced and missing sample data, thus causing IDS training to be complicated. In this paper, we propose using conditional generative adversarial networks (cGANs) to enhance the training process by handling the unbalanced data and coping with the lack of specifics class samples, which may succeed in evading our Convolutional Neural Network-Long Short-Term Memory (CNNLSTM) based-IDS model. We evaluated our proposed IDS model before and after applying the adversarial training using the Bot-IoT dataset. Promising results showed that the accuracy of detecting Theft attacks could be increased by 40%. To the best of our knowledge, we are the first to suggest the combination of cGAN and CNNLSTM based-IDS system to enhance its performance.},
  keywords={Training;Deep learning;Perturbation methods;Intrusion detection;Telecommunication traffic;Generative adversarial networks;Robustness;Internet of Things;Network traffic;Deep Learning;Generative Adversarial Network;Intrusion Detection System;Cyberattacks},
  doi={10.1109/GLOBECOM48099.2022.10000726},
  ISSN={2576-6813},
  month={Dec},}@ARTICLE{10579547,
  author={Bariah, Lina and Debbah, Mérouane},
  journal={IEEE Wireless Communications}, 
  title={AI Embodiment Through 6G: Shaping the Future of AGI}, 
  year={2024},
  volume={31},
  number={5},
  pages={174-181},
  abstract={In the ever-evolving field of technologies, the emergence of artificial general intelligence (AGI), often referred as strong artificial intelligence (AI), stands as a breakthrough in the realm of machine intelligence, promising to witness a new era of capabilities and possibilities. In particular, AGI ventures into human-level cognition, and expands to thinking, reasoning, and awareness. This imminent evolution is envisioned to be manifested through the embodiment of AI machines, allowing machines to transcend their purely computational nature and interact with the world through the different senses. Accordingly, AI agents will be grounded in the physical environment, going through subjective experiences and acquiring the needed knowledge that will lead to understanding and cognition. In our article, we explore the path toward realizing the true vision of AGI through AI embodiment, where we dig into the different types of thinking required to achieve knowledge, and hence, cognition and understanding. Furthermore, we look through the evolution of generative AI models, and shed light on the limitations of auto-regression in large language models (LLMs), with the aim to answer the question: is sensory grounding (through 6G) necessary, and enough, to achieve understanding in LLMs? Finally, we identify the main pillars of AGI and unveil how 6G networks will orchestrate the development of AGI systems.},
  keywords={Artificial intelligence;Cognition;6G mobile communication;Grounding;Computational modeling;Decision making;Brain modeling},
  doi={10.1109/MWC.015.2300521},
  ISSN={1558-0687},
  month={October},}@INPROCEEDINGS{10603113,
  author={Ho, Pin-Chieh and Morsalin, S. M. Salahuddin and Wang, Szu-Hong and Sheu, Ming-Hwa},
  booktitle={2024 4th Interdisciplinary Conference on Electrics and Computer (INTCEC)}, 
  title={Integration of GAN Environmental Sound Filtering and the CNN Sound Recognition System}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={With the development of deep learning in artificial intelligence, many finished products for voice recognition applications are available, such as Shazam recognizes music tunes, Apple Siri, Google Home, Amazon Alexa, and so on, which rely on human voice to execute actions. The embedded systems perform to customize services by using human voices when recognizing. However, their recognition may be affected by environmental sound. This study seeks to employ the conditional generative adversarial network (CGAN) to eliminate noise and residual network 18 (ResNet-18) to increase recognition accuracy by incurring the background sound and removing noise. We have developed the Nvidia Jetson AGX-Xavier framework to integrate an adverse network with the residual network connecting an omnidirectional microphone. The goal is to denoise the background sound and increase the recognition accuracy in a real- time environment for IoT applications.},
  keywords={Virtual assistants;Computational modeling;Noise reduction;Speech recognition;Computer architecture;Generative adversarial networks;Human voice;conditional generative adversarial network;residual network;background sound denoising;sound recognition;AIoT applications},
  doi={10.1109/INTCEC61833.2024.10603113},
  ISSN={},
  month={June},}@ARTICLE{9552559,
  author={Peng, Jun and Zhou, Yiyi and Sun, Xiaoshuai and Cao, Liujuan and Wu, Yongjian and Huang, Feiyue and Ji, Rongrong},
  journal={IEEE Transactions on Multimedia}, 
  title={Knowledge-Driven Generative Adversarial Network for Text-to-Image Synthesis}, 
  year={2022},
  volume={24},
  number={},
  pages={4356-4366},
  abstract={Text-to-Image (T2I) synthesis is a challenging task that aims to convert natural language descriptions to real images. It remains an open problem mainly due to the diversity of text descriptions, which poses a huge obstacle in generating vivid and relevant images. Moreover, the existing evaluation metrics in T2I synthesis are mainly used to evaluate the visual quality of the generated images, while the semantic consistency between the two modalities is often ignored. To address these issues, we present a novel Knowledge-Driven Generative Adversarial Network, termed KD-GAN, and a new evaluation system, named Pseudo Turing Test (PTT for short). Concretely, KD-GAN takes a further step in imitating the behavior of human painting, i.e., drawing an image according to reference knowledge. The introduction of reference knowledge in KD-GAN not only improves the quality of the generated images but also enhances the semantic consistency between them and the input texts. In addition, KD-GAN can also greatly avoid some flaws against common sense during image generation, e.g., skiing in the blue sky. The proposed PTT is an important supplement to the existing evaluation system of T2I synthesis. It includes a set of pseudo-experts of different multimedia tasks to evaluate the semantic consistency between the given texts and the generated images. To validate the proposed KD-GAN, we conducted extensive experiments on two benchmark datasets, i.e., Caltech-UCSD Birds (CUB), and MS-COCO (COCO). The experimental results demonstrate that KD-GAN outperforms state-of-the-art methods on IS, FID, and the proposed PTT metrics.11The codes of KD-GAN are at [Online]. Available: https://github.com/pengjunn/KD-GAN and the codes and models of PTT are at [Online]. Available: https://github.com/pengjunn/PTT.},
  keywords={Visualization;Generative adversarial networks;Task analysis;Semantics;Measurement;Image synthesis;Feature extraction;Text-to-image;knowledge-driven;generative adversarial network;pseudo turing test},
  doi={10.1109/TMM.2021.3116416},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{11166046,
  author={Malik, Ibrahim and Diang’a, Lathifa Jaffer and Stynes, Paul and Pathak, Pramod and Sahni, Anu},
  booktitle={2025 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)}, 
  title={Leukemia Classification through Deep Learning Techniques and Generative AI}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Leukemia is a cancer originating in the bone marrow and leads to rapid proliferation of abnormal blood cells. The main objective of this study is to implement a Convolutional Neural Network (CNN) to detect and classify leukemia from microscopic cell images. The proposed framework combines a Generative Adversarial Network (GAN) that generates synthetic images of healthy cells to address class imbalance and training on a balanced leukemia dataset, with four different CNN architectures (InceptionV3, ResNet50, EfficientNetB3 and InceptionV4) - the effectiveness of this approach is validated on a Breast Cancer tumor dataset consisting of ultrasound images. Unlike prior studies that rely on standard augmentation, our approach incorporates synthetic image quality metrics (FID, IS, SSIM) to validate realism and structural fidelity.The results reveal GAN architecture achieving 16% higher performance on cell images compared to tumor images. Additionally, results obtained for each model were 76%, 80%, 75%, and 75% respectively, with RestNet50 attaining the best result. Obtained results underline potential contribution of deep learning in cancer detection and improving clinical outcomes through GAN-augmentation, addressing class imbalance effectively.},
  keywords={Deep learning;Training;Ultrasonic imaging;Generative AI;Leukemia;Computer architecture;Generative adversarial networks;Convolutional neural networks;Standards;Tumors;Leukemia Classification;Generative AI;Deep Learning;CNNs;GANs},
  doi={10.1109/ACDSA65407.2025.11166046},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10590337,
  author={Hamdi, Mohammed and Kim, Lewy D.},
  booktitle={2023 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={A Prompt-Based Approach for Software Development}, 
  year={2023},
  volume={},
  number={},
  pages={1612-1614},
  abstract={Generative Language-Based AI (Gen-LBAI) models have drawn significant interest in a wide range of fields including software engineering. There has been increasing interest in lever-aging Gen-LBAI models in various areas of software engineering for efficient software development. Successful adoption of AI models can save time by generating various types of software artifacts, which lets the developer focus on more critical and creative tasks. In this paper, we present a prompt-based approach for software development using an AI model. The approach presents a set of guidelines for designing prompts and discusses where and how AI models can be used in software development for improved efficiency. The approach is evaluated in a case study using ChatGPT-4 and compared with manual development. The evaluation shows that the approach increases 41% in efficiency compared to manual development.},
  keywords={Scientific computing;Computational modeling;Manuals;Software;Artificial intelligence;Task analysis;Computational intelligence;ChatGPT;generative artificial intelligence;prompt;software development},
  doi={10.1109/CSCI62032.2023.00267},
  ISSN={2769-5654},
  month={Dec},}@INPROCEEDINGS{10628898,
  author={Ding, Sherry and Raman, Veda},
  booktitle={2024 IEEE 12th International Conference on Healthcare Informatics (ICHI)}, 
  title={Harness the Power of Generative AI in Healthcare with Amazon AI/ML Services}, 
  year={2024},
  volume={},
  number={},
  pages={490-492},
  abstract={As a transformative and innovative technology, gen-erative AI enables us to solve really complex problems and re-imagine how we do things. There are big opportunities in how healthcare companies and organizations will use it to transform the whole industry and deliver amazing experience for their cus-tomers. As a leading cloud computing company with over twenty years innovation in machine learning (ML), AWS has developed a set of AI/ML services that allow healthcare companies and organizations to unleash the power of generative AI. In this paper, we will introduce AWS generative AI service stack, highlight some commonly used AWS AI/ML services in building generative AI applications for the healthcare field. We will discuss architectures of two popular applications in healthcare: chatbot and intelligent document processing (IDP), to showcase how different services work together in generative AI applications.},
  keywords={Cloud computing;Technological innovation;Generative AI;Medical services;Companies;Transforms;Machine learning;Generative AI;AWS AI/ML services;Chatbot;intelligent document processing (IDP)},
  doi={10.1109/ICHI61247.2024.00070},
  ISSN={2575-2634},
  month={June},}@ARTICLE{9296379,
  author={Fu, Yaru and Yang, Howard H. and Doan, Khai Nguyen and Liu, Chenxi and Wang, Xijun and Quek, Tony Q. S.},
  journal={IEEE Vehicular Technology Magazine}, 
  title={Effective Cache-Enabled Wireless Networks: An Artificial Intelligence- and Recommendation-Oriented Framework}, 
  year={2021},
  volume={16},
  number={1},
  pages={20-28},
  abstract={Caching at the network edge can significantly reduce users' perceived latency and relieve backhaul pressure, hence invigorating a new set of innovations toward latency-sensitive applications. Nevertheless, the efficacy of caching policies relies on the users' content preference to be 1) known a priori and 2) highly homogeneous, which is not always the case in the real world. In this article, we explore how artificial intelligence (AI) techniques and recommendation can be leveraged to address those core issues and reap the potentials of cache-enabled wireless networks. Specifically, we present the hierarchical, cache-enabled wireless network architecture, in which AI techniques and recommendation are utilized, respectively, to estimate users' content requests in real time using historical data and to reshape users' content preference. Through case studies, we further demonstrate the effectiveness of an AI-based predictor in estimating users' content requests as well as the superiority of joint recommendation and caching policies over conventional caching policies without recommendation.},
  keywords={Wireless networks;Artificial intelligence;Data collection;Device-to-device communication;Performance evaluation;Generative adversarial networks;Decision making;Real-time systems},
  doi={10.1109/MVT.2020.3033934},
  ISSN={1556-6080},
  month={March},}@INPROCEEDINGS{9631396,
  author={Xu, Mengdi and Cheng, Jiandong and Liu, Yirong and Huang, Wei},
  booktitle={2021 IEEE Symposium on Computers and Communications (ISCC)}, 
  title={DeepGAN: Generating Molecule for Drug Discovery Based on Generative Adversarial Network}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={As one of the most core links in the pharmaceutical industry, drug discovery is an important direction for the application of artificial intelligence technology. It is still a huge challenge to accelerate the discovery process. To address it, we have developed a generative model for de novo small-molecule based on Generative Adversarial Network algorithm called DeepGAN. It is worth mentioning that we make DeepSMILES as training object, which has avoided the limitations of SMILES. And the addition of reinforcement learning keeps away from non-differentiable problem of the discriminator. The model is trained to optimize the rewards and adversarial loss in specific areas through strategy gradient. In this way, DeepGAN compares favorably to ORGAN and its derivatives OR(W)GAN and Naive RL which have been already well-tested. The experiments indicate our model can create molecules which can maintain molecular diversity, increase validity and show improvement in the desired metrics.},
  keywords={Drugs;Training;Measurement;Industries;Computers;Computational modeling;Reinforcement learning;drug discovery;generative adversarial network;deepSMILES},
  doi={10.1109/ISCC53001.2021.9631396},
  ISSN={2642-7389},
  month={Sep.},}@INPROCEEDINGS{10742838,
  author={Yadav, Nitu and Sheoran, Savita Kumari},
  booktitle={2024 First International Conference on Technological Innovations and Advance Computing (TIACOMP)}, 
  title={The Role of Deep Learning in Attaining the Sustainable Development Goals}, 
  year={2024},
  volume={},
  number={},
  pages={437-443},
  abstract={The purpose of this study is to determine whether deep learning, a potent type of artificial intelligence (AI), can help achieve the Sustainable Development Goals (SDGs) set forth by the UN. We investigate the pervasive influence of deep learning across several industries and its potential to achieve the SDGs through a review of previous research and expert comments. To accomplish the three main goals of Zero Hunger (SDG 2), Good Health and Well-Being (SDG 3), and Climate Action (SDG 13), particular uses of deep learning approaches are highlighted. We analyse pertinent information and processes connected to these uses, illustrating how deep learning can be used to address issues with access to healthcare, food security, and climate change mitigation. The results demonstrate the potential of deep learning as a tool for sustainable development. We can hasten the transition to a sustainable future in line with the UN Sustainable Development Goals by putting deep learning solutions into practice with appropriate organisational control and ethical concern.},
  keywords={Climate change;Deep learning;Sustainable development;Artificial intelligence;Performance evaluation;Deep Learning;Sustainable Development Goals;Artificial Intelligence;SDG Implementation;Sustainable Development Impact},
  doi={10.1109/TIACOMP64125.2024.00079},
  ISSN={},
  month={June},}@INPROCEEDINGS{11158362,
  author={Zhang, Yibing and Hu, Zixin and Xin, Haiyang and Lan, Linling},
  booktitle={2025 5th International Conference on Artificial Intelligence and Education (ICAIE)}, 
  title={Empowering Knowledge Building Teachers' Lesson Planning by Agents}, 
  year={2025},
  volume={},
  number={},
  pages={75-79},
  abstract={This study explores the integration of Generative Artificial Intelligence (GAI) agents to empower Knowledge Building (KB) educators in lesson planning. It examines the challenges teachers face in adopting KB principles and the potential of GAI to enhance instructional design. A multi-agent system (MAS) tailored to KB was introduced, focusing on the development of a specialized knowledge base and prompt engineering to align with the “12 Principles.” An empirical study conducted in a Chinese elementary school highlighted the MAS's effectiveness in improving lesson planning efficiency and its alignment with KB pedagogy, while also identifying areas for further refinement. The findings suggest significant potential for GAI-supported lesson planning agents to enhance KB teaching practices.},
  keywords={Education;Knowledge based systems;Focusing;Chatbots;Planning;Prompt engineering;Faces;Multi-agent systems;Artificial Intelligence;Knowledge Building;ChatGPT;Agent;lesson planning;Instructional Design},
  doi={10.1109/ICAIE64856.2025.11158362},
  ISSN={},
  month={May},}@INPROCEEDINGS{10876935,
  author={Al-Shaikh, Mustafa S. and Al-Mousa, Mohammad Rasmi and Al-Ababneh, Hassan Ali and Ali, Mofeed Wild and Alkaawneh, Sabha Maria and Barhoush, Fawaz Mohd Salim and Binsaddig, Ruaa},
  booktitle={2024 25th International Arab Conference on Information Technology (ACIT)}, 
  title={The Challenges of Using Generative AI Applications in Electronic Commerce}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={There has been a lot of activity in recent months to monetize generative AI applications due to their growth in popularity across multiple sectors. Specifically, businesses with a digital direct-to-consumer (D2C) channel, (e.g. e-commerce websites, Instagram shops), are strategically investing in AI tools to improve consumer engagement, enhance marketing effectiveness, and invest in product development. Technology is undergoing a revolution thanks to generative AI, which creates highly personalized and realistic content automatically for a range of media. This study explores the panorama of generative AI applications in e-commerce; including task and technology classification, and maps the main challenges and concerns associated with generative AI applications in e-commerce, covering social, behavioral, and technical limitations.},
  keywords={Ethics;Video games;Systematics;Generative AI;Reviews;Publishing;Toy manufacturing industry;Electronic commerce;Web sites;Usability;Generative AI;E-commerce;AI applications;Direct-to-Consumer},
  doi={10.1109/ACIT62805.2024.10876935},
  ISSN={2831-4948},
  month={Dec},}@INPROCEEDINGS{10828792,
  author={Biswal, Sumitra},
  booktitle={2024 International Conference on Artificial Intelligence, Metaverse and Cybersecurity (ICAMAC)}, 
  title={SCOUT: Surveillance and Cyber harassment Observation of Unseen Threats}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Cyberbullying and cyber harassment pose significant challenges to mental health, with traditional detection methods often falling short, particularly in identifying subtle and passive-aggressive behaviors in textual communication. This research addresses these gaps by developing a Generative Artificial Intelligence (AI)-driven solution that enhances detection capabilities and captures the nuanced nature of cyber harassment across various platforms. Utilizing explainable AI techniques, this approach not only improves detection accuracy but also educates users on behavioral implications, supporting victims and legal authorities. The solution integrates with existing anti-harassment policies in academic institutions, workplaces, and social media environments to provide proactive and tailored interventions. To counter the potential misuse by abusers refining their harassment methods, the solution incorporates adaptive learning algorithms that continuously improve based on new data and detected evasion tactics. Regular audits and updates ensure the system evolves with emerging threats and remains resilient against misuse. This comprehensive approach aims to create safer online and offline spaces by addressing both unresolved and emerging issues in cyberbullying detection.},
  keywords={Training;Accuracy;Metaverse;Law;Surveillance;Refining;Cyberbullying;Mental health;Learning (artificial intelligence);Robustness;Cybercrime Investigation;Behavioral Information Security;Adaptive learning algorithms;Generative AI;Human Rights;Passive Aggression},
  doi={10.1109/ICAMAC62387.2024.10828792},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10908025,
  author={Hu, Ying and Lei, HaoPeng},
  booktitle={2024 International Symposium on Digital Home (ISDH)}, 
  title={CFADiff: A Diffusion Model-Based Approach to Cross-Domain Style Clothing Generation}, 
  year={2024},
  volume={},
  number={},
  pages={243-248},
  abstract={Artificial intelligence-driven digital technologies have profoundly transformed daily life. This paper explores an innovative task in the generation of fashion imagery utilizing advanced AI techniques. Specifically, the goal of this task is to generate novel fashion images by blending texture styles from non-fashion domain images with existing fashion content, offering designers a source of inspiration. Aiming at the problem that the style texture information in style reference images is difficult to define and extract, we proposes CFADiff, an unsupervised cross-domain fashion style clothing generation method based on the diffusion model. The method first uses denoising diffusion implicit model (DDIM) to forward encode the original clothing images to convey structural information, and utilizes deep features extracted by a large-scale self-supervised visual transformer (DINO-VIT) as a priori for style semantics. Finally, the stylistic texture and structural semantics in the reference image are decoupled in an explicit manner for guiding the reverse generation process. Experimental results show that CFADiff performs better in terms of structure preservation, stylistic texture performance, and quality of the generated images compared to the baseline methods compared.},
  keywords={Visualization;Clothing;Semantics;Noise reduction;Feature extraction;Transformers;Diffusion models;Data mining;Artificial intelligence;Diffusion model;Fashion synthesis;Artificial in-telligence},
  doi={10.1109/ISDH64927.2024.00047},
  ISSN={2769-8823},
  month={Nov},}@ARTICLE{8082803,
  author={Wang, Fei-Yue},
  journal={IEEE Intelligent Transportation Systems Magazine}, 
  title={Artificial Intelligence and Intelligent Transportation: Driving into the 3rd Axial Age with ITS}, 
  year={2017},
  volume={9},
  number={4},
  pages={6-9},
  abstract={Welcome to the inaugural issue of Artificial Intelligence Technologies for ITS section. I would like to open the section with a brief on the motivation for its introduction and the vision of its future.},
  keywords={Artificial intelligence;Intelligent vehicles;Social computing;Big Data;Smart grids;Knowledge engineering;Internet of Things},
  doi={10.1109/MITS.2017.2746407},
  ISSN={1941-1197},
  month={winter},}@ARTICLE{10528244,
  author={Xie, Gaochang and Xiong, Zehui and Zhang, Xinyuan and Xie, Renchao and Guo, Song and Guizani, Mohsen and Vincent Poor, H.},
  journal={IEEE Transactions on Wireless Communications}, 
  title={GAI-IoV: Bridging Generative AI and Vehicular Networks for Ubiquitous Edge Intelligence}, 
  year={2024},
  volume={23},
  number={10},
  pages={12799-12814},
  abstract={The growth of intelligent vehicular services, like augmented reality (AR) road simulation, underscores the need for rapid, multi-modal content generation. Generative artificial intelligence (GAI) models, known for their swift production of diverse artificial intelligence-generated content (AIGC), stand out as a prime solution. However, integrating cloud-centric GAI models into vehicular networks is fraught with challenges. Notably, to offer specialized generative edge intelligence (EI) and boost vehicular AIGC, GAI models need to tap into user data and utilize significant computation resources. Moreover, their deployment across vehicular networks is essential for proximity-based distributed inferences. Yet, edge devices are resource-limited, and data sharing can raise safety and privacy concerns. Addressing these challenges, this paper introduces GAI-IoV, an EI-enabled GAI framework facilitated through the cooperation between road-side units (RSUs) and vehicles. Subsequently, we propose the workflow for collaborative fine-tuning and distributed inference. On this basis, two pivotal vehicle-centric problems are then formulated: computation and communication resource allocation for federated fine-tuning (FFT) to optimize time and energy cost, and splitting strategy of shared and local inferences to optimize inference latency and content-generation capability. To solve these optimizations, we introduce a self-adaptive global best harmony search (SGHS) algorithm for resource allocation and a backward induction method for determining inference splitting strategy. Our experiments based on the Stable Diffusion v1-4 model vouch for a superior fine-tuning and inference capabilities of GAI-IoV. Furthermore, simulations underscore its resource utilization and distributed inference efficiency in dynamic vehicular scenarios.},
  keywords={Resource management;Computational modeling;Inference algorithms;Task analysis;Training;Systems architecture;Data privacy;Generative artificial intelligence (GAI);vehicular networks;edge intelligence (EI);fine-tuning;collaborative inference;resource allocation},
  doi={10.1109/TWC.2024.3396276},
  ISSN={1558-2248},
  month={Oct},}@INPROCEEDINGS{10334186,
  author={Singh, Hardeep and Kaur, Kamaljeet and Mohan Nahak, Fakira and Singh, Sandeep Kumar and Kumar, Sandeep},
  booktitle={2023 7th International Conference on Computation System and Information Technology for Sustainable Solutions (CSITSS)}, 
  title={Deepfake as an Artificial Intelligence tool for VFX Films}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Deepfake refers to the technique of replacing human bodies in movie scenes through the utilization of a method called Deepfake, which uses AI's (Artificial Intelligence) most recent advancements. Since we cannot see the reality of these shots, filmmakers use this as an opportunity to express their creativity. In order to advance VFX production, Deepfake is combined with AI. We have discussed the potential impact of Deepfake in future in this study. Students at a university were exposed to Deepfake footage and engaged in a questionnaire-based poll to learn more about the software's value for VFX. Additionally, the Deepfake approach, like Facial Landmarks, Voice Features, Body Movements, Background and Lighting that was employed in two films, has been elaborated. Results have shown that using AI's Deepfake technology improves the calibre of VFX film production and increases box office success.},
  keywords={Deepfakes;Films;Lighting;Production;Motion pictures;Software;Artificial intelligence;component;Deepfake;AI;VFX;Film production},
  doi={10.1109/CSITSS60515.2023.10334186},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9393172,
  author={Baloch, Sajid and Oayyum, Usman and Ahmed, Majeed and Sajid, Maryam and Javed, Hassan and Ahmed, Farrukh Aftab and Khoso, Shahzeb and Raza, Saad and Umair, Urooj and Amin, Zafar and Rehman, Atiq Ur},
  booktitle={2021 International Bhurban Conference on Applied Sciences and Technologies (IBCAST)}, 
  title={COVRAID: COVID-19 Rapid Artificial Intelligence Based Detection}, 
  year={2021},
  volume={},
  number={},
  pages={282-288},
  abstract={World has experienced a new potent challenge in the shape of Coronavirus disease 2019 (COVID-19). Rapid screening and detection of infected patients is important step in fighting against this disease, so that proper measures can be taken to stop it from further spreading. Majority of the countries who have been successful in controlling the disease, have done it through effective early detection. The same factor is very evident in the countries where COVID-19 has gone out of control that they were or are not successful in early detection of suspected patients. This paper presents an artificial intelligence-based approach to provide new screening approach to detect COVID-19 from X-ray images. More than thirty-five thousand local/international negative and positive corona X-ray images were obtained to train VGG-16 model. Proposed method has two classifiers, first classifier distinguishes between negative cases and other infected cases, second classifier identifies pneumonia and other infected cases. These other infected cases will be recognized as COVID-19. Experimental evaluation on different X-ray imaging were conducted where this method classified positive and negative cases very effectively. A comparative study with publicly available network such as COVID-NET is also carried out. Proposed method outperformed COVID-NET in all three major areas such as overall accuracy, sensitivity and specificity. Overall accuracy for our technique is 95.08%, while sensitivity and specificity values are 100% and 93.15% respectively, while overall accuracy, sensitivity, specificity values for COVID-NET are 52.36%, 86.79% and 27.39% respectively.},
  keywords={COVID-19;Sensitivity;Shape;Lung;Sensitivity and specificity;Artificial intelligence;X-ray imaging},
  doi={10.1109/IBCAST51254.2021.9393172},
  ISSN={2151-1411},
  month={Jan},}@INPROCEEDINGS{9124791,
  author={Zong, Lujie and Chen, Lianna},
  booktitle={2019 IEEE International Conference on Unmanned Systems and Artificial Intelligence (ICUSAI)}, 
  title={Single Image Super-Resolution Based on Self-Attention}, 
  year={2019},
  volume={},
  number={},
  pages={56-60},
  abstract={Single image super-resolution (SISR) is a challenging task and has collected extensive attention in both industry and academia. The most challenging problem in super-resolution is how to recover the finer texture details. And we find the generated images usually have low-scale contrast. In this paper, we present a novel super-resolution method based on generative adversarial networks (GAN). Our model is based on SRGAN, instead, we remove most of the batch normalization layers in generator to get higher-scale contrast images and accelerate training speed. Because batch normalization layers can get rid of range flexibility from networks, this causes the generated images have lower-scale contrast compared to the origin images. We also add the self-attention module into generator to get more global dependencies when convolution operations can capture enough local dependencies but little global dependencies. We take advantage of both local dependencies and global dependencies to improve super-resolved texture details and structural, we call our model SASRGAN. The images generated by our model have higher Structural Similarity Index Measure (SSIM), it proves that our model has available performance.},
  keywords={Training;Industries;PSNR;Convolution;Superresolution;Generative adversarial networks;Generators;super-resolution;generative adversarial networks;batch normalization;self-attention},
  doi={10.1109/ICUSAI47366.2019.9124791},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10403302,
  author={Wang, Jun and Lei, Bohan and Xu, Xiaoyin and Zhuang, Yueting and Zhang, Min},
  booktitle={2023 IEEE International Conference on Medical Artificial Intelligence (MedAI)}, 
  title={A Novel Conditional Medical Image Generation GAN with Latent Space Optimal Transport}, 
  year={2023},
  volume={},
  number={},
  pages={453-458},
  abstract={Generative adversarial network (GAN) is widely used to augment training set in medical imaging. However, training GANs can be challenging, as they are susceptible to mode collapse. These challenges stem from the fact that deep neural networks can only represent continuous mappings, while in GAN, the generator aims to compute discontinuous transportation maps between the noise distribution and the data distribution. We propose a novel approach that can overcome mode collapse, and in turn, lead to improved capability by GAN to generate specific classes of medical images. Our method starts by mapping the data manifold to the latent space using an autoencoder (AE). Subsequently, we encode the sample labels and integrate them with the latent representations. Next, we employ extended semi-discrete optimal transport (SDOT) mapping, which maps a Gaussian distribution to the empirical latent distribution, thereby generating new latent representations with known labels. Finally, we employ GAN to establish the mapping from the continuous latent distribution induced by the extended SDOT mapping to the real data distribution, generating high-quality images. We conducted extensive experiments on the DermaMNIST and BloodMNIST datasets. The experimental results highlight the exceptional performance of our model in generating images belonging to specified classes.},
  keywords={Training;Manifolds;Image synthesis;Transportation;Generative adversarial networks;Generators;Biomedical imaging;medical image generation;autoencoder;semi-discrete optimal transport;generative adversarial network;mode collapse},
  doi={10.1109/MedAI59581.2023.00067},
  ISSN={},
  month={Nov},}@ARTICLE{11059341,
  author={Chen, Jiusheng and Zha, Haoxiang and Guo, Runxia and Huang, Chao and Wu, Jun},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={An Enhanced Aircraft Fuselage Defect Detection Model with Hybrid Logical-Feature Distillation}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={Small defects result in the loss of essential information during defect detection, and enhancing the detection accuracy of these minor defects is a widely researched direction, especially in the development of detection network that achieve high accuracy while simultaneously maintaining low model complexity. To strike a balance between accuracy and efficiency, this paper introduces a high-efficiency aircraft fuselage defect detection model. Firstly, we restructured a teacher model consisting of parallel backbone with Aux_IoU. This redesign enhances the detection of small defects by improving the characterization capability of the feature extraction network and implementing fine-grained bounding boxes. Secondly, to decrease the complexity of teacher model while preserving high accuracy, we introduce a hybrid logical-feature distillation framework. The student model is trained to assimilate the teacher’s feature information and logits through mask generative distillation (MGD) and logical distillation, respectively. Finally, to validate the effectiveness of proposed network, we conducted experiments on Aircraft_Fuselage_DET2023 dataset. The experimental results reveal that our student model achieves enhancements of 8.3% and 2.7% over the baseline YOLOv8n on mAP50 and mAP50:95, respectively. Furthermore, it demonstrates improvements of 0.5% and 0.2% compared to the teacher model, while simultaneously reducing the number of parameters and computational complexity by 47.3% and 53.9%. In comparison to mainstream object detection algorithms, our model achieved superior performance.},
  keywords={Atmospheric modeling;Computational modeling;Accuracy;Feature extraction;Defect detection;Aircraft;Artificial intelligence;Real-time systems;Skin;Safety;Object detection;Aircraft fuselage defect detection;Knowledge distillation},
  doi={10.1109/TAI.2025.3584026},
  ISSN={2691-4581},
  month={},}@INPROCEEDINGS{10956298,
  author={Jayarekha, P and V, Nalina and Adhikari, Tanvi and Shrestha, Pooja and S, Varsha},
  booktitle={2024 Third International Conference on Artificial Intelligence, Computational Electronics and Communication System (AICECS)}, 
  title={PicMaker: A Text to Image Converter}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={PicMaker introduces a pioneering framework for generating images from text, focusing on the CUB (Caltech-UCSD Birds) dataset and the AttnGAN (Attention Generative Adversarial Network) model. By utilizing the detailed annotations and varied bird images in CUB, the framework excels in producing high-quality bird images based on textual descriptions. Tailoring AttnGAN specifically for the CUB dataset enhances image quality, coherence, and diversity significantly. Through extensive experimentation and evaluation, PicMaker proves its efficacy in creating lifelike bird images from text. The assessment comprises quantitative and qualitative analysis, comparing the generated images with ground truth images and existing futuristic methods to assess their standard and realism.},
  keywords={Visualization;Computational modeling;Text to image;Transforms;Birds;Generative adversarial networks;User experience;Usability;Standards;Signal to noise ratio;AttnGAN (Attention Generative Adversarial Network);CUB(Caltech-UCSD Birds);Generators;Discriminators;DAMSM(Deep Attentional Multimodal Similarity Model);PSNR(Peak Signal-to-Noise Ratio)},
  doi={10.1109/AICECS63354.2024.10956298},
  ISSN={},
  month={Dec},}@INBOOK{10982305,
  author={Bergeret, Olivier and Abbasi, Asif and Farvault, Joel},
  booktitle={GenAI on AWS: A Practical Approach to Building Generative AI Applications on AWS}, 
  title={Introduction to Foundation Models}, 
  year={2025},
  volume={},
  number={},
  pages={139-168},
  abstract={<p>Foundation models represent a significant evolution in the field of artificial intelligence (AI) and machine learning, offering transformative capabilities that extend across various applications and industries. This chapter delves into the concept of foundation models, their development, key characteristics, and the profound impact they are having on the AI landscape. Foundation models are typically very large in terms of the number of parameters, often featuring hundreds of billions or even trillions of parameters. This large scale allows them to capture rich representations of data. Text&#x2010;to&#x2010;image foundation models generate high&#x2010;quality images from textual descriptions. Foundation models facilitate tasks such as image and video analysis, object detection, and image generation. Their ability to process and understand visual data has opened up new possibilities in content creation. Training foundation models at the scale of billions or trillions of parameters requires staggering amounts of computational resources and energy consumption.</p>},
  keywords={Foundation models;Data models;Adaptation models;Training;Artificial intelligence;Computational modeling;Machine learning;Natural language processing;Self-supervised learning;Annotations},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394281305},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10982305},}@INPROCEEDINGS{10463284,
  author={Yoon, Junwon and Chung, Hyun-Joon and Kang, Jeon-Seong and Kim, Jung-Jun and Jeon, Kwang-Woo and Kim, SeungWoo and Shim, Myounghoon and Ryu, Jae-Kwan},
  booktitle={2024 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Enhancing GAN-Based Motion Data Augmentation Through Dynamic Time Warping Distance Filtering}, 
  year={2024},
  volume={},
  number={},
  pages={440-445},
  abstract={Motion capture data is crucial but creating a large dataset can be challenging due to complexities in acquisition. Generative Adversarial Network (GAN)-based motion data augmentation offers a potential solution to this issue. However, GANs often struggle with learning from limited data, resulting in poor quality output. In this study, we propose a Dynamic Time Warping (DTW) filtering method that filters out generated data significantly deviating from real-world examples. Through this approach, we have achieved an improvement in the fidelity of the generated data, even with dataset size constraints, as evidenced by an increase in action recognition accuracy.},
  keywords={Training;Filtering;Dynamics;Data augmentation;Generative adversarial networks;Motion capture;Complexity theory;data augmentation;generative adversarial network;dynamic time warping;motion capture},
  doi={10.1109/ICAIIC60209.2024.10463284},
  ISSN={2831-6983},
  month={Feb},}@INPROCEEDINGS{10799319,
  author={Wongsekleo, Prab and Nakpaen, Lapat and Cherntanomwong, Panarat and Pattiyanon, Charnon},
  booktitle={2024 19th International Joint Symposium on Artificial Intelligence and Natural Language Processing (iSAI-NLP)}, 
  title={Time Reduction for Collecting Fingerprint Data in Indoor Positioning Systems with Generated Synthetic Data by Ensemble Models and GANs}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Nowadays, the demand for IPS is growing due to the increasing need for accurate indoor location services in applications. The IPS fingerprint techniques are widely popular because they offer high accuracy. However, the process of collecting fingerprint data is labor-intensive and time-consuming. This study aims to alleviate the burden of data collection by generating synthetic data using Machine Learning (ML) and Generative Adversarial Networks (GANs). To create ML synthetic data, we used a dataset containing RSSI values and coordinates. Various regression models were trained using Randomized Search for hyperparameter tuning. The best models were then combined into an ensemble method using Voting Regressor. This ensemble model was used to predict RSSI values for new, synthetic coordinates generated around each reference point, forming the synthetic dataset. We combined synthetic data with actual data from the IPS fingerprint RSSI collecting from the mobile application to create three new datasets with varying ratios of actual to synthetic data from 90:10 to 10:90. These combined datasets were used to train models including Random Forest, Decision Tree, Linear Regression, Gradient Boosting, and K Nearest Neighbors. Our results indicate that models trained on combined datasets significantly reduce the mean distance error (MDE) compared to those trained solely on actual data. This improved performance, however, comes with trade-offs in terms of slightly increased training time, prediction time, and memory usage during both training and prediction phases.},
  keywords={Training;Accuracy;Computational modeling;Fingerprint recognition;Generative adversarial networks;Data models;IP networks;Random forests;Indoor positioning systems;Synthetic data;Indoor Positioning Systems (IPS);generating synthetic data;Machine Learning (ML);and Generative Adversarial Networks (GANs)},
  doi={10.1109/iSAI-NLP64410.2024.10799319},
  ISSN={2831-4565},
  month={Nov},}@INPROCEEDINGS{10911624,
  author={Liu, He},
  booktitle={2024 6th International Conference on Robotics, Intelligent Control and Artificial Intelligence (RICAI)}, 
  title={Enhancing Medical Image Super-Resolution with GANs and Residual Attention Mechanisms}, 
  year={2024},
  volume={},
  number={},
  pages={1336-1339},
  abstract={Medical image super-resolution is crucial for improving the quality of MRI scans, aiding better diagnosis and analysis. In this paper, we propose an enhanced super-resolution approach based on Generative Adversarial Networks (GANs) that incorporates residual attention mechanisms and perceptual loss functions to achieve high-quality image reconstruction. Specifically, we employ Squeeze-and-Excitation (SE) blocks within the generator network to improve feature learning and integrate perceptual and Structural Similarity Index Measure (SSIM) losses to enhance perceptual and structural quality. Experiments on the IXI MRI dataset demonstrate significant improvements over the baseline SRGAN, achieving a PSNR gain of 2.17 dB and an SSIM improvement of 0.062. Our approach effectively enhances visual fidelity and diagnostic relevance in reconstructed MRI images.},
  keywords={Visualization;Attention mechanisms;Magnetic resonance imaging;Superresolution;Generative adversarial networks;Feature extraction;Transformers;Loss measurement;Medical diagnostic imaging;Image reconstruction;Medical Image Super-Resolution;Generative Adversarial Networks (GANs);Magnetic Resonance Imaging (MRI);Deep Learning;Perceptual Loss},
  doi={10.1109/RICAI64321.2024.10911624},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11009874,
  author={Chen, Guoxiong and Pan, Junlong and Cai, Suxiong and Wen, Yun and She, Jiahong},
  booktitle={2025 2nd International Conference on Smart Grid and Artificial Intelligence (SGAI)}, 
  title={Image Inpainting Algorithms for Drone-Containing Images based on GAN Networks}, 
  year={2025},
  volume={},
  number={},
  pages={817-820},
  abstract={Image inpainting has become a crucial area in image processing, allowing for the automatic restoration of missing or damaged portions of images. This paper focuses on image inpainting techniques specifically for images containing drones. Using a Generative Adversarial Network (GAN)-based model, we propose a novel approach to restore drone images that may have missing sections due to occlusions, noise, or transmission errors. By leveraging the strengths of Variational Autoencoders (VAE) and GANs, our model learns to reconstruct the lost parts of the drone and its surrounding environment with high fidelity. The VAE captures the latent features of the drone, while the GAN enhances the realism of the generated image. We also incorporate an attention mechanism to ensure that fine details of the drone, such as propellers and body structure, are accurately restored. The proposed model is validated on a dataset of drone-containing images, showing significant improvements in inpainting quality compared to traditional methods.},
  keywords={Measurement;Image quality;Propellers;Noise;Generative adversarial networks;Image restoration;Smart grids;Faces;Image reconstruction;Drones;Image inpainting;Generative Adversarial Networks;Deep learning;Drones;VAE-GAN},
  doi={10.1109/SGAI64825.2025.11009874},
  ISSN={},
  month={March},}@INPROCEEDINGS{10920723,
  author={S, Vandana and Senthil, Sugavanam and Narasimhadhan, A. V.},
  booktitle={2025 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Exploring One-Shot GANs for Efficient Synthetic Flower Image Creation}, 
  year={2025},
  volume={},
  number={},
  pages={0986-0989},
  abstract={Generative Adversarial Networks (GANs) represent a cutting-edge advancement in deep learning, renowned for their capability to generate synthetic data across various domains including images, music, and text. This project focuses on implementing a one-shot GAN using Python and TensorFlow, aimed at providing a concise yet effective demonstration of GANs in action. The term ‘one-shot’ denotes that the model only has a few training inputs to learn from and make decisions. Through Python and TensorFlow, the project offers a hands-on exploration of GANs.},
  keywords={Training;Measurement;Deep learning;Image synthesis;Computational modeling;One shot learning;Computer architecture;Flowering plants;Generative adversarial networks;Synthetic data;Generative Adversarial Networks;One-shot learning;Deep Convolutional GANs;Synthetic Image Generation;Frechet Inception Distance;FID;DCGAN;Low-data GAN},
  doi={10.1109/ICAIIC64266.2025.10920723},
  ISSN={2831-6983},
  month={Feb},}@INPROCEEDINGS{10442154,
  author={Kucukler, Omer Faruk and Amira, Abbes and Malekmohamadi, Hossein},
  booktitle={2023 International Conference on Electrical, Communication and Computer Engineering (ICECCE)}, 
  title={Augmented EEG Signal Classification for Energy Data Visualizations}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Classification of electroencephalogram (EEG) data is dependent on data size, quality, and generalizability to decode invaluable information from brain-computer interface (BCI) systems. EEG data collection typically occurs within controlled laboratory environments using long sections. Participation in these experiments draws less attention due to the challenging nature of the EEG experiments and the intended objective. Hence, an approach that offers the potential for both cost and time efficiency is the use of artificial data generation. Data augmentation can improve the classification performance by increasing training data. This study employs a Generative Adversarial Network (GAN) model to enhance the empirically collected EEG dataset, which was introduced for the purpose of analyzing the perceptions of energy users regarding energy data visualizations. The data size is initially expanded through the use of a GAN model. Subsequently, the augmented data is assessed in terms of its classification performance. Three different sample groups—defined as male, female, and mixed—are shown in the results. Each group is used to generate synthetic EEGs, separately. To evaluate the enhanced EEG data, a scenario of transforming EEG data into spectrogram images and then classifying them using a Convolutional Neural Network (CNN) is used. The results show that the female sample group performed the best in terms of valence and arousal, with accuracies of 87.9% and 89.06%, respectively. This study shows promising results in terms of increasing EEG data size and improving classification performance.},
  keywords={Data visualization;Generative adversarial networks;Brain modeling;Electroencephalography;Data models;Brain-computer interfaces;Convolutional neural networks;Brain-computer interface;Data visualization;Energy;Electroencephalography;Generative Adversarial Network;Augmentation},
  doi={10.1109/ICECCE61019.2023.10442154},
  ISSN={},
  month={Dec},}@ARTICLE{10702528,
  author={Zabeehullah and Khan, Nauman Ali and Ud Din, Ikram and Almogren, Ahmad and Altameem, Ayman and Guizani, Mohsen},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={Secure and Efficient AI-SDN-Based Routing for Healthcare-Consumer Internet of Things}, 
  year={2025},
  volume={71},
  number={2},
  pages={6769-6776},
  abstract={The advancement of communication technologies and cloud systems has led to the emergence of the Healthcare-Consumer Internet of Things (H-CIoT) as a significant domain. This emergence has transformed the traditional healthcare system into the next generation of H-CIoT, characterized by higher connectivity and intelligence. Software-Defined Networking (SDN) is currently being incorporated into H-CIoT, enabling it to meet the complex, dynamic, and heterogeneous requirements of H-CIoT networks. As the H-CIoT network expands, there is an increasing demand for secure, efficient, and optimal routing to ensure low latency and high throughput. In this paper, we propose an Artificial Intelligence (AI)-based approach that combines the strengths of Generative Adversarial Networks (GANs) and Deep Reinforcement Learning (DRL) to accurately detect anomalies in H-CIoT imbalance data and achieve optimum routing. The DRL model dynamically formulates the optimal routing policies through efficient adaptation to underlying network traffic patterns. It also comprehends the characteristics of imbalance data to enhance its routing decisions. Simulation-based results validate the effectiveness and superiority of our proposed model over OSPF routing optimization technique in term of throughput (12%), latency (20%), and the Probability of avoiding malicious minor class attacks (30%), confirming it as an outstanding suitability for the next-generation H-CIoT network.},
  keywords={Routing;Data models;Security;Medical services;Internet of Things;Training;Quality of service;Optimization;Generative adversarial networks;Artificial intelligence;Artificial intelligence;healthcare-consumer Internet of Thing;software defined network;cloud computing;routing optimization;security},
  doi={10.1109/TCE.2024.3472071},
  ISSN={1558-4127},
  month={May},}@INPROCEEDINGS{10216492,
  author={Hoppe, Abigayle and Degny, Ehyo Marie and Siverson, Callie and Djarnie, Frank and Mahmoud, Mohammed},
  booktitle={2022 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={An Overview of Machine Learning in Biology}, 
  year={2022},
  volume={},
  number={},
  pages={609-612},
  abstract={There is a long history between Machine Learning and its application in Biology. Machine Learning has allowed many advancements in the field of Biology. This includes studies for prediction and discovery by different Machine Learning techniques for specified types of biological data. The versatility of techniques and frameworks has helped improve Machine Learning every day, and hopefully, this will help us improve and become more efficient on new things we discover and grow our database on biological data. In this paper, we will discuss the different applications of Machine Learning in Biology, i.e., Synthetic Gene Circuits, Convolutional Neural Networks, Recurrent Neural Networks and Generative Adversarial Networks. As the biological and medical fields have been quickly growing into a data-rich environment, Machine Learning has become a vital tool to sort through all of this data. The application of Machine Learning helps in two main facets. The first way is to help classify and predict tasks that a machine can quickly do. Secondly, it does not allow much human input, which will help minimize human bias or performance issues. Neural Networks go hand-in-hand with Deep Learning as they are one of its techniques. By utilizing Deep Learning and Neural Networks, we can expand our learning in Biology far more than ever before.},
  keywords={Deep learning;Recurrent neural networks;Scientific computing;Databases;Generative adversarial networks;Biology;History;Machine Learning (ML);Deep Learning (DL);Artificial Intelligence (AI);Biology;Synthetic Gene Circuits;Convolutional Neural Networks (CNNs);Recurrent Neural Networks (RNNs);Generative Adversarial Networks (GANs);Neural Networks},
  doi={10.1109/CSCI58124.2022.00113},
  ISSN={2769-5654},
  month={Dec},}@INPROCEEDINGS{10796409,
  author={Omowaiye, Rebecca and Ghafir, Ibrahim and Lefoane, Moemedi and Kabir, Sohag and Qureshi, Amna and Daham, Mohammed R.},
  booktitle={2024 4th International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME)}, 
  title={Artificial Intelligence and Big Data Analytics for the Detection of Fake News on Social Media}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The advent of social media has facilitated the rapid dissemination of information, prompting news broadcasting organisations to utilise these platforms for wider audience outreach. While this shift has brought substantial benefits to both organisations and individuals, the proliferation of generative Artificial Intelligence has given rise to an increase in false news and deceptive content, often driven by financial incentives. Such misleading information, widely disseminated on social media, presents opportunities for cybercriminals to engage in activities such as extortion, cyberbullying, and the strategic enhancement of social engineering tactics. These activities are integral components of the footprinting and reconnaissance stages in the lifecycle of cyberattacks. The spread of fake and deceptive content necessitates intensified research into the identification and mitigation of fake and deceptive content. This study evaluates the efficacy of Artificial Intelligence (AI) and Big Data Analytics (BDA) for the detection of fake news on social media using Naíve Bayes (NB), Random Forest (RF), Logistic Regression (LR), and Support Vector Machine (SVM) models. In society at large, it is pertinent to spot fake news to prevent disastrous outcomes when certain information is shared. Out of the four machine learning (ML) techniques applied, the SVM model outperformed others with accuracy and precision of 0.81 and 0.82, respectively. The LR model showed similar precision and the highest recall. These methods provide a foundation for reliable automated fake news detection tools.},
  keywords={Support vector machines;Radio frequency;Mechatronics;Prevention and mitigation;Big Data;Reconnaissance;Network reconnaissance;Reliability;Fake news;Random forests;Artificial Intelligence;Machine Learning;Big Data Analytics;Social Media;Fake News Detection},
  doi={10.1109/ICECCME62383.2024.10796409},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9670945,
  author={Kakade, Apoorv and Deshpande, Mihir and Sardeshpande, Suyash and Thokal, Varad},
  booktitle={2021 International Conference on Artificial Intelligence and Machine Vision (AIMV)}, 
  title={3D Modelling using Sequential and Convolutional Generative Adversarial Networks}, 
  year={2021},
  volume={},
  number={},
  pages={1-4},
  abstract={We propose a novel solution for solving a specific problem of generating realistic and varied 3D models for target objects. Existing processes for 3D modelling involve human inspection of CAD models and borrowing parts from them. There have been inspiring advances made by 3D GANs that generate highly varied object shapes but do not adequately attend to objects that are symmetrical or have limited CAD models available as a training data-set. The benefits of the novel model developed by us are three fold: first, it generates realistic shapes by understanding underlying geometry of objects using a limited training data-set; second, it outperforms the 3D-GAN when generating symmetrical 3D object shapes; third, it bridges a research gap by delivering a solution that requires minimal training time and computational resources.},
  keywords={Training;Geometry;Solid modeling;Three-dimensional displays;Shape;Computational modeling;Machine vision;Generative model;Generative Adversarial Networks;3D Modelling;TimeSeries GAN;CAD models},
  doi={10.1109/AIMV53313.2021.9670945},
  ISSN={},
  month={Sep.},}@ARTICLE{10643250,
  author={Richard, Guy Junior and Habonneau, Jérôme and Guériot, Didier and Le Caillec, Jean-Marc},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={Explainable AI Methods for Underwater Mine Warfare}, 
  year={2025},
  volume={18},
  number={},
  pages={12755-12772},
  abstract={Artificial intelligence (AI) has brought new algorithms providing high performance compared to the usual methods. However, the internal behavior of the decision-making process carried out by neural networks requires to be finely understood. This questioning has led to the development of the eXplainable artificial intelligence (XAI). This is especially true in areas where following AI decisions may have serious consequences, such as underwater mine hunting to increase the AI acceptance. We study the application of XAI methods (backpropagation and perturbation) to the classification (mine versus nonmine) and identification (type of mines) of an object detected by a sonar on the seabed. Although the aim of XAI is to locate relevant features in an image, the classification or identification decisions do not involve the same cognitive process. The main aims of this article were to verify that the XAI methods, designed for optical images, can be applied to grayscale sonar images (in particular, we explain why backpropagation methods are not suitable for grayscale images, unlike perturbation methods) and whether they are neural network-dependent (two kinds of network have been tested). The features highlighted by XAI methods for the different classes of mines are compared with each other, but also with those involved in the operator decision-making. Three examples of feature extraction are finally discussed in the case of misclassification. Furthermore, the perturbation approach provides the same highlighted areas for both networks, and these areas on which the neural networks base their classification can be linked to the explanations given by operators.},
  keywords={Sonar;Fuel processing industries;Artificial neural networks;Shape;Feature extraction;Explainable AI;Task analysis;EXplainable artificial intelligence (XAI);heat maps;mine warfare (MW);SHAP;sonar images},
  doi={10.1109/JSTARS.2024.3447093},
  ISSN={2151-1535},
  month={},}@INPROCEEDINGS{9738571,
  author={Chen, Yen-Hung and Lai, Yuan-Cheng and Lu, Cho-Hsun and Huang, Yu-Ching and Chang, Shun-Chieh and Jan, Pi-Tzong},
  booktitle={2022 8th International Conference on Automation, Robotics and Applications (ICARA)}, 
  title={A Deep Learning Methodology to Detect Trojaned AI-based DDoS Defend Model}, 
  year={2022},
  volume={},
  number={},
  pages={243-246},
  abstract={DDoS attack arranges bots to send low-speed traffic to backbone links and paralyze all servers in the target area. DDoS is difficultly defended due to the two research problems (1) indistinguishability of the changing DDoS characteristics and (2) the time series attack pattern, leading that the raising attention of developing varying DDoS defending methodologies. The conventional methods to defend DDoS apply a rules-based methodology that relies on the experience of algorithm designers and cannot reflect the changing attack characteristics of DDoS in a timely manner. Numerous artificial intelligence (AI) methodologies, therefore, are introduced to defend DDoS through end-to-end functionality (Input: network status; Output: defending action) without any manual intervention. However, the AI-based DDoS Defending model often outsources training to a machine-learning-as-a-service (MLaaS) provider because of the scarce training dataset and high hardware requirement. This may cause the model been trained maliciously, which is called the Artificial Intelligence Trojan attack (AI Trojan). AI Trojan means an AI model encounters a malicious training process and then have a good performance on normal data but behaves maliciously with certain data. This study proposes GAN based AI Robustness test algorithm, Deep Learning Attack Generator (DLAG), to verify that the artificial intelligence model has been fully trained to ensure the robustness of the model. DLAG can be divided into five steps: (1) DLAG randomly generates a sample, (2) generates noise that participates in the generation of a confrontation network (DLAG), (3) input the synthetic sample to the testing AI, (4) the test results will be recorded in the test report and fed back to GAN, and (5) a new synthetic sample will be generated again for the next test cycle. The simulation shows that our proposed DLAG can detect that the AI based DDoS/LFA detector is trained by imbalance data. The simulation results also demonstrate the potential and suggested development trait of AI Trojan detection methodology.},
  keywords={Training;Deep learning;Time series analysis;Generative adversarial networks;Robustness;Data models;Trojan horses;Artificial Intelligence;AI Trojan;GAN;Deep Learning;Imbalance Classification},
  doi={10.1109/ICARA55094.2022.9738571},
  ISSN={2767-7745},
  month={Feb},}@INBOOK{10461715,
  author={Banafa, Ahmed},
  booktitle={Introduction to Artificial Intelligence (AI)}, 
  title={6 Generative AI and Other Types of AI}, 
  year={2024},
  volume={},
  number={},
  pages={31-36},
  abstract={Introduction to Artificial Intelligence (AI) provides a comprehensive overview of the latest trends in artificial intelligence. The book covers the state of the art in AI research, including machine learning, natural language processing, computer vision, and robotics. The book offers a forward-looking perspective on the future of AI, exploring the emerging trends and applications that are likely to shape the next decade of AI innovation. It also provides practical guidance for businesses and individuals on how to leverage the power of AI to create new products, services, and opportunities. Overall, the book is an essential read for anyone who wants to stay ahead of the curve in the rapidly evolving field of AI and understand the impact that this transformative technology will have on our lives in the coming years.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770041850},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10461715},}@INPROCEEDINGS{10580562,
  author={Bhagawati, Mrinalini and Paul, Sudip},
  booktitle={2024 5th International Conference on Innovative Trends in Information Technology (ICITIIT)}, 
  title={Generative Adversarial Network-based Deep Learning Framework for Cardiovascular Disease Risk Prediction}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Early risk assessment is essential since cardiovascular disease (CVD) is a significant healthcare burden. Earlier assessment methods either employed machine learning (ML) paradigms or “conventional CVD risk calculators (CCVRC)”. These methods are haphazard, unreliable, incompletely automated, and subject to variability. The Generative Adversarial Network (GAN) paradigm is thus introduced. Data on 1700 individuals with carotid ultrasonography and matching coronary angiography scores (CAS), the gold standard for determining the degree of coronary artery stenosis. 52 factors in all were utilized, and they were grouped to form three sub-groups, namely (i) officebased, (ii) lab-based, and (iii) carotid ultrasound imaging phenotypes. The imbalanced cohort of the risk classes was handled by using the technique called as synthetic minority over-sampling technique (SMOTE). Using 5-fold crossvalidation, the GAN model’s performance was calculated. Benchmarking of GAN was done against LSTM and RNN. The accuracy and AUC (p=0.001) pairings for the GAN model were 93.00% and 0.953, compared to 85.80% and 0.920 for the LSTM and 82.50% and 0.881 for the RNN, respectively. The online system needs 1 s. GAN algorithms are an effective paradigm for predicting the risk along with the groups of coronary artery disease (CAD).},
  keywords={Solid modeling;Accuracy;Phenotypes;Ultrasonography;Generative adversarial networks;Prediction algorithms;Cardiovascular diseases;Deep learning;Coronary artery disease prediction;Artificial intelligence;Carotid ultrasound;Performance evaluation},
  doi={10.1109/ICITIIT61487.2024.10580562},
  ISSN={},
  month={March},}@INPROCEEDINGS{10195076,
  author={Xing, Daitao and Tzes, Anthony},
  booktitle={2023 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Synthetic Aerial Dataset for UAV Detection via Text-to-Image Diffusion Models}, 
  year={2023},
  volume={},
  number={},
  pages={51-52},
  abstract={In this work, we present an approach to generate a synthetic aerial dataset for efficient Unmanned Aerial Vehicle (UAV) detection. We propose controlling the output of a text-to-image diffusion model by applying additional input conditions. Specifically, we train a diffusion model that enables conditional inputs, i.e., binary masks that specify all tractable parameters, including quantity, scale, pose, color, background, etc. Diverse photorealistic images with corresponding ground truth bounding boxes are generated automatically in an end-to-end manner. Without any interference, the dataset can be scaled to a large magnitude to facilitate the training process of UAV detection. Experimental results of YOLOv7 trained on the synthetic dataset demonstrate an extensive precision increment on unseen datasets of real images.},
  keywords={Training;Image color analysis;Interference;Autonomous aerial vehicles;Artificial intelligence;Synthetic data;UAV detection;Text-to-Image Diffusion;Generative Model},
  doi={10.1109/CAI54212.2023.00030},
  ISSN={},
  month={June},}@INPROCEEDINGS{10675953,
  author={Varma, Sandeep and Shivam, Shivam and Ray, Biswarup and Biswas, Snigdha},
  booktitle={2024 11th IEEE Swiss Conference on Data Science (SDS)}, 
  title={Reimagining Enterprise Data Management using Generative Artificial Intelligence}, 
  year={2024},
  volume={},
  number={},
  pages={107-114},
  abstract={Enterprise Data Management (EDM) is a comprehensive approach encompassing data acquisition, profiling, standardization, quality assurance, and transformation, along with governance, to optimize the lifecycle of an organization’s data assets and facilitate meaningful analysis. The recent rise of Large Language Models (LLMs) and Generative Artificial Intelligence has fundamentally transformed data-related tasks. In this study, we delve into the integration of LLMs and Generative AI within EDM, proposing a collaborative approach that incorporates human input for computationally intensive processes. Our proposed pipeline strategically utilizes advanced Large Language Models to tackle challenges at each stage of the Enterprise Data Management process, significantly enhancing overall efficiency. Through the implementation of a case study in the pharmaceutical domain, we replicate conventional steps taken before creating business reports to enhance sales strategies, demonstrating that the proposed pipeline significantly reduces the time needed for the entire EDM process. Additionally, a comparison between various Open Source LLM models and OpenAI GPT-3.5 reveals GPT-3.5’s superior performance in code generation tasks, especially in scenarios requiring complex query generation. The proposed pipeline demonstrated satisfactory performance across various stages, including tasks such as source-totarget identification and primary key identification, as well as in other phases. The study concludes that the proposed pipeline, utilizing LLMs and Generative AI models, holds promising potential for optimizing and transforming data management workflows, providing efficient and effective solutions for organizations.},
  keywords={Quality assurance;Generative AI;Large language models;Pipelines;Standards organizations;Standardization;Organizations;Generative Artificial Intelligence;Enterprise Data Management;Large Language Models;Pharmaceutical Data},
  doi={10.1109/SDS60720.2024.00023},
  ISSN={2835-3420},
  month={May},}@ARTICLE{10077111,
  author={Tang, Bo and Shah, Vijay K. and Marojevic, Vuk and Reed, Jeffrey H.},
  journal={IEEE Wireless Communications}, 
  title={AI Testing Framework for Next-G O-RAN Networks: Requirements, Design, and Research Opportunities}, 
  year={2023},
  volume={30},
  number={1},
  pages={70-77},
  abstract={Openness and intelligence are two enabling features to be introduced in next generation wireless networks, for example, Beyond 5G and 6G, to support service heterogeneity, open hardware, optimal resource utilization, and on-demand service deployment. The open radio access network (O-RAN) is a promising RAN architecture to achieve both openness and intelligence through virtualized network elements and well-defined interfaces. While deploying artificial intelligence (AI) models is becoming easier in O-RAN, one significant challenge that has been long neglected is the comprehensive testing of their performance in realistic environments. This article presents a general automated, distributed and AI-enabled testing framework to test AI models deployed in O-RAN in terms of their decision-making perfor-mance, vulnerability and security. This framework adopts a master-actor architecture to manage a number of end devices for distributed testing. More importantly, it leverages AI to automatically and intelligently explore the decision space of AI models in O-RAN. Both software simulation testing and software-defined radio hardware testing are supported, enabling rapid proof of concept research and experimental research on wireless research platforms.},
  keywords={Wireless networks;Decision making;Training data;Computer architecture;Hardware;Space exploration;Security},
  doi={10.1109/MWC.001.2200213},
  ISSN={1558-0687},
  month={February},}@ARTICLE{10858287,
  author={Hao, Min and Shang, Chen and Wang, Siming and Jiang, Wenchao and Nie, Jiangtian},
  journal={IEEE Internet of Things Journal}, 
  title={UAV-Assisted Zero Knowledge Model Proof for Generative AI: A Multiagent Deep Reinforcement Learning Approach}, 
  year={2025},
  volume={12},
  number={10},
  pages={13441-13454},
  abstract={As more users seek generative AI (GAI) models to enhance work efficiency, GAI and Model-as-a-Service will drive transformative changes and upgrades across all industries. However, when users utilize GAI models provided by the service provider, they cannot be certain that the model’s quality matches the provider’s claims. Considering the need to protect intellectual property, the service provider will not disclose model details for user verification. To this end, we take the Internet of Vehicles as research background, proposing a zero knowledge model proof architecture based on UAVs. We also introduce a multiagent reinforcement learning algorithm to optimize the verification process. In specific, we first propose a verification scheme for the key operations of generative adversarial networks based on noninteractive zero knowledge proof. The zero knowledge proof architecture ensures that model parameters cannot be stolen during the verification process. After that, we propose an Age of Verification (AoV) metric to ensure the timeliness and freshness of zero knowledge proof. We also construct a tradeoff optimization problem between the energy consumption of UAV as a verifier and the AoV of edge servers as service providers, and transform the problem based on Lyapunov optimization theory. Following that, we propose an enhanced multiagent proximal policy optimization algorithm to enable the collaborative verification of edge servers by multiple UAVs. The algorithm simulation results demonstrate that the reward value of our proposed algorithm is over 10% higher than that of the standard algorithm, with a faster and more stable overall convergence speed. Additionally, the zero knowledge proof performance test results indicate that the verification delay in our proposed architecture is less than 500 ms during the verification phase, meeting practical requirements.},
  keywords={Computational modeling;Servers;Zero knowledge proof;Autonomous aerial vehicles;Optimization;Computer architecture;Data models;Artificial intelligence;Security;Generative adversarial networks;Generative AI (GAI);Lyapunov optimization;multiagent deep reinforcement learning;uncrewed aerial vehicle;zero knowledge proof},
  doi={10.1109/JIOT.2025.3531914},
  ISSN={2327-4662},
  month={May},}@INPROCEEDINGS{11048227,
  author={G, Manjunatha and R H, Divyashree and K S, Malashree and M, Adithi and K, Prabhavathi and A, Lokesh},
  booktitle={2025 International Conference on Recent Advances in Electrical, Electronics, Ubiquitous Communication, and Computational Intelligence (RAEEUCCI)}, 
  title={AI-Powered Framework for X-Ray and MRI Image Enhancement Using Python: A Novel Approach to Reducing Noise, Blur, and Artifacts for Superior Diagnostic Precision}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The integration of artificial intelligence (AI) in medical imaging has revolutionized diagnostic accuracy, particularly for X-ray and MRI scans. This paper presents a novel AI-driven framework for image enhancement that reduces noise, blur, and artifacts, significantly improving diagnostic clarity. Using Python, the proposed system leverages state-of-the-art deep learning models, such as Convolutional Neural Networks (CNNs) and Generative Adversarial Networks (GANs), to achieve diagnostic accuracy exceeding 95%. In experiments, the system processed X-ray images with a diagnostic accuracy of 96.3% and MRI scans at 97.1%, outperforming traditional enhancement methods. The framework reduces noise by 25% and minimizes artifacts by 30%, resulting in clearer, more reliable images suitable for automated analysis. Additionally, the system operates at 35 FPS, ensuring real-time clinical applications. Despite these successes, challenges in model scalability and adaptability to diverse datasets persist, with future work focusing on further optimization and integration into clinical workflows for faster decision-making. This research highlights the transformative potential of AI for advancing medical diagnostics.},
  keywords={Accuracy;Magnetic resonance imaging;Scalability;Noise;Real-time systems;Medical diagnosis;Artificial intelligence;X-ray imaging;Image enhancement;Medical diagnostic imaging;AI-powered medical image processing;X-ray enhancement;MRI enhancement;deep learning;noise reduction;artifact removal;diagnostic accuracy;real-time processing},
  doi={10.1109/RAEEUCCI63961.2025.11048227},
  ISSN={},
  month={April},}@ARTICLE{10474404,
  author={Zhang, Wenchao and Yan, Ruonan and Yuan, Lei},
  journal={IEEE Access}, 
  title={How Generative AI Was Mentioned in Social Media and Academic Field? A Text Mining Based on Internet Text Data}, 
  year={2024},
  volume={12},
  number={},
  pages={43940-43947},
  abstract={As ChatGPT has evolved, generative AI (Artificial Intelligence) has gone viral on the internet since 2022. Heated discussions on generative AI have appeared in both social media and academic field, generating massive textual data. Overwhelming media coverage of generative AI may lead to biased conception. To date, there has been no systematic analysis of how generative AI is mentioned on the internet. Moreover, little attention has been paid to demonstrating the gap in perceptions of generative AI between social media and academic field. This study seeks to focus on the following specific research questions: What are the key terms related to generative AI, what are the key term differences in social media and academic field on generative AI, and what are the topic differences of generative AI in social media and academic field? A text-mining approach supported by KH-coder was employed. The research data were drawn from two main text sources: the Sina Weibo platform and the CNKI periodical database. The results revealed statistically significant differences in key terms and topics related to generative AI between the social media and academic field. Our findings enhance the understanding of public ideas and the trend of generative AI on the internet, and provide supportive information for future studies on generative AI applications.},
  keywords={Generative AI;Social networking (online);Text mining;Blogs;Databases;Data mining;Internet;Generative AI;AIGC;KH-coder;text mining},
  doi={10.1109/ACCESS.2024.3379010},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10578567,
  author={Tabuenca, Bernardo and Martín, Sergio and Greller, Wolfgang and Tillmann, Alexander and Uche-Soria, Manuel and Castro, Manuel and Tovar, Edmundo and Rodríguez-Artacho, Miguel},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={IoT and Generative AI Technologies to Support Urban Environmental Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={This research focuses on the critical role of urban environmental education for addressing both human well-being and climate change, especially in densely populated metropolitan regions. Recognizing the particular vulnerability of these urban zones, the study introduces educational innovations to respond to these intertwined societal and ecological challenges. By integrating advanced technologies such as sensors, IoT, and generative Artificial Intelligence with inquiry-based pedagogy, the initiative promotes broader democratic engagement. This approach results in the development of accessible technological solutions that visualize and disseminate data on key urban environmental indicators, such as tree coverage and heat islands. By merging these technologies with pedagogic activities, the study presents novel learning designs that bolster both digital and environmental competencies. A cascading model ensures that educators and academic institutions are equipped with the necessary training, tools, and designs to champion eco-conscious urban information strategies, further supported by open online learning activities for effective real-world application.},
  keywords={Training;Technological innovation;Climate change;Generative AI;Urban areas;Data visualization;Vegetation;environmental education;generative artificial intelligence;green competences;IoT},
  doi={10.1109/EDUCON60312.2024.10578567},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{11018890,
  author={Venkatraman, S and Bamrah, Sumneet Kaur and Rani, D Pushgara},
  booktitle={2025 International Conference on Computing and Communication Technologies (ICCCT)}, 
  title={Automated Multilingual Translation of Exam Question Papers Using Generative AI}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The research article undertakes an experimental analysis of utilizing conversational/generative AI tools for translating question papers from English to other Indian languages, as frequently seen in the question papers of many Indian universities/colleges and competitive recruitment examinations. This automation of question paper translation shall offload a portion of the workload of academic teachers who are into preparing question papers for various types of examinations. A desktop application of GUI type is developed leveraging artificial intelligence backed ChatGPT and Claude AI as a ready to use zero cost application.},
  keywords={Translation;Costs;Automation;Accuracy;Generative AI;Chatbots;Communications technology;Multilingual;Recruitment;Graphical user interfaces;AI;Artificial Intelligence;ChatGPT;Claude AI;conversational;generative;teachers},
  doi={10.1109/ICCCT63501.2025.11018890},
  ISSN={2995-3197},
  month={April},}@INPROCEEDINGS{11153229,
  author={Wiputra, Richard and Gunawan, Ali and Wijaya, Mahaning Indrawaty and Sundaram, David},
  booktitle={2025 17th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC)}, 
  title={Doing More with Less: A Design Principle for Generative AI Adoption in Nonprofits}, 
  year={2025},
  volume={},
  number={},
  pages={34-37},
  abstract={Nonprofit organizations operate under unstable funding, limited staff capacity, and mounting accountability demands. As Generative Artificial Intelligence (GenAI) technologies mature, they offer a timely opportunity to transform nonprofit operations. This study applies a Design Science Research (DSR) methodology to derive actionable design principles for integrating GenAI into the nonprofit sector. We propose four key design principles: (1) Build Financial Stability and Strengthen Financial Management, (2) Design for Strategic and Adaptive Multi-Stakeholder Management, (3) Integrate Social Impact Measurement and Transparent Reporting, and (4) Strengthen Human Capital Management through Engagement and Development. The output of this paper provides nonprofits with a structured pathway to leverage GenAI to boost operational efficiency while maximizing social impact.},
  keywords={Ethics;Generative AI;Navigation;Human-machine systems;Decision making;Organizations;Transforms;Financial management;Sustainable development;Cybernetics;Generative Artificial Intelligence;Nonprofit Organizations;Design Principles;Design Science Research;AI for Social Good},
  doi={10.1109/IHMSC66529.2025.00013},
  ISSN={2157-8982},
  month={Aug},}@INPROCEEDINGS{10675653,
  author={Daram, Likhitha and Pullakhandam, Gayathri and Godari, Nageshwari and S.Shobarani},
  booktitle={2024 Second International Conference on Inventive Computing and Informatics (ICICI)}, 
  title={Virtual Glamour: AI-Enhanced Makeup Recommendations and Trials}, 
  year={2024},
  volume={},
  number={},
  pages={206-213},
  abstract={The Makeup Recommendation System is a tribute to the potential of data-driven technology to improve the user experience in the ever-changing world of beauty and cosmetics. This unique technology creates personalised designs for cosmetics, skin care items and makeup application techniques using complex algorithms and data analysis methodologies. This method not only speeds up shopping, but also allows users to make informed decisions about their beauty products and procedures by considering the user’s unique characteristics such as skin type, complexion, personal preferences and the latest beauty trends. The technology also dives deep into personal preferences to provide a personalised experience that matches an individual’s own interests. This level of customization ensures that the recommendations are not only relevant, but also resonate with the consumer on a deeper level. Users can experiment with different lip colors, eyeshadows and foundations, and thanks to the excellent images, they can see the possible results as if they were physically doing the makeup. The Makeup Recommendation System helps users make more confident makeup decisions by providing personalised recommendations and a virtual trial experience. It not only makes shopping easier, but also fosters a stronger bond between people and their beauty products. This in turn improves the overall user experience, making beauty shopping enjoyable and stress-free.By accurately applying numerous makeup styles to users’ faces, this makeup transfer application’s outcomes aim to enhance the realism of photos. This technology allows users to see realistic previews of various makeup styles before making a purchase, and it finds uses in the production of cosmetic products and virtual makeup try-on experiences.},
  keywords={Image color analysis;Shape;Machine learning;Production;Market research;User experience;Skin;Machine learning;Artificial intelligence;Deep Learning;GAN(Generative Adversarial Network);Makeup Transfer},
  doi={10.1109/ICICI62254.2024.00043},
  ISSN={},
  month={June},}@INPROCEEDINGS{10833976,
  author={Kawash, Ameera},
  booktitle={2024 Artificial Intelligence x Humanities, Education, and Art (AIxHEART)}, 
  title={Critical Archival Futures: Artist-led Innovation in Generative AI and the Global South}, 
  year={2024},
  volume={},
  number={},
  pages={98-99},
  abstract={This study explores artist-led innovation in generative AI, focusing on the Global South and its diasporas. It presents frameworks and use cases informed by critical archival practices. By examining three artistic projects connected to the MENA region and Africa, the study demonstrates how these examples challenge the hegemonic biases embedded in generative AI, shift power dynamics, and address inequalities rooted in colonial legacies and North-to-South knowledge production. Through these artworks, this paper proposes frameworks that leverage both the archival and future-oriented capabilities of generative AI to explore digital artifact creation and abstraction, reimagining the relationship between archives, data, and potential futures.},
  keywords={Technological innovation;Generative AI;Knowledge based systems;Focusing;Production;Companies;Media;History;Cultural differences;Global communication;generative AI;critical archives;Global South;artistic practice;decolonial AI},
  doi={10.1109/AIxHeart62327.2024.00023},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11042434,
  author={N, Maheswaran and G, Vijayaraj and G, Logeswari and S, Bose and G, Gokulraj and D, Prabhu},
  booktitle={2025 2nd International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)}, 
  title={Secure Blockchain-Integrated Deep Learning Framework for Generative AI Model}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Generative AI is an advanced AI subset designed to create new data resembling existing data, widely applied in text generation, image synthesis, and predictive modeling to enhance automation and creativity across industries. Deep learning, particularly Long Short-Term Memory (LSTM) networks, plays a crucial role in generative AI, as LSTM effectively processes sequential data, making it essential for tasks like natural language processing and time-series forecasting. Data security is critical in generative AI, especially when handling sensitive information. Encryption techniques such as Advanced Encryption Standard (AES) and Rivest-Shamir-Adleman (RSA) ensure data security before processing, with AES providing fast encryption and RSA enabling secure key exchanges. Homomorphic encryption allows AI models to process encrypted data without decryption, maintaining confidentiality. Blockchain technology further enhances data security through a decentralized and immutable ledger for verification, employing smart contracts and cryptographic hashing to ensure data integrity. Blockchain-based identity management systems authenticate inputs while preventing unauthorized access, preserving both privacy and security. Implementing encryption and blockchain mechanisms does not compromise generative AI model accuracy, achieving 92.75% accuracy through rigorous testing, validated using benchmarking datasets and performance evaluation metrics. The integration of encryption and blockchain ensures robust data security while maintaining high accuracy.},
  keywords={Deep learning;Industries;Accuracy;Generative AI;Computational modeling;Data protection;Data models;Encryption;Blockchains;Long short term memory;Generative AI;Deep Learning;Encryption;Decryption;Long Short Term Memory;Blockchain},
  doi={10.1109/RMKMATE64874.2025.11042434},
  ISSN={},
  month={May},}@INPROCEEDINGS{11129417,
  author={Pianon, Kompakron and Tep, Puthyrom and Thitayanuwat, Watchara},
  booktitle={2025 10th International STEM Education Conference (iSTEM-Ed)}, 
  title={Enhancing AI Literacy in Junior High School Students Through a Constructionist Project-Based Learning Approach}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Although there has been research on the use of AI in Project-Based Learning (PBL) for college and high school students, gaps remain regarding the use of Generative AI technology for junior high school students and the integration of Constructionist Project-Based Learning (CPBL) with AI technology to develop AI literacy. This study aims to explore the effect of using the CPBL approach with Generative AI toolssuch as ChatGPT, Poe.com, and Kling AI-to enhance the AI literacy of junior high school students, including their knowledge, ethical understanding, and practical application skills. Purposeful sampling was used to select 18 ninth-grade students from Darunsikkhalai School for Innovative Learning. The experiment ran for 10 weeks in the FabLearn Lab class, with data collected before and after the intervention. The paired-samples t-test results indicated that CPBL is capable of imparting knowledge and capabilities in AI literacy. From an educational perspective, this approach enables students to achieve higher-order intellectual functions and computer competencies that are essential 21st-century skills.},
  keywords={Ethics;Accuracy;Generative AI;Education;Writing;Chatbots;Reflection;Pupils;Constructionism;Project-Based Learning;AI Literacy;Generative AI;Middle School Education},
  doi={10.1109/iSTEM-Ed65612.2025.11129417},
  ISSN={},
  month={July},}@INBOOK{10785843,
  author={Tardy, Jean},
  booktitle={The Creation of a Conscious Machine: The Quest for Artificial Intelligence}, 
  title={Index}, 
  year={2023},
  volume={},
  number={},
  pages={207-214},
  abstract={},
  keywords={Artificial intelligence;Generative AI;Problem-solving;Oral communication;Hybrid power systems;Chatbots;Optimization;Machine intelligence;Human intelligence;Evolution (biology)},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9781501518331},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10785843},}@INPROCEEDINGS{10363912,
  author={Zhang, Zhijun and Pan, An and Li, Xingru and Luo, Yamei},
  booktitle={2023 International Annual Conference on Complex Systems and Intelligent Science (CSIS-IAC)}, 
  title={Large-Model and Generative-Intelligence Agricultural Robot Systems*}, 
  year={2023},
  volume={},
  number={},
  pages={752-759},
  abstract={In order to reduce the problem of excessive reliance on labor force in agriculture and achieve automated intelligent operations, a large-model and generative-intelligence agricultural robot systems (LGARS) is proposed. The structure of LGARS is composed of a perception module, a robot cooperation module, a human-computer interaction module, and a robot system center. By collecting, analyzing, and forecasting data from diverse sensors, the systems generate task and control signals for the generative intelligent agricultural robots. Subsequently, the robots coefficiently complete the assigned tasks. The unique contribution of the proposed LGARS is that the user just needs to send a superior task instruction, and all the other task planning, task generation, autonomous decisions, task decomposition and the specific operation process are conducted by the robot. It can greatly reduce labor costs, improve production efficiency and work accuracy.},
  keywords={Agricultural robots;Force;Production;Robot sensing systems;Agriculture;Sensor systems;Real-time systems;large-model;generative-intelligence;agricultural robot;Internet;big data;cloud control platform},
  doi={10.1109/CSIS-IAC60628.2023.10363912},
  ISSN={},
  month={Oct},}@INBOOK{11104984,
  author={Nag, Anindya and Hassan, Md. Mehedi and Karim, Asif and Kumar Reddy C, Kishor},
  booktitle={Generative AI in Neurodegenerative Disorders: Innovations, Views, and Obstacles}, 
  title={9 AI and Neurodegenerative Disorders: From Early Diagnosis to Advanced Care}, 
  year={2025},
  volume={},
  number={},
  pages={219-242},
  abstract={This book delves into the transformative power of AI in the realm of neurodegenerative diseases, covering topics such as ALS, Huntington's, Parkinson's, and Alzheimer's. Generative AI provides new opportunities for early diagnosis, precise therapy, and individualized rehabilitation, which are crucial as these conditions remain major obstacles for healthcare providers and researchers. Researchers, physicians, AI developers, and healthcare professionals will find this book an invaluable resource for understanding how AI is influencing the development of treatments for neurodegenerative diseases. It describes important obstacles and future directions while providing insights into the newest breakthroughs, thus bridging the gap between technology and practical clinical applications. Anyone involved in neurodegenerative healthcare, from scientists conducting AI-driven medical research to physicians seeking to incorporate AI into patient care or AI professionals investigating new healthcare applications, will find the information and insights they need in this comprehensive book. Predictive analytics, biomarker identification, and drug discovery are being transformed by AI-driven models, such as deep neural networks, generative adversarial networks (GANs), and variational autoencoders (VAEs). This book offers a comprehensive examination of these developments. Robots, wearable sensors, and cognitive therapy platforms are some of the AI-enhanced rehabilitation tools covered, as are AI-integrated cutting-edge technologies like fMRI and MRI, gene-editing methods like CRISPR, and more. In addition to discussing recent technical developments, this book takes a close look at the data privacy, ethics, and regulatory issues that arise when using AI to study neurodegenerative disorders. Issues like algorithmic bias, model explainability, and fair AI-driven healthcare are thoroughly investigated in light of the growing usage of AI models in clinical decision-making, mental health applications, and cognitive rehabilitation.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788743801740},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11104984},}
