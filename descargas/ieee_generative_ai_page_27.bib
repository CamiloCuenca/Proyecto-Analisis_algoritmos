@INPROCEEDINGS{11081240,
  author={Simhadri, L. and Venkatesh, K. and Uyyala, Ravi and Vurubindi, Padmavathi},
  booktitle={2025 3rd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS)}, 
  title={Temporal Modeling of Classical Piano Music using GRU-based Recurrent Neural Networks}, 
  year={2025},
  volume={},
  number={},
  pages={1750-1755},
  abstract={This Paper introduces a recurrent neural network framework for music generation focusing on modeling the timing of notes in classical piano music. The system utilizes stacked recurrent neural networks with gated recurrent units (GRU), trained on Maestro dataset, which includes over 200 hours of aligned MIDI and audio recordings-from global piano compositions. Distinct from traditional methods involving generative adversarial networks or transformer models, our approach highlights how deep temporal modeling of note-onset sequences enables the generation of coherent, long-form compositions while maintaining stylistic fidelity. The proposed model attains a note prediction accuracy of 89.6 percent on the validation set by employing curriculum learning strategies that incrementally address polyphonic complexity. Quantitative assessment based on the Music Theory Similarity Index (MTSI) demonstrates an 82.4 percent alignment with classical harmonic progressions, outperforming baseline LSTM models by 14.2 percent. The primary contribution lies in the introduction of a dynamic temperature sampling mechanism, which effectively balances exploration and exploitation during generation, thereby mitigating the over-smoothing phenomenon commonly observed in recurrent neural network-based systems. This study advances automated composition systems by illustrating that targeted temporal modeling of single-instrument repertoires can achieve higher stylistic fidelity than generalized multi-instrument frame-works. The findings indicate strong potential for applications in computer-assisted composition and music education, particularly in preserving historical performance practices through AI-based analysis and generation. This work addresses these challenges by leveraging Gated Recurrent Units (GRUs), a variant of recurrent neural networks known for their efficiency and effectiveness in modeling sequential data with long-term dependencies.},
  keywords={Training;Accuracy;Computational modeling;Gated recurrent units;Music;Predictive models;Harmonic analysis;Transformers;Timing;Artificial intelligence;Music Generation;Artificial Intelligence (AI);Recurrent Neural Networks (RNN);Deep Learning;Classical Piano Music;AI in Music Education},
  doi={10.1109/ICSSAS66150.2025.11081240},
  ISSN={},
  month={June},}@INPROCEEDINGS{9789810,
  author={Mozo, Alberto and Karamchandani, Amit and Sanz, Mario and Moreno, Jose Ignacio and Pastor, Antonio},
  booktitle={NOMS 2022-2022 IEEE/IFIP Network Operations and Management Symposium}, 
  title={B5GEMINI: Digital Twin Network for 5G and Beyond}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Digital Twin Network (DTN) is a new technology that builds on the concept of Digital Twins (DT) to create a virtual representation of the physical objects of a telecommunications network. DTN bridges physical and virtual spaces to enable coordination and synchronization of physical parts while eliminating the need to directly interact with them. In this work, we present B5GEMINI a DTN for 5G and beyond networks that makes an extensive use of artificial intelligence (AI). First, we present the infrastructural and architectural components that support B5GEMINI. Next, we explore five paradigmatic use cases where AI can leverage B5GEMINI for building new AI-powered applications. Finally, we identify the main components of the AI ecosystem of B5GEMINI.},
  keywords={Bridges;5G mobile communication;Ecosystems;Buildings;Digital twins;Telecommunications;Synchronization;digital twin;digital twin networks;artificial intelligence;machine learning;telecommunications},
  doi={10.1109/NOMS54207.2022.9789810},
  ISSN={2374-9709},
  month={April},}@INPROCEEDINGS{8757133,
  author={Stipić, A. and Bronzin, T. and Prole, B. and Pap, K.},
  booktitle={2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)}, 
  title={Deep learning advancements: closing the gap}, 
  year={2019},
  volume={},
  number={},
  pages={1087-1092},
  abstract={This article explains how recent development in the field of Artificial Intelligence (AI) makes gap between human and machine smaller than ever before, by explaining and comparing traditional approach user in development of AI systems with new approach that has been used by AI system AlphaZero, developed by DeepMind. Traditionally AI systems have been tested in chess and the same has been done to demonstrate the power of AlphaZero. But, instead of playing against human, it played against the best (at the time) chess program Stockfish. While chess programs (before AlphaZero), were using powerful hardware and embedded built-in formal knowledge about the game, AlphaZero is using completely new approach, running on standard hardware and using deep learning. It learned about the game by playing a large number of games with itself, learning in the process. Article will also explain what is so revolutionary in AlphaZero approach to AI and how this new approach can be used in different areas of processing visual information, bio-medicine, autonomous driving, robotics and AI generated images/videos of humans.},
  keywords={Games;Deep learning;Neural networks;Hardware;Autonomous vehicles;Big Data;artificial intelligence;deep learning;AlphaZero;bio medicine;autonomous driving;GAN;generated image;video synthesis},
  doi={10.23919/MIPRO.2019.8757133},
  ISSN={2623-8764},
  month={May},}@INPROCEEDINGS{10456514,
  author={Mohamed, Nachaat and Ahmed, Abdussalam Ali and Alsharif, Abdulgader and ElKhozondar, Hala J.},
  booktitle={2023 IEEE 9th International Women in Engineering (WIE) Conference on Electrical and Computer Engineering (WIECON-ECE)}, 
  title={Employing AI-Driven Drones and Advanced Cyber Penetration Tools for Breakthrough Criminal Network Surveillance}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={In this paper, we introduce a groundbreaking approach to criminal network surveillance, utilizing AI-powered drones equipped with advanced cyber penetration tools. Our methodology entails the deployment of drones to intercept wireless networks of targeted criminals, facilitating the collection of crucial evidence without physical intrusion. By harnessing the capabilities of Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL), in conjunction with automated penetration systems, our drones are able to conduct thorough investigations and relay the findings directly to command centers. This innovative technique ensures the acquisition of accurate and reliable evidence, boasting a remarkable success rate of 99.8%, thereby significantly expediting the arrest and prosecution processes. The outcomes of our work underscore the potential of AI drones as vital assets in modern criminal investigations, reshaping the landscape of law enforcement and national security protocols.},
  keywords={Deep learning;Ethics;Protocols;Law enforcement;Surveillance;Wireless networks;Reliability;Drone;Artificial Intelligence;Machine Learning;Police;Computers;Penetration Testing;Crime},
  doi={10.1109/WIECON-ECE60392.2023.10456514},
  ISSN={2837-8245},
  month={Nov},}@INPROCEEDINGS{10607393,
  author={Sai Meghana, Gogu Venkata and Saqlain Afroz, Shaik and Gurindapalli, Rajesh and Katari, Subhash and Swetha, Kolachana},
  booktitle={2024 4th International Conference on Pervasive Computing and Social Networking (ICPCSN)}, 
  title={A Survey paper on Understanding the Rise of AI-driven Cyber Crime and Strategies for Proactive Digital Defenders}, 
  year={2024},
  volume={},
  number={},
  pages={25-30},
  abstract={As artificial intelligence (AI) continues to evolve, so too does its integration into cyber criminal activities, presenting a formidable challenge to digital security. These findings investigate the escalating nexus between AI and cybercrimes, highlighting the emergent dangers posed by AI-driven malicious activities. The study delves into the various ways in which AI technologies are leveraged by cyber criminals to orchestrate sophisticated attacks, incorporating, data breaches, malware propagation, phishing, and social engineering tactics. Furthermore, the methodologies propose proactive research strategies aimed at mitigating the threats posed by AI-facilitated cybercrimes through the lens of digital forensic techniques. By analyzing current trends in AI-driven cyber offenses and their repercussions on digital security frameworks, this research endeavors to elucidate the imperative for novel approaches in digital forensics. Such proactive strategies encompass the establishment of AI-powered forensic tools, the enhancement of detection and attribution methodologies, and the augmentation of cyber resilience through predictive analytics and preemptive measures. Through a comprehensive review of existing literature, case studies, and empirical data, paper analysis seeks to offer insights into the changing landscape of AI-facilitated cybercrimes and the critical importance of digital forensics in countering these threats. By Gaining a more comprehensive grasp of the combined effects or interactions between AI technologies and cyber criminality, this research endeavors to inform stakeholders in the realms of cybersecurity, law enforcement, and policy-making, thereby contributing to the progress or development in proactive measures aimed at safeguarding digital ecosystems against emerging threats.},
  keywords={Surveys;Machine learning algorithms;Digital forensics;Malware;Threat assessment;Classification algorithms;Stakeholders;Artificial Intelligence;Cyber Crime;Digital Security;Digital Forensic;Cyber Resilience;Law enforcement;AI-Driven vehicles;Deep- Fake technology;Human Safety},
  doi={10.1109/ICPCSN62568.2024.00012},
  ISSN={},
  month={May},}@INPROCEEDINGS{10708515,
  author={Al-Bwana, Eman Kamal and Sayahi, Ikbel and Alauthman, Mohammad and Mahjoub, Mohamed Ali},
  booktitle={2024 10th International Conference on Control, Decision and Information Technologies (CoDIT)}, 
  title={Adverserial network augmentation and tabular data for a new covid-19 diagnostics approach}, 
  year={2024},
  volume={},
  number={},
  pages={2000-2005},
  abstract={This paper introduces a novel methodology for diagnosing COVID-19 leveraging Generative Adversarial Networks for Conditional Tabular data (GANCT). GANCT constructs a sophisticated conditional generative adversarial framework specialized for precise modeling of statistical distributions endemic to COVID-19 tabular datasets. Extensive experiments quantify the impact on predictive performance from augmenting the original data with synthetic GANCT samples. Results prove superior COVID-19 screening accuracy and ROC AUC across classifiers when supplementing real data with GANCT synthesizations. Moreover, we identified the optimal augmentation range that markedly improves performance while avoiding overfitting. The key contributions are: 1) A customized GAN architecture for COVID-19 tabular data synthesis, 2) Comprehensive evaluations demonstrating the benefits of GANCT augmentation, 3) Identification of optimal augmentation levels, and 4) Substantial improvements in COVID-19 prediction. GANCT can help overcome data scarcity to develop more reliable AI diagnostic systems for the pandemic.},
  keywords={COVID-19;Accuracy;Pandemics;Statistical distributions;Generative adversarial networks;Reliability;Information technology;Artificial intelligence;Medical diagnostic imaging;Medical Data;Data Augmentation;Generative Adversarial Networks (GANs);CTGAN;Deep Learning},
  doi={10.1109/CoDIT62066.2024.10708515},
  ISSN={2576-3555},
  month={July},}@INPROCEEDINGS{11008003,
  author={Elasri, Asmaa and Lamrani, Driss and Cherradi, Hanae and Hamida, Soufiane and Cherradi, Bouchaib and Bouattane, Omar},
  booktitle={2025 5th International Conference on Innovative Research in Applied Science, Engineering and Technology (IRASET)}, 
  title={A Scoping Review of Machine Learning Techniques for Early Autism Detection and Diagnosis}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder that affects social interactions and is characterized by the repetition of certain behaviors by an individual. Timely diagnosis and treatment can lead to effective interventions. Owing to automated data analysis procedures with the rapid growth of machine learning (ML) and artificial intelligence (AI), ASD can be diagnosed in a straightforward and efficient manner. This is achieved by utilizing multimodal data, such as behavioral, linguistic, and neuroimaging data, to determine signs of ASD, which is proven to be faster and more accurate than conventional methods. Much work remains to be done on the standardization of datasets, model bias, and clinical ethics. This scoping review explored the methods used to detect ASD using machine learning techniques, their challenges, and practical usages, providing a roadmap for future research and clinical applications.},
  keywords={Neuroimaging;Autism;Ethics;Adaptation models;Data privacy;Data analysis;Reviews;Standardization;Reinforcement learning;Linguistics;Autism Spectrum Disorder;Machine Learning;Data Analysis;Artificial Intelligence;Neurodevelopmental;Multimodal Data;Early Diagnosis},
  doi={10.1109/IRASET64571.2025.11008003},
  ISSN={},
  month={May},}@INPROCEEDINGS{10887908,
  author={Zhong, Cheng and Wu, Junlin and Feng, Ziming and Chen, Boan and Yan, Junchi},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Towards Green VAE: A Light Pixel-weighting Technique to Enhance Variational AutoEncoder}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Variational autoencoders (VAEs) has been a popular generative model for its effectiveness, mathematical foundation, and its impact to other approaches in deep generative learning. For its relatively light-weights and easiness for training, compared with Generative Adversarial Networks (GANs) or other large-scale model e.g. Diffusion, VAEs become a viable tool in cost-efficient generative applications especially considering the so-called green AI. However, in comparison to GANs, the performance of VAEs in generating realistic images is still inferior to the state-of-the-art generative adversarial network (GAN). In this paper, we argue that this problem is at least partly due to the irrational reconstruction in VAE that all pixels are equally weighted, which is harmful to the generating ability (or density estimate). Motivated by this, we propose to compute the weights of pixels. First, we formulate the problem of finding the appropriate weights into an optimal problem, and then give an analytical solution. Moreover, we propose a method to apply the computed weights of pixels into the training pipeline with almost no computation overhead which fits with the spirit of green AI for more energy-saving AI especially for deep learning models. Experiments on MNIST, Fashion-MNIST and CIFAR-10 show that our method can significantly improves VAE in terms of FID.},
  keywords={Training;Deep learning;Autoencoders;Pipelines;Speech enhancement;Signal processing;Generative adversarial networks;Mathematical models;Artificial intelligence;Image reconstruction;Generative models;VAE},
  doi={10.1109/ICASSP49660.2025.10887908},
  ISSN={2379-190X},
  month={April},}@ARTICLE{11142324,
  author={Yang, Han and Zheng, Dong and Wang, Lianyu},
  journal={IEEE Access}, 
  title={Deep Learning-Driven Garden Design: Integrating AI Into the Creative Process}, 
  year={2025},
  volume={13},
  number={},
  pages={151365-151383},
  abstract={The integration of artificial intelligence into landscape architecture has opened new frontiers for computational design, enabling the generation of garden and outdoor spatial layouts that blend ecological logic with aesthetic innovation. This study presents a novel AI-driven framework tailored for garden design, synergizing symbolic formalism with neural generative modeling to support the synthesis of complex, context-aware landscape artifacts. Traditional garden design often relies on fixed templates or heuristic rules that limit adaptability to environmental constraints and stylistic variations. These methods struggle with semantic coherence and lack responsiveness to evolving cultural and ecological aesthetics. To overcome these challenges, we propose a dual-component system comprising StyleMorphNet and the Semantic Stylization Protocol (SSP). StyleMorphNet is a multi-branch neural architecture that decomposes the generative process into latent subspaces covering spatial structure, material composition, and stylistic innovation. This modular design supports fine-grained control over layout generation while preserving landscape semantics. Complementing it, SSP embeds domain-specific knowledge—including seasonal dynamics, functional zoning, and regional styles—into the generative loop via rule-conditioned modulation and symbolic-visual reasoning. Empirical evaluations show that our framework produces garden designs with superior spatial harmony, stylistic diversity, and ecological relevance compared to existing models. This work contributes to the field of computational landscape design by providing an adaptive and semantically grounded framework that supports the co-creation of expressive, sustainable outdoor environments.},
  keywords={Market research;Artificial intelligence;Clothing;Adaptation models;Computational modeling;Semantics;Visualization;Data models;Deep learning;Computer architecture;Computational design;generative modeling;semantic coherence;human-media interaction;artificial intelligence},
  doi={10.1109/ACCESS.2025.3602874},
  ISSN={2169-3536},
  month={},}@INBOOK{10982301,
  author={Bergeret, Olivier and Abbasi, Asif and Farvault, Joel},
  booktitle={GenAI on AWS: A Practical Approach to Building Generative AI Applications on AWS}, 
  title={Next Steps}, 
  year={2025},
  volume={},
  number={},
  pages={311-322},
  abstract={<p>In this chapter, the authors share some of their personal opinions on the technology, where it is going, the key challenges that we see that may impact the regulatory environment, and finally how we as a reader can stay abreast of all the key changes happening. One of the most fascinating aspects of Generative AI's evolution has been the dramatic scaling of model architectures. This evolution tells us something profound about the field's maturation. The story of computational efficiency in Generative AI reads like a classic tale of technological democratization. Modern approaches like quantization and distillation have achieved what once seemed impossible: maintaining most of the performance while dramatically reducing the computational footprint. The latest frontier in Generative AI is real&#x2010;time processing, particularly in video generation. This field has evolved from generating static images to creating fluid, coherent video sequences.</p>},
  keywords={Generative AI;Artificial intelligence;Visualization;Writing;Computational modeling;Companies;Streaming media;Training;Technological innovation;Software development management},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394281305},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10982301},}@ARTICLE{8861033,
  author={Li, Dejian and Li, Zejian and Luo, Ruiming and Deng, Jia and Sun, Shouqian},
  journal={IEEE Access}, 
  title={Multi-Pose Facial Expression Recognition Based on Generative Adversarial Network}, 
  year={2019},
  volume={7},
  number={},
  pages={143980-143989},
  abstract={The recognition of human emotions from facial expression images is one of the most important topics in the machine vision and image processing fields. However, recognition becomes difficult when dealing with non-frontal faces. To alleviate the influence of poses, we propose an encoder-decoder generative adversarial network that can learn pose-invariant and expression-discriminative representations. Specifically, we assume that a facial image can be divided into an expressive component, an identity component, a head pose component and a remaining component. The encoder encodes each component into a feature representation space and the decoder recovers the original image from these encoded features. A classification loss on the components and an  $\ell _{1}$  pixel-wise loss are applied to guarantee the rebuilt image quality and produce more constrained visual representations. Quantitative and qualitative evaluations on two multi-pose datasets demonstrate that the proposed algorithm performs favorably compared to state-of-the-art methods.},
  keywords={Generative adversarial networks;Feature extraction;Face recognition;Hidden Markov models;Decoding;Gallium nitride;Head;Facial expression recognition;computer vision;image analysis;convolutional neural networks;multi-pose;generative adversarial network;human-robot interaction;signal processing},
  doi={10.1109/ACCESS.2019.2945423},
  ISSN={2169-3536},
  month={},}@ARTICLE{10565946,
  author={Lo, Frank P.-W. and Qiu, Jianing and Wang, Zeyu and Chen, Junhong and Xiao, Bo and Yuan, Wu and Giannarou, Stamatia and Frost, Gary and Lo, Benny},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Dietary Assessment With Multimodal ChatGPT: A Systematic Analysis}, 
  year={2024},
  volume={28},
  number={12},
  pages={7577-7587},
  abstract={Conventional approaches to dietary assessment are primarily grounded in self-reporting methods or structured interviews conducted under the supervision of dietitians. These methods, however, are often subjective, inaccurate, and time-intensive. Although artificial intelligence (AI)-based solutions have been devised to automate the dietary assessment process, prior AI methodologies tackle dietary assessment in a fragmented landscape (e.g., merely recognizing food types or estimating portion size) and encounter challenges in their ability to generalize across a diverse range of food categories, dietary behaviors, and cultural contexts. Recently, the emergence of multimodal foundation models, such as GPT-4V, has exhibited transformative potential across a wide range of tasks in various research domains. These models have demonstrated remarkable generalist intelligence and accuracy, owing to their large-scale pre-training on broad datasets and substantially scaled model size. In this study, we explore the application of GPT-4V powering multimodal ChatGPT for dietary assessment, along with prompt engineering and passive monitoring techniques. We evaluated the proposed pipeline using a self-collected, semi free-living dietary intake dataset, captured through wearable cameras. Our findings reveal that GPT-4V excels in food detection under challenging conditions without any fine-tuning or adaptation using food-specific datasets. By guiding the model with specific language prompts (e.g., African cuisine), it shifts from recognizing common staples like rice and bread to accurately identifying regional dishes like banku and ugali. Another standout feature of GPT-4V is its contextual awareness. GPT-4V can leverage surrounding objects as scale references to deduce the portion sizes of food items, further facilitating the process of dietary assessment.},
  keywords={Artificial intelligence;Estimation;Task analysis;Chatbots;Monitoring;Accuracy;Visualization;ChatGPT;deep learning;dietary assessment;food recognition;foundation model;GPT-4V;passive monitoring},
  doi={10.1109/JBHI.2024.3417280},
  ISSN={2168-2208},
  month={Dec},}@ARTICLE{11099051,
  author={Duan, Tiehang and Wang, Zhenyi and Shen, Li and Luan, Siyu and Li, Fang and Doretto, Gianfranco and Adjeroh, Donald A. and Niu, Shuteng and Li, Jianfu and Tao, Cui},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Teleportation: Defense against Stealing Attacks of Data-Driven Healthcare APIs}, 
  year={2025},
  volume={},
  number={},
  pages={1-15},
  abstract={The increased popularity of digital healthcare services has prompted the development of different types of datadriven healthcare APIs on top of electronic health records, offering the convenience of aided diagnostic services without compromising privacy. Defense against the unauthorized extraction of healthcare APIs is important due to: 1) the unauthorized cloned model could serve online as fake healthcare service providers and pose harm to the general public; 2) protected training data containing private electronic health records could be further extracted from the stolen model. It is therefore important to protect the data-driven healthcare APIs from unauthorized clone and extraction. In this work, we propose a principled defense strategy with adaptive teleportation of incoming queries to effectively guard against extraction attacks of healthcare APIs. The proposed mechanism prevents unauthorized copy of model functionality while maintaining the utility of APIs to serve benign queries. The adaptive teleportation operations are generated based on the formulated bi-level optimization target and follows the evolution trajectory depicted by the Wasserstein gradient flows, which effectively push attacking queries to cross decision boundary while constraining the deviation level of benign queries, utilizing the fact that attacker generated pseudo-queries are mostly closer to decision boundaries than normal queries. This provides misleading information on malicious queries while preserving model utility. We performed detailed analysis of the proposed mechanism on three healthcare related prediction tasks including in-hospital mortality, bleed risk and ischemic risk prediction for validation of its effectiveness under different types of attacking scenarios. The proposed mechanism is significantly more effective to suppress the performance of cloned model while maintaining comparable serving utility compared to existing defense approaches.},
  keywords={Medical services;Data models;Data mining;Training;Training data;Teleportation;Artificial intelligence;Optimization;Perturbation methods;Cloning;healthcare API;model stealing;machine-learning-as-a-service;perturbation based defense},
  doi={10.1109/TAI.2025.3593470},
  ISSN={2691-4581},
  month={},}@BOOK{10977764,
  author={Alto, Valentina},
  booktitle={Practical Generative AI with ChatGPT: Unleash your prompt engineering potential with OpenAI technologies for productivity and creativity},
  year={2025},
  volume={},
  number={},
  pages={},
  abstract={Transform your professional world with ChatGPT and OpenAI—master prompt design to revolutionize development, marketing, research, and enterprise implementationKey FeaturesTurn ChatGPT into your companion for marketing, research, personal productivity, art and codingLearn prompt engineering techniques that deliver consistent, relevant, and ethical AI-powered resultsBuild custom GPTs and assistants tailored to your specific business needs and workflowsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionPractical Generative AI with ChatGPT is your hands-on guide to unlocking the full potential of ChatGPT. From building AI assistants and mastering prompt engineering to analyzing documents and images and even generating code, this book equips you with the skills to integrate generative AI into your workflow. Written by a technical architect specializing in AI and intelligent applications, this book provides the tools and knowledge you need to streamline tasks, enhance productivity, and create intelligent solutions. You’ll learn how to craft precise prompts, leverage ChatGPT for daily efficiency, and develop custom AI assistants tailored to your needs. The chapters show you how to use ChatGPT’s multimodal capabilities to generate images with DALL·E and even transform images into code. This ChatGPT book goes beyond basic interactions by showing you how to design custom GPTs and integrate OpenAI’s APIs into your applications. You’ll explore how businesses use OpenAI models, from building AI applications, including semantic search, to creating an AI roadmap. Each chapter is packed with practical examples, ensuring you can apply the techniques right away. By the end of this book, you’ll be well equipped to leverage OpenAI's technology for competitive advantage.What you will learnExplore the fundamentals of generative AI and GPT modelsMaster prompt engineering to consistently get relevant and reliable outputs from ChatGPTDevelop marketing strategies and conduct meaningful A/B testing with AI assistanceBoost your coding with code generation, review, and optimizationEnhance research with real-time knowledge miningEnhance your visual creativity with image generation, image understanding, and style transferDesign custom GPTs and assistants tailored to specific business functionsDiscover how enterprises are leveraging large language models for their AI appsWho this book is forThis book is ideal for business professionals, developers, marketers, researchers, and decision-makers who want to leverage AI to enhance productivity. No advanced technical background is required for the foundational sections, making the content accessible to beginners, while later chapters provide depth for technical professionals implementing enterprise solutions. If you’re seeking practical applications of generative AI in business contexts, you’ll find immediate, actionable value in this book.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781836647843},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10977764},}@INPROCEEDINGS{9628978,
  author={Striuk, Oleksandr and Kondratenko, Yuriy},
  booktitle={2021 IEEE 4th International Conference on Advanced Information and Communication Technologies (AICT)}, 
  title={Adaptive Deep Convolutional GAN for Fingerprint Sample Synthesis}, 
  year={2021},
  volume={},
  number={},
  pages={193-196},
  abstract={Real biometric fingerprint samples belong to the category of personal data, and therefore their usage for deep learning model training may have certain limitations. Artificially generated fingerprint images do not relate to a real person and can be used freely (“privacy-friendly”). Synthesized fingerprint samples are of interest for applied research: biological (papillary lines structure and alteration), forensic (computer fingerprint identification, reconstruction, and restoration of damaged samples), technological (various methods of biometric security). Generation of artificial fingerprints that accurately reproduce the textural features of real fingerprints could be a difficult task. In this paper, we present a deep learning framework — Adaptive Deep Convolutional Generative Adversarial Network (ADCGAN) — that we have developed and researched, and which has demonstrated the ability to generate realistic fingerprint samples that are similar to real ones in terms of their feature spectrum. ADCGAN makes it possible to conduct fingerprint research, without restrictions related to the confidential nature of biometric data.},
  keywords={Deep learning;Training;Image synthesis;Image matching;Biological system modeling;Fingerprint recognition;Generative adversarial networks;neural network;artificial intelligence;generative adversarial network;fingerprints;sample},
  doi={10.1109/AICT52120.2021.9628978},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10637537,
  author={Chan, Yu and Lin, Pin-Yu and Tseng, Yu-Yun and Chen, Jen-Jee and Tseng, Yu-Chee},
  booktitle={2024 33rd International Conference on Computer Communications and Networks (ICCCN)}, 
  title={Learning-Based WiFi Fingerprint Inpainting via Generative Adversarial Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={WiFi-based indoor positioning has been extensively studied. A fundamental issue in such solutions is the collection of WiFi fingerprints. However, due to real-world constraints, collecting complete fingerprints at all intended locations is sometimes prohibited. This work considers the WiFi fingerprint inpainting problem. This problem differs from typical image/video inpainting problems in several aspects. Unlike RGB images, WiFi field maps come in any shape, and signal data may follow certain distributions. Therefore, it is difficult to forcefully fit them into a fixed-dimensional matrix, as done with processing images in RGB format. As soon as a map is changed, it also becomes difficult to adapt it to the same model due to scale issues. Furthermore, such models are significantly constrained in situations requiring outward inpainting. Fortunately, the spatial relationships of WiFi signals and the rich information provided among channels offer ample opportunities for this generative model to accomplish inpainting. Therefore, we designed this model to not only retain the characteristic of regression models in generating fingerprints of arbitrary shapes but also to accommodate the observational outcomes from densely deployed APs. This work makes two major contributions. Firstly, we delineate the distinctions between this problem and image inpainting, highlighting potential avenues for research. Secondly, we introduce novel generative inpainting models aimed at capturing both inter-AP and intra-AP correlations while preserving latent information. Additionally, we incorporate a specially designed adversarial discriminator to enhance the quality of inpainting outcomes.},
  keywords={Location awareness;Adaptation models;Solid modeling;Shape;Fingerprint recognition;Robot sensing systems;Generative adversarial networks;adversarial network;indoor localization;inpainting;WiFi fingerprint;wireless sensing},
  doi={10.1109/ICCCN61486.2024.10637537},
  ISSN={2637-9430},
  month={July},}@INPROCEEDINGS{10056500,
  author={Li, Li-Hua and Jiang, Ling-Qi and Peng, Yu-Fang and Liu, Ye-Shan and Chung, Kai-Lun},
  booktitle={2022 International Conference on Technologies and Applications of Artificial Intelligence (TAAI)}, 
  title={Combining Conditional Generative Adversarial Networks and YOLOv4 for Mango Classification}, 
  year={2022},
  volume={},
  number={},
  pages={54-59},
  abstract={Mango is one of the most important exporting products in Taiwan and it has provided Taiwan with numerous economic benefits. To maximize the value, mangos are usually classified into grade A, grade B, and grade C before they are sent to exporting process, domestic sale, or fruit punching factory, respectively. Since the freshness of mangos is limited by time, it is important to accelerate the classification process. To improve the classification performance, this research proposes the Irwin mango classification system (IMCS) by combining Conditional Generative Adversarial Network (CGAN) and YOLOv4. CGAN is applied to help data expansion when the amount of data is insufficient. YOLOv4 is applied to classify the grade of mango and to detect the location of mango. To show our approach is better than other methods, we compare our model with YOLOv3 SPP, YOLOv4, ResNet, AlexNet, VGG 16, DenseNet, ShuffleNet, Fusion model, and the best outcome in AI CUP. The experiments show that our CGAN plus YOLOv4 (CGAN+YOLOv4) model has the best outcome with 85% precision for training, 82% precision for testing, and 90.07% for mAP. The weighted average recall (WAR) is 84.83% which is better than the best outcome of AI CUP 2020.},
  keywords={Training;Economics;Image recognition;Punching;Training data;Generative adversarial networks;Production facilities;YOLOv4;Mango;Quality grading;Object recognition;Artificial intelligence;CGAN},
  doi={10.1109/TAAI57707.2022.00019},
  ISSN={2376-6824},
  month={Dec},}@INBOOK{10951179,
  author={Singh, Shiv},
  booktitle={Marketing with AI For Dummies}, 
  title={Developing Creative Assets}, 
  year={2025},
  volume={},
  number={},
  pages={211-228},
  abstract={Summary <p>An exciting dimension of generative artificial intelligence (AI) is its potential use for the development of creative assets in marketing. This chapter describes about Where's Waldo? to demonstrate both the opportunities and the risks involved in using generative AI to augment the creative process. The combination of AI capabilities and readers' unique brand perspective can create the most powerful visual content. Using AI to personalize e&#x2010;mail campaigns requires careful handling of customer data in compliance with the General Data Protection Regulation or other relevant privacy regulations. Similar to its capabilities for image restoration, AI's audio processing features make it adept at creating, enhancing, and restoring audio recordings. Simpler AI tools, such as Animoto or Lumen5, also allow them to enter natural language queries into the application and provide guidelines for creating short instructional videos.</p>},
  keywords={Artificial intelligence;Generative AI;Image color analysis;Clothing;Visualization;Social networking (online);Text to image;Buildings;Bamboo;Web sites},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394237210},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951179},}@INPROCEEDINGS{11050447,
  author={Zhang, Zhouqing and Liew, Kongmeng and Piumsomboon, Tham},
  booktitle={2025 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={What One Million Prompts Tells Us About AI Usage, Topics, and Preferences}, 
  year={2025},
  volume={},
  number={},
  pages={174-179},
  abstract={With extensive research and significant progress made in AI in recent years, generative conversational AI products (such as ChatGPT, Claude, etc.) have been increasingly integrated into daily life, across a variety of tasks. While much research has focused on improving the capability of conversational AI, such as through developing novel model architectures and richer training corpora, comparatively less attention has been given to understanding how people use conversational AI. In this study, We analyzed a large, naturalistic dataset of 1 million human-AI prompt-response logs to explore and quantify common types of use cases. Focusing primarily on human prompts in a conversational dialogue system, we apply topic modeling techniques, and found that usage preferences were primarily for assisting users with coding and programming (15.54%), business management (10.33%), and visual design (8.76%). We also examined how usage dynamics of multi-turn conversation with a dialogue system-like conversational AI (GPT-series models). The results indicate that the majority of users' multi-turn conversations stay on one topic, and for the few multi-turn conversations identified, most of conversations focused on one topic instead of transitioning between multiple topics. Our research sheds light into usage dynamics for conversational AI, and also highlights the kinds of conversational topics that users use these AI for.},
  keywords={Training;Text mining;Analytical models;Visualization;Conversational artificial intelligence;Focusing;Oral communication;Programming;Encoding;Data models;Conversational AI;topic modeling;data analysis;text mining;NLP},
  doi={10.1109/CAI64502.2025.00035},
  ISSN={},
  month={May},}@INPROCEEDINGS{9225510,
  author={Ghosh, Bhaskar and Dutta, Indira Kalyan and Totaro, Michael and Bayoumi, Magdy},
  booktitle={2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT)}, 
  title={A Survey on the Progression and Performance of Generative Adversarial Networks}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={Generative Adversarial Networks (GANs) are a class of deep neural networks that provide a unique way of modeling and generating data in an unsupervised manner. The literature shows that GANs are currently an important research area, being used in a variety of applications. Our survey paper gives an overview of GANs and how they have progressed to become more efficient and powerful. We discuss the efficiency of GAN-variant models, demonstrate how GANs are used in different applications, elaborate on the shortcomings of GANs, review the various ways that researchers have addressed these issues and list several important metrics that are most used in this field. The objective of this paper is to provide a summary of the progression and performance of GANs and the current research that is being conducted to improve them.},
  keywords={Measurement;Deep learning;Generative adversarial networks;Data models;Artificial intelligence;Faces;Creativity;Generative Adversarial Networks;Artificial Intelligence;Machine Learning;Natural Language Processing;Image Generation},
  doi={10.1109/ICCCNT49239.2020.9225510},
  ISSN={},
  month={July},}@INPROCEEDINGS{10179639,
  author={Khan, Lamia Parven},
  booktitle={2023 Fifth International Conference on Electrical, Computer and Communication Technologies (ICECCT)}, 
  title={Obfuscated Malware Detection Using Artificial Neural Network (ANN)}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Thinking about life without using the internet is impossible. Internet and network have become a part of our daily life. Sharing confidential information through internet and doing lots of important and confidential official work is done easily by using internet. One side internet has made life easy and another side is it cheap and fast compare to other methods such as letter or fax. With the growing technology some third party cybercriminals and hackers are trying to use the internet for their personal gain and harm the users or organizations. Malware is one of those malicious software whose sole purpose is to harm the user, system or organization and steal information and sent it to third party for harmful use. It is necessary to find this malicious software and prevent them from harming through the internet. The proposed model detects the harmful malware lurking on the internet and prevent the user and system from any potential harmful effect. The model is very simple and cost effective yet very efficient. the accuracy of the model is 99.72%.},
  keywords={Electric potential;Costs;Computer hacking;Computational modeling;Organizations;Artificial neural networks;Learning (artificial intelligence);Malware;ANN;accuracy;precision;obfuscated;machine learning},
  doi={10.1109/ICECCT56650.2023.10179639},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{11029428,
  author={Hussain, Waqar},
  booktitle={2025 IEEE/ACM International Workshop on Responsible AI Engineering (RAIE)}, 
  title={Mitigating Values Debt in Generative AI: Responsible Engineering with Graph RAG}, 
  year={2025},
  volume={},
  number={},
  pages={9-12},
  abstract={Generative AI technologies are rapidly transforming industries such as healthcare, education, and transportation. However, this progress often incurs a Values Debt-ethical and operational deficits due to insufficient ethical considerations during development. This paper examines Values Debt in Gen-erative AI and introduces the Helpful, Honest, Harmless (HHH) framework to align AI systems with human values. In developing GRAISE, a Graph RAG-based chatbot for aviation safety, the HHH framework is applied to integrate ethical practices through-out the development process. This case study demonstrates how the HHH framework addresses ethical challenges and provides reliable contextual information to enhance pilot communication, exemplifying responsible AI engineering. These findings advocate for the broader adoption of ethical AI frameworks across various sectors, promoting trust and integrity in AI applications.},
  keywords={Symbiosis;Industries;Ethics;Generative AI;Shape;Transportation;Medical services;Systems engineering and theory;Reliability engineering;Safety;Generative AI;Values Debt;HHH Framework;Ethical AI;Responsible AI;AI Safety;AI Bias;Hallucination},
  doi={10.1109/RAIE66699.2025.00006},
  ISSN={},
  month={April},}@INPROCEEDINGS{10726950,
  author={Qi, Jiayin and Jia, Kun and Zhang, Yuxin and Feng, Xiaobing and Yan, Haiyan},
  booktitle={2024 IEEE 24th International Conference on Software Quality, Reliability, and Security Companion (QRS-C)}, 
  title={Wuli-Shili-Renli-Jili System Approach and Its Application in Large Model Value Alignment}, 
  year={2024},
  volume={},
  number={},
  pages={500-506},
  abstract={As artificial intelligence systems enter a rapid development phase, large models, serving as a new type of hybrid intelligence system for human-machine collaboration, still lack a system methodology that suits them. This study extends the Wuli-Shili-Renli (WSR) system approach, innovatively proposing a Wuli- Shili- Renli- Jili (WSRJ) system approach suitable for large models. It constructs the connotation of the Jili element and explores the application of WSRJ system approach in the technology research of large model value alignment, providing a multi-dimensional system analysis framework of function, logic, humanity, and technology.},
  keywords={Analytical models;Humanities;Adaptation models;Generative AI;Human-machine systems;Software quality;Software reliability;Logic;Security;System analysis and design;Wuli-Shili-Renli-Jili system approach;Wuli-Shili-Renli system approach;Large model value alignment;Large models;Generative artificial intelligence},
  doi={10.1109/QRS-C63300.2024.00069},
  ISSN={2693-9371},
  month={July},}@INPROCEEDINGS{10055814,
  author={Wu, Hai-Yan and Li, Yuan-Ye and Wei, Gong-Zheng},
  booktitle={2022 China Automation Congress (CAC)}, 
  title={A DCGAN image generation algorithm based on AE feature extraction}, 
  year={2022},
  volume={},
  number={},
  pages={4959-4964},
  abstract={Current image generation algorithms have problems such as excessive noise in the generated images, poor image clarity and slow convergence of the generation network. To address the limitations of traditional image generation methods, we propose an image generation algorithm by combining an autoencoder (AE) and a deep convolutional generative adversarial network (DCGAN).The method first uses the feature representation capability of the AE to encode the training images, with the aim of compressing and downscaling the image to obtain an efficient data feature representation of the image. This has significantly less dimension than the original image and carries important features of the original image. This feature representation is then combined with random noise and used as the input to the DCGAN network after data processing. In the recognition phase, the network is continuously adjusted to optimize the model by using gradient descent and receives feedback from the discriminator. Experiments show that the network can generate images with better results to the extent that the human eye cannot separate them from the real data. The advantages of the proposed method are highlighted by comparing it with traditional generative networks.},
  keywords={Training;Image coding;Image synthesis;Computational modeling;Training data;Generative adversarial networks;Feature extraction;com Generative adversarial networks;deep convolutional networks;encoders;image generation;deep learning},
  doi={10.1109/CAC57257.2022.10055814},
  ISSN={2688-0938},
  month={Nov},}@INPROCEEDINGS{10851119,
  author={Hettiarachchi, Anuththara and Rathnayake, Samadhi and Dissanayaka, Kapila},
  booktitle={2024 6th International Conference on Advancements in Computing (ICAC)}, 
  title={A Generative Adversarial Network to Upscale the Resolution of Low-Resolution Galaxy Images}, 
  year={2024},
  volume={},
  number={},
  pages={55-60},
  abstract={High-resolution galaxy images play a crucial role in astronomy and astrophysics, enabling detailed morphological analysis, the identification of faint structures, and distance measurements. However, limitations in telescope technologies, atmospheric conditions, and the vast distances of observed objects often result in low-resolution images. In this research, we leveraged advanced deep-learning methods to enhance the resolution of low-resolution galaxy images. We introduced a Generative Adversarial Network (GAN) specifically developed to upscale galaxy images taken at suboptimal resolutions, with the Enhanced Super Resolution Generative Adversarial Network (ESRGAN) serving as the foundational model. Our self-attention multi-scale GAN architecture utilized deep learning to produce super-resolution images by learning from a dataset of high-resolution galaxy images. Additionally, we incorporated an Explainable AI technique to open the black box of our GAN model, providing insights into its intrinsic decision processes and feature learning mechanisms. This advanced approach not only enhanced image resolution but also improved model transparency and built trust in the model's predictions. Our results demonstrated a significant improvement in the Peak Signal-to-Noise Ratio and Structural Similarity Index Measure and provided a better understanding of the model's operations, which is highly important for scientific analysis and validation in astronomical research.},
  keywords={Training;Computational modeling;Superresolution;Stability criteria;Computer architecture;Predictive models;Telescopes;Generative adversarial networks;Extraterrestrial measurements;Signal resolution;generative adversarial networks;multi-scale architecture;super-resolution;explainable AI;galaxy images},
  doi={10.1109/ICAC64487.2024.10851119},
  ISSN={2837-5424},
  month={Dec},}@ARTICLE{9381251,
  author={Liu, Yunfan and Li, Qi and Sun, Zhenan and Tan, Tieniu},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={A3GAN: An Attribute-Aware Attentive Generative Adversarial Network for Face Aging}, 
  year={2021},
  volume={16},
  number={},
  pages={2776-2790},
  abstract={Face aging has received significant research attention in recent years. Although great progress has been achieved with the success of Generative Adversarial Networks (GANs) in synthesizing realistic images, most existing GAN-based face aging methods have two main problems: 1) unnatural changes of high-level semantic information due to the insufficient consideration of prior knowledge of input faces, and 2) distortions of low-level image content (e.g. modifications in age-irrelevant regions). In this article, we introduce A3GAN, an Attribute-Aware Attentive face aging model to address the above issues. Facial attribute vectors are regarded as the conditional information and embedded into both the generator and discriminator, encouraging synthesized faces to be faithful to attributes of corresponding inputs. To improve the visual fidelity of generation results, we leverage the attention mechanism to restrict modifications to age-related areas and preserve image details. Unlike previous works with attention modules, we introduce face parsing maps to help the generator distinguish image regions of interest and suppress attention activation elsewhere. Moreover, the wavelet packet transform is employed to capture textural features at multiple scales in the frequency space. Extensive experimental results demonstrate the effectiveness of our model in synthesizing photo-realistic aged face images and achieving state-of-the-art performance on popular datasets.},
  keywords={Aging;Faces;Face recognition;Facial features;Generators;Wavelet packets;Visualization;Generative adversarial networks;face aging;facial attribute;attention mechanism;wavelet packet transform},
  doi={10.1109/TIFS.2021.3065499},
  ISSN={1556-6021},
  month={},}@INPROCEEDINGS{10825692,
  author={Rinaldi, Antonio Maria and Romano, Antonio and Russo, Cristiano and Tommasino, Cristian},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={FPSRec: Football Players Scouting Recommendation System based on Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={7141-7150},
  abstract={Player scouting in soccer is witnessing a surge of interest from the research community. Traditional scouting methods are often limited by subjectivity and biases in evaluation. Moreover, the lack of structured data and models hinders the progress of the field. To overcome these limitations, we introduce a novel player recommendation system which integrates similarity techniques and generative artificial intelligence. It aims to support player recruitment by providing a data-driven and inclusive approach. The novelty of our work lies in its use of advanced machine learning and artificial intelligence to accurately predict player potential and performance by similarity measures, thereby mitigating the influence of subjective biases that often affect talent identification. Our contributions represent a significant advancement in the field of sports analytics and talent identification, offering a more equitable and efficient approach to scouting and recruitment. The results obtained underscore the effectiveness of the proposed system, demonstrating the transformative potential of artificial intelligence in revolutionizing talent scouting.},
  keywords={Generative AI;Machine learning;Big Data;Data models;Surges;Recommender systems;Sports;Recruitment;Recommendation Systems;Player Scouting;Generative AI;Football Analytics;Sports Analytics;Data-driven Scouting},
  doi={10.1109/BigData62323.2024.10825692},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{8923404,
  author={Dewi, Christine and Chen, Rung-Ching and Hendry and Liu, Yan-Ting},
  booktitle={2019 IEEE 10th International Conference on Awareness Science and Technology (iCAST)}, 
  title={Similar Music Instrument Detection via Deep Convolution YOLO-Generative Adversarial Network}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={Object detection and image recognition are important research topics in machine learning and artificial intelligence. The major challenge of the computer vision image recognition is to detect and recognize a similar object. Generative Adversarial Network (GAN) based on Convolution Neural Network (CNN) is proposed to faces this challenge. The advantage of the GAN is represented by its architecture which consists of a generator and discriminator to detect real or fake image generated by the machine. In this paper, we adopt the advantage of GAN and combine with YOLO algorithm to identify similar music instruments. YOLO is fast Region based CNN with powerful computation. Using Deep Convolution YOLO-GAN will enhance the capability of YOLO detection process and outperform the original YOLO capability.},
  keywords={Instruments;Gallium nitride;Training;Generators;Computer architecture;Generative adversarial networks;Object detection;Deep Learning;Generative Adversarial Network;YOLO;Similar object detection},
  doi={10.1109/ICAwST.2019.8923404},
  ISSN={2325-5994},
  month={Oct},}@INPROCEEDINGS{10206126,
  author={Liu, Lijuan and Wang, Dingmei and Li, Jin and Wang, Sheng},
  booktitle={2023 6th International Conference on Artificial Intelligence and Big Data (ICAIBD)}, 
  title={An Efficient Hot Spot Detection Method with Small Sample Learning for Photovoltaic Panels}, 
  year={2023},
  volume={},
  number={},
  pages={673-678},
  abstract={With the rapid development of photovoltaic power stations, various faults frequently occur during the maintenance of photovoltaic panels. The hot spot is one of the critical issues which is not easy to observe and has a tremendously harmful impact. Traditional graph target recognition training requires a large amount of data in practical applications. However, there are many issues with hot spot detection in the real world. For example, images with hot spots often have a small sample number, detention methods are low recognition efficiency and slow speed. This paper constructs a fast photovoltaic hot spot detection method, Cheetah, for photovoltaic hot spot recognition with small sample learning. In this paper, we first preprocess the collected small sample dataset, and use the CycleGAN model to enhance the small sample dataset. Then, aiming at the problem of slow recognition speed, an improved YOLOX model is proposed for hot spot detection. Finally, our experimental results show that Cheetah has higher accuracy and stronger generalization ability and robustness than the traditional YOLOX method on the test set.},
  keywords={Photovoltaic systems;Training;Image recognition;Target recognition;Learning (artificial intelligence);Maintenance engineering;Big Data;Deep Neural Network;YOLO;Hot Spot Detection;Small Sample Learning},
  doi={10.1109/ICAIBD57115.2023.10206126},
  ISSN={2769-3554},
  month={May},}@ARTICLE{10247239,
  author={Sun, Shuguang and Yang, Feilong and Wang, Jingqin and Li, Ruijie and Wang, Zewei},
  journal={IEEE Sensors Journal}, 
  title={Fault Assessment of Circuit Breakers Based on Wide-Area Generalization Information and Improved ACGAN}, 
  year={2023},
  volume={23},
  number={20},
  pages={24954-24969},
  abstract={Switching mechanical faults pose a significant risk, characterized by an evolution from mild to severe states. Accurate identification of these faults can greatly improve the operational reliability of conventional circuit breakers (CCBs). In light of this, a fault degree assessment method is proposed based on the wide-area information fusion and improved deep learning models. First, the switching fault-related vibration signal segments are segmented to reduce the interference of invalid components caused by the multisource nature of the vibration signals. Meanwhile, the wide-area information of fault signal segments is fused to synthesize color image samples to enrich the fault characterization information and minimize the limitations of single domain analysis. Second, targeting at the dataset class imbalance, the size of samples is expanded using the Wasserstein auxiliary classifier generative adversarial network with gradient penalty (WACGAN-GP) to balance the dataset. It aims to effectively generate sample data highly similar to the real samples and improve the robustness of fault degree assessment. In addition, the MDA-ResNeXt model is constructed by incorporating the multitask learning (MTL) model into the improved residual network (ResNet) and dual attention network (DANet) to enhance the fault degree assessment by mutual learning of fault classification and degree assessment tasks. The fault degree assessment example analysis shows that this method exhibits higher classification accuracy and operational efficiency compared to other methods.},
  keywords={Circuit faults;Vibrations;Circuit breakers;Fault diagnosis;Image segmentation;Generative adversarial networks;Sensors;Conventional circuit breakers (CCBs);generative adversarial network (GAN);imbalanced fault diagnosis;multitask learning (MTL);wide-area information fusion},
  doi={10.1109/JSEN.2023.3311810},
  ISSN={1558-1748},
  month={Oct},}@INBOOK{10880607,
  author={Prasad, Deepti and Bhatia, Suman},
  booktitle={Generative Artificial Intelligence for Biomedical and Smart Health Informatics}, 
  title={Autism Spectrum Disorder Diagnosis: A Comprehensive Review of Machine Learning Approaches}, 
  year={2025},
  volume={},
  number={},
  pages={89-101},
  abstract={Summary <p>Understanding autism spectrum disorder (ASD) and offering effective, individualized therapies present special challenges. This thorough review analyses various facts about ASD, from its early diagnosis and medical treatments to its cutting&#x2010;edge therapeutic strategies and research endeavors. The study develops through thoroughly examining cutting&#x2010;edge machine learning and deep learning methods used in ASD research. Deep learning, Conditional Inference Forest, Random Forest, and Support Vector Machines emerge as key methods for understanding the complicated genomic and neuroimaging landscapes of ASD. Children with autism get benefit from play therapy and game&#x2010;based interventions because they provide opportunities for social interaction and skill development. The study also looks into the significance of awareness and early intervention. It offers a forward&#x2010;thinking roadmap and highlights the critical need for public education, easily available screening services, and specialized educational programs. The technology will be based on predictions of disease risk, deficits, and behavioral patterns, curating a dataset centered on Indian children and adults and integrating emotional and behavioral nuances. Collaborations with healthcare facilities and governmental organizations can be planned to close the accessibility gap and ensure that ASD treatments are available to people from every socioeconomic background, not just the wealthy few.</p>},
  keywords={Autism;Variable speed drives;Pediatrics;Anxiety disorders;Security;Prediction algorithms;Noise;Medical treatment;Medical diagnostic imaging;Socioeconomics},
  doi={10.1002/9781394280735.ch5},
  ISSN={},
  publisher={IEEE},
  isbn={9781394280728},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10880607},}@INPROCEEDINGS{10219414,
  author={Cheng, Yu-Huei and Chen, Po-Yun},
  booktitle={2023 Sixth International Symposium on Computer, Consumer and Control (IS3C)}, 
  title={Using Generative Adversarial Network Technology for Repairing Dynamically Blurred License Plates}, 
  year={2023},
  volume={},
  number={},
  pages={126-129},
  abstract={In recent years, due to the rapid development of artificial intelligence, many related technologies have been widely used in various fields, including the deep learning-based license plate recognition technology. However, there are still some problems with the deep learning-based license plate recognition technology, such as the inability to process license plate images with low light and dynamic blur. In addition, in real life, due to factors such as the speed of vehicle movement and camera exposure time, license plates often appear blurred, causing difficulties in license plate recognition. Therefore, this study proposes a method for restoring dynamic blur license plates based on Generative Adversarial Network (GAN) technology. Using a dataset of 16,900 original license plates and 25,000 iterations of training, a high-fidelity license plate model was trained and a dataset of 3,000 high-fidelity license plates was randomly generated, with dynamic blur effects added to the high-fidelity license plate dataset. Then, using the structure of the cGAN network in the pix2pix technology, the clear license plate was restored from the dynamic blur license plate. Our model was able to effectively restore 2,873 dynamic blur license plates out of 3,000 license plates with a blur level of 85 or more in the preliminary experiment on the dataset, with a restoration rate of 95.7%. The proposed method is more excellent and adaptable to most physical environments than traditional image processing methods. In the future, we will further improve and optimize the model, and introduce effects such as pollution, exposure, darkness, and obstruction to train a license plate restoration model with multiple functions to meet the increasingly wide-ranging needs of license plate recognition applications.},
  keywords={Training;Degradation;Deep learning;Adaptation models;Pollution;Generative adversarial networks;Image restoration;generative adversarial network;license plate recognition restoration;dynamic blurred license plate},
  doi={10.1109/IS3C57901.2023.00042},
  ISSN={2770-0496},
  month={June},}@INPROCEEDINGS{10569573,
  author={Huang, Zhen and Xiang, Yong},
  booktitle={2024 16th International Conference on Computer and Automation Engineering (ICCAE)}, 
  title={Conditional Generative Adversarial Network for Intrusion Detection System Based on Deep Learning}, 
  year={2024},
  volume={},
  number={},
  pages={237-241},
  abstract={With the development of big data and artificial intelligence, the tremendous amount of data have led to an increase in the number of cyberattacks. Convolutional neural network combined with intrusion detection system has been widely used to improve the performance of the traditional intrusion detection system. And KDD CPU99 is a frequently used dataset with old traffic data and unbalanced data distribution. In this paper, we proposed an intrusion detection system combined with generative adversarial network and deep residual network. The model is trained with NSL-KDD dataset which is an improved version of KDD CPU99. We also use CTGAN to synthesize data to provide more training samples for unknown cyberattacks. All the data is converted into gray scale images for ResNet-18. As a result, the proposed system perfoms well in experiment and shows great generalizaion performance.},
  keywords={Training;Measurement;Deep learning;Computational modeling;Intrusion detection;Generative adversarial networks;Convolutional neural networks;deep residual learning;ResNet-18;conditional generative adversarial network;SDV;Intrusion detection system;NSL-KDD},
  doi={10.1109/ICCAE59995.2024.10569573},
  ISSN={2154-4360},
  month={March},}@INPROCEEDINGS{10421735,
  author={Singhal, Megh and Saxena, Bhawna and Singh, Abhishek Pratap and Baranwal, Anurag},
  booktitle={2023 Second International Conference on Informatics (ICI)}, 
  title={Study of the effectiveness of Generative Adversarial Networks towards Music Generation}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Machine learning-based music generation has the potential to significantly change the music business and creative processes. The field of artificial intelligence offers new opportunities for creativity, artistic inquiry, and individualized musical experiences. Future music composition and generation will continue to be shaped by the research and development carried out in this area. Generative Adversarial Networks and reinforcement learning can be aptly used to improve the caliber and variety of music being created. The presented work discusses about the difficulties faced when creating music, whilst preserving musical coherence and preventing copying. A workflow is proposed for generating music using the LSTMGAN model. Loss graphs were used as the determinant of music quality. The results obtained show that LSTMGAN model performs remarkably well when used for music generation.},
  keywords={Music;Reinforcement learning;Generative adversarial networks;Market research;Data models;Research and development;Context modeling;Generative Adversarial Networks;GAN;LSTM;Music Generation},
  doi={10.1109/ICI60088.2023.10421735},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10421307,
  author={Amar, Vadik and Sonu and Shyan, Hatesh},
  booktitle={2023 International Conference on Integrated Intelligence and Communication Systems (ICIICS)}, 
  title={Text-to-Image Generator using GANs}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Text-to-image generation is a fascinating frontier in artificial intelligence, where machines translate textual descriptions into realistic visual representations. One remarkable approach that has stirred excitement and innovation in this field is the integration of Stable Diffusion, a ground-breaking deep learning framework. This fusion elevates the art of image synthesis, pushing the boundaries of what AI can achieve in creative content generation. At its core, text-to-image generation aims to bridge the semantic gap between language and vision, enabling machines to understand and generate images based on textual descriptions. Stable Diffusion, an evolution of generative adversarial networks (GANs), introduces stability and control to the training process. This method enhances the generation of high-quality images by mitigating issues like mode collapse, enabling better convergence, and facilitating the production of diverse and visually coherent outputs. The incorporation of Stable Diffusion into text-to-image generation projects has yielded remarkable results. It empowers AI models to create intricate and contextually relevant images from textual input. Whether it’s describing a serene mountain landscape or a whimsical unicorn in a magical forest, the AI harnesses the power of Stable Diffusion to breathe life into these imaginative concepts. One of the key advantages of Stable Diffusion is its ability to fine-tune the trade-off between image quality and diversity. By controlling the diffusion process, researchers and developers can manipulate the output variance, allowing them to strike the ideal balance for their specific application. This adaptability makes Stable Diffusion an invaluable tool in the toolkit of text-to-image generation projects. Moreover, the stable training dynamics offered by this framework empower developers to explore various text-conditional generation tasks beyond mere realism. It opens the door to generating images that evoke specific emotional responses, aligning AI-generated visuals with human intentions and artistic vision.},
  keywords={Training;Visualization;Recurrent neural networks;PSNR;Semantics;Generative adversarial networks;Artificial intelligence;Stable Diffusion Model;Machine Learning;Python;Image Synthesis;Creative AI;NLP;Creative Application;Deep Learning Model;Diversity},
  doi={10.1109/ICIICS59993.2023.10421307},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11158030,
  author={Su, Baohua and Peng, Jun and Xu, Heng and Chen, Kaiyi and Zhou, Zhuoxiao and Liu, Hua},
  booktitle={2025 5th International Conference on Artificial Intelligence and Education (ICAIE)}, 
  title={The Personalized Scene-Based AI Agents: Exploring Chinese Language Learning Among International Students}, 
  year={2025},
  volume={},
  number={},
  pages={117-122},
  abstract={With the development of deep learning and large language model (LLM) technologies, AI agents, as a key application of generative artificial intelligence (AIGC), have demonstrated significant potential in the field of international Chinese education. Personalized scenario AI agents, leveraging open-source AI chat frameworks, large-scale Chinese language corpora, and dynamic adjustment mechanisms (RAG, PAL, ReAct), effectively address key challenges in Chinese language acquisition for international students. These challenges include a lack of communicative practice, difficulties in acquiring everyday expressions, the inability of large-class instruction to accommodate individual differences, and the absence of real-time feedback. By constructing immersive interactive scenarios, personalized learning pathways, and intelligent feedback systems, AI agents enhance learning efficiency and flexibility while providing new pathways for the intelligent development of international Chinese education.},
  keywords={Human computer interaction;Deep learning;Generative AI;Large language models;Education;Ecosystems;Learning (artificial intelligence);Cross-cultural communication;Real-time systems;Artificial intelligence;AI agent;personalized learning;international Chinese education;intelligent teaching;language acquisition for international students},
  doi={10.1109/ICAIE64856.2025.11158030},
  ISSN={},
  month={May},}@INPROCEEDINGS{10852487,
  author={Krouska, Akrivi and Troussas, Christos and Voyiatzis, Ioannis and Mylonas, Phivos and Sgouropoulou, Cleo},
  booktitle={2024 2nd International Conference on Foundation and Large Language Models (FLLM)}, 
  title={ChatGPT-based Recommendations for Personalized Content Creation and Instructional Design with a Tailored Prompt Generator}, 
  year={2024},
  volume={},
  number={},
  pages={295-299},
  abstract={Recent advancements in Artificial Intelligence (AI) have significantly influenced educational innovations, making learning environments more sophisticated with personalized learning, tailored feedback, and learning analytics. Among these advancements, Generative AI, namely ChatGPT, has emerged as a powerful tool in education. ChatGPT's ability to generate human-like content in real-time can assist educators with course design and educational material creation, allowing for enhanced instructional strategies without starting from scratch. Moreover, integrating ChatGPT into the recommendation process offers superior understanding of user needs and delivery of context-aware recommendations. In view of the above, this paper explores the integration of ChatGPT with a tailored prompt generator within an intelligent authoring system to offer effective recommendations for personalized content creation and instructional design. The system was evaluated and compared to its conversional version where instructors manually use ChatGPT. The findings indicate significant improvements in system usability, content quality, personalization, and time and effort savings, demonstrating the effectiveness of the proposed approach.},
  keywords={Technological innovation;Authoring systems;Large language models;Education;Learning (artificial intelligence);Chatbots;Generators;Real-time systems;Usability;Recommender systems;Authoring tool;ChatGPT;Conversational recommender system;Generative AI;Educational content;Instructional design;Personalized learning},
  doi={10.1109/FLLM63129.2024.10852487},
  ISSN={},
  month={Nov},}@ARTICLE{6792180,
  author={Risi, Sebastian and Stanley, Kenneth O.},
  journal={Artificial Life}, 
  title={An Enhanced Hypercube-Based Encoding for Evolving the Placement, Density, and Connectivity of Neurons}, 
  year={2012},
  volume={18},
  number={4},
  pages={331-363},
  abstract={Intelligence in nature is the product of living brains, which are themselves the product of natural evolution. Although researchers in the field of neuroevolution (NE) attempt to recapitulate this process, artificial neural networks (ANNs) so far evolved through NE algorithms do not match the distinctive capabilities of biological brains. The recently introduced hypercube-based neuroevolution of augmenting topologies (HyperNEAT) approach narrowed this gap by demonstrating that the pattern of weights across the connectivity of an ANN can be generated as a function of its geometry, thereby allowing large ANNs to be evolved for high-dimensional problems. Yet the positions and number of the neurons connected through this approach must be decided a priori by the user and, unlike in living brains, cannot change during evolution. Evolvable-substrate HyperNEAT (ES-HyperNEAT), introduced in this article, addresses this limitation by automatically deducing the node geometry from implicit information in the pattern of weights encoded by HyperNEAT, thereby avoiding the need to evolve explicit placement. This approach not only can evolve the location of every neuron in the network, but also can represent regions of varying density, which means resolution can increase holistically over evolution. ES-HyperNEAT is demonstrated through multi-task, maze navigation, and modular retina domains, revealing that the ANNs generated by this new approach assume natural properties such as neural topography and geometric regularity. Also importantly, ES-HyperNEAT's compact indirect encoding can be seeded to begin with a bias toward a desired class of ANN topographies, which facilitates the evolutionary search. The main conclusion is that ES-HyperNEAT significantly expands the scope of neural structures that evolution can discover.},
  keywords={Compositional pattern-producing networks;indirect encoding;HyperNEAT;neuroevolution;artificial neural networks;generative and developmental systems},
  doi={10.1162/ARTL_a_00071},
  ISSN={1064-5462},
  month={Oct},}@ARTICLE{10736352,
  author={Ouyang, Fan and Guo, Mingyue and Zhang, Ning and Bai, Xianping and Jiao, Pengcheng},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Comparing the Effects of Instructor Manual Feedback and ChatGPT Intelligent Feedback on Collaborative Programming in China's Higher Education}, 
  year={2024},
  volume={17},
  number={},
  pages={2173-2185},
  abstract={Artificial general intelligence (AGI) has gained increasing global attention as the field of large language models undergoes rapid development. Due to its human-like cognitive abilities, the AGI system has great potential to help instructors provide detailed, comprehensive, and individualized feedback to students throughout the educational process. ChatGPT, as a preliminary version of the AGI system, has the potential to improve programming education. In programming, students often have difficulties in writing codes and debugging errors, whereas ChatGPT can provide intelligent feedback to support students’ programming learning process. This research implemented intelligent feedback generated by ChatGPT to facilitate collaborative programming among student groups and further compared the effects of ChatGPT with instructors’ manual feedback on programming. This research employed a variety of learning analytics methods to analyze students’ computer programming performances, cognitive and regulation discourses, and programming behaviors. Results indicated that no substantial differences were identified in students’ programming knowledge acquisition and group-level programming product quality when both instructor manual feedback and ChatGPT intelligent feedback were provided. ChatGPT intelligent feedback facilitated students’ regulation-oriented collaborative programming, while instructor manual feedback facilitated cognition-oriented collaborative discussions during programming. Compared to the instructor manual feedback, ChatGPT intelligent feedback was perceived by students as having more obvious strengths as well as weaknesses. Drawing from the results, this research offered pedagogical and analytical insights to enhance the integration of ChatGPT into programming education at the higher education context. This research also provided a new perspective on facilitating collaborative learning experiences among students, instructors, and the AGI system.},
  keywords={Programming profession;Chatbots;Manuals;Education;Codes;Collaboration;Artificial general intelligence;MATLAB;Debugging;Graphical user interfaces;Artificial general intelligence (AGI);ChatGPT;collaborative learning;generative artificial intelligence (AI);programming education},
  doi={10.1109/TLT.2024.3486749},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{9725820,
  author={Reshak, Sajid Hamed},
  booktitle={2022 International Conference for Advancement in Technology (ICONAT)}, 
  title={Drugs Designing Using Artificial Intelligence Based Pharmaceutical Systems}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  abstract={In the field of Artificial Neural Networks (ANNs), computer algorithms and comparable to the structure of the brain's neurons are used for modelling and pattern recognition. What the brain does with all of its experiences is learn. When one views the brain as a biological neuron, one finds inputs coming in from a variety of external resources, such as the visual cortex, the hippocampus, and the thalamus, and the cell processes those inputs, performing a nonlinear operation before producing a conclusion. Adaptive biological neurons serve as the ANNs’ analogues, which mimic the biological nervous system. In contrast to statistical modelling, ANNs are simple and versatile and don't need a defined experimental design. They may use partial or historical data to map functions. ANNs are excellent pattern and classification recognizers, as well as having the capacity to make choices while using imprecise input data. The applications of ANNs to many fields, including pharmaceutical research, engineering, psychology, and medicinal chemistry, are well documented. Applied neural network technique has several potential applications in the pharmaceutical sciences. We shall describe several instances of ANNs in drug discovery in this article.},
  keywords={Drugs;Visualization;Computational modeling;Biological system modeling;Neurons;Psychology;Artificial neural networks;Drugs;Machine Learning;ANN;FFNN;Optimization},
  doi={10.1109/ICONAT53423.2022.9725820},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10983285,
  author={Suri, Chanchal Sachdeva and Shukla, Shubhendu Shekher and Pal, Raghavesh and Srivastava, Vivek and Talele, Gokul and B, Mahendra Kumar},
  booktitle={2024 IEEE 11th Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON)}, 
  title={Generative AI in Content Creation: Opportunities and Ethical Challenges}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Generative artificial intelligence has enabled the automation of text, images, audio, and video production, thereby transforming media, marketing, and entertainment among other fields. Through simplification and improvement of processes made possible by this technology, new opportunities like shorter production periods, more innovation, along with tailored content creation arise. Still, there are serious moral issues about these benefits. Some fear that cautious use of artificial intelligence in content creation might result in issues with intellectual property, deepfakes, false information, along with possibly job loss for artistic individuals. Because of their intrinsic biases along with opaque decision making processes, AI models might amplify incorrect information along with support negative beliefs. While generative AI has the power to transform content creation, ethical standards along with responsible conduct have to be followed to control its risks. This paper investigates two of these effects.},
  keywords={Ethics;Technological innovation;Automation;Generative AI;Scalability;Entertainment industry;Production;Transforms;Intellectual property;Standards;AI;Content Creation;Ethical Challenges;Performance;Quality},
  doi={10.1109/UPCON62832.2024.10983285},
  ISSN={2687-7767},
  month={Nov},}@INPROCEEDINGS{11158622,
  author={Yao, Jiajia and Liu, Mingyue and Zhang, Ruohan and Zheng, Yuan},
  booktitle={2025 5th International Conference on Artificial Intelligence and Education (ICAIE)}, 
  title={Research on the Impact of Human-Machine Collaborative Dialogue on Normal University Students' Reflection and Instructional Design Abilities in Teaching Resources}, 
  year={2025},
  volume={},
  number={},
  pages={304-308},
  abstract={In the era of generative artificial intelligence (GAI), the application of human-machine collaborative dialogue, grounded in GAI, holds significant promise within the educational and instructional domains. The integration of artificial intelligence with normal education has emerged as a pivotal topic in the cultivation of prospective teachers. This study has employed exploratory experiments with single pre-post measurements and epistemic network analysis to investigate the influence of human-machine collaborative dialogue on the dialectical reflection and instructional resource design capacities of normal students. The research reveals the following insights: Human-machine collaborative learning activities based on GAI can enhance the dialectical reflection ability of normal education students, and different human-machine collaborative behaviors have varying degrees of impact; The activities can effectively improve the instructional resource design capacity of normal education students, and different human-machine collaborative behaviors have differing effects; The human-machine collaborative dialogue based on GAI can indirectly affect students' instructional resource design capacity by changing their dialectical reflection ability. Drawing on these findings, the research offers recommendations on leveraging GAI to more effectively nurture the reflective and instructional resource design competencies of normal students.},
  keywords={Generative AI;Federated learning;Human-machine systems;Education;Collaboration;Network analyzers;Reflection;Human-machine collaborative dialog;Normal education;Dialectical reflection ability;Instructional resource design capacity;Epistemic Network Analysis},
  doi={10.1109/ICAIE64856.2025.11158622},
  ISSN={},
  month={May},}@INPROCEEDINGS{9954679,
  author={Jo, Sihyeon and Yuan, Zhenyuan and Kim, Seong-Woo},
  booktitle={2022 IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia)}, 
  title={Interactive Storyboarding for Rapid Visual Story Generation}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  abstract={Artificial Intelligence (AI) technologies have impacted almost every domain and its systems, including the entertainment industry. Although AI-based systems are expected to offer significant benefits in making content, it is still challenging to build a real-world AI application that can effectively contribute to content production. In this paper, we present a novel approach for developing a storyboard; a sequence of images displayed for previsualizing a motion picture, animation, motion graphic, or interactive media. We implement a prototype system, Gennie, that can interact with users and suggest AI-generated sketches for each scene of the storyboard.},
  keywords={Deep learning;Visualization;Prototypes;Entertainment industry;Production;Media;Motion pictures;Human-AI Interaction;multimodal embedding;large-scale pre-trained model},
  doi={10.1109/ICCE-Asia57006.2022.9954679},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10578564,
  author={Israilidis, John and Chen, Wen-Yuan and Tsakalerou, Mariza},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Software Development and Education: Transitioning Towards AI Enhanced Teaching}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper investigates the impact of large language model (LLM) AI tools, such as ChatGPT and Copilot, on software development education, focusing on usability, efficiency, and effectiveness in real-world scenarios. The research employs a quantitative approach, utilizing a survey of 50 software developers with varying levels of experience. Preliminary findings suggest that AI tools have a positive influence on expediting coding tasks and automating text generation, particularly in the early stages of product development. Challenges related to customization, accuracy, and transparency, as well as concerns about their potential impacts on employment, personal privacy, and ethical boundaries, have been identified. Pointers and initial recommendations for transitioning to AI-enhanced teaching and optimizing interactions between learners and generative AI practices are provided.},
  keywords={Surveys;Privacy;Ethics;Generative AI;Focusing;Software;Product development;AI tools;software development;education},
  doi={10.1109/EDUCON60312.2024.10578564},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10140749,
  author={Mathur, Aeshita and Dabas, Ameesha and Rana, Parikshit and Kumar, Sanjay},
  booktitle={2023 2nd International Conference on Applied Artificial Intelligence and Computing (ICAAIC)}, 
  title={Recoloring Grayscale Images using GAN}, 
  year={2023},
  volume={},
  number={},
  pages={1628-1632},
  abstract={In this paper, we intend to develop an efficient method for Colorizing Grayscale Images such that the output images are close to their real colors. The main objective is to produce a precise image should be produced, which means that the output image should be as close to its natural color as possible. In colorization, there is no aim to recover the ground truth color; rather, the aim is to create a plausible colorization that is useful to the user, even if it differs from the ground truth color. In order to solve this problem, we use Convolutional Neural Networks (CNN) and a variety of deep learning techniques. Instead of using vectors drawn at random from the probability distribution, we employ Conditional Generative Adversarial Networks (GAN). This will enable it to extract different features and understand the correlations between them in order to predict colored images.},
  keywords={Training;Image coding;Image color analysis;Neural networks;Gray-scale;Generative adversarial networks;Feature extraction;Deep Learning;Colorization;Gray-scale;Generative Adversarial Network;Convolutional Neural Networks;Feature Extraction;Transfer Knowledge;image-to-image translation},
  doi={10.1109/ICAAIC56838.2023.10140749},
  ISSN={},
  month={May},}@INPROCEEDINGS{10168553,
  author={Qi, Pengfei and Zheng, Yuanjin},
  booktitle={2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS)}, 
  title={Image Recovery Through Scattering Media via GAN Reconstruction and SNES Optimization}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Optical image recovery through scattering media is a significant yet challenging problem. Iterative wavefront shaping is one of the powerful tools to re-distribute the diffusive light and compensate for the diffuser by controlling the incident wavefront. However, in the scenario that only a feedback signal on the camera can be obtained, this technology would fail due to the lack of target images. In this paper, we propose a new scheme for recovering images through scattering media in an absence of target images. In particular, we employ an improved Generative Adversarial Network (GAN) for computational reconstruction and separable natural evolution strategy (SNES) for wavefront shaping optimization. Both simulation and experimental results suggest that the proposed scheme will open up new opportunities in the applications of biomedical imaging, optical encryption, holographic display, etc.},
  keywords={Optical feedback;Scattering;Media;Holography;Generative adversarial networks;Optical imaging;Holographic optical components;Inverse scattering;Computational imaging;Generative Adversarial Network;Wavefront shaping},
  doi={10.1109/AICAS57966.2023.10168553},
  ISSN={2834-9857},
  month={June},}@INPROCEEDINGS{10710011,
  author={Wang, Xingang and Li, Zhipeng and Wang, Daigang and Meng, Qing and Xia, Qinghe and Wang, Huachun and Zhang, Chengming},
  booktitle={2024 International Conference on Artificial Intelligence and Power Systems (AIPS)}, 
  title={Distributionally Robust Planning Method of Power Generation and Transmission Considering Multi-Energy Complementary and dc Transmission}, 
  year={2024},
  volume={},
  number={},
  pages={448-452},
  abstract={The large-scale integration of new energy resource with strong uncertainty brings great challenges to the planning and operation of power systems. In this paper, a distribution ally robust planning method of generation and transmission considering the multi-energy complementary and DC transmission is proposed. Firstly, a joint planning model of generation and transmission considering wind-pumped storage complementary and DC transmission power adjustment is established with the objective of minimizing the annual comprehensive planning cost. On this basis, considering the strong uncertainty of wind power output, a two-stage distribution ally robust planning model of generation and transmission is constructed. And a modified generative adversarial network is adopted to generate typical planning scenarios. Finally, simulation with Graver-6 node system verifies that the proposed planning method can form a planning scheme that balances economic improvement and conservative control.},
  keywords={Renewable energy sources;Uncertainty;Fluctuations;Energy resources;Optimization methods;Wind power generation;Generative adversarial networks;Large scale integration;Planning;Power systems;multi-energy complementarity;DC transmission;generation and transmission network planning;distributionally robust optimization;generative adversarial network},
  doi={10.1109/AIPS64124.2024.00098},
  ISSN={},
  month={April},}@INPROCEEDINGS{10409053,
  author={Jia, Junxia and Duan, Feipeng},
  booktitle={2023 IEEE 11th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={CGAN and SVM Based Transformer Fault Acoustic Signal Synthesis Technology}, 
  year={2023},
  volume={11},
  number={},
  pages={811-815},
  abstract={In the actual operation environment of transformer, the fault is relatively rare, and the fault data that can be collected is very limited. The imbalance of data limits the accuracy and stability of fault diagnosis. In order to pay more attention to learning the probability density distribution of the original samples in the imbalanced data classification problem, this paper proposes a new method based on Conditional Generative Adversarial Networks. CGAN) and Support Vector Machine (SVM) are used to synthesize transformer fault acoustic signals to solve the problem of small sample size in transformer fault diagnosis. The three evaluation indicators of Accuracy, G-mean and F-measure are used, and the accuracy of the model used in this paper is more than 90%.},
  keywords={Support vector machines;Fault diagnosis;Training;Transformers;Generative adversarial networks;Acoustics;Signal synthesis;Transformer fault diagnosis;Signal synthesis;Conditional generative adversarial networks;Support vector machine;Imbalanced samples Introduction},
  doi={10.1109/ITAIC58329.2023.10409053},
  ISSN={2693-2865},
  month={Dec},}@INPROCEEDINGS{10823272,
  author={Sivakumar, C and Vali, Tellabati Khasim and Reddy, Pavujenni Sai Bhagyesh and Meghana, Malisetti Lakshmi and Sukumar, Yeddala},
  booktitle={2024 International Conference on IoT Based Control Networks and Intelligent Systems (ICICNIS)}, 
  title={AI-Powered Video Surveillance for Enhanced Intrusion Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1630-1634},
  abstract={The design and development of an AI-Powered Video Surveillance System for Enhanced Intrusion Detection project aims to redefine today's conventional surveillance approaches by integrating cutting-edge artificial intelligence methods for automated detection of threats in real-time. In particular, unlike the existing systems that require human monitoring, and which can result in inattention, missing possible strikes, or false alarms, the current application has the potential to increase the accuracy, efficiency, and responsiveness of intrusion detection in a number of unsecure environments, including businesses, public areas, and facilities. The use of computer vision methods and deep learning principles, such as convolutional neural networks and transformers, enables the system to analyze the feed from a live video and detect unusual activities. The AI solutions are trained on vast datasets to recognize multiple types of intrusions, including both physically and unusual behaviors, thereby reducing the amount of human monitoring and the number of false alarms. Additionally, the current video surveillance approach is not limited to monitoring the current filter but has a number of other features, including object tracking, facial recognition, and general behavioral analysis. The use of AI analytics allows the system to become more accurate through time and gives the current system an ability to learn and recognize new patterns. Overall, the proposed AI-powered video network is more solid, intelligent, and reliable, and allows it to eliminate strikes in unprotected areas and eliminate falsesures and unresponsive behavior.},
  keywords={Accuracy;Image recognition;Face recognition;Wind speed;Intrusion detection;Video surveillance;Transformers;Real-time systems;Convolutional neural networks;Wind forecasting;wind speed forecasting;deep learning;satellite images;weather prediction;CNN;RNN;transfer learning;data augmentation;predictive modeling;wind energy integration;disaster management},
  doi={10.1109/ICICNIS64247.2024.10823272},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10098003,
  author={Ahuja, Mohit Kumar and Sahil, Sahil and Spieker, Helge},
  booktitle={2022 IEEE 34th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={FoCA: Failure-oriented Class Augmentation for Robust Image Classification}, 
  year={2022},
  volume={},
  number={},
  pages={944-948},
  abstract={Image classification with classes of varying difficulty can cause performance disparity in deep learning models and reduce the overall performance and reliability of the predictions. In this paper, we introduce a failure-oriented class augmentation (FoCA) technique to address the problem of imbalanced performance in image classification, where the trained model has performance deficits in some of the dataset's classes. By employing Generative Adversarial Networks (GANs) to augment these deficit classes, we finetune the model towards a balanced performance among the different classes and an overall better performance on the whole dataset. Unlike earlier works, during training, our method focuses on those classes with the lowest accuracy after the initial training phase. Only these classes are augmented to boost the accuracy, which leads to better performance. FoCA is designed to be used with a light-weight GAN method to make the GAN-based augmentation viable and effective, even for datasets with only few images per class, while simultaneously requiring less computation than other, more complex GAN methods. Our implementation of FoCA combines this light-weight GAN method for class-wise data augmentation with state-of-the-art deep neural network techniques for training. Experiments show an overall improvement from FoCA with competitive or better accuracy than the previous state-of-the-art on five datasets with different sizes and image resolutions.},
  keywords={Training;Deep learning;Image resolution;Supervised learning;Pipelines;Predictive models;Generative adversarial networks;deep learning;generative models;data augmentation;image classification;supervised learning},
  doi={10.1109/ICTAI56018.2022.00144},
  ISSN={2375-0197},
  month={Oct},}@INPROCEEDINGS{11140515,
  author={Meng, Qingdian and Zhang, Hong},
  booktitle={2025 4th International Symposium on Robotics, Artificial Intelligence and Information Engineering (RAIIE)}, 
  title={GAN-Based Encoder-Decoder Method for Image Deblurring}, 
  year={2025},
  volume={},
  number={},
  pages={335-338},
  abstract={Image deblurring is one of the classic tasks in the field of computer vision, holding significant research importance and practical value. The Multi-Input Multi-Output (MIMO) encoder-decoder network, characterized by its small parameter size and low training costs, has been adopted for image deblurring. However, this method still suffers from poor generation quality and insufficient capability to capture details and textures. To address these issues, this paper proposes a refined network structure based on MIMO-UNet to improve image quality. The network is optimized across three principal dimensions. Firstly, it integrates a generative adversarial network (GAN) where the generator is structured as a MIMO-UNet and introduces a discriminator, forming a GAN. Secondly, within this GAN framework, the traditional residual blocks in the generator are substituted with Frequency Feature Extraction (FFE) Blocks, which augment the utilization of frequency domain features. Thirdly, the generator's total loss includes additional frequency domain L2 loss, adversarial loss, and edge loss, which improves the model’s ability to extract key features. Experimental results demonstrate that compared to the baseline MIMO-UNet, the proposed method has increased the PSNR metric by 3.54% and the SSIM metric by 0.63%. Overall, the results are satisfactory.},
  keywords={Deblurring;Training;Performance evaluation;Image quality;Costs;Frequency-domain analysis;Image edge detection;Generative adversarial networks;Feature extraction;Generators;Image Deblur;MIMO-UNet;Generative Adversarial Networks;Loss function},
  doi={10.1109/RAIIE65740.2025.11140515},
  ISSN={},
  month={June},}@INPROCEEDINGS{10864165,
  author={Guan, Le and Zhu, Li and Zhao, Hongsen and Wang, Zhen},
  booktitle={2024 5th International Conference on Artificial Intelligence and Computer Engineering (ICAICE)}, 
  title={FM-GAN: A Novel Algorithm Based Data Generation Methodfor Rolling Bearings Under Imbalanced Samples}, 
  year={2024},
  volume={},
  number={},
  pages={378-383},
  abstract={The scarcity of fault samples affects classification accuracy seriously in rotating equipment monitoring. To address data imbalance, this paper proposes a Fourier transform and Multi-head attention optimized Generative Adversarial Network (FM-GAN). The generator, enhanced with multi-head attention, generates signals that are co-optimized with the original signals. Fourier transform is then applied to obtain the real and imaginary parts of the signals for further refinement. Experiments show that the samples generated by FM-GAN are highly integrated with actual data in terms of feature representation and classification performance, effectively addressing the issue of data imbalance.},
  keywords={Training;Fourier transforms;Frequency-domain analysis;Rolling bearings;Data collection;Generative adversarial networks;Data models;Stability analysis;Generators;Monitoring;Deep learning;Generative Adversarial Network;Fourier transform;Data imbalance},
  doi={10.1109/ICAICE63571.2024.10864165},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10405450,
  author={Zhang, Shuo and Gu, Lize},
  booktitle={2023 5th International Conference on Artificial Intelligence and Computer Applications (ICAICA)}, 
  title={Improving Robustness of Unsupervised Domain Adaptation with Adversarial Networks}, 
  year={2023},
  volume={},
  number={},
  pages={307-310},
  abstract={Unsupervised Domain Adaptation (UDA) has been subject to comprehensive investigation and has achieved significant success in real-world scenarios by transferring information from labeled source domains to non-labeled target domains. Nonetheless, the vulnerability of UDA models to adversarial attacks remains a formidable challenge. While Adversarial Training (AT) is acknowledged as one of the most potent defense mechanisms, it cannot be directly applied to UDA settings. Furthermore, there have been few studies that explore the application of AT in UDA setting. In this paper, we strive to leverage Generative Adversarial Network (GAN) to generate adversarial examples for target data, subsequently incorporating them into AT. To generate high-quality adversarial examples and achieve better adversarial robustness of UDA models, we propose the AAT algorithm. We apply AAT to two different UDA algorithms and evaluate on three datasets. The results demonstrate that our model achieves improved adversarial robustness and a balance between accuracy on clean data and accuracy under adversarial conditions.},
  keywords={Training;Adaptation models;Computational modeling;Computer applications;Generative adversarial networks;Robustness;Data models;Unsupervised Domain Adaptation;Adversarial Attacks;Adversarial Training;Generative Adversarial Network;Robustness},
  doi={10.1109/ICAICA58456.2023.10405450},
  ISSN={2833-8413},
  month={Nov},}@INPROCEEDINGS{9951558,
  author={Tiwari, Akshata},
  booktitle={2022 Fourth International Conference on Transdisciplinary AI (TransAI)}, 
  title={Effectiveness of Deep Learning for Erasing Satellite Streaks in Astronomical Photos}, 
  year={2022},
  volume={},
  number={},
  pages={30-31},
  abstract={Since 2019, many companies have been launching their satellites into lower earth orbit to ensure greater global connectivity. However, the vast number of satellites threatens the work of ground-based observatories. Astrophotographers are not able to capture several regions of space without interference from satellites, an indication that efficient tracking of near-earth asteroids is hindered and important observations, such as detecting asteroid proximity, may be compromised. Many scientists have considered artificial intelligence (AI) as a potential solution to erase satellite streaks from these images. In this position paper, we look into the ability of AI to accomplish this task. We mention current developments and limitations of AI software and discuss potential improvements that would enable AI to efficiently mask satellite streaks from astronomical images.},
  keywords={Space vehicles;Earth;Satellites;Observatories;Asteroids;Interference;Software;Astrophotography;Machine Learning;Satellite masking;Image editing},
  doi={10.1109/TransAI54797.2022.00011},
  ISSN={},
  month={Sep.},}@ARTICLE{10254282,
  author={Jiao, Licheng and Huang, Zhongjian and Lu, Xiaoqiang and Liu, Xu and Yang, Yuting and Zhao, Jiaxuan and Zhang, Jinyue and Hou, Biao and Yang, Shuyuan and Liu, Fang and Ma, Wenping and Li, Lingling and Zhang, Xiangrong and Chen, Puhua and Feng, Zhixi and Tang, Xu and Guo, Yuwei and Quan, Dou and Wang, Shuang and Li, Weibin and Bai, Jing and Li, Yangyang and Shang, Ronghua and Feng, Jie},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={Brain-Inspired Remote Sensing Foundation Models and Open Problems: A Comprehensive Survey}, 
  year={2023},
  volume={16},
  number={},
  pages={10084-10120},
  abstract={The foundation model (FM) has garnered significant attention for its remarkable transfer performance in downstream tasks. Typically, it undergoes task-agnostic pretraining on a large dataset and can be efficiently adapted to various downstream applications through fine-tuning. While FMs have been extensively explored in language and other domains, their potential in remote sensing has also begun to attract scholarly interest. However, comprehensive investigations and performance comparisons of these models on remote sensing tasks are currently lacking. In this survey, we provide essential background knowledge by introducing key technologies and recent developments in FMs. Subsequently, we explore essential downstream applications in remote sensing, covering classification, localization, and understanding. Our analysis encompasses over 30 FMs in both natural and remote sensing fields, and we conduct extensive experiments on more than 10 datasets, evaluating global feature representation, local feature representation, and target localization. Through quantitative assessments, we highlight the distinctions among various FMs and confirm that pretrained large-scale natural FMs can also deliver outstanding performance in remote sensing tasks. After that, we systematically presented a brain-inspired framework for remote sensing foundation models (RSFMs). We delve into the brain-inspired characteristics in this framework, including structure, perception, learning, and cognition. To conclude, we summarize 12 open problems in RSFMs, providing potential research directions. Our survey offers valuable insights into the burgeoning field of RSFMs and aims to foster further advancements in this exciting area.},
  keywords={Frequency modulation;Adaptation models;Remote sensing;Brain modeling;Data models;Transformers;Task analysis;Brain modeling;deep learning;foundation model;image analysis;remote sensing},
  doi={10.1109/JSTARS.2023.3316302},
  ISSN={2151-1535},
  month={},}@INPROCEEDINGS{10578883,
  author={Pérez-Colado, Iván J. and Freire-Morán, Manuel and Calvo-Morata, Antonio and Pérez-Colado, Víctor M. and Fernández-Manjón, Baltasar},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={AI Asyet Another Tool in Undergraduate Student Projects: Preliminary Results}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={How do students use artificial intelligence tools in coursework projects when given the liberty to do so, with the only requirement of documenting how, where and why? We describe experiences with two groups of undergraduates in courses related to serious game authoring and human-computer interaction, both carried out in the second semester of 2023. In the serious games course, students were given the option of following a teacher-developed methodology for generating graphical assets for their serious games using a set of generative AI tools. This methodology was explained in the class but not hands on lab was carried out. In the interaction course, students were free to choose which AI tools to use when designing their system or in the development of their project documentation. Despite the limited number of participants (41 in total) we can see very different views and degrees of involvement: while some tried to use AI for as many tasks as possible, others considered that the learning curve for those tools was too steep to be worthwhile. Both experiences included a free-text survey at the end, and taken together, provide insights into how both supervised and unsupervised generative AI use could impact undergraduate projects in similar subjects. In addition to describing how students chose to use the tools, and the main takeaways from their survey response, we also discuss some of the ethical aspects about the access to the tools and what should be the minimal conditions to be met to allow the equitable use of AI in the classroom.},
  keywords={Surveys;Human computer interaction;Generative AI;Games;Documentation;Task analysis;Engineering education;AI in education;generative artificial intelligence;game development;serious games authoring;goal-driven design},
  doi={10.1109/EDUCON60312.2024.10578883},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{9757576,
  author={Rings, Sebastian and Steinicke, Frank},
  booktitle={2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, 
  title={Local Free-View Neural 3D Head Synthesis for Virtual Group Meetings}, 
  year={2022},
  volume={},
  number={},
  pages={333-337},
  abstract={Virtual group meetings provide enormous potential for remote group communication. However, today's video conferences incur numer-ous challenges compared to face-to-face meetings. For instance, perception of correct gaze, deictic relations, or eye-to-eye contact is impeded due to the fact that the camera is offset from the eyes of the other users' avatars and that the gallery view is different for each group member. In this paper, we describe how 3D neural heads can be synthesized to overcome these limitations. Therefore, we generate different head poses using a generative adversarial network for a given source image frame using state-of-the-art technology. These head poses can then be viewed in a local space to freely control the gaze of the head poses. We introduce and discuss five use cases for these synthesized head poses that aim to improve intelligent agents and virtual avatar representations in regular video group meetings.},
  keywords={Solid modeling;Head;Three-dimensional displays;Conferences;Avatars;Virtual groups;User interfaces;Human-centered computing-Human computer interaction (HCI)-HCI theory;concepts and models-;Computing methodologies-Artificial intelligence-Distributed artificial intelligence-Intelligent agents},
  doi={10.1109/VRW55335.2022.00075},
  ISSN={},
  month={March},}@INPROCEEDINGS{10669885,
  author={Sikand, Samarth and Mehra, Rohit and Sharma, Vibhu Saujanya and Kaulgud, Vikrant and Podder, Sanjay and Burden, Adam P.},
  booktitle={2024 IEEE/ACM International Workshop on Responsible AI Engineering (RAIE)}, 
  title={Do Generative AI Tools Ensure Green Code? An Investigative Study}, 
  year={2024},
  volume={},
  number={},
  pages={52-55},
  abstract={Software sustainability is emerging as a primary concern, aiming to optimize resource utilization, minimize environmental impact, and promote a greener, more resilient digital ecosystem. The sustainability or ’greenness’ of software is typically determined by the adoption of sustainable coding practices. With a maturing ecosystem around generative AI, many software developers now rely on these tools to generate code using natural language prompts. Despite their potential advantages, there is a significant lack of studies on the sustainability aspects of AI-generated code. Specifically, how environmentally friendly is the AI-generated code based upon its adoption of sustainable coding practices? In this paper, we present the results of an early investigation into the sustainability aspects of AI-generated code across three popular generative AI tools — ChatGPT, BARD, and Copilot. The results highlight the default non-green behavior of tools for generating code, across multiple rules and scenarios. It underscores the need for further in-depth investigations and effective remediation strategies.CCS CONCEPTS• Social and professional topics → Sustainability; • Computing methodologies → Natural language generation.},
  keywords={Codes;Generative AI;Green products;Ecosystems;Natural languages;Natural language generation;Software;artificial intelligence;sustainability;carbon emissions;generative AI;green code},
  doi={},
  ISSN={},
  month={April},}@INPROCEEDINGS{10910510,
  author={G, Abinaya and Rao, Guttulapavan Durga and Gopal, Pragada Sri Ram and M, Kaushik and Vignesh, B Sai Venkata},
  booktitle={2024 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES)}, 
  title={Automated Document Processing: Combining OCR and Generative AI for Efficient Text Extraction and Summarization}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Technological advancement including the use of new media formats in creating digital documents calls for the development of enhanced processing techniques and methods. Old school Optical Character Recognition (OCR) tools remain useful but are inadequate when faced with sophisticated documents or low-quality scans. Also, summarizing the textual content of such papers continues to be a manual process and adds inefficiency and potential errors in information gathering. Finally, an integrated approach to the automation of both text extraction and summarization based on improved OCR and Google Gemini's generative AI technique is presented in this paper. By using more precise OCR algorithms, the system greatly increases accurate text recognition from poorly quality scans or complex structures. At the same time, the employment of generative AI models contributes to the formulation of brief and relevant summaries and also improves document retrieval and handling. Its effectiveness has thus been confirmed by testing on a variety of documents, and it has increased both accuracy and utility compared to previous techniques.},
  keywords={Accuracy;Automation;Systematics;Generative AI;Text recognition;Optical character recognition;Text summarization;Media;Internet;Testing;Optical Character Recognition (OCR);Generative Artificial Intelligence;Document Processing;Text Summarization;Machine Learning;AI Summarization;Document Workflow Automation},
  doi={10.1109/ICSES63760.2024.10910510},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11098448,
  author={Pleshkova, Snezhana G. and Kostov, Konstantin},
  booktitle={2025 60th International Scientific Conference on Information, Communication and Energy Systems and Technologies (ICEST)}, 
  title={Development of a Model for Digital Transformation in Music Production Using Audio Effects Algorithms Based on Generative AI with Markov Chains}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={There are a lot of methods and algorithms to create audio effects in music production. Using generative AI and digital transformation in musical production is the real way to extend the quality of music creation and mastering. Therefore, the goal of this article is to propose generative AI model based on Markov Chains to carry out digital transformation for audio effects creation in music production.},
  keywords={Generative AI;Databases;Digital transformation;Delay effects;Music;Production;Distance measurement;Delays;Generative artificial intelligence;Markov chains;Digital transformation;Audio effects},
  doi={10.1109/ICEST66328.2025.11098448},
  ISSN={2603-3267},
  month={June},}@INPROCEEDINGS{10441663,
  author={Sathe, Neha and Deodhe, Vaibhav and Sharma, Yash and Shinde, Anand},
  booktitle={2023 International Conference on Advanced Computing & Communication Technologies (ICACCTech)}, 
  title={A Comprehensive Review of AI in Healthcare: Exploring Neural Networks in Medical Imaging, LLM-Based Interactive Response Systems, NLP-Based EHR Systems, Ethics, and Beyond}, 
  year={2023},
  volume={},
  number={},
  pages={633-640},
  abstract={The AI-based technologies used in healthcare systems have witnessed significant growth and innovation, as this growth is attributed to innovations in AI and rise in data collection in the healthcare sector. This survey paper provides a comprehensive overview of the diverse technological advancements reshaping the healthcare landscape. The reviewed topics include Medical Image Interpretation using Deep Learning, Generative AI-based Large Language Models (LLMs), Natural Language Processing for Healthcare Records to give a sense of what AI based systems look like in healthcare. For each of these topics, we've delved into their technical aspects and their applications. Through an overview of these cutting-edge technologies, this research aims to shed light on their current state, challenges, and potential implications for the future of health care. From enhancing diagnostics to improving patient care and accessibility, AI is poised to play pivotal roles in shaping the healthcare industry for years to come. Furthermore, this survey also delves into the ethical considerations surrounding these technologies.},
  keywords={Surveys;Technological innovation;Ethics;Data privacy;Reviews;Medical services;Artificial intelligence;AI;ML;Healthcare;Medicine;CNN;LLM;EHR},
  doi={10.1109/ICACCTech61146.2023.00108},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10743220,
  author={J, Gowrishankar and Deepak, Shashikant and Srivastava, Manish},
  booktitle={2024 International Conference on Advances in Computing Research on Science Engineering and Technology (ACROSET)}, 
  title={Countering the Rise of AI-Generated Content with Innovative Detection Strategies and Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The necessity for novel detection algorithms is of the utmost importance at a time when AI-generated content is ubiquitous. The suggested AI-Guardian methodology provides a novel strategy to combat the proliferation of AI-generated material. This approach uses state-of-the-art algorithms and big language models to tell the difference between AI-generated and human-authored text. The capacity of AI-Guardian to assess language patterns, contextual coherence, and semantic consistency in text is what sets it apart. By creating contextual embeddings and assessing contextual similarities, it provides a thorough comprehension of content's veracity. As a result of this comprehensive contextual analysis, AI-Guardian is able to achieve an impressive 94% detection accuracy. Also, the false positive and false negative rates of AI-Guardian are very low. Its success in content identification is shown by high metrics such as accuracy, recall, F1 score, specificity, and area under the curve (AUC). The comprehensive approach used by AI-Guardian guarantees accurate identification of AI-generated material without compromising accuracy or leading to the accidental deletion of genuine information. AI -Guardian is a dependable lighthouse in the sea of AI-generated content, ushering in a new era of excellence in the field of content identification. It is the go-to solution for protecting against the potentially harmful effects of AI-generated material due to its superior performance metrics and thorough review standards.},
  keywords={Measurement;Accuracy;Reviews;Computational modeling;Large language models;Semantics;Linguistics;Tides;Fake news;Standards;Artificial intelligence;Authentication;Content detection;Contextual analysis;Deceptive content;F1 score;False negatives;False positives;Innovation;Large language models;Linguistic patterns;Precision;Recall;Semantic analysis;Specificity;Trust;Verification;Verification metrics;Visual comparison},
  doi={10.1109/ACROSET62108.2024.10743220},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10748311,
  author={Guo, Yingying and Kang, Xu and Ma, Lei},
  booktitle={2024 3rd International Conference on Artificial Intelligence, Internet of Things and Cloud Computing Technology (AIoTC)}, 
  title={Self-Representation and Generative Adversarial Learning-based Bluetooth Radio Map Reconstruction for Indoor Localization}, 
  year={2024},
  volume={},
  number={},
  pages={11-15},
  abstract={Recently, there has been significant progress in indoor positioning research. While the wireless fingerprint-based positioning method offers excellent performance, its widespread use is hindered by the high cost of creating location-fingerprint databases. The rise of mobile intelligent devices has given way to a new sensing mode called “crowd sensing,” which enables the creation of low-cost location-fingerprint databases. This facilitates the widespread implementation of wireless signal fingerprint positioning methods. However, it's important to note that users participating in crowd sensing tend to gather in specific areas and are limited by event constraints, which means that user trajectories may not cover all detection areas. Consequently, certain areas may have limited or no wireless signal sensing information. To address this, a method for reconstructing radio map based on a small number of observation samples has been proposed in this paper to enable low-cost indoor positioning. To achieve high-quality radio map reconstruction, a combination of self-representation learning and generative adversarial learning architecture is used, with self-representation learning features guiding the generative adversarial learning process to achieve high-quality inference based on small samples. To validate the effectiveness of the proposed method, an indoor Bluetooth positioning system was built in our university's college building using ordinary mobile phone for signal acquisition and map construction. The results verified the superiority of the proposed method in map reconstruction and positioning accuracy compared to traditional methods.},
  keywords={Wireless communication;Wireless sensor networks;Bluetooth;Accuracy;Databases;Fingerprint recognition;Adversarial machine learning;Signal reconstruction;Sensors;Trajectory;indoor localization;radio map construction;selfrepresentation learning;generative adversarial learning;feature extraction},
  doi={10.1109/AIoTC63215.2024.10748311},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9836707,
  author={Li, Licheng and Xiahou, Jiangbin},
  booktitle={2022 IEEE 10th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={Game Image Quality Enhancement Algorithm based on Generative Adversarial Network and Knowledge Distillation}, 
  year={2022},
  volume={10},
  number={},
  pages={2570-2575},
  abstract={Nowadays, with the development of computer graphics and the improvement of related hardware, the picture quality of games is getting higher and higher. Today's mainstream games support resolutions up to 4k or above. At the same time, for a large number of excellent games in the past, the picture quality is far behind today due to technical and hardware limitations at the time. Blurred picture quality is becoming more and more unbearable for users. For this reason, the game company will spend a lot of resources to reset the game to meet the needs of these users. The combination of super-resolution technology based on deep learning and generative adversarial networks can effectively improve image resolution. In this paper, we combines ESRGAN(Enhanced Super-Resolution Generative Adversarial Networks)to design a real-time game image quality enhancement algorithm, and distilled the model, reduce parameters for increase the game frames.},
  keywords={Knowledge engineering;Image quality;Superresolution;Games;Production;Jitter;Rendering (computer graphics);image super resolution;Generative Adversarial Network;Knowledge Distillation},
  doi={10.1109/ITAIC54216.2022.9836707},
  ISSN={2693-2865},
  month={June},}@ARTICLE{9316666,
  author={Baydoun, Atallah and Xu, Ke and Heo, Jin Uk and Yang, Huan and Zhou, Feifei and Bethell, Latoya A. and Fredman, Elisha T. and Ellis, Rodney J. and Podder, Tarun K. and Traughber, Melanie S. and Paspulati, Raj M. and Qian, Pengjiang and Traughber, Bryan J. and Muzic, Raymond F.},
  journal={IEEE Access}, 
  title={Synthetic CT Generation of the Pelvis in Patients With Cervical Cancer: A Single Input Approach Using Generative Adversarial Network}, 
  year={2021},
  volume={9},
  number={},
  pages={17208-17221},
  abstract={Multi-modality imaging constitutes a foundation of precision medicine, especially in oncology where reliable and rapid imaging techniques are needed in order to insure adequate diagnosis and treatment. In cervical cancer, precision oncology requires the acquisition of 18F-labelled 2-fluoro-2-deoxy-D-glucose (FDG) positron emission tomography (PET), magnetic resonance (MR), and computed tomography (CT) images. Thereafter, images are co-registered to derive electron density attributes required for FDG-PET attenuation correction and radiation therapy planning. Nevertheless, this traditional approach is subject to MR-CT registration defects, expands treatment expenses, and increases the patient’s radiation exposure. To overcome these disadvantages, we propose a new framework for cross-modality image synthesis which we apply on MR-CT image translation for cervical cancer diagnosis and treatment. The framework is based on a conditional generative adversarial network (cGAN) and illustrates a novel tactic that addresses, simplistically but efficiently, the paradigm of vanishing gradient vs. feature extraction in deep learning. Its contributions are summarized as follows: 1) The approach–termed sU-cGAN- uses, for the first time, a shallow U-Net (sU-Net) with an encoder/decoder depth of 2 as generator; 2) sU-cGAN’s input is the same MR sequence that is used for radiological diagnosis, i.e. T2-weighted, Turbo Spin Echo Single Shot (TSE-SSH) MR images; 3) Despite limited training data and a single input channel approach, sU-cGAN outperforms other state of the art deep learning methods and enables accurate synthetic CT (sCT) generation. In conclusion, the suggested framework should be studied further in the clinical settings. Moreover, the sU-Net model is worth exploring in other computer vision tasks.},
  keywords={Computed tomography;Cervical cancer;Gallium nitride;Biomedical applications of radiation;Attenuation;Planning;Pelvis;Cervical cancer;computed tomography;deep learning;generative adversarial network;magnetic resonance imaging;U-Net},
  doi={10.1109/ACCESS.2021.3049781},
  ISSN={2169-3536},
  month={},}@ARTICLE{9440897,
  author={Ji, Junzhong and Liu, Jinduo and Han, Lu and Wang, Feipeng},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Estimating Effective Connectivity by Recurrent Generative Adversarial Networks}, 
  year={2021},
  volume={40},
  number={12},
  pages={3326-3336},
  abstract={Estimating effective connectivity from functional magnetic resonance imaging (fMRI) time series data has become a very hot topic in neuroinformatics and brain informatics. However, it is hard for the current methods to accurately estimate the effective connectivity due to the high noise and small sample size of fMRI data. In this paper, we propose a novel framework for estimating effective connectivity based on recurrent generative adversarial networks, called EC-RGAN. The proposed framework employs the generator that consists of a set of effective connectivity generators based on recurrent neural networks to generate the fMRI time series of each brain region, and uses the discriminator to distinguish between the joint distributions of the real and generated fMRI time series. When the model is well-trained and generated fMRI data is similar to real fMRI data, EC-RGAN outputs the effective connectivity by means of the causal parameters of the effective connectivity generators. Experimental results on both simulated and real-world fMRI time series data demonstrate the efficacy of our proposed framework.},
  keywords={Functional magnetic resonance imaging;Time series analysis;Generators;Data models;Brain modeling;Logic gates;Mathematical model;Effective connectivity;generative adversarial networks;recurrent neural networks;fMRI time series},
  doi={10.1109/TMI.2021.3083984},
  ISSN={1558-254X},
  month={Dec},}@ARTICLE{10443607,
  author={Wang, Li and Zhang, Xiaohua and Zhang, Jinhua and Dong, Hua and Meng, Hongyun and Jiao, Licheng},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={Pixel-to-Abundance Translation: Conditional Generative Adversarial Networks Based on Patch Transformer for Hyperspectral Unmixing}, 
  year={2024},
  volume={17},
  number={},
  pages={5734-5749},
  abstract={Spectral unmixing is a significant challenge in hyperspectral image processing. Existing unmixing methods utilize prior knowledge about the abundance distribution to solve the regularization optimization problem, where the difficulty lies in choosing appropriate prior knowledge and solving the complex regularization optimization problem. To solve these problems, we propose a hyperspectral conditional generative adversarial network (HyperGAN) method as a generic unmixing framework based on the following assumption: The unmixing process from pixel to abundance can be regarded as a transformation of two modalities with an internal specific relationship. The proposed HyperGAN is composed of a generator and a discriminator, the former completes the modal conversion from mixed hyperspectral pixel patch to the abundance of corresponding endmember of the central pixel and the latter is used to distinguish whether the distribution and structure of generated abundance are the same as the true ones. In addition, we propose hyperspectral image (HSI) patch transformer as the main component of the generator, which utilizes adaptive attention score to capture the internal pixels correlation of the HSI patch and leverages the spatial-spectral information in a fine-grained way to achieve optimization of the unmixing process. Furthermore, we propose a data synthesis method based on superpixel segmentation and random split to get synthetic data with a spatial structure to further evaluate the effectiveness of our model for unmixing. Experiments on synthetic data and real hyperspectral data achieve impressive results compared with state-of-the-art competitors.},
  keywords={Hyperspectral imaging;Transformers;Vectors;Task analysis;Optimization;Image reconstruction;Generators;Generative adversarial networks (GANs);hyperspectral unmixing (HSU);spatial-spectral information;transformer},
  doi={10.1109/JSTARS.2024.3368286},
  ISSN={2151-1535},
  month={},}@INPROCEEDINGS{10780502,
  author={Bennett, Casey C. and Stanojevic, Cedomir and Oh, Jiyeong and Ahn, Junyeong and Jeon, Yeeun and Son, Kanghee and Abbott, Nikki},
  booktitle={2024 IEEE 20th International Conference on Body Sensor Networks (BSN)}, 
  title={Digital Health Sensor Data in Autism: Developing Few Shot Learning Approaches for Traditional Machine Learning Classifiers}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={There is great interest in applying artificial intelligence (AI) techniques to healthcare issues such as Autism, particularly in combination with digital health technologies (robots, wearables, smartphones, etc.) in user homes. However, a critical challenge is that modern AI techniques like deep learning (DL) typically require large datasets with millions of samples, yet in healthcare we are often working with smaller clinical samples (<50 participants). To address that challenge, we need to develop new approaches that can learn more efficiently from less data. In this paper, we propose a novel approach to few-shot learning (FSL) called SMOTE_FSL, which is applicable to traditional machine learning (ML) models, allowing them to work with smaller sample sizes as well as various types of healthcare data (not only image or text data). We compare SMOTE_FSL on two healthcare sensor datasets gathered using robots and wearables, with results showing SMOTE_FSL performs comparably to state-of-the-art DL-based FSL methods (e.g. autoencoders, generative adversarial networks [GAN]). That indicates such an approach holds potential to expand utilization of FSL to a broad range of healthcare data derived from smaller clinical sample sizes.},
  keywords={Body sensor networks;Autism;Robot sensing systems;Generative adversarial networks;Data models;Electronic healthcare;Wearable devices;Few shot learning;Smart phones;Autism;Sensor Data;Few Shot Learning;Machine Learning;SMOTE;Deep Learning},
  doi={10.1109/BSN63547.2024.10780502},
  ISSN={2376-8894},
  month={Oct},}@INPROCEEDINGS{9412202,
  author={Zhou, Lanxiang and Wang, Yifei and Xiao, Bo and Xu, Qianfang},
  booktitle={2020 25th International Conference on Pattern Recognition (ICPR)}, 
  title={DFH-GAN: A Deep Face Hashing with Generative Adversarial Network}, 
  year={2021},
  volume={},
  number={},
  pages={7012-7019},
  abstract={Face Image retrieval is one of the key research directions in computer vision field. Thanks to the rapid development of deep neural network in recent years, deep hashing has achieved good performance in the field of image retrieval. But for large-scale face image retrieval, the performance needs to be further improved. In this paper, we propose Deep Face Hashing with GAN (DFH-GAN), a novel deep hashing method for face image retrieval, which mainly consists of three components: a generator network for generating synthesized images, a discriminator network with a shared CNN to learn multi-domain face feature, and a hash encoding network to generate compact binary hash codes. The generator network is used to perform data augmentation so that the model could learn from both real images and diverse synthesized images. We adopt a two-stage training strategy. In the first stage, the GAN is trained to generate fake images, while in the second stage, to make the network convergence faster. The model inherits the trained shared CNN of discriminator to train the DFH model by using many different supervised loss functions not only in the last layer but also in the middle layer of the network. Extensive experiments on two widely used datasets demonstrate that DFH-GAN can generate high-quality binary hash codes and exceed the performance of the state-of-the-art model greatly.},
  keywords={Training;Image coding;Face recognition;Image retrieval;Neural networks;Generative adversarial networks;Generators},
  doi={10.1109/ICPR48806.2021.9412202},
  ISSN={1051-4651},
  month={Jan},}@ARTICLE{9709124,
  author={Dhar, Sandipan and Jana, Nanda Dulal and Das, Swagatam},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={An Adaptive-Learning-Based Generative Adversarial Network for One-to-One Voice Conversion}, 
  year={2023},
  volume={4},
  number={1},
  pages={92-106},
  abstract={Voice conversion (VC) emerged as a significant domain of research in the field of speech synthesis in recent years due to its emerging application in voice-assistive technologies, such as automated movie dubbing speech-to-singing conversion, to name a few. VC deals with the conversion of the vocal style of one speaker to another speaker while keeping the linguistic contents unchanged. Nowadays, generative adversarial network (GAN) models are widely used for speech feature mapping from the source speaker to the target speaker. In this article, we propose an adaptive-learning-based GAN model, called ALGAN-VC, to improve the one-to-one VC of speakers. Our ALGAN-VC framework consists of some approaches to improve the speech quality and voice similarity between the source and target speakers. We incorporate a dense residual network architecture into the generator network for efficient speech feature learning between source and target speakers. Our framework also includes an adaptive learning mechanism to compute the loss function for the proposed model. Moreover, a boosted learning rate approach is incorporated to enhance the learning capability of the proposed model. The proposed model is tested on Voice Conversion Challenge 2016, 2018, and 2020 datasets along with our self-prepared Indian regional-language-based speech dataset. In addition, an emotional speech dataset is also considered for evaluating the model’s performance. The objective and subjective evaluations of the generated speech samples indicated that the proposed model elegantly performed the voice conversion task by achieving high speaker similarity and good speech quality.},
  keywords={Generative adversarial networks;Adaptation models;Generators;Data models;Computational modeling;Wide band gap semiconductors;Aluminum gallium nitride;Adaptive learning;boosted learning;generative adversarial network (GAN);speech synthesis;voice conversion (VC)},
  doi={10.1109/TAI.2022.3149858},
  ISSN={2691-4581},
  month={Feb},}@INPROCEEDINGS{10347873,
  author={Li, Zhiyang and Xu, Ruixuan and Xiong, Xin and Fang, Xiaoya and Zhan, Weihang},
  booktitle={2023 8th International Conference on Intelligent Informatics and Biomedical Sciences (ICIIBMS)}, 
  title={Super-Resolution reconstruction of remote sensing image based on generative countermeasure network}, 
  year={2023},
  volume={8},
  number={},
  pages={181-184},
  abstract={The article proposes a method that combines generative countermeasure networks (GANs) and transfer learning on the DRN model to reconstruct remote sensing images. The aim of this method is to address the challenge of obtaining high-resolution remote sensing images by generating reconstructed images with four times higher resolution, richer details, and improved texture. To evaluate the effectiveness of the proposed method, the PP-YOLO model is used to perform object detection on both the original and reconstructed airplane images. The results demonstrate that the average confidence of object detection is significantly improved from 0.5190 to 0.7987, indicating a 0.2797 increase. These findings suggest that the reconstruction method presented in the article effectively enhances image resolution and improves the performance of object detection in remote sensing images.},
  keywords={Atmospheric modeling;Superresolution;Transfer learning;Object detection;Reconstruction algorithms;Satellite images;Informatics;Remote sensing images;GAN ,transfer learning;resolution reconstruction},
  doi={10.1109/ICIIBMS60103.2023.10347873},
  ISSN={2189-8723},
  month={Nov},}@INPROCEEDINGS{11158692,
  author={Guo, Shouchao and Sun, Yuqian and Xu, Zhenguo},
  booktitle={2025 5th International Conference on Artificial Intelligence and Education (ICAIE)}, 
  title={The Impact of Applying GenAI in Scratch Programming on University Students' Computational Thinking}, 
  year={2025},
  volume={},
  number={},
  pages={398-401},
  abstract={Generative Artificial Intelligence (GenAI) is one of the widely applied AI technologies in programming education. However, the impact of applying GenAI in Scratch on university students' computational thinking and learning outcomes remains unclear. Seventy-eight undergraduates participated in this experiment during their Scratch programming course. The study found that both creativity, critical thinking, and computational thinking significantly improved in both the experimental and control groups, with the experimental group showing more significant enhancements in algorithmic thinking and collaborative skills. We further discovered that the Scratch projects created by the experimental group were significantly superior to those of the control group in terms of practicality and technicality, while no differences were observed in creativity and artistry. This research validates the effectiveness of applying GenAI in Scratch programming for fostering computational thinking among university students, providing valuable insights for educational practices aimed at developing computational thinking skills.},
  keywords={Generative AI;Education;Collaboration;Learning (artificial intelligence);Problem-solving;Interviews;Programming profession;Creativity;GenAI;Computational Thinking;University Students;Scratch},
  doi={10.1109/ICAIE64856.2025.11158692},
  ISSN={},
  month={May},}@INPROCEEDINGS{10741797,
  author={Donvir, Anujkumarsinh and Panyam, Sriram and Paliwal, Gunjan and Gujar, Praveen},
  booktitle={2024 International Conference on Engineering Management of Communication and Technology (EMCTECH)}, 
  title={The Role of Generative AI Tools in Application Development: A Comprehensive Review of Current Technologies and Practices}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This paper provides a comprehensive review of the role of Generative AI (GenAI) tools in modern software application development. It highlights the advancements in machine learning, natural language processing, and neural network architectures that have enabled the evolution of GenAI tools from basic code generation and assistance to fully autonomous software development capabilities. Key GenAI tools like GitHub Copilot, TabNine, Cursor AI and Devin AI are examined, with a focus on their functionalities such as code generation, testing, debugging, and deployment. The paper also discusses the productivity benefits, limitations, and ethical considerations of integrating GenAI tools into the development lifecycle. The aim is to equip software developers, managers, and organizations with a deep understanding of the practical applications and future directions of GenAI in streamlining development processes.},
  keywords={Codes;Generative AI;Reviews;Software;Encoding;User experience;Security;Software measurement;Software development management;Testing;Software Application Development;GenAI;SaaS;Cloud Computing;GenAI Tools;GitHub Copilot;TabNine;Cursor AI;Devin AI;Code Generation;Autonomous Software Development;Digital Product Lifecycle;Testing;CI/CD},
  doi={10.1109/EMCTECH63049.2024.10741797},
  ISSN={3064-9382},
  month={Oct},}@INPROCEEDINGS{10485016,
  author={Elbagoury, Bassant M. and Maskeliuans, Rytis and Zaghow, Marwa and Kamel, Nabil},
  booktitle={2024 6th International Conference on Computing and Informatics (ICCI)}, 
  title={A Novel Inception Deep Learning Model for Mobile AI Stroke Prediction System: AI Research and Industry Perspectives for Connected Health}, 
  year={2024},
  volume={},
  number={},
  pages={366-376},
  abstract={Artificial intelligence technologies for the mobile health and smart hospitals are important, by applying predictive Analytics and Deep Learning algorithms and developing new models. The main objective is applying artificial Intelligence methods in the medical field, especially for heart/brain stroke diseases diagnosis and prediction for emergency patients' cases. Thus, to save patients' lives, also through the integration with IoT and wearable technologies, which are integrated with AI and DL algorithms that help to make sense of bio signals predictive analytics such as biomedical sensors processing. and complex diseases predictions and early detection like heart and stroke diseases. Also dealing with EMG sensors for stroke prediction. Moreover, Intelligent Mobile Health based on our previously introduced project of AI smart hospital and Mobile AI stroke prediction system for connected health and stroke emergencies. In this paper, a new deep learning model has been built and tested for Stroke EMG signal prediction by modifying the Inception-v3 architecture and other deep learning models. Also, this paper compares current results of Mobile AI health Inception model with our previous developed Mobile AI stroke engine that depends on hybrid LSTM deep learning for EMG signals prediction. Both models have achieved high accuracies. Moreover, the inception model is more stable and higher average accuracies that reaches 98%. Moreover, AI research and future industry implementations for Generative AI Dell Technologies servers is discussed.},
  keywords={Deep learning;Industries;Analytical models;Hospitals;Predictive models;Stroke (medical condition);Prediction algorithms;Artificial Intelligent;Mobile Computing;Mobile Health;EMG signals analysis;Mobile AI stroke prediction system [1, 2];Inception v3;deep learning model},
  doi={10.1109/ICCI61671.2024.10485016},
  ISSN={},
  month={March},}@ARTICLE{10994795,
  author={Boutayeb, Anasse and Lahsen-Cherif, Iyad and Khadimi, Ahmed El},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={When Machine Learning Meets Geospatial Data: A Comprehensive GeoAI Review}, 
  year={2025},
  volume={18},
  number={},
  pages={13135-13191},
  abstract={In recent years, geospatial artificial intelligence (GeoAI) has gained traction in the most relevant research works and industrial applications, while also becoming involved in various fields of use. This article offers a comprehensive review of GeoAI as a synergistic concept applying artificial intelligence (AI) models, specifically those of machine learning (ML), to geospatial data. A preliminary study is carried out, identifying the methodology of the work, the research motivations, the issues, and the directions to be tracked, followed by exploring how GeoAI can be used in various interesting fields of application, such as precision agriculture, environmental monitoring, disaster management, and urban planning. Next, a statistical and semantic analysis is carried out, followed by a clear and precise presentation of the challenges facing GeoAI. Then, a concrete exploration of the future prospects is provided, based on several information gathered during the census. To sum up, this article provides a complete overview of the correlation between ML and the geospatial domain, while mentioning the research conducted in this context, and emphasizing the close relationship linking GeoAI with other advanced concepts such as geographic information systems and large-scale geospatial data, known as big geodata. This will enable researchers and scientific community to assess the state of progress in this promising field and will help other interested parties to gain a better understanding of the issues involved.},
  keywords={Geospatial analysis;Machine learning;History;Urban planning;Remote sensing;Hands;Data models;Reviews;Precision agriculture;Indexes;Big geodata;geographic information systems (GIS);geospatial artificial intelligence (GeoAI);geospatial data;machine learning (ML)},
  doi={10.1109/JSTARS.2025.3568715},
  ISSN={2151-1535},
  month={},}@ARTICLE{10490142,
  author={Van Huynh, Nguyen and Wang, Jiacheng and Du, Hongyang and Hoang, Dinh Thai and Niyato, Dusit and Nguyen, Diep N. and Kim, Dong In and Letaief, Khaled B.},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Generative AI for Physical Layer Communications: A Survey}, 
  year={2024},
  volume={10},
  number={3},
  pages={706-728},
  abstract={The recent evolution of generative artificial intelligence (GAI) leads to the emergence of groundbreaking applications such as ChatGPT, which not only enhances the efficiency of digital content production, such as text, audio, video, or even network traffic data, but also enriches its diversity. Beyond digital content creation, GAI’s capability in analyzing complex data distributions offers great potential for wireless communications, particularly amidst a rapid expansion of new physical layer communication technologies. For example, the diffusion model can learn input signal distributions and use them to improve the channel estimation accuracy, while the variational autoencoder can model channel distribution and infer latent variables for blind channel equalization. Therefore, this paper presents a comprehensive investigation of GAI’s applications for communications at the physical layer, ranging from traditional issues, including signal classification, channel estimation, and equalization, to emerging topics, such as intelligent reflecting surfaces and joint source channel coding. We also compare GAI-enabled physical layer communications with those supported by traditional AI, highlighting GAI’s inherent capabilities and unique contributions in these areas. Finally, the paper discusses open issues and proposes several future research directions, laying a foundation for further exploration and advancement of GAI in physical layer communications.},
  keywords={Physical layer;Artificial intelligence;Channel estimation;Surveys;Generative adversarial networks;Wireless communication;Generative AI;Generative AI;physical layer communications;channel estimation and equalization;physical layer security;IRS;beamforming;joint source channel coding},
  doi={10.1109/TCCN.2024.3384500},
  ISSN={2332-7731},
  month={June},}@ARTICLE{9921304,
  author={Leonardo, Ricardo and Gonçalves, João and Carreiro, André and Simões, Beatriz and Oliveira, Tiago and Soares, Filipe},
  journal={IEEE Access}, 
  title={Impact of Generative Modeling for Fundus Image Augmentation With Improved and Degraded Quality in the Classification of Glaucoma}, 
  year={2022},
  volume={10},
  number={},
  pages={111636-111649},
  abstract={Glaucoma is a heterogeneous group of diseases characterised by cupping of the optic nerve head and visual field damage, starting with a progressive loss of vision that leads to permanent blindness. When diagnosed in time, Glaucoma can be delayed by adequate treatment. More efficient processes for diagnosis are being proposed, and the role of artificial intelligence in the field is growing. This work presents a pipeline to evaluate the impact of generative modelling in Computer-Aided Diagnosis (CADx) of Glaucoma based on Deep Learning, particularly focused on the optic disc region. The methodology relies on transforming retinal fundus images to improve and degrade their quality to augment the training data and assess the diagnostic performance. The objective evaluation of the proposed model based on Generative Adversarial Networks revealed quantitative and qualitative improvements in image quality. To support this, we propose a new model to evaluate the quality of fundus images, which can also be used within the pipeline to reject samples with lower image quality for diagnosis. Its performance surpassed related work, achieving a balanced accuracy of 0.929. Concerning Glaucoma CADx, the results obtained in public datasets point to a considerable gain in Sensitivity, Specificity, and Accuracy, achieving scores of 0.883 (+0.054), 0.957 (+0.019), and 0.931 (+0.031), respectively, after image data augmentation when compared with previous work targeted at offline inference in mobile devices. Considering the restriction of choosing simpler backbone networks that can run on edge devices, our findings support the importance of image quality diversity and realistic augmentation.},
  keywords={Optical imaging;Retina;Adaptive optics;Image quality;Biomedical optical imaging;Image segmentation;Deep learning;Computer aided diagnosis;Convolutional neural networks;Generative adversarial networks;Computer-aided diagnosis;convolutional neural networks;deep learning;fundus images;generative adversarial networks;glaucoma;image quality;image classification;retina},
  doi={10.1109/ACCESS.2022.3215126},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11087968,
  author={Sharma, Harshit and Kumar, Rakesh and Gupta, Meenu and Pradhan, Chittaranjan},
  booktitle={2025 Seventh International Conference on Computational Intelligence andCommunication Technologies (CCICT)}, 
  title={Evaluating Data Augmentation Techniques for GAN Performance Enhancement}, 
  year={2025},
  volume={},
  number={},
  pages={448-452},
  abstract={GANs are one of the prominent generative AI models for artificial data generation with applications such as video generation, image generation and more.To unlock the full potential of GANs, training dataset should be carefully chosen as GANs are very sensitive to quality and diversity of training dataset. This study employs different data Augmentation techniques to mitigate these problems. The study systematically evaluates the impact of 7 different data augmentation techniques on GAN performance evaluated on CIFAR-10 dataset. The techniques used are geometric transformations, Noise Injection, Color jittering, Frequency Domain Transformation, Cutout, Mixup and CutMix. The performance of these methods is assessed using the Fréchet Inception Distance (FID), a standard metric for GAN evaluation. Results Indicate that noise injection gives the best improvement over baseline performance an improvement of 10.61% is observed, geometric and Cutmix augmentations also displayed marginal improvements. Other methods did not perform as expected and negatively affected the FID score. These findings displays the importance of selecting appropriate augmentation strategies tailored to the specific needs of GAN training. This paper provides a bedrock for optimizing data augmentation techniques to enhance the stability and performance of GANs, contributing valuable insights to the field of generative modelling.},
  keywords={Training;Data privacy;Image color analysis;Generative AI;Frequency-domain analysis;Computational modeling;Training data;Data augmentation;Generative adversarial networks;Data models;Generative AI;Generative Adversarial Networks;Data Augmentation;Limited data;MixUp;CutMix;Noise Based Augmentation;FID score;generative modelling},
  doi={10.1109/CCICT65753.2025.00074},
  ISSN={},
  month={April},}@ARTICLE{10870477,
  author={Gebrehans, Ghebrebrhan and Ilyas, Naveed and Eledlebi, Khouloud and Lunardi, Willian Tessaro and Andreoni, Martin and Yeun, Chan Yeob and Damiani, Ernesto},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Generative Adversarial Networks for Dynamic Malware Behavior: A Comprehensive Review, Categorization, and Analysis}, 
  year={2025},
  volume={6},
  number={8},
  pages={1955-1976},
  abstract={This article highlights the critical role of machine learning (ML) in combating the dynamic nature of cybersecurity threats. Unlike previous studies focusing mainly on static analysis, this work surveys the literature on dynamic analysis-based malware generation and detection. The study addresses the complexities of applying GANs to tabular data with heavy-tailed and multimodal distributions. It also examines the challenges of generating sequential malware behavior data and categorizes GAN-based models and their primary use cases. Furthermore, the article evaluates adversarial losses and their limitations in generating dynamic malware behavior. Finally, it identifies existing metrics to assess GAN generalization in malware research and suggests future research directions based on identified limitations.},
  keywords={Malware;Generative adversarial networks;Data models;Detectors;Feature extraction;Surveys;Artificial intelligence;Reviews;Static analysis;Heavily-tailed distribution;Adversarial training;data imbalance;dynamic analysis;generative adversarial networks (GANs);polymorphic malware;synthetic malware generation},
  doi={10.1109/TAI.2025.3537966},
  ISSN={2691-4581},
  month={Aug},}@ARTICLE{11005596,
  author={Routray, Sudhir K.},
  journal={IEEE Computer Graphics and Applications}, 
  title={Ethical Considerations and Implications of Generative AI in Computer Graphics}, 
  year={2025},
  volume={45},
  number={2},
  pages={78-89},
  abstract={Generative artificial intelligence (AI) has immense potential to create diverse computer graphics for various applications, but it also raises significant ethical issues. This article examines the ethical landscape of using generative AI in computer graphics, highlighting key concerns, such as the authenticity of generated content, intellectual property rights, and cultural appropriation. Additional ethical challenges include algorithmic bias in graphics generation, representation, privacy, inclusivity, and the impact on human–computer interaction and artistic integrity. The displacement of creative professionals, erosion of trust in visual media, and psychological effects of AI-generated content further complicate the ethical debate. Addressing these issues requires a comprehensive approach that integrates technological innovation with regulatory oversight, ethical education, and collaboration among stakeholders. By carefully considering these ethical dimensions, we can fully leverage generative AI's potential in computer graphics while mitigating its risks.},
  keywords={Generative AI;Ethics;Artificial intelligence;Creativity;Intellectual property;Training;Data models;Cultural aspects;Computational modeling},
  doi={10.1109/MCG.2025.3570722},
  ISSN={1558-1756},
  month={March},}@ARTICLE{10580983,
  author={Du, Hongyang and Niyato, Dusit and Kang, Jiawen and Xiong, Zehui and Zhang, Ping and Cui, Shuguang and Shen, Xuemin and Mao, Shiwen and Han, Zhu and Jamalipour, Abbas and Poor, H. Vincent and Kim, Dong In},
  journal={IEEE Network}, 
  title={The Age of Generative AI and AI-Generated Everything}, 
  year={2024},
  volume={38},
  number={6},
  pages={501-512},
  abstract={Generative AI (GAI) has emerged as a significant advancement in artificial intelligence, renowned for its language and image generation capabilities. This paper presents “AI-Generated Everything” (AIGX), a concept that extends GAI beyond mere content creation to real-time adaptation and control across diverse technological domains. In networking, AIGX collaborates closely with physical, data link, network, and application layers to enhance real-time network management that responds to various system and service settings as well as application and user requirements. Networks, in return, serve as crucial components in further AIGX capability optimization through the AIGX lifecycle, i.e., data collection, distributed pre-training, and rapid decision-making, thereby establishing a mutually enhancing interplay. Moreover, we offer an in-depth case study focused on power allocation to illustrate the interdependence between AIGX and networking systems. Through this exploration, the article analyzes the significant role of GAI for networking, clarifies the ways networks augment AIGX functionalities, and underscores the virtuous interactive cycle they form. It is hoped that this article will pave the way for subsequent future research aimed at fully unlocking the potential of GAI and networks.},
  keywords={Semantics;Generative AI;Resource management;Optimization;Laboratories;Communication system security;Adaptation models;Generative AI (GAI);networks;AI-generated everything (AIGC);generative diffusion model},
  doi={10.1109/MNET.2024.3422241},
  ISSN={1558-156X},
  month={Nov},}@ARTICLE{10517328,
  author={Kang, Byungseok and Jo, Youngjae},
  journal={IT Professional}, 
  title={StyleGAN-Based Advanced Semantic Segment Encoder for Generative AI}, 
  year={2024},
  volume={26},
  number={2},
  pages={17-23},
  abstract={StyleGAN is a widely used model in various AI domains that generates high-quality images. It has many advantages but has the disadvantage of per-pixel noise inputs. These noise inputs used from StyleGAN are independent of location information and have a negative impact on natural location information learning because random noise is inserted in pixel units at intervals. This problem was even more problematic in the area of creating human faces. StyleGAN3 was announced to overcome this, but it did not completely solve the existing problems. If the angle of a human face is more than 30° from the front, the restoration rate further decreases. In this article, we propose an advanced semantic segment encoder that accurately generates eyes, nose, and mouth even when the angle of a human face is rotated more than 60°. We developed a face-angle analyzer to accurately measure the angle of a person’s face. The proposed idea improved restoration performance by approximately 30% compared to existing encoders when the face is not straight ahead.},
  keywords={Costs;Generative AI;Noise measurement;Semantics;Image restoration;Image processing;Artificial intelligence;Face recognition;Semantic segmentation;Facial features},
  doi={10.1109/MITP.2023.3338026},
  ISSN={1941-045X},
  month={March},}@ARTICLE{11022747,
  author={Morabito, Roberto and Jang, SiYoung},
  journal={IEEE Internet Computing}, 
  title={Smaller, Smarter, Closer: The Edge of Collaborative Generative AI}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={The rapid adoption of generative AI (GenAI), particularly Large Language Models (LLMs), has exposed critical limitations of cloud-centric deployments, including latency, cost, and privacy concerns. Meanwhile, Small Language Models (SLMs) are emerging as viable alternatives for resource-constrained edge environments, though they often lack the capabilities of their larger counterparts. This article explores the potential of collaborative inference systems that leverage both edge and cloud resources to address these challenges. By presenting distinct cooperation strategies alongside practical design principles and experimental insights, we offer actionable guidance for deploying GenAI across the computing continuum. Ultimately, this work underscores the great potential of edge-first approaches in realizing the promise of GenAI in diverse, real-world applications.},
  keywords={Biological system modeling;Cloud computing;Computational modeling;Collaboration;Artificial intelligence;Generative AI;Mathematical models;Cognition;Accuracy;Reliability},
  doi={10.1109/MIC.2025.3575493},
  ISSN={1941-0131},
  month={},}@INPROCEEDINGS{10862690,
  author={Ashtagi, Rashmi and Rathi, Devanshu and Handoo, Ripul and Purohit, Rishi and Madhavaswala, Abbas and Nogamawala, Mohammad},
  booktitle={2024 Global Conference on Communications and Information Technologies (GCCIT)}, 
  title={Enhancing Doodling Experience Using Generative Adversarial Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={Interacting with AI systems solely through textual prompts often encounters limitations due to the challenges of expressing complex visual ideas in text. This paper introduces an advanced AI system that interprets and visualizes users’ sketches by employing state-of-the-art Generative Adversarial Networks (GANs), such as pix2pix, SketchGAN, DCGAN, and ESRGAN. This system not only significantly enhances real-time interactions but also shows exceptional proficiency in image editing tasks, thus facilitating more intuitive communication between humans and AI. By enabling rapid and accurate visualizations, this technology substantially streamlines and improves design workflows in the architecture and fashion industries. The advancements fostered by this system contribute significantly towards achieving greater capabilities akin to Artificial General Intelligence, enhancing creative processes and production efficiencies.},
  keywords={Training;Visualization;Technological innovation;Accuracy;Image synthesis;Superresolution;Streaming media;Generative adversarial networks;Stability analysis;Real-time systems;Generative Adversarial Network;pix2pix;SketchGAN;DCGAN;ESRGAN;AGI},
  doi={10.1109/GCCIT63234.2024.10862690},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9709974,
  author={Knyazev, Boris and de Vries, Harm and Cangea, Cătălina and Taylor, Graham W. and Courville, Aaron and Belilovsky, Eugene},
  booktitle={2021 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Generative Compositional Augmentations for Scene Graph Prediction}, 
  year={2021},
  volume={},
  number={},
  pages={15807-15817},
  abstract={Inferring objects and their relationships from an image in the form of a scene graph is useful in many applications at the intersection of vision and language. We consider a challenging problem of compositional generalization that emerges in this task due to a long tail data distribution. Current scene graph generation models are trained on a tiny fraction of the distribution corresponding to the most frequent compositions, e.g. <cup, on, table>. However, test images might contain zero- and few-shot compositions of objects and relationships, e.g. <cup, on, surfboard>. Despite each of the object categories and the predicate (e.g. ‘on’) being frequent in the training data, the models often fail to properly understand such unseen or rare compositions. To improve generalization, it is natural to attempt increasing the diversity of the training distribution. However, in the graph domain this is non-trivial. To that end, we propose a method to synthesize rare yet plausible scene graphs by perturbing real ones. We then propose and empirically study a model based on conditional generative adversarial networks (GANs) that allows us to generate visual features of perturbed scene graphs and learn from them in a joint fashion. When evaluated on the Visual Genome dataset, our approach yields marginal, but consistent improvements in zero- and few-shot metrics. We analyze the limitations of our approach indicating promising directions for future research.},
  keywords={Measurement;Training;Visualization;Computer vision;Training data;Genomics;Generative adversarial networks;Scene analysis and understanding;Neural generative models;Vision + other modalities;Visual reasoning and logical representation},
  doi={10.1109/ICCV48922.2021.01553},
  ISSN={2380-7504},
  month={Oct},}@ARTICLE{10664595,
  author={Chen, Gang and Feng, Qing and He, Xiu and Yao, Jian},
  journal={IEEE Access}, 
  title={Multi-Scale Generative Adversarial Network With Multi-Head External Attention for Image Inpainting}, 
  year={2024},
  volume={12},
  number={},
  pages={133456-133468},
  abstract={Inpainting images that have sizable missing blocks presents a considerable challenge in terms of preserving visual consistency and attaining a convincing result. In this study, the multi-scale generative adversarial network with multi-head external attention for image inpainting (denoted as MGDAN) is proposed. First, an adaptive weight style loss is designed into the generator of multi-scale generative adversarial networks (GAN) to guide the inpainting of the style and structure in the image inpainting, which improves the inpainting effect of image contour and emoticon. Second, the Adaptive Mix model is introduced to address the imbalance in generator and discriminator training by reducing the distance between the difficult and easy samples. This approach is intended to improve the overall performance of the network and drive high-quality image generation. Third, the generator and local discriminator in the image inpainting process are enhanced by the introduction of a multi-head external attention mechanism. This addition aims to capture the long-distance and multi-level dependent relationships between different areas of the image. It is proved beneficial for the generating clear geometric contours in the restored images and improving the overall global consistency of the inpainted results. By employing specific experimental methods, we find the optimal number of heads. The effectiveness of the proposed approach also is demonstrated through the extensive experiments conducted on public datasets.},
  keywords={Generative adversarial networks;Training;Image restoration;Dictionaries;Visualization;Image edge detection;Generators;Image inpainting;adaptive mix;external attention;multi-scale GANs},
  doi={10.1109/ACCESS.2024.3454525},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11116279,
  author={Bai, Jingyi and Gao, Pengcheng and Huang, Qiaogao and Chu, Yong},
  booktitle={2024 IEEE 10th International Conference on Underwater System Technology: Theory and Applications (USYS)}, 
  title={A Novel Artificial Intelligence Approach for the Rapid Hydrodynamic Prediction of Manta Ray-like Underwater Vehicles}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={The manta ray-like underwater vehicle exhibits excellent maneuverability and bio-affinity. To enhance the development efficiency of this vehicle and reduce the costs of numerical simulations and experiments, we propose a novel artificial intelligence-based hydrodynamic prediction method called Hydro-DDPM. This model can rapidly and accurately generate time-series curves of drag, lift, and pitch moment variations within a single swimming cycle by inputting motion control parameters such as flapping frequency and amplitude. Hydrodynamic data are generated through a combination of Gaussian noise diffusion processes and neural network-based reverse denoising processes, with motion parameters integrated into the neural network model using a self-attention mechanism. Utilizing the IB-SGKS algorithm, 180 sets of hydrodynamic parameters were initially obtained and subsequently augmented to create a dataset comprising 3600 samples. The results indicate that the model performs well in multi-variable time-series predictions, with maximum prediction errors not exceeding 5% and overall errors within 3%. Compared to traditional CFD methods, our approach generates a set of hydrodynamic data in just a few seconds, achieving a 103-fold increase in efficiency. Furthermore, this method is versatile and can be applied to predict the performance of various underwater vehicles, including those with pump-jet propulsion, rotorcraft, and gliders, by training the model with different datasets.},
  keywords={Training;Noise reduction;Neural networks;Predictive models;Hydrodynamics;Prediction algorithms;Data models;Motion control;Underwater vehicles;Sports;manta ray-like underwater vehicle;hydrodynamic prediction;hydro-DDPM;artificial intelligence},
  doi={10.1109/USYS62456.2024.11116279},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9788166,
  author={Rahul, Nidumukkula V N D S and NagaIndira S Geethika, Sukamanchi and Gayatri, Vemulakonda and Pranathi, K},
  booktitle={2022 6th International Conference on Intelligent Computing and Control Systems (ICICCS)}, 
  title={Facial Emotion Recognition using Artificial Intelligence Techniques}, 
  year={2022},
  volume={},
  number={},
  pages={973-977},
  abstract={Features are the most basic yet impactful to capture emotions. Emotions are the source to depict the person’s state of mind. This acts as the mind reader of a person. Emotions are not long-lasting and remain only for a moment. They vary vibrantly and currently, the mental health of a person has a prominent role to play in the factor of efficiency of that person’s outcome. Emotions have to be recognized and analyzed to determine the person’s opinion or to understand the person’s condition. Emotion detection has a prominent role to be played in different sectors such as psychology, research, corporate field, cognitive science, and many more. Indeed, micro-expressions depict the actual state of the person. This research work has proposed a sophisticated approach to obtain the person’s state of mind by extracting the features. Initially, the faces are detected and using Artificial Intelligence techniques such as Convolution Neural Network (CNN) and Support Vector Machine (SVM) algorithms are implemented to classify the emotion on the FER-2013 dataset. Open CV library is imported to preprocess the image and to extract the image detected. Live picture analysis assists us to stand unique and detect the emotion in the most prescribed manner. Along with living capture motion, video analysis is also combined to capture the micro-expressions that portray the individual’s most precise feelings. This model recognizes all the faces present in a picture or a video and can detect them individually.},
  keywords={Support vector machines;Emotion recognition;Face recognition;Neural networks;Mental health;Feature extraction;Libraries;Convolutional Neural Network;Support Vector Machine;Open CV;Feature extraction;Face Detection;Artificial Intelligence;Live picture analysis;Emotion detection},
  doi={10.1109/ICICCS53718.2022.9788166},
  ISSN={2768-5330},
  month={May},}@INPROCEEDINGS{10657096,
  author={Huang, Ziqi and He, Yinan and Yu, Jiashuo and Zhang, Fan and Si, Chenyang and Jiang, Yuming and Zhang, Yuanhan and Wu, Tianxing and Jin, Qingyang and Chanpaisit, Nattapol and Wang, Yaohui and Chen, Xinyuan and Wang, Limin and Lin, Dahua and Qiao, Yu and Liu, Ziwei},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={VBench: Comprehensive Benchmark Suite for Video Generative Models}, 
  year={2024},
  volume={},
  number={},
  pages={21807-21818},
  abstract={Video generation has witnessed significant advance-ments, yet evaluating these models remains a challenge. A comprehensive evaluation benchmark for video generation is indispensable for two reasons: 1) Existing metrics do not fully align with human perceptions; 2) An ideal eval-uation system should provide insights to inform future de-velopments of video generation. To this end, we present VBench, a comprehensive benchmark suite that dissects “video generation quality” into specific, hierarchical, and disentangled dimensions, each with tailored prompts and evaluation methods. VBench has three appealing proper-ties: 1) Comprehensive Dimensions: VBench comprises 16 dimensions in video generation (e.g., subject identity in-consistency, motion smoothness, temporal flickering, and spatial relationship, etc.). The evaluation metrics with fine-grained levels reveal individual models' strengths and weaknesses. 2) Human Alignment: We also provide a dataset of human preference annotations to validate our benchmarks' alignment with human perception, for each evaluation dimension respectively. 3) Valuable Insights: We look into current models' ability across various evaluation dimensions, and various content types. We also investi-gate the gaps between video and image generation models. We will open-source VBench, including all prompts, evaluation methods, generated videos, and human preference an-notations, and also include more video generation models in VBench to drive forward the field of video generation.},
  keywords={Measurement;Computer vision;Image synthesis;Annotations;Computational modeling;Benchmark testing;Pattern recognition;evaluation;video generation;benchmark;generative models;VBench;benchmark video generation models;evaluate video generation models;prompt;dataset;human alignment;diffusion models;aigc;fine-grained evaluation;human preference},
  doi={10.1109/CVPR52733.2024.02060},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{10340437,
  author={Larey, Ariel and Daniel, Nati and Aknin, Eliel and Fisher, Yael and Savir, Yonatan},
  booktitle={2023 45th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)}, 
  title={DEPAS: De-novo Pathology Semantic Masks using a Generative Model}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={The integration of artificial intelligence (AI) into digital pathology has the potential to automate and improve various tasks, such as image analysis and diagnostic decision-making. Yet, the inherent variability of tissues, together with the need for image labeling, lead to biased datasets that limit the generalizability of algorithms trained on them. One of the emerging solutions for this challenge is synthetic histological images. Debiasing real datasets require not only generating photorealistic images but also the ability to control the cellular features within them. A common approach is to use generative methods that perform image translation between semantic masks that reflect prior knowledge of the tissue and a histological image. However, unlike other image domains, the complex structure of the tissue prevents a simple creation of histology semantic masks that are required as input to the image translation model, while semantic masks extracted from real images reduce the process’s scalability. In this work, we introduce a scalable generative model, coined as DEPAS (De-novo Pathology Semantic Masks), that captures tissue structure and generates high-resolution semantic masks with state-of-the-art quality. We demonstrate the ability of DEPAS to generate realistic semantic maps of tissue for three types of organs: skin, prostate, and lung. Moreover, we show that these masks can be processed using a generative image translation model to produce photorealistic histology images of two types of cancer with two different types of staining techniques. Finally, we harness DEPAS to generate multi-label semantic masks that capture different cell types distributions and use them to produce histological images with on-demand cellular features. Overall, our work provides a state-of-the-art solution for the challenging task of generating synthetic histological images while controlling their semantic information in a scalable way.},
  keywords={Histopathology;Image synthesis;Scalability;Microprocessors;Semantics;Pipelines;Computer architecture;Digital pathology;Generative Adversarial Network;Tissue Image Generation;Histological Image Generation},
  doi={10.1109/EMBC40787.2023.10340437},
  ISSN={2694-0604},
  month={July},}@INPROCEEDINGS{6822149,
  author={Imhoff, Scott Allen and Nguyen, Dave and Kim, Johann},
  booktitle={2014 International Conference on Computational Science and Computational Intelligence}, 
  title={Toward an Artificial Jesus: Part 1, the Representation Problem}, 
  year={2014},
  volume={1},
  number={},
  pages={440-443},
  abstract={Much of the world is interested in the sayings of Jesus of Nazareth. Until now, exegesis of his sayings has been based on analysis rather than synthesis. Using the meta-mathematics of formal languages, we can implement automata in an environment consisting of the words and grammar of Jesus and determine new sayings which constitute an important metadata that can aid our understanding of the sayings of Jesus. We present a number of these new sayings, noting that the quality of the sayings decreases as the complexity of the automata increases if there is no learning.},
  keywords={Learning automata;Automata;Tongue;Grammar;Formal languages;Pragmatics;Genetics;Automata;Greek exegesis;generative grammar;meta-mathematics;linguistics},
  doi={10.1109/CSCI.2014.79},
  ISSN={},
  month={March},}@INPROCEEDINGS{11092062,
  author={Jing, Liying and Zhang, Yi and Chen, Dengkang},
  booktitle={2025 7th International Conference on Computer Science and Technologies in Education (CSTE)}, 
  title={Chatbots in Educational Settings: A Comprehensive Literature Review}, 
  year={2025},
  volume={},
  number={},
  pages={425-429},
  abstract={The application of chatbots based on generative artificial intelligence in education is increasingly widespread. But their effectiveness remains controversial and systematic research is scarce. This study conducts a systematic literature review of 25 empirical studies (2021–2025) to address three key questions: (1) What are the key application scenarios of chatbots in the field of education? (2) What are the key functional roles do chatbots in the field of education play? (3) How do chatbots in education affect students’ learning? The study found that educational chatbots can be divided into three categories: knowledge coordinators, emotional coordinators, and learning process coordinators. These chatbots influence students in cognitive, emotional, and behavioral dimensions. This study provides a structured understanding of chatbot applications in education, offering insights for future research and practice.},
  keywords={Computer science;Systematics;Generative AI;Education;Chatbots;Systematic literature review;chatbot;educational settings;artificial intelligence},
  doi={10.1109/CSTE64638.2025.11092062},
  ISSN={},
  month={April},}@INPROCEEDINGS{11082721,
  author={Al-Alawi, Adel Ismail and Albuainain, Muneera Salem},
  booktitle={2024 International Conference on Open Innovation and Digital Transformation (OIDT)}, 
  title={Unveiling Credit Card Fraud: Harnessing Artificial Neural Networks for Accurate Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In the context of our modern technology-driven societies, the utilization of credit cards has experienced a substantial rise compared to earlier periods. The rise in electronic commerce (e-commerce) can be traced to the extensive implementation of Digital Transformation (DT) in response to the global COVID-19 pandemic, which compelled many businesses to shift their activities to online platforms. This study emphasizes the significance of harnessing Artificial Neural Networks (ANN) inside contemporary online systems to increase fraud detection accuracy. This study evaluates Machine Learning (ML) supervised and ANN models, particularly Recurrent Neural Networks (RNN). The approach involved a ten-step methodology, from keyword searching to comprehensive analysis, followed by data exploration, subjected to rigorous testing to reach results and a conclusion. Two RNN models were built with different numbers of neurons and functions in Python, and the models were tested on two datasets retrieved from Kaggle (Kaggle.com/dataset). Compared to previous studies, the findings and the RNN models provide higher accuracy and fewer errors. The Long Short Term Memory (LSTM) model obtained the highest accuracy at 0.9994. This research specifies an insightful understanding of the advantages of adopting ML models in fraud detection systems. The findings of this study will provide leaders of banks and financial institutions with an understanding of the gains ML can add to their business. Furthermore, executives and professionals can use this research to develop DT strategies that improve their financial transactions.},
  keywords={Recurrent neural networks;Accuracy;Digital transformation;Machine learning;Credit cards;Fraud;Electronic commerce;Long short term memory;Business;Testing;Digital Transformation (DT);Artificial Intelligence (AI);Machine Learning (ML);Artificial Neural Networks (ANN);Recurrent Neural Networks (RNN);Long Short Term Memory (LSTM);Gated Recurrent Unit (GRU)},
  doi={10.1109/OIDT59407.2024.11082721},
  ISSN={},
  month={March},}@INPROCEEDINGS{10842898,
  author={Palliwar, Aakash and Khapre, Aman and Kasare, Aarya and Nikhare, Samiksha},
  booktitle={2024 2nd DMIHER International Conference on Artificial Intelligence in Healthcare, Education and Industry (IDICAIEI)}, 
  title={Real-time inverse kinematics function generation using (GANs) and advanced computer vision for Robotics joints}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This research presents a novel approach for real-time inverse kinematic function generation for robotic joints using Generative Adversarial Networks (GANs) integrated with advanced computer vision techniques. This project includes an automated [15] model that moves based on human hand movements. The system uses Modern computer vision techniques to precisely interpret human hand motions, which enables a robot to imitate hand movements in real-time, mainly in the X and Y axes. The proposed technique leverages GANs for modeling complex, high-dimensional kinematic transformations, allowing for accurate and effortless computation of joint configurations determined by end-effector positions. Thus, if a human hand performs a wave motion, the robotic arm will move from left to right, replicating the wave action. Using sensors, inverse kinematics, and AI/ML algorithms, the outcome shows significant improvements in motion accuracy and computational efficiency over usual inverse kinematic solutions, showcasing the model’s potential in human-robot interactions.},
  keywords={Hands;Computer vision;Accuracy;Service robots;Heuristic algorithms;Computational modeling;Kinematics;Arms;Robot sensing systems;Real-time systems;AI/ML algorithms;inverse kinematics;human-robot interactions;imitating hand movements},
  doi={10.1109/IDICAIEI61867.2024.10842898},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11128113,
  author={Kim, Byungchul and Wang, Tsun-Hsuan and Rus, Daniela},
  booktitle={2025 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Generative-AI-Driven Jumping Robot Design Using Diffusion Models}, 
  year={2025},
  volume={},
  number={},
  pages={6267-6274},
  abstract={Astract-Recent advances in foundation models are significantly expanding the capabilities of AI models. As part of this progress, this paper introduces a robot design framework that uses a diffusion model approach for generating 3D mesh structures. Specifically, we focus on generating directly fabri-cable robot structures that require no post-processing guided by human-imposed design constraints. Our approach can find the optimal design of the robot by optimizing or composing embedding vectors of the model. The efficacy of the framework is validated through an application to design, fabricate, and evaluate a jumping robot. Our solution is an optimized jumping robot with a 41% increase in jump height compared to the state-of-the-art design. Additionally, when the robot is augmented with an optimized foot, it can land reliably with a success ratio of 88% in contrast to the 4% success ratio of the base robot.},
  keywords={Three-dimensional displays;Generative AI;Foundation models;Diffusion models;Vectors;Reliability;Robots;Design optimization;Computational Design;Generative Artificial Intelligence;Design Optimization;Jumping Robot},
  doi={10.1109/ICRA55743.2025.11128113},
  ISSN={},
  month={May},}@INPROCEEDINGS{9289248,
  author={Yoo, Jaesung and Park, Jeman and Wang, An and Mohaisen, David and Kim, Joongheon},
  booktitle={2020 International Conference on Information and Communication Technology Convergence (ICTC)}, 
  title={On the Performance of Generative Adversarial Network (GAN) Variants: A Clinical Data Study}, 
  year={2020},
  volume={},
  number={},
  pages={100-104},
  abstract={Generative Adversarial Network (GAN) is a useful type of Neural Networks in various types of applications including generative models and feature extraction. Various types of GANs are being researched with different insights, resulting in a diverse family of GANs with a better performance in each generation. This review focuses on various GANs categorized by their common traits.},
  keywords={Neural networks;Generative adversarial networks;Feature extraction;Information and communication technology;Gallium nitride;Convergence},
  doi={10.1109/ICTC49870.2020.9289248},
  ISSN={2162-1233},
  month={Oct},}@INPROCEEDINGS{11158799,
  author={Bhuktar, Deepak Madhukar and Ranjan, Ravi and Kumar Singh, Shashank and Bansod, Saurabh},
  booktitle={2025 International Conference on Computing Technologies & Data Communication (ICCTDC)}, 
  title={Real-Time Cyber Threats and Unauthorized Access Detection Using Embedded AI}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={As cyber-physical systems (CPS) and IoT ecosystems grow, protection of these interlinked environments against cyber-attacks and unauthorized access is now a high priority imperative. Conventional centralized security paradigms are becoming less effective with high latency and poor scalability, necessitating real-time, embedded solutions. This work suggests an AI driven embedded system that can identify cyber-attacks and unauthorized access in real time utilizing deep learning models and federated learning. Lightweight neural networks are embedded at the edge to carry out continuous anomaly detection and classification, while dynamic model updating is achieved through cloud driven federated learning. A cyber twin is utilized to perform real-time simulation of attack scenarios and forecast newly emerging vulnerabilities. The AI subsystem embedded identifies recognized and unrecognized threats by utilizing the hybrid models in fusion with CNNs, LSTMs, and auto-encoders in a manner of achieving high accuracy of detection along with negligible delay. Performance validation tests using common benchmarks like CICIDS2017 and NSL-KDD reveal superior quality of performance resulting in higher accuracy of detection, fewer false alarms, and decreased response times for traditional threat detecting mechanisms. The envisioned system delivers a scalable and responsive solution that augments the security of IoT and CPS landscapes against emerging cyber-attacks.},
  keywords={Deep learning;Federated learning;Explainable AI;Biological system modeling;Real-time systems;Threat assessment;Time factors;Artificial intelligence;Cyberattack;Anomaly detection;Embedded AI;Cybersecurity;IoT Security;Anomaly Detection;Real-Time Threat Detection;Intrusion De-tection System (IDS);Federated Learning;Cyber Twin;Digital Twin Technology;Generative Adversarial Networks (GANs);Cyber- Physical Systems (CPS);Artificial Intelligence;Machine Learning;Deep Learning;Explainable AI (XAI);Edge Computing Devices},
  doi={10.1109/ICCTDC64446.2025.11158799},
  ISSN={},
  month={July},}@INPROCEEDINGS{10835605,
  author={Rawat, Danda B. and Bajracharya, Chandra},
  booktitle={2024 IEEE 6th International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (TPS-ISA)}, 
  title={The Intersection of Quantum Computing, AI, and Cybersecurity: Challenges and Opportunities}, 
  year={2024},
  volume={},
  number={},
  pages={176-181},
  abstract={Recent advancements and the collaboration between the groundbreaking artificial intelligence (AI), with the wider visibility sparked by generative AI in late 2022, and quantum computing technologies have the potential to revolutionize the world, reshape the tech industry, and mark the beginning of a new era of business disruption and innovation. Furthermore, quantum computing when combined with AI, has the potential to bring a new computing revolution surpassing today’s innovation by a wide margin for different fields including cybersecurity. In one hand, digital landscape has been complex making cybersecurity more crucial than ever. On the other hand, traditional methods of safeguarding information are being pushed to their limits with the rapid advancement of technologies. The emergence of quantum computing, combined with AI, is poised to revolutionize the field of cybersecurity, presenting both unprecedented opportunities and challenges. This paper presents challenges and perspectives when quantum-powered AI and cybersecurity meet for business and innovations.},
  keywords={Hands;Industries;Technological innovation;Privacy;Quantum computing;Generative AI;Artificial intelligence;Computer crime;Intelligent systems;Business;Quantum-Powered AI;Cybersecurity;AI for cybersecurity;Quantum safe Cybersecurity;Quantum Computing},
  doi={10.1109/TPS-ISA62245.2024.00029},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10308930,
  author={Hamerlik, Endre and Deb, Mayukh and Takáč, Martin},
  booktitle={2023 World Symposium on Digital Intelligence for Systems and Machines (DISA)}, 
  title={Bi-Source Class Visualization: An Adversarial Neural Network-based Approach for Unbiased Class Visualization}, 
  year={2023},
  volume={},
  number={},
  pages={78-83},
  abstract={This paper introduces Bi-Source Class Visualization (BSCV), a novel approach for generating interpretable and visually coherent class visualizations using adversarial neural networks. Unlike existing methods that rely on hand-crafted regularization terms, BSCV incorporates two sources of teaching signals: the loss derived from the activation maximization cost function of a specific logit in a trained classifier, and the adversarial loss obtained from a discriminator network trained on the same dataset. By optimizing the visualizations based on both the classifier and discriminator, BSCV achieves robust and less biased class visualizations. Experimental evaluation demonstrates the efficacy of BSCV in generating visually appealing and discriminative visualizations. Comparison with existing methods highlights the advantages of BSCV in capturing the body of the subject and producing higher contrast visualizations. The paper also discusses future directions for evaluation metrics and explores the limitations and potential applications of BSCV. Overall, BSCV offers a promising approach for understanding and interpreting the internal representations of deep neural networks.},
  keywords={Measurement;Visualization;Education;Artificial neural networks;Cost function;Digital intelligence},
  doi={10.1109/DISA59116.2023.10308930},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11008319,
  author={Izani, M. and Gabr, M. and Harumaini, H. and Trinh, K. and Kaleel, A. and Assad, A.},
  booktitle={2025 5th International Conference on Innovative Research in Applied Science, Engineering and Technology (IRASET)}, 
  title={An AI-Driven Workflow for Preserving Traditional Malay Music Videos: A Case Study in Cultural Heritage Enhancement}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Preserving cultural heritage like traditional arts and traditional music becomes increasingly challenging during the digital age. We presented a workflow that uses generative AI to preserve traditional Malay music in video format with an emphasis on cultural integrity through photorealistic video generation. Our enhanced framework uses Low-Rank Adaptation (LoRA) combined with Splitter.ai-based vocal isolation and Kling.ai motion synchronization along with other artificial intelligence techniques to completely process and enhance audiovisual elements. We started our research design by deploying generative AI tools throughout a production process starting from concept development, facial synthesis, and training alongside motion-lip synchronization before post-production to ensure visual harmony without sacrificing storytelling elements and technical precision. The workflow consists of expert validation points, loop refinement linked to cultural accuracy loss, and computational performance. The end results show that generative AI techniques create successful links between traditional artistic forms with the present multimedia formats to preserve traditional Malay music. This research introduces a workflow that allows reproducible AI-assisted preservation methods which give opportunities to heritage experts and authorities helpful guidance to integrate technical innovations with cultural integrity.},
  keywords={Training;Visualization;Generative AI;Tracking;Cloning;Production;Streaming media;Cultural differences;Synchronization;Faces;Artificial Intelligence;Cultural Heritage;AI-Driven Video Production;LoRA Face Cloning;AI Audio Processing;Motion Synchronization;Intangible Cultural Heritage (ICH)},
  doi={10.1109/IRASET64571.2025.11008319},
  ISSN={},
  month={May},}
