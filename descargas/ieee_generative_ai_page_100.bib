@INPROCEEDINGS{11134920,
  author={Kamath, Deepika and Divya and M, Disha and Gagan and Tauro, Glanil},
  booktitle={2025 6th International Conference on Data Intelligence and Cognitive Informatics (ICDICI)}, 
  title={Deep Learning for Cognitive Human-Computer Interaction: a Comprehensive Review of Models, Techniques, and Applications}, 
  year={2025},
  volume={},
  number={},
  pages={1011-1017},
  abstract={Cognitive human-computer interaction (HCI) aims at improving human-machine interaction by integrating cognitive abilities such as perception, reasoning, and adaptability into computer systems. The development of deep learning (DL) is making machines smarter in their potential to comprehend and react to complicated human behavior and more human-like and adaptable behavior.We critically analyze the use of DL for cognitive HCI in depth. Our survey overviewed the key DL models (CNNs, RNNs, Transformers, GANs) and applications such as emotion detection, brain-computer interfaces (BCI), gesture and gaze, speech, and adaptive user interfaces. We also mention current state-of-the-art techniques and their strengths and weaknesses. Furthermore, we present barriers to usage, such as, but not limited to, real-time performance, data scarcity, interpretability, and ethical considerations. Also, we elaborate on applied research directions to undertake, such as, but not limited to, cognitive digital twins, human-centric explainable AI, and edge AI for real-time interfaces. Our goal in this survey is to educate researchers and practitioners regarding AI and cognitive HCI through an overview of the state-of-the-art nowadays and possible future directions for the development of systems that are more interactional and human-like.},
  keywords={Human computer interaction;Deep learning;Surveys;Adaptation models;Explainable AI;Brain modeling;Transformers;Real-time systems;Brain-computer interfaces;User experience;Cognitive Human-Computer Interface;Deep Learning;Brain-Computer Interface;Emotion Mining;Gesture Tracking;Gaze Estimation;Speech Interfaces;Adaptive User Experience;Explainable AI;Human-Machine Interaction},
  doi={10.1109/ICDICI66477.2025.11134920},
  ISSN={},
  month={July},}@INPROCEEDINGS{11139835,
  author={Selvam, Muthu and Rajasekaran, R. Thalapathi},
  booktitle={2025 IEEE 4th International Conference on Computing and Machine Intelligence (ICMI)}, 
  title={Natural Language Processing for Voice-Based Banking Interactions: Enhancing User Interaction Through Voice Commands}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The following paper will outline every approach to voice-based banking with the help of NLP, voice recognition, and security features to improve financial services' usability. These include state-of-the-art methodologies like ASR or intent classification using BERT and others or context-aware models so that any type of interaction with the user is smooth and the user is engaged accordingly. Security is achieved using voice recognition and multiple-factor authentication (MFA) on sensitive transactions. More advanced fraud identification is done with the help of GANs and SVMs for real-time abnormality detection. Also, it works with multiple languages and has been updated since inputs are received and model calibration is performed. The proposed methodology involves assessment criteria related to performance parameters to get very low speech recognition errors and identify appropriate intent and fraudulence, particularly when banking services are availed through voice commands.},
  keywords={Intent recognition;Computational modeling;Biological system modeling;Banking;Speech recognition;Natural language processing;Real-time systems;Fraud;Security;Context modeling;Voice-based banking;Natural Language Processing;speech recognition;intent classification;contextaware models;biometric voice authentication},
  doi={10.1109/ICMI65310.2025.11139835},
  ISSN={},
  month={April},}@ARTICLE{8882211,
  author={Loyola-Gonz√°lez, Octavio},
  journal={IEEE Access}, 
  title={Black-Box vs. White-Box: Understanding Their Advantages and Weaknesses From a Practical Point of View}, 
  year={2019},
  volume={7},
  number={},
  pages={154096-154113},
  abstract={Nowadays, in the international scientific community of machine learning, there exists an enormous discussion about the use of black-box models or explainable models; especially in practical problems. On the one hand, a part of the community defends that black-box models are more accurate than explainable models in some contexts, like image preprocessing. On the other hand, there exist another part of the community alleging that explainable models are better than black-box models because they can obtain comparable results and also they can explain these results in a language close to a human expert by using patterns. In this paper, advantages and weaknesses for each approach are shown; taking into account a state-of-the-art review for both approaches, their practical applications, trends, and future challenges. This paper shows that both approaches are suitable for solving practical problems, but experts in machine learning need to understand the input data, the problem to solve, and the best way for showing the output data before applying a machine learning model. Also, we propose some ideas for fusing both, explainable and black-box, approaches to provide better solutions to experts in real-world domains. Additionally, we show one way to measure the effectiveness of the applied machine learning model by using expert opinions jointly with statistical methods. Throughout this paper, we show the impact of using explainable and black-box models on the security and medical applications.},
  keywords={Machine learning;Mathematical model;Biological system modeling;Gallium nitride;Biological neural networks;Statistical analysis;Computational modeling;Black-box;white-box;explainable artificial intelligence;deep learning},
  doi={10.1109/ACCESS.2019.2949286},
  ISSN={2169-3536},
  month={},}@ARTICLE{9145558,
  author={Li, Lixiang and Mu, Xiaohui and Li, Siying and Peng, Haipeng},
  journal={IEEE Access}, 
  title={A Review of Face Recognition Technology}, 
  year={2020},
  volume={8},
  number={},
  pages={139110-139120},
  abstract={Face recognition technology is a biometric technology, which is based on the identification of facial features of a person. People collect the face images, and the recognition equipment automatically processes the images. The paper introduces the related researches of face recognition from different perspectives. The paper describes the development stages and the related technologies of face recognition. We introduce the research of face recognition for real conditions, and we introduce the general evaluation standards and the general databases of face recognition. We give a forward-looking view of face recognition. Face recognition has become the future development direction and has many potential application prospects.},
  keywords={Face recognition;Face;Principal component analysis;Feature extraction;Support vector machines;Machine learning;Biological neural networks;Face recognition;image processing;neural network;artificial intelligence},
  doi={10.1109/ACCESS.2020.3011028},
  ISSN={2169-3536},
  month={},}@ARTICLE{9064510,
  author={Xue, Mingfu and Yuan, Chengxiang and Wu, Heyi and Zhang, Yushu and Liu, Weiqiang},
  journal={IEEE Access}, 
  title={Machine Learning Security: Threats, Countermeasures, and Evaluations}, 
  year={2020},
  volume={8},
  number={},
  pages={74720-74742},
  abstract={Machine learning has been pervasively used in a wide range of applications due to its technical breakthroughs in recent years. It has demonstrated significant success in dealing with various complex problems, and shows capabilities close to humans or even beyond humans. However, recent studies show that machine learning models are vulnerable to various attacks, which will compromise the security of the models themselves and the application systems. Moreover, such attacks are stealthy due to the unexplained nature of the deep learning models. In this survey, we systematically analyze the security issues of machine learning, focusing on existing attacks on machine learning systems, corresponding defenses or secure learning techniques, and security evaluation methods. Instead of focusing on one stage or one type of attack, this paper covers all the aspects of machine learning security from the training phase to the test phase. First, the machine learning model in the presence of adversaries is presented, and the reasons why machine learning can be attacked are analyzed. Then, the machine learning security-related issues are classified into five categories: training set poisoning; backdoors in the training set; adversarial example attacks; model theft; recovery of sensitive training data. The threat models, attack approaches, and defense techniques are analyzed systematically. To demonstrate that these threats are real concerns in the physical world, we also reviewed the attacks in real-world conditions. Several suggestions on security evaluations of machine learning systems are also provided. Last, future directions for machine learning security are also presented.},
  keywords={Machine learning;Security;Data models;Machine learning algorithms;Training;Training data;Prediction algorithms;Artificial intelligence security;poisoning attacks;backdoor attacks;adversarial examples;privacy-preserving machine learning},
  doi={10.1109/ACCESS.2020.2987435},
  ISSN={2169-3536},
  month={},}@ARTICLE{9895425,
  author={Khamaiseh, Samer Y. and Bagagem, Derek and Al-Alaj, Abdullah and Mancino, Mathew and Alomari, Hakam W.},
  journal={IEEE Access}, 
  title={Adversarial Deep Learning: A Survey on Adversarial Attacks and Defense Mechanisms on Image Classification}, 
  year={2022},
  volume={10},
  number={},
  pages={102266-102291},
  abstract={The popularity of adapting deep neural networks (DNNs) in solving hard problems has increased substantially. Specifically, in the field of computer vision, DNNs are becoming a core element in developing many image and video classification and recognition applications. However, DNNs are vulnerable to adversarial attacks, in which, given a well-trained image classification model, a malicious input can be crafted by adding mere perturbations to misclassify the image. This phenomena raise many security concerns in utilizing DNNs in critical life applications which attracts the attention of academic and industry researchers. As a result, multiple studies have proposed discussing novel attacks that can compromise the integrity of state-of-the-art image classification neural networks. The raise of these attacks urges the research community to explore countermeasure methods to mitigate these attacks and increase the reliability of adapting DDNs in different major applications. Hence, various defense strategies have been proposed to protect DNNs against adversarial attacks. In this paper, we thoroughly review the most recent and state-of-the-art adversarial attack methods by providing an in-depth analysis and explanation of the working process of these attacks. In our review, we focus on explaining the mathematical concepts and terminologies of the adversarial attacks, which provide a comprehensive and solid survey to the research community. Additionally, we provide a comprehensive review of the most recent defense mechanisms and discuss their effectiveness in defending DNNs against adversarial attacks. Finally, we highlight the current challenges and open issues in this field as well as future research directions.},
  keywords={Deep learning;Neural networks;Training data;Perturbation methods;Security;Computational modeling;Machine learning algorithms;Deep neural networks;artificial intelligence;adversarial examples;adversarial perturbations},
  doi={10.1109/ACCESS.2022.3208131},
  ISSN={2169-3536},
  month={},}@ARTICLE{9934016,
  author={Jiang, Xiaoran and Shi, Jinglei and Guillemot, Christine},
  journal={IEEE Transactions on Image Processing}, 
  title={An Untrained Neural Network Prior for Light Field Compression}, 
  year={2022},
  volume={31},
  number={},
  pages={6922-6936},
  abstract={Deep generative models have proven to be effective priors for solving a variety of image processing problems. However, the learning of realistic image priors, based on a large number of parameters, requires a large amount of training data. It has been shown recently, with the so-called deep image prior (DIP), that randomly initialized neural networks can act as good image priors without learning. In this paper, we propose a deep generative model for light fields, which is compact and which does not require any training data other than the light field itself. To show the potential of the proposed generative model, we develop a complete light field compression scheme with quantization-aware learning and entropy coding of the quantized weights. Experimental results show that the proposed method yields very competitive results compared with state-of-the-art light field compression methods, both in terms of PSNR and MS-SSIM metrics.},
  keywords={Image coding;Image reconstruction;Decoding;Adaptation models;Video compression;Predictive models;Rate-distortion;Light fields;compression;generative model;compact representation},
  doi={10.1109/TIP.2022.3217374},
  ISSN={1941-0042},
  month={},}@INPROCEEDINGS{8489047,
  author={Fu, Lunkai and Li, Jun and Zhou, Langxiong and Ma, Zhenyuan and Liu, Shaopeng and Lin, Zhiyong and Prasad, Mukesh},
  booktitle={2018 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Utilizing Information from Task-Independent Aspects via GAN-Assisted Knowledge Transfer}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={Observed data often have multiple labels with respect to different aspects. For example, a picture can have one label specifying the contents in terms of the object category such as aeroplane, building, cat, etc. and in the meanwhile have another label describing the image style such as photo-realistic or artistic. The central idea of this work is that any annotation of the data contains precious knowledge and is not to be foregone: an analytic task focusing on one aspect of the data can benefit from the knowledge transferred from the other aspects. We propose a passive knowledge transfer scheme for deep neural network training based on the generative adversarial nets (GANs). The adversarial training scheme encourages the nets to encode data into representations that are both discriminative for the target aspect and invariant with respect to the irrelevant aspects. We show that the scheme mixes the conditional distributions of the encoded data on the irrelevant aspects, by the theory on the link between the GAN framework and the Wasserstein metric in distribution spaces. Moreover, we empirically verified the method by i) classifying images despite influence by geometric transform and ii) recognizing the movements (geometric transform) regardless the image contents.},
  keywords={Task analysis;Neural networks;Knowledge transfer;Gallium nitride;Generators;Training;Measurement;Deep Neural Networks;Knowledge Transfer;Generative Adversarial Nets},
  doi={10.1109/IJCNN.2018.8489047},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{10350573,
  author={Boreiko, Valentyn and Hein, Matthias and Metzen, Jan Hendrik},
  booktitle={2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)}, 
  title={Identifying Systematic Errors in Object Detectors with the SCROD Pipeline}, 
  year={2023},
  volume={},
  number={},
  pages={4092-4101},
  abstract={The identification and removal of systematic errors in object detectors can be a prerequisite for their deployment in safety-critical applications like automated driving and robotics. Such systematic errors can for instance occur under very specific object poses (location, scale, orientation), object colors/textures, and backgrounds. Real images alone are unlikely to cover all relevant combinations. We overcome this limitation by generating synthetic images with fine-granular control. While generating synthetic images with physical simulators and hand-designed 3D assets allows fine-grained control over generated images, this approach is resource-intensive and has limited scalability. In contrast, using generative models is more scalable but less reliable in terms of fine-grained control. In this paper, we propose a novel framework that combines the strengths of both approaches. Our meticulously designed pipeline along with custom models enables us to generate street scenes with fine-grained control in a fully automated and scalable manner. Moreover, our framework introduces an evaluation setting that can serve as a benchmark for similar pipelines. This evaluation setting will contribute to advancing the field and promoting standardized testing procedures.},
  keywords={Computer vision;Systematics;Three-dimensional displays;Scalability;Conferences;Pipelines;Detectors;Synthetic data;Model auditing;Generative models;Stable diffusion;Object detection},
  doi={10.1109/ICCVW60793.2023.00442},
  ISSN={2473-9944},
  month={Oct},}@ARTICLE{10666017,
  author={Xing, Dengpeng and Yang, Yiming and Li, Jiale},
  journal={IEEE Transactions on Cognitive and Developmental Systems}, 
  title={Pretrained Dynamics Learning of Numerous Heterogeneous Robots and Gen2Real Transfer}, 
  year={2025},
  volume={17},
  number={2},
  pages={315-327},
  abstract={Acquiring dynamics is vital for robotic learning and serves as the foundation for planning and control. This article addresses two essential inquiries: How can one develop a model that encompasses a vast array of diverse robotic dynamics? Is it possible to establish a model that alleviates the burdens of data collection and domain expertise necessary for constructing specific robot models? We explore the dynamics present in a dataset containing numerous serial articulated robots and introduce a novel concept, ‚ÄúGen2Real,‚Äù to transfer simulated, generalized models to physical, and specialized robots. By randomizing dynamics parameters, topological configurations, and model dimensions, we generate an extensive dataset that corresponds to varying properties, connections, and quantities of robotic links. A structure adapted from the generative pretrained transformer is employed to approximate the dynamics of a multitude of heterogeneous robots. Within Gen2Real, we transfer the pretrained model to a target robot using distillation to enable real-time computation. The results corroborate the superiority of the proposed method in terms of accurately learning an immense scope of robotic dynamics, managing commonly encountered disturbances, and exhibiting versatility in transferring to distinct robots.},
  keywords={Robots;Aerodynamics;Mathematical models;Transformers;Trajectory;Training;Robot kinematics;Generative pretrained transformer;Gen2Real;robot dynamics learning},
  doi={10.1109/TCDS.2024.3454240},
  ISSN={2379-8939},
  month={April},}@INPROCEEDINGS{10467610,
  author={Talib, Doaa A. and Abed, Ali A.},
  booktitle={2023 1st International Conference on Advanced Engineering and Technologies (ICONNIC)}, 
  title={DeepFake Image Detection Using Adaptive Discriminator Augmentation (ADA)}, 
  year={2023},
  volume={},
  number={},
  pages={248-253},
  abstract={The proliferation of Deepfake technology, driven by artificial intelligence (AI), poses a growing threat as it facilitates the dissemination of hate speech and misinformation through convincingly fabricated images. Deepfakes, a subdomain of AI, manipulate and superimpose one person's face onto another's, exploiting the power of machine learning to create deceptive content at an unprecedented pace and affordability. Despite the controversial nature of Deepfakes, their use is expanding both commercially and collectively. This paper offers an in-depth investigation into the effectiveness of StyleGAN2-ADA in identifying fake images, with a particular focus on detecting Deepfakes. We propose a novel GAN Discriminator model designed to enhance the accuracy of this detection process. Our model's training dataset comprises an extensive collection of 76,400 images from the FFHQ dataset. In our experimental evaluation, we subjected our model to 100 fake images, achieving an impressive detection rate of 95.71 %. This remarkable outcome underscores the efficacy of our approach in identifying Deepfakes. Furthermore, our technique demonstrates exceptional precision in distinguishing between real and fake images, promising a robust defense against the harmful impact of AI-generated fake content.},
  keywords={Training;Deepfakes;Image synthesis;Hate speech;Machine learning;Generative adversarial networks;Multitasking;DeepFake images;Detection Fake;Image datasets;StyleGAN2-ADA;Adaptive Discriminator Augmentation},
  doi={10.1109/ICONNIC59854.2023.10467610},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10910552,
  author={Marali, Amulya and Hegde, Ashwini and Annamalai, Madhumitha and V S, Ruchitha and Natarajan, S},
  booktitle={2024 IEEE 3rd International Conference on Data, Decision and Systems (ICDDS)}, 
  title={Completing the Puzzle: Knowledge Graph Augmentation Using GANs}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Knowledge Graphs (KGs) play a crucial role in information management and artificial intelligence connecting complex webs of data, enabling inference and decision-making. However, there is a big problem with KGs: they are incomplete. The proposed study intends to complete Knowledge Graphs by creating vector embeddings for PICKLE and FB15k-237 datasets, identifying sparsity in the generated knowledge graphs using Gini index and node density metrics, generating missing nodes using GANs and embedding the generated nodes along with links in the parent KG. Integration of synthetic nodes and links using Graph Convolutional Networks (GCNs) further enrich the KG, ensuring proper alignment with existing structures. RotatE outperforms other Vector Embedding Models in terms of metrics such as Mean Reciprocal Rank (MRR) and Hits@k.},
  keywords={Measurement;Manifolds;Graph convolutional networks;Decision making;Knowledge graphs;Solids;Generative adversarial networks;Vectors;Indexes;Knowledge transfer;Knowledge Graph Completion;Vector Embed-dings;GANs;GCNs},
  doi={10.1109/ICDDS62937.2024.10910552},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11162180,
  author={Zhang, Xinren and Shang, Chen and Yu, Jiadong},
  booktitle={2025 IEEE International Conference on Communications Workshops (ICC Workshops)}, 
  title={Rethinking the Reward Design for DRL in Mobile Communication Systems with Generative Diffusion Models}, 
  year={2025},
  volume={},
  number={},
  pages={250-255},
  abstract={When applying deep reinforcement learning (DRL) in mobile communication systems, an appropriate reward function can effectively guide the agent towards learning the optimal action. However, it is challenging to accurately design a reward function in the dynamic and uncertain systems. To address the limitations when the reward function is unknown, suboptimal, or involves multiple objectives, we propose the Generative Diffusion Model-based Reward Exploration DRL (GRE-DRL) framework, which includes an exploration module in addition to the designed rewards. The proposed framework is evaluated in the context of a full-duplex (FD) mobile communication system based on deep deterministic policy gradient (DDPG) as the fundamental DRL approach, focusing on improving the performance of beam-forming and power allocation through the specific generative artificial intelligence (GenAI) models (i.e., generative diffusion models (GDM)). Numerical results demonstrate that the proposed algorithm outperforms conventional reward design methods by achieving faster convergence and reducing computation consumption, proving the effectiveness of our approach.},
  keywords={Uncertain systems;Generative AI;Design methodology;Conferences;Heuristic algorithms;Mobile communication;Diffusion models;Numerical models;Resource management;Convergence},
  doi={10.1109/ICCWorkshops67674.2025.11162180},
  ISSN={2694-2941},
  month={June},}@ARTICLE{9399836,
  author={Xie, Guo-Sen and Zhang, Xu-Yao and Yao, Yazhou and Zhang, Zheng and Zhao, Fang and Shao, Ling},
  journal={IEEE Transactions on Image Processing}, 
  title={VMAN: A Virtual Mainstay Alignment Network for Transductive Zero-Shot Learning}, 
  year={2021},
  volume={30},
  number={},
  pages={4316-4329},
  abstract={Transductive zero-shot learning (TZSL) extends conventional ZSL by leveraging (unlabeled) unseen images for model training. A typical method for ZSL involves learning embedding weights from the feature space to the semantic space. However, the learned weights in most existing methods are dominated by seen images, and can thus not be adapted to unseen images very well. In this paper, to align the (embedding) weights for better knowledge transfer between seen/unseen classes, we propose the virtual mainstay alignment network (VMAN), which is tailored for the transductive ZSL task. Specifically, VMAN is casted as a tied encoder-decoder net, thus only one linear mapping weights need to be learned. To explicitly learn the weights in VMAN, for the first time in ZSL, we propose to generate virtual mainstay (VM) samples for each seen class, which serve as new training data and can prevent the weights from being shifted to seen images, to some extent. Moreover, a weighted reconstruction scheme is proposed and incorporated into the model training phase, in both the semantic/feature spaces. In this way, the manifold relationships of the VM samples are well preserved. To further align the weights to adapt to more unseen images, a novel instance-category matching regularization is proposed for model re-training. VMAN is thus modeled as a nested minimization problem and is solved by a Taylor approximate optimization paradigm. In comprehensive evaluations on four benchmark datasets, VMAN achieves superior performances under the (Generalized) TZSL setting.},
  keywords={Semantics;Training;Task analysis;Image reconstruction;Whales;Manifolds;Generative adversarial networks;Zero-shot learning;virtual sample generation;transductive},
  doi={10.1109/TIP.2021.3070231},
  ISSN={1941-0042},
  month={},}@ARTICLE{10339294,
  author={Ling, Yongguo and Zhong, Zhun and Luo, Zhiming and Li, Shaozi and Sebe, Nicu},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Bridge Gap in Pixel and Feature Level for Cross-Modality Person Re-Identification}, 
  year={2024},
  volume={34},
  number={6},
  pages={5104-5117},
  abstract={Visible thermal person re-identification (VT-ReID) plays a vital role in intelligent surveillance systems, particularly in weak lighting environments. VT-ReID faces substantial challenges, including the cross-modality gap and intra-class variations. Existing methods address these challenges through either pixel-level image translation techniques or feature-level metric learning techniques. However, the former approaches require additional computational costs and often generate noisy images, making model training challenging. The latter methods focus on constraining the relations between individual instances or class centers, while often ignoring joint consideration of the relationship between the two aspects. In addition, these works do not fully investigate the mutual benefits at both pixel-level and feature-level. To address these limitations, we propose a unified Dual-level Smooth Gap (DSG) learning framework that simultaneously smooths the cross-modality gap at the pixel and feature levels. Specifically, on the one hand, we develop a parameter-free Class-aware Modality Mix (CMM) to smooth the cross-modality gap at the pixel level. CMM can capture and explore internal information between the two modalities by mixing images from different modalities belonging to the same class. On the other hand, we devise an efficient Center-guided Metric Learning (CML) to reduce the inter-modality discrepancy and intra-class variations at the feature level. CML enhances model discrimination and generalization by enforcing constraints on both class centers and instances. Experiments on two benchmark datasets demonstrate the mutual benefits of our proposed and show the superior performance of our method over state-of-the-art methods.},
  keywords={Feature extraction;Measurement;Lighting;Generative adversarial networks;Cameras;Training;Identification of persons;Modal analysis;Person re-identification;cross-modality;metric learning;modality alignment},
  doi={10.1109/TCSVT.2023.3338813},
  ISSN={1558-2205},
  month={June},}@ARTICLE{10950428,
  author={Li, Tao and Liu, Yun and Ren, Wenqi and Shiri, Babak and Lin, Weisi},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Single Image Dehazing Using Fuzzy Region Segmentation and Haze Density Decomposition}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Images captured under haze weather conditions usually suffer from visual quality degradations, such as blurred details, faded colors, and decreased saturation. Existing physicsbased dehazing methods mainly have two drawbacks: 1) the atmospheric light is treated as a constant for the entire image, and 2) pixel-or patch-based strategies are employed to estimate the model parameters, resulting in inaccurate haze density estimations. Therefore, these methods may lead to over-dehazing or under-dehazing due to insufficient utilization of features from regions with similar haze densities. To address these issues, a novel single image dehazing framework based on fuzzy region segmentation and haze density decomposition is proposed. Specifically, a region-based physical model that considers the non-uniform atmospheric light is first constructed based on the classic atmospheric scattering model. Then, a fuzzy segmentation algorithm is improved to divide the input hazy image into several separate regions. Subsequently, we formulate a simple linear relationship between the atmospheric light and brightness to estimate region-based atmospheric light. On the other hand, we develop a novel haze density decomposition algorithm based on boundary constraints to separate the atmospheric veil into two components: thin part and dense part. Three haze-related features, contrast, gradient and clarity, are extracted from the input hazy image to construct weight maps and a multi-scale fusion is further exploited to combine weight maps and boundary veils to acquire the refined atmospheric veil. Finally, the model inversion is performed to acquire the haze-free result. Experiments on six diverse hazy datasets demonstrate that the proposed algorithm outperforms several state-of-the-art dehazing methods in both visual quality and objective evaluation.},
  keywords={Atmospheric modeling;Image segmentation;Training;Image color analysis;Feature extraction;Brightness;Visualization;Learning systems;Scattering;Generative adversarial networks;Image dehazing;fuzzy region segmentation;haze density decomposition;multi-scale fusion},
  doi={10.1109/TCSVT.2025.3558232},
  ISSN={1558-2205},
  month={},}@INPROCEEDINGS{10615511,
  author={Iuliano, Antonella and Li√≤, Pietro and Manfredi, Gilda and Romaniello, Federico},
  booktitle={2024 IEEE International Workshop on Metrology for Living Environment (MetroLivEnv)}, 
  title={Denoising Probabilistic Diffusion Models for Synthetic Healthcare Image Generation}, 
  year={2024},
  volume={},
  number={},
  pages={415-420},
  abstract={Healthcare data are an essential resource in Machine Learning (ML) and Artificial Intelligence (AI) to improve clinical practice, empower patients and enhance drug development with the aim to discover new medical knowledge. In particular, the biomedical imaging analysis plays a important role in the health-care context producing a huge amount of data that can be used to study complex diseases and their evolution in a deeper way or to predict their onsets. In this work we consider an approach based on Denoising Diffusion Probabilistic Models (DDPM) which is a type of generative model that uses a parameterized Markov chain and variational inference to generate synthetic samples that match real data. In particular, we execute a study by training on Malaria images and generating high-quality synthetic samples in order (i) to test the performance of the DDPMs, (ii) to estimate the association between original and synthetic data and (iii) to understand how the natural and human-made environmental factors impact Malaria disease. Finally, we use a well-defined convolutional neural network for classification tasks to assess the DDPM's goodness in generating the synthetic images.},
  keywords={Training;Malaria;Noise reduction;Medical services;Probabilistic logic;Diffusion models;Data models;Denoising Probabilistic Diffusion Models;Healthcare dataset;Deep Learning;Synthetic data},
  doi={10.1109/MetroLivEnv60384.2024.10615511},
  ISSN={},
  month={June},}@ARTICLE{9903428,
  author={Zhu, Wanning and Zhang, Libao},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={Pan-Sharpening Based on Joint Visual Saliency Analysis and Parallel Bidirectional Network}, 
  year={2022},
  volume={19},
  number={},
  pages={1-5},
  abstract={In remote sensing (RS) images, the demands for spectral and spatial quality of different regions are different, which means that the unified fusion strategy on the whole image is not suitable for pan-sharpening task. Saliency, derived from visual attention mechanism, provides an effective way to satisfy these demands. Inspired by this, we propose a novel pan-sharpening method based on joint visual saliency analysis and parallel bidirectional network (JSPBN). First, considering the complex scenes and uneven distribution of targets in RS images, we develop a Bayesian optimization-based joint visual saliency analysis (B-JVSA) method that integrates prior saliency based on global color contrast with likelihood saliency based on joint co-occurrence histogram, which can highlight common salient regions while suppressing individual ones and irrelevant background by exploring the correlation among multiple RS images. Second, we construct a parallel bidirectional feature pyramid (PBFP) network to obtain coarse fusion features, fully considering individual characteristics of panchromatic (PAN) images and multispectral (MS) images. Finally, we design a saliency-aware layer (SAL) according to B-JVSA to further refine the fusion effect in salient regions and nonsalient regions. With the help of SAL, diverse strategies for certain regions are learned through two independent residual dense networks (RDNs) and thereby generating accurate fusion results. Experimental results show that our proposal performs better than the competing methods in both spatial quality enhancement and spectral fidelity preservation.},
  keywords={Visualization;Image color analysis;Feature extraction;Bayes methods;Histograms;Convolution;Generative adversarial networks;Joint visual saliency analysis;pan-sharpening;parallel bidirectional network;remote sensing (RS)},
  doi={10.1109/LGRS.2022.3209787},
  ISSN={1558-0571},
  month={},}@INPROCEEDINGS{10687511,
  author={Han, Xiaotian and Wang, Yiqi and Zhai, Bohan and You, Quanzeng and Yang, Hongxia},
  booktitle={2024 IEEE International Conference on Multimedia and Expo (ICME)}, 
  title={COCO is ‚ÄúALL‚Äù You Need for Visual Instruction Fine-tuning}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Multi-modal Large Language Models (MLLMs) are increasingly prominent in the field of artificial intelligence. Visual instruction fine-tuning (IFT) is a vital process for aligning MLLMs‚Äô output with user‚Äôs intentions. High-quality and diversified instruction following data is the key to this fine-tuning process. Recent studies propose to construct visual IFT datasets through a multifaceted approach: transforming existing datasets with rule-based templates, employing GPT-4 for rewriting annotations, and utilizing GPT-4V for visual dataset pseudo-labeling. LLaVA-1.5 adopted similar approach and construct LLaVA-Instruct, which is one of the simplest, most widely used, yet most effective IFT datasets today. Notably, when properly fine-tuned with this dataset, MLLMs can achieve state-of-the-art performance on several benchmarks. However, we noticed that models trained with this dataset often struggle to follow user instructions properly in multi-round dialog. In addition, tradition caption and VQA evaluation benchmarks, with their closed-form evaluation structure, are not fully equipped to assess the capabilities of modern open-ended generative MLLMs. This problem is not unique to the LLaVA-Instruct dataset, but may be a potential issue in all IFT datasets constructed from image captioning or VQA sources, though the extent of this issue may vary. We argue that datasets with diverse and high-quality detailed instruction following annotations are essential and adequate for MLLMs IFT. In this work, we establish a new IFT dataset, with images sourced from the COCO dataset along with more diverse instructions. Our experiments show that when fine-tuned with proposed dataset, MLLMs achieve better performance on open-ended evaluation benchmarks in both single-round and multi-round dialog setting.},
  keywords={Visualization;Annotations;Large language models;Benchmark testing;Dataset;COCO;Multi-modal Large Language Models (MLLMs);Instruction Fine-tuning;Open-ended evaluation;Multi-round Dialog},
  doi={10.1109/ICME57554.2024.10687511},
  ISSN={1945-788X},
  month={July},}@INPROCEEDINGS{10328012,
  author={Guo, Ping},
  booktitle={2023 International Conference on Machine Learning and Cybernetics (ICMLC)}, 
  title={Two-Model Synergetic Learning Systems Optimization with Maxwell's Demon Technique}, 
  year={2023},
  volume={},
  number={},
  pages={159-164},
  abstract={A two-model Synergetic Learning Systems (2MSLS) is a special case of the synergetic learning systems. In the 2MSLS, two models (subsystems) are contained: the reduction model and the evolution model, which are governed by neural partial differential equations. The information ‚Äúparticles‚Äù diffusion process is described by evolution model, hence the evolution model is equivalent to the generative model. And the particles condensate process is described by reduction model, which is equivalent to the inference model. In order to optimize 2MSLS, we propose a novel optimization scheme, named Maxwell's demon technique (MDT). The MDT is applied to decrease system entropy, and it is a integrated technique which includes Bayesian pseudoinverse learners, pseudoinverse learning algorithm for autoencoders, probabilistic principle component analysis. Theoretical analysis shows that our proposed 2MSLS has stronger interpretability with statistical physics image. And the MDT has a great efficiency in optimization compared with Monte Carlo Markov Chain sampling methods. This work is of significance in that it presents a clear view of interpretable deep neural networks with statistical physics perspective, and paves the road to physical artificial intelligence.},
  keywords={Learning systems;Machine learning algorithms;Monte Carlo methods;Roads;Partial differential equations;Markov processes;Probabilistic logic;Synergetic Learning Systems;Dissipative Structure;Diffusion and Condensate Process;PseudoInverse Algorithm;Maxwell's Demon Technique},
  doi={10.1109/ICMLC58545.2023.10328012},
  ISSN={2160-1348},
  month={July},}@INPROCEEDINGS{9332367,
  author={Zhang, Shuai and Wang, Decai and Li, Qin and Wang, Jinlong and Sun, Yuexing},
  booktitle={2020 IEEE 3rd International Conference of Safe Production and Informatization (IICSPI)}, 
  title={Research on Intelligent Chat Robot Based on Big Data Analysis}, 
  year={2020},
  volume={},
  number={},
  pages={692-695},
  abstract={With the rapid development of Internet technologies such as big data and artificial intelligence, chat robots have begun to enter people's daily life, providing a lot of convenience for people's life and work. At present, many research institutions focus on the research and development of chat robots, but this field is still in its infancy, and chat robots in the market are more or less deficient. Based on the deep learning technology in big data, this paper constructs and trains the model of attention mechanism, and realizes the generative dialogue chat robot in the open field, which can intelligently generate smooth responses according to the wide input of users; The model is implemented by deep learning TensorFlow coding library, and the results show that the model proposed in this paper is better than the traditional language model in continuous and meaningful dialogue.},
  keywords={Deep learning;Training;Service robots;Big Data;Data models;Internet;Research and development;Big data;Deep learning;Intelligent chat robot},
  doi={10.1109/IICSPI51290.2020.9332367},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9812657,
  author={Ahn, Hyojung and Yu, Jeongmin and Yeom, Jong-Min},
  booktitle={2022 17th Annual System of Systems Engineering Conference (SOSE)}, 
  title={Deep Learning based Prediction of Solar Surface Irradiance with Geostationary Satellite Images}, 
  year={2022},
  volume={},
  number={},
  pages={311-315},
  abstract={Solar energy has been expanding its scope for use in various systems, such as power generation, portable power, and power for eco-friendly moving objects and space power of various sizes depending on the purpose. However, since solar energy can be affected by meteorological and environmental variables, it is difficult to predict and manage energy production. Recently, artificial intelligence techniques have been applied to optimize predictive models and improve predictive performance of renewable solar energy. In this paper, a deep neural network-based prediction model is presented to predict the amount of solar energy potentials using geostationary satellite image data in units of one hour for over 7 years. In most of the previous studies, only a short-time prediction has been possible using only the daytime information, but in this model, the prediction performance is improved by using the image information including the cloud movement during the nighttime. In order to combine images of different characteristics of solar surface irradiance (SSI) and infrared (IR) in successive time and integrate them into one predictive model, after learning the basic structure to solve the trade-off problem between localization and context in the deep neural network structure, a generative model-based learning model is connected for matching between images of the different characteristics. In addition, in order to preserve the value of the target region that occupies a relatively small portion of the image, the performance of the model is supplemented using the region of interest (RoI) mask As a result, a model with improved predictive performance is presented when predicting using both daytime and nighttime image information the previous day.},
  keywords={Deep learning;Location awareness;Computational modeling;Neural networks;Solar energy;Predictive models;Data models;solar energy system;solar energy potential prediction;deep learning;geostationary satellite image;learning model},
  doi={10.1109/SOSE55472.2022.9812657},
  ISSN={},
  month={June},}@INPROCEEDINGS{10771069,
  author={Kaniewski, Sabrina and Holstein, Dieter and Schmidt, Fabian and Heer, Tobias},
  booktitle={2024 Conference on AI, Science, Engineering, and Technology (AIxSET)}, 
  title={Vulnerability Handling of AI-Generated Code - Existing Solutions and Open Challenges}, 
  year={2024},
  volume={},
  number={},
  pages={145-148},
  abstract={The increasing use of generative Artificial Intelligence (AI) in modern software engineering, particularly Large Language Models (LLMs) for code generation, has transformed professional software development by boosting productivity and automating development processes. This adoption, however, has highlighted a significant issue: the introduction of security vulnerabilities into the code. These vulnerabilities result, e.g., from flaws in the training data that propagate into the generated code, creating challenges in tackling them in established ways. Traditional vulnerability handling processes often involve extensive manual review. Applying such traditional processes to AI-generated code is challenging. AI-generated code may include several similar vulnerabilities, possibly in slightly different forms as developers might not build on already implemented code, using functions or libraries, but prompt similar tasks. In this work, we explore the current state of LLM-based approaches for vulnerability handling, focusing on approaches for vulnerability detection, localization, and repair. We provide an overview of recent progress in this area and highlight open challenges that must be addressed to establish a reliable and scalable vulnerability handling process for AI-generated code.},
  keywords={Productivity;Codes;Reviews;Prevention and mitigation;Training data;Manuals;Software reliability;Security;Software engineering;Software development management;Vulnerability Handling;Software Engineering;Large Language Models;Retrieval-Augmented Generation},
  doi={10.1109/AIxSET62544.2024.00026},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10668567,
  author={Yang, Zhonghua and Luo, Wenbo and Sun, Yu and Shi, Xianyu and Yan, Kuixi and Li, Lanqing and Wan, Lixi and Zhang, Wanli},
  booktitle={2024 25th International Conference on Electronic Packaging Technology (ICEPT)}, 
  title={Temperature Gradient Control and Packaging Technologies for Co-Packaged Optics}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={As the demand for computing power driven by generative artificial intelligence continues to increase, the need for data transfer and communication between different components of AI systems is also constantly rising. However, the traditional electrical I/O combined with pluggable optical modules fail to meet the application demands in terms of bandwidth, cost, and power consumption. Co-packaged optics (CPO) is widely regarded as a key solution and development trend for future data center optical interconnects. By integrating Photonic integrated circuits (PICs) and electronic integrated circuits (EIC) on a shared substrate, the CPO solution provides shorter electrical interconnection length, higher bandwidth and energy efficiency. The main challenge in CPO is the susceptibility of optical chips to high temperatures, leading to thermal fragility. Optical chips commonly feature fiber pigtail fixed with UV adhesive and DFB lasers employing flip-chip configuration, both vulnerable to high-temperature packaging processes. The packaging temperature is usually required to be below 100¬∞C, which is incompatible with high-temperature processes such as reflow soldering used for electronic chips packaging. In this work, we propose an low temperature Co-packaged technique. The Application-Specific Integrated Circuit (ASIC) chips and optical engine were packaged on a substrate, achieving a PAM-4 transmission of $4\times 50\ \text{Gbps}$. The measured bit error rate of the receiver is less than $2\times 10^{-4}$, when the input optical power is -13 dBm. We believe that this research provides a significant solution for researchers in the fields of optical communication and data centers, accelerating industry development.},
  keywords={Optical fibers;Integrated optics;Temperature measurement;Optical interconnections;Bandwidth;Packaging;Optical receivers;Co-packaged Optics;Optical Engine;Advanced Packaging;Optical Interconnection},
  doi={10.1109/ICEPT63120.2024.10668567},
  ISSN={2836-9734},
  month={Aug},}@INPROCEEDINGS{10620950,
  author={Dutt, Varun and Hadjigeorgiou, Demetris and Galan, Lucas and Doctor, Faiyaz and Barakat, Lina and Isaacs, Kate},
  booktitle={2024 19th Annual System of Systems Engineering Conference (SoSE)}, 
  title={Explainable Digital Creatives Performance Monitoring using Deep Feature Attribution}, 
  year={2024},
  volume={},
  number={},
  pages={134-139},
  abstract={A key challenge in marketing and advertising research is understanding when and why digital assets such as promotional content perform well during a marketing push. By leveraging raw image feature vectors extracted from large datasets, we can train performance prediction models using online social signals such as likes or views. While the resulting models make accurate predictions, they are opaque and rely on abstract features within the model, making attribution almost impossible. This paper demonstrates an approach to performance prediction modelling for image based digital creative assets. Utilising a combination of pre-trained vision model embeddings with a pipeline of generative Artificial Intelligence (AI) for image synthesis and manipulation, we establish a means of determining the performance of explainable components. This enables flexible performance prediction, even with smaller datasets, with high degree of explainability through the attribution of image features correlating with high or low performance.},
  keywords={Image synthesis;Pipelines;Predictive models;Feature extraction;Transformers;Vectors;Performance analysis;Deep Feature Extractors;Performance Analyses Attribution Pipeline;Transformers;Diffusion Models;Digital Creatives},
  doi={10.1109/SOSE62659.2024.10620950},
  ISSN={2835-3161},
  month={June},}@INPROCEEDINGS{10631380,
  author={Zuo, Haibiao and Huang, Xiaoliang and Zhang, Shiqiao and Chang, Chip-Hong and Zhao, Xiaojin},
  booktitle={2024 IEEE Symposium on VLSI Technology and Circuits (VLSI Technology and Circuits)}, 
  title={An In-Sensor PUF Featuring Optical Reconfigurability and Near-100% Hardware Reuse Ratio for Trustworthy Sensing}, 
  year={2024},
  volume={},
  number={},
  pages={1-2},
  abstract={Mainstream CMOS image sensors are in dire need of having built-in security primitive to facilitate on-chip trustworthy sensing for the attestation of the visual content integrity against photo-realistic spoofing attacks made feasible by the emerging generative artificial intelligence (AI) tools. This paper presents an optically-reconfigurable in-sensor strong physically unclonable function (PUF) leveraging both intrinsic dark signal non-uniformity (DSNU) and photo response non-uniformity (PRNU) of photo sensing pixels as entropy sources. The fabricated $128\times 128$ in-sensor PUF chip features 99.735% hardware reuse ratio, $\sim 1\times 10^{36}\text{bit}/\mathrm{F}^{2}$ area efficiency, $\approx 2.77\times 10^{42}$ challenge-response pairs (CRP) and high resistance against several well-known machine-learning attacks.},
  keywords={Resistance;Visualization;Optical device fabrication;Very large scale integration;Optical imaging;Physical unclonable function;Hardware},
  doi={10.1109/VLSITechnologyandCir46783.2024.10631380},
  ISSN={2158-9682},
  month={June},}@INPROCEEDINGS{10912039,
  author={Elbatanouny, Hagar and Kleanthous, Natasa and Salah, Suhaib and Mahmoud, Soliman and Hussain, Abir},
  booktitle={2024 17th International Conference on Development in eSystem Engineering (DeSE)}, 
  title={Enhancing Freezing of Gait Prediction in Parkinson‚Äôs Disease Using Machine Learning and Explainable AI}, 
  year={2024},
  volume={},
  number={},
  pages={236-241},
  abstract={Parkinson‚Äôs disease (PD) is a progressive neurode-generative disorder that affects millions of individuals worldwide, significantly impairing their quality of life through motor symptoms such as tremors, rigidity, and particularly, Freezing of Gait (FOG). FOG is characterized by transient episodes where patients temporarily lose the ability to initiate or continue walking, posing risks of falls, loss of independence, and psychological distress. This study leverages advancements in machine learning (ML) and explainable artificial intelligence (XAI) to develop and validate a predictive model for FOG. Using a publicly available dataset and employing various ML techniques, the study evaluates the performance of these models in terms of accuracy, precision, recall, and F1-score. Incorporating XAI methods enhances the interpretability of the model, making its predictions more transparent. The results indicate that a 5-second window size with a 5-second pre-FOG period and a Random Forest classifier achieved the highest performance, with an accuracy of $\mathbf{9 9. 3 4 \%}$. Interpretability analyses, including permutation importance and Partial Dependence Plots (PDP), highlight the key features influencing predictions, such as peak frequencies and statistical measures. Future work will focus on model generalizability, exploring additional datasets to improve predictive accuracy and clinical applicability.},
  keywords={Accuracy;Explainable AI;Psychology;Predictive models;Motors;Frequency measurement;Rigidity;Transient analysis;Random forests;Diseases;Freezing of Gait;Parkinson‚Äôs Disease;Machine Learning;Explainable AI;Interpretability},
  doi={10.1109/DeSE63988.2024.10912039},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10306609,
  author={Bharati, Alokam Ujwala and Bhargavi, Motamarri and Harshith, K.V.N.D. Sai and Reddy K, Srinivasa},
  booktitle={2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={A Comparative Sentiment Analysis on ChatGPT Reviews using Machine Learning Models}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Sentiment analysis is a field within natural language processing that seeks to recognize and extract personal and emotional data from textual information, including feelings, viewpoints, and attitudes. Reviews have now turned into an indispensable data source for both consumers and businesses. Analyzing the sentiment of such reviews can offer valuable ideas into customers' likes, contentment, and discontentment. In recent times, Chat Generative Pre-trained Transformer (ChatGPT) has paved new paths in the area of Artificial Intelligence and Natural Language Processing. In our work, sentiment of people is analyzed through reviews taken from people of various age groups from different educational backgrounds to understand the efficiency of ChatGPT. A comparative analysis was carried out by using four different machine learning models and two hybrid models using SVM + Decision Tree and Random Forest + Logistic Regression. The survey also analyzed various effects of using ChatGPT and how it contributes in making people lethargic and decreases logical thinking ability and problem-solving skills.},
  keywords={Support vector machines;Surveys;Analytical models;Sentiment analysis;Computational modeling;Soft sensors;Chatbots;Random Forest;Support Vector Machine;Decision Tree;Logistic Regression;Hybrid model},
  doi={10.1109/ICCCNT56998.2023.10306609},
  ISSN={2473-7674},
  month={July},}@INPROCEEDINGS{11091983,
  author={Zhan, Yuchan and Guo, Jingao and Yuan, Fang},
  booktitle={2025 7th International Conference on Computer Science and Technologies in Education (CSTE)}, 
  title={A Comparative Study of the Efficacy of LLMs in Generating Learning Resources for Non-English Major Postgraduates}, 
  year={2025},
  volume={},
  number={},
  pages={838-842},
  abstract={This study examines the efficacy of prominent large language models, ERNIE Bot and ChatGPT, both domestically and internationally, in producing pertinent language learning materials. The research studied variations in the outcomes of two large language models in assisting non-English major postgraduate students at a university in generating supplementary learning resources. The materials produced by ERNIE Bot and ChatGPT were assessed across four dimensions: vocabulary, translation, reading, writing with evaluations solicited from students and educators. By analyzing the discrepancies in the outputs of the two large language models in producing educational resources, valuable insights were garnered regarding their inherent strengths and weaknesses. An examination of the underlying factors contributing to these differences was conducted, with the ultimate goal of augmenting the generative competencies of large language models, offering more varied developmental pathways for the application of artificial intelligence in education.},
  keywords={Computer science;Vocabulary;Translation;Large language models;Education;Training data;Chatbots;Grammar;LLMs;ChatGPT;ERNIE Bot;EFL;higher education},
  doi={10.1109/CSTE64638.2025.11091983},
  ISSN={},
  month={April},}@INPROCEEDINGS{10392933,
  author={Lee, SooHyung and Lee, HyeRin and Lee, KiSuk},
  booktitle={2023 14th International Conference on Information and Communication Technology Convergence (ICTC)}, 
  title={Knowledge Generation Pipeline using LLM for Building 3D Object Knowledge Base}, 
  year={2023},
  volume={},
  number={},
  pages={1303-1305},
  abstract={With the wide spread of XR(eXtended Reality) contents such as Metaverse and VR(Virtual Reality) / AR(Augmented Reality), the utilization and importance of 3D objects are increasing. In this paper, we describe a knowledge generation pipeline of 3D object for reuse of existing 3D objects and production of new 3D object using generative AI(Artificial Intelligence). 3D object knowledge includes not only the object itself data that are generated in object editing phase but the information for human to recognize and understand objects. The target 3D model for building knowledge is the space model of office for business Metaverse service and the model of objects composing the space. LLM(Large Language Model)-based multimodal AI was used to extract knowledge from 3D model in a systematic and automated way. We plan to expand the pipeline to utilize knowledge base for managing extracted knowledge and correcting errors occurred during the LLM process for the knowledge extraction.},
  keywords={Solid modeling;Three-dimensional displays;Systematics;Metaverse;Pipelines;Knowledge based systems;Production;XR;Metaverse;3D Object;Knowledge Base;MultiModal AI},
  doi={10.1109/ICTC58733.2023.10392933},
  ISSN={2162-1241},
  month={Oct},}@INPROCEEDINGS{10605321,
  author={Rios, Thiago and Lanfermann, Felix and Menzel, Stefan},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Large Language Model-assisted Surrogate Modelling for Engineering Optimization}, 
  year={2024},
  volume={},
  number={},
  pages={796-803},
  abstract={Engineers often utilize data-driven surrogate models in optimization to partially replace the costly computational simulations of physics-based models. However, different aspects affect the accuracy and prediction capability of the surrogate models, e.g., the dimensionality of the data and nonlinearities in the mapping between input and output. Learning well-performing models by selecting appropriate techniques to fit the data benefits from the machine learning and data science expertise of the engineer which may vary depending on the application domain. Recently, large language models (LLMs) have shown promising capabilities to support humans through natural language-based interfaces in approaching technical problems, as well as to co-develop software and to democratize domain knowledge. In this paper, we utilize ChatGPT 4 to co-develop a framework to select and train surrogate models for engineering optimization tasks. More specifically, we interact with ChatGPT to outline a process and software to support the selection and application of regression techniques based on characteristics of the available data and target application. We evaluate the developed methodology on synthetic and realistic engineering optimization data and problems. In our experiments, we demonstrate that the models obtained through the methodology developed with ChatGPT achieve comparable performance in regression and optimization tasks than observed in existing works in the literature. Hence, despite some limitations, such as missing updates of available software libraries, LLMs can support less experienced engineers to solve surrogate-assisted optimization problems more efficiently by providing insights on the application data and software for deploying surrogate models.},
  keywords={Software libraries;Computational modeling;Large language models;Machine learning;Predictive models;Chatbots;Software;Large language models;surrogate modeling;design optimization;generative AI;democratization},
  doi={10.1109/CAI59869.2024.00151},
  ISSN={},
  month={June},}@INPROCEEDINGS{9004231,
  author={Raghavan, Pradheepan and Gayar, Neamat El},
  booktitle={2019 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE)}, 
  title={Fraud Detection using Machine Learning and Deep Learning}, 
  year={2019},
  volume={},
  number={},
  pages={334-339},
  abstract={Frauds are known to be dynamic and have no patterns, hence they are not easy to identify. Fraudsters use recent technological advancements to their advantage. They somehow bypass security checks, leading to the loss of millions of dollars. Analyzing and detecting unusual activities using data mining techniques is one way of tracing fraudulent transactions. transactions. This paper aims to benchmark multiple machine learning methods such as k-nearest neighbor (KNN), random forest and support vector machines (SVM), while the deep learning methods such as autoencoders, convolutional neural networks (CNN), restricted boltzmann machine (RBM) and deep belief networks (DBN). The datasets which will be used are the European (EU) Australian and German dataset. The Area Under the ROC Curve (AUC), Matthews Correlation Coefficient (MCC) and Cost of failure are the 3-evaluation metrics that would be used.},
  keywords={Machine learning;Forestry;Support vector machines;Credit cards;Data models;Artificial neural networks;Europe;credit card;fraud detection;machine learning;deep learning;random forest;k nearest neighbor;support vector machine;autoencoder;restricted boltzmann machine;deep belief networks;convolutional neural networks},
  doi={10.1109/ICCIKE47802.2019.9004231},
  ISSN={},
  month={Dec},}@ARTICLE{10496892,
  author={Guan, Lei and Li, Dongsheng and Shi, Yanqi and Meng, Jian},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={XGrad: Boosting Gradient-Based Optimizers With Weight Prediction}, 
  year={2024},
  volume={46},
  number={10},
  pages={6731-6747},
  abstract={In this paper, we propose a general deep learning training framework XGrad which introduces weight prediction into the popular gradient-based optimizers to boost their convergence and generalization when training the deep neural network (DNN) models. In particular, ahead of each mini-batch training, the future weights are predicted according to the update rule of the used optimizer and are then applied to both the forward pass and backward propagation. In this way, during the whole training period, the optimizer always utilizes the gradients w.r.t. the future weights to update the DNN parameters, making the gradient-based optimizer achieve better convergence and generalization compared to the original optimizer without weight prediction. XGrad is rather straightforward to implement yet pretty effective in boosting the convergence of gradient-based optimizers and the accuracy of DNN models. Empirical results concerning five popular optimizers including SGD with momentum, Adam, AdamW, AdaBelief, and AdaM3 demonstrate the effectiveness of our proposal. The experimental results validate that XGrad can attain higher model accuracy than the baseline optimizers when training the DNN models.},
  keywords={Training;Artificial neural networks;Convergence;Computational modeling;Backpropagation;Proposals;Predictive models;Convergence;deep learning;generalization;gradient-based;optimizer;weight prediction},
  doi={10.1109/TPAMI.2024.3387399},
  ISSN={1939-3539},
  month={Oct},}@INPROCEEDINGS{9418718,
  author={Ravula, Sriram and Jain, Swayambhoo},
  booktitle={2021 Data Compression Conference (DCC)}, 
  title={A Comparison of Classical and Deep Learning-based Techniques for Compressing Signals in a Union of Subspaces}, 
  year={2021},
  volume={},
  number={},
  pages={363-363},
  abstract={Many natural signals lie in a union of subspaces, which we can exploit when compressing these signals to maintain a high level of fidelity while significantly reducing the storage size. Standard compression techniques for natural signals such as images follow a general pipeline which uses predetermined transformations to encode and decode data. Recent advances in deep learning-based techniques for compressing image data have shown results which compete with existing compression standards. Inspired by the success of these deep learning methods, we evaluate various classical and deep learning-based methods for encoding and decoding signals which follow a union-of-subspaces structure. On the classical side, we evaluate compressed sensing with a learned dictionary, whereas for deep learning-based techniques, we consider an autoencoder and a deep generative model-based variant of compressed sensing. Our results suggest that while classical compressed sensing-based methods work well, deep learning-based techniques perform better as the union-of-subspaces signal structure becomes more complex.},
  keywords={Learning systems;Deep learning;Image coding;Dictionaries;Pipelines;Encoding;Sensors;Compression;Compressed Sensing;Autoencoder;Dictionary Learning;Deep Generative Model},
  doi={10.1109/DCC50243.2021.00076},
  ISSN={2375-0359},
  month={March},}@INPROCEEDINGS{10457124,
  author={Park, Chanyeong and Lee, Seongjun and Choi, Hankyul and Kim, Donghyun and Jeong, Yunyoung and Paik, Joonki},
  booktitle={2024 International Conference on Electronics, Information, and Communication (ICEIC)}, 
  title={Enhancing Defense Surveillance: Few-Shot Object Detection with Synthetically Generated Military Data}, 
  year={2024},
  volume={},
  number={},
  pages={1-2},
  abstract={Acquiring military-related data to train object detection algorithms for defense surveillance can be highly challenging due to security restrictions. To overcome this challenge, we utilize a few-shot object detection approach that can identify objects using a limited number of examples, deviating from the standard object detection methods that typically require large datasets for training. To compensate for the limited availability of military data, we employ generative models to create synthetic military datasets. This artificially generated data is then used as a support set to train the few-shot object detection network. We assess our method using a self-created dataset that includes four categories: soldiers, tanks, helicopters, and fighter planes.},
  keywords={Training;Surveillance;Helicopters;Object detection;Military aircraft;Data models;Security;Few-shot Object Detection;Generative Model;Defence Surveillance},
  doi={10.1109/ICEIC61013.2024.10457124},
  ISSN={2767-7699},
  month={Jan},}@ARTICLE{9829023,
  author={Sun, Shilin and Wang, Tianyang and Yang, Hongxing and Chu, Fulei},
  journal={IEEE Transactions on Industrial Electronics}, 
  title={Adversarial Representation Learning for Intelligent Condition Monitoring of Complex Machinery}, 
  year={2023},
  volume={70},
  number={5},
  pages={5255-5265},
  abstract={Condition monitoring (CM) of machinery is important for ensuring the reliability of industrial processes. To adapt to the rareness of data from faulted machinery, semisupervised CM can be implemented by training on only healthy samples. However, the performance of CM can be impaired by the variability of operating data acquired from complex machinery. Additionally, the accuracy of results is limited by the impractical assumption that samples under different health conditions are naturally separable. To address these problems, an adversarial representation learning method is developed herein. The method is trained by reconstructing operating data in both signal and latent spaces, and adversarial evolution is adopted to avoid the convergence at local optima. In this case, data representations of health conditions can be obtained to suppress the volatility of measurements, and redundant information can be reduced by latent codes. Moreover, a strategy of representation embedding is developed to impose constraints on unhealthy data, guaranteeing separable samples under distinct health conditions in the monitoring stage. Furthermore, feature fusion is conducted to avoid missing detailed information on health conditions. The satisfactory performance of the proposed method is demonstrated by experiments in test benches and actual scenarios of wind power generation.},
  keywords={Machinery;Training;Codes;Monitoring;Data models;Representation learning;Signal reconstruction;Artificial intelligence (AI);condition monitoring (CM);deep learning;representation learning},
  doi={10.1109/TIE.2022.3189085},
  ISSN={1557-9948},
  month={May},}@ARTICLE{9293268,
  author={Arias-Londo√±o, Juli√°n D. and G√≥mez-Garc√≠a, Jorge A. and Moro-Vel√°zquez, Laureano and Godino-Llorente, Juan I.},
  journal={IEEE Access}, 
  title={Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19. A Thoughtful Evaluation Approach}, 
  year={2020},
  volume={8},
  number={},
  pages={226811-226827},
  abstract={Current standard protocols used in the clinic for diagnosing COVID-19 include molecular or antigen tests, generally complemented by a plain chest X-Ray. The combined analysis aims to reduce the significant number of false negatives of these tests and provide complementary evidence about the presence and severity of the disease. However, the procedure is not free of errors, and the interpretation of the chest X-Ray is only restricted to radiologists due to its complexity. With the long term goal to provide new evidence for the diagnosis, this paper presents an evaluation of different methods based on a deep neural network. These are the first steps to develop an automatic COVID-19 diagnosis tool using chest X-Ray images to differentiate between controls, pneumonia, or COVID-19 groups. The paper describes the process followed to train a Convolutional Neural Network with a dataset of more than 79, 500 X-Ray images compiled from different sources, including more than 8, 500 COVID-19 examples. Three different experiments following three preprocessing schemes are carried out to evaluate and compare the developed models. The aim is to evaluate how preprocessing the data affects the results and improves its explainability. Likewise, a critical analysis of different variability issues that might compromise the system and its effects is performed. With the employed methodology, a 91.5% classification accuracy is obtained, with an 87.4% average recall for the worst but most explainable experiment, which requires a previous automatic segmentation of the lung region.},
  keywords={COVID-19;Diseases;Lung;X-ray imaging;Deep learning;Computed tomography;Sensitivity;COVID-19;deep learning;pneumonia;radiological imaging;chest X-ray},
  doi={10.1109/ACCESS.2020.3044858},
  ISSN={2169-3536},
  month={},}@ARTICLE{10466766,
  author={Younesi, Abolfazl and Ansari, Mohsen and Fazli, Mohammadamin and Ejlali, Alireza and Shafique, Muhammad and Henkel, J√∂rg},
  journal={IEEE Access}, 
  title={A Comprehensive Survey of Convolutions in Deep Learning: Applications, Challenges, and Future Trends}, 
  year={2024},
  volume={12},
  number={},
  pages={41180-41218},
  abstract={In today‚Äôs digital age, Convolutional Neural Networks (CNNs), a subset of Deep Learning (DL), are widely used for various computer vision tasks such as image classification, object detection, and image segmentation. There are numerous types of CNNs designed to meet specific needs and requirements, including 1D, 2D, and 3D CNNs, as well as dilated, grouped, attention, depthwise convolutions, and NAS, among others. Each type of CNN has its unique structure and characteristics, making it suitable for specific tasks. It‚Äôs crucial to gain a thorough understanding and perform a comparative analysis of these different CNN types to understand their strengths and weaknesses. Furthermore, studying the performance, limitations, and practical applications of each type of CNN can aid in the development of new and improved architectures in the future. We also dive into the platforms and frameworks that researchers utilize for their research or development from various perspectives. Additionally, we explore the main research fields of CNN like 6D vision, generative models, and meta-learning. This survey paper provides a comprehensive examination and comparison of various CNN architectures, highlighting their architectural differences and emphasizing their respective advantages, disadvantages, applications, challenges, and future trends.},
  keywords={Deep learning;Convolutional neural networks;Machine learning;Computer vision;Generative adversarial networks;Classification algorithms;Object detection;Image segmentation;Task analysis;Performance evaluation;Deep learning;DNN;CNN;machine learning;vision transformers;GAN;attention;computer vision;LLM;large language model;transformer;dilated convolution;depthwise,NAS,NAT;object detection;6D vision;vision language model},
  doi={10.1109/ACCESS.2024.3376441},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9791025,
  author={Yoshihara, Kyohei and Hirata, Kouichi},
  booktitle={2021 10th International Congress on Advanced Applied Informatics (IIAI-AAI)}, 
  title={Detecting Campylobacter Bacteria and Phagocytotic Activity of Leukocytes from Gram Stained Smears Images}, 
  year={2021},
  volume={},
  number={},
  pages={10-15},
  abstract={In this paper, we develop the method to detect Campylobacter bacteria and phagocytotic activity of leukocytes from Gram stained smears images. First, we improve VGG16 by adding batch normalization and by replacing flatten with global average pooling and construct the classifier by using transfer learning model based on the improved VGG16. Then, by comparing the detection by the VGG16 with that by the improved VGG16, for the classification of Camphylobacter bacteria, we give experimental results of classifying Campylobacter images with non-Campylobacter images. On the other hand, for the classification of phagocytotic activity of leukocytes, we give experimental results of classifying phagocytotic images with quasi- and non-phagocytotic images and of classifying phagocytotic images, quasi-phagocytotic images and non-phagocytotic images.},
  keywords={Deep learning;Microorganisms;Image color analysis;Transfer learning;Brightness;Training data;Generative adversarial networks;Gram stained smears images;Campylobacter bacteria;phagocytotic activity of leukocytes;classification;CNN;transfer learning;VGG16},
  doi={10.1109/IIAI-AAI53430.2021.00002},
  ISSN={2770-8470},
  month={July},}@INPROCEEDINGS{9695860,
  author={Zhang, Rui and Zhang, Lei and Yu, Tianqi and Huang, Jipeng and Yu, Yan},
  booktitle={2021 3rd International Academic Exchange Conference on Science and Technology Innovation (IAECST)}, 
  title={Feature Fusion CNN-LSTM Network Based Gait Recognition On Covariate Of Clothing And Bag}, 
  year={2021},
  volume={},
  number={},
  pages={304-307},
  abstract={Gait, a ubiquitous but distinctive depiction of how people walk, has received growing attention due to it can gather individual characteristics in a noninteractive way without subject cooperation, particularly when encountering video resolution loss from a long distance. Inspired by the fact that there will be sufficient potential underneath the industry application and scientific research of gait in various fields, the issue of accuracy reduction with variations in bag and clothing is supposed to be addressed. Therefore, we construct a reformative convolutional neural network. The fusion backward and the complementarity of temporal and spatial characteristics maintain more information and reach better performance under experimental evaluations. The state-of-the-art results were achieved on the CASIA-B dataset, demonstrating the applicability and efficiency of our proposed method, with the accuracy of 93.89% and 87.67% under covariate alteration of clothing and bag, respectively.},
  keywords={Technological innovation;Image recognition;Clothing;Industry applications;Network architecture;Transformers;Generative adversarial networks;gait recognition;LSTM;ResNet;gait energy image},
  doi={10.1109/IAECST54258.2021.9695860},
  ISSN={},
  month={Dec},}@ARTICLE{9789124,
  author={Chung, Yi-Hao and Chen, Yen-Lin},
  journal={IEEE Access}, 
  title={Three-Dimensional Image Inpainting System Using 3D-ED-GAN for Efficient Vision-Based Detection for Rotor Dynamic Balance System}, 
  year={2022},
  volume={10},
  number={},
  pages={60025-60038},
  abstract={We propose a three-dimensional (3D) image inpainting system using the 3D encoder‚Äìdecoder generative adversarial network (IISU3EDGAN) for providing accurate detection results in vision-based rotor dynamic balancing processes. The proposed IISU3EDGAN system integrates 3D sensors with a deep learning network to reconstruct corrupted rotor images, thereby optimizing the detection parameters. In rotor component detection processes, overexposed images caused by reflections of the metallic rotor shaft affect the accuracy and performance of vision-based inspection systems. Traditional image restoration technologies or inpainting methods are inadequate for solving this problem. By contrast, our proposed system can repair 3D overexposed images of rotors. Compared with traditional image processing methods, the proposed system can adequately manage the complexity of corrupted images. In addition, it can be used to process complex overexposed rotor images and maintain image details. The proposed system can be applied to a wider range of rotor types, and it can be used to optimize the parameters of vision-based rotor detection systems to improve the accuracy of rotor component detection. We conducted experiments and observed that by using 3D sensors and deep learning, the proposed system improved the success rate in the first round of rotor dynamic balancing, reduced the number of rounds required for balancing, and increased the rotor production output. These results thus indicate that the IISU3EDGAN system is applicable and robust and that it can be used to improve the overall efficiency of dynamic balancing on rotor production lines.},
  keywords={Rotors;Three-dimensional displays;Generative adversarial networks;Sensors;Vibrations;Generators;Deep learning;Dynamic balancing;3D sensor;GAN;image inpainting;manufacturing automation;rotor},
  doi={10.1109/ACCESS.2022.3180339},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10956296,
  author={Rachmat, Hary and Riza, Hammam and Abidin, Taufik Fuadi},
  booktitle={2024 Ninth International Conference on Informatics and Computing (ICIC)}, 
  title={Fine-Tuning Large Language Model (LLM) to Answer Basic Questions for Prospective New Students at Syiah Kuala University Using the Retrieval-Augmented Generation (RAG) Method}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={USK Mistral 7B is a large language model designed to answer basic admission questions at Universitas Syiah Kuala (USK). The model was fine-tuned using the open-source model of Mistral 7B using collected data from admissions and lectures at the university. The QLoRA and RAG techniques were used to train the model and retrieve relevant information from external data sources. The results were evaluated using the ROUGE score. Responses were generated with a score of >0.5 on ten out of 46 questions with the RAG method, and testing with the fine-tuning method was carried out on 20 questions and resulted in responses with a score of 1.0 from all questions asked. The performance of USK Mistral 7B shows its potential as an effective tool in helping students querying information about admission and lectures at USK.},
  keywords={Training;Measurement;Generative AI;Computational modeling;Large language models;Soft sensors;Retrieval augmented generation;Data models;Informatics;Testing;Large Language Model;Fine-tuning;RAG},
  doi={10.1109/ICIC64337.2024.10956296},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10827919,
  author={Jin, Rujia},
  booktitle={2024 IEEE 6th International Conference on Civil Aviation Safety and Information Technology (ICCASIT)}, 
  title={The impacts of artificial intelligence techniques in augmentation of cyber security}, 
  year={2024},
  volume={},
  number={},
  pages={318-327},
  abstract={In order to optimise deep learning models for few-shot website fingerprinting (WF) attacks, this study offers a fresh way to data augmentation technique. For each website, only a few training samples are provided. More sophisticated Deep learning approaches demonstrate the ability to automatically learn representations of features from training data is preferable to earlier WF approaches that relied on manually-engineered feature representations. However, this benefit is dependent on the implausible premise that each website has a large number of training samples; in the absence of such assumptions, the benefit will vanish. In order to tackle this issue, we present a novel approach called Compatible information Augmentation (CIA), which is efficient, model-agnostic, and can greatly enhance deep WF attacking techniques. CIA entails data transformations both within and between samples, which can be employed in a harmonious manner to expand a small training dataset into a large collection of arbitrarily large numbers, thereby successfully and clearly addressed the issue of inherent data scarcity. Extensive experiments were carried out to validate our CIA for enhancing cutting-edge deep learning WF attack models in scenarios of both open-world and closed-world attacks, with a strong defence or not. For example, our CIA approach achieves over 4% higher completeness of classification in the 20-shot learning scenario than the prior state-of-the-art results in the WTF-PAD based defence evaluation scenario, which is more difficult and realistic.},
  keywords={Training;Training data;Optimization methods;Manuals;Fingerprint recognition;Data augmentation;Data models;Safety;Information technology;Few shot learning;Compatible information Augmentation;Deep learning;Few-shot learning;Website fingerprinting},
  doi={10.1109/ICCASIT62299.2024.10827919},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10703854,
  author={Kim, Hannah and Lee, Hyun and Pang, Sunyu and Oh, Uran},
  booktitle={2024 IEEE International Conference on Information Reuse and Integration for Data Science (IRI)}, 
  title={Prompirit: Automatic Prompt Engineering Assistance for Improving AI-Generated Art Reflecting User Emotion}, 
  year={2024},
  volume={},
  number={},
  pages={138-143},
  abstract={Recently, text-to-image generative Artificial Intelligence (AI) models have demonstrated their ability to generate high-quality art with text prompts. However, generative AI is still incapable of creating images that precisely reflect emotion. We propose Prompirit, an automatic prompt engineering assistance for improving AI-generated art in terms of expressiveness of emotion and aesthetics. We explored various approaches to refine users‚Äô free-form text input by incorporating user emotion and style modifiers. Statistical analysis and user evaluation with 100 respondents showed that Prompirit significantly improved the alignment of image-emotion and the aesthetics of the generated image while precisely conveying the content of the original input text. Based on the results, we provide implications for creating affective images.},
  keywords={Bridges;Visualization;Art;Statistical analysis;Text to image;Data science;Rough surfaces;Prompt engineering;Prompt Engineering;Text-to-Image Generative AI;Emotional and Art Technology},
  doi={10.1109/IRI62200.2024.00038},
  ISSN={2835-5776},
  month={Aug},}@INPROCEEDINGS{11155563,
  author={He, Jun and Zheng, Jie},
  booktitle={2025 IEEE Gaming, Entertainment, and Media Conference (GEM)}, 
  title={Dynamic QTE Generation with DeepSeek: Towards AI-Enhanced Adaptive Gameplay}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper presents an AI-driven framework for dynamic Quick Time Event (QTE) generation that adapts to real-time player behavior. Our hybrid architecture combines LSTM networks for 300ms-ahead action prediction (89.2% accuracy) with a dual-constraint GAN for event synthesis, achieving 92.4% narrative coherence. Experimental results with 120 participants demonstrate 23.6% improvement in immersion scores (p=0.017) and 17.2% higher success rates compared to static QTEs, while maintaining real-time performance (14.7ms/frame latency) on consumer GPUs. The system reduces development costs by 15-20% through automated variation generation, addressing critical challenges in adaptive content creation.},
  keywords={Ethics;Adaptive systems;Costs;Accuracy;Tiny machine learning;Entertainment industry;Coherence;Generative adversarial networks;Real-time systems;Long short term memory;Quick Time Events;AI-generated content;Adaptive gameplay;DeepSeek;Real-time systems},
  doi={10.1109/GEM66882.2025.11155563},
  ISSN={2766-6530},
  month={July},}@INPROCEEDINGS{11016293,
  author={Galatro, Daniela and Chakraborty, Sourojeet},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Strategies to Map Education 5.0 and Industry 5.0 in the Context of a Modernized Undergraduate Program in Chemical Engineering}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={Education 5.0 is the direct application of novel technologies to consciously create a humanized, holistic teaching experience, to directly target the requirements of Industry 5.0. This work describes the design and implementation of a set of pedagogical strategies systematically employed to comprehensively map Education 5.0 and Industry 5.0, within the context of modernization of the undergraduate Chemical Engineering & Applied Chemistry program, clustered by (i) core courses such as Heat & Mass Transfer, (ii) electives such as Petroleum Processing, and (iii) 500level (undergraduate/graduate) advanced courses, such as Data Based Modelling for Prediction and Control. Implementation strategies include consciously integrating sustainability and engineering safety practices for chemical process design, using Generative Artificial Intelligence (Generative AI) in class to augment student self-learning, data-driven causation and machine learning versus first-principle-based phenomena analysis by employing dynamic process simulation and computational fluid dynamics tools, industry standards, codes and recommended practices, to instill active learning among students, and circularity indicators for process design and description. Examples of active learning initiatives embedded within our strategies include (i) the Petroleum Processing Lab, where students combine chatbots use and Machine Learning (ML) and/or simulation tools to analyze oil price market trends, mass balances crude distillation units, and risk assessments in oil refineries; and (ii) the Heat and Mass Transfer Lab, where students combine data analysis, machine learning and first-principles to describe and analyze heat convection relationships during the lectures. Chatbots assisted activities are qualitatively assessed for accuracy via a novel APC-EPE approach (Assumptions, Process description, and Calculations, with Effective Prompt Engineering); and we have successfully employed the APC-EPE framework to enhance the chances of chatbots providing accurate and reliable results aligned with students' expectations. Vertical integration of such strategies, right from sophomore to final years of our undergraduate program is implemented in tandem with standalone 'practices' in courses; and dedicated process design / capstone courses which combine several of these practices are offered. Our strategies are currently being assessed via anonymized student surveys, thereby attesting towards their effectiveness and high receptivity, as the department gradually transitions to a more modernized curriculum in upcoming years. Student and faculty feedback is identified as critical towards iteratively improving the course/curriculum design process in future, to ensure that the department's teaching approach towards realizing Education 5.0 is perceived as valuable to Industry 5.0 requirements and demands that employers seek from undergraduates. Our efforts are thus impactful towards creating future generations of the industry workforce trained in Education 5.0 to match Industry 5.0's requirements.},
  keywords={Process design;Industries;Accuracy;Computational fluid dynamics;Chemical engineering;Active learning;Machine learning;Chatbots;Fifth Industrial Revolution;Petroleum;Mapping Education 5.0 and Industry 5.0;curriculum modernization;Generative AI;simulation},
  doi={10.1109/EDUCON62633.2025.11016293},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11124106,
  author={Coronel, Hern√°n and Juela, Kevin and Saquicela, Victor and Aubet, Natalie and Lupercio, Luc√≠a},
  booktitle={2025 28th International Conference on Information Fusion (FUSION)}, 
  title={Artificial Intelligence to the Rescue of the Ecuadorian Amazon: Monitoring Changes with Deep Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Despite the importance of the Amazon region due to its biodiversity, ecosystem services and its enormous contribution to reduce global warming, this region is currently facing critical threats and challenges such as deforestation, urban and agricultural expansion, massive forest fires, illegal/non-regulated mining, among others. Given its vast extension, timely monitoring aimed to mitigate these problems represents a complex task. The lack of adequate tools has hindered environmental monitoring and management in this region, highlighting the need to develop advanced techniques to address these issues. This study focuses on the implementation of methods to detect and classify land cover changes, using an portion of the Ecuadorian Amazon as a case study. Our proposed method combines spectral vegetation indices generated from Sentinel-2 satellite image and deep learning techniques. Multitemporal images have been collected and preprocessed, applying the Bitemporal Adapter Network (BAN) for change detection and ResNet152V2 for land cover classification. The BAN is then re-trained with a specific dataset for the Ecuadorian Amazon. Results attain a good level of accuracy (99.36 unchanged and 89.6 changed) showing that these techniques are effective not only for detecting changes, but also for classifying affected land cover types. These findings provide valuable information for the implementation of conservation and management policies in the Ecuadorian Amazon.},
  keywords={Deep learning;Deforestation;Normalized difference vegetation index;Ecosystems;Land surface;Vegetation mapping;Global warming;Satellite images;Environmental monitoring;Environmental management;Deep learning;change detection;NDVI;Sentinel-2},
  doi={10.23919/FUSION65864.2025.11124106},
  ISSN={},
  month={July},}@INPROCEEDINGS{11156623,
  author={Yang, Chen and Chang, Rong},
  booktitle={2025 International Conference on Asian Language Processing (IALP)}, 
  title={A Multimodal Framework Bridging Classical Thought and Artificial Intelligence for the Digital Preservation and Cross-Cultural Dissemination of the Tao Te Ching}, 
  year={2025},
  volume={},
  number={},
  pages={7-12},
  abstract={This study presents a comprehensive, multimodal approach to exploring and disseminating the Tao Te Ching, a foundational text of classical Chinese philosophy. Recognizing the global significance of this work and the limitations of existing translation and speech synthesis tools, we constructed a high-quality trilingual corpus comprising the original Ancient Chinese text, modern Chinese annotations, and authoritative English translations. This corpus served as the basis for generating both synthetic and real human voice datasets using Neural Text-to-Speech technologies and professional voice recordings, respectively. We systematically introduced regional accent diversity and applied rigorous segmentation standards to enhance the dataset's linguistic variety and processing efficiency. To evaluate the speech quality of AI-generated content, we used the Non-Intrusive Speech Quality Assessment (NISQA) framework and the OpenAI Whisper model, respectively. The results showed that both standard and non-standard accented speech were highly natural and intelligible, but we encountered greater difficulties when processing artificially recorded speech. The findings demonstrate the effectiveness of combining large language models with curated textual and speech resources for advancing cross-cultural communication, preserving classical knowledge, and fine-tuning AI systems for multimodal tasks such as semantic modeling and speech synthesis. This research not only bridges ancient wisdom with modern AI technology but also establishes a replicable framework for digital humanities studies in multilingual and multicultural contexts.},
  keywords={Translation;Philosophical considerations;Annotations;Large language models;Semantics;Text to speech;Recording;Multilingual;Cultural differences;Standards;Tao Te Ching;Multimodal Corpus;Neural Text-to-Speech Synthesis;Cross-Temporal Language Modeling;Low-Resource Language Processing},
  doi={10.1109/IALP68296.2024.11156623},
  ISSN={2159-1970},
  month={Aug},}@ARTICLE{10879400,
  author={Zhang, Chuangchuang and He, Qiang and Li, Fuliang and Wang, Xingwei and Garg, Sahil and Shamim Hossain, M. and Han, Zhu and Yuan, Wei},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={GAI-Based Resource and QoE Aware Service Placement in Next-Generation Multi-Domain IoT Networks}, 
  year={2025},
  volume={11},
  number={2},
  pages={873-885},
  abstract={Network Function Virtualization (NFV) has recently emerged as a highly cost-effective paradigm for flexibly provisioning services in next-generation Internet of Things (IoT) networks, by introducing Service Function Chain (SFC) technology. However, the rapid expansion of network scales and increasing diversification of service requirements in recent years pose significant challenges to ensuring the Quality of Experience (QoE) of users in Next-generation Multi-domain IoT (NMIoT) networks. The effective deployment of SFCs in NMIoT networks to satisfy diversified resource demands while enhancing QoE of users is crucial. The recent breakthroughs in Generative Artificial Intelligence (GAI) technologies bring a new opportunity to deliver customized services and guarantee enhanced service quality in NMIoT networks. To tackle the challenges, in this paper, we investigate the problem of Resource and QoE aware SFC Placement (RQSP) in NMIoT networks. Firstly, we formulate the RQSP problem as a mixed integer linear programming model, taking into account resource demands and Quality of Service (QoS) constraints, aiming to minimize the service cost, which is composed of resource consumption cost, cross-domain operational cost and penalty cost for unsuccessful placement. Then, we prove that the RQSP problem is NP-hard. To solve it, we incorporate GAI technology to devise a novel Generative genetic Algorithm based heuristic SFC Placement (GAP) method. Furthermore, we devise a greedy strategy based population initialization mechanism as well as an elitist and roulette wheel joint selection strategy, to speed up algorithm convergence and reduce runtime overhead. Finally, simulation results demonstrate that compared to benchmark algorithms, the proposed GAP algorithm can achieve better performances on service acceptance ratio, service cost, server utilization and average service delay.},
  keywords={Internet of Things;Costs;Quality of experience;Heuristic algorithms;Next generation networking;Quality of service;Optimization;Delays;Performance evaluation;Genetic algorithms;SFC placement;NFV;NMIoT network;generative genetic algorithm},
  doi={10.1109/TCCN.2025.3540256},
  ISSN={2332-7731},
  month={April},}@INPROCEEDINGS{11044587,
  author={Huang, Kang and Qiu, Chao and Hou, Chenxuan and Li, Xiuhua and Wang, Xiaofei},
  booktitle={IEEE INFOCOM 2025 - IEEE Conference on Computer Communications}, 
  title={HyperJet: Joint Communication and Computation Scheduling for Hypergraph Tasks in Distributed Edge Computing}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={Distributed Edge Computing (DEC) has emerged as a novel paradigm, owing to its superior performance in communication latency, parallel computing efficiency, and energy consumption. With the surge of tasks in generative artificial intelligence, DEC faces higher demands for parallel computing efficiency. Scheduling multiple tasks for simultaneous processing, rather than one-by-one handling, could enhance parallel efficiency. Multiple tasks have multi-dependencies, i.e., sequence dependency, attribute similarity, and attribute correlation. Utilizing the bidirectional edges of traditional graphs to represent multi-dependencies can lead to an explosion in quantity. A hypergraph, with its hyperedges capable of connecting any number of vertices, can significantly solve the above problem. However, the multi-dependencies are rarely studied in the current research, posing the challenges, including incapable representing and unable capturing of multi-dependency hypergraph. In this work, we introduce a Joint communication and computation scheduling for hypErgraph Tasks in DEC, namely HypeJet, To effectively represent multi-dependencies, we employ hypergraph construction to represent task attributes and utilize hypergraph partitioning to clarify and refine task attribute correlations, enhancing parallel efficiency. In response to the challenge of capturing multi-dependencies, we employ a scheduling mechanism with the hypergraph neural network that efficiently acquires higher-order attribute correlated information among convolution matrices, providing enriched contextual information on multi-dependencies that supports decision-making in scheduling tasks. The evaluations using real-world traces demonstrate an 18.07% improvement in parallel efficiency of task scheduling.},
  keywords={Correlation;Processor scheduling;Generative AI;Neural networks;Parallel processing;Computational efficiency;Surges;Joining processes;Faces;Edge computing},
  doi={10.1109/INFOCOM55648.2025.11044587},
  ISSN={2641-9874},
  month={May},}@ARTICLE{7906545,
  author={Lemley, Joseph and Bazrafkan, Shabab and Corcoran, Peter},
  journal={IEEE Access}, 
  title={Smart Augmentation Learning an Optimal Data Augmentation Strategy}, 
  year={2017},
  volume={5},
  number={},
  pages={5858-5869},
  abstract={A recurring problem faced when training neural networks is that there is typically not enough data to maximize the generalization capability of deep neural networks. There are many techniques to address this, including data augmentation, dropout, and transfer learning. In this paper, we introduce an additional method, which we call smart augmentation and we show how to use it to increase the accuracy and reduce over fitting on a target network. Smart augmentation works, by creating a network that learns how to generate augmented data during the training process of a target network in a way that reduces that networks loss. This allows us to learn augmentations that minimize the error of that network. Smart augmentation has shown the potential to increase accuracy by demonstrably significant measures on all data sets tested. In addition, it has shown potential to achieve similar or improved performance levels with significantly smaller network sizes in a number of tested cases.},
  keywords={Training;Biological neural networks;Informatics;Electronic mail;Machine learning;Data models;Artificial intelligence;artificial neural networks;machine learning;computer vision supervised learning;machine learning algorithms;image databases},
  doi={10.1109/ACCESS.2017.2696121},
  ISSN={2169-3536},
  month={},}@ARTICLE{9540230,
  author={Wang, Liyuan and Lei, Bo and Li, Qian and Su, Hang and Zhu, Jun and Zhong, Yi},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Triple-Memory Networks: A Brain-Inspired Method for Continual Learning}, 
  year={2022},
  volume={33},
  number={5},
  pages={1925-1934},
  abstract={Continual acquisition of novel experience without interfering with previously learned knowledge, i.e., continual learning, is critical for artificial neural networks, while limited by catastrophic forgetting. A neural network adjusts its parameters when learning a new task but then fails to conduct the old tasks well. By contrast, the biological brain can effectively address catastrophic forgetting through consolidating memories as more specific or more generalized forms to complement each other, which is achieved in the interplay of the hippocampus and neocortex, mediated by the prefrontal cortex. Inspired by such a brain strategy, we propose a novel approach named triple-memory networks (TMNs) for continual learning. TMNs model the interplay of the three brain regions as a triple-network architecture of generative adversarial networks (GANs). The input information is encoded as specific representations of data distributions in a generator, or generalized knowledge of solving tasks in a discriminator and a classifier, with implementing appropriate brain-inspired algorithms to alleviate catastrophic forgetting in each module. Particularly, the generator replays generated data of the learned tasks to the discriminator and the classifier, both of which are implemented with a weight consolidation regularizer to complement the lost information in the generation process. TMNs achieve the state-of-the-art performance of generative memory replay on a variety of class-incremental learning benchmarks on MNIST, SVHN, CIFAR-10, and ImageNet-50.},
  keywords={Task analysis;Hippocampus;Training data;Brain modeling;Life sciences;Synapses;Biological neural networks;Brain-inspired algorithm;catastrophic forgetting;continual learning;deep learning},
  doi={10.1109/TNNLS.2021.3111019},
  ISSN={2162-2388},
  month={May},}@INPROCEEDINGS{9874193,
  author={Li, Yishan and Guo, Yanming and Xie, Yuxiang and Wang, Qi},
  booktitle={2022 8th International Conference on Big Data and Information Analytics (BigDIA)}, 
  title={A Survey of Defense Methods Against Adversarial Examples}, 
  year={2022},
  volume={},
  number={},
  pages={453-460},
  abstract={With the development of artificial intelligence technology, to our surprise, deep neural networks have made a series of breakthroughs and achieved optimal results in lots of machine learning tasks, while the image field is the most prominent. Although deep learning technology has brought great convenience to our lives, the security problems of artificial intelligence have gradually become prominent. But deep neural networks are very fragile, and usually a small perturbation can have a serious impact on the neural network, especially adversarial examples. As a small imperceptible perturbation, it can cause malicious effects on the results of image classification. What can we do to protect clean examples from perturbations has become the most important and practical research direction in the current image field. A large number of scholars have begun to invest in adversarial examples research, especially in defense, the achievements are more abundant, and related research results have also shown a blowout state. Based on the research status of recent years, this paper first explains the concept of adversarial examples, organizes the current attack methods, and then summarizes different defense methods according to the criteria of detection defense and robust defense. Improvements are discussed to help further development of adversarial defense of images.},
  keywords={Deep learning;Perturbation methods;Neural networks;Big Data;Security;Task analysis;Standards;deep learning;image field;defense methods;adversarial examples},
  doi={10.1109/BigDIA56350.2022.9874193},
  ISSN={2771-6902},
  month={Aug},}@INPROCEEDINGS{10356878,
  author={Zhou, Xinran and Lu, Huayue},
  booktitle={2023 IEEE 3rd International Conference on Intelligent Technology and Embedded Systems (ICITES)}, 
  title={Improved On-Device Hyperdimensional-Computing-based Image Segmentation}, 
  year={2023},
  volume={},
  number={},
  pages={165-170},
  abstract={Today‚Äôs artificial intelligence technology has made great progress and in many fields involved in artificial intelligence, such as medical imaging, logistics, manufacturing, and other fields, one of the most basic tasks is segmentation. Image segmentation is a more difficult segment in segmentation, and its existing problems are: insufficient labeled data leads to weakened performance, and it is difficult to process on the device. Recently, a hyperdimensional-computing-based unsupervised segmentation approach has been proposed, which can process images on-device. However, there are still some problems, like latency. In this work, we have made some improvements based on previous work and propose ImSegHDC having much lower latency with only a little segmentation performance drop.},
  keywords={Performance evaluation;Image segmentation;Sensitivity;Embedded systems;Image color analysis;Manufacturing;Delays;Unsupervised Image Segmentation;On-device Learning;Hyperdimensional Computing},
  doi={10.1109/ICITES59818.2023.10356878},
  ISSN={},
  month={Oct},}@ARTICLE{10847884,
  author={Gholian, Serly Moghadas and Fiandrino, Claudio and Vallina-Rodr√≠guez, Narseo and Fiore, Marco and Widmer, Joerg},
  journal={IEEE Transactions on Mobile Computing}, 
  title={DeExp: Revealing Model Vulnerabilities for Spatio-Temporal Mobile Traffic Forecasting With Explainable AI}, 
  year={2025},
  volume={24},
  number={6},
  pages={5245-5263},
  abstract={The ability to perform mobile traffic forecasting effectively with Deep Neural Networks (DNN) is instrumental to optimize resource management in 5G and beyond generation mobile networks. However, despite their capabilities, these Deep Neural Networks (DNN)s often act as complex opaque-boxes with decisions that are difficult to interpret. Even worse, they have proven vulnerable to adversarial attacks which undermine their applicability in production networks. Unfortunately, although existing state-of-the-art EXplainable Artificial Intelligence (XAI) techniques are often demonstrated in computer vision and Natural Language Processing (NLP), they may not fully address the unique challenges posed by spatio-temporal time-series forecasting models. To address these challenges, we introduce DeExp in this paper, a tool that flexibly builds upon legacy EXplainable Artificial Intelligence (XAI) techniques to synthesize compact explanations by making it possible to understand which Base Stations (BSs) are more influential for forecasting from a spatio-temporal perspective. Armed with such knowledge, we run state-of-the-art Adversarial Machine Learning (AML) techniques on those BSs to measure the accuracy degradation of the predictors under adversarial attacks. Our comprehensive evaluation uses real-world mobile traffic datasets and demonstrates that legacy XAI techniques spot different types of vulnerabilities. While Gradient-weighted Class Activation Mapping (GC) is suitable to spot BSs sensitive to moderate/low traffic injection, LayeR-wise backPropagation (LRP) is suitable to identify BSs sensitive to high traffic injection. Under moderate adversarial attacks, the prediction error of the BSs identified as vulnerable can increase by more than 250%.},
  keywords={Forecasting;Computational modeling;Predictive models;Perturbation methods;Mobile computing;Accuracy;Natural language processing;5G mobile communication;Explainable AI;Computer vision;Explainable AI (XAI);mobile networks;deep learning},
  doi={10.1109/TMC.2025.3531544},
  ISSN={1558-0660},
  month={June},}@INPROCEEDINGS{10770985,
  author={Procko, Tyler Thomas and Davidoff, Alexandra and Elvira, Timothy and Ochoa, Omar},
  booktitle={2024 Conference on AI, Science, Engineering, and Technology (AIxSET)}, 
  title={Leveraging Large Language Models on the Traditional Scientific Writing Workflow}, 
  year={2024},
  volume={},
  number={},
  pages={154-161},
  abstract={Technological advances in Natural Language Processing have brought forth language models capable of advanced response delivery. Scientific papers are traditionally written manually by human researchers, but with the advent of mainstream Large Language Models, e.g., OpenAI's ChatGPT, it is of increasing concern to scientists and academics that content in scientific papers may be generated by Artificial Intelligence (AI). Wishing to stop this is a losing attitude, as large-scale generative AI only becomes more powerful and accessible. Taking the more tenable position of cautious adaptation, this paper argues that there exists a taxonomy in the structure of scientific papers, and that language models can be used by scientific researchers to bootstrap scientific writing. Furthermore, AI can augment their own writing workflow to more efficiently traverse the academic publishing pipeline. Despite the shortcomings of language models, e.g., hallucination, when prompted appropriately with sufficient constraints, language models are extremely accurate and efficient content providers. In this work, the canonical scientific paper is broken down into its taxonomy of parts, where it is then considered how each part can benefit from language models, e.g., in generating abstracts and keywords, reformatting sections, theorizing titles, etc. Finally, a call for consensus among the academic and scientific communities regarding the use of language models in the scientific writing workflow is established.},
  keywords={Adaptation models;Generative AI;Publishing;Large language models;Taxonomy;Pipelines;Writing;Horses;Throughput;Automobiles;literature review;metascience;scientific workflow system;language model;scientific writing;academia;GPT},
  doi={10.1109/AIxSET62544.2024.00028},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10923798,
  author={Rafiee, Gholamreza and Ahmadli, Firuza and Collins, Matthew},
  booktitle={2024 IEEE 13th International Conference on Engineering Education (ICEED)}, 
  title={Fostering Personalized Learning in Data Science: Integrating Innovative Tools and Strategies for Diverse Pathways}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper introduces an innovative teaching approach in data science tailored for students in non-computer science pathways, specifically Business Information Technology (BIT) and Computing and Information Technology (CIT). Over a five-year period, a unique teaching approach has been developed incorporating a virtual reality (VR) game event and ChatGPT-4 as a generative artificial intelligence (AI) tool. To address the inherent complexities of learning data science, particularly the diverse prerequisite skills, this study introduces a framework including a diagnostic assessment centered around a specific education research question: ‚ÄúHow can the learning experiences of individual students be customized to address the multifaceted challenges of data science education?‚Äù Through a diagnostic assessment process, conducted via a survey completed by students, this framework identifies students' unique requirements and skill areas facilitating the delivery of personalized content recommendations within the initial week of teaching. By fostering a culture of self-directed learning, the approach aims to enable students to concentrate on essential customized learning materials. This paper also highlights the overall student satisfaction with the module averaged 4.5 out of 5 with a standard deviation of 0.9 indicating a high level of contentment with the teaching approach. The discussion encompasses the framework's implications for teaching and its alignment with educational theories. This paper contributes to the computing education field by addressing the research question and offering insights for future research and teaching practices.},
  keywords={Surveys;Generative AI;Education;Virtual reality;Games;Data science;Complexity theory;Information technology;Engineering education;Standards;Content recommendation;data science education;individualized learning experience framework;prerequisite skill identification;self-directed learning;ChatGPT-4;Virtual Reality},
  doi={10.1109/ICEED62316.2024.10923798},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10867116,
  author={TS, Marina and Mampilly, Tessa S and S, Deepa and M, Vinay and J, Jayapriya},
  booktitle={2024 4th International Conference on Ubiquitous Computing and Intelligent Information Systems (ICUIS)}, 
  title={Comprehensive Large Language Model for Bathymetry Data}, 
  year={2024},
  volume={},
  number={},
  pages={1237-1244},
  abstract={Only 5% of the world's oceans have been explored, leaving the rest unexplored. Many incidents have been reported surrounding the mystery of random disappearances and intriguing flora and fauna found in these unexplored places. More than 80% of the oceans have not been mapped, so tracking becomes an uphill task. Existing work has been done to find a solution to tackle this rising issue. As Generative Artificial Intelligence(AI) is at the forefront of the race regarding advanced technology, projects have been taken up to leverage AI's capabilities to solve this issue. This paper proposes a framework that handles bathymetric data and harnesses it to empower ocean tracking advancements by incorporating large language models(LLMs).},
  keywords={Reviews;Generative AI;Oceans;Large language models;Flora;Fauna;Vegetation mapping;Ubiquitous computing;Data models;Information systems;Bathymetry;Large Language Models;Retrieval Augmented Generation},
  doi={10.1109/ICUIS64676.2024.10867116},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11006853,
  author={Yin, Ruiyang and Liu, Xuebin},
  booktitle={2025 IEEE 10th International Conference on Smart Cloud (SmartCloud)}, 
  title={From Technological Alienation to Value Regression: Ethical Regulation of Algorithmic Bias in the Post-Truth Era}, 
  year={2025},
  volume={},
  number={},
  pages={32-37},
  abstract={In the current post-truth era characterized by an information explosion and complex and ever-changing circumstances, a large amount of false information and misleading content is widely disseminated, and the public's perception is easily disturbed. As a key mechanism for information screening and pushing, algorithms have seen their bias issues becoming increasingly prominent. In particular, the technological breakthrough of generative artificial intelligence has further transformed the infrastructure of the internet society. Its potential algorithmic bias and discrimination will not only solidify the systemic discrimination and inequality in human society, but may even intensify and create new biases, posing a systemic threat to social fairness and social progress. The algorithmic bias in the post-truth era has a non-negligible impact throughout the entire process of information production, information dissemination, and information construction. The ethical dilemma urgently needs to be addressed. This study reveals the generation logic and manifestations of algorithmic bias in the post-truth era, constructs a systematic path that integrates "technology, value, and institution" as a trinity, provides practical solutions to cope with the ethical challenges of algorithmic bias in the post-truth era, and helps build a more rational, inclusive, and just information society.},
  keywords={Symbiosis;Ethics;Systematics;Generative AI;Production;Regulation;Explosions;Mirrors;Logic;Fake news;Post-truth Era;Algorithmic Bias;Value Regression},
  doi={10.1109/SmartCloud66068.2025.00008},
  ISSN={},
  month={May},}@INPROCEEDINGS{11132252,
  author={Al-kumaim, Nabil Hasan and Hasnah Hassan, Siti and Mohammed, Fathey and Saleh, Abdulrazak Yahya},
  booktitle={2025 5th International Conference on Emerging Smart Technologies and Applications (eSmarTA)}, 
  title={Navigating GenAI in Malaysian Universities: Use, Problems, and Challenges}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={The growing presence of Generative Artificial Intelligence (GenAI) in higher education offers promising advantages but also raises critical concerns that deserve close attention. This study explores how GenAI is being used by university communities in Malaysia, with a focus on user behaviour ‚Äî including usage patterns, motivations, perceived benefits, and perceived risks. Given the limited empirical work in this area, particularly within the Malaysian context, our investigation seeks to provide insights that can inform more thoughtful and responsible integration of AI tools in academia. Using a mixed-methods approach, we collected data from 290 students and academic staff across Malaysian universities. The findings suggest that easy access and reliable, prompt results are major factors encouraging GenAI use. Participants appreciated its ability to save time and enhance problem solving, especially in completing routine academic tasks. However, concerns were also raised ‚Äî notably around the decline of critical thinking skills, potential for information overload, ethical uncertainties, and increasing dependence on AI. Many respondents pointed out the need for better content verification practices, clearer ethical guidelines, and more institutional support to manage the cognitive demands of frequent GenAI use. Overall, this study highlights the urgent need for universities to develop policies, frameworks, and digital well-being strategies that promote ethical, balanced, and sustainable GenAI use. The findings also lay the groundwork for future research and conceptual models aimed at supporting effective AI adoption in higher education.},
  keywords={Ethics;Uncertainty;Generative AI;Navigation;Plagiarism;Education;Pressing;Reliability;Problem-solving;Guidelines;GenAI;Universities;Malaysia;Usage and Challenges},
  doi={10.1109/eSmarTA66764.2025.11132252},
  ISSN={},
  month={Aug},}@INBOOK{10982323,
  author={Pierson, Lillian},
  booktitle={Data & AI Imperative: Designing Strategies for Exponential Growth}, 
  title={Surveying Your Industry and Organization}, 
  year={2024},
  volume={},
  number={},
  pages={141-159},
  abstract={<p>This chapter looks at how to use common generative artificial intelligence (AI) research tools. Companies that offer AI search engine products need to make money, too. The quick assessment example provides an overview of Power BI's strengths and weaknesses, which can then be used to inform decisions on whether it would be suitable for a potential use case readers are evaluating within their data strategy planning process. The chapter looks at case study research, then use case research, and then request for information. Case studies show practical applications of data or AI in addressing issues like the ones at hand within the organization. The chapter looks at how to identify, categorize, and extract insights from use cases. The process and best practices involved in researching use cases are almost identical to those involved in case study research.</p>},
  keywords={Medical services;Market research;Generative AI;Industries;Surveys;Real-time systems;Internet;Data analysis;Search engines;Predictive analytics},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394251971},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10982323},}@INPROCEEDINGS{11132759,
  author={Moreira, Matheus T. and Markosyan, Aram H. and Cummins, Chris and Hunt, Warren and Synnaeve, Gabriel and Beigne, Edith},
  booktitle={2025 62nd ACM/IEEE Design Automation Conference (DAC)}, 
  title={LLMs: A Driving Force in Next Generation Digital Design Automation}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Innovations in generative artificial intelligence (GenAI), particularly large language models (LLMs), are poised to revolutionize silicon design automation. This paper explores the transformative potential of LLMs in automating and enhancing various tasks within the silicon design process. It reviews the current applications of LLMs and their potential to automate silicon design tasks, proposing applications, providing a qualitative analysis of the readiness of the technology to support these applications and setting directions for future research.},
  keywords={Technological innovation;Design automation;Reviews;Generative AI;Large language models;Force;Silicon;Next generation networking;Large language models;design automation},
  doi={10.1109/DAC63849.2025.11132759},
  ISSN={},
  month={June},}@INPROCEEDINGS{10825408,
  author={Ong, Yuya Jeremy and Gala, Jay and An, Sungeun and Moore, Robert and Jadav, Divyesh},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={Adversarially Exploring Vulnerabilities in LLMs to Evaluate Social Biases}, 
  year={2024},
  volume={},
  number={},
  pages={5289-5297},
  abstract={Generative AI has caused a paradigm shift in the area of Artificial Intelligence (AI) and as such has inspired much new research, especially on Large Language Models (LLMs). LLMs are transforming how people interact with computers in service-oriented fields in both the consumer (for example: retail, travel, education, healthcare) and enterprise (customer care, field service, sales, marketing, etc.) spaces. One barrier to widespread adoption is the current unpredictability of LLM behavior: users must trust that LLM-based services and systems are accurate, fair, and unbiased. Model responses that exhibit biases related to race, social status, and other sensitive topics can have serious consequences, ranging from lack of trust in the model to adverse social implications for consumers, all the way to damage to the reputations of the corporations that provide them. This study explores how to uncover biases related to social stigmas in LLM output, by using an adversarial prompt-based approach. Discovering model vulnerabilities of this type is a nontrivial task due to the large search space, making it resource-intensive. We present an evaluation framework for probing and analyzing the behaviors of multiple LLMs systematically. We use a curated set of adversarial prompts with a focus on uncovering biased responses to prompts associated with social attributes.},
  keywords={Training;Accuracy;Systematics;Sensitivity;Generative AI;Computational modeling;Data models;Robustness;Testing;Resilience;Large Language Models;Adversarial Machine Learning;Social Computing},
  doi={10.1109/BigData62323.2024.10825408},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{10757582,
  author={Bouazizi, Mondher and Ohtsuki, Tomoaki},
  booktitle={2024 IEEE 100th Vehicular Technology Conference (VTC2024-Fall)}, 
  title={Multi-Dimensional Representation for Semantic Communication: A New Horizon for Customized Visualization of Shared Knowledge}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Semantic communication plays a crucial role in human interactions, allowing for the exchange of complex ideas and concepts. In this paper, we introduce a novel approach to semantic communication leveraging image generative Artificial Intelligence (AI) models, specifically stable diffusion models. Unlike conventional works, our system enables the transmission of images through a physical channel by transforming them into multi-dimensional semantic representations consisting of text descriptions, low-resolution sketches, and pose information. At the receiver‚Äôs end, these semantic representations are used to reconstruct the original image using a trained stable diffusion model. The benefits of our approach include reduced transmission bandwidth requirements, flexibility in reconstruction styles, adaptability to multiple receivers‚Äô preferences, and the ability to omit unwanted image elements. We present preliminary results demonstrating the feasibility and effectiveness of our method. The similarity score between the transmitted images and reconstructed ones reach values ranging between 0.015 and 0.029 in Root Mean Square Error (RMSE) and between 0.993 and 0.998 using a Siamese network.},
  keywords={Visualization;Vehicular and wireless technologies;Generative AI;Bandwidth;Diffusion models;Distance measurement;Root mean square;Image reconstruction;Semantic communication;stable diffusion;6G;deep learning;goal-oriented communications},
  doi={10.1109/VTC2024-Fall63153.2024.10757582},
  ISSN={2577-2465},
  month={Oct},}@INPROCEEDINGS{11089608,
  author={Indhumathi, G. and G, Saranya and S, Pranitha and M, Ramya Kumari},
  booktitle={2025 6th International Conference on Inventive Research in Computing Applications (ICIRCA)}, 
  title={Enhanced EEG Image Classification Using ESRGAN and Decision Tree for Early Diagnosis of Neurological Disorders}, 
  year={2025},
  volume={},
  number={},
  pages={356-362},
  abstract={Neurological disorder diagnosis from EEG signals is hindered by low data resolution and limitations in feature extraction. In this work, the use of Enhanced Super-Resolution Generative Adversarial Networks (ESRGAN) for boosting EEG-based image reconstructions is discussed, with enhanced readability and representation of brain activity patterns. The classification process can be enhanced by increasing the quality of input images and fine-tuning the classifier's parameters. In this research, ESRGAN is employed to enhance the resolution and clarity of EEG images, aiding in the identification of important patterns and features. Furthermore, the Decision Tree classifier is optimized by adjusting hyperparameters such as the maximum depth, the minimum number of samples necessary for splitting, and selecting an appropriate criterion for splitting, either Gini impurity or entropy. The use of crossvalidation and grid search techniques improves the classifier's effectiveness and minimizes the risk of overfitting, leading to better classification accuracy. The suggested framework maps EEG signals to low-resolution images, which are then processed with ESRGAN to produce high-resolution representations. Wavelet transform and statistical feature extraction using deep learning methods are used to extract distinctive features. A decision tree classifier classifies Alzheimer's disease, Parkinson's disease, and epilepsy with high accuracy. The suggested system has greater spatial resolution, better feature extraction, greater diagnostic accuracy, and early detection of disease potential. This new combination of ESRGAN with EEG analysis benefits neuroscience and artificial intelligence, paving the way towards advanced brain-machine interfaces, early diagnosis, and personalized treatment planning.},
  keywords={Neurological diseases;Wavelet transforms;Accuracy;Superresolution;Feature extraction;Generative adversarial networks;Electroencephalography;Decision trees;Spatial resolution;Image reconstruction;ESRGAN;Decision Tree;EEG Spectrogram;Feature Extraction;Neurological Disorders;EEG Analysis;Image Enhancement;Disease Classification;High-Resolution Imaging;Brain Activity Visualization;Early Diagnosis},
  doi={10.1109/ICIRCA65293.2025.11089608},
  ISSN={},
  month={June},}@INPROCEEDINGS{11068478,
  author={de Almeida Prado, Jose Pacheco and Mangion, David Zammit and Zammit, Brian and Gauci, Jason and Muscat, Alan and Mizzi, Sandro and Manicolo, Andre},
  booktitle={2025 IEEE Aerospace Conference}, 
  title={Enhancing Flight Deck Decision Support with Distributed GenAI: A Multi-Agent Approach}, 
  year={2025},
  volume={},
  number={},
  pages={1-20},
  abstract={The integration of Generative Artificial Intelligence (GenAI) into commercial aviation presents transformative opportunities for enhancing flight deck operations, offering an intuitive natural language interface between pilots and automation. This study investigates a novel GenAI-based multi-agent architecture designed to address the unique demands of aviation, such as the need for rapid decision-making and adherence to stringent safety protocols. By employing lightweight, embedded Large Language Models (LLMs), the architecture optimises task allocation among specialised agents, ensuring operational efficiency without reliance on external cloud infrastructure. Preliminary evaluations demonstrate that the proposed architecture achieves performance comparable to systems using larger models, such as GPT-4, while operating locally with lightweight models. This result underscores the feasibility of implementing autonomous, cloud-independent GenAI solutions embedded directly within aircraft systems. Through a comparative analysis of different LLM configurations, the system balances scalability and precision in handling cockpit-specific tasks. Challenges related to explainability, response latency, and integration with broader Human-Machine Interface (HMI) systems are identified as critical areas for future development.},
  keywords={Protocols;Generative AI;Atmospheric modeling;Scalability;Large language models;Human-machine systems;Natural languages;Decision making;Safety;Resource management},
  doi={10.1109/AERO63441.2025.11068478},
  ISSN={2996-2358},
  month={March},}@INPROCEEDINGS{11049250,
  author={Reeves, Andrew and Dong, Hang},
  booktitle={2025 12th International Conference on Information Technology (ICIT)}, 
  title={Robustness of Question Answering Systems in the Biomedical Domain: a study of the BioASQ dataset}, 
  year={2025},
  volume={},
  number={},
  pages={247-252},
  abstract={Robustness is a critical consideration when integrating artificial intelligence (AI) systems into decision-making processes. This concern is particularly relevant for generative AI systems, which are designed to consistently produce convincing outputs but can be prone to hallucinations, risking overconfidence in their outputs. This paper investigates the performance of fine-tuning and retrieval augmented generation (RAG) under external data quality perturbations, including typographical errors and factual inaccuracies. Results from experiments using the BioASQ Task 12b question answering dataset and PubMed articles showed nuanced trade-offs, with either RAG or fine-tuning performing better for different scenarios. Furthermore, an analysis of LLMs‚Äô self-reported confidence scores indicated a tendency toward overconfidence, particularly in the presence of inconsistent or erroneous context data. A novel mitigation strategy, leveraging an LLM for data quality error correction was evaluated, but the results demonstrated limited effectiveness, highlighting the need for more advanced correction techniques.},
  keywords={Generative AI;Prevention and mitigation;Perturbation methods;Data integrity;Large language models;Retrieval augmented generation;Predictive models;Robustness;Question answering (information retrieval);Information technology;Large language models;Retrieval augmented generation;Robustness;Question answering},
  doi={10.1109/ICIT64950.2025.11049250},
  ISSN={2831-3399},
  month={May},}@INPROCEEDINGS{11074099,
  author={Gajula, Mohan Kumar and Mailewa, Akalanka},
  booktitle={2024 1st International Conference on Sustainability and Technological Advancements in Engineering Domain (SUSTAINED)}, 
  title={The Third Generation of Wireless Networks (5G): Preventing Cyberattacks on Essential Services and Preserving Cyberspace}, 
  year={2024},
  volume={},
  number={},
  pages={126-131},
  abstract={An unparalleled level of speed, ultra-low latency, and the capacity to link billions of devices across the Internet of Things (IoT) are some of the benefits that will be offered by the implementation of the third generation of wireless networks, often known as 5G. This will signal a dramatic leap in the telecom industry. The potential for cyberattacks on key services is growing at an exponential rate as 5G becomes the backbone of critical infrastructures. These infrastructures include healthcare, smart cities, transportation, energy grids, and emergency services. With a particular emphasis on the ways in which cybercriminals and hostile state actors can take advantage of these vulnerabilities, this paper analyzes the security problems that are offered by 5G networks. As a result of software-defined networking (SDN) and network function virtualization (NFV), key dangers include Distributed Denial of Service (DDoS) attacks, the exploitation of network slicing, vulnerabilities in Internet of Things devices, and man-in-the-middle assaults. Enhanced end-to-end encryption, multi-layered authentication protocols, artificial intelligence-driven intrusion detection systems, and secure orchestration of virtualized network operations are some of the advanced security mechanisms that are evaluated in this study. These mechanisms are designed to meet the issues that are associated with 5G settings. Furthermore, it investigates the role that government legislation, international standards bodies, and industry collaboration play in the process of building high-quality security frameworks for 5G connections. Adaptive cybersecurity responses are emphasized by the research, which highlights the significance of proactive threat modeling, real-time network monitoring, and the integration of artificial intelligence (AI) and machine learning (ML) technology. In this study, recommendations are provided for protecting vital infrastructures and maintaining the integrity of cyberspace in this era of ubiquitous connection. These recommendations are derived from an analysis of the existing level of security for 5G communication. With the end goal of contributing to the creation of robust 5G networks that are able to withstand growing cyber attacks and assure the security of key services, this paper‚Äôs ultimate objective is to contribute.},
  keywords={5G mobile communication;Network slicing;Wireless networks;Standards organizations;Cyberspace;Transportation;Network function virtualization;Encryption;Internet of Things;Software defined networking;Software-Defined Networking (SDN);Network Function Virtualization (NFV);Network Slicing;Distributed Denial of Service (DDoS);Quantum-Resistant Encryption;Security Frameworks;Regulatory Standards},
  doi={10.1109/SUSTAINED63638.2024.11074099},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10618584,
  author={Wang, Yaqi and Gui, Renzhou and Zhu, Wenbo and Yin, Yumiao and Tong, Meisong},
  booktitle={2024 Photonics & Electromagnetics Research Symposium (PIERS)}, 
  title={VTVBrain: A Two-stage Brain Encoding Model for Decoding Key Neural Responses in Multimodal Contexts}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={In the field of cognitive neuroscience, understanding how the brain processes multimodal complex stimuli is a long-standing and complex challenge. In this study, we propose a novel two-stage brain coding model called "VTVBrain" that focuses on decoding key neural responses in multimodal environments. In the first stage, we built a high-dimensional multimodal latent space pre-training model using an attentional mechanism-based variational autoencoder, aiming to capture and encode the main perceptual processes of observers when faced with multimodal stimuli integrating textual and visual information. In the second stage, the Versatile Diffusion model is utilized for image reconstruction of the first stage primary representational images for high-level perception. The proposed model further refines the latent space representation approach, explores the relationship between the brain‚Äôs neural responses and complex natural scenes, and provides insight into how the brain integrates and processes information from different senses at a higher level. The introduction of the VTVBrain model not only brings a new perspective to the field of neural decoding, but also has a great potential for application in the development of brain-like artificial intelligence and future cognitive neuroscience research. The introduction of the VTVBrain model not only brings a new perspective to the field of neural decoding, but also has great potential for the development of brain-like artificial intelligence and future cognitive neuroscience research.},
  keywords={Cognitive neuroscience;Semantics;Brain modeling;Diffusion models;Encoding;Decoding;Space exploration},
  doi={10.1109/PIERS62282.2024.10618584},
  ISSN={2831-5804},
  month={April},}@ARTICLE{10348570,
  author={Sorour, Shaymaa E. and Hany, Amr Abo and Elredeny, Mohamed S. and Sedik, Ahmed and Hussien, Reda M.},
  journal={IEEE Access}, 
  title={An Automatic Dermatology Detection System Based on Deep Learning and Computer Vision}, 
  year={2023},
  volume={11},
  number={},
  pages={137769-137778},
  abstract={Automatic medical diagnosis has gained significant attention among researchers, particularly in disease diagnosis. Differentiating between dermatology diseases is pivotal in clinical decision-making as it provides prognostic and predictive information and treatment strategies. This paper proposes a dermatology detection system based on deep learning (DL) and object recognition. The proposed model consists of three phases: Data preprocessing, data augmentation, and classification with localization. In the data preprocessing phase, we apply various operations such as color transformation, resizing, normalization, and labeling to prepare the input image for enrollment in our DL models. The data augmentation phase is carried out on the input images using the convolutional generative adversarial network algorithm. In the third phase, YOLO-V5 is used to classify and localize objects. The dataset is carefully collected with the assistance of medical specialists to ensure its accuracy. The proposed models are evaluated and compared using various metrics. Our empirical results demonstrate that the proposed model outperforms state-of-the-art models in terms of accuracy. Our proposed methodology offers significant improvements in detecting vitiligo and melanoma compared to recent techniques.},
  keywords={Skin;Diseases;Lesions;Solid modeling;Medical diagnostic imaging;Melanoma;Feature extraction;Computer vision;Medical diagnosis;Computer vision;deep learning;medical diagnosis;YOLO-V5},
  doi={10.1109/ACCESS.2023.3340735},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11167521,
  author={Syahidi, Aulia Akhrian and Kiyokawa, Kiyoshi},
  booktitle={2025 IEEE 7th Symposium on Computers & Informatics (ISCI)}, 
  title={Automatic Text Generation in Banjar Language Using GPT-4 for Low-Resource Language Preservation}, 
  year={2025},
  volume={},
  number={},
  pages={238-243},
  abstract={This study explores the capabilities of Generative Pre-trained Transformer 4 (GPT-4), a state-of-the-art Large Language Model (LLM), in generating text in the Banjar language, an under-resourced language from South Kalimantan, Indonesia. Using prompt engineering and both zero-shot and few-shot learning approaches, GPT-4 was guided to understand and generate Banjar text. A parallel dataset and small Banjar corpus were developed for experimentation. Evaluation involved quantitative metrics (Bilingual Evaluation Understudy (BLEU) score, perplexity) and qualitative assessments from five native speakers. The few-shot approach performed best, achieving a BLEU score of 0.56 (std. dev. = $0.04)$, perplexity of 30.8 (std. dev. = 2.1), fluency of 4.2 (std. dev. $=0.3$), and coherence of 4.1 (std. dev. $=0.4$). The zero-shot approach yielded a BLEU score of 0.34 (std. dev. $=0.05$), perplexity of 45.2 (std. dev. $=3.4$), fluency of 3.2 (std. dev. $=0.4$), and coherence of 3.0 (std. dev. $=0.5$). These findings demonstrate that GPT-4, although not trained on Banjar, can generate coherent and natural-sounding text, especially with few-shot prompting. This study contributes to the development of AI technologies for local languages and highlights opportunities for integrating LLMs in cultural preservation efforts.},
  keywords={Measurement;Generative Pre-trained transformer;Coherence;Prompt engineering;Cultural differences;Informatics;Few shot learning;banjar language;generative AI;GPT-4;lowresource language;prompt engineering},
  doi={10.1109/ISCI65687.2025.11167521},
  ISSN={2996-6752},
  month={Aug},}@INPROCEEDINGS{10922077,
  author={Babisha, A. and Srikanth, G. Umarani and Angel Kiruba, D.R. and Sundar, R},
  booktitle={2024 International Conference on Computing and Intelligent Reality Technologies (ICCIRT)}, 
  title={Gloss-Free Sign Language Translation using Sign2gpt-Next Technique}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This work proposes a new approach to convert the data from sign language to spoken language without exposing the data to a gloss layer. Whenever gloss annotations are used which frequently are incomplete and act as an intermediate representation, it is usually found to be a bottleneck in translating sign language videos. In order to avoid this, the authors use a combination of modern machine learning algorithms to arrive at the conclusion. They use Dino-V2 Vision Transformer to implement the function of extracting the spatial features of the input sign language video frames. This model is particularly suitable for learning and visual patterns in general and particularly for capturing fine details of these patterns. Further, a spatio-temporal transformer layer is added to automate the temporal processing of the Sign-Language which helps in the arrangement of the body gestures and limb movements needed at a specific temporal frame. It is then translated into the desired spoken language using a multilingual Generative Pre-trained Transformer (GPT) model. The approach can be said to be a big leap forward in sign language transliteration especially for such situations where few Gloss annotations are available, and making way for better and improved tools for the Deaf and the hard-of-hearing.},
  keywords={Sign language;Visualization;Translation;Annotations;Generative Pre-trainer transformer;Transformers;Feature extraction;Multilingual;Optimization;Videos;Dino-V2 Transformer;Spatio-temporal transformer;Generative Pre-trained Transformer (GPT);Sign Language Translation;Gloss Annotation},
  doi={10.1109/ICCIRT59484.2024.10922077},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10388202,
  author={Bringsjord, Selmer and Slowik, John and Govindarajulu, Naveen Sundar and Giancola, Michael and Oswald, James and Ghosh, Rikhiya},
  booktitle={2023 11th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)}, 
  title={Affect-based Planning for a Meta-Cognitive Robot Sculptor: First Steps}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Today‚Äôs so-called ‚Äúgenerative AI‚Äù is in the minds of some capable of specifically generating genuine visual art; DALL-E is an example. While in fact intensely skeptical, we grant for the sake of argument that the likes of DALL-E can in fact generate genuine visual art. However, we observe that fine visual artistry is by no means monolithic; in particular, some forms of fine visual artistry are seemingly harder than others for artificial agents to achieve. In the traditional ontology, perhaps the very hardest type of fine visual artistry for an AI to achieve is literary sculpture, an activity carried out in the human sphere at the very highest level by Rodin. Artificial agents that operate in this sphere must for obvious reasons be cognitive robots. We explain such literary sculpture in broad terms, making clear that it‚Äôs undertaken by the sculptor in question with the aim of bringing about certain affective states in the mind of the viewer of the sculpture. In short, literary sculpting is affect-driven. We provide a case study of robot sculpting, with help from pre-existing logic-based formalisms and automated-reasoning technology, and the cognitive robot PERI.2, operating as a sculptor. To our knowledge, ours is the very first foray into literary sculpture in AI and cognitive robotics.},
  keywords={Visualization;Affective computing;Art;Generative AI;Conferences;Ontologies;Planning;creativity;AI;cognitive robotics;sculpture;logic-based AI},
  doi={10.1109/ACIIW59127.2023.10388202},
  ISSN={},
  month={Sep.},}@ARTICLE{10620177,
  author={Halvon√≠k, Dominik and Kapusta, Jozef},
  journal={IEEE Access}, 
  title={Large Language Models and Rule-Based Approaches in Domain-Specific Communication}, 
  year={2024},
  volume={12},
  number={},
  pages={107046-107058},
  abstract={Currently, we are once again experiencing a frenzy related to artificial intelligence. Generative Pre-trained Transformers (GPT) models are highly effective at various natural language processing tasks. Different varieties of GPT models are widely used these days to improve productivity. Graphic departments generate art designs, developers engineer intricate software solutions, leveraging services predicated on the GPT framework, and many other industries are also following the lead and implementing these new sets of tools in their workflow. However, there are areas in natural language processing where a simple solution is often more suitable and effective than current Large Language Models. In this article, we decided to analyze and compare the practical use of one of the more popular GPT solutions, J-Large, and the simple rule-based model we implemented. We integrated these two models into the internal information system of a private company focused on communication with customers in the gaming industry. Both models were trained on the same dataset provided as a log of conversational interactions for the last two years in the given system. We observed that GPT models exhibited superior performance in terms of comprehensibility and adequacy. The rule-based models showed noticeable proficiency in handling domain-specific tasks, mainly when fed with datasets extracted from the historical communication between users and a specialized domain system, such as a customer care department. As a result, with a sufficiently tailored and specific dataset at their disposal, rule-based models can effectively outpace GPT models in performing domain-specific tasks.},
  keywords={Data models;Training;Transformers;Task analysis;Biological system modeling;Artificial intelligence;Companies;Chatbots;Large language models;Chatbot;generative pre-trained transformers;large language models;transformer model;rule-based model},
  doi={10.1109/ACCESS.2024.3436902},
  ISSN={2169-3536},
  month={},}@ARTICLE{11017451,
  author={Xue, Liyuan and Dixit, Ankit and Kumar, Naveen and Georgiev, Vihar},
  journal={IEEE Transactions on Electron Devices}, 
  title={Generative Process Variation Modeling and Analysis for Advanced Technology Based on Variational Autoencoder}, 
  year={2025},
  volume={72},
  number={7},
  pages={3889-3895},
  abstract={The development of advanced technology nodes highlights the significant impact of process variations on device electrical characteristics. To analyze and understand these variations, extensive and intensive technology computer-aided design (TCAD) simulations or costly on-wafer testing are often indispensable. This article proposes a novel generative process variation modeling method to alleviate this burden, which can learn from a few discrete sampling points and reproduce or generate analytical electrical responses for variation analysis and circuit simulation without requiring predefined domain knowledge or empirical equations. A silicon nanowire (NW) transistor is employed to showcase the strength of the proposed method, considering two complex process variabilities: metal grain granularity (MGG) and random discrete dopants (RDDs). The trained models on  $\textit {I}_{\textit {d}}$ ‚Äì $\textit {V}_{\textit {g}}$  curves achieve median percentage errors of 0.7% (best case) and 2.8% (worst case). Furthermore, the proposed framework is transfer-learnable, allowing data from a new variability source to be added to a trained model, resulting in even greater accuracy and further reducing the cost of data collection.},
  keywords={Semiconductor process modeling;Analytical models;Computational modeling;Integrated circuit modeling;Metals;Load modeling;Silicon;Data models;Accuracy;Training;Device modeling;metal grain granularity (MGG);nanowire (NW) transistor;process variation;random discrete dopants (RDDs);variational autoencoder (VAE)},
  doi={10.1109/TED.2025.3570675},
  ISSN={1557-9646},
  month={July},}@ARTICLE{11052875,
  author={Cirkovic, Daniel and Wang, Tiandong and Zhang, Xianyang},
  journal={IEEE Transactions on Network Science and Engineering}, 
  title={Likelihood-based Inference for Random Networks with Changepoints}, 
  year={2025},
  volume={},
  number={},
  pages={1-15},
  abstract={Generative, temporal network models play an important role in analyzing the dependence structure and evolution patterns of complex networks. Due to the complicated nature of real network data, it is often naive to assume that the underlying data-generative mechanism itself is invariant with time. Such observation leads to the study of changepoints or sudden shifts in the distributional structure of the evolving network. In this paper, we propose a likelihood-based methodology to detect changepoints in undirected, affine preferential attachment networks where, upon introduction, a new node selects one old to attach to with probability proportional to its degree. In particular, we establish a hypothesis testing framework to detect a single changepoint, together with a consistent estimator for the changepoint. Such results require establishing consistency and asymptotic normality of the MLE under the changepoint regime, which suffers from long range dependence. The methodology is then extended to the multiple changepoint setting via both a sliding window method and a more computationally efficient score statistic. We also compare the proposed methodology with previously developed non-parametric estimators of the changepoint via simulation, and the methods developed herein are applied to modeling the advisor choice in a Mathematics Genealogy Project network over time.},
  keywords={Maximum likelihood estimation;Data models;Mathematical models;Maximum likelihood detection;LoRa;Adaptation models;Testing;Detection algorithms;Artificial intelligence;Training;Change detection algorithms;Maximum likelihood estimation;Stochastic processes;Graph theory},
  doi={10.1109/TNSE.2025.3583550},
  ISSN={2327-4697},
  month={},}@ARTICLE{11052216,
  author={Kim, Heehwan and Park, Sungjune and Choi, Daeseon},
  journal={IEEE Access}, 
  title={Secure and Reversible Face De-Identification With Format-Preserving Encryption}, 
  year={2025},
  volume={13},
  number={},
  pages={116130-116142},
  abstract={With the rapid growth of digital services and transactions, concerns about personal information leakage and security threats have intensified. In particular, facial images stored in surveillance systems, security agency databases, and biometric authentication platforms can be exploited for identity theft, fraud, phishing, illegal marketing, or deepfake-based misinformation. These risks have increased the need for technologies that securely protect stored facial data while enabling authorized restoration when necessary. We propose a reversible face de-identification method using format-preserving encryption (FPE). Our method integrates symmetric-key FPE into two deep neural network (DNN)-based face swap models (FaceShifter and SimSwap) that separate identity and attribute information. This approach enables the generation of de-identified facial images and allows only authorized users to restore the original data. Experiments on the LFW, FFHQ, VGGFace2-HQ, and CelebA-HQ datasets showed that, on average, the FaceShifter model achieved a 98.64% de-identification success rate and 96.86% restoration rate, while SimSwap recorded 99.58% and 99.39%, respectively. Image quality was evaluated using SSIM, FID, LPIPS, PSNR, and BRISQUE, confirming that restored images closely resemble the originals. In conclusion, the proposed method provides a robust privacy-preserving solution for facial data in digital environments, balancing security and utility while supporting lawful restoration.},
  keywords={Image restoration;Face recognition;Feature extraction;Security;Data privacy;Protection;Passwords;Image quality;Privacy;Noise;Artificial intelligence (AI);face de-identification;face privacy;format-preserving encryption (FPE);privacy protection},
  doi={10.1109/ACCESS.2025.3583388},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9811570,
  author={Karnan, Haresh and Torabi, Faraz and Warnell, Garrett and Stone, Peter},
  booktitle={2022 International Conference on Robotics and Automation (ICRA)}, 
  title={Adversarial Imitation Learning from Video Using a State Observer}, 
  year={2022},
  volume={},
  number={},
  pages={2452-2458},
  abstract={The imitation learning research community has recently made significant progress towards the goal of enabling artificial agents to imitate behaviors from video demonstrations alone. However, current state-of-the-art approaches developed for this problem exhibit high sample complexity due, in part, to the high-dimensional nature of video observations. Towards addressing this issue, we introduce here a new algorithm called Visual Generative Adversarial Imitation from Observation using a State Observer (VGAIfO-SO). At its core, VGAIfO-SO seeks to address sample inefficiency using a novel, self-supervised state observer, which provides estimates of lower-dimensional proprioceptive state representations from high-dimensional images. We show experimentally in several continuous control environments that VGAIfO-SO is more sample efficient than other IfO algorithms at learning from video-only demonstrations and can sometimes even achieve performance close to the Generative Adversarial Imitation from Observation (GAIfO) algorithm that has privileged access to the demonstrator's proprioceptive state information.},
  keywords={Visualization;Training data;Reinforcement learning;Learning (artificial intelligence);Observers;Prediction algorithms;Market research},
  doi={10.1109/ICRA46639.2022.9811570},
  ISSN={},
  month={May},}@INPROCEEDINGS{9534437,
  author={Shen, Gehui and Zhang, Song and Chen, Xiang and Deng, Zhi-Hong},
  booktitle={2021 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Generative Feature Replay with Orthogonal Weight Modification for Continual Learning}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={The ability of intelligent agents to learn and remember multiple tasks sequentially is crucial to achieving artificial general intelligence. Many continual learning (CL) methods have been proposed to overcome catastrophic forgetting which results from non i.i.d data in the sequential learning of neural networks. In this paper we focus on class incremental learning, a challenging CL scenario. For this scenario, generative replay is a promising strategy which generates and replays pseudo data for previous tasks to alleviate catastrophic forgetting. However, it is hard to train a generative model continually for relatively complex data. Based on recently proposed orthogonal weight modification (OWM) algorithm which can approximately keep previously learned feature invariant when learning new tasks, we propose to 1) replay penultimate layer feature with a generative model; 2) leverage a self-supervised auxiliary task to further enhance the stability of feature. Empirical results on several datasets show our method always achieves substantial improvement over powerful OWM while conventional generative replay always results in a negative effect. Meanwhile our method beats several strong baselines including one based on real data storage. In addition, we conduct experiments to study why our method is effective.},
  keywords={Neural networks;Memory;Approximation algorithms;Stability analysis;Data models;Intelligent agents;Task analysis},
  doi={10.1109/IJCNN52387.2021.9534437},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{10660285,
  author={Feng, Y. and Snoussi, H. and Teng, J. and Cherouat, A. and Wang, T.},
  booktitle={4th International Conference on Distributed Sensing and Intelligent Systems (ICDSIS 2023)}, 
  title={Large language model-based multi-task UAVs - towards distilled real-time interactive control}, 
  year={2023},
  volume={2023},
  number={},
  pages={114-118},
  abstract={In recent years, unmanned aerial vehicles (UAVs) have gained widespread application due to their advantages such as high durability, low cost, ease of implementation, and flexibility. However, traditional UAV applications often focus on a singular task, requiring redesign and retraining when there are changes in scenarios and objectives. To address this issue, we propose a construction approach for a general UAVs task framework based on Large language models (LLMs), enabling adaptive execution of various UAV tasks in a zero-shot manner. In our methodology, we initiate the extraction of capabilities from black-box LLMs serving as victims, employing a mimicry attack to transfer these abilities into the mimic model CodeT5. Subsequently, fine-tuning is performed using UAV domain data, ensuring that the imitation model is specialized in generating UAV control code. To further compress the model for deployment on UAVs, we employ knowledge distillation techniques, utilizing the fine-tuned imitation model as a teacher to train a high-precision lightweight student model. This generative approach facilitates on-the-edge task execution and auxiliary decision-making. During the execution phase, users can achieve real-time online interaction with UAVs through natural language commands.},
  keywords={},
  doi={10.1049/icp.2024.0472},
  ISSN={},
  month={Dec},}@ARTICLE{11146748,
  author={Kim, Hyoungrae and Kim, Hakil},
  journal={IEEE Access}, 
  title={Data Reliability Testing Framework for Biometric Datasets Using Synthetic Iris and Fingerprint Images Generated via Deep Generative Models}, 
  year={2025},
  volume={13},
  number={},
  pages={155084-155095},
  abstract={This paper presents a comprehensive data reliability testing framework for evaluating synthetic biometric data, addressing privacy concerns in fingerprint and iris recognition systems. This unified and modality-independent methodology establishes six quantitative metrics: randomness, quality similarity, attribute similarity, non-duplication, ID-preservation, and geometric diversity. The framework is implemented through a novel RD-Net architecture consisting of a Random Network for privacy protection and a Deterministic Network for maintaining essential biometric characteristics. Experiments using public datasets (FVC 2002, IITDelhi-Iris, and CASIA-Iris-V4) demonstrate that synthetic samples maintain high dissimilarity from source datasets while preserving their structural properties. The synthetic biometric data generated through the proposed Random Network and Deterministic Network architectures are evaluated using the data reliability testing framework, confirming distribution similarity with real data across all proposed metrics and achieving scores over 80. This approach offers a method for generating and evaluating synthetic biometric data that balances privacy protection with functional validity in biometric system development and testing.},
  keywords={Iris recognition;Reliability;Measurement;Fingerprint recognition;Synthetic data;Data privacy;Testing;Feature extraction;Codes;Biological system modeling;Synthetic iris images;synthetic fingerprints;biometric data evaluation;quality assessment;GANs},
  doi={10.1109/ACCESS.2025.3604894},
  ISSN={2169-3536},
  month={},}@ARTICLE{9311504,
  author={Deja, Kamil and Dubi≈Ñski, Jan and Nowak, Piotr and Wenzel, Sandro and Spurek, Przemys≈Çaw and Trzcinski, Tomasz},
  journal={IEEE Access}, 
  title={End-to-End Sinkhorn Autoencoder With Noise Generator}, 
  year={2021},
  volume={9},
  number={},
  pages={7211-7219},
  abstract={In this work, we propose a novel end-to-end Sinkhorn Autoencoder with a noise generator for efficient data collection simulation. Simulating processes that aim at collecting experimental data is crucial for multiple real-life applications, including nuclear medicine, astronomy, and high energy physics. Contemporary methods, such as Monte Carlo algorithms, provide high-fidelity results at a price of high computational cost. Multiple attempts are taken to reduce this burden, e.g. using generative approaches based on Generative Adversarial Networks or Variational Autoencoders. Although such methods are much faster, they are often unstable in training and do not allow sampling from an entire data distribution. To address these shortcomings, we introduce a novel method dubbed end-to-end Sinkhorn Autoencoder, that leverages the Sinkhorn algorithm to explicitly align distribution of encoded real data examples and generated noise. More precisely, we extend autoencoder architecture by adding a deterministic neural network trained to map noise from a known distribution onto autoencoder latent space representing data distribution. We optimise the entire model jointly. Our method outperforms co mpeting approaches on a challenging dataset of simulation data from Zero Degree Calorimeters of ALICE experiment in LHC. as well as standard benchmarks, such as MNIST and CelebA.},
  keywords={Computational modeling;Noise generators;Training;Neural networks;Decoding;Data models;Standards;Computer simulation;generative modeling;machine learning},
  doi={10.1109/ACCESS.2020.3048622},
  ISSN={2169-3536},
  month={},}@ARTICLE{708434,
  author={Fleishanderl, G. and Friedrich, G.E. and Haselbock, A. and Schreiner, H. and Stumptner, M.},
  journal={IEEE Intelligent Systems and their Applications}, 
  title={Configuring large systems using generative constraint satisfaction}, 
  year={1998},
  volume={13},
  number={4},
  pages={59-68},
  abstract={The authors used generative constraint satisfaction as the basis for Lava, an automated configuration they developed for the complex domain of telephone switching systems. They built Lava using Cocos, their knowledge-based configuration tool.},
  keywords={Costs;Artificial intelligence;Telephony;Switching systems;Manufacturing automation;Switches;Cables;Mass production;Mass customization;Product development},
  doi={10.1109/5254.708434},
  ISSN={2374-9423},
  month={July},}@ARTICLE{10966901,
  author={Valle, Roberto and Buenaposada, Jos√© M. and Baumela, Luis},
  journal={IEEE Access}, 
  title={Reducing Head Pose Estimation Data Set Bias With Synthetic Data}, 
  year={2025},
  volume={13},
  number={},
  pages={73530-73539},
  abstract={Data set bias not only compromises the fairness, accuracy and effectiveness of trained models, but also leads to a lower performance in real-world scenarios compared to the evaluation results obtained with a specific data set. This issue is especially evident in the estimation of head pose, as current data sets suffer from a limited number of images, imbalanced data distributions, the high cost of annotation, and ethical concerns. Synthetic data offers a promising solution to address these challenges, but current semi-synthetic data sets fail to deliver satisfactory results, likely due to the limited realism of the generated faces and the heavily skewed pose distribution. In this paper, we report the existence of data set biases in the most widely used head pose estimation benchmarks, which lead to an optimistic estimation of model performance in real-world scenarios. To mitigate this issue, we create a synthetic image data set using a generative model with explicit control over the head pose. Our experiments demonstrate that incorporating our synthetic images leads to improved generalization and accuracy.},
  keywords={Data models;Faces;Synthetic data;Three-dimensional displays;Pose estimation;Training;Magnetic heads;Solid modeling;Training data;Semantics;Synthetic data;head pose estimation;generative models;data set bias;ethics},
  doi={10.1109/ACCESS.2025.3561506},
  ISSN={2169-3536},
  month={},}@ARTICLE{9837015,
  author={Pham, Minh Tuan and Kim, Jong-Myon and Kim, Cheol Hong},
  journal={IEEE Access}, 
  title={Rolling Bearing Fault Diagnosis Based on Improved GAN and 2-D Representation of Acoustic Emission Signals}, 
  year={2022},
  volume={10},
  number={},
  pages={78056-78069},
  abstract={Bearing fault diagnosis is essential in manufacturing systems to avoid problems such as downtime costs. Convolutional neural network (CNN) models have enabled a new generation of intelligent bearing fault diagnosis methods for smart manufacturing owing to their capability to extract features for 2-dimensional (2D) representations, such as signals represented in the time-frequency domain. Nevertheless, the cost and time required to collect sufficient training data tend to result in a lack of data and data imbalance in real fault diagnosis scenarios. This inevitable consequence leads to a high misclassification rate in conventional CNN models. In this study, to address this problem, we propose a novel effective generative adversarial network (GAN)-based method for rolling bearing fault diagnosis in early-stage and low rotational speeds based on data enhancement, which uses acoustic emission (AE) as a monitoring signal. In the proposed approach, generator, discriminator, and fault classifier models are trained simultaneously with the proposed strategy for updating parameters to avoid the gradient vanishing problem and outperform conventional methods. The fault classifier was developed based on CNN models which are compatible with 2-D signal representations represented by a constant-Q transform. The results of experiments conducted with unbalanced compound fault datasets verify the capabilities of the proposed method in various diagnosis scenarios compared with traditional methods, including SVM, CNN, and DCGAN models.},
  keywords={Fault diagnosis;Generative adversarial networks;Feature extraction;Convolutional neural networks;Training;Monitoring;Generators;Acoustic emission;bearing fault diagnosis;convolutional neural network;GAN;unbalance data},
  doi={10.1109/ACCESS.2022.3193244},
  ISSN={2169-3536},
  month={},}@ARTICLE{9388687,
  author={Liu, Changchun and Tang, Dunbing and Zhu, Haihua and Nie, Qingwei},
  journal={IEEE Access}, 
  title={A Novel Predictive Maintenance Method Based on Deep Adversarial Learning in the Intelligent Manufacturing System}, 
  year={2021},
  volume={9},
  number={},
  pages={49557-49575},
  abstract={Along with the number and the functional complexity of machines increase in the intelligent manufacturing system, the probability of faults will increase, which may lead to huge economic losses. Traditional passive or regular maintenance methods of solving the faults have the problems of low efficiency and huge resource consumption. Besides, traditional maintenance methods mostly contain single model, so all the prognostics and maintenance tasks of the intelligent manufacturing system can hardly be addressed at the same time. Therefore, this paper proposes a novel predictive maintenance (PDM) method based on the improved deep adversarial learning (LSTM-GAN). The long-short-term memory (LSTM) network can solve the disadvantage of vanishing gradients and the mode collapse from the generative adversarial network (GAN). The method can not only avoid the mode collapse of GAN but also realize the self-detection of abnormal data. Meanwhile, the predictive maintenance model includes two prediction models and a maintenance decision model. The prediction models can predict the state of the machine and the fault of the machine in advance. Then the maintenance decision model will arrange maintenance personnel and offer a plan of maintenance. Finally, a case study about predictive maintenance using LSTM-GAN in the intelligent manufacturing system is presented. The fault prediction accuracy of LTSM-GAN is as high as 99.68%. With the comparison between LSTM-GAN and other traditional methods, LSTM-GAN shows priority both in accuracy and efficiency. Moreover, the proposed PDM can reduce maintenance costs and downtime so that the life of machines in the intelligent manufacturing system will extend.},
  keywords={Generative adversarial networks;Intelligent manufacturing systems;Gallium nitride;Predictive maintenance;Predictive models;Manufacturing;Reliability;Predictive maintenance;deep adversarial learning;LSTM-GAN;intelligent manufacturing system},
  doi={10.1109/ACCESS.2021.3069256},
  ISSN={2169-3536},
  month={},}@ARTICLE{8684827,
  author={Yuan, Liuchun and Ruan, Congcong and Hu, Haifeng and Chen, Dihu},
  journal={IEEE Access}, 
  title={Image Inpainting Based on Patch-GANs}, 
  year={2019},
  volume={7},
  number={},
  pages={46411-46421},
  abstract={In this paper, we propose a novel image inpainting framework that takes advantage of holistic and structure information of the broken input image. Different from the existing models that complete the broken pictures using the holistic features of the input, our method adopts Patch-generative adversarial networks (GANs) equipped with multi-scale discriminators and edge process function to extract holistic, structured features, and restore the damaged images. After pre-training our Patch-GANs, the proposed network encourages our generator to find the best encoding of the broken input images in the latent space using a combination of a reconstruction loss, an edge loss, and global and local guidance losses. Besides, the reconstruction and the global guidance losses ensure the pixel reliability of the generated images, and the remaining losses guarantee the contents consistency between the local and global parts. The qualitative and quantitative experiments on multiple public datasets show that our approach has the ability to produce more realistic images compared with some existing methods, demonstrating the effectiveness and superiority of our method.},
  keywords={Generators;Image edge detection;Image reconstruction;Image restoration;Generative adversarial networks;Image coding;Task analysis;Image inpainting;Patch-GANs;multi-scale discriminators},
  doi={10.1109/ACCESS.2019.2909553},
  ISSN={2169-3536},
  month={},}@ARTICLE{9200510,
  author={Xiao, Qingguo and Li, Guangyao and Chen, Qiaochuan},
  journal={IEEE Access}, 
  title={Image Outpainting: Hallucinating Beyond the Image}, 
  year={2020},
  volume={8},
  number={},
  pages={173576-173583},
  abstract={Image inpainting is a technique that aims to fill in the missing regions with visually plausible content. However, an opposite idea, which is painting outside images, receives little work. In this study, we investigate the issue of image outpainting. Considering that the model needs better prediction ability as there is less neighboring information in image outpainting, the study proposes a novel image outpainting architecture that can obtain both deep model performance and detailed information. To fully take advantage of residual learning, dense residual (DR) learning is proposed and the image generative network is built on DR. To avoid losing subtle information caused by downsampling in encoder-decoder, shortcuts are added for transferring previous knowledge. Different from vanilla U-Net, we propose a skip method of the semi-complete form. Experimental results show that the proposed method achieves excellent performance.},
  keywords={Generative adversarial networks;Predictive models;Extrapolation;Decoding;Painting;Task analysis;Gallium nitride;Image outpainting;residual learning;adversarial learning;generation model},
  doi={10.1109/ACCESS.2020.3024861},
  ISSN={2169-3536},
  month={},}@ARTICLE{9206031,
  author={Wen, Shuhuan and Tian, Wenbo and Zhang, Hong and Fan, Shaokang and Zhou, Nannan and Li, Xiongfei},
  journal={IEEE Access}, 
  title={Semantic Segmentation Using a GAN and a Weakly Supervised Method Based on Deep Transfer Learning}, 
  year={2020},
  volume={8},
  number={},
  pages={176480-176494},
  abstract={Semantic image segmentation is of crucial importance to many applications, such as autonomous driving, robot vision, and scene understanding. However, the border of a segmented image tends to be rough, and the labeling process is tedious and labor-intensive. Therefore, this study is the first proposing to use a deep generative adversarial network (GAN) with double-layered upsampling based on max-pooling indexed deconvolution. Our proposed upsampling method replaces the bilinear interpolation upsampling method; i.e., we fuse the deep deconvolution method by saving the indices of relative locations of the max weights computed during pooling. Combined with the deep GAN, our upsampling method can improve the extraction of low-resolution features, and compensate for the loss of the image size. To further reduce the whole network's dependence on labeled datasets, a weakly supervised feedback method is proposed. The unlabeled data can improve the generalization ability of the model. Considering the generalization to unseen image domains, we introduce transfer learning based on a deep GAN and a weakly supervised method. The segmentation model using the trained data in the source domain can obtain good segmentation in the target domain using transfer learning. Extensive experiments in various domains demonstrate the advantages of the proposed method compared to the generalization ability of semantic segmentation. This method also significantly decreases the dependence on labeled data and ensures the network accuracy.},
  keywords={Semantics;Image segmentation;Gallium nitride;Generative adversarial networks;Object segmentation;Deconvolution;Feature extraction;Semantic segmentation;GAN;deep transfer learning},
  doi={10.1109/ACCESS.2020.3026684},
  ISSN={2169-3536},
  month={},}@ARTICLE{10156812,
  author={Wang, Huazhe and Ma, Li},
  journal={IEEE Access}, 
  title={Image Generation and Recognition Technology Based on Attention Residual GAN}, 
  year={2023},
  volume={11},
  number={},
  pages={61855-61865},
  abstract={In accordance with the concept of game antagonism, Generative Adversarial Network (GAN) is a popular model in current image generation technology. However, GAN has problems such as unstable training and difficult convergence, which seriously affect the effectiveness of input feature extraction and image recognition. The study introduces residual network structure and self attention mechanism to calculate the weight parameters of features, and then guides image generation through image label information. The improved GAN model classifier is applied to image recognition. The final experimental data shows that the Fr√©chet Inception Distance (FID) values of the iGAN in facial expressions and behavioral actions are 77.68 and 176.84, respectively, which are closer to the distribution of real image data. In behavioral image recognition, the accuracy of the model is 96.8%, and the required time is 30 seconds. In facial expression recognition, the accuracy and recognition time of the model are 90.1% and 24 seconds, respectively. This indicates that it can generate high-quality images, has stronger feature extraction capabilities, and has higher recognition efficiency. This model provides a new technical reference for the further improvement of image processing technology, and has certain application potential and value.},
  keywords={Feature extraction;Generative adversarial networks;Image recognition;Generators;Image synthesis;Training;Image processing;Attention mechanism;residual network;GAN;image generation;identification technology},
  doi={10.1109/ACCESS.2023.3287854},
  ISSN={2169-3536},
  month={},}@ARTICLE{10086509,
  author={Pahk, Jinu and Shim, Jungseok and Baek, Minhyeok and Lim, Yongseob and Choi, Gyeungho},
  journal={IEEE Access}, 
  title={Effects of Sim2Real Image Translation via DCLGAN on Lane Keeping Assist System in CARLA Simulator}, 
  year={2023},
  volume={11},
  number={},
  pages={33915-33927},
  abstract={Autonomous vehicle (AV) simulation using a virtual environment has the advantage of being able to test algorithms in various scenarios with reduced resources. However, there may exist a visual gap between the virtual environment and the real-world. In this paper, in order to mitigate this gap, we trained Dual Contrastive Learning Generative Adversarial Networks (DCLGAN) to realistically convert the image of the CARLA simulator and then evaluated the effect of the Sim2Real conversion focusing on the lane keeping assist system (LKAS). Moreover, in order to avoid the case where the lane is translated distortedly by DCLGAN, we found the optimal training hyperparameters using feature similarity (FSIM). After training, we built a system that connected the CARLA simulator with DCLGAN and AV in real-time. As for the result, we collected data and analyzed them using the following four methods. First, image reality was measured with Fr√©chet Inception Distance (FID), which we quantitatively verified to reflect the lane characteristics. The CARLA images that passed through DCLGAN had smaller FID values than the original images. Second, lane segmentation accuracy through ENet-SAD was improved by DCLGAN. Third, in the curved route, the case of using DCLGAN drove closer to the center of the lane and had a high success rate. Lastly, in the straight route, DCLGAN improved lane restoring ability after deviating from the center of the lane as much as in reality. Consequently, it convinced that the proposed method could be applicable to mitigate the gap of simulation toward real-world.},
  keywords={Autonomous vehicles;Generative adversarial networks;Cameras;Mathematical models;Global Positioning System;Intelligent vehicles;Lane detection;Software engineering;Intelligent vehicles;vehicle driving;autonomous vehicles;lane keeping assist systems;lane detection;GAN;DCLGAN;FID;autonomous vehicle simulation;CARLA;software-in-the-loop},
  doi={10.1109/ACCESS.2023.3262991},
  ISSN={2169-3536},
  month={},}@ARTICLE{10128113,
  author={Zarzycki, Krzysztof and Chaber, Patryk and Cabaj, Krzysztof and ≈Åawry≈Ñczuk, Maciej and Marusak, Piotr and Nebeluk, Robert and Plamowski, Sebastian and Wojtulewicz, Andrzej},
  journal={IEEE Access}, 
  title={GAN Neural Networks Architectures for Testing Process Control Industrial Network Against Cyber-Attacks}, 
  year={2023},
  volume={11},
  number={},
  pages={49587-49600},
  abstract={Protection of computer systems and networks against malicious attacks is particularly important in industrial networked control systems. A successful cyber-attack may cause significant economic losses or even destruction of controlled processes. Therefore, it is necessary to test the vulnerability of process control industrial networks against possible cyber-attacks. Three approaches employing Generative Adversarial Networks (GANs) to generate fake Modbus frames have been proposed in this work, tested for an industrial process control network and compared with the classical approach known from the literature. In the first approach, one GAN generates one byte of a message frame. In the next two approaches, expert knowledge about frame structure is used to generate a part of a message frame, while the remaining parts are generated using single or multiple GANs. The classical single-GAN approach is the worst one. The proposed one-GAN-per-byte approach generates significantly more correct message frames than the classical method. Moreover, all the generated fake frames have been correct in two of the proposed approaches, i.e., single GAN for selected bytes and multiple GANs for selected bytes methods. Finally, we describe the effect of cyber-attacks on the operation of the controlled process.},
  keywords={Generative adversarial networks;Protocols;Process control;Cyberattack;Testing;Neural networks;Fuzzing;GAN neural networks;cyber-security;cyber-attacks;industrial network},
  doi={10.1109/ACCESS.2023.3277250},
  ISSN={2169-3536},
  month={},}@ARTICLE{10520890,
  author={Markham, Reuben P. and L√≥pez, Juan M. Esp√≠n and Nieto-Hidalgo, Mario and Tapia, Juan E.},
  journal={IEEE Access}, 
  title={Open-Set: ID Card Presentation Attack Detection Using Neural Style Transfer}, 
  year={2024},
  volume={12},
  number={},
  pages={68573-68585},
  abstract={The accurate detection of ID card Presentation Attacks (PA) is becoming increasingly important due to the rising number of online/remote services that require the presentation of digital photographs of ID cards for digital onboarding or authentication. Furthermore, cybercriminals are continuously searching for innovative ways to fool authentication systems to gain unauthorized access to these services. Although advances in neural network design and training have pushed image classification to the state of the art, one of the main challenges faced by the development of fraud detection systems is the curation of representative datasets for training and evaluation. The handcrafted creation of representative presentation attack samples often requires expertise and is very time-consuming, thus an automatic process of obtaining high-quality data is highly desirable. This work explores ID card Presentation Attack Instruments (PAI) in order to improve the generation of samples with four Generative Adversarial Networks (GANs) based image translation models and analyses the effectiveness of the generated data for training fraud detection systems. Using open-source data, we show that synthetic attack presentations are an adequate complement for additional real attack presentations, where we obtain an EER performance increase of 0.63 % points for print attacks and a loss of 0.29 % for screen capture attacks.},
  keywords={Training;Task analysis;Generative adversarial networks;Neural networks;Generators;Databases;Feature extraction;Biometrics (access control);Identity-based encryption;Biometrics;synthetic images;remote verification;presentation attack detection;ID card},
  doi={10.1109/ACCESS.2024.3397190},
  ISSN={2169-3536},
  month={},}@ARTICLE{10288431,
  author={Nishimaki, Kei and Ikuta, Kumpei and Fujiyama, Shingo and Oishi, Kenichi and Iyatomi, Hitoshi},
  journal={IEEE Access}, 
  title={PCSS: Skull Stripping With Posture Correction From 3D Brain MRI for Diverse Imaging Environment}, 
  year={2023},
  volume={11},
  number={},
  pages={116903-116918},
  abstract={A subject‚Äôs head position in magnetic resonance imaging (MRI) scanners can vary significantly with the imaging environment and disease status. This variation is known to influence the accuracy of skull stripping (SS), a method to extract the brain region from the whole head image, which is an essential initial step to attain high performance in various neuroimaging applications. However, existing SS methods have failed to accommodate this wide range of variation. To achieve accurate, consistent, and fast SS, we introduce a novel two-stage methodology that we call posture correction skull stripping (PCSS): the first involves adjusting the subject‚Äôs head angle and position, and the second involves the actual SS to generate the brain mask. PCSS also incorporates various machine learning techniques, such as a weighted loss function, adversarial training from generative adversarial networks, and ensemble methods. Thorough evaluations conducted on five publicly accessible datasets show that the PCSS method outperforms current state-of-the-art techniques in SS performance, achieving an average increase of 1.38 points on the Dice score and demonstrating the contributions of each PCSS component technique.},
  keywords={Training;Magnetic resonance imaging;Head;Three-dimensional displays;Neck;Generative adversarial networks;Diseases;Brain modeling;Skull stripping;brain extraction;MRI;U-Net;GAN;ADNI;CC-12;LPBA40;NFBS;OASIS},
  doi={10.1109/ACCESS.2023.3326342},
  ISSN={2169-3536},
  month={},}@ARTICLE{9110913,
  author={Huang, Shaonian and Zhou, Hongjing and Liu, Yao and Chen, Rongyuan},
  journal={IEEE Access}, 
  title={High-Resolution Crowd Density Maps Generation With Multi-Scale Fusion Conditional GAN}, 
  year={2020},
  volume={8},
  number={},
  pages={108072-108087},
  abstract={The major challenges for density maps estimation and accurate counting stem from the large-scale variations, serious occlusions, and perspective distortions. Existing methods generally suffer from the blurred density maps, which are caused by average convolution kernel, and the ineffective estimation across different crowd scenes. In this paper, we propose a multi-scale fusion conditional generative adversarial network (MFC-GAN) that can generate high-resolution and high-quality density maps. The fusion module of MFC-GAN is embedded in a multi-scale generator and discriminator architecture with a novel adversarial loss, which is designed to guide high-resolution density maps generation. In order to address the problem of scale variation, we further propose a bidirectional fusion module. It combines deep global semantic features and shallow local information by leveraging feature maps presented in different layers of the generator. Furthermore, in order to increase the effectiveness of the multi-scale fusion, we design a cross-attention fusion module, which weights the multi-scale fused feature and learns context-aware feature maps for generating high quality density maps. The experiments on four challenging datasets show the effectiveness, feasibility and robustness of the proposed MFC-GAN.},
  keywords={Feature extraction;Estimation;Generative adversarial networks;Generators;Gallium nitride;Task analysis;Training;Crowd counting;bidirectional fusion;cross-attention fusion;conditional GAN},
  doi={10.1109/ACCESS.2020.3000741},
  ISSN={2169-3536},
  month={},}@ARTICLE{10348561,
  author={Laishram, Lamyanba and Shaheryar, Muhammad and Lee, Jong Taek and Jung, Soon Ki},
  journal={IEEE Access}, 
  title={High-Quality Face Caricature via Style Translation}, 
  year={2023},
  volume={11},
  number={},
  pages={138882-138896},
  abstract={Caricature is an exaggerated form of artistic portraiture that accentuates unique yet subtle characteristics of human faces. Recently, advancements in deep end-to-end techniques have yielded encouraging outcomes in capturing both style and elevated exaggerations in creating face caricatures. Most of these approaches tend to produce cartoon-like results that could be more practical for real-world applications. In this study, we proposed a high-quality, unpaired face caricature method that is appropriate for use in the real world and uses computer vision techniques and GAN models. We attain the exaggeration of facial features and the stylization of appearance through a two-step process: Face caricature generation and face caricature projection. The face caricature generation step creates new caricature face datasets from real images and trains a generative model using the real and newly created caricature datasets. The Face caricature projection employs an encoder trained with real and caricature faces with the pre-trained generator to project real and caricature faces. Using the encoder and generator‚Äôs latent space, we perform an incremental facial exaggeration from the real image to the caricature faces. Our projection preserves the facial identity, attributes, and expressions from the input image. Also, it accounts for facial occlusions, such as reading glasses or sunglasses, to enhance the robustness of our model. Furthermore, we comprehensively compared our approach with various state-of-the-art face caricature methods, highlighting our process‚Äôs distinctiveness and exceptional realism.},
  keywords={Facial features;Visualization;Training;Generators;Generative adversarial networks;Shape measurement;Image analysis;Face caricature;facial exaggeration;image translation;GAN},
  doi={10.1109/ACCESS.2023.3340788},
  ISSN={2169-3536},
  month={},}@ARTICLE{9139251,
  author={Yu, Cheng and Wang, Wenmin and Yan, Jianhao},
  journal={IEEE Access}, 
  title={Self-Supervised Animation Synthesis Through Adversarial Training}, 
  year={2020},
  volume={8},
  number={},
  pages={128140-128151},
  abstract={In this paper, we propose a novel deep generative model for image animation synthesis. Based on self-supervised learning and adversarial training, the model can find labeling rules and mark them without origin sample labels. In addition, our model can generate continuous changing images based on the automatically labels learning. The labels learning model can be implemented on a large number of out-of-order samples to generate two types of pseudo-labels, discrete labels and continuous labels. The discrete labels can generate different animation clips, and the continuous labels can generate different frames in the same clip. Embedding pseudo-labels with latent variables into latent space, our model discovers regularities and features from latent space. Animation features are fully characterized by the pseudo-labels learned from the self-supervised module. Using upgraded adversarial training steps, the model learns to map animation features to pseudo-labels from the latent space and then organizes pseudo-labels embedding into latent variables to generate animation features. By adapting dimensions of pseudo-labels, we match fine features with latent variables. Such as using the two types of pseudo-labels, our model can also generate different styles of videos from the same dataset. The specific implementation tricks depend on the different pseudo-label dimensions and the number of pseudo-label dimensions. Comparing the results of our model with other state-of-the-art approaches, the model does not use complicated components, such as 3D convolution layers and recurrent neural networks. Our experimental results show that an appropriate number of the pseudo-label dimensions can better characterize animation features. In this case, an animation which reached human-level perception can be synthesized. The performance of animation synthesis has reached relatively superior results on several challenging datasets.},
  keywords={Animation;Training;Videos;Generative adversarial networks;Task analysis;Image synthesis;Gallium nitride;Self-supervised learning;animation synthesis;pseudo-label;adversarial training},
  doi={10.1109/ACCESS.2020.3008523},
  ISSN={2169-3536},
  month={},}@ARTICLE{10438422,
  author={Diamantis, Dimitrios E. and Gatoula, Panagiota and Koulaouzidis, Anastasios and Iakovidis, Dimitris K.},
  journal={IEEE Access}, 
  title={This Intestine Does Not Exist: Multiscale Residual Variational Autoencoder for Realistic Wireless Capsule Endoscopy Image Generation}, 
  year={2024},
  volume={12},
  number={},
  pages={25668-25683},
  abstract={Medical image synthesis has emerged as a promising solution to address the limited availability of annotated medical data needed for training machine learning algorithms in the context of image-based Clinical Decision Support (CDS) systems. To this end, Generative Adversarial Networks (GANs) have been mainly applied to support the algorithm training process by generating synthetic images for data augmentation. However, in the field of Wireless Capsule Endoscopy (WCE), the limited content diversity and size of existing publicly available annotated datasets adversely affect both the training stability and synthesis performance of GANs. In this paper a novel Variational Autoencoder (VAE) architecture is proposed for WCE image synthesis, namely ‚ÄòThis Intestine Does not Exist‚Äô (TIDE). This is the first VAE architecture comprising multiscale feature extraction convolutional blocks and residual connections. Its advantage is that it enables the generation of high-quality and diverse datasets even with a limited number of training images. Contrary to the current approaches, which are oriented towards the augmentation of the available datasets, this study demonstrates that using TIDE, real WCE datasets can be fully substituted by artificially generated ones, without compromising classification performance of CDS. It performs a spherical experimental evaluation study that covers both quantitative and qualitative aspects, including a user evaluation study performed by WCE specialists, which validate from a medical viewpoint that both the normal and abnormal WCE images synthesized by TIDE are sufficiently realistic. The quantitative results obtained by comparative experiments validate that the proposed architecture outperforms the state-of-the-art.},
  keywords={Image synthesis;Training;Endoscopes;Lesions;Magnetic resonance imaging;Generative adversarial networks;Decision support systems;Clinical diagnosis;Gastroenterology;Gastrointestinal tract;Encoding;Biomedical monitoring;Clinical decision support systems;endoscopy;gastrointestinal tract;image synthesis;variational autoencoders},
  doi={10.1109/ACCESS.2024.3366801},
  ISSN={2169-3536},
  month={},}@ARTICLE{10478899,
  author={Vieira, Diogo Fr√≥is and Raposo, Afonso and Azeitona, Ant√≥nio and Afonso, Manya V. and Pedro, Lu√≠s Mendes and Sanches, J.},
  journal={IEEE Access}, 
  title={Ultrasound Despeckling With GANs and Cross Modality Transfer Learning}, 
  year={2024},
  volume={12},
  number={},
  pages={45811-45823},
  abstract={Ultrasound images are corrupted by a type of signal-dependent noise, called speckle, difficult to remove or attenuate with the classical denoising methods. On the contrary, structural Magnetic Resonance Imaging (MRI) is usually a high resolution low noise image modality that involves complex and expensive equipment and long acquisition times. Herein, a deep learning-based pipeline for speckle removal in B-mode ultrasound medical images, based on cross modality transfer learning, is proposed. The architecture of the system is based on a pix2pix Generative Adversarial Network (GAN),  $D$ , able to denoise real B-mode ultrasound images by generating synthetic MRI-like versions by an image-to-image translation manner. The GAN  $D$  was trained using two classes of image pairs: i) a set consisting of authentic MRI images paired with synthetic ultrasound images generated through a dedicated ultrasound simulator based on another GAN,  $S$ , designed specifically for this purpose, and ii) a set comprising natural images paired with their corresponding noisy counterparts corrupted by Rayleigh noise. The denoising GAN proposed in this study demonstrates effective removal of speckle noise from B-mode ultrasound images. It successfully preserves the integrity of anatomical structures and avoids reconstruction artifacts, producing outputs that closely resemble typical MRI images. Comparative tests against other state-of-the-art methods reveal superior performance of the proposed denoising strategy across various reconstruction quality metrics.},
  keywords={Generative adversarial networks;Magnetic resonance imaging;Noise reduction;Speckle;Training;Ultrasonic imaging;Three-dimensional displays;Ultrasonic imaging;Deep learning;Modal analysis;Ultrasound;denoising;deep learning;GANs;modality translation},
  doi={10.1109/ACCESS.2024.3381630},
  ISSN={2169-3536},
  month={},}@ARTICLE{9661297,
  author={Maldonado-Romo, Javier and Aldape-P&#x00E9;rez, Mario and Rodr&#x00ED;guez-Molina, Alejandro},
  journal={IEEE Access}, 
  title={Analysis of Depth and Semantic Mask for Perceiving a Physical Environment Using Virtual Samples Generated by a GAN}, 
  year={2022},
  volume={10},
  number={},
  pages={5595-5607},
  abstract={Micro aerial vehicles (MAVs) can make explorations in 3D environments using technologies capable of perceiving the environment to map and estimate the location of objects that could cause collisions, such as Simultaneous Localization and Mapping (SLAM). Nevertheless, the agent needs to move during the environment mapping, reducing the flying time to employ additional activities. It has to be noted that adding more devices (sensors) to MAVs implies more power consumption. Since more energy to perform tasks is required, growing the dimensions of MAVs limits the flying time. Contrarily, Generative Adversarial Networks (GAN) have demonstrated the usefulness of creating images from one domain to another, but the GAN domain changes require a large number of samples. Therefore, an interoperability coefficient is employed to determine a minimum number of samples to connect the different domains. In order to prove the coefficient, the performance to estimate the depth and semantic mask between authentic and virtual samples with the number limited of samples is analyzed. Consequently, an RGB-D sensor can be replaced by a few samples of a real scenario based on GANs. Although GAN allows creating images with depth and semantic mask information, there is an additional problem to be tackled: the presence of intrinsic noise, where a simple GAN architecture is not enough. In this proposal, the performance of this solution against a physical RGB-D sensor (Microsoft Kinect V1) and other state-of-the-art approaches is compared. Experimental results allow us to affirm that this proposal is a viable option to replace a physical RGB-D sensor with limited information.},
  keywords={Generative adversarial networks;Sensors;Semantics;Cost function;Generators;Three-dimensional displays;Navigation;Computer vision;perception environment;3D mapping;machine learning},
  doi={10.1109/ACCESS.2021.3137797},
  ISSN={2169-3536},
  month={},}
