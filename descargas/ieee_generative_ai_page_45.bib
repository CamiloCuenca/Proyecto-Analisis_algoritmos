@BOOK{10769305,
  author={Hwang, Yoon Hyup and Burtch, Nicholas C.},
  booktitle={Machine Learning and Generative AI for Marketing: Take your data-driven marketing strategies to the next level using Python},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Start transforming your data-driven marketing strategies and increasing customer engagement. Learn how to create compelling marketing content using advanced gen AI techniques and stay in touch with the future AI ML landscape. Purchase of the print or Kindle book includes a free eBook in PDF formatKey FeaturesEnhance customer engagement and personalization through predictive analytics and advanced segmentation techniquesCombine Python programming with the latest advancements in generative AI to create marketing content and address real-world marketing challengesUnderstand cutting-edge AI concepts and their responsible use in marketingBook DescriptionIn the dynamic world of marketing, the integration of artificial intelligence (AI) and machine learning (ML) is no longer just an advantage—it's a necessity. Moreover, the rise of generative AI (GenAI) helps with the creation of highly personalized, engaging content that resonates with the target audience. This book provides a comprehensive toolkit for harnessing the power of GenAI to craft marketing strategies that not only predict customer behaviors but also captivate and convert, leading to improved cost per acquisition, boosted conversion rates, and increased net sales. Starting with the basics of Python for data analysis and progressing to sophisticated ML and GenAI models, this book is your comprehensive guide to understanding and applying AI to enhance marketing strategies. Through engaging content & hands-on examples, you'll learn how to harness the capabilities of AI to unlock deep insights into customer behaviors, craft personalized marketing messages, and drive significant business growth. Additionally, you'll explore the ethical implications of AI, ensuring that your marketing strategies are not only effective but also responsible and compliant with current standards By the conclusion of this book, you'll be equipped to design, launch, and manage marketing campaigns that are not only successful but also cutting-edge.What you will learnMaster key marketing KPIs with advanced computational techniquesUse explanatory data analysis to drive marketing decisionsLeverage ML models to predict customer behaviors, engagement levels, and customer lifetime valueEnhance customer segmentation with ML and develop highly personalized marketing campaignsDesign and execute effective A/B tests to optimize your marketing decisionsApply natural language processing (NLP) to analyze customer feedback and sentimentsIntegrate ethical AI practices to maintain privacy in data-driven marketing strategiesWho this book is forThis book targets a diverse group of professionals: Data scientists and analysts in the marketing domain looking to apply advanced AI ML techniques to solve real-world marketing challenges Machine learning engineers and software developers aiming to build or integrate AI-driven tools and applications for marketing purposes Marketing professionals, business leaders, and entrepreneurs who must understand the impact of AI on marketing Reader are presumed to have a foundational proficiency in Python and a basic to intermediate grasp of ML principles and data science methodologies},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835889411},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10769305},}@ARTICLE{10217209,
  author={Wang, Xiaojie and Zhu, Hailin and Ning, Zhaolong and Guo, Lei and Zhang, Yan},
  journal={IEEE Communications Surveys & Tutorials}, 
  title={Blockchain Intelligence for Internet of Vehicles: Challenges and Solutions}, 
  year={2023},
  volume={25},
  number={4},
  pages={2325-2355},
  abstract={With the development of communication and networking technologies, the Internet of Vehicles (IoV) has become the foundation of smart transportation. The development of blockchain and Machine Learning (ML) has contributed to the pervasiveness of the IoV, and they can effectively address the current issues of decentralisation, cyber security and data privacy in the IoV. In this article, blockchain and ML in the IoV are both reviewed, and corresponding technologies to support blockchain intelligence in the IoV are summarized. Importantly, blockchain intelligence is proposed as a key to integrate blockchain and ML, combining the advantages of both to drive the rapid development of the IoV. We discuss general frameworks, issuses, requirements and advantages for the implementation of blockchain intelligence in the IoV. Driven by its advantages, we summarize solutions of blockchain intelligence in the IoV from four aspects, including reliable interaction, network security and data privacy, trustworthy environment and scalability. Finally, a summary of current unresolved issues and challenges of blockchain intelligence in the IoV is presented, which provides guidelines for the future development of the IoV.},
  keywords={Blockchains;Surveys;Security;Data privacy;Artificial intelligence;Servers;Privacy;Internet of Vehicles;blockchain intelligence;blockchain;machine learning and security},
  doi={10.1109/COMST.2023.3305312},
  ISSN={1553-877X},
  month={Fourthquarter},}@INPROCEEDINGS{10391517,
  author={Anderson, Neil and McGowan, Aidan and Galway, Leo and Hanna, Philip and Collins, Matthew and Cutting, David},
  booktitle={2023 7th International Symposium on Innovative Approaches in Smart Technologies (ISAS)}, 
  title={Implementing Generative AI and Large Language Models in Education}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The recent advancements in Generative AI have been highlighted by the emergence of Large Language Models (LLMs) like ChatGPT. We track this evolution from the initial recurrent neural networks to the development of architectures like Transformers and Generative Pre-trained Transformers (GPT). ChatGPT, with its impressive ability to comprehend, process, and produce natural language, has piqued the interest of educators, students, and institutions within the education sector through its creation of high-quality textual responses.This marks the beginning of a new era in educational possibilities: we emphasize the beneficial effects of ChatGPT in learning environments, noting its utility in programming assistance, its clarity in concept explanation, and its role in enhancing automated learning processes. We also recognize potential drawbacks, including the risks of over-reliance, plagiarism, and the inherent constraints of these models in tackling mathematical and linguistic problem-solving tasks.In exploring the Paradox of Automation, we examine the implications of an over-reliance on AI in education. We seek to understand the importance of preserving critical thinking skills and ensuring that technology serves as a tool for augmenting human capabilities rather than supplanting them. Our analysis acknowledges that, while AI, including ChatGPT, can assist in content generation and problem-solving, it is essential for students to cultivate their abilities in analytical thinking, content verification, and error correction.},
  keywords={Recurrent neural networks;Generative AI;Education;Computer architecture;Chatbots;Transformers;Software},
  doi={10.1109/ISAS60782.2023.10391517},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10461408,
  author={Gudepu, Venkateswarlu and Chirumamilla, Bhargav and Reddy Chintapalli, Venkatarami and Castoldi, Piero and Valcarenghi, Luca and Kondepu, Koteswararao},
  booktitle={European Wireless 2023; 28th European Wireless Conference}, 
  title={Generative Adversarial Networks-Based AI/ML Model Adaptive Retraining for Beyond 5G Networks}, 
  year={2023},
  volume={},
  number={},
  pages={224-229},
  abstract={Beyond fifth-generation (B5G) networks aim to support high data rates, low-latency applications, and massive machine communications. Artificial Intelligence (AI) and Machine Learning (ML) can help to improve B5G network performance and efficiency. However, dynamic service demands of B5G cause AI/ML performance degradation, resulting in violations of Service Level Agreements (SLA), over- or under-provisioning of resources, etc. Retraining is essential to address the performance degradation of the AI/ML models. Existing threshold and periodic retraining approaches have potential disadvantages, such as SLA violations and inefficient resource utilization for setting a threshold parameter in a dynamic environment. This paper presents a novel algorithm that predicts when to retrain AI/ML models using the generative adversarial networks (GANs) architecture. The proposed predictive approach is evaluated for a Quality of Service (QoS) prediction use case on O-RAN Software Community (OSC) platform and compared to the predictive approach based on the classifier and the threshold approach. The results show that the proposed predictive approach outperforms both the classifierbased predictive and threshold approaches.},
  keywords={},
  doi={},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10653035,
  author={Tokita, Sayaka},
  booktitle={2024 Portland International Conference on Management of Engineering and Technology (PICMET)}, 
  title={Content Creation by Generative AI and Operator Perception A Focus on Operator's Profit-driven Motivation}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={In recent years, the widespread adoption of generative AI, exemplified by platforms like ChatGPT and Google Bard, has made AI more approachable. This technology allows users to create content seamlessly through prompt inputs, eliminating the need for specialized skills. However, prevailing research indicates a general tendency among individuals to express negative sentiments toward AI-generated content, often attributed to the perceived absence of intentionality in AI. Despite this, contemporary generative AI, an integral part of our daily lives, inherently involves human operators. By explicitly recognizing the human inputting prompts, there exists a potential for perceiving the operator's intentionality. This raises the question of whether the evaluation of AI-generated content might undergo a shift if such intentionality is discerned. This study delves into the investigation of operator intentionality perception. In Study 1, we explore how content evaluation varies when indicating whether it was generated by AI. Study 2 investigates the perception of the profit-driven motives of content creators when AI is utilized in the creation process compared to when it is not.},
  keywords={Generative AI;Chatbots;Internet},
  doi={10.23919/PICMET64035.2024.10653035},
  ISSN={2159-5100},
  month={Aug},}@INPROCEEDINGS{10722592,
  author={Hemasri, Chettim Chetty and Vijayalakshmi, M. and Jyotheesh, Vootukuru},
  booktitle={2024 5th International Conference on Smart Electronics and Communication (ICOSEC)}, 
  title={Redefining Medicine: The Power of Generative AI in Modern Healthcare}, 
  year={2024},
  volume={},
  number={},
  pages={1293-1298},
  abstract={This research study examines how generative models, such as large language models (LLMs) and other forms of artificial intelligence (GAI) and other generative models, are revolutionizing healthcare. GAI technologies, such as GPT-based systems and DALL-E, and specialized medical LLMs, such as Med-PaLM and BioGPT, offer cutting-edge solutions for the development of drugs, imaging in medicine, healthcare for patients, and customized treatment planning. These advanced AI models enable the generation of synthetic medical data, facilitating research and innovation while safeguarding patient privacy. GAI enhances diagnostic accuracy, accelerates drug discovery, and aids clinical decision-making by simulating complex medical phenomena and generating realistic datasets for training and validation. These advanced AI models have been assessed using strong performance parameters, demonstrating their primary impact on diagnostic accuracy, drug discovery, and clinical decision-making. Applications range from creating synthetic medical images and predictive models of disease progression to developing tailored therapeutic strategies and optimizing clinical trials. Despite its transformative potential, integrating GAI into healthcare systems presents challenges, including ensuring data security, addressing ethical concerns, and maintaining regulatory compliance. This study provides a comprehensive overview of the advantages, uses, and necessary ethical and technological issues surrounding GAI healthcare today. The potential of GAI and LLMs to transform patient outcomes and promote healthcare is highlighted in this paper through an examination of real-world case studies and future research possibilities.},
  keywords={Training;Ethics;Technological innovation;Accuracy;Biological system modeling;Decision making;Medical services;Transforms;Drug discovery;Medical diagnostic imaging;GenerativeAI;Health care;GAI Technologies;Large Language Models(LLM);GAI Models},
  doi={10.1109/ICOSEC61587.2024.10722592},
  ISSN={},
  month={Sep.},}@ARTICLE{10769067,
  author={Liu, Shiyu and Chen, Fei and Liu, Zhendong and Qiao, Hongyan},
  journal={IEEE Access}, 
  title={Overcoming Data Scarcity in Wind Power Forecasting: A Deep Learning Approach With Bidirectional Generative Adversarial Network and Neighborhood Search PSO Algorithm}, 
  year={2024},
  volume={12},
  number={},
  pages={183410-183428},
  abstract={The precision and stability of wind power prediction (WPP) are critical for the grid-connected operation of wind farms. However, the insufficient availability of historical data poses challenges for traditional deep learning prediction models to accurately forecast for new-built wind farms (NWF) under the background of a substantial increase in wind power installed capacity worldwide. Hence, there is practical scientific significance in exploring high-precision prediction methods within the domain of NWF WPP. To address the challenge of few sample in WPP, a novel data-enhanced WPP method is proposed, which integrates BiGAN (BiGAN) module, self-attention mechanism (SAM) and neighborhood search particle swarm optimization (NSPSO). Within the data enhancement module, BiGAN is proposed to mitigate convergence difficulties and gradient instability encountered during the training of traditional GANs, thereby fostering closer alignment between the generated distribution and the real distribution. During the prediction stage, SAM is designed to obtain a new input matrix for weight allocation before BiGRU, enhancing its sensitivity to critical input information. Furthermore, to prevent SAM-BiGRU from succumbing to local optima, the Dense layer is optimized by the NSPSO algorithm to improve the prediction accuracy. Extensive experimental results in two scenarios demonstrate that the proposed approach surpasses other advanced methods to a certain extent, achieving one-step-ahead prediction accuracy rates of 0.9775 and 0.9810, respectively. This study provides novel ideas to the field of WPP and demonstrates the potential of the proposed model to improve the accuracy of wind farms in power prediction, especially for those with limited historical data.},
  keywords={Predictive models;Generative adversarial networks;Data models;Numerical models;Accuracy;Wind power generation;Wind forecasting;Autoregressive processes;Atmospheric modeling;Wind farms;New-built wind farms;bidirectional generative adversarial network;self-attention mechanism;bidirectional gate recurrent unit;neighborhood search particle swarm optimization},
  doi={10.1109/ACCESS.2024.3507154},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9544406,
  author={Guoyun, Zhong and Jun, Liu and Yang, Hong and Meifeng, Liu and Hongyang, Sun},
  booktitle={2021 International Conference on Computer Engineering and Artificial Intelligence (ICCEAI)}, 
  title={Fine-grained image classification method based on generating adversarial networks with SIFT texture input}, 
  year={2021},
  volume={},
  number={},
  pages={104-107},
  abstract={A fine-grained image classification method based on generating adversarial networks with SIFT (Scale Invariant Feature Transform) texture input is proposed to improve the recognition ratio of fine-grained image classification by deep learning. For the phenomenon of data sets that require a large amount of labeled information for strong supervised learning, active learning capabilities of generative and adversarial networks and excellent image modeling capabilities for target classification images are used to achieve active learning of image features. Then the difficulty of data set construction and the computational complexity are reduced, and the disturbance to the network that may be caused by manually set labeled boxes is lessened. The input method of generating the adversarial network to is fixed to balance the authenticity and diversity of the generated samples. The idea of image restoration is considered. The random input method of the generative adversarial network that combines image feature points and random noise to is used to reduce the training difficulty of the generative and adversarial network. Experiments results show that our method outperformances the current deep learning methods in fine-grained image classification.},
  keywords={Deep learning;Training;Image recognition;Supervised learning;Transforms;Generative adversarial networks;Data models;component;supervised learning;deep learnin;fine-grained image classification;generating adversarial networks},
  doi={10.1109/ICCEAI52939.2021.00020},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9719234,
  author={Wu, Shasha and Wei, Ran and Lu, Li},
  booktitle={2021 International Conference on Computer Information Science and Artificial Intelligence (CISAI)}, 
  title={Text-Based Point Cloud Generation Adversarial Network}, 
  year={2021},
  volume={},
  number={},
  pages={760-764},
  abstract={Point clouds become the popular representation of 3D shapes. Meanwhile, deep generative adversarial networks (GANs) have been used to generate reasonable point clouds for specific categories, such as airplane, chair. But existing point clouds generation tasks are almost unconditional, which means the generative results cannot be controlled. In this work, we propose the text-based point cloud generative adversarial network short as TPC-GAN for generating point clouds from natural language. To this end, we first contribute a point clouds dataset with text description based on the chair category of ModelNet40. Then we learn the implicit cross-modal con-nections between texts and point clouds through category labels. Using a pretrained text encoder that had gained the mapping relations between texts and class labels to obtain text embedding of input text, which will concatenate with a noise vector and be feed into TPC-GAN. Moreover, the discriminators of TPC-GAN can be regarded as point clouds classifier. Finally, the TPC-GAN can generate point clouds that meet the input text description. To evaluate the performance of our approach, some experiments are conducted. To the best of our knowledge, our method is the first one to generate point clouds from texts.},
  keywords={Point cloud compression;Information science;Three-dimensional displays;Shape;Computational modeling;Natural languages;Generative adversarial networks;TextToPointCloud;Cross-Modality;GAN},
  doi={10.1109/CISAI54367.2021.00154},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10427798,
  author={Baynum, Andrew and Hao, Wei},
  booktitle={2024 IEEE 14th Annual Computing and Communication Workshop and Conference (CCWC)}, 
  title={Exploring the Impact of Cloud Computing and Edge Computing on Resource Consumption for Mobile Devices with Generative Artificial Intelligence APIs}, 
  year={2024},
  volume={},
  number={},
  pages={0603-0609},
  abstract={With the release of OpenAI’s ChatGPT, generative AI has become a hot topic in business. Generative AI APIs can be consumed by mobile devices, which are constrained by resources such as CPU, memory, and battery power. Power can be saved by using both Edge and Cloud Computing. However, there is a penalty to response time implementing these services. There seems to be a greater impact on response time with Cloud Computing than with Edge Computing, however Edge Computing is constrained by limits on payload and maximum response times. Our testing results show that Edge Computing is a good middle ground, providing a balance between savings in CPU time, while somewhat mitigating the penalty in response time. Developers exploring the option to use Cloud and/or Edge Computing for power savings on mobile devices should consider the size of their data sets carefully to determine if an Edge Computing service is a viable option.},
  keywords={Cloud computing;Generative AI;Mobile handsets;Time factors;Edge computing;Testing;Payloads;Generative AI;OpenAI;Mobile Device;Cloud Computing;Edge Computing},
  doi={10.1109/CCWC60891.2024.10427798},
  ISSN={},
  month={Jan},}@ARTICLE{10403990,
  author={Liang, Xingming and Zhou, Lihang and Goldberg, Mitch and Kalluri, Satya and Grassotti, Christopher and Sun, Ninghai and Yan, Banghua and Yang, Hu and Lin, Lin and Liu, Quanhua},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={Improving ATMS Imagery Visualization Using Limb Correction and AI Resolution Enhancement}, 
  year={2024},
  volume={17},
  number={},
  pages={4263-4279},
  abstract={The advanced technology microwave sounder (ATMS) is an important satellite instrument that provides vital data on atmosphere temperature and moisture for weather forecasting and climate research, and helps us plan for extreme weather. However, its coarse resolution and angular dependence have long been a challenge for improving image visualization. This article proposes a method to enhance the imagery visualization for ATMS, combining limb correction (LC) with artificial intelligence (AI) resolution enhancement (RE). Measurement data from the ATMS onboard NOAA-20 were utilized to train the LC method, which were then validated using newly acquired NOAA-21 ATMS data. The AI RE was performed using enhanced super-resolution generative adversarial networks, which increased the pixel resolution by a factor of four. The high-resolution (HR) Advanced Microwave Scanning Radiometer 2 data served as a reference to initially and quantitatively evaluate the RE method. The combined method of LC and AI RE produced an angular-dependence-free and HR ATMS image, resulting in a significant improvement in image visualization, including surface and atmosphere information, and allows for clear identification of severe weather events. For the swift identification and analysis of tropical cyclones in the upcoming season, as of this writing, this proposed method has been routinely employed to produce high-quality global ATMS images, and these images are showcased and tested in the NOAA internal HR imagery visualization system—JSTAR Mapper. Moreover, concentrated efforts are being made to further enhance these images in preparation for an official release.},
  keywords={Meteorology;Artificial intelligence;Satellites;Sea surface;Ocean temperature;Microwave sensors;Convolutional neural networks;Generative adversarial networks;Image resolution;Superresolution;Visualization;National Oceanic and Atmospheric Administration;Advanced technology microwave sounder (ATMS);convolutional neural network (CNN);enhanced super-resolution generative adversarial networks (ESRGAN);generative adversarial network (GAN);image visualization;limb correction (LC);weather event},
  doi={10.1109/JSTARS.2024.3354103},
  ISSN={2151-1535},
  month={},}@ARTICLE{9361225,
  author={Zhang, Yang and Tsang, Ivor W. and Luo, Yawei and Hu, Changhui and Lu, Xiaobo and Yu, Xin},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Recursive Copy and Paste GAN: Face Hallucination From Shaded Thumbnails}, 
  year={2022},
  volume={44},
  number={8},
  pages={4321-4338},
  abstract={Existing face hallucination methods based on convolutional neural networks (CNNs) have achieved impressive performance on low-resolution (LR) faces in a normal illumination condition. However, their performance degrades dramatically when LR faces are captured in non-uniform illumination conditions. This paper proposes a Recursive Copy and Paste Generative Adversarial Network (Re-CPGAN) to recover authentic high-resolution (HR) face images while compensating for non-uniform illumination. To this end, we develop two key components in our Re-CPGAN: internal and recursive external Copy and Paste networks (CPnets). Our internal CPnet exploits facial self-similarity information residing in the input image to enhance facial details; while our recursive external CPnet leverages an external guided face for illumination compensation. Specifically, our recursive external CPnet stacks multiple external Copy and Paste (EX-CP) units in a compact model to learn normal illumination and enhance facial details recursively. By doing so, our method offsets illumination and upsamples facial details progressively in a coarse-to-fine fashion, thus alleviating the ambiguity of correspondences between LR inputs and external guided inputs. Furthermore, a new illumination compensation loss is developed to capture illumination from the external guided face image effectively. Extensive experiments demonstrate that our method achieves authentic HR face images in a uniform illumination condition with a $16\times$16× magnification factor and outperforms state-of-the-art methods qualitatively and quantitatively.},
  keywords={Lighting;Faces;Face recognition;Training;Superresolution;Rain;Generative adversarial networks;Face hallucination;super-resolution;illumination normalization;generative adversarial network},
  doi={10.1109/TPAMI.2021.3061312},
  ISSN={1939-3539},
  month={Aug},}@INPROCEEDINGS{10436249,
  author={R, Oscar I. Iglesias and M, Christian G. Quintero},
  booktitle={2023 IEEE Colombian Caribbean Conference (C3)}, 
  title={Generative AI: The key for everyday problems. A comparison proposal for new users}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Generative AI is yet one of the biggest types of artificial intelligence brought to the public view, proposing a new vision and path for many industries around the world. This artificial intelligence model has brought a huge audience due to its impact on almost every industry, transforming the way some jobs can be pursued. Through an objective position, in this paper generative AI is evaluated to propose a comparison of some of their important tools to give new users a guide to solving their daily life problems, whether in their households or in their jobs, demonstrating the importance of knowing and using this type of AI.},
  keywords={Industries;Generative AI;Proposals;Generative AI;AI Tools;AI Models},
  doi={10.1109/C358072.2023.10436249},
  ISSN={},
  month={Nov},}@ARTICLE{10663202,
  author={Xie, Rui and Haq, Asad Ul and Ma, Linsen and Sun, Krystal and Sen, Sanchari and Venkataramani, Swagath and Liu, Liu and Zhang, Tong},
  journal={IEEE Computer Architecture Letters}, 
  title={SmartQuant: CXL-Based AI Model Store in Support of Runtime Configurable Weight Quantization}, 
  year={2024},
  volume={23},
  number={2},
  pages={199-202},
  abstract={Recent studies have revealed that, during the inference on generative AI models such as transformer, the importance of different weights exhibits substantial context-dependent variations. This naturally manifests a promising potential of adaptively configuring weight quantization to improve the generative AI inference efficiency. Although configurable weight quantization can readily leverage the hardware support of variable-precision arithmetics in modern GPU and AI accelerators, little prior research has studied how one could exploit variable weight quantization to proportionally improve the AI model memory access speed and energy efficiency. Motivated by the rapidly maturing CXL ecosystem, this work develops a CXL-based design solution to fill this gap. The key is to allow CXL memory controllers play an active role in supporting and exploiting runtime configurable weight quantization. Using transformer as a representative generative AI model, we carried out experiments that well demonstrate the effectiveness of the proposed design solution.},
  keywords={Quantization (signal);Random access memory;Artificial intelligence;Computational modeling;Load modeling;Generative AI;Memory management;Quantization;CXL;generative AI},
  doi={10.1109/LCA.2024.3452699},
  ISSN={1556-6064},
  month={July},}@ARTICLE{11168453,
  author={Fang, Nan and Liu, Guiliang and Gong, Wei},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Offline Inverse Constrained Reinforcement Learning for Safe-Critical Decision Making in Healthcare}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={One important application of Reinforcement Learning (RL) is optimizing treatment decisions in healthcare. However, a na¨ıve RL policy can lead to unsafe medical decisions, such as excessive dosages or abrupt treatment changes, often because agents fail to account for common-sense constraints. To mitigate these problems, Constrained Reinforcement Learning (CRL) naturally emerges as a promising approach for safer decision-making by optimizing policies under predefined constraints. To extend CRL to healthcare applications, a fundamental challenge lies in accurately specifying the constraint function for different healthcare scenarios. Recent Inverse Constrained Reinforcement Learning (ICRL) is a promising approach that infers constraints from expert demonstrations. However, ICRL algorithms model Markovian decisions and rely on real-time interactive environments. These settings do not align with the practical requirement of a decision-making system in healthcare, where decisions rely on historical treatment recorded in an offline dataset. To tackle these issues, we propose the Constraint Transformer (CT). Specifically, 1) we utilize a causal attention mechanism to incorporate historical decisions and observations into the constraint modeling, while employing a Non-Markovian layer for weighted constraints to capture critical states. 2) A generative world model is used for exploratory data augmentation, enabling offline RL methods to simulate unsafe decision sequences. In multiple medical scenarios, empirical results demonstrate that CT can capture unsafe states and achieve strategies that approximate lower mortality rates, reducing the occurrence probability of unsafe behaviors.},
  keywords={Medical services;Reinforcement learning;Trajectory;Artificial intelligence;Transformers;Decision making;Sepsis;Mortality;Costs;Entropy;Artificial intelligence;healthcare;medical services;safe reinforcement learning},
  doi={10.1109/TAI.2025.3610390},
  ISSN={2691-4581},
  month={},}@INPROCEEDINGS{9110266,
  author={Casas, Pedro},
  booktitle={NOMS 2020 - 2020 IEEE/IFIP Network Operations and Management Symposium}, 
  title={Two Decades of AI4NETS - AI/ML for Data Networks: Challenges & Research Directions}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={The popularity of Artificial Intelligence (AI) – and of Machine Learning (ML) as an approach to AI, has dramatically increased in the last few years, due to its out-standing performance in various domains, notably in image, audio, and natural language processing. In these domains, AI success-stories are boosting the applied field. When it comes to AI/ML for data communication Networks (AI4NETS), and despite the many attempts to turn networks into learning agents, the successful application of AI/ML in networking is limited. There is a strong resistance against AI/ML-based solutions, and a striking gap between the extensive academic research and the actual deployments of such AI/ML-based systems in operational environments. The truth is, there are still many unsolved complex challenges associated to the analysis of networking data through AI/ML, which hinders its acceptability and adoption in the practice. In this positioning paper I elaborate on the most important show-stoppers in AI4NETS, and present a research agenda to tackle some of these challenges, enabling a natural adoption of AI/ML for networking. In particular, I focus the future research in AI4NETS around three major pillars: (i) to make AI/ML immediately applicable in networking problems through the concepts of effective learning, turning it into a useful and reliable way to deal with complex data-driven networking problems; (ii) to boost the adoption of AI/ML at the large scale by learning from the Internet-paradigm itself, conceiving novel distributed and hierarchical learning approaches mimicking the distributed topological principles and operation of the Internet itself; and (iii) to exploit the softwarization and distribution of networks to conceive AI/ML-defined Networks (AIDN), relying on the distributed generation and re-usage of knowledge through novel Knowledge Delivery Networks (KDNs).},
  keywords={Knowledge engineering;Resistance;Deep learning;Turning;Natural language processing;Internet;Distributed power generation;Machine Learning;Artificial Intelligence;Data Communication Networks;Data-driven networking;Knowledge Delivery Networks (KDNs);AI/ML-defined networking (AIDN)},
  doi={10.1109/NOMS47738.2020.9110266},
  ISSN={2374-9709},
  month={April},}@INPROCEEDINGS{10522366,
  author={Kalra, Ashima and Mittal, Ruchi},
  booktitle={2024 11th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)}, 
  title={Explainable AI for Improved Financial Decision Support in Trading}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In order to improve financial decision support in trading situations, this study presents a strong framework that uses Explainable Artificial Intelligence (XAI) methodologies. The suggested model incorporates essential components, such as a Contrastive Divergence Neural Network for classification, Least Absolute Shrinkage and Selection Operator(LASSO) Regression for feature selection, and min-max normalization for dataset preparation. By using min-max normalization throughout the dataset preparation phase, we hope to guarantee data homogeneity and scalability. Important for reducing biases, standardizing input characteristics, and improving model convergence in later stages, this phase is crucial. One approach to feature selection is to use LASSO Regression, which is well-known for its capacity to isolate and keep the most important characteristics while eliminating the less useful ones. To maximize predicted accuracy and interpretability, the following model is trained on a refined set of variables. An effective unsupervised learning approach, the Contrastive Divergence Neural Network is used by the central classification component. The algorithm is able to spot nuanced trends and correlations that conventional methods miss because of this neural network's exceptional pattern-capturing capabilities in financial data.},
  keywords={Explainable AI;Scalability;Predictive models;Feature extraction;Market research;Prediction algorithms;Data models;Contrastive Divergence Neural Network;Explainable Artificial Intelligence;Financial decision support;min-max normalization;LASSO},
  doi={10.1109/ICRITO61523.2024.10522366},
  ISSN={2769-2884},
  month={March},}@INPROCEEDINGS{10351481,
  author={Ghani, Miharaini Md and Mustafa, Wan Azani and Hanafi, Hafizul Fahri and Lah, Noor Hidayah Che and Al-Dolaimy, Firas and Alkhayyat, Ahmed},
  booktitle={2023 6th International Conference on Engineering Technology and its Applications (IICETA)}, 
  title={AI in Changing the Way People Engage and Communicate in Media: A Review}, 
  year={2023},
  volume={},
  number={},
  pages={51-56},
  abstract={The tremendous influence of artificial intelligence is pretty evident, particularly in the media, where it has opened up new avenues of expression and changed how people perceive the world. The rise of digital technology has revolutionized both commercial processes and consumer shopping habits. Millions worldwide have used social media to express their emotions about the devastating COVID-19 outbreak. This paper aims to review existing literature by conducting a thorough review of the current literature related to the research question to understand the context, identify gaps, and recognize relevant theories or methodologies. Consequently, a deluge of data is flooding social media, with numerous studies conducted to analyze and understand it. Policymakers and decision-makers at relevant institutions may find the results of these analyses helpful as they endeavor to implement effective policies and strategies. The information shared on social media platforms has become increasingly significant for public health research and surveillance. Compared to traditional health reporting methods' time lag and cost, monitoring social media and user-generated data on the Internet enables rapid and affordable information gathering. As an additional data source in the health domain, social media discussions may prove valuable for tracking vaccine-related safety concerns. Monitoring internet observations about novel personal health experiences related to vaccines may enhance the potential for early warnings of emerging vaccine safety hazards.},
  keywords={Knowledge engineering;Social networking (online);Surveillance;Soft sensors;Mental health;Media;Market research;Artificial intelligence;AI;communication;media;change},
  doi={10.1109/IICETA57613.2023.10351481},
  ISSN={2831-753X},
  month={July},}@INPROCEEDINGS{11115680,
  author={Shamim, Maaz and Faridi, Arman Rasool and Masood, Faraz},
  booktitle={2025 12th International Conference on Computing for Sustainable Global Development (INDIACom)}, 
  title={Analysis of Emerging Trends and Challenges in Multimodal Data}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={The rapid development of multimodal data analysis has transformed fields, including social sciences, healthcare, and genetics. Multimodal techniques increase predictive accuracy, enable strong decision-making, and enhance tailored treatments by incorporating visuals, text, sensor outputs, and genomic sequences-many different data kinds. However, handling diverse, high-dimensional data presents significant difficulties in scalability, integration, and processing efficiency; hence, creative fusion methods and AI-driven models are quite necessary. With an eye on applications in neurodegenerative disease diagnosis, cancer detection, and precision medicine, this work investigates developing trends, approaches, and obstacles in multimodal data processing. With statistical and deep learning systems, including Convolutional Neural Networks (CNNs), Transformers, and Bayesian models, we cover fusion methodologies, including early/late integration, kernel-based alignment, and active subspace analysis. Unified data pipelines are shown in case studies of multimodal systems, including INSMA for ICU monitoring and SCALA for genetic profiling, to be rather useful. While it offers scalable infrastructure, interpretable artificial intelligence, and cost effective computational solutions, multimodal analysis constantly struggles with noise reduction, data harmonization, and cross-modal learning. Real-time multimodal integration, including social variables in disease prediction and translational bioinformatics, should be a top priority in future studies to increase clinical relevance and extend society's impact.},
  keywords={Deep learning;Visualization;Translation;Computational modeling;Precision medicine;Noise reduction;Genomics;Market research;Real-time systems;Diseases;Artificial Intelligence;Multimodal;deep learning;healthcare;frameworks},
  doi={10.23919/INDIACom66777.2025.11115680},
  ISSN={},
  month={April},}@INPROCEEDINGS{10918079,
  author={Choi, Hyun-Tae and Go, Kentaro and Chang, Won-Du},
  booktitle={2024 International Conference on Cyberworlds (CW)}, 
  title={Generative Diffusion Model for Electrooculogram}, 
  year={2024},
  volume={},
  number={},
  pages={344-345},
  abstract={Eye-writing, the act of drawing letters using eye movements, offers a promising avenue for human-computer interaction, especially when coupled with electrooculogram (EOG) recognition techniques. However, achieving high accuracy in eye-writing recognition using deep learning requires large datasets, which is challenging due to the time-consuming nature of data collection and privacy concerns. In this paper, we introduce a diffusion model capable of producing synthetic EOG signals, demonstrating the feasibility of generating high-quality bio-signal data. This approach not only mitigates the challenges of data collection but also facilitates the improvement of pattern recognition accuracies in small bio-signal datasets.},
  keywords={Electrooculography;Accuracy;Shape;Biological system modeling;Training data;Data collection;Diffusion models;Data models;Pattern recognition;Bioinformatics;Electrooculogram;Diffusion model;Generative model},
  doi={10.1109/CW64301.2024.00065},
  ISSN={2642-3596},
  month={Oct},}@INPROCEEDINGS{10527227,
  author={Dwi Putra, Taufiq Odhi and Ijtihadie, Royyana Muslim and Ahmad, Tohari},
  booktitle={2024 12th International Symposium on Digital Forensics and Security (ISDFS)}, 
  title={Load Characterization of AI Applications using DQoES Scheduler for Serving Multiple Requests}, 
  year={2024},
  volume={},
  number={},
  pages={01-06},
  abstract={In today's era, many types of Artificial Intelligence (AI)-based applications are being developed to fulfill a variety of needs, for example, counting objects recorded using a camera, identifying diseases by processing MRI images, and predicting traffic congestion levels at specific times. One way to provide infrastructure resources that match the workload of AI-based applications is to understand the patterns or characteristics of their workloads. Because an AI model is run using a Graphical Processing Unit (GPU), several parts of the AI model's architecture use Video Random Access Memory (VRAM) as temporary storage media to speed up the running time. This paper analyzes the characteristics of workloads from AI-based applications in terms of running time and VRAM usage, where experiments are conducted in two request scenarios: sequential request and concurrent request and using four types of AI models from the Super Resolution General Adversarial Network (SRGAN), namely no prune, random unstructured, L1 norm, and L2 norm. Based on the experimental results, the workload of all four types of SRGAN models will be almost the same when using the sequential request scenario, while in the concurrent request scenario, the four types of SRGAN models have different workloads. There are models that are more effectively processed one at a time rather than several at once, for example, in the SRGAN no prune model, and there are models that if processed several at once at the same time will be more effective compared to being processed one at a time, for example in the SRGAN random unstructured and L2 norm models.},
  keywords={Analytical models;Runtime;Superresolution;Graphics processing units;Random access memory;Servers;Security;Application;Artificial Intelligence;Load Characterization;Multiple Requests;Scheduler},
  doi={10.1109/ISDFS60797.2024.10527227},
  ISSN={2768-1831},
  month={April},}@INPROCEEDINGS{11137763,
  author={Liu, Xingzhou and He, Chunlin and Xu, Liming and Liu, Hangjiang},
  booktitle={2025 10th International Conference on Information Science, Computer Technology and Transportation (ISCTT)}, 
  title={DeepSeek for Medical Imaging: Development, Application and Challenges}, 
  year={2025},
  volume={},
  number={},
  pages={01-07},
  abstract={In recent years, the rapid advancement of artificial intelligence technologies, particularly breakthroughs in large language models and computer vision, has brought new opportunities to medical imaging analysis. AI-assisted diagnosis has achieved remarkable performance in many filed, and AI healthcare market is experiencing rapid growth with China's AI medical market size projected to exceed RMB 30 billion by 2025, supported by increasing policy incentives. As a promising technology, DeepSeek leverages robust large-model technologies to demonstrate broad application potential in medical image processing, including image synthesis, classification, denoising and report generation. Concurrently, combining with new learning fashion including few-shot learning and federated learning, DeepSeek-based assisted diagnosis methods improves and enhance significantly model performance, and accelerates AI adoption in healthcare. To this end, this study attempts to provide readers with systematic and comprehensive research about DeepSeek-based assisted diagnosis methods. We first introduce the developments of DeepSeek, including the comparison with other large language model. Then, we present the application of DeepSeek in medical imaging. Finally, we provide the challenges and limitations of DeepSeek.},
  keywords={Technological innovation;Systematics;Federated learning;Image synthesis;Large language models;Precision medicine;Noise reduction;Transportation;Few shot learning;Medical diagnostic imaging;Medical imaging;artificial intelligence;DeepSeek;computer-aided diagnosis;few-shot learning;federated learning},
  doi={10.1109/ISCTT66403.2025.11137763},
  ISSN={},
  month={June},}@INBOOK{10950518,
  author={Khan, Ian},
  booktitle={The Quick Guide to Prompt Engineering: Generative AI Tips and Tricks for ChatGPT, Bard, Dall-E, and Midjourney}, 
  title={Content Generation with AIVA}, 
  year={2024},
  volume={},
  number={},
  pages={387-399},
  abstract={Summary <p>Artificial Intelligence Virtual Artist (AIVA) is an innovative AI&#x2010;driven music composer, a brainchild designed to craft compositions that mirror the intricacies of human&#x2010;generated music, bridging the divide between machine precision and artistic expression. Prompts serve as directive touchpoints, guiding AIVA's creative algorithms to align with specific moods, genres, or desired themes. This chapter delves into the mechanics of how AIVA utilizes prompts. AIVA's interaction with prompts underscores a fundamental truth about the convergence of AI and art. The chapter presents some salient examples of AIVA applications, including film scoring, video games, music education, personal music creation, event management, interactive art installations, and dance performances. It discusses the limitations of AIVA, including lack of genuine emotion, economic implications, ethical concerns of credit and ownership, lack of contextual understanding, and skill erosion. The chapter also explores the possible trajectories and implications for AIVA's future.</p>},
  keywords={Artificial intelligence;Music;Art;Training;Creativity;Video games;Prompt engineering;Mood;Games;Films},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394243341},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10950518},}@INPROCEEDINGS{10566415,
  author={Aref, Shaden Mohamed and Fouad, Mohamed Mostafa and Sayed, Hend Attia and Gaber, Menna Ibrahim},
  booktitle={2024 14th International Conference on Electrical Engineering (ICEENG)}, 
  title={Cross-Selling Artificial Intelligence-Based Approaches in Insurance Industry: A Review}, 
  year={2024},
  volume={},
  number={},
  pages={323-328},
  abstract={For the analysis of exceedingly complex insurance data, artificial intelligence methods have evolved into the most valuable and significant tools. Worldwide, the insurance industry and its clients require a method for efficiently managing the enormous amount of data produced. The current review paper provides an overview of the research conducted in recent years on various cross-selling insurance approaches that have utilized machine learning and deep learning techniques. An evident transition from the utilization of machine learning methods to deep learning methods is demonstrated through the current literature review.},
  keywords={Industries;Training;Deep learning;Self-organizing feature maps;Reviews;Transfer learning;Neural networks;Insurance;cross-selling;machine learning;deep learning},
  doi={10.1109/ICEENG58856.2024.10566415},
  ISSN={},
  month={May},}@ARTICLE{10285884,
  author={Wang, Mo and Wang, Minjuan and Xu, Xin and Yang, Lanqing and Cai, Dunbo and Yin, Minghao},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Unleashing ChatGPT's Power: A Case Study on Optimizing Information Retrieval in Flipped Classrooms via Prompt Engineering}, 
  year={2024},
  volume={17},
  number={},
  pages={629-641},
  abstract={This research project investigates the impact of prompt engineering, a key aspect of chat generative pretrained transformer (ChatGPT), on college students' information retrieval in flipped classrooms. In recent years, an increasing number of students have been using AI-based tools, such as ChatGPT rather than traditional research engines to learn and to complete course assignments. Despite this growing trend, previous research has largely overlooked the influence of prompt engineering on students' use of ChatGPT and effective strategies for improving the quality of information retrieval in learning settings. To address this research gap, this study examines the information quality obtained from ChatGPT in a flipped classroom by evaluating its effectiveness in task completion among 26 novice undergraduates from the same major and cohort. The experimental results provide evidence that proficient mastery of prompt engineering improves the quality of information obtained by students using ChatGPT. Consequently, by acquiring proficiency in prompt engineering, students can maximize the positive impact of ChatGPT, obtain high-quality information, and enhance their learning efficiency in flipped classrooms.},
  keywords={Chatbots;Artificial intelligence;Task analysis;Online services;Electronic learning;Transformers;Oral communication;Chat generative pretrained transformer (ChatGPT);flipped classrooms;information retrieval;prompt engineering},
  doi={10.1109/TLT.2023.3324714},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10371980,
  author={Machmeier, Stefan and Hoecker, Maximilian and Heuveline, Vincent},
  booktitle={2023 IEEE Symposium Series on Computational Intelligence (SSCI)}, 
  title={Explainable Artificial Intelligence for Improving a Session-Based Malware Traffic Classification with Deep Learning}, 
  year={2023},
  volume={},
  number={},
  pages={850-855},
  abstract={In network security, applying deep learning methods to detect network traffic anomalies has achieved great results with various network traffic representations. A possible representation is the transformation of raw network communication to images to extract valuable information from the unmanageable amount of network traffic by applying representation learning. However, since deep learning models can result in black boxes for users, it is interesting to understand what valuable information is learned from network communication converted into images. This paper elaborates on that question using explainable artificial intelligence (XAI) methods to identify network packets that most influence the prediction and verify that packets in a malware communication containing malicious payloads have high influence on the prediction. We inspect the Grad-CAM and visualize the Integrated Gradients of Xception and VGG-19 model and investigate the attention heat maps of our Vision Transformer (ViT) model. In addition, we present a novel transformation of sessions to a new image representation to expand the informativeness of network communication. For multiclass classification, our best model Xception achieves an accuracy of 97.95%, whereas, for binary classification, Xception and VGG-19 achieve well above 99.50%. Our ViT model achieves a significantly lower performance with 95.86% for multiclass and 99.36% for binary classification. In particular, computing centers could benefit by examining their inbound and outbound traffic to detect malicious behaviors ahead of time.},
  keywords={Deep learning;Representation learning;Visualization;Computational modeling;Telecommunication traffic;Network security;Transformers},
  doi={10.1109/SSCI52147.2023.10371980},
  ISSN={2472-8322},
  month={Dec},}@ARTICLE{10750803,
  author={Guo, Jie and Wang, Meiting and Yin, Hang and Song, Bin and Chi, Yuhao and Yu, Fei Richard and Yuen, Chau},
  journal={IEEE Internet of Things Journal}, 
  title={Large Language Models and Artificial Intelligence Generated Content Technologies Meet Communication Networks}, 
  year={2025},
  volume={12},
  number={2},
  pages={1529-1553},
  abstract={Artificial intelligence generated content (AIGC) technologies, with a predominance of large language models (LLMs), have demonstrated remarkable performance improvements in various applications, which have attracted great interests from both academia and industry. Although some noteworthy advancements have been made in this area, a comprehensive exploration of the intricate relationship between AIGC and communication networks remains relatively limited. To address this issue, this article conducts an exhaustive survey from dual standpoints: first, it scrutinizes the integration of LLMs and AIGC technologies within the domain of communication networks and second, it investigates how the communication networks can further bolster the capabilities of LLMs and AIGC. Additionally, this research explores the promising applications along with the challenges encountered during the incorporation of these AI technologies into communication networks. Through these detailed analyses, our work aims to deepen the understanding of how LLMs and AIGC can synergize with and enhance the development of advanced intelligent communication networks, contributing to a more profound comprehension of next-generation intelligent communication networks.},
  keywords={Communication networks;Training;Surveys;6G mobile communication;Noise;Data models;Chatbots;Adaptation models;Security;Reviews;Artificial intelligence generated content (AIGC);communication networks;generative models;large language models (LLMs);novel network architecture},
  doi={10.1109/JIOT.2024.3496491},
  ISSN={2327-4662},
  month={Jan},}@ARTICLE{11144516,
  author={Duan, Shaohua and Zhang, Chunjie and Zheng, Xiaolong and Wang, Yutong and Zhang, Hui and Wang, Fei-Yue},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={24-h Lane Line Detection via Parallel Scene Information Collaboration}, 
  year={2025},
  volume={},
  number={},
  pages={1-14},
  abstract={Lane detection is a critical technology for autonomous driving, but current deep learning-based methods face significant challenges due to the lack of diverse datasets, especially for nighttime conditions. Most datasets are predominantly composed of daytime images, making it difficult to develop models that perform reliably around the clock. Inspired by the parallel system theory, we explore a novel approach to generate comprehensive 24-hour datasets from daytime images alone. In this paper, we propose the Parallel Scene Information Collaboration (PSIC) framework, designed to enhance 24-hour lane detection using only daytime data. The PSIC framework consists of three key components: artificial scene generation, information collaboration, and lane line detection. First, we address the limitations of existing datasets by proposing two generators—one that transforms daytime images into realistic nighttime scenes, and another that refines nighttime images by adding daytime characteristics. Next, to mitigate noise in the generated scenes, we propose a Multi-Spatial Feature Fusion (MSFF) module that effectively integrates features from both real and artificial scenes through spatial collaboration. Finally, the combined information is used by an anchor-based detection head to accurately identify lane positions. Our experiments on the TuSimple, Night TuSimple, and CULane datasets demonstrate that our method achieves state-of-the-art performance in 24-hour lane line detection, significantly improving reliability and robustness across varying conditions.},
  keywords={Lane detection;Accuracy;Data models;Collaboration;Training;Feature extraction;Computational modeling;Shape;Robustness;Polynomials;Lane line detection;parallel system;information collaboration},
  doi={10.1109/TITS.2025.3601380},
  ISSN={1558-0016},
  month={},}@INPROCEEDINGS{10707930,
  author={Nakamoto, Sayaka and Okamoto, Yoshi and Nakakouchi, Takashi and Shimada, Kazutaka},
  booktitle={2024 16th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)}, 
  title={Towards Human-Level Evaluation: Assessing the Potential of GPT-4 in Automated Evaluation and Feedback Generation on Japanese Essays}, 
  year={2024},
  volume={},
  number={},
  pages={156-161},
  abstract={In recent years, Automated Writing Evaluation (AWE) has been extensively researched within the field of AI in education. This paper explores generative AI, such as GPT-4, which has garnered significant attention for its ability to score essays and provide feedback to students. We designed prompts for GPT-4 to assign scores and rationales based on a given rubric and to generate feedback beneficial for students' development. We compared the evaluations produced by GPT-4 with those made by human evaluators. The results demonstrate GPT-4's potential to assist in generating evaluations at a human level. In addition, we analysed the consistency of the scoring and the quality of the rationales and feedback generated by GPT-4. In this paper, we will share our analysis and also describe the points that need to be improved for implementation in practice.},
  keywords={Privacy;Ethics;Generative AI;Education;Writing;Informatics;Automated Writing Evaluation;Automated Essay Scoring;Japanese Short Essay;GPT-4;LLM},
  doi={10.1109/IIAI-AAI63651.2024.00039},
  ISSN={2472-0070},
  month={July},}@ARTICLE{11024037,
  author={Tahvili, Sahar and Borg, Markus},
  journal={IEEE Software}, 
  title={Excel Isn’t a Process, and Not All ‘Intelligence’ Is Smart}, 
  year={2025},
  volume={42},
  number={4},
  pages={11-14},
  abstract={The relationship between requirements engineering and testing has been a key interest throughout my research career. It cannot be that requirements engineers are from Omicron Persei 7 and testers from Omicron Persei 9—we all live on the same planet. I’m happy to co-author this column with a former collaborator from a test automation EU project, now a manager at Ericsson. With this issue’s focus on AI-powered testing, we ask: How can we define corresponding tool and process requirements in practice? This column is twofold. First, Sahar shares her experience. Then, we connect her observations to findings from a longitudinal study on tool adoption. Together, the perspectives give a grounded view from the field.—Markus Borg},
  keywords={Automation;Requirements engineering;Software testing;Artificial intelligence;Machine learning;Deep learning;Computer bugs;Costs;Software tools;Problem-solving;Generative AI;Large language models},
  doi={10.1109/MS.2025.3559192},
  ISSN={1937-4194},
  month={July},}@ARTICLE{11170411,
  author={Hassani, Hossein and Hallaji, Ehsan and Razavi-Far, Roozbeh and Saif, Mehrdad and Lin, Liang},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Towards Sample-Efficiency and Generalization of Transfer and Inverse Reinforcement Learning: A Comprehensive Literature Review}, 
  year={2025},
  volume={},
  number={},
  pages={1-16},
  abstract={Reinforcement learning (RL) is a sub-domain of machine learning, mainly concerned with solving sequential decision-making problems by a learning agent that interacts with the decision environment to improve its behaviour through the reward it receives from the environment. This learning paradigm is, however, well-known for being time-consuming due to the necessity of collecting a large amount of data, making RL suffer from sample inefficiency and difficult generalization. Furthermore, the construction of an explicit reward function that accounts for the trade-off between multiple desiderata of a decision problem is often a laborious task. These challenges have been recently addressed utilizing transfer and inverse RL (T-IRL). In this regard, this paper is devoted to a comprehensive review of realizing the sample efficiency and generalization of RL algorithms through T-IRL. Following a brief introduction to RL, the fundamental T-IRL methods are presented and the most recent advancements in each research field have been extensively reviewed. Our findings denote that a majority of recent research works have dealt with the aforementioned challenges by utilizing human-in-the-loop and sim-to-real strategies for the efficient transfer of knowledge from source domains to the target domain under the transfer learning scheme. Under the IRL structure, training schemes that require a low number of experience transitions and extension of such frameworks to multi-agent and multi-intention problems have been the priority of researchers in recent years. This survey first reviews the theoretical foundations of RL and its challenges, then presents recent advances in T-IRL, and concludes with a discussion of open research directions and future trends.},
  keywords={Training;Artificial intelligence;Reviews;Surveys;Decision making;Reinforcement learning;Predictive models;Learning (artificial intelligence);Vehicle dynamics;Transfer learning;Reinforcement Learning;Transfer Learning;Inverse Reinforcement Learning;Sample Efficiency;Generalization},
  doi={10.1109/TAI.2025.3610590},
  ISSN={2691-4581},
  month={},}@INPROCEEDINGS{10309081,
  author={Severeyn, Erika and Cruz, Alexandra La and Matute, Roberto and Estrada, Juan},
  booktitle={2023 IEEE Seventh Ecuador Technical Chapters Meeting (ECTM)}, 
  title={Neural Networks for Customer Classification Through Clickstream Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Business intelligence (BI) refers to the strategies, technologies, and tools used by organizations to analyze and interpret large amounts of data, with the goal of gaining actionable insights and making informed business decisions. BI can incorporate predictive analytics techniques to forecast future trends and outcomes. By analyzing historical data and applying statistical models, enterprises can make predictions about customer behavior, market trends, and other factors that impact their business. The research aims to classify customers based on their clickstream usage patterns by utilizing artificial neural networks (ANNs). For this purpose, a clickstream-based database collected from the IMOLKO company’s website via the Google Analytics platform was employed. Several experiments were conducted using Monte Carlo cross-validation (MCCV) to adjust the number of hidden layers in the ANNs and utilize different proportions of testing data. To evaluate the model’s performance the accuracy, sensitivity, specificity, positive predictive value, negative predictive value and the F1 score were calculated. The evaluation metrics, calculated through MCCV, exhibited low standard deviations, indicating that the ANN classifier is robust and not significantly affected by random variations in the testing-train database split. The ANN exhibited a sensitivity, specificity, positive predictive value, negative predictive value, and F1 score above 80%. However, it is important to note that there is a 9% of probability of false positives, which slightly affects the F1 score and sensitivity. In conclusion, the ANN employed in this study demonstrated their effectiveness as a classification technique for predicting customers of the corporation IMOLKO C.A.},
  keywords={Training;Sensitivity;Databases;Training data;Artificial neural networks;Predictive models;Market research;Artificial neural networks;Business intelligence;Monte Carlo cross validation;Clickstream},
  doi={10.1109/ETCM58927.2023.10309081},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11106561,
  author={Elhamzaoui, Sara and Jellouli, Omar and Hassan, Alaa and El Ghazi, Abdellatif and Osorio, Ferney and Monticolo, Davy},
  booktitle={2025 IEEE International Conference on Engineering, Technology, and Innovation (ICE/ITMC)}, 
  title={Development of iPhi-3: An AI-Powered Chatbot for Supporting Ideation}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Innovation is crucial for companies wishing to remain competitive in a constantly changing environment. The innovation process comprises a number of stages, including ideation, the aim of which is to generate ideas that could be turned into innovative products or services. However, this stage is often hindered by cognitive limitations and individual creative biases. The rise of artificial intelligence, particularly Generative Artificial Intelligence (GenAI), offers a remarkable opportunity to revolutionize this critical phase. This article introduces the iPhi-3 ideation chatbot, a tool specifically designed to address these challenges. The chatbot leverages the Phi-3 SLM (Small Language Models) model, renowned for its flexibility, energy efficiency, and performance, in contrast to other more costly alternatives. Through specialized training (fine-tuning), iPhi-3 not only enhances the quantity and quality of generated ideas but also enables the seamless integration of distinct concepts, paving the way for pioneering innovation.},
  keywords={Training;Technological innovation;Generative AI;Companies;Chatbots;Energy efficiency;Generative Artificial Intelligence;Innovation;Ideation;Chatbot;Phi-3;Fine-tuning},
  doi={10.1109/ICE/ITMC65658.2025.11106561},
  ISSN={2693-8855},
  month={June},}@INBOOK{10950774,
  author={Orange, Erica},
  booktitle={AI + The New Human Frontier: Reimagining the Future of Time, Trust + Truth}, 
  title={The Acceleration of AI}, 
  year={2024},
  volume={},
  number={},
  pages={30-34},
  abstract={Summary <p>An AI Cambrian explosion looms as a disruptive economic force. Progress in the capabilities of AI systems is driven by advancements in computing power, data, and algorithms&#x2014;and all three are accelerating. To simplify the relationship between AI, machine learning, the neural net, and deep learning, a helpful visual is the Matryoshka (Russian) nesting dolls. Each is essentially a component of the prior term. In other words, machine learning is a subfield of AI. Deep learning is a subfield of machine learning. And think of neural networks as the backbone of deep learning algorithms. The nesting doll analogy serves to set the backdrop for much of the recent buzz around generative AI and help contextualize where we are in AI's evolutionary process. Generative AI is built around vast, complex algorithms trained on reams of text, images, sound files, and other data.</p>},
  keywords={Artificial intelligence;Deep learning;Natural language processing;Generative AI;Speech recognition;Machine learning algorithms;Explosions;Data models;Brain modeling;Smart phones},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394276998},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10950774},}@ARTICLE{10816667,
  author={Liu, Ying and Yin, Jianhui and Zhang, Weiting and An, Changming and Xia, Yu and Zhang, Hongke},
  journal={IEEE Communications Surveys & Tutorials}, 
  title={Integration of Federated Learning and AI-Generated Content: A Survey of Overview, Opportunities, Challenges, and Solutions}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={Artificial intelligence generated content (AIGC) relies on advanced AI algorithms supported by extensive datasets and substantial computing power to generate precise and pertinent content. Federated learning (FL) enables the aggregation of large volumes of data and computing resources from various sources, all while safeguarding privacy. As a result, FL has emerged as a critical enabler in the realm of AIGC. This survey paper provides a comprehensive overview of the integration of FL and AIGC, namely federated AIGC models. First, we introduce the fundamental concepts of FL and AIGC. Next, we summarize four typical types of federated AIGC models. Subsequently, We highlight the threats to centralized federated AIGC models regarding data confidentiality, integrity, and availability and discuss the unique advantages of blockchain technology in decentralized federated AIGC models in addressing these issues. Finally, we look at potential emerging application scenarios and explore open issues and future directions for federated AIGC models.},
  keywords={Data models;Training;Computational modeling;Artificial intelligence;Surveys;Data privacy;Blockchains;Bandwidth;Servers;Security;Federated learning;AI-generated content;Data Privacy;Blockchain},
  doi={10.1109/COMST.2024.3523350},
  ISSN={1553-877X},
  month={},}@INPROCEEDINGS{9952548,
  author={Shin, Chang Jong and Heo, Yong Seok},
  booktitle={2022 13th International Conference on Information and Communication Technology Convergence (ICTC)}, 
  title={GAN Inversion with Semantic Segmentation Map for Image Editing}, 
  year={2022},
  volume={},
  number={},
  pages={927-931},
  abstract={In this paper, we propose a framework to perform Generative Adversarial Network (GAN) inversion using semantic segmentation map to invert input image into the GAN latent space. Generally, it is still difficult to invert semantic information of input image into GAN latent space. In particular, conventional GAN inversion methods usually suffer from inverting accurate semantic information such as shape of glasses and hairstyle. To this end, we propose a framework that uses the semantic segmentation map of the real image to guide the latent space corresponding to feature map with coarse resolution in the Style-GANv2. Experimental results show that our proposed method generates more accurate images and is possible of detailed editing of input images with a variety of semantic information compared with previous GAN inversion methods.},
  keywords={Image resolution;Shape;Semantic segmentation;Semantics;Glass;Generative adversarial networks;Information and communication technology;GAN inversion;image editing;image manipulation},
  doi={10.1109/ICTC55196.2022.9952548},
  ISSN={2162-1241},
  month={Oct},}@INPROCEEDINGS{9897973,
  author={Chen, Yinpeng and Zhang, Jiale and Cao, Zhiguo and Lu, Hao and Zhong, Weicai},
  booktitle={2022 IEEE International Conference on Image Processing (ICIP)}, 
  title={Hyprogan: Breaking the Dimensional wall From Human to Anime}, 
  year={2022},
  volume={},
  number={},
  pages={2066-2077},
  abstract={Image translation from human faces to anime ones brings a low-end, efficient way to create animation characters for animation industry. However, due to the significant inter-domain difference between anime images and human photos, existing image-to-image translation approaches cannot address this task well. To solve this dilemma, we propose HyProGAN, an exemplar-guided image-to-image translation model without paired data. The key contribution of HyPro-GAN is that it introduces a novel hybrid and progressive training strategy that expands the unidirectional translation between two domains into the bidirectional intra-domain and inter-domain translation. To enhance the consistency between input and output, we further propose a local masking loss to align the facial features between the human face and the generated anime face. Extensive experiments demonstrate the superiority of HyProGAN against state-of-the-art models.},
  keywords={Training;Industries;Image processing;Animation;Hybrid power systems;Generators;Data models;generative adversarial network;image-to-image translation;anime face},
  doi={10.1109/ICIP46576.2022.9897973},
  ISSN={2381-8549},
  month={Oct},}@ARTICLE{10854817,
  author={Xiang, Sheng and Xu, Chenhao and Cheng, Dawei and Zhang, Ying},
  journal={IEEE Transactions on Big Data}, 
  title={Scalable Learning-Based Community-Preserving Graph Generation}, 
  year={2025},
  volume={11},
  number={5},
  pages={2457-2470},
  abstract={Graph generation plays an essential role in understanding the formation of complex network structures across various fields, such as biological and social networks. Recent studies have shifted towards employing deep learning methods to grasp the topology of graphs. Yet, most current graph generators fail to adequately capture the community structure, which stands out as a critical and distinctive aspect of graphs. Additionally, these generators are generally limited to smaller graphs because of their inefficiencies and scaling challenges. This paper introduces the Community-Preserving Graph Adversarial Network (CPGAN), designed to effectively simulate graphs. CPGAN leverages graph convolution networks within its encoder and maintains shared parameters during generation to encapsulate community structure data and ensure permutation invariance. We also present the Scalable Community-Preserving Graph Attention Network (SCPGAN), aimed at enhancing the scalability of our model. SCPGAN considerably cuts down on inference and training durations, as well as GPU memory usage, through the use of an ego-graph sampling approach and a short-pipeline autoencoder framework. Tests conducted on six real-world graph datasets reveal that CPGAN manages a beneficial balance between efficiency and simulation quality when compared to leading-edge baselines. Moreover, SCPGAN marks substantial strides in model efficiency and scalability, successfully increasing the size of generated graphs to the 10 million node level while maintaining competitive quality, on par with other advanced learning models.},
  keywords={Generators;Scalability;Training;Computational modeling;Big Data;Stochastic processes;Deep learning;Complexity theory;Graphics processing units;Generative adversarial networks;Graph generation;generative adversarial network;graph neural network},
  doi={10.1109/TBDATA.2025.3533898},
  ISSN={2332-7790},
  month={Oct},}@INPROCEEDINGS{10222808,
  author={Jeong, Hea In and Kim, Boeun and Kim, Chung-Il and Shin, Saim},
  booktitle={2023 IEEE International Conference on Image Processing (ICIP)}, 
  title={Omission-Free Inpainting: A Three-Stage Approach to Ensure Object Generation}, 
  year={2023},
  volume={},
  number={},
  pages={705-709},
  abstract={This paper proposes a novel inpainting framework, omission-free inpainting, which ensures generating the desired object in the masked region. Despite recent advancements in text-driven and class-conditional inpainting models, they often fail to restore the missing object. To address this issue, the proposed framework includes a separate object generation stage, resulting in omission-free inpainting. The framework consists of three stages: background generation, object generation and refinement. The background generation stage restores a harmonious background with the surrounding pixels, while the object generation stage creates the desired object using a blending mask that allows the object to be influenced by the background’s color and brightness. Finally, the refinement stage blends the object and background to produce a visually realistic image. We compare the results qualitatively with the state-of-the-art methods, and our method outperforms the existing methods in CLIP score.},
  keywords={Image color analysis;Brightness;Image restoration;IEEE Regions;Class-conditional inpainting;Object generation;Blending mask;Generative adversarial network;Omission-free inpainting},
  doi={10.1109/ICIP49359.2023.10222808},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9538914,
  author={Li, Yanmiao and Ge, Feng-Xiang and Bai, Yanyu and Li, Mengjia},
  booktitle={2021 IEEE/CIC International Conference on Communications in China (ICCC Workshops)}, 
  title={Pseudo Ship-radiated Noise Generation Based on Adversarial Learning}, 
  year={2021},
  volume={},
  number={},
  pages={222-227},
  abstract={The demand for acoustic positioning is increasing in various fields, meanwhile, it is very important to disturb acoustic positioning for underwater acoustics countermeasure and ship stealth technology. In this paper, a one-dimensional (ID) deep neural network based on adversarial learning to generate pseudo ship-radiated noises is presented, and a ID convolutional network for classification is also given for evaluating the generated pseudo ship-radiated noises. The experimental results show that the proposed solution is effective to generate pseudo ship-radiated noises.},
  keywords={Deep learning;Conferences;Neural networks;Adversarial machine learning;Convolutional neural networks;Underwater acoustics;Marine vehicles;Ship-radiated Noise;Generative Adversarial Networks (GAN);Convolutional Neural Networks (CNN)},
  doi={10.1109/ICCCWorkshops52231.2021.9538914},
  ISSN={2474-9133},
  month={July},}@INPROCEEDINGS{10984157,
  author={Deshpande, Atharva and Gopalan, Kaushik},
  booktitle={2024 IEEE India Geoscience and Remote Sensing Symposium (InGARSS)}, 
  title={A Deep-learning pipeline to estimate instantaneous rain rates from INSAT-3D Outgoing Longwave Radiation data}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={This study proposes a deep learning framework to estimate instantaneous rain rates in India and surrounding regions (latitudes $0 \mathrm{~N}-40 \mathrm{~N}$ and longitudes $60 \mathrm{E}-100 \mathrm{E}$) using the INSAT-3D Imager Outgoing Longwave Radiation (OLR) product as input. The study utilizes OLR data with 4 km spatial resolution from June 2022 for training and June 2021 for testing. The estimation is done using a customized conditional Generative Adversarial Network (cGAN). The generator architecture incorporates downsampling convolutional layers, multiple residual blocks, and upsampling transposed convolutional layers, while the discriminator uses a PatchGAN approach. Results show that the proposed model results in a lower RMSE relative to the operational INSAT Multi-Spectral Rain Algorithm (IMSRA) and HydroEstimator (HE) algorithms (0.88 vs. 1.96 and 3.25). The model demonstrates superior threat scores for lower rainfall thresholds, while the operational methods demonstrate better results for rain rates greater than $10 \mathrm{~mm} / \mathrm{hr}$.},
  keywords={Deep learning;Training;Rain;Pipelines;Geoscience and remote sensing;Estimation;Generative adversarial networks;Generators;Spatial resolution;Testing;INSAT-3D;Precipitation Retrieval;Deep Learning},
  doi={10.1109/InGARSS61818.2024.10984157},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10444243,
  author={Choi, Hyoungki and Choi, Jinsol and Lim, Heunseung and Paik, Joonki},
  booktitle={2024 IEEE International Conference on Consumer Electronics (ICCE)}, 
  title={Face Image Restoration Method Using Semantic and Transformer Splitting Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={This paper delves into the hardware constraints of consumer-grade surveillance camera systems, proposing a unique network architecture that splits into four distinct branches tailored for mainstream consumer electronics. While there have been significant advancements in consumer camera technology, the financial barriers related to surveillance applications in consumer markets remain notably high. Responding to this, our research presents a state-of-the-art method, optimized for everyday consumer devices, to enhance facial regions in videos by utilizing our specialized splitting network design. This model, ideal for consumer technology applications, demonstrates the capacity to precisely reconstruct damaged facial features at a pixel-level, all the while preserving the true aesthetics and authenticity of human faces. Recognizing the critical role of facial regions for personal safety in consumer settings, our solution presents a compelling answer to current challenges. This research accentuates the profound potential of advanced deep learning techniques to fortify personal safety in the modern consumer electronics landscape.},
  keywords={Surveillance;Cameras;Safety;Image restoration;Faces;Consumer electronics;Videos;face restoration;generative adversarial networks;transformer},
  doi={10.1109/ICCE59016.2024.10444243},
  ISSN={2158-4001},
  month={Jan},}@INPROCEEDINGS{10992169,
  author={Feng, Yinqiu and Shen, Aoran and Hu, Jiacheng and Liang, Yingbin and Wang, Shiru and Du, Junliang},
  booktitle={2024 4th International Conference on Digital Society and Intelligent Systems (DSInS)}, 
  title={Enhancing Few-Shot Learning with Integrated Data and GAN Model Approaches}, 
  year={2024},
  volume={},
  number={},
  pages={443-448},
  abstract={This paper presents an innovative approach to enhancing few-shot learning by integrating data augmentation with model fine-tuning in a framework designed to tackle the challenges posed by small-sample data. Recognizing the critical limitations of traditional machine learning models that require large datasets-especially in fields such as drug discovery, target recognition, and malicious traffic detection-this study proposes a novel strategy that leverages Generative Adversarial Networks (GANs) and advanced optimization techniques to improve model performance with limited data. Specifically, the paper addresses the noise and bias issues introduced by data augmentation methods, contrasting them with model-based approaches, such as fine-tuning and metric learning, which rely heavily on related datasets. By combining Markov Chain Monte Carlo (MCMC) sampling and discriminative model ensemble strategies within a GAN framework, the proposed model adjusts generative and discriminative distributions to simulate a broader range of relevant data. Furthermore, it employs MHLoss and a reparameterized GAN ensemble to enhance stability and accelerate convergence, ultimately leading to improved classification performance on small-sample images and structured datasets. Results confirm that the MhERGAN algorithm developed in this research is highly effective for few-shot learning, offering a practical solution that bridges data scarcity with high-performing model adaptability and generalization.},
  keywords={Training;Adaptation models;Target recognition;Generative adversarial networks;Data augmentation;Data models;Drug discovery;Artificial intelligence;Few shot learning;Convergence;Few-Shot Learning;Data Augmentation;Model Fine-Tuning;Meta-Learning;Small-Sample Data Analysis},
  doi={10.1109/DSInS64146.2024.10992169},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10482305,
  author={Durole, Pankaj Hari and Agarwal, Mukta},
  booktitle={2024 IEEE International Students' Conference on Electrical, Electronics and Computer Science (SCEECS)}, 
  title={"A Comprehensive Review of Advanced Artificial Intelligence Techniques to Enhance Intrusion Detection Systems"}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={In the ever-evolving landscape of cybersecurity, the efficacy of IDS (Intrusion Detection System) is paramount. This paper explores the incorporation of advanced IDS techniques namely, reinforcement learning, predictive analysis, genetic algorithms, and artificial neural networks, to enhance the capabilities of IDS. The literature review encompasses a comprehensive examination of existing IDS, shedding light on their limitations and the need for innovative approaches. We delve into studies that employ reinforcement learning, predictive analysis, genetic algorithms, and artificial neural networks, individually, to bolster intrusion detection. The paper then synthesizes these approaches, exploring how their combined application offers a synergistic solution to the challenges posed by modern cyber threats. Methodologies employed in relevant studies are discussed, and the results are taken into account to reveal insights into the strengths and weaknesses of the integrated techniques. Additionally, we highlight challenges in implementation. This paper gives a comprehensive review of the current state of IDS and the idea for the most robust and reliable Intrusion Detection System.},
  keywords={Computer science;Reviews;Computer network reliability;Intrusion detection;Reinforcement learning;Artificial neural networks;Reliability;Intrusion Detection System (IDS);Reinforcement Learning (RL);Predictive Analysis (PA);Genetic Algorithm (GA)},
  doi={10.1109/SCEECS61402.2024.10482305},
  ISSN={2688-0288},
  month={Feb},}@ARTICLE{11083658,
  author={Fang, Xiaohan and Tang, Xianfa and Li, Keke and Xi, Hanting and Fan, Yuan and Pan, Tianhong},
  journal={IEEE Transactions on Smart Grid}, 
  title={Multi-Length Dynamic Shapelets Approach for Non-Intrusive Load Monitoring via Generative Adversarial Networks}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Non-intrusive load monitoring (NILM), offers a privacy-preserving, real-time, and cost-effective approach to perceive power consumption patterns of appliances. The performance of NILM heavily relies on the quality of features extracted from load profiles. The shapelets method captures interpretable features that represent the unique characteristics of loads, proving highly relevant to NILM applications. In this work, an improved shapelets method for event-based NILM is proposed. First, a multi-length shapelets are creatively adopted for load identification, guaranteeing performance with lowfrequency or limited samples. Additionally, dynamic shapelets are obtained using a generative adversarial networks (GAN) instead of traditional search methods, ensuring efficient and distinctive shapelets generation across diverse appliances. Then, these generated shapelets are converted to distance features via shapelet transform and fed into classifier with squeeze-andexcitation network to enhance the accuracy of load identification. Experimental results on COOLL and BLUED datasets demonstrate that the proposed GAN-based multi-length dynamic shapelets method significantly optimizes the shapelet generation process and enhances the effectiveness of load identification in NILM.},
  keywords={Time series analysis;Generative adversarial networks;Feature extraction;Transforms;Load monitoring;Accuracy;Event detection;Training;Real-time systems;Energy consumption;Non-intrusive load monitoring;multi-length shapelets;shapelet transform;generative adversarial networks;squeeze-and-excitation},
  doi={10.1109/TSG.2025.3589997},
  ISSN={1949-3061},
  month={},}@ARTICLE{10325539,
  author={Emam, Ahmed and Stomberg, Timo T. and Roscher, Ribana},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={Leveraging Activation Maximization and Generative Adversarial Training to Recognize and Explain Patterns in Natural Areas in Satellite Imagery}, 
  year={2024},
  volume={21},
  number={},
  pages={1-5},
  abstract={Natural protected areas are vital for biodiversity, climate change mitigation, and supporting ecological processes. Despite their significance, comprehensive mapping is hindered by a lack of understanding of their characteristics and a missing land-cover class definition. This letter aims to advance the explanation of the designating patterns forming protected and wild areas. To this end, we propose a novel framework that uses activation maximization and a generative adversarial model. With this, we aim to generate satellite images that, in combination with domain knowledge, are capable of offering complete and valid explanations for the spatial and spectral patterns that define the natural authenticity of these regions. Our proposed framework produces more precise attribution maps pinpointing the designating patterns forming the natural authenticity of protected areas. Our approach fosters our understanding of the ecological integrity of the protected natural areas and may contribute to future monitoring and preservation efforts.},
  keywords={Adversarial machine learning;Climate change;Biodiversity;Satellite images;Biological system modeling;Climate change;Protected areas;Activation maximization;explainable machine learning;generative models;patterns discovery},
  doi={10.1109/LGRS.2023.3335473},
  ISSN={1558-0571},
  month={},}@INPROCEEDINGS{9776077,
  author={Wang, Ziqi and Guo, Bin and Cui, Helei and Ding, Yasan and Yu, Zhiwen},
  booktitle={2022 IEEE 25th International Conference on Computer Supported Cooperative Work in Design (CSCWD)}, 
  title={Fashion Meets Bot: What Should the Bot Wear?}, 
  year={2022},
  volume={},
  number={},
  pages={932-937},
  abstract={Intelligent bots are evolving with the development of artificial intelligence, especially the deep learning method. Many skills like semantic judgment, speech recognition, and text generation have been added, making bots more like real persons. The latest ones, such as Microsoft XiaoIce, Amazon Alexa, and Apple Siri, focus on enhancing general functionalities but still overlook the personality of the bot itself nevertheless, e.g., unchanging name and its virtual appearance. To further personalize the user experience, we desire to make the appearance of intelligent bots more diverse, i.e., appearing capable of autonomously changing its characteristic appearance according to users’ contexts like the changing geolocation. In this paper, we designe a personalized appearance transformation framework for the next generation intelligent bots. Specifically, Multi-modal crowd-intelligence technology is used for differential analysis of various regions, and generative adversarial network (GAN) is customized to render the bot appearance target domain. We also collecte new region-specific data sets from social media platforms, implement a fully-fledged prototype, and demonstratedthe effectiveness of our proposed framework.},
  keywords={Text recognition;Social networking (online);Virtual assistants;Semantics;Prototypes;Speech recognition;Generative adversarial networks;bot appearance;crowd-intelligence;differential analysis},
  doi={10.1109/CSCWD54268.2022.9776077},
  ISSN={},
  month={May},}@ARTICLE{9699076,
  author={Wang, Dafeng and Liu, Hongbo and Wang, Naiyao and Wang, Yiyang and Wang, Hua and McLoone, Seán},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={SEEM: A Sequence Entropy Energy-Based Model for Pedestrian Trajectory All-Then-One Prediction}, 
  year={2023},
  volume={45},
  number={1},
  pages={1070-1086},
  abstract={Predicting the future trajectories of pedestrians is of increasing importance for many applications such as autonomous driving and social robots. Nevertheless, current trajectory prediction models suffer from limitations such as lack of diversity in candidate trajectories, poor accuracy, and instability. In this paper, we propose a novel Sequence Entropy Energy-based Model named SEEM, which consists of a generator network and an energy network. Within SEEM we optimize the sequence entropy by taking advantage of the local variational inference of $f$f-divergence estimation to maximize the mutual information across the generator in order to cover all modes of the trajectory distribution, thereby ensuring SEEM achieves full diversity in candidate trajectory generation. Then, we introduce a probability distribution clipping mechanism to draw samples towards regions of high probability in the trajectory latent space, while our energy network determines which trajectory is most representative of the ground truth. This dual approach is our so-called all-then-one strategy. Finally, a zero-centered potential energy regularization is proposed to ensure stability and convergence of the training process. Through experiments on both synthetic and public benchmark datasets, SEEM is shown to substantially outperform the current state-of-the-art approaches in terms of diversity, accuracy and stability of pedestrian trajectory prediction.},
  keywords={Trajectory;Predictive models;Generators;Entropy;Stability analysis;Potential energy;Training;Trajectory prediction;mutual information;variational inference;potential energy regularization},
  doi={10.1109/TPAMI.2022.3147639},
  ISSN={1939-3539},
  month={Jan},}@INPROCEEDINGS{9181917,
  author={Liang, Zhiyong and Zhou, Bo and Yang, Boxiong and Xiao, Heng},
  booktitle={2020 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)}, 
  title={Using Raindrops Removal Algorithm to Improve Vehicle Recognition via AttentiveGAN}, 
  year={2020},
  volume={},
  number={},
  pages={1268-1271},
  abstract={When the vehicle image with raindrops is converted into a clear image, the biggest difficulty is that the area blocked by the raindrops is random, and the entire image loses many feature points. Therefore, the method of removing raindrops from a single image via Deep-Learning can effectively extract and mine the depth features in the image. We propose to use AttentiveGAN to remove raindrops from images, which is based on Generative Adversarial Networks (GAN). Using Generator and Discriminator in the GAN, raindrops in the vehicle images are better removed, thereby effectively improving the recognition rate of vehicles. From the final experimental evaluation, the images generated via this algorithm have greatly improved the recognition appearance, PSNR and SSIM, and the recognition rate of the vehicles can be increased by up to 30%.},
  keywords={Generative adversarial networks;Image recognition;Object detection;Conferences;Generators;Gallium nitride;Target recognition;AttentiveGAN;Target Detection;GAN;Raindrops},
  doi={10.1109/ICAICA50127.2020.9181917},
  ISSN={},
  month={June},}@ARTICLE{11073175,
  author={Zhang, Shaofeng and Zhou, Qiang and Wang, Zhibin and Li, Hao and Yan, Junchi},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={EasyOutPainter: One Step Image Outpainting With Both Continuous Multiple and Resolution}, 
  year={2025},
  volume={47},
  number={10},
  pages={9217-9231},
  abstract={Image outpainting aims to generate the content of an input sub-image outside its boundaries, which remains open for existing generative models. This paper explores image outpainting in three directions that have not been achieved in literature to our knowledge: outpainting 1) with continuous multiples (in contrast to the discrete ones by existing methods); 2) with arbitrary resolutions; and 3) in a single step (for any multiples and resolutions). The arbitrary multiple outpainting is achieved by utilizing randomly cropped views from the same image during training to capture arbitrary relative positional information. Specifically, by feeding one view and relative positional embeddings as queries, we can reconstruct another view. At inference, we generate images with arbitrary expansion multiples by inputting an anchor image and its corresponding positional embeddings. The continuous-resolution outpainting is achieved by introducing the multi-scale training strategy into generative models. Specifically, by disentangling the image resolution and the number of patches, it can generate images with arbitrary resolutions without post-processing. Meanwhile, we propose a query-based contrastive objective to make our method not rely on a pre-trained backbone network which is otherwise often required in peer methods. The comprehensive experimental results on public benchmarks show its superior performance over state-of-the-art approaches.},
  keywords={Image resolution;Training;Noise;Extrapolation;Convergence;Semantics;Predictive models;Cameras;Artificial intelligence;Smoothing methods;Image outpainting;generative models;diffusion models;contrastive learning},
  doi={10.1109/TPAMI.2025.3586824},
  ISSN={1939-3539},
  month={Oct},}@ARTICLE{10155164,
  author={Qi, Jia and Liang, Tengfei and Liu, Wu and Li, Yidong and Jin, Yi},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={A Generative-Based Image Fusion Strategy for Visible-Infrared Person Re-Identification}, 
  year={2024},
  volume={34},
  number={1},
  pages={518-533},
  abstract={Cross-modality person re-identification task is a challenging task aiming to recognize images of the same identity between different modalities. To alleviate the cross-modality discrepancies between images, existing approaches mainly guide models to mine modality invariant features. Although those approaches are effective, they lose the modality-specific features that include important information beneficial to VI-ReID. Therefore, some approaches are using generative adversarial networks to compensate for modality information. However, the quality of images generated by these methods is usually poor, and most of them focus only on the learning of modality-sharable features. To solve these problems, this paper proposes a generative-based cross-modality image fusion strategy (GC-IFS), which can generate high-quality cross-modality paired images and fuse the information of the two modalities. Firstly, considering the importance of the identity discriminative information of the generated image, we propose a contrastive-learning image generation (CLIG) network to generate cross-modality paired images. Meanwhile, to fully integrate and utilize the information of the two modalities and eliminate the influence of cross-modality discrepancies, we design a part-based dual multi-modality feature fusion (P-DMFF) module to extract the unified feature representation. Extensive experiments on SYSU-MM01 and RegDB datasets demonstrate that our strategy outperforms the state-of-the-art methods for the VI-ReID task.},
  keywords={Feature extraction;Image synthesis;Image fusion;Cameras;Lighting;Modal analysis;Identification of persons;Image processing;Cross-modality;person re-identification;compensation of information;image generation;feature fusion},
  doi={10.1109/TCSVT.2023.3287300},
  ISSN={1558-2205},
  month={Jan},}@ARTICLE{10817794,
  author={Liu, Yiwen and Yi, Zhengkun and Fang, Senlin and Zhang, Yupo and Wan, Feng and Yang, Zhi-Xin and Lu, Xu and Wu, Xinyu},
  journal={IEEE Transactions on Automation Science and Engineering}, 
  title={TactCLNet: Tactile Continual Learning Network Based on Generative Replay for Object Hardness Recognition}, 
  year={2025},
  volume={22},
  number={},
  pages={10045-10055},
  abstract={Currently, deep neural networks can be extremely effective in robotic tactile perception. However, a major challenge is to solve the problem of continual learning of robotic tactile perception in an open and dynamic environment. In this paper, we propose a novel continual learning method for the domian incremental learning task in the field of tactile perception. To be specific, we introduce a morphology-specific variational autoencoders which can mitigate catastrophic forgetting by generating pseudo-samples for training in the continual learning process. We integrate the generative model and the discriminative model into one model, which reduces the size of model and improves the continual learning ability. In addition, considering the ordinal information between the hardness levels, we propose to add conditional information to the model and introduce a modified loss function to combine the latent value with the hardness information, which improves the continual learning performance by controlling the distribution and quality of pseudo-sample generation. Following this, we designed a tactile robot experiment, collected hardness data, and tested our model on this object hardness recognition task. We show experimentally that, after training, the model can still maintain the accuracy of more than 94% after learning three tasks in terms. Note to Practitioners—In the field of robotics tactile perception, the issue of continual learning in robots is a crucial problem that urgently requires resolution. We hope robots to effectively engage in continual learning across multiple tasks, ensuring the acquisition of new knowledge while mitigating the risk of forgetting previously acquired knowledge. In this paper, we propose a novel continual learning method for the domian incremental learning task. we introduce a morphology-specific variational autoencoders based on replaying pseudo-samples during continual learning process which reduces the size of model and improves the continual learning ability. We enhance model performance by integrating generative and discriminative models, incorporating conditional information to control the distribution of replayed sample types, and leveraging sequential relationships among samples. It is proved that the proposed method is able to effectively improve the accuracy in a tactile domian incremental learning task.},
  keywords={Continuing education;Robots;Data models;Accuracy;Training;Autoencoders;Intelligent systems;Torque;Incremental learning;Computational modeling;Continual learning;robotic tactile perception;object hardness recognition;ordinal network},
  doi={10.1109/TASE.2024.3516378},
  ISSN={1558-3783},
  month={},}@INPROCEEDINGS{10385992,
  author={Jia, Yi and Zheng, Shanshan and He, Tingting and Jiang, Xingpeng},
  booktitle={2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Predicting Microbe-Metabolite Interactions by Integrating Non-negative Matrix Factorization and Generative Network}, 
  year={2023},
  volume={},
  number={},
  pages={165-170},
  abstract={Despite profound impacts on human health and nature, accurately predicting microbe-metabolite interactions remains challenging due to inherent data noise. This study applies non-negative matrix factorization (NMF) and multi-view NMF to reduce noise and exploit associations across data perspectives. NMF obtains low-dimensional microbial and metabolic representations, effectively reducing noise. The dimension-reduced spectral matrices were input into the generative network model to derive conditional probabilities of individual microbe-associated metabolites and microbe-metabolite co-occurrence probabilities, the latter enabling prediction of microbe-metabolite interactions. Moreover, multi-view NMF integrates microbial and metabolic data by mapping them into a shared subspace, thereby enhancing prediction performance and validating cross-perspective correlation modeling. This study demonstrates NMF's efficacy in noise reduction through dimensionality reduction, and multiview NMF's ability to leverage cross-view associations. Both approaches demonstrate enhanced microbe-metabolite interaction prediction utilizing NMF-based and multi-view NMF-based generative network models.},
  keywords={Dimensionality reduction;Correlation;Biological system modeling;Noise reduction;Predictive models;Data models;Bioinformatics;Non-negative matrix factorization;Microbe-metabolite interactions;Multi-view;Microbiome;Metabolome},
  doi={10.1109/BIBM58861.2023.10385992},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{10898501,
  author={Venkatachalam, Murugappan and V, Vijaya Dhaarshini and P, Chitra and Thiagarajan, Priya},
  booktitle={2024 IEEE 31st International Conference on High Performance Computing, Data and Analytics Workshop (HiPCW)}, 
  title={Comm-bot: Generative AI for Optimising Supply Chains integrating LSTM with LLMs}, 
  year={2024},
  volume={},
  number={},
  pages={209-210},
  abstract={The objective of this paper is to improve the efficiency of supply chains in a small commerce environment. It optimises inventory management by increasing the accuracy of demand prediction and recommends suggestions in natural language. Small businesses face challenges such as budget constraints, unaffordable solutions, and a lack of forecasting expertise, which can result in stock shortages or excess inventory, impacting profitability.},
  keywords={Profitability;Generative AI;High performance computing;Conferences;Supply chains;Natural languages;Inventory management;Forecasting;Long short term memory;Faces},
  doi={10.1109/HiPCW63042.2024.00082},
  ISSN={2770-0135},
  month={Dec},}@ARTICLE{9762718,
  author={Kim, Youngsoo and Ha, Jeonghyo and Cho, Yooshin and Kim, Junmo},
  journal={IEEE Access}, 
  title={Unsupervised Blur Kernel Estimation and Correction for Blind Super-Resolution}, 
  year={2022},
  volume={10},
  number={},
  pages={45179-45189},
  abstract={Blind super-resolution (blind-SR) is an important task in the field of computer vision and has various applications in real-world. Blur kernel estimation is the main element of blind-SR along with the adaptive SR networks and a more accurately estimated kernel guarantees a better performance. Recently, generative adversarial networks (GANs), comparing recurrence patches across scales, have been the most successful unsupervised kernel estimation methods. However, they still involve several problems. ① Their sharpness discrimination ability has been noted as being too weak, causing them to focus more on pattern shapes than sharpness. ② In some cases, kernel correction processes were omitted; however, these are essential because the optimally generated kernel may be narrower than a point spread function (PSF) except when the PSF is ideal low-pass filter. ③ Previous studies also did not consider that GANs are affected by the thickness of edges as well as PSF. Thus, in this paper, 1) we propose a degradation and ranking comparison process designed to induce GAN models to became sensitive to image sharpness, and 2) propose a scale-free kernel correction technique using Gaussian kernel approximation including a thickness parameter. To improve the kernel accuracy further, we 3) propose a combination model of the proposed GAN and DIP(deep image prior) for more supervision, and designed a kernel correction network to propagate gradients through developed correction method. Several experiments demonstrate that our methods enhanced the  $l_{2}$  error and the shape of the kernel significantly. In addition, by combining with ordinary blind-SR algorithms, the best reconstruction accuracy was achieved among unsupervised blur kernel estimation methods.},
  keywords={Kernel;Generative adversarial networks;Estimation;Electronics packaging;Superresolution;Image edge detection;Degradation;Blind super-resolution;kernel estimation;kernel correction;generative adversarial networks;deep image prior},
  doi={10.1109/ACCESS.2022.3170053},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10369395,
  author={Prabu, R.T and Diwakaran, S and Balaji, A and Prathima, Ch and Dhanalakshmi, K. M and Vijayakumar, S},
  booktitle={2023 International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)}, 
  title={Robust Attack Identification Strategy to Prevent Document Image Forgeries by using Enhanced Learning Methodology}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Forgery in images is a long-standing issue that spans back to ancient times. Throughout history, images have been employed as evidence or documentation of events. In the present day, the accessibility of image preprocessing tools and affordable hardware has facilitated the creation of manipulated images with ease, often driven by ulterior motives such as disseminating false information or pursuing personal gains unlawfully. In recent years, the spotlight has turned to Artificial Neural Networks (ANNs), sparking significant interest in the realm of image forgery identification. Nevertheless, prevailing image forgery techniques rooted in ANNs are often specialized, geared towards identifying distinct types of forgeries. Consequently, a pressing need arises for an approach adept at efficiently and accurately uncovering unfamiliar forms of image manipulation. This research fills that gap by presenting a robust deep learning-based system designed specifically to spot fakes while working with double image compression. The model's training hinges upon discerning disparities between an original image and its recompressed iterations. To enhance the model's performance, the Ant Lion Optimization (ALO) technique is employed to fine-tune the features of the input data. Noteworthy for its efficiency, the proposed model stands out as a lightweight solution. Empirical results underscore its prowess, showcasing swifter effectiveness compared to prevailing state-of-the-art technique. Encouragingly, the model achieves an impressive overall validation accuracy of 95.87%, reinforcing its efficacy in identifying image forgeries.},
  keywords={Training;Image coding;Pressing;Learning (artificial intelligence);Forgery;Knowledge management;Hardware;Image Forgery Detection;Artificial Neural Networks;Ant Lion Optimization (ALO) technique;Document Image Forgeries},
  doi={10.1109/RMKMATE59243.2023.10369395},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8803570,
  author={Peng, Bo and Huang, Xing and Wang, Shiyuan and Jiang, Jingfeng},
  booktitle={2019 IEEE International Conference on Image Processing (ICIP)}, 
  title={A Real-Time Medical Ultrasound Simulator Based on a Generative Adversarial Network Model}, 
  year={2019},
  volume={},
  number={},
  pages={4629-4633},
  abstract={This paper presents an artificial intelligence-based ultrasound simulator suitable for medical simulation and clinical training. Particularly, we propose a machine learning approach to realistically simulate ultrasound images based on generative adversarial networks (GANs). Using B-mode ultrasound images simulated by a known ultrasound simulator, Field II, an "image-to-image" ultrasound simulator was trained. Then, through evaluations, we found that the GAN-based simulator can generate B-mode images following Rayleigh scattering. Our preliminary study demonstrated that ultrasound B-mode images from anatomies inferred from magnetic resonance imaging (MRI) data were feasible. While some image blurring was observed, ultrasound B- mode images obtained were both visually and quantitatively comparable to those obtained using the Field II simulator. It is also important to note that the GAN-based ultrasound simulator was computationally efficient and could achieve a frame rate of 15 frames/second using a regular laptop computer. In the future, the proposed GAN-based simulator will be used to synthesize more realistic looking ultrasound images with artifacts such as shadowing.},
  keywords={Ultrasonic imaging;Gallium nitride;Computational modeling;Training;Magnetic resonance imaging;Numerical models;Probability density function;Ultrasound;Generative Adversarial Network;Ultrasound Simulation;Deep Learning},
  doi={10.1109/ICIP.2019.8803570},
  ISSN={2381-8549},
  month={Sep.},}@ARTICLE{10032142,
  author={Yang, Jingjian and Zhang, Gang and Chen, Bei and Wang, Yunda},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Vibration Signal Augmentation Method for Fault Diagnosis of Low-Voltage Circuit Breaker Based on W-CGAN}, 
  year={2023},
  volume={72},
  number={},
  pages={1-11},
  abstract={Low-voltage circuit breaker (LVCB) fault diagnosis based on artificial intelligence (AI) algorithm has always been a research hotspot and got some recent advances. However, AI algorithms usually require sufficient data to train the model, so intelligent fault diagnosis is a challenging task when lack of fault signals. To solve this problem, a fault vibration signal augmentation method based on Wasserstein distance (WD) and conditional generative adversarial networks (CGANs) is proposed in this article. The proposed method uses WD to optimize the adversarial training of generator and discriminator, and thus, the generator can generate vibration signals under different fault conditions, which can be used to extend the training dataset. In order to verify the improvement effect of this method on the accuracy of LVCB fault diagnosis, multiple fault classifiers are trained using generated and real fault signals, and a multidimensional evaluation index system is built to evaluate the classification effect. Experimental results reveal that the method can generate fault signals with high similarity and improve the accuracy of fault diagnosis.},
  keywords={Generative adversarial networks;Vibrations;Fault diagnosis;Circuit faults;Training;Generators;Feature extraction;Data augmentation;fault diagnosis;generative adversarial networks (GANs);low-voltage circuit breaker (LVCB);vibration signals},
  doi={10.1109/TIM.2023.3240228},
  ISSN={1557-9662},
  month={},}@ARTICLE{10680721,
  author={Thakur, Poornima Singh and Chaturvedi, Shubhangi and Khanna, Pritee and Sheorey, Tanuja and Ojha, Aparajita},
  journal={IEEE Transactions on AgriFood Electronics}, 
  title={Real-Time Plant Disease Identification: Fusion of Vision Transformer and Conditional Convolutional Network With C3GAN-Based Data Augmentation}, 
  year={2024},
  volume={2},
  number={2},
  pages={576-586},
  abstract={Climate change, adverse weather conditions, and illegitimate farming practices have caused severe damage to the agricultural ecosystem, resulting in significant crop loss in the last decade. One of the major challenges is the breakout of plant diseases that harm the crop in the field. To address this issue, several artificial intelligence and Internet of Things-based systems have been developed for crop monitoring and containment of plant diseases at early stages. In this article, a real-time plant disease identification system is designed using drone-based surveillance and farmer's input. A lightweight plant disease classification model is deployed in the proposed system using a fusion of a vision transformer and a convolutional neural network. The proposed model deploys conditional attention with a statistical squeeze-and-excitation module to efficiently learn the plant disease patterns from images captured under normal and challenging weather conditions. With only 0.95 million trainable parameters, the performance of the proposed plant disease classification model surpasses that of seven state-of-the-art techniques on five public datasets and an in-house developed maize dataset from drone camera-captured images under varying environmental conditions. To provide a better learning experience of real-world data to the model, a generative adversarial network, C3GAN, inspired by cycleGAN, is proposed for data augmentation of the collected maize dataset. The system keeps updating the model parameters based on the feedback of agriculture experts and farmers when new diseases break out or the model's performance deteriorates on unseen data during the surveillance over a period of time.},
  keywords={Climate change;Generative adversarial networks;Real-time systems;Plant diseases;Classification algorithms;Convolutional neural networks;Conditional convolution (CondConv);generative adversarial network (GAN);maize dataset;real-time plant disease classification;vision transformer (ViT)},
  doi={10.1109/TAFE.2024.3447792},
  ISSN={2771-9529},
  month={Sep.},}@INPROCEEDINGS{11071118,
  author={Reddy Basani, Dinesh Kumar and Lakshmi Gudivaka, Rajya and Grandhi, Sri Harsha and Ramanjaneyulu Gudivaka, Basava and Gudivaka, Raj Kumar and Kamruzzaman, M M},
  booktitle={2025 4th OPJU International Technology Conference (OTCON) on Smart Computing for Innovation and Advancement in Industry 5.0}, 
  title={AI-Powered Motion Analysis in Physical Education: GANs and Bayesian Approaches}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Background: Bayesian models and Generative Adversarial Networks (GANs) are some AI tools that are transforming the analysis of motion in physical education. They address some of the problems in motion capture, namely data quality and diversity and uncertainty quantification, thereby making motion capture systems reliable and personalised for individual use.Objective: Project aims include the development of an artificial-intelligence machine analysis framework that incorporates Bayesian inferences, hence GANs, thereby adding quality assurance to motion prediction, advancement to motion capture, provision for real-time feedback, as well as exercise tailoring for inclusive physical education to individuals.Methods: Bayesian inference was used to analyze uncertainty, and GANs for generating synthetic data and fill in data gaps. In the suggested system, features are extracted, preprocessed, data is collected, and adaptive training is used to come up with a comprehensive motion analysis methodology.Results: The combined GAN-Bayesian method has error rate 7% lesser and accuracy, adaptability, and efficiency at 93%, 92%, and 91%, respectively. In case of students' participation and energy ratios, 96.8% and 93.7%, it could be seen that in response to real-time feedback the system is resilient under all circumstances related to physical education.Conclusion: GANs and Bayesian models are combined to optimize motion capture and analysis, ensuring that data-driven targeted training improves performance, inclusivity, and adaptability. With this innovative framework, the approach to physical education is put to a higher standard.},
  keywords={Training;Analytical models;Technological innovation;Uncertainty;Generative adversarial networks;Feature extraction;Motion capture;Real-time systems;Bayes methods;Motion analysis;AI-powered motion analysis;Generative Adversarial Networks;Bayesian inference;physical education;personalized training;motion capture;real-time feedback},
  doi={10.1109/OTCON65728.2025.11071118},
  ISSN={},
  month={April},}@INBOOK{10979670,
  author={},
  booktitle={Wearable Technology IEEE CASS Seasonal School 2024}, 
  title={Chapter 10 Bringing Generative AI on Wearables}, 
  year={2025},
  volume={},
  number={},
  pages={108-119},
  abstract={This book is the result of a groundbreaking milestone CASS seasonal school dedicated to Wearable Technology that was held for the first time in Africa. It is a reference on the evolving terrain of wearable tech and circuit-based technologies in specific fields including data processing and signal analysis, enhancing patient monitoring, and improving quality of life for senior adults. It also covers broad topics such as trends in wearable technology and the art of circuit design. The seasonal school provided exclusive opportunities for attendees to interact with renowned experts across multiple domains. Participants gained invaluable insights into the forefront of innovation, equipping them with the knowledge and skills necessary to thrive in this rapidly evolving field. The school brought forward real-world examples as well as the latest global advancements in wearable technology. Facilitating direct engagement with leading experts in the field and fostering networking opportunities, the school served as a center for knowledge exchange and professional growth.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788743801788},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10979670},}@INPROCEEDINGS{10308170,
  author={Dwivedi, Shubham and Sandhan, Tushar and Pandey, Om Jee and Hegde, Rajesh M},
  booktitle={2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Small-World Inspired Neural Network (SW-NN) for an Effective and Accurate Diagnosis of Diabetes}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={As the use of artificial intelligence in medical diagnosis is growing, the need for enhanced efficacy is becoming paramount. By merging the robustness of neural networks with the distinctive attributes of small-world networks (SWN), the possibility arises for even greater levels of accuracy with maintaining good generalizability. This work presents a novel approach for diagnosing diabetes using a Small-World inspired Neural Network (SW-NN). By constructing a SW-NN using Newman-Watts algorithm, we employ its architecture to classify diabetes and compare it to a conventional NN. The SW-NN outperforms the conventional NN in classification accuracy and evaluation metrics as shown by the experimental results. Our accuracy analysis conclusively demonstrates the superiority of the SW-NN, highlighting its potential to improve diabetes diagnosis.},
  keywords={Measurement;Merging;Artificial neural networks;Computer architecture;Robustness;Diabetes;Classification algorithms;Diabetes;Neural networks;Small-World Networks;Newman-Watts algorithm;Biomedical analysis},
  doi={10.1109/ICCCNT56998.2023.10308170},
  ISSN={2473-7674},
  month={July},}@INPROCEEDINGS{10376108,
  author={Deng, Haiyu and Wang, Xu and Yu, Guangsheng and Dang, Xiaocui and Liu, Ren Ping},
  booktitle={2023 22nd International Symposium on Communications and Information Technologies (ISCIT)}, 
  title={A Novel Weights-less Watermark Embedding Method for Neural Network Models}, 
  year={2023},
  volume={},
  number={},
  pages={25-30},
  abstract={Deep learning-based Artificial Intelligence (AI) technology has been extensively used recently. AI model theft is a regular occurrence. As a result, many academics focus their efforts on safeguarding the Intellectual Property (IP) of trained Neural Network (NN) models. The majority of the most recent white-box setting watermark embedding methods rely on modifying model weights. Weights updated for the NN model during training must take into account the initial task as well as the embedding of watermarks. As a result, the accuracy of the initial task will be affected, necessitating more training time. This research proposes a novel weights-less watermark embedding method for deep neural networks to address this issue. Without actually embedding the watermark within the NN model weights, it uses a principle of code matching between the watermark and the weights. The proposed method requires less time than existing white-box setting watermark embedding methods, and the accuracy of the original task is not much diminished. Additionally, since the NN model weights are left alone, their statistical distribution will remain unchanged, giving the model increased resistance to watermark detection. The experiments in this paper demonstrate the effectiveness, efficiency, and robustness of our method.},
  keywords={Training;Resistance;Statistical distributions;Watermarking;Artificial neural networks;Intellectual property;Robustness;Watermark Embedding;Deep Learning;Neural Networks;Intellectual Property},
  doi={10.1109/ISCIT57293.2023.10376108},
  ISSN={2643-6175},
  month={Oct},}@ARTICLE{10990238,
  author={Qin, Xiaoqi and Sun, Mengying and Dai, Jincheng and Ma, Peixuan and Cao, Yuecheng and Zhang, Jingjing and Wang, Jiacheng and Xu, Xiaodong and Zhang, Ping and Niyato, Dusit},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Generative AI Meets Wireless Networking: An Interactive Paradigm for Intent-Driven Communications}, 
  year={2025},
  volume={11},
  number={4},
  pages={2056-2077},
  abstract={This paper introduces an innovative paradigm in interactive wireless networking, leveraging large language models (LLMs) and generative artificial intelligence (GenAI) to dynamically align network configurations and transmission strategies with user intents. Central to this paradigm is a “human-in-the-loop” framework that incorporates two pivotal processes: intent alignment with the network and streamlined user interaction. Existing quality of experience (QoE) modeling methodologies often suffer from a weak correlation between user intent and network adjustments. To address this, we review intent consistency in QoE modeling, utilizing reinforcement learning from human feedback (RLHF) and advanced prompt engineering to seamlessly integrate human intent into network configurations. Surrounding our paradigm, we provide a comprehensive survey on a multi-layered integration that spans the application, intent, semantic, network, and transmission layers, seamlessly translating user intent into optimized networking and communication outcomes. We investigate key technologies such as semantic communication and GenAI-enabled transmission and networking for pioneering applications, which allow for the real-time understanding and execution of high-layer intents, enabling the integration of user intents with wireless networks. Additionally, we explore cloud-edge-device collaboration within our paradigm, which distributes computational and semantic tasks across the network infrastructure to enable low-latency, scalable, and intelligent interactions. The paper concludes with an analysis of existing challenges and prospective research directions, highlighting the transformative potential of GenAI in shaping the future of intent-driven wireless networks.},
  keywords={Quality of experience;Wireless networks;Artificial intelligence;Prompt engineering;Diffusion models;Reinforcement learning;Semantic communication;Optimization;Collaboration;Training;Interactive wireless networks;generative artificial intelligence (GenAI);large language models (LLMs);human-in-the-loop;reinforcement learning from human feedback (RLHF);experience of quality (QoE);intent alignment;semantic communication (SemCom)},
  doi={10.1109/TCCN.2025.3567613},
  ISSN={2332-7731},
  month={Aug},}@ARTICLE{11106256,
  author={Tang, Xin and Chen, Qian and Weng, Wenjie and Jin, Chao and Liu, Zhang and Wang, Jiacheng and Sun, Geng and Li, Xiaohuan and Niyato, Dusit},
  journal={IEEE Transactions on Mobile Computing}, 
  title={Task Assignment and Exploration Optimization for Low Altitude UAV Rescue via Generative AI Enhanced Multi-agent Reinforcement Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-17},
  abstract={The integration of emerging uncrewed aerial vehicle (UAV) with artificial intelligence (AI) and ground-embedded robots (GERs) has transformed emergency rescue operations in unknown environments. However, the high computational demands of such missions often exceed the capacity of a single UAV, making it difficult for the system to continuously and stably provide high-level services. To address these challenges, this paper proposes a novel cooperation framework involving UAVs, GERs, and airships. This framework enables resource pooling through UAV-to-GER (U2G) and UAV-to-airship (U2A) communications, providing computing services for UAV offloaded tasks. Specifically, we formulate the multi-objective optimization problem of task assignment and exploration optimization in UAVs as a dynamic long-term optimization problem. Our objective is to minimize task completion time and energy consumption while ensuring system stability over time. To achieve this, we first employ the Lyapunov optimization method to transform the original problem, with stability constraints, into a per-slot deterministic problem. We then propose an algorithm named HG-MADDPG, which combines the Hungarian algorithm with a generative diffusion model (GDM)-based multi-agent deep deterministic policy gradient (MADDPG) approach, to jointly optimize exploration and task assignment decisions. In HG-MADDPG, we first introduce the Hungarian algorithm as a method for exploration area selection, enhancing UAV efficiency in interacting with the environment. We then innovatively integrate the GDM and multi-agent deep deterministic policy gradient (MADDPG) to optimize task assignment decisions, such as task offloading and resource allocation. Simulation results demonstrate the effectiveness of the proposed approach, with significant improvements in task offloading efficiency, latency reduction, and system stability compared to baseline methods.},
  keywords={Autonomous aerial vehicles;Optimization;Artificial intelligence;Stability criteria;Mobile computing;Energy consumption;Training;Real-time systems;Optimization methods;Heuristic algorithms;Task assignment;exploration optimization;low-altitude economy;uncrewed aerial vehicle;emergency rescue;generative artificial intelligence;multi-agent reinforcement learning},
  doi={10.1109/TMC.2025.3594188},
  ISSN={1558-0660},
  month={},}@ARTICLE{10066310,
  author={Struski, Łukasz and Sadowski, Michał and Danel, Tomasz and Tabor, Jacek and Podolak, Igor T.},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Feature-Based Interpolation and Geodesics in the Latent Spaces of Generative Models}, 
  year={2024},
  volume={35},
  number={9},
  pages={12068-12082},
  abstract={Interpolating between points is a problem connected simultaneously with finding geodesics and study of generative models. In the case of geodesics, we search for the curves with the shortest length, while in the case of generative models, we typically apply linear interpolation in the latent space. However, this interpolation uses implicitly the fact that Gaussian is unimodal. Thus, the problem of interpolating in the case when the latent density is non-Gaussian is an open problem. In this article, we present a general and unified approach to interpolation, which simultaneously allows us to search for geodesics and interpolating curves in latent space in the case of arbitrary density. Our results have a strong theoretical background based on the introduced quality measure of an interpolating curve. In particular, we show that maximizing the quality measure of the curve can be equivalently understood as a search of geodesic for a certain redefinition of the Riemannian metric on the space. We provide examples in three important cases. First, we show that our approach can be easily applied to finding geodesics on manifolds. Next, we focus our attention in finding interpolations in pretrained generative models. We show that our model effectively works in the case of arbitrary density. Moreover, we can interpolate in the subset of the space consisting of data possessing a given feature. The last case is focused on finding interpolation in the space of chemical compounds.},
  keywords={Interpolation;Kernel;Data models;Manifolds;Extraterrestrial measurements;Brain modeling;Computational modeling;Computational and artificial intelligence;deep learning;machine learning;representation learning},
  doi={10.1109/TNNLS.2023.3251848},
  ISSN={2162-2388},
  month={Sep.},}@INPROCEEDINGS{10849434,
  author={Régin, Florian and De Maria, Elisabetta},
  booktitle={2024 IEEE 36th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Generative Constraint Programming Revisited}, 
  year={2024},
  volume={},
  number={},
  pages={18-26},
  abstract={Around twenty years ago, Generative Constraint Programming techniques, such as the Generative Constraint Satisfaction Problem (GCSP), were developed to deal with problems mainly based on functional constraints or relaxation of such constraints, like the ones in industrial configuration problems. In 2023, we introduced On-the-fly Constraint Programming Search (OTFS), inspired by GCSP, to successfully tackle Model Checking problems that have a lot of functional constraints. This paper aims to show that a revised version of OTFS, called GenCP, can also be used on classical textbook CP problems that do not involve constraints resembling functional constraints: the NQueens and All-Interval problems, and two lesser known CP problems, Graceful Graphs and Langford Number. GenCP significantly reduces execution times on these problems, showing that it is a valid alternative to traditional CP.},
  keywords={Constraint handling;Model checking;Search problems;Artificial intelligence;Standards;constraint programming;generative;on-the-fly;nqueens;allinterval;graceful graphs;langford number;gencp},
  doi={10.1109/ICTAI62512.2024.00012},
  ISSN={2375-0197},
  month={Oct},}@INPROCEEDINGS{10850944,
  author={Maaloul, Kamel},
  booktitle={2024 1st International Conference on Electrical, Computer, Telecommunication and Energy Technologies (ECTE-Tech)}, 
  title={Identifying AI-Written Text in Academia: A Machine Learning-Based Framework}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The rise of AI-generated text poses new challenges to academic integrity, requiring robust mechanisms to identify and differentiate human-written content from machine-generated material in scholarly publications. This paper presents a machine learning-based framework for detecting AI-written text in academia, combining multiple techniques including stylometry, semantic analysis, and citation pattern recognition. The framework utilizes supervised classification models trained on features such as lexical diversity, syntactic complexity, and redundancy patterns to distinguish AI-generated content from genuine research writing. Additionally, unsupervised anomaly detection techniques are employed to flag unusual stylistic deviations. The framework also integrates traditional plagiarism detection tools and enlists human expert review for validating suspicious sections. By addressing both technical and ethical considerations, this approach aims to preserve the authenticity of academic work while adapting to the evolving landscape of AI-driven content generation.},
  keywords={Ethics;Reviews;Plagiarism;Semantics;Diversity reception;Termination of employment;Syntactics;Communications technology;Pattern recognition;Complexity theory;Generative artificial intelligence;research pa-pers;machine learning;AI-generated text;Framework},
  doi={10.1109/ECTE-Tech62477.2024.10850944},
  ISSN={},
  month={Dec},}@ARTICLE{4685900,
  author={Marks, Tim K. and Hershey, John R. and Movellan, Javier R.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Tracking Motion, Deformation, and Texture Using Conditionally Gaussian Processes}, 
  year={2010},
  volume={32},
  number={2},
  pages={348-363},
  abstract={We present a generative model and inference algorithm for 3D nonrigid object tracking. The model, which we call G-flow, enables the joint inference of 3D position, orientation, and nonrigid deformations, as well as object texture and background texture. Optimal inference under G-flow reduces to a conditionally Gaussian stochastic filtering problem. The optimal solution to this problem reveals a new space of computer vision algorithms, of which classic approaches such as optic flow and template matching are special cases that are optimal only under special circumstances. We evaluate G-flow on the problem of tracking facial expressions and head motion in 3D from single-camera video. Previously, the lack of realistic video data with ground truth nonrigid position information has hampered the rigorous evaluation of nonrigid tracking. We introduce a practical method of obtaining such ground truth data and present a new face video data set that was created using this technique. Results on this data set show that G-flow is much more robust and accurate than current deterministic optic-flow-based approaches.},
  keywords={Tracking;Gaussian processes;Optical filters;Inference algorithms;Deformable models;Stochastic processes;Filtering;Computer vision;Image motion analysis;Robustness;Computer vision;generative models;motion;shape;texture;video analysis;face tracking.;Computer vision;Generative models;Motion;Vision and Scene Understanding;Artificial Intelligence;Computing Methodologies;Shape;Texture;Face tracking;Tracking;Scene Analysis;Image Processing;and Computer Vision},
  doi={10.1109/TPAMI.2008.278},
  ISSN={1939-3539},
  month={Feb},}@INPROCEEDINGS{10893118,
  author={Kusam, Venkata Alekhya and Shrestha, Summit and Kattan, Khalid and Maxim, Bruce and Song, Zheng},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={A PBL-Based Mini Course Module for Teaching Computer Science Students to Utilize Generative AI for Enhanced Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research-to-practice paper introduces a mini-course module designed to teach computer science students how to interact more efficiently with Generative AI(GAI). The rapid rise of GAI is transforming education by providing students with easy access to knowledge and answers to their questions, acting as a personal tutor. Particularly in the field of computer science, where GAI can easily generate code based on specific requirements, many instructors struggle to prevent students from using tools like ChatGPT for completing assigned programming assignments and homeworks. However, we argue that 1) the use of GAI is inevitable, necessitating a redesign of courses so that students cannot merely rely on GAI without actual learning; and 2) students' learning can be enhanced if they learn to use GAI more effectively. In this paper, we demonstrate how we integrate Project-Based Learning to design the course module in a concise yet effective manner, which not only facilitates students' learning of GAI but also enriches their learning in relation to the host course where this mini-course module is embedded. In particular, the goal of this module is to teach CS students: 1) the basic principles and workflow of GAI; 2) Prompt Engineering: how to craft questions to interact more effectively with GAI; and 3) Extending GAI: how to create interactive tools by training customized GAI models. Designed to be completed within two weeks, the mini-course module can easily be incorporated into host courses. This mini-course module was integrated into a graduate-level Artificial Intelligence course with 42 students in Winter 2024. To assess the module's impact on student learning and engagement, we conducted pre- and post-course surveys as well as student interviews. The results from the surveys and interviews highlighted key areas for improving the design of educational modules to better teach essential GAI skills. These insights focused on enhancing student engagement and learning efficiency within a concise time frame.},
  keywords={Surveys;Training;Codes;Navigation;Chatbots;Prompt engineering;Interviews;Programming profession;Generative AI;Course Module Design;Project Based Learning(PBL)},
  doi={10.1109/FIE61694.2024.10893118},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10984120,
  author={Singh, Ved Prakash and Jena, Shubhashish and Mathew, Jimson and Taori, Alok},
  booktitle={2024 IEEE India Geoscience and Remote Sensing Symposium (InGARSS)}, 
  title={Harnessing Futuregans For High-Resolution Thunderstorm And Lightning Nowcasting Over Bhopal Region}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={The accurate prediction and quantification of severe weather events, such as heavy rainfall and lightning; remain imperative for disaster management. The implementation of a realtime predictive model that aims to enhance the precision tracking and development of clouds along with estimation of Vertically Integrated Liquid (VIL) over a region for shortterm forecasting (nowcasting) of thunderstorm events using artificial intelligence (AI) based future prediction models. Integrating AI with remote sensing technologies (Radar and satellite) datasets offers a promising approach to improve the prediction and alerting mechanisms for these extreme weather phenomena. In this work, we leveraged the highresolution Doppler Weather RADAR (DWR) imagery of India Meteorological Department (IMD)-Bhopal, ISRO’s NRSC-LDS Network and other data sources (such as Automatic Weather Station (AWS), electric field (EF) recorder and other sensors) to feed to machine learning (ML) models (Generative Adversarial Networks - FutureGAN) for the prediction of thunderstorm-bearing clouds development, their movement and associated lightning threats. Ultimately, the proposed model produces the high-resolution nowcasting of cloud-to-ground lightning strikes in near-future (30 minutes to 1 hour lead time) in the specified Radar coverage area. The nowcast accuracy for thunderstorm/ lightning predictions obtained from proposed model was found to be $80-85 \%$ in June month of studied years around Bhopal city observatory.},
  keywords={Radar remote sensing;Meteorological radar;Accuracy;Clouds;Spaceborne radar;Urban areas;Lightning;Predictive models;Radar imaging;Doppler radar;Weather warnings;Doppler Weather RADAR;Vertically Integrated Liquid;AI/ ML;Deep Learning (DL);Generative Adversarial Networks;FutureGANs;Lightning},
  doi={10.1109/InGARSS61818.2024.10984120},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11064066,
  author={Jasmine, A. Sharan and Suganthi, B.},
  booktitle={2025 3rd International Conference on Communication, Security, and Artificial Intelligence (ICCSAI)}, 
  title={Perception of Essential Sound in Cochlear Implants: Prediction Using Deep Learning Techniques}, 
  year={2025},
  volume={3},
  number={},
  pages={361-367},
  abstract={Cochlear Implant (CI) is the intricate electronic gadget that offers the auditory sense for people who were afflicted with sensorineural hearing loss. It differs from the other hearing aid devices by its acoustic output signal and emulates the herbal listening to function the inner ear through digital stimulation. It stimulates the auditory nerve by applying electric signals to the electrodes which are present inside the cochlea. The auditory nerve sends those signals to the brain to recognize as sound. The performance of CI is sufficient good in the quiet environment, but they are facing more challenges in the noisy environment due to multi-talker and unwanted obstructions. The background noise degrades the functionality of these devices. The hearing ability of CI users depends on the sound stream segregation in the real world listening environment namely, monaural and binaural cues. Hence the CI users require more advanced strategies and algorithms to enhance the hearing ability. This paper provides a detailed review upon the sound recognition algorithms and sound coding strategies which are implemented to improve the intelligibility scores. In the further context of sound quality improvement, music perception, residual acoustic hearing, etc. we analysed the development and present a conceptual frame work to address these issues by focusing on recent works made for achieving higher intelligibility scores, ease of listening using Deep Learning techniques. This paper aims to provide a comprehensive exploration predominantly in the advancement of sound recognition techniques for CI users in reverberation environment through Deep Neural Network implementation.},
  keywords={Deep learning;Training;Cochlear implants;Reviews;Auditory system;Artificial neural networks;Ear;Image restoration;Artificial intelligence;Sound recognition;Cochlear implants;Deep learning;Speech intelligibility},
  doi={10.1109/ICCSAI64074.2025.11064066},
  ISSN={},
  month={April},}@INPROCEEDINGS{10310635,
  author={Hamdaoui, Feriel and Sghaier, Amra and Bdioui, Ahlem and Hmissa, Sihem},
  booktitle={2023 International Conference on Innovations in Intelligent Systems and Applications (INISTA)}, 
  title={A machine learning model for cancer staging, case study: uveal cancer}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={The fields of medicine and computer science have advanced in parallel, providing revolutionary techniques for the diagnosis and treatment of serious diseases. However, despite the accuracy of medical imaging devices, cancer remains a difficult diagnosis. To address this issue, artificial intelligence is increasingly being used for cancer detection. Our work involves in-depth research on the most effective machine learning methods to apply them in the field of medicine. Our key findings include high accuracy in staging uveal cancers using targeted techniques as GAN, and the development of a web application to assist physicians with prediction tasks.},
  keywords={Technological innovation;Medical services;Machine learning;Streaming media;Generative adversarial networks;Cancer detection;Reliability;Machine Learning;uveal cancer;staging;GAN;web app},
  doi={10.1109/INISTA59065.2023.10310635},
  ISSN={2768-7295},
  month={Sep.},}@ARTICLE{9676641,
  author={Cramer, Eike and Gorjão, Leonardo Rydin and Mitsos, Alexander and Schäfer, Benjamin and Witthaut, Dirk and Dahmen, Manuel},
  journal={IEEE Access}, 
  title={Validation Methods for Energy Time Series Scenarios From Deep Generative Models}, 
  year={2022},
  volume={10},
  number={},
  pages={8194-8207},
  abstract={The design and operation of modern energy systems are heavily influenced by time-dependent and uncertain parameters, e.g., renewable electricity generation, load-demand, and electricity prices. These are typically represented by a set of discrete realizations known as scenarios. A popular scenario generation approach uses deep generative models (DGM) that allow scenario generation without prior assumptions about the data distribution. However, the validation of generated scenarios is difficult, and a comprehensive discussion about appropriate validation methods is currently lacking. To start this discussion, we provide a critical assessment of the currently used validation methods in the energy scenario generation literature. In particular, we assess validation methods based on probability density, auto-correlation, and power spectral density. Furthermore, we propose using the multifractal detrended fluctuation analysis (MFDFA) as an additional validation method for non-trivial features like peaks, bursts, and plateaus. As representative examples, we train generative adversarial networks (GANs), Wasserstein GANs (WGANs), and variational autoencoders (VAEs) on two renewable power generation time series (photovoltaic and wind from Germany in 2013 to 2015) and an intra-day electricity price time series form the European Energy Exchange in 2017 to 2019. We apply the four validation methods to both the historical and the generated data and discuss the interpretation of validation results as well as common mistakes, pitfalls, and limitations of the validation methods. Our assessment shows that no single method sufficiently characterizes a scenario but ideally validation should include multiple methods and be interpreted carefully in the context of scenarios over short time periods.},
  keywords={Time series analysis;Generators;Training;Stochastic processes;Wind power generation;Generative adversarial networks;Fluctuations;Artificial neural networks;machine learning;time series analysis;uncertainty;stochastic processes;solar power generation;wind power generation},
  doi={10.1109/ACCESS.2022.3141875},
  ISSN={2169-3536},
  month={},}@ARTICLE{10076456,
  author={Islam, Ashhadul and Belhaouari, Samir Brahim},
  journal={IEEE Access}, 
  title={Fast and Efficient Image Generation Using Variational Autoencoders and K-Nearest Neighbor OveRsampling Approach}, 
  year={2023},
  volume={11},
  number={},
  pages={28416-28426},
  abstract={Researchers gravitate towards Generative Adversarial Networks (GAN) to create artificial images. However, GANs suffer from convergence issues, mode collapse, and overall complexity in balancing the Nash Equilibrium. Images generated are often distorted, rendering them useless. We propose a combination of Variational Autoencoders (VAEs) and a statistical oversampling method called K-Nearest Neighbor OveRsampling (KNNOR) to create artificial images. This combination of VAE and KNNOR results in more life-like images with reduced distortion. We fine-tune several pre-trained networks on a separate set of real and fake face images to test images generated by our method against images generated by conventional Deep Convolutional GANs (DCGANs). We also compare the combination of VAEs and Synthetic Minority Oversampling Technique (SMOTE) to establish the efficacy of KNNOR against naive oversampling methods. Not only are our methods better able to convince the classifiers that the images generated are authentic, but the models are also half in size of DCGANs. The code is available at GitHub for public use.},
  keywords={Generators;Feature extraction;Generative adversarial networks;Decoding;Training;Nash equilibrium;Image synthesis;Face recognition;variational autoencoders;generative adversarial networks;image reconstruction;artificial image creation},
  doi={10.1109/ACCESS.2023.3259236},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10475265,
  author={Shahinzadeh, Hossein and Mahmoudi, Arezou and Asilian, Amirhosein and Sadrarhami, Hamidreza and Hemmati, Mohammadreza and Saberi, Yaghoub},
  booktitle={2024 20th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP)}, 
  title={Deep Learning: A Overview of Theory and Architectures}, 
  year={2024},
  volume={},
  number={},
  pages={1-11},
  abstract={Deep learning (DL), a dynamic subset of machine learning inspired by the human brain, has evolved into a transformative force, showcasing remarkable capabilities across diverse domains. Often referred to as the “Artificial Neural Network,” DL involves neural networks with three or more layers. The integration of DL with the progression of Big Data has facilitated the deployment of intricate neural networks, enabling autonomous analysis of features and correlations within extensive datasets, whether structured or unstructured. Noteworthy is the heightened performance exhibited by DL algorithms when confronted with substantial volumes of data. This paper offers a comprehensive exploration of DL from multifaceted viewpoints, incorporating recent advancements in the field. Beyond elucidating the conceptual and theoretical foundations, the paper systematically addresses challenges, highlights advantages, and proposes solutions intrinsic to DL. Furthermore, it delves into future works in DL, identifying evolving trends and promising areas of exploration such as medical diagnostics, sports training, and energy-efficient approaches. The overarching goal of this paper is to contribute to the continued evolution and widespread application of DL across diverse sectors. By encapsulating the holistic landscape of DL, the research presented herein strives to provide a comprehensive resource for researchers, practitioners, and enthusiasts seeking insights into the current state and future directions of this transformative field.},
  keywords={Training;Deep learning;Signal processing algorithms;Reinforcement learning;Signal processing;Market research;Energy efficiency;Deep learning;Neural networks;Artificial intelligence;Machine learning;Supervised learning;Intelligent systems;Pattern recognition;Computer architecture;Object detection;Computer vision},
  doi={10.1109/AISP61396.2024.10475265},
  ISSN={2640-5768},
  month={Feb},}@INPROCEEDINGS{11147616,
  author={Rai, Nitin and Schumann, Arnold Walter and Boyd, Nathan},
  booktitle={2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={PhytoSynth: Leveraging Multi-modal Generative Models for Crop Disease Data Generation with Novel Benchmarking and Prompt Engineering Approach}, 
  year={2025},
  volume={},
  number={},
  pages={5371-5380},
  abstract={Collecting large-scale crop disease images in the field is labor-intensive and time-consuming. Generative models (GMs) offer an alternative by creating synthetic samples that resemble real-world images. However, existing research primarily relies on Generative Adversarial Net-works (GANs)-based image-to-image translation and lack a comprehensive analysis of computational requirements in agriculture. Therefore, this research explores a multi-modal text-to-image approach for generating synthetic crop disease images and is the first to provide computational benchmarking in this context. We trained three Stable Diffusion (SD) variants-SDXL, SD3.5M (medium), and SD3.5L (large)-and fine-tuned them using Dreambooth and Low-Rank Adaptation (LoRA) fine-tuning techniques to enhance generalization. SD3.5M outperformed the others, with an average memory usage of 18 GB, power consumption of 180 W, and total energy use of 1.02 kWh/500 images (~0.002 kWh/image) during inference task. Our results demonstrate SD3.5M's ability to generate 500 synthetic images from Just 36 in-field samples in ~ 1.5 hours. We recommend SD3.5M for efficient crop disease data generation.},
  keywords={Adaptation models;Translation;Computational modeling;Standards organizations;Crops;Organizations;Benchmark testing;Data collection;Prompt engineering;Diseases;Agriculture;Generative artificial intelligence;Crop disease;Diffusion models;Synthetic dataset.},
  doi={10.1109/CVPRW67362.2025.00534},
  ISSN={2160-7516},
  month={June},}@INPROCEEDINGS{10689826,
  author={Paulose, Renjith and Neelanath, Vinod},
  booktitle={2024 IEEE Recent Advances in Intelligent Computational Systems (RAICS)}, 
  title={Generative AI-Driven Automation of Business Process ReImagination}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Traditional business process automation primarily concentrates on digitizing processes to achieve specific outcomes. However, it grapples with challenges stemming from manual configurations and inflexible workflows, restricting adaptability and creativity. This paper delves into the transformative potential of Generative Artificial Intelligence (AI) in revolutionizing process automation, addressing the limitations inherent in traditional approaches. In contrast to traditional automation, Generative AI adopts a groundbreaking approach by harnessing data from past automation solutions to identify more effective methods. This goes beyond conventional orchestration, dynamically integrating software components, automatically generating rules from historical automation solutions data, and seamlessly integrating external systems. Generative AI unlocks its potential through the analysis of past workflows, gaining insights into components, decisions, and sequences. This knowledge serves as the foundation for creating new, efficient processes based on user-described natural language, resulting in robust workflows and rules that assimilate lessons from past best practices and adapt as needed. This innovative approach signifies a notable departure from traditional constraints, paving the way for a future where business processes evolve dynamically, aligning with the efficiency demands of the ever-changing digital landscape.},
  keywords={Automation;Accuracy;Generative AI;Natural languages;Manuals;Flowering plants;Software;Fuels;Creativity;Business;Generative AI;Large Language Model;business process automation;intelligent automation},
  doi={10.1109/RAICS61201.2024.10689826},
  ISSN={2769-5565},
  month={May},}@INPROCEEDINGS{10535000,
  author={Ji, Eric and Dong, Boxiang and Samanthula, Bharath and Zhou, Na},
  booktitle={2023 IEEE MIT Undergraduate Research Technology Conference (URTC)}, 
  title={2D-FACT: Dual-Domain Fake Image Detection Against Text-to-Image Generative Models}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Recent developments in generative artificial intelligence are bringing great concerns for privacy, security and misinformation. Our work focuses on the detection of fake images generated by text-to-image models. We propose a dual-domain CNN-based classifier that utilizes image features in both the spatial and frequency domain. Through an extensive set of experiments, we demonstrate that the frequency domain features facilitate high accuracy, zero-transfer learning between different generative models, and faster convergence. To our best knowledge, this is the first effective detector against generative models that are finetuned for a specific subject.},
  keywords={Training;Resistance;Analytical models;Privacy;Generative AI;Frequency-domain analysis;Feature extraction;AI generative model;fake image detection;frequency domain},
  doi={10.1109/URTC60662.2023.10535000},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10792859,
  author={He, Yelu},
  booktitle={2024 9th International Conference on Intelligent Informatics and Biomedical Sciences (ICIIBMS)}, 
  title={Diving Deep: The Role of Deep Learning in Medical Image Analysis, Today and Tomorrow}, 
  year={2024},
  volume={9},
  number={},
  pages={537-540},
  abstract={The rapid advancement of information technology and the extensive application of computer technology have led to a significant increase in the scale of information systems, while the volume of data generated across various industries is also expanding rapidly. In the medical sector, the accumulation of unstructured data has reached new heights. Therefore, exploring more effective methods for processing medical imaging data to enhance diagnostic accuracy and efficiency is particularly important. With the continuous advancement of medical informatization, the integration of big data and artificial intelligence technologies in the medical field has become a new trend in industry development. This article will focus on the automated analysis and diagnosis of medical imaging using deep learning technology, provide a brief overview of the current status of deep learning applications in the main technical fields of medical imaging, and analyze the challenges and prospects it faces in clinical applications in medical imaging.},
  keywords={Deep learning;Industries;Ethics;Image analysis;Accuracy;Navigation;Medical services;Market research;Sustainable development;Medical diagnostic imaging;Deep learning;medical imaging;research status;development prospect},
  doi={10.1109/ICIIBMS62405.2024.10792859},
  ISSN={2189-8723},
  month={Nov},}@ARTICLE{10918835,
  author={Feng, Zhixi and Pei, Hongze and Yang, Shuyuan and Yang, Chen},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Fine-Grained Open Set Signal Modulation Classification via Self-Supervised Pre-Training}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Open set automatic modulation classification (OAMC) can identify unexpected unknown modulation types in real-world scenarios, which is receiving increasing interests in electronic countermeasures and signal recognition. However, existing OAMC methods rely on a large number of accurate labeled data, which makes the generalization ability of models poor and undoubtedly brings tremendous difficulties and challenges, especially in the case of limited labeled information. In addition, they only implement simple unknown detection without fine-grained unknown classification, which is necessary especially in areas that require high adaptability and robustness to unknown classes. Therefore, this paper proposes a CNNbased learning framework via self-supervised pre-training with out-of-distribution (OOD) generation and quadratic discrimination for fine-grained OAMC, named FOSSP, to address related problems. First, we use self-supervised pre-training learning paradigm in which a reformed de-biasing weighted contrastive loss is introduced to handle sample imbalance. To effectively capture the semantic features of the signals, we employ a tailored blend of loss functions including reconstruction loss, center loss, and cross-entropy. These are complemented by a suitable distance metric to ensure that the minimal distance between semantic features exceeds the maximum intra-class distance. Despite in the absence of training data for specific signal classes, the proposed FOSSP can distinguish between known and unseen signals. Moreover, FOSSP can determine what kind of unknown class it belongs to when a new signal instance appears. Extensive experiments are conducted on four benchmarks and the results demonstrate the effectiveness of FOSSP.},
  keywords={Modulation;Feature extraction;Training;Artificial intelligence;Support vector machines;Filtering;Data models;Data collection;Adaptation models;Accuracy;Open set automatic modulation classification;Fine-grained unknown classification;Self-supervised pre-training;Quadratic discrimination},
  doi={10.1109/TCCN.2025.3549608},
  ISSN={2332-7731},
  month={},}@INPROCEEDINGS{10544854,
  author={Patel, Shashank and Pandey, Mudita and D, Rajeswari},
  booktitle={2024 International Conference on Inventive Computation Technologies (ICICT)}, 
  title={Skin Cancer Classification using CNN and Transfer Learning (TL)}, 
  year={2024},
  volume={},
  number={},
  pages={808-813},
  abstract={Skin cancer is a predominant and possibly lethal condition that distresses people across the world. Primary detection and precise finding are crucial for leveraging efficacious treatment and enhanced patient consequences. This research study explores the application off Artificial Intelligence (AI) resolutions for the primary finding and analysis of skin cancer. The study leverages a dataset of dermatological images and employs various ML methods, including Convolutional Neural Networks (CNNs), Support Vector Machines (SVMs), and decision trees, to analyse the existence of skin cancer with a higher degree of accuracy. By utilizing a combination of image processing and feature extraction, the AI model demonstrates higher performance in classifying skin lesions into malignant or benign categories. The proposed model has achieved an accuracy rate of 98.52%, making the AI-based system a promising tool for dermatologists and healthcare professionals.},
  keywords={Support vector machines;Technological innovation;Dermatology;Transfer learning;Collaboration;Medical services;Skin;Skin cacer diagnosis;Dermoscopy;Convolutional neural networks;Early detection;Healthcare technology},
  doi={10.1109/ICICT60155.2024.10544854},
  ISSN={2767-7788},
  month={April},}@INBOOK{10948961,
  author={Banafa, Ahmed},
  booktitle={Artificial Intelligence in Action: Real-World Applications and Innovations}, 
  title={11 Can We Stop Robots from Replacing Humans}, 
  year={2025},
  volume={},
  number={},
  pages={71-80},
  abstract={This comprehensive book dives deep into the current landscape of AI, exploring its fundamental principles, development challenges, potential risks, and the cutting-edge breakthroughs that are propelling it forward. Artificial intelligence (AI) is rapidly transforming industries and societies worldwide through groundbreaking innovations and real-world applications. Starting with the core concepts, the book examines the various types of AI systems, generative AI models, and the complexities of machine learning. It delves into the programming languages driving AI development, data pipelines, model creation and deployment processes, while shedding light on issues like AI hallucinations and the intricate path of machine unlearning. The book then showcases the remarkable real-world applications of AI across diverse domains. From preventing job displacement and promoting environmental sustainability, to enhancing disaster response, drone technology, and even nuclear energy innovation, it highlights how AI is tackling complex challenges and driving positive change. The book also explores the double-edged nature of AI, recognizing its tremendous potential while cautioning about the risks of misuse, unintended consequences, and the urgent need for responsible development practices. It examines the intersection of AI and fields like operating system design, warfare, and semiconductor technology, underscoring the wide-ranging implications of this transformative force. As the quest for artificial general intelligence (AGI) and superintelligent AI systems intensifies, the book delves into cutting-edge research, emerging trends, and the pursuit of multimodal, explainable, and causally aware AI systems. It explores the symbiotic relationship between AI and human creativity, the rise of user-friendly "casual AI," and the potential of AI to tackle open-ended tasks. This is an essential guide for understanding the profound impact of AI on our world today and its potential to shape our future. From the frontiers of innovation to the challenges of responsible development, this book offers a comprehensive and insightful exploration of the remarkable real-world applications and innovations driving the AI revolution.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770046190},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10948961},}@INPROCEEDINGS{10554736,
  author={Davila, Nicole and Wiese, Igor and Steinmacher, Igor and Da Silva, Lucas Lucio and Kawamoto, André and Peres Favaro, Gilson José and Nunes, Ingrid},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)}, 
  title={An Industry Case Study on Adoption of AI-based Programming Assistants}, 
  year={2024},
  volume={},
  number={},
  pages={92-102},
  abstract={Programming assistants based on artificial intelligence (AI), such as ChatGPT and GitHub Copilot, have gained worldwide popularity recently. Studies in software development have explored the adoption of these tools, investigating their characteristics and impacts and how practitioners interact and perceive them. To contribute to this growing body of knowledge, in this study, we aim to explore the adoption of AI-based programming assistants in the Brazilian industry. More specifically, we aim to understand how practitioners of a particular Brazilian agroindustry-related company perceive and use AI-based tools to develop software. Using an online survey, we collected and analyzed 72 responses from employees of the studied company. Our findings suggest that practitioners mainly adopt ChatGPT and GitHub Copilot, interacting with these tools to accelerate online searching, typing, and syntax recall. A recurrent difficulty is the lack of context in the suggestions provided by these tools, but participants work on detailed descriptions to contextualize and cope with this challenge. Among the reasons for not using AI-based tools, the most influential is that participants use a commercial programming language, i.e., Uniface, which these tools lack examples. Our results provide insights into the state of the practice related to AI-based programming assistants and discuss implications for practitioners and researchers.},
  keywords={Industries;Surveys;Computer languages;Programming;Syntactics;Chatbots;Software;Artificial Intelligence;Generative AI;ChatGPT;Industry Case Study;Software Development},
  doi={10.1145/3639477.3643648},
  ISSN={2832-7659},
  month={April},}@INPROCEEDINGS{9718914,
  author={Ke, Aihua and Liu, Gang and Chen, Jian and Wu, Xinyun},
  booktitle={2021 International Conference on Computer Information Science and Artificial Intelligence (CISAI)}, 
  title={Trilateral GAN with Channel Attention Residual for Semantic Image Synthesis}, 
  year={2021},
  volume={},
  number={},
  pages={1123-1129},
  abstract={In this paper, a novel method for synthesizing photo-realistic images from semantic label maps using GANs is proposed, which is an ideal and challenging task in computer vision and image synthesis. Due to the sparsity of the information contained in semantic label maps, it is difficult for some existing methods to achieve satisfactory synthesis effect. This paper proposes a trilateral generative adversarial network to support multi-directional transmission between images of different resolutions, called TrilateralGAN. Compared with the traditional single-directional transmission, the design of our TrilateralGAN network can better retain the information in the original image to avoid loss of details. In addition, we further propose a new channel attention residual as the main part of the TrilateralGAN network. This part can enhance the retained information to varying degrees, which can make the image synthesized by TrilateralGAN have clearer edges and richer details. The experimental results on Cityscapes and ADE20K datasets demonstrate the advantage of TrilateralGAN over the state-of-the-art approaches, regarding both visual quality and the representative evaluating criteria.},
  keywords={Visualization;Information science;Computer vision;Image resolution;Image synthesis;Image edge detection;Semantics;image synthesis;Generative Adversarial Networks;semantic label;channel attention residual},
  doi={10.1109/CISAI54367.2021.00223},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11106900,
  author={Adhikari, Manoj and Joshi, Puskar and Ramos, Gabriel Vieira and Doulat, Ahmad Al and Shaik, Shehenaz},
  booktitle={2025 International Conference on Smart Applications, Communications and Networking (SmartNets)}, 
  title={AIDE: Leveraging Retrieval-Augmented Generation for Context-Aware Educational Data Retrieval and Dialogue}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={This study introduces AIDE (Artificial Intelligence for Data Extraction and Dialogue in Education), an innovative platform designed to enhance data retrieval and presentation within academic institutions. AIDE combines large language models with advanced information retrieval systems to deliver precise and contextually relevant responses to user inquiries, facilitated by Retrieval-Augmented Generation (RAG) architecture. The platform's adaptability allows seamless customization across diverse educational settings, thereby improving communication, information accessibility, and user engagement. AIDE's implementation at East Tennessee State University (ETSU) serves as a prototype, demonstrating its practical application and effectiveness. Quantitative evaluations revealed an 85% retrieval accuracy with an average response time of 2.8 seconds, underscoring the system's efficiency and reliability. Key contributions of this research include the development of a scalable AI-driven platform for educational data retrieval, the implementation of domain-specific adaptations to meet institutional needs, and the enhancement of inclusivity through features that accommodate diverse user requirements. These findings confirm AIDE's ability to address prevalent challenges in educational data retrieval, offering a robust and usercentric solution for the academic community.},
  keywords={Accuracy;Large language models;Retrieval augmented generation;Refining;Prototypes;Data retrieval;Natural language processing;Time factors;Reliability;Optimization;Artificial Intelligence (AI);Data Retrieval;Educational Technology;Generative AI (GenAI);Retrieval-Augmented Generation (RAG);Natural Language Processing (NLP)},
  doi={10.1109/SmartNets65254.2025.11106900},
  ISSN={2837-4940},
  month={July},}@INPROCEEDINGS{10502065,
  author={Ababkova, Marianna Yu. and Ilyina, Irina A. and Melnikova, Irina Yu.},
  booktitle={2024 Communication Strategies in Digital Society Seminar (ComSDS)}, 
  title={AI for Tainment Communications: Potential and Pitfalls}, 
  year={2024},
  volume={},
  number={},
  pages={3-8},
  abstract={Tainment communications encompass various technologies for news, content and key data transmitting, thus transforming the relationship between facts consuming, learning and play. Personalization trend in communications, the development of technologies of big data, artificial intelligence (AI), and machine learning transform the communication sphere and contribute to media development optimization, content diversification and polycoding, offering the most engaging tainment materials to target audiences. The analysis of secondary data, the results of the survey of content ultimate consumers and the expert interview revealed the potentials and pitfalls of AI in tainment communications. The pitfalls of further leverage of AI for content creation include limited creativity, shortfall of emotions and empathy, as the context of taintment content is yet incomprehensible to AI. Irrelevant or improper filling of AI-generated content is the main issue related to its leverage in communication and marketing. As students are the main consumers of tainment communications, the results of the survey show the main applications of AI to the content creation.},
  keywords={Surveys;Symbiosis;Seminars;Transforms;Media;Market research;Proposals;tainment communications;Generative Artificial Intelligence;AI-generated content;potential;pitfalls;issues and opportunities of tainment communications},
  doi={10.1109/ComSDS61892.2024.10502065},
  ISSN={2768-4873},
  month={April},}@INPROCEEDINGS{10164910,
  author={Ma, Xiaolin and Cheng, Anxiong and Liu, Xinhua and Kuang, Hailan},
  booktitle={2023 IEEE 3rd International Conference on Information Technology, Big Data and Artificial Intelligence (ICIBA)}, 
  title={A RGB-UV Facial Skin Image Translation Method}, 
  year={2023},
  volume={3},
  number={},
  pages={514-518},
  abstract={In dermatology and cosmetology, ultraviolet (UV) images can reflect deep facial problems better than RGB images, but its reliance on UV imaging devices limits its clinical application and widespread popularity. This paper proposes a UV facial image generation method without using any UV imaging UV equipment. Specifically, many RGB-UV facial skin image pairs are collected and a dataset is then built. The dataset includes high-resolution RGB-UV image pairs of different positions on the face of people in different age groups. By using the dataset, a generative adversarial network-based method for facial skin image translation is proposed, which achieves better results in RGB-UV image conversion than some compared image-to-image translation methods.},
  keywords={Training;Image resolution;Image synthesis;Dermatology;Imaging;Big Data;Skin;RGB-UV skin image;image-to-image translation;generative adversarial network},
  doi={10.1109/ICIBA56860.2023.10164910},
  ISSN={},
  month={May},}@ARTICLE{10304382,
  author={Kim, Minwoo and Pelivanov, Ivan and O’Donnell, Matthew},
  journal={IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control}, 
  title={Review of Deep Learning Approaches for Interleaved Photoacoustic and Ultrasound (PAUS) Imaging}, 
  year={2023},
  volume={70},
  number={12},
  pages={1591-1606},
  abstract={Photoacoustic (PA) imaging provides optical contrast at relatively large depths within the human body, compared to other optical methods, at ultrasound (US) spatial resolution. By integrating real-time PA and US (PAUS) modalities, PAUS imaging has the potential to become a routine clinical modality bringing the molecular sensitivity of optics to medical US imaging. For applications where the full capabilities of clinical US scanners must be maintained in PAUS, conventional limited view and bandwidth transducers must be used. This approach, however, cannot provide high-quality maps of PA sources, especially vascular structures. Deep learning (DL) using data-driven modeling with minimal human design has been very effective in medical imaging, medical data analysis, and disease diagnosis, and has the potential to overcome many of the technical limitations of current PAUS imaging systems. The primary purpose of this article is to summarize the background and current status of DL applications in PAUS imaging. It also looks beyond current approaches to identify remaining challenges and opportunities for robust translation of PAUS technologies to the clinic.},
  keywords={Imaging;Optical imaging;Biomedical optical imaging;Image reconstruction;Acoustics;Optical variables control;Ultrasonic imaging;Deep learning (DL);image reconstruction;neural network;photoacoustic (PA) imaging;PA and ultrasound (PAUS)},
  doi={10.1109/TUFFC.2023.3329119},
  ISSN={1525-8955},
  month={Dec},}@INPROCEEDINGS{10773731,
  author={Chang, Chen-Chi and Chang, Han-Pi and Lee, Hung-Shin},
  booktitle={2024 IEEE International Conference on Recent Advances in Systems Science and Engineering (RASSE)}, 
  title={Leveraging Retrieval-Augmented Generation for Culturally Inclusive Hakka Chatbots: Design Insights and User Perceptions}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In an era where cultural preservation is increasingly intertwined with technological innovation, this study introduces a groundbreaking approach to promoting and safeguarding the rich heritage of Taiwanese Hakka culture through the development of a Retrieval-Augmented Generation (RAG)-enhanced chatbot. Traditional large language models (LLMs), while pow-erful, often fall short in delivering accurate and contextually rich responses, particularly in culturally specific domains. By integrating external databases with generative AI models, RAG technology bridges this gap, empowering chatbots to not only provide precise answers but also resonate deeply with the cultural nuances that are crucial for authentic interactions. This study delves into the intricate process of augmenting the chatbot's knowledge base with targeted cultural data, specifically curated to reflect the unique aspects of Hakka traditions, language, and practices. Through dynamic information retrieval, the RAG-enhanced chatbot becomes a versatile tool capable of handling complex inquiries that demand an in-depth understanding of Hakka cultural context. This is particularly significant in an age where digital platforms often dilute cultural identities, making the role of culturally aware AI systems more critical than ever. System usability studies conducted as part of our research reveal a marked improvement in both user satisfaction and engagement, highlighting the chatbot's effectiveness in fostering a deeper connection with Hakka culture. The feedback underscores the potential of RAG technology to not only enhance user experience but also to serve as a vital instrument in the broader mission of ethnic mainstreaming and cultural celebration. This paper demonstrates the potential of RAG technology in crafting culturally aware conversational AI systems that contribute to ethnic mainstreaming and the celebration of cultural diversity.},
  keywords={Training;Technological innovation;Accuracy;Chatbots;User experience;Cultural differences;Machine translation;Artificial intelligence;Usability;Web search;Taiwanese Hakka;large language models;retrieval-augmented generation;chatbot;conversational AI},
  doi={10.1109/RASSE64357.2024.10773731},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10451618,
  author={Tian, Yawei and Fu, Yusun and Ji, Zhenyuan},
  booktitle={2023 China Automation Congress (CAC)}, 
  title={An Enhanced Network Intrusion Detection Method Using Auxiliary Classifier Generative Adversarial Networks}, 
  year={2023},
  volume={},
  number={},
  pages={688-693},
  abstract={With the development of communication technology and the emerging concept of Internet of everything, the network is at risk of expanding the attack surface, and the associated network security issues have raised widespread concern. Although the intrusion detection system (IDS) based on machine learning has achieved great progress in anomaly detection, they are weak in processing imbalanced data. Machine learning models are unable to learn minority classes of cyber-attacks in imbalanced data, and thus cannot accurately distinguish malicious attacks. In this study, we propose a novel auxiliary classifier generative adversarial networks (ACGAN) that oversamples the raw data to solve the imbalance problem. we introduce an attention mechanism to extract important features in the attack traffic and add an auxiliary classifier to the original generative adversarial networks (GAN) structure, generating attack samples of the specified class. To verify the effectiveness of the proposed model, we perform a comprehensive evaluation on two datasets include NSL-KDD and UNSW-NB15, and compare ACGAN with synthetic minority oversampling technique (SMOTE). The experimental results demonstrate that our method can effectively generate minority class samples and improve the performance of classification.},
  keywords={Process control;Machine learning;Network security;Generative adversarial networks;Feature extraction;Communications technology;Internet of Things;network security;machine learning;imbalanced data;intrusion detection system (IDS);auxiliary classifier gener-ative adversarial networks (ACGAN);oversampling},
  doi={10.1109/CAC59555.2023.10451618},
  ISSN={2688-0938},
  month={Nov},}@INPROCEEDINGS{11016517,
  author={Park, Seong Min and Ho, Marco and Lin, Michael Pin-Chuan and Ryoo, Jeeho},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Evaluating the Impact of Assistive AI Tools on Learning Outcomes and Ethical Considerations in Programming Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={This study critically evaluates the efficacy of GitHub Copilot in low-level programming education, specifically within C programming tasks involving complex concepts like memory management and pointer manipulation. While AI tools have shown promise in supporting high-level programming, its impact on skill-intensive, low-level contexts remains underexplored. We conducted a within-subject experimental study with 34 graduate computer science students, assessing performance on AI -assisted and independent tasks. Statistical analyses revealed that Copilot, one of the AI programming tools, enhances productivity in routine coding activities; however, it is insufficient for tasks requiring deep problem-solving skills. Notably, a significant performance decline in AI-free tasks suggests a dependency on Copilot that may hinder the development of essential independent problem-solving abilities. Survey feedback underscores ethical concerns, with 40.6 % of students expressing uncertainty about responsible AI usage and potential over-reliance. These findings highlight the ne-cessity for structured instructional practices, including AI-free assessments and clear ethical guidelines, to promote balanced technology integration in programming education. This study contributes to educational theory by illuminating the limitations of generative AI within constructivist and self-regulated learning frameworks. Future research should explore the long-term effects of AI dependency on technical skill development and investigate AI advancements tailored for low-level programming to better support foundational skills.},
  keywords={Productivity;Ethics;Memory management;Debugging;Encoding;Problem-solving;Artificial intelligence;Programming profession;Software development management;Guidelines;GitHub Copilot;C Programming;Dependency in Learning;Constructivist Learning;Self-Regulated Learning;Educational Technology Ethics;AI-Assisted Learning;Program-ming Education;Academic Integrity in AI},
  doi={10.1109/EDUCON62633.2025.11016517},
  ISSN={2165-9567},
  month={April},}@ARTICLE{11098858,
  author={Nandkar, Pushkar and Gandhi, Darshan and Farahini, Nasim and Zeffer, Håkan and Long, John and Rydh, Samuel and Musaddiq, Matheen and Zhao, Tuowen and Brot, Joshua and Goodbar, Reid and Du, Yun and Wang, Mingran and Prabhakar, Raghu},
  journal={IEEE Micro}, 
  title={Speculative Decoding on the SN40L Reconfigurable Dataflow Unit}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={Speculative decoding has emerged as a promising optimization strategy to accelerate generative AI inference. This technique enhances the autoregressive decoding phase by using a smaller draft model to generate a few tokens, which are then validated by a larger model. However, synchronization overheads on both GPUs and hosts limit the performance gains. This article explores the implementation and optimization potential of batched speculative decoding within SambaNova’s SN40L reconfigurable dataflow unit (RDU). We achieve more than 75% of the theoretical maximum performance for speculative decoding and delivering a 6× speedup compared to the baseline model. Furthermore, we demonstrate that a single SN40L rack, containing 16 sockets and offering HBM bandwidth comparable to the DGX H100, outperforms the latter by up to 1.7×. The techniques and models discussed are deployed in SambaNova’s production AI inference cloud, cloud.sambanova.ai, showcasing their tangible impact on large-scale AI applications.},
  keywords={Decoding;Computational modeling;Artificial intelligence;Training;Synchronization;Computer architecture;Throughput;Sockets;Runtime;Production},
  doi={10.1109/MM.2025.3592570},
  ISSN={1937-4143},
  month={},}@ARTICLE{10224277,
  author={Han, Peihua and Zhu, Mingda and Zhang, Houxiang},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Interaction-Aware Short-Term Marine Vessel Trajectory Prediction With Deep Generative Models}, 
  year={2024},
  volume={20},
  number={3},
  pages={3188-3196},
  abstract={Navigation safety is of paramount importance in areas with heavy and complex maritime traffic. Any ship navigating such a scenario should be able to foresee the future positions of other ships and adjust its path accordingly to avoid collisions. However, predicting future trajectories is a very challenging problem due to many possible future trajectories from the inherent uncertainty and the complex interaction dynamics between different ships. In this article, we propose a deep generative model based on the conditional variational autoencoder framework to learn marine vessel movement and predict future trajectories. The model is able to produce a multimodal probability distribution over future trajectories and model the complex interactions between vessels. Experiments are performed in two-vessel encounter scenarios from real-world automatic identification system data. The proposed model outperforms the baseline methods, including both kinematics-based and data-driven methods. The trajectories predicted by the proposed model are also analyzed to demonstrate the effectiveness of the model.},
  keywords={Trajectory;Predictive models;Uncertainty;Marine vehicles;Hidden Markov models;Data models;Artificial intelligence;Automatic identification system (AIS) data;generative model;marine vessel;neural network;trajectory prediction},
  doi={10.1109/TII.2023.3302304},
  ISSN={1941-0050},
  month={March},}@INPROCEEDINGS{11160564,
  author={Li, Jiaying and Wang, Zijian},
  booktitle={2025 6th International Conference on Artificial Intelligence and Electromechanical Automation (AIEA)}, 
  title={Image Classification Using GAN, Contrastive Learning, and ResNet: A Case Study on Steel Surface Defect Detection}, 
  year={2025},
  volume={},
  number={},
  pages={01-05},
  abstract={Steel surface defect classification is critical for quality control in industrial manufacturing. Although neural networks have the capability to defect detection, their training often suffers from slow convergence and suboptimal accuracy. In this study, this paper proposed an improved ResNet-based classification framework that integrates GAN-generated data augmentation and contrastive learning. This combination aims to enhance both training efficiency and classification performance. Experiments conducted on the NEU Surface Defect Database have shown that the proposed method achieves faster convergence and significantly improves accuracy, raising it from 96% (baseline) to over 99%.},
  keywords={Training;Visualization;Accuracy;Contrastive learning;Generative adversarial networks;Data augmentation;Stability analysis;Steel;Convergence;Defect detection;steel surface defect classification;GANs;contrastive learning;ResNet},
  doi={10.1109/AIEA66061.2025.11160564},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10715621,
  author={Atbaş, Baran and Calşşkan, Efe and Erdem, Oğuzhan},
  booktitle={2024 Signal Processing: Algorithms, Architectures, Arrangements, and Applications (SPA)}, 
  title={AI-Supported Pneumonia Diagnosis: Performance of Deep Learning Models and Synthetic Data Generation}, 
  year={2024},
  volume={},
  number={},
  pages={115-120},
  abstract={Pneumonia, a respiratory infection that affects the lungs and leads to serious health complications, is diagnosed by physicians based on symptoms, physical exam findings and imaging tests such as chest X-rays, but these methods can be time-consuming and subjective. In this study, we propose a Convolutional Neural Network (CNN) based pneumonia disease detection model utilizing X-ray images for accelerating diagnosis and initiate treatment early to prevent disease progression. Due to the insufficient number of original X-ray samples, we also produced synthetic images with our developed Deep Convolutional Generative Adversarial Network (DC-GAN) model. We comparatively evaluated the performance of our models with pretrained VGG16 and ResNet50 models on synthetic and original image datasets separately and combined. Our results show that all models performed best with the synthetic dataset and also the combined set expanded with synthetic data gave better results in all cases than using the original data alone. The average test accuracy results of all models were obtained as $93 \%$, $89 \%$ and $91 \%$ with synthetic, original and combined datasets, respectively. Thus, it proves that the good quality of the produced synthetic images that can be used to solve the problem of medical image data need, especially in artificial intelligence-based decision support systems. When the models were compared, our CNN model achieved the best performance in all scenarios with the accuracy values of $95 \%, 91 \%$ and $93 \%$ with synthetic, original and combined datasets, respectively.},
  keywords={Deep learning;Pneumonia;Accuracy;Signal processing algorithms;Medical services;Data models;Convolutional neural networks;X-ray imaging;Synthetic data;Diseases;AI;pneumonia;CNN;DC-GAN},
  doi={10.23919/SPA61993.2024.10715621},
  ISSN={2326-0319},
  month={Sep.},}@INPROCEEDINGS{9157384,
  author={Huang, Lei and Zhao, Lei and Zhou, Yi and Zhu, Fan and Liu, Li and Shao, Ling},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={An Investigation Into the Stochasticity of Batch Whitening}, 
  year={2020},
  volume={},
  number={},
  pages={6438-6447},
  abstract={Batch Normalization (BN) is extensively employed in various network architectures by performing standardization within mini-batches. A full understanding of the process has been a central target in the deep learning communities. Unlike existing works, which usually only analyze the standardization operation, this paper investigates the more general Batch Whitening (BW). Our work originates from the observation that while various whitening transformations equivalently improve the conditioning, they show significantly different behaviors in discriminative scenarios and training Generative Adversarial Networks (GANs). We attribute this phenomenon to the stochasticity that BW introduces. We quantitatively investigate the stochasticity of different whitening transformations and show that it correlates well with the optimization behaviors during training. We also investigate how stochasticity relates to the estimation of population statistics during inference. Based on our analysis, we provide a framework for designing and comparing BW algorithms in different scenarios. Our proposed BW algorithm improves the residual networks by a significant margin on ImageNet classification. Besides, we show that the stochasticity of BW can improve the GAN's performance with, however, the sacrifice of the training stability.},
  keywords={Training;Principal component analysis;Covariance matrices;Gallium nitride;Standardization;Optimization;Sociology},
  doi={10.1109/CVPR42600.2020.00647},
  ISSN={2575-7075},
  month={June},}@ARTICLE{9410376,
  author={Zhang, Xiaokang and Zhu, Yuanlue and Chen, Wenting and Liu, Wenshuang and Shen, Linlin},
  journal={IEEE Transactions on Multimedia}, 
  title={Gated SwitchGAN for Multi-Domain Facial Image Translation}, 
  year={2022},
  volume={24},
  number={},
  pages={1990-2003},
  abstract={Recent studies on multi-domain facial image translation have achieved impressive results. The existing methods generally provide a discriminator with an auxiliary classifier to impose domain translation. However, these methods neglect important information regarding domain distribution matching. To solve this problem, we propose a switch generative adversarial network (SwitchGAN) with a more adaptive discriminator structure and a matched generator to perform delicate image translation among multiple domains. A feature-switching operation is proposed to achieve feature selection and fusion in our conditional modules. We demonstrate the effectiveness of our model. Furthermore, we also introduce a new capability of our generator that represents attribute intensity control and extracts content information without tailored training. Experiments on the Morph, RaFD and CelebA databases visually and quantitatively show that our extended SwitchGAN (i.e., Gated SwitchGAN) can achieve better translation results than StarGAN, AttGAN and STGAN. The attribute classification accuracy achieved using the trained ResNet-18 model and the FID score obtained using the ImageNet pretrained Inception-v3 model also quantitatively demonstrate the superior performance of our models.},
  keywords={Switches;Generators;Logic gates;Faces;Control systems;Feature extraction;Task analysis;GANs;Image translation;Feature switching;Attribute intensity control},
  doi={10.1109/TMM.2021.3074807},
  ISSN={1941-0077},
  month={},}@ARTICLE{10916652,
  author={Choi, Yeji and Kim, Haksub and Sohn, Kwanghoon and Kim, Ig-Jae},
  journal={IEEE Access}, 
  title={HiTS: Hierarchical Text-Guided Stylization for Face Sketch-to-Photo Synthesis}, 
  year={2025},
  volume={13},
  number={},
  pages={50885-50894},
  abstract={Face sketch-to-photo synthesis is crucial in law enforcement, converting forensic sketches into RGB images for criminal database matching. A major challenge is ensuring accurate color representation in synthesized images to avoid identification error caused by mismatched skin or eye color. However, direct sketch-to-photo translation struggles with proper color representation as it relies solely on grayscale sketches. While recent text-guided generative methods show promise for style adjustment based on text descriptions, they often produce mixed or exaggerated colors due to using a single representation for text prompts containing multiple entangled attributes. To address these challenges, we propose Hierarchical Text-guided Stylization (HiTS), a novel identity-preserving face sketch-to-photo synthesis method. HiTS categorizes text descriptions into intrinsic and mutable attributes, capturing both global and local color features. Using an encoder-decoder architecture, the encoder extracts global features from intrinsic attributes, while the decoder refines local styles via a semantic-textual embedding map. This map integrates text embeddings with facial parsing masks, enabling precise style adjustments for each facial component, even in small regions. Both quantitative and qualitative results demonstrate that HiTS achieves fine-grained stylization while preserving identity, leading to improved face recognition accuracy.},
  keywords={Image color analysis;Face recognition;Skin;Hair;Image synthesis;Translation;Accuracy;Visualization;Generative adversarial networks;Faces;Face sketch-to-photo synthesis;generative adversarial network (GAN);text-guided image generation},
  doi={10.1109/ACCESS.2025.3549102},
  ISSN={2169-3536},
  month={},}@ARTICLE{9940284,
  author={Sakamoto, Naoki and Sato, Rei and Fukuchi, Kazuto and Sakuma, Jun and Akimoto, Youhei},
  journal={IEEE Access}, 
  title={Explicitly Constrained Black-Box Optimization With Disconnected Feasible Domains Using Deep Generative Models}, 
  year={2022},
  volume={10},
  number={},
  pages={117501-117514},
  abstract={We tackle explicitly constrained black-box continuous optimization problems in which the feasible domain forms a union of disconnected feasible subdomains. The decoder-based constraint-handling technique is a promising approach when the feasible domain is disconnected. However, the design of a reasonable decoder requires deep prior knowledge of the optimization problem to be solved and, hence, human effort. In this study, we investigated the usefulness of a deep neural network as a decoder and developed a training scheme for a deep neural network without prior information, such as a training dataset consisting of feasible and infeasible solutions required by existing decoder approaches. To stabilize the training of the deep generative model as the decoder, we propose decomposing the decoder into sub-models, introducing skip connections to each sub-model, and training the sub-models sequentially with separate loss functions. Numerical experiments using a test problem and a topology optimization problem show that the proposed method can find feasible domains with better objective function values and higher probability than both conventional decoder-based constraint-handling methods and non-decoder-based constraint-handling methods.},
  keywords={Decoding;Optimization;Linear programming;Mathematical models;Closed box;Training data;Neural networks;Black-box optimization;constraint handling;deep learning;disconnected feasible domain;evolutionary computation;explicit constraint;generative models},
  doi={10.1109/ACCESS.2022.3219979},
  ISSN={2169-3536},
  month={},}
