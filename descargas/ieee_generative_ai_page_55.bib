@INPROCEEDINGS{10866024,
  author={Kiran, G. Uday and V., Srilakshmi and Harshith, K. S. and Nikhita, K. and Mokshith, L. V. S. and Sowmya, A.},
  booktitle={2024 3rd Edition of IEEE Delhi Section Flagship Conference (DELCON)}, 
  title={Learning Correspondences Across Domains for Exemplar-Based Image Translation}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This study provides a strong foundation for exemplar-based picture translation, with the goal of producing photorealistic images from inputs coming from different fields, including posture key points, edge maps, and semantic segmentation masks. Ensuring that the generated image faithfully replicates the style-including color and texture-of semantically relevant elements in a given exemplar image is the main objective. Initially, pictures from various domains are aligned to an intermediate domain in order to generate dense correspondences. N ext, the network uses the exemplar's appearance of semantically relevant patches to create synthetic images. The outcomes demonstrate how much our method improves upon current state-of-the-art techniques, producing images of higher quality while maintaining semantic alignment with the exemplar. This method's efficacy is confirmed in several image translation tasks, underscoring its promise in applications where, maintaining style while maintaining semantic accuracy is crucial.},
  keywords={Deep learning;Translation;Attention mechanisms;Accuracy;Image color analysis;Semantic segmentation;Image edge detection;Semantics;Photorealistic images;Biomedical imaging;Semantic Segmentation;Edge Map;Dense correspondence;Semantically Correspondence Patches},
  doi={10.1109/DELCON64804.2024.10866024},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10150310,
  author={Peng, Tao and Zhang, Xincheng and Huang, Junjie and Liu, Junping and Hu, Xinrong and He, Ruhan},
  booktitle={2023 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops)}, 
  title={MSQA: An Unsupervised Domain-Adapted Question Answering Method Based on Multiple Source Domains}, 
  year={2023},
  volume={},
  number={},
  pages={490-495},
  abstract={In recent years, with the development of knowledge bases and crowdsourcing,researchers have successfully proposed several high-quality, large-scaledatasets. The rise of pre-trained language models has extensively promoted theprogress of machine reading comprehension tasks. Even so, the need for large-scaletraining data is one of the critical challenges in this field. Existingmethods: one is to improve the transferability of downstream tasks byoptimizing and improving pre-trained language models; the other is to usemultiple existing datasets to build a more extensive dataset or generatesynthetic data. However, the effect is not ideal and lacks specific logicalgeneralization abilities. In this paper, we propose a new domain adaptationframework based on BERT, called Multi-Source Domain Adaptive QA (MSQA), whichutilizes multiple existing large datasets and uses adversarial domaintechniques to narrow the distribution of multiple sources and target domains,thereby improving performance on target domain datasets. Extensive experimentson multiple widely used English datasets demonstrate that our method exhibitssuperior adaptive performance.},
  keywords={Pervasive computing;Adaptation models;Conferences;Computational modeling;Knowledge based systems;Bit error rate;Question answering (information retrieval);Transfer Learning;Domain Adaptation;Extractive Question Answering;Pre-trained Model},
  doi={10.1109/PerComWorkshops56833.2023.10150310},
  ISSN={2766-8576},
  month={March},}@INPROCEEDINGS{10442099,
  author={Xia, Xuan and Zhang, Jingfei and He, Xing and Tong, Haoran and Zhang, Xiaoguang and Li, Nan and Ding, Ning},
  booktitle={2023 International Conference on Electrical, Communication and Computer Engineering (ICECCE)}, 
  title={Auto Data Augmentation for Image: A Brief Survey}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={Auto data augmentation has emerged as a promising alternative to the laborious manual parameter tuning involved in data augmentation policies. However, the existing approaches have limitations in terms of their applicability to a restricted range of models, datasets, and tasks. In this brief survey, we identify and discuss four key issues that auto data augmentation needs to tackle. We categorize auto data augmentation into two main types: closed-loop/open-loop auto data augmentation and online/offline auto data augmentation. Each of these categories is examined in detail, with a comprehensive analysis of their respective performance. Furthermore, we highlight the challenges that the field of auto data augmentation faces and offer insights into potential research directions. Our survey serves as a valuable resource for researchers seeking a deeper understanding of the evolving landscape of auto data augmentation, providing inspiration and guidance for future work in this area.},
  keywords={Surveys;Deep learning;Propulsion;Data augmentation;Performance analysis;Task analysis;Tuning;Auto data augmentation;Deep learning;Computer vision},
  doi={10.1109/ICECCE61019.2023.10442099},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10826672,
  author={Kim, Chungil and Kim, San and Jang, Jin Yea and Joe, Byunggill and Jung, Minyeoung and Shin, Saim},
  booktitle={2024 15th International Conference on Information and Communication Technology Convergence (ICTC)}, 
  title={SemanticVQVAE for Co-Speech Gesture Quantization with Contrastive Learning}, 
  year={2024},
  volume={},
  number={},
  pages={19-24},
  abstract={In the field of co-speech gesture generation, quantization plays a crucial role in transforming continuous gesture data into discrete tokens or codes, facilitating the alignment and semantic preservation of gestures with speech. This study proposes a semantic-aware Vector Quantized Variational Auto-Encoder (VQVAE) model designed to address the limitations of existing approaches, which often fail to maintain the contextual and semantic coherence of gestures. Our method incorporates context-aware padding and contrastive loss to improve the accuracy and consistency of gesture representations, in order to preserving their semantic integrity. Experimental results demonstrate that our semantic-aware VQVAE outperforms base-line methods across several metrics. These results underscore the potential of our approach to advance high-quality gesture quantization, facilitating more natural and coherent co-speech gesture generation.},
  keywords={Training;Quantization (signal);Accuracy;Speech coding;Semantics;Social robots;Syntactics;Vectors;Robustness;Context modeling;Gesture quantization;Contrastive learning;Co-speech gesture generation;Discrete encoding},
  doi={10.1109/ICTC62082.2024.10826672},
  ISSN={2162-1241},
  month={Oct},}@INPROCEEDINGS{10895155,
  author={Pandey, Harshita and Dhavale, Sunita},
  booktitle={2024 IEEE Pune Section International Conference (PuneCon)}, 
  title={A Survey on Artificial Intelligence based Photovoltaic Cell Defect Detection Techniques}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={With the increase in demand for solar energy in the form of photovoltaic (PV) panels have become an important component in sustainable energy applications. The visible defects (cracks, black spots, corrosion, etc.) in PV cells can occur during manufacturing times or while sustaining under external environmental conditions like rain, extreme temperature, humidity, etc. As a result, timely fault analysis in solar panels is essential in order to enhance both the lifespan and energy efficiency performance. The Electrolumince (EL) imaging technique is one of the popular technique used to scan PV modules in order to identify these critical defects like cracks. However, traditional PV fault detection methods rely on manual inspection and hence tedious, prone to human errors. This survey paper discusses the different methodologies and techniques using artificial intelligence (AI), Deep learning (DL), and Computer vision (CV) for quick, reliable, and efficient crack detection in PV panels using EL imaging analysis. Convolutional Neural Networks (CNNs), Residual Neural Networks (ResNet), and Visual Geometry Group (VGG) have demonstrated significant improvements in defect detection accuracy. This survey paper also discusses the standard datasets available in this domain and a comparative analysis of proposed techniques in the literature.},
  keywords={Surveys;Deep learning;Computer vision;Computer network reliability;Imaging;Solar energy;Manuals;Reliability;Artificial intelligence;Defect detection;Deep Learning;Computer vision;Convolution Neural Network},
  doi={10.1109/PuneCon63413.2024.10895155},
  ISSN={2831-5022},
  month={Dec},}@INPROCEEDINGS{11134479,
  author={Zhang, Zishuai and Zhang, Qinnan and Qiu, Wangjie and Zheng, Hongwei and Miao, Shuyi and Jie, Wanqing and Zhu, Jianming and Dong, Jin and Zheng, Zhiming},
  booktitle={2025 IEEE Global Blockchain Conference (GBC)}, 
  title={A Semantic Detection Incentive Mechanism For Blockchain Transactions Based on Evolutionary Game Theory in Web3 Ecosystem}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Blockchain transaction semantic detection (BTSD) involves identifying illegal accounts and transactions through distributed miners, and combines their detection results to improve the security performance of the blockchain system. Existing related studies focus on BTSD algorithm design and optimization to realize account de-anonymization or fraud transaction detection but ignore the important issue of incentives, without which self-interested miners may be unwilling to participate in the detection tasks. We aim to fill this gap by taking the first step in the incentive mechanism design for BTSD. Specifically, we first propose a BTSD framework in the transaction pool phase. Then, we apply evolutionary game theory to study the interaction mechanism of complex behaviours between miners and users. On this basis, we study the evolutionary stable strategy (ESS) and the impacts of the decayed detection reward on the results. Finally, theoretical analysis and simulation numerical results show that a fixed reward contributes to the central point, while the decayed detection reward contributes to the ESS and a larger initial reward accelerates the system’s evolution toward the ESS.},
  keywords={Semantic Web;Semantics;Ecosystems;Mechanism design;Games;Bitcoin;Blockchains;Fraud;Security;Optimization;Blockchain;Bitcoin;Semantic detection;PoW;Incentive mechanism;ESS;Evolutionary game theory},
  doi={10.1109/GBC60041.2025.11134479},
  ISSN={},
  month={June},}@INPROCEEDINGS{11035373,
  author={Mandapalli, Mahesh Kumar and Thejaswini, P and Kishore, C Ravi and Gomathi, Uttamekala and Reddy, V Yugesh and Koteeswar, Gattappagari},
  booktitle={2025 International Conference on Knowledge Engineering and Communication Systems (ICKECS)}, 
  title={AgriResNet A Deep Learning-Based Model for Plant Disease Detection, Segmentation, and Treatment Recommendation}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Modern precision agriculture promotes plant leaf disease detection as its main focal point for maximizing crop productivity and minimizing losses. The identification of plant pathogens is crucial for prompt response, as it helps to prevent outbreaks and decrease the need for chemical treatments. Typical techniques (often manual) are time-consuming, laborious and potentially erroneous. Advancements in computer vision and machine learning have largely solved these problems by creating automated systems to detect plant leaf diseases. Modern diagnostic systems use convolution neural networks (CNNs) together with deep learning approaches to examine visual data for disease classification and medical diagnosis purposes. Extensive annotated datasets are utilized to train the model for recognizing diseases such as blight, rust, mildew, and leaf spots with high accuracy. Techniques like transfer learning, data augmentation, and ensemble modelling are integrated to further enhance the system's performance.},
  keywords={Precision agriculture;Deep learning;Plant diseases;Image segmentation;Visualization;Accuracy;Transfer learning;Data augmentation;Data models;Diseases;CNNs;Deep learning;High-quality images;Transfer learning;Data augmentation;Ensemble modelling},
  doi={10.1109/ICKECS65700.2025.11035373},
  ISSN={},
  month={April},}@INPROCEEDINGS{10442131,
  author={Patel, Suman and Chandra, Saroj Kumar and Jain, Amit},
  booktitle={2023 3rd International Conference on Smart Generation Computing, Communication and Networking (SMART GENCON)}, 
  title={DeepFake Videos Detection and Classification Using Resnext and LSTM Neural Network}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Deepfake videos, which are artificial intelligence-altered videos that have acquired extensive awareness recently. Deep learning algorithms are utilized to create these deepfake films, which are meant to disseminate false information about anyone, including politicians and celebrities. These movies have been purposefully made viral in order to propagate propaganda and false information, to frighten people, and to destabilize society. It is exceedingly challenging for a casual viewer to recognize a deep fake video with the naked eye. Finding these manipulated films has been extremely difficult and requires careful attention. In order to recognize a deepfake movie, this paper, a novel methodology that combines ResNext, a Convolutional Neural Network (CNN) algorithm, with Long Short-Term Memory (LSTM), a Recurrent Neural Network (RNN) has been developed. It is found that as the number of epochs increased, the model's accuracy increased and its training loss reduced.},
  keywords={Training;Deepfakes;Recurrent neural networks;Films;Computational modeling;Motion pictures;Convolutional neural networks;Artificial Intelligence;Deepfake;Deep learning algorithm;Convolutional Neural Network (CNN);ResNext;LSTM;Recurrent Neural network (RNN)},
  doi={10.1109/SMARTGENCON60755.2023.10442131},
  ISSN={},
  month={Dec},}@ARTICLE{9300234,
  author={Zhang, Xuewen and Qin, Yan and Yuen, Chau and Jayasinghe, Lahiru and Liu, Xiang},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Time-Series Regeneration With Convolutional Recurrent Generative Adversarial Network for Remaining Useful Life Estimation}, 
  year={2021},
  volume={17},
  number={10},
  pages={6820-6831},
  abstract={For health prognostic task, ever-increasing efforts have been focused on machine learning based methods, which are capable of yielding accurate remaining useful life (RUL) estimation for industrial equipment or components without exploring the degradation mechanism. A prerequisite ensuring the success of these methods depends on a wealth of run-to-failure data; however, run-to-failure data may be insufficient in practice. That is, conducting a substantial amount of destructive experiments not only is of high cost but also may cause catastrophic consequences. Out of this consideration, an enhanced RUL framework focusing on data self-generation is put forward for both noncyclic and cyclic degradation patterns for the first time. It is designed to enrich data from a data-driven way, generating realistic-like time-series to enhance current RUL methods. First, high-quality data generation is ensured through the proposed convolutional recurrent generative adversarial network, which adopts a two-channel fusion convolutional recurrent neural network. Next, a hierarchical framework is proposed to combine generated data into current RUL estimation methods. Finally, in this article the efficacy of the proposed method is verified through both noncyclic and cyclic degradation systems. With the enhanced RUL framework, an aero-engine system following noncyclic degradation has been tested using three typical RUL models. State-of-the-art RUL estimation results are achieved by enhancing capsule network with generated time-series. Specifically, estimation errors evaluated by the index score function have been reduced by 21.77$\%$ and 32.67$\%$ for the two employed operating conditions, respectively. Besides, the estimation error is reduced to zero for the lithium-ion battery system, which presents cyclic degradation.},
  keywords={Estimation;Degradation;Generative adversarial networks;Gallium nitride;Data models;Generators;Estimation error;Convolutional recurrent network;degradation pattern learning;generative adversarial network (GAN);multivariate time-series generation;remaining useful life (RUL) estimation},
  doi={10.1109/TII.2020.3046036},
  ISSN={1941-0050},
  month={Oct},}@ARTICLE{9850361,
  author={Calderon-Ramirez, Saul and Yang, Shengxiang and Elizondo, David},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Semisupervised Deep Learning for Image Classification With Distribution Mismatch: A Survey}, 
  year={2022},
  volume={3},
  number={6},
  pages={1015-1029},
  abstract={Deep learning methodologies have been employed in several different fields, with an outstanding success in image recognition applications, such as material quality control, medical imaging, autonomous driving, etc. Deep learning models rely on the abundance of labeled observations to train a prospective model. These models are composed of millions of parameters to estimate, increasing the need of more training observations. Frequently, it is expensive to gather labeled observations of data, making the usage of deep learning models not ideal, as the model might overfit data. In a semisupervised setting, unlabeled data are used to improve the levels of accuracy and generalization of a model with small labeled datasets. Nevertheless, in many situations different unlabeled data sources might be available. This raises the risk of a significant distribution mismatch between the labeled and unlabeled datasets. Such phenomena can cause a considerable performance hit to typical semisupervised deep learning (SSDL) frameworks, which often assume that both labeled and unlabeled datasets are drawn from similar distributions. Therefore, in this article we study the latest approaches for SSDL for image recognition. Emphasis is made in SSDL models designed to deal with a distribution mismatch between the labeled and unlabeled datasets. We address open challenges with the aim to encourage the community to tackle them, and overcome the high data demand of traditional deep learning pipelines under real-world usage settings.},
  keywords={Deep learning;Semisupervised learning;Image classification;Deep learning;distribution mismatch;image classification;semisupervised learning},
  doi={10.1109/TAI.2022.3196326},
  ISSN={2691-4581},
  month={Dec},}@INPROCEEDINGS{10072179,
  author={Strelcenia, Emilija and Prakoonwit, Simant},
  booktitle={2022 International Conference on Computers and Artificial Intelligence Technologies (CAIT)}, 
  title={Generating Synthetic Data for Credit Card Fraud Detection Using GANs}, 
  year={2022},
  volume={},
  number={},
  pages={42-47},
  abstract={Deep learning-based classifiers for object classification and recognition have been utilized in various sectors. However according to research papers deep neural networks achieve better performance using balanced datasets than imbalanced ones. It's been observed that datasets are often imbalanced due to less fraud cases in production environments. Deep generative approaches, such as GANs have been applied as an efficient method to augment high-dimensional data. In this research study, the classifiers based on a Random Forest, Nearest Neighbor, Logistic Regression, MLP, Adaboost were trained utilizing our novel K-CGAN approach and compared using other oversampling approaches achieving higher F1 score performance metrics. Experiments demonstrate that the classifiers trained on the augmented set achieved far better performance than the same classifiers trained on the original data producing an effective fraud detection mechanism. Furthermore, this research demonstrates the problem with data imbalance and introduces a novel model that's able to generate high quality synthetic data.},
  keywords={Time series analysis;Neural networks;Production;Network architecture;Credit cards;Generators;Fraud;Planning;Random forests;Synthetic data;fraud;GANs;synthetic data;class imbalance},
  doi={10.1109/CAIT56099.2022.10072179},
  ISSN={},
  month={Nov},}@ARTICLE{10646468,
  author={Yu, Le and Wang, Lina and Cai, Jijing and Yang, Zijia and Wen, Long and Bashir, Ali Kashif and Wang, Wei},
  journal={IEEE Consumer Electronics Magazine}, 
  title={Consumer Electronics and GenAI Providing User Experiences in Mental Health}, 
  year={2025},
  volume={14},
  number={5},
  pages={84-93},
  abstract={As consumer electronics become more ubiquitous and generative artificial intelligence (GenAI) technologies advance rapidly, processing and analyzing semantic information collected from users to enhance their experiences becomes especially important. Traditionally, monitoring students’ educational and psychological health has relied primarily on teachers, a method that is both inefficient and inadequate for comprehensively grasping students’ needs. Therefore, the application of artificial intelligence is particularly critical. GenAI has the capability to gather semantic information from consumer electronics commonly used by students, such as smartphones, wearable devices, and tablets, and perform in-depth analysis. By analyzing curriculum schedules, GenAI can personalize learning paths and predict students’ psychological states through examining individual mental health and media usage data. This article explores how GenAI processes this information to intervene in students’ education and psychological health, and discusses the analysis of adolescent mental health test data collected in recent years as well. Evidence suggests that students enrolled in high schools suffer from the highest rates of depression and major depressive disorder compared to other stages, at 40% and 12.5%, respectively, underscoring the importance of using GenAI for educational and psychological health monitoring. The article summarizes the relevant technologies and models, highlighting the potential of GenAI in enhancing student well-being and academic performance.},
  keywords={Consumer electronics;Mental health;Education;Semantics;Psychology;Monitoring;Smart phones;Generative AI;User experience;Depression;Performance evaluation;Wearable devices;Artificial intelligence},
  doi={10.1109/MCE.2024.3449558},
  ISSN={2162-2256},
  month={Sep.},}@INPROCEEDINGS{10356238,
  author={Chaddad, Ahmad and Wu, Yihang},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Domain Adaptation in Machine Learning: A Practical Simulation Study}, 
  year={2023},
  volume={},
  number={},
  pages={754-761},
  abstract={Domain adaptation (DA) is a critical technique in machine learning, designed to alleviate distribution differences between training and test sets by leveraging information from similar datasets. This paper presents a practical simulation of both widely-used and recent DA techniques, with a specific focus on unsupervised learning scenarios where labels are only available in the source domain. We thoroughly investigate the impact of these methods on various publicly available datasets, providing detailed explanations of our findings. Furthermore, we conduct an ablation study and elaborate extensively on the simulation results. Our study offers valuable information on the resilience of selected DA algorithms, highlighting the importance of appropriate datasets and neural network architectures with training methodologies to achieve optimal performance in DA tasks.},
  keywords={Training;Machine learning algorithms;Simulation;Neural networks;Training data;Machine learning;Task analysis;Domain adaptation;machine learning;deep learning},
  doi={10.1109/ICTAI59109.2023.00116},
  ISSN={2375-0197},
  month={Nov},}@ARTICLE{11135496,
  author={Abbar, Hamza and Kassan, Sara and Bidet, François and Cherigui, Aya and Guépin, Florent and Renaud, Denis},
  journal={IEEE Access}, 
  title={TrajDD-GAN: A Synthetic Mobility Trajectory Generation Solution Based on Diffusion Models}, 
  year={2025},
  volume={13},
  number={},
  pages={158018-158027},
  abstract={The pervasive integration of GPS-enabled devices and population growth, alongside diverse transportation options, has led to an exponential increase in the collection of trajectory data, driving advancement in spatiotemporal data mining and urban planning. However, sharing trajectory data that includes sensitive user information can significantly threaten personal privacy, as location-based services like mobile apps and vehicle tracking offer valuable insights into travel routes while simultaneously raising serious concerns about the exposure of personal geolocation information. To solve this dilemma, we propose a novel generative model based on a spatiotemporal diffusion probabilistic model: Trajectory Denoising Diffusion Generative Adversarial Network (TrajDD-GAN). TrajDD-GAN reconstructs and synthesizes geographic trajectories through a forward diffusion process that adds Gaussian noise to real trajectory data, followed by a multimodal conditional GAN for iterative denoising. This process significantly reduces the number of required diffusion steps. Our experiments demonstrate the potential of integrating probabilistic diffusion techniques with generative adversarial networks to achieve better sample quality, diversity, and efficiency for real-world applications. Extensive experimental results show that TrajDD-GAN generates synthetic trajectories that preserve the statistical properties of the original mobility data. One of TrajDD-GAN’s main advantages compared to other diffusion models is its cost-effective inference process: fewer steps mean faster generation. In particular, TrajDD-GAN achieves a 98.19% reduction in inference time compared to DiffTraj, while successfully generating up to 1,000,000 synthetic trajectories. This demonstrates its scalability and efficiency, enabling the large-scale generation of high-quality synthetic mobility data for real-world applications.},
  keywords={Trajectory;Noise reduction;Generative adversarial networks;Diffusion models;Data models;Data privacy;Generators;Computational modeling;Synthetic data;Iterative methods;Synthetic mobility trajectory data;generative adversarial networks;denoising diffusion models;privacy;GeoAI},
  doi={10.1109/ACCESS.2025.3602274},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10497409,
  author={Zhang, Xianhong and Lu, Tao and Wang, Jiaming and Xu, Aibo and Xu, Jijun},
  booktitle={2023 International Conference on Artificial Intelligence Innovation (ICAII)}, 
  title={EdgeAware YOLO: Enhancing Small Object Edge Detection in Base Station Equipment Inspection}, 
  year={2023},
  volume={},
  number={},
  pages={12-19},
  abstract={The small object detection task has always presented a significant challenge in the field of object detection research. However, existing methods often struggle to effectively focus on the blurred edges of small objects, leading to overlapping predicted bounding boxes or inaccurate predictions for similar small objects in dense scenarios. In this paper, we propose a novel small object detection network based on the YOLO framework, called EdgeAwareYOLO, to alleviate this challenge. In order to focus on the edge information of small objects and improve the location ability of dense small objects, we propose a novel module called channel attention and spatial attention fusion module. Additionally, we propose Side and Corner Aligned Intersection over Union Loss function to alleviate the issue of gradient vanishing caused by low overlap between predicted bounding boxes and ground truth boxes based on traditional Intersection-over-Union loss and facilitate bounding boxes regression in cases of high overlap. Extensive experiments demonstrate that the proposed EdgeAwareYOLO achieves significant improvements in small object detection by capturing edge details and generating more reliable results. The implications of the proposed method hold promise for enhancing base station equipment inspection.},
  keywords={YOLO;Industries;Base stations;Technological innovation;Image edge detection;Inspection;Feature extraction;small object detection;equipment inspection;attention fusion;edge feature},
  doi={10.1109/ICAII59460.2023.10497409},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10581596,
  author={Yin, Zezhao and Li, Jianbo and Ren, Liuran and Wang, Xinyuan and Wang, Min and Huang, Jin and Zeng, Tao and Rong, Peng},
  booktitle={2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={Joint Structure and Texture-guided Image Inpainting with a Multi-Scale Shared Feature Extractor}, 
  year={2024},
  volume={},
  number={},
  pages={1240-1246},
  abstract={Significant progress has been made in image inpainting by simultaneously leveraging both structure and texture information for the restoration process. However, there remains considerable room for improvement in effectively fusing and mutually utilizing these structure and texture features. In this paper, we propose a Joint Structure and Texture-guided Image Inpainting model with a Multi-Scale Shared Feature Extractor, which include the Gated Contextual Aggregation (GCA) module, the Adaptive Dual Feature Fusion (ADFF) module, and the Multi-Scale Contextual Attention (MA) module. Specifically, we employ a two-stream network, which models structure-guided texture synthesis and texture-guided structure reconstruction to generate structure and texture information. Concurrently, we introduc structure and texture features. This feature extractor effectively reduces the parameter count while adeptly capturing multi-scale features. Then we utilize the ADFF module to better integrate both types of features, ensuring coherence between structure and texture. Additionally, we employ MA module to refine the fused features, leading to the final inpainting results. Extensive experiments conducted on the CelebA benchmark dataset demonstrate the superiority of the proposed method.},
  keywords={Seminars;Adaptation models;Coherence;Logic gates;Feature extraction;Distortion;Image restoration;image inpainting;Multi-scale feature aggregation;Multi-Scale Contextual Attention Introduction},
  doi={10.1109/AINIT61980.2024.10581596},
  ISSN={},
  month={March},}@INPROCEEDINGS{10024692,
  author={Ahammadi, Abdulraqeb and Hassan, Wan Haslina and Shamsan, Zaid Ahmed},
  booktitle={2022 International Conference on Cyber Resilience (ICCR)}, 
  title={An Overview of Artificial Intelligence for 5G/6G Wireless Networks Security}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Fifth-generation (5G) wireless technologies provide a higher capability for millions of devices to be connected with low latency and high-speed transmission. However, having a wide range of enabling technologies brings additional threats. In this context, network security and privacy play an important role for 5G and beyond networks. In 5G networks, artificial intelligence (AI) techniques are useful for improving security. This paper provides an overview of AI-powered intelligent security for 5G and beyond wireless networks. We review several studies on wireless networks that utilize AI features to improve additional security vulnerabilities depending on future technologies at the physical and network levels. The paper also attempts to shed light on potential future research avenues leading to developing security and privacy for 6G networks.},
  keywords={6G mobile communication;Privacy;5G mobile communication;Wireless networks;Network security;Telecommunications;Security;Security;privacy;AI;ML;5G;6G;adversarial ML;generative adversarial network;physical-layer security},
  doi={10.1109/ICCR56254.2022.10024692},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10464455,
  author={Singh, Charanjit and Bansal, Rakesh Kumar and Bansal, Savina},
  booktitle={2023 IEEE International Conference on Computer Vision and Machine Intelligence (CVMI)}, 
  title={Machine Translation Techniques using AI : A Review}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Automation of natural language translation is undergoing a significant evolution, with various approaches emerging over the years. In the context of a vast and diverse country like India, where numerous regional languages are spoken, and people frequently move for various reasons such as- trade, migration, education, tourism, and more- the need for a robust translation mechanism becomes paramount to overcome language barriers. This article delves into the research efforts of various scholars in the field of machine translation and explores the future prospects in this domain. Additionally, it provides insights into the diverse Machine Learning and Artificial Intelligence methodologies employed in Machine Translation.},
  keywords={Measurement;Computer vision;Automation;Reviews;Natural languages;Education;Machine learning;Natural Language Processing;Machine Translation;Machine Learning;Artificial Intelligence},
  doi={10.1109/CVMI59935.2023.10464455},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9414170,
  author={Yang, Yaxi and Wang, Hailin and Qiu, Haiquan and Wang, Jianjun and Wang, Yao},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Non-Convex Sparse Deviation Modeling Via Generative Models}, 
  year={2021},
  volume={},
  number={},
  pages={2345-2349},
  abstract={In this paper, the generative model is used to introduce the structural properties of the signal to replace the common sparse hypothesis, and a non-convex compressed sensing sparse deviation model based on the generative model (ℓq-Gen) is proposed. By establishing ℓq variant of the restricted isometry property (q-RIP) and Set-Restricted Eigenvalue Condition (q-S-REC), the error upper bound of the optimal decoder is derived when the recovered signal is within the sparse deviation range of the generator. Furthermore, it is proved that the Gaussian matrix satisfying a certain number of measurements is sufficient to ensure a good recovery for the generating function with high probability. Finally, a series of experiments are carried out to verify the effectiveness and superiority of the ℓq-Gen model.},
  keywords={Upper bound;Signal processing algorithms;Signal processing;Generators;Eigenvalues and eigenfunctions;Decoding;Sensors;Compressed sensing;generative model;non-convex},
  doi={10.1109/ICASSP39728.2021.9414170},
  ISSN={2379-190X},
  month={June},}@INPROCEEDINGS{10094956,
  author={Cheng, Anda and Cheng, Jian},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={APGP: Accuracy-Preserving Generative Perturbation for Defending Against Model Cloning Attacks}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Well-trained Deep Neural Networks (DNNs) are valuable intellectual properties. Recent studies show that adversaries only with black-box query access can steal the functionality of DNNs by using knowledge distillation (KD) techniques. In this paper, we propose a novel formulation to defend against model cloning attacks. Then we implement our defense as a plug-and-play generative perturbation model, dubbed as Accuracy-Preserving Generative Perturbation (APGP). Our method is the first to effectively defend against KD-based model cloning without damaging model accuracy. Numerous experiments demonstrate the effectiveness of our defense across different datasets and DNN model cloning attacks, and the advances compared to existing methods.},
  keywords={Deep learning;Perturbation methods;Neural networks;Cloning;Intellectual property;Signal processing;Predictive models;Model cloning;Knowledge distillation;Intellectual property protection;Generative model},
  doi={10.1109/ICASSP49357.2023.10094956},
  ISSN={2379-190X},
  month={June},}@ARTICLE{8852672,
  author={Zhang, Tianyang and Cheng, Jun and Fu, Huazhu and Gu, Zaiwang and Xiao, Yuting and Zhou, Kang and Gao, Shenghua and Zheng, Rui and Liu, Jiang},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Noise Adaptation Generative Adversarial Network for Medical Image Analysis}, 
  year={2020},
  volume={39},
  number={4},
  pages={1149-1159},
  abstract={Machine learning has been widely used in medical image analysis under an assumption that the training and test data are under the same feature distributions. However, medical images from difference devices or the same device with different parameter settings are often contaminated with different amount and types of noises, which violate the above assumption. Therefore, the models trained using data from one device or setting often fail to work for that from another. Moreover, it is very expensive and tedious to label data and re-train models for all different devices or settings. To overcome this noise adaptation issue, it is necessary to leverage on the models trained with data from one device or setting for new data. In this paper, we reformulate this noise adaptation task as an image-to-image translation task such that the noise patterns from the test data are modified to be similar to those from the training data while the contents of the data are unchanged. In this paper, we propose a novel Noise Adaptation Generative Adversarial Network (NAGAN), which contains a generator and two discriminators. The generator aims to map the data from source domain to target domain. Among the two discriminators, one discriminator enforces the generated images to have the same noise patterns as those from the target domain, and the second discriminator enforces the content to be preserved in the generated images. We apply the proposed NAGAN on both optical coherence tomography (OCT) images and ultrasound images. Results show that the method is able to translate the noise style. In addition, we also evaluate our proposed method with segmentation task in OCT and classification task in ultrasound. The experimental results show that the proposed NAGAN improves the analysis outcome.},
  keywords={Task analysis;Training data;Data models;Biomedical imaging;Gallium nitride;Generators;Speckle;Generative adversarial network;style transfer;noise adaptation;medical image analysis},
  doi={10.1109/TMI.2019.2944488},
  ISSN={1558-254X},
  month={April},}@ARTICLE{9766407,
  author={Cao, Xingjian and Sun, Gang and Yu, Hongfang and Guizani, Mohsen},
  journal={IEEE Internet of Things Journal}, 
  title={PerFED-GAN: Personalized Federated Learning via Generative Adversarial Networks}, 
  year={2023},
  volume={10},
  number={5},
  pages={3749-3762},
  abstract={Federated learning is gaining popularity as a distributed machine learning method that can be used to deploy AI-dependent Internet of Things applications while protecting client data privacy and security. Due to the differences of clients, a single global model may not perform well on all clients, so the personalized federated learning method, which trains a personalized model for each client that better suits its individual needs, becomes a research hotspot. Most personalized federated learning research, however, focuses on data heterogeneity while ignoring the need for model architecture heterogeneity. Most existing federated learning methods uniformly set the model architecture of all clients participating in federated learning, which is inconvenient for each client’s individual model and local data distribution requirements, and also increases the risk of client model leakage. This article proposes a federated learning method based on co-training and generative adversarial networks (GANs) that allows each client to design its own model to participate in federated learning training independently without sharing any model architecture or parameter information with other clients or a center. In our experiments, the proposed method outperforms the existing methods in mean test accuracy by 42% when the client’s model architecture and data distribution vary significantly.},
  keywords={Data models;Collaborative work;Training;Computer architecture;Task analysis;Machine learning;Computational modeling;Co-training;federated learning;generative adversarial networks (GANs);nonindependent and identically distributed (non-IID) data;personalized model},
  doi={10.1109/JIOT.2022.3172114},
  ISSN={2327-4662},
  month={March},}@ARTICLE{10057409,
  author={Saravanarajan, Vani Suthamathi and Chen, Rung-Ching and Hsieh, Cheng-Hsiung and Chen, Long-Sheng},
  journal={IEEE Access}, 
  title={Improving Semantic Segmentation Under Hazy Weather for Autonomous Vehicles Using Explainable Artificial Intelligence and Adaptive Dehazing Approach}, 
  year={2023},
  volume={11},
  number={},
  pages={38194-38207},
  abstract={Haze-level discriminators are crucial for autonomous vehicles to handle segmentation tasks successfully in hazy and foggy outdoor environments. Deep learning (DL) networks trained to segment clear images exhibit more false positives and fail to recognize the pixel patterns for the class categories when faced with hazy images. To address this issue, we propose a novel dehazing scheme called Adaptive Dehazing (AD) that separates the unacceptable hazy images and applies the dehazing technique only to those images before passing them to the DL for segmentation. We define various thresholds to classify hazy images into four categories: heavy, moderate, slight, and clear. Additionally, we implement a hazy image generator to create hazy synthetic images that replicate actual hazy road scene conditions for testing the proposed algorithm. Moreover, we use the Explainable Artificial Intelligence (XAI) method to understand the feature selected by different layers in the network before and after applying the AD and their contribution to obtaining a final segmented output. Extensive experiments demonstrate both quantitatively and qualitatively the performance improvement in the segmentation task by achieving an optimal balance between Intersection over Union (IoU) and pixel accuracy (PA) metrics of the segmented categories. The improvement in IoU metrics shows that the AD scheme significantly outperforms the previous state-of-the-art dehazing methods.},
  keywords={Image segmentation;Road traffic;Meteorology;Deep learning;Feature extraction;Task analysis;Neural networks;Autonomous vehicles;Semantics;Autonomous vehicle;dehazing;deep learning;semantic segmentation;XAI},
  doi={10.1109/ACCESS.2023.3251728},
  ISSN={2169-3536},
  month={},}@ARTICLE{9829878,
  author={Liu, Chao and Wang, Deli and Zhang, Han and Wu, Wei and Sun, Wenzhi and Zhao, Ting and Zheng, Nenggan},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Using Simulated Training Data of Voxel-Level Generative Models to Improve 3D Neuron Reconstruction}, 
  year={2022},
  volume={41},
  number={12},
  pages={3624-3635},
  abstract={Reconstructing neuron morphologies from fluorescence microscope images plays a critical role in neuroscience studies. It relies on image segmentation to produce initial masks either for further processing or final results to represent neuronal morphologies. This has been a challenging step due to the variation and complexity of noisy intensity patterns in neuron images acquired from microscopes. Whereas progresses in deep learning have brought the goal of accurate segmentation much closer to reality, creating training data for producing powerful neural networks is often laborious. To overcome the difficulty of obtaining a vast number of annotated data, we propose a novel strategy of using two-stage generative models to simulate training data with voxel-level labels. Trained upon unlabeled data by optimizing a novel objective function of preserving predefined labels, the models are able to synthesize realistic 3D images with underlying voxel labels. We showed that these synthetic images could train segmentation networks to obtain even better performance than manually labeled data. To demonstrate an immediate impact of our work, we further showed that segmentation results produced by networks trained upon synthetic data could be used to improve existing neuron reconstruction methods.},
  keywords={Neurons;Image segmentation;Data models;Image reconstruction;Training data;Training;Microscopy;Neuron reconstruction;microscope image simulation;generative model;image segmentation},
  doi={10.1109/TMI.2022.3191011},
  ISSN={1558-254X},
  month={Dec},}@INPROCEEDINGS{10824657,
  author={Yang, Lei and Yang, Xianna and Song, Guangmin and Zeng, Kang and Zeng, Guowen and Feng, Jikai},
  booktitle={2024 3rd International Conference on Cloud Computing, Big Data Application and Software Engineering (CBASE)}, 
  title={The Application Framework of the Generative Large Language Model in the Industrial Field}, 
  year={2024},
  volume={},
  number={},
  pages={774-779},
  abstract={With the rapid development of artificial intelligence technologies, particularly the development of generative Large Language Models (LLMs), new opportunities have emerged in the field of industry. This paper first reviews and analyzes the applications of LLMs in the industrial sector, summarizing their innovations and achievements in areas such as product development, production management, operational services etc. Next, an industrial application framework and flowchart based on LLMs is proposed, which can help to achieve comprehensive intelligence and efficiency improvement in the industrial field. Then, two cases from an aviation maintenance company and a crystal oscillator manufacturing company are used in this paper to validate the proposed method. Finally, the future development trends of LLMs in the industrial sector are discussed.},
  keywords={Flowcharts;Technological innovation;Accuracy;Large language models;Transfer learning;Companies;Market research;Data models;Manufacturing;Maintenance;Large Language Model;Industrial Field Applications;Intelligent Manufacturing},
  doi={10.1109/CBASE64041.2024.10824657},
  ISSN={},
  month={Oct},}@ARTICLE{9766338,
  author={Dideriksen, Bjørn Uttrup and Derosche, Kristoffer and Tan, Zheng-Hua},
  journal={IEEE Access}, 
  title={iVAE-GAN: Identifiable VAE-GAN Models for Latent Representation Learning}, 
  year={2022},
  volume={10},
  number={},
  pages={48405-48418},
  abstract={Remarkable progress has been made within nonlinear Independent Component Analysis (ICA) and identifiable deep latent variable models. Formally, the latest nonlinear ICA theory enables us to recover the true latent variables up to a linear transformation by leveraging unsupervised deep learning. This is of significant importance for unsupervised learning in general as the true latent variables are of principal interest for meaningful representations. These theoretical results stand in stark contrast to the mostly heuristic approaches used for representation learning which do not provide analytical relations to the true latent variables. We extend the family of identifiable models by proposing an identifiable Variational Autoencoder (VAE) based Generative Adversarial Network (GAN) model we name iVAE-GAN. The latent space of most GANs, including VAE-GAN, is generally unrelated to the true latent variables. With iVAE-GAN we show the first principal approach to a theoretically meaningful latent space by means of adversarial training. We implement the novel iVAE-GAN architecture and show its identifiability, which is confirmed by experiments. The GAN objective is believed to be an important addition to identifiable models as it is one of the most powerful deep generative models. Furthermore, no requirements are imposed on the adversarial training leading to a very general model.},
  keywords={Data models;Generative adversarial networks;Biological system modeling;Training;Solid modeling;Representation learning;Object recognition;Identifiability;VAE-GAN;deep learning;latent representation learning},
  doi={10.1109/ACCESS.2022.3172333},
  ISSN={2169-3536},
  month={},}@INBOOK{10785819,
  author={Campesato, Oswald},
  booktitle={Artificial Intelligence, Machine Learning, and Deep Learning}, 
  title={Index}, 
  year={2020},
  volume={},
  number={},
  pages={305-320},
  abstract={},
  keywords={Convolution;Artificial neural networks;Genetic algorithms;Classification algorithms;Bayes methods;Convolutional neural networks;Convolutional codes;Clustering algorithms;Internet;Generative adversarial networks},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9781683924661},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10785819},}@ARTICLE{10836753,
  author={Li, Zhuang and Lu, Zhenyu and Zhang, Yuhao and Li, Yizhe},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={PSRGAN: Generative Adversarial Networks for Precipitation Downscaling}, 
  year={2025},
  volume={22},
  number={},
  pages={1-5},
  abstract={This study proposes an innovative generative adversarial network (GAN)-based downscaling model for precipitation, named PSRGAN, which aims to enhance the spatial resolution of meteorological data using deep learning techniques. The PSRGAN model integrates a multiscale feature fusion module (Rception), a kernel attention module (KAM), and the generator–discriminator framework of GANs to address challenges such as data sparsity and spatiotemporal correlations that traditional precipitation super-resolution (SR) methods struggle with. By extracting multiscale spatial features, PSRGAN improves the model’s ability to detect key precipitation regions and enhances the accuracy of predicting extreme precipitation events. The model is trained and tested using low-resolution (LR) and high-resolution (HR) simulated datasets based on regional climate models (RCMs), with performance evaluated through various metrics. The experimental results demonstrate that PSRGAN achieves strong performance in the precipitation downscaling task.},
  keywords={Precipitation;Feature extraction;Predictive models;Meteorology;Image reconstruction;Generators;Superresolution;Atmospheric modeling;Computational modeling;Brain modeling;Deep learning;generative adversarial network (GAN);precipitation downscaling;precipitation super-resolution (SR)},
  doi={10.1109/LGRS.2025.3528018},
  ISSN={1558-0571},
  month={},}@ARTICLE{10614230,
  author={Wang, Weizhong and Liu, Hai-Lin and Tan, Kay Chen},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Effective Identification of Lower-Level Optimal Solutions via Discriminator of Conditional Generative Adversarial Network}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={Bilevel multi-objective optimization problem (BLMOP) can be seen as a special constrained multi-objective optimization problem (CMOP), where the optimality constraint of the lower-level (LL) problem cannot be easily and quickly checked, but must be verified by solving the LL problem. If there was a relatively simple alternative formulation for effectively identifying LL optimal solutions, the abovementioned special constraint could become as simple as the usual constraints and the nested optimization structure of BLMOP would be altered, which can greatly improve efficiency and effectively find LL optimal solutions with excellent upper-level (UL) performance. In this paper, we improve the training mechanism for conditional generative adversarial network (cGAN) by introducing multiple generators to construct a reasonable reference distribution, so as to prevent the discriminator from performance degradation. With a discriminator identifying LL optimal solutions effectively, the nested optimization structure of BLMOP is altered by adding the objective that maximizing the discriminator output score into the UL objectives and removing the LL optimality constraint, realizing synchronous optimization of UL and LL vectors. The cooperation of generators and discriminator greatly reduces the computational overhead for solving BLMOPs. The proposed algorithm has achieved the best or competitive results in comparison with 6 state-of-the-art algorithms and a nested method on benchmark problems and a real-world problem, whose effectiveness has been demonstrated.},
  keywords={Optimization;Generators;Vectors;Training;Sociology;Evolutionary computation;Task analysis;Bilevel optimization;Multi-objective;Evolutionary algorithm;Conditional generative adversarial network;Discriminator},
  doi={10.1109/TEVC.2024.3435421},
  ISSN={1941-0026},
  month={},}@INPROCEEDINGS{9753179,
  author={Soni, Kanishka and Hasija, Yasha},
  booktitle={2022 IEEE Delhi Section Conference (DELCON)}, 
  title={Artificial Intelligence Assisted Drug Research and Development}, 
  year={2022},
  volume={},
  number={},
  pages={1-10},
  abstract={Artificial Intelligence, abbreviated as AI, is described as a collection of technologies that work together to allow machines to discern, interpret, take action, and acquire knowledge with human level of intelligence. The AI domain includes technologies such as natural language processing (NLP) and machine learning (ML). Each of these is on its separate route of development and, when combined with datasets, analytics, and computerization, may assist organisations in achieving their objectives, whether it's enhancing customer service or improving supply chain. The pipeline of the development of novel drugs is quite extensive and costly apart from being complicated. On average, this entire process requires around 12 years costing approximately 2.6 billion USD. In this age of computational power, AI-based techniques are used in almost all of the steps during the process of discovering and developing drugs. AI has been able to reduce the time requirement and amount of money involved in this process thus expediting the entire procedure of new pharmaceutical inventions. In this manuscript, we have discussed some of the major applications of AI in the pharmaceutical sector. Tools that are employed to forecast the toxicity of drugs and how some of them, for example - Toxtree, ADMET, ProTox etc. have been used by researchers in the drug discovery process, have also been talked about. Further we have mentioned how AI is proving to be a powerful tool in the fight against the COVID-19 pandemic, for example, in the detection of the SARS-Co V -2 virus, development of vaccines, genomics etc. In addition to this, we have discussed about the manner in which the penetration of AI-based companies into the pharmaceutical field has resulted in some notable outcomes, for instance - prediction of the 3-dimensional structure of proteins by DeepMind's AlphaFold2, determination of new drug contender for kidney fibrosis by Insilico Medicine's Chemistry42 etc. Furthermore, we have stated the propitious future that AI is expected to bring about in the pharma world with a special focus on drug development.},
  keywords={Drugs;Proteins;Technological innovation;Toxicology;Supply chains;Pipelines;Natural language processing;artificial intelligence;drug development;COVID-19;drug repurposing;clinical trials;machine learning},
  doi={10.1109/DELCON54057.2022.9753179},
  ISSN={},
  month={Feb},}@ARTICLE{10552760,
  author={Qin, Xiaoli and Bui, Francis Minhthang and Han, Zhu and Khademi, April},
  journal={IEEE Access}, 
  title={Toward Improved Interpretability in Medical Imaging: Revealing the Disease Evidence From Chest X-Ray Images Using an Adversarial Generative Approach}, 
  year={2024},
  volume={12},
  number={},
  pages={82002-82014},
  abstract={In recent years, deep neural networks have made significant progress in the field of automated disease recognition for medical imaging. Although methods based on deep neural networks reported good results in automated disease classification, many of them lack output interpretability. Unlike methods that only aim at predicting if an input image contains disease or not, our work focuses additionally on revealing the disease evidence and offering interpretability of decision-making. We assume that an abnormal image is the additive composition of a hypothetical but synthesizable normal counterpart and a related disease effect map. Therefore we propose a disease decomposition network (DDN) that can explicitly locate, separate the disease evidence from an abnormal image and synthesize this hypothetical normal counterpart simultaneously. The proposed DDN has two branches: one is for translating the input image to a normal image, and the other is for locating the underlying abnormalities accurately if the input is abnormal. The novelty of our proposed DDN is that it not only provides highly accurate visual disease evidence maps, but also generates corresponding healthy images that are close to real normal chest X-rays (CXRs). From an interpretability and user interface perspective, it is insightful and helpful to provide a relevant reference (albeit hypothetical) for better understanding the difference between a normal and diseased CXR image. We evaluated our method on an extensive and well-established public chest X-ray dataset. The results demonstrate that the proposed DDN can translate abnormal CXR images to healthy CXRs while also generating disease evidence maps with good localization performance over other state-of-the-art methods.},
  keywords={Diseases;Generative adversarial networks;Location awareness;Magnetic resonance imaging;Biomedical imaging;Feature extraction;X-ray imaging;Disease evidence;disease decomposition network;interpretability;CXR},
  doi={10.1109/ACCESS.2024.3412608},
  ISSN={2169-3536},
  month={},}@ARTICLE{8882370,
  author={Li, Jinpeng and Qiu, Shuang and Du, Changde and Wang, Yixin and He, Huiguang},
  journal={IEEE Transactions on Cognitive and Developmental Systems}, 
  title={Domain Adaptation for EEG Emotion Recognition Based on Latent Representation Similarity}, 
  year={2020},
  volume={12},
  number={2},
  pages={344-353},
  abstract={Emotion recognition has many potential applications in the real world. Among the many emotion recognition methods, electroencephalogram (EEG) shows advantage in reliability and accuracy. However, the individual differences of EEG limit the generalization of emotion classifiers across subjects. Moreover, due to the nonstationary characteristic of EEG, the signals of one subject change over time, which is a challenge to acquire models that could work across sessions. In this article, we propose a novel domain adaptation method to generalize the emotion recognition models across subjects and sessions. We use neural networks to implement the emotion recognition models, which are optimized by minimizing the classification error on the source while making the source and the target similar in their latent representations. Considering the functional differences of the network layers, we use adversarial training to adapt the marginal distributions in the early layers and perform association reinforcement to adapt the conditional distributions in the last layers. In this way, we approximately adapt the joint distributions by simultaneously adapting marginal distributions and conditional distributions. The method is compared with multiple representatives and recent domain adaptation algorithms on benchmark SEED and DEAP for recognizing three and four affective states, respectively. The experimental results show that the proposed method reaches and outperforms the state of the arts.},
  keywords={Electroencephalography;Brain modeling;Emotion recognition;Adaptation models;Training;Feature extraction;Neural networks;Domain adaptation;electroencephalogram (EEG);emotion recognition;neural network;transfer learning},
  doi={10.1109/TCDS.2019.2949306},
  ISSN={2379-8939},
  month={June},}@INPROCEEDINGS{10564292,
  author={Ghimire, Aashish and Edwards, John},
  booktitle={2024 Intermountain Engineering, Technology and Computing (IETC)}, 
  title={Generative AI Adoption in the Classroom: A Contextual Exploration Using the Technology Acceptance Model (TAM) and the Innovation Diffusion Theory (IDT)}, 
  year={2024},
  volume={},
  number={},
  pages={129-134},
  abstract={The burgeoning development of generative artificial intelligence (GenAI) and the widespread adoption of large language models (LLMs) in educational settings have sparked considerable debate regarding their efficacy and acceptability. Despite the potential benefits, the assimilation of these cutting-edge technologies among educators exhibits a broad spectrum of attitudes, from enthusiastic advocacy to profound skepticism. This study aims to dissect the underlying factors influencing educators' perceptions and acceptance of GenAI and LLMs. We conducted a survey among educators and analyzed the data through the frameworks of the Technology Acceptance Model (TAM) and Innovation Diffusion Theory (IDT). Our investigation reveals a strong positive correlation between the perceived usefulness of GenAI tools and their acceptance, underscoring the importance of demonstrating tangible benefits to educators. Additionally, the perceived ease of use emerged as a significant factor, though to a lesser extent, influencing acceptance. Our findings also show that the knowledge and acceptance of these tools is not uniform, suggesting that targeted strategies are required to address the specific needs and concerns of each adopter category to facilitate broader integration of AI tools in education.},
  keywords={Surveys;Technological innovation;Technology acceptance model;Correlation;Generative AI;Computational modeling;Education;Generative Artificial Intelligence (GenAI);Large Language Models (LLMs);Technology Acceptance Model (TAM);Innovation Diffusion Theory (IDT)},
  doi={10.1109/IETC61393.2024.10564292},
  ISSN={},
  month={May},}@ARTICLE{10858771,
  author={Ma, Yongqiang and Liu, Yulong and Chen, Liangjun and Zhu, Guibo and Chen, Badong and Zheng, Nanning},
  journal={IEEE Transactions on Medical Imaging}, 
  title={BrainCLIP: Brain Representation via CLIP for Generic Natural Visual Stimulus Decoding}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Functional Magnetic Resonance Imaging (fMRI) presents challenges due to limited paired samples and low signal-to-noise ratios, particularly in tasks involving reconstructing natural images or decoding their semantic content. To address these challenges, we introduce BrainCLIP, an innovative fMRI-based brain decoding model. BrainCLIP leverages Contrastive Language-Image Pre-training’s (CLIP) cross-modal generalization abilities to bridge brain activity, images, and text for the first time. Our experiments demonstrate CLIP’s effectiveness in diverse brain decoding tasks, including zero-shot visual category decoding, fMRI-image/text alignment, and fMRI-to-image generation. The core objective of BrainCLIP is to train a mapping network that translates fMRI patterns into a unified CLIP embedding space, achieved through visual and textual supervision integration. Our experiments highlight that this approach significantly enhances performance in tasks such as fMRI-text alignment and fMRI-based image generation. Notably, BrainCLIP surpasses BraVL, a recent multi-modal method, in zero-shot visual category decoding. Moreover, BrainCLIP demonstrates strong capability in reconstructing visual stimuli with high semantic fidelity, competing favorably with state-of-the-art methods in capturing high-level semantic features during fMRI-based natural image reconstruction.},
  keywords={Visualization;Decoding;Functional magnetic resonance imaging;Brain modeling;Semantics;Image reconstruction;Training;Brain;Feature extraction;Contrastive learning;Brain decoding;CLIP;Visual-Linguistic representation;Cross-modal},
  doi={10.1109/TMI.2025.3537287},
  ISSN={1558-254X},
  month={},}@ARTICLE{10971415,
  author={Belano, Andrea and Tortorella, Yvan and Garofalo, Angelo and Benini, Luca and Rossi, Davide and Conti, Francesco},
  journal={IEEE Journal on Emerging and Selected Topics in Circuits and Systems}, 
  title={A Flexible Template for Edge Generative AI With High-Accuracy Accelerated Softmax and GELU}, 
  year={2025},
  volume={15},
  number={2},
  pages={200-216},
  abstract={Transformer-based generative Artificial Intelligence (GenAI) models achieve remarkable results in a wide range of fields, including natural language processing, computer vision, and audio processing. However, this comes at the cost of increased complexity and the need of sophisticated non-linearities such as softmax and GELU. Even if Transformers are computationally dominated by matrix multiplications (MatMul), these non-linearities can become a performance bottleneck, especially if dedicated hardware is used to accelerate MatMul operators. In this work, we introduce a GenAI BFloat16 Transformer acceleration template based on a heterogeneous tightly-coupled cluster containing 256KiB of shared SRAM, 8 general-purpose RISC-V cores, a  $24\times 8$  systolic array MatMul accelerator, and a novel accelerator for Transformer softmax, GELU and SiLU non-linearities: SoftEx. SoftEx introduces an approximate exponentiation algorithm balancing efficiency ( $121\times $  speedup over glibc’s implementation) with accuracy (mean relative error of 0.14%). In 12 nm technology, SoftEx occupies 0.039 mm2, only 3.22% of the cluster, which achieves an operating frequency of 1.12 GHz. Compared to optimized software running on the RISC-V cores, SoftEx achieves significant improvements, accelerating softmax and GELU computations by up to  $10.8\times $  and  $5.11\times $ , respectively, while reducing their energy consumption by up to  $10.8\times $  and  $5.29\times $ . These enhancements translate into a  $1.58\times $  increase in throughput (310 GOPS at 0.8 V) and a  $1.42\times $  improvement in energy efficiency (1.34 TOPS/W at 0.55 V) on end-to-end ViT inference workloads.},
  keywords={Transformers;Tensors;Table lookup;Accuracy;Computational modeling;Hardware acceleration;Computer architecture;Generative AI;Transformer cores;Training;Artificial intelligence (AI) accelerators;system-on-chip;accelerator architectures;edge AI;generative AI (GenAI)},
  doi={10.1109/JETCAS.2025.3562734},
  ISSN={2156-3365},
  month={June},}@INPROCEEDINGS{11023500,
  author={Yu, Yaman and Sharma, Tanusree and Hu, Melinda and Wang, Justin and Wang, Yang},
  booktitle={2025 IEEE Symposium on Security and Privacy (SP)}, 
  title={Exploring Parent-Child Perceptions on Safety in Generative AI: Concerns, Mitigation Strategies, and Design Implications}, 
  year={2025},
  volume={},
  number={},
  pages={2735-2752},
  abstract={The widespread use of Generative Artificial Intelligence (GAI) among teenagers has led to significant misuse and safety concerns. To identify risks and understand parental controls challenges, we conducted a content analysis on Reddit and interviewed 20 participants (seven teenagers and 13 parents). Our study reveals a significant gap in parental awareness of the extensive ways children use GAI, such as interacting with character-based chatbots for emotional support or engaging in virtual relationships. Parents and children report differing perceptions of risks associated with GAI. Parents primarily express concerns about data collection, misinformation, and exposure to inappropriate content. In contrast, teenagers are more concerned about becoming addicted to virtual relationships with GAI, the potential misuse of GAI to spread harmful content in social groups, and the invasion of privacy due to unauthorized use of their personal data in GAI applications. The absence of parental control features on GAI platforms forces parents to rely on system-built controls, manually check histories, share accounts, and engage in active mediation. Despite these efforts, parents struggle to grasp the full spectrum of GAI-related risks and to perform effective real-time monitoring, mediation, and education. We provide design recommendations to improve parent-child communication and enhance the safety of GAI use.},
  keywords={Content management;Generative AI;Social networking (online);Social groups;Control systems;Chatbots;Real-time systems;Safety;Security;Mediation;generative artificial intelligence (gai);teenagers safety;parental controls;safety concerns in gai;ai ethics;responsible ai},
  doi={10.1109/SP61157.2025.00090},
  ISSN={2375-1207},
  month={May},}@ARTICLE{11031191,
  author={Dong, Qiulei and Wang, Zhixi and Gao, Mengyu},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Noise-Aware Epileptic Seizure Prediction Network via Self-Attention Feature Alignment}, 
  year={2025},
  volume={},
  number={},
  pages={1-13},
  abstract={Recently, deep neural networks have been extensively used to extract features from EEG data for epileptic seizure prediction in the epilepsy diagnosis community. Many existing works in literature either use the ultimate-layer feature or aggregate multi-layer features via straightforward concatenation or element-wise addition, but they do not pay a special attention to the contextual consistency between these features as well as the involved noise in these features. To address the above problem, we propose a Noise-aware epileptic seizure prediction network via Self-attention Feature Alignment, called NSFA-Net. The NSFA-Net consists of two modules: a self-attention backbone module to extract multi-layer features from the input EEG data, and a time-frequency feature alignment module to align these features for maintaining the contextual consistency. In addition, during the training process, a noise-aware regularizer is introduced to alleviate the negative influence of noise that is generally inevitable in EEG data. The average sensitivities of the proposed method on the CHB-MIT and Kaggle datasets are 98.68% and 93.57% respectively, and the average false prediction rates are 0.038/h and 0.060/h respectively. These experimental results show the superiority of the proposed method to some state-of-the-art methods.},
  keywords={Feature extraction;Electroencephalography;Time-frequency analysis;Data mining;Training;Signal to noise ratio;Transformers;Aggregates;Bioinformatics;Sensitivity;Epileptic seizure prediction;feature alignment;noise-aware regularizer},
  doi={10.1109/JBHI.2025.3579229},
  ISSN={2168-2208},
  month={},}@BOOK{10972217,
  author={Biswas, Anjanava and Talukdar, Wrick and Scott, Matthew R. and Acero, Dr. Alex},
  booktitle={Building Agentic AI Systems: Create intelligent, autonomous AI agents that can reason, plan, and adapt},
  year={2025},
  volume={},
  number={},
  pages={},
  abstract={Master the art of building AI agents with large language models using the coordinator, worker, and delegator approach for orchestrating complex AI systemsKey FeaturesUnderstand the foundations and advanced techniques of building intelligent, autonomous AI agentsLearn advanced techniques for reflection, introspection, tool use, planning, and collaboration in agentic systemsExplore crucial aspects of trust, safety, and ethics in AI agent development and applicationsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionGain unparalleled insights into the future of AI autonomy with this comprehensive guide to designing and deploying autonomous AI agents that leverage generative AI (GenAI) to plan, reason, and act. Written by industry-leading AI architects and recognized experts shaping global AI standards and building real-world enterprise AI solutions, it explores the fundamentals of agentic systems, detailing how AI agents operate independently, make decisions, and leverage tools to accomplish complex tasks. Starting with the foundations of GenAI and agentic architectures, you’ll explore decision-making frameworks, self-improvement mechanisms, and adaptability. The book covers advanced design techniques, such as multi-step planning, tool integration, and the coordinator, worker, and delegator approach for scalable AI agents. Beyond design, it addresses critical aspects of trust, safety, and ethics, ensuring AI systems align with human values and operate transparently. Real-world applications illustrate how agentic AI transforms industries such as automation, finance, and healthcare. With deep insights into AI frameworks, prompt engineering, and multi-agent collaboration, this book equips you to build next-generation adaptive, scalable AI agents that go beyond simple task execution and act with minimal human intervention.What you will learnMaster the core principles of GenAI and agentic systemsUnderstand how AI agents operate, reason, and adapt in dynamic environmentsEnable AI agents to analyze their own actions and improviseImplement systems where AI agents can leverage external tools and plan complex tasksApply methods to enhance transparency, accountability, and reliability in AIExplore real-world implementations of AI agents across industriesWho this book is forThis book is ideal for AI developers, machine learning engineers, and software architects who want to advance their skills in building intelligent, autonomous agents. It's perfect for professionals with a strong foundation in machine learning and programming, particularly those familiar with Python and large language models. While prior experience with generative AI is beneficial, the book covers foundational concepts for those new to agentic systems.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781801079273},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10972217},}@ARTICLE{11138010,
  author={Zheng, Chuhang and Zhu, Qi and Fei, Lunke and Li, Shengrong and Zhai, Xiangping Bryce and Zhang, David and Zhang, Daoqiang},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Disentangled Representation Learning for Robust Brainprint Recognition}, 
  year={2025},
  volume={20},
  number={},
  pages={9263-9274},
  abstract={Electroencephalography (EEG) biometrics draws increasing attention in high-security requirements due to its advantages of anti-spoofing, live traits, and non-duplicated. However, existing EEG datasets, which rely on external stimuli or task-specific instructions for data collection, often intertwine identity-related information with biases such as emotional states, cognitive tasks, and disease markers. Besides, EEG signals are time-varying, while identity information within EEG signals is relatively fixed, which poses challenges for extracting identity features from EEG to perform accurate person identification. This high correlation hampers the promotion of brainprint recognition in real-life applications. In this paper, we propose a disentangled representation learning based identity recognition framework, which disentangles the EEG signal into intrinsic identity-related information and biased identity-invariant information, thus enhancing the performance of EEG biometrics. First, two parallel encoders are used to extract intrinsic identity-relevant and bias identity-irrelevant factors, respectively, and each encoder consists of a temporal filter module and a novel spatial-temporal attention module. Then, we further refine the disentanglement process through a correlation-driven loss that minimizes factor similarity across spatial-temporal and global representational domains. Adversarial training and reconstruction regularization are introduced to facilitate the identity and biased representations to be independent and complementary to each other. Additionally, we extend supervised contrastive learning to the component level, minimizing cross-component similarity and encouraging each component to independently reflect its unique information, thereby improving the disentanglement efficacy. Our proposed framework achieves state-of-the-art performance on diverse datasets encompassing emotional, motor imagery, and pathological conditions, demonstrating the robustness and effectiveness of our proposed brainprint identity recognition model.},
  keywords={Electroencephalography;Feature extraction;Biometrics;Brain modeling;Training;Contrastive learning;Accuracy;Motors;Disentangled representation learning;Diseases;EEG;biometrics;brainprint;contrastive learning;adversarial training},
  doi={10.1109/TIFS.2025.3602266},
  ISSN={1556-6021},
  month={},}@ARTICLE{10981818,
  author={Pandey, Neeraj and Mathur, Devansh and Sarkar, Debojyoti and Ram, Shobha Sundar},
  journal={IEEE Transactions on Radar Systems}, 
  title={Generating Counterfactual Explanations for Misclassification of Automotive Radar Targets}, 
  year={2025},
  volume={3},
  number={},
  pages={724-737},
  abstract={Prior studies have demonstrated that the inverse synthetic aperture radar (ISAR) images of automotive targets at millimeter-wave (mmW) frequencies provide useful information regarding the target’s shape, size, and trajectory and serve as excellent classification features for deep neural networks. However, the classification performance is limited by environmental conditions, such as multipath, clutter, and occlusion, even when the radar receivers have a high signal-to-noise ratio (SNR). Therefore, for the widespread adoption of deep learning-based ISAR classification in real-world advanced driver assistance systems (ADASs), it is essential to provide a framework for explaining the physics-based phenomena responsible for misclassification and building trust among end users. In this work, we use the deep learning-based generative framework that introduces minimal perturbations on ISAR images belonging to one class to synthesize counterfactual realistic ISAR images that are misclassified as belonging to a second class of automotive vehicles. The networks are specifically trained to emulate occlusions of parts of the target vehicles from the radar. Due to the requirement of controlled experiments for occluding specific parts of the vehicle, simulation radar data are adopted to generate ISAR images. Our results show that the analyses of the counterfactual images generated through this process provide valuable insights into the physics-based causes of misclassification.},
  keywords={Radar;Radar imaging;Generative adversarial networks;Signal to noise ratio;Perturbation methods;Automobiles;Wheels;Vehicle dynamics;Feature extraction;Data mining;Automotive radar;counterfactual explanations;explainable artificial intelligence (AI);inverse synthetic aperture radar (ISAR)},
  doi={10.1109/TRS.2025.3566222},
  ISSN={2832-7357},
  month={},}@INPROCEEDINGS{10503259,
  author={Pant, Himanshu and Lohani, Manoj Chandra and Bhatt, Ashutosh Kumar},
  booktitle={2024 IEEE International Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation (IATMSI)}, 
  title={Neural Perspectives on Chest X-rays: Comparative Evaluation of Deep Learning Models for Thoracic Disorder Detection}, 
  year={2024},
  volume={2},
  number={},
  pages={1-6},
  abstract={Thoracic diseases are viral infections that spread at a rapid rate, and they have affected millions of people around the globe. The increasing prevalence and rapid dissemination of the disease have placed healthcare professionals in a precarious position, impeding their ability to promptly identify and contain the illness. The swiftly developing domain of medical image analysis exhibits potential for effectively tackling this obstacle with enhanced accuracy. This study compares and contrasts a number of modern deep learning architectures, including CapsNet, AlexNet, VGGNet, GoogLeNet, ResNet, and DenseNet, in order to find and label a wide range of thoracic disorders. The study utilized a dataset consisting of 3043 chest X-ray images. Among the patients included were those who were deemed healthy (134 images), those who had tuberculosis (138 images), and those who had COVID-19 (217 images). CapsNet's accuracy of 98.48% serves as proof that it performs poorly when compared to other models based on perplexity and performance metrics.},
  keywords={Deep learning;COVID-19;Training;Technological innovation;Pneumonia;Tuberculosis;Transfer learning;Thoracic disorders;classification;artificial neural networks;deep learning;transfer learning;capsule networks},
  doi={10.1109/IATMSI60426.2024.10503259},
  ISSN={},
  month={March},}@INPROCEEDINGS{11011606,
  author={Baviskar, Vaishali and Sabale, Tejas and Jachak, Prasad and Tapkir, Chaitanya},
  booktitle={2025 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI)}, 
  title={News Article Analysis Chatbot using Generative AI}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The News Analysis Chatbot provides insightful analysis on current events through the generative AI, thus realizing real-time summaries, in-depth analyses of detailed data, and even the perspectives of most matters with all fairness to every aspect concerned. A new tool that ensures you are in the know about current happenings such that you acquire a comprehensive understanding of issues that might otherwise become quagmired. From the generative AI powered analysis of news articles, a changing and intelligent solution for the ability to analyze news content and summarize it. Due to the nature of the advanced NLP techniques used by the chatbot, it is capable of reading and understanding the articles, spotting the main ideas, extracting insights, producing and summarizing user preferences. This will enable users to extract coherent, up-to-the-minute summaries of either lengthy or complicated news articles within an extremely short amount of time. It allows the chatbot to move out of static response spaces by having an interactive discussion about the news, answering follow-up questions, providing context, and offering critical analysis. It can even compare articles within related topics, hint at trends, and even suggest additional readings to enrich the user’s understanding of events. Additionally, it learns the interest of the individual, suggesting articles based on previous interactions. We have introduced the News Research Tool, which is able to extract and process news articles via large language models (LLM). The software takes multiple news article URLs to analyze the news content and an open number of specific questions of the input articles. We deploy Streamlit to design an intuitively-operational user interface and to store the application. We utilize FAISS and a stream to tackle vector-based retrieval and Hugging Face embeddings to let search capture the most relevant context. Lastly, Streamlit Cloud hosts that we deploy our app so that it is accessible as a web application.},
  keywords={Uniform resource locators;Generative AI;Large language models;Writing;User interfaces;Streaming media;Chatbots;Real-time systems;Usability;Faces;Generative AI;Natural Language Processing (NLP);Large Language Model (LLM);FAISS;URL},
  doi={10.1109/ICDSAAI65575.2025.11011606},
  ISSN={},
  month={March},}@ARTICLE{10130164,
  author={Pham, Van-Nguyen and Le, Duc-Tai and Bum, Junghyun and Lee, Eun Jung and Han, Jong Chul and Choo, Hyunseung},
  journal={IEEE Access}, 
  title={Attention-Aided Generative Learning for Multi-Scale Multi-Modal Fundus Image Translation}, 
  year={2023},
  volume={11},
  number={},
  pages={51701-51711},
  abstract={Conventional fundus images (CFIs) and ultra-widefield fundus images (UFIs) are two fundamental image modalities in ophthalmology. While CFIs provide a detailed view of the optic nerve head and the posterior pole of an eye, their clinical use is associated with high costs and patient inconvenience due to the requirement of good pupil dilation. On the other hand, UFIs capture peripheral lesions, but their image quality is sensitive to factors such as pupil size, eye position, and eyelashes, leading to greater variability between examinations compared to CFIs. The widefield retina view of UFIs offers the theoretical possibility of generating CFIs from available UFIs to reduce patient examination costs. A recent study has shown the feasibility of this approach by leveraging deep learning techniques for the UFI-to-CFI translation task. However, the technique suffers from the heterogeneous scales of the image modalities and variations in the brightness of the training data. In this paper, we address these issues with a novel framework consisting of three stages: cropping, enhancement, and translation. The first stage is an optic disc-centered cropping strategy that helps to alleviate the scale difference between the two image domains. The second stage mitigates the variation in training data brightness and unifies the mask between the two modalities. In the last stage, we introduce an attention-aided generative learning model to translate a given UFI into the CFI domain. Our experimental results demonstrate the success of the proposed method on 1,011 UFIs, with 99.8% of the generated CFIs evaluated as good quality and usable. Expert evaluations confirm significant visual quality improvements in the generated CFIs compared to the UFIs, ranging from 10% to 80% for features such as optic nerve structure, vascular distribution, and drusen. Furthermore, using generated CFIs in an AI-based diagnosis system for age-related macular degeneration results in superior accuracy compared to UFIs and competitive performance relative to real CFIs. These results showcase the potential of our approach for automatic disease diagnosis and monitoring.},
  keywords={Optical imaging;Task analysis;Diseases;Ophthalmology;Mathematical models;Deep learning;Biomedical optical imaging;Conventional fundus images;deep learning;generative learning;ophthalmology;unpaired image-to-image translation;ultra wide-field fundus images},
  doi={10.1109/ACCESS.2023.3278596},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8489444,
  author={Liu, Guangcan and Shi, Jing and Chen, Xiuyi and Xu, Jiaming and Xu, Bo},
  booktitle={2018 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Improving Speech Separation with Adversarial Network and Reinforcement Learning}, 
  year={2018},
  volume={},
  number={},
  pages={1-7},
  abstract={In contrast to the conventional deep neural network for single-channel speech separation, we propose a separation framework based on adversarial network and reinforcement learning. The purpose of the adversarial network inspired by the generative adversarial network is to make the separated result and ground-truth with the same data distribution by evaluating the discrepancy between them. Meanwhile, in order to enable the model to bias the generation towards desirable metrics and reduce the discrepancy between training loss (such as mean squared error) and testing metric (such as SDR), we present the future success based on reinforcement learning. We directly optimize the performance metric to accomplish exactly that. With the combination of adversarial network and reinforcement learning, our model is able to improve the performance of single-channel speech separation.},
  keywords={Training;Learning (artificial intelligence);Machine learning;Time-frequency analysis;Generative adversarial networks;Testing;speech separation;generative adversarial network;reinforcement learning},
  doi={10.1109/IJCNN.2018.8489444},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{10223329,
  author={Amer, Ibrahim M. and Oteafy, Sharief M. A. and Hassanein, Hossam S.},
  booktitle={2023 IEEE 48th Conference on Local Computer Networks (LCN)}, 
  title={Affective Communication of Sensorimotor Emotion Synthesis over URLLC}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Affective computing is an emerging field that aims to develop technologies capable of recognizing and responding to human emotions. However, during communication sessions, the exchange of a high volume of data can cause high latency. One approach to mitigating this issue is semantic communication, which may reduce the amount of data exchanged. Hereby, we propose a novel idea that utilizes semantic communication in affective computing by minimizing the amount of information exchanged between endpoints. Specifically, we examine a use case of a remote doctor application, where a patient’s emotions are captured, and their vital signs are obtained using wearable devices, with this information reported to a remote doctor. To reduce data exchange, we utilize semantic communication to extract the meaning of the conveyed information, rather than transmitting the raw information itself. This approach can enhance the efficiency of communication in URLLC applications and has the potential to improve patient outcomes.},
  keywords={Affective computing;Emotion recognition;Wearable computers;Semantics;Medical services;Ultra reliable low latency communication;Computer networks;Affective Computing;Semantic Communication;Artificial Intelligence;Edge Intelligence;Ultra-Low Latency;Tactile Internet;Generative Networks},
  doi={10.1109/LCN58197.2023.10223329},
  ISSN={2832-1421},
  month={Oct},}@INBOOK{10953355,
  author={},
  booktitle={Machine Learning and the City: Applications in Architecture and Urban Design}, 
  title={Frontmatter}, 
  year={2022},
  volume={},
  number={},
  pages={i-xxx},
  abstract={},
  keywords={},
  doi={10.1002/9781119815075.fmatter},
  ISSN={},
  publisher={Wiley},
  isbn={9781119749585},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10953355},}@INPROCEEDINGS{11050549,
  author={Zarei, Mohammad and Jutras, Melanie A and Evans, Eliana and Tan, Mike and Aaramoon, Omid},
  booktitle={2025 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Authentication Identifying Rare Failure Modes in Autonomous Vehicle Perception Systems Using Adversarially Guided Diffusion Models}, 
  year={2025},
  volume={},
  number={},
  pages={936-943},
  abstract={Autonomous Vehicles (AVs) rely on artificial intel-ligence (AI) to accurately detect objects and interpret their surroundings. However, even when trained using millions of miles of real-world data, AVs are often unable to detect rare failure modes (RFMs). The problem of RFMs is commonly referred to as the “long-tail challenge”, due to the distribution of data including many instances that are very rarely seen. In this paper, we present a novel approach that utilizes advanced generative and explainable AI techniques to aid in understanding RFMs. Our methods can be used to enhance the robustness and reliability of AV s when combined with both downstream model training and testing. We extract segmentation masks for objects of interest (e.g., cars) and invert them to create environmental masks. These masks, combined with carefully crafted text prompts, are fed into a custom diffusion model. We leverage the Stable Diffusion inpainting model guided by adversarial noise optimization to generate images containing diverse environments designed to evade object detection models and expose vulnerabilities in AI systems. Finally, we produce natural language descriptions of the generated RFMs that can guide developers and policymakers to improve the safety and reliability of AV systems.},
  keywords={Training;Soft sensors;Object detection;Diffusion models;Robustness;Safety;Automobiles;Autonomous vehicles;Optimization;Testing;Autonomous Vehicles (AVs);Artificial Intelli-gence (AI);Object Detection;Adversarial Machine Learning;Diffusion Models},
  doi={10.1109/CAI64502.2025.00165},
  ISSN={},
  month={May},}@ARTICLE{9253644,
  author={Moon, Jaeuk and Jung, Seungwon and Park, Sungwoo and Hwang, Eenjun},
  journal={IEEE Access}, 
  title={Conditional Tabular GAN-Based Two-Stage Data Generation Scheme for Short-Term Load Forecasting}, 
  year={2020},
  volume={8},
  number={},
  pages={205327-205339},
  abstract={Load forecasting is one of the critical tasks for enhancing the energy efficiency of smart grids. Even though recent deep learning-based load forecasting models have shown excellent forecasting performance, one of the common problems they faced was that their forecasting accuracy was highly dependent on the data quality and quantity available for the model training. Collecting a sufficient amount of high-quality data is expensive and time-consuming. Recently, a generative adversarial network (GAN) has shown its potential as a solution to the data shortage problem by generating virtual data based on a small amount of real data, and several studies have used GAN to generate electric load data for training forecasting models. However, due to the noise data problem of GANs, their predictive performance also deteriorated. To solve this problem, in this study, we propose a two-stage data generation scheme that more effectively generates input and output variables for short-term load forecasting. In the first stage, we generate virtual calendar and temperature data used as input variables using a conditional tabular GAN (CTGAN). In the second stage, we generate electric load data corresponding to the input variables using a deep learning-based regression model. Lastly, we construct our forecasting model by training another regression model using a mixture of generated data and real data. To verify the effectiveness of our scheme, we conducted extensive experiments using various datasets and data generation models. We report some of the results.},
  keywords={Load modeling;Data models;Forecasting;Gallium nitride;Predictive models;Generative adversarial networks;Training;Short-term load forecasting;smart grid;conditional generative adversarial networks},
  doi={10.1109/ACCESS.2020.3037063},
  ISSN={2169-3536},
  month={},}@ARTICLE{9851423,
  author={Groshev, Alexander and Maltseva, Anastasia and Chesakov, Daniil and Kuznetsov, Andrey and Dimitrov, Denis},
  journal={IEEE Access}, 
  title={GHOST—A New Face Swap Approach for Image and Video Domains}, 
  year={2022},
  volume={10},
  number={},
  pages={83452-83462},
  abstract={Deep fake stands for a face swapping algorithm where the source and target can be an image or a video. Researchers have investigated sophisticated generative adversarial networks (GAN), autoencoders, and other approaches to establish precise and robust algorithms for face swapping. However the achieved results are far from perfect in terms of human and visual evaluation. In this study, we propose a new one-shot pipeline for image-to-image and image-to-video face swap solutions - GHOST (Generative High-fidelity One Shot Transfer). We take the FaceShifter (image-to-image) architecture as a baseline approach and propose several major architecture improvements which include a new eye-based loss function, face mask smooth algorithm, a new face swap pipeline for image-to-video face transfer, a new stabilization technique to decrease face jittering on adjacent frames and a super-resolution stage. In the experimental stage, we show that our solution outperforms SoTA face swap architectures in terms of ID retrieval (+1.5% improvement), shape (the second best value) and eye gaze preserving (+1% improvement) metrics. We also established an ablation study for our solution to estimate the contribution of pipeline stages to the overall accuracy, which showed that the eye loss leads to 2% improvement in the ID retrieval and 45% improvement in the eye gaze preserving.},
  keywords={Faces;Face recognition;Pipelines;Deepfakes;Training;Measurement;Image reconstruction;Deep fake;face swap;GHOST;AEI-Net;eye loss;face mask smooth;stabilization;super resolution},
  doi={10.1109/ACCESS.2022.3196668},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9832406,
  author={Ding, Zhitong and Jiang, Shuqi and Zhao, Jingya},
  booktitle={2022 IEEE 2nd International Conference on Electronic Technology, Communication and Information (ICETCI)}, 
  title={Take a close look at mode collapse and vanishing gradient in GAN}, 
  year={2022},
  volume={},
  number={},
  pages={597-602},
  abstract={The Generative Adversarial Nets (GAN) has made great advances during these years. Many research branches of the GAN have appeared. However, the researchers have to face the difficulties of the several problems of the GAN. This paper presents a literature review of two problems in GAN over the years, i.e., mode collapse and vanishing gradient. We start with a comprehensive tutorial of GAN. Then, we review the solution for these two problems from the perspective of architecture and loss. Furthermore, some conclusions about these two main challenges are given. Finally, we look into the GAN's future by summarizing the various GAN applications.},
  keywords={Representation learning;Deep learning;Conferences;Bibliographies;Tutorials;Reinforcement learning;Artificial intelligence;Generative Adversarial Nets (GAN);Architecture},
  doi={10.1109/ICETCI55101.2022.9832406},
  ISSN={},
  month={May},}@ARTICLE{9492072,
  author={Tsai, Tsung-Yu and Lin, Yen-Yu and Jeng, Shyh-Kang and Liao, Hong-Yuan Mark},
  journal={IEEE Access}, 
  title={End-to-End Key-Player-Based Group Activity Recognition Network Applied to Basketball Offensive Tactic Identification in Limited Data Scenarios}, 
  year={2021},
  volume={9},
  number={},
  pages={104395-104404},
  abstract={In this paper, we propose an end-to-end key-player-based group activity recognition network specially applied to the identification of basketball offensive tactics in limited data scenarios. Our previous studies show that basketball tactics can be better recognized via key player detection with multiple instance learning (MIL) using the support vector machine (SVM). However, the SVM in that work is required to extract features depending on basketball- and tactic-specific knowledge for good performance. Thus, in this study, we develop an end-to-end trainable neural network without prior knowledge and integrate MIL into it. As long as a tactic label is given, MIL can train the network to identify tactic's key players. For testing, our network can recognize the key players in a video clip and provide a tag of the tactic related to them. Like other neural network models, our network requires a large annotated dataset. At the same time, we could collect only a few labeled data, which is common in dealing with group activity recognition. To overcome such a limitation, we propose a novel data augmentation framework, the tactical-based conditional generative adversarial network (GAN), for generating new labeled trajectories. The experimental results show that our method significantly improves 9.13 % in tactic recognition and 4.965 % in key player detection.},
  keywords={Trajectory;Generative adversarial networks;Activity recognition;Feature extraction;Sports;Neural networks;Deep learning;Data augmentation;end-to-end deep neural networks;generative adversarial networks;group activity recognition;key player detection;multiple instance learning;sports video analysis},
  doi={10.1109/ACCESS.2021.3098840},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9760684,
  author={Farhan, Faisal and Nafi, Thahmidul Islam},
  booktitle={2022 2nd International Conference on Artificial Intelligence and Signal Processing (AISP)}, 
  title={ANN based approach to predict criminal trends in Bangladesh}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={Crime trend analysis has become a mandatory task as the scale of crime is increasing rapidly all over the globe. In recent years, Bangladesh has encountered various types of crimes and the rate is increasing with its increased population. Both physical and digital based crimes have become very common and their fatality can disrupt the advancement of any country. To tackle the situation, it is important to investigate and forecast the crime patterns that can assist the law enforcement agencies for easier investigation. Machine Learning and Deep Learning based crime analysis has become very popular as they can accurately and efficiently analyze large criminal dataset. In this study, the authors implemented machine learning techniques as well as ANN architecture to assess and forecast crime trends in Bangladesh. The dataset in this experiment was collected from the Bangladesh Police website that consists of criminal records of various crimes during the years 2010 to 2019. Authors evaluated the performance of ANN with other regression models named linear Regression and Support Vector Regression for crime prediction. The proposed model(ANN) outperforms other two models in this study compared to all the performance evaluation metrics. Hence ANN model is suggested by the authors to forecast and analyze future crime trends.},
  keywords={Training;Support vector machines;Analytical models;Law enforcement;Linear regression;Artificial neural networks;Predictive models;ANN;Crime Prediction;Logistic Regression;Support Vector Regression},
  doi={10.1109/AISP53593.2022.9760684},
  ISSN={2640-5768},
  month={Feb},}@ARTICLE{11129693,
  author={Sifat, Md. Sulyman Islam and Kabir, Md Alamgir and Islam, M. M. Manjurul and Rehman, Atiq Ur and Bermak, Amine},
  journal={IEEE Access}, 
  title={GAN-Based Data Augmentation for Fault Diagnosis and Prognosis of Rolling Bearings: A Literature Review}, 
  year={2025},
  volume={13},
  number={},
  pages={148083-148103},
  abstract={In 2014, Goodfellow et al. introduced Generative Adversarial Networks (GANs), an adversarial learning framework designed to generate synthetic data. In rolling bearing fault diagnosis and prognosis, specific GAN variants such as Conditional GANs (cGANs), Wasserstein GANs (WGANs), and their derivatives have been developed to address data scarcity and class imbalance challenges. In this work, we conduct a literature review to systematically examine GAN-based data augmentation techniques for fault diagnosis and prognosis of rolling bearings. Through a rigorous selection process, we identified 229 primary studies that employed GAN-based data augmentation, underscoring the widespread use of GANs to generate synthetic data in this field. Our review shows that GANs were first applied to rolling bearing fault diagnosis in 2018, and their use has grown significantly since then. Among GAN variants, Wasserstein GANs (WGANs) and Conditional GANs (cGANs) have proven highly effective in generating realistic synthetic data, particularly when integrated with Convolutional Neural Networks (CNNs). The review further reveals that CNN models have been widely used, achieving accuracy rates exceeding 95% in fault diagnosis and prognosis. We also report that 90% of studies employ accuracy as the primary evaluation metric, while 15% use F1-score, as detailed in our metric analysis for bearing fault diagnosis. For fault prognosis, RMSE and MAE are the most commonly used metrics, appearing in 11% and 9% of studies, respectively. Our analysis reveals standardized hyperparameter configurations with learning rate 0.0001, Adam optimizer, and batch size 32 being most effective. The review identifies critical challenges including data imbalance (19.7%), training instability (11.0%), and data scarcity (10.7%) as primary bottlenecks for industrial adoption. This review establishes a comprehensive foundation for understanding the current state and future directions of GAN-based approaches for rolling bearing fault diagnosis and prognosis, offering researchers and practitioners a valuable resource in industrial predictive maintenance.},
  keywords={Fault diagnosis;Prognostics and health management;Rolling bearings;Training;Generative adversarial networks;Systematic literature review;Generators;Data augmentation;Convolutional neural networks;Best practices;Data augmentation;predictive maintenance;rolling bearings;fault diagnosis and prognosis;generative adversarial networks},
  doi={10.1109/ACCESS.2025.3600235},
  ISSN={2169-3536},
  month={},}@ARTICLE{10190309,
  author={Tang, Guangyi and Ni, Jianjun and Chen, Yan and Cao, Weidong and Yang, Simon X.},
  journal={IEEE Sensors Journal}, 
  title={An Improved CycleGAN-Based Model for Low-Light Image Enhancement}, 
  year={2024},
  volume={24},
  number={14},
  pages={21879-21892},
  abstract={The low-light image enhancement is a challenging and hot research issue in the image processing field. In order to enhance the quality of low-light images to obtain full structure and details, many low-light image enhancement algorithms have been proposed and deep learning-based methods have achieved great success in this field. However, most of the deep learning methods require paired training data, which is difficult to obtain. And the overall visual quality of the enhanced image is still not very satisfying. To deal with these problems, an unsupervised low-light image enhancement model based on an improved cycle-consistent generative adversarial network (CycleGAN) is proposed in this article. In the proposed model, a low-light enhancement generator of the CycleGAN network is constructed based on an improved U-Net structure, and the adaptive instance normalization (AdaIN) is designed to learn the style of the normal light image. In particular, a detail enhancement method based on multilayer guided filtering is added to the proposed model, which can improve the quality and visual pleasantness of image enhancement. In addition, a joint training strategy based on structural similarity is presented, to strengthen the constraints on generating more realistic and natural images. At last, extensive experiments are conducted and the results show that the proposed method can accomplish the task of transferring low-light images to normal light and outperform the state-of-the-art approaches in various metrics of visual quality.},
  keywords={Image enhancement;Lighting;Generators;Training;Image color analysis;Brightness;Visualization;Cycle-consistent generative adversarial network (CycleGAN);image enhancement;low-light problem;unsupervised learning},
  doi={10.1109/JSEN.2023.3296167},
  ISSN={1558-1748},
  month={July},}@ARTICLE{8834837,
  author={Shi, Xin and Qiu, Robert and Mi, Tiebin and He, Xing and Zhu, Yongli},
  journal={IEEE Transactions on Power Systems}, 
  title={Adversarial Feature Learning of Online Monitoring Data for Operational Risk Assessment in Distribution Networks}, 
  year={2020},
  volume={35},
  number={2},
  pages={975-985},
  abstract={With the deployment of online monitoring systems in distribution networks, massive amounts of data collected through them contain rich information on the operating states of the networks. By leveraging the data, an unsupervised approach based on bidirectional generative adversarial networks (BiGANs) is proposed for operational risk assessment in distribution networks in this paper. The approach includes two stages: (1) adversarial feature learning. The most representative features are extracted from the online monitoring data and a statistical index Nφ is calculated for the features, during which we make no assumptions or simplifications on the real data; (2) operational risk assessment. The confidence level 1 - α for the population mean of the standardized Nφ is combined with the operational risk levels which are divided into emergency, high risk, preventive, and normal, and the p value for each data point is calculated and compared with the pre-defined interval of α/2 to determine the risk levels. The proposed approach is capable of discovering the latent structure of the real data and providing more accurate assessment result. The synthetic data is employed to illustrate the selection of parameters involved in the proposed approach. Case studies on the real-world online monitoring data validate the effectiveness and advantages of the proposed approach in risk assessment.},
  keywords={Feature extraction;Monitoring;Mathematical model;Risk management;Anomaly detection;Phasor measurement units;Indexes;Operational risk assessment;distribution networks;online monitoring data;bidirectional generative adversarial networks (BiGANs);unsupervised approach},
  doi={10.1109/TPWRS.2019.2941162},
  ISSN={1558-0679},
  month={March},}@INPROCEEDINGS{10283495,
  author={Tang, Rui and Gao, Dahua and Yang, Minxi and Guo, Tao and Wu, Huihui and Shi, Guangming},
  booktitle={2023 IEEE International Conference on Communications Workshops (ICC Workshops)}, 
  title={GAN-inspired Intelligent Jamming and Anti-jamming Strategy for Semantic Communication Systems}, 
  year={2023},
  volume={},
  number={},
  pages={1623-1628},
  abstract={The emerging semantic communication is currently receiving extensive attention. It focuses on semantic information transmission rather than the conventional symbol or bit transmission regardless of content. The semantic-level transmission in semantic communication brings new challenges for jamming and anti-jamming. How to attack and defend during semantic information transmission is the essence of jamming and anti-jamming in this communication paradigm. In this paper, we proposed a new intelligent jamming and anti-jamming framework to analyze and promote the security of semantic communication. In the proposed framework, the semantic jammer attempts to make the decoding result and the sent content semantically different. In contrast, the receiver tries to decode the semantic information correctly under the semantic jamming attack. To optimize the semantic jammer and receiver, we build a game model between them in the intelligent jamming and anti-jamming framework. And a game strategy like the generative adversarial network (GAN) is creatively introduced in the proposed framework. Thus, a more robust semantic communication system is built. We apply the proposed framework and strategy to text semantic communication. Multiple experiments were performed to verify the effectiveness of the proposed approaches.},
  keywords={Communication systems;Conferences;Semantics;Symbols;Receivers;Information processing;Games;semantic communication;jamming;anti-jamming;generative adversarial network;text transmission},
  doi={10.1109/ICCWorkshops57953.2023.10283495},
  ISSN={2694-2941},
  month={May},}@INPROCEEDINGS{9519323,
  author={Adedoja, Adedamola O. and Owolawi, Pius A. and Mapayi, Temitope and Tu, Chunling},
  booktitle={2021 International Conference on Artificial Intelligence, Big Data, Computing and Data Communication Systems (icABCD)}, 
  title={Progress on Deep Learning Models for Plant Disease Detection: A Survey}, 
  year={2021},
  volume={},
  number={},
  pages={1-9},
  abstract={Deep Learning (DL) and Artificial Intelligence (AI) are well matured sufficiently and in use in multiple domains of applied sciences and engineering to great success. Research interest in DL has increased over the years and this is because of the great success brought about by it. Another reason for the increase in interest has been the enormous amount of data available and the computing power at our disposal to harness these datasets. As a direct result of the current research interest, different DL models and tools are being created every day to maximise the efficiency of use across multiple domains. This paper does a systematic review of the use of DL models for detecting plant diseases. Images of diseased plant leaves are processed using these DL models to achieve timely and accurate diagnosis in a way that can scale without human effort. The survey shows that various DL networks have been used to detect plant diseases. DL has also been used to check the severity of diseases in different plant species. Plant detection could be an error-prone, time-consuming process and destructive potentially if done in error or too late. This paper shows the current state of DL in plant disease diagnosis and its limitations and challenges that can encourage researchers to investigate further improvements.},
  keywords={Deep learning;Training;Systematics;Machine learning algorithms;Computational modeling;Tools;Feature extraction;Deep Learning;Detection;Diagnosis;Plant Disease},
  doi={10.1109/icABCD51485.2021.9519323},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{11152114,
  author={Mou, Luntian and Zhang, Yuliang and Sun, Yihan and Gao, Feng and Xiang, Yong},
  booktitle={2025 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)}, 
  title={Multitrack Music Generation Combining Transformer and Diffusion Model}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Recent advancements in generative models have made remarkable progress in music generation. However, since most existing methods focus on generating single-track music, generating multitrack music with rich attributes remains a challenging task. In this paper, we propose a novel music generation method based on the combination of the Transformer and the diffusion model. Specifically, the Transformer module is adopted to conduct structural representation learning for multitrack music, and the diffusion model is utilized to gradually denoise and generate structured music. To further enhance inter-track coherence, a track alignment loss is introduced during the generation process to enforce multitrack consistency in rhythm and dynamics, effectively resolving track coordination issues inherent in traditional diffusion models. We conduct objective experiments on evaluation metrics, namely pitch class entropy, scale consistency, and groove consistency. Compared with previous multitrack music generation methods, the proposed method performs better on these metrics.},
  keywords={Measurement;Representation learning;Conferences;Coherence;Diffusion models;Transformers;Rhythm;Entropy;Data models;Multitrack Music Generation;Diffusion Model;Generative Models},
  doi={10.1109/ICMEW68306.2025.11152114},
  ISSN={2995-1429},
  month={June},}@ARTICLE{9802835,
  author={Jia, Xuemei and Zhong, Xian and Ye, Mang and Liu, Wenxuan and Huang, Wenxin},
  journal={IEEE Transactions on Image Processing}, 
  title={Complementary Data Augmentation for Cloth-Changing Person Re-Identification}, 
  year={2022},
  volume={31},
  number={},
  pages={4227-4239},
  abstract={This paper studies the challenging person re-identification (Re-ID) task under the cloth-changing scenario, where the same identity (ID) suffers from uncertain cloth changes. To learn cloth- and ID-invariant features, it is crucial to collect abundant training data with varying clothes, which is difficult in practice. To alleviate the reliance on rich data collection, we reinforce the feature learning process by designing powerful complementary data augmentation strategies, including positive and negative data augmentation. Specifically, the positive augmentation fulfills the ID space by randomly patching the person images with different clothes, simulating rich appearance to enhance the robustness against clothes variations. For negative augmentation, its basic idea is to randomly generate out-of-distribution synthetic samples by combining various appearance and posture factors from real samples. The designed strategies seamlessly reinforce the feature learning without additional information introduction. Extensive experiments conducted on both cloth-changing and -unchanging tasks demonstrate the superiority of our proposed method, consistently improving the accuracy over various baselines.},
  keywords={Training;Task analysis;Semantics;Shape;Representation learning;Generative adversarial networks;Computer science;Person re-identification;cloth-changing;data augmentation},
  doi={10.1109/TIP.2022.3183469},
  ISSN={1941-0042},
  month={},}@ARTICLE{10114420,
  author={Chen, Keyan and Li, Wenyuan and Lei, Sen and Chen, Jianqi and Jiang, Xiaolong and Zou, Zhengxia and Shi, Zhenwei},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Continuous Remote Sensing Image Super-Resolution Based on Context Interaction in Implicit Function Space}, 
  year={2023},
  volume={61},
  number={},
  pages={1-16},
  abstract={Despite its fruitful applications in remote sensing, image super-resolution (SR) is troublesome to train and deploy as it handles different resolution magnifications with separate models. Accordingly, we propose a highly applicable SR framework called FunSR, which settles different magnifications with a unified model by exploiting context interaction within implicit function space. FunSR composes a functional representor, a functional interactor, and a functional parser. Specifically, the representor transforms the low-resolution image from Euclidean space to multiscale pixelwise function maps; the interactor enables pixelwise function expression with global dependencies; and the parser, which is parameterized by the interactor’s output, converts the discrete coordinates with additional attributes to RGB values. Extensive experimental results demonstrate that FunSR reports the state-of-the-art performance on both fixed- and continuous-magnification settings; meanwhile, it provides many friendly applications due to its unified nature. Our code is available at https://github.com/KyanChen/FunSR.},
  keywords={Remote sensing;Superresolution;Spatial resolution;Semantics;Image edge detection;Generative adversarial networks;Deep learning;Continuous image representation;function space;implicit neural network;remote sensing images;super-resolution (SR)},
  doi={10.1109/TGRS.2023.3272473},
  ISSN={1558-0644},
  month={},}@ARTICLE{9242273,
  author={Wang, Yuxi and Zhang, Zhaoxiang and Hao, Wangli and Song, Chunfeng},
  journal={IEEE Transactions on Image Processing}, 
  title={Attention Guided Multiple Source and Target Domain Adaptation}, 
  year={2021},
  volume={30},
  number={},
  pages={892-906},
  abstract={Domain adaptation aims to alleviate the distribution discrepancy between source and target domains. Most conventional methods focus on one target domain setting adapted from one or multiple source domains while neglecting the multi-target domain setting. We argue that different target domains also have complementary information, which is very important for performance improvement. In this paper, we propose an Attention-guided Multiple source-and-target Domain Adaptation (AMDA) method to capture the context dependency information on transferable regions among multiple source and target domains. The innovation points of this paper are as follows: (1) We use numerous adversarial strategies to harvest sufficient information from multiple source and target domains, which extends the generalization and robustness of the feature pools. (2) We propose an intra-domain and inter-domain attention module to explore transferable context information. The proposed attention module can learn domain-invariant representations and reduce the negative transfer by focusing on transferable knowledge. Extensive experiments validate the effectiveness of our method with achieving state-of-the-art performance on several unsupervised domain adaptation datasets.},
  keywords={Semantics;Task analysis;Generators;Generative adversarial networks;Feature extraction;Visualization;Meteorology;Domain adaptation;multiple source and target domains;attention},
  doi={10.1109/TIP.2020.3031161},
  ISSN={1941-0042},
  month={},}@ARTICLE{10287342,
  author={Kholgh, Danial Khosh and Kostakos, Panos},
  journal={IEEE Access}, 
  title={PAC-GPT: A Novel Approach to Generating Synthetic Network Traffic With GPT-3}, 
  year={2023},
  volume={11},
  number={},
  pages={114936-114951},
  abstract={The application of machine learning models, particularly in cybersecurity, has surged significantly in the past few years. However, the effectiveness of these models is predominantly tethered to the quality and breadth of the training data they ingest. The scarcity of realistic datasets within the cybersecurity field constitutes a considerable challenge to the development of industry-grade tools intended for real-world application scenarios. Specifically, current datasets are either significantly outdated or fall short on both qualitative and quantitative fronts, primarily because many organizations exhibit reluctance in data sharing, stemming from privacy concerns or the potential threat to trade secrets. To address this challenge, the paper introduces PAC-GPT, a novel framework to generate reliable synthetic data for machine learning methods based on Open AI’s Generative Pre-trained Transformer 3 (GPT-3). The core components of this framework are two modules, namely a Flow Generator, which is responsible for capturing and regenerating patterns in a series of network packets, and Packet Generator, which can generate individual network packets given the network flow. We also propose a packet generator based on LLM chaining and then proceed to assess, compare, and evaluate its performance using metrics such as loss, accuracy and success rate, concluding that transformers are a suitable approach for synthetic packet generation with minimal fine-tuning performed. Lastly, a streamlined command line interface (CLI) tool has been devised to facilitate the seamless access of this innovative data generation strategy by professionals from various disciplines.},
  keywords={Generators;Telecommunication traffic;Computer security;Transformers;Task analysis;Protocols;Machine learning;Artificial intelligence;Artificial intelligence;cybersecurity;generative pre-trained transformer;GPT-3;machine learning;NLP;transformer;LLMs},
  doi={10.1109/ACCESS.2023.3325727},
  ISSN={2169-3536},
  month={},}@ARTICLE{8720241,
  author={Li, Guohe and Qiao, Yinghan and Zheng, Yifeng and Li, Ying and Wu, Weijiang},
  journal={IEEE Access}, 
  title={Semi-Supervised Learning Based on Generative Adversarial Network and Its Applied to Lithology Recognition}, 
  year={2019},
  volume={7},
  number={},
  pages={67428-67437},
  abstract={Lithology recognition is an essential part of reservoir parameter prediction. Compared to conventional algorithms, deep learning that needs a large amount of training data as support can extract features automatically. In the process of real data acquisition, the labeled data account for only a small portion due to high drilling cost, and it is difficult to achieve the data size required for deep learning training, resulting in a significant variance of the recognition model. In this paper, for this shortage, a semi-supervised algorithm based on generative adversarial network (GAN) with Gini-regularization is proposed, called SGAN_G, which takes borehole-side data as labeled data and seismic data as unlabeled data. First, the SGAN_G is trained by Adam (a method for stochastic optimization) algorithm and utilizes a discriminator to lithology recognition. And, we add the entropy regularization to the initial loss function which enhances the convergence speed and accuracy of the model. Eventually, we propose a novel sampling approach which employs multiple sampling points of seismic data as inputs to use the stratum information implicitly. Through the experimental comparison with a variety of supervised approaches, we can see that the SGAN_G can achieve higher prediction accuracy by using unlabeled data effectively.},
  keywords={Entropy;Data models;Training;Generative adversarial networks;Semisupervised learning;Generators;Petroleum;Entropy regularization;generative adversarial network;lithology recognition;semi-supervised learning},
  doi={10.1109/ACCESS.2019.2918366},
  ISSN={2169-3536},
  month={},}@ARTICLE{10287255,
  author={Xu, Yonghao and Yu, Weikang and Ghamisi, Pedram and Kopp, Michael and Hochreiter, Sepp},
  journal={IEEE Transactions on Image Processing}, 
  title={Txt2Img-MHN: Remote Sensing Image Generation From Text Using Modern Hopfield Networks}, 
  year={2023},
  volume={32},
  number={},
  pages={5737-5750},
  abstract={The synthesis of high-resolution remote sensing images based on text descriptions has great potential in many practical application scenarios. Although deep neural networks have achieved great success in many important remote sensing tasks, generating realistic remote sensing images from text descriptions is still very difficult. To address this challenge, we propose a novel text-to-image modern Hopfield network (Txt2Img-MHN). The main idea of Txt2Img-MHN is to conduct hierarchical prototype learning on both text and image embeddings with modern Hopfield layers. Instead of directly learning concrete but highly diverse text-image joint feature representations for different semantics, Txt2Img-MHN aims to learn the most representative prototypes from text-image embeddings, achieving a coarse-to-fine learning strategy. These learned prototypes can then be utilized to represent more complex semantics in the text-to-image generation task. To better evaluate the realism and semantic consistency of the generated images, we further conduct zero-shot classification on real remote sensing data using the classification model trained on synthesized images. Despite its simplicity, we find that the overall accuracy in the zero-shot classification may serve as a good metric to evaluate the ability to generate an image from text. Extensive experiments on the benchmark remote sensing text-image dataset demonstrate that the proposed Txt2Img-MHN can generate more realistic remote sensing images than existing methods. Code and pre-trained models are available online (https://github.com/YonghaoXu/Txt2Img-MHN).},
  keywords={Remote sensing;Task analysis;Semantics;Prototypes;Sensors;Generators;Generative adversarial networks;Deep learning;image synthesis;modern Hopfield networks;remote sensing;text-to-image generation;zero-shot classification},
  doi={10.1109/TIP.2023.3323799},
  ISSN={1941-0042},
  month={},}@ARTICLE{9121326,
  author={Yang, Meijuan and Jiao, Licheng and Hou, Biao and Liu, Fang and Yang, Shuyuan},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Selective Adversarial Adaptation-Based Cross-Scene Change Detection Framework in Remote Sensing Images}, 
  year={2021},
  volume={59},
  number={3},
  pages={2188-2203},
  abstract={Supervised change detection methods always face a big challenge that the current scene (target domain) is fully unlabeled. In remote sensing, it is common that we have sufficient labels in another scene (source domain) with a different but related data distribution. In this article, we try to detect changes in the target domain with the help of the prior knowledge learned from multiple source domains. To achieve this goal, we propose a change detection framework based on selective adversarial adaptation. The adaptation between multisource and target domains is fulfilled by two domain discriminators. First, the first domain discriminator regards each scene as an individual domain and is designed for identifying the domain to which each input sample belongs. According to the output of the first domain discriminator, a subset of important samples is selected from multisource domains to train a deep neural network (DNN)-based change detection model. As a result, not only the positive transfer is enhanced but also the negative transfer is alleviated. Second, as for the second domain discriminator, all the selected samples are thought from one domain. Adversarial learning is introduced to align the distributions of the selected source samples and the target ones. Consequently, it further adapts the knowledge of change from the source domain to the target one. At the fine-tuning stage, target samples with reliable labels and the selected source ones are used to jointly fine-tune the change detection model. As the target domain is fully unlabeled, homogeneity- and boundary-based strategies are exploited to make the pseudolabels from a preclassification map reliable. The proposed method is evaluated on three SAR and two optical data sets, and the experimental results have demonstrated its effectiveness and superiority.},
  keywords={Feature extraction;Remote sensing;Radar polarimetry;Adaptation models;Synthetic aperture radar;Generative adversarial networks;Reliability;Adaptation;adversarial learning;change detection;deep neural networks (DNNs);domain discriminator;remote sensing images},
  doi={10.1109/TGRS.2020.3001584},
  ISSN={1558-0644},
  month={March},}@ARTICLE{9709514,
  author={Gu, Zhangxuan and Zhou, Siyuan and Niu, Li and Zhao, Zihan and Zhang, Liqing},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={From Pixel to Patch: Synthesize Context-Aware Features for Zero-Shot Semantic Segmentation}, 
  year={2023},
  volume={34},
  number={10},
  pages={7689-7703},
  abstract={Zero-shot learning (ZSL) has been actively studied for image classification tasks to relieve the burden of annotating image labels. Interestingly, the semantic segmentation task requires more labor-intensive pixel-wise annotation, but zero-shot semantic segmentation has not attracted extensive research interest. Thus, we focus on zero-shot semantic segmentation that aims to segment unseen objects with only category-level semantic representations provided for unseen categories. In this article, we propose a novel context-aware feature generation network (CaGNet) that can synthesize context-aware pixel-wise visual features for unseen categories based on category-level semantic representations and pixel-wise contextual information. The synthesized features are used to fine-tune the classifier to enable segmenting of unseen objects. Furthermore, we extend pixel-wise feature generation and fine-tuning to patch-wise feature generation and fine-tuning, which additionally considers the interpixel relationship. Experimental results on Pascal-VOC, Pascal-context, and COCO-stuff show that our method significantly outperforms the existing zero-shot semantic segmentation methods.},
  keywords={Semantics;Image segmentation;Visualization;Task analysis;Generators;Generative adversarial networks;Training;Contextual information;feature generation;semantic segmentation;zero-shot learning (ZSL)},
  doi={10.1109/TNNLS.2022.3145962},
  ISSN={2162-2388},
  month={Oct},}@ARTICLE{10713288,
  author={Liu, Jinyang and Li, Shutao and Tan, Lishan and Dian, Renwei},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Denoiser Learning for Infrared and Visible Image Fusion}, 
  year={2025},
  volume={36},
  number={7},
  pages={13470-13482},
  abstract={Infrared image (IR) and visible image (VI) fusion creates fusion images that contain richer information and gain improved visual effects. Existing methods generally use the operators of manual design, such as intensity and gradient operators, to mine the image information. However, it is hard for them to achieve a complete and accurate description of information, which limits the image fusion performance. To this end, a novel information measurement method is proposed to achieve IR and VI fusion. Its core idea is to guide a generator in achieving image fusion by learning the denoisers. Specifically, by using denoisers to restore fusion images with different noise interference to source images, a mutual competition relationship is formed between denoisers, which helps the generator thoroughly explore the data specificity of the source images and guide it to achieve more accurate feature representation. In addition, a semantic adaptive measurement loss function is proposed to constrain the generator, which fuses semantic information adaptively by considering the semantic information density of different source images. The results of quantitative and qualitative experiments have shown that the proposed method can achieve a higher quality information fusion and has a faster fusion speed on three public datasets when compared with advanced methods.},
  keywords={Image fusion;Generators;Semantics;Loss measurement;Feature extraction;Noise reduction;Generative adversarial networks;Training;Learning systems;Data mining;Deep learning;denoiser;infrared image (IR) and visible image (VI) fusion},
  doi={10.1109/TNNLS.2024.3454811},
  ISSN={2162-2388},
  month={July},}@ARTICLE{10817593,
  author={Li, Wenjie and Shang, Shizhe and Shang, Ronghua and Feng, Dongzhu and Zhang, Weitong and Wang, Chao and Feng, Jie and Xu, Songhua},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Few-Shot Learning Based on Embedded Self-Distillation and Adaptive Wasserstein Distance for Hyperspectral Image Classification}, 
  year={2025},
  volume={63},
  number={},
  pages={1-15},
  abstract={Due to the domain shift, it is challenging to achieve ideal experimental results for cross-domain few-shot learning (FSL) in hyperspectral image (HSI) classification. Most existing FSL algorithms are impacted by the limited samples, and they do not effectively leverage the representations from different layers of the network. Therefore, this article proposes an FSL based on embedded self-distillation and adaptive Wasserstein (ESAW-FSL) distance for HSI classification. First, the embedding self-distillation network is proposed in the feature extraction process of the source domain (SD) and the target domain (TD). The embedding self-distillation network utilizes self-distillation from different perspectives to get discriminative features. In the SD, the mask evaluation of embedded features is employed to guarantee the learning of guiding features. Second, a domain adaptation based on adaptive Wasserstein distance is designed to alleviate the domain shift problem between the domains. A lightweight feature correlation network learns the comprehensive cost matrix in the Wasserstein distance adaptively, and the obtained cost matrix helps achieve domain adaptation by an iterative algorithm. Finally, a focal loss based on double softening is adopted in the process of FSL. The probability is double softened to improve the ratio of correctly classifying hard samples. Experiments are conducted on three widely used hyperspectral datasets and compared with six state-of-the-art algorithms. The overall accuracy (OA) and average accuracy (AA) are achieved in multiple experiments, demonstrating the effectiveness of ESAW-FSL.},
  keywords={Feature extraction;Hyperspectral imaging;Softening;Costs;Image classification;Few shot learning;Correlation;Accuracy;Generative adversarial networks;Knowledge transfer;Cross-domain;deep learning;few-shot learning (FSL);hyperspectral image (HSI) classification;self-distillation},
  doi={10.1109/TGRS.2024.3523712},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{10285809,
  author={Ranja, Feri and Nababan, Erna Budiarti and Candra, Ade},
  booktitle={2023 International Conference on Computer, Control, Informatics and its Applications (IC3INA)}, 
  title={Synthetic Data Generation Using Time-Generative Adversarial Network (Time-GAN) to Predict Cash ATM}, 
  year={2023},
  volume={},
  number={},
  pages={418-423},
  abstract={One of the particular concerns of the Bank for ATM transaction services is the availability of cash at ATMs. Prediction of the availability of ATM money is required by the Bank to manage funds optimally. This study aims to analyze and predict cash availability at ATM machines using Time-GAN and Extreme Gradient Boosting (XGBoost). Time-Series data is highly dependent on the size and consistency of the dataset used in the training. The features available in the dataset are limited and have constraints such as missing dimensions or missing values. Therefore, synthetic data generation technique is used as an effective way to increase the amount of data and handle imbalanced data. Synthetic data generation has been shown to increase the generalizability of models with Time-Series data. The generated data will be divided into Training data, Validation data, and Testing data, resulting in a Load Model that will be analyzed using the XGBoost method. The ultimate goal of this research is to provide a summary of the evaluation and performance that results in better ATM availability for future research. Model performance is evaluated with the Mean Absolute Error (MAE) metric 2.57 value, Mean Squared Error (MSE) 1.64 value, and R-squared 5.02 value.},
  keywords={Training;Measurement;Analytical models;Training data;Predictive models;Prediction algorithms;Data models;Synthetic data generation;Time-GAN;XGBoost},
  doi={10.1109/IC3INA60834.2023.10285809},
  ISSN={},
  month={Oct},}@ARTICLE{11046349,
  author={Chen, Zhuangzhuang and Hu, Tao and Xu, Chengqi and Chen, Jie and Song, Houbing Herbert and Wang, Li and Li, Jianqiang},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Self-Adaptive Fourier Augmentation Framework for Crack Segmentation in Industrial Scenarios}, 
  year={2025},
  volume={21},
  number={10},
  pages={7487-7498},
  abstract={Crack segmentation receives extensive attention in structure health monitoring for many industrial scenarios, e.g., bridges, highways, and nuclear power plants. The current deep learning-based crack segmentation models enjoy the ability to extract discriminative crack features by training with an extensive labeled crack dataset. However, collecting extensive crack samples with accurate annotations from experts for a new scenario is labor-intensive, thereby limiting the effectiveness of these deep models in practical applications. To address this problem, the existing Fourier-based augmentation adopts a vanilla amplitude fusion process, i.e., the portion of amplitude components is fixed or randomly selected, failing to guarantee augmented samples’ semantics consistency, and diversity concerning the original sample. To fill this, this article proposes a self-adaptive Fourier augmentation framework that efficiently synthesizes diverse crack samples for training crack segmentation models. Our proposed framework advances Fourier transformation in an adversarial learning manner, alternating between self-adaptive Fourier-based data augmentation and teacher–student learning. The former aims to guarantee the diversity and semantics consistency of Fourier-based augmented samples, while the latter progressively updates the student network by observing these augmented samples for extracting discriminative features via a knowledge distillation mechanism. It is worth noting that the proposed method is only applied in the training stage without extra computation and memory during inference. Extensive experiments demonstrate the superiority of our method over the existing methods.},
  keywords={Training;Feature extraction;Interpolation;Semantics;Generative adversarial networks;Adversarial machine learning;Data augmentation;Image segmentation;Transformers;Generators;Adversarial learning;crack segmentation;Fourier-based augmentation;industrial scenarios},
  doi={10.1109/TII.2025.3576871},
  ISSN={1941-0050},
  month={Oct},}@INPROCEEDINGS{11139839,
  author={Almohsen, Khadija and Albalooshi, Fawzi and Ammari, Jafla Al},
  booktitle={2025 IEEE 4th International Conference on Computing and Machine Intelligence (ICMI)}, 
  title={Exploring the Use of GenAI in Automating Software Testing}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Software testing is an important step in software development as it ensures the reliability, functionality, and performance of developed software. However, manual testing approaches are often labor-intensive, time-consuming, and prone to human error. Automating this phase offers significant benefits, making it a key area of interest for researchers. This study aims to explore the adoption of generative AI (GenAI) technologies in automating software testing and provides a thorough review of recent advancements. This research work includes a comparative analysis of existing studies, revealing a predominant focus on Large Language Model (LLM)-driven solutions for generating the test cases, with notable applications in unit testing and integration testing. Evaluation metrics such as test coverage, efficiency, and relevance are frequently used to assess the effectiveness of these approaches. Furthermore, the review identifies critical limitations in current GenAI-based solutions and suggests potential directions for future work. This work offers a timely contribution to the software engineering community, laying the groundwork for more advanced research work in the domain.},
  keywords={Software testing;Measurement;Reviews;Large language models;Manuals;Software;Software reliability;Machine intelligence;Software engineering;Software development management;Automation;GenAI;LLMs;Software Testing;RAG},
  doi={10.1109/ICMI65310.2025.11139839},
  ISSN={},
  month={April},}@ARTICLE{10785562,
  author={Ren, Lei and Li, Jinwang and Wang, Haiteng},
  journal={IEEE Internet of Things Journal}, 
  title={An AIGC-Driven Score-Based Diffusion Approach for Industrial Time Series}, 
  year={2025},
  volume={12},
  number={10},
  pages={13132-13143},
  abstract={In the context of Industrial Internet of Things (IIoT), time-series data is essential for maintenance and operational efficiency. However, challenges in IIoT data transmission, such as network instability, and in data annotation, like the high costs, lead to a shortage of high-quality labeled data, hindering system performance and industrial intelligence. Although traditional methods, such as signal imputation and denoising, have been employed, generative artificial intelligence (GAI) offers new possibilities for the generation of industrial time-series data. To address these challenges, we propose a novel score-based diffusion architecture specifically designed for industrial data generation. The score-based approach effectively leverages the gradients of the data distribution, offering a more structured and stable generative process compared to generative adversarial networks (GANs). Furthermore, our model incorporates predictive-corrective (PC) samplers with Langevin dynamics annealing to further optimize the generation process. Experimental results on turbofan engine datasets demonstrate that our model overcomes the inherent training instabilities of GANs, providing a more reliable and effective method for synthesizing high-fidelity industrial time-series data.},
  keywords={Industrial Internet of Things;Data models;Training;Noise;Diffusion models;Time series analysis;Data collection;Noise reduction;Computational modeling;Mathematical models;Generative artificial intelligence (GAI);industrial data generation;industrial foundation model;Industrial Internet of Things (IIoT);score-based models},
  doi={10.1109/JIOT.2024.3509029},
  ISSN={2327-4662},
  month={May},}@ARTICLE{10741276,
  author={Cabrera-Sánchez, Juan-Francisco and Cardoso Pereira, Ricardo and Henriques Abreu, Pedro and Silva-Ramírez, Esther-Lydia},
  journal={IEEE Access}, 
  title={A Perspective on the Missing at Random Problem: Synthetic Generation and Benchmark Analysis}, 
  year={2024},
  volume={12},
  number={},
  pages={162399-162411},
  abstract={Progressively more advanced and complex models are proposed to address problems related to computer vision, forecasting, Internet of Things, Big Data and so on. However, these disciplines require preprocessing steps to obtain meaningful results. One of the most common problems addressed in this stage is the presence of missing values. Understanding the reason why missingness occurs helps to select data imputation methods that are more adequate to complete these missing values. Missing at Random synthetic generation presents challenges such as achieving extreme missingness rates and preserving the consistency of the mechanism. To address these shortcomings, three new methods that generate synthetic missingness under the Missing at Random mechanism are proposed in this work and compared to a baseline model. This comparison considers a benchmark covering 33 data sets and five missingness rates  $(10\%, 20\%, 40\%, 60\%, 80\%)$ . Seven data imputation methods are compared to evaluate the proposals, ranging from traditional methods to deep learning methods. The results demonstrate that the proposals are aligned with the baseline method in terms of the performance and ranking of data imputation methods. Thus, three new feasible and consistent alternatives for synthetic missingness generation under Missing at Random are presented.},
  keywords={Imputation;Benchmark testing;Neural networks;Proposals;Perturbation methods;Generative adversarial networks;Noise reduction;Mathematical models;Generators;Deep learning;Artificial intelligence;Machine learning;Data preprocessing;missing data;missing at random;synthetic missingness;deep learning;machine learning;artificial intelligence},
  doi={10.1109/ACCESS.2024.3490396},
  ISSN={2169-3536},
  month={},}@ARTICLE{9200875,
  author={Khanafer, Mounib and Shirmohammadi, Shervin},
  journal={IEEE Instrumentation & Measurement Magazine}, 
  title={Applied AI in instrumentation and measurement: The deep learning revolution}, 
  year={2020},
  volume={23},
  number={6},
  pages={10-17},
  abstract={In the last few years, hardly a day goes by that we do not hear about the latest advancements and improvements that Artificial Intelligence (AI) has brought to a wide spectrum of domains: from technology and medicine to science and sociology, and many others. AI is one of the core enabling components of the fourth industrial revolution that we are currently witnessing, and the applications of AI are truly transforming our world and impacting all facets of society, economy, living, working, and technology. The field of Instrumentation and Measurement (I&M) is no exception, and has already been impacted by Applied AI. In this article, we give an overview of Applied AI and its usage in I&M. We then take a deeper look at the I&M applications of one specific AI method: Deep Learning (DL), which has recently revolutionized the field of AI. Our survey of DL papers published in the IEEE Transactions on Instrumentation and Measurement (IEEE TIM) and IEEE Instrumentation & Measurement Magazine showed that, since 2017, there is a very strong interest in applying DL methods to I&M, in terms of measurement, calibration, and other I&M challenges. In particular, of the 32 surveyed papers, 75% were published in 2017 or later, and a remarkable 50% were published in 2019 alone. Considering that 2019 was not yet finished when we were writing this article, the recent exponential interest in and impact of DL in I&M is a very evident trend. We also found that although DL is used in a variety of I&M topics, a considerable portion of DL in I&M focuses on Vision Based Measurement (VBM) systems (around 28%) and fault/defect diagnosis/detection/prediction (around 25%). Finally, we found that Convolutional Neural Networks are the most widely used DL technique in I&M, especially in VBM. But to explain all of the above findings, we first need to understand AI itself and what we mean by it in its applied context. So let us begin our discussion with Applied AI.},
  keywords={Feature extraction;Instruments;Neurons;Machine learning;Analytical models;Biological neural networks},
  doi={10.1109/MIM.2020.9200875},
  ISSN={1941-0123},
  month={Sep.},}@ARTICLE{9186438,
  author={Benzaïd, Chafika and Taleb, Tarik},
  journal={IEEE Network}, 
  title={AI for Beyond 5G Networks: A Cyber-Security Defense or Offense Enabler?}, 
  year={2020},
  volume={34},
  number={6},
  pages={140-147},
  abstract={Artificial intelligence (AI) is envisioned to play a pivotal role in empowering intelligent, adaptive and autonomous security management in 5G and beyond networks, thanks to its potential to uncover hidden patterns from a large set of time-varying multi-dimensional data, and deliver faster and accurate decisions. Unfortunately, AI's capabilities and vulnerabilities make it a double-edged sword that may jeopardize the security of future networks. This article sheds light on how<;span class="upper-case"> Ai <;/span>may impact the security of 5G and its successor from its posture of defender, offender or victim, and recommends potential defenses to safeguard from malevolent AI while pointing out their limitations and adoption challenges.},
  keywords={5G mobile communication;Authentication;Security management;Next generation networking;Machine learning},
  doi={10.1109/MNET.011.2000088},
  ISSN={1558-156X},
  month={November},}@ARTICLE{10068744,
  author={Zhang, Junping and Pu, Jian and Xue, Jianru and Yang, Ming and Xu, Xin and Wang, Xiao and Wang, Fei-Yue},
  journal={IEEE Transactions on Intelligent Vehicles}, 
  title={HiVeGPT: Human-Machine-Augmented Intelligent Vehicles With Generative Pre-Trained Transformer}, 
  year={2023},
  volume={8},
  number={3},
  pages={2027-2033},
  abstract={Recently, a chat generative pre-trained transformer (ChatGPT) attracts widespread attention in the academies and industries because of its powerful conversational ability with human and its astonishing emergence ability such as admit mistakes, reject inappropriate problems. However, it is not easy to generalize ChatGPT into the field of intelligent vehicles because of its high computational cost, uncertain answers and decisions, and the difficulty of scenario generation for intelligent vehicles. To address these issues, we propose a novel framework, human-machine-augmented intelligent vehicles with generative pre-trained transformer. Under this framework, we discuss the potential, prospects, limitations and several typical applications of HiVeGPT in the domain of intelligent vehicles.},
  keywords={},
  doi={10.1109/TIV.2023.3256982},
  ISSN={2379-8904},
  month={March},}@ARTICLE{9199792,
  author={Yang, Tingting and Chen, Jiacheng and Zhang, Ning},
  journal={IEEE Network}, 
  title={AI-Empowered Maritime Internet of Things: A Parallel-Network-Driven Approach}, 
  year={2020},
  volume={34},
  number={5},
  pages={54-59},
  abstract={As one of the key technologies for realizing a fully digitalized world, the Internet of Things (IoT) requires ubiquitous connections across both land and sea. However, due to lack of infrastructure such as optical fibers and base stations, maritime communications inevitably face a highly complex and heterogeneous environment, which greatly challenges the connection reliability and traffic steering efficiency for future service-oriented maritime IoT. With the recent burgeoning application of artificial intelligence (AI) in many fields, an AI-empowered autonomous network for maritime IoT is envisioned as a promising solution. However, AI typically involves training/learning processes, which require realistic data/environment in order to obtain valuable outcomes. To this end, this article proposes the parallel network, which can be regarded as the "digital twin" of the real network and is responsible for realizing four key functionalities: self-learning and optimizing, state inference and network cognition, event prediction and anomaly detection, and knowledge database and snapshots. We then explain how various AI methods can facilitate the operation of the parallel- network-driven maritime network. A case study is provided to demonstrate the idea. Research directions are also outlined for further studies.},
  keywords={Marine vehicles;Internet of Things;Reinforcement learning;Complexity theory;Databases},
  doi={10.1109/MNET.011.2000020},
  ISSN={1558-156X},
  month={Sep.},}@ARTICLE{9714048,
  author={Arnold, Nicholas I. and Angelov, Plamen and Atkinson, Peter M.},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={An Improved Explainable Point Cloud Classifier (XPCC)}, 
  year={2023},
  volume={4},
  number={1},
  pages={71-80},
  abstract={Classification of objects from 3-D point clouds has become an increasingly relevant task across many computer-vision applications. However, few studies have investigated explainable methods. In this article, a new prototype-based and explainable classification method called eXplainable point cloud classifier (XPCC) is proposed. The XPCC method offers several advantages over previous explainable and nonexplainable methods. First, the XPCC method uses local densities and global multivariate generative distributions. Therefore, the XPCC provides comprehensive and interpretable object-based classification. Furthermore, the proposed method is built on recursive calculations, thus, is computationally very efficient. Second, the model learns continuously without the need for complete retraining and is domain transferable. Third, the proposed XPCC expands on the underlying learning method explainable deep neural networks (xDNN), and is specific to 3-D. As such, the following three new layers are added to the original xDNN architecture: 1) the 3-D point cloud feature extraction, 2) the global compound prototype weighting, and 3) the SoftMax function. Experiments were performed with the ModelNet40 benchmark, which demonstrated that XPCC is the only one to increase classification accuracy relative to the base algorithm when applied to the same problem. In addition, this article proposes a novel prototype-based visual representation that provides model- and object-based explanations. The prototype objects are superimposed to create a prototypical class representation of their data density within the feature space, called the compound prototype cloud. They allow a user to visualize the explainable aspects of the model and identify object regions that contribute to the classification in a human-understandable way.},
  keywords={Three-dimensional displays;Point cloud compression;Feature extraction;Deep learning;Prototypes;Classification algorithms;Artificial intelligence;3-D;AI;classification;deep learning;explainable;point cloud data},
  doi={10.1109/TAI.2022.3150647},
  ISSN={2691-4581},
  month={Feb},}@INPROCEEDINGS{10747947,
  author={Rush, Libby and Fogle, Eli and Eden, Sarah and Urban, Alexandra D. and Tijare, Harshal and Mooney, Shannon},
  booktitle={2024 IEEE Digital Education and MOOCS Conference (DEMOcon)}, 
  title={Generative Artificial Intelligence Driving More Efficient and Effective Course Optimizations}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The purpose of this study was to explore the efficacy of Generative Artificial Intelligence (GenAI) in optimizing online degree courses to enhance student retention and performance. Within the context of online learning platforms, there is a challenge in efficiently and effectively updating course content, which can impact the quality and relevance of the experience. The aim of this pilot was to utilize GenAI to create and augment educational resources, thus improving the clarity, scaffolding, and engagement of the online degree coursework. The methods employed in this pilot study included a quasi-experimental design where a Performance-Based Admissions (PBA) degree course was selected, its content was optimized using GenAI, and the impact was measured using a Difference-in-Differences (DID) analysis comparing optimized and non-optimized courses. The results indicate a 6% increase in course pass rates and significant improvements in midterm pass rates, average final grades, and the percentage of assignments submitted on time within the optimized course. Given these results, we estimate a 3% to 13% positive impact on second term persistence if all first-term courses received a similar GenAI optimization. The impact of this study is significant, demonstrating the potential of GenAI to revolutionize educational practices by providing quickly-produced, high-quality, low-cost content that enhances student learning outcomes. It supports the shift towards student-centered learning approaches and can be particularly beneficial in resource-constrained environments. In conclusion, the study underscores the transformative role of GenAI in education and emphasizes the need for ethical and responsible use to empower students and improve learning outcomes.},
  keywords={Measurement;Ethics;Computer aided instruction;Electronic learning;Generative AI;Navigation;Engineering profession;Education;Problem-solving;Optimization;GenAI;online teaching;degrees;performance-based admissions;content optimization},
  doi={10.1109/DEMOcon63027.2024.10747947},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10271790,
  author={Tian, Zhiyi and Zhang, Chenhan and Sood, Keshav and Yu, Shui},
  booktitle={2023 IEEE International Conference on Metaverse Computing, Networking and Applications (MetaCom)}, 
  title={Inferring Private Data from AI Models in Metaverse through Black-box Model Inversion Attacks}, 
  year={2023},
  volume={},
  number={},
  pages={49-56},
  abstract={The widespread application of artificial intelligence technologies in metaverse introduces significant privacy concerns. It is critical to study the training information leakage of AI models during the interaction of metaverse. Model inversion attacks have revealed the privacy vulnerability of deep learning models through reconstructing their training data during predictions. In this paper, we reconstruct the training samples of AI models (target model) in metaverse under a more practical threat model, where the adversary only has black-box access to the target model and no side information besides auxiliary dataset. We propose a contrastive supervised model inversion attack (CSMI). Specifically, we modify contrastive learning to train a neural network (projector) for inferring semantical knowledge contained in target model’s outputs. Afterwards, we design a supervised inversion model similar to the architecture of conditional GAN, where the projected outputs of the target model are involved as conditional inputs to supervise the training process. Finally, to generate inversion samples, we propose a bi-level random search strategy to search proper inputs of the trained inversion model through an objective function, which consists of the attacking success rate and the qualities of the reconstructed image. We conduct extensive experiments to evaluate the performance of the proposed CSMI. The experimental results show that samples reconstructed by CSMI are more visually plausible and reveal more features of the target than the state-of-the-art methods under a black-box setting.},
  keywords={Training;Threat modeling;Metaverse;Computational modeling;Closed box;Training data;Predictive models;Metaverse;privacy;deep learning;model inversion},
  doi={10.1109/MetaCom57706.2023.00051},
  ISSN={},
  month={June},}@ARTICLE{10864467,
  author={Calyam, Prasad and Clemm, Alexander and Pandey, Ashish and Roy, Upasana and Keller, Alexander and Das, Sajal K. and Calvert, Ken},
  journal={IEEE Internet Computing}, 
  title={Softwarized Networks in the Age of Generative Artificial Intelligence: Use Cases, Challenges, and Opportunities}, 
  year={2024},
  volume={28},
  number={6},
  pages={68-76},
  abstract={Software-defined networks (SDNs) have fundamentally transformed the networking industry over the past decade, giving network operators unprecedented flexibility to customize network behavior and automate network operations without needing to rely on equipment vendor development cycles. At the same time, generative artificial intelligence (GenAI) has been taking the world by storm, enabling (among other things) big leaps in programmer productivity. SDNs involve a complex programming and significant implementation aspect that today, in many cases, still limits what the network operators can practically achieve. This makes GenAI seemingly an ideal complement for SDNs with the potential of taking it to the next level. But can it? Although the application of GenAI to SDNs indisputably holds considerable promise, many unique challenges are yet to be well understood and resolved to separate hype from reality.},
  keywords={Productivity;Intelligent networks;Data privacy;Generative AI;Programming;Internet;Software defined networking;Optimization},
  doi={10.1109/MIC.2024.3485954},
  ISSN={1941-0131},
  month={Nov},}@ARTICLE{10742384,
  author={Zhang, Qingquan and Wang, Ziqi and Li, Yuchen and Zhang, Keyuan and Yuan, Bo and Liu, Jialin},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Expanding Horizons of Level Diversity via Multi-objective Evolutionary Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-12},
  abstract={In recent years, the generation of diverse game levels has gained increasing interest, contributing to a richer and more engaging gaming experience. A number of level diversity metrics have been proposed in literature, which are naturally multi-dimensional, leading to conflicted, complementary, or both relationships among these dimensions. However, existing level generation approaches often fail to comprehensively assess diversity across those dimensions. This paper aims to expand horizons of level diversity by considering multi-dimensional diversity when training generative models. We formulate the model training as a multi-objective learning problem, where each diversity metric is treated as a distinct objective. Furthermore, a multi-objective evolutionary learning framework that optimises multiple diversity metrics simultaneously throughout the model training process is proposed. Our case study on the commonly used benchmark Super Mario Bros. demonstrates that our proposed framework can enhance multi-dimensional diversity and identify a Pareto front of generative models, which provides a range of tradeoffs among playability and two representative diversity metrics, including a content-based one and a player-centered one. Such capability enables decision-makers to make informed choices when selecting generators accommodating a variety of scenarios and the diverse needs of players and designers.},
  keywords={Measurement;Games;Generators;Training;Video games;Artificial intelligence;Optimization;Grammar;Creativity;Convergence;Artificial intelligence generated content;procedural content generation;content diversity;multi-objective evolutionary learning;games},
  doi={10.1109/TAI.2024.3489534},
  ISSN={2691-4581},
  month={},}@INPROCEEDINGS{10916069,
  author={Xiang, Goh Yu and Loh I-Ling, Alicia and Bingi, Kishore and Omar, Madiah and Ibrahim, Rosdiazli},
  booktitle={International Conference on Green Energy, Computing and Intelligent Technology 2024 (GEn-CITy 2024)}, 
  title={A review of machine learning and drone-based solar panel inspection techniques}, 
  year={2024},
  volume={2024},
  number={},
  pages={125-130},
  abstract={This paper aims to improve defect identification, operational efficiency, and cost-effectiveness of drone-based photovoltaic (PV) solar panel inspection methods by leveraging artificial intelligence (AI) algorithms and modern imaging technologies. As the usage of renewable energy sources develops, it is vital to maintain solar panels in a timely and accurate way to guarantee their maximum perfor- mance. Innovative methods for large-scale solar panel inspection are made possible by drones equipped with thermal imaging, YOLOv8 object detection, Convolutional Neural Networks (CNNs), Single Shot Multibox Detectors (SSD), and mapping tools like Pix4D. Every method has proven effective in locating flaws, including hotspots, dust buildup, and cracks, enhancing system performance. This study thoroughly analyses these techniques, evaluating their feasibility, accuracy, and efficiency for small and large-scale solar installations. We hope to provide insights into the best drone-based solutions for solar panel inspection and maintenance by contrasting the advantages and disadvantages of each strategy, thereby assisting in developing a more dependable and sustainable renewable energy infrastructure.},
  keywords={},
  doi={10.1049/icp.2025.0245},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10685655,
  author={Huang, Jingxiu and Wei, Yufeng and Zhang, Lixin and Chen, Weirui},
  booktitle={2024 International Symposium on Educational Technology (ISET)}, 
  title={Evaluating generative artificial intelligence in answering course-related open questions: A pilot study}, 
  year={2024},
  volume={},
  number={},
  pages={64-69},
  abstract={ChatGPT, which has been discussed in public in recent years, was launched in November 2022, with a continuously expanding market size. Generative Artificial Intelligence (GAI) has been developing rapidly in China. However, we have little knowledge of how well the GAIs are performing at answering course-related open questions, especially in Chinese. Therefore, this study aims to analyze the performances of GAIs in answering course-related open questions from both machine and manual evaluation perspectives. The results from this study showed that GAIs got unsatisfactory scores in this situation. Two different aspects of comparison of GAIs’ scores are discussed. More study on evaluating the performance of GAI is needed to investigate the capabilities of answering course-related open questions in the future.},
  keywords={Generative AI;Manuals;Educational technology;Chatbots;GAI;automatic evaluation;manual evaluation;course-related open questions},
  doi={10.1109/ISET61814.2024.00022},
  ISSN={2766-2144},
  month={July},}@INPROCEEDINGS{10838918,
  author={Villaplana, Hannah Danielle Ladera and Kwak, Jaeyoung and Lees, Michael H. and Li, Hongying and Cai, Wentong},
  booktitle={2024 Winter Simulation Conference (WSC)}, 
  title={Application of Generative Artificial Intelligence for Epidemic Modeling}, 
  year={2024},
  volume={},
  number={},
  pages={2727-2738},
  abstract={Epidemic models have become increasingly useful, especially in the wake of the recent COVID-19 pandemic, emphasizing the crucial role of human behavior in the spread of disease. There has been a recent rise in the usage and popularity of generative artificial intelligence (GenAI), such as ChatGPT especially with its ability to mimic human behavior. In this study, we demonstrate a novel application of GenAI for epidemic modeling. We employed GenAI for creating agents living in a hypothetical town in simulations and simulating their behavior within the context of an ongoing pandemic. We performed a series of simulations to quantify the impact of agent traits and the availability of information for health condition, virus, and government guidelines on the disease spread patterns in terms of peak time and epidemic duration. We also characterized the most influential factors in agents' decision-making using random forest model.},
  keywords={Pandemics;Generative AI;Computational modeling;Government;Decision making;Behavioral sciences;Random forests;Diseases;Guidelines;Context modeling},
  doi={10.1109/WSC63780.2024.10838918},
  ISSN={1558-4305},
  month={Dec},}@ARTICLE{11152690,
  author={Peng, Zhiyuan and Liu, Yuchen and Li, Gaolei and Yang, Zhaohui and Chen, Mingzhe and Xu, Dongkuan and Lin, Xingqin},
  journal={IEEE Communications Magazine}, 
  title={Generative Artificial Intelligence Models for Emerging Communication Systems: Fundamentals and Challenges}, 
  year={2025},
  volume={63},
  number={9},
  pages={36-43},
  abstract={The evolution of generative artificial intelligence (GenAI) marks a pivotal shift in the potential reshaping of technological landscapes. Wireless networks, bolstered by the advent of advanced intelligent technologies, present a promising domain for leveraging GenAI, which could revolutionize the current networking design and communication paradigms. Extensive research has reviewed large language models, a significant yet specialized facet of GenAI, and explored their integration into networks. This article offers a broad introduction to GenAI and delves into its applications within various emerging communication technologies. We start by providing an overview of representative GenAI models, including variational autoencoder, Transformer, and diffusion models, elucidating their foundational principles. Subsequently, we spotlight their emerging applications in advanced communication systems such as digital twins, integrated sensing and communication, and semantic communication. We also underscore crucial challenges and practical considerations, encompassing aspects like data quality, real-time processing capabilities, privacy risks, and security implications. Furthermore, a prospective outlook on research opportunities is taken to surmount these challenges, thereby unlocking the full potential of GenAI in future communication systems.},
  keywords={Data privacy;Generative AI;Data integrity;Transformers;Semantic communication;Integrated sensing and communication;Diffusion models;Real-time systems;Digital twins;Security},
  doi={10.1109/MCOM.001.2400730},
  ISSN={1558-1896},
  month={Sep.},}@INPROCEEDINGS{11135663,
  author={PR, Bipin and Biju, Alen K and M, Balagopal and Shyam, B and Adithya, C A},
  booktitle={2025 4th International Conference on Advances in Computing, Communication, Embedded and Secure Systems (ACCESS)}, 
  title={DeepFake Detection Using CNN Models with Explainable AI Techniques}, 
  year={2025},
  volume={},
  number={},
  pages={341-349},
  abstract={The rapid advancements in artificial intelligence have enabled the creation of highly realistic, AI-generated fake images, commonly referred to as DeepFakes, which pose significant challenges to society by spreading misinformation and causing potential harm through social media platforms. This paper presents a robust DeepFake detection framework that combines high accuracy with enhanced interpretability. Multiple state-of-the-art deep learning models, including XceptionNet, EfficientNet, and MesoNet, are evaluated on the Celeb-DF v2 dataset, a benchmark for DeepFake detection, and an internal dataset containing diverse image manipulations. These models leverage unique convolutional neural network architectures, such as XceptionNet’s depthwise separable convolutions, EfficientNet’s compound scaling, and MesoNet’s lightweight design. To enhance transparency and trust in the detection process, Gradient-weighted Class Activation Mapping (Grad-CAM) is integrated, visualizing critical regions influencing predictions and providing actionable insights into model decisions. Experimental results demonstrate the framework’s effectiveness, with XceptionNet and EfficientNet achieving superior detection performance, while the integration of Grad-CAM ensures greater interpretability and accountability, making this approach a promising tool for mitigating disinformation risks on media platforms.},
  keywords={Deepfakes;Visualization;Accuracy;Explainable AI;Social networking (online);Prevention and mitigation;Robustness;Real-time systems;Convolutional neural networks;Compounds;DeepFake detection;Explainable AI;GradCAM;Convolutional Neural Networks;XceptionNet;Efficient-Net;Celeb-DF v2;Image manipulation;Disinformation mitigation},
  doi={10.1109/ACCESS65134.2025.11135663},
  ISSN={},
  month={June},}@INPROCEEDINGS{10585244,
  author={N, Monisha and G, Gunvanth and Jayapandian, N.},
  booktitle={2023 Fourth International Conference on Smart Technologies in Computing, Electrical and Electronics (ICSTCEE)}, 
  title={Digital Transaction Cyber-Attack Detection Using Particle Swarm Optimization}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The cyber digital world is an essential variant in day-to-day life in advanced technology. There is a better change in the lifestyle as intelligent technology. In larger excite to increase the advanced technology which can be developed to humans in major dependent on network and internet users. Now, in modern times, the internet has changed the primary need in human lifestyle by giving access to everything in the world while sitting in one place knowing and updating the information and usage of online subscribers or Revolution. The world is moving in Rapid and Faster communications within a fraction of a second, at a lesser cost, and it has minimal paper-based processes and relies on the digitization document instead of a paperless environment. The data is handled by finch security practices, which are used in security worldwide to establish protected data management systems like digital lending, credits, mobile Banking, and mobile payment. Cryptocurrency and blockchain, B-trading, and banking as a service are included. At the same time, leveraging the new technologies is to resist hacking cyber-attacks. This article is also involved in artificial intelligence and machine learning (AI&ML) in different cyber-attacks. This article focuses on genetic algorithms to detect the cyber-attack. The main aim of the detection is future to prevent these cyber-attacks. The comparison will take two sample genetic algorithms. The first one is taken for Ant Colony Optimization (ACO), and the proposed model is taken for Particle Swarm Optimization. The average attack detection of ACO algorithm is 45 packets at the same time PSO algorithm will detect 50 packets.},
  keywords={Training;Online banking;Scalability;Intrusion detection;Collaboration;Resists;Network security;Cyber-attacks;Digital Transaction;Genetic Algorithm;Deep Learning;Machine Learning;Particle Swarm Optimization},
  doi={10.1109/ICSTCEE60504.2023.10585244},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11167221,
  author={Wijaya, Lianna and Cheng, Kin Meng and Lasian, Lourdes and Lestari, Made Irma and Wahono, Johannes Widjaja and Anisa, Nova Nur},
  booktitle={2025 4th International Conference on Creative Communication and Innovative Technology (ICCIT)}, 
  title={Determinants of ChatGPT Adoption in Higher Education Students: A UTAUT Framework Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={As generative AI technologies such as ChatGPT gain traction, their capacity to transform higher education learning experiences is widely acknowledged. Yet, the specific drivers behind student acceptance of these tools are not yet fully understood. To address this gap, the current study investigates the key factors determining ChatGPT adoption by applying the theoretical lens of the Unified Theory of Acceptance and Use of Technology (UTAUT). Employing a quantitative approach, the research gathered survey data from 256 undergraduates in Metro Manila, Philippines, and analyzed it using Partial Least Squares Structural Equation Modeling (PLS-SEM). The analysis confirmed that effort expectancy, performance expectancy, soial influence, and facilitating conditions are all instrumental in forming a student’s intention to use the technology. Performance expectancy was identified as the primary determinant. Interestingly, effort expectancy exerted a negative influence, underscoring that students prioritize the utility of ChatGPT over its simplicity. Subsequently, the study established a strong, positive link between the intention to use and actual user behavior. These findings not only affirm the relevance of the UTAUT model for studying educational AI but also provide actionable recommendations for institutions seeking to foster AI-enhanced learning ecosystems. The research thus advances theoretical knowledge of technology acceptance and holds practical implications for optimizing AI integration in education. Further investigation into other contextual variables in varied educational settings is recommended.},
  keywords={Surveys;Generative AI;Instruments;Education;Ecosystems;Transforms;Chatbots;Mathematical models;Data models;Lenses;Social Influence;Effort Expectancy;Facilitating Conditions;UTAUT;Performance Expectancy},
  doi={10.1109/ICCIT65724.2025.11167221},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10934633,
  author={Ye, Zhou and Sirivesmas, Veerawat and Joneurairatana, Eakachat and Simatrang, Sone},
  booktitle={2025 International Conference on Intelligent Systems and Computational Networks (ICISCN)}, 
  title={Design and Application of Painting Teaching System based on Hyperlink-Induced Topic Search Algorithm}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={With the rapid advancement of artificial intelligence and big data, traditional painting teaching methods face challenges in adapting to modern educational needs. This paper proposes a painting teaching system based on the Hyperlink-Induced Topic Search (HITS) algorithm to enhance teaching efficiency and improve student engagement. The HITS algorithm, widely used in web link analysis, is leveraged to establish a knowledge graph that identifies key artistic concepts and relationships between painting techniques. The system enables personalized learning by recommending relevant teaching materials based on students’ preferences and progress. Additionally, an intelligent evaluation module assesses students’ artwork using deep learning techniques, providing constructive feedback to enhance their artistic skills. The proposed system integrates interactive multimedia resources, fostering an immersive learning environment. Experimental results demonstrate that the system significantly improves learning outcomes by offering targeted guidance and optimizing teaching resources. Compared to traditional methods, the HITS-based system provides a more adaptive and student-centric approach. The real-time data analysis aids instructors in refining their teaching strategies. This study highlights the potential of AI-driven methodologies in revolutionizing art education. Moreover, the system incorporates collaborative learning features, allowing students to share their work and receive peer feedback, enhancing creativity and engagement. Security measures and access control mechanisms ensure a safe and personalized learning environment for students. The experimental measure value shows that this implementation performs well with the accuracy score of 97.6%, precision of 96.6%, Recall of 95.34% and F1 score of 97.3%. It focuses on enhancing system adaptability and incorporating advanced image recognition techniques for more precise evaluations, paving the way for a smarter and more efficient art education framework.},
  keywords={Data analysis;Art;Multimedia systems;Education;Refining;Knowledge graphs;Real-time systems;Intelligent systems;Painting;Immersive learning;painting technique;HITS;traditional methods;immersive learning;real time data analysis},
  doi={10.1109/ICISCN64258.2025.10934633},
  ISSN={},
  month={Jan},}@ARTICLE{8648422,
  author={Zhang, Min and Liu, Shuheng and Yang, Fangyun and Liu, Ji},
  journal={IEEE Access}, 
  title={Classification of Canker on Small Datasets Using Improved Deep Convolutional Generative Adversarial Networks}, 
  year={2019},
  volume={7},
  number={},
  pages={49680-49690},
  abstract={This paper proposes a deep learning model for the classification of citrus canker that overcomes the shortcomings of traditional approaches, and the scarce number of available images for training, which have been subject to the overfitting limitation. To address the issues, we propose two approaches, namely, the feature magnification and objective breakdown optimization, to augment datasets, and emphasizes meaningful features and prevent the model from overfitting noise signals. The first approach mimics the distribution of positive samples with a generative model based on deep convolutional generative adversarial networks. The second approach updates different parts of the model with optimization objectives, whereby back-propagated error signals are no longer the only signal for updating parameters. To validate the proposed approaches, we present theoretical proofs to justify the correctness of our methods and conduct extensive case studies and experiments to show that the proposed approaches clearly outperform traditional approaches on the classification of accuracy and efficiency of small training sets. In this paper, a methodology is proposed to generate a general model. The model can be applied to other bio-medical applications, where the scarcity of visual samples makes it difficult for a normal deep learning model to work without overfitting.},
  keywords={Training;Gallium nitride;Computational modeling;Biological system modeling;Optimization;Visualization;Task analysis;Generative adversarial networks;Siamese learning;feature magnification;optimization objective breakdown},
  doi={10.1109/ACCESS.2019.2900327},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11012512,
  author={R. S, Padmalakshmi. and C. K, Shawn Basil.},
  booktitle={2025 3rd International Conference on Advancements in Electrical, Electronics, Communication, Computing and Automation (ICAECA)}, 
  title={AI Driven Exploit Mitigation for Zero Day Vulnerability Using SVM and Autoencoder}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={This study is about the action taken to reduce the risk or impact of a "zero-day vulnerability" (flaw or weakness in a software that is unknown to the makers or the public but that can be exploited by attackers). This study helps to analyze the exploits in a software to prevent cyberattacks. This study evaluates the performance of SVM and Autoencoder to classify the "zero-day vulnerability" dataset. SVM classifier got an accuracy of 94.9%, precision and recall values of 20.83% and 30%, f1-score at 23% and specificity of 94%. Whereas, autoencoder got an accuracy of 81.6%, precision and recall values of 21% and 28%, f1-score at 21.05% and specificity of 81%. According to the achieved values, SVM provides better accuracy than autoencoder in analyzing the dataset.},
  keywords={Support vector machines;Accuracy;Prevention and mitigation;Autoencoders;Intrusion detection;Network security;Feature extraction;Malware;Telecommunication computing;Unsupervised learning;Zero-day vulnerabilities;SVM (support vector machine);autoencoder;anomaly detection;intrusion detection systems (ids);cybersecurity;machine learning;deep learning;network security;attack detection;malware detection;security analytics;feature extraction;unsupervised learning;artificial intelligence in cybersecurity},
  doi={10.1109/ICAECA63854.2025.11012512},
  ISSN={},
  month={April},}@INPROCEEDINGS{9999103,
  author={Ali, Muhammad Shahroze and Azam, Farooque and Safdar, Aon and Anwar, Muhammad Waseem},
  booktitle={2022 IEEE International Conference on Agents (ICA)}, 
  title={Intelligent Agents in Educational Institutions: NEdBOT - NLP-based Chatbot for Administrative Support Using DialogFlow}, 
  year={2022},
  volume={},
  number={},
  pages={30-35},
  abstract={Artificial intelligence (AI)-based chatbot systems have seen increased adaption in the educational domain in recent years owing to increased sophistication in the AI domain. However, most of the communication between students and educational institutions is still performed physically and causes major administrative overhead, especially during the time of admission. Contemporary pattern-matching-based and generative-based chatbots underperform to queries outside a limited scope, grammatically and structurally ambiguous inputs, outliers to pre-defined rule-set, and longer response times for a huge knowledge base. We proposed a NEdBOT-An NLP-based Educational Bot, developed by Natural Language Processing models integrated within the DialogFlow platform utilizing a Retrieval-based approach. We evaluate the developed chatbot on a custom dataset generated for the admissions use case of a prominent university. We used an objective evaluation criterion with real-world users to achieve an intent classification accuracy of 76.8% at an average mean response time of 216.43ms per query and a user-friendliness score of 72% on the System Usability Scale (SUS). The results demonstrate the proposed approach's ability to create robust, reliable, responsive, and user-friendly web-based smart chatbots that are highly scalable with the capability to handle wider scopes and vague inputs with ease.},
  keywords={Training;Text mining;Text recognition;Text categorization;Knowledge based systems;Chatbots;Time factors;Educational Chatbot;Artificial Intelligence;DialogFlow;Natural Language Processing;Retrieval-based approach},
  doi={10.1109/ICA55837.2022.00012},
  ISSN={},
  month={Nov},}@INBOOK{10950533,
  author={Vashishta, Vin},
  booktitle={From Data To Profit: How Businesses Leverage Data to Grow Their Top and Bottom Lines}, 
  title={Large Model Monetization Strategies&#x2014;Quick Wins}, 
  year={2023},
  volume={},
  number={},
  pages={215-227},
  abstract={Summary <p>This chapter provides frameworks for monetizing large models like GPT and all the ones that will follow. Generative search is one example of a product built on AI operating system models. The earliest implementations were Bard for Google and GPT for Microsoft's Bing. The AI platforms are becoming the new App Store. Large AI operating system platforms are trying to replicate the business model. Customers get the GPT series of models, the platform, and the App Store. Most quick&#x2010;win opportunities will fall under the digital paradigm. Opportunities follow the paradigm of integrating these AI operating system models into existing applications. Every business needs a governance framework for AI operating system models. Scenario planning and risk mitigation are essential parts of monetization strategy. It's equally important to find risk mitigation strategies rather than making risk avoidance the centerpiece of monetization strategy.</p>},
  keywords={Artificial intelligence;Operating systems;Business;Biological system modeling;Ecosystems;Companies;Internet;Translation;Data models;Software},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394196227},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10950533},}@INPROCEEDINGS{10833970,
  author={Kim, Mira and Kim, Taylor and Nguyen, Alexander and Gomez, Eduardo Nunez and Jin, Jennifer},
  booktitle={2024 Artificial Intelligence x Humanities, Education, and Art (AIxHEART)}, 
  title={TinyTeller AI, an AI-based Adaptive Storytelling Application}, 
  year={2024},
  volume={},
  number={},
  pages={44-51},
  abstract={Reading in early childhood is crucial as it has been shown there is a positive link between reading for pleasure in childhood with better cognition, mental health, and educational attainment in adolescence [1]. However, conventional reading and storytelling have limitations in engaging diverse audiences. Conventional storytelling with fixed narrative structures often fails to capture the attention of young children as it lacks adaptability and personalization. In this paper, we introduce an innovative approach for adaptive storytelling application developed with young children in mind to remedy the limitations. We implemented TinyTeller AI, an AI-based adaptive storytelling software application which generates personalized stories for young children. We utilize GPT to acquire adaptive stories based on user profiles and preferences and format the stories for high comprehensibility.},
  keywords={Pediatrics;Adaptation models;Art;Generative Pre-trainer transformer;Mental health;Software;Cognition;Artificial intelligence;Adaptive storytelling;GPT (Generative Pre-Trained Model);Personalized reading},
  doi={10.1109/AIxHeart62327.2024.00017},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10986113,
  author={Ziatdinov, Rushan and Nabiyev, Rifkat},
  booktitle={2025 International Russian Smart Industry Conference (SmartIndustryCon)}, 
  title={Generating Digital Models Using Text-to-3D and Image-to-3D Prompts: Critical Case Study}, 
  year={2025},
  volume={},
  number={},
  pages={719-724},
  abstract={In the world of technology and AI, digital models play an important role in our lives and are an essential part of the digital twins of real-world objects. They can be created by designers, artists, or game developers using spline curves and surfaces, meshes, and voxels, but making such models is too time-consuming. With the growth of AI tools, there is interest in the automated generation of 3D models, such as generative design approaches, which can save creators valuable time. This paper reviews several online 3D model generators and critically analyses the results, hoping to see higher-quality results from different prompts.},
  keywords={Solid modeling;Analytical models;Three-dimensional displays;Computational modeling;Space shuttles;Generators;Software;Digital twins;Artificial intelligence;Splines (mathematics);text-to-3D;image-to-3D;digital twin;digital model;design;CAD;computer graphics},
  doi={10.1109/SmartIndustryCon65166.2025.10986113},
  ISSN={},
  month={March},}@INBOOK{10950671,
  author={Diamond, Stephanie and Allan, Jeffrey},
  booktitle={Writing AI Prompts For Dummies}, 
  title={Dealing with the Ethical Considerations of Responsible AI}, 
  year={2024},
  volume={},
  number={},
  pages={211-224},
  abstract={Summary <p>AI is becoming a big part of our lives. This chapter guides readers in understanding how to use AI the right way. Generative AI (GenAI), which creates new content, also applies the greatest&#x2010;good approach by generating ideas and solutions that can benefit many. In the broader scope, the greatest&#x2010;good approach with GenAI should still consider the potential for misuse and strive to minimize harm. Rule&#x2010;based ethics in AI works by setting clear rules for the AI to follow. These rules are like the rules of the road that guide AI on what to do or avoid. Rule&#x2010;based ethics play a critical role in GenAI platforms such as ChatGPT. In education, AI tutors with character&#x2010;based ethics are patient and encouraging, adapting to each student's unique learning style. In AI, bias and fairness are important issues. Fairness&#x2010;aware modeling in AI refers to making AI systems that think about and deal with fairness when they make choices.</p>},
  keywords={Artificial intelligence;Ethics;Privacy;Chatbots;Standards;Programming profession;Motion pictures;Companies;Writing;Vehicles},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394244683},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10950671},}@INBOOK{10950738,
  author={Blount, Jeb and Iannarino, Anthony},
  booktitle={The AI Edge: Sales Strategies for Unleashing the Power of AI to Save Time, Sell More, and Crush the Competition}, 
  title={Practice and Prompts}, 
  year={2024},
  volume={},
  number={},
  pages={87-99},
  abstract={Summary <p>Prompt engineering is the process of structuring text into a format that can be interpreted and understood by generative AI. AI tools are trained on massive datasets of text and code. They can generate text, translate languages, write different kinds of creative sales content, and answer our questions in an informative way. A prompt is a natural language text that describes the task that an AI should perform. The goal of prompt engineering is to write prompts that are clear, concise, and produce the information we seek on the first try. The prompt should be specific enough to tell the AI tool what to do, but it should not be so specific that it limits creativity. The prompt should also be grammatically correct and free of errors. Accordingly, the path to mastering AI prompts to make the readers faster, better, and stronger is the decision to jump in and get started.</p>},
  keywords={Artificial intelligence;Prompt engineering;Robots;Translation;Psychology;Codes;Buildings;Tires;Stars;Sports},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394244492},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10950738},}@INPROCEEDINGS{10873502,
  author={Lue, Hang-Ting and Hung, Chun-Hsiung and Wang, Keh-Chung and Lu, Chih-Yuan},
  booktitle={2024 IEEE International Electron Devices Meeting (IEDM)}, 
  title={Prospects of Computing in or Near Flash Memories}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Memory-centric computing is emerging as a potential solution to address the memory bottleneck, especially in generative AI. In current AI hardware, most users focus primarily on the processor and DRAM as the main computing devices, while Flash memory remains peripheral to AI. In this paper, we explore the potential of Flash memory to play a more effective role in AI computing. Flash memory offers advantages such as high density and non-volatility, making it suitable for both edge and cloud AI computing, which require low-cost and low-power solutions. Flash memory will continue to leverage monolithic 3D stacking for higher density, improve read bandwidth to approach that of DRAM, and most importantly, add computing functions near or in Flash memory to support various AI computing tasks. We provide two specific examples. First, we introduce 3D NOR technology and the concept of high-bandwidth digital computing in memory (HB dCIM) to support the general matrix-vector (GEMV) accelerator for large language model (LLM) inference. Second, we discuss an in-memory search (IMS) accelerator using 3D NAND for approximate nearest-neighbor search applications.},
  keywords={Cloud computing;Technological innovation;Three-dimensional displays;Large language models;Stacking;Random access memory;Nearest neighbor methods;Hardware;Flash memories;Artificial intelligence},
  doi={10.1109/IEDM50854.2024.10873502},
  ISSN={2156-017X},
  month={Dec},}@INPROCEEDINGS{10956783,
  author={Akhmedov, Farrukh and Umarov, Mukhriddin and Urinov, Elmurod and Turgunov, Bekzod},
  booktitle={2024 International Conference on Information Science and Communications Technologies (ICISCT)}, 
  title={An Algorithm of Recognition Uzbek Sign Language}, 
  year={2024},
  volume={},
  number={},
  pages={220-225},
  abstract={This article highlights an algorithm for recognizing the dactyl alphabet of Uzbek Sign Language using the YOLO architecture, based on deep convolutional neural networks. For training the model, developed a dataset that consist of images which representing of signs of Uzbek sign language. Metrics such as precision, recall, and average nrecision were used to evaluate the model's nerformance.},
  keywords={Training;YOLO;Measurement;Sign language;Vocabulary;Translation;Text recognition;Software algorithms;Speech recognition;Software;Sign language;Artificial neural networks;YOLO;Dactyl alphabet;Image dataset;Evaluation metrics;Object detection},
  doi={10.1109/ICISCT64202.2024.10956783},
  ISSN={},
  month={Nov},}
