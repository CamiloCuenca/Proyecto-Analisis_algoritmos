@ARTICLE{10992261,
  author={Tran, Van-Nhan and Le, Hoanh-Su and Choi, Piljoo and Lee, Suk-Hwan and Kwon, Ki-Ryong},
  journal={IEEE Open Journal of the Computer Society}, 
  title={MEViT: Generalization of Deepfake Detection With Meta-Learning EfficientNet Vision Transformer}, 
  year={2025},
  volume={6},
  number={},
  pages={789-800},
  abstract={Deepfakes are digitally manipulated videos that appear realistic but are actually fake. With the rapid advances in deep generative models, the accessibility and sophistication of such manipulation technologies are increasing, making it more challenging to detect fake content. Different facial forgery techniques result in complex data distributions, and most existing deepfake detection approaches rely on convolutional neural networks (CNNs) that treat the task as a binary classification problem. While these methods achieve high accuracy on specific datasets, their generalization performance across datasets is often poor due to overfitting to manipulation techniques seen during training. In this study, we propose a model called MEViT, which integrates the EfficientNet Vision Transformer with a meta-learning framework to enhance generalization in deepfake detection. Furthermore, we introduce a pair-discrimination loss to push the feature representations of fake samples away from those of real samples, and a domain adjustment loss to reduce domain shifts across different manipulation methods. The MEViT model is trained on a specific manipulation method in the FaceForensics++ dataset and evaluated on other unseen methods from the same dataset. Additionally, we conduct extensive experiments on multiple deepfake benchmarks, including FaceForensics++ and CelebDF-v2, and compare our method with various state-of-the-art approaches to demonstrate its effectiveness.},
  keywords={Deepfakes;Metalearning;Training;Forgery;Face recognition;Adaptation models;Transformers;Computer vision;Proposals;Generative adversarial networks;Deep learning;deepfake detection;GAN;generalization;meta-learning;video forensics},
  doi={10.1109/OJCS.2025.3568044},
  ISSN={2644-1268},
  month={},}@ARTICLE{10551859,
  author={Chen, Xuehan and Luo, Linfeng and Tang, Fengxiao and Zhao, Ming and Kato, Nei},
  journal={IEEE Network}, 
  title={AIGC-Based Evolvable Digital Twin Networks: A Road to the Intelligent Metaverse}, 
  year={2024},
  volume={38},
  number={6},
  pages={370-379},
  abstract={The future Metaverse aims to provide users with an immersive experience in a persistent online 3-D virtual environment at any given time or location. To achieve this goal, the future wireless communication system should provide high quality communication service with ultra-high capacity and reliability, ultra-low latency, and so on. As one of the key technologies to achieve the Metaverse, Digital Twin Network (DTN) is applied to improve the network performance by dynamically mapping the virtual and real wireless system in real-time throughout its lifecycle, but the construction and evolution of the digital twin (DT) models highly depend on real-time sensing data from the physical world. In addition, the Metaverse is not only a high-precision replica of the real world, but also consists of some exploration things extending from the real world to enrich the users’ experience. Recently, Artificial Intelligence- Generated Content (AIGC) is proposed as an efficient method to allow the automatic generation of content and experiences in virtual worlds using Artificial Intelligence (AI) algorithms creatively, which offers fresh concepts to effectively address the aforementioned challenges, and leads to a more immersive and dynamic Metaverse. To this end, this paper aims to depict a novel path to achieve the intelligent Metaverse. First, the frontier capabilities and key elements of AIGC are presented. Then, we discuss how AIGC drives an evolvable DTN, and how DTN is applied to promote the application of AIGC, thereby facilitating the development of the Metaverse. Finally, a case study is presented to show the efficiency of AIGC in the DTN for the Metaverse, and some future directions are given.},
  keywords={Metaverse;Data models;Computational modeling;Artificial intelligence;User experience;Training;6G mobile communication;Immersive experience;Content distribution networks;AIGC;Metaverse;DTN;intelligent},
  doi={10.1109/MNET.2024.3411008},
  ISSN={1558-156X},
  month={Nov},}@INPROCEEDINGS{9020449,
  author={Zamstein, Lavi M. and Smith, Brandt A. and Hodhod, Rania},
  booktitle={2019 SoutheastCon}, 
  title={A Comparative Study of Opponent Type Effects on Speed of Learning for an Adversarial Q-Learning Agent}, 
  year={2019},
  volume={},
  number={},
  pages={1-7},
  abstract={One goal of artificial intelligence has been to approximate human thought. The ability to learn is common to both humans and artificial intelligence agents, but the methods can sometimes differ. Reinforcement learning is one area where machine learning was initially based on the learning methods of humans and animals. In the case of two-player, turn-based adversarial games, it is advantageous to be able to train the learning agent against an opponent. The skill level of the opponent, however, is important, and can lead to different learning speeds, breadth of learning, or efficiency. We demonstrate the outcomes when having a learning agent play a simple game (tic-tac-toe) against an unskilled opponent, an opponent of equal skill, and an advanced opponent.},
  keywords={Games;Learning (artificial intelligence);Machine learning;Sparse matrices;Task analysis;Animals;Q-learning;reinforcement learning;human learning;adversarial reinforcement learning},
  doi={10.1109/SoutheastCon42311.2019.9020449},
  ISSN={1558-058X},
  month={April},}@INPROCEEDINGS{10838939,
  author={Marti, Silvan and Lopes, Paulo Victor and Chen, Siyuan and Rajashekarappa, Mohan and Bana, Elham Rekabi and Göppert, Amon and Déspeisse, Mélanie and Stahre, Johan and Johansson, Björn},
  booktitle={2024 Winter Simulation Conference (WSC)}, 
  title={Synthetic Simulated Environment for Discrete Manufacturing Systems: A Demonstrator Through a Computational Modeling Approach}, 
  year={2024},
  volume={},
  number={},
  pages={1716-1727},
  abstract={In light of the challenges posed by the often unavailability of coherent data in manufacturing for operational Artificial Intelligence (AI) decision support systems, the generation and utilization of synthetic datasets have become essential. This study introduces a simple numerical Synthetic Simulated Environment (SSE) using timed and parametrizable Petri Net (PN) modules, embedded in a Directed Acyclic Graph (DAG) structure described by an adjacency matrix to represent material flow. Implemented in PyTorch for seamless integration with AI components, our simulation framework simplifies manufacturing systems, yet remains expandable for diverse use cases. The simulation model was demonstrated displaying its capability of generating synthetic data. This approach explores the practicality and applicability of generated data. It could serve as an ideal environment to benchmark Artificial Intelligence (AI) algorithms in comparative experiments, investigating operational problems featured in the dynamic interactions of discrete manufacturing systems.},
  keywords={Decision support systems;Directed acyclic graph;Heuristic algorithms;Computational modeling;Petri nets;Benchmark testing;Data models;Artificial intelligence;Manufacturing systems;Synthetic data},
  doi={10.1109/WSC63780.2024.10838939},
  ISSN={1558-4305},
  month={Dec},}@ARTICLE{11062656,
  author={Li, Hao and Xu, Zhibin and Gong, Maoguo and Qin, A.K. and Wu, Yue and Xing, Lining and Zhou, Yu},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Privacy-Enhanced Offline Data-Driven Evolutionary Optimization Based on Cloud Server}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Data-driven evolutionary algorithms (DDEAs) have achieved significant success in numerous real-world optimization problems, where exact objective functions and constraint functions do not exist, and they mainly rely on available data. However, the existing DDEAs primarily focus on improving performance through data and surrogate, without considering that the users may lack the specialized domain knowledge and sufficient computing resources required for DDEAs. To address the aforementioned issues, this paper proposes a novel paradigm called Evolutionary Learning and Optimization as a Service (ELOaaS) and investigates the potential collusion attacks between machine learning modules and evolutionary computing modules on cloud server, which may lead to privacy leakage. Consequently, a privacy-enhanced DDEA (PEDDEA) is proposed as an instantiation algorithm of ELOaaS, which is designed to tackle offline data-driven evolutionary optimization within the ELOaaS paradigm. In the proposed PEDDEA, a subspace learning-based privacy protection strategy is designed to defense the collusion attacks. Additionally, a model management strategy based on Kendall tau metric is introduced to construct high-quality surrogate ensembles. PEDDEA enables users to outsource private offline data to cloud servers, thereby approaching the optimal solution while ensuring privacy protection. Comprehensive experiments are conducted on benchmark problems and safety evaluation problems of autonomous vehicles. According to the experimental results, the proposed algorithm has significant performance advantages over existing offline DDEAs while ensuring privacy protection.},
  keywords={Optimization;Servers;Evolutionary computation;Privacy;Protection;Data models;Cloud computing;Predictive models;Machine learning;Data privacy;Data-driven optimization;evolutionary computation;evolutionary learning and optimization as a service;privacy protection;model management},
  doi={10.1109/TEVC.2025.3584882},
  ISSN={1941-0026},
  month={},}@ARTICLE{10531039,
  author={Lee, Gyeong-Geon and Zhai, Xiaoming},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Using ChatGPT for Science Learning: A Study on Pre-service Teachers' Lesson Planning}, 
  year={2024},
  volume={17},
  number={},
  pages={1643-1660},
  abstract={While ongoing efforts have continuously emphasized the integration of ChatGPT with science teaching and learning, there are limited empirical studies exploring its actual utility in the classroom. This study aims to fill this gap by analyzing the lesson plans developed by 29 pre-service elementary teachers and assessing how they integrated ChatGPT into science learning activities. We first examined how ChatGPT was integrated with the subject domains, teaching methods/strategies, and then evaluated the lesson plans using a generative artificial intelligence (AI)-technological pedagogical and content knowledge (TPACK)-based rubric. We further examined pre-service teachers' perceptions and concerns about integrating ChatGPT into science learning. Results show a diverse number of ChatGPT applications in different science domains—e.g., Biology (9/29), Chemistry (7/29), and Earth Science (7/29). A total of 14 types of teaching methods/strategies were identified in the lesson plans. On average, the pre-service teachers' lesson plans scored high on the modified TPACK-based rubric (M = 3.29; SD = 0.91; on a 1–4 scale), indicating a reasonable envisage of integrating ChatGPT into science learning, particularly in “instructional strategies and ChatGPT” (M = 3.48; SD = 0.99). However, they scored relatively lower on exploiting ChatGPT's functions toward its full potential (M = 3.00; SD = 0.93), compared to other aspects. We also identified several inappropriate use cases of ChatGPT in lesson planning (e.g., as a source of hallucinated Internet material and technically unsupported visual guidance). Pre-service teachers anticipated ChatGPT to afford high-quality questioning, self-directed learning, individualized learning support, and formative assessment. Meanwhile, they also expressed concerns about its accuracy and the risks that students may be overly dependent on ChatGPT. They further suggested solutions to systemizing classroom dynamics between teachers and students. The study underscores the need for more research on the roles of generative AI in actual classroom settings and provides insights for future AI-integrated science learning.},
  keywords={Chatbots;Education;Artificial intelligence;Planning;Ethics;Privacy;Navigation;ChatGPT;generative artificial intelligence (GenAI);lesson plan;pre-service teacher;science education;technology integration},
  doi={10.1109/TLT.2024.3401457},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10915298,
  author={Gupta, Rohan and Ghanghas, Peshal},
  booktitle={2025 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)}, 
  title={An integrated approach to detect online financial transaction fraud using negative and clonal selection algorithms with AIS}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The relevancy of fraud detection in account takeover fraud in online financial transactions is at it’s peak. The traditional fraud detection approaches have seen a downwards trend. This paper adds more onto the utilization of Biological Immune System to level an AI-based Immune system for detecting frauds and the emerging patterns within it’s domain. By implementing various machine learning algorithms such as negative and clonal selection the proposed system can accurately identify previously unknown fraud patterns and various attack strategies used by the unauthorized users and hackers. The integration of this approach seems promising in improving the security and enhancing the dependability of the transactions, hence, safeguarding people from account takeover fraud.},
  keywords={Machine learning algorithms;Computer hacking;Artificial immune systems;Market research;Biology;Fraud;Security;Artificial intelligence;Artificial Immune system(AIS);Fraud Detection (FD);Biological Immune System principles(BISP);online financial transaction fraud;negative selection algorithm;clonal selection algorithm},
  doi={10.1109/IITCEE64140.2025.10915298},
  ISSN={},
  month={Jan},}@ARTICLE{11052217,
  author={Patro, Peetabas and Das, Tapan Kumar},
  journal={IEEE Access}, 
  title={Artificial Intelligence in Action (2019-2024): A Review on Parkinson’s Disease Detection Using Non-Invasive Procedures}, 
  year={2025},
  volume={13},
  number={},
  pages={116586-116605},
  abstract={Alzheimer’s disease, Parkinson’s disease (PD), multiple sclerosis, epilepsy, and stroke are among the most significant neurological disorders. This paper focuses on PD. Although there is currently no cure for PD, early identification can help manage the condition. We present a comprehensive review of cutting-edge research on computerized methods for detecting and monitoring Parkinson’s disease. Our study covers various feature extraction techniques, methods for reducing dimensionality, feature selection approaches, and classification strategies related to PD. The articles reviewed were chosen from various journals, from January 2019 to September 2024, based on the data sources and symptoms used to diagnose PD. We conducted a thorough analysis and documented information about datasets, software tools, and libraries for future use of researchers in this field.},
  keywords={Diseases;Motors;Systematic literature review;Neurological diseases;Magnetic resonance imaging;Deep learning;Databases;Rigidity;Muscles;Monitoring;Neurological disorder;Parkinson’s disease;deep learning;non-invasive technique;machine learning},
  doi={10.1109/ACCESS.2025.3583572},
  ISSN={2169-3536},
  month={},}@ARTICLE{9864654,
  author={Wang, Haixia and Zhang, Zhigang and Hu, Zhanyi and Dong, Qiulei},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={SAR-to-Optical Image Translation With Hierarchical Latent Features}, 
  year={2022},
  volume={60},
  number={},
  pages={1-12},
  abstract={Due to the all-weather and all-time imaging capability of synthetic aperture radar (SAR), SAR remote sensing analysis has attracted much attention recently. However, compared with the optical images, SAR images are more difficult to be interpreted. If an SAR image could be translated into its corresponding optical image, then the generated optical image would be helpful for assisting the interpretation. Addressing this issue, we investigate how to translate SAR images into optical ones in this work and propose a parallel generative adversarial model for SAR-to-optical image translation, called parallel generative adversarial network (Parallel-GAN), consisting of a backbone image translation subnetwork and an adjoint optical image reconstruction subnetwork. Under the proposed model, the backbone image translation subnetwork is designed to translate SAR images into optical ones, and simultaneously some of its intermediate layers are required to output similar latent features to those from the corresponding layers of the adjoint image reconstruction subnetwork. Thanks to the imposed hierarchical latent optical features, the proposed Parallel-GAN could achieve the SAR-to-optical image translation effectively. Extensive experimental results on three public datasets demonstrate that the proposed method outperforms ten state-of-the-art methods for SAR-to-optical image translation.},
  keywords={Optical imaging;Optical sensors;Image reconstruction;Radar polarimetry;Adaptive optics;Optical design;Synthetic aperture radar;Parallel generative adversarial model;SAR;synthetic aperture radar (SAR)-to-optical image translation},
  doi={10.1109/TGRS.2022.3200996},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{9664950,
  author={Ukwuoma, Chiagoziem C. and Belal Bin Heyat, Md and Masadeh, Mahmoud and Akhtar, Faijan and Zhiguang, Qin and Bondzie - Selby, Emmanuel and AlShorman, Omar and Alkahtani, Fahad},
  booktitle={2021 International Conference on Microelectronics (ICM)}, 
  title={Image Inpainting and Classification Agent Training Based on Reinforcement Learning and Generative Models with Attention Mechanism}, 
  year={2021},
  volume={},
  number={},
  pages={96-101},
  abstract={What distinguishes the field of artificial intelligence (AI) from others is to develop fully independent agents that learn optimal behavior, change, and evolve solely through the communication of trial and error with the surrounding environment. Reinforcement learning (RL) can be seen in multiple aspects of Machine Learning (ML), provided the environment, reward, actions, the state will be defined. Agent training in previous years is seen to only relate to robotics, games, and self-driving cars. While trying to divert the focus of researchers from the view of self-driving cars, games, robots, etc. Here, we investigated using reinforcement learning in the aspect of task completion. We deployed our architecture in an inpainting task where the agent generates the distorted or missing image content into an eminent fidelity completed the image by using reinforcement learning to influence the generative model utilized. The Generative Adversary Network (GAN) problem of not being steady and challenging to train was overwhelmed by utilizing latent space representation. The dimension is reduced compared to the distorted or corrupted image in training the GAN. Then reinforcement learning was deployed to pick the correct GAN input to get the image’s latent space representation that is most suitable for the current input of the missing or distorted image region. In this paper, we also learned that the trained agent enhances the accuracy in a classification task of images with missing data. We successfully examined the classification enhancement on images missing 30%, 50%, and 70%.},
  keywords={Training;Pipelines;Reinforcement learning;Games;Generative adversarial networks;Real-time systems;Autonomous automobiles;Reinforcement Learning;Generative Adversary Networks;Object Classification;Image Inpainting;Attention Mechanism},
  doi={10.1109/ICM52667.2021.9664950},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11148893,
  author={Xing, Xiaoyu and Lu, Dingyi and Yang, Peng and Cao, Xianbin and Xiong, Zehui and Quek, Tony Q. S.},
  booktitle={2025 IEEE/CIC International Conference on Communications in China (ICCC)}, 
  title={Generative AI Agent Empowered Multi-User Beamforming Design for HAP Downlink Communications}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The high altitude platform (HAP) network has emerged as an essential network component of the emerging sixth-generation of mobile communication systems. This paper investigates the power consumption optimization for HAP downlink communications with the assistance of a designed generative artificial intelligence (AI) framework. The AI architecture incorporates the unique operational characteristics of the HAP network. Assisted by the AI agent, a beamforming optimization problem is formulated to enhance user quality of service (QoS) and improve the energy efficiency (EE) of HAP downlink communications. A QoS-enhanced energy-efficient (Q3E) beamforming algorithm is proposed to solve this problem. The Q3E algorithm employs an artificial neural network architecture without training by supervised datasets to accelerate the solution of the beamforming problem. The simulation results demonstrate that the proposed Q3E algorithm achieves significant performance improvements compared to benchmarks. Index Terms-High altitude platform (HAP), HAP communications, generative AI agent, beamforming},
  keywords={Training;Power demand;Array signal processing;Generative AI;Simulation;Quality of service;Downlink;Mobile communication;Energy efficiency;Optimization},
  doi={10.1109/ICCC65529.2025.11148893},
  ISSN={2377-8644},
  month={Aug},}@INPROCEEDINGS{11093463,
  author={Gao, Bingjie and Gao, Xinyu and Wu, Xiaoxue and Zhou, Yujie and Qiao, Yu and Niu, Li and Chen, Xinyuan and Wang, Yaohui},
  booktitle={2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={The Devil is in the Prompts: Retrieval-Augmented Prompt Optimization for Text-To-Video Generation}, 
  year={2025},
  volume={},
  number={},
  pages={3173-3183},
  abstract={The evolution of Text-To-video (T2V) generative models, trained on large-scale datasets, has been marked by significant progress. However, the sensitivity of T2V generative models to input prompts highlights the critical role of prompt design in influencing generative outcomes. Prior research has predominantly relied on Large Language Models (LLMs) to align user-provided prompts with the distribution of training prompts, albeit without tailored guidance encompassing prompt vocabulary and sentence structure nuances. To this end, we introduce RAPO, a novel Retrieval-Augmented Prompt Optimization framework. In order to address potential inaccuracies and ambiguous details generated by LLM-generated prompts. RAPO refines the naive prompts through dual optimization branches, selecting the superior prompt for T2V generation. The first branch augments user prompts with diverse modifiers extracted from a learned relational graph, refining them to align with the format of training prompts via a fine-tuned LLM. Conversely, the second branch rewrites the naive prompt using a pre-trained LLM following a well-defined instruction set. Extensive experiments demonstrate that RAPO can effectively enhance both the static and dynamic dimensions of generated videos, demonstrating the significance of prompt optimization for user-provided prompts. Project website: GitHub.},
  keywords={Training;Vocabulary;Sensitivity;Large language models;Instruction sets;Refining;Pattern recognition;Text to video;Optimization;Software development management;text-to-video;prompt optimization},
  doi={10.1109/CVPR52734.2025.00302},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{8396200,
  author={Yin, Chuanlong and Zhu, Yuefei and Liu, Shengli and Fei, Jinlong and Zhang, Hetong},
  booktitle={2018 International Conference on Artificial Intelligence and Big Data (ICAIBD)}, 
  title={An enhancing framework for botnet detection using generative adversarial networks}, 
  year={2018},
  volume={},
  number={},
  pages={228-234},
  abstract={The botnet, as one of the most formidable threats to cyber security, is often used to launch large-scale attack sabotage. How to accurately identify the botnet, especially to improve the performance of the detection model, is a key technical issue. In this paper, we propose a framework based on generative adversarial networks to augment botnet detection models (Bot-GAN). Moreover, we explore the performance of the proposed framework based on flows. The experimental results show that Bot-GAN is suitable for augmenting the original detection model. Compared with the original detection model, the proposed approach improves the detection performance, and decreases the false positive rate, which provides an effective method for improving the detection performance. In addition, it also retains the primary characteristics of the original detection model, which does not care about the network payload information, and has the ability to detect novel botnets and others using encryption or proprietary protocols.},
  keywords={Botnet;Generators;Machine learning;Feature extraction;Gallium nitride;Training;Protocols;generative adversarial networks;botnet;botnet detection;deep learning;anomaly detection},
  doi={10.1109/ICAIBD.2018.8396200},
  ISSN={},
  month={May},}@ARTICLE{10077779,
  author={de Araujo-Filho, Paulo Freitas and Naili, Mohamed and Kaddoum, Georges and Fapi, Emmanuel Thepie and Zhu, Zhongwen},
  journal={IEEE Transactions on Network and Service Management}, 
  title={Unsupervised GAN-Based Intrusion Detection System Using Temporal Convolutional Networks and Self-Attention}, 
  year={2023},
  volume={20},
  number={4},
  pages={4951-4963},
  abstract={Fifth-generation (5G) networks provide connectivity to a massive number of devices and boost a plethora of applications in several different domains. However, the large adoption of connected devices increases attack surfaces and introduces several security threats that can severely damage physical objects and risk people’s lives. Despite existing intrusion detection systems (IDSs), there are still several challenges to be addressed in the detection of cyber-attacks. For instance, while unsupervised IDSs are required to detect zero-day attacks, they usually present high false positive rates. Moreover, most existing IDSs rely on long short-term memory (LSTM) networks to consider time-dependencies among data. However, LSTM networks have recently been shown to present several drawbacks and limitations, which put into question their performance on sequence modeling tasks. Thus, in this paper, we investigate generative adversarial networks (GANs), a promising unsupervised approach to detecting attacks by implicitly modeling systems, and alternatives to LSTM networks to consider temporal dependencies among data. We propose a novel unsupervised GAN-based IDS that uses temporal convolutional networks (TCNs) and self-attention to detect cyber-attacks. The proposed IDS leverages edge computing and is proposed for edge servers, which bring computation resources closer to end nodes. Experiment results show that our proposed IDS can be configured to satisfy different detection rate and detection time requirements. Moreover, they show that our IDS is more accurate and at least 3.8 times faster than two state-of-the-art GAN-based IDSs that are used as baselines.},
  keywords={Generative adversarial networks;Cyberattack;Computer architecture;Internet of Things;Security;Internet;Anomaly detection;Intrusion detection system (IDS);Internet of Things (IoT);machine learning;generative adversarial network (GAN);temporal convolutional network (TCN);self-attention},
  doi={10.1109/TNSM.2023.3260039},
  ISSN={1932-4537},
  month={Dec},}@ARTICLE{9756577,
  author={Freitas de Araujo-Filho, Paulo and Kaddoum, Georges and Naili, Mohamed and Fapi, Emmanuel Thepie and Zhu, Zhongwen},
  journal={IEEE Communications Letters}, 
  title={Multi-Objective GAN-Based Adversarial Attack Technique for Modulation Classifiers}, 
  year={2022},
  volume={26},
  number={7},
  pages={1583-1587},
  abstract={Deep learning is increasingly being used for many tasks in wireless communications, such as modulation classification. However, it has been shown to be vulnerable to adversarial attacks, which introduce specially crafted imperceptible perturbations, inducing models to make mistakes. This letter proposes an input-agnostic adversarial attack technique that is based on generative adversarial networks (GANs) and multi-task loss. Our results show that our technique reduces the accuracy of a modulation classifier more than a jamming attack and other adversarial attack techniques. Furthermore, it generates adversarial samples at least 335 times faster than the other techniques evaluated, which raises serious concerns about using deep learning-based modulation classifiers.},
  keywords={Modulation;Perturbation methods;Wireless communication;Generators;Generative adversarial networks;Receivers;Task analysis;Adversarial attacks;wireless security;modulation classification;deep learning;generative adversarial networks},
  doi={10.1109/LCOMM.2022.3167368},
  ISSN={1558-2558},
  month={July},}@ARTICLE{10795179,
  author={Joubaud, Dorian and Kubler, Sylvain and Lourenço, Raoni and Cordy, Maxime and Le Traon, Yves},
  journal={IEEE Access}, 
  title={Decision Support Model for Time Series Data Augmentation Method Selection}, 
  year={2024},
  volume={12},
  number={},
  pages={196553-196566},
  abstract={Data augmentation (DA) plays a crucial role in machine learning by improving model generalization and tackling data scarcity issues, particularly prevalent in domains with limited access to sensitive information or rare events. Despite the availability of various DA techniques for handling imbalanced time-series classification (ITSC) problems, there is a lack of comprehensive guidelines for selecting the most appropriate technique based on input data features and the chosen classifier. This paper empirically demonstrates the limitations of conventional data balancing practices through experiments conducted on 720 ITSC datasets, using 7 classifier architectures and 6 DA techniques (TimeGAN, SMOTE, ADASYN, Random Oversampling, Jittering, Time Warping). Our study not only explores the relationship between DA techniques and the inherent characteristics of ITSC datasets and classifiers but also introduces a novel ML-based decision support system, BALANCER (imBALanced AugmeNtation reCommendER), which has been trained based on empirical data to offer an automated approach for ML practitioners to select the most appropriate DA method for their own/specific application. BALANCER’s recommendation model comes with a prediction of the performance enhancement that is expected from data balancing using the recommended method. Evaluation of BALANCER against traditional mean rank recommendations reveals significant improvements, with BALANCER achieving an average Kendall’s tau of 0.36 (compared to −0.01 for traditional mean rank recommendations) and a root mean square error of  $1.5\times 10^{-2}$  on individual predictions. The reasons behind the notable disparity in results between the mean rank recommendation strategy and BALANCER are analyzed using eXplainable AI (XAI), demonstrating that BALANCER can uncover deeper and more complex feature interactions compared to a mean rank recommendation-like strategy.},
  keywords={Feature extraction;Benchmark testing;Data models;Data augmentation;Artificial neural networks;Computer architecture;Computational modeling;Complexity theory;Adaptation models;Synthetic data;Imbalanced time-series classification;data augmentation;oversampling;synthetic data;machine learning;artificial intelligence},
  doi={10.1109/ACCESS.2024.3516369},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10603328,
  author={Huang, Chihan},
  booktitle={2024 4th International Conference on Computer Communication and Artificial Intelligence (CCAI)}, 
  title={INTJ: A Two-Stage Generative Adversarial Network for Cultural Image Restoration}, 
  year={2024},
  volume={},
  number={},
  pages={87-93},
  abstract={Cultural artifacts, due to their value and prolonged deterioration, demand digital restoration. Conventional image restoration methods, tailored for images with simple and regular damages, fall short when applied directly to cultural artifact images characterized by complex texture, large irregular damages, and intricate structures. To address these challenges, we propose a novel two-stage image restoration model INTJ (Improved-UNet GAN with Two-stage and Joint-loss), based on an improved U-Net and joint loss. The U-Net's dense connection module and SE module enhance feature representation, addressing issues like significant semantic gaps, information loss, and fine-grained detail loss while improving the model's ability to capture global information. The far aggregation module in fine-grained restoration further elevates the model's capability to aggregate long-distance information. The refined joint loss ensures a focused emphasis on the reconstruction of damaged areas. Both visual and quantitative results demonstrate the INTJ model's advantages in semantic coherence, information accuracy, and visual naturalness.},
  keywords={Visualization;Semantics;Information processing;Generative adversarial networks;Generators;Image restoration;Cultural differences;image restoration;GAN;U-Net;cultural artifacts},
  doi={10.1109/CCAI61966.2024.10603328},
  ISSN={},
  month={May},}@ARTICLE{9791107,
  author={Li, Lin and Liu, Dan and Zhao, Lingyun and Zhang, Jianwei and Liu, Jinhang},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Evidence Mining for Interpretable Charge Prediction via Prompt Learning}, 
  year={2024},
  volume={11},
  number={4},
  pages={4556-4566},
  abstract={Nowadays, more and more researchers are committed to applying artificial intelligence technology to the legal field to support decision-making. Charge prediction is a subtask of legal judgment prediction (LJP). Its purpose is to analyze the fact description of natural language text and predict a charge corresponding to a case. At present, most of the research takes charge prediction as a multiclass classification task, which leads to unsatisfactory interpretation due to the weak semantic correlation between the fact descriptions and charge labels. In order to solve this problem, we propose a method of generative evidence mining based on prompt learning. Specifically, in the training phase, we reformulate the charge labels into the prompt template that we design to enhance the semantic correlation between the charge labels and the fact descriptions. In the testing phase, the charge labels are generated via the model based on prompt learning. Meanwhile, we calculate the attention score of each sentence from the multihead self-attention in the transformer encoder and choose the sentence with the highest attention score as the evidence. Our experimental results on a real dataset show that our method is better than the traditional fine-tuning-based classification method.},
  keywords={Predictive models;Law;Semantics;Visualization;Neural networks;Computational modeling;Program processors;Prompt engineering;Charge prediction;interpretability;prompt learning},
  doi={10.1109/TCSS.2022.3178551},
  ISSN={2329-924X},
  month={Aug},}@INPROCEEDINGS{10403243,
  author={Yang, Zongqing and Liu, Hanyue and Yu, Hong and Hu, Feng},
  booktitle={2023 IEEE International Conference on Medical Artificial Intelligence (MedAI)}, 
  title={Multi-View Disease-Symptom Association Prediction Based on Disease Knowledge Graph Embedding}, 
  year={2023},
  volume={},
  number={},
  pages={133-142},
  abstract={Disease symptoms are significant in disease treatment and diagnosis, as well as in developing a hierarchical model from disease phenotypes to genes to improve our understanding of complex disease causes. While previous studies have focused on genetics and proteomics, this study proposes a novel compu-tational model, MGAEMF, based on disease knowledge graph embedding for disease-symptom association (DSA) prediction (i.e., disease nodes have connections with multiple other node types). First, the disease knowledge graph is decomposed into multiple disease-related bipartite networks, form which multiple disease similarity networks and symptom similarity networks can be extracted, and the similarity networks about diseases and symptoms are separately integrated into a single similarity network. Then, the integrated disease similarity network and symptom similarity network are combined with bipartite networks built of known disease-symptom connections to generate nonlinear feature representations of diseases and symptoms using GAE. Meanwhile, the disease-symptom association matrix is calculated using a non-negative matrix factorization to provide linear feature representations of diseases and symptoms. Finally, a fully connected neural network incorporating the linear and nonlinear representations of diseases and symptoms calculates the final prediction scores for all disease-symptom pairs. During the 10-fold cross-validation experiment, the MGAEMF model outperforms other comparable methods with a superior average AUC value of 0.8372.},
  keywords={Neural networks;Knowledge graphs;Predictive models;Prediction algorithms;Data models;Reliability;Diseases;Disease-symptom associations;multiview;similarity networks;disease knowledge graphs;graph self-encoders;link prediction},
  doi={10.1109/MedAI59581.2023.00026},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10632916,
  author={Zhai, Mingwei and Wang, Hongpeng and Han, Jianda and Wu, Tingting and Ye, Hongwei},
  booktitle={2024 IEEE International Conference on Mechatronics and Automation (ICMA)}, 
  title={Generating PET images from low-dose data using a cycle PET reconstruction convolutional neural network}, 
  year={2024},
  volume={},
  number={},
  pages={369-374},
  abstract={A high-quality PET image usually requires the injection of a sufficient amount of radiotracer, which increases the risk of radiation exposure to the examinee and medical staff. Therefore, performing PET scanning with a reduced injection dose has broad application in clinical practice. However, low-dose PET data can cause problems in the reconstruction process, such as increased noise and degraded image quality. To address these issues, we adopt the idea of a back-projection filter (BPF) based on deep learning methods to reconstruct images. First, the raw data is back-projected (BP) to generate a low-dose BP (LDBP) image, as the PET sinogram is quite large. Second, a cycle PET reconstruction convolutional neural network (CPR-CNN) is introduced to realize a reconstruction process from a LDBP image to a deep learning-based full-dose PET (DL-FDPET) image. CPR-CNN employs two reconstruction models to separately learn bidirectional mappings between pairs of input images to enhance the image reconstruction performance. Our proposed CPR-CNN achieves comparable results in maintaining resolution and denoising of DL-FDPET images.},
  keywords={Mechatronics;Noise reduction;Noise;Neural networks;Positrons;Convolutional neural networks;Positron emission tomography;Positron emission tomography;Low-dose;Image reconstruction;Cycle consistency;Convolutional neural network},
  doi={10.1109/ICMA61710.2024.10632916},
  ISSN={2152-744X},
  month={Aug},}@ARTICLE{10877794,
  author={Yang, Jae-Won and Hong, Seungbin and Sim, Jae-Young},
  journal={IEEE Access}, 
  title={Lifelong Person Search}, 
  year={2025},
  volume={13},
  number={},
  pages={27359-27370},
  abstract={Person search is the task to localize a query person in gallery datasets of scene images. Existing methods have been mainly developed to handle a single target dataset only, however diverse datasets are continuously given in practical applications of person search. In such cases, they suffer from the catastrophic knowledge forgetting in the old datasets when trained on new datasets. In this paper, we first introduce a novel problem of lifelong person search (LPS) where the model is incrementally trained on the new datasets while preserving the knowledge learned in the old datasets. We propose an end-to-end LPS framework that facilitates the knowledge distillation to enforce the consistency learning between the old and new models by utilizing the prototype features of the foreground persons as well as the hard background proposals in the old domains. Moreover, we also devise the rehearsal-based instance matching to further improve the discrimination ability in the old domains by using the unlabeled person instances additionally. Experimental results demonstrate that the proposed method achieves significantly superior performance of both the detection and re-identification to preserve the knowledge learned in the old domains compared with the existing methods.},
  keywords={Feature extraction;Proposals;Data models;Training;Prototypes;Object detection;Search problems;Adaptation models;Solid modeling;Pedestrians;Person search;person re-identification;lifelong learning;continual learning},
  doi={10.1109/ACCESS.2025.3539927},
  ISSN={2169-3536},
  month={},}@ARTICLE{10786996,
  author={Gebreab, Senay and Musamih, Ahmad and Salah, Khaled and Jayaraman, Raja and Boscovic, Dragan},
  journal={IEEE Access}, 
  title={Accelerating Digital Twin Development With Generative AI: A Framework for 3D Modeling and Data Integration}, 
  year={2024},
  volume={12},
  number={},
  pages={185918-185936},
  abstract={Digital twins (DTs) have been introduced as valuable tools for digitally representing physical objects or assets. However, developing comprehensive and accurate DTs remains challenging due to the complexity of adding diverse data sources, creating realistic models, and enabling real-time synchronization. In this paper, we propose a DT framework that uses Generative Artificial Intelligence (GenAI) techniques integrated into the DT development pipeline to address these challenges and accelerate the creation of these virtual representations. We demonstrate how 3D generative models utilizing pre-trained 2D diffusion models, and Large Language Models (LLMs) can automate and accelerate key stages of the DT development process, which include 3D modeling, data acquisition and integration, as well as simulation and monitoring. By providing a use-case scenario of a smart medical cooler box, we demonstrate the effectiveness of the proposed framework, highlighting the potential of GenAI to reduce manual effort and streamline the integration of DT components. In particular, we illustrate how it can accelerate the creation of 3D models for DTs from 2D images by using 2D-to-3D generative models. Additionally, we show the use of LLM-based agents in automating the integration of data sources with a DT and connecting physical devices with their virtual counterparts. Challenges related to computational scalability, data privacy, and model hallucinations are highlighted, which need to be addressed for the widespread adoption of GenAI in DT development.},
  keywords={Three-dimensional displays;Solid modeling;Data models;Rendering (computer graphics);Monitoring;Computational modeling;Adaptation models;Accuracy;Surface treatment;Soft sensors;Generative AI;large language models;3D generative models;diffusion models;digital twin},
  doi={10.1109/ACCESS.2024.3514175},
  ISSN={2169-3536},
  month={},}@ARTICLE{10757328,
  author={Zhang, Shuhang and Jiang, Shuai and Lin, Wanjie and Fang, Zheng and Liu, Kangjun and Zhang, Hongliang and Chen, Ke},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Generative AI on SpectrumNet: An Open Benchmark of Multiband 3-D Radio Maps}, 
  year={2025},
  volume={11},
  number={2},
  pages={886-901},
  abstract={Radio map is an efficient demonstration for visually displaying the wireless signal coverage within a certain region. It has been considered to be increasingly helpful for the future sixth generation (6G) of wireless networks, as wireless nodes are becoming more crowded and complicated. However, the construction of high resolution radio map is very challenging due to the sparse sampling in practical systems. Generative artificial intelligence (AI), which is capable to create synthetic data to fill in gaps in real-world measurements, is an effective technique to construct high precision radio maps. Currently, generative models for radio map construction are trained with two-dimension (2D) single band radio maps in urban scenario, which has poor generalization in diverse terrain scenarios, spectrum bands, and heights. To tackle this problem, we provide a multiband three-dimension (3D) radio map dataset with consideration of terrain and climate information, named SpectrumNet. It is the largest radio map dataset in terms of dimensions and scale, which contains the radio map of 3 spacial dimensions, 5 frequency bands, 11 terrain scenarios, and 3 climate scenarios. We introduce the parameters and settings for the SpectrumNet dataset generation, and evaluate four baseline methods for radio map construction based on the SpectrumNet dataset. Experiments show the necessity of the SpectrumNet dataset for training models with strong generalization in spacial, frequency, and terrain scenario domains. Future works on the SpectrumNet dataset are also discussed, including the dataset expansion and calibration, as well as the extended studies on generative models for radio map construction based on the SpectrumNet dataset.},
  keywords={Meteorology;Accuracy;Sensors;Radio transmitters;Radio propagation;Frequency-domain analysis;Training;Wireless networks;Three-dimensional displays;Solid modeling;Radio map;dataset;generative AI;terrain information},
  doi={10.1109/TCCN.2024.3502492},
  ISSN={2332-7731},
  month={April},}@INPROCEEDINGS{10716298,
  author={Marques, Adriell Gomes and Candido de Figueiredo, Marcus Vinicius and da Costa Nascimento, José Jerovane and de Souza, Cidcley Teixeira and Jaborandy de Mattos Dourado Junior, Carlos Mauricio and de Albuquerque, Victor Hugo C. and de Freitas Souzal, Luís Fabrício},
  booktitle={2024 37th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)}, 
  title={New Approach Generative AI Melanoma Data Fusion for Classification in Dermoscopic Images with Large Language Model}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Skin cancer is a disease that causes thousands of deaths each year. Early diagnosis and monitoring the progression of the disease are crucial factors for the treatment and health indicators of a society. This study presents an innovative approach for the detection, segmentation, and classification of melanomas in dermoscopic images using advanced Computer Vision and Artificial Intelligence (AI) methods. Specifically, it applies Large Language Model (LLM) solutions for pre-diagnosis results through generative AI. This work explores combinations of methods for melanoma detection and segmentation based on the YOLO and SAM architectures, achieving 99% accuracy, surpassing various studies in the literature. The classification phase is based on a pipeline integrating feature extraction and selecting the best combination for melanoma region classification, achieving an accuracy of 86.0%, also outperforming different studies in the literature.},
  keywords={YOLO;Image segmentation;Accuracy;Generative AI;Malignant tumors;Large language models;Transfer learning;Pipelines;Feature extraction;Diseases},
  doi={10.1109/SIBGRAPI62404.2024.10716298},
  ISSN={2377-5416},
  month={Sep.},}@INPROCEEDINGS{11135936,
  author={N, Manikandan and Lodh, Shayaree and Kumar, Chekuri Yaswanth and K, Sisnu S. and Reddy, Thigulla Sai Varun and D, Ruby},
  booktitle={2025 International Conference on Sensors and Related Networks (SENNET) Special Focus on Digital Healthcare(64220)}, 
  title={Beyond The Chart: AI-powered Storytelling in Business Intelligence Dashboards}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={In the current data-driven era, stakeholders often face challenges in interpreting static and complex datasets using conventional business intelligence (BI) tools. These systems typically lack personalization, dynamic interaction, and predictive capabilities, limiting their accessibility for non-technical users. This paper introduces a novel AI-powered BI dashboard that integrates Long Short-Term Memory (LSTM) neural networks for future prediction, dynamic graph generation, and generative AI for automated insight extraction. The platform transforms raw data into interactive visualizations and human-readable narratives, enabling users to easily explore trends and make data-driven decisions. Its scalable architecture supports domain-specific customization, enhancing usability across industries. The proposed system redefines BI tools by combining predictive analytics, advanced visualization, and natural language generation—bridging the gap between complex data and human understanding.},
  keywords={Neural networks;Data visualization;Transforms;Predictive models;Market research;Business intelligence;Stakeholders;Predictive analytics;Usability;Long short term memory;LSTM neural networks;predictive analytics;dynamic graph generation;automated insight extraction;interactive visualizations;human-readable narratives;data-driven decision-making;data interpretation},
  doi={10.1109/SENNET64220.2025.11135936},
  ISSN={},
  month={July},}@ARTICLE{10531779,
  author={Zhu, Fenghao and Wang, Xinquan and Huang, Chongwen and Alhammadi, Ahmed and Chen, Hui and Zhang, Zhaoyang and Yuen, Chau and Debbah, Mérouane},
  journal={IEEE Wireless Communications Letters}, 
  title={Beamforming Inferring by Conditional WGAN-GP for Holographic Antenna Arrays}, 
  year={2024},
  volume={13},
  number={7},
  pages={2023-2027},
  abstract={The beamforming technology with large holographic antenna arrays is one of the key enablers for the next generation of wireless systems, which can significantly improve the spectral efficiency. However, the deployment of large antenna arrays implies high algorithm complexity and resource overhead at both receiver and transmitter ends. To address this issue, advanced technologies such as artificial intelligence have been developed to reduce beamforming overhead. Intuitively, if we can implement the near-optimal beamforming only using a tiny subset of the all channel information, the overhead for channel estimation and beamforming would be reduced significantly compared with the traditional beamforming methods that usually need full channel information and the inversion of large dimensional matrix. In light of this idea, we propose a novel scheme that utilizes Wasserstein generative adversarial network with gradient penalty to infer the full beamforming matrices based on very little of channel information. Simulation results confirm that it can accomplish comparable performance with the weighted minimum mean-square error algorithm, while reducing the overhead by over 50%.},
  keywords={Array signal processing;Antenna arrays;Generators;Decoding;Training;MIMO communication;Generative adversarial networks;Beamforming;beam inferring;artificial intelligence;holographic antenna arrays;generative adversarial networks},
  doi={10.1109/LWC.2024.3402102},
  ISSN={2162-2345},
  month={July},}@INPROCEEDINGS{10724410,
  author={Kanchana Devi, V and Sreenivas, R and Umamaheshwari, E and Bacanin, Nebojsa},
  booktitle={2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Adversarial Auto-Encoders Based Model for Classification of Speech Dysarthria}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Communication is effective based on various parameters, out of which phonetic or oral communication plays a vital role. Slurred speech or improper speech will lead to misunderstanding in speech, which could toss up any situation. There are many people, ranging from children to adults, who are affected with slurred speech, which is technically termed as Speech Dysarthria, a disease which tampers effective oral communication. Distinguishing between people affected with dysarthria and people with normal speech will be tedious process manually. Machine Learning (ML), and Artificial Intelligence (AI), can be pitched in to solve the problem. There are existing methodologies which classify people affected with speech dysarthria and people who communicate in a normal way. Some of the existing technologies used are Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), and so on. This paper aims at distinguishing between people affected with speech dysarthria and people with normal speech, using Adversarial Auto Encoders (AAE), a model which has its roots from Variational Auto Encoders (VAE) and Generative Adversarial Networks (GAN). This paper brings out a good result and proves to be effective.},
  keywords={Recurrent neural networks;Computational modeling;Machine learning;Phonetics;Speech;Generative adversarial networks;Distance measurement;Convolutional neural networks;Speech processing;Diseases;Speech Dysarthria;Artificial Intelligence;Machine Learning;Adversarial Auto Encoders;Variational Auto Encoders;Generative Adversarial Networks},
  doi={10.1109/ICCCNT61001.2024.10724410},
  ISSN={2473-7674},
  month={June},}@INPROCEEDINGS{10920815,
  author={Ruengsurat, Satida and Eawsivigoon, Jaimai and Sookplang, Vidchaphol and Sumongkayothin, Karin and Siritanawan, Prarinya and Beuran, Razvan and Kazunori, Kotani},
  booktitle={2025 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Human-in-the-Loop for Machine Learning in Offensive Cybersecurity}, 
  year={2025},
  volume={},
  number={},
  pages={0331-0336},
  abstract={Penetration testing is one of the methods that is used to find the exploitable vulnerabilities so that we are able to fix those vulnerabilities. Intrusion detection system is one of the defensive systems that needs to be improved all the time to prevent the intruders or the cyber criminals from bypassing the detection system and stealing important and valuable information or data. Nowadays, there are automation tools that are used to support the adversarial attack on intrusion detection systems. However, those tools may have some errors that, even if they can not be detected by intrusion detection systems, they can be seen by human experts. Including the human experts in the development of the tool therefore is a way to improve the attack performance and decrease the errors of the tool. In this study, we developed a model that mimics normal traffic behavior while also being capable of evading existing detection systems, with human expert assistance to improve the performance. The result of the experiment shows that the model successfully decreases the detection rate and the performance of the attack is up to the attack types. Moreover, with the help from the expert in developing the model and in the attack process, the errors in the tool are reduced and the performance of the attack is increased.},
  keywords={Support vector machines;Protocols;Intrusion detection;Generators;Mathematical models;Human in the loop;Behavioral sciences;Random forests;Tuning;Testing;Human-in-the-Loop;Adversarial crafted traffic;Machine learning},
  doi={10.1109/ICAIIC64266.2025.10920815},
  ISSN={2831-6983},
  month={Feb},}@INPROCEEDINGS{11156046,
  author={Kamil, Faishal and Maharani, Eleanor Maritsa and Rahmania, Rissa},
  booktitle={2025 IEEE International Conference on Artificial Intelligence for Learning and Optimization (ICoAILO)}, 
  title={ResNeXt-50 and LSTM for Deepfake Detection}, 
  year={2025},
  volume={},
  number={},
  pages={113-118},
  abstract={Deepfake technology presents a significant threat to digital security due to its increasing sophistication and potential for misuse. This research proposes a Deepfake detection model combining ResNeXt-50 32×4d for spatial feature extraction and Long Short-Term Memory (LSTM) networks for temporal analysis. A video processing pipeline was implemented to isolate and retain facial regions from each frame in the dataset. Videos were decomposed into frames, with faces detected using a pre-trained model of face recognition and frames containing faces were cropped, resized to 256×256 pixels, and saved. Only the first 150 frames per video were processed to maintain temporal order for sequential analysis, with the dataset split into training, validation, and test sets (70%, 20%, 10%). The processed frames were then passed through the ResNeXt-50 for spatial feature extraction and LSTM for temporal dependencies. Evaluated on the Celeb-DF and FaceForensics++ datasets, the model achieved peak accuracies of 99.90% and 99.13%, respectively. Future research will focus on integrating multimodal data and leveraging Explainable AI to further improve detection accuracy and interpretability.},
  keywords={Training;Deepfakes;Sequential analysis;Accuracy;Pipelines;Feature extraction;Security;Long short term memory;Faces;Optimization;Deepfake Detection;ResNeXt-5032x4d;LSTM;Celeb-DF;FaceForensics++},
  doi={10.1109/ICoAILO66760.2025.11156046},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10933152,
  author={S, Poornima and Krishnaveni, A. and Francis Raj, J. Relin and Divya, R. and Rajkumar, G. Vinoth and Sakthidevi, I.},
  booktitle={2025 4th International Conference on Sentiment Analysis and Deep Learning (ICSADL)}, 
  title={Personalised Travel Ratings using AI and Enhancing User Experience Through Multi-Dimensional Analytics}, 
  year={2025},
  volume={},
  number={},
  pages={1180-1187},
  abstract={The rapid advancements in Artificial Intelligence (AI) have enabled the development of intelligent systems for personalized travel recommendations. This study proposes a novel framework, Generative Adversarial Networks with Real-Time Analytics for Travel Experience (GAN-RATE), designed to enhance user satisfaction by integrating synthetic data generation and real-time feedback mechanisms. The GAN component addresses the challenge of sparsely rated travel attributes by generating high-quality synthetic data, while the Real- Time Analytics module evaluates user interactions and feedback to refine the recommendation process dynamically. The proposed framework considers multiple dimensions, including comfort, cleanliness, timeliness, entertainment amenities, and customer feedback, ensuring a holistic approach to travel rating prediction. Simulation analysis is conducted to compare the performance of GAN-RATE with existing algorithms. Metrics such as accuracy, mean absolute error (MAE), precision, recall, and computational efficiency are employed to evaluate system performance. Results indicate that GAN-RATE outperforms baseline models in prediction accuracy and adaptability to sparse datasets while demonstrating superior real-time response capabilities. The findings highlight the potential of GAN-RATE in improving user experience through personalized, data-driven recommendations, setting a new benchmark for AI-based travel recommendation systems.},
  keywords={Training;Adaptation models;Accuracy;Heuristic algorithms;Generative adversarial networks;Prediction algorithms;Real-time systems;User experience;Recommender systems;Synthetic data;Artificial Intelligence;Generative A dversa ria I Networks;Personalized Recommendations;Real-Time Feedback;Travel Ratings;Machine Learning},
  doi={10.1109/ICSADL65848.2025.10933152},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{11081378,
  author={Devarajan, Haripriya and Palli, Issac Sathwik Vijay and Ahammed, Azam and Kolagatla, Hemanth Reddy},
  booktitle={2025 3rd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS)}, 
  title={Deepfake Content Detection using Deep Learning Techniques}, 
  year={2025},
  volume={},
  number={},
  pages={1561-1568},
  abstract={The rapid advancement of deep learning has led to the widespread use of deepfake technology, enabling realistic media manipulations that pose significant ethical and security challenges. This paper presents a novel deepfake detection framework leveraging the usage of deep learning techniques i.e, Vision Transformers (ViTs) for Image classification, Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) for Video Classification, Librosa and Mel-Frequency Cepstral Coefficients (MFCCs) for audio classification with enhanced computational efficiency and detection accuracy. The proposed models possessed 98 percent accuracy in detecting the fake content. By optimizing deep neural network models with hardware acceleration (leveraging the use of GPU), the system effectively distinguishes between authentic and manipulated media. This research contributes to the development of robust AI-driven security measures to counter misinformation and safeguard digital integrity.},
  keywords={Deep learning;Deepfakes;Computer vision;Accuracy;Recurrent neural networks;Cepstral analysis;Computational modeling;Transformers;Convolutional neural networks;Reliability;Deepfake Detection;Vision Transformers (ViTs);Convolutional Neural Networks (CNNs);Recurrent Neural Networks (RNNs);TensorFlow;Librosa;Mel-Frequency Cepstral Coefficients (MFCCs);Deep Learning;Images;Videos;Audios;real-time detection},
  doi={10.1109/ICSSAS66150.2025.11081378},
  ISSN={},
  month={June},}@ARTICLE{10478521,
  author={Punnappurath, Abhijith and Zhao, Luxi and Abdelhamed, Abdelrahman and Brown, Michael S.},
  journal={IEEE Access}, 
  title={Advocating Pixel-Level Authentication of Camera-Captured Images}, 
  year={2024},
  volume={12},
  number={},
  pages={45839-45846},
  abstract={The authenticity of digital images posted online and shared on social media is often questioned due to the ability of photo-editing software to alter image content and generative AI methods that can produce visually compelling deepfakes. Only images directly produced by cameras are deemed unaltered and beyond suspicion, as they have not undergone any modifications. However, there is a recent trend among camera manufacturers to integrate AI-based modules into the dedicated onboard hardware, specifically the image signal processor (ISP), responsible for processing the captured sensor image into the final saved image for users. Many of these AI modules utilize perceptual or generative losses during training, which can “hallucinate” image content. While this hallucinated content often manifests as small details and textures, there are instances where these regions unintentionally impact the interpretation of the entire image. This paper aims to bring attention to this issue and advocate for in-camera strategies to validate the authenticity of camera-captured images at a pixel level. We propose the creation of an “authenticity” mask that could be stored as additional metadata with each image. This information can be extracted and overlaid on the image to easily identify the hallucinated regions. Considering the widespread implications of image authenticity (e.g., in courtroom evidence, news broadcasts, and other media forms), we anticipate that authentication metadata will become a standard practice for any ISP utilizing AI.},
  keywords={Cameras;Artificial intelligence;Authentication;Metadata;License plate recognition;Image reconstruction;Ions;Authenticity;AI camera;metadata;neural ISP;generative models;adversarial loss;perceptual loss;digital forensics},
  doi={10.1109/ACCESS.2024.3381521},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11041310,
  author={S, Govindaraj and S, Mangai and S, Nabisathul Musriya and M, Nithya and J, Shalini J and S, Thrisha},
  booktitle={2025 3rd International Conference on Artificial Intelligence and Machine Learning Applications Theme: Healthcare and Internet of Things (AIMLA)}, 
  title={Coronary Artery Disease Detection Using Deep Learning Algorithm}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Coronary artery disease (CAD) is a chronic worldwide condition that necessitates precise and timely diagnosis to successfully treat it. Deep learning algorithms, specifically Deep Convolutional Generative Adversarial Networks (DCGANs), have shown great promise in medical images by producing synthetic images of quality. It examines the use of DCGANs in the detection of CAD by learning implicit patterns from images of coronary angiograms and the differentiation between normal and pathological cases. The model is trained with actual medical images and additionally enhanced with synthetic data produced by DCGANs for improved detection accuracy. Experimental results prove the effectiveness of the model in detecting CAD, depicting the role of generative models in computerized disease diagnosis. The method presents an alternative method of CAD detection with little reliance on large annotated data and increased diagnostic accuracy.},
  keywords={Deep learning;Solid modeling;Accuracy;Computational modeling;Magnetic resonance imaging;Generative adversarial networks;Data models;Medical diagnostic imaging;Arteries;Diseases;Coronary Artery Disease (CAD);Deep Convolutional Generative Adversarial Networks (DCGANs);Medical Image Synthesis;Automated Disease Detection;Deep Learning in Healthcare},
  doi={10.1109/AIMLA63829.2025.11041310},
  ISSN={},
  month={April},}@INPROCEEDINGS{10911254,
  author={Zhou, Huan and Shen, Yue},
  booktitle={2024 6th International Conference on Robotics, Intelligent Control and Artificial Intelligence (RICAI)}, 
  title={An improved air situation assessment method based on intuitive fuzzy reasoning}, 
  year={2024},
  volume={},
  number={},
  pages={1180-1187},
  abstract={Accurately and reliably identifying and predicting the air situation under the conditions of refusal environment and strong confrontation is the prerequisite and foundation for the command and control system to make reasonable task decisions and achieve predetermined goals. In response to this situation assessment issue, this article proposes an improved air situation assessment method based on intuitive fuzzy reasoning, using basic theoretical methods such as fuzzy theory and threat assessment. Firstly, describe the problem of air situation assessment, analyze the characteristics of typical situation assessment methods, and focus on summarizing the shortcomings of current research. Furthermore, utilizing the expressive power of generative adversarial networks and fuzzy reasoning, the situation in the denied air environment is modeled, and an improved air situation evaluation method based on intuitionistic fuzzy reasoning is designed by integrating intuitionistic fuzzy set theory, three-way decision strategy, and cumulative prospect theory. The simulation results show that the proposed Generative Adversarial Intuitive Situation Assessment method can effectively evaluate the current air situation.},
  keywords={Atmospheric modeling;Simulation;Decision making;Information processing;Generative adversarial networks;Threat assessment;Robustness;Fuzzy reasoning;Robots;Intelligent control;Intuitive ambiguity;situational assessment;inferential decision-making;generative adversarial learning;deep learning},
  doi={10.1109/RICAI64321.2024.10911254},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9643199,
  author={Li, Lujun and Kürzinger, Ludwig and Watzel, Tobias and Rigoll, Gerhard},
  booktitle={2021 IEEE 33rd International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={A Global Discriminant Joint Training Framework for Robust Speech Recognition}, 
  year={2021},
  volume={},
  number={},
  pages={544-551},
  abstract={Robustness in adverse acoustic conditions is critical for practical human-machine interaction. A common solution for this problem is adding an independent speech enhancement front-end. Nonetheless, due to being trained separately from the automatic speech recognition (ASR) module, the independent enhancement front-end falls into the sub-optimum easily. Besides, the handcrafted loss function of the enhancement module tends to introduce unseen distortions, which even degrade the ASR performance. To address this concern, a promising idea of the joint training is progressively drawing more interests. Nevertheless, none of the previously proposed joint-training frameworks is built on the increasingly popular self-attention mechanism or generative adversarial architecture. This paper proposes a novel joint-training framework, concatenating a speech enhancement generative adversarial network as the front-end and a self-attention based ASR module as the back-end to be jointly trained as an extensive network, to boost the noise robustness of the end-to-end ASR system. A Sinc convolution layer is usefully merged into the speech enhancement front-end for more representative features extraction. Moreover, a discriminant component plays the role of the local guide of the enhancement module and the global guide in the joint training simultaneously, which guides the enhancement front-end to output more desirable features for the subsequent ASR module and thereby offsets the limitation of the separate training and handcrafted loss functions.Systematic experiments reveal that the proposed framework significantly overtakes other competitive solutions, especially in challenging environments.},
  keywords={Training;Visualization;Convolution;Conferences;Speech enhancement;Generative adversarial networks;Feature extraction;Sinc convolution;self-attention mechanism;generative adversarial networks;speech enhancement;joint training framework;robust speech recognition},
  doi={10.1109/ICTAI52525.2021.00088},
  ISSN={2375-0197},
  month={Nov},}@ARTICLE{9760273,
  author={Mira, Rodrigo and Vougioukas, Konstantinos and Ma, Pingchuan and Petridis, Stavros and Schuller, Björn W. and Pantic, Maja},
  journal={IEEE Transactions on Cybernetics}, 
  title={End-to-End Video-to-Speech Synthesis Using Generative Adversarial Networks}, 
  year={2023},
  volume={53},
  number={6},
  pages={3454-3466},
  abstract={Video-to-speech is the process of reconstructing the audio speech from a video of a spoken utterance. Previous approaches to this task have relied on a two-step process where an intermediate representation is inferred from the video and is then decoded into waveform audio using a vocoder or a waveform reconstruction algorithm. In this work, we propose a new end-to-end video-to-speech model based on generative adversarial networks (GANs) which translates spoken video to waveform end-to-end without using any intermediate representation or separate waveform synthesis algorithm. Our model consists of an encoder–decoder architecture that receives raw video as input and generates speech, which is then fed to a waveform critic and a power critic. The use of an adversarial loss based on these two critics enables the direct synthesis of the raw audio waveform and ensures its realism. In addition, the use of our three comparative losses helps establish direct correspondence between the generated audio and the input video. We show that this model is able to reconstruct speech with remarkable realism for constrained datasets such as GRID, and that it is the first end-to-end model to produce intelligible speech for Lip Reading in the Wild (LRW), featuring hundreds of speakers recorded entirely “in the wild.” We evaluate the generated samples in two different scenarios—seen and unseen speakers—using four objective metrics which measure the quality and intelligibility of artificial speech. We demonstrate that the proposed approach outperforms all previous works in most metrics on GRID and LRW.},
  keywords={Hidden Markov models;Task analysis;Spectrogram;Visualization;Speech recognition;Predictive models;Feature extraction;Computer vision;deep learning;end-to-end;generative adversarial networks (GANs);speech synthesis;video-to-speech},
  doi={10.1109/TCYB.2022.3162495},
  ISSN={2168-2275},
  month={June},}@INPROCEEDINGS{11011376,
  author={Chettier, Thiyagarajan Mani and Ashok Kumar Boyina, Venkata and Jorepalli, Sunil and Singh, Charanjit and Gupta, Neha},
  booktitle={2025 3rd International Conference on Advancement in Computation & Computer Technologies (InCACCT)}, 
  title={Scalable Explainable AI with a Cloud-Native Approach for Cybersecurity Threat Detection}, 
  year={2025},
  volume={},
  number={},
  pages={686-691},
  abstract={The growing complexity and number of cyber threats call for sophisticated detection approaches that provide both high performance and interpretability. The proposed hybrid AI approach (AE-RF-CNN-LSTM) is a promising hybrid up-to-date improving SEO framework for cybersecurity. All these models play a steady role in performance improvement. Autoencoders are trained to sense patterns from normal data to assist in anomaly detection, random forests help with the robustness of the model with overfitting reduction, and CNN-LSTMs assist greatly in recognizing the complex temporal dependencies in network traffic data. Experimental results show that this approach achieves substantially improved accuracy nearest neighbor anomaly detection and surpasses every single model in terms of accuracy. This hybrid framework, thus, helps to detect known and unknown cyber threats, leading to a huge decrease in false positive and false negative rates. Furthermore, integrating explainable AI (XAI) methods, including SHAP (SHapley Additive explanations) and LIME (Local Interpretable Model-Agnostic Explanations), to enhance decision interpretability. The methods enable security analysts to comprehend the most relevant features of making predictions and, therefore, trust the model and correct further cybersecurity actions. This not only allows for the improvement of defense mechanisms against cyberattacks but also builds confidence in AI-driven security solutions by providing interpretability and assurance of performance.},
  keywords={Accuracy;Explainable AI;Autoencoders;Telecommunication traffic;Threat assessment;Software;Robustness;Real-time systems;Software reliability;Anomaly detection;Scalable Explainable AI;Cloud-Native Security;Cyber Threat Intelligence;Anomaly Detection;Autoencoders;CNN-LSTM;Hybrid AI Models},
  doi={10.1109/InCACCT65424.2025.11011376},
  ISSN={},
  month={April},}@ARTICLE{10542240,
  author={Chen, Zhuo and Xu, Xudong and Yan, Yichao and Pan, Ye and Zhu, Wenhan and Wu, Wayne and Dai, Bo and Yang, Xiaokang},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={HyperStyle3D: Text-Guided 3D Portrait Stylization via Hypernetworks}, 
  year={2024},
  volume={34},
  number={10},
  pages={9997-10010},
  abstract={Portrait stylization is a long-standing task enabling extensive applications. Although 2D-based methods have made great progress in recent years, real-world applications such as metaverse and games often demand 3D content. On the other hand, the requirement of 3D data, which is costly to acquire, significantly impedes the development of 3D portrait stylization methods. In this paper, inspired by the success of 3D-aware GANs that bridge 2D and 3D domains with 3D fields as the intermediate representation for rendering 2D images, we propose a novel method, dubbed HyperStyle3D, based on 3D-aware GANs for 3D portrait stylization. At the core of our method is a hyper-network learned to manipulate the parameters of the generator in a single forward pass. It not only offers a strong capacity to handle multiple styles with a single model, but also enables flexible fine-grained stylization that affects only texture, shape, or local part of the portrait. While the use of 3D-aware GANs bypasses the requirement of 3D data, we further alleviate the necessity of style images with the CLIP model being the style guidance. We conduct an extensive set of experiments across the style, attribute, and shape, and meanwhile, measure the 3D consistency. These experiments demonstrate the superior capability of our HyperStyle3D model in rendering 3D-consistent images in diverse styles, deforming the face shape, and editing various attributes. Our project page: https://windlikestone.github.io/HyperStyle3D-website/.},
  keywords={Three-dimensional displays;Shape measurement;Generators;Solid modeling;Semantics;Deformable models;Generative adversarial networks;3D-aware GAN;style transfer;hyper-network},
  doi={10.1109/TCSVT.2024.3407135},
  ISSN={1558-2205},
  month={Oct},}@INPROCEEDINGS{11031716,
  author={Rakhmawati, Ani and Saddhono, Kundharu and Maryelliwati and Rahardi, R. Kunjana and Sultan and Pitoyo, Andri},
  booktitle={2025 International Conference on Frontier Technologies and Solutions (ICFTS)}, 
  title={The Machine as Author: Examining AI's Contribution to New Literary Genres}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={The rapid growth of artificial intelligence - especially in creative domains - has literature in its sights. This opposes the rising phenomenon of AI, which assumes a growing role as a literary coauthor, and examines its reading effect on the crystallization as well as creation of literary genres. Traditional texts are a part of human conscious, emotions and life style. But with AI-generated texts, such conventions become challenging when narrative structures, experimental aesthetics, and genre-bending compositions are introduced - things that range from narratives that upend common literary conventions. This study adopts an interdisciplinary perspective to investigate how machine-generated narratives are revolutionizing the art of creative writing. Working through outputs from language models like OpenAI's GPT family, Google's BERT and various generative tools, we start to notice some of the traits of AI fiction and poetry, which tend to be more surreal, hyperreal and posthuman than texts composed by humans. These are stories that marry humanmade prompts with algorithmic creativity, with hybrid genres that straddle author and machine. Throughout this paper, a large thread of the focus is the emergence of a form of “algorithmic literature”, which we define as the moment when the machine goes beyond being a simple tool, or perhaps even a partner in authorship, and can at times, achieve full autorship. This transformation challenges conventional ideas of authorship, originality and intellectual property. A formulation that allows the machine logic and statistical predictability to be used to completely different narrative logic and styled choices that literatures expressions no longer make. In this context we explore the implications of AI in practices such as speculative fiction, flash fiction and digital poetry. AI's ability to recognize patterns, synthesize and generate text at enormous scale and speed offers an opportunity for micro-narratives and bizarro prose that, who knows, might have been too hard for human scribes to even conceive themselves. These elements nurture creativity - they force new forms of literature to sprout up, ones that explore concepts of artificial consciousness, existential paradoxes as well as alt-reality - all topics theoretically reverberating with the essence of what AI is. It also goes on to comment on implications of AI-written content in publishing, academia, and in reception from readers.},
  keywords={Technological innovation;Text recognition;Publishing;Resists;Writing;Linguistics;Posthuman;Logic;Artificial intelligence;Creativity;AI;machine-generated texts;literary genres;authorship;creative writing;AI literature;algorithmic literature;hybrid genres;generative models;literary innovation},
  doi={10.1109/ICFTS62006.2025.11031716},
  ISSN={},
  month={March},}@ARTICLE{11134085,
  author={Zhang, Yanni and Yang, Lei and Zhu, Licai and Zhou, Caigen and Nanehkaran, Yaser A. and Wang, Jianzhong},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={A Deep Supervised Change Detection Network Based on Context-Rich Information}, 
  year={2025},
  volume={18},
  number={},
  pages={21564-21577},
  abstract={With the rapid advancement of deep learning techniques, convolutional neural network (CNN)-based change detection (CD) methods have achieved remarkable progress in remote sensing image analysis, primarily attributed to their exceptional ability to extract localized spatial features. However, these methods remain constrained by two fundamental limitations: first, restricted receptive field that hinder comprehensive contextual understanding, and second inadequate capacity for capturing long-range global dependencies. To address these challenges, we propose a deep supervised change detection network based on context-rich information (DSCRNet) featuring three innovative components: a CNN TransConv Block (CTCB), a hybrid dual-attention block (HDAB), and a multiscale-supervised module (MSM). The CTCB module synergistically integrates lightweight convolutional operations with Transformer architectures through a novel dual-branch framework. This hybrid design not only enhances CNN’s ability in local feature extraction but also leverages Transformer’s self-attention mechanism to effectively model global contextual relationships. The HDAB module enhances discriminative feature learning through two key innovations: first, spatial–channel transformation operations enabling cross-scale feature interaction, and second, a parallel attention mechanism combining channel-wise and spatial attention to produce more discriminative feature representations. The MSM introduces a parameter-free multiscale supervision mechanism that enables progressive refinement of change features through hierarchical feature fusion while maintaining computational efficiency. The experimental results and ablation studies conducted on the LEVIR-CD, CDD, and DSIFN-CD datasets indicate that the proposed DSCRNet achieves superior performance than the existing methods, attributed to the integration of the CTCB and other key modules.},
  keywords={Feature extraction;Transformers;Context modeling;Accuracy;Decoding;Computer architecture;Remote sensing;Generative adversarial networks;Attention mechanisms;Data mining;CNN-transformer;change detection (CD);context-rich information;multiscale supervise},
  doi={10.1109/JSTARS.2025.3601214},
  ISSN={2151-1535},
  month={},}@ARTICLE{10147235,
  author={Wang, Juan and Yuan, Chunfeng and Li, Bing and Deng, Ying and Hu, Weiming and Maybank, Stephen},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Self-Prior Guided Pixel Adversarial Networks for Blind Image Inpainting}, 
  year={2023},
  volume={45},
  number={10},
  pages={12377-12393},
  abstract={Blind image inpainting involves two critical aspects, i.e., “where to inpaint” and “how to inpaint”. Knowing “where to inpaint” can eliminate the interference arising from corrupted pixel values; a good “how to inpaint” strategy yields high-quality inpainted results robust to various corruptions. In existing methods, these two aspects usually lack explicit and separate consideration. This paper fully explores these two aspects and proposes a self-prior guided inpainting network (SIN). The self-priors are obtained by detecting semantic-discontinuous regions and by predicting global semantic structures of the input image. On the one hand, the self-priors are incorporated into the SIN, which enables the SIN to perceive valid context information from uncorrupted regions and to synthesize semantic-aware textures for corrupted regions. On the other hand, the self-priors are reformulated to provide a pixel-wise adversarial feedback and a high-level semantic structure feedback, which can promote the semantic continuity of inpainted images. Experimental results demonstrate that our method achieves state-of-the-art performance in metric scores and in visual quality. It has an advantage over many existing methods that assume “where to inpaint” is known in advance. Extensive experiments on a series of related image restoration tasks validate the effectiveness of our method in obtaining high-quality inpainting.},
  keywords={Convolution;Image restoration;Semantics;Watermarking;Layout;Image color analysis;Visualization;Blind image inpainting;semantic-discontinuity detection;layout map prediction;pixel generative adversarial network},
  doi={10.1109/TPAMI.2023.3284431},
  ISSN={1939-3539},
  month={Oct},}@INPROCEEDINGS{10749931,
  author={Kiourtis, Athanasios and Mavrogiorgou, Argyro and Makridis, Georgios and Kyriazis, Dimosthenis and Soldatos, John and Fatouros, Georgios and Ntalaperas, Dimitrios and Papageorgiou, Xanthi and Almeida, Bruno and Guedes, Joana and Maló, Pedro and Oliveira, Jorge and Scholze, Sebastian and Rosinha, Antonio and Reis, Joaquim and Falsetta, Matteo},
  booktitle={2024 36th Conference of Open Innovations Association (FRUCT)}, 
  title={XR5.0: Human-Centric AI-Enabled Extended Reality Applications for Industry 5.0}, 
  year={2024},
  volume={},
  number={},
  pages={314-323},
  abstract={Applications for Extended Reality (XR) are rapidly expanding across a wide range of industries, including gaming, entertainment, and healthcare. Accompanying this trend is the field of digital manufacturing, which encompasses a broad range of applications such as quick product design, remote maintenance, production process simulation, employee safety, and training. Industrial personnel may benefit from ergonomic and user-friendly cyber-representations of production processes using XR applications, particularly in the industrial arena. These cyber-representations are utilized to create augmented environments for training, simulation, and testing. The wave of Industry 5.0 (I5.0) applications that are certain to be human-centric and emphasize trustworthy human-machine collaboration cannot be supported by current systems because of several issues, such as the requirement for individualized XR visualizations and new methods for world-building, content production, and flow control aspects of XR systems. The XR5.0 project is presented in this publication with the goal of addressing these issues and offering a revolutionary Person-Centric and AI-based XR paradigm that will be customized to the needs and characteristics of I5.0 applications. The project outlines the organizing concepts and guidelines for utilizing XR in I5.0 applications, with a focus on the creation of cutting-edge "XR-made-in-Europe" technology that complements human-centered manufacturing techniques and upholds European ideals. The associated applications consider the workers’ environment through the incorporation of human-centered digital twins (DTs), which make up the "digital image" of the workers. This allows for the simultaneous design and implementation of an innovative fusion of cutting-edge AI paradigms and XR technology. The added value of the XR5.0 project is discussed, and potential use cases and user journeys are analyzed, leading to a discussion of the project’s revolutionary benefits and additional steps that should be taken.},
  keywords={Training;Visualization;Technological innovation;Extended reality;Production;Product design;Manufacturing;Safety;Fifth Industrial Revolution;Testing},
  doi={10.23919/FRUCT64283.2024.10749931},
  ISSN={2305-7254},
  month={Oct},}@INPROCEEDINGS{10674412,
  author={Chen, Tingshuai and Yuan, Ye and Yin, Bingyang},
  booktitle={2024 4th International Conference on Machine Learning and Intelligent Systems Engineering (MLISE)}, 
  title={Application of Prompt Engineering in AIGC — Taking Stable Diffusion as an Example}, 
  year={2024},
  volume={},
  number={},
  pages={465-469},
  abstract={In recent years, AIGC technology has gradually received attention from many fields. The emergence of AI painting generation tools such as Stable Diffusion has had a profound impact on the design field, especially in optimizing and simplifying the product design process. At present, prompt words are a major challenge. This article proposes a design framework for prompt word engineering, aiming to share how to quickly write prompt words that meet one's own needs based on product design concepts and creative ideas, and use Stable Diffusion to quickly achieve creative ideas and generate product design drawings. At the same time, a LoRA fine-tuning model is also trained to guide product style, and the ControlNet network is combined to control the generated content, thereby generating a series of products. Through the experience and reflection during the experimental process, we hope that this article can provide valuable reference and inspiration for peers.},
  keywords={Machine learning;Product design;Reflection;Prompt engineering;Modeling;Intelligent systems;Creativity;diffusion model;Generative artificial intelligence;Stable Diffusion;Prompt Engineering;product design},
  doi={10.1109/MLISE62164.2024.10674412},
  ISSN={},
  month={June},}@INPROCEEDINGS{10775283,
  author={Ahmad, Noor Wahyuni and Ruslan, Suzana},
  booktitle={2024 14th International Conference on System Engineering and Technology (ICSET)}, 
  title={Crafting Effective Prompts: A Guideline for Successful Image Generation}, 
  year={2024},
  volume={},
  number={},
  pages={84-89},
  abstract={AI’s ability to convert text into high-quality visuals is revolutionizing a number of study sectors, including the creative industries. This work focuses on how prompt construction plays a crucial role in maximizing large language models’ (LLMs’) efficacy in image production. While prompt engineering encompasses many study fields, this work focuses primarily on how prompts should be designed to enhance the quality of generated images utilizing prompt anatomy as input. In this study, two student groups were compared: one group produced photos on their own without any supervision, and the other group was given tips on how to make efficient suggestions. Clarity, detail, relevance, aesthetic appeal, and inventiveness were the criteria used to assess the prompts and the final photos. According to the panel of experts evaluating the results, the group who received guided prompt creation generated photos that were both much better and more in line with the intended concept. This work emphasizes how crucial good prompt design is for AI-driven image production and shows that appropriate prompt crafting training can significantly improve output quality. These results offer a foundation for the more efficient application of AI technologies and have important ramifications for AI-assisted design, education, and the creative industries.},
  keywords={Industries;Training;Visualization;Image synthesis;Text to image;Production;Systems engineering and theory;Prompt engineering;Anatomy;Guidelines;Prompt Engineering;Image Generation;Prompt anatomy;Text-to-Image;AI;Comparative Study;GANs},
  doi={10.1109/ICSET63729.2024.10775283},
  ISSN={2470-640X},
  month={Oct},}@INPROCEEDINGS{10447128,
  author={Korgialas, Christos and Pantraki, Evangelia and Kotropoulos, Constantine},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Interpretable Face Aging: Enhancing Conditional Adversarial Autoencoders with Lime Explanations}, 
  year={2024},
  volume={},
  number={},
  pages={5260-5264},
  abstract={An innovative approach is proposed that leverages a perturbation explainable system within the Conditional Adversarial Autoencoder (CAAE) framework. The incorporation of the perturbation-based explainable system in the CAAE model harnesses the explanatory power of Local Interpretable Model-Agnostic Explanations (LIME). LIME generates perturbations in the latent space of the CAAE and provides insightful explanations for the discrepancies between fake and real face images. By indicating the areas that contribute most significantly to the aging process, LIME guides the adversarial training process to focus on those aspects, resulting in corrective feedback to the discriminator. The performance of the proposed framework, against state-of-the-art methods, is assessed by objective figures of merit demonstrating superior results in face aging.},
  keywords={Training;Perturbation methods;Aging;Speech enhancement;Signal processing;Acoustics;Faces;Face Aging;Explainable Artificial Intelligence;Generative Adversarial Networks},
  doi={10.1109/ICASSP48485.2024.10447128},
  ISSN={2379-190X},
  month={April},}@ARTICLE{10832463,
  author={Kshetri, Nir and Rojas-Torres, Diana and M. Hanafi, Mamduh and Al-kfairy, Mousa and O’Keefe, Gayle and Feeney, Nathan},
  journal={IT Professional}, 
  title={Harnessing Generative Artificial Intelligence: A Game-Changer for Small and Medium Enterprises}, 
  year={2024},
  volume={26},
  number={6},
  pages={84-89},
  abstract={This article examines the rising adoption of generative AI (GAI) among small and medium enterprises (SMEs) and its potential to enhance operational efficiency and strategic decision making. Although SMEs currently lag behind larger firms in GAI integration, they increasingly utilize these tools to overcome challenges such as resource constraints and high marketing costs.},
  keywords={Productivity;Costs;Generative AI;Decision making;Finance;Customer relationship management;Personnel;Business},
  doi={10.1109/MITP.2024.3501552},
  ISSN={1941-045X},
  month={Nov},}@INPROCEEDINGS{10395736,
  author={Sowjanya, M. and Laxmi, M. and Sreelatha, B. and G, Vallathan},
  booktitle={2023 International Conference on System, Computation, Automation and Networking (ICSCAN)}, 
  title={Unsupervised Medical Image Denoising Using CycleGAN: Improving Low-Dose CT Image Quality}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Medical imaging plays a significant role in clinical diagnosis, but the use of low radiation doses in CT imaging can lead to poor image resolution and precise diagnosis. In this investigation, a novel method has been suggested to enhance low-dose CT (LDCT) images using an unsupervised deep learning model based on CycleGAN. The CycleGAN architecture enables us to perform image-to-image translation without the need for paired data, making it suitable for medical image denoising where matching high-dose CT (HDCT) images are often unavailable. Our model employs two generators for LDCT-to-HDCT and HDCT-to-LDCT translation, along with two discriminators to differentiate real and generated images in both domains. Extensive experiments demonstrate that our approach significantly improves the quality of LDCT images, yielding highfidelity HDCT-like images. This technique holds great promise for enhancing medical image quality and ultimately benefiting patient care.},
  keywords={Image quality;Measurement;PSNR;Image resolution;Computed tomography;Noise reduction;Generators;Unsupervised Learning;Medical Image Denoising;CycleGAN;Low-Dose CT;High-Dose CT;Deep Learning;Image -to -Image Translation;Generative Adversarial Network;Enhancement;Radiology;Computer Tomography;Artificial Intelligence},
  doi={10.1109/ICSCAN58655.2023.10395736},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11010332,
  author={Lau, Christina L. and Davaji, Benyamin and Ding, Shuhan and Xie, Yutong and Lal, Amit and Doerschuk, Peter C.},
  booktitle={2025 36th Annual SEMI Advanced Semiconductor Manufacturing Conference (ASMC)}, 
  title={Process-Aware Digital Twins for Nanofabrication Processes}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Digital twins are computer representations of the structure, context, and behavior of a physical system; for example, nanofabrication cleanroom process equipment such as a DUV stepper or plasma etcher. For process equipment where the input and output can be described by images, such as optical or SEM images, this paper proposes HyperPix2Pix, a deep neural network that can be trained to represent a variety of equipment, including the effects of process parameters. In this paper, we demonstrate HyperPix2Pix on DUV photolithography and plasma etch tools. Compared to previous work, HyperPix2Pix introduces structured process parameters through multimodal learning that elucidates the role of different parameters in nanofabrication processes.},
  keywords={Performance evaluation;Nanofabrication;Lithography;Optical computing;Semiconductor device manufacture;Optical fiber networks;Optical imaging;Plasmas;Digital twins;Standards;DUV photolithography;plasma etch;digital twins;machine learning;generative artificial intelligence;Pix2Pix},
  doi={10.1109/ASMC64512.2025.11010332},
  ISSN={2376-6697},
  month={May},}@INPROCEEDINGS{11081537,
  author={Freise, Nina and Heitlinger, Marius and Nuredini, Ruben and Meixner, Gerrit},
  booktitle={2025 IEEE 13th International Conference on Healthcare Informatics (ICHI)}, 
  title={IPROPS - Iterative Prompt Refinement for Optimizing Privacy-Preserving Synthetic Data Generation}, 
  year={2025},
  volume={},
  number={},
  pages={197-208},
  abstract={The integration of AI in healthcare is heavily impacted by limitations associated with medical data. Data scarcity, strict privacy regulations, and inherent biases affect the development and deployment of AI solutions in medical settings. One common strategy to combat data limitations is by generating synthetic data and utilizing it for training AI models. We introduce IPROPS—a novel framework for synthetic data generation designed specifically to address the inherent limitations of medical data. IPROPS employs advanced prompt optimization techniques that enable automatic refinement of input prompts in prompt-based models and is designed to operate without requiring direct or explicit access to real patient data. Our framework operates as an integrated pipeline with components that function in an iterative manner to generate high-quality, privacy-compliant synthetic data. To validate IPROPS and demonstrate its practical utility, we implemented and evaluated a prototype. Specifically, we applied our framework to generate synthetic German cardiology discharge letters—a complex medical text generation task requiring both clinical accuracy and strict privacy preservation. Results demonstrate the effectiveness of the actor-critic feedback loop and guided mutation strategies in iterating prompts, ultimately producing synthetic data that closely resembles real data. While opportunities for enhancement remain, the IPROPS framework offers substantial benefits, especially in domains where regulatory constraints and data access restrictions present significant barriers to AI advancement.},
  keywords={Accuracy;Computational modeling;Medical services;Brain modeling;Data models;Iterative methods;Optimization;Synthetic data;Biomedical imaging;Context modeling;iterative prompt refinement;privacy-preserving AI;prompt optimization;clinical text generation;synthetic medical data},
  doi={10.1109/ICHI64645.2025.00031},
  ISSN={2575-2634},
  month={June},}@INPROCEEDINGS{11167455,
  author={Chandra, Saurabh and Yadav, Hritesh and Aravind, S. and Saini, Rakesh Kumar and Sharma, Upasana and Katta, Siva Koteswara Rao},
  booktitle={2025 3rd International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)}, 
  title={AI and ML-based Cybersecurity Enhancement for Financial Institutions}, 
  year={2025},
  volume={},
  number={},
  pages={431-436},
  abstract={Financial institutions operating in the current period of advanced digital threats encounter more complex attacks against their critical financial resources in addition to their sensitive information. Current cybersecurity approaches have shown weak results against advanced persistent threats (APTs) which makes financial institutions require next-generation automated protection solutions. In order to strengthen their cybersecurity systems, finite institutions must integrate AI and ML. Financial entities enhance their immediate security threat detection abilities by using AI-powered automatic threat identification systems. The paper evaluates different ML algorithms like supervised learning and anomaly detection and deep learning models to detect security breaches while spotting unauthorized transactions and new threats. This paper evaluates the reduction of human errors and the accelerated response times along with the scalability which these operational techniques deliver for dynamic cyber threats. Our research includes actual financial cybersecurity framework case studies that show how AI and ML technology applies for risk management as well as fraud prevention assessment. The study demonstrates that financial institutions should implement AI and ML technologies for cybersecurity because they enhance detection while protecting their systems from upcoming cyber threats.},
  keywords={Deep learning;Recurrent neural networks;Explainable AI;Scalability;Threat assessment;Real-time systems;Fraud;Convolutional neural networks;Computer security;Anomaly detection;Cybersecurity;AI;Machine Learning;Threat Detection;Financial Institutions},
  doi={10.1109/ICSCDS65426.2025.11167455},
  ISSN={},
  month={Aug},}@INBOOK{9536362,
  author={},
  booktitle={Game Theory and Machine Learning for Cyber Security}, 
  title={Front Matter}, 
  year={2021},
  volume={},
  number={},
  pages={i-xxx},
  abstract={The prelims comprise: <list style="bulleted"> <listItem>Half&#x2010;Title Page</listItem> <listItem>Series Page</listItem> <listItem>Title Page</listItem> <listItem>Copyright Page</listItem> <listItem>Contents</listItem> <listItem>Editor Biographies</listItem> <listItem>Contributors</listItem> <listItem>Foreword</listItem> <listItem>Preface</listItem> </list>},
  keywords={},
  doi={10.1002/9781119723950.fmatter},
  ISSN={},
  publisher={IEEE},
  isbn={9781119723912},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/9536362},}@INBOOK{9933553,
  author={},
  booktitle={Deep Learning for Healthcare Decision Making}, 
  title={1 Amalgamation of Deep Learning in Healthcare Systems}, 
  year={2022},
  volume={},
  number={},
  pages={1-24},
  abstract={Health care today is known to suffer from siloed and fragmented data, delayed clinical communications, and disparate workflow tools due to the lack of interoperability caused by vendor-locked health care systems, lack of trust among data holders, and security/privacy concerns regarding data sharing. The health information industry is ready for big leaps and bounds in terms of growth and advancement. This book is an attempt to unveil the hidden potential of the enormous amount of health information and technology. Throughout this book, we attempt to combine numerous compelling views, guidelines, and frameworks to enable personalized health care service options through the successful application of deep learning frameworks. The progress of the health-care sector will be incremental as it learns from associations between data over time through the application of suitable AI, deep net frameworks, and patterns. The major challenge health care is facing is the effective and accurate learning of unstructured clinical data through the application of precise algorithms. Incorrect input data leading to erroneous outputs with false positives is intolerable in healthcare as patients&#x2019; lives are at stake. This book is written with the intent to uncover the stakes and possibilities involved in realizing personalized health-care services through efficient and effective deep learning algorithms. The specific focus of this book will be on the application of deep learning in any area of health care, including clinical trials, telemedicine, health records management, etc.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770223881},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/9933553},}@INBOOK{10566566,
  author={Desalegn, Wendwossen and Shaikh, Javed and Taye, Bayisa},
  booktitle={Methodology to Improve Control Plane Security in SDN Environments}, 
  title={5 Future Directions}, 
  year={2024},
  volume={},
  number={},
  pages={77-90},
  abstract={This Rapids book unveils a blueprint for safeguarding the very backbone of modern communication networks. It offers a roadmap towards fortifying SDN infrastructures against the relentless onslaught of cyber threats, ensuring resilience and reliability in an ever-evolving digital landscape. This is an exhaustive study of crafting a robust security solution tailored for the SDN environment, specifically targeting the detection and mitigation of distributed denial of service (DDoS) attacks on the control plane. The methodology hinges on an early detection strategy, meticulously aligned with industry standards, serving as a beacon for professionals navigating the intricate realm of implementing security solutions. This reference elucidates an innovative approach devised to identify and mitigate the inherent risks associated with the OpenFlow protocol and its POX controller. Validated through rigorous simulations conducted within controlled environments utilizing the Mininet tool and SDN controller, the methodology unfolds, showcasing the intricate dance between theory and practice. Through meticulous observation of detection algorithm results in simulated environments, followed by real-world implementation within network testbeds, the proposed solution emerges triumphant. Leveraging network entropy calculation, coupled with swift port blocking mechanisms, the methodology stands as a formidable barrier against a DDoS attack such as TCP, UDP, and ICMP floods.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770041942},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10566566},}@INPROCEEDINGS{10447380,
  author={Chung, Yoonjin and Lee, Junwon and Nam, Juhan},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={T-Foley: A Controllable Waveform-Domain Diffusion Model for Temporal-Event-Guided Foley Sound Synthesis}, 
  year={2024},
  volume={},
  number={},
  pages={6820-6824},
  abstract={Foley sound, audio content inserted synchronously with videos, plays a critical role in the user experience of multimedia content. Recently, there has been active research in Foley sound synthesis, leveraging the advancements in deep generative models. However, such works mainly focus on replicating a single sound class or a textual sound description, neglecting temporal information, which is crucial in the practical applications of Foley sound. We present T-Foley, a Temporal-event-guided waveform generation model for Foley sound synthesis. T-Foley generates high-quality audio using two conditions: the sound class and temporal event feature. For temporal conditioning, we devise a temporal event feature and a novel conditioning technique named Block-FiLM. T-Foley achieves superior performance in both objective and subjective evaluation metrics and generates Foley sound well-synchronized with the temporal events. Additionally, we showcase T-Foley’s practical applications, particularly in scenarios involving vocal mimicry for temporal event control. We show the demo on our companion website.1},
  keywords={Measurement;Streaming media;Signal processing;Controllability;User experience;Acoustics;Usability;Foley Sound Synthesis;Controllable Sound Generation;General Audio Synthesis;Waveform Domain Diffusion},
  doi={10.1109/ICASSP48485.2024.10447380},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10284878,
  author={Hu, Chunhui and Chen, Jianfeng},
  booktitle={2023 International Conference on Networking and Network Applications (NaNA)}, 
  title={A Dimensional Perspective Analysis on the Cybersecurity Risks and Opportunities of ChatGPT-Like Information Systems}, 
  year={2023},
  volume={},
  number={},
  pages={324-331},
  abstract={As a recent breakthrough in generative artificial intelligence, ChatGPT is capable of creating new data, images, audio, or text content based on user context. In the field of cybersecurity, it provides generative automated AI services such as network detection, malware protection, and privacy compliance monitoring. However, it also faces significant security risks during its design, training, and operation phases, including privacy breaches, content abuse, prompt word attacks, model stealing attacks, abnormal structure attacks, data poisoning attacks, model hijacking attacks, and sponge attacks. This paper starts from the risks and events that ChatGPT has recently faced, proposes a framework for analyzing cybersecurity in cyberspace, and envisions adversarial models and systems. It puts forward a new evolutionary relationship between attackers and defenders using ChatGPT to enhance their own capabilities in a changing environment and predicts the future development of ChatGPT from a security perspective.},
  keywords={Training;Analytical models;Supply chains;Predictive models;Chatbots;Data models;Security;ChatGPT;dimensional Analysis;cyberspace security;risks and opportunities},
  doi={10.1109/NaNA60121.2023.00061},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9843668,
  author={Blasch, Erik and Shen, Dan and Chen, Genshe and Insaurralde, Carlos C. and Niu, Ruixin},
  booktitle={2022 IEEE Aerospace Conference (AERO)}, 
  title={Artificial Intelligence Fusion of Information for Aerospace (AIFIA) Systems}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={For intelligence and surveillance methods, information fusion techniques typically increase the accuracy and reliability of results through uncertainty reduction. Recently, artificial intelligence and machine learning (AI/ML) methods presented the engineering community with numerous opportunities to improve avionics controls, structural health monitoring, and platform design. Hence, alignment of traditional Fusion Integration of Sensor Harvesting (FISH) with that of AI/ML should advance aerospace performance. As such, Artificial Intelligence Fusion of Information for Aerospace (AIFIA) Systems relies on multiple sensors for systems and situation identification. This paper identifies some aerospace applications of AI enhancing information fusion methods; while outlining areas of future opportunity in aerospace systems design. The example utilizes the ESCAPE data using machine and deep learning (DL) to monitor an area, detect moving platforms, and meeting certifiable bounds.},
  keywords={Uncertainty;Surveillance;Aerospace electronics;Ontologies;Maintenance engineering;Market research;Reliability;Avionics;Information Fusion;Structural Health Monitoring},
  doi={10.1109/AERO53065.2022.9843668},
  ISSN={1095-323X},
  month={March},}@INPROCEEDINGS{9730973,
  author={Bi, Jianauan and Zhang, Guohui and Yang, Chaohong and Jin, Liya and Zhang, Wei},
  booktitle={2021 3rd International Conference on Machine Learning, Big Data and Business Intelligence (MLBDBI)}, 
  title={Architecture Design of Typical Target Detection and Tracking System in Battlefield Environment}, 
  year={2021},
  volume={},
  number={},
  pages={473-477},
  abstract={Aiming at the characteristics of small targets, few samples, many occlusions, and strong camouflage in the battlefield environment, a target detection and tracking system based on multi-source sensor data is designed. The system is mainly composed of three parts: the unmanned aerial vehicle (UAV) platform, the ground display control platform (GDCP), and the offline algorithm training platform. The offline-trained target detection and tracking algorithm is deployed in the UAV-borne AI processing chip, which can conduct the real-time detection and tracking of typical targets in the battlefield and send the results and attitude information of UAVs to the GDCP. The system can realize real-time detection of typical battlefield targets and tracking control through the GDCP.},
  keywords={Training;Target tracking;Systems architecture;Data integration;Object detection;Machine learning;Big Data;target detection;target tracking;deep learning;architecture design},
  doi={10.1109/MLBDBI54094.2021.00096},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10590364,
  author={Libin, Alexander and Treitler, Jonah T. and Shao, Yijun},
  booktitle={2023 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Evaluating and Reducing AI Model Group Disparity: An Analysis of COVID Test Outcomes in Children}, 
  year={2023},
  volume={},
  number={},
  pages={1511-1513},
  abstract={AI fairness in healthcare has attracted significant attention due to the potential risk of perpetuating health disparity. This study assessed the group parity of a set of machine learning (ML) models trained on the National Health Interview Survey data, with COVID test result as the outcome. We also experimented with the use of synthetic data to reduce group disparity. Our results suggests that group disparity is prevalent in ML models though often not statistically significant, and the use of synthetic data can sometimes enhance group parity.},
  keywords={COVID-19;Surveys;Scientific computing;Computational modeling;Medical services;Machine learning;Data models;AI fairness;group parity;machine learning;synthetic data},
  doi={10.1109/CSCI62032.2023.00248},
  ISSN={2769-5654},
  month={Dec},}@INPROCEEDINGS{11088050,
  author={Reddy, Baireddy Sreenivasa and Sathish, Anchula},
  booktitle={2025 Seventh International Conference on Computational Intelligence andCommunication Technologies (CCICT)}, 
  title={Attention-Infused U-Net Framework for Robust Brain Tumor Segmentation and Classification}, 
  year={2025},
  volume={},
  number={},
  pages={489-493},
  abstract={Brain tumor segmentation and classification are essential in medical image analysis, enabling accurate diagnosis and effective treatment planning. Manual analysis of MRI scans is time-intensive, prone to human error, and requires specialized expertise, necessitating the development of automated techniques for improved detection accuracy and patient outcomes. This study proposes a brain tumor classification model implemented in Python, integrating MultiRes U-Net with an Adaptive Inception Net. The model operates with a population size of 15 over 65 iterations, achieving high accuracy (98.4282%), sensitivity (98.4884%), specificity (98.4172%), and precision (97.4177%). Comparative evaluation against existing deep learning models demonstrates its superior performance, as evidenced by the highest F1-score (97.4384%) and Matthews Correlation Coefficient (90.8171%), along with the lowest False Discovery Rate (3.2514%). These findings emphasize the effectiveness and dependability of the MultiRes U-Net combined with the Adaptive Inception Net model in brain tumor segmentation and classification, contributing to enhanced clinical decision-making and patient outcomes.},
  keywords={Deep learning;Adaptation models;Image segmentation;Accuracy;Sensitivity;Brain tumors;Brain modeling;Transformers;Real-time systems;Reliability;MultiRes U-Net;tumor;Inception net;Accuracy;Segmentation;brain},
  doi={10.1109/CCICT65753.2025.00080},
  ISSN={},
  month={April},}@INPROCEEDINGS{8665063,
  author={Wang, Xingchao and Gao, Zenghao and Qian, Huihuan and Xu, Yangsheng},
  booktitle={2018 IEEE International Conference on Robotics and Biomimetics (ROBIO)}, 
  title={Jukepix: A Cross-Modality Approach to Transform Paintings into Music Segments}, 
  year={2018},
  volume={},
  number={},
  pages={456-461},
  abstract={The challenges in transforming paintings into music is well-known, since the relationship between two kinds of art is unclear. Different composers write different music when the same painting is presented to them. In this paper, a cross-mordality model has been proposed for transforming images into multitrack music based on the framework of deep convolutional generative adversarial networks (DCGANs). The proposed model is trained on a classical music dataset and a dataset of impressionist paintings. The model can be applied to transfer impressionist paintings into classical music with two tracks. By using music evaluation methods, the harmonicity of the generated music can be confirmed. Our model is the first attempt of our knowledge at transforming paintings into music segments.},
  keywords={Bars;Generators;Painting;Image segmentation;Training;Art;Feature extraction;Cross-modality;DCGANs;Image to Music},
  doi={10.1109/ROBIO.2018.8665063},
  ISSN={},
  month={Dec},}@ARTICLE{4359071,
  author={Tu, Zhuowen and Narr, Katherine L. and Dollar, Piotr and Dinov, Ivo and Thompson, Paul M. and Toga, Arthur W.},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Brain Anatomical Structure Segmentation by Hybrid Discriminative/Generative Models}, 
  year={2008},
  volume={27},
  number={4},
  pages={495-508},
  abstract={ In this paper, a hybrid discriminative/generative model for brain anatomical structure segmentation is proposed. The learning aspect of the approach is emphasized. In the discriminative appearance models, various cues such as intensity and curvatures are combined to locally capture the complex appearances of different anatomical structures. A probabilistic boosting tree (PBT) framework is adopted to learn multiclass discriminative models that combine hundreds of features across different scales. On the generative model side, both global and local shape models are used to capture the shape information about each anatomical structure. The parameters to combine the discriminative appearance and generative shape models are also automatically learned. Thus, low-level and high-level information is learned and integrated in a hybrid model. Segmentations are obtained by minimizing an energy function associated with the proposed hybrid model. Finally, a grid-face structure is designed to explicitly represent the 3-D region topology. This representation handles an arbitrary number of regions and facilitates fast surface evolution. Our system was trained and tested on a set of 3-D magnetic resonance imaging (MRI) volumes and the results obtained are encouraging. },
  keywords={Anatomical structure;Hybrid power systems;Brain modeling;Shape;Magnetic resonance imaging;Image segmentation;Protocols;Biomedical imaging;Boosting;Neuroimaging;Brain anatomical structures;discriminative models;generative models;probabilistic boosting tree (PBT);segmentation;Brain anatomical structures;discriminative models;generative models;probabilistic boosting tree;segmentation},
  doi={10.1109/TMI.2007.908121},
  ISSN={1558-254X},
  month={April},}@ARTICLE{9528933,
  author={Liu, Xiyan and Meng, Gaofeng and Xiang, Shiming and Pan, Chunhong},
  journal={IEEE Signal Processing Letters}, 
  title={Handwritten Text Generation via Disentangled Representations}, 
  year={2021},
  volume={28},
  number={},
  pages={1838-1842},
  abstract={Automatically generating handwritten text images is a challenging task due to the diverse handwriting styles and the irregular writing in natural scenes. In this paper, we propose an effective generative model called HTG-GAN to synthesize handwritten text images from latent prior. Unlike single-character synthesis, our method is capable of generating images of sequence characters with arbitrary length, which pays more attention to the structural relationship between characters. We model the structural relationship as the style representation to avoid explicitly modeling the stroke layout. Specifically, the text image is disentangled into style representation and content representation, where the style representation is mapped into Gaussian distribution and the content representation is embedded using character index. In this way, our model can generate new handwritten text images with specified contents and various styles to perform data augmentation, thereby boosting handwritten text recognition (HTR). Experimental results show that our method achieves state-of-the-art performance in handwritten text generation.},
  keywords={Training;Gaussian distribution;Text recognition;Image reconstruction;Task analysis;Generators;Convolution;Handwritten text generation;disentangled representation;generative adversarial networks;deep learning},
  doi={10.1109/LSP.2021.3109541},
  ISSN={1558-2361},
  month={},}@ARTICLE{9920543,
  author={Egbert, Austin and Baylis, Charles and Marks, Robert J.},
  journal={IEEE Transactions on Microwave Theory and Techniques}, 
  title={Extrapolation of Load-Pull Data: A Novel Use of GAN Artificial Intelligence Image Completion}, 
  year={2022},
  volume={70},
  number={11},
  pages={4849-4856},
  abstract={Amplifier design, both in traditional approaches and real-time circuit optimization, greatly benefits from fast and thorough extraction of information from measurement data. Using only a few performance samples at varying impedances, deep learning image completion techniques can be utilized to extrapolate an entire set of Smith chart load-pull contours. In addition to speeding nonlinear device characterizations, this extrapolation can be performed in an iterative fashion for use as a circuit optimization algorithm with a very low number of measurements. The techniques of this work have been tested in the measurement of a nonlinear, large-signal amplifier. The load impedance can be estimated with a typical error of < 0.1 linear units using as few as seven impedances and yields even better accuracy with larger sample sizes.},
  keywords={Extrapolation;Generators;Performance evaluation;Impedance measurement;Impedance;Power measurement;Load modeling;Artificial neural networks;circuit optimization;machine learning algorithms;measurement techniques;power amplifiers},
  doi={10.1109/TMTT.2022.3209700},
  ISSN={1557-9670},
  month={Nov},}@ARTICLE{10546311,
  author={Guo, Yuhan and Shao, Hanning and Liu, Can and Xu, Kai and Yuan, Xiaoru},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={PrompTHis: Visualizing the Process and Influence of Prompt Editing During Text-to-Image Creation}, 
  year={2025},
  volume={31},
  number={9},
  pages={4547-4559},
  abstract={Generative text-to-image models, which allow users to create appealing images through a text prompt, have seen a dramatic increase in popularity in recent years. However, most users have a limited understanding of how such models work and often rely on trial and error strategies to achieve satisfactory results. The prompt history contains a wealth of information that could provide users with insights into what has been explored and how the prompt changes impact the output image, yet little research attention has been paid to the visual analysis of such process to support users. We propose the Image Variant Graph, a novel visual representation designed to support comparing prompt-image pairs and exploring the editing history. The Image Variant Graph models prompt differences as edges between corresponding images and presents the distances between images through projection. Based on the graph, we developed the PrompTHis system through co-design with artists. Based on the review and analysis of the prompting history, users can better understand the impact of prompt changes and have a more effective control of image generation. A quantitative user study and qualitative interviews demonstrate that PrompTHis can help users review the prompt history, make sense of the model, and plan their creative process.},
  keywords={Visualization;History;Analytical models;Reviews;Interviews;Image edge detection;Navigation;Editing history;generative art;image visualization;provenance;text visualization;text-to-image generation},
  doi={10.1109/TVCG.2024.3408255},
  ISSN={1941-0506},
  month={Sep.},}@ARTICLE{10538199,
  author={Mengara, Axel Gedeon Mengara and Yoo, Younghwan and Leung, Victor C. M.},
  journal={IEEE Internet of Things Journal}, 
  title={IoTSecUT: Uncertainty-Based Hybrid Deep Learning Approach for Superior IoT Security Amidst Evolving Cyber Threats}, 
  year={2024},
  volume={11},
  number={16},
  pages={27715-27731},
  abstract={The rapid expansion of digital infrastructure has led to increased security threats. Deep learning (DL) algorithms have emerged as potent tools for detecting cyberattacks in Internet of Things (IoT) ecosystems. However, challenges like imbalanced class distribution and vast data volumes remain, resulting in inaccurate classification outcomes and inflated accuracy rates. Additionally, memory-constrained IoT devices often find it challenging to accommodate robust DL methods. This article introduces an innovative approach that addresses class imbalance and the challenges posed by high-dimensional data in intrusion detection systems. Our framework encompasses: 1) a conditional generative adversarial network (cGAN) for minority class upsampling; 2) an auxiliary autoencoder for dimensionality reduction; and 3) an unique hybrid uncertainty-based transformer architecture for efficient network traffic classification. We undertake extensive experiments on two specific data sets: 1) BoT-IoT and 2) CICIDS2018, affirming the efficacy of our hybrid DL-based approach. Initially, we assess the quality of synthetic data produced by various techniques, comparing their principal component analysis (PCA) plots to authentic data. Our generative adversarial network-generated data closely mirror the PCA of real data, denoting a high similarity in distribution. Subsequently, we benchmark our auxiliary autoencoder against established dimensionality reduction techniques. The results indicate that our auxiliary autoencoder has significantly lower noise levels than contemporary methods, reducing the data storage volume of network traffic by 93.02% on BoT-IoT and 96.25% on CICIDS2018 data sets. Finally, we illustrate the enhanced capability of our uncertainty-based attention model in detecting cyberattacks across both data sets.},
  keywords={Internet of Things;Uncertainty;Security;Data models;Dimensionality reduction;Computer crime;Telecommunication traffic;Artificial intelligence;cybersecurity;deep learning (DL);dimensionality reduction;imbalanced data sets;Internet of Things (IoT);uncertainty attention},
  doi={10.1109/JIOT.2024.3404808},
  ISSN={2327-4662},
  month={Aug},}@INPROCEEDINGS{10343296,
  author={Chan, Miguel Morales and Amado-Salvatierra, Hector R. and Hernandez-Rizzardini, Rocael and De La Roca, Mónica},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={The potential role of AI-based Chatbots in Engineering Education. Experiences from a teaching perspective}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={The irruption of Artificial Intelligence (AI) based chatbot tools is undoubtedly at the frontiers of education. AI chatbots in education has emerged as a promising solution to enhance the quality of education and to improve learning outcomes. As all new technology does, it has begun to generate news about prohibition, ethical aspects, anti-plagiarism detection tools, and a series of policies from different educational systems. However, we should not deny the positive aspects of these tools if they are well used. AI-based chatbots have interesting potential to help both teachers and students, who must learn to use them well for their own benefit. This article provides an overview of AI-based chatbots, particularly ChatGPT, an artificial intelligence language model developed by OpenAI. GPT, or “Generative Pre-Training Transformer” is a neural network trained to generate “human-like text” by predicting the next word in a sequence given a large dataset of examples. ChatGPT uses the neural network model and is used to generate responses to students' questions in real time, in the sense of a personal teacher assistant. Chatbots are designed to be able to carryon a natural conversation by understanding the context of the conversation, generating appropriate responses, and engaging in active interaction. Nowadays, this type of tool can generate more than just text; for example, the use of LaTeX code (using TeXGPT) or tools for coding and debugging programming exercises. This work explores the potential role that AI-based chatbots can have in engineering education, by examining the answers of a group of teachers' about how the use of AI-based chatbots can improve the learning process of the students in engineering education. The questions that teachers had to answer, from a pedagogical and technological perspective, are related to how chatbots can be integrated into the curriculum to enhance the efficiency of engineering education, their potential impact on the learning process, and actual examples of possible learning activities using AI-based chatbots in their courses.},
  keywords={Training;Education;Neural networks;Oral communication;Chatbots;Transformers;Real-time systems;AI-based education;Engineering education;Natural Language Processing},
  doi={10.1109/FIE58773.2023.10343296},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10978306,
  author={Baccour, Emna and Erbad, Aiman and Mohamed, Amr and Hamdi, Mounir and Guizani, Mohsen},
  booktitle={2025 IEEE Wireless Communications and Networking Conference (WCNC)}, 
  title={Active Prompt Caching in Edge Networks for Generative AI and LLMs: An RL-Based Approach}, 
  year={2025},
  volume={},
  number={},
  pages={01-07},
  abstract={Generative AI (GAI) and Large Language Models (LLMs) have revolutionized natural language processing and content creation. However, their significant computational demands during inference often require cloud servers, which are currently the only viable option for handling complex multi-modal models like GPT-4. The inherent complexity of these models increases latency, posing challenges even within cloud environments. Furthermore, cloud reliance brings other challenges, including high bandwidth consumption to transfer diverse data types. Worse, in personalized GAI applications like virtual assistants, similar prompts frequently occur, causing redundant transmission and computation of replies, which further increases overhead. Accelerating the inference of multi-modal systems is, therefore, critical in artificial intelligence. In this paper, we aim to improve the inference efficiency through prompt caching; if a current prompt is semantically similar to a previous one, the system can reuse the earlier response without invoking the model again. We leverage collaborative edge computing to cache popular replies and store their request embeddings. New prompts are locally processed to extract embeddings, with their qualities determined by the resources available on edge servers. Our problem is formulated as an optimization to manage offloading decisions for GAI tasks, aiming to avoid cloud inferences and minimize latency while maximizing reply quality. Given its non-convex nature, we propose to solve it via Block Successive Upper Bound Minimization (BSUM). Reinforcement learning is employed to actively pre-cache prompts, tackling the complexity of unknown prompt popularity. Our approach demonstrates near-optimal performance, significantly outperforming cloud-only solutions.},
  keywords={Cloud computing;Upper bound;Generative AI;Computational modeling;Wireless networks;Virtual assistants;Collaboration;Complexity theory;Servers;Edge computing;Generative AI;LLM;collaborative edge computing;prompts caching;BSUM;RL},
  doi={10.1109/WCNC61545.2025.10978306},
  ISSN={1558-2612},
  month={March},}@INPROCEEDINGS{9799213,
  author={Pasini, Massimiliano Lupo and Yin, Junqi},
  booktitle={2021 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Stable Parallel Training of Wasserstein Conditional Generative Adversarial Neural Networks}, 
  year={2021},
  volume={},
  number={},
  pages={1-7},
  abstract={We use a stable parallel approach to train Wasserstein Conditional Generative Adversarial Neural Networks (W-CGANs). The parallel training reduces the risk of mode collapse and enhances scalability by using multiple generators that are concurrently trained, each one of them focusing on a single data label. The use of the Wasserstein metric reduces the risk of cycling by stabilizing the training of each generator. We apply the approach on the CIFAR10 and the CIFAR100 datasets, two standard benchmark datasets with images of the same resolution, but different number of classes. Performance is assessed using the inception score, the Fréchet inception distance, and image quality. An improvement in inception score and Fréchet inception distance is shown in comparison to previous results obtained by performing the parallel approach on deep convolutional conditional generative adversarial neural networks (DC-CGANs). Weak scaling is attained on both datasets using up to 100 NVIDIA V100 GPUs on the OLCF supercomputer Summit.},
  keywords={Training;Measurement;Image quality;Image resolution;Scientific computing;Scalability;Neural networks;Artificial Intelligence;High Performance Computing;Multicore processing},
  doi={10.1109/CSCI54926.2021.00026},
  ISSN={},
  month={Dec},}@ARTICLE{10171153,
  author={Razghandi, Mina and Zhou, Hao and Erol-Kantarci, Melike and Turgut, Damla},
  journal={IEEE Transactions on Smart Grid}, 
  title={Smart Home Energy Management: VAE-GAN Synthetic Dataset Generator and Q-Learning}, 
  year={2024},
  volume={15},
  number={2},
  pages={1562-1573},
  abstract={In recent years, there has been a growing interest in academia and industry in the analysis of electrical consumption in residential buildings and the implementation of smart home energy management systems (HEMS) to reduce household energy usage and costs. HEMS have been designed to emulate the statistical and functional characteristics of real smart grids. However, a major challenge in this research area is the limited availability of publicly accessible datasets. To address this challenge and further leverage the potential of artificial HEMS applications, it is crucial to develop time series that accurately represent diverse operating conditions of synthetic systems. This paper introduces a novel approach based on the combination of variational auto-encoder-generative adversarial network (VAE-GAN) techniques to generate time-series data of energy consumption in smart homes. Additionally, we investigate the performance of the generative model when integrated with a Q-learning based HEMS. The effectiveness of the Q-learning based HEMS is assessed through online experiments using real-world smart home data. To evaluate the quality of the generated dataset, we employ various metrics including Kullback–Leibler (KL) divergence, maximum mean discrepancy (MMD), and the Wasserstein distance, which quantify the disparities between probability distributions of the real and synthetic data. Our experimental results demonstrate that the synthetic data generated by VAE-GAN closely aligns with the distribution of real data. Furthermore, we demonstrate that the utilization of the generated data facilitates the training of a more efficient Q-learning based HEMS, surpassing the performance achieved with datasets generated using baseline approaches.},
  keywords={Synthetic data;Data models;Smart homes;Training;Load modeling;Q-learning;Smart grids;Synthetic data;load consumption;smart grid;deep learning;generative adversarial network;q-learning},
  doi={10.1109/TSG.2023.3288824},
  ISSN={1949-3061},
  month={March},}@INPROCEEDINGS{10507584,
  author={Sakurai, Wataru and Asano, Masato and Imoto, Daisuke and Honma, Masakatsu and Kurosawa, Kenji},
  booktitle={2023 9th International Conference on Computer and Communications (ICCC)}, 
  title={Efficient Authorship Attribution Method Using Ensemble Models Built by Knowledge Distillation}, 
  year={2023},
  volume={},
  number={},
  pages={2357-2362},
  abstract={Authorship attribution is a task to identify the author of given documents. It is often treated as a classification task that predicts the author of a written text among given candidates. From practical application perspectives, such as forensic science, the interpretation of results is essential, and the ability to perform authorship attribution with many sentences at high speed will become increasingly important for developing authorship attribution methods. Recently, transformer-based large-scale language models have been developed in natural language processing, and high accuracy has been achieved in various fields. The attention mechanism implemented in the encoder part of the transformer is called self-attention, which calculates the degree of attention given to each word in a sentence. However, in classification problems such as author attribution, the only evidence used as a basis for judgment is the attention distribution, which is a single dimension of the matrix calculated by self-attention and is computationally inefficient. In addition, since this attention distribution is obtained for the number of attentions in the model, its contribution to estimation results and utilization is difficult to examine. In this study, we propose an authorship attribution method that ensembles compact models that substitute each attention of a fine-tuned transformer made by knowledge distillation. We also examine the contribution of each attention to the estimation results based on the accuracy of each ensemble model. In authorship attribution experiments using the works of modern Japanese authors, the ensemble of distillation models achieved results comparable to those of bidirectional encoder representations from transformers. Furthermore, if the process can be ideally parallelized, the computational time required for inference by the proposed method can be significantly reduced.},
  keywords={Generative AI;Computational modeling;Forensics;Estimation;Transformers;Natural language processing;Matrices;authorship attribution;transformer;natural language processing;text classification;deep learning},
  doi={10.1109/ICCC59590.2023.10507584},
  ISSN={2837-7109},
  month={Dec},}@INPROCEEDINGS{9550953,
  author={Omrčen, Luka and Leventić, Hrvoje and Romić, Krešimir and Galić, Irena},
  booktitle={2021 International Symposium ELMAR}, 
  title={Integration of Blockchain and AI in EHR sharing: A survey}, 
  year={2021},
  volume={},
  number={},
  pages={155-160},
  abstract={In the past decade, the digitalization of the health-care industry and electronic healthcare records (EHR) rises rapidly. The concept of smart health gradually gains momentum as information technology advances. Smart healthcare transforms and improves traditional medical systems in efficiency, service and personalization by integrating technologies like the internet of things (IoT), big data, cloud computing, and artificial intelligence (AI). On the other hand, smart healthcare systems are highly prone to security breaches and various malicious attacks. Blockchain technology has recently emerged as a promising solution for improving data management, access control, and integrity inside healthcare systems. This paper presents a survey of research on the latest blockchain solutions combined with AI technologies for improving and innovating new technical standards for the healthcare ecosystem related to medical diagnostics and electronic health records sharing, with a special focus on medical imaging.},
  keywords={Industries;Law;Ecosystems;Medical services;Transforms;Blockchains;Internet of Things;Blockchain;AI;Medical data;Healthcare;Survey},
  doi={10.1109/ELMAR52657.2021.9550953},
  ISSN={1334-2630},
  month={Sep.},}@INPROCEEDINGS{10364117,
  author={Zhang, Zhijun and Wu, Zhentao and Ge, Ren},
  booktitle={2023 International Annual Conference on Complex Systems and Intelligent Science (CSIS-IAC)}, 
  title={Generative-Model-Based Autonomous Intelligent Unmanned Systems}, 
  year={2023},
  volume={},
  number={},
  pages={766-772},
  abstract={In order to improve the autonomous decision-making ability and dynamic environment adaptability of unmanned systems, a universal framework of generative intelligent unmanned systems (GIUS) is proposed and designed. The GIUS framework consists of a human-machine interaction module, an environment perceiving module, a task generation and autonomous decision-making module, and a motion planning module. By obtaining the overall task description through human-machine interaction, GIUS can autonomously perceive and predict environment task information through generative models. Based on the understanding of the environment, the unmanned system can achieve task generation and decision-making independently, and realize path generation and motion generation. Under the framework of GIUS, unmanned systems can perform various tasks in complex environments with minimal or no human intervention. Compared to existing unmanned systems, generative intelligent unmanned systems have significant improvements in autonomy, intelligence, and efficiency.},
  keywords={Human computer interaction;Decision making;Dynamics;Computer architecture;Predictive models;Control systems;Real-time systems;Generative network;Unmanned Systems;Autonomous Control},
  doi={10.1109/CSIS-IAC60628.2023.10364117},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10440990,
  author={Hossain, Md. Zahid and Uz Zaman, Farhad and Islam, Md. Rakibul},
  booktitle={2023 26th International Conference on Computer and Information Technology (ICCIT)}, 
  title={Advancing AI-Generated Image Detection: Enhanced Accuracy through CNN and Vision Transformer Models with Explainable AI Insights}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={In recent years, the world has witnessed remarkable progress in the field of Generative AI. These advancements have ushered in an era where we can generate images that appear extremely lifelike, making it challenging for the human eye to distinguish them from reality. Such lifelike images have the potential to be harnessed for various purposes, including manipulation and the dissemination of misinformation. Consequently, it has become increasingly crucial to detect these AI-generated images accurately to safeguard the integrity of visual information. For this purpose, we delved into the realm of Convolutional Neural Network (CNN) models and Vision Transformer models, exploring their capabilities in distinguishing between authentic and AI-generated images. We conducted our investigations using a publicly available dataset called the CIFAKE: Real and AI-Generated Synthetic Images dataset. Through training different architectures and tuning hyperparameters, we identified the optimal model for this crucial task. Our selected CNN model exhibited an impressive accuracy rate of 96.31%, signifying a substantial stride toward the accurate identification of AI-generated images. We used Grad-CAM (Gradient-weighted Class Activation Mapping) to interpret the model’s output and enhance our understanding of how it generates these outputs. This interpretative tool allowed us to elucidate the model’s decision-making process, shedding light on the discriminative features and patterns it utilizes to distinguish real from synthetic images.},
  keywords={Training;Visualization;Explainable AI;Computational modeling;Transformers;Convolutional neural networks;Tuning;AI-generated Image;Classification;CNN;Vision Transformer;and Explainable AI},
  doi={10.1109/ICCIT60459.2023.10440990},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{6577834,
  author={Grzesiak-Kopeć, Katarzyna and Ogorzałek, Maciej},
  booktitle={2013 6th International Conference on Human System Interactions (HSI)}, 
  title={Intelligent 3D layout design with shape grammars}, 
  year={2013},
  volume={},
  number={},
  pages={265-270},
  abstract={Shape grammars are generative systems dedicated to specific needs of designers. In the last few years, they have received increased interest especially in building reconstruction and building model generation. We propose to combine the formalism with computational intelligence methods and apply to the 3D layout problem which require efficient search of large and discontinuous spaces. The approach is illustrated by the example of a designing 3D ICs layouts. The presented results have been generated with a use of a dedicated application PerfectShape.},
  keywords={Shape;Grammar;Layout;Buildings;Visualization;Computational intelligence;Optimization;Computer Aided Design;Computational Intelligence;Optimization;Shape Grammar},
  doi={10.1109/HSI.2013.6577834},
  ISSN={2158-2254},
  month={June},}@INPROCEEDINGS{10673027,
  author={Gaikwad, Aniket and Sangole, Aditya and Madankar, Mangala and Thakre, Darpan and Tembhurne, Aashay and Mali, Harsh},
  booktitle={2024 7th International Conference on Circuit Power and Computing Technologies (ICCPCT)}, 
  title={ChatGPT: Unraveling User Challenges & Proposing Targeted Improvements}, 
  year={2024},
  volume={1},
  number={},
  pages={17-20},
  abstract={This research paper investigates the multifaceted challenges users encounter with chatbots, focusing specifically on the widely adopted Generative Pre-trained Transformer (GPT) models. Despite GPT's commendable proficiency in natural language understanding, issues arise, notably in the realm of mathematical calculations. A comprehensive literature review outlines the strengths and limitations of GPT across diverse user queries. Additionally, the paper sheds light on user-reported concerns, including GPT's neutral responses that may not address queries adequately, occasional unreliability, and security vulnerabilities. The study meticulously assesses GPT's performance in mathematical problem-solving, uncovering instances of inaccuracies and user dissatisfaction. The discussion delves into potential contributing factors, such as model architecture and training data, while proposing enhancements to mitigate these challenges. Moreover, the research acknowledges broader concerns, such as the delivery of excessively long answers and the lack of artistic touch and creativity in responses. Noteworthy is the observation that identical questions often yield remarkably similar responses, indicating a potential limitation in the model's diversity and adaptability. The paper concludes by underscoring the importance of addressing these challenges for an enhanced user experience and recommends future research directions for refining the ability of language models like GPT.},
  keywords={Adaptation models;Computational modeling;Refining;Training data;Computer architecture;Chatbots;Mathematical models;ChatGPT;GPT;NLP;AI;LLM;Large Language Model},
  doi={10.1109/ICCPCT61902.2024.10673027},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10073684,
  author={Lathamaheswari, U. and Jebathangam, J.},
  booktitle={2023 Third International Conference on Artificial Intelligence and Smart Energy (ICAIS)}, 
  title={A Novel Deep Belief Network with Butterfly Optimization Algorithm for the Classification of Paddy Leaf Disease Detection}, 
  year={2023},
  volume={},
  number={},
  pages={789-796},
  abstract={The widespread presence of a wide variety of diseases during paddy farming is one of the most significant elements that annually contributes to enormous economic losses. These losses occur as a direct result of the widespread prevalence of these diseases. In this paper, a deep learning algorithm using Deep Belief Network (DBN) and a meta-heuristic optimization using Butterfly optimization algorithm (BOA) is used to classify the images to detect the diseases in a Plant Leaf. The steps of classification involve three different process that includes pre-processing, feature extraction and classification. The simulation is conducted in python to test the efficacy of the classifier. The result of simulation shows that the proposed method has obtained higher classification rate than the existing machine learning classifiers. .},
  keywords={Deep learning;Machine learning algorithms;Metaheuristics;Real-time systems;Classification algorithms;Internet of Things;Task analysis;Image Augmentation;Image Processing;Generative Adversarial Network;Paddy Leaf},
  doi={10.1109/ICAIS56108.2023.10073684},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10578778,
  author={Hireche, Abdelhadi and Belkacem, Abdelkader Nasreddine},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Integrating Pepper Robot and GPT for Neuromyth Educational Conversation}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The emergence of neuromyths, or false beliefs about brain function and learning, has been a significant challenge in the field of education. These myths often hinders the learning process. Our study delves into this challenge by combining the cutting-edge large language models (LLMs) and humanoid robotics, aiming to dispel neuromyths in an educational setting. By integrating OpenAI's advanced Generative Pre-trained Transformers (GPT) model with a humanoid robot. This study focuses on neuromyth dispelling to investigate the integration of advanced large language models with humanoid robotics in education. We developed a system combining a Pepper robot with OpenAI's GPT model to educate users about common neuromyths. The system was evaluated through interactive sessions, where our queries were assessed on relevance, context, accuracy, response time, and speech recognition fluency. The findings reveal that the system effectively delivers relevant, contextually appropriate, and accurate information. Although response time was moderately rated, it did not significantly impact the overall user experience. The speech recognition system showed high efficiency, ensuring smooth interactions. These results demonstrate the potential of AI-humanoid robot integration as a valuable educational tool, especially for neuromyths. Our research contributes to educational technology by highlighting the effectiveness of such integrations in enriching learning experiences.},
  keywords={Accuracy;Large language models;Humanoid robots;Speech recognition;Oral communication;Transformers;User experience;Neuromyths;Human-robot interaction;Education;GPT},
  doi={10.1109/EDUCON60312.2024.10578778},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10577779,
  author={Ahmad, Imran Shafiq and Siddiqui, Nazia and Boufama, Boubakeur},
  booktitle={2024 IEEE 12th International Symposium on Signal, Image, Video and Communications (ISIVC)}, 
  title={A Comparative Study of Text-to-Image Generative Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Recent advancements of deep learning (DL) techniques have revolutionized various fields such as computer vision, image processing, artificial intelligence, and natural language processing. One notable application that showcases the power of these algorithms is the field of image synthesis, where new images are created from textual descriptions. Generative models play a crucial role in this process, enabling the generation of novel data based on patterns learned from the training set. Diffusion models are a distinctive class of generative models that operate by introducing random noise to existing data, and subsequently learning to reverse this diffusion process. This technique is particularly valuable in scenarios where the transformation of data over time or through sequential steps is a critical aspect of the generation process. The ability to translate textual descriptions into visual representations offers new possibilities for human-computer interaction and creative expressions. This paper provides a comparison and analysis of generative adversarial networks (GANs) and diffusion models within the domain of “text-to-image generation” to understand the strength and weaknesses of different models in specific contexts. For this purpose, we are using a combination of Vector-Quantized GAN (VQGAN) and Contrastive Language-Image Pre-training (CLIP) model. This combination provides a powerful integration of two distinct machine learning (ML) techniques for the purpose of creating images from textual input. Guided Language to Image Diffusion for Generation and Editing (GLIDE) is the diffusion model used in this study. For both models, text input from the MS-COCO data set is used. Evaluation of generated images is performed using Fréchet Inception Distance (FID) and Inception Score (IS) metrics. Semantic object accuracy score (SOA) is also used as a metric to add an additional layer for analysis by considering the relevance of the generated images to the provided captions during the image generation process. This metric is helpful not only to assessing visual quality of the generated images but also their alignment with the intended semantic content.},
  keywords={Measurement;Training;Human computer interaction;Visualization;Image synthesis;Semantics;Noise;text-to-image generation;generative adversarial networks;diffusion models;Fréchet Inception Distance;semantic object accuracy;Inception Score},
  doi={10.1109/ISIVC61350.2024.10577779},
  ISSN={2832-8337},
  month={May},}@INPROCEEDINGS{11149298,
  author={Lu, Zhaoyi and Xu, Wenchao and Hua, Cunqing},
  booktitle={2025 IEEE/CIC International Conference on Communications in China (ICCC)}, 
  title={Generative Forgery Attack for Radio Frequency Fingerprints Spoofing}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Radio frequency (RF) fingerprints are unique signal distortions resulting from hardware imperfections during manufacturing. These unique characteristics help identify radio devices and mitigate network attacks such as identity spoofing and impersonation. However, advancements in artificial intelligence (AI) have significantly enhanced generative models, enabling RF fingerprint forgery. This paper identifies a security threat enabled by surrogate models, where conditional generative networks produce forgery samples with specified labels, deceiving classifiers into misidentifying the intended identity. Specifically, the generative model crafts perturbations, allowing a transmitter to mimic another device’s fingerprint and mislead receiver identification. Extensive experiments validate the effectiveness of forged fingerprints, demonstrating high spoofing success rates and robustness under diverse SNR conditions and channel fading scenarios. Furthermore, the proposed approach achieves notable performance even in challenging black-box attack settings, leveraging surrogate models to successfully deceive the target classifiers. To minimize the impact on communication quality, a power constraint mechanism is implemented, ensuring that perturbations remain imperceptible and practical for real-world deployment.},
  keywords={Radio frequency;Fading channels;Perturbation methods;Radio transmitters;Closed box;Fingerprint recognition;Forgery;Robustness;Security;Object recognition;RF fingerprinting;Spoofing attack;Black-box attack;Fingerprint forgery;Generative Models},
  doi={10.1109/ICCC65529.2025.11149298},
  ISSN={2377-8644},
  month={Aug},}@ARTICLE{9090326,
  author={Zhang, Feifei and Zhang, Tianzhu and Mao, Qirong and Xu, Changsheng},
  journal={IEEE Transactions on Image Processing}, 
  title={A Unified Deep Model for Joint Facial Expression Recognition, Face Synthesis, and Face Alignment}, 
  year={2020},
  volume={29},
  number={},
  pages={6574-6589},
  abstract={Facial expression recognition, face synthesis, and face alignment are three coherently related tasks and can be solved in a joint framework. To achieve this goal, in this paper, we propose a novel end-to-end deep learning model by exploiting the expression code, geometry code and generated data jointly for simultaneous pose-invariant facial expression recognition, face image synthesis, and face alignment. The proposed deep model enjoys several merits. First, to the best of our knowledge, this is the first work to address these three tasks jointly in a unified deep model to complement and enhance each other. Second, the proposed model can effectively disentangle the global and local identity representation from different expression and geometry codes. As a result, it can automatically generate facial images with different expressions under arbitrary geometry codes. Third, these three tasks can further boost their performance for each other via our model. Extensive experimental results on three standard benchmarks demonstrate that the proposed deep model performs favorably against state-of-the-art methods on the three tasks.},
  keywords={Face;Task analysis;Face recognition;Geometry;Feature extraction;Training;Generators;Facial expression recognition;facial image synthesis;generative adversarial network;facial landmarks},
  doi={10.1109/TIP.2020.2991549},
  ISSN={1941-0042},
  month={},}@INPROCEEDINGS{11158595,
  author={Zheng, Ji and Song, Huanan and Wang, Ziqin and Han, Chunxu and Liu, Chao and Chai, Kok Keong and Chen, Yue},
  booktitle={2025 5th International Conference on Artificial Intelligence and Education (ICAIE)}, 
  title={Evaluating the Impact of Using GenAI in Higher Education for University Students}, 
  year={2025},
  volume={},
  number={},
  pages={765-772},
  abstract={The rapid advancement of Generative Artificial Intelligence (GenAI) is transforming higher education, presenting both opportunities and challenges. This research investigates the integration of GenAI in higher education, focusing on its effects on teaching, learning, and administrative processes. Through focus group discussions with university students from the joint programme between Beijing University of Posts and Telecommunications (BUPT) and Queen Mary University of London (QMUL), this study explores the utilisation of GenAI tools in enhancing educational experiences and outcomes. Findings indicate that while GenAI facilitates personalised learning, improves instructional materials, and streamlines administrative tasks, it also raises concerns regarding the reliability of AI-generated content, academic integrity, and ethical considerations. To further explore these issues, this paper conducted group discussions and workshops with faculty staff from both BUPT and QMUL to gather insights on the responsible integration of GenAI in higher education. The workshop participants provided valuable feedbacks on strategies for enhancing digital literacy, promoting academic integrity, and establishing ethical guidelines for the use of GenAI technologies. The study serves as a foundational step toward the development of a comprehensive framework for integrating GenAI competencies into university curricula, specifically tailored to transnational educational contexts. This research contributes to the academic discourse on AI in education and offers practical guidelines for leveraging GenAI to enhance educational practices and institutional efficiency, while addressing the ethical and pedagogical challenges that arise from the rapid adoption of these transformative technologies.},
  keywords={Ethics;Technological innovation;Generative AI;Conferences;Education;Materials reliability;Reliability theory;Telecommunications;Problem-solving;Guidelines;GenAI;Higher Education;Student Focus Group;Educational Technology;Workshop;Academic Integrity},
  doi={10.1109/ICAIE64856.2025.11158595},
  ISSN={},
  month={May},}@INPROCEEDINGS{10832147,
  author={Li, Chenda and Cornell, Samuele and Watanabe, Shinji and Qian, Yanmin},
  booktitle={2024 IEEE Spoken Language Technology Workshop (SLT)}, 
  title={Diffusion-Based Generative Modeling With Discriminative Guidance for Streamable Speech Enhancement}, 
  year={2024},
  volume={},
  number={},
  pages={333-340},
  abstract={Diffusion-based generative models (DGMs) have recently attracted attention in speech enhancement (SE) research as previous works showed a remarkable generalization capability. However, DGMs are also computationally intensive, since they usually require many iterations in the reverse diffusion process (RDP), making them impractical for streaming SE systems. In this paper, we propose to use scores estimated from discriminative models in the first steps of the RDP. These discriminative-based scores require only one forward pass with the discriminative model for multiple RDP steps, thus greatly reducing computations. This approach also allows for performance improvements. We show that choosing an appropriate number of discriminative guidance steps can result in an overall model with better performance than generative and discriminative models. Furthermore, we propose a novel streamable time-domain generative model with an algorithmic latency of 50 ms, which has no significant performance degradation compared to offline models.},
  keywords={Degradation;Computational modeling;Conferences;Diffusion processes;Speech enhancement;Time-domain analysis;Speech Enhancement;Generative Model;Online Processing},
  doi={10.1109/SLT61566.2024.10832147},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11117038,
  author={Du, Mingxuan and Zhu, Lili and Di Nardo, Mario},
  booktitle={2025 8th International Symposium on Big Data and Applied Statistics (ISBDAS)}, 
  title={A Deep Neural Networks-Based Research Method for Investigating the Mechanisms of Educational Resource Equalization}, 
  year={2025},
  volume={},
  number={},
  pages={37-41},
  abstract={With technological advancements, particularly in artificial intelligence, the application of Deep Neural Networks (DNN) technologies for optimizing educational resources has become increasingly feasible. The gap in educational resources is a significant global issue, affecting students' learning outcomes and future opportunities. This study aims to explore the mechanisms and effects of applying DNN techniques to narrow the gap in educational resources for the development of sustainable education. Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) were utilized to analyze the usage of educational resources and students' learning data. A controlled experiment was designed to compare the resource utilization efficiency and academic performance between the experimental group (using DNN technology) and the control group (using traditional resource allocation methods). The research found that DNN technology significantly enhanced the efficiency of educational resource distribution, particularly in resource-limited environments, by more accurately predicting and meeting students' learning needs. The academic performance and satisfaction of students in the experimental group improved markedly. DNN technology demonstrates substantial potential in the allocation of educational resources, offering new possibilities and directions for narrowing the gap in educational resources.},
  keywords={Recurrent neural networks;Education;Artificial neural networks;Big Data;Resource management;Convolutional neural networks;Artificial intelligence;Optimization;component;Deep Neural Network;Sustainable Education;Educational Resource;Education Quality},
  doi={10.1109/ISBDAS64762.2025.11117038},
  ISSN={},
  month={Feb},}@ARTICLE{10720711,
  author={Ranasingha, Chinthaka and Gammulle, Harshala and Fernando, Tharindu and Sridharan, Sridha and Fookes, Clinton},
  journal={IEEE Sensors Journal}, 
  title={Physics Augmented Tuple Transformer for Autism Severity-Level Detection}, 
  year={2024},
  volume={24},
  number={23},
  pages={39981-39991},
  abstract={Early diagnosis of autism spectrum disorder (ASD) is an effective and favorable step toward enhancing the health and well-being of children with ASD. Manual ASD diagnosis testing is labor-intensive, complex, and prone to human error due to several factors contaminating the results. This article proposes a novel framework that exploits the laws of physics for ASD severity recognition. The proposed physics-informed neural network architecture encodes the behavior of the subject extracted by observing a part of the skeleton-based motion trajectory in a higher dimensional latent space. Two decoders, namely, physics-based and nonphysics-based decoder, use this latent embedding and predict the future motion patterns. The physics branch leverages the laws of physics that apply to a skeleton sequence in the prediction process while the nonphysics-based branch is optimized to minimize the difference between the predicted and actual motion of the subject. A classifier also leverages the same latent space embeddings to recognize the ASD severity. This dual generative objective explicitly forces the network to compare the actual behaviors of the subject with the general normal behaviors of children that are governed by the laws of physics, aiding the ASD recognition task. The proposed method attains state-of-the-art performance on multiple ASD diagnosis benchmarks. To illustrate the utility of the proposed framework beyond the task ASD diagnosis, we conduct a third experiment using a publicly available benchmark for the task of fall prediction and demonstrate the superiority of our model.},
  keywords={Decoding;Transformers;Autism;Variable speed drives;Feature extraction;Sensors;Computer architecture;Pediatrics;Detection algorithms;Artificial neural networks;Autism severity-level detection;deep neural networks;physics-informed neural networks;transformers},
  doi={10.1109/JSEN.2024.3477751},
  ISSN={1558-1748},
  month={Dec},}@ARTICLE{9741798,
  author={Chen, Haihua and Pieptea, Lavinia F. and Ding, Junhua},
  journal={IEEE Transactions on Reliability}, 
  title={Construction and Evaluation of a High-Quality Corpus for Legal Intelligence Using Semiautomated Approaches}, 
  year={2022},
  volume={71},
  number={2},
  pages={657-673},
  abstract={A high-quality corpus is essential for building an effective legal intelligence system. The quality of a corpus includes both the quality of original data and the quality of its corresponding labeling. The major quality dimensions of a legal corpus include comprehensiveness, freshness, and correctness. However, building a comprehensive, correct, and fresh legal corpus is a grand challenge. In this article, we propose a semiautomated machine learning framework to address the challenge. We first created an initial corpus with 4937 instances that were manually labeled. Several strategies were implemented to assure its quality. The initial results showed that class imbalance and insufficiency of training data are the two major quality issues that negatively impacted the quality of the system that was built on the data. We experimented and compared three class-imbalance-handling techniques and found that the mixed-sampling method, which combines upsampling and downsampling, was the most effective way to address the issue. In order to address the insufficiency of training data, we experimented several machine learning methods for automated data augmentation including pseudolabeling, co-training, expectation-maximization, and generative adversarial network (GAN). The results showed that GAN with deep learning models achieved the best performance. Finally, ensemble learning of different classifiers was proposed and experimented with for the construction of a legal corpus, which achieves higher quality in comprehensiveness, freshness, and correctness compared to existing work. The semiautomated machine learning framework and the data quality evaluation method developed in this research can be used for data augmentation and quality evaluation of a large dataset as well as a reference for the selection of machine learning methods for data augmentation and generation. The machine learning models, the training data, and the legal corpus are published and publicly accessible at [Online]. Available: https://github.com/haihua0913/legalArgumentmining.},
  keywords={Law;Annotations;Data integrity;Machine learning;Data mining;Task analysis;Deep learning;BERT;data augmentation;data quality;deep learning;expectation-maximization (EM);generative adversarial network (GAN);legal argument;legal artificial intelligence (legal AI);machine learning corpus},
  doi={10.1109/TR.2022.3156126},
  ISSN={1558-1721},
  month={June},}@INPROCEEDINGS{9892336,
  author={Yu, Jialin and Cristea, Alexandra I. and Harit, Anoushka and Sun, Zhongtian and Aduragba, Olanrewaju Tahir and Shi, Lei and Moubayed, Noura Al},
  booktitle={2022 International Joint Conference on Neural Networks (IJCNN)}, 
  title={INTERACTION: A Generative XAI Framework for Natural Language Inference Explanations}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={XAI with natural language processing aims to produce human-readable explanations as evidence for AI decision-making, which addresses explainability and transparency. However, from an HCI perspective, the current approaches only focus on delivering a single explanation, which fails to account for the diversity of human thoughts and experiences in language. This paper thus addresses this gap, by proposing a generative XAI framework, INTERACTION (explain aNd predicT thEn queRy with contextuAl CondiTional varIational autO-eNcoder). Our novel framework presents explanation in two steps: (step one) Explanation and Label Prediction; and (step two) Diverse Evidence Generation. We conduct intensive experiments with the Transformer architecture on a benchmark dataset, e-SNLI [1]. Our method achieves competitive or better performance against state-of-the-art baseline models on explanation generation (up to 4.7% gain in BLEU) and prediction (up to 4.4% gain in accuracy) in step one; it can also generate multiple diverse explanations in step two.},
  keywords={Human computer interaction;Neural networks;Decision making;Predictive models;Benchmark testing;Transformers;Natural language processing;generative model;neural network;deep learning;natural language processing;XAI},
  doi={10.1109/IJCNN55064.2022.9892336},
  ISSN={2161-4407},
  month={July},}@ARTICLE{11097041,
  author={Weng, Zhenzi and Wang, Zijing and Qin, Zhijin and Tao, Xiaoming},
  journal={IEEE Transactions on Wireless Communications}, 
  title={Generative Semantic Communications for Robust Speech-to-Text Translation}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={In this article, we propose a robust semantic communication system for speech transmission, named Ross-S2T, to execute the speech-to-text translation (S2TT) transmission efficiently. First, a deep semantic encoder is developed to directly convert speech in the source language to textual features associated with the target language, facilitating the end-to-end (E2E) semantic exchange to perform the S2TT task and reducing the amount of transmission data without performance degradation. To mitigate semantic impairments inherent in the corrupted speech, a novel generative adversarial network (GAN)-enabled deep semantic compensator is established to estimate the hidden semantic information within the speech and extract deep semantic features simultaneously, which enables robust semantic transmission for corrupted speech. Furthermore, a semantic probe-aided compensator is devised to enhance the semantic fidelity of recovered semantic features and improve the understandability of the target text. According to simulation results, the proposed Ross-S2T exhibits superior S2TT performance compared to conventional approaches and high robustness against semantic impairments.},
  keywords={Semantic communication;Feature extraction;Encoding;Training;Translation;Transformers;Data mining;Robustness;Image reconstruction;Wireless communication;Deep learning;generative adversarial network;semantic communications;speech-to-text translation},
  doi={10.1109/TWC.2025.3590671},
  ISSN={1558-2248},
  month={},}@INPROCEEDINGS{11165906,
  author={Tiwari, Vaibhavi and Wang, Jiayin},
  booktitle={2025 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)}, 
  title={GANterpolate: Improving Climate Modeling through Synthetic Data Generation}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Data sparsity remains a significant challenge in climate modeling, particularly in remote and under-observed regions that play a crucial role in global climate dynamics. This study proposes GANterpolate, a novel hybrid approach that integrates Generative Adversarial Networks (GANs) with interpolation techniques to reconstruct missing surface temperature data. Utilizing the ERA5 reanalysis dataset, artificial data gaps are systematically introduced in climatologically significant regions such as the Arctic and Equatorial Pacific. The GAN-based generator produces an initial reconstruction, while interpolation methods refine the generated data to enhance accuracy and spatial coherence. The discriminator, a deep convolutional neural network (CNN), evaluates the authenticity of the reconstructed data, optimizing adversarial loss to improve realism. Comparative analysis against traditional interpolation techniques demonstrates that GANterpolate outperforms standalone methods in capturing complex spatial-temporal dependencies. Quantitative results indicate that GANterpolate achieves a Root Mean Square Error (RMSE) of 0.320 and a Mean Absolute Error (MAE) of 0.126 with a perfect Pearson correlation of 1.0 in randomly masked scenarios. In clustered masked regions, it achieves an RMSE of 5.368, MAE of 4.161, and Pearson correlation of 0.958, significantly surpassing both GAN-only and interpolation-based baselines. These findings demonstrate the transformative potential of synthetic data generation in enhancing the quality of climate datasets, paving the way for more robust and reliable climate simulations in data-scarce regions.},
  keywords={Interpolation;Temperature distribution;Surface reconstruction;Correlation;Atmospheric modeling;Generative adversarial networks;Data models;Reliability;Meteorology;Synthetic data;Synthetic Data Generation;Climate Modeling;Generative Adversarial Networks (GANs)},
  doi={10.1109/ACDSA65407.2025.11165906},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10824523,
  author={Salman, Husain and Aliif, Muhammad and Ibrahim, Roliana and Mahmood, Jamilah},
  booktitle={2024 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT)}, 
  title={Technology Readiness for Generative AI Among Academic Researchers}, 
  year={2024},
  volume={},
  number={},
  pages={329-336},
  abstract={The use of Generative Artificial Intelligence tools in academic research has recently created a debate in the higher education sector. This study explores researchers' awareness, concerns, and usage of generative AI tools in the academic research process. In addition, the study investigates the current level of readiness among researchers to adopt these tools using the Technology Readiness Index 2.0. Results indicate a high familiarity among respondents with the applications of Generative AI tools in academic research. However, only about half of the participants (51.54%) stated that they are currently adopting these tools mainly for academic writing assistance and language support. In addition, researchers expressed significant concerns about the accuracy of the information, ethical considerations, the authenticity of work, and data privacy and security, with (58.96%) indicating that these concerns may influence their future decisions to adopt or continue adopting these tools. The findings also indicate that the overall readiness level is moderate but reflects a degree of discomfort and insecurity which can inhibit researchers' readiness for adoption. Furthermore, senior researchers tend to feel more insecure than other researcher groups, and AI literacy skills were shown to impact the innovativeness sub-scale.},
  keywords={Training;Ethics;Data privacy;Technological innovation;Accuracy;Generative AI;Predictive models;Writing;Stress;Context modeling;Generative AI;Academic Research;TRI;Adoption;Researcher;GAI},
  doi={10.1109/3ict64318.2024.10824523},
  ISSN={2770-7466},
  month={Nov},}@INPROCEEDINGS{8836993,
  author={Chen, Shoulong and Xu, Qiang and Zhong, Shangping and Chen, Kaizhi},
  booktitle={2019 2nd International Conference on Artificial Intelligence and Big Data (ICAIBD)}, 
  title={GAN Evaluation by Multi-Method Fusion}, 
  year={2019},
  volume={},
  number={},
  pages={36-44},
  abstract={Generative adversarial networks (GAN) have made great progress in areas, such as computer vision, but evaluation of GAN models is still a daunting task. Numerous researchers have proposed many methods for GAN model evaluation. However, most methods have strong pertinence, which leads to large deviations in the results of different evaluation methods. To date, no consensus has been reached on which method best captures the advantages and limitations of GAN models. In this study, a multi-method fusion approach is proposed to evaluate GAN models from many aspects, such as accuracy, diversity of the images generated by the model, and similarity with the training images. This method provides a new idea for GAN model assessment. Meanwhile, a strategy similar to ensemble learning is used to analyze the generalization of multi-method fusion for GAN assessment. This method and the human eye cognitive assessment model are used on celebA benchmarks and self-acquired image data sets to generate results. Through human eye cognition and comparison with the latest GAN model assessment method, showing that the multi-method fusion GAN evaluation method proposed in this paper has strong robustness and effectiveness.},
  keywords={Gallium nitride;Generative adversarial networks;Computational modeling;Data models;Entropy;Training;Generators;GAN evaluation;images evaluation;multi-method;ensemble learning},
  doi={10.1109/ICAIBD.2019.8836993},
  ISSN={},
  month={May},}@INPROCEEDINGS{9859867,
  author={Tang, Anni and Huang, Yan and Ling, Jun and Zhang, Zhiyu and Zhang, Yiwei and Xie, Rong and Song, Li},
  booktitle={2022 IEEE International Conference on Multimedia and Expo (ICME)}, 
  title={Generative Compression for Face Video: A Hybrid Scheme}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={As the latest video coding standard, versatile video coding (VVC) has shown its ability in retaining pixel quality. To excavate more compression potential for video conference scenarios under ultra-low bitrate, this paper proposes a bitrate-adjustable hybrid compression scheme for face video. This hybrid scheme combines the pixel-level precise recovery capability of traditional coding with the generation capability of deep learning based on abridged information, where Pixel-wise Bi-Prediction, Low-Bitrate-FOM and Lossless Keypoint Encoder collaborate to achieve PSNR up to 36.23 dB at a low bitrate of 1.47 KB/s. Without introducing any additional bi-trate, our method has a clear advantage over VVC under a completely fair comparative experiment, which proves the effectiveness of our proposed scheme. Moreover, our scheme can adapt to any existing encoder/configuration to deal with different encoding requirements, and the bitrate can be dynamically adjusted according to the network condition.},
  keywords={Video coding;Deep learning;Bit rate;Streaming media;Encoding;Hybrid power systems;Faces;face video;video compression;versatile video coding;deep generation;generative compression},
  doi={10.1109/ICME52920.2022.9859867},
  ISSN={1945-788X},
  month={July},}@INPROCEEDINGS{10605379,
  author={Tsagarakis, Nick and Maniadakis, Michail},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={On the generation and assessment of synthetic waste images}, 
  year={2024},
  volume={},
  number={},
  pages={1011-1016},
  abstract={In contemporary waste recycling, the assistance of autonomous robotic systems, equipped with machine learning capabilities, has become crucial for the identification and sorting of recyclable materials. The evolution of computer vision applications, reliant on machine learning, heavily hinges on extensive datasets employed for training intricate deep neural network models. Recently several works from various fields have explored techniques that facilitate the generation of big synthetic datasets starting from an initially limited set of images. This paper proposes a novel approach for generating synthetic waste images, which involves two main steps. The first regards the use of a neural network to implement a "critic" that can evaluate how realistic, synthetic images of recyclable objects may be. The second involves applying multiple random elastic deformations to images of individual recyclable objects to generate a large number of new appearances of the given objects. The critic evaluates the generated images, gauging their realism through a confidence score. We employ a rigorous confidence threshold to identify synthetic images with a notably realistic appearance. These individual object images are then utilized to craft composite synthetic images depicting multiple recyclable objects on a conveyor belt transporting recyclable waste in an industrial setting. The above summarized process facilitates the creation of expansive artificial datasets crucial for training neural networks. The efficacy of these datasets is assessed by examining their impact on the performance of trained detection models when applied to previously unseen and challenging industrial images. The obtained results show that the use of the synthetic datasets leads to better classification models in terms of both precision and accuracy, motivating more research in the field of artificially generated datasets.},
  keywords={Training;Computer vision;Deformation;Computational modeling;Machine learning;Fasteners;Belts;Synthetic Images;Generator;Discriminator;Waste Categorization},
  doi={10.1109/CAI59869.2024.00184},
  ISSN={},
  month={June},}@INPROCEEDINGS{10914360,
  author={Wøien, Mina Cecilie and Catak, Ferhat Ozgur and Kuzlu, Murat and Cali, Umit},
  booktitle={2024 IEEE Virtual Conference on Communications (VCC)}, 
  title={Neural Networks Meet Elliptic Curve Cryptography: A Novel Approach to Secure Communication}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In recent years, neural networks have been used to implement symmetric cryptographic functions for secure communications. Extending this domain, the proposed approach explores the application of asymmetric cryptography within a neural network framework to safeguard the exchange between two communicating entities, i.e., Alice and Bob, from an adversarial eavesdropper, i.e., Eve. It employs a set of five distinct cryptographic keys to examine the efficacy and robustness of communication security against eavesdropping attempts using the principles of elliptic curve cryptography. The experimental setup reveals that Alice and Bob achieve secure communication with negligible variation in security effectiveness across different curves. It is also designed to evaluate cryptographic resilience. Specifically, the loss metrics for Bob oscillate between 0 and 1 during encryption-decryption processes, indicating successful message comprehension post-encryption by Alice. The potential vulnerability with a decryption accuracy exceeds 60%, where Eve experiences enhanced adversarial training, receiving twice the training iterations per batch compared to Alice and Bob.},
  keywords={Training;Measurement;Accuracy;Neural networks;Elliptic curve cryptography;Trajectory;Cryptography;Artificial intelligence;Eavesdropping;Resilience;Artificial Intelligence;Elliptic Curve;Neural Cryptography},
  doi={10.1109/VCC63113.2024.10914360},
  ISSN={},
  month={Dec},}@ARTICLE{9667357,
  author={Abdalgawad, N. and Sajun, A. and Kaddoura, Y. and Zualkernan, I. A. and Aloul, F.},
  journal={IEEE Access}, 
  title={Generative Deep Learning to Detect Cyberattacks for the IoT-23 Dataset}, 
  year={2022},
  volume={10},
  number={},
  pages={6430-6441},
  abstract={The rapid growth of Internet of Things (IoT) is expected to add billions of IoT devices connected to the Internet. These devices represent a vast attack surface for cyberattacks. For example, these IoT devices can be infected with botnets to enable Distributed Denial of Service (DDoS) attacks. Signature-based intrusion detection systems are traditional countermeasures for such attacks. However, these methods rely on human experts and are time-consuming in terms of updates and may not exhaust all attack types especially zero-day attacks. Deep learning has shown some promise in intrusion detection. This paper shows that it is possible to use generative deep learning methods like Adversarial Autoencoders (AAE) and Bidirectional Generative Adversarial Networks (BiGAN) to detect intruders based on an analysis of the network data. The recently posted full IoT-23 dataset based on Somfy door lock, Philips Hue and Amazon Echo devices was used to train generative deep learning models to detect a variety of attacks like DDoS, and various botnets like Mirai, Okiruk and Torii. Over 1.8 million network flows were used to train the various models. The resulting generative models outperform traditional machine learning techniques like Random Forests. Both AAE and BiGAN-based models were able to achieve an F1-Score of 0.99. A BiGAN to detect unknown attacks was also trained to detect novel zero-day attacks with an F1-Score from 0.85 to 1.},
  keywords={Botnet;Computer crime;Internet of Things;Generative adversarial networks;Convolutional neural networks;Intrusion detection;Servers;Adversarial autoencoders;cyber security;generative adversarial networks;Internet of Things;intrusion detection systems},
  doi={10.1109/ACCESS.2021.3140015},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10830834,
  author={Tündik, Máté Ákos and Kovács, Ferenc and Blaskó, Márk},
  booktitle={2024 IEEE 24th International Symposium on Computational Intelligence and Informatics (CINTI)}, 
  title={Building Domain Specific Chatbot: A Telco Case Study}, 
  year={2024},
  volume={},
  number={},
  pages={135-140},
  abstract={The generative AI and LLMs are getting commonly used solution to ease the daily work. There are special domains where the out of box solution cannot provide sufficient outcomes as the domains have their own specialties, jargons or rules. In this paper we investigate telco related specialties and how they can be handled to tailor a general purpose chatbot.},
  keywords={Generative AI;Computational modeling;Buildings;Chatbots;Informatics;Computational intelligence;generative AI;multimodal chatbot;domain specific chatbot;large language models;retrieval augmented generation;telecommunication;6G},
  doi={10.1109/CINTI63048.2024.10830834},
  ISSN={2471-9269},
  month={Nov},}@ARTICLE{10786852,
  author={Simões, Marcelo Godoy and Ribeiro, Paulo F.},
  journal={IEEE Electrification Magazine}, 
  title={Reflections and a Vision Toward a Sustainable Education in Electrical Engineering: Next generation of electrical engineers.}, 
  year={2024},
  volume={12},
  number={4},
  pages={104-115},
  abstract={The area of Electrical and Electronics Engineering had been evolving tremendously in the past 100+ years, from electrotechnology of the 20th century then electronics, microprocessors, computers, analog, digital and advanced control, with software becoming further and more advanced, cybernetics, continuous path on intelligence based solutions, the 21st century made the reality of distributed computing, cloud-based services, ultrafast real-time execution of control with digital twin, incorporation of highly sophisticated mathematical models, and then artificial intelligence becoming prominent, further with a Nobel Prize for AI developments for computer scientists. Electrification is also a process of empowering individuals and is bringing change to our modern society. Allowing industry and social impact requires effective renewable generation technologies to supply a network and ever evolving dynamic demand, this critical life-sustaining infrastructure. In this paper the authors describe how the past has shaped our present, and where we are at right now and attempting forecast and advise regarding pathways towards the next generation of Electrical Engineers.},
  keywords={Surveys;Education;Electrification;Artificial intelligence;Sustainable development;Next generation networking;Electrical engineering education;Curriculum development;Educational programs;History;Software engineering;Forecasting;Artificial intelligence},
  doi={10.1109/MELE.2024.3473409},
  ISSN={2325-5889},
  month={Dec},}@INPROCEEDINGS{10568897,
  author={S, Venkatesh and Jeevitha, D. and Gnanaselvi, J. Anitha},
  booktitle={2024 Ninth International Conference on Science Technology Engineering and Mathematics (ICONSTEM)}, 
  title={Calligraphy Alphabet Perception Using Artificial Intelligence}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={The human brain has a simple time analyzing and processing images. The brain is able to rapidly deconstruct and distinguish an image's various components when the eye perceives it. With the Convolutional Neural Network (CNN) as its foundation, this research suggests deep learning conceptual models. When the algorithms are compared, it becomes clear that CNN-based classification of handwritten alphabets performs better than other algorithms in terms of accuracy. The Manual Net, Alex Net, and LeNet Architectures are among the CNN algorithms employed in this research. The convulational layer, max pooling, flattening, feature assortment, rectifier lined unit, and completely linked softmaxx layers are each components of the aforementioned designs. The proposed network is tested using an image dataset comprising 530 training photos and 2756 testing images. The top precision and cost-efficient model will be used in the Django context to build a handler line for supplying the appeal to be recognized and obtaining the productivity outcome of recognized appeal.},
  keywords={Training;Productivity;Accuracy;Rectifiers;User interfaces;Mathematical models;Classification algorithms;Calligraphy Perception Scripts;Unfathomable Education;Tensor Flow;CNN;Django},
  doi={10.1109/ICONSTEM60960.2024.10568897},
  ISSN={},
  month={April},}@INPROCEEDINGS{10945228,
  author={Li, Chengyu and Li, Weihai and Xu, Zikai and Yu, Nenghai},
  booktitle={2024 IEEE 23rd International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)}, 
  title={StegaFDS: Generative Steganography Based on First-Order DPM-Solver}, 
  year={2024},
  volume={},
  number={},
  pages={109-116},
  abstract={Image steganography aims to conceal secret messages within an image without detection and has a long development history. With the rapid development of generative artificial intelligence, generative image steganography is also thriving. However, existing generative steganography methods struggle to balance steganographic capacity, extraction accuracy, and security. This paper proposes a high-capacity generative steganography method based on the first-order DPM-Solver, called StegaFDS. By utilizing our efficiently designed mapping function, which connects secret messages to the noise space of the diffusion probabilistic model (DPM), we achieve a significant increase in hiding capacity and detection resistance, while maintaining distribution-preserving. To improve message extraction accuracy further, we also optimize the existing first-order DPM-Solver inversion. Additionally, based on pre-trained diffusion models, StegaFDS can generate high-quality stego images without training. Experimental results show that StegaFDS performs exceptionally better than other generative steganography methods in the abovementioned metrics and demonstrates strong potential and availability.},
  keywords={Resistance;Training;Measurement;Steganography;Privacy;Accuracy;Noise;Diffusion models;Security;History;Generative Steganography;Diffusion Probabilistic Model;Distribution-Preserving;DDIM Inversion},
  doi={10.1109/TrustCom63139.2024.00042},
  ISSN={2324-9013},
  month={Dec},}@INPROCEEDINGS{10510736,
  author={AYGÜN, İrfan and KAYA, Mehmet},
  booktitle={7th IET Smart Cities Symposium (SCS 2023)}, 
  title={Use of large language models for medical synthetic data generation in mental illness}, 
  year={2023},
  volume={2023},
  number={},
  pages={652-656},
  abstract={Data quantity and quality are very important for the development of medical artificial intelligence research. Nowadays, thanks to easier access to data, studies in this field produce very successful results. However, many factors such as protection of patient rights in medical data and confidentiality of personal data prevent researchers from directly accessing the data. For this reason, synthetic data creation studies are often needed both to expand the training and test sets and to create sample cases to be used in the relevant field. In this study, various synthetic patient data are created to be presented to a language model that enables the detection of psychological disorders through patient text. Synthetic data sets were produced with 200 artificial patient data created with popular LLM examples ChatGPT and Google Bard. The quality of synthetic data was measured with the help of a pre-trained BERT model using these datasets. In the experiments, it was observed that chatbots that generate instant data, such as ChatGPT and Google Bard, produced successful results at rates of 89% and 86% with the language representation model. With the experimental results, it appears that LLM studies can provide more successful results than advanced language models in various medical text production tasks.},
  keywords={},
  doi={10.1049/icp.2024.1033},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11032354,
  author={Botirova, Halima and Sattorova, Zilola and Nazarova, Saodat and Madraimov, Abdumajid and Kalandarov, Aybek and Jumaniyozov, Yunus},
  booktitle={2025 International Conference on Computational Innovations and Engineering Sustainability (ICCIES)}, 
  title={Restoring Historical Paintings Using Diffusion Models and GANs}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Restoring historical paintings is crucial for preserving cultural heritage, but traditional methods often struggle with severe degradation, color fading, and missing details. Recent advancements in deep learning, particularly Generative Adversarial Networks (GANs) and diffusion models have provided innovative solutions for digital restoration. Existing restoration techniques, such as manual retouching and classical image inpainting, require expert knowledge and often fail to reconstruct fine details lost over time. Furthermore, conventional deep-learning methods may introduce artifacts or fail to generalize across diverse artistic styles. We propose a restoration framework combining GANs with diffusion models to address these challenges. GANs, with their adversarial training mechanism, enhance texture and structure recovery, while diffusion models improve noise reduction and fine-grain detail reconstruction. The approach refines missing regions, corrects color degradation, and maintains stylistic consistency through adversarial learning and probabilistic diffusion-based denoising. The proposed method enables museums and researchers to restore paintings more accurately and efficiently, reducing reliance on manual interventions while ensuring historically faithful reconstructions. Experimental results demonstrate that our approach outperforms conventional methods regarding perceptual quality, structural similarity, and artistic fidelity. Integrating GANs and diffusion models offers a powerful tool for cultural heritage preservation.},
  keywords={Degradation;Image color analysis;Noise reduction;Manuals;Diffusion models;Museums;Image restoration;Cultural differences;Image reconstruction;Painting;Historical Painting Restoration;GANs;Digital Image Restoration;Deep Learning},
  doi={10.1109/ICCIES63851.2025.11032354},
  ISSN={},
  month={April},}
