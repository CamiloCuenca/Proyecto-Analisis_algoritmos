@ARTICLE{10879226,
  author={Liu, Hongdan and Wu, Congjie and Li, Bing and Zong, Zhengcong and Shu, Yaqing},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Research on Ship Anomaly Detection Algorithm Based on Transformer-GSA Encoder}, 
  year={2025},
  volume={26},
  number={6},
  pages={8752-8763},
  abstract={As global economies continue to expand, maritime trade is projected to double by the year 2050. In this context, the development of a new generation of maritime intelligent supervision systems, which rely on precise information perception and machine learning-based technologies, is crucial for ensuring the safety of maritime navigation. Traditional methods for detecting abnormal ship behavior often suffer from inadequate feature extraction capabilities, leading to ineffective and inaccurate anomaly detection. To address this issue, this paper introduces a Transformer-GSA encoder detection model. This model enhances ship information data through BCE-GAN, extracts multi-layer convolutional features, and utilizes the Transformer-GSA module to capture the dependencies between trajectory features and time-series data, thereby effectively identifying abnormal ship behaviors. An evaluation conducted using AIS data from the Yantai-Qingdao route in January 2021 demonstrates that the model achieves an accuracy of 96.26%, with a reduced parameter count of 12.11M. These results confirm the model’s efficacy and superiority in detecting abnormal ship trajectories, contributing to the reduction of maritime accidents and illegal activities, alleviating the management burden on duty personnel, and enhancing the quality of intelligent ship traffic services and port operation efficiency under the maritime Internet of Things architecture.},
  keywords={Marine vehicles;Data models;Transformers;Trajectory;Feature extraction;Anomaly detection;Biological system modeling;Artificial intelligence;Accuracy;Navigation;Ship anomaly detection;AIS;Transformer encoder;global attention;lightweight},
  doi={10.1109/TITS.2025.3536483},
  ISSN={1558-0016},
  month={June},}@INPROCEEDINGS{10157489,
  author={Bergmann, Sandra and Moussa, Denise and Brand, Fabian and Kaup, André and Riess, Christian},
  booktitle={2023 11th International Workshop on Biometrics and Forensics (IWBF)}, 
  title={Frequency-Domain Analysis of Traces for the Detection of AI-based Compression}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The JPEG algorithm is the most popular compression method on the internet. Its properties have been extensively studied in image forensics for examining image origin and authenticity. However, the JPEG standard will in the near future be extended with AI-based compression. This approach is fundamentally different from the classic JPEG algorithm, and requires an entirely new set of forensics tools.As a first step towards forensic tools for AI compression, we present a first investigation of forensic traces in HiFiC, the current state-of-the-art AI-based compression method. We investigate the frequency space of the compressed images, and identify two types of traces, which likely arise from GAN upsampling and in homogeneous areas. We evaluate the detectability on different patch sizes and unseen postprocessing, and report a detectability of 96.37%. Our empirical results also suggest that further, yet unidentified, compression traces can be expected in the spatial domain.},
  keywords={Image forensics;Image coding;Biometrics (access control);Frequency-domain analysis;Conferences;Transform coding;Artificial intelligence;AI-based compression;frequency analysis},
  doi={10.1109/IWBF57495.2023.10157489},
  ISSN={},
  month={April},}@INPROCEEDINGS{10943555,
  author={Cheng, Yongkang and Liang, Mingjiang and Huang, Shaoli and Han, Gaoge and Ning, Jifeng and Liu, Wei},
  booktitle={2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, 
  title={Conditional GAN for Enhancing Diffusion Models in Efficient and Authentic Global Gesture Generation from Audios}, 
  year={2025},
  volume={},
  number={},
  pages={2164-2173},
  abstract={Audio-driven simultaneous gesture generation is vital for human-computer communication, AI games, and film pro-duction. While previous research has shown promise, there are still limitations. Methods based on VAEs are accompa-nied by issues of local jitter and global instability, whereas methods based on diffusion models are hampered by low generation efficiency. This is because the denoising process of DDPM in the latter relies on the assumption that the noise added at each step is sampled from a unimodal distribution, and the noise values are small. DDIM bor-rows the idea from the Euler method for solving differential equations, disrupts the Markov chain process, and increases the noise step size to reduce the number of denoising steps, thereby accelerating generation. However, simply increasing the step size during the step-by-step denoising process causes the results to gradually deviate from the original data distribution, leading to a significant drop in the quality of the generated actions and the emergence of unnatural artifacts. In this paper, we break the assumptions of DDPM and achieves breakthrough progress in denoising speed and fidelity. Specifically, we introduce a conditional GAN to capture audio control signals and implicitly match the multimodal denoising distribution between the diffusion and denoising steps within the same sampling step, aiming to sample larger noise values and apply fewer denoising steps for high-speed generation. In addition, to enable the model to generate high-fidelity global gestures and avoid artifacts, we introduce an explicit motion geometric loss to enhance the quality and global stability of the generated gestures. Numerous qualitative and quantitative experiments show that compared to contemporary diffusion-based methods, our method offers faster generation speed and higher fidelity, and compared to non-diffusion methods, it provides a more stable global effect and a more natural user experience.},
  keywords={Computer vision;Noise reduction;Noise;Games;Differential equations;Jitter;Diffusion models;User experience;Stability analysis;Artificial intelligence},
  doi={10.1109/WACV61041.2025.00217},
  ISSN={2642-9381},
  month={Feb},}@INPROCEEDINGS{10411515,
  author={Wang, Jie and Li, Dan and Zheng, Zibin and Ng, See-Kiong},
  booktitle={2023 IEEE International Conference on Data Mining Workshops (ICDMW)}, 
  title={Adversarial Maritime Trajectory Prediction with Real-time Spatial-Temporal Mutual Influence}, 
  year={2023},
  volume={},
  number={},
  pages={852-859},
  abstract={As the driving force of global trade, it is essential to ensure the safety and security of maritime transportation effectively. Due to human operators’ physiology and experience limitations, it is unreliable to depend entirely on them for maritime surveillance. Fortunately, massive data collected by the Automatic Identification System (AIS) enables machine-aided navigation and surveillance, based on which enormous studies on ship trajectory prediction have arisen for further maritime traffic monitoring/tracking, abnormal vessel detection, collision avoidance at sea, etc. However, previous works mainly predict vessel trajectories by modeling and grasping a single vessel’s past navigation information based on well-cleaned AIS data, ignoring dynamic correlations caused by real-time ship interactions. In this work, we developed an Adversarial Maritime Trajectory Prediction with a Real-time Mutual Influence (MI-AMTP) model to predict vessel trajectories in the same scene without complicated data pre-processing, which contains three main modules, namely trajectory embedding module (TEM), mutual influence module (MIM), adversarial prediction module (APM). Especially in MIM, by grasping the time dynamics, the proposed model can obtain real-time mutual influences of the vessels in order to predict the trajectories timely. The proposed MI-AMTP model was evaluated on one private maritime dataset collected from Southeast Asia and several publicly available AIS datasets. Experimental results denoted that the proposed model outperformed the state-of-the-art methods.},
  keywords={Navigation;Surveillance;Predictive models;Real-time systems;Trajectory;Artificial intelligence;Marine vehicles;Trajectory Prediction;Adversarial Learning;Real-Time Dynamics;Mutual Influence},
  doi={10.1109/ICDMW60847.2023.00115},
  ISSN={2375-9259},
  month={Dec},}@INPROCEEDINGS{11099149,
  author={Haffner, Oto and Kučera, Erik and Beňo, Lukáš and Melekhova, Anna and Pajpach, Martin and Janecký, Dominik},
  booktitle={2025 International Conference on Control, Automation and Diagnosis (ICCAD)}, 
  title={Gesture Recognition for Mechatronic System Control Using Motion-Capture Suit Rokoko SmartSuit Pro II}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={This study explores the processing and evaluation of data collected from a motion-capture suit to facilitate gesture recognition for controlling mechatronic devices. In the context of advanced human-machine interaction (HMI) and human-robot interaction (HRI), the research investigates the utilization of motion-capture technology as a tool for capturing and interpreting operator gestures. The study begins with the selection of a cost-effective motion-capture suit, followed by a comprehensive analysis of data acquisition techniques. A program is then designed to process and evaluate the captured data using computational intelligence methods, including Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) networks. The results demonstrate the efficacy of these models in accurately recognizing gestures, which are then translated into control commands for mechatronic devices. This work contributes to the development of more intuitive and efficient interfaces for human-machine communication, with potential applications in various fields, including robotics, healthcare, and industrial automation.},
  keywords={Mechatronics;Automation;Service robots;Human-machine systems;Robot vision systems;Human-robot interaction;Gesture recognition;Robustness;Long short term memory;Remote control;motion-capture;human-machine interface;mechatronic system;gesture recognition;neural networks},
  doi={10.1109/ICCAD64771.2025.11099149},
  ISSN={2767-9896},
  month={July},}@ARTICLE{9138418,
  author={Zhang, Sicong and Xie, Xiaoyao and Xu, Yang},
  journal={IEEE Access}, 
  title={A Brute-Force Black-Box Method to Attack Machine Learning-Based Systems in Cybersecurity}, 
  year={2020},
  volume={8},
  number={},
  pages={128250-128263},
  abstract={Machine learning algorithms are widely utilized in cybersecurity. However, recent studies show that machine learning algorithms are vulnerable to adversarial examples. This poses new threats to the security-critical applications in cybersecurity. Currently, there is still a short of study on adversarial examples in the domain of cybersecurity. In this paper, we propose a new method known as the brute-force attack method to better evaluate the robustness of the machine learning classifiers in cybersecurity against adversarial examples. The proposed method, which works in a black-box way and covers some shortages of the existing adversarial attack methods based on generative adversarial networks, is simple to implement and only needs the output of the target classifiers to generate adversarial examples. To have a comprehensive evaluation of the attack performance of the proposed method, we use our method to generate adversarial examples against the common machine learning based security systems in cybersecurity including host intrusion detection systems, Android malware detection systems, and network intrusion detection systems. We compare the attack performance of the proposed method against these security systems with that of state-of-the-art adversarial attack methods based on generative adversarial networks. The preliminary experimental results show that the proposed method, which is more efficient in computation and outperforms the state-of-the-art attack methods based on generative adversarial networks, can be used to evaluate the robustness of various machine learning based systems in cybersecurity against adversarial examples.},
  keywords={Computer security;Machine learning;Malware;Intrusion detection;Machine learning algorithms;Generative adversarial networks;Adversarial examples;machine learning;deep learning;intrusion detection;malware detection;neural networks;black-box method},
  doi={10.1109/ACCESS.2020.3008433},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10306184,
  author={Bauer, Markus and Augenstein, Christoph},
  booktitle={2023 18th Conference on Computer Science and Intelligence Systems (FedCSIS)}, 
  title={Can Unlabelled Data Improve AI Applications? A Comparative Study on Self-Supervised Learning in Computer Vision}, 
  year={2023},
  volume={},
  number={},
  pages={93-101},
  abstract={Artificial Intelligence (AI) represents a highly investigated area of study at present and has already become an indispensable component within an extensive range of business models and applications. One major downside of current supervised AI approaches lies in the need of numerous annotated data points to train the models. Self-supervised learning (SSL) circumvents the need for annotation, by creating supervision signals such as labels from the data itself, rather than requiring experts for this task. Current approaches mainly include the use of generative methods such as autoencoders and joint embedding architectures to fulfil this task. Recent works present comparable results to supervised learning in downstream scenarios such as classification after SSL-pretraining. To achieve this, typically modifications are required to suit the approach for the exact downstream task. Yet, current review works haven't paid too much attention to the practical implications of using SSL. Thus, we investigated and implemented popular SSL approaches, suitable for downstream tasks such as classification, from an initial collection of more than 400 papers. We evaluate a selection of these approaches under real-world dataset conditions, and in direct comparison to the supervised learning scenario. We discuss SSL's potential to take up with supervised learning, as well as the influence of the right training methods. Furthermore, we also introduce future directions for SSL research, as well as current limitations in real-world applications.},
  keywords={Training;Computer vision;Computational modeling;Supervised learning;Focusing;Self-supervised learning;Machine learning},
  doi={10.15439/2023F8371},
  ISSN={},
  month={Sep.},}@ARTICLE{10444547,
  author={Zhang, Huiying and Yao, Feifan and Gong, Yifei and Zhang, Qinghua},
  journal={IEEE Access}, 
  title={Anemone Image Generation Based on Diffusion-Stylegan2}, 
  year={2024},
  volume={12},
  number={},
  pages={37310-37325},
  abstract={Given the complexity and uncertainty of the underwater environment, it is of great importance to generate realistic and high-quality images. In this paper, we propose six unconditional generative models based on the Diffusion-Styegan2 generative model, incorporating Wasserstein, R2 regularization terms, and other techniques for anemone image generation. The Wasserstein distance technique is used in the loss part of Diffusion-Styegan2, combined with the back propagation algorithm to compute the gradient in the neural network while retaining the computational map to improve the training efficiency and training stability; the R2 regularization term is used to introduce the r2 hyperparameter, and the L2 regularization technique is used based on the original R1 regularization term to regularize the gradient of the discriminator to improve the training and generation performance of the model; the ADA technique is used based on DWBG-Stylegan2 to further improve the quality and stability of the generated images. In addition, a set of SA datasets (sea anemone datasets) with a resolution of  $256^{\ast} 256$  is proposed in this paper. The experimental results show that the FID value of Diffusuion-Stylegan2 is 10.31, the value of FID of DWBG-Stylegan2 is 8.32, the value of FID of Diffusion-Stylegan2-R2 is 9.58, and the optimal FID value of this experiment is achieved by DWBG-Stylegan2-ADA with a value of 5.67, which is considerably lower compared to the FID value of Diffusion-Stylegan2. Therefore, techniques such as Wasserstein and R2 regularization terms can effectively generate more realistic images of anemones. Meanwhile, this experiment provides new ideas and methods for the construction of the unconditional generative model.},
  keywords={Training;Biological system modeling;Generative adversarial networks;Image synthesis;Generators;Diffusion processes;Computational modeling;Data models;Underwater navigation;Underwater technology;Diffusion-Stylegan2;Wasserstein;R2 regularization term;SA datasets},
  doi={10.1109/ACCESS.2024.3369234},
  ISSN={2169-3536},
  month={},}@ARTICLE{11045414,
  author={Zhu, Shumin and Zou, Xingxing and Yang, Wenhan and Wong, Wai Keung},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Any Fashion Attribute Editing: Dataset and Pretrained Models}, 
  year={2025},
  volume={47},
  number={10},
  pages={8856-8872},
  abstract={Fashion attribute editing is essential for combining the expertise of fashion designers with the potential of generative artificial intelligence. In this work, we focus on ‘any’ fashion attribute editing: 1) the ability to edit 78 fine-grained design attributes commonly observed in daily life; 2) the capability to modify desired attributes while keeping the rest components still; and 3) the flexibility to continuously edit on the edited image. To this end, we present the Any Fashion Attribute Editing (AFED) dataset, which includes 830 K high-quality fashion images from sketch and product domains, filling the gap for a large-scale, openly accessible fine-grained dataset. We also propose Twin-Net, a twin encoder-decoder GAN inversion method that offers diverse and precise information for high-fidelity image reconstruction. This inversion model, trained on the new dataset, serves as a robust foundation for attribute editing. Additionally, we introduce PairsPCA to identify semantic directions in latent space, enabling accurate editing without manual supervision. Comprehensive experiments, including comparisons with ten state-of-the-art image inversion methods and four editing algorithms, demonstrate the effectiveness of our Twin-Net and editing algorithm. All data and models are available at https://github.com/ArtmeScienceLab/AnyFashionAttributeEditing.},
  keywords={Semantics;Image reconstruction;Codes;Training;Accuracy;Electronic mail;Textiles;Manuals;Iterative methods;Image resolution;Fashion attribute editing dataset;encoder -based GAN inversion;attribute editing in latent space},
  doi={10.1109/TPAMI.2025.3581793},
  ISSN={1939-3539},
  month={Oct},}@INPROCEEDINGS{10390315,
  author={S, Keerthi K and N, Jagadisha and Aluvala, Srinivas and Sasikala, M. and Almusawi, Muntather},
  booktitle={2023 International Conference on Ambient Intelligence, Knowledge Informatics and Industrial Electronics (AIKIIE)}, 
  title={A Linear Nearest Neighbour Lasso Step Based Honey Badger Algorithm for Robust Network Intrusion Detection System}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Nowadays, one of the biggest issues facing network-based intrusion detection systems are handling massive volumes of network data (IDS). These data typically have a large number of duplicated or unnecessary attributes. Using feature selection techniques, pertinent features must be extracted from the original data in order to increase the effectiveness of IDS. Feature selection is a crucial component of intrusion detection and helps to enhance intrusion detection performance. For feature selection of network intrusion detection, a Honey Badger method based on Linear Nearest Neighbour Lasso Step (LNNLS-HB) is presented to address the issue of low efficiency and high false positive rate in IDS caused by increasing high-dimensional data. The LNNLS-HB algorithm's fitness evaluation function incorporates the quantity of characteristics used and the precision of the classification. Finally, the Convolutional Neural Network (CNN) classification is performed optimal solution, the updated HB location is subjected to the linear closest neighbour lasso step optimisation. To assess and compare the performance of the proposed methodology with other widely used feature selection techniques, the intrusion detection benchmark dataset (CIC-IDS2017) is used. Empirical results demonstrate that the proposed LNNLS-HB achieves a better accuracy of 99.52% when compared with the existing methods.},
  keywords={Industrial electronics;Network intrusion detection;Medical services;Feature extraction;Classification algorithms;Convolutional neural networks;Data mining;Deep Learning;Feature Selection;Honey Badger;Intrusion Detection System;Linear Nearest Neighbour Lasso Step},
  doi={10.1109/AIKIIE60097.2023.10390315},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10108835,
  author={Numan, Nels and Giunchi, Daniele and Congdon, Benjamin and Steed, Anthony},
  booktitle={2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, 
  title={Ubiq-Genie: Leveraging External Frameworks for Enhanced Social VR Experiences}, 
  year={2023},
  volume={},
  number={},
  pages={497-501},
  abstract={This paper describes the Ubiq-Genie framework for integrating external frameworks with the Ubiq social VR platform. The proposed architecture is modular, allowing for easy integration of services and providing mechanisms to offload computationally intensive processes to a server. To showcase the capabilities of the framework, we present two prototype applications: 1) a voice- and gesture-controlled texture generation method based on Stable Diffusion 2.0 and 2) an embodied conversational agent based on ChatGPT. This work aims to demonstrate the potential of integrating external frameworks into social VR for the creation of new types of collaborative experiences.},
  keywords={Three-dimensional displays;Conferences;Systems architecture;Prototypes;Collaboration;Virtual reality;Computer architecture;social virtual reality;collaboration;open source;system architecture;generative artificial intelligence},
  doi={10.1109/VRW58643.2023.00108},
  ISSN={},
  month={March},}@INPROCEEDINGS{9213159,
  author={Zhang, Teng and Deng, Lirui and Zhang, Liang and Dang, Xianglei},
  booktitle={2020 IEEE 3rd International Conference on Computer and Communication Engineering Technology (CCET)}, 
  title={Deep Learning in Face Synthesis: A Survey on Deepfakes}, 
  year={2020},
  volume={},
  number={},
  pages={67-70},
  abstract={Deepfake stemming from the combined words of "deep learning" and "fake", refers to a type of fake images and video generation technology based on artificial intelligence. In recent years, with the continuous development of deep learning, especially auto-encoders and generative adversarial networks, deepfake has made tremendous progress, resulting in the emergence of some easy-to-use application software in the market, reducing the application difficulty of face-synthesis technology. This paper provides a thorough review of deepfake, introducing its development in the past three years.},
  keywords={Faces;Tools;Streaming media;Image reconstruction;Mouth;Lips;Feature extraction;deepfake;deep learning;generative adversarial networks},
  doi={10.1109/CCET50901.2020.9213159},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10487259,
  author={Kim, Dae-Kyoo and Chen, Jingshu and Ming, Hua and Lu, Lunjin},
  booktitle={2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE)}, 
  title={Assessment of ChatGPT's Proficiency in Software Development}, 
  year={2023},
  volume={},
  number={},
  pages={2637-2644},
  abstract={This paper presents an assessment of ChatGPT's proficiency in software development, using an online tour reservation system (TORS) as a case study. The findings indicate that ChatGPT has significant potential in software development, demonstrating its capabilities in assisting various activities throughout the development process, including requirements analysis, domain modeling, design modeling, and implementation. Notably, the model performed well in implementation, generating more than 90% of the code and fixing a majority of errors. It also demonstrated its capability in making design decisions in the design phase. However, the study also identified non-trivial limitations, such as a lack of traceability and inconsistencies among produced artifacts, which required human involvement. Overall, the results suggest that when combined with human developers, ChatGPT can serve as a valuable tool in software development. It has the potential to enhance productivity and efficiency in various aspects of the development process, while acknowledging the need for human expertise to mitigate the limitations.},
  keywords={Productivity;Analytical models;Codes;Chatbots;Software;assessment;ChatGPT;generative artificial intelligence;software development},
  doi={10.1109/CSCE60160.2023.00421},
  ISSN={},
  month={July},}@INPROCEEDINGS{10367090,
  author={B V, Vishnu and Rao, Sharath S and B, Netravathi},
  booktitle={2023 International Conference on Recent Advances in Information Technology for Sustainable Development (ICRAIS)}, 
  title={An Interactive Framework for Querying Data from Large Pdf Files}, 
  year={2023},
  volume={},
  number={},
  pages={25-30},
  abstract={With the evolution of huge language models, it is now possible to converse with robots on any topic. However, unstructured data, such as PDF files, must still be converted into a format that these models can easily analyze. Through this study, we present a framework for creating conversational PDF applications that are powered by language models, specifically OpenAI's GPT-3 architecture. Our framework, enables users to connect their language model APIs to other data sources, such as PDF files, and allows the language model to interact with the data source. We show our framework's usefulness by breaking a big PDF document into smaller chunks, transforming each chunk into embeddings, and constructing a knowledge base that users may query. The results obtained suggest that employing embeddings rather than comparing text directly can greatly reduce data size while improving search result accuracy.},
  keywords={Semantic search;Soft sensors;Scalability;Transfer learning;Portable document format;Transformers;Natural language processing;Artificial Intelligence;Deep Learning;Generative pre-trained Transformer;Natural Language processing},
  doi={10.1109/ICRAIS59684.2023.10367090},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10800008,
  author={Xue, Liu and Jie, Liu and Peipei, Zhu and Tao, Xiang},
  booktitle={2024 7th International Conference on Machine Learning and Natural Language Processing (MLNLP)}, 
  title={MilChat: A Large Language Model and Application for Military Equipment}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={To offer the military personnel a good service of assisting them to get information about enemy's equipment outside Internet, we build a system named MilChat which includes a large language model that has the ability to generate texts and an application which is easy to use. The model of MilChat is fine-tuned by the method of LoRA with military datasets from the basic model, Qwen-7B-Chat which is opensource and has good performance. After fine-tuning, the new model has higher scores than the basic one. Besides, we use the method of Prompt Learning to limit the answers into a standard format. Therefore, it is more accurate and professional than the basic model. This study has also a value of industrial application.},
  keywords={Accuracy;Large language models;Machine learning;Natural language processing;Libraries;Internet;Personnel;Standards;Military equipment;MilChat;military equipment;generative artificial intelligence;fine-tune;LLM},
  doi={10.1109/MLNLP63328.2024.10800008},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10689912,
  author={Prathiksha, K and Tamizh Malar, S G and Nivedha, P and Divya, D.M. and Srijayanthi, S.},
  booktitle={2024 5th International Conference on Electronics and Sustainable Communication Systems (ICESC)}, 
  title={IntelliAid: A Personal Assistant Chat-Bot for Enhanced Task Management}, 
  year={2024},
  volume={},
  number={},
  pages={432-436},
  abstract={Personalized chatbots offer a practical solution to manage daily tasks in today's fast-paced world. Leveraging AI and NLP, these virtual assistants streamline appointment scheduling, meal planning, payment reminders, and medication alerts. By continuously learning from user interactions, the chatbot provides increasingly accurate and relevant recommendations. This research explores the development and implementation of a customized chatbot, emphasizing the role of NLP, machine learning, and secure data management. The chatbot's ability to understand and respond to user needs enhances productivity, reduces stress, and improves overall well-being.},
  keywords={Productivity;Electric potential;Privacy;Virtual assistants;Machine learning;Chatbots;Transformers;Planning;Stress;Optimization;Artificial Intelligence;Machine learning;Natural Language Processing (NLP);Generative Pre-trained Transformer 3 (GPT-3)},
  doi={10.1109/ICESC60852.2024.10689912},
  ISSN={2996-5357},
  month={Aug},}@INPROCEEDINGS{10696988,
  author={Assayed, Suha Khalil and Alkhatib, Manar and Shaalan, Khaled},
  booktitle={2024 Mediterranean Smart Cities Conference (MSCC)}, 
  title={Transforming Student Advising in Smart Cities: A Deep Learning Conversational AI Chatbot}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Citizens, including students, teachers and parents can all be significantly involved in the smart cities, as smart education is one of the main key drivers in developing smart citizens. Indeed, high school plays an essential role not only in shaping students’ future career, but also in contributing to the development of smart citizens. High school students who benefit from college-career advising will be more prepared and motivated to universities compared to students from other schools. Because the availability of college-career guidance position can vary in schools, students might not get the proper guidance equally. Therefore, in this paper a novel deep learning based chatbot is implemented by using the Seq2Seq model trained on 2944 students’ inquiries for taking the role of a college-career guidance in high schools. In this model a BiLSTM layer is configured with 400 units in each direction of LSTM layer and a single dense layer with Softmax activation is included in the decoder component. The model, when tested with the Adam optimizer, demonstrated a notable performance enhancement over the SGD optimizer. Evaluation with ROUGE-N metrics indicated a high precision score of 92% in the ROUGE-1 measure.},
  keywords={Deep learning;Measurement;Smart cities;Engineering profession;Educational technology;Chatbots;Decoding;Long short term memory;Adam;Artificial Intelligence;BiLSTM;Chatbot;Generative;NLP;Smart City;Seq2Seq;SGD},
  doi={10.1109/MSCC62288.2024.10696988},
  ISSN={},
  month={May},}@INPROCEEDINGS{10391501,
  author={Gahlawat, Devansh and Suhag, Shilpa and Rani, Uma and Madavi, Sarika},
  booktitle={2023 Second International Conference On Smart Technologies For Smart Nation (SmartTechCon)}, 
  title={Hybrid deep learning model for IT-OT integration in Industry 4.0}, 
  year={2023},
  volume={},
  number={},
  pages={1025-1030},
  abstract={Industry 4.0 revolutionizes the manufacturing sector by integrating information technology (IT) and operational technology (OT) to create smart factories. The IT-OT integration enables the collection, analysis, and utilization of vast amounts of data from various sources, leading to enhanced decision-making, increased efficiency, and improved productivity. Deep learning, a subset of artificial intelligence, has shown tremendous potential in extracting valuable insights from complex and unstructured data. However, deploying deep learning models for IT-OT integration in Industry 4.0 presents unique challenges, including the need for real-time processing, handling diverse data types, and ensuring robustness and reliability. In this study, we propose a hybrid deep learning model specifically designed for IT-OT integration in Industry 4.0. The model combines the strengths of multiple deep learning architectures, including convolutional neural networks (CNNs), recurrent neural networks (RNNs), and generative adversarial networks (GANs), to tackle the aforementioned challenges. The hybrid model leverages CNNs for image and video analysis, RNNs for time-series data processing, and GANs for data generation and augmentation. To address the real-time processing requirement, the hybrid model incorporates parallel computing techniques and optimizes the model’s architecture for efficient resource utilization. Additionally, to handle diverse data types, the model employs transfer learning and multimodal fusion techniques, enabling the integration of various data sources such as sensor data, log files, and maintenance records. The robustness and reliability of the hybrid model are ensured through a combination of techniques, including regularization, dropout, and model ensembling. The model is trained on a large-scale dataset comprising real-world IT and OT data collected from smart factories. The performance evaluation of the hybrid model demonstrates its effectiveness in extracting actionable insights, predicting equipment failures, and optimizing production processes. The proposed hybrid deep learning model for IT-OT integration in Industry 4.0 presents a promising solution for leveraging the power of deep learning in smart manufacturing environments. By combining various deep learning architectures and addressing the unique challenges of IT-OT integration, the model enables efficient data analysis, enhanced decision-making, and improved overall performance in the era of Industry 4.0. Future research directions include exploring federated learning approaches for distributed IT-OT systems and investigating the model’s scalability and adaptability to evolving manufacturing environments.},
  keywords={Deep learning;Adaptation models;Recurrent neural networks;Computational modeling;Data models;Robustness;Real-time systems;IT-OT integration;Industry 4.0;Smart factories;Deep learning architectures;Convolutional neural networks (CNNs);Recurrent neural networks (RNNs);Generative adversarial networks (GANs);Real-time processing},
  doi={10.1109/SmartTechCon57526.2023.10391501},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10498880,
  author={Wason, Ritika and Arora, Parul and Arora, Devansh and Kaur, Jasleen and Singh, Sunil Pratap and Hoda, M. N.},
  booktitle={2024 11th International Conference on Computing for Sustainable Global Development (INDIACom)}, 
  title={Appraising Success of LLM-based Dialogue Agents}, 
  year={2024},
  volume={},
  number={},
  pages={1570-1573},
  abstract={Large language models (LLM) can be prompted to exhibit human like dialogue. However, LLM-based dialogue agentsmay in many senses mimic a human being as well as differentiate from the same. In this manuscript we try to unveil the intricacies of an LLM-based dialogue agent. The capabilities of these models have shaken the business as well as research world. However, the success of such models in any given domain depends on a number of considerations. In this manuscript we outline the same.},
  keywords={Computational modeling;Business;Large Language Models (LLM);Dialogue Agents;GPT;Generative Model;Artificial General Intelligence (AGI)},
  doi={10.23919/INDIACom61295.2024.10498880},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10455465,
  author={Wang, Zhongming and Wang, Haiyong},
  booktitle={2023 3rd International Conference on Digital Society and Intelligent Systems (DSInS)}, 
  title={GAN-based PPO-LSTM high-speed railway line optimization}, 
  year={2023},
  volume={},
  number={},
  pages={125-130},
  abstract={With the transfer of my country's railway construction center to the western region, due to the complex terrain, desert, seasonal frozen soil and other extreme geographical environments in the western region, manual line selection design faces many difficulties. To reduce the cost of line selection, it is necessary to design a line selection method based on artificial intelligence. To build a deep reinforcement learning model for railway line selection, the learning speed is extremely slow due to the lack of empirical data in the early stage of training, and it is impossible to avoid impassable areas in advance. This paper proposes to use the generative confrontation network to learn the probability distribution of real experience sample data to generate virtual samples, and then select data in batches from the real experience sample pool and virtual sample pool for training, to improve the learning speed. The LSTM network is added to the deep reinforcement learning model PPO, and the characteristics of LSTM processing time series data are used to realize the prediction and avoidance of impassable areas in advance during action selection. Provide reference for design optimization of western railways.},
  keywords={Training;Time series analysis;Soil;Deep reinforcement learning;Rail transportation;Data models;Proposals;Generative Adversarial Networks;deep reinforcement learning;PPO;LSTM},
  doi={10.1109/DSInS60115.2023.10455465},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10326253,
  author={Parvizi, Arya and Salimi-Badr, Armin},
  booktitle={2023 13th International Conference on Computer and Knowledge Engineering (ICCKE)}, 
  title={Generating Hand-Written Symbols With Trajectory Planning Using A Robotic Arm}, 
  year={2023},
  volume={},
  number={},
  pages={335-339},
  abstract={In this paper an evolutionary-based pattern generator to draw lines, curves, and shapes using a robotic arm without explicit instructions, is presented. Drawing is considered to be denoting a symbol with continuous curves and lines, which is different from the work of a printer. First, we consider drawing the digits 0 to 9 in the simulation environment with a robotic arm. Next, the ability of the method to learn drawing more complicated patterns is studied. The method is applied to control the irb4600 robotic arm for drawing patterns, in the Webots simulation environment. Our proposed method is compared with some other relevant methods the advantages and disadvantages of each approach were examined. The advantage of our algorithm is that it allows us to draw the desired shapes by the robot without prior training and the need for large amounts of data. The results of this paper can greatly benefit the applications in the industry of autonomous cutting, welding, drawing, and industrial design. We were able to successfully draw various types of shapes and symbols in the simulation and generate an accurate (more than 94% across distinct runs) trajectory for our robot.},
  keywords={Training;Shape;Service robots;Welding;Sociology;Semantics;Symbols;Autonomous Robotics;Robotic Arm;Trajectory Planning;Evolutionary Algorithms;Generative Artificial Intelligence},
  doi={10.1109/ICCKE60553.2023.10326253},
  ISSN={2643-279X},
  month={Nov},}@INPROCEEDINGS{10880799,
  author={Mejia, Jose M. Ruiz and Rawat, Danda B.},
  booktitle={2024 IEEE International Conference on E-health Networking, Application & Services (HealthCom)}, 
  title={ClinicalGraph: An Applied Approach in Clinical EHR Knowledge Graph Generation for Optimized Clinical Decision Support System}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Electronic Health Records (EHR) are well-known for their extensive capabilities in storing pertinent patient information across various specializations. However, EHRs are part of a broader ecosystem of applications that support the medical treatment process. This ecosystem, although somewhat centralized, does not have the interoperability that many assume. The main issue is that current triage models are not personalized to each patient. Context matters in a medical emergency situation especially when resources are low. In this research, we propose a possible solution by applying state of the art techniques in order to develop a clinical knowledge graph that contains relevant data used for triage optimization. We utilize a fine-tuned named entity recognition model (NER) to extract 41 label entity categories from previous medical records. Additionally, we employed prompt engineering utilizing a large language text generation model with medical knowledge to generate relationships. This resulted in a sum of 1,429 relationship type categories and approximately 999 entity nodes were created with 2,387 relationships.},
  keywords={Decision support systems;Reviews;Biological system modeling;Large language models;Ecosystems;Retrieval augmented generation;Medical treatment;Knowledge graphs;Prompt engineering;Medical diagnostic imaging;Rapid Triage;E-triage;Generative Artificial Intelligence;Knowledge Graph Generation;Patient Centered Nodes;Knowledge Graph;Clinical Knowledge Graph},
  doi={10.1109/HealthCom60970.2024.10880799},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10158812,
  author={Parfenov, Denis and Grishina, Lyubov and Legashev, Leonid and Zhigalov, Artur and Parfenov, Anton},
  booktitle={2023 IEEE Ural-Siberian Conference on Biomedical Engineering, Radioelectronics and Information Technology (USBEREIT)}, 
  title={Investigation of the Security of ML-models in IoT Networks from Adversarial Attacks}, 
  year={2023},
  volume={},
  number={},
  pages={229-232},
  abstract={Due to the growth of digital intelligent technologies and the introduction of applied machine learning models in various industries, the demand for their protection has increased. The security of computing systems from adversarial attacks is an area of research of cybersecurity algorithms, which have become particularly relevant at the moment. The purpose of this work is to study the effectiveness of targeted adversarial attacks on machine learning models based on tabular data, which are based on gradient methods for optimizing the loss function. Within the framework of this study, an approach to conducting an adversarial attack using the Low ProFool algorithm is considered, and an approach to the use of generative-adversarial networks for generating synthetic adversarial samples based on substitution of real values of the output feature is proposed. The basic machine learning models are based on a set of data generated on the DeepMIMO platform according to the ray tracing scenario in open space, in order to identify the presence of end devices with the base station. The results obtained can be used in the development of secure models for the convergence of artificial intelligence and the Internet of Things, the future direction of research includes the development of methods to counter the considered adversarial attacks.},
  keywords={Base stations;Machine learning algorithms;Computational modeling;Machine learning;Ray tracing;Data models;Internet of Things;DeepMIMO;adversarial attacks;generative-adversarial networks;Internet of Things;tabular data},
  doi={10.1109/USBEREIT58508.2023.10158812},
  ISSN={2769-3635},
  month={May},}@INPROCEEDINGS{10533467,
  author={Ayappan, Kavitha and Mathana, J.M and Thangakumar, J},
  booktitle={2024 International Conference on Advances in Data Engineering and Intelligent Computing Systems (ADICS)}, 
  title={Predictive Risk and Complexity Score Assessment Model for Cloud Computing}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={With the rapid growth in information technology and being called the Digital Era, it is very evident that no one can survive without internet or ICT advancements. The day-to-day life operations and activities are dependent on these technologies. The latest technology trends in the market and industry are computing power, Smart devices, artificial intelligence, Robotic process automation, metaverse, IOT (Internet of things), cloud computing, Edge computing, Block chain and much more in the coming years. When looking at all these aspect and advancements, one common thing is cloud computing and data which must be protected and safeguarded which brings in the need for cyber/cloud security. Hence cloud security challenges have become an omnipresent concern for organizations or industries of any size where it has gone from a small incident to threat landscape. When it comes to data and cyber/ cloud security there are lots of challenges seen to safeguard these data. Towards that it is necessary that everyone must be aware of the latest technological advancements, evolving cyber threats, data as a valuable asset, Human Factor, Regulatory compliance, Cyber resilience. To handle all these challenges, security and risk prediction framework is proposed in this paper. This framework PRCSAM (Predictive Risk and Complexity Score Assessment Model) will consider factors like impact and likelihood of the main risks, threats and attacks that is foreseen in cloud security and the recommendation of the Risk management framework with automatic risk assessment and scoring option catering to Information security and privacy risks. This framework will help management and organizations in making informed decisions on the cyber security strategy as this is a data driven, dynamic & proactive approach to cyber security and its complexity calculation. This paper also discusses on the prediction techniques using Generative AI techniques.},
  keywords={Industries;Cloud computing security;Computational modeling;Organizations;Predictive models;Data models;Complexity theory;Cloud Security;Risk assessment;Cyber threats;Incidents;Cloud threats;Predictive Risk and Complexity Score Assessment Model (PRCSAM);Generative AI},
  doi={10.1109/ADICS58448.2024.10533467},
  ISSN={},
  month={April},}@INPROCEEDINGS{10541846,
  author={Almatrafi, Omaima},
  booktitle={2024 7th International Conference on Information and Computer Technologies (ICICT)}, 
  title={Assessing ChatGPT’s Capability to Generate Course Learning Outcomes}, 
  year={2024},
  volume={},
  number={},
  pages={527-531},
  abstract={ChatGPT is transforming higher education through the utilization of advanced neural networks and large language models to produce human-like content. However, its integration in various educational contexts has yet to be comprehensively evaluated. This study aims to assess ChatGPT’s ability to create course learning outcomes (CLOs) effectively, which remains unexplored. ChatGPT was instructed to generate 10-15 CLOs for 10 courses in the information systems department, based on the course title, description, and topics. The CLOs generated by ChatGPT were then evaluated using two different methods: 1) automatic evaluation metrics (BERTScore) to measure semantic similarity and 2) experts who provided a more comprehensive evaluation of the CLOs relevance to the course and diagnose the characteristic of poorly generated CLOs. The findings demonstrate that ChatGPT can serve as a supportive tool for instructors. The majority of the generated CLOs are either similar to or novel additions to those developed by humans. Nonetheless, approximately 20% of experts CLOs were missing and 22% of the produced CLOs were incorrect, mainly identified as irrelevant. Therefore, it is crucial to exercise caution when using this tool and to rely on human expertise to assess the CLOs generated by ChatGPT.},
  keywords={Productivity;Measurement;Reviews;Computational modeling;Education;Semantics;Neural networks;ChatGPT;learning outcomes;generative artificial intelligence;empirical study;course design;education},
  doi={10.1109/ICICT62343.2024.00092},
  ISSN={2769-4542},
  month={March},}@INPROCEEDINGS{10888660,
  author={Trioux, Anthony and Gao, Yusong and Song, Jiarun and Wu, Wenjie and Ma, Faming and Yang, Fuzheng},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Subjective Fidelity Assessment of Audio- and Video-Driven Talking Head Generation Methods}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Audio- and Video-Driven Talking Head Generation methods have attracted considerable research interest due to recent advances in Artificial Intelligence Generated Content (AIGC) technologies. In such approaches, a single image is artificially animated by leveraging audio and/or motion features extracted from video sources. Despite notable progress, current performance assessments rely primarily on traditional objective metrics, often neglecting subjective evaluation aspects. To address this issue, we propose in this paper a subjective fidelity assessment of recent Audio- and/or Video-Driven Talking Head Generation methods. This study aims to assess how accurately and convincingly the generated video reproduces the visual and behavioral characteristics of a real human face, as well as how closely the video aligns with expected natural human expressions, movements, and/or audio synchronization. In order to provide a detailed assessment of the fidelity in the context of talking heads, our study focuses on six key criteria: Overall Fidelity, Gaze Fidelity, Audio-Video Sync Fidelity, Head Pose Fidelity, Expression Fidelity, and Overall Visual Quality. Experiments results reveal a nuanced picture of the fidelity in this context, where the performance varies significantly depending on the video content itself as well as how the animation is generated, highlighting the needs for further research. This research represents an initial step towards the evaluation of Audio- and Video-Driven generative image animation methods for Talking heads while offering insights for improving the accuracy and realism of those techniques. The dataset and corresponding results are available at https://github.com/a-trioux/Subjective-Fidelity-Assessment-Talking-Head.},
  keywords={Measurement;Visualization;Head;Signal processing;Feature extraction;Animation;Behavioral sciences;Synchronization;Speech processing;Faces;Audio- and Video-Driven Talking Head Generation;Multimodal Fidelity Assessment;AIGC;Generative models;Video conferencing},
  doi={10.1109/ICASSP49660.2025.10888660},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10600856,
  author={Hossain, Md Imran and Zamzmi, Ghada and Mouton, Peter and Sun, Yu and Goldgof, Dmitry},
  booktitle={2024 IEEE 37th International Symposium on Computer-Based Medical Systems (CBMS)}, 
  title={Enhancing Concept-Based Explanation with Vision-Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={219-224},
  abstract={Although concept-based approaches are widely used to explain a model’s behavior and assess the contributions of different concepts in decision-making, identifying relevant concepts can be challenging for non-experts. This paper introduces a novel method that simplifies concept selection by leveraging the capabilities of a state-of-the-art large Vision-Language Model (VLM). Our method employs a VLM to select textual concepts that describe the classes in the target dataset. We then transform these influential textual concepts into human-readable image concepts using a text-to-image model. This process allows us to explain the targeted network in a post-hoc manner. Further, we use directional derivatives and concept activation vectors to quantify the importance of the generated concepts. We evaluate our method on a neonatal pain classification task, analyzing the sensitivity of the model’s output for the generated concepts. The results demonstrate that the VLM not only generates coherent and meaningful concepts that are easily understandable by non-experts but also achieves performance comparable to that of natural image concepts without the need for additional annotation costs.},
  keywords={Pediatrics;Tongue;Sensitivity;Pain;Statistical analysis;Text to image;Mouth;Explainability;Generative Artificial Intelligence;Deep Neural Networks;Concept-based XAI},
  doi={10.1109/CBMS61543.2024.00044},
  ISSN={2372-9198},
  month={June},}@INPROCEEDINGS{10786497,
  author={Stone, William and Stone, Samuel and Lindstedt, John K.},
  booktitle={2024 IEEE Western New York Image and Signal Processing Workshop (WNYISPW)}, 
  title={Beyond Scale: Deductive Reasoning Capabilities in Large Language Models Through the Lens of the Wason Selection Task}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Large Language Models (LLMs) have demonstrated remarkable capabilities in various natural language processing tasks, garnering significant public interest, but their ability to perform deductive reasoning remains an open question. Understanding the quality of answers generated by language models is of increasing importance as they are becoming applied to real-world applications ranging from customer service to medicine. It’s essential that the public trusts language models applied in such contexts. A trusted framework for evaluating the deductive reasoning abilities of LLMs would aid in public understanding of the limitations of such models. As inferencing LLMs is computationally expensive, smaller models may be chosen to limit costs or for real-time applications, but this could result in unexpected degradation in the quality of reasoning without impacting obvious signs in the soundness or grammar of responses. This paper evaluates the ability for a range of popular, publicly-available LLMs to reason using the Wason Selection Criteria, an established test of deductive reasoning, characterizing the impact of model size on performance. Results indicate that performance on Wason selection criteria could be a useful metric to evaluate degradation in reasoning in model pruning, though this metric alone does not provide a comprehensive assessment of model performance.},
  keywords={Training;Degradation;Accuracy;Systematics;Computational modeling;Large language models;Signal processing;Cognition;Real-time systems;Natural language processing;Artificial intelligence;Generative AI;Large Language Models;Trusted AI},
  doi={10.1109/WNYISPW63690.2024.10786497},
  ISSN={2471-9242},
  month={Nov},}@ARTICLE{10887195,
  author={Yang, Jing and Intan Raihana Ruhaiyem, Nur and Zhou, Chichun},
  journal={IEEE Access}, 
  title={A 3M-Hybrid Model for the Restoration of Unique Giant Murals: A Case Study on the Murals of Yongle Palace}, 
  year={2025},
  volume={13},
  number={},
  pages={38809-38824},
  abstract={The unique giant murals of Yongle Palace, as valuable cultural heritage, have suffered damage and urgently require restoration. Deep learning inpainting algorithm offers promising solutions for image restoration. However, the restoration of unique giant murals presents two challenges: 1) The unique and scarce data of mural poses significant training difficulties, and 2) the giant size leads to a wider range of defect types and sizes, increasing the complexity of restoration. To address these challenges, a 3M-Hybrid model is proposed. Firstly, on the data level, based on the frequency characteristics of mural data, multi-frequency complementary learning is employed to enhance the model’s restoration capability. Secondly, on the model structure level, a pre-trained Visual Transformer (VIT) is integrated into the Convolutional Neural Networks (CNN) module to alleviate data scarcity and reduce domain bias. Finally, seam and structural distortion problems arising from repairing oversized defects are mitigated by multi-scale and multi-perspective strategies, including data segmentation and fusion. Experimental results demonstrate the efficacy of our proposed model. In regular-sized mural restoration, it improves Structural Similarity Image Measurement (SSIM) and Peak Signal-to-Noise Ratio (PSNR) by 14.61% and 4.73%, respectively, compared to the best model among four representative CNN models. Additionally, it achieves favorable results in the final restoration of giant murals.},
  keywords={Image restoration;Transformers;Feature extraction;Convolutional neural networks;Data models;Context modeling;Computational modeling;Noise reduction;Generative adversarial networks;Training;Image inpainting;mural inpainting;deep learning},
  doi={10.1109/ACCESS.2025.3542320},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9157090,
  author={Liu, Daquan and Long, Chengjiang and Zhang, Hongpan and Yu, Hanning and Dong, Xinzhi and Xiao, Chunxia},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={ARShadowGAN: Shadow Generative Adversarial Network for Augmented Reality in Single Light Scenes}, 
  year={2020},
  volume={},
  number={},
  pages={8136-8145},
  abstract={Generating virtual object shadows consistent with the real-world environment shading effects is important but challenging in computer vision and augmented reality applications. To address this problem, we propose an end-to-end Generative Adversarial Network for shadow generation named ARShadowGAN for augmented reality in single light scenes. Our ARShadowGAN makes full use of attention mechanism and is able to directly model the mapping relation between the virtual object shadow and the real-world environment without any explicit estimation of the illumination and 3D geometric information. In addition, we collect an image set which provides rich clues for shadow generation and construct a dataset for training and evaluating our proposed ARShadowGAN. The extensive experimental results show that our proposed ARShadowGAN is capable of directly generating plausible virtual object shadows in single light scenes. Our source code is available at https://github.com/ldq9526/ARShadowGAN.},
  keywords={Rendering (computer graphics);Lighting;Three-dimensional displays;Cameras;Light sources;Solid modeling;Training},
  doi={10.1109/CVPR42600.2020.00816},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{10205475,
  author={Yang, Honghui and He, Tong and Liu, Jiaheng and Chen, Hua and Wu, Boxi and Lin, Binbin and He, Xiaofei and Ouyang, Wanli},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={GD-MAE: Generative Decoder for MAE Pre-Training on LiDAR Point Clouds}, 
  year={2023},
  volume={},
  number={},
  pages={9403-9414},
  abstract={Despite the tremendous progress of Masked Autoencoders (MAE) in developing vision tasks such as image and video, exploring MAE in large-scale 3D point clouds remains challenging due to the inherent irregularity. In contrast to previous 3D MAE frameworks, which either design a complex decoder to infer masked information from maintained regions or adopt sophisticated masking strategies, we instead propose a much simpler paradigm. The core idea is to apply a Generative Decoder for MAE (GD-MAE) to automatically merges the surrounding context to restore the masked geometric knowledge in a hierarchical fusion manner. In doing so, our approach is free from introducing the heuristic design of decoders and enjoys the flexibility of exploring various masking strategies. The corresponding part costs less than 12% latency compared with conventional methods, while achieving better performance. We demonstrate the efficacy of the proposed method on several large-scale benchmarks: Waymo, KITTI, and ONCE. Consistent improvement on downstream detection tasks illustrates strong robustness and generalization capability. Not only our method reveals state-of-the-art results, but remarkably, we achieve comparable accuracy even with 20% of the labeled data on the Waymo dataset. Code will be released.},
  keywords={Point cloud compression;Representation learning;Three-dimensional displays;Laser radar;Transformers;Robustness;Decoding;Autonomous driving},
  doi={10.1109/CVPR52729.2023.00907},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{11140170,
  author={Sagili, Sreenivas Reddy and K, Veeranjaneyulu and Puli, Balaram and Sundaramoorthy, Pandian and R, Murugadoss and N V, Keerthana},
  booktitle={2025 6th International Conference for Emerging Technology (INCET)}, 
  title={Advancing Cervical Cancer Identification using Generative-based Adversarial Networks: An Integrative Learning Methodology}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={The Proposed system leveraged on Generative based Adversarial Networks (GANs) to enhance the detection and diagnosing of cervical based cancer by an integrative deep learning-based methodology. The system provides a comprehensive graphical representations of core cervical cancer-depended metrics, including age distribution, histological type distribution, tumour size distribution, and HPV based status distribution. By analyzing these parameters, the system aims to improve the accuracy level and efficacy of cervical cancer screening processes. The persons age distribution analysis helps to identify prevalent age groups affected by the disorder, while the histological type of distribution offers insights into the most common histological subtypes. Depending on tumour size, distribution will aid in understanding the range and severity of tumour sizes over the patients. Additionally, HPV status distribution highlighted the prevalence of HPV infection in cervical cancer cases. With advanced data visualization mechanisms, the proposed system facilitates a better understanding of the underlying data patterns and risk factors associated with cervical cancer, ultimately contributing to more informed clinically generated decision-making and to have a personalized patient care.},
  keywords={Measurement;Squamous cell carcinoma;Decision making;Surgery;Vaccines;Radiation therapy;Public healthcare;Prognostics and health management;Cervical cancer;Tumors;HPV status distribution analysis;histologically type distribution;clinical decision-making process;cervical type of cancer detection},
  doi={10.1109/INCET64471.2025.11140170},
  ISSN={2996-4490},
  month={May},}@INPROCEEDINGS{11095132,
  author={Ji, Bin and Pan, Ye and Liu, Zhimeng and Tan, Shuai and Jin, Xiaogang and Yang, Xiaokang},
  booktitle={2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={POMP: Physics-constrainable Motion Generative Model through Phase Manifolds}, 
  year={2025},
  volume={},
  number={},
  pages={22690-22701},
  abstract={Numerous researches on real-time motion generation primarily focus on kinematic aspects, often resulting in physically implausible outcomes. In this paper, we present POMP ("Physics-cOnstrainable Motion Generative Model through Phase Manifolds"), a kinematics-based framework that synthesizes physically realistic motions by leveraging phase manifolds to align motion priors with physics constraints. POMP operates as a frame-by-frame autoregressive model with three core components: a diffusion-based kinematic module, a simulation-based dynamic module, and a phase encoding module. At each timestep, the kinematic module first generates an initial pose, which is subsequently revised by the dynamic module through a simulation step to incorporate physical constraints. While individual simulation steps induce negligible kinematic distortion, accumulated discrepancies can drive the result beyond the motion prior learned by the kinematic module, leading to failure in subsequent motion generation. To address this, the phase encoding module applies semantic alignment in the phase manifold, projecting the simulated result back to the motion prior. Moreover, we present a pipeline in Unity for generating terrain maps and capturing full-body motion impulses from existing motion capture dataset. The collected terrain topology and motion impulse data facilitate the training of POMP, enabling it to robustly respond to underlying contact forces and applied dynamics. Extensive evaluations demonstrate the efficacy of POMP across various tasks.},
  keywords={Manifolds;Training;Target tracking;Simulation;Dynamics;Kinematics;Encoding;Real-time systems;Topology;Physics},
  doi={10.1109/CVPR52734.2025.02113},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{9315189,
  author={S, Dhivya and S, Mohanavalli and S, Karthika and S, Shivani and R, Mageswari},
  booktitle={2020 4th International Conference on Computer, Communication and Signal Processing (ICCCSP)}, 
  title={GAN based Data Augmentation for Enhanced Tumor Classification}, 
  year={2020},
  volume={},
  number={},
  pages={1-5},
  abstract={With the incredible breakthrough of medical imaging intertwined with the computer aided diagnosis and artificial intelligence paved a way for the early detection of tumor. Though Deep Neural Networks is the new paradigm in the field of computer vision yet, they are highly reliable on large dataset to avoid overfitting. To overcome this problem, our work focuses on data augmentation, a quintessential solution to handle the inadequate medical data. This paper involves conventional data augmentation using affine transformations. The conventionally augmented data are further synthesized using General Adversarial Networks (GANs). These methods are employed on the benchmark breast tumor datasets namely MIAS, DDSM and INBreast. The classification of benchmark dataset resulted in an accuracy of 69.85%, which are increased by the conventional data augmentation techniques to 88%. The synthesized image when merged with the original benchmark dataset and the conventional augmented images outperformed the others with an increased accuracy of 94%.},
  keywords={Generative adversarial networks;Breast;Biomedical imaging;Training;Medical diagnostic imaging;Mammography;Feature extraction;General Adversarial Networks;CNN;Breast Tumor;data augmentation;classification},
  doi={10.1109/ICCCSP49186.2020.9315189},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10113002,
  author={Aishwarya, R. and Froila Stephanie, P.A and Yogitha, R. and Srinivas, Chegoni Dhanusha},
  booktitle={2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS)}, 
  title={Aquatic Plant Disease Detection Using Deep Learning}, 
  year={2023},
  volume={1},
  number={},
  pages={426-430},
  abstract={A subset of artificial intelligence is deep learning. With the advantages of feature extraction and automatic learning, it has received a lot of attention in recent years from both academic and professional circles. Natural language processing, voice processing, and image and video processing all make extensive use of it. In addition, it has developed into a hub for research in the area of aquatic plant protection, involving the study of pest ranges and the diagnosis of illnesses affecting aquatic plants. Deep learning may be used to recognise aquatic plant diseases in order to minimise the limitations associated with artificially selecting disease spot features, increase objectivity in the extraction of aquatic plant disease features, and quicken the pace of scientific and technical advancement. This review details the development of deep learning technology in recent years for identifying leaf diseases. Using deep learning and cutting-edge imaging techniques, In this work, we discuss the current patterns and challenges in the identification of aquatic plant leaf disease. We anticipate that this work will be a useful tool for scientists looking into the identification of aquatic plant diseases. We also talked about some of the current difficulties and issues that need to be fixed at the same time.},
  keywords={Deep learning;Plant diseases;Imaging;Crops;Predictive models;Feature extraction;Distortion;Aquatic;Plant disease;Detection;Features;Deep Learning;Agriculture and Prediction},
  doi={10.1109/ICACCS57279.2023.10113002},
  ISSN={2575-7288},
  month={March},}@INPROCEEDINGS{10679447,
  author={Saunders, Braden J. and de Grande, Robson E. and Carvalho, Glaucio H.S. and Woungang, Isaac},
  booktitle={2024 IEEE International Conference on Cyber Security and Resilience (CSR)}, 
  title={Deep Graph Learning for DDoS Detection and Multi-Class Classification IDS}, 
  year={2024},
  volume={},
  number={},
  pages={96-100},
  abstract={Critical infrastructure systems have been preyed on by cyber criminals that target to disrupt their operations and national security. Among the most nefarious attacks, the Distributed Denial of Service (DDoS) attack is wreaking havoc on the Telecommunications sector. This paper invests in the vision that Artificial Intelligence (AI) plays an important role in shoring up the cybersecurity of critical infrastructure providers by detecting and classifying malicious engagements. In this respect, we propose an efficient and dependable DDoS specialized intrusion section system (IDS). The proposed system is empowered by Graph Convolutional Networks (GCN), a deep learning technique, which is capable of capturing the topological and statistical information between the attack network and the victim network. The results show that the proposed GCN IDS can detect and classify multiple variations of DoS with a high confidence level.},
  keywords={Measurement;Graph convolutional networks;Denial-of-service attack;Generative adversarial networks;Critical infrastructure;Telecommunications;Computer crime;Distributed Denial of Service;Deep Learning;Graph Neural Networks;Intrusion Detection Systems},
  doi={10.1109/CSR61664.2024.10679447},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9847877,
  author={Banothu, Balaji and Tulasiram, Jinaga},
  booktitle={2022 2nd International Conference on Intelligent Technologies (CONIT)}, 
  title={Sensitive Lesions and Tumour Detection in Brain using Deep Convolutional Neural Network}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={A brain tumour is an abnormal development of abnormal brain cells that causes harm to the blood vessels and neurons of the human body. The two forms of brain tumours are benign and malignant. It is vital to diagnose a brain tumour early in order to save the life of someone who is in danger. According to research conducted in the United Kingdom, only approximately 15 persons out of 100 will be able to survive for ten years or longer after being recognised. Because of the advent of Artificial Intelligence, Deep Learning models are now being utilised to identify brain cancers using Magnetic Resonance Imaging (MRI) images. MRI is a type of scanning method that uses high magnetic fields and radio waves to obtain detailed pictures of the interior body. The notion of Transfer Learning and Residual Networks were employed in the suggested work. The model utilised is a classification task that uses MRI images to determine whether or not a tumour is present. We may use the same transfer learning techniques to precisely pinpoint the tumour once it has been found. We utilised several optimizers in Resnet-50 to see how our model responds to changes in optimization strategies. Our suggested model has accuracy with Amsgrad optimizer compared with Adam optimizer, demonstrating improved robustness over the state-of-the-art techniques.},
  keywords={Magnetic resonance imaging;Transfer learning;Brain modeling;Generative adversarial networks;Robustness;Convolutional neural networks;Task analysis;Benign;Malignant;Magnetic Resonance Imaging;Transfer learning;Resnet-50;Optimizers;Adam;Amsgrad},
  doi={10.1109/CONIT55038.2022.9847877},
  ISSN={},
  month={June},}@INPROCEEDINGS{10825993,
  author={Ari, Ismail and Balkan, Kerem and Pirbhulal, Sandeep and Abie, Habtamu},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={Ensuring Security Continuum from Edge to Cloud : Adaptive Security for IoT-based Critical Infrastructures using FL at the Edge}, 
  year={2024},
  volume={},
  number={},
  pages={4921-4929},
  abstract={Securing IoT-based Critical Infrastructures (CI) necessitates a cross-domain management of IT/OT systems encompassing hardware, software, data, and models along with their application scenarios. There is no feasible way to manually secure such heterogeneous, weakly-protected and physically distributed systems. In this work, we propose an adaptive security framework that uses Federated Learning (FL) for IoT data monitoring and analysis at the edge. We use Deep Neural Network (DNN) model selection and switching inside FL to address performance and security problems. We began prototyping the Edge-FL system using single board computers (a Raspberry Pi-5 cluster). We measure and compare the impacts of hardware heterogeneity. The framework aims to provide continuum of security and intelligence from IoT device to Edge to Cloud.},
  keywords={Performance evaluation;Training;Adaptation models;Cloud computing;Adaptive systems;Artificial neural networks;Switches;Hardware;Security;Internet of Things;Adaptive security;IoT;critical infrastructures;attack surface;federated learning;edge;cloud;5G;6G;GAN},
  doi={10.1109/BigData62323.2024.10825993},
  ISSN={2573-2978},
  month={Dec},}@ARTICLE{9116840,
  author={Singh, Gary},
  journal={IEEE Computer Graphics and Applications}, 
  title={Zen Mind, Machine Mind}, 
  year={2020},
  volume={40},
  number={4},
  pages={5-7},
  abstract={Artificial intelligence and machine learning are often discussed in grandiose contexts. Global technologies, trillion–dollar companies or sweeping societal implications tend to dominate the arguments. Terms like big data and petabyte storage evoke vastness. As an artist, David Young wants nothing to do with any of this. He would rather concern himself with beauty, mystery, and the little things in life—machine life, that is. There is nothing “big” about his work. },
  keywords={Generative adversarial networks;Visualization;Media;Companies;Machine learning;Big Data},
  doi={10.1109/MCG.2020.2995535},
  ISSN={1558-1756},
  month={July},}@INPROCEEDINGS{8781970,
  author={González, Francisco J. and Satizábal, Héctor F. and Perez-Uribe, Andres and López, Jesús A.},
  booktitle={2019 IEEE Colombian Conference on Applications in Computational Intelligence (ColCACI)}, 
  title={DCGAN Model Used To Generate Body Gestures On a Human-Humanoid Interaction System}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  abstract={The current availability of the humanoid robots opens up a wide range of applications, for instance, in the domain of hospitality the humanoids can be programmed to behave autonomous ways to provide help to people. The aspect of the humanoids and the humanness of interaction are key components of success. We developed a system to endow the humanoid robot Pepper, from SoftBank Robotics, with the capability of both: identify the emotion state of the humans and exhibiting emotional states via gestures and postures generated using a DCGAN model to learn from the human body language and to create originals body expressions to exhibit like-human movements.},
  keywords={Gallium nitride;Robot sensing systems;Humanoid robots;Skeleton;Service robots;Biological system modeling;Artificial Neural Networks;Generative Adversarial Model;Humanoid Robots;Human-Humanoid Interaction},
  doi={10.1109/ColCACI.2019.8781970},
  ISSN={},
  month={June},}@ARTICLE{9992111,
  author={Tu, Liyun and Talbot, Austin and Gallagher, Neil M. and Carlson, David E.},
  journal={IEEE Transactions on Signal Processing}, 
  title={Supervising the Decoder of Variational Autoencoders to Improve Scientific Utility}, 
  year={2022},
  volume={70},
  number={},
  pages={5954-5966},
  abstract={Probabilistic generative models are attractive for scientific modeling because their inferred parameters can be used to generate hypotheses and design experiments. This requires that the learned model accurately represents the input data and yields a latent space that effectively predicts outcomes relevant to the scientific question. Supervised Variational Autoencoders (SVAEs) have previously been used for this purpose, as a carefully designed decoder can be used as an interpretable generative model of the data, while the supervised objective ensures a predictive latent representation. Unfortunately, the supervised objective forces the encoder to learn a biased approximation to the generative posterior distribution, which renders the generative parameters unreliable. This issue has remained undetected as reconstruction losses commonly used to evaluate model performance do not detect bias in the encoder. We address this previously-unreported issue by developing a new framework (SOS-VAE) that updates the decoder parameters, rather than the encoder, to induce a predictive latent representation. This ensures that the encoder maintains a reliable posterior approximation and the decoder parameters can be effectively interpreted. We extend this technique to allow the user to trade-off the bias in the generative parameters for improved predictive performance, acting as an intermediate option between SVAEs and SOS-VAE. We also use this methodology to address missing data issues that often arise when combining recordings from multiple scientific experiments. We demonstrate the effectiveness of these developments using synthetic data and electrophysiological recordings with an emphasis on how our learned representations can be used to design scientific experiments.},
  keywords={Predictive models;Decoding;Standards;Computational modeling;Brain modeling;Task analysis;Recording;Scientific analysis;probabilistic generative models;interpretable models;supervised learning;variational autoencoders;second-order gradient},
  doi={10.1109/TSP.2022.3230329},
  ISSN={1941-0476},
  month={},}@INPROCEEDINGS{10628537,
  author={Salman, Ahmed and Creese, Sadie and Goldsmith, Michael},
  booktitle={2024 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW)}, 
  title={Position Paper: Leveraging Large Language Models for Cybersecurity Compliance}, 
  year={2024},
  volume={},
  number={},
  pages={496-503},
  abstract={This position paper proposes the use of Large Language Models (LLMs) to evaluate the compliance of cybersecurity controls with organisational policies. We high-light the challenges related to efficiency, accuracy, and coverage associated with conventional compliance approaches and discuss how LLMs can address these issues. Additionally, we emphasise that organisational events and data can provide insightful evidence to measure true cybersecurity compliance value, rather than relying solely on documentary evidence. We develop our position by exploring current research directions in the use of LLMs within cybersecurity and demonstrating how their capability to assimilate and analyse unstructured data can be leveraged to provide a comprehensive compliance assessment for organisations. We present our research agenda to investigate this hypothesis and outline a comprehensive roadmap for studying the utility of LLMs in cybersecurity compliance.},
  keywords={Accuracy;Generative AI;Large language models;Current measurement;Computer security;Generative AI;LLMs;Large language Models;Cybersecurity Compliance},
  doi={10.1109/EuroSPW61312.2024.00061},
  ISSN={2768-0657},
  month={July},}@INPROCEEDINGS{11167568,
  author={Bhagwat, Swaroop and Panchangam, Sraina and Sawant, Aryaan and Sharma, Prakhar and Nayak, Udaychandra},
  booktitle={2025 5th International Conference on Intelligent Technologies (CONIT)}, 
  title={NyAI Saathi - Legal Research Tool leveraging GenAI (RAG)}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={This paper presents NyAI Saathi, a GenAI-powered legal research assistant that enhances legal information retrieval using Retrieval-Augmented Generation (RAG) and vector-based semantic search. It provides context-aware legal insights with references, streamlining research for legal professionals, researchers, and students. The system integrates Qdrant for efficient document retrieval, a Fast-API backend, and a React.js front end for seamless interaction. Built on the Haystack framework, it supports voice-to-text input, text-to-speech output as voice assistance, dynamically suggested queries helping the users to frame their own queries and multilingual support. By automating legal research, NyAI Saathi reduces workload, improves decisionmaking, and enhances workflow efficiency. This paper details its architecture, implementation, and performance, demonstrating its scalability as an AI-driven legal research solution.},
  keywords={Law;Semantic search;Generative AI;Databases;Scalability;Retrieval augmented generation;Information retrieval;Vectors;Multilingual;Text to speech;Generative AI;Retrieval-Augmented Generation (RAG);Vector Databases;Qdrant;AI-driven Legal Assistance;Multilingual Support},
  doi={10.1109/CONIT65521.2025.11167568},
  ISSN={},
  month={June},}@INPROCEEDINGS{10912328,
  author={Mathur, Nishad and Sharma, Ashutosh and Kaushik, Shubh and Bakkialakshmi, V S and Kavadiya, Vishishta and Aneja, Nagender},
  booktitle={2024 2nd International Conference on Advances in Computation, Communication and Information Technology (ICAICCIT)}, 
  title={SAGA-Integrating AI for Enhanced Recruitment: A System with Audio-Video Proctoring and Comprehensive Evaluation}, 
  year={2024},
  volume={1},
  number={},
  pages={395-399},
  abstract={AI has transformed recruitment, overcoming logictical issues and interviewer prejudice. The COVID-19 epidemic compounded matters. Advanced AI interview systems use natural language processing and computer vision algorithms to assess candidates’ verbal and non-verbal cues using audio and video. Systems have uniform standards, high integrity, security, and scalability. In addition, speech, sentiment, face, and emotion detection are provided. Online learning and telemedicine could be added to recruitment apps. These technologies improve feedback quality and transparency for safe, efficient, and balanced global change.},
  keywords={Generative AI;Scalability;Face recognition;Telemedicine;Natural language processing;Information and communication technology;Security;Interviews;Standards;Recruitment;Proctoring Systems;Generative AI;Comparative Evaluation;Unbiased Assessment;Automated Analysis;Environmental Monitoring},
  doi={10.1109/ICAICCIT64383.2024.10912328},
  ISSN={},
  month={Nov},}@INBOOK{10948925,
  author={Banafa, Ahmed},
  booktitle={Artificial Intelligence in Action: Real-World Applications and Innovations}, 
  title={43 Objective-driven AI: Optimizing for Specific Goals in a ComplexWorld}, 
  year={2025},
  volume={},
  number={},
  pages={283-292},
  abstract={This comprehensive book dives deep into the current landscape of AI, exploring its fundamental principles, development challenges, potential risks, and the cutting-edge breakthroughs that are propelling it forward. Artificial intelligence (AI) is rapidly transforming industries and societies worldwide through groundbreaking innovations and real-world applications. Starting with the core concepts, the book examines the various types of AI systems, generative AI models, and the complexities of machine learning. It delves into the programming languages driving AI development, data pipelines, model creation and deployment processes, while shedding light on issues like AI hallucinations and the intricate path of machine unlearning. The book then showcases the remarkable real-world applications of AI across diverse domains. From preventing job displacement and promoting environmental sustainability, to enhancing disaster response, drone technology, and even nuclear energy innovation, it highlights how AI is tackling complex challenges and driving positive change. The book also explores the double-edged nature of AI, recognizing its tremendous potential while cautioning about the risks of misuse, unintended consequences, and the urgent need for responsible development practices. It examines the intersection of AI and fields like operating system design, warfare, and semiconductor technology, underscoring the wide-ranging implications of this transformative force. As the quest for artificial general intelligence (AGI) and superintelligent AI systems intensifies, the book delves into cutting-edge research, emerging trends, and the pursuit of multimodal, explainable, and causally aware AI systems. It explores the symbiotic relationship between AI and human creativity, the rise of user-friendly "casual AI," and the potential of AI to tackle open-ended tasks. This is an essential guide for understanding the profound impact of AI on our world today and its potential to shape our future. From the frontiers of innovation to the challenges of responsible development, this book offers a comprehensive and insightful exploration of the remarkable real-world applications and innovations driving the AI revolution.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770046190},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10948925},}@ARTICLE{9031432,
  author={Li, Mingyu and Liu, Zhiqiang and Shi, Xuanhua and Jin, Hai},
  journal={IEEE Access}, 
  title={ATCS: Auto-Tuning Configurations of Big Data Frameworks Based on Generative Adversarial Nets}, 
  year={2020},
  volume={8},
  number={},
  pages={50485-50496},
  abstract={Big data processing frameworks (e.g., Spark, Storm) have been extensively used for massive data processing in the industry. To improve the performance and robustness of these frameworks, developers provide users with highly-configurable parameters. Due to the high-dimensional parameter space and complicated interactions of parameters, manual tuning of parameters is time-consuming and ineffective. Building performance-predicting models for big data frameworks is challenging for several reasons: (1) the significant time required to collect training data and (2) the poor accuracy of the prediction model when training data are limited. To meet this challenge, we proposes an auto-tuning configuration parameters system (ATCS), a new auto-tuning approach based on Generative Adversarial Nets (GAN). ATCS can build a performance prediction model with less training data and without sacrificing model accuracy. Moreover, an optimized Genetic Algorithm (GA) is used in ATCS to explore the parameter space for optimum solutions. To prove the effectiveness of ATCS, we select five frequently-used workloads in Spark, each of which runs on five different sized data sets. The results demonstrate that ATCS improves the performance of five frequently-used Spark workloads compared to the default configurations. We achieved a performance increase of 3.5× on average, with a maximum of 6.9×. To obtain similar model accuracy, experiment results also demonstrate that the quantity of ATCS training data is only 6% of Deep Neural Network (DNN) data, 13% of Support Vector Machine (SVM) data, 18% of Decision Tree (DT) data. Moreover, compared to other machine learning models, the average performance increase of ATCS is 1.7× that of DNN, 1.6× that of SVM, 1.7× that of DT on the five typical Spark programs.},
  keywords={Predictive models;Data models;Training data;Big Data;Sparks;Genetic algorithms;Support vector machines;Big data;generative adversarial nets;spark;genetic algorithm;automatic tune parameters},
  doi={10.1109/ACCESS.2020.2979812},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9760981,
  author={Gandhi, Vaibhav C. and Gandhi, Priyesh P.},
  booktitle={2022 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)}, 
  title={A Survey - Insights of ML and DL in Health Domain}, 
  year={2022},
  volume={},
  number={},
  pages={239-246},
  abstract={For the past few years, concepts like Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL) have been slowly infiltrating the health industry, bringing with them technology and solutions that are transforming the face of healthcare. Each of these technologies is interconnected, offering something unique to the business and altering how medical professionals manage their duties and provide patient care. While AI is the most well-known of the technical terminology, DL in healthcare is a subset of AI that has disruptive potential and adds a new layer to medical technology solutions. DL is gradually becoming the leader in the field of ML, which is entering its golden age. To develop computer models, DL employs numerous layers to represent data abstractions.},
  keywords={Industries;Deep learning;Terminology;Neural networks;Medical services;Network architecture;Predictive analytics;Computer Vision;Artificial Intelligence;Machine Learning;Deep Learning;Neural Network;Healthcare Industry;Artificial Neural Network},
  doi={10.1109/ICSCDS53736.2022.9760981},
  ISSN={},
  month={April},}@INBOOK{10955670,
  author={Siva Kumar, Ram Shankar and Anderson, Hyrum and Schneier, Bruce},
  booktitle={Not with a Bug, But with a Sticker: Attacks on Machine Learning Systems and What To Do About Them}, 
  title={Salt, Tape, and Split&#x2010;Second Phantoms}, 
  year={2023},
  volume={},
  number={},
  pages={29-54},
  abstract={Summary <p>The cartoon movie The Mitchells vs. the Machines is available in the kids' section of Netflix, but its representation of artificial intelligence (AI) systems is quite realistic and worthy of adult attention. This chapter explores how the Goliath of AI systems can be brought down&#x2014;not just by the skilled David Benioffs but also by amateurs, ragtags, and bobtails. The phantom image existed for a mere 125 millisecond&#x2014;short enough for humans to miss it, but long enough for Tesla's sensors to pick it up. All it takes for an attacker to confuse a complicated machine learning algorithm is to identify and hack these shortcuts. An amateur can cause traffic jams on Google Maps with a wagon full of phones, entrap a self&#x2010;driving car with salt and electric tape, and evade porn filters by coloring the pictures green.</p>},
  keywords={Artificial intelligence;Computer vision;Shape;Error analysis;Automobiles;Computational modeling;Salt;Phantoms;Object recognition;Internet},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781119884903},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10955670},}@INPROCEEDINGS{9585857,
  author={Makarov, Ilya and Borisenko, Gleb},
  booktitle={2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)}, 
  title={Depth Inpainting via Vision Transformer}, 
  year={2021},
  volume={},
  number={},
  pages={286-291},
  abstract={Depth inpainting is a crucial task for working with augmented reality. In previous works missing depth values are completed by convolutional encoder-decoder networks, which is a kind of bottleneck. But nowadays vision transformers showed very good quality in various tasks of computer vision and some of them became state of the art. In this study, we presented a supervised method for depth inpainting by RGB images and sparse depth maps via vision transformers. The proposed model was trained and evaluated on the NYUv2 dataset. Experiments showed that a vision transformer with a restrictive convolutional tokenization model can improve the quality of the inpainted depth map.},
  keywords={Training;Image color analysis;Computational modeling;Pipelines;Transformers;Tokenization;Graph neural networks;Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality;Computing methodologies;Artificial intelligence;Computer vision;Reconstruction;3D imaging;Computational photograph},
  doi={10.1109/ISMAR-Adjunct54149.2021.00065},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10956356,
  author={Chauhan, Shanvi and Lila, Manish Kumar and Kumar, Gotte Ranjith},
  booktitle={2024 International Conference on Information Science and Communications Technologies (ICISCT)}, 
  title={A Fine-Tuned ConvNextSmall Approach for Accurate Footwear Classification: Model Performance and Evaluation}, 
  year={2024},
  volume={},
  number={},
  pages={428-433},
  abstract={Emphasizing three independent categories: shoes, sandals, and boots, we study in this work the application of deep learning techniques for footwear classification. We accomplished this with a well-known performance and efficiency in image classification challenges and finely tuned ConvNextSmall convolutional neural network (CNN) architecture. The dataset employed consists of 27,000 labeled images overall; these were divided into training (12,000), validation (7,500), and testing (7,500) groups. Originally tailored to maximize performance for this specific footwear category task, the model was pre-trained using a large-scale image dataset. Several techniques of data augmentation improved generalization; the model was trained with an adaptive learning rate strategy to avoid overfitting. On the test set, evaluation with a 99% accuracy yielded quite exceptional performance for the model. This high degree of performance reveals the prospects of employing finely adjusted ConvNextSmall architectures for accurate and efficient classification in the footwear domain, therefore offering a solid solution for automated retail, inventory management, and fashion industry uses. While reducing inequality in technology access and deployment, the results enable good work and economic growth, so enabling sustainable development using responsible consumption and production, industry innovation, and solution providing.},
  keywords={Training;Economics;Deep learning;Adaptation models;Accuracy;Footwear;Clothing industry;Convolutional neural networks;Image classification;Testing;Artificial intelligence;Deep learning;Footwear classification;Economic growth;Image classification},
  doi={10.1109/ICISCT64202.2024.10956356},
  ISSN={},
  month={Nov},}@ARTICLE{9990918,
  author={Cao, Hu and Chen, Guang and Li, Zhijun and Feng, Qian and Lin, Jianjie and Knoll, Alois},
  journal={IEEE/ASME Transactions on Mechatronics}, 
  title={Efficient Grasp Detection Network With Gaussian-Based Grasp Representation for Robotic Manipulation}, 
  year={2023},
  volume={28},
  number={3},
  pages={1384-1394},
  abstract={Deep learning methods have achieved excellent results in the field of grasp detection. However, deep learning-based models for general object detection lack the proper balance of accuracy and inference speed, resulting in poor performance in real-time grasp tasks. This work proposes an efficient grasp detection network with n-channel images as inputs for robotic grasp. The proposed network is a lightweight generative structure for grasp detection in one stage. Specifically, a Gaussian kernel-based grasp representation is introduced to encode the training samples, embodying the maximum center that possesses the highest grasp confidence. A receptive field block is plugged into the bottleneck to improve the model's feature discriminability. In addition, pixel-based and channel-based attention mechanisms are used to construct a multidimensional attention fusion network to fuse valuable semantic information, achieved by suppressing noisy features and highlighting object features. The proposed method is evaluated on the Cornell, Jacquard, and extended OCID grasp datasets. The experimental results show that our method achieves excellent balancing accuracy and running speed performance. The network gets a running speed of $\text{6}\,\text{ms}$, achieving better performance on the Cornell, Jacquard, and extended OCID grasp datasets with 97.8, 95.6, and 76.4% accuracy, respectively. Subsequently, an excellent grasp success rate in a physical environment is obtained using the UR5 robot arm.},
  keywords={Robots;Feature extraction;Task analysis;Grasping;Kernel;Robot kinematics;Training;Efficient grasp detection;fully convolutional neural network;Gaussian-based grasp representation (GGR);multidimension attention fusion;receptive field block (RFB)},
  doi={10.1109/TMECH.2022.3224314},
  ISSN={1941-014X},
  month={June},}@INPROCEEDINGS{9878684,
  author={Lee, Seung Hyun and Roh, Wonseok and Byeon, Wonmin and Yoon, Sang Ho and Kim, Chanyoung and Kim, Jinkyu and Kim, Sangpil},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Sound-Guided Semantic Image Manipulation}, 
  year={2022},
  volume={},
  number={},
  pages={3367-3376},
  abstract={The recent success of the generative model shows that leveraging the multi-modal embedding space can manipu-late an image using text information. However, manipulating an image with other sources rather than text, such as sound, is not easy due to the dynamic characteristics of the sources. Especially, sound can convey vivid emotions and dynamic expressions of the real world. Here, we propose a framework that directly encodes sound into the multi-modal (image-text) embedding space and manipulates an image from the space. Our audio encoder is trained to pro-duce a latent representation from an audio input, which is forced to be aligned with image and text representations in the multi-modal embedding space. We use a direct latent op-timization method based on aligned embeddings for sound-guided image manipulation. We also show that our method can mix different modalities, i.e., text and audio, which en-rich the variety of the image modification. The experiments on zero-shot audio classification and semantic-level image classification show that our proposed model outperforms other text and sound-guided state-of-the-art methods.},
  keywords={Computer vision;Codes;Computational modeling;Semantics;Dynamics;Pattern recognition;Unsupervised learning;Image and video synthesis and generation; Self-& semi-& meta- & unsupervised learning},
  doi={10.1109/CVPR52688.2022.00337},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{10377379,
  author={Nag, Sauradip and Zhu, Xiatian and Deng, Jiankang and Song, Yi-Zhe and Xiang, Tao},
  booktitle={2023 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={DiffTAD: Temporal Action Detection with Proposal Denoising Diffusion}, 
  year={2023},
  volume={},
  number={},
  pages={10328-10340},
  abstract={We propose a new formulation of temporal action detection (TAD) with denoising diffusion, DiffTAD in short. Taking as input random temporal proposals, it can yield action proposals accurately given an untrimmed long video. This presents a generative modeling perspective, against previous discriminative learning manners. This capability is achieved by first diffusing the ground-truth proposals to random ones (i.e., the forward/noising process) and then learning to reverse the noising process (i.e., the backward/denoising process). Concretely, we establish the denoising process in the Transformer decoder (e.g., DETR) by introducing a temporal location query design with faster convergence in training. We further propose a cross-step selective conditioning algorithm for inference acceleration. Extensive evaluations on ActivityNet and THUMOS show that our DiffTAD achieves top performance compared to previous art alternatives. The code is available at https://github.com/sauradip/DiffusionTAD.},
  keywords={Training;Noise reduction;Diffusion processes;Transformers;Inference algorithms;Decoding;Proposals},
  doi={10.1109/ICCV51070.2023.00951},
  ISSN={2380-7504},
  month={Oct},}@ARTICLE{9882141,
  author={Song, Cao and Lu, Wenkai and Wang, Yuqing and Jin, Songbai and Tang, Jinliang and Chen, Lei},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Reservoir Prediction Based on Closed-Loop CNN and Virtual Well-Logging Labels}, 
  year={2022},
  volume={60},
  number={},
  pages={1-12},
  abstract={Reservoir prediction is a significant issue in seismic interpretation, and it is difficult to reach a tradeoff point for the reservoir prediction accuracy and spatial continuity. Nowadays, though numerous machine learning methods have been widely applied in reservoir prediction, so few available well-logging labels are still a major obstacle for improving prediction performance. Considering for such a critical factor, we propose a semisupervised deep-learning framework, in which the closed-loop convolutional neural network (CNN). and virtual well-logging labels are used. The closed-loop CNN, which is consisting of the predictive and generative subnetworks, can be trained directly by using the seismic attribute data not only with well-logging labels but also without well-logging labels. The virtual well-logging labels (Vl) are generated by fusing the results of two existing reservoir predicting methods, one based on polynomial linear regression and the other based on CNN. Vl contributes to improve the spatial continuity and accuracy of the predicted reservoir as constraint items in network training process. Finally, cross-validation experiments on real-field data are carried out, and 3-D field reservoir prediction results show that the proposed method outperforms several existing machine-learning-based methods.},
  keywords={Reservoirs;Convolutional neural networks;Training;Linear regression;Deep learning;Oils;Logic gates;Closed-loop network;convolutional neural network (CNN);data driven;deep learning;reservoir prediction},
  doi={10.1109/TGRS.2022.3205301},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{10376792,
  author={Li, Lijiang and Li, Huixia and Zheng, Xiawu and Wu, Jie and Xiao, Xuefeng and Wang, Rui and Zheng, Min and Pan, Xin and Chao, Fei and Ji, Rongrong},
  booktitle={2023 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={AutoDiffusion: Training-Free Optimization of Time Steps and Architectures for Automated Diffusion Model Acceleration}, 
  year={2023},
  volume={},
  number={},
  pages={7082-7091},
  abstract={Diffusion models are emerging expressive generative models, in which a large number of time steps (inference steps) are required for a single image generation. To accelerate such tedious process, reducing steps uniformly is considered as an undisputed principle of diffusion models. We consider that such a uniform assumption is not the optimal solution in practice; i.e., we can find different optimal time steps for different models. Therefore, we propose to search the optimal time steps sequence and compressed model architecture in a unified framework to achieve effective image generation for diffusion models without any further training. Specifically, we first design a unified search space that consists of all possible time steps and various architectures. Then, a two stage evolutionary algorithm is introduced to find the optimal solution in the designed search space. To further accelerate the search process, we employ FID score between generated and real samples to estimate the performance of the sampled examples. As a result, the proposed method is (i).training-free, obtaining the optimal time steps and model architecture without any training process; (ii). orthogonal to most advanced diffusion samplers and can be integrated to gain better sample quality. (iii). generalized, where the searched time steps and architectures can be directly applied on different diffusion models with the same guidance scale. Experimental results show that our method achieves excellent performance by using only a few time steps, e.g. 17.86 FID score on ImageNet 64 × 64 with only four steps, compared to 138.66 with DDIM.},
  keywords={Training;Computer vision;Image coding;Image synthesis;Computational modeling;Computer architecture;Evolutionary computation},
  doi={10.1109/ICCV51070.2023.00654},
  ISSN={2380-7504},
  month={Oct},}@ARTICLE{6449296,
  author={Doyle, Orla M. and Tsaneva-Atansaova, Krasimira and Harte, James and Tiffin, Paul A. and Tino, Peter and Díaz-Zuccarini, Vanessa},
  journal={IEEE Transactions on Biomedical Engineering}, 
  title={Bridging Paradigms: Hybrid Mechanistic-Discriminative Predictive Models}, 
  year={2013},
  volume={60},
  number={3},
  pages={735-742},
  abstract={Many disease processes are extremely complex and characterized by multiple stochastic processes interacting simultaneously. Current analytical approaches have included mechanistic models and machine learning (ML), which are often treated as orthogonal viewpoints. However, to facilitate truly personalized medicine, new perspectives may be required. This paper reviews the use of both mechanistic models and ML in healthcare as well as emerging hybrid methods, which are an exciting and promising approach for biologically based, yet data-driven advanced intelligent systems.},
  keywords={Diseases;Mathematical model;Biological system modeling;Machine learning;Data models;Genetics;Predictive models;Generative embedding;machine learning (ML);mechanistic models;personalized medicine},
  doi={10.1109/TBME.2013.2244598},
  ISSN={1558-2531},
  month={March},}@ARTICLE{10731578,
  author={Xue, Jinlong and Deng, Yayue and Gao, Yingming and Li, Ya},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Auffusion: Leveraging the Power of Diffusion and Large Language Models for Text-to-Audio Generation}, 
  year={2024},
  volume={32},
  number={},
  pages={4700-4712},
  abstract={Recent advancements in diffusion models and large language models (LLMs) have significantly propelled the field of generation tasks. Text-to-Audio (TTA), a burgeoning generation application designed to generate audio from natural language prompts, is attracting increasing attention. However, existing TTA studies often struggle with generation quality and text-audio alignment, especially for complex textual inputs. Drawing inspiration from state-of-the-art Text-to-Image (T2I) diffusion models, we introduce Auffusion, a TTA system adapting T2I model frameworks to TTA task, by effectively leveraging their inherent generative strengths and precise cross-modal alignment. Our objective and subjective evaluations demonstrate that Auffusion surpasses previous TTA approaches using limited data and computational resources. Furthermore, the text encoder serves as a critical bridge between text and audio, since it acts as an instruction for the diffusion model to generate coherent content. Previous studies in T2I recognize the significant impact of encoder choice on cross-modal alignment, like fine-grained details and object bindings, while similar evaluation is lacking in prior TTA works. Through comprehensive ablation studies and innovative cross-attention map visualizations, we provide insightful assessments, being the first to reveal the internal mechanisms in the TTA field and intuitively explain how different text encoders influence the diffusion process. Our findings reveal Auffusion's superior capability in generating audios that accurately match textual descriptions, which is further demonstrated in several related tasks, such as audio style transfer, inpainting, and other manipulations.},
  keywords={Diffusion models;Spectrogram;Adaptation models;Training;Text to image;Large language models;Gaussian noise;Feature extraction;Diffusion processes;Data models;Text-to-audio generation;diffusion model;text-to-image generation;large language model},
  doi={10.1109/TASLP.2024.3485485},
  ISSN={2329-9304},
  month={},}@ARTICLE{10490098,
  author={Jia, Jia and Lee, Geunho and Wang, Zhibo and Lyu, Zhi and He, Yuchu},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={Siamese Meets Diffusion Network: SMDNet for Enhanced Change Detection in High-Resolution RS Imagery}, 
  year={2024},
  volume={17},
  number={},
  pages={8189-8202},
  abstract={In recent years, the application of deep learning to change detection (CD) has significantly progressed in remote sensing images. CD tasks have mostly used architectures, such as CNN and Transformer to locate image changes. However, these architectures have shortcomings in representing boundary details and are prone to false alarms and missed detections under complex lighting and weather conditions. For that, we propose a new network, Siamese meets diffusion network (SMDNet), a CD model that combines discriminative and generative architecture. By leveraging the power of the Siam-U2Net feature differential encoder (SU-FDE) and denoising diffusion implicit model (DDIM), it not only improves the accuracy of object edge detection but also enhances the data through iterative denoising and thinning reconstruction detail detection accuracy. Improves the model's robustness under environmental changes. First, we propose an SU-FDE module that uses shared weight features to capture differences between time series images, refine edge detection, and combine it with the attention mechanism to identify vital coarse features, thereby improving model sensitivity and accuracy. Finally, the progressive sampling of DDIM is used to integrate further these key features, and the adaptability of the model in different environments is enhanced with the help of the denoising ability of the diffusion model and the accurate capture of the probability distribution of image data. The performance evaluation of SMDNet on LEVIR-CD, DSIFN-CD, and CDD datasets yields validated F1 scores of 89.17%, 88.48%, and 88.23%, respectively. This substantiates the advanced capabilities of our model in accurately identifying variations and intricate details.},
  keywords={Feature extraction;Image edge detection;Task analysis;Noise reduction;Deep learning;Adaptation models;Transformers;Change detection (CD);deep learning;diffusion model (DM);remote sensing (RS);Siamese network},
  doi={10.1109/JSTARS.2024.3384545},
  ISSN={2151-1535},
  month={},}@ARTICLE{10540321,
  author={Luo, Sheng and Chen, Wei and Tian, Wanxin and Liu, Rui and Hou, Luanxuan and Zhang, Xiubao and Shen, Haifeng and Wu, Ruiqi and Geng, Shuyi and Zhou, Yi and Shao, Ling and Yang, Yi and Gao, Bojun and Li, Qun and Wu, Guobin},
  journal={IEEE Transactions on Intelligent Vehicles}, 
  title={Delving Into Multi-Modal Multi-Task Foundation Models for Road Scene Understanding: From Learning Paradigm Perspectives}, 
  year={2024},
  volume={9},
  number={12},
  pages={8040-8063},
  abstract={Foundation models have indeed made a profound impact on various fields, emerging as pivotal components that significantly shape the capabilities of intelligent systems. In the context of intelligent vehicles, leveraging the power of foundation models has proven to be transformative, offering notable advancements in visual understanding. Equipped with multi-modal and multi-task learning capabilities, multi-modal multi-task visual understanding foundation models (MM-VUFMs) effectively process and fuse data from diverse modalities and simultaneously handle various driving-related tasks with powerful adaptability, contributing to a more holistic understanding of the surrounding scene. In this survey, we present a systematic analysis of MM-VUFMs specifically designed for road scenes. Our objective is not only to provide a comprehensive overview of common practices, referring to task-specific models, unified multi-modal models, unified multi-task models, and foundation model prompting techniques, but also to highlight their advanced capabilities in diverse learning paradigms. These paradigms include open-world understanding, efficient transfer for road scenes, continual learning, interactive and generative capability. Moreover, we provide insights into key challenges and future trends, such as closed-loop driving systems, interpretability, low-resource conditions, embodied driving agents, and world models.},
  keywords={Multitasking;Data models;Surveys;Foundation models;Image analysis;Architecture;Systematic literature review;Foundation model;multi-modal learning;multi-task learning;road scene;visual understanding},
  doi={10.1109/TIV.2024.3406372},
  ISSN={2379-8904},
  month={Dec},}@INPROCEEDINGS{10495652,
  author={Tran, Martin and Shipard, Jordan and Mulyono, Hermawan and Wiliem, Arnold and Fookes, Clinton},
  booktitle={2024 IEEE/CVF Winter Conference on Applications of Computer Vision Workshops (WACVW)}, 
  title={SafeSea: Synthetic Data Generation for Adverse & Low Probability Maritime Conditions}, 
  year={2024},
  volume={},
  number={},
  pages={821-829},
  abstract={High-quality training data is essential for enhancing the robustness of object detection models. Within the maritime domain, obtaining a diverse real image dataset is particularly challenging due to the difficulty of capturing sea images with the presence of maritime objects, especially in stormy conditions. These challenges arise due to resource limitations, in addition to the unpredictable appearance of maritime objects. Nevertheless, acquiring data from stormy conditions is essential for training effective maritime detection models, particularly for search and rescue, where real-world conditions can be unpredictable. In this work, we introduce SafeSea, which is a stepping stone towards transforming actual sea images with various Sea State backgrounds while retaining maritime objects. Compared to existing generative methods such as Stable Diffusion Inpainting [27], this approach reduces the time and effort required to create synthetic datasets for training maritime object detection models. The proposed method uses two automated filters to only pass generated images that meet the criteria. In particular, these filters will first classify the sea condition according to its Sea State level and then it will check whether the objects from the input image are still preserved. This method enabled the creation of the SafeSea dataset, offering diverse weather condition backgrounds to supplement the training of maritime models. Lastly, we observed that a maritime object detection model faced challenges in detecting objects in stormy sea backgrounds, emphasizing the impact of weather conditions on detection accuracy. The code, and dataset are available at https://github.com/martin-3240/SafeSea.},
  keywords={Training;YOLO;Sea surface;Filters;Training data;Sea state;Data models},
  doi={10.1109/WACVW60836.2024.00094},
  ISSN={2690-621X},
  month={Jan},}@INPROCEEDINGS{10378010,
  author={Han, Seungju and Hessel, Jack and Dziri, Nouha and Choi, Yejin and Yu, Youngjae},
  booktitle={2023 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Champagne: Learning Real-world Conversation from Large-Scale Web Videos}, 
  year={2023},
  volume={},
  number={},
  pages={15452-15463},
  abstract={Visual information is central to conversation: body gestures and physical behaviour, for example, contribute to meaning that transcends words alone. To date, however, most neural conversational models are limited to just text. We introduce Champagne, a generative model of conversations that can account for visual contexts. To train Champagne, we collect and release YTD-18M, a large-scale corpus of 18M video-based dialogues. YTD-18M is constructed from web videos: crucial to our data collection pipeline is a pretrained language model that converts error-prone automatic transcripts to a cleaner dialogue format while maintaining meaning.Human evaluation reveals that YTD-18M is more sensible and specific than prior resources (MMDialog [17], 1M dialogues), while maintaining visual-groundedness. Experiments demonstrate that 1) Champagne learns to conduct conversation from YTD-18M; and 2) when fine-tuned, it achieves state-of-the-art results on four vision-language tasks focused on real-world conversations. We release data, models, and code at https://seungjuhan.me/champagne.},
  keywords={Visualization;Computer vision;Computational modeling;Pipelines;Oral communication;Data collection;Data models},
  doi={10.1109/ICCV51070.2023.01421},
  ISSN={2380-7504},
  month={Oct},}@ARTICLE{10480714,
  author={Huang, Panjian and Hou, Saihui and Cao, Chunshui and Liu, Xu and Hu, Xuecai and Huang, Yongzhen},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Integral Pose Learning via Appearance Transfer for Gait Recognition}, 
  year={2024},
  volume={19},
  number={},
  pages={4716-4727},
  abstract={Gait recognition plays an important role in video surveillance and security by identifying humans based on their unique walking patterns. The existing gait recognition methods have achieved competitive accuracy with shape and motion patterns under limited-covariate conditions. However, when extreme appearance changes distort discriminative features, gait recognition yields unsatisfactory results under cross-covariate conditions. In this work, we first indicate that the integral pose in each silhouette maintains an appearance-unrelated discriminative identity. However, the monotonous appearance variables in a gait database cause gait models to have difficulty extracting integral poses. Therefore, we propose an Appearance-transferable Disentangling and Generative Network (GaitApp) to generate gait silhouettes with rich appearances and invariant poses. Specifically, GaitApp leverages multi-branch cooperation to disentangle pose features and appearance features, and transfers the appearance information from one subject to another. By simulating a person constantly changing appearances under limited-covariate conditions, downstream models enable to extract discriminative integral pose features. Extensive experiments demonstrate that our method allows representative gait models to stand at a new altitude, further promoting the exploration to cross-covariate gait recognition. All the code is available at https://github.com/Hpjhpjhs/GaitApp.git},
  keywords={Feature extraction;Gait recognition;Shape;Three-dimensional displays;Thigh;Visualization;Representation learning;Integral pose;appearance transfer;gait recognition;disentangling representation learning},
  doi={10.1109/TIFS.2024.3382606},
  ISSN={1556-6021},
  month={},}@INPROCEEDINGS{10658047,
  author={Li, Yapeng and Luo, Yong and Wang, Zengmao and Du, Bo},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Improving Generalized Zero-Shot Learning by Exploring the Diverse Semantics from External Class Names}, 
  year={2024},
  volume={},
  number={},
  pages={23344-23353},
  abstract={Generalized Zero-Shot Learning (GZSL) methods often assume that the unseen classes are similar to seen classes, and thus perform poor when unseen classes are dissimilar to seen classes. Although some existing GZSL approaches can alleviate this issue by leveraging additional semantic information from test unseen classes, their generalization ability to dissimilar unseen classes is still unsatisfactory. This motivates us to study GZSL in the more practical setting, where unseen classes can be either similar or dissimilar to seen classes. In this paper, we propose a simple yet effective GZSL framework by exploring diverse semantics from external class names (DSECN), which is simultaneously robust on the similar and dissimilar unseen classes. This is achieved by introducing diverse semantics from external class names and aligning the introduced semantics to visual space using the classification head of pretrained network. Furthermore, we show that the design idea of DSECN can easily be integrate into other advanced GZSL approaches, such as the generative-based ones, and enhance their robustness for dissimilar unseen classes. Extensive experiments in the practical setting including both similar and dissimilar unseen classes show that our method significantly outperforms the state-of-the-art approaches on all datasets and can be trained very efficiently.},
  keywords={Visualization;Computer vision;Zero-shot learning;Semantics;Robustness;Pattern recognition;Generalized Zero-Shot Learning;External Class Names;Dissimilar Unseen Classes;Transfer Learning},
  doi={10.1109/CVPR52733.2024.02203},
  ISSN={2575-7075},
  month={June},}@ARTICLE{9681266,
  author={Xie, Zhenping and Ren, Liyuan and Zhan, Qianyi and Liu, Yuan},
  journal={IEEE Transactions on Cybernetics}, 
  title={A Constructivist Ontology Relation Learning Method}, 
  year={2022},
  volume={52},
  number={7},
  pages={6434-6441},
  abstract={From the perspective of philosophy, ontology relations denote ultimate semantic relations of related knowledge concepts. Beyond doubt, it is still a very difficult problem on how to automatically depict and construct ontology relations because of its high abstractness. Some latest research attempted to realize ontology relation learning by learning abstract hierarchies or similarities among knowledge concepts. Inspired by the requirements of associative semantic cognition like in the human brain, a constructivist ontology relation learning (CORL) method is put forward in this study by borrowing the idea of the constructivist learning theory. Wherein, two following points are supposed: 1) each symbol knowledge is looked as a token of representing certain abstract pattern and 2) each pattern denotes a type of relation structures on other patterns, or a directly observed event data, such as physical sensing data, natural image, sound data, text word etc. So, ontology relation could be considered as the associative support degrees from other knowledge concepts to the target concept, which reflects how one knowledge ontology can be demarcated by other knowledge concepts. Then, the knowledge network can be employed to represent an entire domain knowledge system. Meanwhile, an associative random walk mechanism (ARWM) on knowledge network can be considered to explain the semantic generative process of every document. Thus, CORL can be realized by integrating ARWM into an extended latent Dirichlet allocation (LDA) model. Some theoretical and experimental analysis are done. The corresponding results demonstrate that CORL can obtain effective associative semantic relations among concept words, and gain some novel characteristics in better representing knowledge ontology than existing methods.},
  keywords={Ontologies;Semantics;Knowledge engineering;Probabilistic logic;Computational modeling;Resource management;Philosophical considerations;Constructivist learning theory;knowledge network;latent Dirichlet allocation (LDA);ontology relation learning;random walk},
  doi={10.1109/TCYB.2021.3138452},
  ISSN={2168-2275},
  month={July},}@INPROCEEDINGS{10350420,
  author={Utz, Jonas and Weise, Tobias and Schlereth, Maja and Wagner, Fabian and Thies, Mareike and Gu, Mingxuan and Uderhardt, Stefan and Breininger, Katharina},
  booktitle={2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)}, 
  title={Focus on Content not Noise: Improving Image Generation for Nuclei Segmentation by Suppressing Steganography in CycleGAN}, 
  year={2023},
  volume={},
  number={},
  pages={3858-3866},
  abstract={Annotating nuclei in microscopy images for the training of neural networks is a laborious task that requires expert knowledge and suffers from inter- and intra-rater variability, especially in fluorescence microscopy. Generative networks such as CycleGAN can inverse the process and generate synthetic microscopy images for a given mask, thereby building a synthetic dataset. However, past works report content inconsistencies between the mask and generated image, partially due to CycleGAN minimizing its loss by hiding shortcut information for the image reconstruction in high frequencies rather than encoding the desired image content and learning the target task. In this work, we propose to remove the hidden shortcut information, called steganography, from generated images by employing a low pass filtering based on the discrete cosine transform (DCT). We show that this increases coherence between generated images and cycled masks and evaluate synthetic datasets on a downstream nuclei segmentation task. Here we achieve an improvement of 5.4 percentage points in the F1-score compared to a vanilla CycleGAN. Integrating advanced regularization techniques into the CycleGAN architecture may help mitigate steganography-related issues and produce more accurate synthetic datasets for nuclei segmentation.},
  keywords={Training;Knowledge engineering;Image segmentation;Steganography;Image synthesis;Microscopy;Neural networks;cycle gan;nuclei;segmentation;fluorescence microscopy;data generation;steganography;dct;synthetic data},
  doi={10.1109/ICCVW60793.2023.00417},
  ISSN={2473-9944},
  month={Oct},}@ARTICLE{10891470,
  author={Alemaw, Abrham Shiferaw and Slavic, Giulia and Zontone, Pamela and Marcenaro, Lucio and Gomez, David Martin and Regazzoni, Carlo},
  journal={IEEE Transactions on Multimedia}, 
  title={Modeling Interactions Between Autonomous Agents in a Multi-Agent Self-Awareness Architecture}, 
  year={2025},
  volume={27},
  number={},
  pages={5035-5049},
  abstract={Learning from experience is a fundamental capability of intelligent agents. Autonomous systems rely on sensors that provide data about the environment and internal situations to their perception systems for learning and inference mechanisms. These systems can also learn Self-Aware and Situation-Aware generative modules from these data to localize themselves and interact with the environment. In this paper, we propose a self-aware cognitive architecture capable to perform tasks where the interactions between the self-state of an agent and the surrounding environment are explicitly and dynamically represented. We specifically develop a Deep Learning (DL) based Self-Aware interaction model, empowered by learning from Multi-Modal Perception (MMP) and World Models using multi-sensory data in a novel Multi-Agent Self-Awareness Architecture (MASAA). Two sub-modules are developed, the Situation Model (SM) and the First-Person model (FPM), that address different and interrelated aspects of the World Model (WM). The MMP model, instead, aims at learning the mapping of different sensory perceptions into Exteroceptive (EI) and Proprioceptive (PI) latent information. The WM then uses the learned MMP model as experience to predict dynamic self-behaviors and interaction patterns within the experienced environment. WM and MMP Models are learned in a data-driven way, starting from the lower-dimensional odometry data used to guide the learning of higher-dimensional video data, thus generating coupled Generalized State Hierarchical Dynamic Bayesian Networks (GS-HDBNs). We test our model on KITTI, CARLA, and iCab datasets, achieving high performance and a low average localization error (RMSE) of 2.897%, when considering two interacting agents.},
  keywords={Training;Data mining;Artificial intelligence;Hierarchical dynamic bayesian networks;linear prediction models;multi-modal perception;variational autoencoder;world model},
  doi={10.1109/TMM.2025.3543110},
  ISSN={1941-0077},
  month={},}@ARTICLE{11142340,
  author={Shen, Hang and Liu, Qi and Liu, Yu and Wang, Tianjing and Bai, Guangwei},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={MA-DyNN: Modal-Adaptive Dynamic Neural Network for Crowd-Counting on Consumer Drones}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Consumer drones are increasingly used for crowd-counting in complex environments; however, their deployment faces challenges from adverse external conditions such as low illumination and inclement weather, as well as inherent limitations like constrained onboard computational resources. To address these constraints, we present MA-DyNN (Modal-Adaptive Dynamic Neural Network), a lightweight and robust framework that dynamically adapts to varying modality conditions for accurate crowd counting. This framework employs an efficient single-stream architecture with specialized modal extractors to capture and integrate complementary information from both visible and thermal infrared (TIR) inputs. Based on the extracted modal features, we design a modality-adaptive gating mechanism to dynamically select the optimal modality based on environmental conditions, favoring visible imagery for inference efficiency in well-lit scenarios and leveraging TIR as auxiliary support under low-light or degraded conditions. To enhance robustness against sensor failure or missing modalities, we develop a density-aware modality converter that adds crowd density constraints to a cycle-consistent generative adversarial learning framework to generate high-fidelity TIR images. This enables consistent performance by aligning synthetic and real TIR-based counting outcomes through adversarial learning. Extensive experiments on DroneRGBT and RGBT datasets show that MA-DyNN achieves superior accuracy, generalization, and real-time performance compared to state-of-the-art multimodal baselines. Its inference acceleration performance approaches single-modality models without compromising the accuracy gains provided by multimodal learning},
  keywords={Feature extraction;Drones;Computer architecture;Computational efficiency;Real-time systems;Consumer electronics;Robustness;Neural networks;Meteorology;Accuracy;Consumer drone;crowd counting;multimodal;dynamic neural networks},
  doi={10.1109/TCE.2025.3602952},
  ISSN={1558-4127},
  month={},}@INPROCEEDINGS{11127496,
  author={Luo, Rundong and Geng, Haoran and Deng, Congyue and Li, Puhao and Wang, Zan and Jia, Baoxiong and Guibas, Leonidas and Huang, Siyuan},
  booktitle={2025 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={PhysPart: Physically Plausible Part Completion for Interactable Objects}, 
  year={2025},
  volume={},
  number={},
  pages={12386-12393},
  abstract={Interactable objects are ubiquitous in our daily lives. Recent advances in 3D generative models make it possible to automate the modeling of these objects, benefiting a range of applications from 3D printing to the creation of robot simulation environments. However, while significant progress has been made in modeling 3D shapes and appearances, modeling object physics, particularly for interactable objects, remains challenging due to the physical constraints imposed by interpart motions. In this paper, we tackle the problem of physically plausible part completion for interactable objects, aiming to generate 3D parts that not only fit precisely into the object but also allow smooth part motions. To this end, we propose a diffusion-based part generation model that utilizes geometric conditioning through classifier-free guidance and formulates physical constraints as a set of stability and mobility losses to guide the sampling process. Additionally, we demonstrate the generation of dependent parts, paving the way toward sequential part generation for objects with complex part-whole hierarchies. Experimentally, we introduce a new metric for measuring physical plausibility based on motion success rates. Our model outperforms existing baselines over shape and physical metrics, especially those that do not adequately model physical constraints. We also demonstrate our applications in 3D printing, robot manipulation, and sequential part generation, showing our strength in realistic tasks with the demand for high physical plausibility.},
  keywords={Measurement;Solid modeling;Accuracy;Shape;Three-dimensional printing;Stability analysis;Motion measurement;Robots;Physics},
  doi={10.1109/ICRA55743.2025.11127496},
  ISSN={},
  month={May},}@ARTICLE{10855541,
  author={Wu, Jiaqi and Zhang, Shihao and Hou, Mingshuo and Wang, Zehua and Chen, Wei and Tian, Zijian and Yu, F. Richard and Leung, Victor C. M.},
  journal={IEEE Transactions on Multimedia}, 
  title={CLIP-AE: A Multi-Modal Unsupervised Images Enhancement Method Based on High-Order Adaptive Curve for Visual Disbalance Defects}, 
  year={2025},
  volume={27},
  number={},
  pages={4269-4283},
  abstract={For visual disbalance defects (VDDs) in low-light images, such as brightness unevenness and color imbalance, existing enhancement methods struggle to extract defect features from local regions and apply adaptive enhancement based on varying degrees of these defects. To address these challenges, we propose an unsupervised multi-modal enhancement method based on a high-order adaptive curve, named CLIP-AE. Specifically, we introduce a multi-modal recurrent optimization approach utilizing contrastive language-image pre-training (CLIP). This method iteratively optimizes variable embedded prompts and an Adaptive Enhancement Module (AEM) to establish dependencies between the prompts and detailed style features in the images, guiding the AEM to perform adaptive image enhancement. Additionally, we implement a progressive feature alignment strategy to enhance the model's ability to perceive style features and improve optimization efficiency by using multiple enhanced images with identical content features and incremental style features. In the AEM, the optimized Hyperparameters Generative Network (HGN) generates the optimal hyperparameters, which drive a High-Dimensional Nested Gamma correction (HDN-Gamma) to perform pixel-wise adaptive enhancement for VDDs. HDN-Gamma further maps pixel values using specific enhancement curves to avoid artifacts. Extensive experiments demonstrate that our method effectively improves visual disbalance defects and reduces artifacts. Compared to seven state-of-the-art algorithms, our method shows significant improvements (PSNR: 16.46%, 16.89%, and 15.14%; SSIM: 9.26%, 8.02%, and 9.85%; MUSIQ: 6.37%, 6.54%, and 7.45%) on the LOL, SICE, and MIT-Adobe FiveK datasets. Our approach offers a novel solution for applying multimedia technology in low-light image enhancement tasks.},
  keywords={Visualization;Brightness;Image enhancement;Feature extraction;Adaptation models;Lighting;Image color analysis;Contrastive learning;Optimization;Unsupervised learning;Contrastive language-image pre-training;gamma correction;low-light images enhancement;multi-modal mechanism;unsupervised learning;visual disbalance defect},
  doi={10.1109/TMM.2025.3535333},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{10337097,
  author={Zhao, Bingfei and Zan, Hongying and Niu, Chengzhi and Zhang, Kunli},
  booktitle={2023 International Conference on Asian Language Processing (IALP)}, 
  title={Chinese Long Text Summarization Generation Based on Multi-Task Re-Ordering and Smooth Gating Control}, 
  year={2023},
  volume={},
  number={},
  pages={112-117},
  abstract={Abstractive summarization is a key technique for automatic text summarization. However, existing generative models typically rely on beam search decoding, which leads to poor performance due to the large search space. To address this, we propose a multi-task learning framework for text reordering. Specifically, we introduce a multi-task learning model to reorder the text according to different evaluation metrics, in order to select the optimal summary candidates. Furthermore, we replace the gating network in mixture-of-experts models with a smooth gating control method to alleviate the unsmooth parameter issue. To improve the ability of extracting semantic information, we incorporate textcnn into the basic encoder to enhance the semantic understanding of the model. Experiments on the Chinese long text summarization datasets CLTS and CLTS+ show significant improvements of our method over the best models reported in prior work, demonstrating the efficacy of the multi-task re-ordering framework and smooth gating control. Ablation studies are conducted to analyze the impact of different decoding methods and beam sizes, as well as the contribution of different re-ordering methods integrated into the framework.},
  keywords={Training;Measurement;Smoothing methods;Semantics;Process control;Logic gates;Multitasking;Abstractive summarization;Multi-task learning framework;Smooth gating control;Textcnn},
  doi={10.1109/IALP61005.2023.10337097},
  ISSN={2159-1970},
  month={Nov},}@INPROCEEDINGS{10610037,
  author={Kenghagho K., Franklin and Neumann, Michael and Mania, Patrick and Beetz, Michael},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Perception through Cognitive Emulation : "A Second Iteration of NaivPhys4RP for Learningless and Safe Recognition and 6D-Pose Estimation of (Transparent) Objects"}, 
  year={2024},
  volume={},
  number={},
  pages={7679-7685},
  abstract={In our previous work, we designed a human-like white-box and causal generative model of perception NaivPhys4RP, essentially based on cognitive emulation to understand the past, the present and the future of the state of complex worlds from poor observations. In this paper, as recommended in that previous work, we first refine the theoretical model of NaivPhys4RP in terms of integration of variables as well as perceptual inference tasks to solve. Intuitively, the system is closed under the injection, update and dependency of variables. Then, we present a first implementation of NaivPhys4RP that demonstrates the learningless and safe recognition and 6D-Pose estimation of objects from poor sensor data (e.g., occlusion, transparency, poor-depth, in-hand). This does not only make a substantial step forward comparatively to classical perception systems in perceiving objects in these scenarios, but escape the burden of data-intensive learning and operate safely (transparency and causality — we fit sensor data into mentally constructed meaningful worlds). With respect to ChatGPT’s ambitions, it can imagine physico-realistic socio-physical scenes from texts, demonstrate understanding of these texts, and all these with no data- and resource-intensive learning.},
  keywords={Fluids;Emulation;Ontologies;Robot sensing systems;Solids;Search problems;System software},
  doi={10.1109/ICRA57147.2024.10610037},
  ISSN={},
  month={May},}@INPROCEEDINGS{10394361,
  author={Lv, Yifan and Du, Xiaoqin and Zhou, Jiashuang and Liu, Yongqi and Xu, Han},
  booktitle={2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={STMotionFormer: Language Guided 3D Human Motion Synthesis with Spatial Temporal Transformer}, 
  year={2023},
  volume={},
  number={},
  pages={4470-4475},
  abstract={Inspired by the Transformer's adaptive capability in natural language processing and computer vision domains, and supported by CLIP's strong semantic prior knowledge, we propose a novel generative model named STMotionFormer based on improved Transformer block and CLIP for language-guided 3D skeleton-based human motion synthesis. The skeleton sequence, as a kind of spatial temporal dynamic data, not only contains temporal information but also consists of a natural graph structure by different body parts. We focus on this, propose Temporal Transformer block (T-Former) applies attention mechanism along the temporal dimension to capture the long-term relationship, and propose spatial Transformer block (S-Former) applies attention mechanism in the spatial dimension to aggregate and update joints' spatial features. Therefore, our approach can automatically explore both spatial and temporal information, which can generate skeleton sequence with reasonable graph structure as well as global time relationship. Moreover, powerful semantic prior knowledge of CLIP are injected into our motion-language joint manifold. We evaluate our method on the public KIT motion language dataset that contains manually annotated 3D pose sequences. Experimental results show that our model outperforms the state-of-the-art in terms of APE and AVE respectively. Qualitative visualization results indicate that our model can generate human motions that are more compatible with semantic information even than the GroundTruth.},
  keywords={Solid modeling;Three-dimensional displays;Semantics;Transformers;Skeleton;Spatial databases;Natural language processing;Motion synthesis;Transformer;Spatial Temporal;CLIP;Language Guided},
  doi={10.1109/SMC53992.2023.10394361},
  ISSN={2577-1655},
  month={Oct},}@ARTICLE{10899829,
  author={Deng, Liangjun and Lei, Hang and Khan, Fazlullah and Srivastava, Gautam and Chen, Jingxue and Haque, Mainul},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={GPT-Based Automated Induction: Vulnerability Detection in Medical Software}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={Integrating Natural Language Processing (NLP) with Generative Pre-trained Transformer (GPT) models plays a pivotal role in enhancing the accuracy and efficiency of healthcare software, which is essential for patient safety and providing high-quality care. The precision of healthcare software is fundamental to protecting the well-being of the patient. In addition, it can ensure the delivery of superior care, maintain the integrity of healthcare systems, and promote trust and cost-effectiveness. It is necessary to emphasize the importance of software reliability in its development and deployment. Symbolic execution serves as a vital technology in automated vulnerability detection. However, symbolic execution often faces problems such as path explosion, which seriously affects efficiency. Although there have been several studies to reduce the number of computational paths in symbolic execution, this problem remains a major obstacle. Therefore, more efficient solutions are urgently needed to ensure the software security. This paper proposes a large-scale language model(LLM) induction method mitigating path explosion applied to symbolic execution engines. In contrast to traditional symbolic execution engines, which often result in timeout or out-of-memory detection, our approach achieves the task of detecting vulnerabilities in seconds. Furthermore, our proposal improves the scalability of symbolic execution, allowing more extensive and complex programs to be analyzed without significant increases in computational resources or time. This scalability is crucial to tackling modern software systems and improving the efficiency and effectiveness of automated defect verification in healthcare software.},
  keywords={Software;Explosions;Medical services;Codes;Security;Engines;Cognition;Bioinformatics;Artificial intelligence;Testing;symbolic execution;WebAssembly;Deep Learning;LLM;healthcare software},
  doi={10.1109/JBHI.2025.3544560},
  ISSN={2168-2208},
  month={},}@ARTICLE{11006017,
  author={Huang, Nisha and Dong, Weiming and Zhang, Yuxin and Tang, Fan and Li, Ronghui and Ma, Chongyang and Li, Xiu and Lee, Tong-Yee and Xu, Changsheng},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={CreativeSynth: Cross-Art-Attention for Artistic Image Synthesis With Multimodal Diffusion}, 
  year={2025},
  volume={31},
  number={10},
  pages={8425-8438},
  abstract={Although remarkable progress has been made in image style transfer, style is just one of the components of artistic paintings. Directly transferring extracted style features to natural images often results in outputs with obvious synthetic traces. This is because key painting attributes including layout, perspective, shape, and semantics often cannot be conveyed and expressed through style transfer. Large-scale pretrained text-to-image generation models have demonstrated their capability to synthesize a vast amount of high-quality images. However, even with extensive textual descriptions, it is challenging to fully express the unique visual properties and details of paintings. Moreover, generic models often disrupt the overall artistic effect when modifying specific areas, making it more complicated to achieve a unified aesthetic in artworks. Our main novel idea is to integrate multimodal semantic information as a synthesis guide into artworks, rather than transferring style to the real world. We also aim to reduce the disruption to the harmony of artworks while simplifying the guidance conditions. Specifically, we propose an innovative multi-task unified framework called CreativeSynth, based on the diffusion model with the ability to coordinate multimodal inputs. CreativeSynth combines multimodal features with customized attention mechanisms to seamlessly integrate real-world semantic content into the art domain through Cross-Art-Attention for aesthetic maintenance and semantic fusion. We demonstrate the results of our method across a wide range of different art categories, proving that CreativeSynth bridges the gap between generative models and artistic expression.},
  keywords={Semantics;Visualization;Painting;Image synthesis;Art;Text to image;Diffusion models;Electronic mail;Transformers;Training;Visual art;diffusion models;multimodal guidance;image generation},
  doi={10.1109/TVCG.2025.3570771},
  ISSN={1941-0506},
  month={Oct},}@ARTICLE{10999055,
  author={Zhang, Yuxin and Dong, Weiming and Tang, Fan and Huang, Nisha and Huang, Haibin and Ma, Chongyang and Wan, Pengfei and Lee, Tong-Yee and Xu, Changsheng},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={MotionCrafter: Plug-and-Play Motion Guidance for Diffusion Models}, 
  year={2025},
  volume={31},
  number={10},
  pages={8372-8384},
  abstract={The essence of a video lies in the dynamic motions. While text-to-video generative diffusion models have made significant strides in creating diverse content, effectively controlling specific motions through text prompts remains a challenge. By utilizing user-specified reference videos, the more precise guidance for character actions, object movements, and camera movements can be achieved. This gives rise to the task of motion customization, where the primary challenge lies in effectively decoupling the appearance and motion within a video clip. To address this challenge, we introduce MotionCrafter, a novel one-shot instance-guided motion customization method that is suitable for both pre-trained text-to-video and text-to-image diffusion models. MotionCrafter employs a parallel spatial-temporal architecture that integrates the reference motion into the temporal component of the base model, while independently adjusting the spatial module for character or style control. To enhance the disentanglement of motion and appearance, we propose an innovative dual-branch motion disentanglement approach, which includes a motion disentanglement loss and an appearance prior enhancement strategy. To facilitate more efficient learning of motions, we further propose a novel timestep-layered tuning strategy that directs the diffusion model to focus on motion-level information. Through comprehensive quantitative and qualitative experiments, along with user preference tests, we demonstrate that MotionCrafter can successfully integrate dynamic motions while maintaining the coherence and quality of the base model, providing a wide range of appearance generation capabilities. MotionCrafter can be applied to various personalized backbones in the community to generate videos with a variety of artistic styles.},
  keywords={Diffusion models;Text to video;Dynamics;Cameras;Training;Visualization;Tuning;Hair;Computational modeling;Text to image;Text-to-video generation;diffusion models;motion generation},
  doi={10.1109/TVCG.2025.3568880},
  ISSN={1941-0506},
  month={Oct},}@ARTICLE{10906712,
  author={Raval, Vishwam and Zeid, Mohamed and Enjeti, Prasad and Pitel, Grant},
  journal={IEEE Power Electronics Magazine}, 
  title={Circuit AI for Bill of Materials, Switching Loss Optimization, Capacitor RMS Estimation, and More}, 
  year={2025},
  volume={12},
  number={1},
  pages={64-74},
  abstract={Circuit AI is an advanced generative AI-driven tool designed to streamline electronic design by integrating bill of materials (BOM) optimization with advanced performance analysis. Leveraging a pretrained large language model, it automates tasks such as switching loss analysis, component availability checks, and cost optimization, significantly enhancing the efficiency of BOM workflows. Additionally, Circuit AI incorporates a fine-tuned version of the pretrained model to estimate capacitor RMS currents (I cap-rms), a critical performance metric for ensuring reliable thermal operation and prolonging component lifespan in power electronics applications. By seamlessly combining BOM optimization with performance evaluation, Circuit AI supports engineers in making more efficient decisions throughout the design process, from initial selection to final production.},
  keywords={Costs;Bills of materials;Capacitors;Switching loss;Power electronics;Software reliability;Artificial intelligence;Integrated circuit modeling;Optimization;Switching circuits},
  doi={10.1109/MPEL.2024.3524782},
  ISSN={2329-9215},
  month={March},}@INPROCEEDINGS{11152939,
  author={Shah, Syed Danial Ali and Nezami, Zeinab and Hafeez, Maryam and Zaidi, Syed Ali Raza},
  booktitle={IEEE INFOCOM 2025 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, 
  title={The Interplay of AI-and-RAN: Dynamic Resource Allocation for Converged 6G Platform}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The concept of AI-RAN as specified by the AI-RAN alliance is geared to explore a converged 6G platform that can support management, orchestration, and deployment of both AI and RAN workloads. This concept is central to the development of a 6G architecture that aims to exploit the accelerated compute capabilities for supporting both real-time signal processing and offloading of Generative AI (GenAI) workloads. However, both the architectural framework required to support this vision and the dynamic resource allocation strategy are still in their infancy. The O-RAN architecture intrinsically allows cloud-native disaggregated implementation. Consequently, we explore a framework that can allow orchestration of AI-and-RAN workloads by expanding the Near Real-Time RAN Intelligent Controller (NRT-RIC) within O-RAN. The framework incorporates a monitoring xApp that tracks RAN KPIs and exposes radio analytics to the proposed E2E orchestrator via a recently introduced Y1 interface. The orchestrator implements a Soft Actor-Critic (SAC) reinforcement learning algorithm to dynamically allocate critical computing resources, e.g., Multi-Instance GPUs (MIGs), between latency-sensitive RAN network functions and computationally intensive AI workloads on shared RAN infrastructure. The proposed framework provides insight on how the traditional RAN architecture can be evolved to inherently support emerging GenAI workloads. Our framework prioritizes the real-time requirements of RAN workloads while maintaining efficient resource sharing for AI applications. The simulation results demonstrate the benefits of the proposed framework, as it meets nearly 99% of the requests for RAN workload while effectively supporting AI workloads and achieving 100% utilization of the RAN infrastructure resources in a dynamic environment.},
  keywords={6G mobile communication;Heuristic algorithms;Open RAN;Computer architecture;Reinforcement learning;Dynamic scheduling;Real-time systems;Resource management;Artificial intelligence;Monitoring;O-RAN;5G;AI;xApp;RIC;SAC},
  doi={10.1109/INFOCOMWKSHPS65812.2025.11152939},
  ISSN={2833-0587},
  month={May},}@INPROCEEDINGS{11089097,
  author={D, Prabhu and K, Jeyakarthika and Paul, Anish Thankaih and M, Dinesh Babu and M, Ezhilvendan and R, Siva Subramanian},
  booktitle={2025 11th International Conference on Communication and Signal Processing (ICCSP)}, 
  title={Enhancing Transparency and Trust in AI: the Role of Explainable AI and Visualization Techniques}, 
  year={2025},
  volume={},
  number={},
  pages={19-24},
  abstract={The concepts of Explainable AI (XAI), and visualization methods are crucial in improving the interpretability of the ML models. With AI solutions being used in important industries including healthcare, finance, and autonomous, there is a need to explain the results produced by the models. The following survey focuses on the perspective of visualization in XAI to better illustrate the mechanisms by which models function and which are understandable to users. We present and compare several types of visualizations that might be applied for the given model: model-specific and model-agnostic ones as well as more complex approaches such as saliency maps and counterfactual visualization. The paper also considers the primary use cases for XAI and visualization across the contexts and responds to concerns, including scalability, ethicality, and the dilemma of the explainable accuracy vs. interpretability. Last, it presents future work findings in evaluation metrics, real-time system incorporation, and generative AI for visualization.},
  keywords={Surveys;Measurement;Visualization;Ethics;Explainable AI;Finance;Medical services;Real-time systems;Stakeholders;Artificial intelligence;Machine learning;AI;XAI;visualization;post hoc model interpretation;transparency;saliency maps;real-time},
  doi={10.1109/ICCSP64183.2025.11089097},
  ISSN={2836-1873},
  month={June},}@INBOOK{10952033,
  author={Lewrick, Michael and Hatamleh, Omar},
  booktitle={AI and Innovation: How to Transform Your Business and Outpace the Competition with Generative AI}, 
  title={WHY AI MATTERS}, 
  year={2025},
  volume={},
  number={},
  pages={42-87},
  abstract={Summary <p>AI will continue to evolve and trigger remarkable waves of technological innovation across various fields. There is a tremendous causal relationship between advances in AI and innovation. At its core is the ability of AI to analyze and interpret vast amounts of data. Increasingly, it identifies patterns and uncovers previously unimagined insights and unseen trends based on synthetic and real data in the shortest possible time. AI enables individuals and teams to focus on creativity, problem&#x2010;solving, and value&#x2010;added activities. Evidence&#x2010;based customer needs and a better understanding of competitive and collaborative forces in the ecosystem are paramount to generating business value through AI and innovation. AI plays a key role in the development and operation of information and data protection. It is a game changer in the biotechnology and healthcare value chain.</p>},
  keywords={},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394254996},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952033},}@INBOOK{10951986,
  author={Lewrick, Michael and Hatamleh, Omar},
  booktitle={AI and Innovation: How to Transform Your Business and Outpace the Competition with Generative AI}, 
  title={INTRODUCTION TO EXPONENTIAL CHANGE}, 
  year={2025},
  volume={},
  number={},
  pages={16-42},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394254996},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951986},}@INBOOK{10955668,
  author={Subramanian, Shreyas},
  booktitle={Large Language Model-Based Solutions: How to Deliver Value with Cost-Effective Generative AI Applications}, 
  title={Front Matter}, 
  year={2024},
  volume={},
  number={},
  pages={i-xxvii},
  abstract={<p>The prelims comprise: <ul> <li>Half&#x2010;Title Page</li> <li>Title Page</li> <li>Copyright Page</li> <li>Dedication</li> <li>About the Author</li> <li>About the Technical Editor</li> <li>Contents</li> <li>Introduction</li> </ul> </p>},
  keywords={},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394240746},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10955668},}@INBOOK{10951645,
  author={Lewrick, Michael and Hatamleh, Omar},
  booktitle={AI and Innovation: How to Transform Your Business and Outpace the Competition with Generative AI}, 
  title={WHAT TOOLS AND METHODS SUPPORT AI ACTIVITIES?}, 
  year={2025},
  volume={},
  number={},
  pages={152-205},
  abstract={Summary <p>Primary considerations of the AI value chain rely on so&#x2010;called foundation models. These models have triggered an entire value chain aiming to improve and utilize the technology. This chapter dives into how Large language models (LLMs) operate, focusing on understanding context and generating results based on prompts. It breaks down how the LLM processes and utilizes words, along with exploring the concept of self&#x2010;attention. The chapter provide a foundation for grasping how LLMs generate text that considers context and builds upon the information we provide. It demonstrates how prompts can be used to process and generate human&#x2010;like text, translate languages, create code, write different kinds of creative content, or answer questions in an informative way. The chapter explores the tools and techniques needed to gain higher labor productivity with AI. It presents many ways to increase employee productivity and add to top&#x2010;line revenue growth.</p>},
  keywords={},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394254996},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951645},}@INBOOK{10951726,
  author={Lewrick, Michael and Hatamleh, Omar},
  booktitle={AI and Innovation: How to Transform Your Business and Outpace the Competition with Generative AI}, 
  title={HOW TO MAKE A DIFFERENCE WITH AI}, 
  year={2025},
  volume={},
  number={},
  pages={88-151},
  abstract={Summary <p>This chapter discusses how to make a difference with AI based on four AI design principles: AI strategy, AI capabilities, AI ethics, and AI regulations. The AI strategy is the core to making a difference with AI, and it is the overall plan of how an organization will use AI to achieve its goals. The strategy should also discuss the potential risks associated with AI and which capabilities are needed to evaluate and develop AI opportunities. In the author's experience, particular attention must be paid to risk management when formulating an AI strategy, as AI is a complex technology that can introduce new risks such as bias, privacy concerns, and security risks. The execution of use cases and monetization of an AI strategy requires a comprehensive and well&#x2010;thought&#x2010;out roadmap to ensure proper AI adoption. AI can be used to better construct and validate the strategy.</p>},
  keywords={},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394254996},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951726},}@INBOOK{10955673,
  author={Subramanian, Shreyas},
  booktitle={Large Language Model-Based Solutions: How to Deliver Value with Cost-Effective Generative AI Applications}, 
  title={CONCLUSION}, 
  year={2024},
  volume={},
  number={},
  pages={163-180},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394240746},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10955673},}@INBOOK{10982316,
  author={Bergeret, Olivier and Abbasi, Asif and Farvault, Joel},
  booktitle={GenAI on AWS: A Practical Approach to Building Generative AI Applications on AWS}, 
  title={Machine Learning}, 
  year={2025},
  volume={},
  number={},
  pages={19-44},
  abstract={<p>In recent years, Machine Learning (ML) has risen as a game&#x2010;changing technology with the capacity to reshape numerous industries and domains. This chapter delves into the fundamental principles of machine learning, covering its definition, essential components, diverse types, and real&#x2010;world applications. Reinforcement learning is a type of machine learning where an agent learns to interact with an environment by taking actions and receiving feedback in the form of rewards or penalties. Machine learning models can classify images into predefined categories or classes based on their visual features. Image classification is used in various applications, including object recognition, medical imaging, and autonomous vehicles. Furthermore, the installation and configuration of Apache Spark and its associated components can be more involved compared to standalone machine learning libraries, potentially creating a higher barrier to entry for some users.</p>},
  keywords={Machine learning;Machine learning algorithms;Data models;Prediction algorithms;Unsupervised learning;Supervised learning;Predictive models;Classification algorithms;Training;Semisupervised learning},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394281305},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10982316},}@INBOOK{11049745,
  author={HERMAN, ERIK},
  booktitle={Optimizing Prompt Engineering for Generative AI}, 
  title={Chapter 2: Crafting Effective Prompts}, 
  year={2025},
  volume={},
  number={},
  pages={17-38},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9781501521379},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11049745},}@ARTICLE{8244274,
  author={Dai, Yinglong and Wang, Guojun},
  journal={IEEE Access}, 
  title={Analyzing Tongue Images Using a Conceptual Alignment Deep Autoencoder}, 
  year={2018},
  volume={6},
  number={},
  pages={5962-5972},
  abstract={Artificial intelligence can learn some concepts by analyzing sensory data similarly to humans. This paper explores how artificial neural networks (ANNs) can learn abstract concepts by analyzing tongue images based on concepts from traditional Chinese medicine (TCM), which is a discipline that relies heavily on practitioner experience. A computer-aided method will be investigated that analyzes sensory data for TCM practitioners. This paper proposes capitalizing on deep learning techniques. A method called the conceptual alignment deep auto-encoder (CADAE) is proposed to analyze tongue images that represent different body constitution (BC) types, which are the underlying concepts in TCM. In the first step, CADAE encodes the images to a representation space; in the second step, it decodes the patterns. The experiments demonstrate that CADAE can learn effective representations of abstract concepts aligned with BC types by encoding the tongue images. Furthermore, the representation space of the hidden conceptual neurons can be visualized by a decoder network. The experiments also demonstrate that ANNs acquire different data perspectives when different loss functions are used for training. Numerous representation spaces of ANNs remain to be explored. To some extent, our exploration demonstrates that artificial intelligence (AI) has the ability to learn some concepts in a manner similarly to human beings. Based on this ability, AI shows promise in helping humans form new effective concepts that can facilitate medical development and alleviate the burdens of medical practitioners.},
  keywords={Tongue;Machine learning;Medical diagnostic imaging;IEEE Constitution;Biological system modeling;Neurons;Conceptual alignment deep autoencoder;deep learning;representation learning;tongue image;traditional Chinese medicine},
  doi={10.1109/ACCESS.2017.2788849},
  ISSN={2169-3536},
  month={},}@ARTICLE{10413447,
  author={Ghanadian, Hamideh and Nejadgholi, Isar and Osman, Hussein Al},
  journal={IEEE Access}, 
  title={Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models}, 
  year={2024},
  volume={12},
  number={},
  pages={14350-14363},
  abstract={Suicidal ideation detection is a vital research area that holds great potential for improving mental health support systems. However, the sensitivity surrounding suicide-related data poses challenges in accessing large-scale, annotated datasets necessary for training effective machine learning models. To address this limitation, we introduce an innovative strategy that leverages the capabilities of generative AI models, such as ChatGPT, Flan-T5, and Llama, to create synthetic data for suicidal ideation detection. Our data generation approach is grounded in social factors extracted from psychology literature and aims to ensure coverage of essential information related to suicidal ideation. In our study, we benchmarked against state-of-the-art NLP classification models, specifically, those centered around the BERT family structures. When trained on the real-world dataset, UMD, these conventional models tend to yield F1-scores ranging from 0.75 to 0.87. Our synthetic data-driven method, informed by social factors, offers consistent F1-scores of 0.82 for both models, suggesting that the richness of topics in synthetic data can bridge the performance gap across different model complexities. Most impressively, when we combined a mere 30% of the UMD dataset with our synthetic data, we witnessed a substantial increase in performance, achieving an F1-score of 0.88 on the UMD test set. Such results underscore the cost-effectiveness and potential of our approach in confronting major challenges in the field, such as data scarcity and the quest for diversity in data representation.},
  keywords={Synthetic data;Task analysis;Data models;Chatbots;Mental health;Social networking (online);Social factors;Artificial intelligence;Deep learning;Mental health;Synthetic data;Artificial intelligence;deep learning;large language models;suicide detection;synthetic data generation;transformer based models},
  doi={10.1109/ACCESS.2024.3358206},
  ISSN={2169-3536},
  month={},}@ARTICLE{10500822,
  author={Wang, Jiao and Zheng, Yi and Luo, Jun and Tin-Yan Lee, Timothy and Li, Pengfei and Zhang, Ying-Qi and Cheung, James Chung-Wai and Wong, Duo Wai-Chi and Ni, Ming},
  journal={IEEE Access}, 
  title={Applications of Deep Learning Models on the Medical Images of Osteonecrosis of the Femoral Head (ONFH): A Comprehensive Review}, 
  year={2024},
  volume={12},
  number={},
  pages={57613-57632},
  abstract={Deep learning models have demonstrated promising results in the early and accurate diagnosis of osteonecrosis of the femoral head (ONFH), enabling early detection and informed surgical decision-making. The objective of this review is to summarize the applications of deep learning models on the medical images of ONFH. English papers were searched from CINAHL via EBSCOhost, Embase, IEEE Xplore® Digital Library, PubMed, Scopus, and Web of Science. Sixteen studies (n =16) were eligible for data synthesis. Among these, five studies (n =5) focusing on radiographs, ten studies (n =10) focusing on magnetic resonance imaging, and one study (n =1) focusing on computed tomographic images. The applications of these studies included identifying ONFH from normal or other hip pathologies, classifying severity, segmenting, and detecting femoral head and necrotic regions, predicting signs and symptoms of ONFH, and predicting potential ONFH after fracture fixation. Generally, the models demonstrated good to excellent classification performance and excellent discriminatory power; and generally comparable to that of experienced physicians and superior to that of less experienced physicians. However, the external validity of these studies demonstrated only moderate, as evidenced by the performance on the external testing set and might be attributed to the relatively small data size used during model training. we observed a shift from CNN-based models to U-Net-based models (i.e., with encoder-decoder architecture). In addition to streamlining the segmentation, detection, and classification procedures, future studies will explore multimodal attention, self-supervised learning, explainable models, and data augmentation through generative models.},
  keywords={Hip;Feature extraction;Magnetic heads;Head;Deep learning;Medical diagnostic imaging;Artificial intelligence;Machine learning;Osteoporosis;Artificial intelligence;machine learning;osteonecrosis;avascular necrosis;femoral head collapse hip arthroplasty;literature review},
  doi={10.1109/ACCESS.2024.3389669},
  ISSN={2169-3536},
  month={},}@ARTICLE{10272352,
  author={Wang, Jingyu and Zhang, Lei and Yang, Yiran and Zhuang, Zirui and Qi, Qi and Sun, Haifeng and Lu, Lu and Feng, Junlan and Liao, Jianxin},
  journal={Journal of Communications and Information Networks}, 
  title={Network Meets ChatGPT: Intent Autonomous Management, Control and Operation}, 
  year={2023},
  volume={8},
  number={3},
  pages={239-255},
  abstract={Telecommunication has undergone significant transformations due to the continuous advancements in internet technology, mobile devices, competitive pricing, and changing customer preferences. Specifically, the most recent iteration of OpenAI's large language model chat generative pre-trained transformer (ChatGPT) has the potential to propel innovation and bolster operational performance in the telecommunications sector. Nowadays, the exploration of network resource management, control, and operation is still in the initial stage. In this paper, we propose a novel network artificial intelligence architecture named language model for network traffic (NetLM), a large language model based on a transformer designed to understand sequence structures in the network packet data and capture their underlying dynamics. The continual convergence of knowledge space and artificial intelligence (AI) technologies constitutes the core of intelligent network management and control. Multi-modal representation learning is used to unify the multi-modal information of network indicator data, traffic data, and text data into the same feature space. Furthermore, a NetLM-based control policy generation framework is proposed to refine intent incrementally through different abstraction levels. Finally, some potential cases are provided that NetLM can benefit the telecom industry.},
  keywords={Cloud computing;Chatbots;6G mobile communication;Autonomous networks;Telecommunications;Maintenance engineering;Artificial intelligence;network management and control architecture;generative pre-trained transformer;intent-based networking;NetLM;network knowledge},
  doi={10.23919/JCIN.2023.10272352},
  ISSN={2509-3312},
  month={Sep.},}@ARTICLE{10759588,
  author={Zhang, Xinyuan and Nie, Jiangtian and Huang, Yudong and Xie, Gaochang and Xiong, Zehui and Liu, Jiang and Niyato, Dusit and Shen, Xuemin},
  journal={IEEE Transactions on Wireless Communications}, 
  title={Beyond the Cloud: Edge Inference for Generative Large Language Models in Wireless Networks}, 
  year={2025},
  volume={24},
  number={1},
  pages={643-658},
  abstract={Generative Artificial Intelligenge (GAI) is revolutionizing the world with its unprecedented content creation ability. Large Language Model (LLM) is one of its most embraced branches. However, due to LLM’s substantial size and resource-intensive nature, it is cloud-hosted, raising concerns about privacy, usage limitations, and latency. In this paper, we propose to utilize ubiquitous distributed wireless edge computing resources for real-time LLM inference. Specifically, we introduce a novel LLM edge inference framework, incorporating batching and model quantization to ensure high throughput inference on resource-limited edge devices. Then, based on the architecture of transformer decoder-based LLMs, we formulate an edge inference optimization problem which is NP-hard, considering batch scheduling and joint allocation of communication and computation resources. The solution is the optimal throughput under edge resource constraints and heterogeneous user requirements on latency and accuracy. To solve this NP-hard problem, we develop an OT-GAH (Optimal Tree-search with Generalized Assignment Heuristics) algorithm with reasonable complexity and  $\frac {1}{2}$ -approximation ratio. We first design the OT algorithm with online tree-pruning for single-edge-node multi-user case, which navigates the inference request selection within the tree structure to miximize throughput. We then consider the multi-edge-node case and propose the GAH algorithm, which recrusively invokes the OT in each node’s inference scheduling iteration. Simulation results demonstrate the superiority of OT-GAH batching over other benchmarks, revealing an over 45% time complexity reduction compared to brute-force searching.},
  keywords={Computational modeling;Quantization (signal);Accuracy;Inference algorithms;Throughput;Wireless networks;Transformers;Resource management;Optimization;Chatbots;Generative AI;edge inference;wireless networks;multiuser edge computing},
  doi={10.1109/TWC.2024.3497923},
  ISSN={1558-2248},
  month={Jan},}@ARTICLE{10902388,
  author={Na, Hyunsik and Choi, Daeseon},
  journal={IEEE Access}, 
  title={TrapMI: A Data Protection Method to Resist Model Inversion Attacks in Split Learning}, 
  year={2025},
  volume={13},
  number={},
  pages={39364-39379},
  abstract={Split learning is a neural network training approach that can overcome the limitations of traditional deep neural networks in edge artificial intelligence environments. It offers the advantage of privacy protection because it transmits intermediate features that are calculated via the client-side model and the client does not need to send the original input data to the server. However, concerns remain regarding data privacy leakage because an attacker can still attempt model inversion attacks based on the intermediate features. We introduce several shortcomings of existing defense techniques for such attacks and present a new defense approach called TrapMI. The proposed method can induce an attacker to generate a class-specific target image that appears different from the original image when inverting the input image. We analyze the performance through quantitative and qualitative evaluations. Furthermore, the AutoGenerator is proposed to overcome the problem whereby the client cannot perform modulation that requires the target image because the class of the input image is unknown during this phase. De-identified images are automatically modulated in the inference phase using this approach. The proposed method was evaluated on two datasets, three classification models, and three split points. Its resistance was measured using a deeper and stronger inverse model than those in previous studies. Overall, the proposed method ensures data privacy protection at a significantly higher level while maintaining a similar task performance to that of existing defense technologies.},
  keywords={Servers;Data models;Training;Data privacy;Noise;Image reconstruction;Computational modeling;Protection;Feature extraction;Artificial neural networks;Artificial intelligence security;data privacy protection;model inversion attack;split learning},
  doi={10.1109/ACCESS.2025.3545597},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10404381,
  author={Xu, Mingfeng and Li, Yang and Li, Mingyu and Cui, Houxiao and Jiang, Jiamo and Du, Ying},
  booktitle={2023 International Conference on Wireless Communications and Signal Processing (WCSP)}, 
  title={A Denoising Diffusion Probabilistic Model Based Data Augmentation Method for Wireless Channel}, 
  year={2023},
  volume={},
  number={},
  pages={195-200},
  abstract={With the employment of artificial intelligence (AI) technology, remarkable performance improvements can be achieved in many wireless communication fields, which enables the evolution of conventional wireless networks towards intelligence. However, since these data-driven methods are highly dependent on data volume, problems such as the large cost and high complexity for data collection in practical systems have gradually become one of the bottlenecks. In order to get rid of the potential dilemma of insufficient data volume, the generative model based data augmentation strategy is regarded as one of the promising strategies. In this paper, we investigate the feasibility of using the recently emerging powerful generative model named denoising diffusion probabilistic model (DDPM) to produce abundant vivid synthetic wireless channel samples for supporting the model training with limited samples. In particular, the channel state information (CSI) feedback task under the fast fading channel environment in the orthogonal frequency division multiplexing (OFDM) system is selected as the experimental task. Simulation results show that our proposed scheme can provide a certain performance gain on the accuracy of channel reconstruction under various moving speed scenarios by comparing with the scheme without data augmentation, especially when the training data volume is insufficient. Besides, it also shows that more synthetic samples as appropriate can achieve better performance to a certain degree.},
  keywords={Training;Solid modeling;Training data;Performance gain;Data augmentation;Data models;Task analysis;Data augmentation;DDPM;CSI feedback;OFDM fast fading channel environment},
  doi={10.1109/WCSP58612.2023.10404381},
  ISSN={},
  month={Nov},}@ARTICLE{9681156,
  author={Wang, Shaofei and Dang, Depeng},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={A Generative Answer Aggregation Model for Sentence-Level Crowdsourcing Tasks}, 
  year={2023},
  volume={35},
  number={4},
  pages={3299-3312},
  abstract={Previous answer aggregation methods for sentence-level crowdsourcing tasks extract one sentence from a collection of redundant sentences. However, these extractive methods have a drawback in that they ignore the phenomenon of answer complementarity and the spammer dilemma in crowdsourcing. To alleviate this problem, in this paper, we generate new, comprehensive sentences that synthesize all redundant sentences. To achieve this goal, we design a sequence-to-sequence neural model composed of an encoder and decoder. Specifically, considering the complementarity phenomenon, the encoder synthesizes all the collected sentences into hidden states, which are then utilized by the decoder to generate the final sentence. Next, considering the spammer dilemma, we model the workers in the neural network to detect spammers. Furthermore, to train the neural model better, we construct pseudo-sentences to enrich the training data. The experimental results demonstrate that our method can efficiently aggregate redundant sentences and generate comprehensive sentences with increased quality.},
  keywords={Task analysis;Decoding;Crowdsourcing;Transformers;Satellites;Feeds;Training;Crowdsourcing;answer aggregation;sentence-level task},
  doi={10.1109/TKDE.2022.3142821},
  ISSN={1558-2191},
  month={April},}@INPROCEEDINGS{10655582,
  author={Ye, Fei and Bors, Adrian G.},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Online Task-Free Continual Generative and Discriminative Learning via Dynamic Cluster Memory}, 
  year={2024},
  volume={},
  number={},
  pages={26202-26212},
  abstract={Online Task-Free Continual Learning (OTFCL) aims to learn novel concepts from streaming data without accessing task information. Most memory-based approaches used in OTFCL are not suitable for unsupervised learning because they require accessing supervised signals to implement their sample selection mechanisms. In this study, we address this issue by proposing a novel memory management approach, namely the Dynamic Cluster Memory (DCM), which builds new memory clusters to capture distribution shifts over time without accessing any supervised signals. DCM introduces a novel memory expansion mechanism based on the knowledge discrepancy criterion, which evaluates the novelty of the incoming data as the signal for the memory expansion, ensuring a compact memory capacity. We also propose a new sample selection approach that automatically stores incoming data samples with similar semantic information in the same memory cluster, while also facilitating the knowledge diversity among memory clusters. Further-more, a novel memory pruning approach is proposed to automatically remove overlapping memory clusters through a graph relation evaluation, ensuring a fixed memory capacity while maintaining the diversity among the samples stored in the memory. The proposed DCM is model-free, plug-and-play, and can be used in both supervised and unsupervised learning without modifications. Empirical results on OTFCL experiments show that the proposed DCM outperforms the state-of-the-art while requiring fewer data samples to be stored. The source code is available at https://github.com/dtuzi123/DCM.},
  keywords={Training;Continuing education;Computer vision;Source coding;Memory management;Semantics;Pattern recognition;Task-Free continual learning;Memory buffer;Diffusion model},
  doi={10.1109/CVPR52733.2024.02476},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{10571163,
  author={Yang, Zheng and Zhang, Yuting and Zeng, Jie and Zhu, Chao and Bu, Xiangyuan},
  booktitle={2024 IEEE Wireless Communications and Networking Conference (WCNC)}, 
  title={Self-Adaptive and Robust 6G Network Architecture Integrating Native GPTs}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The emergence of generative pre-trained transform-ers (GPTs) will thoroughly change the application of sixth generation mobile communications (6G) networks. Therefore, it is necessary to design new network architectures to support ubiq-uitous deployment and real-time applications of GPTs. Aiming to integrate GPTs and the 6G network, this paper investigates the typical application scenarios of 6G+GPTs and summarizes the requirements of network key performance indicators (KPIs). Then, to address the complex and dynamically changing commu-nication environment, a self-adaptive 6G network architecture is proposed based on autonomous learning and self-optimization. Additionally, a novel mechanism based on attack samples is studied to improve the security of applying GPTs in 6G networks. Finally, we demonstrate that the proposed network architecture and security mechanism can satisfy the KPIs and improve robustness effectively. Overall, this paper provides a theoretical basis for the support of native GPTs with a novel 6G network architecture.},
  keywords={6G mobile communication;Industries;Privacy;Smart cities;Network architecture;Robustness;Real-time systems;6G;Endogenous Intelligence;GPTs;Network Architecture;Network Security},
  doi={10.1109/WCNC57260.2024.10571163},
  ISSN={1558-2612},
  month={April},}@INPROCEEDINGS{10371520,
  author={Nakashima, Hiroto and Shimada, Kazutaka},
  booktitle={2023 14th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)}, 
  title={Disfluency detection with context information from real utterances and generative utterances}, 
  year={2023},
  volume={},
  number={},
  pages={462-467},
  abstract={Disfluency is one of the linguistic phenomenons that often occurs in speech. Recently, automatic speech recognition has improved the accuracy of its transcript. The perfect transcript contains filler, self-repairs, distluency, and so on, because they often occurs. We focus on distluency in speech recognition outputs. The distluency in the transcript can be noise for the downstream tasks that use the transcript. In this paper, we propose a BERT-based distluency detection model for dialogue utterance. BERT handles contextual information of a target utterance to detect distluency. However, dialogue utterances can be interrupted by other speakers in conversation. Hence, utterances in dialogue tend to be short and have less contextual information. Therefore, the context of the target utterances should be complemented. In this paper, we propose two types of complementing approaches. The complement is preprocessing for the input of BERT. The first complement approach utilizes real utterances around the target utterance. In this approach, we need to select sentences from real utterances, based on some conditions: e.g., the number of utterances and the same speaker or not. The second complement approach utilizes utterances generated by a language model. The language model is trained to generate continuous utterances from the input. The generated utterance is utilized for expanding the context of the input data. In experiments, utterances from the speaker of target utterances improve the distluency detection performance. However, generated context could not outperform the real context.},
  keywords={Decision making;Data preprocessing;Batch production systems;Oral communication;Linguistics;Real-time systems;Task analysis;disfluency detection;disfluency;dialogue generation;context complement},
  doi={10.1109/IIAI-AAI59060.2023.00095},
  ISSN={2472-0070},
  month={July},}@ARTICLE{11169307,
  author={Zhao, Changyuan and Wang, Jiacheng and Zhang, Ruichen and Niyato, Dusit and Sun, Geng and Du, Hongyang and Kim, Dong In and Jamalipour, Abbas},
  journal={IEEE Wireless Communications}, 
  title={Generative AI-Enabled Wireless Communications for Robust Low-Altitude Economy Networking}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={Low-Altitude Economy Networks (LAENets) have emerged as significant enablers of social activities, offering low-altitude services such as the transportation of packages, groceries, and medical supplies. Owing to their control mechanisms and ever-changing operational factors, LAENets are inherently more complex and vulnerable to security threats than traditional terrestrial networks. As applications of LAENet continue to expand, the robustness of these systems becomes crucial. In this paper, we propose a generative artificial intelligence (GenAI) optimization framework that tackles robustness challenges in LAENets. We conduct a systematic analysis of robustness requirements for LAENets, complemented by a comprehensive review of robust Quality of Service (QoS) metrics from the wireless physical layer perspective. We then investigate existing GenAI-enabled approaches for robustness enhancement. This leads to our proposal of a novel diffusion-based optimization framework with a Mixture of Experts (MoE)-transformer actor network. In the robust beamforming case study, the proposed framework demonstrates its effectiveness by optimizing beamforming under uncertainties, achieving a more than 15% increase over four learning baselines in the worst-case achievable secrecy rate. These findings highlight the significant potential of GenAI in strengthening LAENet robustness.},
  keywords={Robustness;Optimization;Uncertainty;Quality of service;Accuracy;Drones;Stability criteria;Security;Physical layer;Wireless sensor networks;Generative AI;wireless physical layer;low-altitude economy networking;robustness},
  doi={10.1109/MWC.2025.3597910},
  ISSN={1558-0687},
  month={},}@ARTICLE{9703195,
  author={Yang, Linyao and Wang, Xiao and Zhang, Jun and Yang, Jun and Xu, Yancai and Hou, Jiachen and Xin, Kejun and Wang, Fei-Yue},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={HackGAN: Harmonious Cross-Network Mapping Using CycleGAN With Wasserstein–Procrustes Learning for Unsupervised Network Alignment}, 
  year={2023},
  volume={10},
  number={2},
  pages={746-759},
  abstract={Network alignment (NA) that identifies equivalent nodes across networks is an effective tool for integrating knowledge from multiple networks. The state-of-the-art NA methods learn inter-network node similarities based on labeled anchor links, which are costly, time-consuming, and difficult to acquire. Therefore, a few unsupervised network alignment (UNA) methods propose solving NA problems without anchor links. However, most existing UNA methods rely on discriminative attributes to capture nodes’ similarities and are hard to obtain optimal one-to-one alignments. Toward these issues, this article proposes a novel method named HackGAN to solve the UNA problem solely based on the structural information. Specifically, HackGAN represents nodes with embeddings based on an unsupervised graph neural network (GNN) to capture their global and local structural features. After that, it initializes mapping functions to transform the embedding spaces of different networks into the same vector space by iteratively solving the Wasserstein–Procrustes problem. The mapping functions are then refined by an adversarial model with cycle-consistency and Sinkhorn distance losses to obtain optimized one-to-one mappings. Based on the distances between mapped embeddings, accurate and robust results are obtained with a collective alignment algorithm. Experimental comparisons on both synthetic and real-world datasets demonstrate the superiority of HackGAN.},
  keywords={Task analysis;Optimization;Generative adversarial networks;Computational modeling;Automation;Training;Standards;Embedding;generative adversarial network;network alignment (NA);optimal transport;unsupervised learning},
  doi={10.1109/TCSS.2022.3144350},
  ISSN={2329-924X},
  month={April},}@INPROCEEDINGS{10932153,
  author={Mehta, Leena Rohan and Borse, Megha Sunil},
  booktitle={2025 1st International Conference on AIML-Applications for Engineering & Technology (ICAET)}, 
  title={A Comprehensive Review on Deep Learning Approaches for Gingivitis Detection}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Gingivitis is earlier stage of periodontitis, hence its need to be treated in time otherwise it may lead to severe damages. Due to lack of awareness, socio-economic background in developing nations, oral health is always ignored. So, automation in detection is necessary. This literature review analyses current state of the art machine and “deep learning models” employed in gingivitis detection. Though much of the literature reviewed focuses on intra-oral photographs, some of them also make use of different types of image dataset. But overall availability of diverse datasets still remains a gap in the research resulting in generalization. The findings indicate that models like “DeepLabv3+, Faster R-CNN, and MobileNetV2” have been effectively used, achieving high sensitivity and specificity in gingivitis detection. The review identifies gaps in current research, such as limited performance in real-world clinical settings and the integration of explainable AI techniques. Future research directions include improving dataset quality and size, refining model architectures for better accuracy, and exploring the application of “generative adversarial networks (GANs)” for data augmentation.},
  keywords={Deep learning;Analytical models;Sensitivity;Accuracy;Refining;Diversity reception;Sensitivity and specificity;Reliability;Socioeconomics;Systematic literature review;Gingivitis;deep learning;DeepLabv3+;ResNet50V2;MobileNetV2;VGG16;Dental radiographs},
  doi={10.1109/ICAET63349.2025.10932153},
  ISSN={},
  month={Jan},}
