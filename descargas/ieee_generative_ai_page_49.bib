@INPROCEEDINGS{10547869,
  author={Goel, Aaditya and Rao, Prateek and Bhat, Pratham and Ramesh, Rahul and Natarajan, S},
  booktitle={2024 10th International Conference on Applied System Innovation (ICASI)}, 
  title={An Exploration of Diffusion Models in the Context of Data Augmentation}, 
  year={2024},
  volume={},
  number={},
  pages={232-234},
  abstract={This survey paper examines the transformative role of medical imaging in healthcare and the integration of AI systems for diagnosis and treatment. The emergence of HealthTech startups and AI algorithms highlights the industry's rapid evolution. However, challenges persist in obtaining sensitive medical data due to consent and privacy concerns. The survey paper orchestrates an exhaustive exploration of potential remedies, harnessing the capabilities of Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and the innovative Stable Diffusion architecture. These cutting-edge frameworks collectively facilitate the synthesis of highly authentic medical images, adeptly alleviating the challenges tied to data procurement. In parallel, the survey paper undertakes a meticulous comparative analysis underpinned by three pivotal benchmarks: sampling efficiency, image diversity, and the overarching quality of the generated images.},
  keywords={Surveys;Procurement;Technological innovation;Data privacy;Medical services;Generative adversarial networks;Data augmentation;Diffusion models;synthetic data;machine learning;computer vision},
  doi={10.1109/ICASI60819.2024.10547869},
  ISSN={2768-4156},
  month={April},}@INPROCEEDINGS{9987099,
  author={Li, Tianbai and Liu, Yeung and Miao, Yingpei and Zhu, Zihe},
  booktitle={2022 IEEE 4th International Conference on Civil Aviation Safety and Information Technology (ICCASIT)}, 
  title={Analysis on Generative Adversarial Networks: Application in Graphics and Image Processing}, 
  year={2022},
  volume={},
  number={},
  pages={822-827},
  abstract={General Adversarial Network, or GAN, a novel algorithm that is efficient and not too sophisticated for most computer engineers with often greater precision than other existing algorithms, has exhibited vast amounts of merits and conveniences after dominating the major computer domains. So far, the method has been applied to and made some singular achievements in statistical and medical and other similar domains. In today’s and future’s fast paced world, this paper has seen greater demands for such a method to provide more reliable data with fewer resources and time, inspiring us to uncover the potential and possible applications of this algorithm in the future.},
  keywords={Visualization;Image processing;Computer network reliability;Superresolution;Object detection;Generative adversarial networks;Market research;Visual Application;GAN;Artificial Intelligence},
  doi={10.1109/ICCASIT55263.2022.9987099},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11016450,
  author={Benkhelifa, Fatma and Lakhani, Farha and Jendoubi, Takoua and Paltalidis, Nickos and Wijeratne, Vindya},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Exploring the Use of Genai Code Assistants for Engineering Students in Transnational Education Programmes: A Pilot Study}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={The effective use of Generative Artificial Intelligence (GenAI) in education is rapidly increasing at all levels and educators are exploring this technology to make the best use of it. This paper proposes exploiting GenAI to help engineering students perform their laboratory tasks effectively. In Transnational Education (TNE) programmes based on block teaching, students may face uneven intensive study load with nonconsistent face-to-face student-teacher contact throughout the term. There is a post-COVID impact even after lifting restrictions and bringing a change in students' behaviour of more reliance on online resources rather than in-class lectures. To address these concerns, this work aims to develop a GenAI-based tool that leverages student reliance on self-study while filling the gap between teacher-student interaction during non-teaching weeks. The AI mentor will be informed/trained with all the lab-related material for the module and is expected to support students during the lab sessions. In this paper, the authors present a pilot study and engage third-year engineering students to evaluate their willingness to use existing GenAI based code assistants in solving lab tasks that involve programming exercises. Results indicate students use GenAI tools either occasionally or frequently, to assist with programming-related assignments. When applied to lab tasks, majority of the students find GenAI code assistant quite helpful for understanding concepts and solving the programming tasks. Additionally, students utilize these tools for diverse purposes, including writing code, solving errors, and answering questions. Findings reveal high enthusiasm among students for incorporating GenAI based code assistants into labs. In the future, this work aims to do refinements in further studies and engage second-year engineering students as we believe engaging them will provide a broader perspective on the adoption and use of these technologies. As engineering graduates are generally expected to swiftly adapt to new technologies and digital environments, developing this ability pre-graduation is crucial for their skillset and their professional readiness.},
  keywords={Codes;Generative AI;Writing;Filling;Engineering students;Programming profession;Faces;Transnational education;engineering;generative AI;virtual AI mentor;practical coursework},
  doi={10.1109/EDUCON62633.2025.11016450},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11100023,
  author={E, Padma. and M, Girija Gayathri and R, Gowri Shankar and M, Monisha R},
  booktitle={2025 International Conference on Emerging Technologies in Engineering Applications (ICETEA)}, 
  title={Hybrid Deep Learning Framework for Melanoma Detection: Integrating GANs, Capsule Networks, and CNN + SVM}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Melanoma is an aggressive kind of skin cancer, coming under dire need of being detected early for effective treatment. The paper proposes a hybrid deep-learning model that combines the principles of Generative Adversarial Networks (GAN), Capsule Networks (CapsNet), and a CNN-SVM Ensemble model for improved level of melanoma classification. Herein, the GAN is used for data augmentation, while CapsNet provides enhancement concerning spatial feature extraction and, in turn, contributes to passing high-level features to CNN-SVM model ensuring high accuracy in classification. The model is evaluated on a publicly available dataset, outperforming traditional methods with an accuracy of 92% to 96%. This approach shows a promising tool for early detection of melanoma, thus helping dermatologists to make the right diagnosis and conduct appropriate treatment.},
  keywords={Deep learning;Accuracy;Mortality;Melanoma;Feature extraction;Generative adversarial networks;Data augmentation;Hybrid power systems;Usability;Image classification;Melanoma;Deep Learning;GANs;Capsule Networks;CNN-SVM;Skin Cancer Detection;Image Classification},
  doi={10.1109/ICETEA64585.2025.11100023},
  ISSN={},
  month={June},}@INPROCEEDINGS{9008137,
  author={Siddiquee, Md Mahfuzur Rahman and Zhou, Zongwei and Tajbakhsh, Nima and Feng, Ruibin and Gotway, Michael and Bengio, Yoshua and Liang, Jianming},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Learning Fixed Points in Generative Adversarial Networks: From Image-to-Image Translation to Disease Detection and Localization}, 
  year={2019},
  volume={},
  number={},
  pages={191-200},
  abstract={Generative adversarial networks (GANs) have ushered in a revolution in image-to-image translation. The development and proliferation of GANs raises an interesting question: can we train a GAN to remove an object, if present, from an image while otherwise preserving the image? Specifically, can a GAN ``virtually heal'' anyone by turning his medical image, with an unknown health status (diseased or healthy), into a healthy one, so that diseased regions could be revealed by subtracting those two images? Such a task requires a GAN to identify a minimal subset of target pixels for domain translation, an ability that we call fixed-point translation, which no GAN is equipped with yet. Therefore, we propose a new GAN, called Fixed-Point GAN, trained by (1) supervising same-domain translation through a conditional identity loss, and (2) regularizing cross-domain translation through revised adversarial, domain classification, and cycle consistency loss. Based on fixed-point translation, we further derive a novel framework for disease detection and localization using only image-level annotation. Qualitative and quantitative evaluations demonstrate that the proposed method outperforms the state of the art in multi-domain image-to-image translation and that it surpasses predominant weakly-supervised localization methods in both disease detection and localization. Implementation is available at https://github.com/jlianglab/Fixed-Point-GAN.},
  keywords={Gallium nitride;Diseases;Generative adversarial networks;Hair;Image color analysis;Biomedical imaging;Face},
  doi={10.1109/ICCV.2019.00028},
  ISSN={2380-7504},
  month={Oct},}@INPROCEEDINGS{9484393,
  author={Qi, Xingqun and Sun, Muyi and Wang, Weining and Dong, Xiaoxiao and Li, Qi and Shan, Caifeng},
  booktitle={2021 IEEE International Joint Conference on Biometrics (IJCB)}, 
  title={Face Sketch Synthesis via Semantic-Driven Generative Adversarial Network}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={Face sketch synthesis has made significant progress with the development of deep neural networks in these years. The delicate depiction of sketch portraits facilitates a wide range of applications like digital entertainment and law enforcement. However, accurate and realistic face sketch generation is still a challenging task due to the illumination variations and complex backgrounds in the real scenes. To tackle these challenges, we propose a novel Semantic-Driven Generative Adversarial Network (SDGAN) which embeds global structure-level style injection and local class-level knowledge re-weighting. Specifically, we conduct facial saliency detection on the input face photos to provide overall facial texture structure, which could be used as a global type of prior information. In addition, we exploit face parsing layouts as the semantic-level spatial prior to enforce globally structural style injection in the generator of SDGAN. Furthermore, to enhance the realistic effect of the details, we propose a novel Adaptive Re-weighting Loss (ARLoss) which dedicates to balance the contributions of different semantic classes. Experimentally, our extensive experiments on CUFS and CUFSF datasets show that our proposed algorithm achieves state-of-the-art performance.},
  keywords={Knowledge engineering;Law enforcement;Semantics;Layout;Lighting;Generative adversarial networks;Generators},
  doi={10.1109/IJCB52358.2021.9484393},
  ISSN={2474-9699},
  month={Aug},}@INPROCEEDINGS{10833973,
  author={Hu, Yaodong and Chen, Zhen and Lin, Yuxiang and Wang, Junyu and Liu, Yishan and Lin, Weiran and Zhang, Lie and Guo, Min},
  booktitle={2024 Artificial Intelligence x Humanities, Education, and Art (AIxHEART)}, 
  title={MEMOS : Multimodal Educational Mentor and Optimisation System Based on Multi-Agent}, 
  year={2024},
  volume={},
  number={},
  pages={58-63},
  abstract={In the rapidly evolving field of AI, education stands as a significant application domain. This paper presents an intelligent system designed to assist both teaching and learning by integrating multimodal large models and a multi-agent framework. Our system leverages intelligent hardware to record real classroom videos, which are then processed by multimodal models for recognition, comprehension, and description. These courses’ data are stored in a vector database and interacted with large models to automatically generate teaching and learning reports. The system's core functions include automated lecture recording, note generation, and interactive feedback mechanisms, fostering an adaptive and efficient educational environment. This process aims to enhance teaching content and planning for educators, while also improving learning efficiency for students.},
  keywords={Adaptation models;Reviews;Education;User interfaces;Hardware;Data models;Vectors;Recording;Videos;Testing;multimodal large models;AI agent;generative AI;intelligent hardware;education},
  doi={10.1109/AIxHeart62327.2024.00018},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10161205,
  author={Chiu, Sheng–Yang and Huang, Yu–Ting and Lin, Chieh–Ting and Tseng, Yu–Chee and Chen, Jen–Jee and Tu, Meng–Hsuan and Tung, Bo–Chen and Nieh, YuJou},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Privacy-Preserving Video Conferencing via Thermal-Generative Images}, 
  year={2023},
  volume={},
  number={},
  pages={9478-9485},
  abstract={Due to the COVID-19 epidemic, video conferencing has evolved as a new paradigm of communication and teamwork. However, private and personal information can be easily leaked through cameras during video conferencing. This includes leakage of a person's appearance as well as the contents in the background. This paper proposes a novel way of using online low-resolution thermal images as conditions to guide the synthesis of RGB images, bringing a promising solution for real-time video conferencing when privacy leakage is a concern. SPADE-SR [1] (Spatially-Adaptive De-normalization with Self Resampling), a variant of SPADE, is adopted to incorporate the spatial property of a thermal heatmap and the non-thermal property of a normal, privacy-free pre-recorded RGB image provided in a form of latent code. We create a PAIR-LRT-Human (LRT = Low-Resolution Thermal) dataset to validate our claims. The result enables a convenient way of video conferencing where users no longer need to groom themselves and tidy up backgrounds for a short meeting. Additionally, it allows a user to switch to a different appearance and background during a conference.},
  keywords={Heating systems;Privacy;Image synthesis;Switches;Light rail systems;Thermal sensors;Sensor systems;conditional GAN;confidentiality and privacy;image synthesis;sensor system;video conference},
  doi={10.1109/ICRA48891.2023.10161205},
  ISSN={},
  month={May},}@INPROCEEDINGS{10413016,
  author={Wang, Hsi Yeh and Utama, Surapong},
  booktitle={2023 7th International Conference on Information Technology (InCIT)}, 
  title={Investigating the Generative-AI Evaluation Methods and Correlation with Fashion Designers}, 
  year={2023},
  volume={},
  number={},
  pages={508-513},
  abstract={AI drawing tools set off a revolutionary trend in the field of image creation. However, there is still no clear and appropriate evaluation standard to rank AI graphics in fashion. In addition, most fashion industry insiders never used AI tools before. This research aims to evaluate whether AI-generated images could satisfy fashion designers’ needs by comparing automatic and human evaluations. Therefore, AI-generated fashion datasets with 25 images using Leonardo AI were created, and a survey was conducted to check how the experts ranked the AI images. Automatic evaluation methods, such as FID and Clip scores of each picture were measured to observe the correlation with human evaluation. The result showed the correlation coefficient between expert scores to FID scores is only 0.30, while the correlation coefficient between expert scores to Clip scores is 0.05. In other words, human evaluation and automatic evaluation are not so related and both have insufficiencies. Automatic evaluation is unable to provide judgments on fashion and aesthetics. The evaluations of different experts vary greatly due to the subjective consciousness and cannot provide fair and objective standards. Thus, it is necessary to create a new evaluation method that can evaluate the generated image in both fashion and AI aspects.},
  keywords={Surveys;Industries;Correlation coefficient;Correlation;Software;Artificial intelligence;Standards;Generative AI;Fashion design;AI Evaluation method},
  doi={10.1109/InCIT60207.2023.10413016},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10977144,
  author={Zuo, Yu and Shen, Xiaobing and Tian, Fanghao and Kong, Jiaze and Wouters, Hans and Martinez, Wilmar},
  booktitle={2025 IEEE Applied Power Electronics Conference and Exposition (APEC)}, 
  title={cGANET-Enhanced Voltage Gain Modeling: Elevating CLLC Converter Accuracy}, 
  year={2025},
  volume={},
  number={},
  pages={2167-2172},
  abstract={The voltage gain model of resonant converters is crucial for parameter design and optimization. Common methods, such as Fundamental Harmonic Approximation (FHA), lack sufficient accuracy, and time-domain analysis (TDA) is computationally intensive and varies across different operating modes. Therefore, this paper proposes a voltage gain prediction model based on conditional Generative Adversarial Networks (cGANET). The new voltage gain model is developed by training the cGANET with a dataset of voltage gain data from simulations under various conditions, enabling accurate predictions of the complex, non-linear interactions within the resonant converter without relying on simplifying assumptions or mode-specific formulas like FHA and TDA. Leveraging its powerful extrapolation and interpolation abilities, the cGANET model maintains high accuracy for voltage gain within and beyond the training range, even with limited training data, and adapts to new conditions without extensive reconfiguration. To validate the proposed model, a prototype CLLC converter was constructed and tested across various switching frequencies. The results demonstrates that the proposed model improves accuracy by 60% under the worst conditions compared to FHA, beneficial for enhancing design and optimization of resonant converters.},
  keywords={Adaptation models;Interpolation;Accuracy;Computational modeling;Training data;Voltage;Resonant converters;Predictive models;Data models;Optimization;CLLC resonant converter;Wide voltage range;Analysis methodologies;Conditional generative adversarial networks;Artificial intelligence (AI)},
  doi={10.1109/APEC48143.2025.10977144},
  ISSN={2470-6647},
  month={March},}@ARTICLE{8887504,
  author={Ye, Fei and Zhu, Fei and Fu, Yuchen and Shen, Bairong},
  journal={IEEE Access}, 
  title={ECG Generation With Sequence Generative Adversarial Nets Optimized by Policy Gradient}, 
  year={2019},
  volume={7},
  number={},
  pages={159369-159378},
  abstract={Electrocardiogram (ECG) is a method used by physicians to detect cardiac disease. Requirements for batch processing and accurate recognition of clinical data have led to the applications of deep-learning methods for feature extraction, classification, and denoising of ECGs; however, deep learning requires large amounts of data and multi-feature integration of datasets, with most available methods used for ECGs incapable of extracting global features or resulting in unstable, low quality training. To address these deficiencies, we proposed a novel generative adversarial architecture called RPSeqGAN using a training process reliant upon a sequence generative adversarial network (SeqGAN) algorithm that adopts the policy gradient (PG) in reinforcement learning. Based on clinical records collected from the MIT-BIH arrhythmia database, we compared our proposed model with three deep generative models to evaluate its stability by observing the variance of their loss curves. Additionally, we generated ECGs with five periods and evaluated them according to six metrics suitable for time series. The results indicate that the proposed model showed the highest stability and data quality.},
  keywords={Electrocardiography;Generative adversarial networks;Training;Generators;Gallium nitride;Mathematical model;Stochastic processes;Deep learning;generative adversarial networks;policy gradient;electrocardiogram;time series},
  doi={10.1109/ACCESS.2019.2950383},
  ISSN={2169-3536},
  month={},}@ARTICLE{9551995,
  author={Ann, Kyeongjin and Jang, Yeonggul and Shim, Hackjoon and Chang, Hyuk-Jae},
  journal={IEEE Access}, 
  title={Multi-Scale Conditional Generative Adversarial Network for Small-Sized Lung Nodules Using Class Activation Region Influence Maximization}, 
  year={2021},
  volume={9},
  number={},
  pages={139426-139437},
  abstract={Automatic detection and classification of thoracic diseases using deep learning algorithms have many applications supporting radiologists’ diagnosis and prognosis. However, in the medical field, the class-imbalanced problem is extremely common due to the differences in prevalence among diseases, making it difficult to develop these applications. Many GAN-based methods have been proposed to solve the class-imbalance problem on chest X-ray (CXR) data. However, these models have not been trained well for small-sized diseases because it is challenging to extract sufficient information with only a few pixels. In this paper, we propose a novel deep generative model called a class activation region influence maximization conditional generative adversarial network (CARIM-cGAN). The proposed network can control the target disease’s presence, location, and size with a controllable conditional mask. We newly introduced class activation region influence maximization (CARIM) loss to maximize the probability of disease occurrence in the bounded region represented by a conditional mask. To demonstrate an enhanced generative performance, we conducted numerous qualitative and quantitative evaluations with the samples generated using a CARIM-cGAN. The results showed that our method has a better performance than other methods. In conclusion, because the CARIM-cGAN can generate high-quality samples based on information on the location and size of the disease, we can contribute to solving problems such as disease classification, -detection, and -localization, requiring a higher annotation cost.},
  keywords={Diseases;Generators;Generative adversarial networks;Training;Computational modeling;X-ray imaging;Training data;Conditional generative model;medical image augmentation;class activation map;high resolution image;nodule classification and detection;chest X-ray},
  doi={10.1109/ACCESS.2021.3116034},
  ISSN={2169-3536},
  month={},}@ARTICLE{8993709,
  author={Oluwasanmi, Ariyo and Aftab, Muhammad Umar and Shokanbi, Akeem and Jackson, Jehoiada and Kumeda, Bulbula and Qin, Zhiquang},
  journal={IEEE Access}, 
  title={Attentively Conditioned Generative Adversarial Network for Semantic Segmentation}, 
  year={2020},
  volume={8},
  number={},
  pages={31733-31741},
  abstract={Generative Adversarial Network has proven to produce state-of-the-art results by framing a generative modeling task into a supervised learning problem. In this paper, we propose Attentively Conditioned Generative Adversarial Network (ACGAN) for semantic segmentation by designing a segmentor model that generates probability maps from images and a discriminator model which discriminates the segmentor's output from the ground truth labels. Additionally, we conditioned the discriminator's dual inputs with extra information as a conditional adversarial model such that, an attention obtained probability distribution of the segmentor's feature maps is incorporated, and the ground truth is also accompanied by a vector of the class label. We demonstrate that our proposed model can provide better semantic segmentation results while stabilizing the discriminator to model long-range dependencies as a result of the supplementary inputs to the network. The attention network particularly provides more insights by extracting cues from the feature locations, and alongside the class label vector, gives the model an advantage to inform better spectral sensitivity. Experiments on the PASCAL VOC 2012 and the CamVid datasets show that our adversarial training technique yields improved accuracy.},
  keywords={Image segmentation;Semantics;Generative adversarial networks;Gallium nitride;Task analysis;Feature extraction;Training;Generative adversarial network;deep convolutional neural network;attention network;conditional gan;semantic segmentation;deep learning},
  doi={10.1109/ACCESS.2020.2973296},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10617633,
  author={Purbandini and Fatichah, Chastine and Amaliah, Bilqis},
  booktitle={2024 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT)}, 
  title={Image Enhancement Using Deblur Generative Network and Deep Deblur Adversarial}, 
  year={2024},
  volume={},
  number={},
  pages={136-141},
  abstract={The increased use of digital cameras has given rise to new challenges such as reduced image quality resulting in poor clarity or distortion, which can result in loss or unclearness of recorded information. To overcome this problem, deep learning-based approaches such as DeblurGAN and DeepDeblur have been developed for the clarity of blurry images. This research aims to compare the performance of the two approaches in the context of improving the clarity of blurry images. The research steps include collecting data from the GoPro dataset, dividing the data into training data and test data, analyzing the data using the DeblurGAN and DeepDeblur methods, and evaluating the results using Structural Similarity Index Measure (SSIM), Mean Square Estimation (MSE), and Peak Signal-to-Noise Ratio (PSNR). The evaluation results show that the DeblurGAN method achieves the best results with SSIM values of 0.958, MSE of 0.00057, and PSNR of 33.18. This shows that DeblurGAN has better evaluation performance compared to Deep Deblur in improving the clarity of blurry images},
  keywords={Training;PSNR;Noise;Training data;Maintenance engineering;Generative adversarial networks;Image restoration;blur image;DeblurGAN;DeepDeblur;image enhancement;motion blur image},
  doi={10.1109/IAICT62357.2024.10617633},
  ISSN={2834-8249},
  month={July},}@ARTICLE{10947040,
  author={Bao, Tiffany and Trousil, Kylie and Duy Tran, Quang and Di Troia, Fabio and Park, Younghee},
  journal={IEEE Access}, 
  title={Generating Synthetic Malware Samples Using Generative AI}, 
  year={2025},
  volume={13},
  number={},
  pages={59725-59736},
  abstract={Malware attacks have a significant negative impact on organizations of varied scales in the field of cybersecurity. Recently, malware researchers have increasingly turned to machine learning techniques to combat sophisticated obfuscation methods used in malware. However, collecting a diverse set of malware samples with various obfuscation techniques is challenging and often takes years, especially for newly developed malware. This issue is further compounded by a well-known limitation of machine learning models: their poor performance when training data is scarce. In this paper, we propose a new system for generating synthetic malware samples to augment imbalanced malware dataset. Our approach decomposes malware binary samples into mnemonic opcode sequences, leveraging natural language processing to extract contextual meaning behind malware opcode features to aid the learning of generative AI (GenAI) employed in this paper, Generative Adversarial Networks (GAN), Wasserstein Generative Adversarial Networks with Gradient Penalty (WGAN-GP), and a modified Diffusion model. The experiment results show that augmenting training data with Diffusion-based synthetic data significantly improves classification performance for minor classes by up to 60% on average. This enhancement ultimately leads to an overall malware classification performance of 96%, an 8% improvement. These findings demonstrate the high quality and fidelity of the synthetic data, its robustness, and its potential applications in malware analysis. Specifically, synthetic malware data proves effective in improving the classification of minor malware classes and detection rates, even though the size of known malware data is significantly small.},
  keywords={Computer viruses;Hidden Markov models;Training;Natural language processing;Generative adversarial networks;Feature extraction;Vectors;Data models;Synthetic data;Robustness;Diffusion;GAN;generative AI;malware;natural language processing;machine learning;imbalanced datasets;data augmentation},
  doi={10.1109/ACCESS.2025.3556704},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10655134,
  author={Fu, Bin and Yu, Fanghua and Liu, Anran and Wang, Zixuan and Wen, Jie and He, Junjun and Qiao, Yu},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Generate Like Experts: Multi-Stage Font Generation by Incorporating Font Transfer Process into Diffusion Models}, 
  year={2024},
  volume={},
  number={},
  pages={6892-6901},
  abstract={Few-shot font generation (FFG) produces stylized font images with a limited number of reference samples, which can significantly reduce labor costs in manual font designs. Most existing FFG methods follow the style-content dis-entanglement paradigm and employ the Generative Adver-sarial Network (GAN) to generate target fonts by combining the decoupled content and style representations. The complicated structure and detailed style are simultaneously generated in those methods, which may be the sub-optimal solutions for FFG task. Inspired by most manual font design processes of expert designers, in this paper, we model font generation as a multi-stage generative process. Specifically, as the injected noise and the data distribution in diffusion models can be well-separated into different sub-spaces, we are able to incorporate the font transfer process into these models. Based on this observation, we generalize diffusion methods to modelfont generative process by separating the reverse diffusion process into three stages with different functions: The structure construction stage first generates the structure information for the target character based on the source image, and the font transfer stage subsequently transforms the source font to the target font. Finally, the font refinement stage enhances the appearances and local details of the target font images. Based on the above multi-stage generative process, we construct our font generation framework. named MSD-Font, with a dual-network approach to generate font images. The superior performance demonstrates the effectiveness of our model. The code is available at: https://github.com/fubinfbIMSD-Font.},
  keywords={Costs;Noise;Diffusion processes;Transforms;Manuals;Diffusion models;Generative adversarial networks;Diffusion Model;Few-shot Font Generation;Probabilistic Generative Model},
  doi={10.1109/CVPR52733.2024.00658},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{9878954,
  author={Sun, Jimeng and Weng, Shuchen and Chang, Zheng and Li, Si and Shi, Boxin},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={UniCoRN: A Unified Conditional Image Repainting Network}, 
  year={2022},
  volume={},
  number={},
  pages={11359-11368},
  abstract={Conditional image repainting (CIR) is an advanced image editing task, which requires the model to generate visual content in user-specified regions conditioned on multiple cross-modality constraints, and composite the visual content with the provided background seamlessly. Existing methods based on two-phase architecture design assume dependency between phases and cause color-image incongruity. To solve these problems, we propose a novel Unified Conditional image Repainting Network (UniCoRN). We break the two-phase assumption in the CIR task by constructing the interaction and dependency relationship between background and other conditions. We further introduce the hierarchical structure into cross-modality similarity model to capture feature patterns at different levels and bridge the gap between visual content and color condition. A new Landscape-CIR dataset is collected and annotated to expand the application scenarios of the CIR task. Experiments show that UniCoRN achieves higher synthetic quality, better condition consistency, and more realistic compositing effect.},
  keywords={Photography;Visualization;Computer vision;Image color analysis;Computer architecture;Pattern recognition;Task analysis;Image and video synthesis and generation; Computational photography},
  doi={10.1109/CVPR52688.2022.01108},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{9262172,
  author={Qiao, Linhan and Zhang, Youmin and Qu, Yaohong},
  booktitle={2020 2nd International Conference on Industrial Artificial Intelligence (IAI)}, 
  title={Pre-processing for UAV Based Wildfire Detection: A Loss U-net Enhanced GAN for Image Restoration}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={In this paper, a U-net with feature loss enhanced generative adversarial network (GAN) is designed for the wildfire or smoke images restoration which is captured by unmanned aerial vehicles in a serious environment. Based on the concepts of GAN, feature loss, and fastai API, we firstly crappy the target images, and train a U-net architecture based generator, then load the adaptive loss of discriminator and the mean square error together to train the GAN model. After the GAN, a second U-net grabs the feature loss from an Imagenet pre-trained loss network to generate the GAN output images with one more step. This U-net enhanced the generator of GAN and helped to get the main features in human conception. Comparing with other restoration methods, this model used the adaptive loss to train the GAN and perceptual loss to train the next U-net. Learning rate with simulation annealing helped jumping out of the local minimum. The result proved the good performance of this model.},
  keywords={Generative adversarial networks;Gallium nitride;Generators;Lips;Mathematical model;Training;Image restoration;GAN;spectral normalization;feature loss},
  doi={10.1109/IAI50351.2020.9262172},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10486783,
  author={Dandekar, Pranali and Bhojwani, Bhavika and Balpande, Aarya and Zanwar, Sanskar and Deb, Ankan},
  booktitle={2024 2nd International Conference on Computer, Communication and Control (IC4)}, 
  title={Image Super Resolution using U-Net architecture and SRGAN: Comparative Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Super-resolution is an important image processing task that improves the resolution of high-resolution images. Low resolution is used in many different fields, including medical imaging, satellite imagery, and computer vision. This paper presents a new approach to ultra-high resolution using the U-Net architecture, a deep learning framework known for its success in image segmentation and restoration tasks.In this study, we propose an adaptive U-Net model specifically designed for ultra-high-resolution tasks. The architecture includes an encoder-decoder network with bypass connections, enabling multi-scale feature extraction and high-resolution detail reconstruction. Our model is trained on a diverse dataset of low- and high-resolution image pairs, allowing it to learn complex relationships and patterns in images.We evaluate the performance of the U-Net based superresolution method using standard image quality metrics and qualitative visual evaluation. Test results show a significant improvement in image quality, with improved sharpness, texture, and detail recovery. Furthermore, our model outperforms state-of-the-art super-resolution methods in terms of signal-to-noise ratio (PSNR) and structural similarity index (SSIM).},
  keywords={Image quality;Analytical models;Adaptation models;Visualization;Computational modeling;Superresolution;Computer architecture;Super Resolution;U-Net Model;SRGAN model},
  doi={10.1109/IC457434.2024.10486783},
  ISSN={},
  month={Feb},}@ARTICLE{10964261,
  author={Sánchez, Valentina and Güven, Çiçek and Nápoles, Gonzalo and Postma, Marie Šafář},
  journal={IEEE Access}, 
  title={Data Augmentation Techniques for fMRI Data: A Technical Survey}, 
  year={2025},
  volume={13},
  number={},
  pages={66529-66556},
  abstract={The application of machine learning to fMRI data classification, prediction, and analysis tasks has experienced rapid growth in recent years. However, its implementation has been limited by the relatively small size of labeled fMRI datasets. Data augmentation, a technique that artificially increases the size and diversity of the training dataset, can help mitigate this issue. In this technical survey, we outline the main existing techniques for augmenting fMRI data, primarily represented as image, time series, and graph data. For each of these representations, we explore specific data augmentation methods. We provide a structured framework for understanding and comparing these principal fMRI data augmentation techniques. We define and summarize examples for each category, including image augmentation, time-series augmentation, graph augmentation, and additionally cover simulation and modeling approaches. For each main technique, we offer a general definition, discuss the technical details, and provide schematic illustrations. The final section provides a critical analysis of all methods, offering recommendations on which methods to use in different scenarios, and includes a comparative table of all techniques. This survey aims to serve as a valuable resource for researchers working on fMRI-based machine learning applications, guiding them in selecting appropriate augmentation techniques and inspiring novel approaches to enhance the performance and generalizability of their models.},
  keywords={Functional magnetic resonance imaging;Data augmentation;Surveys;Data models;Brain modeling;Training;Synthetic data;Neuroimaging;Interpolation;Generators;Data augmentation;deep learning;fMRI;machine learning;synthetic data},
  doi={10.1109/ACCESS.2025.3560395},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11035207,
  author={Jyoti, Shivya and Tejpal, Moulik and R, Jothi K},
  booktitle={2025 5th International Conference on Pervasive Computing and Social Networking (ICPCSN)}, 
  title={Optimizing Generative AI Applications: A Comparative Study of Effective Prompting Techniques}, 
  year={2025},
  volume={},
  number={},
  pages={389-396},
  abstract={Generative Artificial Intelligence (GenAI) has emerged as a pivotal technology across various industries, driving advancements in automation, decision-making, and content generation. This paper investigates the efficacy of the prompt engineering methods such as zero-shot, one-shot, and few-shot prompting—in optimizing GenAI systems for diverse applications. Through a comprehensive literature review and an empirical survey involving 13 use cases such as chatbots, content creation, and medical decision support, we evaluate the performance of these prompting methods. The findings reveal that few-shot prompting excels in complex tasks, while zero-shot and one-shot prompting are more effective for simpler tasks. These insights provide practical guidance for leveraging GenAI across different domains, contributing to the advancement of AI-driven solutions.},
  keywords={Surveys;Pervasive computing;Industries;Decision support systems;Social networking (online);Large language models;Chatbots;Prompt engineering;Human resource management;Systematic literature review;Generative Artificial Intelligence (GenAI);Large Language Models (LLMs);Prompt Engineering (PE);Zero-Shot Prompting (ZSP);Few-Shot Prompting (FSP);One-Shot Prompting (OSP);Clinical Decision Support Systems (CDSS);Human Resource Management (HRM)},
  doi={10.1109/ICPCSN65854.2025.11035207},
  ISSN={},
  month={May},}@INPROCEEDINGS{9752063,
  author={Pavan Kumar, Illa and Mahaveerakannan, R and Praveen Kumar, K and Basu, Indranil and Anil Kumar, T. Ch. and Choche, Manasi},
  booktitle={2022 International Conference on Electronics and Renewable Systems (ICEARS)}, 
  title={A Design of Disease Diagnosis based Smart Healthcare Model using Deep Learning Technique}, 
  year={2022},
  volume={},
  number={},
  pages={1444-1449},
  abstract={A Smart Healthcare System (SHS) is developed from traditional healthcare by integrating the Internet of Things (IoT) with Artificial Intelligence (AI). The data are captured by millions of devices and sensors, where it is exchanged continuously with medical staff to monitor the health of patients. An important message can then be analyzed using various machine learning (ML) / deep learning (DL) algorithms to predict the severity of diseases and then shared through wireless connectivity with medical professionals who can make appropriate recommendations. The main aim of the research work is to develop a disease detection model based on SHS for diabetic disease using DL classifiers. The method considered both collected and public datasets stored in the cloud for building SHS to allow accurate time monitoring of patient health conditions. IoT devices as sensors enable smooth data gathering, while AI algorithms use the data to diagnose diseases. For disease diagnosis, Restricted Boltzmann Machine based generative adversarial network (RBM -GAN) model has only three stages for the full prediction process. The experiments are carried out in two datasets, where the performance of the proposed RBM-GAN model is compared with existing DL classifiers. The simulation results show that the proposed model increased the accuracy by 5% on both two datasets than current DL classifiers. The proposed RBM-GAN model is used as a suitable illness analysis tool for SHS from these results.},
  keywords={Simulation;Predictive models;Generative adversarial networks;Prediction algorithms;Real-time systems;Data models;Diabetes;Artificial Intelligence;Internet of Things;Deep Learning;Generative Adversarial Network;Smart Healthcare System;Disease Detection},
  doi={10.1109/ICEARS53579.2022.9752063},
  ISSN={},
  month={March},}@ARTICLE{10966044,
  author={Zhang, Xueqiao and Zhang, Chao and Sun, Jianwen and Xiao, Jun and Yang, Yi and Luo, Yawei},
  journal={IEEE Transactions on Learning Technologies}, 
  title={EduPlanner: LLM-Based Multiagent Systems for Customized and Intelligent Instructional Design}, 
  year={2025},
  volume={18},
  number={},
  pages={416-427},
  abstract={Large language models (LLMs) have significantly advanced smart education in the artificial general intelligence era. A promising application lies in the automatic generalization of instructional design for curriculum and learning activities, focusing on two key aspects: 1) customized generation: generating niche-targeted teaching content based on students' varying learning abilities and states and 2) intelligent optimization: iteratively optimizing content based on feedback from learning effectiveness or test scores. Currently, a single large LLM cannot effectively manage the entire process, posing a challenge for designing intelligent teaching plans. To address these issues, we developed EduPlanner, an LLM-based multiagent system comprising an evaluator agent, an optimizer agent, and a question analyst, working in adversarial collaboration to generate customized and intelligent instructional design for curriculum and learning activities. Taking mathematics lessons as our example, EduPlanner employs a novel Skill-Tree structure to accurately model the background mathematics knowledge of student groups, personalizing instructional design for curriculum and learning activities according to students' knowledge levels and learning abilities. In addition, we introduce the CIDDP, an LLM-based 5-D evaluation module encompassing Clarity, Integrity, Depth, Practicality, and Pertinence, to comprehensively assess mathematics lesson plan quality and bootstrap intelligent optimization. Experiments conducted on the GSM8K and Algebra datasets demonstrate that EduPlanner excels in evaluating and optimizing instructional design for curriculum and learning activities. Ablation studies further validate the significance and effectiveness of each component within the framework.},
  keywords={Education;Mathematics;Optimization;Mathematical models;Collaboration;Artificial intelligence;Multi-agent systems;Educational technology;Training;Sugar;Instructional design;intelligent agent;large language models (LLMs);multiple agents;smart education},
  doi={10.1109/TLT.2025.3561332},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{9897587,
  author={Zhou, Jinli and Chen, Yaxiong and Sun, Zhaoyang and Zhan, Chang and Liu, Feng and Xiong, Shengwu},
  booktitle={2022 IEEE International Conference on Image Processing (ICIP)}, 
  title={Feature Space Disentangling Based on Spatial Attention for Makeup Transfer}, 
  year={2022},
  volume={},
  number={},
  pages={3006-3010},
  abstract={Makeup transfer aims at rendering the makeup style from a given reference image to a source image. Most existing works have achieved promising progress by disentangled representation. However, these methods do not consider the spatial distribution of makeup style, which inevitably change the makeup-irrelevant regions. To solve the problem, we introduce a novel feature space disentangling framework based on spatial attention mechanism for makeup transfer. In particular, we first utilize a single encoder to extract all the features of the image. Then we propose a learnable spatial semantic classifier to classify the extracted features into makeup-specific and makeup-irrelevant features. Finally, we complete makeup transfer by swapping the classified features. Experiments demonstrate that the makeup-specific features precisely signify the spatial distribution of makeup style. The superiority of our approach is well demonstrated by the experiment that it produces promising visual results and keeps those makeup-irrelevant regions unchanged.},
  keywords={Deep learning;Visualization;Graphical models;Computational modeling;Semantics;Feature extraction;Rendering (computer graphics);Makeup transfer;spatial attention;disentangled representation;generative adversarial network},
  doi={10.1109/ICIP46576.2022.9897587},
  ISSN={2381-8549},
  month={Oct},}@ARTICLE{10993361,
  author={Kuo, Ming-Mu and Li, Xiangfang and Obiomon, Pamela and Qian, Lijun and Dong, Xishuang},
  journal={IEEE Access}, 
  title={Improving Student Learning Outcome Tracing at HBCUs Using Tabular Generative AI and Deep Knowledge Tracing}, 
  year={2025},
  volume={13},
  number={},
  pages={82407-82420},
  abstract={Historically Black Colleges and Universities in the United States serve a vital role in providing educational opportunities and training, particularly for underrepresented students, facing a challenge of lower retention and graduation rates compared to other institutions. To overcome this challenge, this study explores the application of generative artificial intelligence models to generate synthetic data, augmenting real datasets to improve student learning outcome tracing at these colleges and universities using Deep Knowledge Tracing techniques, which potentially offers actionable insights to identify at-risk students and enables proactive interventions to enhance retention and graduation rates in Science, Technology, Engineering and Math education. Utilizing two years of educational data from Prairie View A&M University, it applied data augmentation with tabular generative artificial intelligence models. The experimental results indicate that augmenting training data with synthetic samples generated by these models improved tracing performance measured by AUC and accuracy by approximately 5% and 3%, respectively, underscoring the potential of synthetic data to enhance the monitoring of student learning outcomes in diverse educational contexts. These findings highlight the critical role of data augmentation through generative artificial intelligence in improving the student learning outcome tracing, offering valuable insights for strategies to enhance retention and graduation rates.},
  keywords={Data models;Synthetic data;Predictive models;Accuracy;Generative AI;Numerical models;Education;Training;Knowledge engineering;Adaptation models;Generative AI;student learning outcome tracing;historically black colleges and universities;STEM education},
  doi={10.1109/ACCESS.2025.3568171},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10611321,
  author={Moos, Janosch and Derstroff, Cedric and Schröder, Niklas and Clever, Debora},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Learning to Play Foosball: System and Baselines}, 
  year={2024},
  volume={},
  number={},
  pages={4326-4332},
  abstract={This work stages Foosball as a versatile platform for advancing scientific research, particularly in the realm of robot learning. We present an automated Foosball table along with its corresponding simulated counterpart, showcasing a diverse range of challenges through example tasks within the Foosball environment. Initial findings are shared using a simple baseline approach. Foosball constitutes a versatile learning environment with the potential to yield cutting-edge research in various fields of artificial intelligence and machine learning, notably robust learning, while also extending its applicability to industrial robotics and automation setups. To transform our physical Foosball table into a research-friendly system, we augmented it with a 2 degrees of freedom kinematic chain to control the goalkeeper rod as an initial setup with the intention to be extended to the full game as soon as possible. Our experiments reveal that a realistic simulation is essential for mastering complex robotic tasks, yet translating these accomplishments to the real system remains challenging, often accompanied by a performance decline. This emphasizes the critical importance of research in this direction. In this concern, we spotlight the automated Foosball table as an invaluable tool, possessing numerous desirable attributes, to serve as a demanding learning environment for advancing robotics and automation research.},
  keywords={Training;Visualization;Video games;Games;Learning (artificial intelligence);Transforms;Robot learning},
  doi={10.1109/ICRA57147.2024.10611321},
  ISSN={},
  month={May},}@INPROCEEDINGS{10871777,
  author={J, Teena. A. and Acharya, Shreenath and Coelho, Reevan and Fernandes, Edita and Sa, Jane Rachel D and Shetty, Nithyananda},
  booktitle={2024 International Conference on Computing, Semiconductor, Mechatronics, Intelligent Systems and Communications (COSMIC)}, 
  title={An Analysis on Transliterated Dravidian Text}, 
  year={2024},
  volume={},
  number={},
  pages={272-276},
  abstract={The rapid growth and accessibility of social media platforms have led to an exponential increase in content generation across multilingual code-mixed languages. Sentiment analysis on multilingual inputs presents significant challenges due to the absence of well-developed corpora, standardized script systems, and the widespread use of transliterated text. In language processing, transliteration enables users to interact with original scripts through more familiar scripts, such as the Latin alphabet. However, it introduces complexities like out-of-vocabulary words, dialectal variations, and orthographic inconsistencies. To bridge this gap, we present a comprehensive study on sentiment analysis of transliterated Dravidian languages. Utilizing online discourse platforms, we developed a large-scale corpus consisting of 26,000 examples and constructed two models. The first model is trained to classify text into three categories, while the second model generates descriptive sentiment labels, offering deeper insights into user opinions. The presented work has acquired an accuracy of 89% and has implications for businesses, policymakers, and researchers seeking to analyze and understand public opinion in Kannada-speaking regions.},
  keywords={Sentiment analysis;Accuracy;Text analysis;Mechatronics;Social networking (online);Decision making;Writing;Multilingual;Intelligent systems;Emojis;Sentiment Analysis;Transliterated text;Kannada;Classification;Generative;BeRT;Gemma},
  doi={10.1109/COSMIC63293.2024.10871777},
  ISSN={},
  month={Nov},}@ARTICLE{10697463,
  author={Sharma, Megha and Tomar, Abhinav and Hazra, Abhishek},
  journal={IEEE Consumer Electronics Magazine}, 
  title={From Connectivity to Intelligence: The Game-Changing Role of AI and IoT in Industry 5.0}, 
  year={2025},
  volume={14},
  number={5},
  pages={6-12},
  abstract={Industry 5.0 emphasizes the profound synergy between intelligent systems and human involvement in various applications, combining precise automation in production with important cognitive abilities. Integrating robust, low-latency networking with AI and Internet of Things (IoT) technology expedites industrial advancement, showcasing the smooth merging of the physical and digital domains in Industry 5.0. We explain different design concepts that govern the integration of AI and IoT in Industry 5.0. We highlight the significance of task offloading using deep reinforcement learning approaches. In addition, we explore the fundamental structure, established guidelines, and communication methods that support IoT systems enhanced by AI. Our goal is to seamlessly integrate the capabilities of AI with the underlying infrastructure of IoT. Finally, we emphasize important research obstacles and remaining concerns, which require collaborative efforts to achieve the full potential of Industry 5.0.},
  keywords={Fifth Industrial Revolution;Artificial intelligence;Industries;Decision making;Robot sensing systems;Protocols;Industrial Internet of Things;Service robots;Real-time systems;Generative AI;Internet of Things;Artificial intelligence},
  doi={10.1109/MCE.2024.3470340},
  ISSN={2162-2256},
  month={Sep.},}@ARTICLE{10817610,
  author={Choudhary, Tavishi},
  journal={IEEE Access}, 
  title={Political Bias in Large Language Models: A Comparative Analysis of ChatGPT-4, Perplexity, Google Gemini, and Claude}, 
  year={2025},
  volume={13},
  number={},
  pages={11341-11379},
  abstract={Artificial Intelligence large language models have rapidly gained widespread adoption, sparking discussions on their societal and political impact, especially for political bias and its far-reaching consequences on society and citizens. This study explores the political bias in large language models by conducting a comparative analysis across four popular AI models—ChatGPT-4, Perplexity, Google Gemini, and Claude. This research systematically evaluates their responses to politically charged prompts and questions from the Pew Research Center’s Political Typology Quiz, Political Compass Quiz, and ISideWith Quiz. The findings revealed that ChatGPT-4 and Claude exhibit a liberal bias, Perplexity is more conservative, while Google Gemini adopts more centrist stances based on their training data sets. The presence of such biases underscores the critical need for transparency in AI development and the incorporation of diverse training datasets, regular audits, and user education to mitigate any of these biases. The most significant question surrounding political bias in AI is its consequences, particularly its influence on public discourse, policy-making, and democratic processes. The results of this study advocate for ethical implications for the development of AI models and the need for transparency to build trust and integrity in AI models. Additionally, future research directions have been outlined to explore and address the complex AI bias issue.},
  keywords={Artificial intelligence;Biological system modeling;Training;Data models;Internet;Generative AI;Ethics;Adaptation models;Training data;Decision making;Large language models (LLM);generative AI (GenAI);AI governance and policy;ethical AI systems},
  doi={10.1109/ACCESS.2024.3523764},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10707921,
  author={Shrestha, Raju and Korneliussen, Hanne},
  booktitle={2024 IEEE 7th International Conference on Multimedia Information Processing and Retrieval (MIPR)}, 
  title={A Framework for Generating Images and Hashtags for Social Media Posts for Artificial Influencers}, 
  year={2024},
  volume={},
  number={},
  pages={42-48},
  abstract={This paper introduces a novel framework that leverages artificial intelligence to create engaging social media content, encompassing both images and hashtags, using a diffusion model and interactive evolution computation. In the era of digital influencers, this approach stands out by not only generating new content that adapts to user feedback but also by its capability to engage audiences effectively. Through a series of experiments, the framework's performance was assessed based on the quality, diversity, and engagement level of the content it produces. The evaluation was conducted using both offline metrics and real-world online testing on Instagram, revealing that the framework not only excels in fostering user engagement in controlled environments but also sustains this engagement in live social media settings. The findings underscore the promising application of artificial influencers in content generation and offer valuable insights into the deployment of the proposed framework in this burgeoning field.},
  keywords={Measurement;Social networking (online);Computational modeling;Information processing;Diffusion models;Real-time systems;Web sites;Multimedia communication;Cultural differences;Testing;Social Media;Artificial Influencer;User Engagement;Interactive Evolutionary Computation;Image generation;Hashtag generation;Diffusion model},
  doi={10.1109/MIPR62202.2024.00014},
  ISSN={2770-4319},
  month={Aug},}@INPROCEEDINGS{11070773,
  author={Gopalakrishnan, Amudha and Joseph, Nalini},
  booktitle={2025 3rd International Conference on Data Science and Information System (ICDSIS)}, 
  title={Addressing Adversarial Attack Vulnerability on Medical Image Analysis Systems and Improving Robustness using GAN}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The rapid global spread of the coronavirus disease 2019 (COVID-19) led to its classification as a pandemic. Research on COVID-19 that uses AI has the potential to produce some interesting results. However, due to the integration of AI techniques in COVID-19 research, the majority of studies have overlooked the importance of ensuring the security and reliability of AI systems. To address these problems, use COVID-19 X-ray scans for examining adversarial attacks on a deep learning system. In this study, a Generative Adversarial Network (GAN) is implemented to address adversarial attacks in medical image analysis and improve robustness. This GAN on chest X-ray images increase image resolution, help in accurate diagnoses, and generate synthetic data for enhance classification performance. Because GAN can produce data that is similar to a given data and can also defend against adversarial attacks by learning to generate robust data distributions that capture underlying patterns and variations, the GAN is widely used. So, this GAN makes difficult for attackers to exploit vulnerabilities in the model. Data from COVID-19 X-ray images are collected from the Chest X-ray dataset. This process is employed by developing a GAN result that can be more powerful than adversarial data manipulation. The experimental results are showed that the implemented approach achieves the greater performance and attains the values of 99.74% of accuracy, 99.53% of recall, 99.60% of precision, and 99.70% of f1-measure when, it is compared to the existing methods including Convolutional Neural Network (CNN) and Vision Transformer (ViT), and VGG19 with CNN (VGG19 and CNN).},
  keywords={COVID-19;Accuracy;Generative adversarial networks;Robustness;Convolutional neural networks;Security;Artificial intelligence;X-ray imaging;Medical diagnostic imaging;Synthetic data;adversarial attack;covid-19;deep learning;generative adversarial networks;medical imaging},
  doi={10.1109/ICDSIS65355.2025.11070773},
  ISSN={},
  month={May},}@INPROCEEDINGS{11016490,
  author={Zhang, Yue and Reusch, Pascal},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Trust in and Adoption of Generative AI in University Education: Opportunities, Challenges, and Implications}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={Generative AI has emerged as a transformative tool in the realm of higher education, offering a wealth of opportunities for personalized learning, automated feedback, and enhanced collaboration. However, its successful adoption within university environments is significantly dependent on the trust it earns from its users, particularly students. This study investigates the levels of trust and the adoption of Generative AI among students enrolled in both German and international study programs at Hochschule Bielefeld (HSBI) and its transnational partner, Hainan Bielefeld University of Applied Sciences (BiUH). Utilizing a comprehensive questionnaire, the research explores students' perceptions of the trustworthiness of Generative AI, their usage patterns, and their concerns regarding the ethical and academic implications of its use. Preliminary findings suggest that while students widely recognize the potential of Generative AI to improve learning outcomes and efficiency, the degree of trust in its reliability and fairness varies significantly. Key factors influencing this trust include the transparency of AI systems, the perceived accuracy of outputs, and concerns about bias and misuse. Students in international and cross-cultural programs face additional challenges, such as language barriers and cultural differences, which affect how AI is perceived and utilized. Ethical concerns, particularly regarding plagiarism and academic integrity, are prevalent across all groups, underscoring the need for clear institutional guidelines and policies. The findings highlight the importance of fostering AI literacy and providing support structures to build trust and encourage responsible use. Recommendations include the implementation of transparent AI tools, tailored training programs, and the development of ethical guidelines to ensure that Generative AI enhances education while upholding academic standards. This research provides actionable insights for universities aiming to integrate Generative AI into diverse educational contexts, ensuring that it serves as a beneficial tool that complements traditional educational methods while preparing students for a future where AI plays an increasingly central role.},
  keywords={Training;Ethics;Generative AI;Plagiarism;Learning automata;Reliability;Artificial intelligence;Engineering education;Standards;Guidelines;Generative AI;trust;university education;adoption;academic integrity;AI literacy},
  doi={10.1109/EDUCON62633.2025.11016490},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11137979,
  author={Yang, Tao and Qin, Shixiong},
  booktitle={2025 7th International Conference on Artificial Intelligence Technologies and Applications (ICAITA)}, 
  title={Optimization of Forest Park Road Alignment using Genetic Algorithm}, 
  year={2025},
  volume={},
  number={},
  pages={457-461},
  abstract={Forest park roads are integral to connecting functional zones, preserving ecological balance, and enhancing visitor experience. However, in mountainous areas, the complex terrain and diverse user requirements present challenges for achieving optimal road alignment. To address these challenges, this study introduces a parametric road alignment optimization method for forest parks, integrating generative AI with a visual programming model in Grasshopper. By using the Analytic Hierarchy Process (AHP) for determining multi-factor weights, and incorporating digital elevation data alongside user preference analysis, the method utilizes a genetic algorithm to refine road alignment. Applied to Qipanshan Forest Park as a case study, the results indicate that the optimized route reduces total road length by approximately $7.2\%$ compared to the existing route, optimizing both the length and slope. This not only improves travel efficiency and safety but also enhances the park's connectivity and the overall visitor experience. The proposed method offers a scientifically grounded approach to road alignment design in small- and medium-scale forest parks, providing a practical reference for future designs.},
  keywords={Visualization;Generative AI;Roads;Forestry;Writing;Programming;Reliability engineering;Safety;User preference;Genetic algorithms;Forest Park;Road alignment;Generative AI;Rhino+Grasshopper;Genetic Algorithm},
  doi={10.1109/ICAITA67588.2025.11137979},
  ISSN={},
  month={June},}@INBOOK{10359393,
  author={Banafa, Ahmed},
  booktitle={Transformative AI: Responsible, Transparent, and Trustworthy AI Systems}, 
  title={6 Generative AI and Other Types of AI}, 
  year={2024},
  volume={},
  number={},
  pages={33-40},
  abstract={Transformational Artificial Intelligence provides a comprehensive overview of the latest trends, challenges, applications, and opportunities in the field of Artificial Intelligence. The book covers the state of the art in AI research, including machine learning, natural language processing, computer vision, and robotics, and explores how these technologies are transforming various industries and domains, such as healthcare, finance, education, and entertainment. The book also addresses the challenges that come with the widespread adoption of AI, including ethical concerns, bias, and the impact on jobs and society. It provides insights into how to mitigate these challenges and how to design AI systems that are responsible, transparent, and trustworthy. The book offers a forward-looking perspective on the future of AI, exploring the emerging trends and applications that are likely to shape the next decade of AI innovation. It also provides practical guidance for businesses and individuals on how to leverage the power of AI to create new products, services, and opportunities. Overall, the book is an essential read for anyone who wants to stay ahead of the curve in the rapidly evolving field of Artificial Intelligence and understand the impact that this transformative technology will have on our lives in the coming years.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770040181},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10359393},}@INPROCEEDINGS{10191202,
  author={Peketi, Divya and Chalavadi, Vishnu and Mohan, C Krishna and Chen, Yen Wei},
  booktitle={2023 International Joint Conference on Neural Networks (IJCNN)}, 
  title={FLWGAN: Federated Learning with Wasserstein Generative Adversarial Network for Brain Tumor Segmentation}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Recently, the potential of deep learning in identifying complex patterns is gaining research interest in medical applications specifically for brain tumor diagnosis. To segment tumors accurately in brain MRIs, there is a need for a large amount of data for training deep learning models. Also, hospitals cannot share patient data for centralization on the server since health records are prone to privacy and ownership challenges. To deal with these challenges, we set up an efficient federated learning (FL) pipeline with Wasserstein generative adversarial networks (FLWGAN) to ensure data privacy and data sufficiency. FL preserves the data privacy of clients by sharing only the trained model parameters to a centralized server instead of raw data. A modified 3D Wasserstein generative adversarial network with gradient penalty (WGAN-GP) and is incorporated at the client side to generate image-segmentation pairs for efficient training segmentation models. Here, 3D-UNet with an attention module is used for the brain MRI segmentation. The attention module is integrated into a 3D-UNet encoder network for effective brain tumor segmentation. Our approach aims to allow each client to benefit from locally available real data and synthetic data. This process enhances the learning performance while respecting data privacy. The efficacy of our proposed pipeline is demonstrated on the brain tumor task of the medical segmentation decathlon (MSD) dataset. We designed FLWGAN frameworks for predicting four segmentation tasks, i.e., whole tumor (WT), enhanced tumor (ET), tumor core (TC), and multiclass. Our proposed approach achieves state of the art performance in terms of various segmentation metrics.},
  keywords={Training;Image segmentation;Data privacy;Federated learning;Brain modeling;Generative adversarial networks;Data models;Federated Learning;Wasserstein generative adversarial network-gradient penalty;3D-UNet segmentation model with attention;Brain tumor segmentation},
  doi={10.1109/IJCNN54540.2023.10191202},
  ISSN={2161-4407},
  month={June},}@INPROCEEDINGS{10890440,
  author={Guan, Hongzheng and Jin, Tao and Xiao, Li and Qu, Gang and Wang, Yu-Ping},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Spatio-Temporal Mapping Generative Adversarial Network for Functional Connectivity Network Reconstruction across Brain Atlases}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Functional connectivity networks (FCNs), as graph-structured data derived from functional magnetic resonance imaging (fMRI), are essential for understanding how brain functions coordinate with behavior and cognition. However, the utility of these FCNs is often limited by the brain atlas, since the predefined regions of interest by the atlas represent nodes in FCNs. To address these limitations and enhance the comparability of functional connectivity analyses across different atlases, we introduce the Spatio-Temporal Mapping Generative Adversarial Network (STMap-GAN) based on generative modeling. Convolutional networks and long short-term memory modules are used in the generator to improve the spatio and temporal consistency of generated fMRI time series for target brain atlases. The transformer module in the discriminator can effectively capture different features in fMRI time series, thus accurately distinguishing the generated time series from ground truth. This study demonstrates the ability of STMap-GAN to maintain high fidelity in FCN mapping across various atlases, ensuring consistency and replicability in neuroscience research.},
  keywords={Time series analysis;Functional magnetic resonance imaging;Signal processing;Transformers;Generative adversarial networks;Convolutional neural networks;Speech processing;Image reconstruction;Long short term memory;Replicability;brain atlases;functional connectivity networks;generative adversarial networks},
  doi={10.1109/ICASSP49660.2025.10890440},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10467652,
  author={Satapathy, Ashutosh and Duda, Neelima and Machcha, Jaswanthi and Thottempudi, Kokila},
  booktitle={2024 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)}, 
  title={A Multiclass Semi-Supervised Deep Convolutional Generative Adversarial Network for Music Genre Classification Using Mel-Frequency Cepstral Coefficients}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The growing consumer base and expanding market for various music styles highlight the necessity of classifying music genres to cater to people's preferences. Manual music ranking is a labor-intensive process for listeners, prompting the need for a more efficient approach. This involves the extraction of Mel-frequency cepstral coefficient feature maps from the log Mel-spectrograms of audio clips. The extracted feature maps are supplied to a multiclass semi-supervised deep convolutional generative adversarial network where the discriminator behaves as a classifier. The training of models involves utilizing the GTZAN standardized dataset, a publicly accessible collection of thousands of audio files spanning ten different genres, from which 80% and 20% of the data are used for training and testing, respectively. Finally, the paper discusses the performance of the semi-supervised deep convolutional generative adversarial network through the RMSprop and Adam optimizers on the original and augmented labeled and unlabeled MFCC feature maps. Without any data augmentation, the discriminator achieves a training accuracy of 97.9% and a test accuracy of about 45.67%. In contrast, the discriminator's training accuracy is about 98.3%, and the test accuracy is 84.75% with data augmentation.},
  keywords={Training;Computational modeling;Training data;Music;Generative adversarial networks;Feature extraction;Data augmentation;Semi-Supervised Deep Convolutional Generative Adversarial Network;Mel-frequency Cepstral Coefficients;GTZAN;Indian Music Genre;Data Augmentation;Multiclass Classification},
  doi={10.1109/IITCEE59897.2024.10467652},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10447038,
  author={Hu, Yulan and Ouyang, Sheng and Yang, Zhirui and Zhao, Yi and Wan, Junchen and Zhang, Fuzheng and Wang, Zhongyuan and Liu, Yong},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={GFMAE: Self-Supervised GNN-Free Masked Autoencoders}, 
  year={2024},
  volume={},
  number={},
  pages={7500-7504},
  abstract={Generative self-supervised learning, represented by graph autoencoders (GAEs), has begun to exhibit significant potential in addressing graph tasks. However, GAEs often rely on Graph Neural Networks (GNNs) for encoding and decoding, this can pose a computation challenge due to the inherent complexities of the aggregation mechanism in GNNs. Furthermore, the bipartite structure of GAEs introduces additional computational burdens. In contrast, Multi-Layer Perceptrons (MLPs) have no graph dependency and can train much faster than GNNs. Motivated by this, in this work, we introduce a simple yet effective alternative: the GNN-Free Masked AutoEncoder (GFMAE), which employs MLPs rather than GNNs to serve as the backbone model to speed up training. Additionally, we devise comprehensive decoding strategies to compensate for the inability of MLPs in characterizing the graph. Our comprehensive experiments conducted on eight datasets demonstrate that GFMAE achieves performance comparable to GNNs while also enhancing the training efficiency of generative models with GNNs as the backbone.},
  keywords={Training;Computational modeling;Self-supervised learning;Signal processing;Encoding;Graph neural networks;Decoding;Generative Learning;Autoencoder;Multi-Layer Perceptrons;Self-supervised Learning},
  doi={10.1109/ICASSP48485.2024.10447038},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10628367,
  author={Rajput, Saurabhsingh and Sharma, Tushar},
  booktitle={2024 IEEE 21st International Conference on Software Architecture Companion (ICSA-C)}, 
  title={Benchmarking Emerging Deep Learning Quantization Methods for Energy Efficiency}, 
  year={2024},
  volume={},
  number={},
  pages={238-242},
  abstract={In the era of generative artificial intelligence (AI), the quest for energy-efficient AI models is increasing. The increasing size of recent AI models has led to quantization techniques that reduce large models' computing and memory requirements. This study aims to compare the energy consumption of five quantization methods, viz. Gradient-based Post-Training Quantization (GPTQ),Activation-aware Weight Quantization (AWQ), GPT-Generated Model Language (GGML), GPT-Generated Unified Format (GGUF), and Bits and Bytes (BNB). We benchmark and analyze the energy efficiency of these commonly used quantization methods during inference. This preliminary exploration found that GGML and its successor GGUF were the most energy-efficient quantization methods. Our findings reveal significant variability in energy profiles across methods, challenging the notion that lower precision universally improves efficiency. The results underscore the need to benchmark quantization techniques from an energy perspective beyond just model compression. Our findings could guide the selection of models using quantization techniques and the development of new quantization techniques that prioritize energy efficiency, potentially leading to more environmentally friendly AI deployments.},
  keywords={Deep learning;Energy consumption;Quantization (signal);Software architecture;Generative AI;Computational modeling;Memory management;Quantization;Energy Consumption;Green AI;Energy Efficiency},
  doi={10.1109/ICSA-C63560.2024.00049},
  ISSN={2768-4288},
  month={June},}@INPROCEEDINGS{10973906,
  author={Rivadeneira, Franco and Carcausto, Daniela and Ore, Clara and Saga, Gabriela and Vilca, Macarena and Arroyo, Dante},
  booktitle={2025 20th ACM/IEEE International Conference on Human-Robot Interaction (HRI)}, 
  title={AI - Driven Design of a Robotic Companion with Feline-Inspired Behaviors for Stress Relief}, 
  year={2025},
  volume={},
  number={},
  pages={1568-1572},
  abstract={The rising levels of stress and anxiety among university students have become increasingly alarming, largely driven by academic pressures, social expectations, and the transition to adulthood. These challenges often result in a decline in mental well-being, necessitating innovative solutions to help ease the burden. This paper presents the design and development process of Purry, a social robot inspired by cat behaviors, created to provide stress relief for university students. Purry was designed to of Fer emotional comfort in a unique way, harnessing the calming effects of pet-like interactions. The design process focused on achieving both aesthetic appeal and functional efficiency, combining modern and traditional technologies such as generative artificial intelligence and low-cost materials, following the double diamond methodology. The robot mimics feline behaviors like kneading and purring, exploring both active and passive tactile interactions, which have been shown to reduce stress through sensory stimulation. Iterative development cycles, guided by user feedback, led to significant advancements in balancing form and function. The final result is a robotic experience that combines emotional support with innovative design, offering a product that not only addresses students' mental health needs but also fosters an engaging and comforting presence in their environment.},
  keywords={Cats;Generative AI;Social robots;MIMICs;Anxiety disorders;Mental health;Robot sensing systems;Diamond;Iterative methods;Design Process;Robot-Human Interaction;Active Touch},
  doi={10.1109/HRI61500.2025.10973906},
  ISSN={},
  month={March},}@ARTICLE{11077726,
  author={Xu, Changfu and Guo, Jianxiong and Liang, Yuzhu and Zou, Haodong and Zeng, Jiandian and Dai, Haipeng and Jia, Weijia and Cao, Jiannong and Wang, Tian},
  journal={IEEE Transactions on Mobile Computing}, 
  title={Enhancing QoE in Collaborative Edge Systems with Feedback Diffusion Generative Scheduling}, 
  year={2025},
  volume={},
  number={},
  pages={1-16},
  abstract={Collaborative edge computing is a promising approach for delivering low-delay services to computation-intensive Internet of Things applications. Deep Reinforcement Learning (DRL) has become an effective way to solve task scheduling decisions in edge systems due to its adaptive learning ability to interact with the environment. However, current DRL-based task scheduling methods still face several challenges, such as limited exploration, sample inefficiency, and performance instability, which can lead to degraded user Quality of Experience (QoE). To address these challenges, we observe that diffusion models, famous for their performance in image generation, exhibit strong exploration, data efficiency, and performance stability. This inspires us to propose FDEdge, a novel feedback diffusion generative scheduling method for enhancing user QoE in collaborative edge systems. We first design an innovative Feedback Diffusion (FDN) model by leveraging historical action probability information during the denoising process. We then incorporate the FDN model into DRL, forming an effective and efficient framework for task scheduling in collaborative edge systems. We also present a probability derivation to ensure the FDEdge's rationality. Extensive experimental results demonstrate that our FDEdge method significantly reduces service delays by $45.42\%$ to $87.57\%$ and speeds up training episode durations by $2.5\times$ times for a higher QoE than state-of-the-art methods. We release our open-source code at https://github.com/ChangfuXu/FDEdge.},
  keywords={Processor scheduling;Collaboration;Optimal scheduling;Edge computing;Quality of experience;Heuristic algorithms;Diffusion models;Delays;Training;Computational modeling;Edge computing;Generative task scheduling;Feedback diffusion;Deep reinforcement learning},
  doi={10.1109/TMC.2025.3587744},
  ISSN={1558-0660},
  month={},}@INPROCEEDINGS{11035267,
  author={Zhou, Bo and Liu, Jia},
  booktitle={2025 IEEE 6th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={Generative Phishing URL Detection Based on Large Language Model}, 
  year={2025},
  volume={},
  number={},
  pages={1838-1842},
  abstract={Phishing is a form of cyberattack in which the attacker pretends to be a trustworthy entity to trick users into providing sensitive information. The most common form of phishing is URL-based phishing, which uses fake URLs to trick users into entering sensitive information, leading to serious security risks. The core of the phishing URL detection task is to accurately identify forged URLs and prevent potential threats. Although existing detection methods have achieved certain results, there are still some shortcomings, including only giving labels without giving reasons for judgment, and not being able to handle complex and changeable URLs. To alleviate these deficiencies, and inspired by the deep semantic understanding capabilities of large language models, we propose a phishing URL detection model based on large language models. In this work, we transform the traditional classification paradigm in phishing URL detection into a generation paradigm to increase the interpretability of model judgment and improve the detection performance. At the same time, by doing so, we also fill the gap of underutilization of large models in phishing URL detection. We have conducted sufficient experiments, and the results show that the proposed model is superior to existing models in terms of detection accuracy and other metrics. At the same time, the proposed model requires less training data and also shows better generalization ability.},
  keywords={Uniform resource locators;Measurement;Seminars;Phishing;Large language models;Semantics;Training data;Transforms;Security;Information technology;phishing url;generation;large language model},
  doi={10.1109/AINIT65432.2025.11035267},
  ISSN={},
  month={April},}@ARTICLE{10496445,
  author={He, Kangjia and Liu, Li and Zhang, Youmin and Wang, Ye and Liu, Qun and Wang, Guoyin},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Learning Counterfactual Explanation of Graph Neural Networks via Generative Flow Network}, 
  year={2024},
  volume={5},
  number={9},
  pages={4607-4619},
  abstract={Counterfactual subgraphs explain graph neural networks (GNNs) by answering the question: “How would the prediction change if a certain subgraph were absent in the input instance?” The differentiable proxy adjacency matrix is prevalent in current counterfactual subgraph discovery studies due to its ability to avoid exhaustive edge searching. However, a prediction gap exists when feeding the proxy matrix with continuous values and the thresholded discrete adjacency matrix to GNNs, compromising the optimization of the subgraph generator. Furthermore, the end-to-end learning schema adopted in the subgraph generator limits the diversity of counterfactual subgraphs. To this end, we propose CF-GFNExplainer, a flow-based approach for learning counterfactual subgraphs. CF-GFNExplainer employs a policy network with a discrete edge removal schema to construct counterfactual subgraph generation trajectories. Additionally, we introduce a loss function designed to guide CF-GFNExplainer's optimization. The discrete adjacency matrix generated in each trajectory eliminates the prediction gap, enhancing the validity of the learned subgraphs. Furthermore, the multitrajectories sampling strategy adopted in CF-GFNExplainer results in diverse counterfactual subgraphs. Extensive experiments conducted on synthetic and real-world datasets demonstrate the effectiveness of the proposed method in terms of validity and diversity.},
  keywords={Graph neural networks;Trajectory;Predictive models;Optimization;Generators;Drugs;Training;Counterfactual subgraph;generative flow network;graph neural networks (GNNs);model explanation},
  doi={10.1109/TAI.2024.3387406},
  ISSN={2691-4581},
  month={Sep.},}@INPROCEEDINGS{10730325,
  author={Apriyadi, Steven and Juwitasary, Hanny},
  booktitle={2024 8th International Conference on Information Technology, Information Systems and Electrical Engineering (ICITISEE)}, 
  title={The Impact of Familiarity Using Generative AI to Influence Intention to Use AI}, 
  year={2024},
  volume={},
  number={},
  pages={533-538},
  abstract={AI has gained massive popularity in recent years with many tools coming out to be used and help people in daily life, especially AI writing tools. This scientific research investigates engagement and intention to use AI writing tools among students, from middle school to college. Despite the popularity, the study found that several students face issues while engaging with AI that problem can come from the complexity of the AI and the output of the AI, reducing their desire to use it. The research employs the Social Cognitive Theory (SCT) as its framework. Data were collected from 372 students, with 311 meeting the criteria for being processed using SmartPLS. The study's variables include familiarity, engagement (cognitive, behavioral, affective dimensions), and intention to use. The results indicate that five out of six hypotheses were accepted, with one hypothesis which is the relationship between familiarity and affective engagement being rejected. And the rest of the hypotheses are being accepted with a significant result},
  keywords={Electrical engineering;Generative AI;Writing;Complexity theory;Artificial intelligence;Information technology;Faces;Information systems;AI writing tools;social cognitive theory;engagement;intention to use;familiarity},
  doi={10.1109/ICITISEE63424.2024.10730325},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{11024606,
  author={Ubach, Melissa Castillo and Jiménez-Picado, Cindy},
  booktitle={2025 Institute for the Future of Education Conference (IFE)}, 
  title={Brecha Generacional y Uso de la Inteligencia Artificial Generativa en la Educación: Un Estudio de Varianza}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={This article explores the variance in generative artificial intelligence (generative AI) usage frequency among different generations. Through a survey administered to a sample of 71 individuals, factors such as age, generative tool usage, and specific tool types that impact familiarity and adoption of generative AI are analyzed. The findings reveal a tendency where the “Millennial” generation utilizes generative AI tools more frequently compared to other generations. However, a general interest in receiving training on the use of these technologies is identified, regardless of age. This study lays the groundwork for future research that will delve deeper into the educational implications of generative AI use across different age groups.},
  keywords={Generative AI;Predictive models;Silicon;Computational modeling;Videos;Training;Surveys;Solid modeling;Millennials;Iron;Generative artificial intelligence;technology adoption;generations;education},
  doi={10.1109/IFE63672.2025.11024606},
  ISSN={},
  month={Jan},}@ARTICLE{10883995,
  author={Álvarez Ariza, Jonathan and Benitez Restrepo, Milena and Hernández Hernández, Carola},
  journal={IEEE Access}, 
  title={Generative AI in Engineering and Computing Education: A Scoping Review of Empirical Studies and Educational Practices}, 
  year={2025},
  volume={13},
  number={},
  pages={30789-30810},
  abstract={Since the release of diverse generative AI (GenAI) tools such as ChatGPT, Google Gemini, DALL $\cdot $ E, and GitHub Copilot, there has been much debate around the impacts and implications of these tools on education. Currently, extant literature remarks on the affordances, challenges, and opportunities of GenAI, but few studies report and analyze empirical studies and educational practices coming up by GenAI usage in learning settings. Then, in this Scoping Review (ScR) based on 146 studies retrieved from the databases SCOPUS, Web of Science (WoS), and ERIC, we analyzed the implications of integrating GenAI in engineering and computing education from K-12 to tertiary levels. We adopted an approach starting from the bibliometric features of the studies in terms of authors, cites, years, or cluster topics, and navigating to the identification of methodologies, strategies, AI literacy instruments and guidelines, learning outcomes, and students’ and teachers’ perceptions, among other features. We advocate that current educational practices in engineering and computing with GenAI can indicate to us a roadmap of its potentialities, uses, and risks from the standpoint of both teachers and students, and this could help us to create more reflexive methodologies that enhance the teaching-learning process based on the evidence. Our purpose with the outcomes and conclusions of this scoping review is to support educators, faculty members, and other stakeholders in engineering and computing education to co-create educational methodologies that articulate GenAI with curricula, AI literacy, and prompt engineering encompassing students’ learning domains such as cognitive, affective, or behavioral.},
  keywords={Artificial intelligence;Education;Ethics;Chatbots;Systematic literature review;Computational modeling;Affordances;Privacy;Plagiarism;Training;Generative AI;GenAI;GAI;artificial intelligence;AI;computer science education;engineering education;computing education;prompt engineering;AI literacy},
  doi={10.1109/ACCESS.2025.3541424},
  ISSN={2169-3536},
  month={},}@ARTICLE{8924873,
  author={Ballagas, Rafael and Wei, Jishang and Vankipuram, Mithra and Li, Zhiyuan and Spies, Keanu and Horii, Hiroshi},
  journal={IEEE Pervasive Computing}, 
  title={Exploring Pervasive Making Using Generative Modeling and Speech Input}, 
  year={2019},
  volume={18},
  number={4},
  pages={20-28},
  abstract={Digital manufacturing technologies, especially three-dimensional (3-D) printing, are rapidly transforming the way we experience retail. Consumer products can now be deeply customized to an individual both in terms of fit, as well as style. However, consumers typically lack the design tools and expertise to express their design intent. In this article, we explore a human-centered approach for leveraging artificial intelligence (AI) to scaffold 3-D design tasks to make them accessible to more consumers. Our sunglasses kiosk prototype allows users to iteratively express their design intent at a high-level, using voice. The AI generates new 3-D designs of sunglasses that reflect the user's refined design intent. A user study examines the attitudes and behaviors toward this AI-powered kiosk approach.},
  keywords={Manufacturing processes;Three-dimensional printing;Artificial intelligence;Generators;Pervasive computing},
  doi={10.1109/MPRV.2019.2929130},
  ISSN={1558-2590},
  month={Oct},}@ARTICLE{10319350,
  author={Zhou, Yujia and Yao, Jing and Wu, Ledell and Dou, Zhicheng and Wen, Ji-Rong},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={WebUltron: An Ultimate Retriever on Webpages Under the Model-Centric Paradigm}, 
  year={2024},
  volume={36},
  number={9},
  pages={4996-5006},
  abstract={Document retrieval has been extensively studied within the index-retrieve framework for decades, which has withstood the test of time. However, this approach inherently segregates the indexing and retrieval processes, preventing a cohesive, end-to-end optimization. To bridge this divide, we introduce WebUltron, a revolutionary model-centric indexer for document retrieval. This system embeds the entirety of document knowledge within the model, striving for seamless end-to-end retrieval. Two primary challenges with this indexer are the representation of document identifiers (docids) and the model's training. Current methods grapple with docids that lack semantic depth and the constraints of limited supervised data, making scaling up to larger datasets challenging. Addressing this, we’ve engineered two novel docid types imbued with richer semantics that also streamline model inference. Further enhancing WebUltron's capabilities, we’ve developed a three-stage training regimen, leveraging deeper corpus insights and fortifying query-docid relationships. Experiments on two public datasets demonstrate the superiority of WebUltron over advanced baselines for document retrieval.},
  keywords={Task analysis;Semantics;Indexes;Training;Decoding;Data models;Computational modeling;Document retrieval;generative model;model-based IR},
  doi={10.1109/TKDE.2023.3332858},
  ISSN={1558-2191},
  month={Sep.},}@INPROCEEDINGS{10437312,
  author={Yan, Miao and Su, Zhou and Wang, Yuntao and Ran, Xiandong and Liu, Yiliang and Luan, Tom H.},
  booktitle={GLOBECOM 2023 - 2023 IEEE Global Communications Conference}, 
  title={Shared DNN Model Ownership Verification in Cross-Silo Federated Learning: A GAN-Based Watermark Approach}, 
  year={2023},
  volume={},
  number={},
  pages={1807-1811},
  abstract={Cross-silo federated learning, as a distributed learning paradigm, allows clients to collaboratively train an artificial intelligence (AI) model and jointly share the model ownership without local data transfer or exposure. However, the valuable AI models are facing fatal intellectual property (IP) infringement threats when offering AI services. Existing researches on IP protection mainly focus on the centralized models (i.e., single ownership), but leave federated models (i.e., shared ownership) unexplored. In this paper, we propose IPSF, a novel shared IP protection framework with all-round verification for multiple owners under cross-silo federated learning. Specifically, instead of embedding private watermarks individually, we adopt joint watermarks and soft labels as a conjoint fingerprint, and present a watermark generative adversarial network (WM-GAN) mechanism to fuse private watermarks and facilitate the integrated verification. We also design a diversity-and similarity-oriented assessment mechanism to support mutual evaluation between private and joint watermarks. Through the designed assessment mechanism, the correlation and variability between private and joint watermarks are dynamically maintained to ensure the stability of WM-GAN and the fairness among users in verification. Extensive experiments validates that our IPSF achieves desirable fidelity and high robustness under attacks.},
  keywords={Resistance;Federated learning;Watermarking;Data models;Stability analysis;Robustness;Artificial intelligence;Federated learning;watermark;intellectual property protection;generative adversary network},
  doi={10.1109/GLOBECOM54140.2023.10437312},
  ISSN={2576-6813},
  month={Dec},}@INPROCEEDINGS{10578969,
  author={Jackson, Gavin and Valles, Damian},
  booktitle={2024 IEEE World AI IoT Congress (AIIoT)}, 
  title={Dataset Enlargement with Generative Adversarial Neural Networks}, 
  year={2024},
  volume={},
  number={},
  pages={0045-0051},
  abstract={Addressing dataset imbalance remains a critical challenge in human facial emotion classification. The predominant dataset, Facial Emotion Recognition 2013 (FER2013), exhibits significant class disparity among its 28,709 training and 3,589 test samples across seven emotions: anger, disgust, fear, happiness, sadness, surprise, and neutrality. The disproportionate representation, notably the predominance of ‘Happy’ (7,215 samples) and scarcity of ‘Disgust’ (436 samples), biases classification models towards overestimating happiness and underestimating disgust. We introduce the Transfer-Learning with Filters Generative Adversarial Network (TLF-GAN) approach to counteract this imbalance. TLF-GAN synthesizes artificial samples for underrepresented classes to balance the dataset. A base GAN model is initially trained using a comprehensive artificial face dataset. Subsequently, this model undergoes further training on underrepresented class samples. This process is supplemented by integrating binary classification models as filters within the TLF-GAN’s loss function, refining the generated outputs towards desired characteristics. This methodology augments the representation of scarce classes and establishes a feedback mechanism, enabling the continuous generation of quality samples for further training enhancements. The TLF-GAN approach offers a promising solution to the dataset imbalance issue, paving the way for more equitable and accurate emotion classification models. Moreover, its implications extend beyond facial emotion recognition, offering a viable strategy for mitigating data scarcity across various domains within artificial intelligence. This research underscores the importance of balanced datasets in training AI models, potentially leading to more accurate and fair outcomes in automated emotion recognition and beyond.},
  keywords={Training;Emotion recognition;Filters;Accuracy;Face recognition;Refining;Neural networks;Generative AI;Neural Networks;Facial Emotion Classification;Dataset Augmentation},
  doi={10.1109/AIIoT61789.2024.10578969},
  ISSN={},
  month={May},}@ARTICLE{10704718,
  author={Huang, Wenli and Deng, Ye and Wu, Yang and Wang, Jinjun},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Attentive Contextual Attention for Cloud Removal}, 
  year={2024},
  volume={62},
  number={},
  pages={1-12},
  abstract={Cloud cover can significantly hinder the use of remote sensing images for Earth observation, prompting urgent advancements in cloud removal technology. Recently, deep learning strategies, especially convolutional neural networks (CNNs) with attention mechanisms, have shown strong potential in restoring cloud-obscured areas. These methods utilize convolution to extract intricate local features and attention mechanisms to gather long-range information, improving the overall comprehension of the scene. However, a common drawback of these approaches is that the resulting images often suffer from blurriness, artifacts, and inconsistencies. This is partly because attention mechanisms apply weights to all features based on generalized similarity scores, which can inadvertently introduce noise and irrelevant details from cloud-covered areas. To overcome this limitation and better capture relevant distant context, we introduce a novel approach named attentive contextual attention (AC-Attention). This method enhances conventional attention mechanisms by dynamically learning data-driven attentive selection scores, enabling it to filter out noise and irrelevant features effectively. By integrating the AC-Attention module into the DSen2-CR cloud removal framework, we significantly improve the model’s ability to capture essential distant information, leading to more effective cloud removal. Our extensive evaluation of various datasets shows that our method outperforms existing ones regarding image reconstruction quality. In addition, we conducted ablation studies by integrating AC-Attention into multiple existing methods and widely used network architectures. These studies demonstrate the effectiveness and adaptability of AC-Attention and reveal its ability to focus on relevant features, thereby improving the overall performance of the networks. The code is available at https://github.com/huangwenwenlili/ ACA-CRNet.},
  keywords={Clouds;Convolutional neural networks;Attention mechanisms;Remote sensing;Image reconstruction;Optical sensors;Optical imaging;Generative adversarial networks;Earth;Correlation;Attentive contextual attention (AC-Attention);cloud removal;relevant distant context;remote sensing images},
  doi={10.1109/TGRS.2024.3472645},
  ISSN={1558-0644},
  month={},}@ARTICLE{10363199,
  author={Pavate, Aruna and Bansode, Rajesh and Srinivasu, Parvathaneni Naga and Shafi, Jana and Choi, Jaeyoung and Ijaz, Muhammad Fazal},
  journal={IEEE Access}, 
  title={Associative Discussion Among Generating Adversarial Samples Using Evolutionary Algorithm and Samples Generated Using GAN}, 
  year={2023},
  volume={11},
  number={},
  pages={143757-143770},
  abstract={The remarkable accomplishments of deep neural networks (DNN) have led to their widespread adoption in various contexts, including safety-critical applications. Many strategies have been implemented to generate adversarial samples using DNN, raising the question of the security of the model. Adding slight magnitude noise to the input samples during training or testing can misguide DNN to produce different results than the actual one. DNNs are sensitive to indiscernible adversarial samples but readily identifiable by them. Currently, gradient-based approaches are used to generate adversarial samples. Gradient-based methods require internal details of the model, such as several parameters, model type, Etc. Usually, these details are practically unavailable, and calculating the gradient for non-differential models is impossible. In this work, we propose a novel DESapsDE framework based on evolutionary algorithms to generate adversarial samples from the probability of labels. We also incorporated the discussion with the various Generative Adversarial Networks (GANs) models, such as ACGAN, DCGAN, and SAGAN. It has been observed that GANs differ from adversarial sample generation methods and can be applied as defense mechanisms. The proposed method reduced model confidence to 13.09% for the ResNet50 model, 30.34% for the WideResNet model, and 23.1% for the DenseNet model, with an FID score of 16.45. The proposed model varies from the GAN model. It applies to attack-on-network models as a preventive major to make the model robust.},
  keywords={Artificial neural networks;Generative adversarial networks;Evolutionary computation;Computational modeling;Perturbation methods;Data models;Training;Optimization methods;Adversarial examples;attacks;differential evolutionary algorithm;deep neural networks;generative adversary networks;optimization methods},
  doi={10.1109/ACCESS.2023.3343754},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10687528,
  author={Vijayakumar Bharathi, S and Patil, Kanchan Pranay},
  booktitle={2024 OPJU International Technology Conference (OTCON) on Smart Computing for Innovation and Advancement in Industry 4.0}, 
  title={From Algorithms to Appetizers: Exploring the Adoption of Generative AI in Culinary Robotics}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The culinary sector is changing as kitchens explore the application of robotic cooking. This study explores consumers’ reasons for and against using cooking robots in the culinary business. Data from a structured questionnaire administered online to 229 customers of the culinary industry was analyzed using structural equation modelling. According to the study, cultural food values favourably affect RoboChef’s reasons for and reasons against adoption but do not impact customer attitude. The results also show that attitude mediates the association between reasons (for and against) and intention to implement robochef in culinary. According to this study, the main drivers of adoption are anthropomorphism, social intelligence, and knowledge. The main reasons against adoption were anxiety, perceived risk and perceived cost. Robochef adoption was not primarily motivated by its dependability. Furthermore, governments may reduce the current gap between customer attitude and intention by addressing the reasons that prevent consumers from embracing robochefs. In this regard, the culinary industry should to create a marketing plan highlighting the advantages of deploying robo-chef.},
  keywords={Industries;Technological innovation;Costs;Service robots;Anxiety disorders;Mathematical models;Social intelligence;Robochef;behavioural reason theory;Cultural food values;culinary industry;Generative AI},
  doi={10.1109/OTCON60325.2024.10687528},
  ISSN={},
  month={June},}@INPROCEEDINGS{10730139,
  author={He, Long and Yu, Yue and Liu, Chang and Sun, Yangyang and Jiang, Feng and Hu, Xiaoning and Pan, Chengwei and Dong, Xiwang},
  booktitle={2024 6th International Conference on Industrial Artificial Intelligence (IAI)}, 
  title={Fuzzy-Cycle: Visible to Infrared Ship Image Translation Based on CycleGAN}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Detecting targets in infrared ship images is crucial for various applications, such as maritime rescue and ship inspection. Training contemporary mainstream detection and segmentation models, however, requires large-scale, high-quality infrared ship image datasets. In open-world maritime confrontation scenarios, the complex and variable environment, scarcity of target ships, and limited acquisition conditions make it challenging to construct high-quality infrared ship image datasets. To address this issue, this paper proposes an unpaired visible-infrared ship image translation model based on CycleGAN, named Fuzzy-Cycle. The model introduces a fuzzy cycle loss to encourage the model to learn feature mapping rules between different domains while minimizing attention to unnecessary features. Additionally, the method employs U-Net as the generator network to retain shallow image features during upsampling and selects PatchGAN as the discriminator network, embedding Haar wavelet transform to enhance the discriminator's ability to analyze image frequency domain features. Experiments on the VAIS dataset demonstrate that the proposed algorithm outperforms mainstream unpaired image transfer models, showing excellent performance in the task of visible-infrared ship image translation. Furthermore, zero-shot image translation experiments on the HRSC2016 dataset prove the generalizability and reliability of the proposed method.},
  keywords={Training;Wavelet transforms;Visualization;Wavelet domain;Statistical analysis;Surveillance;Inspection;Wavelet analysis;Reliability;Marine vehicles;generative adversarial network;infrared image generation;unpaired image-to-image translation},
  doi={10.1109/IAI63275.2024.10730139},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10445544,
  author={Clocchiatti, Alessandro and Fumerò, Nicolo and Soccini, Agata Marta},
  booktitle={2024 IEEE International Conference on Artificial Intelligence and eXtended and Virtual Reality (AIxVR)}, 
  title={Character Animation Pipeline based on Latent Diffusion and Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={398-405},
  abstract={Artificial intelligence and deep learning techniques are revolutionizing the film production pipeline. The majority of the current screenplay-to-animation pipelines focus on understanding the screenplay through natural language processing techniques, and on the generation of the animation through custom engines, missing the possibility to customize the characters. To address these issues, we propose a high-level pipeline for generating 2D characters and animations starting from screenplays, through a combination of Latent Diffusion Models and Large Language Models. Our approach uses ChatGPT to generate character descriptions starting from the screenplay. Then, using that data, it generates images of custom characters with Stable Diffusion and animates them according to their actions in different scenes. The proposed approach avoids well-known problems in generative AI tools such as temporal inconsistency and lack of control on the outcome. The results suggest that the pipeline is consistent and reliable, benefiting industries ranging from film production to virtual, augmented and extended reality content creation.},
  keywords={Industries;Solid modeling;Generative AI;Pipelines;Production;Animation;Reliability;artificial intelligence;deep learning;generative art;virtual reality;extended reality;computer animation},
  doi={10.1109/AIxVR59861.2024.00067},
  ISSN={2771-7453},
  month={Jan},}@INBOOK{10952330,
  author={Brooks, Chuck},
  booktitle={Inside Cyber: How AI, 5G, IoT, and Quantum Computing Will Transform Privacy and Our Security}, 
  title={Artificial Intelligence and Health Care}, 
  year={2025},
  volume={},
  number={},
  pages={147-150},
  abstract={Summary <p>Artificial intelligence (AI) and health can have an impact on each other in two ways. First is the threat to hospitals and health care facilities from cyberattacks, and the potential damage that can therefore occur. Second is the enormous impact AI is already making on accelerating treatment capabilities and enabling the quality of health care. Hospitals are vulnerable to cyberattacks due to the volume of data they handle and the numerous weak points in their various systems. Cybersecurity in the health care industry is changing and complex. AI is already transforming health care through its application in medication discovery and analysis of mixtures of substances and procedures that will improve human health and combat illnesses and pandemics. Predictive analytics is one of the most interesting applications of AI in health care. AI will get more sophisticated at controlling sickness, creating individualized care plans, and forecasting health outcomes as it develops.</p>},
  keywords={Medical services;Hospitals;Biomedical imaging;Codes;Research and development;Generative AI;Productivity;Industries;Computer hacking;Tuberculosis},
  doi={10.1002/9781394310562.ch18},
  ISSN={},
  publisher={Wiley},
  isbn={9781394254965},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952330},}@INPROCEEDINGS{11106069,
  author={Agarwal, Darsh and Srinath, Ramamoorthy},
  booktitle={2025 11th International Conference on Computing and Artificial Intelligence (ICCAI)}, 
  title={RJ-AI: A Radio Jockey Agent developed using Markov Models and Personality Fine-tuning}, 
  year={2025},
  volume={},
  number={},
  pages={473-481},
  abstract={This paper investigates the potential of Probabilistic Models combined with Generative Artificial Intelligence (GenAI) in mass media and entertainment, with a specific focus on its application in radio broadcasting. We present a methodology that applies Markov models to develop an Agentic framework capable of generating engaging radio show segments. The proposed system aims to produce engaging audio commentary, recommend and play relevant music, and integrate demographically contextual daily news and weather updates, ensuring both content coherence and the organic structure of the generated programme.},
  keywords={Adaptation models;Generative AI;Large language models;Computational modeling;Hidden Markov models;Entertainment industry;Media;Probabilistic logic;Real-time systems;Recommender systems;Generative AI;Markov Models;Fine-Tuned Large language models;Mass media applications;Artificial Intelligence Agentic framework;Recommendation systems;Intelligent agents;Machine learning},
  doi={10.1109/ICCAI66501.2025.00078},
  ISSN={},
  month={March},}@INPROCEEDINGS{10822015,
  author={Ciobanu, Madalina G. and Tucci, Cesare and Fasano, Fausto},
  booktitle={2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={LLMs for Autism Treatment: Current Trends and Emerging Strategies}, 
  year={2024},
  volume={},
  number={},
  pages={6797-6804},
  abstract={This paper reviews the current role of Large Language Models (LLMs) in the treatment and support of people with autism spectrum disorder (ASD). We explore applications of LLM-based systems designed to improve communication, social skills, and emotional learning for individuals with ASD, highlighting their ability to generate personalized conversational interactions and simulate social scenarios. Current research demonstrates promising results in different domains, such as dialogue interventions, emotional recognition training, and work-related communication assistance. However, significant challenges remain, including ethical concerns about overreliance on AI, personalization, and privacy. This review synthesizes recent findings, highlights gaps in the existing literature, and proposes directions for future investigations. It particularly underscores the need for real-world applications and long-term studies to assess the efficacy of LLM efficacy in interventions for ASD.},
  keywords={Training;Autism;Ethics;Privacy;Emotion recognition;Large language models;Transformers;Market research;Safety;Systematic literature review;Large Language Models (LLMs);Autism Spectrum Disorder (ASD);Generative Pre-trained Transformer (GPT);Rapid Literature Review},
  doi={10.1109/BIBM62325.2024.10822015},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{10491621,
  author={Wang, Jian and Liu, Xuehua and Zheng, Xunhua and Zhou, Zhongmei},
  booktitle={2023 International Conference on Artificial Intelligence and Automation Control (AIAC)}, 
  title={Survey on Deep-learning-based Malware Identification Research}, 
  year={2023},
  volume={},
  number={},
  pages={227-231},
  abstract={The proliferation of malware poses a serious security threat to individual users, enterprises, industrial production, and networks. The complexity of malware is rapidly changing with the development of artificial intelligence technologies, and the struggle between security analysts and malware developers is essentially a game between people. The identification methods based on signature and heuristic rules are not enough to cope with the development of new malware. Compared with traditional detection methods, intelligent detection techniques based on deep learning technologies are better able to detect previously unseen malware because they do not require manual development of detection rules and have stronger generalization capabilities. The application of machine learning and deep learning techniques in malware detection has become a hot topic of current research. This survey aims to provide a basic overview of deep learning-based malware detection techniques for Windows platforms, to help researchers understand the field of malware detection, and to explore new developments and research directions.},
  keywords={Deep learning;Surveys;Reviews;Production;Manuals;Feature extraction;Market research;Vision;Few-shot learning;Meta-learning},
  doi={10.1109/AIAC61660.2023.00068},
  ISSN={},
  month={Nov},}@ARTICLE{8954667,
  author={Tian, Anjie and Lu, Lu},
  journal={IEEE Access}, 
  title={Attentional Generative Adversarial Networks With Representativeness and Diversity for Generating Text to Realistic Image}, 
  year={2020},
  volume={8},
  number={},
  pages={9587-9596},
  abstract={In recent years, with the emergence and rapid development of Generative Adversarial Networks (GANs), the generation of realistic images consistent with their semantics based on text description has become one of the most popular research directions in the field of computer vision. Although the idea of applying attention mechanism has been raised out in many implementation methods, it is required to treat the sub-regions of the generated images equally. For this reason, this paper proposes a novel generative adversarial networks, rdAttnGAN, which generate text to fine images by training multi-pair generators and discriminators. Comparing with the conventional models, it pays more attention to the representativeness and diversity of the generated images. In addition, an optimization method for calculating the similarity between the generated image and the text description is also introduced to enhance the representative judgment of the images. By paying more attention to the generation of important sub-regions of images, the model can further optimize the training of generators. In order to verify the effectiveness of our proposed framework, a comprehensive set of experiments are conducted on CUB dataset and COCO dataset. The results demonstrate viability to improve the representativeness and diversity of images with our rdAttnGAN.},
  keywords={Gallium nitride;Generators;Generative adversarial networks;Training;Image resolution;Diversity reception;Computer vision;GANs;representativeness and diversity;text-to-image generation},
  doi={10.1109/ACCESS.2020.2964946},
  ISSN={2169-3536},
  month={},}@ARTICLE{9580478,
  author={Nguyen, Dinh C. and Ding, Ming and Pathirana, Pubudu N. and Seneviratne, Aruna and Zomaya, Albert Y.},
  journal={IEEE Internet of Things Journal}, 
  title={Federated Learning for COVID-19 Detection With Generative Adversarial Networks in Edge Cloud Computing}, 
  year={2022},
  volume={9},
  number={12},
  pages={10257-10271},
  abstract={COVID-19 has spread rapidly across the globe and become a deadly pandemic. Recently, many artificial intelligence-based approaches have been used for COVID-19 detection, but they often require public data sharing with cloud data centers and thus, remain privacy concerns. This article proposes a new federated learning (FL) scheme, called FedGAN, to generate realistic COVID-19 images for facilitating privacy-enhanced COVID-19 detection with generative adversarial networks (GANs) in edge cloud computing. Particularly, we first propose a GAN where a discriminator and a generator based on convolutional neural networks (CNNs) at each edge-based medical institution alternatively are trained to mimic the real COVID-19 data distribution. Then, we propose a new FL solution, which allows local GANs to collaborate and exchange learned parameters with a cloud server, aiming to enrich the global GAN model for generating realistic COVID-19 images without the need for sharing actual data. To enhance the privacy in federated COVID-19 data analytics, we integrate a differential privacy solution at each hospital institution. Moreover, we propose a new blockchain-based FedGAN framework for secure COVID-19 data analytics by decentralizing the FL process with a new mining solution for low running latency. Simulations results demonstrate the superiority of our approach for COVID-19 detection over the state-of-the-art schemes.},
  keywords={COVID-19;Training;Generative adversarial networks;Data models;Hospitals;Servers;Pandemics;COVID-19;edge cloud;federated learning (FL);generative adversarial network (GAN)},
  doi={10.1109/JIOT.2021.3120998},
  ISSN={2327-4662},
  month={June},}@INPROCEEDINGS{8900698,
  author={Jaskie, Kristen and Spanias, Andreas},
  booktitle={2019 10th International Conference on Information, Intelligence, Systems and Applications (IISA)}, 
  title={Positive And Unlabeled Learning Algorithms And Applications: A Survey}, 
  year={2019},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper will address the Positive and Unlabeled learning problem (PU learning) and its importance in the growing field of semi-supervised learning. In most real-world classification applications, well labeled data is expensive or impossible to obtain. We can often label a small subset of data as belonging to the class of interest. It is frequently impractical to manually label all data we are not interested in. We are left with a small set of positive labeled items of interest and a large set of unknown and unlabeled data. Learning a model for this is the PU learning problem.In this paper, we explore several applications for PU learning including examples in biological/medical, business, security, and signal processing. We then survey the literature for new and existing solutions to the PU learning problem.},
  keywords={Surveys;Machine learning algorithms;Signal processing algorithms;Learning (artificial intelligence);Machine learning;Signal processing;Semisupervised learning;Classification algorithms;Security;Business;PU learning;positive unlabeled learning;machine learning;artificial intelligence;classification},
  doi={10.1109/IISA.2019.8900698},
  ISSN={},
  month={July},}@INPROCEEDINGS{9643440,
  author={Manu, Daniel and Sheng, Yi and Yang, Junhuan and Deng, Jieren and Geng, Tong and Li, Ang and Ding, Caiwen and Jiang, Weiwen and Yang, Lei},
  booktitle={2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD)}, 
  title={FL-DISCO: Federated Generative Adversarial Network for Graph-based Molecule Drug Discovery: Special Session Paper}, 
  year={2021},
  volume={},
  number={},
  pages={1-7},
  abstract={The outbreak of the global COVID-19 pandemic emphasizes the importance of collaborative drug discovery for high effectiveness; however, due to the stringent data regulation, data privacy becomes an imminent issue needing to be addressed to enable collaborative drug discovery. In addition to the data privacy issue, the efficiency of drug discovery is another key objective since infectious diseases spread exponentially and effectively conducting drug discovery could save lives. Advanced Artificial Intelligence (AI) techniques are promising to solve these problems: (1) Federated Learning (FL) is born to keep data privacy while learning data from distributed clients; (2) graph neural network (GNN) can extract structural properties of molecules whose underlying architecture is the connected atoms; and (3) generative adversarial network (GAN) can generate novel molecules while retaining the properties learned from the training data. In this work, we make the first attempt to build a holistic collaborative and privacy-preserving FL framework, namely FL-DISCO, which integrates GAN and GNN to generate molecular graphs. Experimental results demonstrate the effectiveness of FL-DISCO on: (1) IID data for ESOL and QM9, where FL-DISCO can generate highly novel compounds with high drug-likeliness, uniqueness and LogP scores compared to the baseline; (2) non-IID data for ESOL and QM9, where FL-DISCO generates 100% novel compounds with high validity and LogP scores compared to the baseline. We also demonstrate how different fractions of clients, generator and discriminator architectures affect our evaluation scores.},
  keywords={Drugs;Measurement;Data privacy;Collaboration;Computer architecture;Generative adversarial networks;Collaborative work;Federated learning;Generative adversarial network;Graph neural network;Drug discovery},
  doi={10.1109/ICCAD51958.2021.9643440},
  ISSN={1558-2434},
  month={Nov},}@ARTICLE{11146482,
  author={Swindell, Jonathan Edwin and Egbert, Austin and Goad, Adam C. and Baylis, Charles and Marks, Robert J.},
  journal={IEEE Transactions on Microwave Theory and Techniques}, 
  title={Multidimensional Load-Pull Extrapolation of Unknown Devices Using Generative Adversarial Networks}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={Nonlinear amplifier designers benefit from fast, accurate performance assessment and optimization techniques for computer-aided design. We demonstrate the synthesis of missing measurement dataset portions, even when extrapolating data beyond the boundary of the partial dataset’s domain. A novel method is presented to optimize device load impedance in conjunction with a third parameter. We demonstrate that this method can optimize settings for generic devices where an a priori estimate of the data range is unknown. A modified neural network architecture is used for improved data quality, and Bayesian optimization is applied to infer proper neural network normalization parameters for an unknown device. After applying the learned normalization parameters, the extrapolated dataset realizes a predicted optimal reflection coefficient per input power within a vector distance of about 0.1 on the Smith chart, with a mean output power error of less than 0.5 dB. This was accomplished using only 32 measurements—about 0.1% of the full set of 24192 measurements. If an a priori estimate of the normalization parameters is available, similar performance can be achieved in as few as 16 measurements. This is expected to be a useful tool for reducing design time and improving optimization accuracy in the computer-aided design of transistor amplifiers.},
  keywords={Extrapolation;Load modeling;Optimization;Generative adversarial networks;Generators;Power amplifiers;Neural networks;Accuracy;Training data;Three-dimensional displays;Artificial intelligence (AI);circuit optimization;design automation;generative adversarial networks (GANs);interpolation techniques;machine learning (ML);measurement techniques;power amplifier (PA)},
  doi={10.1109/TMTT.2025.3600312},
  ISSN={1557-9670},
  month={},}@ARTICLE{10942364,
  author={Lee, Han-Ju and Kim, Jin-Seoung and Lee, Han-Jin and Choi, Seok-Hwan},
  journal={IEEE Access}, 
  title={POSES: Patch Optimization Strategies for Efficiency and Stealthiness Using eXplainable AI}, 
  year={2025},
  volume={13},
  number={},
  pages={57166-57176},
  abstract={Adversarial examples, which are carefully crafted inputs designed to deceive deep learning models, create significant challenges in Artificial Intelligence. While adversarial examples have primarily focused on digital-world attacks, recent research has proposed adversarial patches as the focus expands to physical-world attacks. Unlike traditional adversarial examples that use small perturbations, adversarial patches employ large perturbations to bypass existing defense mechanisms against adversarial attacks. Adversarial patches have been shown to be highly effective in causing deep learning models to misclassify. However, existing adversarial patches are often limited by their noticeable appearance and the high computational cost of generating them. To solve these problems, we propose a new adversarial patch generation method called Patch Optimization Strategies for Efficiency and Stealthiness (POSES). POSES uses a two-step optimization architecture that employs an eXplainable AI-based method to optimize the location and size of adversarial patches. Experimental results on benchmark datasets demonstrate that POSES enhances the stealthiness of adversarial patches while maintaining a high attack success rate. We also show that POSES improves attack efficiency by reducing the number of iterations required.},
  keywords={Perturbation methods;Computational modeling;Deep learning;Explainable AI;Data models;Optimization methods;Linear programming;Generative adversarial networks;Computer vision;Benchmark testing;Adversarial example;adversarial patch;eXplainable AI (XAI)},
  doi={10.1109/ACCESS.2025.3555044},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11142033,
  author={Wei, Shuna and Xia, Zhenjie},
  booktitle={2025 5th Asia-Pacific Conference on Communications Technology and Computer Science (ACCTCS)}, 
  title={Automatic Generation and Optimization of Visual Design Elements Based on Generative Adversarial Networks}, 
  year={2025},
  volume={},
  number={},
  pages={472-478},
  abstract={With the rapid development of artificial intelligence technology, generative adversarial networks (GANs) have shown remarkable potential in the field of image generation and optimization. However, existing methods often limit themselves to single scenarios or lack a comprehensive consideration of diversity and aesthetic optimization when dealing with visual design elements. To address this issue, this paper proposes an innovative algorithm framework based on GANs (AGOD-GAN) for the automatic generation and optimization of visual design elements. The framework introduces a multimodal feature extraction module, achieving multidimensional feature modeling and prominence enhancement of visual design elements by combining self-attention mechanisms and style transfer techniques. In the generation phase, an improved generator structure is adopted, introducing a hierarchical feature fusion strategy to enhance the quality and diversity of generated elements. Additionally, by introducing an adaptive discriminator, the weights of the discriminative network are dynamically adjusted, significantly enhancing the model's adaptability in complex visual tasks. Furthermore, to address aesthetic bias in the generated results, this paper designs an iterative optimization mechanism based on user feedback, which can further optimize the artistic and functional aspects of the generated elements while maintaining style consistency. Experimental results show that the proposed method exhibits excellent performance in visual design tasks, achieving significant improvements in both generation quality and diversity compared to existing mainstream methods, and also demonstrating strong practicality in aesthetic optimization. This study provides a new technical approach for the automation of visual design, with broad application potential.},
  keywords={Measurement;Visualization;Solid modeling;Adaptation models;Heuristic algorithms;Diversity reception;Virtual reality;Generative adversarial networks;Feature extraction;Optimization;Generative Adversarial Networks;Multi-dimensional Feature Modeling;Attention Mechanism},
  doi={10.1109/ACCTCS66275.2025.00088},
  ISSN={},
  month={April},}@ARTICLE{10349216,
  author={Chen, Jinshu and Xu, Qihui and Kang, Qi and Zhou, MengChu},
  journal={IEEE Transactions on Systems, Man, and Cybernetics: Systems}, 
  title={MOGAN: Morphologic-Structure-Aware Generative Learning From a Single Image}, 
  year={2024},
  volume={54},
  number={4},
  pages={2021-2033},
  abstract={In most interactive image generation tasks, given regions of interest (ROI) by users, the generated results are expected to have adequate diversities in appearance while maintaining correct and reasonable structures in original images. Such tasks become more challenging if only limited data is available. Recently proposed generative models complete training based on only one image. They pay much attention to the monolithic feature of the sample while ignoring the actual semantic information of different objects inside the sample. As a result, for ROI-based generation tasks, they may produce inappropriate samples with excessive randomicity and without maintaining the related objects’ correct structures. To address this issue, this work introduces a morphologic-structure-aware generative adversarial network named MOGAN that produces random samples with diverse appearances and reliable structures based on only one image. For training for ROI, we propose to utilize the data coming from the original image being augmented and bring in a novel module to transform such augmented data into knowledge containing both structures and appearances, thus enhancing the model’s comprehension of the sample. To learn the rest areas other than ROI, we employ binary masks to ensure the generation isolated from ROI. Finally, we set parallel and hierarchical branches of the mentioned learning process. Compared with other single image generative adversarial network schemes, our approach focuses on internal features, including the maintenance of rational structures and variation on appearance. Experiments confirm a better capacity of our model on ROI-based image generation tasks than its competitive peers.},
  keywords={Task analysis;Image synthesis;Training;Periodic structures;Feature extraction;Semantics;Generative adversarial networks;Generative adversarial networks (GANs);machine learning;morphologic awareness;regions of interest (ROI)-based image generation tasks;single sample},
  doi={10.1109/TSMC.2023.3331227},
  ISSN={2168-2232},
  month={April},}@INPROCEEDINGS{10123795,
  author={Fiscal, Luca La and Jennebauffe, Celiane and Bruyneel, Marie and Ris, Laurence and Lefebvre, Laurent and Siebert, Xavier and Gosselin, Bernard},
  booktitle={2023 11th International IEEE/EMBS Conference on Neural Engineering (NER)}, 
  title={Explainable AI for EEG Biomarkers Identification in Obstructive Sleep Apnea Severity Scoring Task}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The assessment of Obstructive Sleep Apneas and hypopneas (OSAs) severity has known an increasing interest over the last decade with the use of Apnea-Hypopnea Index (AHI) being highly criticized by the majority of sleep scientists. To go beyond the single AHI, alternative metrics such as hypoxic burden, arousal intensity, odds ratio product, and cardiopulmonary coupling have been investigated in the literature. However, no consensus has currently been found for a common efficient metric. In this paper, we propose a novel architecture of deep learning model aiming at discovering an objective metric for OSAs severity assessment. We demonstrate the efficiency of this method by identifying features of interest in the Electroencephalographic (EEG) signals while training the model based on biomarkers not or indirectly derived from the EEG, i.e. the desaturation area, the arousal events and the respiratory event duration. By inspecting what the model looks for to make the different classifications, we identified that EEG signals from posterior and medial regions in low frequency bands (0–8 Hz) are highly affected by the apnea-hypopnea severity. With this proof of concept, we pave the way towards the use of Explainable Artificial Intelligence (xAI) to make OSAs severity assessment more objective and find a consensus metric adopted across the community of sleep scientists as well as to boost EEG biomarkers discovery in multiple tasks.},
  keywords={Measurement;Training;Biological system modeling;Neural engineering;Biomarkers;Brain modeling;Electroencephalography;EEG;obstructive sleep apnea;explainable AI;semi-supervised learning;proof-of-concept},
  doi={10.1109/NER52421.2023.10123795},
  ISSN={1948-3554},
  month={April},}@ARTICLE{9093842,
  author={Waheed, Abdul and Goyal, Muskan and Gupta, Deepak and Khanna, Ashish and Al-Turjman, Fadi and Pinheiro, Plácido Rogerio},
  journal={IEEE Access}, 
  title={CovidGAN: Data Augmentation Using Auxiliary Classifier GAN for Improved Covid-19 Detection}, 
  year={2020},
  volume={8},
  number={},
  pages={91916-91923},
  abstract={Coronavirus (COVID-19) is a viral disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The spread of COVID-19 seems to have a detrimental effect on the global economy and health. A positive chest X-ray of infected patients is a crucial step in the battle against COVID-19. Early results suggest that abnormalities exist in chest X-rays of patients suggestive of COVID-19. This has led to the introduction of a variety of deep learning systems and studies have shown that the accuracy of COVID-19 patient detection through the use of chest X-rays is strongly optimistic. Deep learning networks like convolutional neural networks (CNNs) need a substantial amount of training data. Because the outbreak is recent, it is difficult to gather a significant number of radiographic images in such a short time. Therefore, in this research, we present a method to generate synthetic chest X-ray (CXR) images by developing an Auxiliary Classifier Generative Adversarial Network (ACGAN) based model called CovidGAN. In addition, we demonstrate that the synthetic images produced from CovidGAN can be utilized to enhance the performance of CNN for COVID-19 detection. Classification using CNN alone yielded 85% accuracy. By adding synthetic images produced by CovidGAN,the accuracy increased to 95%. We hope this method will speed up COVID-19 detection and lead to more robust systems of radiology.},
  keywords={Generative adversarial networks;Training;Biomedical imaging;X-ray imaging;Computer architecture;Machine learning;COVID-19;Deep learning;convolutional neural networks;generative adversarial networks;synthetic data augmentation;COVID-19 detection},
  doi={10.1109/ACCESS.2020.2994762},
  ISSN={2169-3536},
  month={},}@ARTICLE{10628023,
  author={Lai, Bingkun and Wen, Jinbo and Kang, Jiawen and Du, Hongyang and Nie, Jiangtian and Yi, Changyan and Kim, Dong In and Xie, Shengli},
  journal={IEEE Wireless Communications}, 
  title={Resource-Efficient Generative Mobile Edge Networks in 6G Era: Fundamentals, Framework and Case Study}, 
  year={2024},
  volume={31},
  number={4},
  pages={66-74},
  abstract={As the next-generation wireless communication system, sixth-generation (6G) technologies are emerging, enabling various mobile edge networks that can revolutionize wireless communication and connectivity. By integrating generative artificial intelligence (GAI) with mobile edge networks, generative mobile edge networks possess immense potential to enhance the intelligence and efficiency of wireless communication networks. In this article, we propose the concept of generative mobile edge networks and overview widely adopted GAI technologies and their applications in mobile edge networks. We then discuss the potential challenges faced by generative mobile edge networks in resource-constrained scenarios. To address these challenges, we develop a universal resource-efficient generative incentive mechanism framework, in which we design resource-efficient methods for network overhead reduction, formulate appropriate incentive mechanisms for the resource allocation problem, and utilize generative diffusion models (GDMs) to find the optimal incentive mechanism solutions. Furthermore, we conduct a case study on resource-constrained mobile edge networks, employing model partitioning for efficient AI task offloading, and proposing a GDM-based Stackelberg model to motivate edge devices to contribute computing resources for mobile edge intelligence. Finally, we propose several open directions that could contribute to the future popularity of generative mobile edge networks.},
  keywords={Wireless communication;6G mobile communication;Training;Generative AI;Computational modeling;Design methodology;Diffusion models},
  doi={10.1109/MWC.007.2300582},
  ISSN={1558-0687},
  month={August},}@ARTICLE{10976669,
  author={Bai, Xiaofeng and Haq, Qazi Mazhar Ul and Khan, Aftab Alam and Li, Chaohui and Alsharif, Hind and Anwar, Muhammad Shahid and Li, Chengwei},
  journal={IEEE Access}, 
  title={Ball Bearing Fault Diagnosis Based on Hybrid Adversarial Learning}, 
  year={2025},
  volume={13},
  number={},
  pages={74163-74174},
  abstract={Ball bearings are prone to faults in their inner and outer rings and rolling elements. Timely detection of these faults is crucial, especially when adversarial perturbations are present, as deep learning-based fault diagnosis models may misclassify these faults. To address this issue, this study proposes a hybrid adversarial learning method that combines convolutional neural networks with a generative adversarial network framework. In this method, the generator introduces perturbations and adaptively adjusts them based on their magnitude and gradient information. The discriminator was used to verify the effectiveness of adversarial perturbations. The goal of this hybrid adversarial learning method is to improve the fault recognition accuracy of a model when subjected to perturbation attacks. The experimental results show that under adversarial perturbation attacks, the proposed method outperforms other deep learning models and defence methods, demonstrating the effectiveness of this approach.},
  keywords={Fault diagnosis;Perturbation methods;Convolutional neural networks;Continuous wavelet transforms;Accuracy;Generative adversarial networks;Feature extraction;Time-frequency analysis;Adversarial machine learning;Vibrations;Ball bearings;convolutional neural networks;continuous wavelet transforms;deep learning;data visualization;fault diagnosis;generative adversarial networks;machine learning;robustness;signal processing algorithms},
  doi={10.1109/ACCESS.2025.3564484},
  ISSN={2169-3536},
  month={},}@ARTICLE{11031451,
  author={Wang, Xijun and López-Tapia, Santiago and Wu, Xinyi and Molina, Rafael and Katsaggelos, Aggelos K.},
  journal={IEEE Access}, 
  title={Spatially-Aware Loss Functions for GAN-Driven Super-Resolution}, 
  year={2025},
  volume={13},
  number={},
  pages={108561-108572},
  abstract={Generative Adversarial Networks (GANs) have shown great performance on super-resolution problems since they can generate more visually realistic images and video frames. However, these models often introduce side effects into the outputs, such as unexpected artifacts and noises. To reduce these artifacts and enhance the perceptual quality of the results, in this paper, we propose a general method that can be effectively used in most GAN-based super-resolution (SR) models by introducing essential spatial information into the training process. We extract spatial information from the input data and incorporate it into the training loss, making the corresponding loss a spatially adaptive (SA) one. After that, we utilize it to guide the training process. We will show that the proposed approach is independent of the methods used to extract the spatial information and independent of the SR tasks and models. This method consistently guides the training process towards generating visually pleasing SR images and video frames, substantially mitigating artifacts and noise, ultimately leading to enhanced perceptual quality.},
  keywords={Training;Image edge detection;Superresolution;Generative adversarial networks;Data mining;Adaptation models;Visualization;Spatial resolution;Network architecture;Accuracy;Super-resolution;spatially adaptive loss;generative adversarial networks},
  doi={10.1109/ACCESS.2025.3579004},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11016557,
  author={Offor, Kennedy John},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Leveraging Generative AI to Simulate Stakeholder Involvement in the Engineering Design Process: A Case Study of MSc Team-Based Projects}, 
  year={2025},
  volume={},
  number={},
  pages={1-3},
  abstract={In engineering education, stakeholder engagement plays a critical role in developing solutions that meet both technical and user-centred requirements. During the 2023/24 academic year, GenAl, specifically ChatGPT, was integrated into an MSc team-based project module to simulate stakeholder involvement. This approach allowed students to explore stakeholder dynamics by using AI to identify relevant stakeholders, generate questions for consultation, and simulate interactions. These AI-driven simulations enhanced students' understanding of stakeholder needs and decision-making processes. However, students' engagement was initially hampered by a lack of prompt engineering skills, which limited their ability to effectively communicate with the AI and extract meaningful responses. This underscores the importance of incorporating GenAl prompt engineering in training engineers of the future. To address this challenge, students were given predefined prompts to guide their GenAl interactions, helping them refine questions for better stakeholder insights. Despite these initial challenges, the use of GenAl helped students appreciate the complexities of real-world engineering problems and fostered a deeper understanding of how to balance diverse stakeholder needs. Preliminary results suggest the need for prompt engineering training and that incorporating GenAl into engineering education can significantly enhance students' ability to critically evaluate and integrate feedback into their designs. Future research will explore incorporating human stakeholder engagement methods, alongside prompt engineering training, to further enhance learning outcomes and compare the impact of AI versus human involvement. This work contributes to ongoing discussions on the role of GenAl in education.},
  keywords={Training;Decision making;Chatbots;Complexity theory;Stakeholders;Prompt engineering;Engineering education;Generative AI;GenAI;engineering design process;stakeholder engagement;engineering education (key words)},
  doi={10.1109/EDUCON62633.2025.11016557},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10430931,
  author={Srinivasan, Srihari},
  booktitle={2023 4th International Conference on Communication, Computing and Industry 6.0 (C216)}, 
  title={Understanding User Perception of Biometric Privacy in the Era of Generative AI}, 
  year={2023},
  volume={},
  number={},
  pages={01-06},
  abstract={In the dynamic world of technology, the fusion of biometrics and artificial intelligence has ushered in an unprecedented era marked by convenience, security, and cutting-edge innovation. Biometrics, the science of using unique physical or behavioral attributes for identification and authentication, has seamlessly merged into daily routines. From unlocking smartphones with a fingerprint to clearing airport security with facial recognition, biometrics has transformed the way people interact with technology and the world. Simultaneously, Generative AI, powered by machine learning models, has unlocked new frontiers in generating remarkably realistic synthetic data, including human faces, voices, and fingerprints. This convergence of biometrics and Generative AI lies at the heart of a complex and rapidly evolving landscape, giving rise to profound questions concerning individual privacy and security. This study examines the correlation between demographic factors like age, gender, educational background, technological competence, and the regularity of employing biometric authentication, and their awareness about biometric technologies. Additionally, this research explores concerns regarding the potential misuse of biometric data and the notion that organizations should seek explicit consent before collecting such data. Lastly, it assesses the awareness of potential privacy risks and the belief that individuals should receive education regarding the utilization of their biometric data in AI systems. Descriptive research design has been used in this study. The first section of the questionnaire using Microsoft Forms covers the demographic factors, technological proficiency and frequency of using biometric authentication (e.g., fingerprint, facial recognition). The next section focuses on awareness and usage of biometric technologies, biometric privacy, trust, education, awareness of biometrics, generative AI and deepfakes using the Likert Scale. 53 samples were obtained through Simple Random Sampling from UAE residents. Then, testing of hypothesis using correlation analysis was done using SPSS. The results reveal that demographic variables do not exhibit a statistically significant relationship with privacy concerns. However, there is a statistically significant correlation exists between biometric authentication and awareness & knowledge parameters.},
  keywords={Privacy;Correlation;Biometrics (access control);Generative AI;Authentication;Fingerprint recognition;Security;Biometrics;artificial intelligence;generative AI;deepfakes;privacy concerns},
  doi={10.1109/C2I659362.2023.10430931},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10739224,
  author={Pramod, Dhanya and Patil, Kanchan Pranay and Kumar, Deepak and Singh, Dev Ratna and Singh Dodiya, Chandragupt and Noble, Daral},
  booktitle={2024 International Conference on Electrical Electronics and Computing Technologies (ICEECT)}, 
  title={Generative AI and deep fakes in Media Industry - An Innovation Resistance Theory Perspective}, 
  year={2024},
  volume={1},
  number={},
  pages={1-5},
  abstract={This empirical study intends to study users resistance towards emerging technologies like generative artificial intelligence (AI) and deep fakes affecting the media industry. The research's basic framework, the Innovation Resistance Theory, aids in making sense of the challenges and obstacles associated with adopting new technology. This theory can be used in research on generative AI and deepfakes to empirically analyze resistance variables and provide mitigation strategies for unfavorable impacts. A structured questionnaire was administered to gather information from media industry users (N= 283). Data analysis was performed using Smart-PLS 4.0 software, and the technique used was partial least square-structural equation modeling. Findings indicate that consumers’ functional barrier like value barrier and risk barrier, along with psychological barriers like traditional barriers, and image barrier were significantly impacting generative AI and deepfakes usage intentions. However, usage barrier did not have significant influence on deepfake usage. sThis paper adds to the ongoing discourse on responsible innovation in media. As deepfake technology becomes more widespread, it's relevant for policymakers, media professionals, and the public to know about associated risks.},
  keywords={Resistance;Industries;Deepfakes;Technological innovation;Ethics;Electric potential;Generative AI;Psychology;Media;Mathematical models;Deepfakes;Generative Artificial Intelligence;Innovation resistance theory;Media industry},
  doi={10.1109/ICEECT61758.2024.10739224},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{11135608,
  author={Sabu, Faith and Abraham, Emil and Mathew, Ebin and Daniel, Jeena Rachel and Mathew, Jabin},
  booktitle={2025 4th International Conference on Advances in Computing, Communication, Embedded and Secure Systems (ACCESS)}, 
  title={Image Inspired Clothing Design System using Generative AI}, 
  year={2025},
  volume={},
  number={},
  pages={510-515},
  abstract={The project "Image Inspired Clothing Design using Generative AI" aims to revolutionize fashion design by leveraging generative artificial intelligence to create unique dress designs inspired by user-provided images. This system extracts color palettes from the input image and generates innovative dress designs that reflect these colors. The proposed approach employs a hybrid model architecture, combining a pretrained dress generation model with a custom model specifically trained on a tailored dataset for recoloring tasks. This combination enables the generation of aesthetically appealing and contextually accurate designs, surpassing the capabilities of general pretrained models such as Stable Diffusion. Our system focuses on optimizing generative outputs for the specific task of image-inspired clothing design, ensuring enhanced color coherence, style diversity, and design relevance. By incorporating domain-specific training and recoloring capabilities, the model achieves superior performance in producing high-quality designs tailored to individual preferences. This project represents a significant advancement in AI-driven creativity, providing a robust tool for fashion designers and enthusiasts to explore and innovate effortlessly.},
  keywords={Training;Adaptation models;Visualization;Accuracy;Image color analysis;Generative AI;Image synthesis;Clothing;Transforms;Hybrid power systems;Artificial Intelligence;Generative Adversarial Networks;Image Generation;PaletteNet;Stable Diffusion},
  doi={10.1109/ACCESS65134.2025.11135608},
  ISSN={},
  month={June},}@ARTICLE{8970569,
  author={Liu, Hao and Sun, Penghui and Zhang, Jiaqiang and Wu, Suping and Yu, Zhenhua and Sun, Xuehong},
  journal={IEEE Transactions on Multimedia}, 
  title={Similarity-Aware and Variational Deep Adversarial Learning for Robust Facial Age Estimation}, 
  year={2020},
  volume={22},
  number={7},
  pages={1808-1822},
  abstract={In this paper, we propose a similarity-aware deep adversarial learning (SADAL) approach for facial age estimation. Instead of making full access to the limited training samples which likely leads to bias age prediction, our SADAL aims to seek batches of unobserved hard-negative samples based on existing training samples, which typically reinforces the discriminativeness of the learned feature representation for facial ages. Motivated by the fact that age labels are usually correlated in real-world scenarios, we carefully develop a similarity-aware function to well measure the distance of each face pair based on the age value gaps. Consequently, the age-difference information is exploited in the synthetic feature space for robust age estimation. During the learning process, we jointly optimize both procedures of generating hard negatives and learning discriminative age ranker via a sequence of adversarial-game iterations. Another major issue lies on that existing methods only enforce the indiscriminativeness within each class, which is probably trapped into model overfitting and thus the generation capacity is limited particularly on unseen age classes with many individuals. To circumvent this problem, we propose a variational deep adversarial learning (VDAL) paradigm, which learns to encode each face sample in two factorized parts, i.e., the intra-class variance distribution and the intra-class invariant class center. Moreover, our VDAL principally optimizes the variational confidence lower bound on the variational factorized feature representation. To better enhance the discriminativeness of the age representation, our VDAL further learns to encode the ordinal relationship among age labels in the reconstructed subspace. Experimental results on folds of widely-evaluated benchmarking datasets demonstrate that our approach achieves promising performance in contrast to most state-of-the-art age estimation methods.},
  keywords={Estimation;Training;Face;Aging;Measurement;Generators;Convergence;Facial age estimation;deep learning;generative adversarial network;variational auto-encoder;biometrics},
  doi={10.1109/TMM.2020.2969793},
  ISSN={1941-0077},
  month={July},}@INPROCEEDINGS{9719242,
  author={Zhang, Haichun and Huang, Kelin and Wang, Jie and Liu, Zhenglin},
  booktitle={2021 International Conference on Computer Information Science and Artificial Intelligence (CISAI)}, 
  title={CAN-FT: A Fuzz Testing Method for Automotive Controller Area Network Bus}, 
  year={2021},
  volume={},
  number={},
  pages={225-231},
  abstract={The Controller Area Network (CAN) bus is the de-facto standard for connecting the Electronic Control Units (ECUs) in automobiles. However, there are serious cyber-security risks due to the lack of security mechanisms. In order to mine the vulnerabilities in CAN bus, this paper proposes CAN-FT, a fuzz testing method for automotive CAN bus, which uses a Generative Adversarial Network (GAN) based fuzzy message generation algorithm and the Adaptive Boosting (AdaBoost) based anomaly detection mechanism to capture the abnormal states of CAN bus. Experimental results on a real-world vehicle show that CAN-FT can find vulnerabilities more efficiently and comprehensively.},
  keywords={Information science;Fuzzing;Generative adversarial networks;Boosting;Explosions;Security;Automobiles;CAN bus;fuzz testing;Generative Adversarial Networks;AdaBoost},
  doi={10.1109/CISAI54367.2021.00050},
  ISSN={},
  month={Sep.},}@ARTICLE{10167789,
  author={Lyu, Yueming and Chen, Peibin and Sun, Jingna and Peng, Bo and Wang, Xu and Dong, Jing},
  journal={IEEE Transactions on Multimedia}, 
  title={DRAN: Detailed Region-Adaptive Normalization for Conditional Image Synthesis}, 
  year={2024},
  volume={26},
  number={},
  pages={1969-1982},
  abstract={In recent years, conditional image synthesis has attracted growing attention due to its controllability in the image generation process. Although recent works have achieved realistic results, most of them have difficulty handling fine-grained styles with subtle details. To address this problem, a novel normalization module, named Detailed Region-Adaptive Normalization (DRAN), is proposed. It adaptively learns both fine-grained and coarse-grained style representations. Specifically, we first introduce a multi-level structure, Spatiality-aware Pyramid Pooling, to guide the model to learn coarse-to-fine features. Then, to adaptively fuse different levels of styles, we propose Dynamic Gating, making it possible to adaptively fuse different levels of styles according to different spatial regions. Finally, we collect a new makeup dataset (Makeup-Complex dataset) that contains a wide range of complex makeup styles with diverse poses and expressions. To evaluate the effectiveness and show the general use of our method, we conduct a set of experiments on makeup transfer and semantic image synthesis. Quantitative and qualitative experiments show that equipped with DRAN, simple baseline models are able to achieve promising improvements in complex style transfer and detailed texture synthesis.},
  keywords={Semantics;Image synthesis;Modulation;Fuses;Feature extraction;Task analysis;Hair;Conditional image synthesis;makeup transfer;semantic image synthesis;generative adversarial network},
  doi={10.1109/TMM.2023.3290481},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{10205591,
  author={Villarini, Barbara and Radoglou-Grammatikis, Panagiotis and Lagkas, Thomas and Sarigiannidis, Panagiotis and Argyriou, Vasileios},
  booktitle={2023 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT)}, 
  title={Detection of Physical Adversarial Attacks on Traffic Signs for Autonomous Vehicles}, 
  year={2023},
  volume={},
  number={},
  pages={31-37},
  abstract={Current vision-based detection models within Autonomous Vehicles, can be susceptible to changes within the physical environment, which cause unexpected issues. Physical attacks on traffic signs could be malicious or naturally occurring, causing incorrect identification of the traffic sign which can drastically alter the behaviour of the autonomous vehicle. We propose two novel deep learning architectures which can be used as detection and mitigation strategy for environmental attacks. The first is an autoencoder which detects anomalies within a given traffic sign, and the second is a reconstruction model which generates a clean traffic sign without any anomalies. As the anomaly detection model has been trained on normal images, any abnormalities will provide a high reconstruction error value, indicating an abnormal traffic sign. The reconstruction model is a Generative Adversarial Network (GAN) and consists of two networks; a generator and a discriminator. These map the input traffic sign image into a meta representation as the output. By using anomaly detection and reconstruction models as mitigation strategies, we show that the performance of the other models in pipelines such as traffic sign recognition models can be significantly improved. In order to evaluate our models, several types of attack circumstances were designed and on average, the anomaly detection model achieved 0.84 accuracy with a 0.82 F1-score in real datasets whereas the reconstruction model improved performance of traffic sign recognition model from average F1-score 0.41 to 0.641.},
  keywords={Performance evaluation;Training;Pipelines;Prototypes;Generative adversarial networks;Internet of Things;Image reconstruction;scene analysis;anomaly detection;Generative Adversarial Network;attack restoration;autonomous vehicles},
  doi={10.1109/IAICT59002.2023.10205591},
  ISSN={2834-8249},
  month={July},}@ARTICLE{10960539,
  author={Fu, Xueqian and Chang, Fuhao and Sun, Hongbin and Zhang, Pei and Zhang, Youmin},
  journal={IEEE Transactions on Power Systems}, 
  title={Knowledge-Integrated GAN Model for Stochastic Time-Series Simulation of Year-Round Weather for Photovoltaic Integration Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={1-13},
  abstract={The temporal stochastic simulation of weather has become crucial for stochastic production simulation in power systems with a high proportion of photovoltaic (PV) generation. Generative artificial intelligence (AI) has become the central technology for the stochastic simulation of weather sequences. This research presents a novel approach for the stochastic simulation of annual weather scenarios driven by data and knowledge fusion, in light of the uncontrollability in content production by generative AI technologies. The fusion work encompasses the establishment of the monthly weather generative adversarial network (MWGAN), a generative scenario quality enhancement approach based on statistical probability knowledge, and a suite of statistical machine learning methods for evaluating generated weather scenarios. Weather data from a location in Guangdong, China, over 48 years, was utilized to validate the proposed method for stochastic simulation of annual weather scenarios. By comparing the proposed model to five cutting-edge generative adversarial networks (GAN) and two shallow statistical machine learning models, the superior performance of the proposed model in simulating the temporality and probability of weather is confirmed. The Wasserstein distance is reduced by an average of 46% when compared to the best GAN used for comparison (the smaller the distance, the more accurate the simulation of uncertainty). The effectiveness of the proposed weather sequence stochastic simulation method for probabilistic load flow calculation is verified using an actual distribution network in Guangdong, China.},
  keywords={Meteorology;Generative adversarial networks;Data models;Solar radiation;Computational modeling;Uncertainty;Probabilistic logic;Predictive models;Machine learning;Generators;Data and Knowledge Fusion;Renewable Energy;Deep Learning;Scenario Generation;Stochastic Weather Generator},
  doi={10.1109/TPWRS.2025.3559455},
  ISSN={1558-0679},
  month={},}@INPROCEEDINGS{10483968,
  author={Wang, Xudong and Niu, Li and Cao, Junyan and Hong, Yan and Zhang, Liqing},
  booktitle={2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, 
  title={Painterly Image Harmonization via Adversarial Residual Learning}, 
  year={2024},
  volume={},
  number={},
  pages={5129-5138},
  abstract={Image compositing plays a vital role in photo editing. After inserting a foreground object into another background image, the composite image may look unnatural and inharmonious. When the foreground is photorealistic and the background is an artistic painting, painterly image harmonization aims to transfer the style of background painting to the foreground object, which is a challenging task due to the large domain gap between foreground and background. In this work, we employ adversarial learning to bridge the domain gap between foreground feature map and background feature map. Specifically, we design a dual-encoder generator, in which the residual encoder produces the residual features added to the foreground feature map from main encoder. Then, a pixel-wise discriminator plays against the generator, encouraging the refined foreground feature map to be indistinguishable from background feature map. Extensive experiments demonstrate that our method could achieve more harmonious and visually appealing results than previous methods.},
  keywords={Bridges;Computer vision;Generators;Adversarial machine learning;Task analysis;Painting;Algorithms;Generative models for image;video;3D;etc},
  doi={10.1109/WACV57701.2024.00506},
  ISSN={2642-9381},
  month={Jan},}@INPROCEEDINGS{10176715,
  author={Wang, Yuxin and Xie, Yuanyuan and Ji, Xiangmin and Liu, Ziao and Liu, Xiaolong},
  booktitle={2023 4th International Conference on Electronic Communication and Artificial Intelligence (ICECAI)}, 
  title={RacPixGAN: An Enhanced Sketch-to-Face Synthesis GAN Based on Residual modules, Multi-Head Self-Attention Mechanisms, and CLIP Loss}, 
  year={2023},
  volume={},
  number={},
  pages={336-342},
  abstract={In this paper, we present an enhanced model to overcome the drawbacks of the traditional Pix2pix GAN (Image-to-Image Translation with Conditional Adversarial Networks) in generating performance for sketch-to-face synthesis. This model integrates residual modules and multi-head self-attention mechanisms. Additionally, to enhance the model’s generative capabilities in sketch-to-face synthesis tasks, we introduce a brand-new loss function called CLIP (Contrastive Language-Image Pretraining) Loss. We begin by providing a comprehensive overview of the key theories and techniques for our model. Then, we empirically test the upgraded model and contrast it with the traditional Pix2pix GAN. The experimental outcomes demonstrate that the new model significantly outperforms the traditional Pix2pix GAN in terms of generating performance for sketch-to-face synthesis tasks, supporting the idea that adding residual modules and multi-head self-attention mechanisms can significantly improve the generator’s performance in such tasks. The addition of CLIP Loss has also been shown to improve the quality of image generation.},
  keywords={Training;Image synthesis;Generative adversarial networks;Feature extraction;Data augmentation;Data models;Data mining;Generative Adversarial Networks (GANs);CLIP Loss;Residual Modules;Multi-Head Self-Attention Mechanisms;Sketch-to-Face Synthesis},
  doi={10.1109/ICECAI58670.2023.10176715},
  ISSN={},
  month={May},}@INPROCEEDINGS{8852314,
  author={Wu, Di and Hu, Ruiqi and Zheng, Yu and Jiang, Jing and Sharma, Nabin and Blumenstein, Michael},
  booktitle={2019 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Feature-Dependent Graph Convolutional Autoencoders with Adversarial Training Methods}, 
  year={2019},
  volume={},
  number={},
  pages={1-8},
  abstract={Graphs are ubiquitous for describing and modeling complicated data structures, and graph embedding is an effective solution to learn a mapping from a graph to a low-dimensional vector space while preserving relevant graph characteristics. Most existing graph embedding approaches either embed the topological information and node features separately or learn one regularized embedding with both sources of information, however, they mostly overlook the interdependency between structural characteristics and node features when processing the graph data into the models. Moreover, existing methods only reconstruct the structural characteristics, which are unable to fully leverage the interaction between the topology and the features associated with its nodes during the encoding-decoding procedure. To address the problem, we propose a framework using autoencoder for graph embedding (GED) and its variational version (VEGD). The contribution of our work is two-fold: 1) the proposed frameworks exploit a feature-dependent graph matrix (FGM) to naturally merge the structural characteristics and node features according to their interdependency; and 2) the Graph Convolutional Network (GCN) decoder of the proposed framework reconstructs both structural characteristics and node features, which naturally possesses the interaction between these two sources of information while learning the embedding. We conducted the experiments on three real-world graph datasets such as Cora, Citeseer and PubMed to evaluate our framework and algorithms, and the results outperform baseline methods on both link prediction and graph clustering tasks.},
  keywords={Decoding;Peer-to-peer computing;Clustering algorithms;Training;Matrix decomposition;Prediction algorithms;Task analysis;Graph Embedding;Graph Convolutional Neural Networks;Generative Adversarial Network},
  doi={10.1109/IJCNN.2019.8852314},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{9794505,
  author={Iqbal, Azlan},
  booktitle={2022 IEEE 12th Symposium on Computer Applications & Industrial Electronics (ISCAIE)}, 
  title={Evidence of the Transmutation of Creative Elements Using a Computational Creativity Approach}, 
  year={2022},
  volume={},
  number={},
  pages={139-143},
  abstract={Computational creativity is a relatively new subfield of artificial intelligence (AI). In short, it focuses on the ability of computers to generate objects that most humans with sufficient domain knowledge would consider having creative value, e.g., music, art, puzzles. In this article, the author presents rare evidence of the transmutation of creative elements or properties from one domain to another using a computational creativity approach, i.e., the Digital Synaptic Neural Substrate (DSNS). Specifically, in the domain of chess problem composition. This evidence suggests that creative elements, typically in the form of fragmented information or data, can indeed be transferred between domains. For instance, by drawing upon the characteristics of seemingly unrelated images (e.g., paintings, photographs) and sequences taken from chess games, valid chess problems or puzzles can be automatically generated. It is generally difficult to fully trace this kind of transmutation and simultaneously rule out algorithmic repetition or chance. However, there was at least one distinct example that left little room for contention. The author presents arguments for this "creative transmutation," additional supportive examples that were discovered, and likely directions for future work.},
  keywords={Industrial electronics;Neuroscience;Psychology;Games;Reliability;Artificial intelligence;Creativity;computational;creativity;transmutation;chess;intelligence},
  doi={10.1109/ISCAIE54458.2022.9794505},
  ISSN={},
  month={May},}@ARTICLE{11037762,
  author={Ridhawi, Ismaeel Al and Aloqaily, Moayad},
  journal={IEEE Network}, 
  title={AI-Driven Next-Generation Edge Computing: Current and Future Trends}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Traditional edge computing architectures envisioned for the Sixth Generation (6G) network cannot meet the ever-increasing task and processing demands of immersive services due to their limited ability to adapt to highly dynamic and resource-intensive scenarios. The absence of a robust Space-Air-Ground Integrated Network (SAGIN) framework in 6G for dynamic task allocation and resource management provides an obstacle to the realization of a true 6G network. In this article, we discuss some of the edge computing obstacles and challenges facing the provisioned upcoming 6G network and introduce a framework designed to optimize task and resource management in edge computing devices within SAGIN. The solution leverages contemporary technologies including metaverse-enabled Digital Twin (DT) and a plethora of Artificial Intelligence (AI) techniques that collectively enhance the adaptability, scalability, and computational efficiency of the network. The solution supports autonomous decision-making and coordination among distributed network entities, predict entity demands and network dynamics, facilitating real-time, proactive resource allocation, and optimize task offloading and load balancing by identifying efficient resource distribution paths across hierarchical network layers. Decentralized optimization and entity privacy preservation is maintained through Federated Learning (FL) and Blockchain. This work establishes a transformative pathway for the integration of the aforementioned technologies into 6G and lays the foundations for next-generation cooperative edge computing.},
  keywords={Edge computing;6G mobile communication;Resource management;Artificial intelligence;Real-time systems;Autonomous aerial vehicles;Scalability;Space-air-ground integrated networks;Next generation networking;Market research;6G;Edge Computing;Metaverse;Digital Twin;Federated Learning;Generative AI;Agentic AI;Deep Learning},
  doi={10.1109/MNET.2025.3580540},
  ISSN={1558-156X},
  month={},}@INPROCEEDINGS{9666349,
  author={Mertes, Silvan and Kiderle, Thomas and Schlagowski, Ruben and Lingenfelser, Florian and Andre, Elisabeth},
  booktitle={2021 9th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)}, 
  title={On the Potential of Modular Voice Conversion for Virtual Agents}, 
  year={2021},
  volume={},
  number={},
  pages={1-7},
  abstract={Virtual Agents are a way to give humans a familiar way to interact with the computer. An important component in the design of virtual agents is the voice with which they express themselves. The voice is not only a mere medium for information transfer, but also contains non-verbal functions such as the transmission of emotions. Additionally, in the context of virtual agents, it is important that the user accepts the voice of the agent and considers it consistent. To make this possible, it is necessary that such voices are highly customisable and adaptable. Current systems for generating speech from text are conceptually limited by the fact that a large part of their task is to model the semantics of what is spoken. Systems in the field of voice conversion, however, are decoupled from this, as they only need to model non-verbal features. Such systems become particularly efficient when they are limited to the transformation of dedicated, single characteristics. This paper proposes that the use of such voice conversion systems, and furthermore the exploitation of the possibility to cascade them, can be an immense improvement for conventional Text-to-Speech systems for virtual agents.},
  keywords={Adaptation models;Affective computing;Conferences;Semantics;Task analysis;voice conversion;virtual agents;affective speech;generative adversarial networks},
  doi={10.1109/ACIIW52867.2021.9666349},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11041509,
  author={Kavitha, V and K, Ms. Baby and Kumaresan, T. and Gopu, A. P and Kumar, T. Suresh and K, Ms. Gayathri Devi},
  booktitle={2025 3rd International Conference on Artificial Intelligence and Machine Learning Applications Theme: Healthcare and Internet of Things (AIMLA)}, 
  title={Next Generation Watermark Removal: An Efficient and Robust Framework with Transfer Learning and Gan}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Watermark removal has emerged as a critical area of study in digital media processing, with applications spanning from content recovery to intellectual property safeguarding. “Next Generation Watermark Removal: An Efficient and Robust Frame work with Transfer Learning and GAN” is the title of this paper's novel framework. For enhanced watermark removal efficiency and robustness, the proposed approach utilizes transfer learning and generative adversarial networks (GANs). Two significant features include adversarial training for high-quality restoration and meta-learning for adaptability across various watermarking systems. Experimental results are compared to existing methods, and it is found that peak signal-to-noise ratio (PSNR) and structural similarity index measure (SSIM) are better. The architecture is robust across a range of datasets and watermark types, paving the way for future-proof secure digital media management solutions.},
  keywords={Metalearning;Training;PSNR;Transfer learning;Watermarking;Media;Generative adversarial networks;Robustness;Image restoration;Next generation networking;Watermark Removal;Transfer Learning;Generative Adversarial Networks;Meta-Learning;Image Restoration},
  doi={10.1109/AIMLA63829.2025.11041509},
  ISSN={},
  month={April},}@INPROCEEDINGS{10730311,
  author={Nishika, Nandita and Sharma, Anurag},
  booktitle={2024 IEEE International Conference on Artificial Intelligence in Engineering and Technology (IICAIET)}, 
  title={Exploring MCMC Guided GAN and Comparative Analysis for Uneven Class Distribution}, 
  year={2024},
  volume={},
  number={},
  pages={177-182},
  abstract={Uneven class distribution in data sets poses a significant challenge in the classification model which causes the sub-optimal performance and a biased model towards the majority class. This paper investigates the sampling method of Generative Adversarial Network (GAN) on a Bayesian Framework utilizing Markov Chain Monte Carlo (MCMC) to enhance the sampling. MCMC is employed to explore the solution space effectively, while GAN generates synthetic samples to balance the class distribution. The integration of these two techniques aims to enhance the model's robustness and generalization capabilities. Experimental results demonstrate potential improvements in classification accuracy, highlighting the potential of the proposed method in handling uneven class distribution that is MCMC Guided GAN. This method along with other methods including Synthetic Minority Over-sampling Technique (SMOTE), Smotified-GAN, GAN and MCMC. The promising results obtained highlight the potential of the MCMC Guided GAN method as a valuable tool in addressing the challenges associated with imbalanced datasets. This research contributes to the advancement of techniques for more effective and equitable classification models.},
  keywords={Monte Carlo methods;Accuracy;Noise;Generative adversarial networks;Sampling methods;Data models;Robustness;Probability distribution;Space exploration;Bayes methods;Generative Adversa rial Network (GAN);Imbalanced class problem;Markov Chain Monte Carlo (MCMC);Bayesian Framework},
  doi={10.1109/IICAIET62352.2024.10730311},
  ISSN={},
  month={Aug},}@ARTICLE{9724287,
  author={Ay, Betul},
  journal={IEEE Access}, 
  title={Open-Set Learning-Based Hologram Verification System Using Generative Adversarial Networks}, 
  year={2022},
  volume={10},
  number={},
  pages={25114-25124},
  abstract={In this study, we address the hologram authenticity challenge by introducing a novel deep-learning based end-to-end hologram verification system. The system ultimately makes the decision whether the hologram image captured from a mobile application is fake or not by employing a robust classifier. We built the system by training three major deep networks; generative networks, convolutional networks and region-based convolutional networks. One major challenge in this study was the lack of negative class samples or so-called fake holograms. To the best of our knowledge there are no publicly available fake hologram datasets and it is not clear how the attackers imitate the real holograms. Therefore, the negative class in the practical hologram classification task is actually “unknown” class, as it is unknown how to imitate holograms by attackers. We hereby consider the problem of hologram classification as in a similar logic to open-set recognition. To make hologram classifier more sensitive to forgery, we generate synthetic images using generative adversarial networks (GANs) to represent negative class. We conduct extensive and comparative experiments on the closed-set and open-set using the-state-of-the-art backbone convolutional neural networks (CNNs). The proposed system gives an impressive accuracy 97.5% and 79% for closed-set and open-set samples, respectively. The reported results show the strong generalization performance of the system for unknown samples.},
  keywords={Generative adversarial networks;Generators;Training;Deep learning;Security;Task analysis;Convolutional neural networks;Deep learning;generative adversarial networks;convolutional neural networks;image classification;computer vision},
  doi={10.1109/ACCESS.2022.3155870},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9951072,
  author={Cha, Gi Soon and Asim, Usman and Song, Myung Keun and Niaz, Asim and Choi, Kwang Nam},
  booktitle={2022 Asia Conference on Advanced Robotics, Automation, and Control Engineering (ARACE)}, 
  title={Image Generation Network Model based on Principal Component Analysis}, 
  year={2022},
  volume={},
  number={},
  pages={76-80},
  abstract={In the field of Artificial Intelligence, a large and densely annotated dataset is required for training making it a time and resource-expensive task. In this paper, we propose an image generation network model that keeps the training examples at a minimal level. The proposed model gives additional feature maps to the input value (latent space) of the DCGAN model, which is an adversarial image generation model using a convolutional neural network. To solve the problem that the neural network model cannot generate clear images in case of lack of training data, one additional feature map was added to the input value of the generation model, latent space. The feature map was extracted from 2,000 images of the CelebA dataset consisting of human face images through principal component analysis. We used 3,838 Large-Age-Gap datasets and one feature image for training. Compare to the previous model which uses 200,000 images, the proposed model generates more natural facial images with only 3,829 examples and the error rate is significantly reduced than the previous model at the beginning of the model training.},
  keywords={Training;Analytical models;Image synthesis;Error analysis;Face recognition;Training data;Feature extraction;Deep Learning;Principal Component Analysis;Generation Network Model},
  doi={10.1109/ARACE56528.2022.00022},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{11081369,
  author={Biswas, Swarnava and Patra, Bipasa Bimalendu and Das, Anindya Sundar},
  booktitle={2025 International Conference on Advances in Modern Age Technologies for Health and Engineering Science (AMATHE)}, 
  title={Chest X-Ray Based AI-Driven Method for Detection of COVID-19 Infected Patients}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={The global health and economy were devastated by the COVID-19 pandemic. The limited availability of COVID-19 test kits is to blame for this unavoidable diagnostic lag. Therefore, there is an immediate need to develop new low-cost and lowresource diagnostic methods. Chest X-ray is the first step in making a correct diagnosis of COVID-19 since it may easily detect any abnormalities in the chest (e.g., lung inflammation). Additionally, most hospitals have X-ray machines that can be used for early diagnosis of COVID-19. Although early COVID-19 diagnosis is crucial to effective treatment, a lack of radiologists is a major limiting issue. This research provides a method based on artificial intelligence, medical expertise, and deep Convolutional Neural Networks for the early diagnosis of COVID-19 from chest X-ray pictures (CNNs). Specifically, we aim for optimal performance in detecting COVID-19 by building and tuning a deep learning model. The suggested method achieves above 99 per cent accuracy in recognizing COVID-19, as shown by experimental findings on recent benchmark datasets.},
  keywords={COVID-19;Deep learning;Radiography;Accuracy;Sensitivity;Hospitals;Convolutional neural networks;Artificial intelligence;X-ray imaging;Tuning;COVID-19;deep learning;F-measure;sensitivity;covid detection;radiography},
  doi={10.1109/AMATHE65477.2025.11081369},
  ISSN={},
  month={April},}@INPROCEEDINGS{11151923,
  author={Hsu, Bo-Yuan and Chen, Tzung-Shi},
  booktitle={2025 IEEE VTS Asia Pacific Wireless Communications Symposium (APWCS)}, 
  title={Pedestrian Trajectory Prediction Based on Social Pooling and Spatio-Temporal Graph Convolution Network}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={In recent years, trajectory prediction has become a major focus in the field of smart cities. This paper investigates the use of Socially Acceptable Trajectories with Generative Adversarial Networks (Social GAN) for pedestrian trajectory prediction, specifically addressing the issue of social interactions between pedestrians. We optimized the Socially Acceptable Trajectories with Generative Adversarial Networks for this purpose. In our study, we preprocessed real-world pedestrian data, taking into account factors such as pedestrian interactions, the dimensions of graph expansion, and the distribution of each neural network layer, to enhance accuracy in trajectory prediction. We introduced three social application methods based on the social pooling layer, converting the Social GAN into a Spatio-Temporal Graph Convolution Network (ST-GCN) which led to improved performance in terms of Average Displacement Error (ADE) and Final Displacement Error (FDE). Our experimental results demonstrate that our proposed method shows significant improvement in both ADE and FDE compared to traditional GANs.},
  keywords={Wireless communication;Pedestrians;Accuracy;Smart cities;Convolution;Neural networks;Asia;Generative adversarial networks;Trajectory;Artificial intelligence;Artificial Intelligence;Pedestrian Trajectory Prediction;Smart Cities;Social GAN;ST-GCN},
  doi={10.1109/APWCS67981.2025.11151923},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10894433,
  author={Ruchi and Kumar, Lovish and Aggarwal, Sneha and Verma, Tanisha and Harshita and Wasson, Vikas},
  booktitle={2024 2nd International Conference on Recent Trends in Microelectronics, Automation, Computing and Communications Systems (ICMACC)}, 
  title={Synthetic Vs Real: A Comparative Study on AI Generated Art for Improved Learning in AI}, 
  year={2024},
  volume={},
  number={},
  pages={58-63},
  abstract={This research offers an in-depth comparison of emotion detection models developed using real-world and synthetic datasets in the field of artificial intelligence and machine learning. The research rigorously analyses model performance, generalization capacities, and robustness in various circumstances to evaluate the use of synthetic data for machine learning applications. We provide thorough empirical research to examine essential issues concerning predictive accuracy, robustness against adversarial inputs, and biases present in synthetic datasets. Our findings indicate a distinct superiority of real-world datasets, which regularly exceed synthetic datasets in accuracy, precision, and practical utility. This result offers significant insights for researchers and practitioners, highlighting the indispensable importance of genuine data in attaining optimal performance and influencing the future of AI-based emotion recognition systems.},
  keywords={Training;Emotion recognition;Accuracy;Focusing;Machine learning;Market research;Data models;Robustness;Microelectronics;Synthetic data;component;Emotion detection;Synthetic data;Real-world datasets;Comparative study;Machine learning;Performance metrics;Accuracy;Robustness;Adversarial inputs;Data scarcity;Privacy concerns;Training strategies;Evaluation methodologies;Emotional expressions;Model performance},
  doi={10.1109/ICMACC62921.2024.10894433},
  ISSN={},
  month={Dec},}@ARTICLE{10858006,
  author={Gao, Mengyu and Dong, Qiulei},
  journal={IEEE Transactions on Image Processing}, 
  title={Self-Assembled Generative Framework for Generalized Zero-Shot Learning}, 
  year={2025},
  volume={34},
  number={},
  pages={914-924},
  abstract={Generative models have attracted much attention for handling the generalized zero-shot learning (GZSL) task recently. Most of the existing generative GZSL models are trained for visual feature synthesis by utilizing the unique semantic feature of each object class as input but its kaleidoscopic real visual features as supervisions. However, since the real visual features are inevitably infiltrated by some class-irrelevant information, the trained generative models could not guarantee the discriminability of their synthesized visual features. In this paper, we firstly provide an empirical analysis on this problem, finding that among the elements of the real visual features, some elements contain more class-irrelevant information than the others, resulting in ambiguous visual feature synthesis. Then according to this finding, we propose a self-assembled generative GZSL framework, where both the real and synthesized visual features are re-assembled by identifying and updating the class-irrelevant elements in a self-learning manner, called SaG. Moreover, an element-affinity regularizer is explored for constraining the affinity among different elements, so that the synthesized visual features under the SaG framework approach the updated feature elements. In principle, different generative GZSL models could be seamlessly embedded into the SaG framework, resulting in different GZSL methods. Extensive experimental results demonstrate that the derived methods, by embedding three baseline generative GZSL models into SaG respectively, could boost the performances of their baselines significantly, and one of the derived methods outperforms 20 state-of-the-art GZSL methods in most cases.},
  keywords={Visualization;Semantics;Feature extraction;Noise reduction;Vectors;Zero shot learning;Diffusion models;Training;Noise measurement;Data mining;Denoising diffusion model;visual feature self-assembling;generalized zero-shot learning},
  doi={10.1109/TIP.2025.3531697},
  ISSN={1941-0042},
  month={},}@ARTICLE{10679152,
  author={Zhang, Ruichen and Du, Hongyang and Liu, Yinqiu and Niyato, Dusit and Kang, Jiawen and Xiong, Zehui and Jamalipour, Abbas and In Kim, Dong},
  journal={IEEE Journal on Selected Areas in Communications}, 
  title={Generative AI Agents With Large Language Model for Satellite Networks via a Mixture of Experts Transmission}, 
  year={2024},
  volume={42},
  number={12},
  pages={3581-3596},
  abstract={In response to the needs of 6G global communications, satellite communication networks have emerged as a key solution. However, the large-scale development of satellite communication networks is constrained by complex system models, whose modeling is challenging for massive users. Moreover, transmission interference between satellites and users seriously affects communication performance. To solve these problems, this paper develops generative artificial intelligence (AI) agents for model formulation and then applies a mixture of experts (MoE) approach to design transmission strategies. Specifically, we leverage large language models (LLMs) to build an interactive modeling paradigm and utilize retrieval-augmented generation (RAG) to extract satellite expert knowledge that supports mathematical modeling. Afterward, by integrating the expertise of multiple specialized components, we propose an MoE-proximal policy optimization (PPO) approach to solve the formulated problem. Each expert can optimize the optimization variables at which it excels through specialized training through its own network and then aggregate them through the gating network to perform joint optimization. The simulation results validate the accuracy and effectiveness of employing a generative agent for problem formulation. Furthermore, the superiority of the proposed MoE-ppo approach over other benchmarks is confirmed in solving the formulated problem. The adaptability of MoE-PPO to various customized modeling problems has also been demonstrated.},
  keywords={Generative AI;Satellites;Optimization;Low earth orbit satellites;Adaptation models;Mathematical models;Resource management;Satellite communications;generative AI agent;MoE;LLM;PPO;network design},
  doi={10.1109/JSAC.2024.3459037},
  ISSN={1558-0008},
  month={Dec},}@INPROCEEDINGS{10578746,
  author={Styve, Arne and Virkki, Outi T. and Naeem, Usman},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Developing Critical Thinking Practices Interwoven with Generative AI Usage in an Introductory Programming Course}, 
  year={2024},
  volume={},
  number={},
  pages={01-08},
  abstract={Software development has evolved significantly. In the past, developers were required to have comprehensive understanding of programming languages, algorithms, and computer architecture. However, with the emergence of the Internet, software libraries, frameworks, and forums became widely available, which utilize reusable software components that can reduce development time and costs. The advent of Generative Artificial Intelligence (AI) tools, such as ChatGPT, GitHub Copilot, and Amazon CodeWhisperer, has further enhanced the developer's toolkit, as these tools can be used for a wide variety of tasks such as code generation, documentation, commenting and reviewing. As programming is often slow and requires trial and error, novice programmers can be tempted to apply the first solution found on the Internet or proposed by an AI tool without much critical reflection or notion of responsibility. Hence, the advances of AI have raised both excitement and concerns among Information Technology (IT)/Computer Science (CS) students and educators. Yet, AI tools are here to stay, and students must learn to use them responsibly. The aim of this paper is to investigate how to design learning activities that introduce Generative AI tools (GitHub Copilot and ChatGPT) for programming while promoting critical thinking practices among students in an introductory programming course in the first semester. Students' opinions and customs were surveyed before and after the AI-based programming assignment. The results indicate that students' awareness of the possibilities and limitations of AI, as well as practices of critical thinking in programming increased. This is encouraging as critical thinking is an integral part of best programming practices.},
  keywords={Software libraries;Generative AI;Software algorithms;Chatbots;Software;Reflection;Internet;Generative AI;Critical Thinking;Higher Education;CS1},
  doi={10.1109/EDUCON60312.2024.10578746},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10405148,
  author={Adwaith Krishna, E R and Sha, Akhbar and Anvesh, Kalwa and Reddy, Nancharla Abhinay and Raj, Bhupathi Shwejan and Nisha, K S},
  booktitle={2023 2nd International Conference on Automation, Computing and Renewable Systems (ICACRS)}, 
  title={Generative AI-Driven Approach to Converting Numerical Code into Mathematical Functions}, 
  year={2023},
  volume={},
  number={},
  pages={661-666},
  abstract={In the era of Artificial Intelligence (AI), the role of Generative AI models has witnessed a paradigm shift in addressing programming challenges. This research delves into the evolving landscape of Generative AI-driven code generation for programming problems, with a focus on the convergence behavior, algorithmic efficiency, learning dynamics, and code-length-performance dynamics of AI models, exemplified by ChatGPT and BARD. Through meticulous experimentation and analysis, this study elucidates key findings that illuminate the strengths and nuances of these models in code generation contexts. ChatGPT demonstrates rapid initial convergence, making it advantageous in time-sensitive scenarios, while BARD exhibits potential for precision-critical tasks. Algorithmic efficiency comparisons reveal subtle differences, emphasizing the need for further investigation into runtime influences. Learning curve analysis underscores the significance of early iterations in training, while code length-performance dynamics present intriguing correlations that warrant in-depth exploration. These insights provide a foundation for informed model selection and training strategies, while highlighting the ethical considerations and future avenues in AI-driven code generation.},
  keywords={Training;Codes;Runtime;Generative AI;Programming;Chatbots;Convergence;Generative AI;Code Generation;Programming Problems;Convergence Behavior;ChatGPT;BARD},
  doi={10.1109/ICACRS58579.2023.10405148},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10755794,
  author={Correa, Nelson and Correa, Antonio and Zadrozny, Wlodek},
  booktitle={2024 IEEE ANDESCON}, 
  title={Generative AI for Consumer Communications: Classification, Summarization, Response Generation}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Generative AI showed the unexpected power of large language models (LLMs) for understanding and generation of natural language text and other modalities at the end of 2022. This paper presents a novel generative AI system for text classification, summarization and response generation of consumer communications. The system uses the same foundation model and a uniform pipeline for the tasks proposed. Consumer communications are massive and served mainly via voice and text, and until recently could be handled only with human agents (customer service representatives). However, they must be handled with quality, consistency, speed and low cost, at scale. We limit our attention to financial consumer communications from the U.S. Consumer Financial Protection Bureau (CFPB), publicly available in a dataset of over 4.7 million complaints. Performance reaches 88 % accuracy (without fine-tuning) for classification and over 72 % for summarization and response generation. Artificial intelligence has great positive impacts for business and society, but its application and deployment also poses risks and unknowns. We thus address the important questions of risk, bias, interpretability, explainability, safety and regulatory compliance with the emerging legal frameworks.},
  keywords={Costs;Generative AI;Law;Large language models;Customer services;Text categorization;Pipelines;Natural languages;Protection;Business;Generative AI;natural language processing;large language models;text classification;text summarization;vector embeddings;AI safety},
  doi={10.1109/ANDESCON61840.2024.10755794},
  ISSN={2996-895X},
  month={Sep.},}@INPROCEEDINGS{11158636,
  author={Vadisetty, Rahul and Polamarasetti, Anand and Goyal, Mahesh Kumar and Rongali, Sateesh Kumar and Prajapati, Sameer kumar and Butani, Jinal Bhanubhai},
  booktitle={2025 International Conference on Advancements in Smart, Secure and Intelligent Computing (ASSIC)}, 
  title={Cloud-Based Immersive Learning: The Role of Virtual Reality, Big Data, and Generative AI in Transformative Education Experiences}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Immersive learning transforms education by integrating Virtual Reality (VR), Big Data, and Generative Artificial Intelligence (AI) in cloud environments. This work discusses these technologies' contribution towards increased engagement, personalized learning, and recall through flexible and interactive experiences. Realistic simulations in a secure environment, real-time analysis via Big Data, and dynamically personalized information via Generative AI make immersive learning a reality. Nevertheless, scalability, security, and ease of integration are yet to be addressed. This article proposes an integrated model for cloud-based immersive learning, comparing conventional and AI-facilitated approaches through experimental evaluation. Besides, technical, ethical, and legislative considerations and future directions for inquiry are addressed. In conclusion, with its potential for personalized, scalable, and data-intensive instruction, AI-facilitated immersive learning is a transformational technology for educational delivery.},
  keywords={Cloud computing;Solid modeling;Generative AI;Scalability;Education;Transforms;Big Data;Real-time systems;Security;Immersive learning;Cloud-based learning;Virtual Reality;Big Data;Generative AI;Personalized Education;Learning Analytics},
  doi={10.1109/ASSIC64892.2025.11158636},
  ISSN={},
  month={May},}
