@ARTICLE{10721579,
  author={Sharaby, Israa and Magdy Balaha, Hossam and Alksas, Ahmed and Mahmoud, Ali and Abou El-Ghar, Mohamed and Khalil, Ashraf and Ghazal, Mohammed and Contractor, Sohail and El-Baz, Ayman},
  journal={IEEE Access}, 
  title={Artificial Intelligence-Based Kidney Segmentation With Modified Cycle-Consistent Generative Adversarial Network and Appearance-Based Shape Prior}, 
  year={2024},
  volume={12},
  number={},
  pages={162536-162548},
  abstract={This study presents an innovative deep learning framework for kidney segmentation in magnetic resonance imaging (MRI) data. The framework integrates both kidney appearance and prior shape information using a residual cycle-consistent generative adversarial network (CycleGAN). An appearance-based shape prior model is developed, utilizing iso-circular contours generated from the kidney centroid and employing the fast marching level sets method for shape extraction. By utilizing the kidney centroid and matching cross-circular iso-circular contours’ appearance, the proposed appearance-based shape prior model remains invariant to translation, rotation, and scaling, eliminating the need for alignment. Additionally, a novel weighted loss function, the H-Loss, is introduced to enhance segmentation performance and prevent overfitting. The proposed approach is tested on 34 blood-oxygen-level-dependent (BOLD) grafts from patients in our kidney transplant program, achieving an average dice score of 92%. These promising results validate the effectiveness of the approach, with optimized hyperparameters ensuring high segmentation quality.},
  keywords={Kidney;Image segmentation;Tumors;Cancer;Generative adversarial networks;Training;Medical diagnostic imaging;Level set;Computer architecture;Shape measurement;Appearance-based shape prior;CycleGAN;generative adversarial network;kidney segmentation},
  doi={10.1109/ACCESS.2024.3483661},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11060533,
  author={Kituku, Benson and Araka, Eric and Muuro, Elizaphan},
  booktitle={2025 IST-Africa Conference (IST-Africa)}, 
  title={Integrating Generative Artificial Intelligence in Assessment Generation for Higher Education: Computer Science Use Case}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={The overburdened lecturers today face the dual challenge of monitoring online attendance and ensuring active student engagement, while also receiving instant feedback on concept comprehension during live lectures. They are further pressed to extend practical problem-solving experiences beyond the classroom and deliver higher-order thinking assessments - all without increasing their workload. In response, this paper presents a one-year experiment involving 590 students across seven computer science units. The study integrated generative AI-generated questions into live lectures, weekly discussion forums, and both formative and summative exams. The findings reveal that, with ethical use and proper human-in-the-loop, AI can significantly boost student engagement, promptly rectify misconceptions, and foster collaborative learning outside traditional settings and offer diverse question styles. However, given potential pitfalls such as low-quality outputs and overreliance, instructors must adhere to best practices and maintain rigorous oversight to ensure that assessments remain balanced, engaging, and of high quality, eventually benefiting both educators and learners.},
  keywords={Computer science;Generative AI;Federated learning;Education;Human in the loop;Problem-solving;Monitoring;Best practices;Faces;Testing;Generative AI;Assessment;Multiple choice questions;Higher education;Computer Science and Prompt},
  doi={10.23919/IST-Africa67297.2025.11060533},
  ISSN={2576-8581},
  month={May},}@INPROCEEDINGS{10457279,
  author={Choi, Minseo and Shin, Wunjong and Pyo, Heesu and Song, Wootaek and Jung, Byungjun and Shin, Minwoo and Paik, Joonki},
  booktitle={2024 International Conference on Electronics, Information, and Communication (ICEIC)}, 
  title={Face Recognition for Soldiers with Bulletproof Helmets Using Generative Networks and Data Augmentation}, 
  year={2024},
  volume={},
  number={},
  pages={1-2},
  abstract={Face recognition (FR) is a key technology for a wide range of applications, including privacy-preserving security, education, entertainment, and emotion recognition. However, existing FR methods require a large amount of data to train, and their performance can be degraded by factors such as bulletproof helmets worn by soldiers. This paper proposes a new FR method for soldiers with bulletproof helmets that uses generative networks and data augmentation techniques to effectively increase the amount of training data. The proposed method first generates synthetic face images of soldiers with bulletproof helmets using a generative network. Then, it uses data augmentation techniques to further increase the diversity of the training data. The proposed method is evaluated on both our own dataset of soldiers with bulletproof helmets and a public dataset. The results show that the proposed method outperforms existing FR methods on both datasets, especially in the presence of bulletproof helmets. Overall, the proposed method is a promising new approach for FR for soldiers with bulletproof helmets. It can be used to improve the performance of FR systems in military applications, such as soldier identification and authentication.},
  keywords={Emotion recognition;Head;Face recognition;Supervised learning;Training data;Entertainment industry;Data augmentation;Face Recognition;Generative Model;Data Augmentation},
  doi={10.1109/ICEIC61013.2024.10457279},
  ISSN={2767-7699},
  month={Jan},}@INPROCEEDINGS{10810680,
  author={Cardenuto, João P. and Mandelli, Sara and Moreira, Daniel and Bestagini, Paolo and Delp, Edward and Rocha, Anderson},
  booktitle={2024 IEEE International Workshop on Information Forensics and Security (WIFS)}, 
  title={Explainable Artifacts for Synthetic Western Blot Source Attribution}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Recent advancements in artificial intelligence have enabled generative models to produce synthetic scientific images that are indistinguishable from pristine ones, posing a challenge even for expert scientists habituated to working with such content. When exploited by organizations known as paper mills, which systematically generate fraudulent articles, these technologies can significantly contribute to the spread of misinformation about ungrounded science, potentially undermining trust in scientific research. While previous studies have explored black-box solutions, such as Convolutional Neural Networks, for identifying synthetic content, only some have addressed the challenge of generalizing across different models and providing insight into the artifacts in synthetic images that inform the detection process. This study aims to identify explainable artifacts generated by state-of-the-art generative models (e.g., Generative Adversarial Networks and Diffusion Models) and leverage them for open-set identification and source attribution (i.e., pointing to the model that created the image).},
  keywords={Forensics;Conferences;Paper mills;Closed box;Organizations;Generative adversarial networks;Diffusion models;Security;Convolutional neural networks;Fake news;Western blots;synthetically generated images;image forensics;source attribution;scientific integrity},
  doi={10.1109/WIFS61860.2024.10810680},
  ISSN={2157-4774},
  month={Dec},}@ARTICLE{10131946,
  author={Paola, Zárate L. and Jesús, López S. and Christian, Arroyo H. and Sonia, Rincón U.},
  journal={IEEE Access}, 
  title={Correction of Banding Errors in Satellite Images With Generative Adversarial Networks (GAN)}, 
  year={2023},
  volume={11},
  number={},
  pages={51960-51970},
  abstract={This research proposes an innovative method for correcting banding errors in satellite images based on Generative Adversarial Networks (GAN). Small satellites are frequently launched into space to obtain images that can be used in scientific or military research, commercial activities, and urban planning, among other applications. However, its small cameras are more susceptible to radiometric, geometric errors, and other distortions caused by atmospheric interference. The proposed method was compared to the conventional correction technique using experimental data, showing the similar performance (92.64% and 90.05% accuracy, respectively). These experimental results suggest that generative models utilizing Artificial Intelligence (AI) techniques, specifically Deep Learning, are getting closer to achieving automatic correction close to conventional methods. Advantages of the GAN models include automating the task of correcting banding in satellite images, reducing the required time, and facilitating the processing without requiring prior technical knowledge in handling Geographic Information Systems (GIS). Potentially, this technique could represent a valuable tool for satellite image processing, improving the accuracy of the results and making the process more efficient. The research is particularly relevant to the field of remote sensing and can have practical applications in various industries.},
  keywords={Satellite broadcasting;Generative adversarial networks;Generators;Training;Radiometry;Remote sensing;Image coding;Artificial neural network;deep learning;generative adversarial network;satellite images;radiometric error;banding},
  doi={10.1109/ACCESS.2023.3279265},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10609905,
  author={Malla, Alejandro and Omwenga, Maxwell M. and Kumar Bera, Pallav},
  booktitle={2024 IEEE International Conference on Electro Information Technology (eIT)}, 
  title={Exploring Image Similarity through Generative Language Models: A Comparative Study of GPT-4 with Word Embeddings and Traditional Approaches}, 
  year={2024},
  volume={},
  number={},
  pages={275-279},
  abstract={In this article, we propose a novel approach for determining image similarity, leveraging advancements in generative artificial intelligence. At the heart of our method is the use of OpenAI’s GPT-4 large language model for generating image captions, combined with the Ada v2 word embedding model for semantic analysis. This technique involves creating textual descriptions of images via GPT-4 and subsequently computing cosine similarity of these descriptions using Ada v2 word embeddings. We compare this innovative approach with traditional image similarity methods, with a particular focus on the VGG16 neural network approach, employing the DISC21 dataset for our analysis. Preliminary results demonstrate the promising potential of this method in the field of image similarity assessment. The paper delves into both the advantages and current limitations of our approach, including constraints like rate limits in experimentation and the rapidly evolving capabilities of language models in vision tasks. Our findings indicate a trajectory towards improved outcomes as these models continue to advance, underscoring the growing intersection of language and vision models in artificial intelligence for applications like image similarity evaluation.},
  keywords={Heart;Analytical models;Generative AI;Large language models;Computational modeling;Semantics;Neural networks;Image Similarity Assessment;Generative Language Models (GPT-4);Word Embeddings (Ada v2);Deep Learning in Computer Vision (VGG16);Semantic Analysis},
  doi={10.1109/eIT60633.2024.10609905},
  ISSN={2154-0373},
  month={May},}@INPROCEEDINGS{8995243,
  author={Zhou, Xinyu and Peng, Yang},
  booktitle={2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Short-Spoken Language Intent Classification with Conditional Sequence Generative Adversarial Network}, 
  year={2019},
  volume={},
  number={},
  pages={1753-1756},
  abstract={As one of the most thrilling tasks of natural language understanding (NLU), intent classification in a dialogue system has received a great deal of attention in both industry and academia. The major limiting factor on intent classification is the lack of tagged data. To solve it, in this paper, we propose a conditional sequence generative adversarial network (cSeq-GAN) for intent classification of short-spoken language, in which we simultaneously train a generative model and a discriminative model for two tasks, one to distinguish the generated text from the real spoken one, while the other to predict its intent category. More reliable tagged data obtained by the generator greatly improves the performance of the intent classification task. Extensive experiments on both Air Travel Information System (ATIS) and our selling robot dialogue system for insurance industries demonstrate that our cSeq-GAN achieves competitive classification accuracy with other state-of-art methods of text classification.},
  keywords={GAN;Dialogue System;Intent Classification},
  doi={10.1109/ICTAI.2019.00261},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{10920549,
  author={An, Congying and Wu, Jingjing and Zhang, Huanlong},
  booktitle={2024 International Conference on Sensing, Measurement & Data Analytics in the era of Artificial Intelligence (ICSMD)}, 
  title={Occlusion-Aware Segmentation Via RCF-Pix2Pix Generative Network}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Segmentingimage objects overlapped by other objects is challenging, because the shapes in occluded areas are unknown, and occlusion boundaries typically have no distinction from real object contours. Unlike traditional segmentation methods using convolutional networks, we explored the segmentation capabilities of generative networks in occluded areas and proposed a new edge-guided network architecture (RCF-Pix2Pix). The network simulates the human thought process for estimating the shape of occluded areas, using edge and overall contour information from visible parts to infer the shape of the occluded portion. RCF-Pix2Pix enhances the edge features by integrating edge information. It also uses edge contours as conditional input for the discriminator, guiding the network to predict contours in invisible areas. Moreover, by combining MSE-SSIM-L1 loss and edge loss, it improves the accuracy of target segmentation and stabilizes the quality of segmented images, making it more effective in handling complex imaging tasks. Experimental results show that our method has achieved significant improvements on the chip dataset, with an mIOU of 98.9%, Boundary IoU of 86.6% (+10.4%), and also achieved significant accuracy improvements in the D2SA dataset tests. This confirms the effectiveness and practical value of the RCF-Pix2Pix network in dealing with complex obstruction situations. Code is available at: https://github.com/CongyingAn/RCF-Pix2Pix-Generative-Network.},
  keywords={Training;Image segmentation;Accuracy;Shape;Image edge detection;Noise;Production;Network architecture;Generators;Surface treatment;RCF-Pix2Pix;Occluded areas;conditional information;Edge},
  doi={10.1109/ICSMD64214.2024.10920549},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10974174,
  author={Al Rawi, Anas and Jabeur, Nafaa and Anwar, Raja Waseem},
  booktitle={2024 Artificial Intelligence Revolutions (AIR)}, 
  title={Generative AI-Based Tool for Brute Forcing IoT Devices' Default Credentials}, 
  year={2024},
  volume={},
  number={},
  pages={102-108},
  abstract={This study beneficially uses the power of generative AI to search for vendor-specific default credentials and uses them to brute force IoT devices logins. IoT devices have a diverse set of open ports used for accessing and configuration. With the increased usage of IoT devices, keeping all devices' ports wellsecured is overwhelming and costly, especially for SMEs. Using a variety of methods to approach the problem, this research studied IoT attacks, characteristics, IoT penetration tools, and small to medium size enterprises (SMEs) requirements to produce an automated solution. Findings indicated that a lot of IoT devices are still configured with default credentials making the networks they are connected to vulnerable attacks. The solution presented, is a script that integrates OpenAI GPT to search for default credentials, Nmap to scan for open ports, and Hydra to attack the device. The tool is implemented to assess some specific widely used ports. To detect vulnerable IoT devices and report them to the user, the tool analyses login pages available on ports 80 and 443 to search for the brand and model of the IoT device. The output is used for the default credentials GPT search. Despite its ability to shortlist the dictionary for a brute force list, it should be tested on an experiential environment that includes different IoT simulators with several open ports on changed credentials and default ones. Then verified its functionality on a real IoT network. Further research could explore implementing machine learning to thoroughly analyse IoT device firmware.},
  keywords={Analytical models;Dictionaries;Generative AI;Force;Machine learning;Internet of Things;Microprogramming;Generative AI;IoT Device;Default Credentials;Brute Force;SMEs;Python Script},
  doi={10.1109/AIR63653.2024.00015},
  ISSN={},
  month={Oct},}@INBOOK{10951427,
  author={Minnick, Chris},
  booktitle={Coding with AI For Dummies}, 
  title={Parsing Machine Learning and Deep Learning}, 
  year={2024},
  volume={},
  number={},
  pages={37-56},
  abstract={Summary <p>This chapter covers some of the basics of AI and machine learning. Machine learning is a type of AI that focuses on developing and using computer systems that can learn and adapt without following explicit instructions. Deep learning is a type of machine learning based on artificial neural networks. Natural&#x2010;language processing (NLP) is the branch of AI concerned with giving computers the capability to understand human language in written and spoken form. NLP can be further divided into two subsets: natural&#x2010;language understanding and natural&#x2010;language generation. Transformer models use a self&#x2010;attention mechanism to find dependencies between inputs and outputs. AI chatbots are language models tuned for conversation. The standard ChatGPT response to even a simple question reads like a high school book report, containing an introduction, an analysis of an issue from multiple viewpoints, and a summary.</p>},
  keywords={Biological neural networks;Dogs;Neurons;Deep learning;Generative AI;Artificial neural networks;Writing;Encoding;Training;Shape},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394249152},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951427},}@INPROCEEDINGS{10908263,
  author={Tai, Nguyen Ngoc and Tai, Nguyen Ngoc and Tan, Nguyen Duc and Tan, Nguyen Duc and To, Trong-Nghia and To, Trong-Nghia and Duy, Phan The and Duy, Phan The and Pham, Van-Hau and Pham, Van-Hau},
  booktitle={2024 International Conference on Advanced Technologies for Communications (ATC)}, 
  title={A Robust and Trustworthy Intrusion Detection System Using Adversarial Machine Learning and XAI}, 
  year={2024},
  volume={},
  number={},
  pages={407-412},
  abstract={Network attacks are increasingly sophisticated. Advances in Artificial Intelligence (AI), particularly deep learning, have improved intrusion detection systems (IDS). However, deep learning (DL) in cybersecurity faces challenges, such as imbalanced training data, vulnerability to adversarial attacks and a lack of transparency regarding AI systems. To address these problems, we developed the RobustAdvTrain (Robustness Adversarial Training) framework to train IDS models for high accuracy and resilience against adversarial attacks. This framework provides explainable AI for transparent IDS predictions. We propose the sAoEGAN (self-Attention on Explanation Generative Adversarial Network) model, which combines explainable AI and self-attention mechanisms to generate high-quality adversarial samples. Our approach improves intrusion detection, resilience to adversarial samples, and transparency in deep learning-based IDS systems.},
  keywords={Training;Deep learning;Explainable AI;Computational modeling;Scalability;Memory management;Intrusion detection;Training data;Generative adversarial networks;Resilience;Intrusion Detection System;Adversarial Machine Learning;Explainable AI},
  doi={10.1109/ATC63255.2024.10908263},
  ISSN={2162-1039},
  month={Oct},}@INPROCEEDINGS{9823913,
  author={Thakur, Pooja and Soni, Bikash Kumar and Agarwal, Divyansh},
  booktitle={2022 2nd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)}, 
  title={Role of DNN in CyberSecurity: A Review}, 
  year={2022},
  volume={},
  number={},
  pages={947-950},
  abstract={The advent of the cyberspace had us living in the lap of luxury, connecting us to every part of the world. It has also become a dependable depot for storing all forms data. This has also led to an upsurge in the number of cyber threats in the past few years. Data breaches, Identity theft, Cyberterrorism and many other forms of threats have been affecting innumerable individuals and organizations. Cybercriminals have been constantly redefining their skills to pose even greater threat to the world. Cybersecurity experts are constantly trying to evade such failures; still the current security methods have been proven not to be much effective on many fronts. The addition of the potentials of Artificial Intelligence could serve as a boon for this purpose as this machine based form of intelligence can use its abilities to enhance different forms of pre-existing cybersecurity methods and probably also to create some new methods. Artificial Intelligence has been a revolutionary creation. The key intent of this paper is to examine various features of A.I. which can be blended with other security methods to create a more secure environment and make it a crucial weapon in our depository to act as a counter against the cyber threats.},
  keywords={Technological innovation;Social networking (online);Pandemics;Weapons;Neural networks;Multimedia Web sites;Organizations;Cyber-security;Cyber threats;Generative Adversarial Networks;DNN},
  doi={10.1109/ICACITE53722.2022.9823913},
  ISSN={},
  month={April},}@ARTICLE{10767756,
  author={Wu, Xingyu and Wu, Sheng-Hao and Wu, Jibin and Feng, Liang and Tan, Kay Chen},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Evolutionary Computation in the Era of Large Language Model: Survey and Roadmap}, 
  year={2025},
  volume={29},
  number={2},
  pages={534-554},
  abstract={Large language models (LLMs) have not only revolutionized natural language processing but also extended their prowess to various domains, marking a significant stride toward artificial general intelligence. The interplay between LLMs and evolutionary algorithms (EAs), despite differing in objectives and methodologies, share a common pursuit of applicability in complex problems. Meanwhile, EA can provide an optimization framework for LLM’s further enhancement under closed box settings, empowering LLM with flexible global search capacities. On the other hand, the abundant domain knowledge inherent in LLMs could enable EA to conduct more intelligent searches. Furthermore, the text processing and generative capabilities of LLMs would aid in deploying EAs across a wide range of tasks. Based on these complementary advantages, this article provides a thorough review and a forward-looking roadmap, categorizing the reciprocal inspiration into two main avenues: 1) LLM-enhanced EA and 2) EA-enhanced LLM. Some integrated synergy methods are further introduced to exemplify the complementarity between LLMs and EAs in diverse scenarios, including code generation, software engineering, neural architecture search, and various generation tasks. As the first comprehensive review focused on the EA research in the era of LLMs, this article provides a foundational stepping stone for understanding the collaborative potential of LLMs and EAs. The identified challenges and future directions offer guidance for researchers and practitioners to unlock the full potential of this innovative collaboration in propelling advancements in optimization and artificial intelligence. We have created a GitHub repository to index the relevant papers: https://github.com/wuxingyu-ai/LLM4EC.},
  keywords={Optimization;Closed box;Reviews;Evolutionary computation;Codes;Search problems;Collaboration;Surveys;Software engineering;Prompt engineering;Algorithm generation;evolutionary algorithm (EA);large language model (LLM);neural architecture search (NAS);optimization problem;prompt engineering},
  doi={10.1109/TEVC.2024.3506731},
  ISSN={1941-0026},
  month={April},}@ARTICLE{11005557,
  author={He, Yibo and Seng, Kah Phooi and Ang, Li-Minn},
  journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering}, 
  title={Collaborative AI Dysarthric Speech Recognition System With Data Augmentation Using Generative Adversarial Neural Network}, 
  year={2025},
  volume={33},
  number={},
  pages={2097-2111},
  abstract={This paper proposes a novel collaborative dysarthric speech recognition system designed to convert dysarthric speech into non-dysarthric speech to enhance the robustness of automatic speech recognition (ASR) systems fine-tuned for dysarthric speech. The system employs an innovative three-stage data augmentation framework: The first stage collaboratively augments the training dataset by generating static data and high-quality synthetic speech samples using a natural text-to-speech model (Tacotron2). The second stage applies a tempo perturbation technique that simulates the natural variation of speech rhythms by adjusting the playback tempo to improve the model’s adaptability to varying speech speeds. The third stage integrates the Inception-ResNet module with a temporal masking strategy using an enhanced CycleGAN-based conversion model to efficiently map conformal and non-conformal phonological features while preserving the overall speech structure and resolving temporal irregularities. Experiments conducted on the UASpeech corpus demonstrate a significant reduction in the word error rate (WER) compared to the baseline approach. Specifically, the three-stage data enhancement process achieves a reduction in the WER for the fine-tuned Wav2Vec2-XLSR and Whisper-Tiny models by 9.81% and 6.56%, respectively, with an average WER of 13.58% for the best performing system. These results highlight the effectiveness of the collaborative framework in improving the accuracy and naturalness of speech recognition for dysarthria, thereby offering individuals with dysarthria a more natural and intelligible communication experience.},
  keywords={Speech recognition;Data augmentation;Perturbation methods;Data models;Speech enhancement;Collaboration;Artificial intelligence;Training;Robustness;Generative adversarial networks;Collaborative AI;data augmentation;generative adversarial networks (GANs);deep learning;speech recognition;dysarthric speech},
  doi={10.1109/TNSRE.2025.3570383},
  ISSN={1558-0210},
  month={},}@INPROCEEDINGS{10472376,
  author={Chaddad, Ahmad},
  booktitle={2023 IEEE International Conference on E-health Networking, Application & Services (Healthcom)}, 
  title={Stability in Radiomics Analysis: Advancements and Challenges}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Radiomics has emerged as a rapidly expanding field within precision medicine, offering promising applications for cancer diagnosis, classification, prognosis, prediction, and evaluation. However, the clinical viability of radiomics depends on the stability of its features and models. This paper provides a comprehensive analysis of recent advances in the assessment of the stability, repeatability, and reproducibility of radiomics. It explores various methodologies that aim to improve these performance metrics while addressing the challenges and limitations encountered in clinical applications. The survey emphasizes the critical importance of establishing unified standards that can harmonize data acquisition and analysis practices across multiple institutions. By promoting standardized approaches, this seeks to enable the delivery of more reliable and stable radiomic data, thus improving the overall stability of models and facilitating widespread adoption in clinical settings. Additionally, this paper explores the integration of artificial intelligence (AI) and medical imaging, recognizing it as a potential avenue for fostering secure data sharing while protecting patient privacy. Using AI techniques, healthcare professionals can collaborate and share insights more efficiently, accelerating the progress of radiomics research and its translation into clinical practice. By addressing these critical aspects, our work contributes to the continuous development and broader implementation of radiomics within the field of precision medicine.},
  keywords={Analytical models;Precision medicine;Stability criteria;Feature extraction;Reproducibility of results;Reliability;Artificial intelligence;Radiomics;stability;medical imaging;AI},
  doi={10.1109/Healthcom56612.2023.10472376},
  ISSN={},
  month={Dec},}@INBOOK{10880572,
  author={RaviKrishna, Bhallamudi and Reddy, Madireddy Vijay and Soni, Mukesh and Byeon, Haewon and Pande, Sagar D. and Rusho, Maher A.},
  booktitle={Generative Artificial Intelligence for Biomedical and Smart Health Informatics}, 
  title={Deep Learning Model for Resolution Enhancement of Biomedical Images for Biometrics}, 
  year={2025},
  volume={},
  number={},
  pages={321-341},
  abstract={Summary <p>In the fields of precision biometrics and healthcare, high&#x2010;resolution biometric images play a crucial role as objective proof for accurate illness diagnosis. However, due to limitations in hardware resolution and scanning duration, real&#x2010;time acquisition of high&#x2010;resolution biomedical images poses challenges. Classic image super&#x2010;resolution reconstruction (SRR) algorithms suffer from difficulties in estimating model parameters, resulting in blurry and unrealistic reconstructed images, making them unsuitable for biomedical images. To address this issue, this chapter proposes a sparse&#x2010;coding nonlocal attention dual&#x2010;network. By employing sparse&#x2010;coding nonlocal attention mechanisms, Gaussian constraints, and parameter sharing strategies in the up&#x2010;sampling and down&#x2010;sampling dual branches, SRR of biomedical images is achieved. It has a high signal&#x2010;to&#x2010;noise ratio of 30.84&#x2009;dB and a structural identity of 0.914 for the rebuilt biomedical images. The research shows that the suggested method not only correctly reconstructs details at a high frequency in biomedical images but it also improves modeling efficiency with lightweight sparse&#x2010;coding nonlocal attention mechanisms. This makes it a useful method for reconstructing biomedical images at very high resolutions in biometrics.</p>},
  keywords={Feature extraction;Image reconstruction;Hafnium;Biological system modeling;Biometrics;Biomedical imaging;Data mining;Superresolution;Semantics;Training},
  doi={10.1002/9781394280735.ch16},
  ISSN={},
  publisher={IEEE},
  isbn={9781394280728},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10880572},}@INPROCEEDINGS{10935540,
  author={Zhang, Bingge and Shao, Xiuting and Song, Ziwen},
  booktitle={2024 14th International Conference on Information Technology in Medicine and Education (ITME)}, 
  title={Development and Classroom Application Research of Q&A System Based on LangChain + LLMs}, 
  year={2024},
  volume={},
  number={},
  pages={698-702},
  abstract={As China emphasizes intelligent education, the application of Artificial Intelligence (AI) in this field is becoming increasingly widespread. Q&A systems, as one of the key technologies of AI, are gradually being integrated into classroom teaching. The application plays a significant role in improving teaching quality and promoting personalized learning. However, the application process faces several problems, such as insufficient digital literacy, the inapplicability of traditional assessment methods, and the backwardness of educational concepts and methods. Moreover, in the era of information overload, the information provided by intelligent Q&A systems may be inaccurate. To address these problems, this study developed an intelligent Q&A system based on LangChain framework and LLMs. The system creates a web interface using Streamlit, integrates with LLMs, and enables generative Q&A based on the content of PDF documents. In addition, the study further explores the application of the system in classroom teaching, aiming to change teachers' mindset, promote teachers' teaching innovation, enhance students' personalized learning experience, alleviate the problem of digital literacy deficit, and promote equity and change in education. This study not only provides a new teaching aid for educators, but also provides a practical reference for the in-depth development of smart education.},
  keywords={Technological innovation;Education;Educational technology;Portable document format;Digital intelligence;Artificial intelligence;Information technology;Faces;component;LangChain;Digital literacy;LLMs;Q&A system},
  doi={10.1109/ITME63426.2024.00142},
  ISSN={2474-3828},
  month={Sep.},}@ARTICLE{11086491,
  author={Lu, Han and Xie, Yichen and Ding, Mingyu and Zhan, Wei and Yang, Xiaokang and Tomizuka, Masayoshi and Yan, Junchi},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Sel4FT: Annotation Selection for Pretraining-Finetuning With Distribution Shift}, 
  year={2025},
  volume={},
  number={},
  pages={1-16},
  abstract={The pretraining-finetuning paradigm has become dominant in computer vision, yet strategically exploiting limited annotation budgets during finetuning remains unexplored. We introduce active finetuning—a novel task for selecting the most informative samples to annotate within this paradigm. We propose Sel4FT, a unified annotation selection framework that optimizes a parametric model in continuous feature space to identify a subset preserving the entire pool's distribution while maintaining diversity. To address distribution shifts from data augmentation, we develop Sel4FT++ with augmentation-aware selection mechanisms. We theoretically prove our approach minimizes the Earth Mover's Distance between selected subset and full data pool. Our framework eliminates iterative retraining and annotation process during selection, providing an efficient solution for real-world deployment. Extensive experiments on image classification, long-tailed recognition, and semantic segmentation demonstrate state-of-the-art performance with over 100× speedup compared to existing methods. Code is released at https://github.com/yichen928/ActiveFT.},
  keywords={Training;Annotations;Data augmentation;Active learning;Optimization;Data models;Training data;Artificial intelligence;Parametric statistics;Heavily-tailed distribution;Active learning;continuous space optimization;pretraining-finetuning},
  doi={10.1109/TPAMI.2025.3591018},
  ISSN={1939-3539},
  month={},}@INPROCEEDINGS{10912343,
  author={Aryan, Prakash},
  booktitle={2024 IEEE Conference on Engineering Informatics (ICEI)}, 
  title={LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial Search for Adaptive Arguments}, 
  year={2024},
  volume={},
  number={},
  pages={1-11},
  abstract={This paper introduces DebateBrawl, an innovative AI-powered debate platform that integrates Large Language Models (LLMs), Genetic Algorithms (GA), and Adversarial Search (AS) to create an adaptive and engaging debating experience. DebateBrawl addresses the limitations of traditional LLMs in strategic planning by incorporating evolutionary optimization and game-theoretic techniques. The system demonstrates remarkable performance in generating coherent, contextually relevant arguments while adapting its strategy in real-time. Experimental results involving 23 debates show balanced outcomes between AI and human participants, with the AI system achieving an average score of ${2. 7 2}$ compared to the human average of ${2. 6 7}$ out of 10. User feedback indicates significant improvements in debating skills and a highly satisfactory learning experience, with 85% of users reporting improved debating abilities and ${7 8 \%}$ finding the AI opponent appropriately challenging. The system’s ability to maintain high factual accuracy (92% compared to ${7 8 \%}$ in human-only debates) while generating diverse arguments addresses critical concerns in AI-assisted discourse. DebateBrawl not only serves as an effective educational tool but also contributes to the broader goal of improving public discourse through AI-assisted argumentation. The paper discusses the ethical implications of AI in persuasive contexts and outlines the measures implemented to ensure responsible development and deployment of the system, including robust fact-checking mechanisms and transparency in decision-making processes.},
  keywords={Training;Ethics;Visualization;Large language models;Decision making;Strategic planning;Problem-solving;Artificial intelligence;Research and development;Genetic algorithms;Machine Learning;Deep Learning;Generative AI;Large Language Models;Genetic Algorithms;Adversarial Search},
  doi={10.1109/ICEI64305.2024.10912343},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10193894,
  author={Rădoi, Teodor-Cristian},
  booktitle={2023 15th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)}, 
  title={Artificial Intelligence in Data Analysis for Open-Source Investigations}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The developed OSINT platform organizes data hierarchically and integrates a GPT model for faster, easier large data processing. Users can interact with the GPT model through natural language communication with a virtual agent for data processing commands. Open source investigations face challenges like vast data volumes and incorrect information. To address these issues, a real-time data processing tool is needed. Our OSINT platform integrates a GPT model trained to learn from data, enhancing the efficiency of open source investigations. We assessed various natural language processing models, focusing on the benefits of pretraining, fine-tuning., and generative models in open source investigations. GPT models excel due to pretraining on extensive text data, allowing fine-tuning for specific tasks and domains., giving investigators a robust tool for text analysis. The generative nature of GPT models benefits OSINT investigations by producing human-like text for extracting insights and identifying patterns. Fine-tuning enables customization to specific domains or topics., increasing accuracy and reliability while reducing time and effort in data analysis. In conclusion., our OSINT platform presents an innovative solution for open source investigations by incorporating a GPT model for efficient information processing. The Davinci model by OpenAI outperforms other evaluated models., enhancing investigation efficiency and maintaining grammatical accuracy. This work highlights the significance of natural language processing models in open source investigations and paves the way for future research.},
  keywords={Analytical models;Data analysis;Data models;Natural language processing;Real-time systems;Reliability;Data mining;GPT;BERT;Artificial Intelligence;Open Source Intelligence;Information},
  doi={10.1109/ECAI58194.2023.10193894},
  ISSN={},
  month={June},}@INBOOK{11077880,
  author={},
  booktitle={Brain Networks in Neuroscience: Personalization Unveiled Via Artificial Intelligence}, 
  title={3 Understanding Brain Connectivity: From Synapses to Networks}, 
  year={2025},
  volume={},
  number={},
  pages={41-66},
  abstract={This book is an in-depth exploration of brain networks, providing a comprehensive understanding of their structures, functions, and implications for personalization through artificial intelligence. Readers will gain insights into the intricate workings of the brain, making this book an indispensable resource for those seeking a thorough grasp of neuroscience concepts. It offers the seamless integration of neuroscience principles with artificial intelligence applications. The book bridges these two domains, elucidating how advancements in AI draw inspiration from the complexities of the human brain. This interdisciplinary approach sets the book apart, offering readers a holistic view of cutting-edge technologies. Readers can expect practical applications and real-world case studies that illustrate the tangible benefits of the concepts discussed. From personalized healthcare solutions to adaptive learning systems, the book goes beyond theory, empowering readers to apply knowledge in diverse domains. This practical emphasis enhances the book&#x2019;s relevance for professionals and researchers alike. The inclusion of online enhancements, such as interactive visualizations, downloadable supplementary materials, and engaging video content, transforms the reading experience into an interactive learning journey. This added value distinguishes the book by providing readers with hands-on tools to deepen their understanding and apply newfound knowledge. This book doesn&#x2019;t just dwell on current technologies; it takes readers into the future by exploring emerging trends at the intersection of neuroscience and artificial intelligence. By delving into potential breakthroughs and innovations, the book equips readers with insights that are forward-thinking and relevant in an ever-evolving technological landscape.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770047357},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11077880},}@ARTICLE{10902408,
  author={Kim, Tae-Jung and Ha, Min-Ho and Arshad, Saba and Park, Tae-Hyoung},
  journal={IEEE Access}, 
  title={MIN: Moiré Inpainting Network With Position Adaptive Mask for 3-D Height Reconstruction}, 
  year={2025},
  volume={13},
  number={},
  pages={37501-37513},
  abstract={In the AI-driven computer vision industry, height measurement of Printed Circuit Board images typically relies on laser or Moiré methods. In this paper, we focus on the Moiré method, known for its high accuracy and fast measurement speed. However, when using Moiré method, shadows and light reflections are generated on Printed Circuit Board surface that cause significant errors in height measurement. To address this problem, we propose a Moiré Inpainting Network, which integrates the Moiré method with an image inpainting model architecture. Our approach leverages a Generative Adversarial Network to accurately identify and reconstruct shadow and reflection regions. The network takes 2D Printed Circuit Board Moiré images as input and outputs heights of Printed Circuit Board. We evaluate performance using Height Reconstruction Rate, Shadow Reconstruction Rate, and Reflection Reconstruction Rate, metrics we define in this paper. Comparative experiments show that our method outperforms state-of-the-art inpainting models for Moiré images, proving its effectiveness in computer vision applications. Moreover, we achieve a reasonable inference time, enabling real-time deployment in Printed Circuit Board manufacturing.},
  keywords={Image reconstruction;Printed circuits;Reflection;Generative adversarial networks;Context modeling;Height measurement;Integrated circuit modeling;Computational modeling;Solid modeling;Adaptive systems;Artificial intelligence;computer vision;generative adversarial networks;image inpainting;anomaly detection;Moiré;printed circuit board},
  doi={10.1109/ACCESS.2025.3545748},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11167566,
  author={Navaneeth, P G and Kar, Mithun Kumar},
  booktitle={2025 5th International Conference on Intelligent Technologies (CONIT)}, 
  title={A Novel CSRU-GAN Framework for Polyp Segmentation}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Polyp segmentation plays a crucial role in the early detection and diagnosis of fatal diseases such as colorectal cancer during colonoscopy procedures. Timely diagnosis of such catastrophic diseases could assist medical experts and potentially avert impending crisis Over the years, image segmentation in biomedical applications has been undergoing a massive surge especially with the introduction of the U-Net architecture in 2015 and the FCN (Fully Convolutional Network). This architecture went on to become a traditional thresholding and edge-detection technique. Several years hence, more sophisticated deep learning models of the U-Net such as Attention U-Net and ResU-Net were introduced. These architectures have significantly enhanced segmentation accuracy by capturing complex spatial hierarchies. However, conventional encoder-decoder frameworks still face limitations in capturing long-range dependencies and generating fine-grained boundaries in challenging scenarios. In order to tackle the aforementioned issues, several GAN (Generative Adversarial Network) models were introduced to enhance the quality of segmentation masks. These architectures massively outperformed the conventional architectures in terms of dice and IOU scores which are touted to be the primordial metrics designed to evaluate the authenticity of the masks generated by the models. This paper attempts to propose a new Conditional Generative Adversarial Network model called CSRU-GAN (Conditional SWIN ResU-Net Generative Adversarial Network) which intends to use the ability of the residual connections inspired from the ResNet architecture to clip the vanishing gradient problem, the ability of SWIN transformers to capture hierarchical features by making use of shifted windows and attention mechanism. Lastly, it makes use of the adversarial training of the CGAN (Conditional Generative Adversarial Network) while also taking into account the ground truth information. The proposed model when tested on the CVC database performed admirably in terms of the Dice and IOU (Intersection Over Union) scores which were found out to be $\mathbf{9 1. 2 1 \%}$ and $\mathbf{8 3. 2 9 \%}$ respectively.},
  keywords={Training;Deep learning;Representation learning;Image segmentation;Accuracy;Colonoscopy;Generative adversarial networks;Transformers;Generators;Surges;U-Net;ResNet;ResU-Net;SWIN transformers;GAN;CVC dataset;dice score;IOU},
  doi={10.1109/CONIT65521.2025.11167566},
  ISSN={},
  month={June},}@INPROCEEDINGS{10890943,
  author={Du, Chenpeng and Guo, Yiwei and Wang, Hankun and Yang, Yifan and Niu, Zhikang and Wang, Shuai and Zhang, Hui and Chen, Xie and Yu, Kai},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={VALL-T: Decoder-Only Generative Transducer for Robust and Decoding-Controllable Text-to-Speech}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Recent TTS models with decoder-only Transformer architecture, such as SPEAR-TTS and VALL-E, achieve impressive naturalness and demonstrate the ability for zero-shot adaptation given a speech prompt. However, such decoder-only TTS models lack monotonic alignment constraints, sometimes leading to hallucination issues such as mispronunciation, word skipping and repeating. To address this limitation, we propose VALL-T, a generative Transducer model that introduces shifting relative position embeddings for input phoneme sequence, explicitly indicating the monotonic generation process while maintaining the architecture of decoder-only Transformer. Consequently, VALL-T retains the capability of prompt-based zero-shot adaptation and demonstrates better robustness against hallucinations with a relative reduction of 28.3% in the word error rate. The audio samples are available at https://cpdu.github.io/vallt.},
  keywords={Training;Adaptation models;Transducers;Error analysis;Posterior probability;Signal processing;Transformers;Robustness;Text to speech;Speech processing;transducer;text-to-speech;decoder-only;hallucination},
  doi={10.1109/ICASSP49660.2025.10890943},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10739326,
  author={Pawar, Pratik and Dube, Raghav and Joshi, Amogh and Gulhane, Zinee and Patil, Ratna},
  booktitle={2024 International Conference on Electrical Electronics and Computing Technologies (ICEECT)}, 
  title={Automated Generation and Evaluation of MultipleChoice Quizzes using Langchain and Gemini LLM}, 
  year={2024},
  volume={1},
  number={},
  pages={1-7},
  abstract={The research study investigates the use of cutting-edge technologies like Langchain and Gemini AI for the automated creation and assessment of multiple-choice questions (MCQs). Although producing multiple-choice questions (MCQs) has traditionally been done by hand and required a lot of work, advances in artificial intelligence (AI) and natural language processing (NLP) have opened up new possibilities. The creation and implementation of an MCQ generator—which uses Gemini AI to generate MCQs and Langchain for rapid engineering are covered in this paper. Customizing prompts for prompt engineering, chaining prompts with the Gemini AI model, and utilizing OpenAI's GPT-3.5 and multiple Language Learning Models (LLMs) to assess the created MCQs are the steps in the process. The study intends to assess these models' efficiency in handling intricate queries, producing appropriate answers, and examining the caliber of the MCQs that are produced.},
  keywords={Measurement;Computers;Analytical models;Computational modeling;Educational technology;Natural language processing;Generators;Prompt engineering;mcq generator;large language models;natural language processing;google gemini pro;langchain;generative ai},
  doi={10.1109/ICEECT61758.2024.10739326},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10780708,
  author={Shi, Jiayi and E, Haihong and Liu, Jianhua and Hu, Tianyi and Qiao, Xiaodong and Ding, Junpeng and Huang, Jiayu},
  booktitle={2024 11th International Conference on Behavioural and Social Computing (BESC)}, 
  title={Hybrid Dual-Channel Input Image Tampering Detection for Scientific Papers}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={With the development of science and technology, the application of digital image processing and artificial intelligence technology is becoming more and more widespread, which makes it easier and more difficult to detect forged academic images, and academic images have become a high incidence of scientific and technological journal paper forgery. To ensure the authenticity of academic images and scientific reproducibility of experiments, we developed a network called MultiScopeNet. It combines RGB and DCT streams, performs multi-resolution fusion at each layer, and can comprehensively analyze spatial and frequency domain features of images. We also created a new dataset based on an existing tamper detection dataset by applying an image complementation model to train and validate our model against academic misconduct of tampering using generatively forged images. MultiScopeNet significantly outperforms existing state-of-the-art models in dealing with image tampering at different resolutions and sizes.},
  keywords={Training;Visualization;Frequency-domain analysis;Transform coding;Transforms;Reproducibility of results;Discrete cosine transforms;Detection algorithms;Spatial resolution;Streams;image tampering;generative image tampering dataset;image detection for scientific papers},
  doi={10.1109/BESC64747.2024.10780708},
  ISSN={2689-8284},
  month={Aug},}@INPROCEEDINGS{11150277,
  author={Zhang, Meng and Chen, Yihang and Wang, Xue and Cui, Tong and Ren, Yan and Chen, Xinyu},
  booktitle={2025 40th Youth Academic Annual Conference of Chinese Association of Automation (YAC)}, 
  title={A Generative Virtual Leader Network Framework for Enhanced Synchronization and Disturbance Resistance in Multi-Agent Systems}, 
  year={2025},
  volume={},
  number={},
  pages={3087-3092},
  abstract={This paper introduces a novel control method for multi-agent systems by integrating a Generative Virtual Leader Network (GVLN) to improve synchronization speed and disturbance resistance. Unlike traditional single-layer complex network-based methods, the proposed approach leverages a multi-layer synchronization framework, where the GVLN provides auxiliary control to the follower network. Simulation results demonstrate that this method significantly reduces synchronization time and system oscillations while enhancing robustness against disturbances. Experiments on chaotic systems confirm the superiority of the proposed approach in achieving faster state coordination and improved stability. These findings offer new insights into complex network synchronization and practical multi-agent system control.},
  keywords={Resistance;Simulation;Complex networks;Nonhomogeneous media;Control systems;Robustness;Stability analysis;Synchronization;Oscillators;Multi-agent systems;Complex Network;Multi-Agent;State Following;Virtual Leader Network},
  doi={10.1109/YAC66630.2025.11150277},
  ISSN={2837-8601},
  month={May},}@INPROCEEDINGS{9403820,
  author={Yu, Qiu and Malaeb, Jamal and Ma, Wenjun},
  booktitle={2020 International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE)}, 
  title={Architectural Facade Recognition and Generation through Generative Adversarial Networks}, 
  year={2020},
  volume={},
  number={},
  pages={310-316},
  abstract={With the development of artificial intelligence technology, the ideas of machine learning have been introduced into the field of design in recent years. The research methods of “AI + Architecture” have brought new ideas for solving traditional problems. Generative Adversarial Network (GAN) is a machine learning model for image generation. Pix2pix is an improved version of GAN, which is specially designed to learn and generate pairs of image data with similar characteristics. In this study, Pix2pix is applied to the recognition and generation of building facade. The purpose is to explore the feasibility of using image generation technology to achieve rapid recognition and generation of building facade based on pix2pix. This paper also discusses the application scenarios of this technology. The existing building façade datasets and the self-made Chinese traditional building datasets are used to test and verify that pix2pix under different types of datasets can nicely identify and generate facade images. Then we summarize a set of working methods based on GAN to realize the overall or local reconstruction design of the facade, so as to provide new ideas for the improvement of the efficiency of related industries and the expansion of teaching tools.},
  keywords={Industries;Image recognition;Image synthesis;Buildings;Education;Machine learning;Tools;facade;GAN;image recognition;image generation},
  doi={10.1109/ICBASE51474.2020.00072},
  ISSN={},
  month={Oct},}@BOOK{10163173,
  author={Sawarkar, Kunal},
  booktitle={Deep Learning with PyTorch Lightning: Swiftly build high-performance Artificial Intelligence (AI) models using Python},
  year={2022},
  volume={},
  number={},
  pages={},
  abstract={Build, train, and deploy deep learning models quickly and accurately to improve your productivity using PyTorch Lightning WrapperKey FeaturesBecome well-versed with PyTorch Lightning and learn how to implement it in various applicationsSpeed up your research using PyTorch Lightning by creating new loss functions, and architecturesTrain and build new DL applications for images, audio, video, structured and unstructured dataBook DescriptionBuilding and implementing deep learning (DL) is becoming a key skill for those who want to be at the forefront of progress.But with so much information and complex study materials out there, getting started with DL can feel quite overwhelming. Written by an AI thought leader, Deep Learning with PyTorch Lightning helps researchers build their first DL models quickly and easily without getting stuck on the complexities. With its help, you’ll be able to maximize productivity for DL projects while ensuring full flexibility – from model formulation to implementation. Throughout this book, you’ll learn how to configure PyTorch Lightning on a cloud platform, understand the architectural components, and explore how they are configured to build various industry solutions. You’ll build a neural network architecture, deploy an application from scratch, and see how you can expand it based on your specific needs, beyond what the framework can provide. In the later chapters, you’ll also learn how to implement capabilities to build and train various models like Convolutional Neural Nets (CNN), Natural Language Processing (NLP), Time Series, Self-Supervised Learning, Semi-Supervised Learning, Generative Adversarial Network (GAN) using PyTorch Lightning. By the end of this book, you’ll be able to build and deploy DL models with confidence.What you will learnCustomize models that are built for different datasets, model architecturesUnderstand a variety of DL models from image recognition, NLP to time seriesCreate advanced DL models to write poems (Semi-Supervised) or create fake images (GAN)Learn to train on unlabelled images using Self-Supervised Contrastive LearningLearn to use pre-trained models using transfer learning to save computeMake use of out-of-the-box SOTA model architectures using Lightning FlashExplore techniques for model deployment & scoring using ONNX formatRun and tune DL models in a multi-GPU environment using mixed-mode precisionsWho this book is forIf you’re a data scientist curious about deep learning but don't know where to start or feel intimidated by the complexities of large neural networks, then this book is for you. Expert data scientists making the transition from other DL frameworks to PyTorch will also find plenty of useful information in this book, as will researchers interested in using PyTorch Lightning as a reference guide. To get started, you’ll need a solid grasp on Python; the book will teach you the rest},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781800569270},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10163173},}@INPROCEEDINGS{10276257,
  author={Gupta, Richa and Kumar Shukla, Surendra and Tripathi, Vikas},
  booktitle={2023 4th International Conference on Smart Electronics and Communication (ICOSEC)}, 
  title={New Deep Learning Models for Medical Imaging: Deep Belief Network, GAN, Autoencoder}, 
  year={2023},
  volume={},
  number={},
  pages={907-913},
  abstract={Deep learning (DL) is being utilized in different clinical imaging process and has accomplished promising results. Nonetheless, incorporating DL in clinical imaging also presents significant challenges. This research study presents the characteristics of clinical imaging that features both clinical requirements and specialized challenges and depicts how the patterns in DL are resolving these issues. This study presents a few contextual investigations that are commonly found, including advanced pathology and respiratory, chest, brain, and ophthalmology imaging. Rather than presenting a thorough writing review, this study highlights some notable exploration aspects associated with the contextual analysis. This study is concluded with a discussion and stating some possible future research directions.},
  keywords={Deep learning;Pathology;Image resolution;Writing;Generative adversarial networks;Brain modeling;Ophthalmology;Deep Learning;Medical images;Deep belief network (DBN);Generative Adversarial Network GAN;Autoencoder},
  doi={10.1109/ICOSEC58147.2023.10276257},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11136724,
  author={Jahani, Masoumeh and Baruah, Bidyut and Ward, Tony},
  booktitle={2025 34th Annual Conference of the European Association for Education in Electrical and Information Engineering (EAEEIE)}, 
  title={Exploring Ethical Awareness and Learning Impact: A Study on the Use of ChatGPT and Generative AI in Higher Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={The rapid adoption of generative AI (GenAI) tools like ChatGPT is reshaping higher education by transforming how students access information, engage with content, and develop academic skills. These tools offer personalised feedback, encourage self-directed learning, and support knowledge construction. However, their increasing use also raises concerns about academic integrity, ethical awareness, and potential impacts on critical thinking.This study examines the use of GenAI tools among postgraduate students in the Engineering Management programme at the University of York. Employing a mixed-methods approach, data were collected via a survey of 42 students and semi-structured interviews with 15 academic staff. The research explores student motivations, ethical perceptions, and the influence of GenAI on academic development.Findings indicate that over 90% of students use GenAI primarily for formative tasks such as research, idea generation, and writing support, driven by goals of efficiency, conceptual understanding, and overcoming language barriers. While many perceive GenAI as empowering independent learning, concerns about over-reliance and ethical implications persist. Institutional support and policy clarity were found lacking, highlighting the need for inclusive digital literacy training and clear guidelines.Academic staff stress the importance of aligning AI use with learning objectives and enhancing faculty training. To maximise benefits while preserving academic integrity, a balanced, human-centred approach to GenAI integration is essential, combining innovation with ethical responsibility.},
  keywords={Training;Surveys;Ethics;Technological innovation;Generative AI;Learning (artificial intelligence);Writing;Chatbots;Digital intelligence;Interviews;Artificial Intelligence;GenAI;AI-based learning;ChatGPT;Higher Education;Engineering Education;Ethical Awareness;AI in Assessment;Academic Integrity},
  doi={10.1109/EAEEIE65428.2025.11136724},
  ISSN={2472-7687},
  month={June},}@INPROCEEDINGS{10823299,
  author={G, Kaleeswari and R, Sundarrajan},
  booktitle={2024 International Conference on IoT Based Control Networks and Intelligent Systems (ICICNIS)}, 
  title={A Comprehensive Survey on Phytopathogen Surveillance with Modern Artificial Intelligence Practices}, 
  year={2024},
  volume={},
  number={},
  pages={1491-1496},
  abstract={The most important aspect of modern agriculture is the detection of plant diseases with the goal of improving crop quality and output. This survey paper investigates modern approaches of deep learning algorithms, Explainable AI and Federated Learning to plant disease diagnosis. The background and broadening of plant disease detection are briefly reviewed at the outset of the study, with a focus on the importance of precise and effective identification techniques. The multivariate normal DL neural network (MNDLNN) classifier and Customized CNN are the most robust feature extraction and classification techniques among the examined technologies. Using Higher-Order Whitened Singular Value Decomposition (HOWSVD), complex data is processed in a way that highlights distinct patterns and features for easy data classification and also increases accuracy. The E-GreenNet generates disease classification features based on a MobileNetV3. The ResNet9 and Improved Vision Transformer models perform better when processing complicated visual data. Spectral Generative Adversarial Neural Network (DSGAN2) and Lite Multikernel Depthwise Convolutions architecture are suitable for real-time applications because they provide promising results with less computational overhead. These findings' implications point to a possible move toward disease detection systems that are easier to use and more effective, which would improve crop management and food security. The development of more affordable solutions for small scale farmers, the integration of Embedded systems for real-time monitoring, and the improvement of these models for increased precision are some future directions. This survey highlights the transformative potential of combining deep learning with other techniques like Federated Learning in advancing agricultural practices.},
  keywords={Surveys;Deep learning;Plant diseases;Visualization;Federated learning;Surveillance;Neural networks;Crops;Transformers;Real-time systems;Deep learning;Federated learning;Explainable AI;Real-time detection},
  doi={10.1109/ICICNIS64247.2024.10823299},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10791156,
  author={Sugiantoro, Bambang},
  booktitle={2024 IEEE International Symposium on Consumer Technology (ISCT)}, 
  title={Deepfake Face Images: Explainable Detection using Deep Neural Networks and Class Activation Mapping}, 
  year={2024},
  volume={},
  number={},
  pages={86-90},
  abstract={Our study presents an improved method for detecting deepfake content using advanced explainable artificial intelligence (XAI) techniques. We focused on enhancing deep neural networks, specifically Residual Network (ResNet) models such as ResNet50V2, ResNet101V2, and ResNet152V2, with Gradient-weighted Class Activation Mapping (Grad-CAM) to more accurately differentiate between real and artificial faces. The addition of XAI principles through Grad-CAM not only increases the detection accuracy but also makes the decision-making process of the models transparent, fostering trust, and making the technology more accessible for real-world applications. We evaluated our models using the FFHQ dataset, which comprises a vast array of real and fake facial images. The results demonstrated significant improvements in both precision and recall rates across all models with the integration of Grad-CAM. Specifically, the enhanced ResNet50V2 model achieved a precision of 87% for fake images and 94% for real images, with recall rates of 94% for fake images and 86% for real images, resulting in f1 scores of 90% for both classes. The ResNet101V2 and ResNet152V2 models with Grad-CAM also showed notable improvements, with the ResNet101V2 + Grad-CAM model reaching a precision of 87% for fake and 96% for real, and the ResNet152V2 + Grad-CAM model achieving a precision of 90% for fake and 92% for real, both with high recall and f1 scores, highlighting the precision and reliability of the method. Our approach not only addresses the challenge of detecting deepfakes with high accuracy but also balances the model complexity with computational efficiency. Despite some limitations, such as data set biases and occasional misclassifications, our method significantly advances digital media authentication and shows promising prospects for identity and security verification. Future work will focus on refining these models, emphasizing the importance of XAI, and exploring their application to broader image-classification challenges to strengthen defenses against the evolving threat of deepfake technology.},
  keywords={Training;Deepfakes;Accuracy;Explainable AI;Computational modeling;Decision making;Media;Complexity theory;Faces;Testing;Deepfake;Detection;Explainable Artificial Intelligence;Grad-CAM;ResNet},
  doi={10.1109/ISCT62336.2024.10791156},
  ISSN={2159-1423},
  month={Aug},}@INPROCEEDINGS{10932320,
  author={Gokhale, Varada and Naik, Anjali},
  booktitle={2025 1st International Conference on AIML-Applications for Engineering & Technology (ICAET)}, 
  title={Credit Card Fraud Detection using Machine Learning Models and Increasing Explainability using Explainable AI Methods}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Intentional deception and exploitation through credit card fraud remain prevalent in the banking industry, as fraudsters continue to obtain credit card details without authorization. Recent years have seen a significant increase in the number of credit card accounts and expenditure, accompanied by a noticeable rise in fraud instances. For fraud detection, the financial sector has employed various machine learning (ML) models and artificial intelligence (AI) techniques. This research follows a systematic methodology to identify and elucidate instances of credit card fraud. A Credit Card Fraud dataset was used. Machine learning models, including Explainable Boosting Machine (EBM), Decision Tree (DT), Random Forest (RF), XGBoost (XGB) and an Artificial Neural Network (ANN) were instantiated. Explainable AI models such as SHAP, LIME, and EBM were applied to the outputs of these ML models to enhance the explainability. The results indicated that the EBM and Decision Tree models achieved the highest accuracy at 96.35%.},
  keywords={Radio frequency;Accuracy;Explainable AI;Artificial neural networks;Predictive models;Credit cards;Fraud;Decision trees;Stakeholders;Random forests;fraud;ML;XAI;explain;accuracy},
  doi={10.1109/ICAET63349.2025.10932320},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9990245,
  author={Abduljawad, Mohamed and Alsalmani, Abdullah},
  booktitle={2022 International Conference on Electrical and Computing Technologies and Applications (ICECTA)}, 
  title={Towards Creating Exotic Remote Sensing Datasets using Image Generating AI}, 
  year={2022},
  volume={},
  number={},
  pages={84-88},
  abstract={Over the past few years, neural networks have been used more often to solve long lasting challenges. Remote sensing and data classification were some of the fields that have widely depended on this continuously developing technology. In this context, remote sensing data related to places with harsh conditions have been missing, especially the ones related to SAR imagery. Such conditions include deserts, glaciers, and icebergs, where lots of people have lost their lives in, due to the lack of efficient methods of searching and finding these people in such critical timing. Training AI models on similar scenarios to fasten the process can be beneficial, but the lack of data is an obstacle in the way of development such models. In this paper, we propose using image generating AI systems to generate remote sensing datasets that are difficult to collect using normal imagery, thus creating more efficient image classification systems that can be used in scenarios such as locating missing people. Several AI models are discussed in this paper: Dall-E 2, Stable Diffusion and Midjourney, where they are found to vary a lot in terms of the generated images, that could be because of the architecture of the model, and the data they trained on. The overall performance of the AI models is promising. Dall-E 2 performed the best in our tests, followed by Stable Diffusion, and finally Midjourney. This research could open the door to using such models in generating lots of datasets, which might solve crucial problems.},
  keywords={Training;Satellites;Neural networks;Computer architecture;Data models;Radar polarimetry;Timing;Generative Adversarial Networks;Diffusion Models;Remote Sensing;Datasets},
  doi={10.1109/ICECTA57148.2022.9990245},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9970645,
  author={Ma, Keyi and Wang, Xiaohong},
  booktitle={2022 International Conference on Cyber-Physical Social Intelligence (ICCSI)}, 
  title={Research on Cartoon Face Generation Based on CycleGAN Assisted with Facial Landmarks}, 
  year={2022},
  volume={},
  number={},
  pages={356-361},
  abstract={Turn real faces into cartoon faces is a topic of style transfer, and style transfer is a hot topic in the application of generative adversarial networks in image. CycleGAN is one of generative adversarial networks. It has obvious universal applicability, and has a good transformation effect on various types of style transfer. But to the facial style transfer, it only focuses on the transformation of the whole face, and it is not ideal for the transformation of the details of the facial features. How can this situation be improved? In this paper, we use facial landmarks to assist the transformation of facial features. In the beginning, we use stacked hourglass networks to detection and capture landmarks of real faces. And then, use them to assist cartoon faces generation. In view of the fact that the hourglass network has its own advantages in feature extraction, we use it to replace the generator structure of the original CycleGAN for transformation. And in order to avoid the Checkerboard Artifacts and ensure the quality of image generation, we use bilinear interpolation in the upsampling part of the generator to replace the deconvolution of the original generator and the nearest interpolation of the hourglass network. Experiments show that these practices have good results in optimizing conversion performance and improving image quality.},
  keywords={Image quality;Interpolation;Deconvolution;Image synthesis;Generative adversarial networks;Feature extraction;Generators;style transfer;CycleGAN;stacked hourglass networks facial landmark},
  doi={10.1109/ICCSI55536.2022.9970645},
  ISSN={},
  month={Nov},}@ARTICLE{10599257,
  author={Saadatinia, Mehrshad and Salimi-Badr, Armin},
  journal={IEEE Access}, 
  title={An Explainable Deep Learning-Based Method for Schizophrenia Diagnosis Using Generative Data-Augmentation}, 
  year={2024},
  volume={12},
  number={},
  pages={98379-98392},
  abstract={Schizophrenia is an example of a rare mental disorder that is challenging to diagnose using conventional methods. Deep learning methods have been extensively employed to aid in the diagnosis of schizophrenia. However, their efficacy relies heavily on data quantity, and their black-box nature raises trust concerns, especially in medical diagnosis contexts. In this study, we leverage a deep learning-based method for the automatic diagnosis of schizophrenia using EEG brain recordings. This approach utilizes generative data augmentation, a powerful technique that enhances the accuracy of the diagnosis. Additionally, our study provides a framework to use when dealing with the challenge of limited training data for the diagnosis of other potential rare mental disorders. To enable the utilization of time-frequency features, spectrograms were extracted from the raw signals. After exploring several neural network architectural setups, a proper convolutional neural network (CNN) was used for the initial diagnosis. Subsequently, using Wasserstein GAN with Gradient Penalty (WGAN-GP) and Variational Autoencoder (VAE), two different synthetic datasets were generated in order to augment the initial dataset and address the over-fitting issue. The augmented dataset using VAE achieved a 3.0% improvement in accuracy, reaching 99.0%, and also demonstrated faster convergence. Finally, we addressed the lack of trust in black-box models using the Local Interpretable Model-agnostic Explanations (LIME) algorithm to determine the most important superpixels (frequencies) in the diagnosis process.},
  keywords={Mental disorders;Brain modeling;Electroencephalography;Accuracy;Convolutional neural networks;Feature extraction;Data models;Medical diagnosis;Data augmentation;Encoders;Medical diagnosis;schizophrenia;generative data augmentation;variational autoencoder;generative adversarial networks;explainable artificial intelligence (XAI)},
  doi={10.1109/ACCESS.2024.3428847},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9547887,
  author={Liang, Xixi and Zhao, Erdun and Li, Ting and Lin, Zhuocheng},
  booktitle={AIIPCC 2021; The Second International Conference on Artificial Intelligence, Information Processing and Cloud Computing}, 
  title={A coil counting model based on full convolution regression neural networks}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper studies the visual counting problem of the number of winding turns on the micro terminal. Its main task is to distinguish the counting of cross coils and standard coils. Relying on manual counting is not only inefficient but also has large error. In order to improve the work efficiency of product detection, deep learning technology is used to realize automatic counting. The common deep learning counting model is realized by convolution neural network classification, but it can only recognize the fixed number of turns. A full revolution region neural network (FCRN) model is then proposed to solve the winding problem on micro terminal. The model consists of three parts: (a) the Faster RCNN to detect coils from scene images; (b) a FCRN network including a full convolution network (FCN) followed by two ASPP pooling to extract the coil features, and two prediction branches, i.e. a semantic segmentation branch and a regression counting branch to predict the coil segmentation images and to predict the coil turns number, respectively; and, (c) the horizontal projection algorithm to analyse whether the prediction images represent cross coil. The experimental results show that, compared with the counting model directly using CNN classification, the FCRN counting model works well in the environment with fewer samples, and can identify cross coil at the same time of counting, which improves its adaptability and accuracy. Thus, it can improve the detection rate of products.},
  keywords={},
  doi={},
  ISSN={},
  month={June},}@ARTICLE{10812716,
  author={Cheamsiri, Wannisa and Jitpattanakul, Anuchit and Muneesawang, Paisarn and Wongpatikaseree, Konlakorn and Hnoohom, Narit},
  journal={IEEE Access}, 
  title={Enhancing Quality Control: A Study on AI and Human Performance in Flip Chip Defect Detection}, 
  year={2024},
  volume={12},
  number={},
  pages={197840-197855},
  abstract={This study introduces an advanced defect inspection model that utilizes object detection techniques to identify defects in Flip Chip cross-section images. The model serves as a valuable tool for failure analysis (FA) engineers working with Chip-on-Wafer (CoW) products by enhancing inspection precision and accuracy, save time and costs, reduce human error, and ensure reliability. The dataset, provided by an electronics manufacturing service provider in Thailand, and is divided into four categories: good bump, head-in-pillow (HIP) defect, non-wetting defect, and solder void defect. High-resolution images were captured with an Olympus BX53M microscope at  $1000\times $  magnification, focusing on a 50-micrometer copper pillar (CP) bump diameter. To address dataset imbalances, this research applies image augmentation techniques and generative artificial intelligence (AI) to synthesize additional HIP defect images. The experimental setup involved seven image datasets used to train multiple object detection models, including YOLOv5, YOLOv6, YOLOv7, and YOLOv8, resulting in a total of 26 trained models. Results show that YOLOv5 and YOLOv8 required the shortest training time, clocking in at 0.86 hours (51 minutes 48 seconds), making them the most computationally efficient models. F1-score evaluations indicated that YOLOv5 achieved scores ranging from 0.948 to 0.981, outperforming the other models. Additionally, testing with a panel of five experts revealed that the model achieved higher accuracy and precision than experts with over 20 years of experience.},
  keywords={Flip-chip devices;Defect detection;Accuracy;Inspection;Cows;X-ray imaging;Hip;YOLO;Three-dimensional displays;Deep learning;Flip chip defect;cross section;generative artificial intelligence;deep learning;object detection;YOLO models},
  doi={10.1109/ACCESS.2024.3521459},
  ISSN={2169-3536},
  month={},}@INBOOK{10880591,
  author={Maiti, Niladri and Chawla, Riddhi and Quraishi, Aadam and Soni, Mukesh and Rusho, Maher Ali and Pande, Sagar Dhanraj},
  booktitle={Generative Artificial Intelligence for Biomedical and Smart Health Informatics}, 
  title={Generative Intelligence&#x2010;Based Federated Learning Model for Brain Tumor Classification in Smart Health}, 
  year={2025},
  volume={},
  number={},
  pages={435-453},
  abstract={Summary <p>This study presents a sophisticated ResNet&#x2010;10 convolutional neural network model that is specifically developed to address the classification difficulties of brain computed tomography (CT) images, particularly those associated with Alzheimer's disease (AD), brain lesions (including tumors), and normal aging in smart healthcare. The model employs a residual hybrid attention module (RHAM) to enhance the specificity of features, enabling it to effectively collect both spatial information and relevant content within brain tissue. These enhancements enhance the model's efficacy in both traditional categorization and brain tumor diagnosis through the utilization of associative learning and interpretable generative artificial intelligence (GAI). To streamline the intricacy of the design, a global media collecting layer is implemented, and a dropout mechanism is incorporated in the subsequent levels to prevent unnecessary installation. Throughout training, this model makes use of label smoothing entropy loss functions to enhance its capacity for generalization, even with a limited quantity of training samples. The advanced ResNet&#x2010;10 network model has been extensively tested and proven effective on brain CT scans, obtaining an incredible 97.47% classification accuracy. The demonstration emphasized its potential application in broader domains such as GAI&#x2010;based collaborative learning and brain tumor detection.</p>},
  keywords={Brain modeling;Computed tomography;Lesions;Accuracy;Visualization;Feature extraction;Brain tumors;Analytical models;Visual systems;Stacking},
  doi={10.1002/9781394280735.ch22},
  ISSN={},
  publisher={IEEE},
  isbn={9781394280728},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10880591},}@ARTICLE{10414101,
  author={Khan, Faiza Babar and Durad, Muhammad Hanif and Khan, Asifullah and Khan, Farrukh Aslam and Rizwan, Muhammad and Ali, Aftab},
  journal={IEEE Access}, 
  title={Design and Performance Analysis of an Anti-Malware System Based on Generative Adversarial Network Framework}, 
  year={2024},
  volume={12},
  number={},
  pages={27683-27708},
  abstract={The cyber realm is overwhelmed with dynamic malware that promptly penetrates all defense mechanisms, operates unapprehended to the user, and covertly causes damage to sensitive data. The current generation of cyber users is being victimized by the interpolation of malware each day due to the pervasive progression of Internet connectivity. Malware is dispersed to infiltrate the security, privacy, and integrity of the system. Conventional malware detection systems do not have the potential to detect novel malware without the accessibility of their signatures, which gives rise to a high False Negative Rate (FNR). Previously, there were numerous attempts to address the issue of malware detection, but none of them effectively combined the capabilities of signature-based and machine learning-based detection engines. To address this issue, we have developed an integrated Anti-Malware System (AMS) architecture that incorporates both conventional signature-based detection and AI-based detection modules. Our approach employs a Generative Adversarial Network (GAN) based Malware Classifier Optimizer (MCOGAN) framework, which can optimize a malware classifier. This framework utilizes GANs to generate fabricated benign files that can be used to train external discriminators for optimization purposes. We describe our proposed framework and anti-malware system in detail to provide a better understanding of how a malware detection system works. We evaluate our approach using the Figshare dataset and state-of-the-art models as discriminators. Our results showcase enhanced malware detection performance, yielding a 10% performance boost, thus affirming the efficacy of our approach compared to existing models.},
  keywords={Malware;Generative adversarial networks;Support vector machines;Machine learning;Generators;Terminology;Training;Performance evaluation;Anti-malware system;generative adversarial networks;malware sandboxes;malware;unpacker;performance},
  doi={10.1109/ACCESS.2024.3358454},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10544960,
  author={Revathi, B. and Usharani, C. and Kezial Elizabeth, S. K. and P, Nagaraj and Nithya, D.},
  booktitle={2024 International Conference on Inventive Computation Technologies (ICICT)}, 
  title={Deep Learning Classification Techniques on Detecting Diabetic Retinopathy Dataset}, 
  year={2024},
  volume={},
  number={},
  pages={663-668},
  abstract={Deep learning algorithms can summarize images to understand how to carry out necessary tasks. The purpose of this study is to compare several deep learning methods. Both experience-based and explanation-based learning are possible in deep learning. The most widely utilized algorithms, such as Convolutional Neural Networks (CNN), Multilayer Perceptron (MLP), Generative Adversarial Networks (GAN), Radial Basis Function Networks (RBFN), and Deep Belief Networks (DBN), and the Diabetic Retinopathy dataset is utilized in this study to evaluate the effectiveness of the algorithms. A comparative study of the classifiers reveals that CNN performs more accurately than the other approaches.},
  keywords={Deep learning;Diabetic retinopathy;Reviews;Radial basis function networks;Multilayer perceptrons;Generative adversarial networks;Classification algorithms;Diabetic Retinopathy;Deep learning;Preprocessing;Classification;Data Validation},
  doi={10.1109/ICICT60155.2024.10544960},
  ISSN={2767-7788},
  month={April},}@INPROCEEDINGS{10730665,
  author={Razali, Samirah},
  booktitle={2024 5th International Conference on Artificial Intelligence and Data Sciences (AiDAS)}, 
  title={Lecturers' and Students' Perspectives on Using Chat-GPT in Academics for Creative Problem Solving: A Dilemma or an Opportunity for Improvement?}, 
  year={2024},
  volume={},
  number={},
  pages={30-34},
  abstract={Emerging intelligent tools such as Chat-GPT and other generative AI technologies have gained significant interest, especially in higher education. Despite the ease that Chat-GPT can provide for both lecturers and students, there are rising concerns related to critical and creative problem-solving and innovative skills. There are unclear perspectives among lecturers and students on these rising issues. This study explores the opinions of both lecturers and students regarding the use of Chat-GPT in higher education, its impacts on accuracy, ethical issues, and creative problem-solving and innovative skills. This study uses descriptive analysis, gathering responses from 100 people, including 50 lecturers and 50 students, to understand their knowledge of Chat-GPT, how often they use it, its effectiveness, the main concerns, and the opportunities Chat-GPT can provide. The results show a balanced view of Chat-GPT and strategies to address the potential hindrance of creative problem-solving skills. This research provides useful insights into current attitudes towards AI in education, helping to understand its benefits and challenges and provide strategies to reduce the over-reliance on Chat-GPT in academics.},
  keywords={Ethics;Accuracy;Generative AI;Education;Problem-solving;Chat-GPT;Education;Artificial Intelligence;Problem Solving;Ethical},
  doi={10.1109/AiDAS63860.2024.10730665},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10725256,
  author={Paroha, Abhay Dutt},
  booktitle={2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Generative AI-based Health Monitoring and Prediction of Electrical Submersible Pumps}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Algorithms, Analytics, Modeling, and Knowledge-Based Techniques are used to propose an innovative solution in this research paper to enhance the prognostic health monitoring (PHM) of electrical submersible pumps (ESPs) by incorporating Generative Artificial Intelligence (AI) methods. The method under consideration creates artifacts that mimic various conditions of ESP failure and degradation by training deep learning models such as Generative Adversarial Networks (GANs). Thanks to the use of synthetic data for constructing machine learning models, it becomes possible to predict the conditions in which the ESP function will start degrading and could potentially find the root cause before it becomes an issue. The data gathered from this experiment affirm that this method is most efficient in enhancing maintenance plans and reducing downtime to achieve optimum dependability and effectiveness of ESP operations. The proposed architecture of PHM involves the incorporation of Generative AI for enhancing the time of operation of the ESPs in industrial applications and presents significant opportunities for preventive maintenance.},
  keywords={Training;Generative AI;Predictive models;Maintenance;Security;Resource management;Prognostics and health management;Underwater vehicles;Monitoring;Synthetic data;Electric Submersible Pump;Generative AI;Predictive Maintenance;Fault Detection;Deep Learning},
  doi={10.1109/ICCCNT61001.2024.10725256},
  ISSN={2473-7674},
  month={June},}@ARTICLE{10916843,
  author={Chai, Lu and Wang, Zidong and Shao, Yuheng and Liu, Qinyuan},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, 
  title={A Novel Hierarchical Generative Model for Semi-Supervised Semantic Segmentation of Biomedical Images}, 
  year={2025},
  volume={9},
  number={3},
  pages={2219-2231},
  abstract={In biomedical vision research, a significant challenge is the limited availability of pixel-wise labeled data. Data augmentation has been identified as a solution to this issue through generating labeled dummy data. While enhancing model efficacy, semi-supervised learning methodologies have emerged as a promising alternative that allows models to train on a mix of limited labeled and larger unlabeled data sets, potentially marking a significant advancement in biomedical vision research. Drawing from the semi-supervised learning strategy, in this paper, a novel medical image segmentation model is presented that features a hierarchical architecture with an attention mechanism. This model disentangles the synthesis process of biomedical images by employing a tail two-branch generator for semantic mask synthesis, thereby excelling in handling medical images with imbalanced class characteristics. During inference, the k-means clustering algorithm processes feature maps from the generator by using the clustering outcome as the segmentation mask. Experimental results show that this approach preserves biomedical image details more accurately than synthesized semantic masks. Experiments on various datasets, including those for vestibular schwannoma, kidney, and skin cancer, demonstrate the proposed method's superiority over other generative-adversarial-network-based and semi-supervised segmentation methods in both distribution fitting and semantic segmentation performance.},
  keywords={Biomedical imaging;Lesions;Biological system modeling;Semantics;Generators;Feature extraction;Data models;Training;Semantic segmentation;Generative adversarial networks;Generative adversarial network;semi-supervised learning;hierarchical architecture;attention mechanism;biomedical image segmentation},
  doi={10.1109/TETCI.2025.3540418},
  ISSN={2471-285X},
  month={June},}@INPROCEEDINGS{11152855,
  author={Li, Peizheng and Aijaz, Adnan},
  booktitle={IEEE INFOCOM 2025 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, 
  title={Task-Oriented Connectivity for Networked Robotics with Generative AI and Semantic Communications}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The convergence of robotics, advanced communication networks, and artificial intelligence (AI) holds the promise of transforming industries through fully automated and intelligent operations. In this work, we introduce a novel co-working frame-work for robots that unifies goal-oriented semantic communication (SemCom) with a Generative AI (GenAI)-agent under a semantic-aware network. SemCom prioritizes the exchange of meaningful information among robots and the network, thereby reducing overhead and latency. Meanwhile, the GenAI-agent leverages generative AI models to interpret high-level task instructions, allocate resources, and adapt to dynamic changes in both network and robotic environments. This agent-driven paradigm ushers in a new level of autonomy and intelligence, enabling complex tasks of networked robots to be conducted with minimal human intervention. We validate our approach through a multi-robot anomaly detection use-case simulation, where robots detect, compress, and transmit relevant information for classification. Simulation results confirm that SemCom significantly reduces data traffic while preserving critical semantic details, and the GenAI-agent ensures task coordination and network adaptation. This synergy provides a robust, efficient, and scalable solution for modern industrial environments.},
  keywords={Industries;Service robots;Generative AI;Robot kinematics;Simulation;Semantic communication;Dynamic scheduling;Real-time systems;Anomaly detection;Next generation networking;AI-native network;generative AI agent;net-worked robotics;semantic communications;variational autoen-coder;workflow},
  doi={10.1109/INFOCOMWKSHPS65812.2025.11152855},
  ISSN={2833-0587},
  month={May},}@INPROCEEDINGS{10892813,
  author={Baradari, Dünya and Han, Harry and Xia, Julia and Strelecki, Carey Ann},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Beyond Imagination: Leveraging Generative AI to Enhance Learning Through Story World Analogies}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This innovative practice full paper describes ConceptualTales, a conversational AI that explains STEM and social science concepts using analogies from popular story worlds and Socratic reasoning. The disconnect between conventional teaching strategies and student engagement is a persistent challenge in educational systems, particularly STEM fields. Traditional methods often fail to resonate with students, rendering the learning process monotonous and detached from their personal interests. Concurrently, students are enthusiastic about and dedicated to fictional worlds such as Marvel, Harry Potter, and Disney. This observation forms the basis for our innovative practice: integrating these beloved narratives into educational content through generative AI. ConceptualTales was tried with middle and high school students in the USA and China and received overwhelmingly positive feedback. Our system combines fiction-inspired learning, analogical reasoning, and Socratic questions, to make educational content personal and interesting to students.},
  keywords={Conversational artificial intelligence;Generative AI;Social sciences;Education;Rendering (computer graphics);Cognition;STEM;analogies;concepts;generative AI;story worlds;narratives;artificial intelligence in education (AIinEd)},
  doi={10.1109/FIE61694.2024.10892813},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10409100,
  author={Lin, Lanxin},
  booktitle={2023 IEEE 11th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={Multilingual Text Classification Based On Deep Learning Models}, 
  year={2023},
  volume={11},
  number={},
  pages={1202-1205},
  abstract={In an era characterized by global interconnectedness, the imperative for seamless communication across diverse languages is more pronounced than ever. The present research introduces a sophisticated pre-trained model, denoted as Multilingual BERT (mBERT), meticulously engineered to execute text classification with efficacy across 21 European languages. This model is pivotal in augmenting performance uniformity amongst a myriad of European language families. Significantly, mBERT showcases enhanced parallelization and a notable reduction in processing time for extensive documents, standing out in comparison to its contemporaries. In addition, a distilled model is cultivated under the tutelage of mBERT, aiming to delve into the intricacies of knowledge transfer between the two entities. The empirical results corroborate the superior proficiency of mBERT in the realm of language type classification, thereby furnishing a robust methodology for language categorization. Concurrently, the distilled model adeptly assimilates knowledge from its precursor, mBERT, thereby validating the efficacy of the proposed methodology.},
  keywords={Deep learning;Adaptation models;Text categorization;Europe;Task analysis;Information technology;Knowledge transfer;multilingual texts classification;large language models;model distillation;pre-trained models;knowledge transferring},
  doi={10.1109/ITAIC58329.2023.10409100},
  ISSN={2693-2865},
  month={Dec},}@INPROCEEDINGS{9207181,
  author={Thanh-Tung, Hoang and Tran, Truyen},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Catastrophic forgetting and mode collapse in GANs}, 
  year={2020},
  volume={},
  number={},
  pages={1-10},
  abstract={In this paper, we show that Generative Adversarial Networks (GANs) suffer from catastrophic forgetting even when they are trained to approximate a single target distribution. We show that GAN training is a continual learning problem in which the sequence of changing model distributions is the sequence of tasks to the discriminator. The level of mismatch between tasks in the sequence determines the level of forgetting. Catastrophic forgetting is interrelated to mode collapse and can make the training of GANs non-convergent. We investigate the landscape of the discriminator's output in different variants of GANs and find that when a GAN converges to a good equilibrium, real training datapoints are wide local maxima of the discriminator. We empirically show the relationship between the sharpness of local maxima and mode collapse and generalization in GANs. We show how catastrophic forgetting prevents the discriminator from making real datapoints local maxima, and thus causes non-convergence. Finally, we study methods for preventing catastrophic forgetting in GANs.},
  keywords={Gallium nitride;Task analysis;Training;Generators;Convergence;Generative adversarial networks;Neural networks;GANs;generative;catastrophic forgetting;mode collapse},
  doi={10.1109/IJCNN48605.2020.9207181},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{10578670,
  author={Domenichini, Diana and Bucchiarone, Antonio and Chiarello, Filippo and Schiavo, Gianluca and Fantoni, Gualtiero},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={An AI-Driven Approach for Enhancing Engagement and Conceptual Understanding in Physics Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={This Work in Progress paper introduces the design of an innovative educational system that leverages Artificial Intelligence (AI) to address challenges in physics education. The primary objective is to create a system that dynamically adapts to the individual needs and preferences of students while maintaining user-friendliness for teachers, allowing them to tailor their teaching methods. The emphasis is on fostering motivation and engagement, achieved through the implementation of a gamified virtual environment and a strong focus on personalization. Our aim is to develop a system capable of autonomously generating learning activities and constructing effective learning paths, all under the supervision and interaction of teachers. The generation of learning activities is guided by educational taxonomies that delineate and categorize the cognitive processes involved in these activities. The proposed educational system seeks to address challenges identified by Physics Education Research (PER), which offers valuable insights into how individuals learn physics and provides strategies to enhance the overall quality of physics education. Our specific focus revolves around two crucial aspects: concentrating on the conceptual understanding of physics concepts and processes, and fostering knowledge integration and coherence across various physics topics. These aspects are deemed essential for cultivating enduring knowledge and facilitating practical applications in the field of physics.},
  keywords={Cognitive processes;Taxonomy;Virtual environments;Coherence;Physics education;Artificial intelligence;Educational System;Adaptive Learning;Gamification;Artificial Intelligence in Education (AIED);Generative AI;Conceptual Understanding;Physics Education},
  doi={10.1109/EDUCON60312.2024.10578670},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10220695,
  author={Gupta, Raj Kumar and N, Naveena and Rao, B. Srinivasa and RS, Rajasree and Sarkar, Swagata and Kumar, Kallakunta Ravi},
  booktitle={2023 5th International Conference on Inventive Research in Computing Applications (ICIRCA)}, 
  title={Deep Learning for Uneven Data in Industrial IoT Using a Distributed Bias-Aware Adversarial Network}, 
  year={2023},
  volume={},
  number={},
  pages={1435-1440},
  abstract={In minority class and noisy data situations, supervised learning performs more favorably for the majority class but cannot generalize testing data. Performance in the aforementioned use cases might be improved with the help of neural-based data augmentation approaches for generating new data and deep convolutional models for classification. GANs (generative adversarial networks) have recently demonstrated impressive advancements in picture generation. To address the restrictions imposed by the distribution bias problem between the produced data and the unique data, and to provide a more vigorous data augmentation, the presented distribution bias aware collaborative GAN (DGAN) model for unbalanced deep learning in industrial IoT. By including an auxiliary classifier in the foundational GAN model, a comprehensive data augmentation system may be built. In particular, a provisional source of energy with random labels is envisioned and trained combatively with the classification model to appropriately augment the amount of data specimens in minority classes, and a mass fraction system is newly envisioned between two distinct feature extraction, allowing the cooperative adversarial training among some of the power source, voltage divider, and classification algorithm. The next step is to develop an augmentation approach for smart anomaly detection in class imbalance, which, by adjusting for dispersion bias using the properly balanced data, might significantly improve classification precision. Experiment assessments using real-world unbalanced datasets show the superior recital of the suggested model in addressing the distribution biased issue for multi-class classification in class imbalance for commercial IoT applications, as compared to five baseline techniques.},
  keywords={Deep learning;Training;Collaboration;Voltage;Generative adversarial networks;Data augmentation;Data models;Generative Adversarial Networks;Anomaly Identification;Bias Aware Collaborative;Class Imbalance;Industrial IoT},
  doi={10.1109/ICIRCA57980.2023.10220695},
  ISSN={},
  month={Aug},}@ARTICLE{11023070,
  author={Sharmin, Zeseya and Xiang, Yong and Uddin, Md Palash and Chen, Feifei and Zhang, Yushu and Tang, Jine},
  journal={IEEE Transactions on Network Science and Engineering}, 
  title={Federated TSRN-Enabled GANs for Effective Cyber Attack Detection in Edge Computing}, 
  year={2025},
  volume={},
  number={},
  pages={1-17},
  abstract={Edge Computing (EC) processes data locally at edge servers, reducing latency, conserving bandwidth, enhancing privacy, and managing large data volumes independently of central servers, making it critical for applications like autonomous vehicles and healthcare. However, EC is vulnerable to cyber attacks, as edge nodes can compromise edge servers and exploit communication between them. Traditional Machine Learning (ML) methods, which require centralizing communication (activity) data, are ineffective for privacy-sensitive EC scenarios. Federated Learning (FL) offers a distributed ML approach for Federated Cyber-Attack Detection (FedCAD), preserving data privacy by training a shared model locally at each edge server, with a central server aggregating updates to form a global model. However, FedCAD faces challenges with unlabeled and non-Independent and non-Identically Distributed (non-IID) activity data. Existing Generative Adversarial Networks (GANs) methods for synthetic data generation do not fully address these issues. To overcome these challenges, we propose FedTSRGNet, which integrates novel Temporal Sequential Recurrent Network (TSRN)-enabled GANs with FL to generate realistic sequential data by capturing complex temporal patterns in local datasets. Additionally, we introduce a reformulated loss function to optimize TSRN-enabled GAN training within the FL paradigm, improving convergence and ensuring the synthetic data closely mimics real data. Theoretical analysis and extensive experiments on two benchmark datasets demonstrate that FedTSRGNet outperforms four state-of-the-art methods by achieving up to 89% accuracy for unlabeled non-IID and 95% accuracy in labeled IID distributions, representing a significant improvement over comparative methods.},
  keywords={Servers;Cyberattack;Image edge detection;Training;Data models;Synthetic data;Data privacy;Generative adversarial networks;Federated learning;Distributed databases;Federated cyber-attack detection;Edge computing;Federated learning;Generative adversarial network;Temporal convolutional network},
  doi={10.1109/TNSE.2025.3576322},
  ISSN={2327-4697},
  month={},}@INPROCEEDINGS{9985936,
  author={Dai, Jin and Guo, Qiuyan and Zheng, Zhifang and Liu, Xiao},
  booktitle={2022 3rd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)}, 
  title={Research on Variational Autoencoders and its Interpretability Based on Gaussian Cloud Model}, 
  year={2022},
  volume={},
  number={},
  pages={119-122},
  abstract={As one of the important generative models, Variational Autoencoders (VAEs) can complete the feature characterization and generation of data. However, their reconstruction effect on high-resolution images is often not high. The poor image quality is partly due to the limited space for hiding variables. In order to solve this problem, based on the optimization model GCMVAE based on VAEs, this paper improves the generation ability of the model and studies its interpretability. In this study, the interpretability research focuses on the interpretation of some models without semantic information in different stages of the model. Finally, through the analysis of the results, we can get the characteristics of data, the distribution characteristics of implicit variables and the different learning stages experienced in the process of data generation.},
  keywords={Representation learning;Cloud computing;Analytical models;Convolution;Semantics;Data visualization;Learning (artificial intelligence);VAEs;Generative Model;Gaussian Cloud Model;Interpretability},
  doi={10.1109/ICBAIE56435.2022.9985936},
  ISSN={},
  month={July},}@INPROCEEDINGS{11050821,
  author={Kula, Raula Gaikovina},
  booktitle={2025 IEEE/ACM International Workshop on Bots in Software Engineering (BotSE)}, 
  title={Reducing Alert Fatigue via AI-Assisted Negotiation: A Case for Dependabot}, 
  year={2025},
  volume={},
  number={},
  pages={11-12},
  abstract={The increasing complexity of software dependencies has led to the emergence of automated dependency management tools, such as Dependabot. However, these tools often overwhelm developers with a high volume of alerts and notifications, leading to alert fatigue. This paper presents a position on using Artificial Intelligence (AI) agents as dependency negotiators to reduce alert fatigue. We then examine specific use cases where AI agents can facilitate dependency negotiations, such as when working with external dependencies or managing complex, multi-component systems. Our findings highlight the need for more research on the design and evaluation of AI-driven dependency mediation mechanisms. With a focus on ensuring transparency, explainability, and human trustworthiness in these GitHub software projects, our goal is to reduce alert fatigue to an extent that maintainers no longer feel overwhelmed and welcome pull requests just like any other contribution into their projects},
  keywords={Generative AI;Conferences;Supply chains;Fatigue;Software;Complexity theory;Security;Mediation;Software engineering;Software development management;Generative AI;Security Supply Chain},
  doi={10.1109/BotSE67031.2025.00010},
  ISSN={},
  month={April},}@INPROCEEDINGS{11103568,
  author={Vidaković, Luka and Stojanović, Dimitrije and Pavković, Bogdan and Četić, Nenad and Krunić, Momčilo},
  booktitle={2025 IEEE Zooming Innovation in Consumer Technologies Conference (ZINC)}, 
  title={Comparative Analysis of Docker and Python Runtimes for AWS Lambda in RAG-Based AI Solutions}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={As the use of large language models (LLMs) continues to grow and the rapid growth of artificial intelligence (AI)-based applications accelerates, scalable, cost-effective, low-latency solutions are needed. Serverless computing on AWS Lambda has emerged as a key platform for deploying AI applications, yet selecting the optimal runtime environment remains a significant challenge for Retrieval-Augmented Generation (RAG)-based solutions. We provide a thorough comparison between Docker-based and Python-native runtimes, examining key performance metrics such as cold start latency, warm execution time, and build time. Our empirical findings show that the Python-native runtime achieves substantial improvements resulting in up to an 84% reduction in execution times. We provide insights that equip developers with actionable information, leading to more efficient, scalable, and cost-effective serverless AI deployments.},
  keywords={Technological innovation;Runtime environment;Generative AI;Scalability;Large language models;Retrieval augmented generation;Serverless computing;Performance metrics;Low latency communication;Zinc;Cloud computing;Serverless computing;Retrieval-Augmented Generation;Scalability;Generative AI},
  doi={10.1109/ZINC65316.2025.11103568},
  ISSN={2995-2689},
  month={May},}@ARTICLE{9809820,
  author={He, Shenghong and Wang, Ruxin and Liu, Tongliang and Yi, Chao and Jin, Xin and Liu, Renyang and Zhou, Wei},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={Type-I Generative Adversarial Attack}, 
  year={2023},
  volume={20},
  number={3},
  pages={2593-2606},
  abstract={Deep neural networks are vulnerable to adversarial attacks either by examples with indistinguishable perturbations which produce incorrect predictions, or by examples with noticeable transformations that are still predicted as the original label. The latter case is known as the Type I attack which, however, has achieved limited attention in literature. We advocate that the vulnerability comes from the ambiguous distributions among different classes in the resultant feature space of the model, which is saying that the examples with different appearances may present similar features. Inspired by this, we propose a novel Type I attack method called generative adversarial attack (GAA). Specifically, GAA aims at exploiting the distribution mapping from the source domain of multiple classes to the target domain of a single class by using generative adversarial networks. A novel loss and a U-net architecture with latent modification are elaborated to ensure the stable transformation between the two domains. In this way, the generated adversarial examples have similar appearances with examples of the target domain, yet obtaining the original prediction by the model being attacked. Extensive experiments on multiple benchmarks demonstrate that the proposed method generates adversarial images that are more visually similar to the target images than the competitors, and the state-of-the-art performance is achieved.},
  keywords={Gallium arsenide;Perturbation methods;Generative adversarial networks;Transforms;Videos;Task analysis;Predictive models;Type I attack;resultant feature space;similar features;adversarial attack;generative adversarial network},
  doi={10.1109/TDSC.2022.3186918},
  ISSN={1941-0018},
  month={May},}@INPROCEEDINGS{10363970,
  author={Yao, Yueyang and Liu, Yahui and Dai, Xingyuan and Chen, Shichao and Lv, Yisheng},
  booktitle={2023 International Annual Conference on Complex Systems and Intelligent Science (CSIS-IAC)}, 
  title={A Graph-Based Scene Encoder for Vehicle Trajectory Prediction Using the Diffusion Model}, 
  year={2023},
  volume={},
  number={},
  pages={981-986},
  abstract={To boost autonomous driving safety even further, autonomous vehicles must be able to predict future trajectory states, allowing them to grasp their surroundings in real time, just like a human driver. In this paper, we conduct research on the defects of poor multimodal richness and unstable training of existing vehicle trajectory prediction models, and propose an improved model MID++. In order to better grasp the interaction between agents and road elements, we mainly introduce an GNN-based ALEncoder to replace the traditional CNN block. Meanwhile, an importance sampling strategy is exploited in the training process. According to the experimental results on Argoverse 2 dataset, our model enhances the accuracy and variety of trajectory predictions and significantly shortens the training time.},
  keywords={Training;Monte Carlo methods;Pedestrians;Roads;Predictive models;Real-time systems;Trajectory;Autonomous Driving;Trajectory Prediction;Diffusion Model},
  doi={10.1109/CSIS-IAC60628.2023.10363970},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10511639,
  author={Park, Jaeyong},
  booktitle={2024 8th IEEE Electron Devices Technology & Manufacturing Conference (EDTM)}, 
  title={AI driven Process Diagnostic & Control: Device Manufacturing}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={This paper explores the integration of Artificial Intelligence (AI) in process control and diagnostics in semiconductor manufacturing. It highlights current trends, including machine learning (ML) for data alignment and predictive maintenance, and anticipates future advancements in data sharing and standardization. This overview showcases AI’s transformative impact on equipment optimization and industry collaboration, underlining its role in shaping efficient, proactive manufacturing processes.},
  keywords={Industries;Manufacturing processes;Process control;Collaboration;Standardization;Semiconductor device manufacture;Market research;AI;ML;Generative AI;Manufacturing},
  doi={10.1109/EDTM58488.2024.10511639},
  ISSN={},
  month={March},}@INBOOK{10788858,
  author={},
  booktitle={Artificial Intelligence for Data-Driven Medical Diagnosis}, 
  title={Index}, 
  year={2021},
  volume={},
  number={},
  pages={305-310},
  abstract={},
  keywords={Medical diagnostic imaging;Indexes;Feature extraction;Tumors;Support vector machines;Robot sensing systems;Peer-to-peer computing;Informatics;Generative adversarial networks;Artificial intelligence},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9783110668384},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10788858},}@INPROCEEDINGS{10986983,
  author={Gong, Lishu},
  booktitle={2025 IEEE International Conference on Electronics, Energy Systems and Power Engineering (EESPE)}, 
  title={Construction and Application Research of University Academic Early Warning System Based on AIGC Technology}, 
  year={2025},
  volume={},
  number={},
  pages={283-291},
  abstract={Traditional university academic early warning systems often suffer from single data dimensions, rigid warning thresholds, and a lack of personalized intervention, making it difficult to accurately identify high-risk students and provide effective support[1]. This research innovatively proposes a construction method for a university academic early warning system based on Artificial Intelligence Generated Content (AIGC) technology [2]. This system integrates multi-dimensional data such as student academic performance, classroom behavior, online interactions, and psychological state. Leveraging AIGC technologies, including Natural Language Processing (NLP) and Generative Adversarial Networks (GANs), the system deeply mines students' potential learning behavior patterns and psychological states, generating more interpretable warning reports and personalized intervention suggestions. By constructing a multi-modal data fusion model and intelligent warning algorithms, the system can achieve early and accurate identification of students' academic risks. Simultaneously, personalized learning resources and tutoring suggestions generated using AIGC technology can more effectively help students overcome learning difficulties and improve their academic performance. This research aims to explore the application potential of AIGC technology in the field of university academic early warning and verify the advantages of this system in improving warning accuracy and intervention effectiveness, providing theoretical support and practical reference for building a more intelligent and humanized university academic support system.},
  keywords={Power engineering;Accuracy;Buildings;Psychology;Data integration;Alarm systems;Generative adversarial networks;Natural language processing;Data models;Artificial intelligence;Artificial Intelligence Generated Content (AIGC);Academic Early Warning;Higher Education;Multi-modal Data Fusion;Personalized Intervention;Natural Language Processing;Generative Adversarial Network},
  doi={10.1109/EESPE63401.2025.10986983},
  ISSN={},
  month={March},}@INBOOK{10952356,
  author={Shah, Priten},
  booktitle={AI and the Future of Education: Teaching in the Age of Artificial Intelligence}, 
  title={Adapting and Growing with AI in Education}, 
  year={2023},
  volume={},
  number={},
  pages={218-221},
  abstract={Summary <p>This chapter presents some closing thoughts on the concepts covered in the preceding chapters of this book. The book outlines how AI systems are making our dreams as a community come true. There are clear areas where the education system has shortcomings in serving our students, and this is a perfect opportunity to address those head&#x2010;on. The book also outlines how students will need the skills to use these technologies, protect themselves from the malicious actors who manipulate the technologies to harm others, and contribute meaningfully to society side&#x2010;by&#x2010;side as AI technologies take on greater shares of the workload. As AI handles more and more of the routine tasks that make up our day, there will be a shift in the roles of educators. The book provides some ways educators can continue adapting to these changes with the right resources and tools.</p>},
  keywords={Artificial intelligence;Education;Generative AI;Chatbots;Pandemics;Buildings;Urban areas;Technological innovation;Navigation;Monitoring},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394219261},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952356},}@INPROCEEDINGS{11022004,
  author={Sun, Dandan and Jia, Lixia and Zhou, Li and Shi, Yuxia},
  booktitle={2024 8th Asian Conference on Artificial Intelligence Technology (ACAIT)}, 
  title={Research on the Application and Model Building of Image Recognition Technology Based on CNN in English Teaching}, 
  year={2024},
  volume={},
  number={},
  pages={1552-1559},
  abstract={The traditional English teaching model relies on basic teaching materials and cannot improve students' understanding and interest in English learning. Therefore, this study applies convolutional neural network image recognition technology to English teaching, utilizing convolutional neural networks to achieve image recognition technology and improve the effectiveness of English teaching. This study first builds a convolutional neural network image recognition model, and then optimizes the design and method research of the convolutional neural network model, and secondly, the convolutional neural network image recognition technology is added on the basis of English teaching. Finally, the stability of the algorithm is determined through data processing and experimental analysis. The experimental results show that the error value of the convolutional neural network algorithm is 0.91, and the highest fitness is 0.96. The error is lower than that of traditional image recognition algorithms, and the fitness is higher than that of traditional image recognition algorithms. This shows that the convolutional neural network algorithm is able to recognize and analyze images, and at the same time can optimize the traditional English teaching mode.},
  keywords={Adaptation models;Image recognition;Design methodology;Education;Buildings;Data processing;Stability analysis;Convolutional neural networks;Artificial intelligence;Convolutional Neural Networks;Image Recognition;English Language Teaching;Adaptability},
  doi={10.1109/ACAIT63902.2024.11022004},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10913495,
  author={Belkaid, Maryem and Alaoui, El Arbi Abdellaoui and Merras, Mostafa and Berrajaa, Achraf and Akkad, Nabil El},
  booktitle={2024 3rd International Conference on Embedded Systems and Artificial Intelligence (ESAI)}, 
  title={Review of 3D Scene Reconstruction: From Traditional Methods to Advanced Deep Learning Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-11},
  abstract={3D scene reconstruction represents a pivotal domain within computer vision, involving a diverse array of techniques ranging from classical geometry-driven approaches to modern deep learning-based models. This review article offers an extensive summary of cutting-edge methods for 3D reconstruction, including techniques such as Structure-from-Motion (SfM) and Multi-View Stereo (MVS), as well as cutting-edge deep learning techniques including CNNs, GANs,Variational Autoencoders (VAEs) and Neural Radiance Fields (NeRF). We analyze the strengths and limitations of each approach, particularly in terms of accuracy, efficiency, generalization, and their ability to handle complex scenes. Furthermore, we delve into the key challenges faced in 3D scene reconstruction, including the trade-offs between computational efficiency and model accuracy, the generalization to diverse environments, and the integration of multi-modal data sources. Special attention is given to NeRF, a breakthrough in the field, discussing its current capabilities and potential areas for improvement in future research. This review aims to serve as a resource for researchers and practitioners by summarizing the current landscape of 3D reconstruction technologies and identifying promising directions for future exploration.},
  keywords={Solid modeling;Technological innovation;Three-dimensional displays;Accuracy;Reviews;Computational modeling;Autoencoders;Virtual reality;Neural radiance field;Artificial intelligence;3D Reconstruction Scenes;Artificial Intelligence;Deep Learning;Neural Radiance Fields;Generative Adversarial Networks;Variational Autoencoders;Convolutional Neural Networks},
  doi={10.1109/ESAI62891.2024.10913495},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9643213,
  author={Ma, Zulong and Lu, Jiamin and Feng, Jun and Zhang, Yunfei and Wu, Wei},
  booktitle={2021 IEEE 33rd International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Semantic-based Bidirectional Adversarial Neural Topic Model}, 
  year={2021},
  volume={},
  number={},
  pages={376-380},
  abstract={The topic models can effectively reduce the dimensionality of document representation. In recent years, Generative Adversarial Networks (GANs) have begun to be applied to topic models, but most researches do not fully consider the documents’ context information, leading to the fact that the generated results of the encoder networks cannot represent the real data distribution. To this end, we propose a novel topic model named Semantic-based Bidirectional Adversarial Neural Topic Model (SNTM), which introduces semantic information into Bidirectional Generative Adversarial Networks (BiGAN) by adding the word embedding and BiLSTM-Attention mechanism. This improvement makes the encoder network in our model generate a distribution closer to the real document-topic distribution. Furthermore, we also propose a topic difference evaluation indicator, which more comprehensively evaluates the quality of the generated topics. The experimental results on different datasets show that SNTM performs better than the baseline topic model.},
  keywords={Conferences;Semantics;Generative adversarial networks;Data models;Artificial intelligence;Context modeling;topic model;topic mining;generative adversarial network;semantic information;neural network},
  doi={10.1109/ICTAI52525.2021.00061},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{11137839,
  author={Jia, Yihan},
  booktitle={2025 7th International Conference on Artificial Intelligence Technologies and Applications (ICAITA)}, 
  title={Research on the Application of Multi-Scale Feature Fusion GAN Framework in Vintage Photo Restoration and Colorization}, 
  year={2025},
  volume={},
  number={},
  pages={500-505},
  abstract={Vintage photographs preserve precious historical memories but often suffer from damage and fading due to time erosion. This paper proposes a multi-scale feature fusion model based on Generative Adversarial Networks (GAN) for intelligent restoration and colorization of old photos. The model captures detailed information at different levels of old photos through a multi-scale feature extraction module, designs a fusion strategy to organically integrate local and global features, and enhances the authenticity of restored images via generative adversarial mechanisms. Experimental results show that compared with traditional methods, the model significantly improves in indicators such as Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM), enabling better restoration of the original appearance of old photos. This study provides an effective solution for the digital protection and restoration of vintage photographs.},
  keywords={Fading channels;PSNR;Generative adversarial networks;Feature extraction;Image restoration;Indexes;Protection;Artificial intelligence;Erosion;Generative Adversarial Networks (GAN);old photo restoration;colorization;multi-scale feature fusion},
  doi={10.1109/ICAITA67588.2025.11137839},
  ISSN={},
  month={June},}@INPROCEEDINGS{10356488,
  author={Nossier, Soha A. and Wall, Julie and Moniri, Mansour and Glackin, Cornelius and Cannings, Nigel},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Enhancing Automatic Speech Recognition Quality with a Second-Stage Speech Enhancement Generative Adversarial Network}, 
  year={2023},
  volume={},
  number={},
  pages={546-552},
  abstract={Speech enhancement is an essential preprocessing stage for automatic speech recognition in noisy conditions; however, the distortion caused by the denoising process may lead to degradation in automatic speech recognition performance. This paper presents a deep learning-based speech enhancement architecture to overcome this issue by applying a second-stage network that deals with distortion noise. Moreover, a signal-to-noise ratio binary classifier is implemented to activate the speech enhancement network for intrusive noise environments only, which improves the overall performance. The proposed architecture outperforms powerful models in the literature, as it improves a challenging noisy speech test set by 0.8 and 5.9% improvement in the quality and intelligibility scores, respectively. Furthermore, the architecture improves the performance of automatic speech recognition with a 13.8% reduction in the word error rate at 0dB signal-to-noise ratio. Finally, the second-stage network was proven to improve the performance of first-stage speech enhancement models, not previously seen in the training process.},
  keywords={Training;Degradation;Error analysis;Noise reduction;Speech enhancement;Distortion;Generative adversarial networks;Automatic speech recognition;deep learning;generative adversarial network;speech distortion;speech enhancement},
  doi={10.1109/ICTAI59109.2023.00087},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{10708135,
  author={Çaldağ, Murat Tahir},
  booktitle={2024 10th International Conference on Control, Decision and Information Technologies (CoDIT)}, 
  title={AI Pair Programming Acceptance: A Value-Based Approach with AHP Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={556-561},
  abstract={The emergence of Artificial Intelligence (AI) tools is transforming every aspect of life with new opportunities and risks. An impact of AI tools can be seen in AI pair programming which is defined as a generative and creative support tool with real-time interaction. The goal of this study is to explore the AI pair programming acceptance. To identify, describe, categorize, and rank the factors affecting the acceptance of AI pairs a literature review, a research model proposal based on an extension of the Value-based Adoption Model (VAM) framework, and an Analytic Hierarchy Process (AHP) analysis is conducted. The proposed model consists of six main factors and twenty-two sub-factors which are validated with an AHP analysis including eleven experts’ judgments. The findings presented the most essential factors as productivity, code accuracy, complexity, personal development, and innovativeness. The least significant factors were inspiration, motivation, intellectual property violation, AI interaction, and trust. This study provides insight to AI tool developers and producers in the context of programming on the key factors to consider for success.},
  keywords={Productivity;Analytical models;Codes;Accuracy;Intellectual property;Programming;Real-time systems;Complexity theory;Artificial intelligence;Software development management},
  doi={10.1109/CoDIT62066.2024.10708135},
  ISSN={2576-3555},
  month={July},}@INPROCEEDINGS{11107113,
  author={Cosentino, Cristian and Defilippo, Annamaria and Guzzi, Pietro Hiram and Liò, Pietro and Iuliano, Antonella},
  booktitle={2025 IEEE International Workshop on Metrology for Living Environment (MetroLivEnv)}, 
  title={Denoising Probabilistic Diffusion Models, ResNet, and Class Activation Maps for Healthcare Imaging}, 
  year={2025},
  volume={},
  number={},
  pages={515-520},
  abstract={Artificial Intelligence (AI) has the potential to enhance clinical practice by leveraging the vast amount of clinical data available today. In particular, biomedical imaging analysis plays a crucial role in healthcare, generating extensive datasets that can be used to study complex diseases, track their progression, and even predict their onset. This study focuses on an approach based on Denoising Diffusion Probabilistic Models (DDPMs), a type of generative model that utilizes a parameterized Markov chain and variational inference to generate synthetic samples that closely resemble real data. The model was trained on pneumonia images, producing high-quality synthetic samples to assess the performance of DDPMs by separately analyzing class 0 (healthy) and class 1 (pneumonia) cases. Furthermore, a ResNet-based convolutional neural network was employed for classification tasks to evaluate the effectiveness of DDPMs in generating synthetic images. The classification performance was compared using both real and synthetic images. Additionally, Class Activation Maps (CAM) were applied to provide visual explanations of the classification results, thereby enhancing the interpretability of our findings.},
  keywords={Visualization;Pneumonia;Noise reduction;Medical services;Diffusion models;Data models;Artificial intelligence;Synthetic data;Videos;Residual neural networks;DDPM;Healthcare images;Synthetic data;ResNet;CAM},
  doi={10.1109/MetroLivEnv64961.2025.11107113},
  ISSN={},
  month={June},}@INPROCEEDINGS{9157564,
  author={Schönfeld, Edgar and Schiele, Bernt and Khoreva, Anna},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={A U-Net Based Discriminator for Generative Adversarial Networks}, 
  year={2020},
  volume={},
  number={},
  pages={8204-8213},
  abstract={Among the major remaining challenges for generative adversarial networks (GANs) is the capacity to synthesize globally and locally coherent images with object shapes and textures indistinguishable from real images. To target this issue we propose an alternative U-Net based discriminator architecture, borrowing the insights from the segmentation literature. The proposed U-Net based architecture allows to provide detailed per-pixel feedback to the generator while maintaining the global coherence of synthesized images, by providing the global image feedback as well. Empowered by the per-pixel response of the discriminator, we further propose a per-pixel consistency regularization technique based on the CutMix data augmentation, encouraging the U-Net discriminator to focus more on semantic and structural changes between real and fake images. This improves the U-Net discriminator training, further enhancing the quality of generated samples. The novel discriminator improves over the state of the art in terms of the standard distribution and image quality metrics, enabling the generator to synthesize images with varying structure, appearance and levels of detail, maintaining global and local realism. Compared to the BigGAN baseline, we achieve an average improvement of 2.7 FID points across FFHQ, CelebA, and the proposed COCO-Animals dataset.},
  keywords={Generators;Gallium nitride;Decoding;Training;Generative adversarial networks;Image segmentation;Computer architecture},
  doi={10.1109/CVPR42600.2020.00823},
  ISSN={2575-7075},
  month={June},}@INBOOK{10614268,
  author={Ojanperä, Tero},
  booktitle={AI Revolution: Mastering AI for Personal and Organizational Growth}, 
  title={7 At Least Lawyers Have Plenty of Work}, 
  year={2024},
  volume={},
  number={},
  pages={107-124},
  abstract={"The AI Revolution" is a practical guide to using new AI tools, such as ChatGPT, DALLE and Midjourney. Learn how to multiply your productivity by guiding or prompting AI in various ways. The book also introduces Microsoft Copilot, Google Bard, and Adobe Photoshop Generative Fill, among other new applications. ChatGPT reached a hundred million users in just two months after its release, faster than any other application before. This marked the advent of the generative AI era. Generative AI models generate text, images, music, videos, and even 3D models in ways previously thought impossible for machines. The book explains in an understandable manner how these AI models work. The book provides examples of how AI increases productivity, which professions are changing or disappearing, and how job markets will evolve in the coming years. With this book, you'll learn to recognize the opportunities and risks AI offers. Understand what this change demands from individuals and companies and what strategic skills are required. The book also covers legal questions caused by generative AI, like copyrights, data protection, and AI regulation. It also ponders societal impacts. AI produces content, thus influencing language, culture, and even worldviews. Therefore, it's crucial to understand by whom and how AI is trained. The AI revolution started by ChatGPT is just the beginning. This handbook is for you if you want to keep up with the rapid development of AI.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770042314},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10614268},}@INPROCEEDINGS{10707879,
  author={ELsharif, Wala and Agus, Marco and Alzubaidi, Mahmoud and She, James},
  booktitle={2024 IEEE 7th International Conference on Multimedia Information Processing and Retrieval (MIPR)}, 
  title={Cultural Relevance Index: Measuring Cultural Relevance in AI-Generated Images}, 
  year={2024},
  volume={},
  number={},
  pages={410-416},
  abstract={This paper introduces the Cultural Relevance Index (CRI), a metric designed to evaluate and quantify the cultural relevance of AI-generated images. Leveraging the detection capabilities of GPT technology and our proposed mathematical formulas aligned with human perception, CRI assesses the extent to which the content of an image is relevant to a particular culture such as Arabic, a capability not commonly found in many AI technologies. Through rigorous validation, including comparison with human judgments and a mathematical baseline, with focus on Arabic culture, CRI demonstrates a compelling similarity (around 95%) with human judgement, outperforming a quantified baseline metric (over 28%). CRI also succeeds to matches human judgment in comparing cultural images 100% of the time.},
  keywords={Measurement;Information processing;Cultural differences;Indexes;Artificial intelligence;Cultural Relevance;AI-generated images;Human assessment;Arabic culture},
  doi={10.1109/MIPR62202.2024.00071},
  ISSN={2770-4319},
  month={Aug},}@ARTICLE{9967399,
  author={V, Indu and Thampi, Sabu M.},
  journal={IT Professional}, 
  title={Cognitive AI for Mitigation of Misinformation in Online Social Networks}, 
  year={2022},
  volume={24},
  number={5},
  pages={37-45},
  abstract={Misinformation propagation in social networks has emerged as a crucial problem that needs to be attended with prime importance. Despite the existence of several fact-checking mechanisms and misinformation detection tools, users of social media platforms continue to be the victims of misinformation propagation. This is because human cognition is a strong factor that drives users in consuming and spreading misinformation. This article highlights the significance of cognitive psychology in misinformation propagation analysis and summarizes the challenges faced by current misinformation detection mechanisms. The study shows that there is an immediate requirement for efficient mechanisms combining AI and cognitive psychology that can support humans in making judgements regarding the information appearing on social networks. A cognitive AI framework is proposed that can augment humans’ capability in assessing the veracity of the information online and reinforce positive information sharing behavior in individuals thereby reducing the spread of misinformation.},
  keywords={Social networking (online);Psychology;Information sharing;Feature extraction;Cognition;Fake news;Artificial intelligence},
  doi={10.1109/MITP.2022.3168790},
  ISSN={1941-045X},
  month={Sep.},}@ARTICLE{11098641,
  author={Farhadi, Hamed and Banerjee, Bitan and Berkvens, Rafael and Bhat, Nabeel Nisar and Bodji, Emmanuelle and Dampahalage, Dilin and Eldeeb, Eslam and Famaey, Jeroen and Fettweis, Gerhard P. and Jeong, Jaeseong and Korpi, Dani and Kumar, Siddhartha and Lebrun, Yann and Legouable, Rodolphe and Mateos-Ramos, José Miguel and Mahmood, Nurul Huda and Moghaddam, Mohammad Hossein and Nimr, Ahmad and Rajatheva, Nandana and Rajapaksha, Nuwanthika and Stavridis, Athanasios and Svensson, Tommy and Yu, Han and Wilhelmsson, Leif and Wymeersch, Henk},
  journal={IEEE Communications Magazine}, 
  title={6G AI-Driven Air Interface — Hexa-X-II View}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={This article presents the European 6G Flagship project Hexa-X-II's view on 6G AI-driven air interface. It outlines motivations for AI in the physical layer, selected applications of AI for communication and sensing, their achieved performance, and the challenges to be addressed. The article also provides an overview of the relevant standardization activities.},
  keywords={Artificial intelligence;6G mobile communication;Hardware;Parity check codes;Communication channels;Receivers;Estimation;Decoding;Codes;Classification tree analysis},
  doi={10.1109/MCOM.001.2400394},
  ISSN={1558-1896},
  month={},}@INPROCEEDINGS{11019764,
  author={M, Hariharasuthan and S, Mohanraj and K, Shamridha and Madhavi, S.},
  booktitle={2025 International Conference on Computing and Communication Technologies (ICCCT)}, 
  title={Bran AI: An Integrated Approach to Heart Attack Risk Prediction Using Retinal Fundus Image}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={This study introduces Bran AI, an advanced framework for heart attack prediction, using retinal fundus images integrated with clinical data to assess cardiovascular risk. The system's core employs a neural network-based segmentation model for detailed image analysis, enabling the extraction of critical biomarkers. Bran AI combines this with BERT for medical metadata processing, capturing relevant factors such as age, sex, and diabetes status to enhance prediction accuracy. The model architecture integrates dense layers and attention mechanisms to optimize prediction, while explainability tools such as SHAP and Grad-CAM clarify the model's decision-making process for clinical applicability. Recent studies have demonstrated the efficacy of retinal image analysis in cardiovascular risk prediction, underscoring its potential as a diagnostic tool. Bran AI achieves a high predictive performance with 92.4% accuracy, demonstrated by AUC-ROC and F1-score metrics. This innovative approach positions Bran AI as a valuable tool for healthcare professionals in cardiovascular diagnostics, fostering early detection and personalized management of heart attack risks.},
  keywords={Accuracy;Image analysis;Biological system modeling;Medical services;Cardiac arrest;Predictive models;Biomarkers;Retina;Artificial intelligence;Standards;BERT;Retinal Fundus Imaging;Biomarker;SHAP},
  doi={10.1109/ICCCT63501.2025.11019764},
  ISSN={2995-3197},
  month={April},}@INPROCEEDINGS{10546022,
  author={Lakhanpal, Sorabh and Devi, KSKN Venkata Ramana and K, Aravinda and Jain, Sachindra Kumar and Adnan, Myasar Mundher and Kumar, Ashwani},
  booktitle={2024 IEEE 13th International Conference on Communication Systems and Network Technologies (CSNT)}, 
  title={Designing Explainable Defenses Against Sophisticated Adversarial Attacks}, 
  year={2024},
  volume={},
  number={},
  pages={280-285},
  abstract={The requirement for strong defenses against complex adversarial assaults is increasing fast in the constantly evolving AI ecosystem. Considering this need, we put up the Explain Defend Net architecture, a unique adversarial defensive mechanism. This framework utilizes state-of-the-art methods to improve the robustness, openness, and flexibility of models. To protect the model from external interference, the Robust Feature Recalibrator (RFR) selectively adjusts the calibration of input features. The Explain Intercept Layer (EIL) offers transparency by offering interpretable insights into the decision-making process, enhancing human comprehension. The model can adapt to new forms of adversarial attack because of the dynamic adaptability guaranteed by Adaptive Reinforce Guard (ARG). With its comprehensive defensive strategy, Explain Defend Net is designed to outperform more conventional approaches. The suggested framework is put through rigorous testing, and the results indicate that it outperforms six established approaches in a wide range of categories. The findings show that Explain Defend Net regularly outperforms conventional techniques, proving its efficacy in protecting AI systems from malicious actors. Explain Defend Net is state-of-the-art in the field of adversarial defense because of its novel mix of recalibration, interpretability, and adaptive reinforcement.},
  keywords={Adaptation models;Biological system modeling;Decision making;Interference;Robustness;Security;Artificial intelligence;Adversarial attacks;AI security;Adaptive defense;Deep learning;Explainability;Human-in-the-loop;Interpretability;Machine learning;Robustness;Selective recalibration;Sophisticated},
  doi={10.1109/CSNT60213.2024.10546022},
  ISSN={2473-5655},
  month={April},}@ARTICLE{9106415,
  author={Yang, Jiachen and Wang, Chenguang and Jiang, Bin and Song, Houbing and Meng, Qinggang},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Visual Perception Enabled Industry Intelligence: State of the Art, Challenges and Prospects}, 
  year={2021},
  volume={17},
  number={3},
  pages={2204-2219},
  abstract={Visual perception refers to the process of organizing, identifying, and interpreting visual information in environmental awareness and understanding. With the rapid progress of multimedia acquisition technology, research on visual perception has been a hot topic in the academical field and industrial applications. Especially after the introduction of artificial intelligence theory, intelligent visual perception has been widely used to promote the development of industrial production towards intelligence. In this article, we review the previous research and application of visual perception in different industrial fields such as product surface defect detection, intelligent agricultural production, intelligent driving, image synthesis, and event reconstruction. The applications basically cover most of the intelligent visual perception processing technologies. Through this survey, it will provide a comprehensive reference for research on this direction. Finally, this article also summarizes the current challenges of visual perception and predicts its future development trends.},
  keywords={Visual perception;Fabrics;Production;Surface treatment;Informatics;Machine vision;Surface morphology;Artificial intelligence;industrial application;visual perception},
  doi={10.1109/TII.2020.2998818},
  ISSN={1941-0050},
  month={March},}@INPROCEEDINGS{8932813,
  author={Lee, Sun-Kyung and Kim, Jong-Hwan},
  booktitle={2019 7th International Conference on Robot Intelligence Technology and Applications (RiTA)}, 
  title={BALD-VAE: Generative Active Learning based on the Uncertainties of Both Labeled and Unlabeled Data}, 
  year={2019},
  volume={},
  number={},
  pages={6-11},
  abstract={The following topics are dealt with: learning (artificial intelligence); mobile robots; robot vision; object detection; path planning; cameras; image classification; emotion recognition; SLAM (robots); feature extraction.},
  keywords={Uncertainty;Data models;Measurement uncertainty;Bayes methods;Entropy;Generative adversarial networks;Labeling},
  doi={10.1109/RITAPP.2019.8932813},
  ISSN={},
  month={Nov},}@INBOOK{10953204,
  author={Nourian, Pirouz and Azadi, Shervin and Uijtendaal, Roy and Bai, Nan},
  booktitle={Artificial Intelligence in Performance-Driven Design: Theories, Methods, and Tools}, 
  title={Augmented Computational Design}, 
  year={2024},
  volume={},
  number={},
  pages={1-30},
  abstract={Summary <p>This chapter presents methodological reflections on the necessity and utility of artificial intelligence (AI) in generative design. Specifically, the chapter discusses how generative design processes can be augmented by AI to deliver in terms of a few outcomes of interest or performance indicators while dealing with hundreds or thousands of small decisions. The core of the performance&#x2010;based generative design paradigm is about making statistical or simulation&#x2010;driven associations between these choices and their consequences for mapping and navigating such a complex decision space. This chapter will discuss promising directions in AI for augmenting decision&#x2010;making processes in architectural design for mapping and navigating complex design spaces.</p>},
  keywords={Artificial intelligence;Mathematical models;History;Decision making;Data models;Probabilistic logic;Predictive models;Physics;Navigation;Manifolds},
  doi={10.1002/9781394172092.ch1},
  ISSN={},
  publisher={Wiley},
  isbn={9781394172085},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10953204},}@ARTICLE{8476290,
  author={Li, Xiaoqiang and Chen, Liangbo and Wang, Lu and Wu, Pin and Tong, Weiqin},
  journal={IEEE Access}, 
  title={SCGAN: Disentangled Representation Learning by Adding Similarity Constraint on Generative Adversarial Nets}, 
  year={2019},
  volume={7},
  number={},
  pages={147928-147938},
  abstract={We proposed a novel generative adversarial net called similarity constraint generative adversarial network (SCGAN), which is capable of learning the disentangled representation in a completely unsupervised manner. Inspired by the smoothness assumption and our assumption on the content and the representation of images, we design an effective similarity constraint. SCGAN can disentangle interpretable representations by adding this similarity constraint between conditions and synthetic images. In fact, similarity constraint works as a tutor to instruct generator network to comprehend the difference of representations based on conditions. SCGAN successfully distinguishes different representations on a number of datasets. Specifically, SCGAN captures digit type on MNIST, clothing type on Fashion-MNIST, lighting on SVHN, and object size on CIFAR10. On the CelebA dataset, SCGAN captures more semantic representations, e.g., poses, emotions, and hair styles. Experiments show that SCGAN is comparable with InfoGAN (another generative adversarial net disentangles interpretable representations on these datasets unsupervisedly) on disentangled representation learning. Code is available at https://github.com/gauss-clb/SCGAN.},
  keywords={Gallium nitride;Generative adversarial networks;Generators;Mutual information;Machine learning;Face;Clamps;Generative adversarial nets;representation learning;unsupervised learning},
  doi={10.1109/ACCESS.2018.2872695},
  ISSN={2169-3536},
  month={},}@ARTICLE{10113627,
  author={Fathallah, Mohamed and Sakr, Mohamed and Eletriby, Sherif},
  journal={IEEE Access}, 
  title={Stabilizing and Improving Training of Generative Adversarial Networks Through Identity Blocks and Modified Loss Function}, 
  year={2023},
  volume={11},
  number={},
  pages={43276-43285},
  abstract={Generative adversarial networks (GANs) are a powerful tool for synthesizing realistic images, but they can be difficult to train and are prone to instability and mode collapse. This paper proposes a new model called Identity Generative Adversarial Network (IGAN) that addresses these issues. This model is based on three modifications to the baseline deep convolutional generative adversarial network (DCGAN). The first change is to add a non-linear identity block to the architecture. This will make it easier for the model to fit complex data types and cut down on the time it takes to train. The second change is to smooth out the standard GAN loss function by using a modified loss function and label smoothing. The third and final change is to use minibatch training to let the model use other examples from the same minibatch as side information to improve the quality and variety of generated images. These changes help to stabilize the training process and improve the model’s performance. The performance of the GAN models is compared using the inception score (IS) and the Fréchet inception distance (FID), which are widely used metrics for evaluating the quality and diversity of generated images. The effectiveness of our approach was tested by comparing an IGAN model with other GAN models on the CelebA and stacked MNIST datasets. Results show that IGAN outperforms all the other models, achieving an IS of 13.95 and an FID of 43.71 after traning for 200 epochs. In addition to demonstrating the improvement in the performance of the IGAN, the instabilities, diversity, and fidelity of the models were investigated. The results showed that the IGAN was able to converge to a distribution of the real data more quickly. Furthermore, the experiments revealed that IGAN is capable of producing more stable and high-quality images. This suggests that IGAN is a promising approach for improving the training and performance of GANs and may have a range of applications in image synthesis and other areas.},
  keywords={Training;Generators;Generative adversarial networks;Smoothing methods;Data models;Standards;Optimization;Generative adversarial network;deep learning;mode collapse;label smoothing;identity block},
  doi={10.1109/ACCESS.2023.3272032},
  ISSN={2169-3536},
  month={},}@ARTICLE{11098884,
  author={Pathirana, Nethmi and Imtiaz, Azma and Saheel, Shakir and Karunanayaka, Kasun and David Cheok, Adrian},
  journal={IEEE Access}, 
  title={CRGAN: A Context-Aware Clothing Design and Recommendation System for Young Sri Lankan Females Using Generative Adversarial Networks}, 
  year={2025},
  volume={13},
  number={},
  pages={135776-135790},
  abstract={The fashion industry is constantly undergoing notable transformations fueled by advancements in technology, particularly AI and ML. This shift is driven by the desire for personalized clothing recommendations, especially among young females, who seek tailored suggestions based on their preferences, climate, and style. While traditional recommendation systems rely on existing databases to suggest predefined outfit options, this research takes a novel approach by integrating generative modeling techniques to create unique outfit designs based on contextual factors. The proposed system leverages a Conditional Generative Adversarial Network (GAN) model, trained on three predefined parameters–attire type, temperature conditions, and the user’s skin tone. This innovative integration of context-aware features marks a significant advancement over prior research, which has largely neglected these combined parameters, particularly in the context of cultural demographics. Targeting young Sri Lankan females, this study fills a critical gap in generative clothing systems by addressing the unique cultural and environmental needs of this population. Experiment results on a labeled dataset demonstrate the model’s ability to generate accurate and personalized outputs based on up to three input parameters. Results are verified through quantitative model evaluations and user studies, underscoring the system’s potential to redefine personalized fashion recommendations.},
  keywords={Training;Generative adversarial networks;Data models;Image synthesis;Clothing;Cultural differences;Adaptation models;Recommender systems;Meteorology;Deep learning;Context-aware recommendation;deep learning;generative adversarial networks;image generation},
  doi={10.1109/ACCESS.2025.3593498},
  ISSN={2169-3536},
  month={},}@ARTICLE{10025749,
  author={Tantawy, Dina and Zahran, Mohamed and Wassal, Amr G.},
  journal={IEEE Access}, 
  title={PTcomp: Post-Training Compression Technique for Generative Adversarial Networks}, 
  year={2023},
  volume={11},
  number={},
  pages={9763-9774},
  abstract={In a time of virtual spaces, the usage of generative adversarial networks is inevitable. Generative adversarial networks (GANs) are generative deep-learning models that can generate realistic data. GANs have been used in many applications like text-to-image, image-to-image, image synthesis, speech synthesis, etc. Its power lies in the diversity and novelty of the generated data. Despite their advantages, GANs are resource-hungry. GANs’ output resolution and high correlation make it more challenging to compress and fit on edge-devices storage and power budget. Hence, traditional compression techniques are not the best fit to use with GANs. Additionally, GANs training instability adds another dimension of difficulty. Therefore, compression techniques that require retraining are challenging for GANs. In this paper, we developed a weight clustering technique to compress GANs without the need for retraining, hence the name post-training compression technique (PTcomp). We also proposed a clustered-based pruning which adds more savings. Experiments on Cyclegan, Deep convolution gan (DCGAN), and Stargan using several datasets show the superiority of our technique against traditional post-training quantization. Our technique provides a 4x to 8x compression ratio with comparable quality to original models and 14% fewer mac operations due to pruning.},
  keywords={Generative adversarial networks;Generators;Quantization (signal);Training;Mathematical models;Clustering algorithms;Tensors;Compression;deep-learning;generative adversarial networks;post-training;clustering;pruning},
  doi={10.1109/ACCESS.2023.3239786},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10381195,
  author={Zeng, Ang and Cheng, Xusen and Wang, Yajie},
  booktitle={2023 8th International Conference on Data Science in Cyberspace (DSC)}, 
  title={Exploring the Factors and Influence Mechanisms of User Loyalty for Generative AI}, 
  year={2023},
  volume={},
  number={},
  pages={397-400},
  abstract={This article explores the antecedent variables and mechanisms of influence for user satisfaction with generative AI. The variables and models were extracted through a literature review, combining the technology acceptance model, self-determination theory, and anthropomorphism and perceptual intelligence as two domain-specific influences on generative AI. Data was collected by distributing a questionnaire to conduct an empirical study. The empirical results showed that perceived usefulness, perceived intelligence, and anthropomorphism have a significant positive impact on user satisfaction, while the mechanisms that influence loyalty are through the individual's internal perception rather than external pressure. The paper proposes a user loyalty model for generative AI that extends loyalty research to the emerging field of generative AI and provides guidance for the rapid iterative development of generative AI.},
  keywords={Technology acceptance model;Bibliographies;Cyberspace;Data science;Data models;Iterative methods;Data mining;artificial intelligence;generative AI;loyalty;TAM;self-determination theory},
  doi={10.1109/DSC59305.2023.00063},
  ISSN={},
  month={Aug},}@ARTICLE{10356776,
  author={Wu, Fei and Ma, Yongheng and Jin, Hao and Jing, Xiao-Yuan and Jiang, Guo-Ping},
  journal={IEEE Signal Processing Letters}, 
  title={MFECLIP: CLIP With Mapping-Fusion Embedding for Text-Guided Image Editing}, 
  year={2024},
  volume={31},
  number={},
  pages={116-120},
  abstract={Recently, generative adversarial networks (GAN) have made remarkable progress, particularly with the advent of Contrastive Language-Image Pretraining (CLIP), which take image and text into a joint latent space, bridging the gap between these two modalities. Several impressive text-guided image editing methods based on GANs and CLIP have emerged. However, in these studies, most of them simply minimize the distance between the target image embedding and text embedding in the CLIP space, and take this objective as network's optimization goal, overlooking the real distance between them may be large. This may result in inability to accurately guide the editing process according to the text prompts and the changes in text-irrelevant attributes. To mitigate this issue, we propose a novel approach named CLIP with Mapping-Fusion Embedding (MFECLIP) for text-guided image editing, which comprises two components: the MFE Block and MFE Loss. Through the MFE Block, we obtain Mapping-Fusion Embedding (MFE), which can further eliminate the modality gap, and it can serve as a superior guide for editing process instead of the original text embedding. Based on contrastive learning, the MFE Loss is designed to achieve accurate alignment between the target image and text prompt. We have conducted extensive experiments on real datasets, CUB and Oxford, demonstrating the favorable performance of the proposed method.},
  keywords={Semantics;Generative adversarial networks;Training;Task analysis;Flowering plants;Birds;Telecommunications;Text-guided image editing;GAN;CLIP},
  doi={10.1109/LSP.2023.3342649},
  ISSN={1558-2361},
  month={},}@INPROCEEDINGS{10642894,
  author={Deng, Zhichao and Xiong, Siting and Zhang, Bochen and Li, Qingquan},
  booktitle={IGARSS 2024 - 2024 IEEE International Geoscience and Remote Sensing Symposium}, 
  title={TADGAN-Based Anomaly Detection for PS-InSAR Deformation}, 
  year={2024},
  volume={},
  number={},
  pages={7420-7423},
  abstract={Interferometric Synthetic Aperture Radar (InSAR) has become a widely used and efficient tool for monitoring large-scale, long-term land subsidence. Most applications, especially those related to risky assessment, utilize only the mean deformation rate derived through a linear fit of the InSAR-derived time series deformations without considering the full-time sequence. In this way, the embedded information, such as the onset, duration, and patterns of abnormal deformations, is ignored. This information, however, should not be compromised as it is critical for assessing the risky deformations and recognizing the causal factors. Due to the large data volume, processing the full-time-series information derived by InSAR analysis can be a challenge. In this study, we propose to use the Time-series Anomaly Detection Generative Adversarial Network (TadGAN) to deal with the time series InSAR deformation and recognize the onset and duration of abnormal epochs. The proposed method has been tested with InSAR-derived results over the Hong Kong airport region. It performs better than conventional risk assessment methods, such as the one based on Mean Absolute Deviation (MAD) outlier detection.},
  keywords={Training;Deformation;Time series analysis;Geoscience and remote sensing;Generative adversarial networks;Airports;Risk management;PS-InSAR;GAN;anomaly detection;time series deformation},
  doi={10.1109/IGARSS53475.2024.10642894},
  ISSN={2153-7003},
  month={July},}@ARTICLE{10379614,
  author={Wang, Weili and Abbasi, Omid and Yanikomeroglu, Halim and Liang, Chengchao and Tang, Lun and Chen, Qianbin},
  journal={IEEE Network}, 
  title={VHetNets for AI and AI for VHetNets: An Anomaly Detection Case Study for Ubiquitous IoT}, 
  year={2024},
  volume={38},
  number={6},
  pages={170-177},
  abstract={Vertical heterogeneous networks (VHetNets) and artificial intelligence (AI) play critical roles in 6G and beyond networks. This article presents an AI-native VHetNets architecture to enable the synergy of VHetNets and AI, thereby supporting varieties of AI services while facilitating the intelligent network management. Anomaly detection stands as an essential AI service across various applications in Internet of Things (IoT), including intrusion detection, state monitoring, analysis of device activities, and security supervision. In this article, we first discuss the possibilities of VHetNets used for distributed AI model training to provide the anomaly detection service for ubiquitous IoT, i.e., VHetNets for AI. After that, we study the application of AI approaches in helping implement the intelligent network management functionalities for VHetNets, i.e., AI for VHetNets, whose aim is to facilitate the efficient implementation of the anomaly detection service. Finally, a case study is presented to demonstrate the efficiency and effectiveness of the proposed AInative VHetNets-enabled anomaly detection framework.},
  keywords={Artificial intelligence;Internet of Things;Sensors;Data models;Autonomous aerial vehicles;Anomaly detection;Training;Heterogeneous networks;Ubiquitous computing},
  doi={10.1109/MNET.2023.3349309},
  ISSN={1558-156X},
  month={Nov},}@INBOOK{10789125,
  author={Monteiro, Ana Carolina Borges and França, Reinaldo Padilha and Arthur, Rangel and Iano, Yuzo},
  booktitle={Deep Learning for Personalized Healthcare Services}, 
  title={An overview of the technological performance of deep learning in modern medicine}, 
  year={2021},
  volume={},
  number={},
  pages={225-244},
  abstract={: Artificial intelligence is a technology that uses several layers of data and information, encompassing algorithms, machine and also deep learning models, pattern matching, and even cognitive computing, learning to digitally assimilate data, gain insights on diagnoses, the variability of medical treatment, as also patient outcome with machine learning (ML). ML programming models are trained on data sets before being implemented, with properties to create their own rules or questions. It automatically and gradually improves their efficiency, accuracy, and precision with the number of experiments in which these models (algorithms) are trained. Deep learning (DL) replicates the basic structure of biological neurons, using complex algorithms, allowing predictive digital health and also allowing logical and complex structures to be established, without the need for human supervision. In other words, it is a digital architecture to study, understand, and learn how to interpret information related to the object of study that helps to more accurately identify a tumor, for example, considering that they do not need to be an expert in the field to perform this type of identification through technology. In the same sense as more pertinent diagnostic recommendations, are some examples of the application of this type of technology that can be widely used in various health segments. Emphasizing that it will give the doctor and the patient more accurate diagnoses, faster diagnoses, more assertive treatments, better-calculated risks, possibility of detecting infections, abnormalities, and diseases in a matter of seconds, the use of deep learning in health is very well accepted for reducing the margin of human error. Therefore, this manuscript aims to provide an updated overview of DL, concerning its essential concepts and in the field of medicine, as also its relationships in frameworks with meaningful intelligent properties, enabling cost-effective personalized digital services as a primary goal in healthcare in the current modern scenario.},
  keywords={Medical diagnostic imaging;Artificial intelligence;Medical services;Image recognition;Digital images;Deep learning;Data models;Computational modeling;Biological system modeling;Drugs},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9783110708172},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10789125},}@INPROCEEDINGS{11042202,
  author={Lv, Wenlong and Wang, Yipeng and Tang, Fei and Tang, Yuwen},
  booktitle={2025 7th International Conference on Information Science, Electrical and Automation Engineering (ISEAE)}, 
  title={Adversarial Multi-feature Fusion for Sentiment Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={806-810},
  abstract={Existing text sentiment classification methods suffer from several limitations: they struggle to capture global semantic information, fail to fully utilize positional and relational features of words, and exhibit inadequate handling of long-range semantic dependencies or emotional transitions. Moreover, the suboptimal fusion of features often leads to unsatisfactory classification accuracy. To address these issues, this paper proposes a multichannel sentiment analysis model. First, BERT is employed for data preprocessing. Next, Graph Convolutional Networks (GCN) are utilized to extract part-of-speech and syntactic features, while Convolutional Neural Networks (CNN) capture positional and local semantic features. Additionally, Bidirectional Simple Recurrent Units (Bi-SRU) are applied to model contextual dependencies, enabling deep exploration of textual features. Finally, a Generative Adversarial Network (GAN) is introduced to fuse these features, enhancing their complementarity. Ablation experiments validate the effectiveness of each module, and comparative results on public datasets demonstrate that the proposed model outperforms existing baseline methods, showcasing its superior performance.},
  keywords={Training;Sentiment analysis;Analytical models;Accuracy;Semantics;Syntactics;Feature extraction;Generative adversarial networks;Encoding;Context modeling;Deep Learning;Local Feature Extraction;Multi-Channel Sentiment Analysis Model;Feature Fusion},
  doi={10.1109/ISEAE64934.2025.11042202},
  ISSN={},
  month={April},}@ARTICLE{10813561,
  author={Yang, Yaoqi and Du, Hongyang and Sun, Geng and Xiong, Zehui and Niyato, Dusit and Han, Zhu},
  journal={IEEE Network}, 
  title={Exploring Equilibrium Strategies in Network Games With Generative AI}, 
  year={2025},
  volume={39},
  number={5},
  pages={191-200},
  abstract={Game theory offers a powerful framework for analyzing strategic interactions among decision-makers, providing tools to model, analyze, and predict their behavior. However, implementing game theory can be challenging due to difficulties in deriving solutions, understanding interactions, and ensuring optimal performance. Traditional non-AI and discriminative AI approaches have made valuable contributions but struggle with limitations in handling large-scale games and dynamic scenarios. In this context, generative AI emerges as a promising solution because of its superior data analysis and generation capabilities. This paper comprehensively summarizes the challenges, solutions, and outlooks of combining generative AI with game theory. We start with reviewing the limitations of traditional non-AI and discriminative AI approaches in employing game theory, and then highlight the necessity and advantages of integrating generative AI. Next, we explore the applications of generative AI in various stages of the game theory lifecycle, including model formulation, solution derivation, and strategy improvement. Additionally, from game theory viewpoint, we propose a generative AI-enabled framework for optimizing machine learning model performance against false data injection attacks, supported by a case study to demonstrate its effectiveness. Finally, we outline future research directions for generative AI-enabled game theory, paving the way for its further advancements and development.},
  keywords={Game theory;Artificial intelligence;Generative AI;Predictive models;Digital twins;Data models;Analytical models;Standards;Adaptation models;Generative AI;game theory;game theoretical model formulation;equilibrium solution derivation},
  doi={10.1109/MNET.2024.3521887},
  ISSN={1558-156X},
  month={Sep.},}@INPROCEEDINGS{10332091,
  author={Zheng, Yangboyin and Li, Shidong and Su, Ting and Chi, Kuo and Yang, Yongqin and Xing, Wenqing},
  booktitle={2023 IEEE 6th International Conference on Pattern Recognition and Artificial Intelligence (PRAI)}, 
  title={An Efficient Wave Propagation Prediction Model Generated by CycleGAN with Ray Tracing Data}, 
  year={2023},
  volume={},
  number={},
  pages={1130-1135},
  abstract={The ray tracing technique is an application of optical ray technology in the field of electromagnetic computing, which can accurately consider various propagation paths of electromagnetic waves with high computational accuracy but large computational volume. In this paper, we generate an accurate and efficient prediction model for urban radio propagation using Cycle Generative Adversarial Network (CycleGAN). The color information of red, green and blue (RGB) channels of the planar images of the urban area is used to characterize the power of radio wave propagation, CycleGAN is used to learn this information to achieve the prediction effect. Compared with the traditional modeling methods, the method proposed in this paper can greatly reduce the time required for prediction, and the structural similarity between the prediction and the actual simulation results can reach 0.95. It takes 10.85s to calculate the same number of city area images using Winprop software, while the proposed method only needs 3.08s, which saves a lot of time.},
  keywords={Image color analysis;Propagation;Simulation;Urban areas;Electromagnetic scattering;Green products;Predictive models;wave propagation;ray tracing;cycle generative adversarial network (CycleGAN)},
  doi={10.1109/PRAI59366.2023.10332091},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8462579,
  author={Han, Jing and Zhang, Zixing and Ren, Zhao and Ringeval, Fabien and Schuller, Björn},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Towards Conditional Adversarial Training for Predicting Emotions from Speech}, 
  year={2018},
  volume={},
  number={},
  pages={6822-6826},
  abstract={Motivated by the encouraging results recently obtained by generative adversarial networks in various image processing tasks, we propose a conditional adversarial training framework to predict dimensional representations of emotion, i. e., arousal and valence, from speech signals. The framework consists of two networks, trained in an adversarial manner: The first network tries to predict emotion from acoustic features, while the second network aims at distinguishing between the predictions provided by the first network and the emotion labels from the database using the acoustic features as conditional information. We evaluate the performance of the proposed conditional adversarial training framework on the widely used emotion database RECOLA. Experimental results show that the proposed training strategy outperforms the conventional training method, and is comparable with, or even superior to other recently reported approaches, including deep and end-to-end learning.},
  keywords={Training;Artificial neural networks;Gallium nitride;Generators;Generative adversarial networks;Feature extraction;Predictive models;Emotion recognition;conditional adversarial training;generative adversarial network},
  doi={10.1109/ICASSP.2018.8462579},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10008363,
  author={Alanazi, Fatimah},
  booktitle={2022 14th International Conference on Computational Intelligence and Communication Networks (CICN)}, 
  title={Comparative Analysis of Deep Fake Detection Techniques}, 
  year={2022},
  volume={},
  number={},
  pages={119-124},
  abstract={Deep learning and artificial intelligence are important knowledge areas that have provided solutions allowing the successful resolution of complex problems. Some of these problems include, but are not limited to, human-level control, data analytics and other digitisation challenges. One of the offshoots of deep learning is a concept termed ‘deepfake’, which can be described as the imposition of video of a face image from a source to video of the face image of a target individual in order to make the targeted person appear to express the content of the source video [2]. It is important to establish the fact that deepfakes have been used for malicious purposes, becoming a threat to national security, privacy, democracy, and society at large. It is, therefore, fundamental to review the science behind the method, and the available detection techniques to curtail this digital innovation, so as to reduce its level of threat; that is the focus of this paper.},
  keywords={Deep learning;Deepfakes;Technological innovation;Privacy;Image resolution;Recurrent neural networks;Fingerprint recognition;deepfakes;artificial intelligence;deep learning;autoencoders;forensics;GAN;generative adversarial networks},
  doi={10.1109/CICN56167.2022.10008363},
  ISSN={2472-7555},
  month={Dec},}@INPROCEEDINGS{10999131,
  author={Azodinia, Mohammadreza and Mudabbir, Mohamed and Ardabili, Sina and Varkonyi-Koczy, Annamaria and Iskakov, Kazizat and Mosavi, Amir},
  booktitle={2025 IEEE 12th International Conference on Computational Cybernetics and Cyber-Medical Systems (ICCC)}, 
  title={Service Life Modeling of Pavement with Ensemble Learning}, 
  year={2025},
  volume={},
  number={},
  pages={000167-000174},
  abstract={Random Forest (RF) is an ensemble learning which creates multiple decision trees and combines their outputs for creating models with less over-fitting. In this study, we apply RF to model the remaining service life (RSL) of rural pavements, a critical factor for developing optimal maintenance strategies and ensuring long-lasting infrastructure. We utilize key variables such as asphalt concrete thickness, base thickness, and surface temperature, along with data from Falling Weight Deflectometer (FWD) measurements. RF demonstrated performance in predicting RSL with consistent accuracy across a variety of conditions. The ensemble nature of RF allows it to effectively manage complex interactions among variables and handle the inherent variability in pavement performance data which makes it well-suited for rural road networks, where environmental and material differences are significant. While some sensitivity to parameter adjustments was noted, the robustness and reliability of RF highlights its potential to be a transformative tool in rural pavement management.},
  keywords={Radio frequency;Temperature measurement;Temperature distribution;Asphalt;Accuracy;Roads;Telecommunication traffic;Ensemble learning;Random forests;Testing;ensemble learning;ensemble;random forest;artificial intelligence;machine learning;remaining service life;service life;pavement;big data;data mining;engineering;mathematics;deep learning;civil engineering;data science;generative AI;applied artificial intelligence;applied mathematics;applied informatics;information systems;soft computing;geoscience;earth science;industry 4.0;society 5.0;AI;XAI;simulation;sustainable development;sustainable development goals;neural networks;pavement engineering;asphalt pavement;concrete pavement;pavement durability;traffic load;surface roughness;asphalt mix;concrete mix;bitumen;aggregates;subgrade;base course;reinforced pavement;flexible pavement;rigid pavement;pavement distress;cracking;rutting;skid resistance;drainage performance;load-bearing capacity;structural integrity;pavement degradation;thermal expansion;ground-penetrating radar;radargram analysis;non-destructive testing;pavement condition index;road surface profiling;geotechnical investigation;structural health monitoring;machine learning for pavement defects;predictive maintenance},
  doi={10.1109/ICCC64928.2025.10999131},
  ISSN={2689-7768},
  month={April},}@ARTICLE{11142690,
  author={Gong, Yongzhi and Yang, Zhongyan and Luo, Zhengya and Zhang, Zequ and Zhang, Jijun},
  journal={IEEE Access}, 
  title={Research on Fast Calculation Method for Relay Protection Setting Mismatch Points of Lines Based on Deep Learning}, 
  year={2025},
  volume={13},
  number={},
  pages={151714-151725},
  abstract={In complex ring networks, a significant amount of time is typically required to determine the coordination relationships of backup protection settings during online adjustment, which affects the efficiency of the online setting process. To address this, the paper introduces a data-driven approach by applying artificial intelligence technology—specifically, for the first time—into the field of online setting. A fast computation scheme for online backup protection setting based on Generative Adversarial Networks (GANs) is proposed. Firstly, a conditional GAN based on the Wasserstein distance is constructed, using system operating modes as conditional labels. The coordination pairs of backup protection settings are transformed into matrix indices, forming a backup protection coordination matrix, which serves as real sample data for GAN training. The generator and discriminator networks of the GAN are primarily composed of Convolutional Neural Networks (CNNs), and batch normalization is applied to the outputs of the neural networks to improve training stability. Next, the specific implementation of the GAN-based online setting scheme for backup protection is presented. Parallel computing techniques are employed to accelerate the computation of both the CNN and the setting values, further enhancing the efficiency of the online adjustment process. Finally, the IEEE 39-bus system is used as an example to compute backup protection coordination matrices under various operating conditions, thus constructing the dataset required for GAN training and validating the proposed scheme. Simulation results show that the proposed method can learn the complex coordination relationships among various backup protection settings from real sample data via GANs. It can generate the corresponding coordination matrix according to different operating modes, thereby achieving fast computation for online backup protection setting.},
  keywords={Protection;Generative adversarial networks;Generators;Training;Noise;Real-time systems;Vectors;Protective relaying;Computational efficiency;Artificial intelligence;Backup protection;online setting;generative adversarial network;operating mode;protection coordination pair;data-driven},
  doi={10.1109/ACCESS.2025.3603252},
  ISSN={2169-3536},
  month={},}@INBOOK{10952520,
  author={Haq, Rashed},
  booktitle={Enterprise Artificial Intelligence Transformation}, 
  title={The Future of Society, Work, and AI}, 
  year={2020},
  volume={},
  number={},
  pages={289-311},
  abstract={Summary <p>This chapter looks at the future of society and work, and how near&#x2010;future developments within artificial intelligence (AI) &#x2013; that is, developments prior to the arrival of artificial general intelligence &#x2013; will impact both the advances we expect and the challenges we will face. In the years to come, AI will show up in many applications, from robotics to productivity enhancements to the emerging technology of quantum computing. In robotics, companies such as Intuitive Surgical are already developing robot&#x2010;assisted technologies, tools, and services for surgical operations. Machines will interact with one another using AI algorithms and make decisions about the production chain without the need for human intervention. Even during the time of the industrial revolution, Karl Marx, in the chapter on machinery and modern industry from his book Capital.</p>},
  keywords={Artificial intelligence;Robots;Medical services;Faces;Business;Surveillance;Safety;Regulation;Internet;Employment},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781119665861},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952520},}@INPROCEEDINGS{10400632,
  author={Zhang, Y. and Wu, J. and Yi, H. and Deng, W. and Li, Q.},
  booktitle={5th International Conference on Artificial Intelligence and Advanced Manufacturing (AIAM 2023)}, 
  title={Design of an intelligent reminder system based on EEG monitoring}, 
  year={2023},
  volume={2023},
  number={},
  pages={48-52},
  abstract={EEG waves reflect the synchronized firing of neurons in the brain, and different waveform patterns are associated with different cognitive states, such as attention, relaxation, or sleep. In this paper, we design an intelligent reminder system based on EEG monitoring. The process of system involves several steps, including pre-processing, filtering, artifact removal, feature extraction, and classification. Preprocessing involves removing any artifacts or noise from the raw EEG signal. Filtering is used to remove unwanted frequencies or amplify desired frequencies. Artifact removal techniques include independent component analysis and template matching, which can identify and remove artifacts such as eye blinks or heartbeats. Feature extraction algorithms aim to extract significant information from the processed signal. Classification algorithms are then used to classify the extracted features into specific categories, such as cognitive states, diseases, or mental tasks. Commonly used classification algorithms include support vector machines, neural networks, and linear discriminant analysis. EEG collection can potentially have an effect on reminding fatigue driving, as it may increase drivers' awareness of their cognitive states and alert them to signs of fatigue. By monitoring the electrical activity of the brain, EEG can provide real-time feedback on changes in cognitive states, such as decreased attention or increased drowsiness.},
  keywords={},
  doi={10.1049/icp.2023.2914},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10696448,
  author={Singh, Gurpreet and Guleria, Kalpna and Sharma, Shagun},
  booktitle={2024 Second International Conference on Intelligent Cyber Physical Systems and Internet of Things (ICoICI)}, 
  title={A Fine-Tuned MobileNetV3 Model for Real and Fake Image Classification}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This study focuses on the utilization of the MobileNet model for the classification of artificial and real images, addressing the increasing demand for accurate image identification in the digital realm. Through the implementation of convolutional neural networks (CNNs), specifically optimized for mobile and embedded devices, we aim to distinguish between authentic and digitally manipulated images efficiently. After training the MobileNet model on a dataset comprising both real and artificial images, we evaluated its performance on a validation set. The results indicate a validation accuracy of 95.02%, demonstrating the model's robustness in distinguishing between the two image categories. Additionally, the validation loss was found to be 0.1621, indicating minimal discrepancies between predicted and actual labels. Furthermore, the precision and recall metrics provide insights into the model's ability to identify real and artificial images accurately. With a validation precision of 0.9494 and a validation recall of 0.9511, the MobileNet model showcases high precision in correctly classifying both image types while minimizing false positives and negatives. Overall, these findings highlight the effectiveness of the MobileNet model in artificial image detection, offering a reliable solution for combating the proliferation of manipulated visuals in various domains, from social media to journalism and beyond.},
  keywords={Training;Deepfakes;Adaptation models;Visualization;Accuracy;Social networking (online);Computational modeling;Transfer learning;Topology;Image classification;Machine learning;Deep learning;Image processing;MobileNet Model;Artificial Images;Real Image},
  doi={10.1109/ICoICI62503.2024.10696448},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{11089795,
  author={Shanthi, A.S. and Nikhil, M. and M, Naveen Kumar and D, Sam Alwin Satyavasagan and D, Santhosh Kumar},
  booktitle={2025 6th International Conference on Inventive Research in Computing Applications (ICIRCA)}, 
  title={An Approach for Detecting Myocardial Infarction and Multi-Label Classification Using GAN, GNNs and DBN}, 
  year={2025},
  volume={},
  number={},
  pages={1811-1815},
  abstract={Myocardial Infarction (MI), also referred to as heart attack is leading cause of death globally, commonly caused by issues in the coronary arteries and Left Ventricle (LV) changes. Early medical care is essential to minimize the chances of death from MI. Existing algorithms are effective at identifying most cases of MI but tend to fail to catch early signs of the disease. In most cases, detection of MI depends on algorithms such as DNN [4], CNN, RNN, and LSTM. We're investigating advanced technologies like GAN, DBN, and GNNs. Such novel technologies have the potential to enhance early detection and more accurate diagnosis resulting in improved patient outcomes and reduced mortality. With these novel tools, we seek to improve the accuracy and efficacy of MI detection and intervention.},
  keywords={Neurology;Accuracy;Recurrent neural networks;Mortality;Multi label classification;Medical services;Myocardium;Generative adversarial networks;Long short term memory;Medical diagnostic imaging;Myocardial Infarction;Cardiovascular disease;Deep Learning;Convolutional Neural Network;Recurrent Neural Network;Deep Neural Network;Long Short-Term Memory},
  doi={10.1109/ICIRCA65293.2025.11089795},
  ISSN={},
  month={June},}@INPROCEEDINGS{8508269,
  author={Day, Min-Yuh and Lin, Jian-Ting and Chen, Yuan-Chih},
  booktitle={2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)}, 
  title={Artificial Intelligence for Conversational Robo-Advisor}, 
  year={2018},
  volume={},
  number={},
  pages={1057-1064},
  abstract={With the advent of the artificial intelligence (AI) era, the combination of AI with financial technology (FinTech) has become a development trend in the financial industry. However, deep learning (DL) on the application of automated financial management has been rarely investigated. Thus, this research focuses on the applications of FinTech and DL in asset allocation and aims to optimize investment portfolio. The best investment portfolio in index-based funds based on Taiwan's index-type security investment trust funds are the main investment targets. Time series models for DL, that is, long short-term memory, predict the increase of each investment target and find the best investment portfolio in combination with the relevant asset allocation theory. In this research, we use the Markowitz mean-variance and Black-Litterman models as our asset allocation models for robo-advisor. Results show that the Black-Litterman model has a better accumulated return performance than the Morkowitz model and outperforms other strategies. The Human-Computer Interaction (HCI) dialogue service adopts artificial intelligence markup language (AIML) and a generative model. The main contribution of this paper is that we have developed an integrated knowledge-based and generative-based models for AI conversational robo-advisor.},
  keywords={Resource management;Portfolios;Investment;Computational modeling;Neural networks;Knowledge based systems;Artificial Intelligence (AI);Conversational Commerce;Deep Learning;Financial Technology (FinTech);Robo-Advisor},
  doi={10.1109/ASONAM.2018.8508269},
  ISSN={2473-991X},
  month={Aug},}@INPROCEEDINGS{10594061,
  author={Shi, Yuzhe},
  booktitle={2024 IEEE 4th International Conference on Electronic Technology, Communication and Information (ICETCI)}, 
  title={Automatic Face Image Restoration Based on an Improved Generative Adversarial Network}, 
  year={2024},
  volume={},
  number={},
  pages={358-365},
  abstract={Recent advance in computer network and camera technology, the volume of face image data on the internet is expanding rapidly. However, these images often suffer from hole-like missing or occlusions that can compromise their visual presentation. Identifying and reconstructing such occlusions is a key solution for these problems, which aims to detect all the missing and fill them with suitable pixels to complete the restoration task. The technology remains a challenge due to the difficulties of high computational complexity, varied shapes of obstructions and high requirement on the visual consistency across the image. In this paper, we propose a novel face image restoration method that builds on the traditional generative adversarial network (GAN) by incorporating a classifier. This addition enables the method to classify the images based on the different face features to be repaired and the classified images are repaired after entering the generative adversarial network of the corresponding category. Experimental results indicate that the proposed method can achieve great performance in many indexes and produce better results when compared with existing methods.},
  keywords={Visualization;Shape;Generative adversarial networks;Feature extraction;Generators;Skin;Image restoration;Face image restoration;Generative adversarial network;Image classifier;Face feature},
  doi={10.1109/ICETCI61221.2024.10594061},
  ISSN={},
  month={May},}
