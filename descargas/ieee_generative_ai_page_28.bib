@INPROCEEDINGS{10097956,
  author={Sauber-Cole, Rick and Khoshgoftaar, Taghi M. and Johnson, Justin M.},
  booktitle={2022 IEEE 34th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={GANs for Class-Imbalanced Data: A Meta-Analysis of GitHub Projects}, 
  year={2022},
  volume={},
  number={},
  pages={1419-1424},
  abstract={Generative Adversarial Networks (GANs) have increasingly been the subject of intense research interest for their ability to augment datasets to correct for class imbalance. The collaborative and complex code bases for these GANs are often written in a high-level, general-purpose programming language such as Python and housed on the GitHub platform. The goal of this work is to summarize the research aims of 18 GitHub repositories of projects that implement GANs in regimes of class imbalance, in both tabular and non-tabular settings, as well to summarize and analyze the patterns and characteristics of these code bases. With respect to the latter task, we conduct our analysis from a perspective of library reliance and from the structural properties of the code base. The insights discovered herein are meant to serve as a gentle introduction to the various tools available and recommended best practices for the enterprising researcher seeking to apply GANs as data augmenters in imbalanced settings.},
  keywords={Deep learning;Computer vision;Codes;Focusing;Generative adversarial networks;Data engineering;Libraries;class imbalance;generative adversarial networks;GitHub;PyTorch;TensorFlow},
  doi={10.1109/ICTAI56018.2022.00214},
  ISSN={2375-0197},
  month={Oct},}@INPROCEEDINGS{11041546,
  author={Gayathri, S. and Synthan, P and Vishnu Karthikeyan, K and Gokulnath, V},
  booktitle={2025 3rd International Conference on Artificial Intelligence and Machine Learning Applications Theme: Healthcare and Internet of Things (AIMLA)}, 
  title={An AI-Powered Chatbot for Advanced Scan Interpretation of Brain Tumors, Pneumonia, and Lung Cancer}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={By combining Natural Language Processing with cutting-edge Machine Learning techniques, the intelligent medical chatbot will transform healthcare by helping to diagnose brain tumors, pneumonia, and different types of cancer. It will be possible for users to upload CT and MRI scans for a wide-range analysis using TensorFlow-driven deep learning models that will be accurate in detecting abnormalities. The system will also allow interactive medical consultations. Users will be able to talk about symptoms, illnesses, and diagnoses in a natural, conversational way. It will be supported by LangChain for intelligent dialogue management, Sentence Transformers for semantic understanding, and FAISS for rapid medical information retrieval. Ngrok API will be ensuring secure and scalable web deployment to let as many people reach the chatbot. This is an innovation that combines advanced image analysis with conversational AI to enhance medical diagnostics. It provides a new simple yet extremely effective tool for health assessment and consultation to people.},
  keywords={Deep learning;Pneumonia;Image analysis;Accuracy;Semantics;Brain tumors;Chatbots;Information retrieval;User experience;Medical diagnostic imaging;Medical Chatbot;Image Analysis;Natural Language Processing;Cancer Detection;Machine Learning;Deep Learning},
  doi={10.1109/AIMLA63829.2025.11041546},
  ISSN={},
  month={April},}@ARTICLE{10848481,
  author={Li, Jun and Jiang, Wentao and Shen, Liyan and Ren, Yawei},
  journal={IEEE Internet of Things Journal}, 
  title={Optimized Frequency Collaborative Strategy Drives AI Image Detection}, 
  year={2025},
  volume={12},
  number={11},
  pages={16192-16203},
  abstract={Artificial intelligence (AI) image generation powered by large language model (large language modelss (LLMs)) enables highly realistic image synthesis and manipulation, posing significant security risks to Internet of Things (IoT) systems, particularly in identity authentication and data integrity. Although multidomain synthetic image detection has advanced, how spatial and frequency domain features affect decision making is still an open question, causing models to emphasize less critical areas and fall into local optimality. Through multidomain empirical analysis, we reveal the common contrastive differences in image textures and further demonstrate that frequency analysis helps capture the spectral differences in images. Building on this, we propose the collaborative spatial and frequency detector (CSFD). First, the image is decomposed into strong and weak texture regions in the spatial domain. Second, it aggregates different components in the frequency domain, using weighted channel attention to enhance spatial reasoning. Finally, the texture regions are combined to discriminate synthetic images. Experimental results demonstrate that incorporating channel attention based on frequency information improves the detection of synthetic images with spectral defects. On a comprehensive AI-generated image detection benchmark, the proposed method improves accuracy by 2.61% over current methods. Our code is available at https://github.com/JackPotProject/Frequency-Collaborative.},
  keywords={Frequency-domain analysis;Feature extraction;Internet of Things;Detectors;Filters;Security;Collaboration;Semantics;Image synthesis;Discrete cosine transforms;artificial intelligence (AI) image detection;deep learning;domain fusion;Internet of Things (IoT) security},
  doi={10.1109/JIOT.2025.3531053},
  ISSN={2327-4662},
  month={June},}@INPROCEEDINGS{9377923,
  author={Zhang, Xiaoguang and Xia, Xuan and Li, Nan and Lin, Ma and Song, Junlin and Ding, Ning},
  booktitle={2020 IEEE International Conference on Big Data (Big Data)}, 
  title={Exploring the Tricks for Road Damage Detection with A One-Stage Detector}, 
  year={2020},
  volume={},
  number={},
  pages={5616-5621},
  abstract={Fast and accurate road damage detection is essential for the automatization of road inspection. This paper describes our solution submitted to the Global Road Damage Detection Challenge of the 2020 IEEE International Conference on Big Data, for typical road damage detection in digital images based on deep learning. The recently proposed YOLOv4 is chosen as the baseline network, while the effects of data augmentation, transfer learning, Optimized Anchors, and their combination are evaluated. We propose a novel road damage data generation method based on a generative adversarial network, which can generate multi-class samples with a single model. The evaluation results demonstrate the effectiveness of different tricks and their combinations on the road damage detection task, which provides a reference for practical application. The code of our solution is available at https://github.com/ZhangXG001/RoadDamgeDetection.git.},
  keywords={Roads;Conferences;Transfer learning;Detectors;Big Data;Generative adversarial networks;Data models;road damage detection;deep learning;data augmentation;generative adversarial network},
  doi={10.1109/BigData50022.2020.9377923},
  ISSN={},
  month={Dec},}@ARTICLE{9729410,
  author={Li, Shaojie and Lin, Mingbao and Wang, Yan and Chao, Fei and Shao, Ling and Ji, Rongrong},
  journal={IEEE Transactions on Multimedia}, 
  title={Learning Efficient GANs for Image Translation via Differentiable Masks and Co-Attention Distillation}, 
  year={2023},
  volume={25},
  number={},
  pages={3180-3189},
  abstract={Generative Adversarial Networks (GANs) have been widely-used in image translation, but their high computation and storage costs impede the deployment on mobile devices. Prevalent methods for CNN compression cannot be directly applied to GANs due to the peculiarties of GAN tasks and the unstable adversarial training. To solve these, in this paper, we introduce a novel GAN compression method, termed DMAD, by proposing a Differentiable Mask and a co-attention Distillation. The former searches for a light-weight generator architecture in a training-adaptive manner. To overcome channel inconsistency when pruning the residual connections, an adaptive cross-block group sparsity is further incorporated. The latter simultaneously distills informative attention maps from both the generator and discriminator of a pre-trained model to the searched generator, effectively stabilizing the adversarial training of our light-weight model. Experiments show that DMAD can reduce the Multiply Accumulate Operations (MACs) of CycleGAN by 13× and that of Pix2Pix by 4× while retaining a comparable performance against the full model.},
  keywords={Generators;Training;Generative adversarial networks;Task analysis;Image coding;Complexity theory;Network architecture;Generative adversarial networks;GAN compression;image translation;knowledge distillation;network pruning},
  doi={10.1109/TMM.2022.3156699},
  ISSN={1941-0077},
  month={},}@ARTICLE{9123901,
  author={Li, Xiufang and Sun, Qigong and Li, Lingling and Liu, Xu and Liu, Hongying and Jiao, Licheng and Liu, Fang},
  journal={IEEE Access}, 
  title={SSCV-GANs: Semi-Supervised Complex-Valued GANs for PolSAR Image Classification}, 
  year={2020},
  volume={8},
  number={},
  pages={146560-146576},
  abstract={Polarimetric synthetic aperture radar (PolSAR) image classification has been widely applied in many fields, such as agriculture, meteorology and military. However, some problems, such as the deficiency of labeled data and the underutilization of data information, are always the challenges that can not be ignored in PolSAR image classification. In this paper, a semi-supervised complex-valued generative adversarial networks (SSCV-GANs) is proposed for the first time to address the two issues mentioned above simultaneously. On the one hand, the complex-valued model conforms with the physical mechanism of PolSAR data and it plays an important role for retaining and utilizing amplitude and phase information of PolSAR data. On the other hand, we also present a new complex-valued GANs together with semi-supervised learning to alleviate the problem of insufficient labeled data. Specifically, our complex-valued GANs expands the training data set by generating fake data. Flevoland data and San Francisco data are used to validate the effectiveness of our model. Experimental results show that our model outperforms existing state-of-the-art models in terms of classification accuracy, especially for conditions with fewer labeled data. In particular, the analysis of the statistical distribution of the generated fake data and the real data further demonstrate the effectiveness of the proposed SSCV-GANs.},
  keywords={Data models;Biological neural networks;Gallium nitride;Generative adversarial networks;Semisupervised learning;Recurrent neural networks;Polarimetric synthetic aperture;image classification;complex-valued operations;generative adversarial networks (GANs);semi-supervised learning},
  doi={10.1109/ACCESS.2020.3004591},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10780003,
  author={T, Uma Mageswari and S, Gopinath and A, Rajasekar and G V, Sharmiela and T, Monica and R, Pooja Mercy},
  booktitle={2024 International Conference on Power, Energy, Control and Transmission Systems (ICPECTS)}, 
  title={Deepfake and Face Swapping Detection: A Review}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The rapid growth of deep learning techniques, especially Generative Adversarial Networks (GANs) has paved way to the creation of deepfake and face swapped media, which is posing a scere threat to digital content authenticity .These technologies have advanced to the point that manipulated photos and videos are identical to the original material, which has caused worries in a number of industries, including public safety, journalism, and cybersecurity. This review paper highlights the latest developments in detection strategies and offers a thorough examination of the approaches used to identify face-swapped media and deepfakes .Convolutional neural networks (CNNs), which are frequently used for identifying visual distortions including pixel inconsistencies and abnormal face features, are one of many methods that are explored in this research. This study highlights the ongoing issues in the field and identifies promising areas for future research by weighing the benefits and drawbacks of current datasets and detection systems. In order to preserve the integrity of digital media, the aim is to present a thorough framework of the present deepfake and face-swapping detection techniques, providing insights that can direct the creation of more robust and efficient detection systems in the future.},
  keywords={Industries;Deepfakes;Visualization;Reviews;Neural networks;Media;Generative adversarial networks;Journalism;Public security;Faces;Generative Adversarial Networks (GANs);Convolutional neural networks (CNNs);digital media;public safety;face swapped media},
  doi={10.1109/ICPECTS62210.2024.10780003},
  ISSN={},
  month={Oct},}@ARTICLE{9908159,
  author={Park, Cheolhee and Lee, Jonghoon and Kim, Youngsoo and Park, Jong-Geun and Kim, Hyunjin and Hong, Dowon},
  journal={IEEE Internet of Things Journal}, 
  title={An Enhanced AI-Based Network Intrusion Detection System Using Generative Adversarial Networks}, 
  year={2023},
  volume={10},
  number={3},
  pages={2330-2345},
  abstract={As communication technology advances, various and heterogeneous data are communicated in distributed environments through network systems. Meanwhile, along with the development of communication technology, the attack surface has expanded, and concerns regarding network security have increased. Accordingly, to deal with potential threats, research on network intrusion detection systems (NIDSs) has been actively conducted. Among the various NIDS technologies, recent interest is focused on artificial intelligence (AI)-based anomaly detection systems, and various models have been proposed to improve the performance of NIDS. However, there still exists the problem of data imbalance, in which AI models cannot sufficiently learn malicious behavior and thus fail to detect network threats accurately. In this study, we propose a novel AI-based NIDS that can efficiently resolve the data imbalance problem and improve the performance of the previous systems. To address the aforementioned problem, we leveraged a state-of-the-art generative model that could generate plausible synthetic data for minor attack traffic. In particular, we focused on the reconstruction error and Wasserstein distance-based generative adversarial networks, and autoencoder-driven deep learning models. To demonstrate the effectiveness of our system, we performed comprehensive evaluations over various data sets and demonstrated that the proposed systems significantly outperformed the previous AI-based NIDS.},
  keywords={Generative adversarial networks;Data models;Deep learning;Anomaly detection;Network intrusion detection;Feature extraction;Internet of Things;Anomaly detection;generative adversarial network (GAN);network intrusion detection system (NIDS);network security},
  doi={10.1109/JIOT.2022.3211346},
  ISSN={2327-4662},
  month={Feb},}@INPROCEEDINGS{10622524,
  author={El alami, Hassan and Rawat, Danda B.},
  booktitle={ICC 2024 - IEEE International Conference on Communications}, 
  title={DroneDefGANt: A Generative AI-Based Approach for Detecting UAS Attacks and Faults}, 
  year={2024},
  volume={},
  number={},
  pages={1933-1938},
  abstract={Recently, Unmanned Aerial Systems (UAS) have become heavily reliant on communication, navigation, and other critical components such as sensors and actuators, which are essential for operations in both civilian and defense applications. However, this increasing reliance makes UAS more vulnerable to attacks and faults, posing rising threats. While there have been many advances in UAS security, a significant number of studies have proposed artificial intelligence (AI)-enhanced solutions to address these challenges. Yet, no research has explored the potential of generative AI (GenAI) in this domain. GenAI stands out due to its ability to detect and prevent cyberattacks by continuously learning and adapting to new threats and vulnerabilities. In this paper, we propose DroneDefGANt, a GenAI-based approach that combines the capabilities of generative adversarial networks (GAN) and transformer models. The DroneDefGANt is designed to detect both external UAS attacks like GPS spoofing and jamming, and internal attacks such as actuator faults. Through evaluations using synthetic datasets, DroneDefGANt surpassed various conventional AI models, demonstrating superior accuracy and robustness, particularly in the presence of Gaussian noise.},
  keywords={Actuators;Navigation;Generative adversarial networks;Transformers;Sensor systems and applications;Robustness;Security;Generative AI;UAS;cybersecurity;GPS spoofing;GPS jamming;Fault detection},
  doi={10.1109/ICC51166.2024.10622524},
  ISSN={1938-1883},
  month={June},}@INPROCEEDINGS{10919941,
  author={Mairaj ud din, Qazi and Merola, Francesco and Ahmed, Qadeer},
  booktitle={2024 IEEE 27th International Conference on Intelligent Transportation Systems (ITSC)}, 
  title={GAttack: Generative Attack on In-Vehicle Network}, 
  year={2024},
  volume={},
  number={},
  pages={2556-2561},
  abstract={The rapid progression of Artificial Intelligence (AI) is propelling the connected and autonomous capabilities of modern vehicles to new heights, leading to more sophisticated levels of network integration. This rapid technological stride, however, has escalated the cybersecurity challenges by broadening the attack surface, thus increasing the risk of compromise to In-Vehicle Networks (IVN) and vehicular functionalities. This work investigates the potential threats posed by sophisticated Generative AI-based attacks. It demonstrates a Long ShortTerm Memory (LSTM) based Generative Adversarial Network (GAN) attack mechanism, capable of bypassing state of the art Intrusion Detection System (IDS). The GAN model is capable of learning temporal characteristics of network traffic without needing the system details which makes it applicable to wide range of network. It is able to produce malicious data that can bypass the IDS without triggering the thresholds and penetrate the network stealthily, thereby compromising the integrity of the system. GAttack is validated by testing it against a state-of-the-art IDS, demonstrating a low detection rate of 35.29%, compared to the 85% or higher detection rates achieved against other known attacks.},
  keywords={Intrusion detection;Telecommunication traffic;Generative adversarial networks;Safety;Controller area networks;Computer security;Vehicle dynamics;Long short term memory;Testing;Synthetic data;Cybersecurity;Controller Area Network;Generative Adversarial Network;Intrusion Detection System;Stealthy Attack},
  doi={10.1109/ITSC58415.2024.10919941},
  ISSN={2153-0017},
  month={Sep.},}@INPROCEEDINGS{11035270,
  author={Zinzuvadiya, Nikul and Parida, Chiranjib and Samanta, Pravin Kumar and Dash, Adyasha and Jena, Junali Jasmine and Darshana, Subhashree},
  booktitle={2025 4th International Conference on Distributed Computing and Electrical Circuits and Electronics (ICDCECE)}, 
  title={X-GAN: Explainable Generative Adversarial Networks for Rare Disease Data Augmentation and Clinical Insights}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Rare disease imaging faces dual challenges: limited annotated data and the lack of interpretability in AI-based diagnostic models. To address these issues, we propose X-GAN, a novel framework that integrates StyleGAN2 for synthetic data generation with advanced explainable AI (XAI) techniques, including Grad-CAM++ and SHAP. The model enhances data diversity while providing transparency into both generative and diagnostic processes. Synthetic images achieved high fidelity with a Frechet Inception Distance (FID) of 18.4 and Structural Similarity Index (SSIM) of 0.91. Diagnostic models trained on real and synthetic data achieved a classification accuracy of 92.6% and a Dice Coefficient of 0.89, outperforming state-of-the-art methods. Clinical experts rated the outputs highly for diagnostic relevance and trustworthiness. This integration of GAN and XAI techniques demonstrates a significant advancement in addressing data scarcity, improving model interpretability, and fostering clinical adoption of AI in rare disease workflows.},
  keywords={Accuracy;Explainable AI;Pipelines;Semisupervised learning;Generative adversarial networks;Data models;Integrated circuit modeling;Medical diagnostic imaging;Synthetic data;Diseases;Synthetic Data Augmentation;Generative Adversarial Networks (GANs);Explainable Artificial Intelligence (XAI);Grad-CAM++;StyleGAN2;Medical Image Analysis;Diagnostic Model Transparency},
  doi={10.1109/ICDCECE65353.2025.11035270},
  ISSN={},
  month={April},}@INPROCEEDINGS{10197028,
  author={Talal, Entesar B. and Oraibi, Zakariya A. and Wali, Ali},
  booktitle={2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Gait Recognition using Deep Residual Networks and Conditional Generative Adversarial Networks}, 
  year={2023},
  volume={},
  number={},
  pages={1179-1185},
  abstract={In biometric authentication, the subject of distinguishing people by their gait is considered very important. However, it suffers from several challenges, including changing the angle of walking, wearing a coat, as well as wearing high shoes. The development of artificial intelligence, especially the subject of deep learning, has made a breakthrough in this field. In this research, a new technique was proposed that depends on the use of the conditional generative adversarial network in addition to the ResNet network in order to generate and classify images. The new method relies on the side view angle because it generates various body characteristics. The framework can be divided into three parts: the first part is the process of extracting silhouettes, calculating the gait cycle, and then calculating gait energy images. The second part is the process of generating images through conditional generative adversarial networks and discriminators models. The third part is the process of classifying images using the ResNet network. To evaluate our framework, experiments are performed on a public gait recognition dataset called CASIA database. Results demonstrate that the proposed three-stage framework works better than cutting-edge methods, particularly in carrying-bag and wearing-coat sequences.},
  keywords={Legged locomotion;Databases;Surveillance;Footwear;Generative adversarial networks;Software;Generators;Gait;Gait Cycle;Gait Recognition;Conditional Generative Adversarial Networks;ResNet-50},
  doi={10.1109/COMPSAC57700.2023.00178},
  ISSN={0730-3157},
  month={June},}@INPROCEEDINGS{8876932,
  author={Ay, Betül and Aydın, Galip and Koyun, Zeynep and Demir, Mehmet},
  booktitle={2019 International Conference on Deep Learning and Machine Learning in Emerging Applications (Deep-ML)}, 
  title={A Visual Similarity Recommendation System using Generative Adversarial Networks}, 
  year={2019},
  volume={},
  number={},
  pages={44-48},
  abstract={The goal of content-based recommendation system is to retrieve and rank the list of items that are closest to the query item. Today, almost every e-commerce platform has a recommendation system strategy for products that customers can decide to buy. In this paper we describe our work on creating a Generative Adversarial Network based image retrieval system for e-commerce platforms to retrieve best similar images for a given product image specifically for shoes. We compare state-of-the-art solutions and provide results for the proposed deep learning network on a standard data set.},
  keywords={Generators;Feature extraction;Generative adversarial networks;Footwear;Convolutional codes;Visualization;Training;image retrieval, deep learning, image similarity},
  doi={10.1109/Deep-ML.2019.00017},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10778756,
  author={Ali, Mohammad and Zhang, Jielun},
  booktitle={2024 Cyber Awareness and Research Symposium (CARS)}, 
  title={Exploring the Effectiveness of Synthetic Data in Network Intrusion Detection through XAI}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Machine learning based Intrusion Detection Systems often utilize synthesized samples to address class imbalance in datasets and improve the detection of rare malicious activities. It is commonly assumed that models trained on synthetic data exhibit the same interpretability as those trained on real data. In this study, we challenge this assumption by integrating Conditional Generative Adversarial Networks (CGANs) with eXplainable AI (XAI) techniques to analyze differences in model behavior, specifically in feature importance and decision boundaries, relative to overall performance. We train multiple Multilayer Perceptron classifiers using both synthetic and real samples and employ SHapley Additive exPlanations to investigate variations in interpretability. Our experimental results demonstrate comparable performance achieved by models trained using synthetic and real data, however there are significant differences in interpretive characteristics suggesting that synthetic data can influence model behavior in distinct ways.},
  keywords={Analytical models;Additives;Explainable AI;Network intrusion detection;Multilayer perceptrons;Generative adversarial networks;Data models;Generators;Automobiles;Synthetic data;Generative adversarial networks;data synthesis;eXplainable AI (XAI);intrusion detection systems (IDS);network analytics},
  doi={10.1109/CARS61786.2024.10778756},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10698051,
  author={Park, Ga Eun and Lee, Hae Won and Kim, Bo Min and Oh, Ju Yeon and Bae, Seong Geon},
  booktitle={2024 International Conference on Electrical, Computer and Energy Technologies (ICECET}, 
  title={Enhancing a three-dimensional effect through Depth-based Visual Effects in the Style Transfer of generative Cartoon}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={With the development of artificial intelligence, the generating AI technology is rapidly increasing, and CartoonGAN generates a specific style of cartoon image to reduce the cost incurred in the production process. However, there is a limitation in expressing the three-dimensional effect, so it is difficult to transfer the style of the actual image. This study proposes an algorithm to improve the three-dimensional effect in the cartoon image by applying a depth estimation algorithm. The three-dimensional effect was emphasized by dividing the image into three layers according to the depth and applying a visual effect to each layer. Since real-time processing is difficult due to the size and complexity of the model, we intend to find a way to reduce the size and complexity of the model through future research.},
  keywords={Costs;Image synthesis;Computational modeling;Estimation;Production;Visual effects;Real-time systems;User experience;Complexity theory;Artificial intelligence;GAN;Style Transfer;Image Processing;CartoonGAN;Depth Estimation},
  doi={10.1109/ICECET61485.2024.10698051},
  ISSN={},
  month={July},}@ARTICLE{9640487,
  author={Shi, Jiachen and Fan, Yi and Zhou, Guoqiang and Shen, Jun},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Distributed GAN: Toward a Faster Reinforcement-Learning-Based Architecture Search}, 
  year={2022},
  volume={3},
  number={3},
  pages={391-401},
  abstract={In the existing reinforcement learning (RL)-based neural architecture search (NAS) methods for a generative adversarial network (GAN), both the generator and the discriminator architecture are usually treated as the search objects. In this article, we take a different perspective to propose an approach by treating the generator as the search objective and the discriminator as the judge to evaluate the performance of the generator architecture. Consequently, we can convert this NAS problem to a GAN-style problem, similar to using a controller to generate sequential data via reinforcement learning in a sequence GAN, except that the controller in our methods generates serialized data information of architecture. Furthermore, we adopt an RL-based distributed search method to update the controller parameters $\theta$. Generally, the reward value is calculated after the whole architecture searched, but as another novelty in this article, we employ the reward shaping method to judge the intermediate reward and assign it to every cell in the architecture to encourage the diversity and the integrity of all cells. The main contribution of this article is to provide a novel performance estimation mechanism, which could speed up the efficiency of architecture search, and improve the searching results with specific supplementary strategies. Crucially, this estimation mechanism can be applied to most RL-based NAS methods for the GAN. The experiments demonstrate that our methods achieve satisfactory results against our design objectives.},
  keywords={Computer architecture;Search problems;Generative adversarial networks;Microprocessors;Reinforcement learning;Generators;Artificial intelligence;Generative adversarial network (GAN);neural architecture search (NAS);reinforcement learning (RL);reward shaping},
  doi={10.1109/TAI.2021.3133509},
  ISSN={2691-4581},
  month={June},}@INPROCEEDINGS{10593482,
  author={Anand, Pooja and Sharma, Mayank and Saroliya, Anil},
  booktitle={2024 International Conference on Communication, Computer Sciences and Engineering (IC3SE)}, 
  title={A Comparative Analysis of Artificial Neural Networks in Time Series Forecasting Using Arima Vs Prophet}, 
  year={2024},
  volume={},
  number={},
  pages={527-533},
  abstract={Artificial intelligence heavily relies on neural networks, which enable machines to acquire knowledge and make informed choices by processing data inputs. Time series analysis plays a crucial role in enhancing the capabilities of AI systems powered by artificial neural networks (ANNs). This report provides an overview of neural networks, including the basic components, different types, and the training process. The report also explores advanced topics in neural networks, such as transfer learning, generative adversarial networks, and reinforcement learning. Finally, the report concludes by discussing the advancements and challenges in the field, as well as the future trends and prospects for neural networks. The report provides a comprehensive understanding of this complex but crucial aspect of AI. The aim of this piece is to introduce the concept of time series analysis using artificial neural networks and how it can be a powerful tool for modelling and forecasting complex temporal data. This article is targeted towards individuals with basic knowledge of statistics or machine learning who are interested in learning about time series analysis and its application in artificial neural networks. The focus of this article will be on explaining the fundamentals of time series analysis, exploring the capabilities and limitations of artificial neural networks in analyzing temporal data, and providing examples or case studies showcasing their effectiveness. The tone should be informative, clear, and accessible. Avoid jargon as much as possible while ensuring that technical terms are explained. Use examples to illustrate key concepts whenever appropriate.},
  keywords={Knowledge engineering;Training;Time series analysis;Transfer learning;Reinforcement learning;Prediction algorithms;Data models;Time series;ANN;Machine learning;ARIMA;prophet},
  doi={10.1109/IC3SE62002.2024.10593482},
  ISSN={},
  month={May},}@INPROCEEDINGS{11166618,
  author={Zhang, Enyang and Shakiba, Masoud and Lin, Fangxu and Hassandoust, Farkhondeh and Varastehpour, Soheil},
  booktitle={2025 International Conference on Computer Technology Applications (ICCTA)}, 
  title={Optimising Social Media with Gen AI - A Study on SEO Strategies for Influencers}, 
  year={2025},
  volume={},
  number={},
  pages={244-249},
  abstract={Evaluating the effectiveness of generative artificial intelligence in optimising social media account strategies, the study compares content produced using generative artificial intelligence with manually created content across various platforms. Given that social media significantly influences consumer behaviour—particularly during economic downturns— a single generative artificial intelligence model is employed to examine its impact on search engine optimisation strategies and user engagement among social media influencers. The study further investigates how generative artificial intelligence enhances account visibility, boosts engagement, and improves overall performance by tailoring content to diverse audiences. Specifically, one expected outcome is to elucidate the differences between content produced using generative artificial intelligence and human-generated content in terms of key performance metrics such as engagement, reach, and cost efficiency. Ultimately, the findings underscore the potential of generative artificial intelligence as an indispensable tool for social media influencers in today's competitive digital landscape.},
  keywords={Measurement;Costs;Generative AI;Social networking (online);Search engines;Performance metrics;Optimization;generative AI;social media optimisation;SEO strategies;GPT3.5 Turbo},
  doi={10.1109/ICCTA65425.2025.11166618},
  ISSN={},
  month={May},}@INPROCEEDINGS{11166001,
  author={Izani, M. and Pracha, Mustafa and Alkhalidi, Abdulsamad and Fouda, Basma and Gabr, Mona and Eldib, Heba},
  booktitle={2025 International Conference on Computer Technology Applications (ICCTA)}, 
  title={Understanding AI Animation Through Principle Patterns: A Framework for Future Development}, 
  year={2025},
  volume={},
  number={},
  pages={238-243},
  abstract={This study presents a systematic evaluation of how generative AI animations adhere to the fundamental principles of animation established by Thomas and Johnston. Through rigorous analysis of five AI-generated animations evaluated by three expert animators against ten classical principles, we identified distinct patterns in AI's animation capabilities. Our methodology combined expert evaluation with comprehensive statistical analysis, including inter-rater reliability assessment (κ = 0.84), factor analysis, and capability mapping. Results revealed three clear capability clusters: consistently implemented principles (Staging, Solid Drawing, Appeal; 100% presence), variably implemented principles (Timing, Straight-Ahead Action/Pose-to-Pose, Follow-Through; 20-73% presence), and consistently absent principles (Squash and Stretch, Anticipation, Exaggeration; 0% presence). The findings demonstrate that current AI systems excel at spatial and compositional elements but struggle with dynamic, physics-based principles. This research contributes to the field by establishing a structured framework for evaluating AI animation capabilities, providing actionable insights for both developers and practitioners, and suggesting effective hybrid workflow approaches. Our analysis indicates clear pathways for future development, emphasizing the need for enhanced temporal control and physics-based animation capabilities in AI systems.},
  keywords={Systematics;Generative AI;Statistical analysis;Writing;Animation;Solids;Remote working;Timing;Reliability;Videos;Principles of animation;AI;Generative AI video;Animation},
  doi={10.1109/ICCTA65425.2025.11166001},
  ISSN={},
  month={May},}@INPROCEEDINGS{10772892,
  author={Saurabh, Basu and Utkrisht, Singh and Sandeep, Sharma and Pankaj Kumar, Dalela and Rajkumar, Upadhyay},
  booktitle={2024 ITU Kaleidoscope: Innovation and Digital Transformation for a Sustainable World (ITU K)}, 
  title={Generative AI Enabled Actionable Decision Support in Cyber Security Operations for Enterprise Security}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={In the evolving cyber threat landscape, enterprises employ multiple security solutions such as Endpoint Detection and Response (EDR), Security Information and Event Management (SIEM), and Security Orchestration, Automation, and Response (SOAR). Security analysts are inundated with millions of security event logs from such security tools that makes it increasingly complex to manage and analyze these huge data effectively. Further, there is unavailability of dedicated as well as skilled manpower who can understand and analyse such security events. This paper proposes a novel approach based on generative AI using the state-of-the-art Mistral-7B language model to generate clear and actionable security response messages from these event logs. We demonstrate that this cutting-edge language model can translate complex logs into human-understandable security insights which can enhance analysts’ ability to prioritize and respond to threats.},
  keywords={Technological innovation;Automation;Generative AI;Large language models;Digital transformation;Natural language processing;ITU;Security;Floods;Computer crime;Enterprise Security;Cyber Security Operations;Generative AI;Security Information and Event Management (SIEM)},
  doi={10.23919/ITUK62727.2024.10772892},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8706286,
  author={Meng, Xia and Ali, Saba Ghazanfar and Li, Ping and Masood, Anum and Sheng, Bin and Ren, Jie},
  booktitle={2018 IEEE International Conference on Progress in Informatics and Computing (PIC)}, 
  title={An Interior Decoration System via Virtual Reality and Artificial Intelligence}, 
  year={2018},
  volume={},
  number={},
  pages={221-225},
  abstract={In this paper, we proposed an interior design system. We have implemented the scene selection function and the house type drawing function to get the apartment type. After getting the basic apartment type, we have also provided some other basic decoration functions such as furniture placement, furniture conversion, material conversion, and light switch. These functions are operated by mouse clicking and keyboard control. In addition, we have added some AI modules to provide an additional assistant. Through the recognition of the picture, the texture can be trained, and the ideal texture has been obtained. The implementing environment of our design system is UE4, and the AI algorithm was written in Python and tensor flow.},
  keywords={Artificial intelligence;Generators;Transforms;Feature extraction;Convolution;Training;Image color analysis;Interior design;AI;CycleGAN},
  doi={10.1109/PIC.2018.8706286},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10197055,
  author={Akter, Mst Shapna and Shahriar, Hossain and Lo, Dan and Sakib, Nazmus and Qian, Kai and Whitman, Michael and Wu, Fan},
  booktitle={2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Authentic Learning Approach for Artificial Intelligence Systems Security and Privacy}, 
  year={2023},
  volume={},
  number={},
  pages={1010-1012},
  abstract={The main objective of authentic learning is to offer students an exciting and stimulating educational setting that provides practical experiences in tackling real-world security issues. Each educational theme is composed of pre-lab, lab, and post-lab activities. Through the application of authentic learning, we create and produce portable lab equipment for AI Security and Privacy on Google CoLab. This enables students to access and practice these hands-on labs conveniently and without the need for time-consuming installations and configurations. As a result, students can concentrate more on learning concepts and gain more experience in hands-on problem-solving abilities.},
  keywords={Privacy;Software algorithms;Learning (artificial intelligence);Software;Internet;Security;Problem-solving;Authentic learning;ML/DL algorithm;Adversarial attack;Security;Privacy;Education},
  doi={10.1109/COMPSAC57700.2023.00151},
  ISSN={0730-3157},
  month={June},}@INPROCEEDINGS{11015358,
  author={Bui, Nguyen Tuan Anh and Nguyen, Linh and Nguyen, Ngoc Dang Khoa and Hoang, Cuong Chi},
  booktitle={2024 International Conference on Logistics and Industrial Engineering (ICLIE)}, 
  title={Generative AI-driven Digital Transformation in Education: Systematic Review and Future Research Directions}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Generative artificial intelligence (AI) has emerged as a transformative force in multiple disciplines, particularly in education amidst the post-COVID-19 era. The systematic review synthesizes findings from 59 peer-reviewed articles published from 2014 to 2024. Through a rigorous analysis, we delve into several benefits and challenges associated with Generative AI-driven digital transformation in education. Notably, Generative AI offers numerous benefits for educational institutions such as tailored learning experiences, improved student engagement, cost-effective learning solutions and so forth. Nevertheless, reaping such benefits often necessitates grappling with challenges, including technological intricacies, ethical consideration and pedagogical implications. These findings gleaned from this review serve as an invaluable resource for researchers and practitioners seeking to harness Generative AI’s potential to optimize teaching and learning performance. Such a review also lays a robust foundation for future research endeavors, paving the way for continued advancements in this domain.},
  keywords={Ethics;Generative AI;Digital transformation;Education;Force;Industrial engineering;Systematic literature review;Logistics;Generative AI;education sector;digital transformation;systematic literature review},
  doi={10.1109/ICLIE61478.2024.11015358},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10986034,
  author={Nikolaev, Evgeny and Zakharova, Nataly and Zakharov, Vladimir},
  booktitle={2025 International Russian Smart Industry Conference (SmartIndustryCon)}, 
  title={Cloud Removal in Satellite Images Using a Generative Adversarial Approach}, 
  year={2025},
  volume={},
  number={},
  pages={614-618},
  abstract={Automation of a wide range of operations in the agro-industrial sector at the current stage of technology development involves the application of advanced solutions in electronics, biotechnology, and information technologies. One of the directions of process optimization in agriculture is the introduction of information systems functioning on the basis of satellite imagery data analysis. To improve the efficiency of satellite data application, it is advisable to use machine learning and artificial intelligence methods. Satellite data allow monitoring a set of indicators describing chemical and physical characteristics, soil types, weather conditions, humidity. These indicators play an important role in the decision-making process of smart farming systems. The indicators are available in the form of satellite images, the quality of which depends on many factors. In order to apply such images in agricultural information systems, it is necessary to perform deep image analysis and cleaning. The approach aimed at applying a generative deep neural network to clean satellite images from clouds and shadows is proposed. The approach is based on training the neural network on synthesized data.},
  keywords={Training;Smart agriculture;Satellites;Clouds;Soil;Satellite images;Information technology;Optimization;Monitoring;Information systems;deep learning;GAN;agricultural information systems;cloud detection;cloud removal;data augmentation},
  doi={10.1109/SmartIndustryCon65166.2025.10986034},
  ISSN={},
  month={March},}@INPROCEEDINGS{10748468,
  author={Jasmitha, T. and Meeradevi and J, Sowmya B},
  booktitle={2024 5th International Conference on Circuits, Control, Communication and Computing (I4C)}, 
  title={Artificial Intelligence for Lyric Generator based on Bi-Directional LSTM and Transformers}, 
  year={2024},
  volume={},
  number={},
  pages={228-234},
  abstract={In the endeavor of fusing music composition with AI, generation of lyrics has been a persistent issue of concern. Incredible music is a perfect blend of melody and significant lyrics. In this exertion, distinct techniques and strategies have been introduced. The venture of lyric generation using deep learning techniques has been advancing over a decade. One such project in this field is our AI LYRIC WRITER. This project is a comparative study that evaluates the effectiveness of various AI models in generating lyrics. The models are trained on a dataset available on Kaggle, featuring the lyrics by artist Taylor Swift. We have experimented with different models. One of these models is an integration of Bi-directional LSTM and N gram language processing. A bi-directional LSTM architecture processes a sequence of words, both in forward and in backward direction, to understand and remember them better. A CuDNN LSTM layer, which is beneficial for efficient training, is also incorporated into the model. A dropout layer is added to the model which acts as a safety net to prevent overfitting. In an attempt to improve the accuracy, we explored various pre-trained models such as GPT-2, T-5 and XLNET. Although GPT-2 and T-5 were fruitful in learning contexts and patterns, their accuracy was compromised. XLNet proved to be successful in predicting the lyrics aligned with the vocabulary adapted by the artist and reproducing the precise genre employed by the artist. The training data has driven to nearly perfect accuracy in the model's performance.},
  keywords={Training;Adaptation models;Analytical models;Accuracy;Computational modeling;Training data;Transformers;Market research;Artificial intelligence;Integrated circuit modeling;AI Lyric Generation;Bi-directional LSTM;GPT-2;T5;XLNet;Deep Learning;Music Composition},
  doi={10.1109/I4C62240.2024.10748468},
  ISSN={2473-7690},
  month={Oct},}@INPROCEEDINGS{9336798,
  author={Swetha, M. and Rajendiran, M.},
  booktitle={2020 9th International Conference System Modeling and Advancement in Research Trends (SMART)}, 
  title={A Review on Effectiveness of Artificial Intelligence Techniques in the Detection of COVID-19}, 
  year={2020},
  volume={},
  number={},
  pages={98-102},
  abstract={The Corona virus Disease 2019 (COVID-19) is an epidemic and life threatening disease that has an abundant influence on the public health of people all around the world affecting their normal day to day life. The medical monitoring of the infected patients reveals various symptoms that can be analysed, classified and the output can help the physicians to treat the new cases. In this paper we have done an extensive research of the various Machine Learning(ML) and Deep Learning (DL) algorithms employed by the researchers and health workers over the COVID-19 data obtained from the affected patients in the classification of the disease. This extensive analysis will help the future analysts to consider the effective technique that can provide them faster results during both the phases of training and inference. We have given a comparative analysis of the various ML/DL techniques employed for COVID-19 and its remarks.},
  keywords={COVID-19;Training;Pandemics;Transfer learning;Systems modeling;Lesions;Artificial intelligence;COVID-19;Machine Learning;Deep Learning;Epidemic},
  doi={10.1109/SMART50582.2020.9336798},
  ISSN={},
  month={Dec},}@INBOOK{11049831,
  author={Campesato, Oswald},
  booktitle={Large Language Models for Developers: A Prompt-based Exploration of LLMs}, 
  title={Chapter 1: The Generative AI Landscape}, 
  year={2024},
  volume={},
  number={},
  pages={1-84},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9781501520952},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11049831},}@INPROCEEDINGS{10588188,
  author={Ma, Zhuojia and Liu, Meiqin and Zhang, Senlin and Dong, Shanling and Wei, Ping},
  booktitle={2024 36th Chinese Control and Decision Conference (CCDC)}, 
  title={Surface Defect Detection of Mobile Phone Screen Based on Generative Adversarial Networks}, 
  year={2024},
  volume={},
  number={},
  pages={518-523},
  abstract={This paper proposes a novel defect detection method for mobile phone screens based on Generative Adversarial Networks (GANs). It aims at solving the overfitting problem due to insufficient data and enhancing the effectiveness of the detection network. To achieve the goal, we first present Multiscale Generative Adversarial Networks (MsGANs) to expand the dataset. As two important components in MsGANs, multi-scale generators and pyramidal discriminators are obtained by optimizing the structure of Conditional Generative Adversarial Networks (CGANs). Multi-scale generators are built from coarse to fine, where the global generator produces images with lower resolution, and the local enhancer provides missing details to ensure the creation of excellent images. Pyramidal discriminators utilize three distinct scales of image feature pyramids. Further-more, we establish the multi-label classification network to tackle the defect detection problem that multiple categories of defects are involved in a single sample. A pre-trained ResNet-50 is used to extract high-level image features. Finally, the experimental results demonstrate the effectiveness of MsGANs combined with ResNet-50 for mobile phone screen defect detection.},
  keywords={Image resolution;Semantics;Production;Generative adversarial networks;Feature extraction;Data augmentation;Mobile handsets;Multiscale Generative Adversarial Networks (MsGANs);defect detection;data augmentation;multi-label classification;transfer model},
  doi={10.1109/CCDC62350.2024.10588188},
  ISSN={1948-9447},
  month={May},}@INPROCEEDINGS{10578712,
  author={Ciolacu, Monica Ionita and Marghescu, Cristina and Mihailescu, Bogdan and Svasta, Paul},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Does Industry 5.0 Need an Engineering Education 5.0? Exploring Potentials and Challenges in the Age of Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Increasing disruption from Industry 4.0/5.0, climate change, digital transformation, wars and high levels of volatility, uncertainty, complexity and ambiguity (VUCA) are leading to major changes in the labor market. In addition, improvements in chatbots and Generative AI are opening new opportunities for students and the future workforce. They seem to have become ‘creative’ in their field of study and are turning to AI applications for their learning, assignments or theses. However, there are concerns about academic integrity and cybersecurity. Students and researchers have already started using AI chatbots to learn, program, write academic essays or conduct research faster and more effectively. This paper explores whether AI can serve as a bicycle for human creativity and innovation. What are the first words that come to mind when you think of Engineering Education 5.0? Have you used Artificial Intelligence tools in your teaching, learning or research? This paper presents the results of a survey conducted at the Faculty of Electronics, Technology and Information Technology on the challenges and opportunities of using Generative AI(GenAI) in Engineering Education. This paper also outlines the Generative AI ecosystem for teaching, learning and research. Engineering Education 5.0 needs a future ready Curricula including AI Literacy, new teaching and learning methods, analytical and critical thinking, reflection, collaboration and complex problem-solving, and communities of practice with the industry to foster innovation and creativity.},
  keywords={Industries;Learning systems;Technological innovation;Generative AI;Education;Artificial intelligence;Engineering education;engineering education 5.0;technology-enhanced learning;innovation;creativity;generative AI},
  doi={10.1109/EDUCON60312.2024.10578712},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{11028413,
  author={De Araújo Luz Junior, Jonas and Prado Saldanha Ribeiro, Guadalupe and Pessoa, Rafael Fonseca and Huarastaca Taveira Magalhães, Alberto and Formico Rodrigues, Maria Andréia},
  booktitle={2025 IEEE/ACM 9th International Workshop on Games and Software Engineering (GAS)}, 
  title={Generative AI for Facial Expressions in 3D Game Characters: A Retrieval-Augmented Approach}, 
  year={2025},
  volume={},
  number={},
  pages={9-16},
  abstract={This paper examines a Retrieval-Augmented Generation (RAG) approach for generating facial expressions in 3D game characters using artificial intelligence. By integrating large language models within a RAG-based architecture, we developed a proof-of-concept system that animates expressions based on Facial Action Coding System (FACs) action units. Testing demonstrates the potential of RAG-driven animations to create immersive, adaptive experiences with contextually appropriate expressions that enhance perceived emotional responsiveness in Non-Playable Characters, highlighting RAG’s promise for dynamic character interactions and AI-driven personalization in game development.},
  keywords={Three-dimensional displays;Generative AI;Large language models;Conferences;Retrieval augmented generation;Games;Animation;Encoding;Testing;Software engineering;Artificial Intelligence;Large Language Models;Retrieval-Augmented Generation;Facial Expressions;3D Character Animation;Games},
  doi={10.1109/GAS66647.2025.00007},
  ISSN={2996-5187},
  month={April},}@ARTICLE{10179928,
  author={Fan, Yang and Jiang, Xingguo and Lan, Shuxing and Lan, Jianghai},
  journal={IEEE Access}, 
  title={Facial Expression Transfer Based on Conditional Generative Adversarial Networks}, 
  year={2023},
  volume={11},
  number={},
  pages={82276-82283},
  abstract={With the development of computer vision and image transfer, facial expression transfer has been more and more widespread applications. But there are still some problems, such as lack of realistic expression, poor retention of facial identity features and low synthesis efficiency. In order to solve the problems of facial expression transfer, the paper proposes a facial expression transfer model based on conditional generative adversarial network, which can generate a highly realistic face image with source facial expression and target facial identity features, when gave a source face image and a target face image. The model consists of two parts: the facial feature point fusion module and the expression transfer module. Among them, the facial feature point fusion module uses an auto-encoder to encode the face key feature point image of the source facial expression and the face feature key point image of the target face, so as to transfer the source facial expression information to the corresponding face key feature points of the target image; the expression transfer module uses the facial feature point fusion module to generate the face key feature point image and the target face image, and then generates an image with the source facial expression and the target face identity features through the modified U-net network. The model is finally validated on two publicly available datasets, RaFD and CK+, and the experimental results show that the generated facial expression is more realistic than the pix2pix model, and the model only needs to be trained once to complete the transfer between any facial expression.},
  keywords={Facial features;Generative adversarial networks;Feature extraction;Convolution;Solid modeling;Three-dimensional displays;Face recognition;Face features;facial expression transfer;conditional generative adversarial networks;U-net;face editing},
  doi={10.1109/ACCESS.2023.3294697},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11050548,
  author={Karaca, Yasemin and Sarsar, Gozde and Dogan, Huseyin and Giff, Stephen},
  booktitle={2025 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Generative AI to Enhance Situational Awareness and Collaboration: A Co-Worker for Tech Support in Enterprise Environments}, 
  year={2025},
  volume={},
  number={},
  pages={1324-1331},
  abstract={Generative AI (GenAl) is revolutionizing enterprise operations by enhancing Situational Awareness (SA) and decision-making. This paper integrates insights from the OODA Loop and the Agent Teaming Situation Awareness (ATSA) framework to explore human-AI team (HAT) collaboration in tech support. Key themes include Shared Situational Awareness (SSA), Shared Mental Models (SMMs), Belief-Desire-Intention (BDI), and Explainable AI (XAI). Emphasizing trust and transparency, the paper proposes a hybrid system to address challenges in achieving trust in AI systems. Findings demonstrate how GenAl improves productivity while fostering adaptability and trust in dynamic enterprise environments.},
  keywords={Productivity;Explainable AI;Generative AI;Decision making;Collaboration;Cognitive science;GenAl;OODA Loop;ATSA;SSA;HAT;SMMs;BDI;SAT;XAI. Trust},
  doi={10.1109/CAI64502.2025.00250},
  ISSN={},
  month={May},}@ARTICLE{8641270,
  author={Lee, Minhyeok and Seok, Junhee},
  journal={IEEE Access}, 
  title={Controllable Generative Adversarial Network}, 
  year={2019},
  volume={7},
  number={},
  pages={28158-28169},
  abstract={Recently introduced generative adversarial networks (GANs) have been shown numerous promising results to generate realistic samples. In the last couple of years, it has been studied to control features in synthetic samples generated by the GAN. Auxiliary classifier GAN (ACGAN), a conventional method to generate conditional samples, employs a classification layer in discriminator to solve the problem. However, in this paper, we demonstrate that the auxiliary classifier can hardly provide good guidance for training of the generator, where the classifier suffers from overfitting. Since the generator learns from classification loss, such a problem has a chance to hinder the training. To overcome this limitation, here, we propose a controllable GAN (ControlGAN) structure. By separating a feature classifier from the discriminator, the classifier can be trained with data augmentation technique, which can support to make a fine classifier. Evaluated with the CIFAR-10 dataset, ControlGAN outperforms AC-WGAN-GP which is an improved version of the ACGAN, where Inception score of the ControlGAN is 8.61 ± 0.10. Furthermore, we demonstrate that the ControlGAN can generate intermediate features and opposite features for interpolated input and extrapolated input labels that are not used in the training process. It implies that the ControlGAN can significantly contribute to the variety of generated samples.},
  keywords={Generative adversarial networks;Gallium nitride;Generators;Training;Face;Input variables;Artificial neural network;generative adversarial networks;generative model;sample generation},
  doi={10.1109/ACCESS.2019.2899108},
  ISSN={2169-3536},
  month={},}@ARTICLE{10729844,
  author={Yang, Shiau-Ru and Chien, Jen-Tzung and Lee, Chen-Yi},
  journal={IEEE Open Journal of Engineering in Medicine and Biology}, 
  title={Advancements in Clinical Evaluation and Regulatory Frameworks for AI-Driven Software as a Medical Device (SaMD)}, 
  year={2025},
  volume={6},
  number={},
  pages={147-151},
  abstract={Owing to the rapid progress in artificial intelligence (AI) and the widespread use of generative learning, the problem of sparse data has been solved effectively in various research fields. The application of AI technologies has resulted in important transformations in healthcare, particularly in radiology. To ensure the high quality, safety, and effectiveness of AI and machine learning (ML) medical devices, the US Food and Drug Administration (FDA) has established regulatory guidelines to support the performance evaluation of medical devices. Furthermore, the FDA has proposed continuous surveillance requirements for AI/ML medical devices. This paper presents a summary of SaMD products that have passed the FDA 510 (k) AI/ML pathway, the challenges associated with the current AI/ML software-as-a-medical-device, and solutions for promoting the development of AI technologies in medicine. We hope to provide valuable information pertaining to medical-device design, development, and monitoring to ultimately achieve safer and more effective personalized medical services.},
  keywords={Medical services;Medical devices;Artificial intelligence;Performance evaluation;Medical diagnostic imaging;FDA;Safety;Drugs;Clinical trials;Software;Software as a medical device (SaMD);AI/ML;computer-aided detection (CADe);computer-aided diagnosis (CADx);computer-aided triage (CADt)},
  doi={10.1109/OJEMB.2024.3485534},
  ISSN={2644-1276},
  month={},}@INPROCEEDINGS{10749224,
  author={Glenn Carter, H. and Vinegar, Chris and Terres, Victor and Rupert, Jason},
  booktitle={2024 AIAA DATC/IEEE 43rd Digital Avionics Systems Conference (DASC)}, 
  title={Considerations for Tool Qualification in Flight-Critical Applications Using Machine Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={In the development of Machine Learning-based applications, tools play a prevalent role. This extends to the use of Machine Learning (ML) in flight-critical applications. ML-based tools, such as generative Artificial Intelligence (AI) tools, and traditional tools used for ML applications, like simulation generation tools, can accomplish various processes and objectives in the ML-based item lifecycle. These include creating high-level requirements (HLRs) and generating synthetic datasets used for model training, validation, and testing. The integration of tools for such applications raises crucial questions about tool qualification. Tool qualification criteria are traditionally contingent on the potential for a tool to introduce errors into its output that may impact the final deployed item. The examination of tool qualification further involves distinguishing between scenarios where the tool may overlook errors during testing. Higher tool qualification rigor is deemed necessary, particularly for the development of items with a higher assurance level. In the ML-based item lifecycle, evaluating tool qualification is vital, especially for the ML development lifecycle, because qualification increases the assurance of the tool and confidence in its output. This paper explores the applicability of tool qualification across the ML-based lifecycle and then examines two specific examples: the utilization of generative AI tools and synthetic data generation tools for ML training, validation, and testing.},
  keywords={Generative AI;Machine learning;Aerospace electronics;Software;Accreditation;Qualifications;Testing;Synthetic data;tool qualification;Machine Learning;generative Artificial Intelligence;assurance expectations},
  doi={10.1109/DASC62030.2024.10749224},
  ISSN={2155-7209},
  month={Sep.},}@INPROCEEDINGS{9348880,
  author={Zheng, Xiaolong and Yang, Chuanchuan and Feng, Jiqiang and Xu, Chen and Wang, Ziyu},
  booktitle={2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall)}, 
  title={Generative Adversarial Method Considering Communication Transmission Distortion for Neural Network Codec}, 
  year={2020},
  volume={},
  number={},
  pages={1-5},
  abstract={Recently, induced by incorporating the ubiquitous data collected by AI application, there are more and more demand for transferring data to cloud servers due to the restriction of computing resources of devices. To transfer image data efficiently, neural network (NN) codec can be a wise choice, which can result in higher ratio of compression with similar image quality compared with conventional codec methods. However, when the NN codec is employed in the communication system, it is likely that it can be disturbed by channel distortions. In this paper, we innovatively propose a norm method to measure the NN codec's robustness for certain tasks. And with the aid of this method, we develop a greedy algorithm using gradients to find adversarial samples of certain tasks considering communication system distortions, i.e. channel distortions during compressed image or video transferring to cloud server systems. Aided by the adversarial samples, the NN codec has been proved to have better tolerance of communication distortions that the Top-1 accuracy of the image classification can be improved 1.8%.},
  keywords={Codecs;Image coding;Communication systems;Artificial neural networks;Distortion;Servers;Task analysis;Communication system;Adversarial Sample;Codec;Neural Network},
  doi={10.1109/VTC2020-Fall49728.2020.9348880},
  ISSN={2577-2465},
  month={Nov},}@INPROCEEDINGS{11050553,
  author={Tong, Richard J. and Cortês, Marina and DeFalco, Jeanine A. and Underwood, Mark and Zalewski, Janusz},
  booktitle={2025 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={A First-Principles Based Risk Assessment Framework and the IEEE P3396 Standard}, 
  year={2025},
  volume={},
  number={},
  pages={1588-1595},
  abstract={Generative Artificial Intelligence (AI) is enabling unprecedented automation in content creation and decision support, but it also raises novel risks. This paper presents a first-principles risk assessment framework underlying the IEEE P3396 Recommended Practice for AI Risk, Safety, Trustworthiness, and Responsibility. We distinguish between process risks (risks arising from how AI systems are built or operated) and outcome risks (risks manifest in the AI system's outputs and their real-world effects), arguing that generative AI governance should prioritize outcome risks. Central to our approach is an information-centric ontology that classifies AI-generated outputs into four fundamen-tal categories: (1) Perception-level information, (2) Knowledge-level information, (3) Decision/Action plan information, and (4) Control tokens (access or resource directives). This classification allows systematic identification of harms and more precise attribution of responsibility to stakeholders (developers, deployers, users, regulators) based on the nature of the information produced. We illustrate how each information type entails distinct outcome risks (e.g, deception, misinformation, unsafe recommendations, security breaches) and requires tailored risk metrics and mitigations. By grounding the framework in the essence of information, human agency, and cognition, we align risk evaluation with how AI outputs influence human understanding and action. The result is a principled approach to AI risk that supports clear accountability and targeted safeguards, in contrast to broad application-based risk categorizations. We include example tables mapping information types to risks and responsibilities. This work aims to inform the IEEE P3396 Recommended Practice and broader AI governance with a rigorous, first-principles foundation for assessing generative AI risks while enabling responsible innovation.},
  keywords={Ethics;Technological innovation;Regulators;Generative AI;Standards organizations;Organizations;Cognition;Stakeholders;Security;Fake news;Risk;Information Categorization;AI Agency;Human Agency;GenAl},
  doi={10.1109/CAI64502.2025.00237},
  ISSN={},
  month={May},}@ARTICLE{10721454,
  author={Su, Shih-Wen and Hung, Chao-Hsiang and Chen, Li-Xian and Yuan, Shyan-Ming},
  journal={IEEE Access}, 
  title={Development of an AI-Based System to Enhance School Counseling Models for Asian Elementary Students With Emotional Disorders}, 
  year={2024},
  volume={12},
  number={},
  pages={159121-159136},
  abstract={In Asia, the availability of school counselors is significantly lower than global standards recommend, particularly in elementary education settings. This shortage is exacerbated by rising mental health concerns among young students, particularly those with emotional disorders. Considering the critical gap in the provision of mental health services in Asia, this paper studies a digital intervention approach with an AI-driven supportive system developed by adopting OpenAI to enhance the effectiveness of counseling in elementary education. Twenty-two students with ADHD, autism spectrum disorder, and emotional disorders undergoing counseling at a primary school in Taiwan were recruited as participants for a three-month experiment, with the five Social-Emotional competencies as dependent variables. The treatment group utilized the proposed system with a digital journaling platform to help students reflect on their emotions, thoughts, and actions after counseling sessions, fostering an ongoing dialogue with their counselors through the system. Conversely, the control group received standard counseling without integrating the use of the proposed platform. The results of a two-factor mixed design ANOVA revealed that students who did not use the supportive system showed significant improvement in self-awareness. In contrast, students who went through the new model demonstrated significant changes in all competencies. These findings highlight the value of the proposed intervention approach for students with emotional disorders and suggest broader applications for AI technologies in school counseling, offering valuable insights for educators and policymakers.},
  keywords={Employee welfare;Artificial intelligence;Asia;Mental health;Engineering profession;Autism;Cultural differences;Analytical models;Urban areas;Standards;Education;Cognitive behavioral therapy (CBT);artificial intelligence;school counseling;social-emotional learning (SEL);OpenAI},
  doi={10.1109/ACCESS.2024.3483456},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11140624,
  author={Saxena, Archana B and Sharma, Deepti and Aggarwal, Deepshikha},
  booktitle={2025 8th International Conference on Computing Methodologies and Communication (ICCMC)}, 
  title={Influence of Generative AI on Students’: Interpersonal & Technical Skills}, 
  year={2025},
  volume={},
  number={},
  pages={1846-1851},
  abstract={The current research focuses the implications of use of Generative AI in students’ Inter-personnel and technical skills. The study primarily focuses on post graduate level students. The study covers various aspects Like How and when students use GenAI tools in their technical and inter-personnel communications. To achieve the objective of the study, authors have implied qualitative data collection methods Like Questionnaire, Observation and interview. To keep in sync with study the, all the techniques are applied to the students pursuing their post graduate degree/diploma. The study explores the cognitive aspect of students when they are presented with a problem or case, when they are assigned any assignment, how and when they use GenAI tool when they have to communicate on any social media platform or public addressing.The study reveals that at post graduate level almost everyone is familiar with GenAI tools that are available to support in their respective streams. Most of the students are implementing these tools in their regular chores. While analysing the collected data and observing few cases of the selected population it has been noticed that in some cases (particularly in IT and related sectors) use of GenAI tools raises ethical, social and educational challenges which can hazardous for the technical and communicational abilities of students. Although there are substantial benefits that can be extracted by using these tools if they are used judiciously during their technical and inter personnel development.},
  keywords={Ethics;Generative AI;Social networking (online);Education;Data collection;Personnel;Synchronization;Interviews;Generative AI;GenAI in Education;GenAI for inter personnel skills;Artificial Intelligence},
  doi={10.1109/ICCMC65190.2025.11140624},
  ISSN={},
  month={July},}@INPROCEEDINGS{10971861,
  author={Ruparel, Hardik and Daftary, Harshal and Singhai, Videet and Kumar, Pramod},
  booktitle={2024 IEEE/ACM 17th International Conference on Utility and Cloud Computing (UCC)}, 
  title={The Impact of Generative AI on Cloud Data Security: A Systematic Study of Opportunities and Challenges}, 
  year={2024},
  volume={},
  number={},
  pages={185-188},
  abstract={Since the launch of ChatGPT, Generative AI (GenAI) has transformed virtually every domain, addressing complex problems in areas previously considered insurmountable. At the same time, the adoption of cloud computing for storing confidential data has been rapidly increasing. This swift shift to the cloud has highlighted the critical need for robust data protection measures. In this paper, we merge these two emerging fields to examine how GenAI influences cloud data security. While research on traditional AI-based solutions for cyber threats has been ongoing, the recent surge in GenAI adoption calls for a focused, systematic study to address specific research questions related to GenAI. We formulate 7 research questions and analyze data from 4 major digital repositories (IEEE, Springer, ACM, Wiley) to provide an extensive overview of how GenAI contributes to mitigating key cloud security threats such as Malware, Denial-Of-Service (DoS), and Phishing, among others. We also discuss the potential risks posed by GenAI in cloud security and highlight the operational and ethical challenges that impede its widespread adoption. This systematic study aims to provide valuable insights for fellow researchers and IT professionals, guiding them in effectively leveraging GenAI to enhance cloud data security while being mindful of its limitations and challenges.},
  keywords={Ethics;Systematics;Generative AI;Shape;Data security;Cloud computing security;Surge protection;Solids;Surges;Research and development;Cloud Data Security;Cyber Threats;Generative AI;Artificial Intelligence;Deep Learning;Information Security;Large Language Models},
  doi={10.1109/UCC63386.2024.00033},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10467943,
  author={Borah, Asha Rani and T N, Nischith and Gupta, Saksham},
  booktitle={2024 2nd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)}, 
  title={Improved Learning Based on GenAI}, 
  year={2024},
  volume={},
  number={},
  pages={1527-1532},
  abstract={This research introduces a novel strategy to improve learning outcomes by incorporating generative artificial intelligence (AI) into educational frameworks. Using sophisticated machine learning algorithms, GenAI analyzes each learner's profile and modifies educational tactics and content in real time. This flexible and dynamic learning environment offers a customized experience that is unmatched by conventional educational models, accommodating a wide range of learning styles, interests, and aptitudes. With the growing importance of individualized learning, GenAI presents itself as a transformative invention with the potential to completely change the face of education. This article highlights how GenAI has the ability to completely change the way we approach and provide education by outlining its architecture, the machine learning algorithms that underpin it, and how it has transformed educational practices.},
  keywords={Adaptation models;Technological innovation;Machine learning algorithms;Generative AI;Education;Transforms;Learning (artificial intelligence);Advanced learning;Generative AI (GenAI);Stable diffusion},
  doi={10.1109/IDCIoT59759.2024.10467943},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{8802976,
  author={Kim, Byungju and Lee, Jaeyoung and Kim, Kyungsu and Kim, Sungjin and Kim, Junmo},
  booktitle={2019 IEEE International Conference on Image Processing (ICIP)}, 
  title={Collaborative Method for Incremental Learning on Classification and Generation}, 
  year={2019},
  volume={},
  number={},
  pages={390-394},
  abstract={Although well-trained deep neural networks have shown remarkable performance on numerous tasks, they rapidly forget what they have learned as soon as they begin to learn with additional data with the previous data stop being provided. In this paper, we introduce a novel algorithm, Incremental Class Learning with Attribute Sharing (ICLAS), for incremental class learning with deep neural networks. As one of its component, we also introduce a generative model, incGAN, which can generate images with increased variety compared with the training data. Under challenging environment of data deficiency, ICLAS incrementally trains classification and the generation networks. Since ICLAS trains both networks, our algorithm can perform multiple times of incremental class learning. The experiments on MNIST dataset demonstrate the advantages of our algorithm.},
  keywords={Generators;Task analysis;Training;Generative adversarial networks;Silicon;Image recognition;Decoding;Incremental Learning;Deep Neural Networks;Generative Adversarial Networks},
  doi={10.1109/ICIP.2019.8802976},
  ISSN={2381-8549},
  month={Sep.},}@INPROCEEDINGS{10014971,
  author={Iliadis, Lazaros Alexios and Zaharis, Zaharias D. and Sotiroudis, Sotirios P. and Sarigiannidis, Panagiotis and Christodoulou, Christos and Goudos, Sotirios K.},
  booktitle={2022 25th International Symposium on Wireless Personal Multimedia Communications (WPMC)}, 
  title={Patch Antenna Design using Artificial Intelligence Methods for 4G/5G Applications}, 
  year={2022},
  volume={},
  number={},
  pages={497-500},
  abstract={The advent of fifth generation wireless communications (5G), highlights the need for new priorities in research. Especially, the growing mobile networks require abilities for mas-sive connectivity, advanced security, increased network capacity and extremely low-latency. Antennas play a crucial part of this ecosystem, thus, their design is a challenging task. In this work, a Boundary - Seeking Generative Adversarial Network is trained to serve as a surrogate model for the design of a patch antenna with random slots and two operating frequencies at 2.6 GHz and 3.5 GHz, making it suitable for 4G/5G applications. The outcome of the trained model is used as an initial population for further op-timization using the biogeography-based optimization algorithm. The final design achieves $S_{11}=-37$ dB and $S_{11}=-33$ dB at 2.6 GHz and 3.5 GHz respectively.},
  keywords={Wireless communication;Machine learning algorithms;Biological system modeling;Patch antennas;Sociology;Security;Multimedia communication;Machine Learning;Generative Adversarial Net-works;Surrogate model;Patch antenna;Evolutionary Algorithms},
  doi={10.1109/WPMC55625.2022.10014971},
  ISSN={1882-5621},
  month={Oct},}@INBOOK{10954432,
  author={Singh, Shiv},
  booktitle={Marketing with AI For Dummies}, 
  title={Getting Comfortable with Generative AI}, 
  year={2025},
  volume={},
  number={},
  pages={119-131},
  abstract={Summary <p>ChatGPT became the fastest growing application in history: It quickly reached 100 million active monthly users by the end of January 2023. Generative AI refers to a subset of artificial intelligence (AI) that focuses on creating new content, ranging from text and images to music and code. At the core of generative AI are machine learning models, particularly those that are based on deep learning techniques and trained on extremely large data sets. The training process of generative AI models is a sophisticated procedure that enables these models to generate new data that closely resembles the training data set. Generative Pre&#x2010;trained Transformer models emerged as a significant breakthrough in the field of natural language processing and generative AI. Consumers can experience AI outputs firsthand through the simple chatbot interfaces of ChatGPT &#x2014; even on smartphone apps such as ChatOn and Alissu.</p>},
  keywords={Generative AI;Artificial intelligence;Data models;Training;Chatbots;Aerospace electronics;Synthetic data;Ethics;Costs;Transformers},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394237210},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10954432},}@INPROCEEDINGS{8836968,
  author={Chen, Hao and Qin, Zhiguang and Ding, Yi and Lan, Tian},
  booktitle={2019 2nd International Conference on Artificial Intelligence and Big Data (ICAIBD)}, 
  title={Brain Tumor Segmentation with Generative Adversarial Nets}, 
  year={2019},
  volume={},
  number={},
  pages={301-305},
  abstract={Accurate brain tumor segmentation is the key of clinical diagnostics and treatment planning. However, a large quantity of data produced by Magnetic resonance imaging (MRI) prevents manual segmentation in a reasonable time. So, automatic approaches are required for quick and effective segmentation. Nevertheless, the spatial and structural variability among brain tumors bring a challenge to automatically segment MRI images. In this paper, an automatic end-to-end method based on Generative Adversarial Nets (GAN) is proposed for brain tumor segmentation. This method combines the generating model with the discriminant model and takes GAN instead of conditional random fields (CRF) as high-order smoothing method. The proposed method was validated in the BRATS 2015 database, it can be proven that the proposed method achieves a competitive result and the use of GAN improve the performance of networks. Furthermore, comparing with other recent CNN-based methods, the approach only takes about 10.8s to segment a patient case.},
  keywords={Image segmentation;Tumors;Training;Feature extraction;Gallium nitride;Generators;Task analysis;generative adversarial networks;deep learning;brain tumor segmentation;magnetic resonance imaging},
  doi={10.1109/ICAIBD.2019.8836968},
  ISSN={},
  month={May},}@INPROCEEDINGS{9308017,
  author={Sandouka, Soha B. and Bazi, Yakoub and Rahhal, Mohamad Mahmoud Al},
  booktitle={2020 International Conference on Artificial Intelligence & Modern Assistive Technology (ICAIMAT)}, 
  title={EfficientNet Combined with Generative Adversarial Networks for Presentation Attack Detection}, 
  year={2020},
  volume={},
  number={},
  pages={1-5},
  abstract={In recent years, fingerprint-based biometric systems have grown rapidly as they are used for various applications such as mobile payments, international border security, and financial transactions. Although the widespread of these systems, it has been found that they are vulnerable to presentation attacks (i.e., spoof attacks). Therefore, improving the generalization ability of fingerprint PAD over unknown materials and unknown sensors is of primary importance. In this work, we proposed a fingerprint PAD with improved cross-sensor and cross-material generalization based on state-of-the-art CNN network; i.e., EfficientNet combined with Generative Adversarial Network (GANs). We will validate the proposed methodologies on the public LivDet2015 dataset provided by the liveness detection competition.},
  keywords={Fingerprint recognition;Sensors;Image matching;Generators;Biometrics (access control);Gallium nitride;Image sensors;Fingerprint presentation attack detection;liveness detection;deep learning;Convolutional Neural Networks (CNN);generalization;Generative Adversarial Network (GANs)},
  doi={10.1109/ICAIMAT51101.2020.9308017},
  ISSN={},
  month={Nov},}@ARTICLE{10840187,
  author={Yao, Qiong},
  journal={IEEE Access}, 
  title={Application of Artificial Intelligence Virtual Image Technology in Photography Art Creation Under Deep Learning}, 
  year={2025},
  volume={13},
  number={},
  pages={14542-14556},
  abstract={With the continuous advancement of artificial intelligence (AI) and deep learning technologies, virtual image generation exhibits significant potential for application in photographic art creation. The primary objective of this study is to investigate the use of AI virtual image technology in photography, particularly focusing on achieving creative expression and artistic style transfer through deep learning models. Consequently, this study proposes a novel model that integrates conditional generative adversarial networks (cGANs) with variational autoencoders (VAEs). This model aims to effectively address the challenges associated with image generation and style conversion in photographic art by leveraging the realistic generation capabilities of cGANs alongside the diversity maintenance features of VAEs. In the experimental section, the proposed cGANs + VAEs model is systematically compared with traditional Deep Convolutional GANs (DCGAN) and Pix2Pix models through empirical analysis. The experimental results indicate that the cGANs + VAEs model significantly outperforms traditional models in terms of image quality, artistic expression, and user satisfaction. Expert reviews further confirm the model’s superiority in artistic style imitation and creative generation. Additionally, user surveys reveal that most participants are highly satisfied with the images generated by the model, particularly regarding artistic perception and visual effects. Moreover, the cGANs + VAEs model demonstrates strong performance in Frechet Inception Distance (FID) and Inception Score (IS) across multiple datasets, yielding FID values of 13.67, 9.45, and 11.90 on the COCO, CelebA, and WikiArt datasets, respectively. In summary, the proposed cGANs + VAEs model not only achieves remarkable advancements in the technical performance of image generation but also exhibits considerable potential for practical applications in photographic art creation.},
  keywords={Image synthesis;Deep learning;Art;Artificial intelligence;Photography;Training;Diversity reception;Data models;Analytical models;Translation;Deep learning;conditional generative adversarial networks;variational autoencoder;photography artistic creation;virtual image technology},
  doi={10.1109/ACCESS.2025.3529521},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9644352,
  author={Franchi, Valerio and Ntagiou, Evridiki},
  booktitle={2021 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)}, 
  title={Augmentation of a Virtual Reality Environment Using Generative Adversarial Networks}, 
  year={2021},
  volume={},
  number={},
  pages={219-223},
  abstract={Building a dataset to train machine and deep learning models has become a challenging task ever since more complex architectures and deeper neural networks have begun to be utilized with higher frequency, especially across computer vision applications in various fields. This hardship is prompted by the lack of data readiness and the difficulty associated with gathering enough of it, in order to avoid unbalanced datasets and overfitting during training. Occasionally, simulation environments are employed as a result of the unavailability of time and resources to collect real-world data. We present an application of Generative Adversarial Network (GAN) data augmentation in a vision-based planetary rover localisation application. Due to the absence of extra-terrestrial data, the system was trained on several artificially-built lunar terrains inside a Virtual Reality (VR) simulation environment. In order to further enhance our dataset, a GAN was utilized to augment the data retrieved from the simulation, while simultaneously averting a reduction in image quality, which is common with other forms of data augmentation. Despite the fact that GAN was trained with only a small number of images, it was able to recreate areas of the VR environment with high precision. Additionally, training the system with the GAN enhanced data improved the output compared to employing only basic data augmentation techniques.},
  keywords={Location awareness;Training;Solid modeling;Three-dimensional displays;Neural networks;Moon;Virtual reality;virtual reality;generative adversarial networks;computer vision;rover localisation},
  doi={10.1109/AIVR52153.2021.00050},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9544167,
  author={Htet, Aung Si Min and Lee, Hyo Jong},
  booktitle={2021 International Conference on Computer Engineering and Artificial Intelligence (ICCEAI)}, 
  title={TripletGAN VeinNet: Palm Vein Recognition Based on Generative Adversarial Network and Triplet Loss}, 
  year={2021},
  volume={},
  number={},
  pages={454-458},
  abstract={In recent years, palm vein recognition has obtained significant attention as its uniqueness, stable features, and high recognition rate. Although state-of-art deep learning methods can outperform several research domains, the lack of sufficiently large data for vein-based biometric recognition can suffer from generalization problems and degrades the model accuracy. Our approach trained Generative Adversarial Nets (GAN) with triplet loss for classification as an additional task. Lately, triplet networks are widely applied as it learns the latent space representation between neighbors and performs significantly higher accuracy even for insufficient data size. Moreover, in practical application, the quality of acquired vein images is low due to external factors and affects the recognition accuracy. To overcome this problem, we propose a CNN-based Encoder-Decoder network for vein segmentation to utilize the accuracy performance. Jerman enhancement filter is applied to enhance the vein ROI images for labeling the ground truth mask images for training the Encoder-Decoder network.},
  keywords={Training;Image segmentation;Image recognition;Veins;Supervised learning;Training data;Semisupervised learning;component;Palm Vein Recognition;Triplet Loss;Generative Adversarial Network;Encoder-Decoder Network},
  doi={10.1109/ICCEAI52939.2021.00088},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8328496,
  author={Bhat, Rajendra Rana and Viswanath, Vivek and Li, Xiaolin},
  booktitle={2017 IEEE 15th Intl Conf on Dependable, Autonomic and Secure Computing, 15th Intl Conf on Pervasive Intelligence and Computing, 3rd Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress(DASC/PiCom/DataCom/CyberSciTech)}, 
  title={DeepCancer: Detecting Cancer via Deep Generative Learning Through Gene Expressions}, 
  year={2017},
  volume={},
  number={},
  pages={901-908},
  abstract={Transcriptional profiling on microarrays to obtain gene expressions has frequently been a subject of medical analysis in an effort to facilitate cancer diagnosis. Motivated by the intention to further this analysis, we propose DeepCancer: a deep generative machine learning model that learns features from unlabeled microarray data. This model has been used in conjunction with traditional classifiers that perform classification of the tissue samples as either being cancerous or non-cancerous. The proposed model has been tested on two different clinical datasets. Furthermore, evaluation metrics report a high precision score, while significantly controlling the false positive and false negative scores, thus appropriately justifying the learning and detection ability of our model.},
  keywords={Data models;Gene expression;Generators;Breast cancer;Training;Prostate cancer;gene expressions;deep generative learning;supervised classification},
  doi={10.1109/DASC-PICom-DataCom-CyberSciTec.2017.152},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10581812,
  author={Huang, Luosen and Liu, Hengyuan and Liu, Yong and Shang, Ying and Li, Zheng},
  booktitle={2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={A Generative Adversarial Imitation Learning Method for Continuous Integration Testing}, 
  year={2024},
  volume={},
  number={},
  pages={1084-1089},
  abstract={In Continuous Integration (CI), Test Case Prioritization (TCP) is crucial for the efficiency and effectiveness of the software testing. While Reinforcement Learning (RL) offers a promising approach for TCP, it struggles with the low failure rates of test cases in industrial CI environment, leading to sparse rewards and unstable learning efficiency. Furthermore, designing a proper reward function is challenging due to its dependency on the abstracted features of the test cases. To address these issues, we propose a Generative Adversarial Imitation Learning (GAIL) method for TCP, which allows agents to learn directly from the expert experience rather than through potentially biased reward functions. We use the Copeland method as a pairwise ranking strategy and train the agent using optimal rankings, considered as expert experience generated from previous CI cycles, leading to more stable and efficient learning. In addition, we introduce a new metric, the Average of the Percentage of Faults Detected based on Execution Time (APFDET), to evaluate the effectiveness of the proposed approach. Empirical studies are performed on six industrial datasets. The results show that GAIL has a better fault detection capability on TCP problems.},
  keywords={Software testing;Seminars;Measurement;Imitation learning;Fault detection;Reinforcement learning;Continuous integration;Continuous Integration;Test Case Prioritization;Generative Adversarial Imitation Learning},
  doi={10.1109/AINIT61980.2024.10581812},
  ISSN={},
  month={March},}@ARTICLE{11029501,
  author={Chen, Zhenqin and Lin, Yiwei and Luo, Qiong and Xu, Jinshan},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={DIFF-FECG: A Conditional Diffusion-Based Method for Fetal ECG Extraction from Abdominal ECG}, 
  year={2025},
  volume={},
  number={},
  pages={1-13},
  abstract={Fetal electrocardiography (FECG) is a crucial tool for assessing fetal cardiac health and pregnancy status. Direct invasive FECG provides reliable fetal heart rate signals, but poses risks and is limited to use during labor. Conversely, non-invasive monitoring of the fetal heart is possible via abdominal electrocardiography (AECG), which detects fetal heart waveforms using electrodes positioned on the mother’s abdomen. However, this method is often subject to interference from maternal cardiac activity and other external sources. To address this issue, we propose a novel diffusion method, DIFF-FECG, aimed at improving the extraction of FECG signals from AECG recordings. This method leverages a condition-driven diffusion process to learn specific conditional probability distributions, enabling the effective separation of high-quality FECG signals from noisy AECG data. By adaptively managing the inherent non-Gaussian noise characteristics of MECG within the AECG, DIFF-FECG achieves more effective FECG reconstruction. Furthermore, the quality of the generated FECG signals is also enhanced by adding reconstruction loss and multiple reconstructions. Experimental results on two public databases demonstrate that the proposed DIFF-FECG method yields satisfactory results, with an average Pearson correlation coefficient of 0.922 for the estimated FECG. These findings underscore the potential of diffusion probabilistic models in advancing FECG signal extraction techniques, thereby contributing to improved fetal health monitoring.},
  keywords={Noise;Diffusion models;Recording;Electrocardiography;Databases;Artificial intelligence;Training;Pregnancy;Monitoring;Image reconstruction;Fetal ECG exaction;abdominal ECG;generative network;diffusion model},
  doi={10.1109/TAI.2025.3578007},
  ISSN={2691-4581},
  month={},}@INPROCEEDINGS{9551049,
  author={Liu, Zenghao and Wang, Haoran and Zhang, Yudong and Wang, Xingli},
  booktitle={2021 4th International Conference on Pattern Recognition and Artificial Intelligence (PRAI)}, 
  title={Deep Masking Generative Network For Irregularly Sampled Multivariate Time Series}, 
  year={2021},
  volume={},
  number={},
  pages={296-300},
  abstract={Irregularly sampled multivariate time series data arise naturally in many application domain where they present a significant challenge to standard deep learning models, because they do not naturally yield a fixed-dimensional representation. In this paper, we propose a new deep learning framework named Deep Masking Generative Network from the perspective of missing data. And we introduce masking layer and unmasking layer to convert the sampled multivariate time series data into a fixed dimensional temporal representation and obtain the sampled values at any time point respectively. To process continuous time series data efficiently, we further propose continuous convolution layers with tunable kernel width. We investigate the performance of our framework on classification tasks using real datasets. Experiments show that our model performs better than a range of baseline while offering significantly faster training times.},
  keywords={Deep learning;Training;Convolution;Time series analysis;Feature extraction;Data models;Data mining;Irregularly sampled multivariate time-series;Generative network;Variational autoencoder;Continuous convolution},
  doi={10.1109/PRAI53619.2021.9551049},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10281235,
  author={Yang, Shuopeng},
  booktitle={2023 4th International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)}, 
  title={Enhancement Method of Reservoir Numerical Simulation Based on Generative Adversarial Networks}, 
  year={2023},
  volume={},
  number={},
  pages={132-135},
  abstract={In practical simulation research of fluid flow in reservoir porous media, the demand for computational resources in numerical simulation greatly limits its accuracy and practical usage. While the numerical solution of Darcy flow’s PDE is based on the idea of discretizing the continuous geology models into an upscaled grid to proximate the analytical solution. The grid size which can significantly affect the computational effort becomes an essential factor. In our research, we borrow the idea from super-resolution technique to map the relationship between the simulation results by coarse and fine grids and propose a simulation enhancement method based on GAN structure. The designed network called petrophysical constrained simulation generative adversarial network (PCSGAN) employs RRDB and attention mechanism to achieve the above target. Different from traditional super-resolution methods, PCSGAN innovatively uses the petrophysical grid data to constrain and guide the enhancement procedure to improve its accuracy. To demonstrate the PCSGAN’s ability, we design some simulation experiments by finite volume of the 2D anisotropy reservoir models. Each model has two scale sizes, the fine one is 16 times larger than the coarse one. The target of PCSGAN is to enhance the simulation result from coarse gird to match the one from fine grid. From these experiments, the effect of PCSGAN is fully evaluated, the analysis and discussion of these results are also provided.},
  keywords={Solid modeling;Simulation;Superresolution;Fluid flow;Media;Reservoirs;Numerical simulation;Generative adversarial networks;simulation enhancement;high-dimensional PDEs;numerical simulation;fluid flow;porous media},
  doi={10.1109/ICBAIE59714.2023.10281235},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{11040619,
  author={Neelukumari, K.S. and Murali, L. and R., Rithika and E., Shenbagalakshmi and N., Nancy},
  booktitle={2025 3rd International Conference on Artificial Intelligence and Machine Learning Applications Theme: Healthcare and Internet of Things (AIMLA)}, 
  title={A Predictive Machine Learning Analysis for Stroke Prediction}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Stroke impact on an individual's health remains alarming around the globe, and requires analysis and treatment on time. This paper discusses the design and implementation of IoT based health device incorporating highly sophisticated machine learning techniques for realtime stroke prediction. The system is comprised of temperature, pulse, and ECG sensors connected through an ESP32 microcontroller. The data is collected and stored on the ThingSpeak cloud for further analysis. The ANN algorithm within MATLAB showcased the highest stroke prediction accuracy at 92%, demonstrating strong performance for identifying at-risk patients. For comparison, the same dataset was utilized to train a Generative AI (Gen AI) model and results showed an 88% accuracy, which is lower than ANN due to structured health data complexity. Beyond showing the promise of Gen AI in healthcare analytics, this demonstrates how more complex models can fail to outperform simpler models for certain applications. The device provides real time alarms and predictive information, which is a step towards more advanced healthcare systems.},
  keywords={Temperature sensors;Temperature measurement;Cloud computing;Machine learning algorithms;Medical services;Machine learning;Artificial neural networks;Mathematical models;Real-time systems;Monitoring;ANN - artificial neural network;GEN AI - generative AI},
  doi={10.1109/AIMLA63829.2025.11040619},
  ISSN={},
  month={April},}@ARTICLE{10115278,
  author={Yu, Youshan and Lakemond, Nicolette and Holmberg, Gunnar},
  journal={IEEE Transactions on Engineering Management}, 
  title={AI in the Context of Complex Intelligent Systems: Engineering Management Consequences}, 
  year={2024},
  volume={71},
  number={},
  pages={6512-6525},
  abstract={As artificial intelligence (AI) is increasingly integrated into the context of complex products and systems (CoPS), making complex systems more intelligent, this article explores the consequences and implications for engineering management in emerging complex intelligent systems (CoIS). Based on five engineering management aspects, including design objectives, system boundaries, architecting and modeling, predictability and emergence, and learning and adaptation, a case study representing future CoIS illustrates how these five aspects, as well as their relationship to criticality and generativity, emerge as AI becomes an integrated part of the system. The findings imply that a future combined perspective on allowing generativity and maintaining or enhancing criticality is necessary, and notably, the results suggest that the understanding of system integrators and CoPS management partly fundamentally alters and partly is complemented with the emergence of CoIS. CoIS puts learning and adaptation characteristics in the foreground, i.e., CoIS are associated with increasingly generative design objectives, fluid system boundaries, new architecting and modeling approaches, and challenges predictability. The notion of bounded generativity is suggested to emphasize the combination of generativity and criticality as a direction for transforming engineering management in CoPS contexts and demands new approaches for designing future CoIS and safeguard its important societal functions.},
  keywords={Artificial intelligence;Complex systems;Engineering management;Stakeholders;Safety;Complex systems;Context awareness;Intelligent systems;Artificial intelligence (AI);complex intelligent systems (CoIS);criticality;engineering management;generativity},
  doi={10.1109/TEM.2023.3268340},
  ISSN={1558-0040},
  month={},}@ARTICLE{10287345,
  author={Niu, Yanmin and Xue, Han},
  journal={IEEE Access}, 
  title={Exercise Generation and Student Cognitive Ability Research Based on ChatGPT and Rasch Model}, 
  year={2023},
  volume={11},
  number={},
  pages={116695-116705},
  abstract={In the context of generative artificial intelligence (AI), AIGCP (content generation-based AI products), represented by ChatGPT, have attracted extensive attention in the field of education. This study focuses on the discipline of university operating systems and adopts the Rasch model as the theoretical foundation. By combining ChatGPT with existing question banks and using the bidirectional fine-grained table method, it compiles questions that match the corresponding abilities for three different levels of student groups. This aims to explore personalized question matching and student cognitive ability analysis methods to support personalized teaching. The research findings indicate that ChatGPT is capable of matching exercises of similar difficulty under the Rasch model, but its accuracy in generating exercise content is relatively low, and the variety of exercise content is limited. Students’ performance in overall competency requires improvement. This study aims to leverage the combined strengths of ChatGPT and traditional educational assessment methods to introduce an innovative approach to support personalized instruction. It aims to establish the routine utilization of exercise creation by ChatGPT and personalized analysis of student cognitive abilities, thereby better fulfilling the demands of education within the classroom setting.},
  keywords={Computational modeling;Chatbots;Mathematical models;Education;Analytical models;Testing;Operating systems;Generative adversarial networks;Artificial intelligence;Question answering (information retrieval);Generative artificial intelligence;Rasch model;personalized question matching;cognitive ability;operating system exercises},
  doi={10.1109/ACCESS.2023.3325741},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10452539,
  author={Boyapati, Neeraj and Tej, Medam Bhanu and Darshitha, M and Shreya, P and Namasivaya Naveen, S and Rajive Gandhi, C and Amrutha, V},
  booktitle={2023 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI)}, 
  title={Alzheimer’s Disease Prediction using Convolutional Neural Network (CNN) with Generative Adversarial Network (GAN)}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Alzheimer’s is the most common form of dementia in older individuals, which presents a global health challenge with 10 million new cases annually. This neurological disorder causes neurodegenerative alterations in the brain to unfold gradually, commencing with mild memory impairment and then escalating to loss of social interaction and awareness of the environment. Alzheimer Disease International (ADI) believes that 75% of dementia cases globally go undetected, making the early diagnosis challenging. Currently, stopping the development of Alzheimer’s disease is difficult since there are no viable diagnosis and treatment solutions available. To overcome these challenges, there is now great interest in using machine learning (ML) for early diagnosis of metabolic disorders such as Alzheimer’s. In this work, we propose utilizing a deep convolutional neural network to detect the different phases of Alzheimer’s disease using brain MRI structural data analysis. Magnetic resonance imaging (MRI) aids in the early detection of Alzheimer’s disease and achieves greater efficacy for initial-stage detection. Clinicians can use the suggested categorization approach to diagnose these disorders much earlier. With these ML algorithms, it is highly advantageous to reduce yearly death rates of Alzheimer’s disease in early diagnosis. The suggested technique achieves improved results, with an approved mean score of 96.1% on Alzheimer’s Disease test data. Compared to previous efforts, the current score for accuracy is much greater.},
  keywords={Magnetic resonance imaging;Computational modeling;Predictive models;Generative adversarial networks;Brain modeling;Convolutional neural networks;Reliability;Alzheimer's disease;Diseases;Python;Alzheimer’s disease;dementia;early detection;deep convolutional neural network},
  doi={10.1109/ICDSAAI59313.2023.10452539},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10168628,
  author={Su, Yu-Chi and Chiu, Ching-Te and Cheng, Chih-Han and Liu, Kuan-Hsien and Lee, Tsung-Chan and Chen, Jia-Lin and Luo, Jie-Yu and Chung, Wei-Chang and Chang, Yao-Ren and Ho, Kuan-Ying},
  booktitle={2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS)}, 
  title={CPGAN: Collective Punishment Generative Adversarial Network for Dry Fingerprint Image Enhancement}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Fingerprint has been widely used in our daily life, such as mobile. However, some circumstances may lead to low unlocking rate, like fingerprint at low temperature(dry fingerprint) or washed fingerprint. Our method mainly focuses on the former by making it close to normal temperature fingerprint. The main idea of our method, which called "CPGAN", is to improve GAN to boost the quality of the enhanced fingerprint. Our objective is to make the generator generates the high quality of enhanced fingerprint. The method is divided into two parts: "strengthening the discriminator" and "strengthening the generator". For strengthening the generator, we adopt the mechanism of "Collective Punishment" to our work. For strengthening the discriminator, we utilize two generators and feature extractor to boost the discriminator. In our experiments, the results surpass the state-of-the-arts on FVC2002 about 75%.},
  keywords={Image recognition;Circuits and systems;Image matching;Neural networks;Fingerprint recognition;Generative adversarial networks;Feature extraction;Image enhancement;Dry fingerprints;GAN;Fingerprint recognition;Convolution Neural Network},
  doi={10.1109/AICAS57966.2023.10168628},
  ISSN={2834-9857},
  month={June},}@INPROCEEDINGS{10165297,
  author={Wu, Qiong and Jiang, Zhanjun},
  booktitle={2023 IEEE 3rd International Conference on Information Technology, Big Data and Artificial Intelligence (ICIBA)}, 
  title={Two-stage processing of image restoration problem based on generative adversarial network}, 
  year={2023},
  volume={3},
  number={},
  pages={751-755},
  abstract={Aiming at the problem that texture details and edge information of images are easily lost in the process of image recovery, a two-stage processing algorithm is proposed that combines denoising processing and super-resolution reconstruction processing. The algorithm is divided into two stages, the first stage uses the improved DEGAN network to denoise the image, and the training set and the test set are denoising the training set and the test set respectively through the optimal path obtained by training, and the result is directly transferred to the dataset for the second stage of super-resolution processing. In the second stage, the denoising training set is reconstructed with the improved SRGAN network, and a clean image dataset with the noise processing needs to be added as the target image for super-resolution processing. Compared with single denoising and super-resolution reconstruction, the images recovered by two-stage training processing have significantly improved subjective perception and objective evaluation indicators.},
  keywords={Training;Image edge detection;Superresolution;Noise reduction;Big Data;Generative adversarial networks;Data models;image restoration;image denoising;image super-resolution reconstruction.},
  doi={10.1109/ICIBA56860.2023.10165297},
  ISSN={},
  month={May},}@INPROCEEDINGS{9696113,
  author={Bao, Shuai},
  booktitle={2021 2nd International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE)}, 
  title={Review on Generative Adversarial Network in Computer Vision: Methods and Metrics}, 
  year={2021},
  volume={},
  number={},
  pages={535-542},
  abstract={Generate adversarial networks (GAN) is a popular method, which can be widely used in numerous research areas, such as computer vision, natural language processing, and time series synthesis. However, few references are proposed to give a comprehensive review on GAN based methods. This paper aims to provide a detailed review of GAN based algorithms on computer vision tasks, such as image style transfer, image/video generation, image matting, and image super-resolution. Furthermore, we conclude the evaluation metrics for those tasks to show the effectiveness of GAN based on method. Our review can help beginners recognize the GAN based methods and give a brief introduction on how to apply them to their tasks.},
  keywords={Measurement;Computer vision;Superresolution;Time series analysis;Generative adversarial networks;Natural language processing;Task analysis;GAN;Image style transfer;Image matting;Image generation;Video generation;Image super-resolution},
  doi={10.1109/ICBASE53849.2021.00105},
  ISSN={},
  month={Sep.},}@ARTICLE{9781420,
  author={Naveed, Muhammad Haris and Hashmi, Umair Sajid and Tajved, Nayab and Sultan, Neha and Imran, Ali},
  journal={IEEE Access}, 
  title={Assessing Deep Generative Models on Time Series Network Data}, 
  year={2022},
  volume={10},
  number={},
  pages={64601-64617},
  abstract={To achieve zero touch automation in next generation wireless networks through artificial intelligence (AI), large amounts of training data is required. This training data is publicly unavailable and is a major hindrance in research on AI applications to wireless communication. One solution is using limited real data to generate synthetic data that can be used in lieu of real data. Generative Adversarial Networks (GAN) have been used successfully for this purpose. In this paper, we choose two publicly available GAN - based models and one deep learning - based auto-regressive model. We then compare their performance at generating synthetic time-series wireless network traffic data. We also assess the impact of data scarcity on the generated data quality by varying the level of data available to the models for training. Moreover, in order to assess the usefulness of this generated data, we compare the performance of a gradient boosting regressor trained solely on generated data, real data, and a mix of both at forecasting network traffic. Our experiments show that the GANs perform better than the auto-regressive approach in each aspect considered in this work and forecasting models trained to predict network load based on data generated by these GANs yield error rates comparable to models trained on real data. Finally, augmenting small amounts of real data with generated data leads to minor performance gains in some cases.},
  keywords={Data models;Generative adversarial networks;Telecommunications;Solid modeling;Training data;Time series analysis;Predictive models;Machine learning;GAN;TimeGAN;PAR;DoppleGANger;time series;forecast analysis},
  doi={10.1109/ACCESS.2022.3177906},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10397858,
  author={Mitsunaga, Takuho},
  booktitle={2023 IEEE International Conference on Computing (ICOCO)}, 
  title={Heuristic Analysis for Security, Privacy and Bias of Text Generative AI: GhatGPT-3.5 case as of June 2023}, 
  year={2023},
  volume={},
  number={},
  pages={301-305},
  abstract={With the rapid advancement of technology and the expansion of available data, AI has permeated many aspects of people's lives. Large Language Models(LLMs) such as ChatGPT are increasing the accuracy of their response and achieving a high level of communication with humans. These AIs can be used in business to benefit, for example, customer support and documentation tasks, allowing companies to respond to customer inquiries efficiently and consistently. In addition, AI can generate digital content, including texts, images, and a wide range of digital materials based on the training data, and is expected to be used in business. However, the widespread use of AI also raises ethical concerns. The potential for unintentional bias, discrimination, and privacy and security implications must be carefully considered. Therefore, While AI can improve our lives, it has the potential to exacerbate social inequalities and injustices. This paper aims to explore the unintended outputs of AI and assess their impact on society. Developers and users can take appropriate precautions by identifying the potential for unintended output. Such experiments are essential to efforts to minimize the potential negative social impacts of AI transparency, accountability, and use. We will also discuss social and ethical aspects with the aim of finding sustainable solutions regarding AI.},
  keywords={Privacy;Generative AI;Training data;Security;Artificial intelligence;Task analysis;Business;ChatGPT;Generative AI;Privacy;Bias;Security},
  doi={10.1109/ICOCO59262.2023.10397858},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10718770,
  author={Khan, Gulraiz and Maraha, Heyam and Li, Qingde and Pimbblet, Kevin},
  booktitle={2024 29th International Conference on Automation and Computing (ICAC)}, 
  title={A Brief Review of Recent Advances in AI-Based 3D Modeling and Reconstruction in Medical, Education, Surveillance and Entertainment}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In the era of rapid technological development, 3D models are being used more frequently. In reaction to the growing need for 3D Modeling applications, this survey thoroughly looks at the many uses of 3D technologies with special focus on medical, education, surveillance, and entertainment sectors. In this study we explore techniques used, challenges faced and algorithmic complexities for each application of reviewed 3D technology to improve overall comprehension and enable well-informed decisions. This study adds to the body of knowledge on the technological integration of Machine Learning based 3D applications while also highlighting the qualitative and quantitative comparison of a subset of applications in each of the four domains that were chosen, as shown in the tabular matrix. Further, this paper suggests an ongoing research to address the limitations in 3D Modeling applications, highlighting the necessity of directing the path of development towards Generative Networks in these related fields for the betterment of society.},
  keywords={Surveys;Solid modeling;Visualization;Three-dimensional displays;Machine learning algorithms;Reviews;Surveillance;Education;Entertainment industry;Security;3D Reconstruction;3D Printing;3D Modeling Applications;Deep Generative Networks},
  doi={10.1109/ICAC61394.2024.10718770},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9054036,
  author={Liu, Kai and Zhou, Huan},
  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Text-Independent Speaker Verification with Adversarial Learning on Short Utterances}, 
  year={2020},
  volume={},
  number={},
  pages={6569-6573},
  abstract={A text-independent speaker verification system suffers severe performance degradation under short utterance condition. To address the problem, in this paper, we propose an adversarially learned embedding mapping model that directly maps a short embedding to an enhanced embedding with increased discriminability. In particular, a Wasserstein GAN with a bunch of loss criteria are investigated. These loss functions have distinct optimization objectives and some of them are less favoured for the speaker verification research area. Different from most prior studies, our main objective in this study is to investigate the effectiveness of those loss criteria by conducting numerous ablation studies. Experiments on Voxceleb dataset showed that some criteria are beneficial to the verification performance while some have trivial effects. Lastly, a Wasserstein GAN with chosen loss criteria, without finetuning, achieves meaningful advancements over the baseline, with 4% relative improvements on EER and 7% on minDCF in the challenging scenario of short 2second utterances.},
  keywords={Training;Signal processing;Generative adversarial networks;Gallium nitride;Speech processing;Kernel;Optimization;speaker embedding;speaker verification;generative adversarial network},
  doi={10.1109/ICASSP40776.2020.9054036},
  ISSN={2379-190X},
  month={May},}@INPROCEEDINGS{11079133,
  author={Giorgi, Giada and Michelotti, Lorenzo and Narduzzi, Claudio and Bertocco, Matteo},
  booktitle={2025 IEEE International Instrumentation and Measurement Technology Conference (I2MTC)}, 
  title={Test-set generation for AI-augmented measurement systems}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Recent advancements in artificial intelligence (AI) have enabled the integration of sophisticated diagnostic algorithms into measurement systems. This innovation poses new challenges in properly validating these AI-augmented measurement systems. In particular, the availability of a sufficient large number of reference signals plays an important role in a correct assessment of system performances. This paper presents a method for generating synthetic traces, using a generative AI approach based on an explainable variational autoencoder with a two-dimensional latent space. Trained on a limited dataset, the proposed method can generate synthetic traces similar to the original data, as well as entirely new synthetic samples. The generation process is straightforward, and can be easily controlled by a human operator, offering promising new possibilities for the generation of test signals. 1},
  keywords={Technological innovation;Privacy;Generative AI;Atmospheric measurements;Autoencoders;Process control;Aerospace electronics;Particle measurements;Testing;Noise level;testing;generative artificial intelligence;variational autoencoder;ECG},
  doi={10.1109/I2MTC62753.2025.11079133},
  ISSN={2642-2077},
  month={May},}@INPROCEEDINGS{10624626,
  author={De La Trinidad-Rendón, Julio Sebastián and Reyes-Avendaño, Jorge Antonio and González-Hernández, Hugo Gustavo},
  booktitle={2024 7th International Conference on Electronics, Communications, and Control Engineering (ICECC)}, 
  title={Towards Diffusion Model Based Dataset Augmentation for Negative Obstacle Detection Systems}, 
  year={2024},
  volume={},
  number={},
  pages={7-11},
  abstract={This work presents a methodology to generate synthetic images of negative obstacles such as potholes to train artificial vision systems for autonomous vehicles. The proposed methodology uses Latent Diffusion Models and Dreambooth LoRAs to fine-tune models to includer subjects of which we have few photographs. The method is validated by training a simple predictive model with a subset of the synthetically generated images and testing it with a mixed training dataset of real and synthetic images. The model shows good precision in distinguishing roads with and without potholes. As such, the proposed methodology demonstrates the plausibility of generating realistic images with the objective to train artificial vision models focused in autonomous vehicles whit some limitations such as the generation of unusable images due to aberrations and the labelling requirements.},
  keywords={Training;Generative AI;Roads;Machine vision;Predictive models;Diffusion models;Labeling;Synthetic Datasets;Diffusion Models;Artificial Intelligence;Generative Artificial Intelligence},
  doi={10.1109/ICECC63398.2024.00009},
  ISSN={},
  month={March},}@ARTICLE{9904031,
  author={Jiang, Xiaoyu and Ge, Zhiqiang},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={RAGAN: Regression Attention Generative Adversarial Networks}, 
  year={2023},
  volume={4},
  number={6},
  pages={1549-1563},
  abstract={Despite surrounding by Big Data, we still need to learn from insufficient data in many scenarios. Building an accurate regression model for a small amount of data is a pretty tricky and exciting problem. At present, it is a promising solution to augment limited real data by generating data through generative adversarial networks (GANs). However, when GAN is used to generate labeled data in regression modeling, it lacks attention to the relationship between independent and dependent variables, resulting in poor performance of regression modeling. This article proposes a novel regression attention GAN (RA-GAN) for augmented regression modeling. Regression attention mechanisms are introduced into network parameters learning of both generator and discriminator in RA-GAN to establish a known relationship between variables. This makes RA-GAN restore the regression information during data generation. In addition, an indicator called cross regression score is designed to describe the quality of the generated data before augmented regression modeling, effectively evaluating data augmentation performance in advance. The effectiveness and superiority of the proposed methods are verified in an actual industrial soft-sensing case and a diabetes prediction case through data augmentation regression applications.},
  keywords={Data models;Generative adversarial networks;Predictive models;Training;Soft sensors;Generators;Big Data;Data augmentation;Performance evaluation;Regression analysis;Data augmentation;evaluation indicator;generative adversarial networks (GANs);regression attention;regression model},
  doi={10.1109/TAI.2022.3209956},
  ISSN={2691-4581},
  month={Dec},}@INPROCEEDINGS{9288324,
  author={Zhou, Shizhe and Liu, Zeyu},
  booktitle={2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Sketch2Relief: Generating Bas-relief from Sketches with Deep Generative Networks}, 
  year={2020},
  volume={},
  number={},
  pages={510-517},
  abstract={We present a novel sketch-based system for generating digital bas-relief sculptures. All existing computational methods for generating digital bas-reliefs first require the input of a three-dimensional (3D) scene, thus preventing artists from freely creating or exploring designs when 3D data are not available. Motivated by this limitation, we propose a generative adversarial network (GAN)-based sketch modeling system for generating digital bas-reliefs from freehand user sketches (see Figure 1, 5). The basic tool underpinning the interface is a conditional GAN (cGAN) that digitally learns a functional map from a contour image to a 3D model for any given viewpoint of the corresponding bas-relief model. When using our system for designing bas-reliefs, the user only needs to draw 2D sketch lines without having to designate any additional hints on the lines. The interface returns bas-relief results in interactive time (500 ms per bas-relief on average). We tested the quality and robustness of our approach with extensive and comprehensive experiments. By carefully analyzing the results, we verified that our system can faithfully reconstruct bas-reliefs from a test dataset and can generate completely new reliefs from raw amateur sketches.},
  keywords={Solid modeling;Three-dimensional displays;Two dimensional displays;Neural networks;Tools;Generative adversarial networks;Robustness;Multimedia Sketching Interface;Shape Modeling;Bas-Relief Design;Generative Adversarial Neural Networks},
  doi={10.1109/ICTAI50040.2020.00085},
  ISSN={2375-0197},
  month={Nov},}@ARTICLE{11173659,
  author={Wang, Shuai and Zhang, Xiaorui and Song, Zhe and Hua, Zizheng and Song, Jinpeng and Wang, Jiacheng and Pan, Gaofeng and Niyato, Dusit},
  journal={IEEE Wireless Communications}, 
  title={Generative AI Empowered Covert Communications: Autonomy, Efficiency, and Suitability}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={Given tremendously growing security and privacy concerns, there is a substantial surge in demand for covert communication techniques. Traditional methods, constrained by static configurations and an inability to leverage historical data, suffer from inefficiencies in resource utilization, vulnerability to evolving threats, and limited adaptability to interference. This article introduces a Generative Artificial Intelligence (GAI)-driven framework to overcome such limitations, integrating advanced models such as Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), and Generative Diffusion Models (GDMs) into covert communication systems. By employing unsupervised learning, the framework dynamically optimizes transmission parameters—including power allocation, modulation schemes, and frequency hopping—in real time, enabling adaptive responses to channel conditions and historical patterns. Through this optimization, the proposed approach enhances security via unpredictable transmission patterns, reduces bit error rates with optimized modulation and coding schemes, and strengthens resistance to interference and interception through noise-like signal generation. In addition to these advancements, the paper identifies key challenges and further outlines future directions. This work underscores GAI’s transformative potential in balancing concealment, efficiency, and adaptability for next-generation covert communication systems.},
  keywords={Interference;Security;Reliability;Communication systems;Adaptation models;Aerospace electronics;Spread spectrum communication;Resource management;Generative adversarial networks;Jamming;Covert Communication;Generative Artificial Intelligence;Network Optimization;Spectrum Management},
  doi={10.1109/MWC.2025.3596961},
  ISSN={1558-0687},
  month={},}@ARTICLE{11072042,
  author={Pavithran, Shilpa and Nair, Vineeta V and S, Aravind and George, Elizabeth and James, Alex},
  journal={IEEE Journal of Selected Areas in Sensors}, 
  title={Position Monitoring of Human Hands Using Cross-Slot Antennas and AI Integration for Hand Swing Activity Analysis}, 
  year={2025},
  volume={2},
  number={},
  pages={212-221},
  abstract={This work details the position monitoring of human hands using two similar cross-slot antennas operating in the frequency range of 2–3 GHz. Here, one antenna is kept on the chest and the other one is kept on the hand of a volunteer to monitor hand swing activity. The measured transmission values ($S_{21}$) along with corresponding frequencies from the antenna are used for generating synthetic $S_{21}$ data using custom generative adversarial networks (GANs). Classification of data for two positions is performed on an artificial neural network (ANN), support vector machines (SVMs), decision tree (DT), and random forest. ANN gives an accuracy of 85% and is implemented on FPGA. The article also discusses the electromagnetic (EM) wave propagation around the human torso.},
  keywords={Hands;Generative adversarial networks;Antennas;Training;Support vector machines;Artificial neural networks;Synthetic data;Monitoring;Transmitting antennas;Table lookup;Artificial neural network (ANN);cross-slot antenna;FPGA;generative adversarial network (GAN);transmission characteristics},
  doi={10.1109/JSAS.2025.3586207},
  ISSN={2836-2071},
  month={},}@ARTICLE{9690406,
  author={Woollaston, Victoria},
  journal={Engineering & Technology}, 
  title={Is fake data good news?}, 
  year={2021},
  volume={16},
  number={8},
  pages={1-7},
  abstract={FAKE NEWS. Fake reviews. Deep-fake videos. Technology has made it easier than ever to generate content with the aim of obfuscating. 'Fake' has always had inherently negative connotations, yet there is a rising genre of fake content that is altogether more positive. It's still algorithmically generated, it's still created with the purpose of disguising the truth, but it has potential to make the world fairer, more open, and safer. At least, that's what advocates of synthetic data are on a mission to prove as the technology gets set to enter the mainstream.},
  keywords={Artificial intelligence;Generative adversarial networks;COVID-19;Data models;Urban areas;Data privacy;Videos},
  doi={10.1049/et.2021.0812},
  ISSN={1750-9637},
  month={Sep.},}@INPROCEEDINGS{11140600,
  author={Nitin, V and Das, N Enoch and Sahithi, E Meghana and Santhosh, T. and Sai, K. Tarun},
  booktitle={2025 8th International Conference on Computing Methodologies and Communication (ICCMC)}, 
  title={Enhancing Emotion Detection in Social Media with a Generative AI Approach to Analyzing Twitter Reviews}, 
  year={2025},
  volume={},
  number={},
  pages={787-794},
  abstract={This study presents an automated approach to emotion detection and classification in informal text using SpaCy, with a focus on social media content such as tweets. The inherent brevity and colloquial nature of platforms like Twitter pose significant challenges for emotion analysis. To address this, the methodology incorporates web scraping of user reviews, each tagged with a unique identifier, and utilizes a Generative AI model to extract structured insights including dish names, ratings, pros, and cons in Markdown format. The analysis is conducted on the AIT-2018 dataset, enhanced with lexical resources such as WordNet-Affect and EmoSenticNet, enabling more nuanced emotion recognition. Experimental results demonstrate that the proposed model significantly outperforms traditional methods, particularly in handling short-form social media text. The findings underscore the effectiveness of automated systems in sentiment analysis and affective computing, offering valuable advancements in understanding user emotions and improving human-computer interaction.},
  keywords={Emotion recognition;Sentiment analysis;Affective computing;Social networking (online);Reviews;Generative AI;Computational modeling;Blogs;Emotion Detection;Sentiment Analysis;Affective Computing;Twitter Data;Natural Language Processing},
  doi={10.1109/ICCMC65190.2025.11140600},
  ISSN={},
  month={July},}@INPROCEEDINGS{10782966,
  author={Ruiperez-Campillo, Samuel and Ryser, Alain and Sutter, Thomas M. and Feng, Ruibin and Ganesan, Prasanth and Deb, Brototo and Brennan, Kelly A. and Kolk, Maarten Z.H. and Tjong, Fleur V.Y. and Rogers, Albert J. and Narayan, Sanjiv M. and Vogt, Julia E.},
  booktitle={2024 46th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}, 
  title={Can Generative AI Learn Physiological Waveform Morphologies? A Study on Denoising Intracardiac Signals in Ischemic Cardiomyopathy}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Reducing electrophysiological (EP) signal noise is essential for diagnosis, mapping, and ablation, yet traditional approaches are suboptimal. This study tests the hypothesis that generative artificial intelligence (AI), specifically Variational Autoencoders (VAEs), can effectively denoise these signals by forming robust internal representations of ‘clean' signals. Utilizing a dataset of 5706 time series from 42 patients with ischemic cardiomyopathy at risk of cardiac sudden death, we set out to apply a β-VAE model to denoise and reconstruct intra-ventricular monophasic action potential (MAP) signals, which have verifiable morphology. The β-VAE model is evaluated against various noise types, including EP noise, demonstrating superior denoising performance compared to traditional methods (Pearson’s Correlation of denoised vs original of 0.967 ± 0.009 for our proposed model vs 0.879 ± 0.022 for the best performing baseline). Results indicate that the model effectively reduces a wide array of noise types, particularly EP noise. We conclude that generative AI provides powerful tools that can eliminate diverse sources of noise in single beats by learning essential signal features without manual annotation, outperforming state-of-the-art denoising techniques.Clinical Relevance— The proposed β-VAE model’s ability to effectively denoise and reconstruct intracardiac signals, particularly in the challenging context of arrhythmias, can significantly enhance diagnostic accuracy across a variety of heart rhythm disorders and improve treatment efficacy.},
  keywords={Generative AI;Heart beat;Filtering;Noise;Noise reduction;Time series analysis;Morphology;Manuals;Robustness;Real-time systems},
  doi={10.1109/EMBC53108.2024.10782966},
  ISSN={2694-0604},
  month={July},}@ARTICLE{10963909,
  author={Chamola, Vinay and Shall Peelam, Mritunjay and Guizani, Mohsen and Niyato, Dusit},
  journal={IEEE Open Journal of the Communications Society}, 
  title={Future of Connectivity: A Comprehensive Review of Innovations and Challenges in 7G Smart Networks}, 
  year={2025},
  volume={6},
  number={},
  pages={3555-3613},
  abstract={The evolution from 1G to 6G networks has transformed global communication, progressing from basic voice calls in 1G to the immersive, AI-enabled experiences of 6G. As emerging AI-driven applications like autonomous systems, the Internet of Everything (IoE), and immersive technologies demand unprecedented capabilities, 7G networks are set to redefine connectivity by overcoming the limitations of earlier generations. This paper comprehensively reviews the innovations and challenges in 7G networks, focusing on integrating advanced AI and machine learning paradigms such as meta-learning, incremental learning, distributed intelligence, and reinforcement learning to enhance adaptability, resource allocation, and edge performance. The review also examines the role of Large Language Models (LLMs) in enabling real-time actionable intelligence and optimizing edge devices within 7G. The paper highlights the use of technologies, including blockchain for decentralized security, quantum computing for robust encryption, terahertz communication for ultra-fast data transfer, zero-energy solutions for sustainability, and generative AI for intelligent network optimization and automation. By addressing these challenges and exploring cutting-edge strategies, this paper envisions 7G networks as the foundation for a secure, intelligent, and sustainable digital future, equipped to combat emerging cyber warfare threats, enhance resilience against technological disruptions, and support innovations across smart cities, autonomous systems, healthcare, and industrial IoT.},
  keywords={6G mobile communication;Artificial intelligence;Terahertz communications;5G mobile communication;Real-time systems;Technological innovation;Quantum computing;Security;Quantum entanglement;Wireless communication;7G networks;intelligent networking;machine learning;AI;LLM;wireless;terahertz communication;meta-learning;self-sustaining;security;XAI;explainable AI;distributed intelligence;edge performance;real-time actionable intelligence;generative AI},
  doi={10.1109/OJCOMS.2025.3560035},
  ISSN={2644-125X},
  month={},}@INPROCEEDINGS{9498052,
  author={Bouaafia, Soulef and Messaoud, Seifeddine and Khemiri, Randa and Sayadi, Fatma Elzahra},
  booktitle={2021 IEEE International Conference on Design & Test of Integrated Micro & Nano-Systems (DTS)}, 
  title={COVID-19 Recognition based on Deep Transfer Learning}, 
  year={2021},
  volume={},
  number={},
  pages={1-4},
  abstract={With the rapid development technology, Artificial Intelligence is the most powerful technique, it has made great progress in many areas, including computer vision and medical imaging. This paper proposes a deep learning-based framework for COVID-19 detection. Deep transfer learning models-based on a pre-trained Deep convolutional Neural Network are proposed. Several pre-trained models, such as DensNet201, InceptionV3, VGG16, and ResNet50 were evaluated for this analysis.The datasets used in this paper for training model are a mix of X-ray and CT images in two distinct categories: Normal and COVID-19. The experimental results proved that the DensNet201 was the most suitable deep transfer model according to the test accuracy measure and that it reached 97% with the other performance metrics such as F1 score, precision, and recall.},
  keywords={COVID-19;Measurement;Training;Analytical models;Computational modeling;Computed tomography;Transfer learning;Artificial Intelligence;COVID-19;Medical images;Transfer Learning},
  doi={10.1109/DTS52014.2021.9498052},
  ISSN={},
  month={June},}@INPROCEEDINGS{9763651,
  author={Williams, Daniel and Clark, Chelece and McGahan, Rachel and Potteiger, Bradley and Cohen, Daniel and Musau, Patrick},
  booktitle={2022 IEEE International Conference on Assured Autonomy (ICAA)}, 
  title={Discovery of AI/ML Supply Chain Vulnerabilities within Automotive Cyber-Physical Systems}, 
  year={2022},
  volume={},
  number={},
  pages={93-96},
  abstract={Steady advancement in Artificial Intelligence (AI) development over recent years has caused AI systems to become more readily adopted across industry and military use-cases globally. As powerful as these algorithms are, there are still gaping questions regarding their security and reliability. Beyond adversarial machine learning, software supply chain vulnerabilities and model backdoor injection exploits are emerging as potential threats to the physical safety of AI reliant CPS such as autonomous vehicles. In this work in progress paper, we introduce the concept of AI supply chain vulnerabilities with a provided proof of concept autonomous exploitation framework. We investigate the viability of algorithm backdoors and software third party library dependencies for applicability into modern AI attack kill chains. We leverage an autonomous vehicle case study for demonstrating the applicability of our offensive methodologies within a realistic AI CPS operating environment.},
  keywords={Machine learning algorithms;Supply chains;Software algorithms;Cyber-physical systems;Software;Software reliability;Safety;Cyber-Physical Systems;Artificial Intelligence;Machine Learning;Autonomous Vulnerability Discovery;Supply Chain;Autonomous Vehicles},
  doi={10.1109/ICAA52185.2022.00020},
  ISSN={},
  month={March},}@INPROCEEDINGS{10803205,
  author={Soni, Palvi and Sharma, Chirag},
  booktitle={2024 International Conference on Cybernation and Computation (CYBERCOM)}, 
  title={Machine Learning Applications in the Diagnosis of PCOS: A Systematic Review}, 
  year={2024},
  volume={},
  number={},
  pages={388-393},
  abstract={Today we are living in a digital era, in which female's reproductive health is proven to be a bigger concern. Worldwide, a large number of women suffer from PCOS, a condition marked by hormonal imbalance, ovarian cysts, and metabolic abnormalities. Follicles, which are tiny collections of fluid inside the ovaries that don't produce eggs on a monthly basis, can proliferate in the ovaries. This disease contributes to a number of other health problems, including type 2 diabetes, obesity, blood pressure, and other metabolic diseases, in addition to impairing a woman's ability to conceive. The use of artificial intelligence (AI), machine learning (ML), and image processing (IP) techniques in gaining knowledge and treatment of PCOS is examined in this research. In this research, authors tackle issues like interpreting algorithms, handling heterogeneous data, and ethical considerations. It makes recommendations for future paths to enhance AI-driven techniques in PCOS research and clinical practice. This research demonstrates how AI and image processing can be used to improve early detection, customize treatment, and increase our understanding of PCOS, all of which can improve patient outcomes and healthcare delivery.},
  keywords={Obesity;Ethics;Machine learning algorithms;Fluids;Image processing;Machine learning;Medical services;IP networks;Diseases;Systematic literature review;Polycystic ovaries;Artificial Intelligence;Machine learning;Hormonal disbalance;PCOS;Deep learning;DL and ML},
  doi={10.1109/CYBERCOM63683.2024.10803205},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11082910,
  author={Alghanmi, Razan and Kulaibi, Shahad and Alghamdi, Jana and Bahashwan, Elaf and Aeshmawi, Alaa},
  booktitle={2025 International Conference on Innovation in Artificial Intelligence and Internet of Things (AIIT)}, 
  title={HuntSmart: Hypothesis-Driven Threat Hunting Using GenAI}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={As cyber threats grow in sophistication and frequency, organizations face increasing pressure to detect and mitigate these threats swiftly and accurately. Threat hunting—a proactive approach to identifying malicious activity beyond traditional defenses—remains essential yet challenging. Extracting Tactics, Techniques, and Procedures (TTPs) from vast, unstructured threat data is largely manual, time-consuming, and inconsistent. Additionally, effective threat hunting requires generating actionable hypotheses, a process traditionally reliant on human expertise.This project introduces HuntSmart (2024), a tool designed to automate critical aspects of threat hunting. HuntSmart enhances TTP extraction through the use of the SecureBERT deep learning model, which is configured as a one-to-one classifier to handle cyber threat intelligence (CTI) data. The tool integrates generative AI for automated hypothesis generation via the Gemini API, aligning each hypothesis with the MITRE ATT&CK framework and including Indicators of Compromise (IoCs). HuntSmart prioritizes hypotheses by risk factors such as impact and detection complexity, enabling threat hunters to focus on high-risk threats and providing targeted mitigation suggestions. By automating TTP extraction, risk-based prioritization, and mitigation and detection guidance, HuntSmart offers a scalable and effective approach to threat hunting, contributing a structured, AI-driven methodology to enhance organizational cybersecurity resilience.},
  keywords={Deep learning;Adaptation models;Technological innovation;Accuracy;Generative AI;Prevention and mitigation;Threat assessment;Cyber threat intelligence;Data mining;Computer security;Cyber Threat Intelligence;Hypothesis-Driven Threat Hunting;Generative AI;TTP Extraction;Risk-Based Prioritization;MITRE ATT&CK Framework;Machine Learning in Cybersecurity},
  doi={10.1109/AIIT63112.2025.11082910},
  ISSN={},
  month={May},}@INPROCEEDINGS{9180200,
  author={Corcoran, Peter and Javidnia, Hossein and Lemley, Joseph E. and Varkarakis, Viktor},
  booktitle={2020 31st Irish Signals and Systems Conference (ISSC)}, 
  title={Generative Augmented Dataset and Annotation Frameworks for Artificial Intelligence (GADAFAI)}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={Recent Advances in Artificial Intelligence (AI), particularly in the field of compute vision, have been driven by the availability of large public datasets. However, as AI begins to move into embedded devices there will be a growing need for tools to acquire and re-acquire datasets from specific sensing systems to train new device models. In this paper, a roadmap in introduced for a data-acquisition framework that can build the large synthetic datasets required to train AI systems from small seed datasets. A key element to justify such a framework is the validation of the generated dataset and example results are shown from preliminary work on biometric (facial) datasets.},
  keywords={Training;Cameras;Neural networks;Gallium nitride;Sensors;Machine learning;Generative Models;Data Augmentation;Data Annotation;Synthetic Data},
  doi={10.1109/ISSC49989.2020.9180200},
  ISSN={2688-1454},
  month={June},}@INPROCEEDINGS{10482312,
  author={Ali, Mohd and Ali, Mehboob and Javed, Mohd},
  booktitle={2024 IEEE International Students' Conference on Electrical, Electronics and Computer Science (SCEECS)}, 
  title={DCGAN for Synthetic Data Augmentation of Cervical Cancer for Improved Cervical Cancer Classification}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Medical diagnosis and treatment are greatly aided by biomedical image analysis. Deep learning model training is difficult, nevertheless, due to the scarcity of labelled medical images. For creating synthetic biological images to supplement the training data, Generative Adversarial Networks (GANs) have shown good promise. In this research paper, we focus on the application of GANs for biomedical image augmentation. Specifically, we investigate and compare the performance of a prominent GAN architecture: Deep Convolutional GAN (DCGAN) is a variant of GAN specifically designed for image generation tasks. We assess the generated images based on their quality, diversity, and preservation of biomedical aspects using different evaluation metrics. We also used a classification process to compare the classifier on real and synthetic augmented data. Our test findings show that DCGAN is capable of producing realistic synthetic biomedical images. The results of this work advance knowledge of GANs for biomedical image enhancement and offer guidance on choosing the DCGAN designs for tasks requiring medical image analysis. Researchers and practitioners can increase the diversity and quantity of training data by utilizing GAN-based augmentation strategies, which will enhance the performance and generalization of deep learning models in biomedical applications.The primary objective of this study is to evaluate the effectiveness of DCGAN in generating synthetic microscopic biomedical images of cervical cancer that can augment the training data for deep learning classification models. We aim to assess the quality, diversity, and preservation of biomedical features in the generated images.The structure of this study is as follows: we begin by brief introduction of Cervical cancer, GAN in general and DCGAN. Section 2: lays down review of the related literature. Section 3: presents the methodology of the study. Section 4: presents the results and discussion from the study. Section 5: summaries the finding and concludes with prospective future applications.},
  keywords={Deep learning;Training;Biological system modeling;Training data;Generative adversarial networks;Data models;Task analysis;Generative Adversarial Network;Deep Learning;Convolutional Network;Cervical cancer and Data augmentation},
  doi={10.1109/SCEECS61402.2024.10482312},
  ISSN={2688-0288},
  month={Feb},}@INPROCEEDINGS{10928752,
  author={You, Weijie},
  booktitle={2025 IEEE 5th International Conference on Power, Electronics and Computer Applications (ICPECA)}, 
  title={Research on the Enhanced Target Detection Model of Drone Aerial Images Based on AIGC}, 
  year={2025},
  volume={},
  number={},
  pages={706-710},
  abstract={This paper proposes an image enhancement and target detection model based on AI GC (artificial intelligence generated content). The model innovatively combines GAN and self-attention mechanism, and effectively improves the quality of aerial images through processing steps such as super-resolution, denoising and contrast enhancement. The generator performs image enhancement through a deep convolutional network, and the self-attention mechanism focuses on the key areas in the image to restore more details and textures. Experimental results show that compared with traditional image enhancement methods, the AIGC method shows superior performance in different scenarios. Specifically, after AIGC enhancement processing, the mean average precision (mAP) of target detection is improved by 18.5%, the recall rate is improved by 15.2%, and the F1-score reaches 90.4%. Furthermore, the results show that the proposed model is effective in complicated background and low light environment, and the PSNR and structure similarity (SSIM) are improved by 12 dB and 0.18. It is proved that the AIGC technique can greatly improve the performance of the VA V, and it is an effective way to solve the problem of the complicated scene.},
  keywords={Training;Superresolution;Object detection;Generative adversarial networks;Generators;Robustness;Satellite images;Artificial intelligence;Image enhancement;Drones;AIGC;generative adversarial network;image enhancement;target detection;drone aerial photography;deep learning},
  doi={10.1109/ICPECA63937.2025.10928752},
  ISSN={},
  month={Jan},}@ARTICLE{10700762,
  author={Feng, Qizhang and Du, Mengnan and Zou, Na and Hu, Xia},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Fair Machine Learning in Healthcare: A Survey}, 
  year={2025},
  volume={6},
  number={3},
  pages={493-507},
  abstract={The digitization of healthcare data coupled with advances in computational capabilities has propelled the adoption of machine learning (ML) in healthcare. However, these methods can perpetuate or even exacerbate existing disparities, leading to fairness concerns such as the unequal distribution of resources and diagnostic inaccuracies among different demographic groups. Addressing these fairness problems is paramount to prevent further entrenchment of social injustices. In this survey, we analyze the intersection of fairness in ML and healthcare disparities. We adopt a framework based on the principles of distributive justice to categorize fairness concerns into two distinct classes: equal allocation and equal performance. We provide a critical review of the associated fairness metrics from a ML standpoint and examine biases and mitigation strategies across the stages of the ML lifecycle, discussing the relationship between biases and their countermeasures. The article concludes with a discussion on the pressing challenges that remain unaddressed in ensuring fairness in healthcare ML and proposes several new research directions that hold promise for developing ethical and equitable ML applications in healthcare.},
  keywords={Medical services;Machine learning;Medical diagnostic imaging;Surveys;Measurement;Artificial intelligence;Resource management;Ethics;Biological system modeling;Machine learning algorithms;Artificial intelligence;fairness;healthcare;machine learning (ML)},
  doi={10.1109/TAI.2024.3361836},
  ISSN={2691-4581},
  month={March},}@ARTICLE{10665907,
  author={Cao, Jiahang and Guo, Hanzhong and Wang, Ziqing and Zhou, Deming and Cheng, Hao and Zhang, Qiang and Xu, Renjing},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Spiking Diffusion Models}, 
  year={2025},
  volume={6},
  number={1},
  pages={132-143},
  abstract={Recent years have witnessed spiking neural networks (SNNs) gaining attention for their ultra-low energy consumption and high biological plausibility compared with traditional artificial neural networks (ANNs). Despite their distinguished properties, the application of SNNs in the computationally intensive field of image generation is still under exploration. In this article, we propose the spiking diffusion models (SDMs), an innovative family of SNN-based generative models that excel in producing high-quality samples with significantly reduced energy consumption. In particular, we propose a temporal-wise spiking mechanism (TSM) that allows SNNs to capture more temporal features from a bio-plasticity perspective. In addition, we propose a threshold-guided strategy that can further improve the performances by up to 16.7% without any additional training. We also make the first attempt to use the ANN-SNN approach for SNN-based generation tasks. Extensive experimental results reveal that our approach not only exhibits comparable performance to its ANN counterpart with few spiking time steps, but also outperforms previous SNN-based generative models by a large margin. Moreover, we also demonstrate the high-quality generation ability of SDM on large-scale datasets, e.g., LSUN bedroom. This development marks a pivotal advancement in the capabilities of SNN-based generation, paving the way for future research avenues to realize low-energy and low-latency generative applications.},
  keywords={Training;Diffusion models;Energy consumption;Computational modeling;Brain modeling;Artificial intelligence;Standards;Brain-inspired learning;deep generative models;spiking neural networks (SNNs)},
  doi={10.1109/TAI.2024.3453229},
  ISSN={2691-4581},
  month={Jan},}@ARTICLE{10858159,
  author={Liao, Peng and Wang, Xuyu and Shan, Yingxin and An, Lingling and Mao, Shiwen},
  journal={IEEE Network}, 
  title={Wireless Sensing in Artificial Intelligence of Things: A General Quantum Machine Learning Framework}, 
  year={2025},
  volume={39},
  number={3},
  pages={207-214},
  abstract={With the emergence of the 5G and beyond, wireless networks have transformed from a simple communication medium to ubiquitous versatile platforms. This trend has enabled numerous device-free and non-contact applications. As computing power and machine learning algorithms continue to improve, deep learning techniques are increasingly used in wireless sensing applications. However, the limits of deep learning-centered wireless sensing approaches are still being explored. Concurrently, research in quantum computing is advancing rapidly, prompting researchers to explore the burgeoning field of quantum machine learning, which combines quantum computing and machine learning, for its boundless potential. In this article, we propose a general quantum machine learning framework for wireless sensing applications in the Artificial Internet of Things (AIoT). The proposed framework provides a systematic approach for designing deeply interpreted wireless sensing models based on quantum machine learning. We then present several representative applications and case studies, and conclude this article with a discussion of the challenges and future research directions in this exciting area.},
  keywords={Wireless communication;Wireless sensor networks;Sensors;Quantum computing;Machine learning;Communication system security;Internet of Things;Qubit;Wireless fidelity;Computers;Wireless Sensing;Quantum Machine Learning;Quantum Computing;Artificial Internet of Things},
  doi={10.1109/MNET.2025.3536925},
  ISSN={1558-156X},
  month={May},}@ARTICLE{10781335,
  author={Zhao, Terry and Faruqui, Nuruzzaman},
  journal={IEEE Access}, 
  title={EconoFormer: A Novel Macroeconomic Policy Analysis and Implementation Planner Using Generative Transformer Model}, 
  year={2024},
  volume={12},
  number={},
  pages={184714-184725},
  abstract={Macroeconomic policy analysis and implementation planning are critical for economic growth, increasing employment rates, and ensuring price stability. It has become challenging to keep pace with today’s fast-evolving, technology-driven economy, as policy analysis is a time-consuming process. This paper proposes a Generative Transformer (GT)-based macroeconomic policy analysis and implementation planner model, EconoFormer, designed with 1 billion parameters and trained on 5358 pages of documents related to macroeconomic policies. It achieved a perplexity score of 12.3, which indicates high prediction confidence. The innovative prompt filtering mechanism incorporated with it blocks irrelevant prompts with 98.22% accuracy. The EconoFormer model is scalable and maintains a linear relationship with the processing time and the number of policy analyses while maintaining a stable accuracy, precision, recall, and F1-score. Moreover, the performance remains stable for wide ranges of macroeconomic policies from different sectors. Most importantly, the policy impact rating similarity test shows that it is as good as macroeconomics policy experts in policy analysis. The EconoFormer has the capability to process real-time data in prompts, establish non-linear relations among 44 different economic indicators, and develop effective and plans for policy implementation. The unique concept, robust capability, and outstanding performance make the EconoFormer a potential framework for rapid macroeconomic policy analysis and implementation plan development.},
  keywords={Macroeconomics;Economics;Artificial intelligence;Analytical models;Data models;Real-time systems;Predictive models;Transformers;Stability analysis;Robustness;Transformer model;generative AI;macroeconomic policy;LLM;economic indicators},
  doi={10.1109/ACCESS.2024.3512594},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10716849,
  author={Park, Junhyung and You, Gunsang and Ji, Yeontae and Youm, Heung Youl},
  booktitle={2024 19th Asia Joint Conference on Information Security (AsiaJCIS)}, 
  title={Security Requirements for Fully Automated AI Systems to Exercise and Ensure the Rights of Data Subjects}, 
  year={2024},
  volume={},
  number={},
  pages={107-112},
  abstract={As the commercialization of AI has increased, various services using it are being provided, and it is approaching our lives relatively closely. Humans used the results presented by the AI system to make human decisions. However, systems are also being developed in which artificial intelligence makes all decisions without human decision-making and systems that process personal data within these systems. Various personal information threats can occur in AI systems that process personal information, and each country is making efforts to encourage the safe use of AI by enacting AI guidelines and laws to protect personal information. Recently, in Korea, the Personal Information Protection Act was revised to establish procedures for exercising data subjects' rights regarding fully automated decisions using artificial intelligence. This is to guarantee the rights of data subjects, such as viewing and correction of personal information in the general personal information processing process, as well as the rights of data subjects in fully automated systems that process personal information. Therefore, in this paper, we aim to contribute to ensuring the rights of information subjects by identifying security threats that violate the rights of information subjects in fully automated systems by the AI system stage and analyzing the requirements to mitigate them.},
  keywords={Privacy;Generative AI;Explainable AI;Information security;Information processing;Data models;Security;Artificial intelligence;Protection;Guidelines;Artificial intelligence;Information Security;Privacy;Threat and requirement;Automated system},
  doi={10.1109/AsiaJCIS64263.2024.00026},
  ISSN={2765-9712},
  month={Aug},}@INPROCEEDINGS{8904574,
  author={Rubin, Jonathan and Abulnaga, S. Mazdak},
  booktitle={2019 IEEE International Conference on Healthcare Informatics (ICHI)}, 
  title={CT-To-MR Conditional Generative Adversarial Networks for Ischemic Stroke Lesion Segmentation}, 
  year={2019},
  volume={},
  number={},
  pages={1-7},
  abstract={Infarcted brain tissue resulting from acute stroke readily shows up as hyperintense regions within diffusion-weighted magnetic resonance imaging (DWI). It has also been proposed that computed tomography perfusion (CTP) could alternatively be used to triage stroke patients, given improvements in speed and availability, as well as reduced cost. However, CTP has a lower signal to noise ratio compared to MR. In this work, we investigate whether a conditional mapping can be learned by a generative adversarial network to map CTP inputs to generated MR DWI that more clearly delineates hyperintense regions due to ischemic stroke. We detail the architectures of the generator and discriminator and describe the training process used to perform image-to-image translation from multi-modal CT perfusion maps to diffusion weighted MR outputs. We evaluate the results both qualitatively by visual comparison of generated MR to ground truth, as well as quantitatively by training fully convolutional neural networks that make use of generated MR data inputs to perform ischemic stroke lesion segmentation. Segmentation networks trained using generated CT-to-MR inputs result in at least some improvement on all metrics used for evaluation, compared with networks that only use CT perfusion input.},
  keywords={Training;Image segmentation;Visualization;Translation;Computed tomography;Medical services;Stroke (medical condition);Generative adversarial networks;Lesions;Signal to noise ratio;Conditional adversarial networks;Image-to-Image translation;Ischemic stroke lesion segmentation;CT perfusion},
  doi={10.1109/ICHI.2019.8904574},
  ISSN={2575-2634},
  month={June},}@INPROCEEDINGS{10223662,
  author={Elsayed, Saber},
  booktitle={2023 IEEE Region 10 Symposium (TENSYMP)}, 
  title={Towards Mitigating ChatGPT's Negative Impact on Education: Optimizing Question Design Through Bloom's Taxonomy}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The popularity of generative text AI tools in answering questions has led to concerns regarding their potential negative impact on students' academic performance and the challenges that educators face in evaluating student learning. To address these concerns, this paper introduces an evolutionary approach that aims to identify the best set of Bloom's taxonomy keywords to generate questions that these tools have low confidence in answering. The effectiveness of this approach is evaluated through a case study that uses questions from a Data Structures and Representation course being taught at the University of New South Wales in Canberra, Australia. The results demonstrate that the optimization algorithm can find keywords from different cognitive levels to create questions that ChatGPT has low confidence to answer. This study is a step forward to offer valuable insights for educators seeking to create more effective questions that promote critical thinking among students.},
  keywords={Taxonomy;Chatbots;Data structures;Australia;Artificial intelligence;Optimization;Faces;Evolutionary computation;genetic algorithms;generative text AI tools;ChatGPT;Bloom's taxonomy},
  doi={10.1109/TENSYMP55890.2023.10223662},
  ISSN={2642-6102},
  month={Sep.},}@INPROCEEDINGS{8545383,
  author={Liu, Xiyan and Meng, Gaofeng and Xiang, Shiming and Pan, Chunhong},
  booktitle={2018 24th International Conference on Pattern Recognition (ICPR)}, 
  title={Semantic Image Synthesis via Conditional Cycle-Generative Adversarial Networks}, 
  year={2018},
  volume={},
  number={},
  pages={988-993},
  abstract={Traditional approaches for semantic image synthesis mainly focus on text descriptions while ignoring the related structures and attributes in the original images. Therefore, some critical information, e.g., the style, backgrounds, objects shapes and pose, is missed in the generated images. In this paper, we propose a novel framework called Conditional Cycle-Generative Adversarial Network (CCGAN) to address this issue. Our model can generate photo-realistic images conditioned on the given text descriptions, while maintaining the attributes of the original images. The framework mainly consists of two coupled conditional adversarial networks, which are able to learn a desirable image mapping that can keep the structures and attributes in the images. We introduce a conditional cycle consistency loss to prevent the contradiction between two generators. This loss allows the generated images to retain most of the features of the original image, so as to improve the stability of network training. Moreover, benefiting from the mechanism of circular training, the proposed networks can learn the semantic information of the text much accurately. Experiments on Caltech-UCSD Bird dataset and Oxford-102 flower dataset demonstrate that the proposed method significantly outperforms the existing methods in terms of image details reconstruction and semantic information expression.},
  keywords={Birds;Generators;Generative adversarial networks;Semantics;Gallium nitride;Training;Image generation},
  doi={10.1109/ICPR.2018.8545383},
  ISSN={1051-4651},
  month={Aug},}@INPROCEEDINGS{9871672,
  author={Yang, Yulin and Iwamoto, Yutaro and Chen, Yen-Wei and Xu, Caie and Chen, Qingqing and Hu, Hongjie and Han, Xian-Hua and Tong, Ruofeng and Lin, Lanfen},
  booktitle={2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)}, 
  title={Synthesizing Contrast-enhanced Computed Tomography Images with an Improved Conditional Generative Adversarial Network}, 
  year={2022},
  volume={},
  number={},
  pages={2097-2100},
  abstract={Contrast-enhanced computed tomography (CE-CT) images are used extensively for the diagnosis of liver cancer in clinical practice. Compared with the non-contrast CT (NC-CT) images (CT scans without injection), the CE-CT images are obtained after injecting the contrast, which will increase physical burden of patients. To handle the limitation, we proposed an improved conditional generative adversarial network (improved cGAN) to generate CE-CT images from non-contrast CT images. In the improved cGAN, we incorporate a pyramid pooling module and an elaborate feature fusion module to the generator to improve the capability of encoder in capturing multi-scale semantic features and prevent the dilution of information in the process of decoding. We evaluate the performance of our proposed method on a contrast-enhanced CT dataset including three phases of CT images, (i.e., non-contrast image, CE-CT images in arterial and portal venous phases). Experimental results suggest that the proposed method is superior to existing GAN-based models in quantitative and qualitative results.},
  keywords={Computed tomography;Computational modeling;Biological system modeling;Semantics;Liver;Generative adversarial networks;Generators},
  doi={10.1109/EMBC48229.2022.9871672},
  ISSN={2694-0604},
  month={July},}@INBOOK{10952740,
  author={Garg, Pallavi Sharda and Sharma, Samarth and Singh, Archana and Kumar, Nitendra},
  booktitle={Mathematical Models Using Artificial Intelligence for Surveillance Systems}, 
  title={AI&#x2010;Based Surveillance Systems for Effective Attendance Management}, 
  year={2024},
  volume={},
  number={},
  pages={69-89},
  abstract={Summary <p>The traditional system of attendance requires maintaining an attendance register and manually noting the attendance of every student. This system is prone to errors and marking of proxy attendance. The solution lies in use of deep learning technologies to automate the process. These techniques use face recognition and identification to instantly identify people. They are used extensively in real&#x2010;time security surveillance systems. These techniques are also being applied in Automatic Attendance Management (AAM) at various institutions.</p> <p>This chapter is divided into nine sections. The first section discusses the importance of managing student attendance and the problems associated with traditional attendance management systems. This is followed by a discussion of Artificial Intelligence (AI) and Smart Surveillance, and Artificial Intelligence (AI) and Attendance Management. The next section is an overview of various image processing technologies in Automatic Attendance Management, and after that the discussion delves into deep Learning and Various Neural Network Techniques for Attendance Management. Further sections discuss the role of AI Technologies in Attendance Management, the challenges and opportunities for the deep learning technique&#x2010;based face recognition techniques. Finally, there is a discussion and conclusion.</p>},
  keywords={Face recognition;Surveillance;Artificial intelligence;Security;Face detection;Radiofrequency identification;Deep learning;Real-time systems;Feature extraction;Mathematical models},
  doi={10.1002/9781394200733.ch4},
  ISSN={},
  publisher={Wiley},
  isbn={9781394200726},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952740},}@INBOOK{10880530,
  author={Diwakar, Diwakar and Raj, Deepa},
  booktitle={Generative Artificial Intelligence for Biomedical and Smart Health Informatics}, 
  title={Generative AI in Wearables: Exploring the Impact of GANs, VAEs, and Transformers*}, 
  year={2025},
  volume={},
  number={},
  pages={1-34},
  abstract={Summary <p>This research article investigates the transformative potential of integrating generative artificial intelligence (GenAI) with wearable technology, a synergy poised to revolutionize personal computing and healthcare. It delves into the theoretical underpinnings of GenAI, including cutting&#x2010;edge models like Generative Adversarial Networks and Variational Autoencoders, and the advancements in wearable technology that enables real&#x2010;time health monitoring and personalized user experiences. Despite the promising opportunities such as enhanced healthcare solutions, predictive monitoring, and user engagement, the article also addresses significant challenges including data privacy, computational limitations, and ethical considerations. Furthermore, it explores the future directions of this integration, emphasizing the need for innovative solutions to overcome technical hurdles and ethical dilemmas. The conclusion posits a future where wearable technology and GenAI work in harmony to not only improve health outcomes but also enrich the human experience, highlighting the importance of a multidisciplinary approach to navigate the complexities of this evolving field.</p>},
  keywords={Biomedical monitoring;Transformers;Artificial intelligence;Data models;Temperature measurement;Wearable Health Monitoring Systems;Training;Temperature sensors;Sensor arrays;Optical variables measurement},
  doi={10.1002/9781394280735.ch1},
  ISSN={},
  publisher={IEEE},
  isbn={9781394280728},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10880530},}@INPROCEEDINGS{11035339,
  author={Sarasan, Ashish P and M, Anuvind and S, Sreelekshmi},
  booktitle={2025 5th International Conference on Pervasive Computing and Social Networking (ICPCSN)}, 
  title={Explainable Generative AI: Enhancing Stable Diffusion with Machine Learning and Generative AI}, 
  year={2025},
  volume={},
  number={},
  pages={571-577},
  abstract={Explainable AI (XAI) increases the transparency of AI, it is a set of techniques that help us how machine learning algorithm make decisions however issues persist, particularly in understanding image generation tasks. Numerical interpretability is the major issue that makes it challenging for models to understand numerical values in prompts to recognize the number of subjects for image generation using diffusion models. In this study, prompt engineering using Generative AI and SHAP-based (Shapley Additive Explanations) explainability are used to enhance the prompt and understand the features that contribute to the generated image. The Gemini API prompts refined model responses and increases numerical interpretability because generative AI can reduce human errors and enhance image features through structured prompts. Prompt engineering techniques are used to guide Artificial Intelligence models to produce desired output, techniques such as dynamic prompting expands the prompt and improve the numerical interpretability and clarity of the actual input.Synthetic images were tested for distortion using Peak Signal-to-Noise Ratio (PSNR: 9.11 dB) and our model is 20% better than the existing model and the Learned Perceptual Image Patch Similarity (LPIPS: 0.69) for 69% dissimilarity between the generated images of our extensible diffusion model model and the existing stable diffusion model, the Structural Similarity Index Measure (SSIM: 24%) for structural consistency and the Con trastive Language-Image Pre-training (CLIP) Score for semantic alignment between text and image. The results indicated reduced noise, better prompt alignment, and greater transparency. By combining structured prompting, explainability, and quantitative testing, this method improves generative model control, ensuring efficiency, interpretability, and better image quality for real-world applications.},
  keywords={Image quality;Training;PSNR;Additives;Explainable AI;Image synthesis;Diffusion models;Numerical models;Prompt engineering;Indexes;SHAP (Shapley Additive Explanations);CLIP (Contrastive Language-Image Pre- training);PSNR (Peak Signal-to-Noise Ratio);SSIM (Structural Similarity Index Measure);XAI (Explainable Artificial Intelligence);LPIPS (Learned Perceptual Image Patch Similarity);GEN AI (Generative Artificial Intelligence)},
  doi={10.1109/ICPCSN65854.2025.11035339},
  ISSN={},
  month={May},}@INBOOK{10880623,
  author={Singh, Sudhanshu and Singh, Suruchi and Raghuvanshi, C.S.},
  booktitle={Generative Artificial Intelligence for Biomedical and Smart Health Informatics}, 
  title={Generating Synthetic Medical Data Using GAI}, 
  year={2025},
  volume={},
  number={},
  pages={51-71},
  abstract={Summary <p>The scene of clinical examination is going through a change in outlook, filled by the extraordinary force of Generative Computerized reasoning (GAI). This part dives into the interesting domain of Producing Manufactured Clinical Information utilizing GAI, investigating reforming healthcare enormous potential. We set out on an excursion directed by the four mainstays of imagination, decisive reasoning, cooperation, and correspondence.</p> <p>Creativity ignites our exploration, as we envision a kaleidoscope of possibilities. From crafting realistic patient populations to simulating intricate disease progressions, GAI paints a vibrant canvas of synthetic data, unconstrained by the limitations of real&#x2010;world cohorts.</p> <p>Decisive reasoning fills in as our compass, guaranteeing we explore this early field with reasonability. We dig into the moral contemplations, possible predispositions, and generalizability challenges intrinsic in manufactured information age. By fundamentally assessing these angles, we prepare for mindful and effective applications. Joint effort turns into the extension that associates assorted points of view. We investigate the collaboration between clinical experts, information researchers, and simulated intelligence trained professionals, underscoring the force of interdisciplinary groups in saddling the maximum capacity of GAI for clinical information age. Correspondence shapes the extension between the specialized complexities and the more extensive clinical local area. We endeavor to introduce complex ideas in an open and drawing in way, cultivating an exchange that engages specialists, clinicians, and general society to comprehend and use the extraordinary force of manufactured clinical information. This section isn't only a specialized piece; it is a solicitation to an ensemble of innovativeness, decisive reasoning, joint effort, and correspondence. Together, we can open the tremendous capability of GAI in creating manufactured clinical information, pushing medical care towards a future overflowing with conceivable outcomes. <ul> <li>Crafted with Creativity Imagine a world where AI conjures realistic patient cohorts, mirroring the intricate tapestry of human health and disease. We'll investigate GAI's kaleidoscope of strategies, from Contingent Generative Ill&#x2010;disposed Organizations (cGANs) that paint clear pictures of clinical imaging to Variational Autoencoders (VAEs) that murmur the mysteries concealed inside hereditary information. We should release our creative mind and investigate the unfamiliar regions of engineered information age, where illness displaying and drug revelation waltz connected at the hip.</li> <li>Fueled by Critical Thinking But venturing into the synthetic realm demands a discerning eye. We'll fastidiously take apart the moral contemplations and expected traps of GAI&#x2010;produced information, guaranteeing it fills in as a dependable reflection, not a mutilated mirror, of human wellbeing. We'll consider the fragile dance between information constancy and security, and investigate strategies to relieve inclination and guarantee the mindful utilization of this incredible asset.</li> <li>Rooted in Collaboration This journey is not meant to be traversed alone. We'll praise the soul of coordinated effort, cultivating associations between specialists, clinicians, and simulated intelligence specialists. Envision interdisciplinary groups, where clinical aptitude guides artificial intelligence advancement, and man&#x2010;made intelligence bits of knowledge enlighten clinical practice. We'll investigate open&#x2010;source stages and information sharing drives, building spans that prepare for aggregate advancement.</li> <li>Articulated with Clarity Our narrative unfolds with clear, concise language, accessible to a diverse audience. We'll make an interpretation of perplexing specialized ideas into absorbable exposition, guaranteeing that the groundbreaking capability of GAI resounds with everybody, from prepared scientists to inquisitive understudies.</li> <li>Creative Ideas for the Chapter Patient Avatar Generation: Describe a GAI system that creates personalized patient avatars, complete with medical histories, genetic profiles, and virtual responses to treatment interventions. Disease Progression Simulation: Showcase a GAI model that simulates the real&#x2010;time progression of complex diseases, enabling researchers to test treatment strategies in a virtual environment. Drug Discovery Acceleration: Explore how GAI&#x2010;generated synthetic data can be used to virtually screen millions of potential drug candidates, significantly accelerating the drug discovery process. Personalized Medicine Advancements: Discuss how synthetic data can be used to tailor treatment plans to individual patients, ushering in a new era of personalized medicine. Ethical Considerations and Societal Impact: Dedicate a section to the ethical considerations and potential societal impacts of GAI&#x2010;generated medical data, fostering responsible and inclusive applications.</li> </ul> </p>},
  keywords={Biomedical imaging;Diseases;Data privacy;Autoencoders;Artificial intelligence;Paints;Genetics;Generators;Ethics;Wrist},
  doi={10.1002/9781394280735.ch3},
  ISSN={},
  publisher={IEEE},
  isbn={9781394280728},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10880623},}@INPROCEEDINGS{10942135,
  author={Diallo, Elhadj Moustapha and Liao, Yancheng and Kakati, Amayika and Jain, Deepak Kumar},
  booktitle={2024 10th International Conference on Computer and Communications (ICCC)}, 
  title={Generative Model for Joint Resource Management in Multi-Cell Multi-Carrier NOMA Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1596-1600},
  abstract={In this work, we design a generative artificial intelligence(GAI) -based framework for joint resource allocation, beamforming, and power allocation in multi-cell multi-carrier non-orthogonal multiple access (NOMA) networks. We formulate the proposed problem as sum rate maximization problem. Next, we design a novel multi-task transformer (MTT) framework to handle the problem in real-time. To provide the necessary training set, we consider simplified but powerful mathematical techniques from the literature. Then, we train and test the proposed MTT. We perform simulation to evaluate the efficiency of the proposed MTT and compare its performance with the mathematical baseline.},
  keywords={Training;NOMA;Array signal processing;Processor scheduling;Generative AI;Transformers;Multitasking;Real-time systems;Mathematical models;Resource management;Generative AI;multi-Cell multi-Carrier;non-orthogonal multiple access (NOMA);user scheduling;beamforming;power allocation;sum rate maximization},
  doi={10.1109/ICCC62609.2024.10942135},
  ISSN={2837-7109},
  month={Dec},}@INPROCEEDINGS{10329840,
  author={Nikita, Fedosov and Voskoboynikov, Alexey},
  booktitle={2023 IEEE Ural-Siberian Conference on Computational Technologies in Cognitive Science, Genomics and Biomedicine (CSGB)}, 
  title={Deep Active Inference Agent with Continuous Action Space}, 
  year={2023},
  volume={},
  number={},
  pages={215-220},
  abstract={Active inference is a promising and unifying framework for the intelligent agent behavior formal description, with ongoing intensive research of the means for sophisticated model implementations which would be able to challenge complex realistic environments. In this paper we introduce a previously used deep learning-based active inference model with a few adaptations into the action-perception architecture and propose our new generative adversarial network (GAN) -based approach to optimally sample from the continuous action space unlike from discrete one as it was done in most of related works. We show that the proposed model is able to learn and solve a simple but realistic environment, optimize its effect on the world in accordance with its own preferences, exhibiting the exploration behavior at the same time. We hope our work will help to make active inference agent design principles more flexible and generalizable.},
  keywords={Adaptation models;Genomics;Computer architecture;Generative adversarial networks;Behavioral sciences;Cognitive science;Intelligent agents;Active Inference;Reinforcement Learning},
  doi={10.1109/CSGB60362.2023.10329840},
  ISSN={},
  month={Sep.},}@ARTICLE{9241509,
  author={Evans, James},
  journal={Journal of Social Computing}, 
  title={Social Computing Unhinged}, 
  year={2020},
  volume={1},
  number={1},
  pages={1-13},
  abstract={Social computing is ubiquitous and intensifying in the 21st Century. Originally used to reference computational augmentation of social interaction through collaborative filtering, social media, wikis, and crowdsourcing, here I propose to expand the concept to cover the complete dynamic interface between social interaction and computation, including computationally enhanced sociality and social science, socially enhanced computing and computer science, and their increasingly complex combination for mutual enhancement. This recommends that we reimagine Computational Social Science as Social Computing, not merely using computational tools to make sense of the contemporary explosion of social data, but also recognizing societies as emergent computers of more or less collective intelligence, innovation and flourishing. It further proposes we imagine a socially inspired computer science that takes these insights into account as we build machines not merely to substitute for human cognition, but radically complement it. This leads to a vision of social computing as an extreme form of human computer interaction, whereby machines and persons recursively combine to augment one another in generating collective intelligence, enhanced knowledge, and other social goods unattainable without each other. Using the example of science and technology, I illustrate how progress in each of these areas unleash advances in the others and the beneficial relationship between the technology and science of social computing, which reveals limits of sociality and computation, and stimulates our imagination about how they can reach past those limits together.},
  keywords={Social computing;Cognition;Collaboration;Social networking (online);Artificial intelligence;Encyclopedias;social computing;complex systems;computer supported cooperative work;computational social science;artificial intelligence;human computer interaction;human-centered computing},
  doi={10.23919/JSC.2020.0002},
  ISSN={2688-5255},
  month={Sep.},}@ARTICLE{9174748,
  author={Liu, Caixia and Kong, Dehui and Wang, Shaofan and Li, Jinghua and Yin, Baocai},
  journal={IEEE Transactions on Multimedia}, 
  title={DLGAN: Depth-Preserving Latent Generative Adversarial Network for 3D Reconstruction}, 
  year={2021},
  volume={23},
  number={},
  pages={2843-2856},
  abstract={Although deep networks based methods outperform traditional 3D reconstruction methods which require multiocular images or class labels to recover the full 3D geometry, they may produce incomplete recovery and unfaithful reconstruction when facing occluded parts of 3D objects. To address these issues, we propose Depth-preserving Latent Generative Adversarial Network (DLGAN) which consists of 3D Encoder-Decoder based GAN (EDGAN, serving as a generator and a discriminator) and Extreme Learning Machine (ELM, serving as a classifier) for 3D reconstruction from a monocular depth image of an object. Firstly, EDGAN decodes a latent vector from the 2.5D voxel grid representation of an input image, and generates the initial 3D occupancy grid under common GAN losses, a latent vector loss and a depth loss. For the latent vector loss, we design 3D deep AutoEncoder (AE) to learn a target latent vector from ground truth 3D voxel grid and utilize the vector to penalize the latent vector encoded from the input 2.5D data. For the depth loss, we utilize the input 2.5D data to penalize the initial 3D voxel grid from 2.5D views. Afterwards, ELM transforms float values of the initial 3D voxel grid to binary values under a binary reconstruction loss. Experimental results show that DLGAN not only outperforms several state-of-the-art methods by a large margin on both a synthetic dataset and a real-world dataset, but also predicts more occluded parts of 3D objects accurately without class labels.},
  keywords={Three-dimensional displays;Image reconstruction;Shape;Gallium nitride;Generative adversarial networks;Two dimensional displays;Transforms;3D reconstruction;depth loss;ELM;latent vector;monocular depth image},
  doi={10.1109/TMM.2020.3017924},
  ISSN={1941-0077},
  month={},}@ARTICLE{11121171,
  author={Panagoulias, Dimitrios P. and Tsichrintzi, Evangelia-Aikaterini and Sotiropoulos, Dionisios N. and Chrysafiadi, Konstantina and Sakkopoulos, Evangelos and Tsihrintzis, George A. and Virvou, Maria},
  journal={IEEE Access}, 
  title={LYRICEL: Knowledge Graphs Combined With Large Language Models and Machine Learning for Cross-Cultural Analysis of Lyrics—The Case of Greek Songs}, 
  year={2025},
  volume={13},
  number={},
  pages={141985-142006},
  abstract={This paper presents LYRICEL, a framework integrating Knowledge Graph (KG) representation learning, Large Language Models (LLMs), and machine learning for reliable, explainable, and validatable cross-cultural lyric analysis. The core component, Sequential Language Model Integration (SLMI), enhances the interpretability and reliability of transformer-based LLMs by addressing explainability and validation challenges through Retrieval-Augmented Generation (RAG), hybrid search, and rule-based evaluation. An important feature of LYRICEL is its use of KG visualizations, which serve as dynamic links to improve interpretability and validatability by structuring data relationships and sources. These visualizations are central to advancements in four areas: KG representation learning, knowledge acquisition, temporal KGs, and knowledge-aware applications. Tested on Greek folk music with models like GPT-4o and BERT, LYRICEL’s trustworthiness is assessed using the VIRTSI model, which quantifies cognitive trust in human-computer interactions. The framework shows strong potential for cross-cultural applications, particularly in languages such as Modern Greek which encompasses a rich cultural heritage spanning centuries of history and traditions resulting in a complex study. The outcomes of GPT-enabled LYRICEL are compared to ChatGPT alone and show a significant improvement in the reliability and efficiency of interactions that can reach a global audience, enhancing the accessibility and understanding of diverse cultural heritages.},
  keywords={Artificial intelligence;Cultural differences;Knowledge graphs;Reliability;Semantics;Chatbots;Accuracy;Integrated circuit modeling;Education;Transformers;ChatGPT;LLMs;e-learning;machine learning;artificial intelligence;cultural heritage;AI-based poem analysis;generative AI;intelligent tutoring systems;natural language processing;educational software;knowledge graphs},
  doi={10.1109/ACCESS.2025.3597213},
  ISSN={2169-3536},
  month={},}
