@INPROCEEDINGS{10854312,
  author={Zhang, Qichen},
  booktitle={6th International Conference on Artificial Intelligence and Advanced Manufacturing (AIAM 2024)}, 
  title={Network traffic classification method based on attention-CNN-BiLSTM}, 
  year={2024},
  volume={2024},
  number={},
  pages={735-742},
  abstract={With the wide application of artificial intelligence, cloud computing and Internet of things, we have entered a new era of intelligent interconnection. However, network security threats and risks are also increasing. At present, it is urgent to solve how to effectively combat network attacks and ensure network security. Network traffic analysis plays a key role in intrusion detection. By accurately classifying network traffic, network intrusion can be more targeted. However, due to the imbalance of categories in the data samples, the recognition accuracy of minority classes is low. In order to cope with this challenge, an improved network traffic analysis method based on Attention-CNN-Bi LSTM is proposed. This method first balances the data set, then uses the feature selection strategy to eliminate unnecessary features, and uses the combined neural network model for training. The experimental simulation of this method shows that the AUC value of the minority class exceeds 0.85 on both data sets, which shows that the method has good generalization performance for the minority class and solves the problem of low accuracy of the minority class in the unbalanced data set.},
  keywords={},
  doi={10.1049/icp.2024.4308},
  ISSN={},
  month={Oct},}@ARTICLE{9517097,
  author={Batool, Uzma and Shapiai, Mohd Ibrahim and Tahir, Muhammad and Ismail, Zool Hilmi and Zakaria, Noor Jannah and Elfakharany, Ahmed},
  journal={IEEE Access}, 
  title={A Systematic Review of Deep Learning for Silicon Wafer Defect Recognition}, 
  year={2021},
  volume={9},
  number={},
  pages={116572-116593},
  abstract={Advancements in technology have made deep learning a hot research area, and we see its applications in various fields. Its widespread use in silicon wafer defect recognition is replacing traditional machine learning and image processing methods of defect monitoring. This article presents a review of the deep learning methods employed for wafer map defect recognition. A systematic literature review (SLR) has been conducted to determine how the semiconductor industry is leveraged by deep learning research advancements for wafer defects recognition and analysis. Forty-four articles from well-known databases have been selected for this review. The articles’ detailed study identified the prominent deep learning algorithms and network architectures for wafer map defect classification, clustering, feature extraction, and data synthesis. The identified learning algorithms are grouped as supervised learning, unsupervised learning, and hybrid learning. The network architectures include different forms of Convolutional Neural Network (CNN), Generative Adversarial Network (GAN), and Auto-encoder (AE). Various issues of multi-class and multi-label defects have been addressed, solving data unavailability, class imbalance, instance labeling, and unknown defects. For future directions, it is recommended to invest more efforts in the accuracy of the data generation procedures and the defect pattern recognition frameworks for defect monitoring in real industrial environments.},
  keywords={Deep learning;Systematics;Fabrication;Monitoring;Databases;Silicon;Integrated circuits;Wafer map defects;wafer bin map;defect recognition;deep learning;systematic literature review},
  doi={10.1109/ACCESS.2021.3106171},
  ISSN={2169-3536},
  month={},}@ARTICLE{10605849,
  author={Xiang, Xuanyu and Tan, Yihua and Yan, Longfei},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Cloud-Guided Fusion With SAR-to-Optical Translation for Thick Cloud Removal}, 
  year={2024},
  volume={62},
  number={},
  pages={1-15},
  abstract={Deep learning has been widely used in thick cloud removal (TCR) for optical satellite images. Since thick clouds completely block the surface, synthetic aperture radar (SAR) images have recently been used to assist in the recovery of occluded information. However, this approach faces several challenges: 1) the significant domain gap between SAR and optical features can cause interference in recovering occluded optical information from SAR and 2) the TCR methods need to distinguish between cloudy and non-cloudy regions; otherwise, inconsistencies may arise between the recovered regions and the remaining non-cloudy regions. To this end, we propose a new SAR-assisted TCR method based on a two-step fusion framework, which consists of the feature alignment translation (FAT) network and the cloud-guided fusion (CGF) network. First, the FAT leverages the common features between SAR and optical images to translate SAR images into corresponding optical images, thus recovering the occluded information. Considering the gap between the translated images and the real cloud-free images, the CGF utilizes cloudy images to further refine the translated images, resulting in the cloud-removed images. In the CGF, cloud distribution is predicted to distinguish between cloudy and non-cloudy regions. Then, the cloud distribution is used to guide the refinement of recovered regions using non-cloudy regions. Extensive experiments on both simulated and real datasets show that the proposed algorithm achieves better performance compared with the state-of-the-art methods.},
  keywords={Clouds;Cloud computing;Optical imaging;Radar polarimetry;Fats;Optical sensors;Feature extraction;Cloud removal;data fusion;deep learning;generative adversarial network (GAN);synthetic aperture radar (SAR)-to-optical translation},
  doi={10.1109/TGRS.2024.3431556},
  ISSN={1558-0644},
  month={},}@ARTICLE{10587314,
  author={Yu, Qianzi and Zhu, Kai and Cao, Yang and Xia, Feijie and Kang, Yu},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={TF²: Few-Shot Text-Free Training-Free Defect Image Generation for Industrial Anomaly Inspection}, 
  year={2024},
  volume={34},
  number={11},
  pages={11825-11837},
  abstract={Anomaly inspection aims at identifying various defects in real time on modern industrial production lines. However, due to insufficient anomaly data, existing detectors cannot effectively accomplish the classification of defects, thereby failing to provide guidance for subsequent production. To address it, we propose TF2, a few-shot text-free training-free defect image generation method, which jointly models the image distribution of class-agnostic defects and backgrounds, achieving efficient semantic enhancement. Firstly, we propose the Response Alignment Strategy, which merges the reversed latent space of both defect-free and defective samples, generating new defect images not limited to textual descriptions yet with consistent content. Moreover, we introduce the Defect Moving Strategy and the Regional Average Loss to merge the reversed latent space of the moving areas and enhance the variability of detail features, increasing both the location and content diversity of defects. Extensive experiments demonstrate the superiority of our model over the state-of-the-art competitors. The metrics indicate that our generated anomaly data focuses on balancing both image quality and diversity, effectively improving the performance of downstream anomaly inspection tasks.},
  keywords={Inspection;Diffusion models;Feature extraction;Image synthesis;Electronic mail;Task analysis;Production;Anomaly generation;diffusion model;generative model;defect classification;anomaly inspection},
  doi={10.1109/TCSVT.2024.3424435},
  ISSN={1558-2205},
  month={Nov},}@INPROCEEDINGS{10169621,
  author={Duan, Xinran and Jiang, Chaoyong and Fan, Yachun},
  booktitle={2023 9th International Conference on Virtual Reality (ICVR)}, 
  title={Enhanced Inpainting Model Revitalizes Historical Paintings with Vision Transformer}, 
  year={2023},
  volume={},
  number={},
  pages={582-589},
  abstract={This paper presents a deep learning architecture for restoring ancient paintings, which have immense historical and artistic value as they vividly record history from diverse perspectives. Due to the passage of time, many historical works have suffered damage, which requires time-consuming manual restoration by skilled professionals. Our proposed method utilizes a sophisticated edge detection model to extract structure information from the paintings, including texture, painting style, and structure, which are applied for restoration. The effectiveness of the proposed method was validated by training and testing on various ancient painting datasets. This work has significant value in that it can expedite and enhance the accuracy of the restoration process without compromising the original artistic style and intent, thereby better preserving and transmitting our historical culture. We believe that the contribution of this work is meaningful for VR cultural heritage conservation and presentation.},
  keywords={Training;Solid modeling;Computational modeling;Image edge detection;Virtual reality;Transformers;Data models;image inpainting;ancient paintings;generative adversarial network;transformer},
  doi={10.1109/ICVR57957.2023.10169621},
  ISSN={2331-9569},
  month={May},}@ARTICLE{10433498,
  author={Jamil, Azhar and Saif-Ur-Rehman and Mahmood, Khalid and Villar, Monica Gracia and Prola, Thomas and Diez, Isabel De La Torre and Samad, Md Abdus and Ashraf, Imran},
  journal={IEEE Access}, 
  title={Deep Learning Approaches for Image Captioning: Opportunities, Challenges and Future Potential}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={Generative intelligence relies heavily on the integration of vision and language. Much of the research has focused on image captioning, which involves describing images with meaningful sentences. Typically, when generating sentences that describe the visual content, a language model and a vision encoder are commonly employed. Because of the incorporation of object areas, properties, multi-modal connections, attentive techniques, and early fusion approaches like bidirectional encoder representations from transformers (BERT), these components have experienced substantial advancements over the years. This research offers a reference to the body of literature, identifies emerging trends in an area that blends computer vision as well as natural language processing in order to maximize their complementary effects, and identifies the most significant technological improvements in architectures employed for image captioning. It also discusses various problem variants and open challenges. This comparison allows for an objective assessment of different techniques, architectures, and training strategies by identifying the most significant technical innovations, and offers valuable insights into the current landscape of image captioning research.},
  keywords={Visualization;Feature extraction;Convolutional neural networks;Context modeling;Task analysis;Surveys;Computational modeling;Deep learning;Artificial intelligence;Natural language processing;Image processing;Image capture;Image captioning;deep learning;image processing;artificial intelligence},
  doi={10.1109/ACCESS.2024.3365528},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10012991,
  author={Zhao, Longhai and Xiong, Qi and Yang, Yunchuan and Li, Pengru and Yu, Bin and Sun, Feifei and Sun, Chengjun and Xue, Peng},
  booktitle={2022 IEEE 96th Vehicular Technology Conference (VTC2022-Fall)}, 
  title={Enabling Accurate Positioning in NLOS Scenarios by Hybrid Machine Learning with Denoising and Inpainting}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={Positioning for non-line-of-sight (NLOS) scenarios is a long-live challenging task, since the conventional approaches for positioning are mostly LOS-dependent, and perform poorly in NLOS scenarios. Thanks to the powerful computing and learning abilities of artificial intelligence (AI), the present study on machine learning (ML) based approaches shows promising potential to conquer the challenge in theory. Nonetheless, one critical aspect for using AI model is the generalizing ability, which tells the inference level in practice. This problem is more vital for ML based positioning, since the channel information (CI) for actual usage may not be aligned with that for training. One typical case is the noisy or incomplete CI, which may degrade the inference performance and even leads the trained model unusable. In this paper, a novel hybrid machine learning (HML) approach is introduced by exploiting both supervised and unsupervised learning models developed with denoising and inpainting abilities to enable accurate positioning in NLOS scenarios. The simulation shows the proposed approach can have 10 times higher accuracy than conventional approaches.},
  keywords={Training;Vehicular and wireless technologies;Noise reduction;Supervised learning;Machine learning;Learning (artificial intelligence);Noise measurement;Positioning;NLOS;Machine learning;Diffusion generative models},
  doi={10.1109/VTC2022-Fall57202.2022.10012991},
  ISSN={2577-2465},
  month={Sep.},}@ARTICLE{11018396,
  author={Nguyen, Van-Linh and Nguyen, Lan-Huong and Hwang, Ren-Hung and Canberk, Berk and Duong, Trung Q.},
  journal={IEEE Communications Standards Magazine}, 
  title={Quantum Machine Learning for 6G Network Intelligence and Adversarial Threats}, 
  year={2025},
  volume={9},
  number={3},
  pages={40-48},
  abstract={Quantum computing has been a major priority for several nations and prominent institutions in their pursuit of a transformative breakthrough in the fields of computation and encryption. By using the principles of quantum mechanics, particularly quantum superposition and entanglement, quantum computing and quantum machine learning (QML) have the potential to enhance artificial intelligence (AI) and achieve quantum supremacy with unprecedented computational power. However, despite its exceptional learning capabilities, QML-based applications face several emerging security threats. Unlike previous studies focused on classical quantum cryptography and secure quantum communications, this work investigates adversarial risks in QML-assisted network functions and digital twin applications. Specifically, we highlight vulnerabilities such as quantum kernel poisoning, backdoor attacks, and adversarial noise. Key findings reveal that adversaries can intercept quantum states in transit, manipulate parameterized quantum circuits (PQCs), and exploit variational quantum algorithms (VQAs) through adversarial qubit perturbations. These attacks can mislead QML-based optimization processes, leading to incorrect digital twin predictions, faulty resource allocation, or disruptions in QML-aided network functions. To mitigate these risks, defense strategies such as quantum-safe cryptography, data sanitization, adversarial training, defensive distillation, and gradient masking in quantum circuit design can be employed. However, the key issue is the absence of robust security solutions for real-world deployment. Future research should examine the trade-off between adversarial robustness and generative learning performance. Key areas include quantum state discrimination, secure quantum federated learning, quantum decoherence control, and secure quantum semantic communications for real-world deployment.},
  keywords={Quantum computing;6G mobile communication;Qubit;Optimization;Security;Quantum state;Integrated circuit modeling;Computational modeling;Training;Quantum entanglement;Quantum machine learning;quantum circuits;quantum kernel poisoning;quantum adversarial attacks;adversarial defense;6G quantum networks;semantic communications},
  doi={10.1109/MCOMSTD.2025.3575261},
  ISSN={2471-2833},
  month={Sep.},}@INPROCEEDINGS{11140209,
  author={Khaire, Sneha Arjun and Monica, C. L. and Parasar, Anuradha and Praveen, RVS and Kalinskaya, Ekaterina and B, Dineshkumar},
  booktitle={2025 6th International Conference for Emerging Technology (INCET)}, 
  title={Enhancing Automated Assignment Assessment in Higher Education with a CNN–BiLSTM Model}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Educational technology theories have lagged behind the rapid development of relevant technologies. Due to advancements in information and communication technologies, college students can now reach audiences beyond their professors. Assignments are now being graded based on podcasts, infographics, blog posts, and social media marketing. In addition to improving their theoretical and practical abilities, students are able to reach a wider audience with the use of these instruments. Improved assignment evaluation was achieved by a multi-stage prediction model utilising CNN and BILSTM. Latent Dirichlet Allocation was used for feature extraction after data was prepped by removing duplicate and incomplete information. To examine school records, the CNN-BILSTM model applies geographic information gleaned from traffic records. With a Recall of 95.56% and an F-Measure of 99.49%, the model performed admirably while evaluating assignments. A more precise assessment of assignments may be possible with the use of sophisticated DL techniques, according to these results. The necessity for ongoing technological advancement in educational assessment is emphasised by the fact that ICT-based communication tools enhance students' engagement with real-world audiences.},
  keywords={Social networking (online);Generative AI;Soft sensors;Instruments;Bidirectional long short term memory;Predictive models;Feature extraction;Cleaning;Information and communication technology;Resource management;Information Communication Technology (ICT);Assessment Higher Education (AHE);Latent Dirichlet Allocation (LDA);Generative Artificial Intelligence (GAI);Two-Phase Concept Map Construction (TP-CMC)},
  doi={10.1109/INCET64471.2025.11140209},
  ISSN={2996-4490},
  month={May},}@INPROCEEDINGS{11016531,
  author={Grey, Stuart},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Enhancing Ethical Reasoning in Engineering Education through Student-Created Interactive Ethical Scenarios Using Generative AI}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={In modern engineering education, integrating ethical reasoning into technical curricula is increasingly vital due to the complex societal issues engineers face. Traditional pedagogies-relying on static case studies and theoretical discussions-often fall short in preparing students for the dynamic nature of real-world ethical challenges. This study introduces an innovative approach that engages engineering students in creating and debugging interactive ethical scenarios using generative AI, particularly Large Language Models (LLMs). Leveraging LLMs' natural language processing capabilities, students generate evolving scenarios that respond to their inputs, fostering a learning environment that mirrors the complexities of the real-world. Grounded in the constructivist paradigm and employing a qualitative methodology, the research involves semi-structured interviews and surveys of engineering students participating in this immersive assessment approach. Analysis of the collected data aims to understand the impact on students' ethical comprehension, reasoning processes, and engagement with ethical dilemmas. By positioning students as active participants in constructing ethical scenarios, the method enhances their ethical reasoning skills and acquaints them with emerging AI technologies integral to modern engineering. Aligned with the Accreditation of Higher Education Programs (AHEP4) framework-which emphasises competencies in addressing ethical issues and complex problems-this study addresses gaps in the current literature concerning innovative, student-centred approaches in engineering ethics education. Findings suggest that active involvement in scenario creation, facilitated by LLMs, leads to a deeper understanding and practical application of ethical principles. The research contributes to advancing ethics education in engineering by demonstrating how technology can create a more dynamic and immersive learning experience. It underscores the potential of LLMs to revolutionise ethics education, aligning pedagogical practices with the evolving demands of the engineering profession in a technology-driven society.},
  keywords={Surveys;Ethics;Decision making;Debugging;Cognition;Natural language processing;Stakeholders;Prompt engineering;Mirrors;Engineering students;ethics;artificial intelligence;assessment},
  doi={10.1109/EDUCON62633.2025.11016531},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11141112,
  author={Lau, Michael},
  booktitle={2025 IEEE 4th International Conference on Computing and Machine Intelligence (ICMI)}, 
  title={AI-Driven Innovations in Predicting Respiratory Diseases: Review of Progress and Applications}, 
  year={2025},
  volume={},
  number={},
  pages={01-07},
  abstract={Chronic Obstructive Pulmonary Disease (COPD), a specific lung disease, causes approximately 3 million deaths per year globally and currently affects around 480 million people worldwide. However, the current method of diagnosing COPD through physical medical professional visits and checkups is both time-consuming and costly due to the need for specialized medical personnel and equipment. While application of artificial intelligence (AI) shows promise in a future direction for clinical diagnosis, machine learning model development presents significant challenges and remains in the research phase. This paper reviews progress made in the past five years in predictive AI for respiratory illnesses, especially through classical machine learning (ML) and deep learning (DL) model development. The paper first introduces seven databases used to develop predictive ML models. Secondly, it briefly compares architectures between classical ML and DL. Thirdly, the paper summarizes common ML models for prediction and provides a summary and comparison of advantages for classical ML and DL real-life applications. Finally, this paper addresses the challenges and opportunities of using AI for clinical predictions.},
  keywords={Deep learning;Technological innovation;Reviews;Databases;Predictive models;Prediction algorithms;Chronic obstructive pulmonary disease;Personnel;Medical diagnostic imaging;Machine intelligence;Machine Learning;Deep Learning;AI;COPD;Respiratory Illness;Prediction;Diagnosis},
  doi={10.1109/ICMI65310.2025.11141112},
  ISSN={},
  month={April},}@ARTICLE{9265181,
  author={Batbaatar, Erdenebileg and Park, Kwang Ho and Amarbayasgalan, Tsatsral and Davagdorj, Khishigsuren and Munkhdalai, Lkhagvadorj and Pham, Van-Huy and Ryu, Keun Ho},
  journal={IEEE Access}, 
  title={Class-Incremental Learning With Deep Generative Feature Replay for DNA Methylation-Based Cancer Classification}, 
  year={2020},
  volume={8},
  number={},
  pages={210800-210815},
  abstract={Developing lifelong learning algorithms are mandatory for computational systems biology. Recently, many studies have shown how to extract biologically relevant information from high-dimensional data to understand the complexity of cancer by taking the benefit of deep learning (DL). Unfortunately, new cancer growing up into the hundred types that make systems difficult to classify them efficiently. In contrast, the current state-of-the-art continual learning (CL) methods are not designed for the dynamic characteristics of high-dimensional data. And data security and privacy are some of the main issues in the biomedical field. This article addresses three practical challenges for class-incremental learning (Class-IL) such as data privacy, high-dimensionality, and incremental learning problems. To solve this, we propose a novel continual learning approach, called Deep Generative Feature Replay (DGFR), for cancer classification tasks. DGFR consists of an incremental feature selection (IFS) and a scholar network (SN). IFS is used for selecting the most significant CpG sites from high-dimensional data. We investigate different dimensions to find an optimal number of selected CpG sites. SN employs a deep generative model for generating pseudo data without accessing past samples and a neural network classifier for predicting cancer types. We use a variational autoencoder (VAE), which has been successfully applied to this research field in previous works. All networks are sequentially trained on multiple tasks in the Class-IL setting. We evaluated the proposed method on the publicly available DNA methylation data. The experimental results show that the proposed DGFR achieves a significantly superior quality of cancer classification tasks with various state-of-the-art methods in terms of accuracy.},
  keywords={Cancer;DNA;Task analysis;Data models;Computational modeling;Feature extraction;Biological system modeling;Computational biology;deep learning;class-incremental learning;continual learning;deep generative model;variational autoencoder;DNA methylation;cancer classification},
  doi={10.1109/ACCESS.2020.3039624},
  ISSN={2169-3536},
  month={},}@ARTICLE{9729827,
  author={Sripanuskul, Nuntida and Buayai, Prawit and Mao, Xiaoyang},
  journal={IEEE Access}, 
  title={Generative Data Augmentation for Automatic Meter Reading Using CNNs}, 
  year={2022},
  volume={10},
  number={},
  pages={28471-28486},
  abstract={While smart meters are still not widely installed in many countries, automatic reading of traditional-type meters is useful from the perspective of both cost and safety. Although convolutional neural network (CNN) showed a high potential for automatic meter reading under unconstrained environment, it is facing various challenges. One is the difficulty of collecting a sufficient amount of training dataset since some digits of a meter may take a long time to update. Another challenging issue is how to recognize the transitional state between two consecutive numbers. To solve these problems, we propose a new data augmentation technique that can automatically generate annotated images of numbers, including the transitional states. By taking advantage of the state-of-the-art generative neural network model, the generated numbers resemble the local appearance of those in the original meter images. Evaluation experiments confirm that our proposed generative data augmentation techniques improve the robustness of the recognition model and achieve outstanding results when compared to the previous work.},
  keywords={Meters;Training data;Neural networks;Object detection;Image recognition;Convolutional neural networks;Automatic meter reading;Automatic meter reading;image data augmentation;generative neural network;object detection and recognition},
  doi={10.1109/ACCESS.2022.3157706},
  ISSN={2169-3536},
  month={},}@ARTICLE{8341743,
  author={Das, Abhishek and Kottur, Satwik and Gupta, Khushi and Singh, Avi and Yadav, Deshraj and Lee, Stefan and Moura, José M. F. and Parikh, Devi and Batra, Dhruv},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Visual Dialog}, 
  year={2019},
  volume={41},
  number={5},
  pages={1242-1256},
  abstract={We introduce the task of Visual Dialog, which requires an AI agent to hold a meaningful dialog with humans in natural, conversational language about visual content. Specifically, given an image, a dialog history, and a question about the image, the agent has to ground the question in image, infer context from history, and answer the question accurately. Visual Dialog is disentangled enough from a specific downstream task so as to serve as a general test of machine intelligence, while being sufficiently grounded in vision to allow objective evaluation of individual responses and benchmark progress. We develop a novel two-person real-time chat data-collection protocol to curate a large-scale Visual Dialog dataset (VisDial). VisDial v0.9 has been released and consists of $\sim$∼1.2M dialog question-answer pairs from 10-round, human-human dialogs grounded in $\sim$∼120k images from the COCO dataset. We introduce a family of neural encoder-decoder models for Visual Dialog with 3 encoders—Late Fusion, Hierarchical Recurrent Encoder and Memory Network (optionally with attention over image features)—and 2 decoders (generative and discriminative), which outperform a number of sophisticated baselines. We propose a retrieval-based evaluation protocol for Visual Dialog where the AI agent is asked to sort a set of candidate answers and evaluated on metrics such as mean-reciprocal-rank and recall$@k$@k of human response. We quantify the gap between machine and human performance on the Visual Dialog task via human studies. Putting it all together, we demonstrate the first ‘visual chatbot’! Our dataset, code, pretrained models and visual chatbot are available on https://visualdialog.org.},
  keywords={Visualization;Task analysis;Artificial intelligence;History;Protocols;Natural languages;Wheelchairs;Visual dialog;computer vision;natural language processing;machine learning},
  doi={10.1109/TPAMI.2018.2828437},
  ISSN={1939-3539},
  month={May},}@INPROCEEDINGS{10078578,
  author={Yin, Kang and Lee, Byeong-Hoo and Kwon, Byoung-Hee and Cho, Jeong-Hyun},
  booktitle={2023 11th International Winter Conference on Brain-Computer Interface (BCI)}, 
  title={Target-centered Subject Transfer Framework for EEG Data Augmentation}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Data augmentation approaches are widely explored for the enhancement of decoding electroencephalogram signals. In subject-independent brain-computer interface system, domain adaption and generalization are utilized to shift source subjects’ data distribution to match the target subject as an augmentation. However, previous works either introduce noises (e.g., by noise addition or generation with random noises) or modify target data, thus, cannot well depict the target data distribution and hinder further analysis. In this paper, we propose a target-centered subject transfer framework as a data augmentation approach. A subset of source data is first constructed to maximize the source-target relevance. Then, the generative model is applied to transfer the data to target domain. The proposed framework enriches the explainability of target domain by adding extra real data, instead of noises. It shows superior performance compared with other data augmentation methods. Extensive experiments are conducted to verify the effectiveness and robustness of our approach as a prosperous tool for further research.},
  keywords={Brain modeling;Brain-computer interfaces;Robustness;Electroencephalography;Data models;Decoding;Data augmentation;brain-computer interface;generative adversarial network;electroencephalogram},
  doi={10.1109/BCI57258.2023.10078578},
  ISSN={2572-7672},
  month={Feb},}@ARTICLE{10909109,
  author={Zhuansun, Chenlu and Li, Pengdeng and Liu, Yuan and Tian, Zhihong},
  journal={IEEE Internet of Things Journal}, 
  title={Generative AI-Assisted Mobile-Edge Computation Offloading in Digital-Twin-Enabled IIoT}, 
  year={2025},
  volume={12},
  number={10},
  pages={13248-13258},
  abstract={As a key technology in the Industrial Internet of Things (IIoT), the combination of digital twins (DTs) and mobile-edge computing (MEC) facilitates edge intelligence in B5G, while the application of generative artificial intelligence (GenAI) further enhances edge intelligence in resource allocation. However, the DT-enabled MEC system in IIoT faces the challenges of the low latency and high reliability demands, especially with the massive increase in machine-type communication devices and limited wireless and computing resources. To reduce overall delay and ensure high-reliability communication among machine devices (MDs), we propose an optimization problem for joint wireless and MEC computation resource allocation (JWMC-RA), which is shown to be NP-hard and intractable. Thereafter, the original problem is decomposed into two stages, i.e., machine-to-machine (M2M) links clustering, and MEC computing resource management. In the step of M2M links clustering, a heuristic clustering scheme via spectrum radius (HCS-SR) is presented for reducing interference of MDs which uses GenAI and graph theory. In the step of MEC computing resource management, the initial optimization problem is transformed to a convex problem, then, the optimal task offloading ratios of MD and MEC computing resource allocation are obtained. Finally, simulations show that the JWMC-RA scheme can reduce the overall delay and ensure the communication reliability.},
  keywords={Industrial Internet of Things;Servers;Resource management;Reliability;Delays;Machine-to-machine communications;Wireless communication;Computational modeling;Optimization;Data privacy;Generative artificial intelligence (GenAI);Industrial Internet of Things (IIoT);mobile-edge computation (MEC);resource allocation},
  doi={10.1109/JIOT.2025.3547370},
  ISSN={2327-4662},
  month={May},}@INPROCEEDINGS{10975909,
  author={Huang, Min and Ma, Jiarui and Bo, Sun},
  booktitle={2025 14th International Conference on Educational and Information Technology (ICEIT)}, 
  title={Design and Implementation of a Multi-Level Personalized Teaching Framework Based on LLM}, 
  year={2025},
  volume={},
  number={},
  pages={8-14},
  abstract={Personalized teaching is a key focus in modern education, aiming to meet individual student needs and improve learning efficiency. Traditional teaching methods struggle to address student differences in large-scale settings, leading to suboptimal personalized instruction. Recent advancements in generative artificial intelligence (GAI) and large language models (LLMs) offer significant support for the design and implementation of personalized teaching. This paper proposes a multilevel personalized teaching framework that integrates the core elements of the educational system, supporting personalized learning for students, optimizing teaching tasks for teachers, and enhancing resource management for higher education institutions. The framework operates from three perspectives: student, teacher, and institution, offering personalized services throughout the teaching process, including lesson planning, real-time adjustments, and post-class evaluations. The paper discusses the implementation approach based on technologies such as Mixture of Experts (MoE), Chain-of-Thought (CoT) reasoning, and dynamic prompting techniques, along with scenario examples and a validation scheme. The proposed framework provides theoretical support and practical guidance for universities to implement more effective personalized teaching based on AI technologies.},
  keywords={Emotion recognition;Adaptation models;Large language models;Scalability;Education;Transforms;Cognition;Resource management;Testing;Software engineering;Personalized Teaching;Artificial Intelligence;Large Language Models (LLMs);Multi-level;Teaching Framework},
  doi={10.1109/ICEIT64364.2025.10975909},
  ISSN={},
  month={March},}@INPROCEEDINGS{8864448,
  author={Mirwan and Nugroho, Aryo and Hendarta, Ferial and Hidayatillah, Rumaisah and Hassan, Firdaus and Nana, Kristovel Printo},
  booktitle={2018 International Seminar on Research of Information Technology and Intelligent Systems (ISRITI)}, 
  title={Virtual Assistant Using Lstm Networks In Indonesian}, 
  year={2018},
  volume={},
  number={},
  pages={652-655},
  abstract={Researches into the development of virtual assistants that are human-like today were an active research that has been developed over the past few decades. Currently the generative model virtual assistant is a few steps towards artificial general intelligence, the smart computer with complex feelings and characteristics. One method for building the generative model virtual assistant is by using the LSTM Networks. This method has been popular for building English virtual assistant. Our aim is to test whether this method could be applied in Indonesian or not. We used the dataset from many movie subtitles in Indonesian languages. The LSTM variant that we used was the sequence-to-sequence model embedded with word2vec. The results show that the model could answer appropriately to the simple questions such as greetings. Although the models were failed to answer some complex questions, the results still give potential works on the future.},
  keywords={Personal digital assistants;Motion pictures;Training;Computer science;Buildings;Data visualization;Context modeling;Artificial General Intelligence;Generative Models;Indonesian Languages;LSTM Networks;Virtual Assistant},
  doi={10.1109/ISRITI.2018.8864448},
  ISSN={},
  month={Nov},}@ARTICLE{8941108,
  author={Yang, Linlin and Shangguan, Hong and Zhang, Xiong and Wang, Anhong and Han, Zefang},
  journal={IEEE Access}, 
  title={High-Frequency Sensitive Generative Adversarial Network for Low-Dose CT Image Denoising}, 
  year={2020},
  volume={8},
  number={},
  pages={930-943},
  abstract={Low-dose computed tomography (LDCT) imaging has attracted tremendous attention because it reduces the potential cancer risk for patients by decreasing the radiation dose. However, reducing the radiation dose may cause image quality degradation due to the introduction of noise and artifacts. The details of pathological information mainly exist in the high-frequency domain of LDCT image. Therefore, some useful details may be lost or destroyed while removing the noise and artifacts. To address this problem, we propose a high-frequency sensitive generative adversarial network (HFSGAN). The new generator includes two sub-networks. One is the high-frequency domain U-Net, which is specially designed to deal with the high-frequency components decomposed from LDCT image. The other is image space U-Net, which is used to process information from the whole image of LDCT. In addition, the discriminator in HFSGAN adopts an inception module to increase the receptive field and width of network, and to extract the multi-scale features of the true and false images. The experiments show that the proposed network preserves more texture details of denoised image while removing noise and artifacts. Compared with the state-of-the-art networks, the proposed denoising method achieves better performance both quantitatively and visually.},
  keywords={Noise reduction;Computed tomography;Generative adversarial networks;Generators;Image denoising;Image reconstruction;Linear programming;Low-dose CT;image denoising;GAN;U-Net;inception module},
  doi={10.1109/ACCESS.2019.2961983},
  ISSN={2169-3536},
  month={},}@ARTICLE{8808903,
  author={Wang, Xiangyang and Cao, Zhongzheng and Wang, Rui and Liu, Zhi and Zhu, Xiaoqiang},
  journal={IEEE Access}, 
  title={Improving Human Pose Estimation With Self-Attention Generative Adversarial Networks}, 
  year={2019},
  volume={7},
  number={},
  pages={119668-119680},
  abstract={Human pose estimation in images is challenging and important for many computer vision applications. Large improvements in human pose estimation have been achieved with the development of convolutional neural networks. Even though, when encountered some difficult cases even the state-of-the-art models may fail to predict all the body joints correctly. Some recent works try to refine the pose estimator. GAN (Generative Adversarial Networks) has been proved to be efficient to improve human pose estimation. However, GAN can only learn local body joints structural constrains. In this paper, we propose to apply Self-Attention GAN to further improve the performance of human pose estimation. With attention mechanism in the framework of GAN, we can learn long-range body joints dependencies, therefore enforce the entire body joints structural constrains to make all the body joints to be consistent. Our method outperforms other state-of-the-art methods on two standard benchmark datasets MPII and LSP for human pose estimation. Our code is available at: https://github.com/idotc/Hg-SAGAN.},
  keywords={Pose estimation;Generative adversarial networks;Training;Generators;Gallium nitride;Convolutional neural networks;Benchmark testing;Human pose estimation;convolutional neural networks;stacked hourglass networks;self-attention GAN},
  doi={10.1109/ACCESS.2019.2936709},
  ISSN={2169-3536},
  month={},}@ARTICLE{8701640,
  author={Cui, Qi and Zhou, Zhili and Fu, Zhangjie and Meng, Ruohan and Sun, Xingming and Wu, Q. M. Jonathan},
  journal={IEEE Access}, 
  title={Image Steganography Based on Foreground Object Generation by Generative Adversarial Networks in Mobile Edge Computing With Internet of Things}, 
  year={2019},
  volume={7},
  number={},
  pages={90815-90824},
  abstract={Mobile edge computing provides low-latency service computing for the Internet of Things (IoT). Considering the computational cost of high-quality image steganography in practical mobile applications, we believe that mobile edge computing could provide real-time service computing for covert communications. As a mainstream approach to convert communication, image steganographic algorithms prefer to hide secret data in well-textured regions in order to reduce the possibility of being detected. Recently, the generative adversarial networks (GAN) has become one of the most popular architectures for image steganography. However, the GAN-based image steganographic algorithms directly conduct the secret data embedding on the entire cover images and do not sufficiently take the regional texture complexity into account, which will compromise the anti-detection ability. To address this issue, we propose a novel image steganographic algorithm on the generated foreground object region with rich textures. More specifically, the foreground object region is generated onto a given cover image by the GAN, and the secret data is embedded in the foreground object region simultaneously during the generation of the region. The experimental results show that the proposed method can resist steganalysis effectively without significant degradation of image quality and achieve real-time processing.},
  keywords={Gallium nitride;Training;Image quality;Distortion;Generative adversarial networks;Task analysis;Edge computing;Steganography;mobile edge computing;GAN;foreground object segmentation},
  doi={10.1109/ACCESS.2019.2913895},
  ISSN={2169-3536},
  month={},}@ARTICLE{9492218,
  author={Huang, Chun-Ming and Wijanto, Eddy and Cheng, Hsu-Chih},
  journal={IEEE Access}, 
  title={Applying a Pix2Pix Generative Adversarial Network to a Fourier-Domain Optical Coherence Tomography System for Artifact Elimination}, 
  year={2021},
  volume={9},
  number={},
  pages={103311-103324},
  abstract={The presence of artifacts, including conjugate, DC, and auto-correlation artifacts, is a critical limitation of Fourier-domain optical coherence tomography (FD-OCT). Many methods have been proposed to resolve this problem to obtain high-quality images. Furthermore, the development of deep learning has resulted in many prospective advancements in the medical field; image-to-image translation by using generative adversarial networks (GANs) is one such advancement. In this study, we propose applying the Pix2Pix GAN to eliminate artifacts from FD-OCT images. The first experiment results showed that the proposed framework could translate conventional FD-OCT depth profiles into artifact-free FD-OCT depth profiles. In addition, the FD-OCT depth profile and optical distance of translated images matched those of ground truth images. Second experiment verified that the proposed GAN-based FD-OCT can be applied to generate artifact-free FD-OCT image with different parameters of sample refractive index, the front surface of the sample toward the zero-delay position, and the physical thickness of the sample. Third experiment proved that the proposed model could translated the conventional FD-OCT depth profiles with additional Gaussian noises source image into artifacts-free FD-OCT and successfully relieved the noise.},
  keywords={Generative adversarial networks;Mirrors;Imaging;Couplers;Optical imaging;Generators;Feature extraction;Artifacts;FD-OCT;image-to-image translation;Pix2Pix GAN},
  doi={10.1109/ACCESS.2021.3098865},
  ISSN={2169-3536},
  month={},}@ARTICLE{10131900,
  author={Lee, Subin and Yoon, Young-Il and Jung, Yong Ju},
  journal={IEEE Access}, 
  title={Generative Adversarial Network-Based Signal Inpainting for Automatic Modulation Classification}, 
  year={2023},
  volume={11},
  number={},
  pages={50431-50446},
  abstract={Automatic modulation classification (AMC) aims to automatically identify the modulation type of a detected signal in an intelligent wireless receiver, such as software-defined radio (SDR). Recently, deep learning-based methods such as convolutional neural networks have been applied to AMC, showing high-accuracy performance. However, the earlier studies do not consider various signal degradations that can possibly occur during the transmission and reception of wireless signals. Particularly, the signal reception can be often unstable, and the signal can be partially received due to the dynamic spectrum sensing or signal sensing in the intelligent wireless systems. The corrupted signal with missing samples considerably degrades the accuracy of modulation classification of the deep learning-based models, because it is very different from the training datasets. To address this issue, the preprocessing process of restoring the corrupted signal, called signal inpainting, is essential. Although it is significant for the modulation classification, no studies have been performed to investigate the effect of signal inpainting on AMC. To that end, this study proposes a generative adversarial network(GAN)-based signal inpainting method that fills in the missing samples in a wireless signal. The proposed inpainting method can restore the time-domain signal with up to 50% missing samples while maintaining the global structure of each modulation type. The correct recovery of the global structure enables the extraction of distinctive features that play a key role in the modulation classification. To investigate this effect of signal inpainting on AMC, we perform intensive experiments on the RadioML dataset that has been widely used in the AMC studies. We compare the accuracy performance of the two state-of-the-art AMC models with and without the proposed signal inpainting, respectively. Through the analysis of the results, we show that the proposed GAN-based inpainting method significantly improves the accuracy of AMC.},
  keywords={Modulation;Wireless communication;Feature extraction;Data models;Image restoration;Wireless sensor networks;Signal processing;Convolutional neural networks;Generative adversarial networks;Software defined networking;Signal inpainting;signal restoration;modulation classification;CNN;GAN;SDR},
  doi={10.1109/ACCESS.2023.3279022},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10968479,
  author={Ranjan, Radha and Goswami, Arpita and M, Benzigar and Irudayasamy, Julius and Lokeswar Reddy, K. and Rathnamma, M V},
  booktitle={2025 3rd International Conference on Integrated Circuits and Communication Systems (ICICACS)}, 
  title={Improving EFL Students' Reading Skills Using Graph Attention Networks and Intelligence-Based Tasks}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Reading is an engaging practice that helps language learners understand texts. Develop and prioritize basic skills like reading strategies to improve performance and learn new languages. Reading and reading methods will be defined, distinct reading techniques reviewed, successful reading models established, and essential reading principles investigated. The suggested approach involves preprocessing, feature extraction, and model training. PREP techniques such stop word reduction and Porter stemming address data sparsity. Latent Dirichlet Allocation (LDA) selects features, and Hierarchical Generative Adversarial Network trains models. When compared to BERT and GAN, the recommended model wins. The model's 95.39% accuracy is impressive. This proposed shows that the suggested technique improves reading comprehension and text processing precision. Superior preprocessing, feature selection, and hierarchical GAN-based training make it superior to state-of-the-art methods.},
  keywords={Training;Accuracy;Inspection;Generative adversarial networks;Feature extraction;Resource management;Proposals;Integrated circuit modeling;Pupils;Text processing;EFL learners;reading strategies;latent dirichlet allocation (LDA)},
  doi={10.1109/ICICACS65178.2025.10968479},
  ISSN={},
  month={Feb},}@ARTICLE{9808103,
  author={Xia, Kun and Duch, Wlodzislaw and Sun, Yu and Xu, Kedi and Fang, Weili and Luo, Hanbin and Zhang, Yi and Sang, Dong and Xu, Xiaodong and Wang, Fei-Yue and Wu, Dongrui},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Privacy-Preserving Brain–Computer Interfaces: A Systematic Review}, 
  year={2023},
  volume={10},
  number={5},
  pages={2312-2324},
  abstract={A brain–computer interface (BCI) establishes a direct communication pathway between the human brain and a computer. It has been widely used in medical diagnosis, rehabilitation, education, entertainment, and so on. Most research so far focuses on making BCIs more accurate and reliable, but much less attention has been paid to their privacy. Developing a commercial BCI system usually requires close collaborations among multiple organizations, e.g., hospitals, universities, and/or companies. Input data in BCIs, e.g., electroencephalogram (EEG), contain rich privacy information, and the developed machine learning model is usually proprietary. Data and model transmission among different parties may incur significant privacy threats, and hence, privacy protection in BCIs must be considered. Unfortunately, there does not exist any contemporary and comprehensive review on privacy-preserving BCIs. This article fills this gap, by describing potential privacy threats and protection strategies in BCIs. It also points out several challenges and future research directions in developing privacy-preserving BCIs.},
  keywords={Electroencephalography;Privacy;Data privacy;Computational modeling;Data models;Brain modeling;Feature extraction;Brain-computer interfaces (BCIs);electroencephalogram (EEG);machine learning (ML);privacy},
  doi={10.1109/TCSS.2022.3184818},
  ISSN={2329-924X},
  month={Oct},}@ARTICLE{10589387,
  author={Corbacho-Abelaira, Dolores and Casal-Guisande, Manuel and Corbacho-Abelaira, Fernando and Arnaiz-Fernández, Miguel and Trinidad-López, Carmen and Delgado Sánchez-Gracián, Carlos and Sánchez-Montañés, Manuel and Ruano-Raviña, Alberto and Fernández-Villar, Alberto},
  journal={IEEE Access}, 
  title={Proposal and Definition of an Intelligent Decision- Support System Based on Deep Learning Techniques for the Management of Possible COVID-19 Cases in Patients Attending Emergency Departments}, 
  year={2024},
  volume={12},
  number={},
  pages={95035-95046},
  abstract={The COVID-19 pandemic drastically transformed the integration of technology into medicine, testing the ability of health systems to make quick and effective decisions. This has been especially noticeable in emergency departments, which were overwhelmed by the massive influx of patients. In this context, this article presents the design, development, and proof of concept of a new intelligent decision support system applied to the management of patients suspected of having COVID-19 upon their arrival at an emergency department. To achieve this, starting from our proprietary database of chest X-rays (CXRs) collected at the Ribera Povisa Hospital, two modules based on the use of convolutional neural networks (CNNs) were sequentially run. The first was based on the DenseNet-121 model to identify whether a pneumonia condition was presented in the CXR, while the second was based on the COVID-Net CXR-S model and aimed to quantify the severity of airspace opacity in the CXR on a scale 0–24. Thus, based on this architecture, it will be possible to make predictions based on the CXR of new patients that, after interpretation, might allow physicians to determine whether cases are high-risk and, for example, should be admitted to the intensive care unit. Although the results we obtained were encouraging, it is important to note that this proposal is still at a conceptual stage of development and so future work will be required to validate it in real environments and develop techniques that can help explain its results.},
  keywords={COVID-19;Pneumonia;Hospitals;X-ray imaging;Diseases;Artificial intelligence;Databases;Convolutional neural networks;Decision making;Decision support systems;Artificial intelligence;convolutional neural networks;decision making;deep learning;decision support systems},
  doi={10.1109/ACCESS.2024.3424907},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11156423,
  author={Sinha, Shweta and Dubey, Priyanka},
  booktitle={2025 2nd International Conference On Multidisciplinary Research and Innovations in Engineering (MRIE)}, 
  title={An Adaptive Real-Time Fraud Detection with Explainable AI and Kernel-Level Optimization}, 
  year={2025},
  volume={},
  number={},
  pages={818-822},
  abstract={Observing the current increase in patterns of pretense and pseudo users in the domain of financial transactions combined with digital services available to us, this paper presents the real-time fraud detection model. Existing algorithms such as: Random Forest, SVM, and Logistic Regression are unable to provide satisfactory results when it comes to concurrent fraud trends. Since the existing algorithms of Machine Learning or Deep Learning provide limited results, a need for robust and more powerful model was visible and a framework is proposed in the current research to support the requirements. With the rapid increase in malpractices and other security threats, the existing algorithms face tremendous limitations to cope with this scenario. This paper proposes a system that includes (i) GAN, (ii) ADWIN technique, and (iii) in-kernel simulation. With the use of GAN, the system creates its own fraudulent and safe data and detects the type of transaction. The ADWIN technology is responsible for evolution in the fraud trend. Simulation is done through in-kernel process. By following the significant path with three major components, this paper presents the approaches to overcome the limitations of AI algorithms in fraud detection.},
  keywords={Technological innovation;Logistic regression;Machine learning algorithms;Adaptive systems;Generative adversarial networks;Market research;Real-time systems;Fraud;Random forests;Optimization;Real-time fraud detection;self-learning systems;GAN;ADWIN;kernel-level execution;adaptive models;financial cybersecurity},
  doi={10.1109/MRIE66930.2025.11156423},
  ISSN={},
  month={July},}@BOOK{10559421,
  author={Guilmette, Aaron},
  booktitle={Power Platform and the AI Revolution: Explore modern AI services to develop apps, bots, and automation patterns to enhance customer experiences},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Unlock the untapped potential of ChatGPT, CoPilot, and Azure AI services by integrating them with the Microsoft Power PlatformKey FeaturesGain insights into the latest AI technologies and their business applicationsUse generative AI to build apps, workflows, and chatbotsLearn how to integrate AI services to automate work and deliver apps for specific business needsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionIn this AI era, employing leading machine learning and AI models such as ChatGPT for responding to customer feedback and prototyping applications is crucial to drive business success in the competitive market. This book is an indispensable guide to integrating cutting-edge technology into business operations and leveraging AI to analyze sentiment at scale, helping free up valuable time to enhance customer relationships. Immerse yourself in the future of AI-enabled application development by working with Power Automate, Power Apps, and the new Copilot Studio. With this book, you’ll learn foundational AI concepts as you explore the extensive capabilities of the low-code Power Platform. You’ll see how Microsoft's advanced machine learning technologies can streamline common business tasks such as extracting key data elements from customer documents, reviewing customer emails, and validating passports and drivers’ licenses. The book also guides you in harnessing the power of generative AI to expedite tasks like creating executive summaries, building presentations, and analyzing resumes. You’ll build apps using natural language prompting and see how ChatGPT can be used to power chatbots in your organization. By the end of this book, you’ll have charted your path to developing your own reusable AI automation patterns to propel your business operations into the future.What you will learnInteract with ChatGPT using connectors and HTTP callsTrain AI models to identify the key elements of documentsUse generative AI to answer questions about organizational contentLeverage AI image recognition services to describe picturesUse generative AI tools to help build workflows and appsBuild chatbots using the new Copilot StudioAnalyze customer feedback using AI sentiment analysis tools such as AI BuilderWho this book is forIf you’re interested in exploring the capabilities of modern AI technologies in the workplace, this book is for you. Specially tailored for IT professionals, developers, business leaders, human resources administrators, managers, and entrepreneurs–anyone aspiring to become a productivity rockstar will find this book helpful for extending their skill set through hands-on exercises. The content is beginner-friendly, assuming no knowledge of machine learning or artificial intelligence concepts, making it a perfect starting point for newcomers to the field.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835089927},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10559421},}@INPROCEEDINGS{9158216,
  author={Sadman, Nafiz and Datta Gupta, Kishor and Haque, Md Ariful and Sen, Sajib and Poudyal, Subash},
  booktitle={2020 17th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)}, 
  title={Stylometry as a Reliable Method for Fallback Authentication}, 
  year={2020},
  volume={},
  number={},
  pages={660-664},
  abstract={Over the decades with advancement in artificial intelligent systems, stylometry has proven to be crucial in authorship attribution. It is an evident that by natural development, writing styles between individuals are unique and cannot be fabricated. Stylometric analysis research has been done for author identification and there is significant progress to recognize an author based on their written texts. This paper aims to evaluate the efficiency o f u sing s tylometry a s a fall back authentication method. We proposed to detect differences between writings on the same topic provided by a set of users and tested whether these differences are enough to use for an authentication system. We observed 74% accuracy in detecting the actual authors and concluded that with additional features the accuracy can be pushed to above 90%. Moreover, we deviced a threshold for authentication of a particular user. We observed that the combination of textual features can support authenticity of the user. We also analyzed the impact of some data cleaning systems like removing stop words and punctuation marks, and how they affected the overall detection outcome.},
  keywords={Authentication;Feature extraction;Writing;Support vector machines;Machine learning;Password;Data models;NLP;Stylometry;Fallback authentication;Exploratory data anaylsis;Metric evaluation},
  doi={10.1109/ECTI-CON49241.2020.9158216},
  ISSN={},
  month={June},}@ARTICLE{9696243,
  author={Rhee, Chi-Hyoung and Lee, Chang Ha},
  journal={IEEE Access}, 
  title={Estimating Physically-Based Reflectance Parameters From a Single Image With GAN-Guided CNN}, 
  year={2022},
  volume={10},
  number={},
  pages={13259-13269},
  abstract={We present a method that estimates the physically accurate reflectance of materials from a single image and reproduces real world materials which can be used in well-known graphics engines and tools. Recovering the BRDF (bidirectional reflectance distribution function) from a single image is an ill-posed problem due to the insufficient irradiance and geometry information as well as the insufficient samples on the BRDF parameters. The problem could be alleviated with a simplified representation of the surface reflectance such as Phong reflection model. Recent works have appealed that convolutional neural network successfully predicts parameters of empirical BRDF models for non-Lambertian surfaces. However, parameters of the physically-based model confront the problem of having non-orthogonal space, making it difficult to estimate physically meaningful results. In this paper, we propose a method to estimate parameters of a physically-based BRDF model from a single image. We focus on the metallic property of the physically-based model to enhance the estimation accuracy. Since metals and nonmetals have very different characteristics, our method processes them separately. Our method also generates auxiliary maps using a cGAN (conditional generative adversarial network) architecture to help in estimating more accurate BRDF parameters. Based on the experimental results, the auxiliary map is selected as an irradiance environment map for the metallic and a specular map for the nonmetallic. These auxiliary maps help to clarify the contributions of different actors, including light color, material color, specular component, and diffuse component, to the surface color. Our method first estimates whether the material on the input image is metallic or nonmetallic. Then, it estimates BRDF parameters using CNN (convolutional neural networks) architecture guided by generated auxiliary maps. Our results show that our method is effective to estimate BRDF parameters both on synthesized as well as real images.},
  keywords={Reflectivity;Rendering (computer graphics);Lighting;Color;Reflection;Metals;Estimation;Physically-based rendering;BRDF estimation;artificial intelligence;convolutional neural networks;generative adversarial networks;supervised learning},
  doi={10.1109/ACCESS.2022.3147483},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10711156,
  author={Ovsiannikova, Polina and Liakh, Tatiana and Jhunjhunwala, Pranay and Vyatkin, Valeriy},
  booktitle={2024 IEEE 29th International Conference on Emerging Technologies and Factory Automation (ETFA)}, 
  title={Generative AI Co-Pilot for Rapid Prototyping of IEC 61499 Control Applications}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={This work develops a concept of a natural language co-pilot for the creation of IEC 61499 applications to accelerate initial testing and development. The co-pilot addresses the challenge of generating the correct function blocks that can be opened in popular IEC 61499 IDEs. In our case study, we focus on the generation of the centralised controller that operates particular equipment to perform a defined process. In addition, we have developed a scheme for how the co-pilot will be integrated into the FBME IDE as an AI assistant in the next steps. In the discussion, we provide valuable information for future co-pilot developers on the possible problems they might face in this area and how to overcome them.},
  keywords={IEC Standards;Codes;Process control;XML;Artificial intelligence;Chatbots;Testing;Natural languages;Encoding;Vectors;co-pilot;IEC 61499;FBD generation},
  doi={10.1109/ETFA61755.2024.10711156},
  ISSN={1946-0759},
  month={Sep.},}@ARTICLE{10638800,
  author={Fang, Wenxuan and Du, Wei and Yu, Guo and He, Renchu and Tang, Yang and Jin, Yaochu},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Preference Prediction-Based Evolutionary Multiobjective Optimization for Gasoline Blending Scheduling}, 
  year={2025},
  volume={6},
  number={1},
  pages={79-92},
  abstract={Gasoline blending scheduling is challenging, involving multiple conflicting objectives and a large decision space with many mixed integers. Due to these difficulties, one promising solution is to use preference-based multiobjective evolutionary algorithms (PBMOEAs). However, in practical applications, suitable preferences of decision makers are often difficult to generalize and summarize from their operational experience. This article proposes a novel framework called preference prediction-based evolutionary multiobjective optimization (PP-EMO). In PP-EMO, suitable preferences for a new environment can be automatically obtained from historical operational experience by a machine learning-based preference prediction model when we feed the model with the input of the optimization environment. We have found that the predicted preference is able to guide the optimization to efficiently obtain a set of promising scheduling scenarios. Finally, we conducted comparative tests across various environments, and the experimental results demonstrate that the proposed PP-EMO framework outperforms existing methods. Compared with no preference, PP-EMO reduces operating costs by about 25% and decreases blending errors by 50% under demanding operational conditions.},
  keywords={Petroleum;Job shop scheduling;Optimization;Oils;Production;Dynamic scheduling;Schedules;Evolutionary multiobjective optimization (EMO);gasoline blending scheduling;Gaussian process;user-preference},
  doi={10.1109/TAI.2024.3444736},
  ISSN={2691-4581},
  month={Jan},}@INPROCEEDINGS{10972480,
  author={Hu, Yong-Hao and Matsumoto, Atsuya and Ito, Kenichiro and Narumi, Takuji and Kuzuoka, Hideaki and Amemiya, Tomohiro},
  booktitle={2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, 
  title={Avatar Motion Generation Pipeline for the Metaverse via Synthesis of Generative Models of Text and Video}, 
  year={2025},
  volume={},
  number={},
  pages={767-771},
  abstract={Efforts to integrate AI avatars into the metaverse to enhance interactivity have progressed in both research and commercial domains. AI avatars in the metaverse are expected to exhibit not only verbal responses but also avatar motions, such as non-verbal gestures, to enable seamless communication with users. Large Language Models (LLMs) are known for their advanced text processing capabilities, such as user input, avatar actions, and even entire virtual environments as text, making them a promising approach for planning avatar motions. However, generating the avatar motions solely from the textual information often requires extensive training data whereas the configuration is very challenging, with results that often lack diversity and fail to match user expectations. On the other hand, AI technologies for generating videos have progressed to the point where they can depict diverse and natural human movements based on prompts. Therefore, this paper introduces a novel pipeline, TVMP, that synthesizes LLMs with advanced text processing capabilities and video generation models with the ability to generate videos containing a variety of motions. The pipeline first generates videos from text input, then estimates the motions from the generated videos, and lastly exports the estimated motion data into the avatars in the metaverse. Feedback on the TVMP prototype suggests further refinement is needed, such as speed control, display of the progress, and direct edition for contextual relevance and usability enhancements. The proposed method enables AI avatars to perform highly adaptive and diverse movements to fulfill user expectations and contributes to developing a more immersive metaverse.},
  keywords={Solid modeling;Adaptation models;Metaverse;Avatars;Computational modeling;Pipelines;Prototypes;Artificial intelligence;Videos;Text processing;Human-centered computing;Visualization;Visualization techniques;Treemaps;Visualization design and evaluation methods},
  doi={10.1109/VRW66409.2025.00155},
  ISSN={},
  month={March},}@INBOOK{10951361,
  author={McGeorge, Donna},
  booktitle={The ChatGPT Revolution: Get Curious, Get Productive and Get Creative with AI}, 
  title={Generative tales}, 
  year={2024},
  volume={},
  number={},
  pages={183-195},
  abstract={Summary <p>In September 2023, Amazon began restricting authors from self&#x2010;publishing more than three books per day, after concerns that there was an influx of suspected AI&#x2010;generated material. Amazon also introduced a requirement that authors inform the company when their content is AI&#x2010;generated. ChatGPT can help readers with all sorts of creative writing. The readers can describe what they are looking for, and ChatGPT can provide suggestions and prompts to spark their creativity. If readers are stuck on a particular scene or unsure how to proceed with their story, readers can chat with ChatGPT about their dilemma. Sometimes, simply talking through readers' ideas can help them break through creative barriers and find new directions to explore. ChatGPT can assist by generating conversation snippets based on the characters and context the readers provide. This can serve as inspiration or help the readers refine their dialogue until it feels authentic.</p>},
  keywords={Writing;Chatbots;Artificial intelligence;Publishing;Australia;Translation;Stress;Sparks;Particle swarm optimization;Oral communication},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394283149},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951361},}@ARTICLE{11086582,
  author={Ohno, Kasumi and Makino, Kohei and Miwa, Makoto and Sasaki, Yutaka},
  journal={IEEE Access}, 
  title={Long-Term, Multivariate Time Series Generation With the Capture of Intervariate Correlations and Variatewise Characteristics}, 
  year={2025},
  volume={13},
  number={},
  pages={130747-130757},
  abstract={This paper proposes a novel Time Series Generation (TSG) model, the Attended Variate-Conditioned GAN (AVC-GAN), for generating multivariate long-term time series data. Recently, generative approaches to TSG have been explored for applications such as privacy protection, anomaly detection, and time series classification/forecasting. Since existing TSG methods, particularly Generative Adversarial Networks (GANs)-based methods, focus on modeling long-term time series and capturing intervariate correlations, they often struggle to adequately capture the characteristics of each variate, such as specific patterns of waveforms. To address these issues with TSG simultaneously, we propose a novel generative model, AVC-GAN. The key components of AVC-GAN are as follows: 1) a nonautoregressive architecture for modeling long-term time series, 2) variate conditioning for capturing variatewise characteristics, and 3) a multihead attention mechanism for capturing intervariate correlations. Our experiments on multiple benchmark datasets for Long-Term Time Series Forecasting (LTSF) demonstrate that AVC-GAN outperforms state-of-the-art GAN-based generative models across a range of evaluation metrics. In terms of distance-based metrics, calculated as the MSE between real and generated data, our method achieves improvements of 29.8% and 33.7% over state-of-the-art methods in assessing overall intervariate correlations and variatewise characteristics, respectively. Visualization also confirms the superior quality of the generated time series.},
  keywords={Time series analysis;Correlation;Generators;Data models;Generative adversarial networks;Forecasting;Training;Decoding;Vectors;Transformers;Generative adversarial networks;multivariate long-term time series;time series generation},
  doi={10.1109/ACCESS.2025.3590728},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10586740,
  author={Thielen, Nils and Rachinger, Ben and Schröder, Felix and Preitschaft, Anja and Meier, Sven and Seidel, Reinhardt and Reinhardt, Andreas and Franke, Jörg},
  booktitle={2024 1st International Conference on Production Technologies and Systems for E-Mobility (EPTS)}, 
  title={Comparative Study on Different Methods to Generate Synthetic Data for the Classification of THT Solder Joints}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Automated Optical Inspection (AOI) is still one of the major tools for the quality control of solder joints; especially, if the requirements for the solder joints' mechanical and electrical properties are high. This is the case for products in the automotive sector, e.g. air bags or brake systems. Conventional test routines are time-consuming to define and not flexible regarding quality limits and lead to a high amount of manual reinspection. Thus, Artificial Intelligence offers the potential to address these disadvantages. Artificial Intelligence, on the other hand, suffers from highly imbalanced datasets resulting from the low amount of defects on solder joint level. One possibility to face this challenge is the utilization of synthetic data. This work compares different methods to generate data using both conventional data augmentation and deep generative models as well as virtual world rendering in order to enhance dataset quality in general. These are applied to an industrial dataset of THT solder joints. All tested approaches lead to an improvement in model quality. The best results are achieved with synthetic images from a Generative Adversarial Network, relatively increasing performance by around 6 % while minimizing error slip.},
  keywords={Safety devices;Production;Quality control;Optical imaging;Rendering (computer graphics);Adaptive optics;Mechanical factors;Synthetic Data;Artificial Intelligence;Automated Optical Inspection;Electronics Production},
  doi={10.1109/EPTS61482.2024.10586740},
  ISSN={},
  month={June},}@ARTICLE{10318035,
  author={Saeed, Mudassir and Naseer, Asma and Masood, Hassan and Rehman, Shafiq Ur and Gruhn, Volker},
  journal={IEEE Access}, 
  title={The Power of Generative AI to Augment for Enhanced Skin Cancer Classification: A Deep Learning Approach}, 
  year={2023},
  volume={11},
  number={},
  pages={130330-130344},
  abstract={Skin cancer, particularly the malignant melanoma subtype, is widely recognized as a highly lethal form of cancer characterized by abnormal melanocyte cell growth. However, diagnosing and classifying skin lesions, as well as automatically recognizing malignant tumors from dermoscopy images, present significant challenges. To address this challenge, our study employs variants of Convolutional Neural Networks (CNNs) to effectively diagnose and classify various skin lesion types using the latest benchmark datasets ISIC 2019 and 2020. The dataset underwent rigorous preprocessing, which involves employing advanced Generative Artificial Intelligence (AI) techniques i.e., Generative Adversarial Networks (GANs) and Enhanced Super-Resolution Generative Adversarial Networks (ESRGAN), for augmentation. These generative techniques are carefully evaluated and compared for their effectiveness. Our CNN-based approach involves aggregating results from multiple transfer learning models, including VGG16, VGG19, SVM along with a hybrid model in combination of VGG19 and SVM. On ISIC 2019, we have achieved promising accuracies of 92% for VGG16 and 93% for VGG19. Notably, the hybrid VGG19+SVM model exhibits the highest accuracy of 96%. On ISIC 2020, VGG16, VGG19, and SVM achieves accuracies of 90%, 92%, and 92%, respectively. Our findings underscore the potential of generative AI for augmentation, and the efficacy of CNN-based transfer learning models in improving skin cancer classification accuracy.},
  keywords={Skin cancer;Lesions;Melanoma;Convolutional neural networks;Support vector machines;Generative adversarial networks;Feature extraction;Classification algorithms;Skin cancer;CNNs;VGG16;VGG19;GAN;ESRGAN;classification},
  doi={10.1109/ACCESS.2023.3332628},
  ISSN={2169-3536},
  month={},}@ARTICLE{10909280,
  author={Shi, Duanpeng and Zheng, Wendong and Guo, Di and Liu, Huaping},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Conditional Diffusion Model for Electrical Impedance Tomography}, 
  year={2025},
  volume={74},
  number={},
  pages={1-13},
  abstract={The electrical impedance tomography (EIT) is a noninvasive imaging technique, which has been widely used in the fields of industrial inspection, medical monitoring, and tactile sensing. However, due to the inherent nonlinearity and ill-conditioned nature of the EIT inverse problem, the reconstructed image is highly sensitive to the measured data, and random noise artifacts often appear in the reconstructed image, which greatly limits the application of EIT. To address this issue, a conditional diffusion model (CDM) with voltage consistency (CDMVC) is proposed in this study. The method consists of a preimaging module, a CDM for reconstruction, a forward voltage constraint network (FVCN), and a scheme of voltage consistency constraint during the sampling process. The preimaging module is employed to generate the initial reconstruction. This serves as a condition for training CDM. Finally, based on FVCN, a voltage consistency constraint is implemented in the sampling phase to incorporate forward information of EIT, thereby enhancing imaging quality. A more complete dataset, including both common and complex concave shapes, is generated. The proposed method is validated using both simulation and physical experiments. Experimental results demonstrate that our method can significantly improve the quality of reconstructed images. In addition, experimental results also demonstrate that our method has good robustness and generalization performance.},
  keywords={Electrical impedance tomography;Image reconstruction;Diffusion models;Voltage measurement;Conductivity;Deep learning;Training;Noise;Inverse problems;TV;Conditional diffusion model (CDM);electrical impedance tomography (EIT);image reconstruction;voltage consistency},
  doi={10.1109/TIM.2025.3547525},
  ISSN={1557-9662},
  month={},}@ARTICLE{10965648,
  author={Mansour, Mohammad and Djenouri, Djamel and Said, Lobna A. and Latif, Shahid and Maalel, Ahmed and Abdelhadi, Ameer M. S.},
  journal={IEEE Access}, 
  title={ARUC-GAN: A CycleGAN-Based Attention Residual U-Net for Low-Dose CT Denoising in Smart Healthcare}, 
  year={2025},
  volume={13},
  number={},
  pages={72544-72557},
  abstract={Low-dose computed tomography (LDCT) is increasingly adopted in medical imaging to minimize radiation exposure. However, the diagnostic accuracy is primarily affected by different noise sources, e.g., quantum, electronic, and reconstruction. Moreover, conventional denoising methods struggle with the non-uniform noise distributions in LDCT images and often require complex projection data, which limits their effectiveness and generalizability. Herein, we propose an AI-based denoising approach using an Attention Residual U-Net (ARU-Net) architecture integrated into the CycleGAN framework named Attention Residual U-Net CycleGAN (ARUC-GAN). The proposed framework outperforms state-of-the-art denoising models, such as RED-CNN, EDCNN, and CTformer, according to experimental evaluation on the Mayo Clinic abdominal CT dataset. The model exhibits a peak signal-to-noise ratio (PSNR) of 34.82 dB, a structural similarity index (SSIM) of 0.85, and an RMSE of 0.018. Furthermore, the model successfully maintains edge structures with an Edge Keeping Index (EKI) of 0.835. The visual examination validates ARUC-GAN’s superior texture and detail preservation. The results indicate that the suggested method has great promise as a smart health tool for improving diagnosis accuracy in LDCT scans.},
  keywords={Computed tomography;Noise reduction;Noise;Image reconstruction;Accuracy;Generative adversarial networks;Electronic mail;X-ray imaging;Indexes;Image quality;Smart healthcare;artificial intelligence;GAN;image processing;medical imaging},
  doi={10.1109/ACCESS.2025.3560945},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9850263,
  author={Tariq, Irfan and Qiao, Meng and Yao, Shunyu and Ullah, Kalim and Khan, Sifat Ullah and Wei, Liu},
  booktitle={2022 4th International Conference on Computer Communication and the Internet (ICCCI)}, 
  title={Cost Sensitive Self-normalized Deep Convolutional Neural Network for Pulsars Selection}, 
  year={2022},
  volume={},
  number={},
  pages={116-121},
  abstract={Machine learning and deep learning algorithms have been used to classify pulsar and non-pulsar signals in large radio astronomical datasets. These existing machine learning and deep learning algorithms improve classification efficiency, but they have limitations when dealing with large amounts of astronomical data, such as class imbalance and the polarization of high recall and precision. In this paper, a new classification method for dealing with the class imbalance problem as well as the data training process is proposed. The proposed method is based on a cost-sensitive, Scaled Exponential Linear Unit (SELU) activation function and a convolutional neural network (CNN). The proposed method is entitled (CS-SNDCNN). A cost matrix was generated and then applied to each misclassification depending on class distribution. After that, these costs were then applied to the training process in order to improve the final classification accuracy. The proposed method was compared with the state-of-the-art baseline models, which revealed that our model performed much better than existing approaches, almost gaining 3% and 4% better F1-score and precision, respectively.},
  keywords={Training;Deep learning;Costs;Machine learning algorithms;Radio astronomy;Computational modeling;Classification algorithms;Pulsar classification;cost-sensitive;Convolutional neural network;Radio astronomy},
  doi={10.1109/ICCCI55554.2022.9850263},
  ISSN={},
  month={July},}@ARTICLE{10818642,
  author={Wen, Jinbo and Kang, Jiawen and Niyato, Dusit and Zhang, Yang and Mao, Shiwen},
  journal={IEEE Transactions on Industrial Cyber-Physical Systems}, 
  title={Sustainable Diffusion-Based Incentive Mechanism for Generative AI-Driven Digital Twins in Industrial Cyber-Physical Systems}, 
  year={2025},
  volume={3},
  number={},
  pages={139-149},
  abstract={Industrial Cyber-Physical Systems (ICPSs) are an integral component of modern manufacturing and industries. By digitizing data throughout product life cycles, Digital Twins (DTs) in ICPSs enable a shift from current industrial infrastructures to intelligent and adaptive infrastructures. Thanks to data process capability, Generative Artificial Intelligence (GenAI) can drive the construction and update of DTs to improve predictive accuracy and prepare for diverse smart manufacturing. However, mechanisms that leverage Industrial Internet of Things (IIoT) devices to share sensing data for DT construction are susceptible to adverse selection problems. In this paper, we first develop a GenAI-driven DT architecture in ICPSs. To address the adverse selection problem caused by information asymmetry, we propose a contract theory model and develop a sustainable diffusion-based soft actor-critic algorithm to identify the optimal feasible contract. Specifically, we leverage dynamic structured pruning techniques to reduce parameter numbers of actor networks, allowing sustainability and efficient implementation of the proposed algorithm. Numerical results demonstrate the effectiveness of the proposed scheme and the algorithm, enabling efficient DT construction and updates to monitor and manage ICPSs.},
  keywords={Data models;Contracts;Industrial Internet of Things;Heuristic algorithms;Digital twins;Sensors;Real-time systems;Prediction algorithms;Optimization;Decision making;Contract theory;digital twins (DTs);generative AI;industrial cyber-physical systems;sustainable diffusion models},
  doi={10.1109/TICPS.2024.3524483},
  ISSN={2832-7004},
  month={},}@INPROCEEDINGS{10072275,
  author={Liu, Dazhuang and Yang, Zhen and Zhang, Ru and Liu, Jianyi},
  booktitle={2022 International Conference on Computers and Artificial Intelligence Technologies (CAIT)}, 
  title={MaskGAN: A Facial Fusion Algorithm for Deepfake Image Detection}, 
  year={2022},
  volume={},
  number={},
  pages={71-78},
  abstract={The rapid development of deepfakes has caused serious harm to social cognition. However, the current deepfake detection algorithms generally have the problem of poor generalization, and the accuracy rate drops sharply on datasets with unknown deepfake methods. In this paper, we propose a facial fusion algorithm called MaskGAN to enable more generalized deepfake detection. The generator of MaskGAN uses U-Net and SSE to extract the features of face images, and realizes mask generation and face fusion, The discriminator of MaskGAN uses the convolution layer to discriminate the face-swaping images generated by MaskGAN. Then, the obtained face-swaping images are used as training sets and input into an improved Deeplab V3+for training, so that the network can extract the fusion feature circle generated during the face-swaping process from the face-swaping images, so as to identify the authenticity of the face-swaping images. We achieve accurate face swapping with only fused features introduced, generating a face swapping dataset with fused labels. It solves the common problems of over-fitting and poor generalization of existing algorithms. Through a large number of experiments, it is proved that MaskGAN enabled Deeplab V3+detection model can perform well in the case of unknown tampering methods, which achieved 23.02% and 6.9% cross-domain AUC performance improvement.},
  keywords={Training;Deepfakes;Image color analysis;Convolution;Feature extraction;Generative adversarial networks;Generators;generative adversarial network;deepfake detection;fusion feature;faceswap detection},
  doi={10.1109/CAIT56099.2022.10072275},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10097969,
  author={Liu, Jianwen and Xue, Jiarui and Zhang, Juan and Yang, Ying},
  booktitle={2022 IEEE 34th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Image Inpainting with Context Flow Network}, 
  year={2022},
  volume={},
  number={},
  pages={923-930},
  abstract={Image inpainting using deep and complicated convolutional neural networks(CNN) has recently produced outstanding results. Several researchers have considered employing large receptive fields and deep networks for long-distance information transfer to obtain semantically coherent inpainting results. As a side effect, these strategies would lead to the loss of detail and other artifacts. Motivated by the attention mechanism and sequence-to-sequence model, a novel convolution structure called context flow module is introduced into a coarse-to-fine two stages network, extracting information from distant regions without extra network layers or details loss. The context flow module in the refinement network can effectively gather both spatial and contextual data in the distance, and flow information to the next layer patch by patch. The coarse and refinement networks' backbones are encoder-decoder architecture stacked with gated and dilated convolutions. The refinement network encloses two extra elements: the context flow module and a feature-sharing space. The coarse network generates semantically consistent images with no gaps. The refinement network enhances the sharpness and enriches the details of the initial results. Moreover, a patch-based GAN is applied to stabilize training and generate semantically reasonable results. Experimental results show that our method excels at the performance of the state-of-the-art methods on faces(CelebA), buildings(Paris Street View), and natural images(Places2) datasets. The proposed context flow module can be easily integrated with any existing networks to improve their inpainting performance.},
  keywords={Training;Convolution;Shape;Semantics;Memory management;Generative adversarial networks;Feature extraction;Image inpainting;Attention mechanism;Generative adversarial network(GAN);Deep learning},
  doi={10.1109/ICTAI56018.2022.00141},
  ISSN={2375-0197},
  month={Oct},}@ARTICLE{10148574,
  author={Ye, Zipeng and Luo, Wenjian and Naseem, Muhammad Luqman and Yang, Xiangkai and Shi, Yuhui and Jia, Yan},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={C2FMI: Corse-to-Fine Black-Box Model Inversion Attack}, 
  year={2024},
  volume={21},
  number={3},
  pages={1437-1450},
  abstract={Privacy-preserving machine learning requires that models do not reveal any private information about their training data. However, model inversion attacks (MIAs), which aim to recover the features of training data, pose a huge threat to the security of AI models. Most existing MIAs assume that the target model is white-box, but most models deployed in reality are black-box, and these models can only be accessed like an oracle. There are a few studies for black-box scenarios, but their performance is limited. In this article, we first formulate the MIA problem completely in Bayesian perspective. Second, we propose a novel two-stage MIA approach, the Coarse-to-Fine Model Inversion Attack (C2FMI), which efficiently addresses the MIA problem in the black-box scenario. In stage I of C2FMI, we design a reverse network that constrains the recovered images (also named attacked images) to fall near the manifold space of the training data. In stage II, we design a black-box oriented strategy which further facilitates the attacked images to approach the training data. Empirically, C2FMI achieves a performance that even surpasses existing white-box attack methods. Furthermore, we design the stability analysis method for analyzing the stability of C2FMI along with existing MIAs. Finally, we explore the potential countermeasures which could defend against our attacks.},
  keywords={Closed box;Data models;Training data;Glass box;Feature extraction;Security;Computational modeling;Artificial intelligence security;privacy protection;model inversion attack;black-box attack},
  doi={10.1109/TDSC.2023.3285071},
  ISSN={1941-0018},
  month={May},}@INPROCEEDINGS{10616464,
  author={Swamy, Samatha R and Nandini Prasad, K S},
  booktitle={2024 International Conference on Knowledge Engineering and Communication Systems (ICKECS)}, 
  title={Revolutionizing Healthcare Intelligence Multisensory Data Fusion with Cutting-Edge Machine Learning and Deep Learning for Patients’ Cognitive Knowledge}, 
  year={2024},
  volume={1},
  number={},
  pages={1-7},
  abstract={The study explores the recent advancements in healthcare that have witnessed an unprecedented integration of multisensory data, ranging from wearable devices to medical imaging and electronic health records. This paper explores the transformative impact of cutting-edge machine learning algorithms and deep learning algorithms in processing and interpreting this multisensory data, offering unparalleled insights into patients’ cognitive well-being. The review delves into the types and challenges of multisensory data, evaluating performance of supervised and supervised machine learning models for disease detection and pattern recognition respectively. Additionally, it scrutinizes the importance of deep learning applications that are based on convolutional neural networks as well as recurrent neural networks for medical image classification. The paper also mentions the importance of the integration of multisensor data fusion with these advanced algorithms, emphasizing real-time monitoring systems and ethical considerations. Summaries from research data shows effectiveness of remote patient care and predictive analysis and personalized treatment plans. The exploration of future directions and opportunities underscores the prime importance for further advancements in explainable AI, collaborative learning, and edge computing, consolidating the vision of a healthcare paradigm revolutionized by intelligent data fusion and cutting-edge technologies.},
  keywords={Deep learning;Knowledge engineering;Ethics;Machine learning algorithms;Data integration;Medical services;Data models;Healthcare Intelligence;Multisensor Data Fusion;Machine Learning;Deep Learning;Cognitive Knowledge},
  doi={10.1109/ICKECS61492.2024.10616464},
  ISSN={},
  month={April},}@INPROCEEDINGS{10723913,
  author={Pundir, Brajesh Singh and Kumar, Rakesh and Gupta, Meenu and Obaid, Ahmed J.},
  booktitle={2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Synthetic Image Generation for Improved Detection of Bone Defects Using GAN}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Automated Fractures of Bone Detection in orthopedic radiographs is crucial in assisting doctors to correctly and properly diagnose fractures. For this assignment, we investigate a Generative Adversarial Networks (GAN)-based solution that employs sophisticated artificial intelligence models capable of producing realistic photos while detecting anomalies. It display efficiency of GAN-based models in boosting fracture detection performance by applying multiple assessment criteria, such precision, accuracy, and F1-score, and detection speed, through thorough testing and evaluation of musculoskeletal radiograph datasets (MURA). GANs function by retraining networks of generators to produce artificial pictures and a network of discriminators. This antagonistic process encourages the formation of realistic radiography with fractures, enabling precise and automatic detection. Our proposed approach makes use of GANs’ capability to produce artificial pictures with cracks and recognize, abnormal patterns, thereby improving fracture diagnosis These findings highlight the prospect of introducing GANs into automated evaluation, which might assist with develop fracture detection systems in orthopaedics. Our findings advance fracture detection approaches, paving the way for improved and more accurate orthopaedic diagnostic tools.},
  keywords={Musculoskeletal system;Accuracy;Image synthesis;Medical services;Generative adversarial networks;Bones;Generators;Pattern recognition;Diagnostic radiography;Testing;GAN;Deep Learning;X-ray image;Bone detection;Diagnosis;Orthopedics},
  doi={10.1109/ICCCNT61001.2024.10723913},
  ISSN={2473-7674},
  month={June},}@INPROCEEDINGS{11100439,
  author={Zhao, Ming and Jiang, Jian and Tang, Hongliang and Xing, Jiali and Zhang, Shuiyun and Yeoh, Peiquan and Wang, Zheng},
  booktitle={2025 IEEE International Symposium on the Application of Artificial Intelligence in Electrical Engineering (AAIEE)}, 
  title={Source-Load-Topo Joint Scenario Generation Based on Graph Variational Auto-Encoder}, 
  year={2025},
  volume={},
  number={},
  pages={51-56},
  abstract={Scenario generation is a key approach for analyzing uncertainty in power systems. However, existing methods focus solely on generating source-load node states while overlooking topology uncertainty, which limits the accuracy and comprehensiveness of the generated scenarios. To bridge this gap, a source-load-topo joint scenario generation model, SLT-VAE, is proposed to simultaneously determine the corresponding topology states when generating the source-load scenarios. SLT-VAE comprises a spatial-temporal graph encoder and a joint scenario graph decoder. Specifically, the encoder utilizes spatial-temporal attention to adaptively extract information across spatial-temporal dimension. A spatial-temporal convolution is applied to fuse the spatial dependency among source-load nodes and temporal features in different time steps to obtain a dense latent variable containing multi-scale spatial-temporal information. The decoder then outputs the source-load node attribute matrix and its corresponding adjacency matrix in a one-shot manner, leveraging this variable to simultaneously generate source-load and topology scenarios, while quantifying the uncertainty in the topology state. Furthermore, the simulated grid dataset containing 100 different topology scenarios is provided to validate the effectiveness of the proposed method. Experimental results indicate that SLT-VAE can capture complex spatial-temporal correlations and dynamics. Its generated source-load scenarios with topology states is as real as ground-truth data. This facilitates a more comprehensive source-load scenario generation, thus enhancing the operation and planning of power system.},
  keywords={Uncertainty;Correlation;Convolution;Power system dynamics;Feature extraction;Power grids;Topology;Decoding;Scenario generation;Data mining;Scenario Generation;Variational Auto-Encoder;Graph Convolution;Attention Mechanism;Graph Generative Model},
  doi={10.1109/AAIEE64965.2025.11100439},
  ISSN={},
  month={April},}@ARTICLE{11007653,
  author={Nguyen-Duc, Minh and Nguyen, Luong Vuong and Nguyen-Ho-Nhat, Huy and Nguyen, Tri-Hai and Lee, O-Joun},
  journal={IEEE Access}, 
  title={A Comparative Study of Deep Audio Models for Spectrogram- and Waveform-Based SingFake Detection}, 
  year={2025},
  volume={13},
  number={},
  pages={95739-95752},
  abstract={Recent advancements in singing voice synthesis have significantly improved the quality of artificial singing voices, raising concerns about their potential misuse in generating deepfake singing, or “singfake” voices. Detecting these synthetic voices presents unique challenges due to the complex nature of singing, which involves pitch, timbre, and accompaniment variations. In this study, we conduct a comparative analysis of two model types for singfake detection: (1) models utilizing Log-Mel spectrograms, such as Audio Spectrogram Transformer (AST) and Whisper, and (2) models that process raw waveform inputs, including UniSpeech-SAT and HuBERT. Our experiments on the SingFake dataset evaluate these models under two input conditions—separated vocal tracks and full song mixtures—across different test subsets. The results indicate that spectrogram-based models generally outperform waveform-based models, notably on unseen singers. Metrics such as Precision, Recall, F1-score, Equal Error Rate (EER), and Area Under the Curve (AUC) provide insights into the strengths and weaknesses of each approach. Our findings contribute to developing more effective deepfake singing detection methods, with implications for security, media authentication, and digital content protection.},
  keywords={Feature extraction;Deepfakes;Spectrogram;Acoustics;Mel frequency cepstral coefficient;Analytical models;Transformers;Deep learning;Convolutional neural networks;Timbre;Singfake detection;singing voice synthesis;spectrogram-based models;waveform-based models;neural networks},
  doi={10.1109/ACCESS.2025.3571728},
  ISSN={2169-3536},
  month={},}@ARTICLE{10251703,
  author={Ma, Chuan and Li, Jun and Wei, Kang and Liu, Bo and Ding, Ming and Yuan, Long and Han, Zhu and Vincent Poor, H.},
  journal={Proceedings of the IEEE}, 
  title={Trusted AI in Multiagent Systems: An Overview of Privacy and Security for Distributed Learning}, 
  year={2023},
  volume={111},
  number={9},
  pages={1097-1132},
  abstract={Motivated by the advancing computational capacity of distributed end-user equipment (UE), as well as the increasing concerns about sharing private data, there has been considerable recent interest in machine learning (ML) and artificial intelligence (AI) that can be processed on distributed UEs. Specifically, in this paradigm, parts of an ML process are outsourced to multiple distributed UEs. Then, the processed information is aggregated on a certain level at a central server, which turns a centralized ML process into a distributed one and brings about significant benefits. However, this new distributed ML paradigm raises new risks in terms of privacy and security issues. In this article, we provide a survey of the emerging security and privacy risks of distributed ML from a unique perspective of information exchange levels, which are defined according to the key steps of an ML process, i.e., we consider the following levels: 1) the level of preprocessed data; 2) the level of learning models; 3) the level of extracted knowledge; and 4) the level of intermediate results. We explore and analyze the potential of threats for each information exchange level based on an overview of current state-of-the-art attack mechanisms and then discuss the possible defense methods against such threats. Finally, we complete the survey by providing an outlook on the challenges and possible directions for future research in this critical area.},
  keywords={Surveys;Privacy;Data privacy;Distance learning;Distributed databases;Machine learning;Security;Federated learning;Multi-agent systems;Artificial intelligence;Trusted computing;Distributed machine learning (ML);federated learning (FL);multiagent systems;privacy;security;trusted artificial intelligence (AI)},
  doi={10.1109/JPROC.2023.3306773},
  ISSN={1558-2256},
  month={Sep.},}@ARTICLE{9789171,
  author={Shahid, Wajiha and Jamshidi, Bahman and Hakak, Saqib and Isah, Haruna and Khan, Wazir Zada and Khan, Muhammad Khurram and Choo, Kim-Kwang Raymond},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Detecting and Mitigating the Dissemination of Fake News: Challenges and Future Research Opportunities}, 
  year={2024},
  volume={11},
  number={4},
  pages={4649-4662},
  abstract={Fake news is a major threat to democracy (e.g., influencing public opinion), and its impact cannot be understated particularly in our current socially and digitally connected society. Researchers from different disciplines (e.g., computer science, political science, information science, and linguistics) have also studied the dissemination, detection, and mitigation of fake news; however, it remains challenging to detect and prevent the dissemination of fake news in practice. In addition, we emphasize the importance of designing artificial intelligence (AI)-powered systems that are capable of providing detailed, yet user-friendly, explanations of the classification / detection of fake news. Hence, in this article, we systematically survey existing state-of-the-art approaches designed to detect and mitigate the dissemination of fake news, and based on the analysis, we discuss several key challenges and present a potential future research agenda, especially incorporating AI explainable fake news credibility system.},
  keywords={Fake news;Feature extraction;Social networking (online);Artificial intelligence;Computer science;Taxonomy;Support vector machines;Artificial intelligence (AI) explainability;blockchain-based detection;deceptive content;deep fakes;fake news;misinformation;news propaganda;social bots;social media},
  doi={10.1109/TCSS.2022.3177359},
  ISSN={2329-924X},
  month={Aug},}@ARTICLE{10253654,
  author={Zhao, Sicheng and Hong, Xiaopeng and Yang, Jufeng and Zhao, Yanyan and Ding, Guiguang},
  journal={Proceedings of the IEEE}, 
  title={Toward Label-Efficient Emotion and Sentiment Analysis}, 
  year={2023},
  volume={111},
  number={10},
  pages={1159-1197},
  abstract={Emotion and sentiment play a central role in various human activities, such as perception, decision-making, social interaction, and logical reasoning. Developing artificial emotional intelligence (AEI) for machines is becoming a bottleneck in human–computer interaction. The first step of AEI is to recognize the emotion and sentiment that are conveyed in different affective signals. Traditional supervised emotion and sentiment analysis (ESA) methods, especially deep learning-based ones, usually require large-scale labeled training data. However, due to the essential subjectivity, complexity, uncertainty and ambiguity, and subtlety, collecting such annotations is expensive, time-consuming, and difficult in practice. In this article, we introduce label-efficient ESA from the computational perspective. First, we present a hierarchical taxonomy for label-efficient learning based on the availability of sample labels, emotion categories, and data domains during training. Second, for each of the seven paradigms, i.e., unsupervised, semisupervised, weakly supervised, low-shot, incremental, domain-adaptive, and domain-generalizable ESA, we give the definition, summarize existing methods, and present our views on the quantitative and qualitative comparison. Finally, we provide several promising real-world applications, followed by unsolved challenges and potential future directions.},
  keywords={Training;Emotion recognition;Sentiment analysis;Complexity theory;Taxonomy;Speech recognition;Affective computing;Human factors;Artificial intelligence;Labeling;Affective computing;artificial emotional intelligence (AEI);emotion and sentiment analysis (ESA);label-efficient learning},
  doi={10.1109/JPROC.2023.3309299},
  ISSN={1558-2256},
  month={Oct},}@INPROCEEDINGS{9730983,
  author={Ma, Jiaming and Li, Jiaqi and Feng, Shenglu},
  booktitle={2021 3rd International Conference on Machine Learning, Big Data and Business Intelligence (MLBDBI)}, 
  title={Human Pose Estimation Based on GAN and DCGAN Models}, 
  year={2021},
  volume={},
  number={},
  pages={212-215},
  abstract={As an important application based on the field of computer vision, the various human movements and gestures can be reconstructed by detecting the key articulation points of the human body. It is mainly used in human behavior recognition, human-computer interaction, and attitude tracking. However, the current human pose estimation models have many challenges, such as difficulty detecting the non-typical articulation points of the human body and inaccurate locating of the extremities. They are prone to error or lack of information in complex situations. This paper proposed GAN and DCGAN models to tackle this issue, which can improve the accuracy of human posture prediction. This paper mainly focuses on the contribution of Generative Adversarial Network to the detection of human key articulation points, revising the original model posture and obtaining a model that is closer to the real posture of the human body. The experimental results demonstrated that the model's accuracy is improved to a certain extent after using the DCGAN model. Furthermore, we note that in most cases, the performance of the proposed model is superior to others.},
  keywords={Training;Analytical models;Convolution;Tracking;Biological system modeling;Pose estimation;Neural networks;Human pose estimation;Key articulation points detection;DCGAN model;Experimental analysis},
  doi={10.1109/MLBDBI54094.2021.00048},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9587480,
  author={Deepalakshmi, R and Amudha, J},
  booktitle={2021 2nd Global Conference for Advancement in Technology (GCAT)}, 
  title={A Reinforcement Learning based Eye-Gaze Behavior Tracking}, 
  year={2021},
  volume={},
  number={},
  pages={1-7},
  abstract={In video established eye tracking methods, there are both mechanical and electrical based approaches existing. With the emerging spread of gaze tracking technology in the recent years and its significance in daily life routine, the data content acquired from the eye behavior tracing turn into important. Several research works were proposed to track the behavior of gaze while playing videos. Tracking an eye gaze while playing a dynamic videos consisting of numerous frames is a complex problem which needs excessive computational efforts. To handle such a complex task, this research proposes Reinforcement Learning (RL) based gaze behavior prediction model. These techniques are found to be invasive in nature and for visual attention behavior analysis applications, these invasive eye tracking system is not applicable. Hence the non-invasive eye tracking could be developed by determining the point of gaze based on observed image processing techniques. Some of the prevailing techniques include artificial intelligence, deep learning, and reinforcement learning and so on. Though quite a few research works has been admitted in this research area, there are several challenges existing so far. The suggested learning techniques are found to be computationally complex and time consuming. This current research work intends to propose a deep convolutional reinforcement learning (DC-RL) model for predicting the visual attention behavior of a person over dynamic scenes.},
  keywords={Deep learning;Visualization;Computational modeling;Image processing;Reinforcement learning;Gaze tracking;Learning (artificial intelligence);artificial intelligence;gaze points;invasive eye tracking;deep learning reinforcement learning.},
  doi={10.1109/GCAT52182.2021.9587480},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10220806,
  author={Sainudeen, Jinu P and Hemavathy, P and Sathyalakshmi, S.},
  booktitle={2023 International Conference on Innovations in Engineering and Technology (ICIET)}, 
  title={Deep Learning Architecture Based Skin Cancer Detection Using Deep Belief Network and Grey Wolf Optimization}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={Skin cancer is becoming more common every year, and this trend is seen in various nations. As a result of lifestyle modifications and sun-seeking behavior, skin cancer cases are increasing. Melanoma can be successfully treated when skin cancer is discovered early; as a result, curing and surviving melanoma directly depend on eliminating it when it is in its early stages. Unfortunately, traditional procedures for detecting skin cancer can be imprecise and frequently result in more testing. In this work, artificial intelligence (AI) techniques are used to create a special deep learning model that combines deep belief networks and grey wolf optimization. By integrating the advantages of two reliable methods, this network achieves maximum accuracy. The suggested method's performance is evaluated against current state-of-the-art methods and a DBN. The effectiveness of the proposed technique is evaluated using the Human Against Machine (HAM10000) dataset. The proposed technology's accuracy and effectiveness allow for the early clinical detection of skin cancer by doctors and dermatologists.},
  keywords={Deep learning;Training;Technological innovation;Melanoma;Skin;Lesions;Artificial intelligence;Deep learning;Skin cancer prediction;deep belief network;Artificial intelligence},
  doi={10.1109/ICIET57285.2023.10220806},
  ISSN={},
  month={July},}@INPROCEEDINGS{9926669,
  author={Moulouel, Koussaila and Chibani, Abdelghani and Abdelkawy, Hazem and Amirat, Yacine},
  booktitle={2022 IEEE 18th International Conference on Automation Science and Engineering (CASE)}, 
  title={Hybrid approach for anticipating human activities in Ambient Intelligence environments}, 
  year={2022},
  volume={},
  number={},
  pages={2006-2011},
  abstract={Recognising the human context in terms of ongoing human activities is of major importance to ensure an efficient context-aware assistance. In this paper, a hybrid approach combining deep learning and probabilistic commonsense reasoning is proposed for anticipating human activities in AmI environments. Deep learning models are exploited for recognising environment objects, human hands and user’s indoor locations. To implement probabilistic commonsense reasoning, probabilistic fluents are introduced in the formalism of event calculus formulated in answer set programming (ECASP). The reasoning axiomatization is based on an ontology describing the user’s context when performing an activity. Using reasoning based on temporal projection and abduction enables an eXplainable AI (XAI) approach for activity anticipation. Experimental results show the high accuracy of inferences in terms of activity anticipation and a very low computation time in knowledge-intensive scenarios, rendering the system compatible with real-time applications.},
  keywords={Deep learning;Robot vision systems;Ontologies;Probabilistic logic;Cameras;Rendering (computer graphics);Real-time systems},
  doi={10.1109/CASE49997.2022.9926669},
  ISSN={2161-8089},
  month={Aug},}@ARTICLE{10885533,
  author={Ciriello, Raffaele Fabio and Chen, Angelina Ying and Rubinsztein, Zara Annette},
  journal={IEEE Transactions on Technology and Society}, 
  title={Compassionate AI Design, Governance, and Use}, 
  year={2025},
  volume={6},
  number={3},
  pages={270-275},
  abstract={The rapid rise of generative AI reshapes society, transforming jobs, relationships, and core beliefs about human essence. AI’s ability to simulate empathy, once considered uniquely human, offers promise in industries from marketing to healthcare but also risks exploiting emotional vulnerabilities, fostering dependency, and compromising privacy. These risks are particularly acute with AI companion chatbots, which mimic emotional speech but may erode genuine human connections. Rooted in Schopenhauer’s compassionate imperative, we present a novel framework for compassionate AI design, governance, and use, emphasizing equitable distribution of AI’s benefits and burdens based on stakeholder vulnerability. We advocate for responsible AI development that prioritizes empathy, dignity, and human flourishing.},
  keywords={Artificial intelligence;Ethics;Stakeholders;Privacy;Chatbots;Business;Regulation;Mental health;Interoperability;Generative AI;Artificial intelligence;companion;responsibility;chatbot;compassion;sexbot;design;governance;adoption},
  doi={10.1109/TTS.2025.3538125},
  ISSN={2637-6415},
  month={Sep.},}@INPROCEEDINGS{10696616,
  author={Shirisha, N. and Pranitha, V.Penna and Balaram, Allam and Kalpana Chowdary, M and Shekar, Kukunoor},
  booktitle={2024 Second International Conference on Intelligent Cyber Physical Systems and Internet of Things (ICoICI)}, 
  title={A Learning-Based Intelligent Method for Signature Forgery Detection Using Pre-Trained Deep Models}, 
  year={2024},
  volume={},
  number={},
  pages={1337-1345},
  abstract={Signature of a person can uniquely identify the person and it is widely used in social situations and monetary transactions with individuals and financial entities. Many fraud cases have been appearing in society where signature of a person is forged for financial and other benefits. There is need for detecting forged signatures with technology driven approaches. With the emergence of Artificial Intelligence (AI), there are unprecedented possibilities in solving problems of the real world with responsible usage of AI. Deep learning (DL) is one part of AI which extends neural networks has become very significant in computer vision applications. From the existing approaches, it is observed that there is need for a complete framework for end to end processing of signatures for efficient detection of forgeries. Towards this end, we proposed a DL based framework for automatic detection of signature forgery. This study has proposed an algorithm known as Learning based Signature Forgery Detection (LbSFD), which exploits pipeline of multiple DL models such as CNN, VGG16 and Siamese. All the models are CNN variants used to improve efficiency in signature forgery detection. A benchmark signature dataset is used for our empirical study. Our experiments revealed that the CNN based models are highly efficient in signature forgery detection. Highest accuracy with 98.26% is achieved when VGG16 model is employed with transfer learning.},
  keywords={Deep learning;Computer vision;Neural networks;Transfer learning;Pipelines;Benchmark testing;Forgery;Fraud;Internet of Things;Artificial intelligence;Signature Forgery Detection;Artificial Intelligence;Deep Learning;Convolutional Neural Networks},
  doi={10.1109/ICoICI62503.2024.10696616},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10778825,
  author={Li, Fuhao and Wu, Hongyu and Shi, Qinxuan and Shao, Sicong and Zhang, Jielun},
  booktitle={2024 Cyber Awareness and Research Symposium (CARS)}, 
  title={Towards Quality Controllable Data Synthesis: A Case Study on Synthesizing Network Intrusions}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Network intrusion detection plays a significant role in safeguarding network traffic against malicious activities. As the integration of Big Data and Artificial Intelligence (AI) in Intrusion Detection Systems (IDS) becomes more prevalent, achieving high detection accuracy has become increasingly feasible. However, the development of AI-based IDS is often hindered by limited access to diverse and high-quality training datasets, coupled with concerns over sharing raw intrusion data due to privacy and security issues. To mitigate these challenges, a framework that focuses on quality-controllable data synthesis is proposed, specifically for network intrusions. This framework leverages autoencoders for intrusion data generation, ensuring that the synthesized data maintains the characteristics necessary for effective IDS training while enabling controls on the data quality. Our method not only allows for the safe sharing of synthesized intrusion data but also preserves the essential features required for IDS development. We implemented a Deep Learning approach to assess the proposed framework using a benchmark dataset. The results show that our proposed data synthesis approach retains high IDS performance while enabling quality-controllable data synthesis.},
  keywords={Training;Data privacy;Accuracy;Training data;Quality control;Telecommunication traffic;Data models;Security;Artificial intelligence;Synthetic data;Data synthesis;network intrusion detection;data augmentation;autoencoder;Artificial Intelligence},
  doi={10.1109/CARS61786.2024.10778825},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11113575,
  author={Wang, Lu and Xie, Youru and Ke, Jiamin},
  booktitle={2025 International Symposium on Educational Technology (ISET)}, 
  title={Using Structural Equation Modeling to Analyze Impact Factors on Students and AI Agents Interaction Effectiveness in Elementary English Classes}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={A generative classroom relies on a novel interactive environment designed to achieve predefined educational objectives and generate additional values. The rapid evolution of AI Agent technology has presented immense potential for advancing the optimization and transformation of generative teaching methodologies. Initially, drawing upon collaborative interaction theory, this study established a framework of AI agent-supported human-computer interaction (HCI) learning environment, aiming to thoroughly reveal the mechanism of HCI within elementary English generative classrooms. Subsequently, based on this framework and grounded in dialogic education theory and information ecology theory, the study proposed some hypotheses regarding the impact factors on the students and AI agent interaction effectiveness in such classrooms. To test these hypotheses, empirical research was conducted utilizing structural equation modeling. The findings revealed that content usefulness, content ease of use, perceived enjoyment, teacher guidance, interaction atmosphere, technological facilitation, and interaction willingness are crucial factors in interaction effectiveness between students and AI agents in elementary English generative classrooms. Notably, interaction willingness often served as a mediating variable influencing interaction effectiveness. Based on these insights, this study proposed the following strategies. a). Leverage DeepSeek's performance advantages to drive innovation and upgrade of AI agents. b). Optimize corpus processing mechanisms to enhance the content value of AI agents. c). Build the interaction environment to enhance students' willingness to interact with AI agents. Ultimately, this study aimed to provide theoretical guidance and practical insights for the efficient application of AI agents in elementary English classes.},
  keywords={Human computer interaction;Analytical models;Technological innovation;Atmospheric modeling;Collaboration;Mathematical models;Ecology;Artificial intelligence;Mediation;Optimization;Elementary English;Generative Classrooms;Students and AI Agents Interaction;Effectiveness;Impact Factors},
  doi={10.1109/ISET65607.2025.00071},
  ISSN={2766-2144},
  month={July},}@INPROCEEDINGS{9686184,
  author={Ahmed, Ahmed Ehab and Salama, Cherif and Khalil, Mahmoud},
  booktitle={2021 16th International Conference on Computer Engineering and Systems (ICCES)}, 
  title={MetaFlow: A Meta Learning With Normalizing Flows Approach For Few Shots Learning}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Humans can generalize and learn new concepts fast. They are able to learn new concepts given only a few examples and quickly adapt to new situations. In order to do so, they conclude knowledge from their prior experiences, as they are able to combine previous observations with small amounts of new evidence to learn fast. On the other hand, in most machine learning systems there are two distinct phases: Training and testing. The training phase consists of updating the model parameters using data, and during testing, the model is deployed as a decision-making engine. Meta learning, or learning to learn, gained a huge rise in interest in recent years. Contrary to traditional approaches to artificial intelligence where a given problem is solved from scratch using a standard learning algorithm, what meta learning aims at is to improve the learning algorithm itself. In this paper, we consider meta learning problems, where there is a distribution of meta learning tasks, and we would like to train a model that does well and learns quickly when presented with unseen tasks sampled from this distribution. We propose an approach to enhance gradient-based algorithms for meta learning, where we achieved a mean accuracy of 62% with only 3 training iterations over tasks sampled from the Omniglot dataset.},
  keywords={Training;Decision making;Learning (artificial intelligence);Machine learning;Data models;Task analysis;Standards;Artificial intelligence;Meta learning;Deep learning;Few shots learning;Normalizing flows},
  doi={10.1109/ICCES54031.2021.9686184},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10961299,
  author={Patil, Atharva Ashok and Dhir, Renu and Sounkhla, Indu},
  booktitle={2025 International Conference on Visual Analytics and Data Visualization (ICVADV)}, 
  title={A Novel Approach to Steganography and its Countermeasures Against Deep Learning and MITM Attacks}, 
  year={2025},
  volume={},
  number={},
  pages={276-282},
  abstract={Steganography, the old art of hiding a message into the digital format has took a lot of changes due to modern technology. The recent advancement of AI along with Deep Learning took a drastic turn in the act of steganalysis. Steganalysis is the reverse of steganography, where Steganography is the science of hiding the data into image Steganalysis is the art of unrevealing the hidden data from the stego image. This advancement is a boon for steganalysis, but it completely shatters the steganography encryption. This paper introduces a new modern method to securely the concealed image. It combines Steganography with various advanced Techniques like image scrambling, image splitting and fragmentation. This multi-layered approach is intended to thwart contemporary threats, such as attacks utilizing deep learning-based detection and Man-in-the-Middle attacks (MITM). By breaking the image up into pieces and scrambling the pixels, the technique operates. Several encrypted channels are then used to transmit these pieces, making it very difficult for attackers to intercept and recreate the original picture. This results when the attacker even if he gets the fragments of message, he cannot recreate the complete message as the fragments are the key itself which makes this approach unique and robust as each fragment which is send is a key to the complete message. Particularly in high-stakes communication situations, this novel approach seeks to ensure secure and effective image transmission by offering strong protection for sensitive visual data compared to old steganography techniques this method ensures protection against Artificial Intelligence.},
  keywords={Deep learning;Resistance;Industries;Steganography;Art;Visual analytics;Image communication;Reliability;Artificial intelligence;Protection;Steganography;Image scrambling;Fragmentation;Deep-learning;Artificial intelligence;MITM attacks},
  doi={10.1109/ICVADV63329.2025.10961299},
  ISSN={},
  month={March},}@ARTICLE{10936983,
  author={Kavouras, Ioannis and Rallis, Ioannis and Sardis, Emmanuel and Doulamis, Anastasios and Doulamis, Nikolaos},
  journal={IEEE Computer Graphics and Applications}, 
  title={Voting-Based Intervention Planning Using AI-Generated Images}, 
  year={2025},
  volume={45},
  number={2},
  pages={31-46},
  abstract={The continuous evolution of artificial intelligence and advanced algorithms capable of generating information from simplified input creates new opportunities for several scientific fields. Currently, the applicability of such technologies is limited to art and medical domains, but it can be applied to engineering domains to help the architects and urban planners design environmentally friendly solutions by proposing several alternatives in a short time. This work utilizes the image-inpainting algorithm for suggesting several alternative solutions to four European cities. In addition, this work suggests the utilization of a voting-based framework for finding the most preferred solution for each case study. The voting-based framework involves the participation of citizens and, as a result, decentralizes and democratizes the urban planning process. Finally, this research indicates the importance of deploying generative models in engineering applications by proving that generative AI models are capable of supporting the architects and urban planners in urban planning procedures.},
  keywords={Generative AI;Artificial intelligence;Art;Urban planning;Medical diagnostic imaging;Image synthesis;Climate change;Visualization;Diffusion models},
  doi={10.1109/MCG.2025.3553620},
  ISSN={1558-1756},
  month={March},}@ARTICLE{10902504,
  author={Li, Xiao and Chen, Liquan and Fu, Tong and Fu, Zhangjie and Gao, Yuan},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Coverless Image Steganography Based on Semantic-Controlled Text-to-Image Generation}, 
  year={2025},
  volume={35},
  number={8},
  pages={8391-8405},
  abstract={Artificial Intelligence Generated Content (AIGC) has created a fertile ground for image steganography. Existing Coverless Image Steganography (CIS) methods rely on image semantics to encode secrets, transmitting stego images without embedding, inherently resisting steganalysis. However, constructing CIS Datasets (CISDs) for these methods demands excessive resources, making them impractical for communication. Moreover, achieving low cost and high security is unattainable under these conditions. Therefore, we propose a CIS method based on semantic-controlled text-to-image generation. Our method disguises users as typical AIGC community members utilizing mainstream black-box text-to-image generation with Stable Diffusion (SD). During pre-processing, plain prompts, derived from dialogues with a large language model, are divided into coded and uncoded prompts through our encryption process, where a secret key determines coded prompts. In communication, confusion prompts are selected from uncoded and coded prompts, excluding those determined by secrets. Subsequently, our stego shuffling process combines topic, secret, and confusion prompts to produce stego prompt sets. Diverse stego images maintaining visual topic consistency are generated from these sets using SD with generation seeds indicating transmission order. By introducing confusion prompts, our method is secure from recognition when revealing stego prompts. Experimental results demonstrate our method achieves low communication costs and enhances communication security.},
  keywords={Semantics;Text to image;Steganography;Security;Costs;Artificial intelligence;Visualization;Receivers;Image recognition;Electronic mail;Coverless image steganography (CIS);image steganography;text-to-image generation;artificial intelligence generated content (AIGC)},
  doi={10.1109/TCSVT.2025.3545067},
  ISSN={1558-2205},
  month={Aug},}@ARTICLE{11175219,
  author={Xu, Xin-Yue and Wang, Su-Mei and Liu, Wen-Qiang and Ni, Yi-Qing},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Advancements in Obstacle Intrusion Detection Methods for Rail Transit: A Comprehensive Review}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Developing intelligent obstacle intrusion detection systems (OIDS) is crucial for the safety of train operations. Advances in graphics processing units (GPUs) and image sensing technologies have driven research and development of railway environmental perception using artificial intelligence (AI). However, compared with road transport, the current research and development efforts of railway OIDS are relatively insufficient. Although several papers have reviewed obstacle detection methods in railway applications, a comprehensive summary and discussion of the state-of-the-art AI-based methods is lacking. In view of this, this article aims to provide a thorough review of the traditional visual sensor-based and AI-based obstacle intrusion detection (OID) methods used in railways. The article first discusses the characteristics and advantages of various sensing devices, including cameras, LiDAR, and millimeter-wave radar, as well as the integration of these sensors. The focus is on rail area detection algorithms and obstacle detection algorithms, and the algorithm principles and model structures are summarized. In addition, the article provides an in-depth discussion of strategies for improving and optimizing the OID algorithms. Finally, the challenges and future requirements of OIDS in railway applications are outlined and potential research directions are highlighted.},
  keywords={Rail transportation;Sensors;Rails;Cameras;Feature extraction;Object detection;Laser radar;Millimeter wave radar;Image segmentation;Artificial intelligence;Rail transit;obstacle intrusion detection;computer vision;artificial intelligence},
  doi={10.1109/TIM.2025.3612624},
  ISSN={1557-9662},
  month={},}@INPROCEEDINGS{9445247,
  author={Irfan, Muhammad Maaz and Ali, Sheraz and Yaqoob, Irfan and Zafar, Numan},
  booktitle={2021 International Conference on Artificial Intelligence (ICAI)}, 
  title={Towards Deep Learning: A Review On Adversarial Attacks}, 
  year={2021},
  volume={},
  number={},
  pages={91-96},
  abstract={Attacker determines their targets strategically and deliberately depend on vulnerabilities they have ascertained. Organization and individuals mostly try to protect themselves from one occurrence or type on an attack. Still, they have to acknowledge that the attacker may easily move focus to advanced uncovered vulnerabilities. Even if someone successfully tackles several attacks, risks remain, and the need to face threats will happen for the predictable future. Machine learning algorithms have earned much popularity in artificial intelligence (A.I) in the modern era. Large organizations like Google, Facebook, and Microsoft use large volumes of user data to train machine learning models. Then they use it for social ads. Like these days, Whatsapp will make a new privacy policy to share their data on Facebook. That data may be used for companies advertisements in future. So, in this way, the privacy of an individual might be breech out. Due to the high probability of attacks and the leakage of sensitive data in deep learning on distributive computation, adversarial examples demonstrated the vulnerability of machine learning techniques in terms of robustness. Besides, this allowed adversaries to make use of the vulnerability to target machine learning systems. Although adversarial attacks on real-world applications did not occur until recently, it is difficult to inject an artificial adversary to the model that is being hosted without infringement of the reliability. Recently few attacks occur in terms of facial recognition, road signs classification by finally, the difference between theoretical methodologies for the generation of adversarial examples and practical schemes of attacks on real-world applications. To direct future studies in the real defence of adversarial examples in real-world applications, For realistic attacks, we integrate the threat model with adversarial examples and give an overview with future direction.},
  keywords={Deep learning;Machine learning algorithms;Social networking (online);Perturbation methods;Computational modeling;Face recognition;Roads;deep learning;adversarial attacks;security;AI systems security},
  doi={10.1109/ICAI52203.2021.9445247},
  ISSN={},
  month={April},}@ARTICLE{10103603,
  author={Hu, Yufan and Gao, Junyu and Xu, Changsheng},
  journal={IEEE Transactions on Multimedia}, 
  title={Learning Multi-Expert Distribution Calibration for Long-Tailed Video Classification}, 
  year={2024},
  volume={26},
  number={},
  pages={555-567},
  abstract={Most existing state-of-the-art video classification methods assume that the training data obey a uniform distribution. However, video data in the real world typically exhibit an imbalanced long-tailed class distribution, resulting in a model bias towards head class and relatively low performance on tail class. While the current long-tailed classification methods usually focus on image classification, adapting them to video data is not a trivial extension. We propose an end-to-end multi-expert distribution calibration method to address these challenges based on two-level distribution information. The method jointly considers the distribution of samples in each class (intra-class distribution) and the overall distribution of diverse data (inter-class distribution) to solve the issue of imbalanced data under long-tailed distribution. By modeling the two-level distribution information, the model can jointly consider the head classes and the tail classes and significantly transfer the knowledge from the head classes to improve the performance of the tail classes. Extensive experiments verify that our method achieves state-of-the-art performance on the long-tailed video classification task.},
  keywords={Tail;Head;Calibration;Training;Data models;Task analysis;Visualization;Long-tailed distribution;video classification;multi-expert calibration},
  doi={10.1109/TMM.2023.3267887},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{10098047,
  author={Chen, Luyao and Xie, Shaorong and Pang, Tao and Yu, Hang and Luo, Xiangfeng and Zhang, Zhenyu},
  booktitle={2022 IEEE 34th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Learning from Suboptimal Demonstration via Trajectory-Ranked Adversarial Imitation}, 
  year={2022},
  volume={},
  number={},
  pages={486-493},
  abstract={Robots trained by Imitation Learning(IL) are used in many tasks(e.g., autonomous vehicle manipulation). Generative Adversarial Imitation Learning (GAIL) assumes that the demonstration set used for training is of high quality. However, such demonstrations are difficult and expensive to obtain. GAIL-related methods fail to learn effective strategies if non-high quality demonstrations are used because the performance of agents trained by this method is limited by the demonstrator's operations. Our idea is to enable the agent to learn strategy with better performance than the demonstrator from a suboptimal demonstration set, which contains non-high quality demonstrations that are easier to obtain. Inspired by this, we propose the Trajectory-Ranked Adversarial Imitation Learning (TRAIL) method. First, for demonstration set processing, we introduce a ranking process and define the concept of Performance Relative Advantage of suboptimal demonstrations to specify the ranking order. Second, for model training, we reconstruct the objective function of GAIL and use an experience replay buffer, enabling the agent to learn implicit features and ranking information from the ranked suboptimal demonstration set and possess the ability to outperform the demonstrator. Experiments show that in Mujoco's tasks, our method can learn from a suboptimal demonstration set and can achieve better performance than baseline methods.},
  keywords={Training;Learning (artificial intelligence);Linear programming;Task analysis;Robots;Autonomous vehicles;Reinforcement learning;Imitation learning;Suboptimal demonstration;Trajectory-Ranked},
  doi={10.1109/ICTAI56018.2022.00078},
  ISSN={2375-0197},
  month={Oct},}@ARTICLE{10814671,
  author={Zhang, Jinpu and Li, Ziwen and Wei, Ruonan and Wang, Yuehuan},
  journal={IEEE Transactions on Multimedia}, 
  title={Augment One With Others: Generalizing to Unforeseen Variations for Visual Tracking}, 
  year={2025},
  volume={27},
  number={},
  pages={1461-1474},
  abstract={Unforeseen appearance variation is a challenging factor for visual tracking. This paper provides a novel solution from semantic data augmentation, which facilitates offline training of trackers for better generalization. We utilize existing samples to obtain knowledge to augment another in terms of diversity and hardness. First, we propose that the similarity matching space in Siamese-like models has class-agnostic transferability. Based on this, we design the Latent Augmentation (LaAug) to transfer relevant variations and suppress irrelevant ones between training similarity embeddings of different classes. Thus the model can generalize across a more diverse semantic distribution. Then, we propose the Semantic Interaction Mix (SIMix), which interacts moments between different feature samples to contaminate structure and texture attributes and retain other semantic attributes. SIMix simulates the occlusion and complements the training distribution with hard cases. The mixed features with adversarial perturbations can empirically enable the model against external environmental disturbances. Experiments on six challenging benchmarks demonstrate that three representative tracking models, i.e., SiamBAN, TransT and OSTrack, can be consistently improved by incorporating the proposed methods without extra parameters and inference cost.},
  keywords={Semantics;Training;Target tracking;Data augmentation;Feature extraction;Visualization;Contamination;Perturbation methods;Object tracking;Computational modeling;Class-agnostic;diversity and hardness;offline training;semantic data augmentation;visual object tracking},
  doi={10.1109/TMM.2024.3521842},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{10356593,
  author={Schwab, Malgorzata and Biswas, Ashis Kumer},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Invertible Neural Networks for Trustworthy AI}, 
  year={2023},
  volume={},
  number={},
  pages={480-485},
  abstract={This study combines research in machine learning and system engineering practices to conceptualize a paradigm enhancing trustworthiness of machine learning inference process. We explore the topic of reversibility in deep neural networks and introduce their anomaly detection capabilities to build a framework of integrity verification checkpoints across the inference pipeline of a deployed model. We leverage previous findings and principles regarding several types of autoencoders, deep generative maximum-likelihood training and invertibility of neural networks to propose an improved network architecture for anomaly detection. A remarkable ability of an Invertible Neural Network (INN) to reconstruct data from its compressed representation and to solve inverse problems is then generalized and applied in the field of Trustworthy AI. To achieve integrity verification of an inference pipeline we place the INN-based Trusted Neural Network nodes around the mission critical parts of the system, achieving an end-to-end outcome verification. This work aspires to enhance robustness and reliability of applications employing artificial intelligence, which are playing increasingly noticeable role in highly consequential decision-making processes across many industries and problem domains.},
  keywords={Training;Maximum likelihood detection;Inverse problems;Pipelines;Mission critical systems;Machine learning;Network architecture;Invertible;Integrity;Robustness;Trustworthy},
  doi={10.1109/ICTAI59109.2023.00076},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{9297323,
  author={Kamoun, Faouzi and Iqbal, Farkhund and Esseghir, Mohamed Amir and Baker, Thar},
  booktitle={2020 International Symposium on Networks, Computers and Communications (ISNCC)}, 
  title={AI and machine learning: A mixed blessing for cybersecurity}, 
  year={2020},
  volume={},
  number={},
  pages={1-7},
  abstract={While the usage of Artificial Intelligence and Machine Learning Software (AI/MLS) in defensive cybersecurity has received considerable attention, there remains a noticeable research gap on their offensive use. This paper reviews the defensive usage of AI/MLS in cybersecurity and then presents a survey of its offensive use. Inspired by the System-Fault-Risk (SFR) framework, we categorize AI/MLS-powered cyberattacks by their actions into seven categories. We cover a wide spectrum of attack vectors, discuss their practical implications and provide some recommendations for future research.},
  keywords={Computer security;Malware;Machine learning;Computer crime;Tools;Neural networks;Digital forensics;Security;Cybersecurity;AI;machine learning;deep learning;neural networks;adversarial techniques},
  doi={10.1109/ISNCC49221.2020.9297323},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9826133,
  author={Pu, Muxin and Kuan, Meng Yi and Lim, Nyee Thoang and Chong, Chun Yong and Lim, Mei Kuan},
  booktitle={2022 IEEE/ACM 7th International Workshop on Metamorphic Testing (MET)}, 
  title={Fairness Evaluation in Deepfake Detection Models using Metamorphic Testing}, 
  year={2022},
  volume={},
  number={},
  pages={7-14},
  abstract={Fairness of deepfake detectors in the presence of anomalies are not well investigated, especially if those anomalies are more prominent in either male or female subjects. The primary motivation for this work is to evaluate how deepfake detection model behaves under such anomalies. However, due to the black-box nature of deep learning (DL) and artificial intelligence (AI) systems, it is hard to predict the performance of a model when the input data is modified. Crucially, if this defect is not addressed properly, it will adversely affect the fairness of the model and result in discrimination of certain sub-population unintentionally. Therefore, the objective of this work is to adopt metamorphic testing to examine the reliability of the selected deepfake detection model, and how the transformation of input variation places influence on the output. We have chosen MesoInception-4, a state-of-the-art deepfake detection model, as the target model and makeup as the anomalies. Makeups are applied through utilizing the Dlib library to obtain the 68 facial landmarks prior to filling in the RGB values. Metamorphic relations are derived based on the notion that realistic perturbations of the input images, such as makeup, involving eyeliners, eye shadows, blushes, and lipsticks (which are common cosmetic appearance) applied to male and female images, should not alter the output of the model by a huge margin. Furthermore, we narrow down the scope to focus on revealing potential gender biases in DL and AI systems. Specifically, we are interested to examine whether MesoInception-4 model produces unfair decisions, which should be considered as a consequence of robustness issues. The findings from our work have the potential to pave the way for new research directions in the quality assurance and fairness in DL and AI systems.},
  keywords={Deepfakes;Quality assurance;Perturbation methods;Detectors;Predictive models;Robustness;Libraries;Metamorphic testing;fairness testing;robustness testing;oracle problem},
  doi={10.1145/3524846.3527337},
  ISSN={},
  month={May},}@INPROCEEDINGS{9743542,
  author={AtaŞ, Serhat and İlhan, İsmail and KarakÖse, Mehmet},
  booktitle={2022 26th International Conference on Information Technology (IT)}, 
  title={An Efficient Deepfake Video Detection Approach with Combination of EfficientNet and Xception Models Using Deep Learning}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  abstract={Artificial intelligence is used in many areas and is constantly being developed. In recent years, videos made with deep fakes, which are often heard, have also developed. The use of videos made with deep fakes as blackmail in people's lives, manipulating the videos of important people to cause anxiety on people and etc. due to the fact that it poses a threat in many areas presents a big problem today. Efforts are being made to prevent this threat by detecting deep fake videos. Deep fake detection is still not fully resolved. For this reason, prominent technology companies provide support to researchers in this field and develop deep fraud detection by suggesting methods and organizing contests on most platforms such as Kaggle. In this article, a detection method is proposed to minimize the current concern of deep forgery. In the proposed method, the Xception model with high performance and speed and the EfficientNetB4 model with high accuracy were used. The proposed method aims to achieve better results and improvements in detecting fake videos.},
  keywords={Deep learning;Anxiety disorders;Companies;Data models;Forgery;Information technology;Artificial intelligence},
  doi={10.1109/IT54280.2022.9743542},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10434896,
  author={Garg, Diya and Gill, Rupali},
  booktitle={2023 10th IEEE Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON)}, 
  title={Deepfake Generation and Detection - An Exploratory Study}, 
  year={2023},
  volume={10},
  number={},
  pages={888-893},
  abstract={Deepfakes generated through algorithms based on deep learning have obtained a lot of interest recently. Deepfakes are utilized to manipulate content (audio, video and image) with high realism. Deepfakes have been influenced using artificial intelligence to make it look like someone is saying or doing something that they never actually said or did. Deepfakes can be used for malicious purposes, such as to tarnish someone's reputation or to influence public opinion. Researchers are developing new methods to detect deepfakes, as it is a challenging to distinguish between real and fake content. Deep learning is a powerful tool that is usable to develop both deepfake generation and detection methods. This article provides an extensive review of the existing state of research in creation and detection of deepfakes. It covers the diverse techniques for creation and detection, and existing benchmark datasets.},
  keywords={Deep learning;Deepfakes;Computational modeling;Benchmark testing;Artificial intelligence;Faces;Audio-visual systems;Deepfakes;Deep Learning;Forgery;Audio Deepfake;Video Deepfake;Image Deepfake;Face swap},
  doi={10.1109/UPCON59197.2023.10434896},
  ISSN={2687-7767},
  month={Dec},}@ARTICLE{10517327,
  author={Maniyal, Vishal and Kumar, Vijay},
  journal={IT Professional}, 
  title={Unveiling the Deepfake Dilemma: Framework, Classification, and Future Trajectories}, 
  year={2024},
  volume={26},
  number={2},
  pages={32-38},
  abstract={Deepfake is a type of artificial intelligence technology that makes use of deep learning to generate fake multimedia. A large number of images, audios, and videos have surfaced, particularly on social media, in which deepfake technology is used. This has raised concerns because it can be misleading or fraudulent media, can spread misinformation and propaganda, or potentially cause harm to individuals’ reputations. This article presents a comprehensive review of deepfake technology, focusing on its underlying principles and methodologies. The analysis highlights both the positive as well as negative implications of deepfake technology, shedding light on its potential benefits in filmmaking, digital art, and content creation, alongside its ethical and societal implications, including concerns about misinformation, privacy violations, and cyberthreats.},
  keywords={Deepfakes;Technological innovation;Privacy;Systematics;Social networking (online);Watermarking;Artificial intelligence;Classification algorithms},
  doi={10.1109/MITP.2024.3369948},
  ISSN={1941-045X},
  month={March},}@INPROCEEDINGS{10195519,
  author={Wu, Junjie and Huang, Xueting and Liu, Jingnian and Huo, Yingzi and Yuan, Gaojing and Zhang, Ronglin},
  booktitle={2023 IEEE 10th International Conference on Cyber Security and Cloud Computing (CSCloud)/2023 IEEE 9th International Conference on Edge Computing and Scalable Cloud (EdgeCom)}, 
  title={NLP Research Based on Transformer Model}, 
  year={2023},
  volume={},
  number={},
  pages={343-348},
  abstract={Natural language processing technology is an important research area in artificial intelligence which occupies a pivotal position in deep learning. This paper describes in detail the research of NLP based on Transformer structure, thus showing its ultra-high performance and development prospects. Therefore, this article provides a detailed description of the research on NLP based on the Transformer structure, in order to demonstrate its ultra-high performance and development prospects.},
  keywords={Deep learning;Cloud computing;Computational modeling;Transformers;Natural language processing;Production facilities;History;Transformer;NLP;RNN;Transformer XL},
  doi={10.1109/CSCloud-EdgeCom58631.2023.00065},
  ISSN={2693-8928},
  month={July},}@INPROCEEDINGS{10714771,
  author={Jadhav, Dhiraj and Agrawal, Sakshee and Jagdale, Sakshi and Salunkhe, Pranav and Salunkhe, Raj},
  booktitle={2024 8th International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)}, 
  title={AI-Driven Text-to-Multimedia Content Generation: Enhancing Modern Content Creation}, 
  year={2024},
  volume={},
  number={},
  pages={1610-1615},
  abstract={This research investigates the use of artificial intelligence for the creation of multimedia content from textual sources, such as press articles, stories, and scripts. The system utilizes Natural Language Processing and image generation techniques to create relevant visuals and voiceovers, enhancing content creation efficiency without sacrificing quality. The system processes various input formats, using Optical Character Recognition (OCR) for non-text formats and advanced large language models (LLMs) like LLaMA2 and Gemini for text summarization. It automatically extracts keywords and uses them to generate synchronized visual and audio content, utilizing tools like Google Text-to-Speech (GTTS) and AI-based image generation models such as DALL-E and Stable Diffusion. The multimedia content is assembled and rendered using MoviePy, ensuring seamless integration of text, audio, visuals, and subtitles. Applications in journalism, marketing, and education are examined to showcase how this technology improves accessibility and audience engagement. Overall, the study demonstrates the potential of AI in automating media content creation, streamlining the process while maintaining narrative coherence and enhancing the user experience.},
  keywords={Visualization;Presses;Accuracy;Image synthesis;Optical character recognition;Media;Streaming media;Journalism;Real-time systems;Synchronization;Media Content Creation;Audience Engagement;Text-to-Video Generation;Natural Language Processing (NLP);Computer Vision;Optical Character Recognition (OCR);Large Language Models (LLMs)},
  doi={10.1109/I-SMAC61858.2024.10714771},
  ISSN={2768-0673},
  month={Oct},}@ARTICLE{9632396,
  author={He, Dongxiao and Wu, Yanli and Wang, Youyou and Yu, Zhizhi and Feng, Zhiyong and Wang, Xiaobao and Huang, Yuxiao},
  journal={IEEE Transactions on Big Data}, 
  title={Identification of Communities With Multi-Semantics via Bayesian Generative Model}, 
  year={2022},
  volume={8},
  number={4},
  pages={869-881},
  abstract={Discovering communities is an essential step in the analysis of complex systems, and it has two purposes: to identify functional modules and to interpret semantics. However, most of the existing community detection methods only focused on identify communities, while learning the semantics interpretation of communities has not been fully studied. In this paper, we focused on the problem of identifying communities and learning the semantics interpretation of modules jointly in an end-to-end model. We designed a novel generative model which combines two closely related parts, one for community discovery and the other for content clustering and semantics interpretation. By extracting the potential correlation between these two parts, our new method is not only robust to discovering communities, but also able to provide a community with more than one semantic topic. As for model inference, we developed a variational algorithm from a Bayesian point of view. Experimental results on the artificial benchmark and real networks showed the superior performance of the proposed approach over existing methods in terms of effectiveness and efficiency. We also analyzed semantic interpretability of community detection results through a case study over a large-scale music platform dataset.},
  keywords={Semantics;Bayes methods;Network topology;Inference algorithms;Data models;Analytical models;Modeling;Big Data applications;Network topology;Network analysis;community detection;semantic description;bayesian model;variational inference},
  doi={10.1109/TBDATA.2021.3131707},
  ISSN={2332-7790},
  month={Aug},}@INPROCEEDINGS{10723875,
  author={Koritala, Sai Pragna and Chimata, Mahitha and Polavarapu, Sai Naren and Vangapandu, Bhavya Sri and Gogineni, Tarun Krishna and Manikandan, V. M.},
  booktitle={2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={A Deepfake detection technique using Recurrent Neural Network and EfficientNet}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={A deepfake is a computer-generated image or video that appears to be real but is a fabricated representation created to make an individual appear to be saying or doing something that did not occur. Deepfakes generate misleading or deceptive information by manipulating and superimposing faces onto pre-existing footage using artificial intelligence. This paper introduces a novel approach for deepfake detection through a combination of EfficientNet and Recurrent Neural Networks (RNNs). This method enhances detection efficiency by leveraging the hierarchical features acquired by EfficientNet and employing RNNs, specifically Long Short-Term Memory (LSTM) networks, to capture temporal dependencies. Application of this approach to the Celeb-DF dataset resulted in an accuracy of $\mathbf{9 9. 9 8 \%}$.},
  keywords={Deepfakes;Accuracy;Recurrent neural networks;Scalability;Feature extraction;Real-time systems;Artificial intelligence;Long short term memory;Faces;EfficientNet;Recurrent Neural Network(RNN);LSTM;Deepfake detection},
  doi={10.1109/ICCCNT61001.2024.10723875},
  ISSN={2473-7674},
  month={June},}@ARTICLE{8685767,
  author={Yin, Liuguo and Jiang, Chuanao and Jiang, Chunxiao and Ge, Ning and Kuang, Linling and Guizani, Mohsen},
  journal={IEEE Wireless Communications}, 
  title={A Communication Framework with Unified Efficiency and Secrecy}, 
  year={2019},
  volume={26},
  number={4},
  pages={133-139},
  abstract={Future wireless networks are confronted with the pressure to meet the requirements of network efficiency and communication secrecy, which require a new communication framework to unify and jointly optimize efficiency and secrecy. The challenges are to extend the current communication architecture and reveal the relationship of efficiency and secrecy, so that unification and joint optimization can be achieved. Artificial Intelligence (AI) is a powerful tool to solve these problems. In this article, a unified efficiency and secrecy communication framework (UESCF) is proposed to provide the theoretical bases for the applications of AI technology in wireless networks. Under the proposed framework, AI technologies are applied to generate the network common knowledge and communication private knowledge, with the purpose of improving efficiency and secrecy. The goal of this article is to establish the UESCF for future wireless networks and offer an overview to illuminate the potential applications of AI in the proposed framework.},
  keywords={Knowledge engineering;Entropy;Wireless networks;Encryption;Zinc},
  doi={10.1109/MWC.2019.1800361},
  ISSN={1558-0687},
  month={August},}@INPROCEEDINGS{9622944,
  author={Gao, Kunyu and Wang, Jinbo and Wang, Bin and Wang, Ruixue and Jia, Jiao},
  booktitle={2021 8th International Conference on Dependable Systems and Their Applications (DSA)}, 
  title={UAV Test Data Generation Method based on CycleGAN}, 
  year={2021},
  volume={},
  number={},
  pages={338-343},
  abstract={Unmanned aerial vehicles (UAV) have developed rapidly in recent years. With the popularity of artificial intelligence, UAV has been closely related to the military, economic and life fields. However, there are still security concerns with intelligent software. If these hidden dangers appear in reality, they will cause economic losses and even endanger people’s lives. Thus, intelligent software must be tested and verified before they can be put into service. To ensure the effectiveness of testing, we need to generate high-quality, large-scale and low-cost datasets. However, due to weather, technical conditions and other factors, the existing datasets are difficult to meet the demand. Accordingly, we propose a novel method to generate dataset for UAV software testing based on Cycle-Consistent Adversarial Networks (CycleGAN) in this paper. In addition, We conduct experiments and verification on the real dataset of Google Maps. The results show that even if the dataset is disturbed, the images we generate are still of high quality.},
  keywords={Economics;Software testing;Autonomous aerial vehicles;Software;Internet;Security;Artificial intelligence;UAV;CycleGAN;Test data generation},
  doi={10.1109/DSA52907.2021.00052},
  ISSN={2767-6684},
  month={Aug},}@INPROCEEDINGS{10396936,
  author={Mithillesh Kumar, P. and Supriya, M.},
  booktitle={2023 IEEE 3rd Mysore Sub Section International Conference (MysuruCon)}, 
  title={Performance of Single Agent based Deep Reinforcement Models in Urban and Semi Urban Conditions for ORAN Network}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Open Radio Access Networks (ORAN) are the building blocks of the present day communication systems. Global organizations are trying to improve the performance of the ORAN networks to enhance the customer satisfaction. This is done by using various optimization techniques and modern day Artificial Intelligence (AI) based models. Reinforcement learning (RL) models which can be classified as the on-policy and off-policy algorithms are widely adopted for this purpose. The network performance is a typical scenario which can be designed and optimized using RL models. The limitations of RL has led to the rise of Deep Reinforcement Learning (DRL) algorithms. This work focuses on implementing and analyzing the performance of DRL algorithms such as the Advantage Actor-Critic (A2C) and the Proximal Policy Optimization (PPO) for the ORAN network architecture developed using the Mobile Environment. DRL models are chosen to solve the problem statement of optimizing the network in real-time. The environment is designed based on the Okumura - Hata model (OHM) for the urban and Sub-urban scenarios and the performance is analyzed. The simulation shows that the A2C model is better in optimizing the network with a reward of -7 as compared to -10 of PPO model in urban conditions, and a reward of 50 as compared to 47 of PPO in suburban conditions.},
  keywords={Reinforcement learning;Organizations;Network architecture;Real-time systems;Classification algorithms;Artificial intelligence;Optimization;ORAN;PPO;A2C;Okumura-Hata model},
  doi={10.1109/MysuruCon59703.2023.10396936},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10714269,
  author={Williams, Alice and Kovalerchuk, Boris},
  booktitle={2024 28th International Conference Information Visualisation (IV)}, 
  title={Synthetic Data Generation and Automated Multidimensional Data Labeling for AI/ML in General and Circular Coordinates}, 
  year={2024},
  volume={},
  number={},
  pages={272-279},
  abstract={Insufficient amounts of available training data is a critical challenge for both development and deployment of artificial intelligence and machine learning (AI/ML) models. This paper proposes a unified approach to both synthetic data generation (SDG) and automated data labeling (ADL) with a unified SDG-ADL algorithm. SDG-ADL uses multidimensional (n-D) representations of data visualized losslessly with General Line Coordinates (GLCs), relying on reversible GLC properties to visualize n-D data in multiple GLCs. This paper demonstrates use of the new Circular Coordinates in Static and Dynamic forms, used with Parallel Coordinates and Shifted Paired Coordinates, since each GLC exemplifies unique data properties, such as inter-attribute n-D distributions and outlier detection. The approach is interactively implemented in computer software with the Dynamic Coordinates Visualization system (DCVis). Results with real data are demonstrated in case studies, evaluating impact on classifiers.},
  keywords={Machine learning algorithms;Data visualization;Training data;Machine learning;Data models;Software;Labeling;Tuning;Recommender systems;Synthetic data;Synthetic Data Generation;Automated Data Labeling;General Line Coordinates;Circular Coordinates;Parallel Coordinates;Shifted Paired Coordinates;Tabular AI/ML Data;Multidimensional Data Visualization;Visual Knowledge Discovery},
  doi={10.1109/IV64223.2024.00054},
  ISSN={2375-0138},
  month={July},}@INPROCEEDINGS{10386933,
  author={Timilsina, Mohan and Buosi, Samuele and Song, Ping and Yang, Yang and Haque, Rafiqul and Curry, Edward},
  booktitle={2023 IEEE International Conference on Big Data (BigData)}, 
  title={Enabling Dataspaces Using Foundation Models: Technical, Legal and Ethical Considerations and Future Trends}, 
  year={2023},
  volume={},
  number={},
  pages={4712-4721},
  abstract={Foundation Models are pivotal in advancing artificial intelligence, driving notable progress across diverse areas. When merged with dataspace, these models enhance our capability to develop algorithms that are powerful, predictive, and honor data sovereignty and quality. This paper highlights the potential benefits of a comprehensive repository of Foundation Models, contextualized within dataspace. Such an archive can streamline research, development, and education by offering a comparative analysis of various models and their applications. While serving as a consistent reference point for model assessment and fostering collaborative learning, the repository does face challenges like unbiased evaluations, data privacy, and comprehensive information delivery. The paper also notes the importance of the repository being globally applicable, ethically constructed, and user-friendly. We delve into the nuances of integrating Foundation Models within dataspace, balancing the repository’s strengths against its limitations.},
  keywords={Technological innovation;Ethics;Analytical models;Predictive models;Prediction algorithms;Market research;Data models;dataspace;linked;machine learning;foundation model},
  doi={10.1109/BigData59044.2023.10386933},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10515944,
  author={Zhao, Qingyao and Wei, Xiaoyan and Dong, Chenxi and Jin, Bo and Yu, Zheng and Gao, Fei and Xu, Huan and Meng, Haohua and Zheng, Lei and Chen, Chen},
  booktitle={2024 International Conference on Distributed Computing and Optimization Techniques (ICDCOT)}, 
  title={Malware Detection and Analysis based on AI Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In the context of the rapid development of computer technology, malware has gradually attracted widespread attention and been widely used. The research focus of this article is to explore how to use artificial intelligence algorithms to analyze data acquisition in machine learning and complete corresponding simulation tasks. First, this article introduces several mainstream methods and models that are commonly used at present, and discusses their respective advantages and disadvantages; then, this article combines specific cases to further summarize the existing machine learning methods and processes, and proposes ideas for improvement; finally, this article obtains recognition rules by comparing different feature thresholds, and calculates the recognition results based on the obtained parameters to draw conclusions. The test results show that the classification accuracy of the malware detection model is as low as 73% and as high as 94.3%; the detection accuracy is as low as 83.37% and as high as 94.6%; the recall rate is as low as 74.86% and as high as 89.47%. These results illustrate that the performance of the optimized malware detection model can meet user needs and the effect is obvious.},
  keywords={Machine learning algorithms;Computational modeling;Software algorithms;Neural networks;Machine learning;Prediction algorithms;Market research;AI algorithm;malware attack;software detection;software analysis},
  doi={10.1109/ICDCOT61034.2024.10515944},
  ISSN={},
  month={March},}@INPROCEEDINGS{10779954,
  author={Kucuk, Osman Furkan and Bar, Niyazi Furkan and Karakose, Mehmet},
  booktitle={2024 2nd International Conference on Sustaining Heritage: Embracing Technological Advancements (ICSH)}, 
  title={The Role of Image Inpainting Techniques in the Restoration of Artworks: An Evaluation and Comparative Study}, 
  year={2024},
  volume={},
  number={},
  pages={51-54},
  abstract={Cultural heritages represent crucial and distinctive facets of humanity's historical legacy. These structures possess intrinsic value in terms of their historical and artistic significance and function as tangible reflections of the identities and values embedded within societies. However, they are susceptible to deterioration over time, stemming from natural calamities or human-induced disturbances, underscoring the imperative of safeguarding and preserving cultural heritage. Alongside conventional restoration methodologies, contemporary approaches such as artificial intelligence (AI) and image-processing techniques have emerged as pivotal tools in cultural heritage restoration efforts. The burgeoning capabilities and advancements in image-processing technology have spurred scientists to intensify their endeavors in this domain. This study delves into the impact of image inpainting techniques on restoring artistic and cultural works. Several prominent models have been adeptly utilized in restoring obscured images, with an in-depth assessment of their performance and success metrics. Subsequently, the findings have been meticulously scrutinized and evaluated to ascertain their implications.},
  keywords={Measurement;Art;Disasters;Reflection;Data models;Image restoration;Cultural differences;Data mining;Artificial intelligence;cultural heritages;deep learning;inpainting;restoration},
  doi={10.1109/ICSH62408.2024.10779954},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10260970,
  author={Pereira, Jayr and Nogueira, Rodrigo and Zanchettin, Cleber and Fidalgo, Robson},
  booktitle={2023 IEEE International Conference on Advanced Learning Technologies (ICALT)}, 
  title={An Augmentative and Alternative Communication Synthetic Corpus for Brazilian Portuguese}, 
  year={2023},
  volume={},
  number={},
  pages={202-206},
  abstract={In recent years, Augmentative and Alternative Communication (AAC) systems have grown significantly in Brazil, particularly for individuals with cognitive disorders who rely on high-tech AAC tools. Artificial Intelligence (AI) has significantly improved high-tech AAC systems by enhancing accessibility, increasing output generation speed, and improving AAC interfaces' customization and adaptability. This study investigates the use of Large Language Models (LLMs) to generate synthetic text data to augment a corpus for AAC in Brazilian Portuguese. A three-step method was used to augment an initial corpus of 667 AAC-like sentences produced by specialists to a corpus of 13k sentences, comprising sentence collection, corpus augmentation using GPT-3 in a few-shot setting, and corpus cleaning. The quality and reliability of the generated corpus were assessed through a coverage analysis, comparing the content of the generated sentences with the original human-composed sentences. The results provide insights into the methods' strengths and limitations and inform future efforts to improve the generation of synthetic text data for the AAC domain in Brazilian Portuguese.},
  keywords={Training;Adaptation models;Training data;Data models;Cleaning;Reliability;Artificial intelligence;Augmentative and Alternative Communication;Brazilian Portuguese;Corpus;Text Augmentation},
  doi={10.1109/ICALT58122.2023.00066},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{10868487,
  author={Jain, Jaishree and Kaur, Inderjeet},
  booktitle={2024 2nd International Conference on Advancements and Key Challenges in Green Energy and Computing (AKGEC)}, 
  title={Exploring the Cloud and Fog: Addressing Security Risks in AI Applications}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={There are various security risks with cloud- or fog-based machine learning services. Because machine learning applications rely on these services, it is imperative to secure the underlying cloud or fog services to prevent serious disruptions to the applications. We distinguish based on whether Artificial Intelligence applications are employed in a fog computing network or the cloud because the needs for these applications can also vary. This consequently gives rise to various threats or avenues for attack. Security responsibilities for cloud platforms can be split up amongst several parties. Even though fog computing networks have fewer responsibilities, we still need to safeguard services from physical access to the devices at the network’s edge because they have been moved there. Lastly, we go into specific information security requirements for AI-related applications.},
  keywords={Green energy;Information security;Machine learning;Edge computing;AI applications;cyber security;cloud network;fog computing},
  doi={10.1109/AKGEC62572.2024.10868487},
  ISSN={},
  month={Nov},}@ARTICLE{10777917,
  author={Staron, Miroslaw and Abraháo, Silvia and Serebrenik, Alexander and Penzenstadler, Birgit and Horkoff, Jennifer and Honnenahalli, Chetan},
  journal={IEEE Software}, 
  title={Laws, Ethics, and Fairness in Software Engineering}, 
  year={2025},
  volume={42},
  number={1},
  pages={110-113},
  abstract={Software engineering in the era of generative AI, large data sets and superfast pace of software development often tends to focus on technology, tools and methods, putting aside us, software engineers. In this column, we focus on softer aspects of software engineering and report from two conferences: 28th International Conference on Evaluation and Assessment in Software Engineering (EASE 2024) and 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM 2024). The selection of papers provides a glimpse on handling privacy, documenting ethical considerations in AI models and trustworthy AI.},
  keywords={Ethics;Privacy;Generative AI;Software measurement;Software engineering;Software development management;Artificial intelligence},
  doi={10.1109/MS.2024.3469488},
  ISSN={1937-4194},
  month={Jan},}@INPROCEEDINGS{9845296,
  author={Gracia, Mulumba Banza and Malele, Vusumuzi and Ndlovu, Sphiwe Promise and Mathonsi, Topside Ehleketani and Maaka, Lebogang and Muchenje, Tonderai},
  booktitle={2022 IEEE 13th International Conference on Mechanical and Intelligent Manufacturing Technologies (ICMIMT)}, 
  title={6G Security Challenges and Opportunities}, 
  year={2022},
  volume={},
  number={},
  pages={339-343},
  abstract={The Sixth Generation (6G) is currently under development and it is a planned successor of the Fifth Generation (5G). It is a new wireless communication technology expected to have a greater coverage area, significant fast and a higher data rate. The aim of this paper is to examine the literature on challenges and possible solutions of 6G's security, privacy and trust. It uses the systematic literature review technique by searching five research databases for search engines which are precise keywords like “6G,” “6G Wireless communication,” and “sixth generation”. The latter produced a total of 1856 papers, then the security, privacy and trust issues of the 6G wireless communication were extracted. Two security issues, the artificial intelligence and visible light communication, were apparent. In conclusion, there is a need for new paradigms that will provide a clear 6G security solutions.},
  keywords={6G mobile communication;Wireless communication;Privacy;Systematics;Search engines;Manufacturing;Security;6G wireless communication;5G security;6G security;privacy;trust;wireless communication security},
  doi={10.1109/ICMIMT55556.2022.9845296},
  ISSN={},
  month={May},}@INPROCEEDINGS{10546768,
  author={Alamin, Khaled Sidahmed Sidahmed and Appello, Davide and Beghi, Alessandro and Dall'Ora, Nicola and Depaoli, Fabio and Di Cataldo, Santa and Fummi, Franco and Gaiardelli, Sebastiano and Lora, Michele and Macii, Enrico and Mascolini, Alessio and Pagano, Daniele and Ponzio, Francesco and Susto, Gian Antonio and Vinco, Sara},
  booktitle={2024 Design, Automation & Test in Europe Conference & Exhibition (DATE)}, 
  title={An AI-Enabled Framework for Smart Semiconductor Manufacturing}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={With the rise of Machine Learning (ML) and Artificial Intelligence (AI), the semiconductor industry is undergoing a revolution in how it approaches manufacturing. The SMART-IC project (DATE'24 MPP category: initial stage) works in this direction, by proposing an AI-enabled framework to support the smart monitoring and optimization of the semiconductor manufacturing process. An AI-powered engine examines sensor data recording physical parameters during production (like gas flow, temperature, voltage, etc.) as well as test data, with different goals: (1) the identification of anomalies in the production chain, either offline from collected data-traces or online from a continuous stream of sensed data; (2) the forecasting of new data of the future production; and (3) the automatic generation of synthetic traces, to strengthen the data-based algorithms. All such tasks provide valuable information to an advanced Manufacturing Execution System (MES), which reacts by optimizing the production process and management of the equipment maintenance policies. SMART-IC is a 300k€ academic project funded by the Italian Ministry of University and supported by STMicroelectronics and Technoprobe with industrial expertise and real-world applications. This paper shares the view of SMART-IC on the future of semiconductor manufacturing, the preliminary efforts, and the future results that will be reached by the end of the project, in 2025.},
  keywords={Temperature sensors;Temperature distribution;Production;Voltage;Semiconductor device manufacture;Manufacturing;Recording},
  doi={10.23919/DATE58400.2024.10546768},
  ISSN={1558-1101},
  month={March},}@INPROCEEDINGS{10825681,
  author={Marantos, Charalampos and Evangelatos, Spyridon and Veroni, Eleni and Lalas, George and Chasapas, Konstantinos and Christou, Ioannis T. and Lappas, Pantelis},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={Leveraging Large Language Models for Dynamic Scenario Building targeting Enhanced Cyber-threat Detection and Security Training}, 
  year={2024},
  volume={},
  number={},
  pages={2779-2788},
  abstract={As cybercrime is becoming increasingly sophisticated, effective cybersecurity is crucial to safeguard digital assets and protect critical infrastructures from emerging threats. Several security applications exploit recent advances in (Big) data analysis and Artificial Intelligence (AI) to prevent and respond to malicious activities. Towards this direction, supervised and unsupervised Machine Learning (ML) methods are used to detect anomalies or reveal patterns that may indicate potential threats. However, the successful implementation of these technologies requires security practitioners to undergo specialized training to fully understand and use AI-driven tools and data analytics. On the other hand, AI models themselves are vulnerable to a variety of cyber threats, which can compromise their training data and learning processes. To ensure the safe operation of these systems, especially when deployed in adversarial environments, it is crucial to create novel AI adversarial algorithms and models that are resilient against diverse security threats. This work presents a conceptual framework based on Large Language Models (LLMs) supported by a Multi-Agent layer for training of security practitioners in various advanced technologies and enhance ML models ability to detect and respond to emerging cyber threats effectively.},
  keywords={Training;Explainable AI;Large language models;Buildings;Training data;Transforms;Big Data;Data models;Security;Multi-agent systems;Scenario Building;LLM;Adversarial Learning;Data Augmentation;Explainable AI},
  doi={10.1109/BigData62323.2024.10825681},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{10593327,
  author={Agnihotri, Nishant and Hole, Komal},
  booktitle={2024 International Conference on Communication, Computer Sciences and Engineering (IC3SE)}, 
  title={Deep Learning: An In-Depth Study of Algorithms and Application Areas}, 
  year={2024},
  volume={},
  number={},
  pages={1807-1813},
  abstract={Deep learning, an innovative paradigm within artificial intelligence, brings about significant transformations across diverse sectors, ranging from healthcare to autonomous systems. This work explores the latest developments and uses of Deep Learning Algorithms. Highlighted domains include cancer diagnosis, precision medicine, autonomous vehicles, and speech recognition. The review thoroughly explores optimization techniques, aiming to improve training accuracy and reduce time across numerous architectural designs, such as recurrent neural networks, residual networks, and convolutional networks.},
  keywords={Deep learning;Training;Reviews;Precision medicine;Speech recognition;Medical services;Distance measurement;Deep Learning;Optimization Techniques;Convolutional Networks;Recurrent Neural Networks},
  doi={10.1109/IC3SE62002.2024.10593327},
  ISSN={},
  month={May},}@INPROCEEDINGS{10317246,
  author={Chen, Young-Long and Huang, Hsin -I and Yen, Tzu-Te},
  booktitle={2023 Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)}, 
  title={Learned String Quartet Music with Variational Auto Encoder}, 
  year={2023},
  volume={},
  number={},
  pages={1646-1651},
  abstract={Music holds a distinct place within the realm of human artistic. Music generation is also considered as one of the highly challenging domains, demanding significant expertise and innovation artificial intelligence of in the field. In this paper, we propose a novel architecture with multi-track encoder for multi-decoder network. Furthermore, we present a novel music dataset specifically designed for string quartet compositions. Experimental results demonstrate that our architecture is capable of generating very rich musical compositions.},
  keywords={Technological innovation;Memory architecture;Asia;Music;Information processing;Artificial intelligence;Long short term memory},
  doi={10.1109/APSIPAASC58517.2023.10317246},
  ISSN={2640-0103},
  month={Oct},}@INPROCEEDINGS{10941020,
  author={Nabil, Rahat Morshed and Kundu, Tarunnyamoye},
  booktitle={2024 IEEE International Conference on Signal Processing, Information, Communication and Systems (SPICSCON)}, 
  title={Enhanced YOLOv9-Based Endangered Tiger Detection Framework for Wildlife Surveillance}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Tiger conservation requires integrating diverse strategies, including preserving natural habitats, stringent anti-poaching efforts, and active community participation to ensure sustainable tiger population growth. The emergence of artificial intelligence presents an opportunity to enhance tiger surveillance through automated object detection. This paper introduces a robust, illumination-invariant framework that leverages Enlight-enGAN and the advanced YOLOv9c model for detecting Amur tigers. The fine-tuned YOLOv9c model, coupled with illumination enhancement techniques, achieves an impressive mAP50-95 score of 71.2% and an mAP50 score of 98.7% on the ATRW dataset. This approach significantly advances the state-of-the-art in tiger detection and highlights the potential of AI -driven solutions in wildlife conservation.},
  keywords={Deep learning;Accuracy;Surveillance;Wildlife;Habitats;Lighting;Object detection;Signal processing;Robustness;Artificial intelligence;Deep Learning;ATRW;Amur- Tiger;YOLOv9;Re-Identification;Wildlife Conservation},
  doi={10.1109/SPICSCON64195.2024.10941020},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10943021,
  author={Xylouris, George and Trakadas, Panagiotis and Giannopoulos, Anastasios and Nikolakakis, Vasileios and Patsourakis, Gerasimos and Gkonis, Panagiotis and Nomikos, Nikolaos and Mandilaris, Charilaos},
  booktitle={2024 IEEE 29th International Workshop on Computer Aided Modeling and Design of Communication Links and Networks (CAMAD)}, 
  title={A Distributed Trustable AI Engine for Anomaly Detection in 6G Networks: Architecture, Use Cases and Performance Evaluation}, 
  year={2024},
  volume={},
  number={},
  pages={01-06},
  abstract={The evolution towards sixth-generation (6G) networks requires new architecture enhancements to support the broad device ecosystem, comprising users, machines, autonomous vehicle and Internet-of-Things devices. Moreover, high heterogeneity in the desired Quality-of-Service (QoS) is expected, as 6G networks will offer extremely low-latency and high-throughput services and error-free communication. This complex environment raises significant challenges in resource management, while adhering to security and privacy constraints, due to the plethora of data generation endpoints. In this work, we present an artificial intelligence/machine learning (AI/ML)-aided distributed trustable engine (DTE), collecting data from diverse sources of the 6G infrastructure and employing AI/ML modules for anomaly detection against diverse threat types. Moreover, we present the DTE architecture and its components, providing data management, AI/ML model training and classification capabilities for anomaly detection. To promote privacy-aware networking, a federated learning (FL) framework to extend the DTE is discussed. Then, the anomaly detection capabilities of the AI/ML-aided DTE are presented in detail together with the ML model training process, considering various ML models. For this purpose, we use two open datasets, representing attack scenarios in the core and the edge parts of the network. It is shown that the AI/ML-aided DTE can efficiently train ML models with reduced dimensionality and deploy them in diverse cybersecurity scenarios to improve anomaly detection in 6G networks.},
  keywords={6G mobile communication;Training;Computational modeling;Quality of service;Computer architecture;Threat assessment;Resource management;Computer security;Anomaly detection;Engines;6G networks;anomaly detection;cybersecurity;machine learning;threat detection},
  doi={10.1109/CAMAD62243.2024.10943021},
  ISSN={2378-4873},
  month={Oct},}@INPROCEEDINGS{10278520,
  author={Rueb, Matthias and Herbst, Jan and Lipps, Christoph and Schotten, Hans Dieter},
  booktitle={Mobile Communication - Technologies and Applications; 27th ITG-Symposium}, 
  title={6G and the Sustainability Aspect: Exploiting Surplus Renewable Energy for Distributed Learning Clusters in 6G Networks}, 
  year={2023},
  volume={},
  number={},
  pages={139-144},
  abstract={Main design criteria within the development of 6G are sustainability and resource-efficient application. With advances in Artificial Intelligence (AI) methods towards increasingly larger and more complex Neural Network (NN) architectures, the question arises of how the ever-greater computational effort and the associated power consumption can be compatible with sustainability and environmental requirements. Therefore, in this work, the utilization of excess renewable energy sources to operate server clusters for the computation of AI in the context of autonomous processing in upcoming 6G frameworks is discussed. The current trend toward larger AI models and the necessity of collaborative work is highlighted. In particular, a vision of incorporating small-scale computational units via wireless communication into holistic collaborative schemes in upcoming wireless networks is presented. Since wind power is, analogous to solar energy unreliable and the production depends on natural factors, the requirements and challenges for existing frameworks are elaborated. In this context, synthetic data of the Baltic Eagle windfarm in the northeast of Germany is utilized to illustrate the energy fluctuations of surplus energy and then derive the requirements for predictive AI and cluster organization. For that purpose, a heuristic simulation framework is designed investigating the impact of prediction accuracy for server failure due to such fluctuations utilizing Autoregressive Integrated Moving Average (ARIMA) as a baseline for future research.},
  keywords={},
  doi={},
  ISSN={},
  month={May},}@INPROCEEDINGS{10725606,
  author={Jaiswal, Shruti and Gollapudi, Krishna Chaitanya and Susma, R},
  booktitle={2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Comprehensive Framework for Robustness evaluation on Numeric data classification}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={As its an era of Artificial Intelligence, and we have started relying on decisions made by machine in almost every domain. To do so, we need a framework on responsible AI which can help bring out better analytics on models’ decision. This paper presents a comprehensive framework for evaluating the robustness of classification models on numeric data. Robustness evaluation is crucial for ensuring model reliability in real-world applications where data distribution may vary. The framework encompasses a range of evaluation metrics and techniques tailored specifically for numeric data classification problems. It addresses challenges such as model sensitivity to data perturbations, generalization across diverse datasets, and performance under adversarial conditions. We have built a framework to analyze model’s behavior in most of the corner cases. Through extensive experimentation and analysis, the framework provides insights into model behavior, strengths, and weaknesses, aiding practitioners in selecting robust classification solutions for their applications. To evaluate the model, we have added data augmentation, counterfactual analysis, adversarial testing, randomized smoothing, and Out-of-distribution detection in the framework, so that we are able to do rigorous evaluation of any model. We have tested our framework on six different classification models working on six different datasets primarily on healthcare domain.},
  keywords={Analytical models;Smoothing methods;Sensitivity;Computational modeling;Perturbation methods;Data models;Robustness;Numerical models;Artificial intelligence;Testing;Robustness;responsible AI;adversarial testing;counterfactual analysis;randomized smoothing;out of distribution;classification;healthcare},
  doi={10.1109/ICCCNT61001.2024.10725606},
  ISSN={2473-7674},
  month={June},}@ARTICLE{10418906,
  author={Levine, Sergey and Hausman, Karol},
  journal={IEEE Spectrum}, 
  title={Using Big Data to Make Robots More Capable}, 
  year={2024},
  volume={61},
  number={2},
  pages={42-46},
  abstract={The generative AI revolution embodied in tools like ChatGPT, Midjourney, and many others is at its core based on a simple formula: Take a very large neural network, train it on a huge dataset scraped from the Web, and then use it to fulfill a broad range of user requests. Large language models (LLMs) can answer questions, write code, and spout poetry, while image-generating systems can create convincing cave paintings or contemporary art.},
  keywords={Codes;Generative AI;Neural networks;Big Data;Chatbots;Robots;Artificial intelligence;Mobile robots;Product design;Product development;Cognitive processes;Performance evaluation;Test equipment},
  doi={10.1109/MSPEC.2024.10418906},
  ISSN={1939-9340},
  month={February},}@INPROCEEDINGS{11131969,
  author={Pehar, Franjo},
  booktitle={2025 MIPRO 48th ICT and Electronics Convention}, 
  title={AI as Synthetic Users in Human-Centred Design: A Systematic Review}, 
  year={2025},
  volume={},
  number={},
  pages={1500-1509},
  abstract={In human-centred design (HCD), real users are the foundation of the design process, but ensuring their active involvement is often challenged by time, cost and resource constraints. Recent advances in artificial intelligence (AI) have introduced the concept of 'synthetic users' - AIdriven agents that simulate human participation in design and evaluation processes. This paper presents a systematic literature review of 52 peer-reviewed studies investigating how large language models (LLMs) and agent-based simulations function as synthetic users in different phases of HCD. Following PRISMA guidelines, we conducted structured searches in Web of Science and Scopus and applied inductive thematic analysis to group the studies into four main themes: (A) AI-generated personas and user profiles for user research; (B) AI support for ideation and prototyping; (C) simulated users for usability testing and evaluation; and (D) agent-based simulations for system validation and decision support. Our findings show that while synthetic users can significantly accelerate early design iterations and support creative exploration through rapid and scalable feedback, they also raise concerns about authenticity, variability, bias, and ethical validity. We examine these trade-offs and propose a hybrid evaluation model in which AI-driven techniques augment - without replacing - real user input, thereby preserving the fundamental role of real user insight in human-centred design.},
  keywords={Ethics;Humanities;Large language models;Human factors;Trajectory;Usability;System validation;Interviews;Systematic literature review;Testing;human-centred design (HCD);synthetic users;large language models (LLMs);user simulation;agent-based modelling;design evaluation},
  doi={10.1109/MIPRO65660.2025.11131969},
  ISSN={1847-3938},
  month={June},}@ARTICLE{10965578,
  author={Li, Zhenyu and Chen, Jianing and Zou, Zongfeng},
  journal={IT Professional}, 
  title={Bringing Personalization Back to E-Commerce via Virtual Live Streaming}, 
  year={2025},
  volume={27},
  number={2},
  pages={54-63},
  abstract={Virtual live streaming is widely regarded as the next frontier in e-commerce. Constrained by current hardware and technology limitations, this field remains a blue ocean. Traditional e-commerce has succeeded tremendously in the Web 2.0 era thanks to digital transformation and personalized recommendations. Live streaming has been proven to be a valuable tool for delivering an immersive and interactive experience. However, it has lost the essence of e-commerce: personalization. The recent explosion of artificial intelligence (AI)-generated content and “AI being” sheds light on this area. In this article, we consider virtual live streaming as a new transformation enabled by data and AI technologies that have the potential to reshape the e-commerce industry. As this evolution is incremental, we propose a system framework to support the development of virtual live streaming, ultimately bringing personalization back to marketing.},
  keywords={Electronic commerce;Virtual environments;Streaming media;Market opportunities;Digital transformation;Web 2.0},
  doi={10.1109/MITP.2025.3530768},
  ISSN={1941-045X},
  month={March},}
