@ARTICLE{10944292,
  author={Zhou, Longyu and Feng, Wenjiao and Chen, Zihan and Ruan, Tianchen and Leng, Supeng and Yang, Howard H. and Fu, Yaru and Quek, Tony Q. S.},
  journal={IEEE Vehicular Technology Magazine}, 
  title={Cooperative Generative AI for UAV-Based Scenarios: An Intelligent Cooperative Framework}, 
  year={2025},
  volume={20},
  number={2},
  pages={44-52},
  abstract={The Internet of Things (IoT) has been expediting unmanned aerial vehicle (UAV) network autonomy for 5G and beyond applications. In this context, generative artificial intelligence (GAI) is widely applied to improve service efficiency. It can provide customized service decisions for diverse UAV requirements through deep learning. However, existing GAI solutions may fail to generalize well for mission-critical UAV scenarios due to dynamic changes in physical environments and limited computing resources. We propose a cooperative GAI framework to achieve a highly accurate and low-latency GAI implementation performance with a double-sized GAI manner. We first propose a model aggregation and splitting algorithm to acquire accurate large-sized GAI models by combining small-sized GAI models using a multimodal-based deep learning method. Then, we propose a model update algorithm to reduce the latency of GAI implementation for real-time service provisions. We demonstrate the effectiveness of our terminal-edge cooperative GAI framework using a case study of UAV-based target tracking. The results indicate that our solution ensures an accurate GAI implementation with a successful tracking ratio of up to 90% as well as a low system latency of under 2 s compared to the existing GAI pattern on average, respectively.},
  keywords={Computational modeling;Data models;Accuracy;Autonomous aerial vehicles;Adaptation models;Low latency communication;Training;Real-time systems;Target tracking;Image edge detection;Internet of Things;5G mobile communication;Generative AI},
  doi={10.1109/MVT.2025.3544817},
  ISSN={1556-6080},
  month={June},}@ARTICLE{10839236,
  author={Zhao, Changyuan and Du, Hongyang and Niyato, Dusit and Kang, Jiawen and Xiong, Zehui and Kim, Dong In and Shen, Xuemin and Letaief, Khaled B.},
  journal={IEEE Wireless Communications}, 
  title={Enhancing Physical Layer Communication Security Through Generative AI with Mixture of Experts}, 
  year={2025},
  volume={32},
  number={3},
  pages={176-184},
  abstract={AI technologies have become increasingly adopted in wireless communications. As an emerging type of AI technologies, generative artificial intelligence (GAI) is gaining attention in communication security. Due to its powerful learning ability, GAI models have demonstrated superiority over conventional AI methods. However, GAI still has several limitations, including high computational complexity and limited adaptability. Mixture of experts (MoE) technology, which uses multiple expert models for prediction through a gate mechanism, proposes possible solutions. In this article, we first review GAI model applications in physical layer communication security, discuss limitations, and explore how MoE can help GAI overcome these limitations. Furthermore, we propose an MoE-enabled GAI framework for network optimization problems for communication security. To demonstrate the framework's effectiveness, we provide a case study in a cooperative-friendly jamming scenario. The experimental results show that the MoE-enabled framework effectively assists the GAI algorithm, solves its limitations, and enhances communication security.},
  keywords={Wireless communication;Adaptation models;Generative AI;Computational modeling;Physical layer;Safety;Security;Jamming;Optimization},
  doi={10.1109/MWC.001.2400150},
  ISSN={1558-0687},
  month={June},}@INPROCEEDINGS{11117791,
  author={Cheng, Guoli and Shang, Jingwei and Yun, Lei and Ma, Yanjiao and Du, Linfeng},
  booktitle={2024 6th International Academic Exchange Conference on Science and Technology Innovation (IAECST)}, 
  title={Fuzz Testing of Vehicle CAN Bus Based on Sequence Generative Adversarial Network}, 
  year={2024},
  volume={},
  number={},
  pages={2095-2099},
  abstract={With the rapid development of advanced technologies such as artificial intelligence, computer vision, and image processing, modern cars have evolved from traditional transportation into new intelligent terminals, but the demand for safety and reliability remains unchanged. As the basic network for internal communication in vehicles, the CAN bus is the key targets of malicious attacks. Once invaded, it will cause serious security issues. Fuzz testing is an essential method for assessing the security level of CAN bus, which identifies CAN bus weaknesses and vulnerabilities at an early stage. However, in practical scenarios, it will face problems such as data explosion and protocol reverse difficulty. This paper proposes a fuzz testing approach based on sequence generative adversarial network (SeqGAN), which employs the dynamic game between the generator and the discriminator to extract the global features of the protocol for bypassing reverse parsing. In this way, the proposal can generate high-quality test data without communication matrix, which improve test efficiency significantly. Experimental results show that our approach is superior to the current mainstream solutions in terms of testing input pass and vulnerability mining.},
  keywords={Protocols;Transportation;Fuzzing;Generative adversarial networks;Feature extraction;Generators;Explosions;Proposals;Vehicle dynamics;Testing;Vehicle Cybersecurity;CAN bus;Fuzz testing;adversarial learning},
  doi={10.1109/IAECST64597.2024.11117791},
  ISSN={},
  month={Dec},}@ARTICLE{11152696,
  author={Zhang, Jifa and Sheng, Min and Liu, Junyu and Zhao, Nan and Wang, Xianbin},
  journal={IEEE Communications Magazine}, 
  title={Generative AI-Enabled Integrated Sensing and Communication}, 
  year={2025},
  volume={63},
  number={9},
  pages={44-50},
  abstract={Integrated sensing and communication (ISAC) is an effective technique to enable both conventional communications and new capabilities by sharing spectrum resources and hardware platform, thus facilitating diverse vertical applications. Nevertheless, ISAC usually requires complex system design and signal processing to achieve the integration gain. Recently, generative artificial intelligence (GAI) has showcased its remarkable capability of digital content generation and data processing, which is expected to enable the ISAC from diverse perspectives. In this article, we first overview the ISAC and GAI, and discuss the motivation of introducing GAI to ISAC. Subsequently, we investigate both the direct and indirect applications of GAI for ISAC with the focus on the system modeling, data processing and decision making. Subsequently, we propose a GAI-enhanced deep reinforcement learning algorithm for the beamforming design in the double reconfigurable intelligent surface (RIS)-aided ISAC. The superiority of the proposed algorithm over benchmarks is verified via simulation. Finally, open research challenges are discussed.},
  keywords={Array signal processing;Generative AI;Decision making;Signal processing algorithms;Systems modeling;Reconfigurable intelligent surfaces;Integrated sensing and communication;Data processing;Deep reinforcement learning;Hardware},
  doi={10.1109/MCOM.001.2400746},
  ISSN={1558-1896},
  month={Sep.},}@INPROCEEDINGS{10903609,
  author={Mehrabi, A. and Nejad, D. A. and Jahani, A. and Rezaei, A. and Khalilpour, S. A. and Seyedi, H. Kh. and Taghirad, H. D.},
  booktitle={2024 12th RSI International Conference on Robotics and Mechatronics (ICRoM)}, 
  title={Variational Autoencoders: Tackling Imbalanced Data through Generative Modeling}, 
  year={2024},
  volume={},
  number={},
  pages={388-393},
  abstract={With the advancement of artificial intelligence models, the challenge of working with real-world data has become increasingly important in fields such as computer vision, autonomous vehicles, medical and forecasting. Among them, the issue of imbalanced data in real datasets is very crucial. While the capabilities of Variational Autoencoders (VAEs) have been introduced in various fields, this study is the first to leverage VAE as a powerful tool to tackle the challenge of imbalanced data in real-world scenarios. In this study, a cluster-based oversampling model based on VAE is introduced. Following the formation of the latent space during training and learning the data distribution, VAE is employed to generate synthetic data and balance the dataset based on the learned parameters. This model has been implemented on a real-world imbalanced dataset that we have developed, and it is shown it well outperforms traditional oversampling methods and Generative Adversarial Network (GAN) in all evaluation rubrics. Additionally, this model has significantly lower computational costs. Given these advantages, the proposed model is very promising to be harnessed in different fields that are encountering imbalanced data challenges.},
  keywords={Training;Computer vision;Runtime;Computational modeling;Autoencoders;Predictive models;Generative adversarial networks;Data models;Forecasting;Synthetic data;Variational Autonencoders;Class imbalance;Oversampling;GAN;Clustering},
  doi={10.1109/ICRoM64545.2024.10903609},
  ISSN={2572-6889},
  month={Dec},}@INPROCEEDINGS{11127765,
  author={Biancucci, Massimiliano and Galdelli, Alessandro and Narang, Gagan and Pietrini, Rocco and Mancini, Adriano and Zingaretti, Primo},
  booktitle={2025 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={COIGAN: Controllable Object Inpainting Through Generative Adversarial Network for Defect Synthesis in Data Augmentation}, 
  year={2025},
  volume={},
  number={},
  pages={9046-9052},
  abstract={Predictive maintenance is a key aspect for the safety of critical infrastructure such as bridges, dams, and tunnels, where a failure can lead to catastrophic outcomes in terms of human lives and costs. The surge in Artificial Intelligence-driven visual robotic inspection methods necessitates high-quality datasets containing diverse defect classes with several instances on different conditions (e.g., material, illumination). In this context, we introduce a Controllable Object Inpainting Generative Adversarial Network (COIGAN) to synthetically generate realistic images that augment defect datasets. The effectiveness of the model is quantitatively validated by a Fréchet Inception Distance, which measures the similarity between the generated and training samples. To further evaluate the impact of COIGAN-generated images, a segmentation task was conducted, utilizing key performance metrics such as segmentation accuracy, mAP, mIoU, and F1 score, demonstrating that the synthetic images integrate seamlessly and produce results comparable to real defect images. Subsequently, COIGAN generability was successfully used for the segmentation of a defect-free dataset by inpainting defects. The results showcase COIGAN's ability to learn defect patterns and apply them in new contexts, preserving the original features of the base image and allowing the creation of new datasets with a desired multi-class distribution. Specifically, in the context of predictive maintenance, COIGAN enriches datasets, enabling deep learning models to more effectively identify potential infrastructure anomalies. Project page: https://bit.ly/4bzxwqf.},
  keywords={Training;Image segmentation;Visualization;Predictive models;Generative adversarial networks;Performance metrics;Safety;Surges;Robots;Predictive maintenance},
  doi={10.1109/ICRA55743.2025.11127765},
  ISSN={},
  month={May},}@INPROCEEDINGS{10067042,
  author={Kacker, Tanmay and Perrusquia, Adolfo and Guo, Weisi},
  booktitle={2023 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Multi-Spectral Fusion using Generative Adversarial Networks for UAV Detection of Wild Fires}, 
  year={2023},
  volume={},
  number={},
  pages={182-187},
  abstract={Wild fires are now increasingly responsible for immense ecological damage. Unmanned aerials vehicles (UAVs) are being used for monitoring and early-detection of wild fires. Recently, significant research has been conducted for using Deep Learning (DL) vision models for fire and smoke segmentation. Such models predominantly use images from the visible spectrum, which are operationally prone to large false-positive rates and sub-optimal performance across environmental conditions. In comparison, fire detection using infrared (IR) images has shown to be robust to lighting and environmental variations, but long range IR sensors remain expensive. There is an increasing interest in the fusion of visible and IR images since a fused representation would combine the visual as well as thermal information of the image. This yields significant benefits especially towards reducing false positive scenarios and increasing robustness of the model. However, the impact of fusion of the two spectrum on the performance of fire segmentation has not been extensively investigated. In this paper, we assess multiple image fusion techniques and evaluate the performance of a U-Net based segmentation model on each of the three image representations - visible, IR and fused. We also identify subsets of fire classes that are observed to have better results using the fused representation.},
  keywords={Image segmentation;Visualization;Biological system modeling;Fires;Lighting;Infrared image sensors;Image representation;fire detection;deep learning;UAV;drone;GAN},
  doi={10.1109/ICAIIC57133.2023.10067042},
  ISSN={2831-6983},
  month={Feb},}@ARTICLE{8528524,
  author={Wu, Shuang and Li, Guoqi and Deng, Lei and Liu, Liu and Wu, Dong and Xie, Yuan and Shi, Luping},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={ $L1$ -Norm Batch Normalization for Efficient Training of Deep Neural Networks}, 
  year={2019},
  volume={30},
  number={7},
  pages={2043-2051},
  abstract={Batch normalization (BN) has recently become a standard component for accelerating and improving the training of deep neural networks (DNNs). However, BN brings in additional calculations, consumes more memory, and significantly slows down the training iteration. Furthermore, the nonlinear square and sqrt operations in the normalization process impede low bit-width quantization techniques, which draw much attention to the deep learning hardware community. In this paper, we propose an  $L1$ -norm BN (L1BN) with only linear operations in both forward and backward propagations during training. L1BN is approximately equivalent to the conventional  $L2$ -norm BN (L2BN) by multiplying a scaling factor that equals  $({\pi }/{2})^{1/2}$ . Experiments on various convolutional neural networks and generative adversarial networks reveal that L1BN can maintain the same performance and convergence rate as L2BN but with higher computational efficiency. In real application-specified integrated circuit synthesis with reduced resources, L1BN achieves 25% speedup and 37% energy saving compared to the original L2BN. Our hardware-friendly normalization method not only surpasses L2BN in speed but also simplifies the design of deep learning accelerators. Last but not least, L1BN promises a fully quantized training of DNNs, which empowers future artificial intelligence applications on mobile devices with transfer and continual learning capability.},
  keywords={Training;Convergence;Convolution;Standards;Acceleration;Gaussian distribution;Neural networks;Batch normalization (BN);deep neural network (DNN);discrete online learning;  $L1$    -norm;mobile intelligence},
  doi={10.1109/TNNLS.2018.2876179},
  ISSN={2162-2388},
  month={July},}@ARTICLE{11071306,
  author={Ahmed, Zeeshan and Munir, Kashif and Usama Tanveer, Muhammad and Hassan, Syed Rizwan and Ur Rehman, Ateeq and Hamam, Habib},
  journal={IEEE Access}, 
  title={Deep Pseudogene Categorization and Genome-Wide Transcription Prediction Using GANP-Based Feature Selection and TabNet Interpretability}, 
  year={2025},
  volume={13},
  number={},
  pages={118096-118111},
  abstract={Pseudogenes, once regarded as genomic relics, have emerged as critical regulators of gene expression, influencing cancer, neurodegenerative disorders, and developmental processes. This study introduces an advanced framework for pseudogene classification, leveraging deep learning to address the challenges of large-scale transcriptomic analysis. The proposed approach integrates an autoencoder for dimensionality reduction, a conditional generative adversarial network (cGAN) for synthetic data generation, and a TabNet classifier for final prediction. Extensive literature on pseudogenes highlights their interaction with coding genes, non-coding RNAs, and epigenetic mechanisms, which are pivotal in transcriptional and post-transcriptional regulation. The pipeline uses SMOTE to mitigate class imbalance and applies synthetic feature augmentation to boost classification performance. Tested on a large-scale curated transcriptomic dataset, our framework achieves an accuracy of 96%, surpassing traditional machine learning models. Visualization tools such as t-SNE, heatmaps, and SHAP plots further enhance model interpretability. The system is fully implemented on accessible AI platforms (Google Colab, Kaggle), ensuring real-time simulation and reproducibility, especially for research teams with limited computational resources. This method offers a scalable, explainable solution for pseudogene identification and non-coding RNA characterization, with broad applications in cancer research, genome annotation, and precision transcriptomics. The results underscore the power of deep learning and generative models in unveiling the regulatory complexity of pseudogenes, contributing to future genomic studies and clinical precision medicine. Additionally, a user-friendly Gradio interface has been developed, enabling interactive exploration and prediction of pseudogene classes, providing a practical tool for biologists and clinicians alike.},
  keywords={Bioinformatics;Genomics;Feature extraction;Deep learning;Biological system modeling;Autoencoders;Data models;Accuracy;Computational modeling;Annotations;Pseudogene classification;transcriptome analysis;explainable artificial intelligence;deep learning;bioinformatics;AI tools},
  doi={10.1109/ACCESS.2025.3585601},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10581531,
  author={Xi, Sicheng and Peng, Yanhui},
  booktitle={2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={Interpretability Research of Variational Autoencoder Generation Process Based on Feature Disentanglement}, 
  year={2024},
  volume={},
  number={},
  pages={157-163},
  abstract={Variational Autoencoder (VAE), as one of the main generative models, has a powerful representation learning capability. However, the hidden space representation learned by VAE is a high-dimensional and complex vector space, which makes it difficult to explain how the model gradually learns and composes the final generated results on different semantic features. To address this problem, firstly, this paper increases the degree of decoupling between different semantic features by increasing the independence between the hidden variables of the modal hermitian space, and explains the learning process of the model on different hermitian spaces by visualization based on the feature decoupling model. In addition, this paper also proposes a hidden variable contribution index to measure the influence of different dimensional hidden variables on the generation results, so as to explain the learning process of the model.},
  keywords={Training;Seminars;Representation learning;Visualization;Correlation;Semantics;Vectors;VAE;Disentanglement;Interpretability},
  doi={10.1109/AINIT61980.2024.10581531},
  ISSN={},
  month={March},}@INPROCEEDINGS{9764188,
  author={Charlish, Alexander and Schwalm, Carolin},
  booktitle={2022 IEEE Radar Conference (RadarConf22)}, 
  title={Generating NLFM Radar Waveforms using Variational Autoencoders}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={The rapid synthesis of radar waveform modulations is key to enabling a radar to react to the environment in order to optimize performance. This paper proposes the use of generative models for radar waveform generation. Specifically, variational autoencoders (VAEs) comprising neural networks that are trained with a novel reconstruction loss are proposed. It is shown for simple classes of non-linear FM waveforms that the decoder from the proposed VAE can generate new radar waveform modulations that possess required ambiguity function characteristics, even though they were not represented in the training data.},
  keywords={Frequency modulation;Navigation;Conferences;Neural networks;Training data;Radar;Radar imaging;Waveform diversity;cognitive radar;radar waveform synthesis;generative models;variational autoencoder;neural networks;machine learning;artificial intelligence},
  doi={10.1109/RadarConf2248738.2022.9764188},
  ISSN={},
  month={March},}@INPROCEEDINGS{5423207,
  author={Song, Qingsong and Feng, Zuren},
  booktitle={2009 IEEE International Symposium on Computational Intelligence in Robotics and Automation - (CIRA)}, 
  title={Stable trajectory generator-echo state network trained by particle swarm optimization}, 
  year={2009},
  volume={},
  number={},
  pages={21-26},
  abstract={Recurrent neural networks (RNNs) have good modeling capability for nonlinear dynamic systems, but due to the difficulties for training this superiority is discounted. Echo state network (ESN) is a new paradigm for using RNNs with a simpler training method, where an RNN is generated randomly and only a readout is trained. ESN method has quickly become popular in robotics, such as for motor control, for navigation. However, the classical training method for ESNs can not ensure the dynamics asymptotic stability if the trained ESNs run in a closed-loop self-generative mode. The reason is analyzed at first. We then consider the ESN training problem as an optimization problem with a nonlinear constraint, and take a particle swarm optimization (PSO) algorithm solve it. In our simulation experiments, the ESNs are trained as ¿figure-eight¿ trajectory generators. The results show that the proposed PSO-based training method can effectively ensure the dynamics asymptotic stability as well as the precision of generating trajectories of the trained ESNs.},
  keywords={Particle swarm optimization;Recurrent neural networks;Asymptotic stability;Systems engineering and theory;Backpropagation algorithms;Mobile robots;Noise robustness;Output feedback;Navigation;Manufacturing systems;Echo state networks;particle swarm optimization;recurrent neural networks;asymptotic stability},
  doi={10.1109/CIRA.2009.5423207},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8455664,
  author={Ferrin, Giovanni and Snidaro, Lauro and Foresti, Gian Luca},
  booktitle={2018 21st International Conference on Information Fusion (FUSION)}, 
  title={Describing Capability Through Lexical Semantics Exploitation: Foundational Arguments}, 
  year={2018},
  volume={},
  number={},
  pages={1-5},
  abstract={In everyday life as well as in asymmetric warfare domain, to achieve the intended goals, agents often do not make use of the designed and purpose-built tools, but some other tools whose features simply fit for the purpose. The present paper discusses the possibility of capturing and integrating relations and features from context that could drive the retrieval of possible candidate substitutes for the properly designed artifacts through Lexical Semantics Exploitation. Generative Lexicon theory assumes a structure (Qualia Structure) organizing the semantic content carried by lexical items through roles. Among them, the Telic role exposes the function or purpose of the predicated entity and the Constitutive role exposes its component parts. We argue that the typical function an entity has been thought for is related to its internal constituents. We also argue that a knowledge base and a proper metrics can be conveniently built extracting Qualia elements from suitable text corpora.},
  keywords={Semantics;Tools;Ontologies;Linguistics;Biology;Blades;Natural Language;Generative Lexicon;Distributed Memory;Artificial Intelligence},
  doi={10.23919/ICIF.2018.8455664},
  ISSN={},
  month={July},}@INPROCEEDINGS{9805400,
  author={Cobb, Adam and Roy, Anirban and Elenius, Daniel and Jha, Susmit},
  booktitle={2022 IEEE Workshop on Design Automation for CPS and IoT (DESTION)}, 
  title={Trinity AI Co-Designer for Hierarchical Oracle-guided Design of Cyber-Physical Systems}, 
  year={2022},
  volume={},
  number={},
  pages={42-44},
  abstract={The design of complex cyber-physical systems entails satisfying several competing performance objectives. In practice, some design requirements are often implicit in the intuition and knowledge of designers who have many years of experience working with similar designs. Designers use this experience to sample a few promising candidates in the design space and evaluate or simulate them using detailed, typically slow scientific models. The goal in design is usually to generate a diverse set of high-performing design configurations that allow trade-offs across different objectives and avoid early concretization. In this paper, we present a demonstration of Trinity AI co-designer that implements a machine learning approach to automate some aspects of system design. Trinity implements an extension of oracle-guided inductive synthesis, where the learning approaches interact with a hierarchy of oracles that range from detailed slow-to-evaluate scientific models to fast but low fidelity deep neural network surrogate models and symbolic rules. The goal is to enable fast design iterations for earlier phases of design. Trinity uses deep generative models to learn a manifold of the valid design space, followed by a joint exploration and optimization of designs over the learned manifold, producing a diverse set of optimal designs with respect to given design objectives. In our demonstration, we will use several case studies including the design of propellers, a ground vehicle, air vehicle and underwater vehicle. Across these case studies, we successfully show how our method generates high-performing and diverse designs.},
  keywords={Manifolds;Uncertainty;Design automation;Propellers;Neural networks;Cyber-physical systems;Land vehicles;Synthesis;Design;Machine Learning;Generative Modeling;Neurosymbolic Artificial Intelligence;Uncertainty Quantification},
  doi={10.1109/DESTION56136.2022.00013},
  ISSN={},
  month={May},}@INPROCEEDINGS{10847487,
  author={B, Venkata Sai Laxman and Kulkarni, Sanat Shantanu and Hareesh, Beecha Venkata Naga and Enduri, Murali Krishna},
  booktitle={2024 IEEE 16th International Conference on Computational Intelligence and Communication Networks (CICN)}, 
  title={Explainable Depression Detection in Social Media Using Transformer-Based Models: A Comparative Analysis of Machine Learning}, 
  year={2024},
  volume={},
  number={},
  pages={321-325},
  abstract={The growing use of online platforms like Twitter and Reddit has created new opportunities in the field of mental health by enabling the analysis of language patterns in user-generated content. This study explores how transformer-based models such as Bidirectional Encoder Representations from Transformers (BERT), Generative Pre-trained Transformer (GPT-2), Robustly Optimized BERT Approach (RoBERTa), and Term Frequency-Inverse Document Frequency (TF-IDF) for text feature matrices can be applied to detect depressive symptoms in social media posts. The study utilizes machine learning algorithms, including Logistic Regression (LR), Random Forest, Support Vector Machine (SVM), Decision Tree, Naive Bayes, Multi-Layer Perceptron (MLP), and XGBoost, to improve the detection of depression-related markers in textual data. By leveraging annotated datasets specifically focused on depression, these models are trained to identify depression indicators in the language used by social media users. We employ supervised learning techniques to enhance model performance across various platforms, aiming to achieve greater accuracy and generalizability.},
  keywords={Support vector machines;Analytical models;Social networking (online);Computational modeling;User-generated content;Bidirectional control;Transformers;Depression;Encoding;Bayes methods;Transformer Models;Machine Learning;XGBoost;Navi Bayes;binary Classification;Explainable Depression Detection in Social Media Analysis;Depression detection},
  doi={10.1109/CICN63059.2024.10847487},
  ISSN={2472-7555},
  month={Dec},}@INPROCEEDINGS{10866520,
  author={Patil, AaditYa and Bendale, Yash and Bhangare, Prathamesh and Patil, Siddhasen},
  booktitle={2024 4th International Conference on Ubiquitous Computing and Intelligent Information Systems (ICUIS)}, 
  title={OdinEye: An AI Based Visual Assistive Device for the Blind and Partially Sighted}, 
  year={2024},
  volume={},
  number={},
  pages={158-163},
  abstract={Vision impairment is a significant global challenge, with over 2.2 billion people affected by near or distance vision impairment, and 36 million experiencing complete blindness. Many of these cases remain unaddressed, despite technological advancements. Existing solutions often fall short of providing comprehensive assistance due to limitations in adaptability and precision. To address this gap, this work proposes OdinEye, an AI-based visual assistive system designed to support individuals with blindness or severe visual impairment. By leveraging cutting-edge generative AI, OdinEye aims to offer a more versatile and personalized solution. The system integrates advanced components, including the Gemini API to enhance real-time object detection, navigation assistance, and environment interpretation, empowering users with greater independence and safety.},
  keywords={Performance evaluation;Visualization;Text recognition;Visual impairment;Blindness;Cameras;Ubiquitous computing;Real-time systems;Text to speech;Sensors;Visual Impairment;Assistive Technology;Artificial Intelligence (AI);Generative AI;OdinEye;Object Detection;Navigation Assistance;Real-Time Assistance;Blindness Solutions;Computer Vision;Accessibility;Visual Assistive Devices;AI for Accessibility},
  doi={10.1109/ICUIS64676.2024.10866520},
  ISSN={},
  month={Dec},}@ARTICLE{9420733,
  author={Zhou, Yun-Feng and Xie, Kai and Zhang, Xin-Yu and Wen, Chang and He, Jian-Biao},
  journal={IEEE Access}, 
  title={Efficient Traffic Accident Warning Based on Unsupervised Prediction Framework}, 
  year={2021},
  volume={9},
  number={},
  pages={69100-69113},
  abstract={Recognizing potentially hazardous objects is crucial in the field of transportation, especially in assisted and unmanned driving. However, most existing studies do not focus on defensive driving as they only identify accidents ahead of the vehicle in which they are not involved. In this paper, a driving assistance system is proposed to predict the risk score of potential targets ahead of the vehicle and provide an early warning, which relies on a deep architecture called Fusion-Residual Predictive Network (FRPN) that fused multi-scale residual features and improved adversarial learning. This architecture provides an environment for the generator to perform joint learning from ground-truth images and discriminators with gradient penalty constraints. The deeper convolutional neural network can greatly improve the quality of the image by fusing residual features. Several deep convolutional neural network models were used to evaluate the method on various datasets; among them, the prediction model based on the VGG network, with peak signal-to-noise ratio of 32.67 and structural similarity index of 0.921, respectively, yielded the best results. Subsequently, we utilize the tracking model to design a risk score evaluation method based on the location of the target and it have an improvement in ability to give early warning with 1.95s earlier in the best case. These results prove that our method can effectively reduce the risk of traffic accidents.},
  keywords={Accidents;Predictive models;Target tracking;Prediction algorithms;Generative adversarial networks;Dynamics;Automobiles;Generative adversarial network;video prediction;recurrent neural network;convolution neural network;object tracking;traffic warning;unsupervised learning;risk score assessment},
  doi={10.1109/ACCESS.2021.3077120},
  ISSN={2169-3536},
  month={},}@ARTICLE{9606863,
  author={Ferreira, Francisco and Lourenço, Nuno and Cabral, Bruno and Fernandes, João Paulo},
  journal={IEEE Access}, 
  title={When Two are Better Than One: Synthesizing Heavily Unbalanced Data}, 
  year={2021},
  volume={9},
  number={},
  pages={150459-150469},
  abstract={Nowadays, data is king and if treated and used properly it promises to give organizations a competitive edge over rivals by enabling them to develop and design Intelligent Systems to improve their services. However, they need to fully comply with not only ethical but also regulatory obligations, where, e.g., privacy (strictly) needs to be respected when using or sharing data, thus protecting both the interests of users and organizations. Fraud Detection systems are examples of such systems where Machine Learning algorithms leverage information to classify financial transactions as legitimate or illicit. The data used to create these solutions is usually highly structured and contains categorical and continuous features characterised by complex distributions. One of the main challenges of fraud detection is concerned with the scarcity of fraudulent instances which results in highly unbalanced datasets. Additionally, privacy is crucial, and it is usually forbidden, or not possible, to share the data of organizations and individuals for creating or improving models.In this paper we propose a framework for private data sharing based on synthetic data generation using Generative Adversarial Networks (GAN) that learns the specificities of financial transactions data and generates fictitious data that keeps the utility of the original datasets. Our proposal, called Duo-GAN, uses two GAN generators to handle the data imbalance problem, one generator for fraudulent instances and the other for legitimate instances. With this approach, we observed, at most, a 5% disparity in F1 scores between classifiers trained and tested with actual data and the ones trained with synthetic data and tested with actual data.},
  keywords={Data models;Generative adversarial networks;Data privacy;Generators;Image synthesis;Feeds;Training;Fraud detection;generative adversarial networks;privacy;machine learning;synthetic data generation;tabular data},
  doi={10.1109/ACCESS.2021.3126656},
  ISSN={2169-3536},
  month={},}@ARTICLE{9744609,
  author={Kim, Sihwan},
  journal={IEEE Access}, 
  title={A Virtual Knowledge Distillation via Conditional GAN}, 
  year={2022},
  volume={10},
  number={},
  pages={34766-34778},
  abstract={Knowledge distillation aims at transferring the knowledge from a pre-trained complex model, called teacher, to a relatively smaller and faster one, called student. Unlike previous works that transfer the teacher’s softened distributions or feature spaces, in this paper, we propose a novel approach, called Virtual Knowledge Distillation (VKD), that transfers a softened distribution generated by a virtual knowledge generator conditioned on class label. A virtual knowledge generator is trained independently, but concurrently with a teacher, to mimic the teacher’s softened distributions. Afterwards, when training a student, virtual knowledge generator can be exploited instead of the teacher’s softened distributions or combined with the existing distillation methods in a straightforward manner. Moreover, with slight modifications, VKD can be utilized not only for the self-knowledge distillation method but also for the collaborative learning method. We compare our method with several representative distillation methods in various combinations of teacher and student architectures on the image classification tasks. Experimental results on various image classification tasks demonstrate that VKD show a competitive performance compared to the conventional distillation methods, and when combined with them, the performance is improved with a substantial margin.},
  keywords={Training;Generators;Knowledge engineering;Bridges;Generative adversarial networks;Task analysis;Collaborative work;Image classification;model compression;knowledge distillation;self-knowledge distillation;collaborative learning;conditional generative adversarial network},
  doi={10.1109/ACCESS.2022.3163398},
  ISSN={2169-3536},
  month={},}@ARTICLE{8704221,
  author={Lee, Sukhan and Islam, Naeem Ul},
  journal={IEEE Access}, 
  title={Robust Image Translation and Completion Based on Dual Auto-Encoder With Bidirectional Latent Space Regression}, 
  year={2019},
  volume={7},
  number={},
  pages={58695-58703},
  abstract={Automated image translation and completion is a subject of keen interest due to their impact on image representation, interpretation, and enhancement. To date, a conditional or a dual adversarial framework with a convolutional auto-encoder embedded as a generator is known to offer the best accuracy in image translation. However, although the frequency is excellent, the adversarial framework may suffer from a lack of generality, i.e., the accuracy drops when translating incomplete and corrupted data given as untrained noisy input data. This paper proposes an approach to robust image-to-image translation that offers a high level of generality while keeping accuracy high as well. The proposed approach is referred to here as a dual auto-encoder with bidirectional latent space regression or Bi-directionally Associative DualAE, for short. The proposed BA-DualAE is configured with two auto-encoders the individual latent spaces of which are tightly associated by a bidirectional regression network. Once the two auto-encoders are trained independently for their respective domains, and then, the bidirectional regression network is trained to learn the general association between data pairs. With its capability of robust and bidirectional image translation, BA-DualAE performed direct image completion with no iterative search. The experiments with photo-sketch datasets demonstrated that the proposed BA-DualAE is highly robust under incomplete or corrupted data conditions and is far superior to adversarial frameworks in terms of generality and robustness.},
  keywords={Generative adversarial networks;Gallium nitride;Bidirectional control;Training;Noise measurement;Image reconstruction;Three-dimensional displays;Convolutional neural network;auto-encoder;bidirectional latent space regression;image-to-image translation;generative adversarial network},
  doi={10.1109/ACCESS.2019.2914273},
  ISSN={2169-3536},
  month={},}@ARTICLE{10443404,
  author={Wang, Haitao and Dai, Xiyang and Shi, Lichen and Li, Mingjun and Liu, Zelin and Wang, Ruihua and Xia, Xiaohua},
  journal={IEEE Access}, 
  title={Data-Augmentation Based CBAM-ResNet-GCN Method for Unbalance Fault Diagnosis of Rotating Machinery}, 
  year={2024},
  volume={12},
  number={},
  pages={34785-34799},
  abstract={In practical engineering scenarios, machines are seldom in a faulty operating state, so it is difficult to get enough available sample data to train the fault diagnosis model, leading to the problem of the small and unbalanced number of rotating machinery fault samples and low fault diagnosis accuracy. To solve this problem, this paper introduces a novel approach to machinery fault diagnosis. This approach involves the integration of a Convolutional Attention Residual Network (CBAM-ResNet) with a Graph Convolutional Neural Network (GCN). Firstly, to comprehensively exploit time-domain information from one-dimensional vibration signals, this study utilize Gram Angular Field (GAF) coding to transform traits of vibration signals into two-dimensional image characteristics. The resultant two-dimensional image is then expanded by applying the Wasserstein Distance Gradient Penalty Generation Adversarial Network (WGAN-GP) to produce a representative sample image. Secondly, the image is input to CBAM-ResNet to perform focused feature extraction and construct the feature matrix. Lastly, the adjacency matrix is derived through Graph Generation Layer (GGL); subsequently, the feature matrix and adjacency matrix are utilized as inputs for the GCN. After deep feature extraction, fault feature classification is executed via Softmax. Performance tests were conducted using the Case Western Reserve University bearing dataset and the planetary gearbox dataset. The method demonstrated remarkable results, achieving an accuracy of over 99% on the unbalanced dataset and surpassing 98% in 0dB noise compared to various other models. This illustrates the effectiveness and feasibility of the proposed method.},
  keywords={Feature extraction;Fault diagnosis;Vibrations;Machinery;Data models;Generative adversarial networks;Graph neural networks;Rotating machines;Attentional mechanism;fault diagnosis;gram angle difference field;generative adversarial network;graph neural network (GCN);rotating machinery},
  doi={10.1109/ACCESS.2024.3368755},
  ISSN={2169-3536},
  month={},}@ARTICLE{8778728,
  author={Bae, Seho and Ud Din, Nizam and Javed, Kamran and Yi, Juneho},
  journal={IEEE Access}, 
  title={Efficient Generation of Multiple Sketch Styles Using a Single Network}, 
  year={2019},
  volume={7},
  number={},
  pages={100666-100674},
  abstract={In the real world, different artists draw sketches of the same person with different artistic styles both in texture and shape. Our goal is to synthesize realistic face sketches of different styles while retaining the input face identity, only using a single network. To achieve this, we employ a modified conditional GAN with a target style label as input. Our method is capable of synthesizing multiple sketch styles even though it is based on a single network. Sketches created by our method show sketch quality comparable to the state-of-the-art sketch synthesis methods that use multiple networks.},
  keywords={Face;Generators;Gallium nitride;Training;Shape;Generative adversarial networks;Mathematical model;Generative adversarial network;face sketch synthesis},
  doi={10.1109/ACCESS.2019.2931544},
  ISSN={2169-3536},
  month={},}@ARTICLE{10540088,
  author={Trinh, Luan Thanh and Hamagami, Tomoki},
  journal={IEEE Access}, 
  title={Latent Denoising Diffusion GAN: Faster Sampling, Higher Image Quality}, 
  year={2024},
  volume={12},
  number={},
  pages={78161-78172},
  abstract={Diffusion models are emerging as powerful solutions for generating high-fidelity and diverse images, often surpassing GANs under many circumstances. However, their slow inference speed hinders their potential for real-time applications. To address this, DiffusionGAN leveraged a conditional GAN to drastically reduce the denoising steps and speed up inference. Its advancement, Wavelet Diffusion, further accelerated the process by converting data into wavelet space, thus enhancing efficiency. Nonetheless, these models still fall short of GANs in terms of speed and image quality. To bridge these gaps, this paper introduces the Latent Denoising Diffusion GAN, which employs pre-trained autoencoders to compress images into a compact latent space, significantly improving inference speed and image quality. Furthermore, we propose a Weighted Learning strategy to enhance diversity and image quality. Experimental results on the CIFAR-10, CelebA-HQ, and LSUN-Church datasets prove that our model achieves state-of-the-art running speed among diffusion models. Compared to its predecessors, DiffusionGAN and Wavelet Diffusion, our model shows remarkable improvements in all evaluation metrics. Code and pre-trained checkpoints: https://github.com/thanhluantrinh/LDDGAN.git.},
  keywords={Noise reduction;Image quality;Generative adversarial networks;Gaussian distribution;Image coding;Image synthesis;Image synthesis;Diffusion models;image generation;generative adversarial networks},
  doi={10.1109/ACCESS.2024.3406535},
  ISSN={2169-3536},
  month={},}@ARTICLE{8667297,
  author={Soeseno, Jonathan Hans and Tan, Daniel Stanley and Chen, Wen-Yin and Hua, Kai-Lung},
  journal={IEEE Access}, 
  title={Faster, Smaller, and Simpler Model for Multiple Facial Attributes Transformation}, 
  year={2019},
  volume={7},
  number={},
  pages={36400-36412},
  abstract={There are many existing models that are capable of changing hair color or changing facial expressions. These models are typically implemented as deep neural networks that require a large number of computations in order to perform the transformations. This is why it is challenging to deploy on a mobile platform. The usual setup requires an internet connection, where the processing can be done on a server. However, this limits the application's accessibility and diminishes the user experience for consumers with low internet bandwidth. In this paper, we develop a model that can simultaneously transform multiple facial attributes with lower memory footprint and fewer number of computations, making it easier to be processed on a mobile phone. Moreover, our encoder-decoder design allows us to encode an image only once and transform multiple times, making it faster as compared to the previous methods where the whole image has to be processed repeatedly for every attribute transformation. We show in our experiments that our results are comparable to the state-of-the-art models but with $4\times $ fewer parameters and $3\times $ faster execution time.},
  keywords={Computational modeling;Facial features;Generators;Gallium nitride;Generative adversarial networks;Transforms;Hair;Facial attribute transformations;generative adversarial networks;image translation},
  doi={10.1109/ACCESS.2019.2905147},
  ISSN={2169-3536},
  month={},}@ARTICLE{9333577,
  author={Wang, Hongyu and Huang, Mengxing and Wu, Di and Li, Yuchun and Zhang, Weichao},
  journal={IEEE Access}, 
  title={Supervised Video-to-Video Synthesis for Single Human Pose Transfer}, 
  year={2021},
  volume={9},
  number={},
  pages={17544-17556},
  abstract={In this paper, we focus on human pose transfer in different videos, i.e., transferring the dance pose of a person in given video to a target person in the other video. Our methods can be summed up in three stages to tackle this challenging scenario. Firstly, we extract the frames and pose masks from the source video and target video. Secondly, we use our model to synthesize the frames of target person with the given dance pose. Thirdly, we refine the generated frames to improve the quality of outputs. Our model is built on three stages: 1) human pose extraction and normalization. 2) a GAN based on cross-domain correspondence mechanism to synthesize dance-guided person image in target video by consecutive frames and pose stick images. 3) coarse-to-fine generation strategy which includes two GANs: a GAN used to reconstruct human face in target video, the other generates smoothing frame sequences. Finally, we compress the sequential frames generated from our model into video format. Compared with previous works, our model manifests better person appearance consistency and time coherence in video-to-video synthesis for human motion transfer, which makes the generated video look more realistic. The qualitative and quantitative comparisons represent our approach performs significant improvements over the state-of-the-art methods. Experiments on synthetic frames and ground truth validate the effectiveness of the proposed method.},
  keywords={Videos;Generators;Generative adversarial networks;Task analysis;Gallium nitride;Training;Skeleton;Generative adversarial network (GAN);image-to-image translation;video-to-video synthesis;pose-guided person image generation},
  doi={10.1109/ACCESS.2021.3053617},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9576815,
  author={Altakrouri, Saleh and Usman, Sahnius Bt and Ahmad, Norulhusna Binti and Justinia, Taghreed and Noor, Norliza Mohd},
  booktitle={2021 IEEE International Conference on Signal and Image Processing Applications (ICSIPA)}, 
  title={Image to Image Translation Networks using Perceptual Adversarial Loss Function}, 
  year={2021},
  volume={},
  number={},
  pages={89-94},
  abstract={Image to image translation based on deep learning models is a subject of immense importance in the disciplines of Artificial Intelligence (AI) and Computer Vision (CV). A variety of traditional tasks such as image colorization, image denoising and image inpainting, are categorized as typical paired image translation tasks. In computer vision, super-resolution regeneration is particularly important field. We proposed an improved algorithm to mitigate the issues that arises during the reconstruction using super resolution based on generative adversarial network. It is difficult to train in reconstruction of results. The generated images and the corresponding ground-truth images should share the same fundamental structure in order to output the required resultant images. The shared basic structure between the input and the corresponding output image is not as optimal as assumed for paired image translation tasks, which can greatly impact the generating model performance. The traditional GAN based model used in image-to-image translation tasks used a pre-trained classification network. The pre-trained networks perform well on the classification tasks compared to image translation tasks because they were trained on features that contribute to better classification. We proposed the perceptual loss based efficient net Generative Adversarial Network (PL-E-GAN) for super resolution tasks. Unlike other state of the art image translation models, the PL-E-GAN offers a generic architecture for image super-resolution tasks. PL-E-GAN is constituted of two convolutional neural networks (CNNs) that are the Generative network and Discriminator network Gn and Dn, respectively. PL-E-GAN employed both the generative adversarial loss and perceptual adversarial loss as objective function to the network. The integration of these loss function undergoes an adversarial training and both the networks Gn and Dn trains alternatively. The feasibility and benefits of the PL-E-GAN over several image translation models are shown in studies and tested on many image-to-image translation tasks},
  keywords={Training;Computer vision;Superresolution;Generative adversarial networks;Linear programming;Convolutional neural networks;Task analysis;Generative adversarial network;super-resolution;image-to-image translation;convolutional neural network;EfficientNet;perceptual loss},
  doi={10.1109/ICSIPA52582.2021.9576815},
  ISSN={2642-6471},
  month={Sep.},}@INPROCEEDINGS{10602454,
  author={Roseline, S. Abijah and Karthik, Saraf and Sruti, Immadi Naga Venkata Divya},
  booktitle={2024 International Conference on Advances in Computing, Communication and Applied Informatics (ACCAI)}, 
  title={Intelligent Human Anomaly Detection using LSTM Autoencoders}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Unsupervised deep learning techniques have emerged as powerful tools for detecting anomalies in human behavior patterns, offering a promising solution to the persistent challenge of securing sensitive information. This paper presents a novel approach to human anomaly detection utilizing a Convolutional Long Short-Term Memory (Conv-LSTM) Encoder-Decoder model. The proposed system addresses the critical need for accurate anomaly detection in diverse human activities such as surveillance, healthcare monitoring, and industrial safety. The Conv-LSTM Encoder-Decoder model is adept at learning spatiotemporal patterns in video sequences, enabling the detection of anomalous behaviors effectively. The model’s architecture incorporates convolutional layers to capture spatial information and LSTM layers to model temporal dependencies, facilitating robust anomaly detection. Experimental evaluation of the UCSD Anomaly Detection Dataset demonstrates the system’s capability to accurately identify anomalies while minimizing false positives. The proposed human anomaly detection system autonomously identifies deviations from normal human behavior without manual labeling, contributing to improved security and safety across diverse applications.},
  keywords={Surveillance;Video sequences;Medical services;Manuals;Behavioral sciences;Safety;Spatiotemporal phenomena;Unsupervised deep learning;Autoencoders;Anomaly detection;Human behavior},
  doi={10.1109/ACCAI61061.2024.10602454},
  ISSN={},
  month={May},}@ARTICLE{9363871,
  author={Hsu, Gee-Sern and Xie, Rui-Cang and Chen, Zhi-Ting},
  journal={IEEE Access}, 
  title={Wasserstein Divergence GAN With Cross-Age Identity Expert and Attribute Retainer for Facial Age Transformation}, 
  year={2021},
  volume={9},
  number={},
  pages={39695-39706},
  abstract={We propose the Wasserstein Divergence GAN with an identity expert and an attribute retainer for facial age transformation. The Wasserstein Divergence GAN (WGAN-div) can better stabilize the training and lead to better target image generation. The identity expert aims to preserve the input identity at output, and the attribute retainer aims to preserve the input attribute at output. Unlike the previous works which take a specific model for identity and attribute preservation without giving a reason, both the identity expert and the attribute retainer in our proposed model are determined from a comprehensive comparison study on the state-of-the-art pretrained models. The candidate networks considered for identity preservation include the VGG-Face, VGG-Face2, LightCNN and ArcFace. The candidate backbones for making the attribute retainer are the VGG-Face, VGG-Object and DEX networks. This study offers a guidebook for choosing the appropriate modules for identity and attribute preservation. The interactions between the identity expert and attribute retainer are also extensively studied and experimented. To further enhance the performance, we augment the data by the 3DMM and explore the advantages of the additional training on cross-age datasets. The additional cross-age training is validated to make the identity expert capable of handling cross-age face recognition. The performance of our approach is justified by the desired age transformation with identity well preserved. Experiments on benchmark databases show that the proposed approach is highly competitive to state-of-the-art methods.},
  keywords={Face recognition;Generative adversarial networks;Gallium nitride;Training;Aging;Feature extraction;Faces;Generative adversarial network;facial age transformation;face recognition},
  doi={10.1109/ACCESS.2021.3062499},
  ISSN={2169-3536},
  month={},}@ARTICLE{10040653,
  author={Tolcha, Yalew and Kim, Kyoung Hoon and Kim, Daeyoung},
  journal={IEEE Access}, 
  title={ImprovedSSGAN: Ranking Discriminator With Semi-Supervised GAN for Ordinal Information}, 
  year={2023},
  volume={11},
  number={},
  pages={13447-13455},
  abstract={We propose Improved SSGAN, a multi-Generator/Discriminator semi-supervised GAN architecture to address the well-known problem of mode collapse in addition to an improved classification for ordinal information. To reduce the vulnerability of the generator to a relatively superior discriminator, semi-supervised GAN was introduced to make the job of the discriminator tough. However, such architecture doesn’t solve the collapse problem where the generator is stuck generating some specific mode of the data. In this work, N-1 rank discriminators with two-dimensional outputs are proposed for ordinal information by applying rank estimation techniques. The first dimension in each discriminator is used to predict binary rank information which is aggregated to make the final prediction. The second dimension in each discriminator is independently used to train one or more generators where a collapse in any of the discriminators is supported by other discriminators. We have also extended the architecture to a conditioned generator where the output of one generator is fed into another, which improves image quality. Weight-sharing techniques among the discriminators have also shown a faster convergence during training. Through extensive experiments on age face data, we have demonstrated that Improved SSGAN outperforms the semi-supervised GAN both in image generation quality and age estimation.},
  keywords={Generators;Estimation;Data models;Generative adversarial networks;Training;Predictive models;Image generation;Ranking (statistics);Image generation;age estimation;ranking algorithms;semi-supervised classification;generative adversarial network (GAN)},
  doi={10.1109/ACCESS.2023.3243340},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10550620,
  author={Ghahremani, Ehsan and Joyce, Jeff and Lechner, Sid},
  booktitle={2024 Integrated Communications, Navigation and Surveillance Conference (ICNS)}, 
  title={Avoiding Confirmation Bias in a Safety Management System (SMS)}, 
  year={2024},
  volume={},
  number={},
  pages={1-11},
  abstract={Confidence in a safety management system (SMS) could be undermined by a tendency to search for, interpret, choose, or recall information in a way that supports a favorable view of how safety risk is managed in an organization. This tendency, sometimes called "confirmation bias", might be unintentional. Otherwise, it might be the result of a misguided loyalty to an organization, a reluctance to "open a can of worms" or even an intention to mislead or deceive. A temptation to rely on Generative AI as a substitute for critical thinking in the development and maintenance of a SMS might also be a source of confirmation bias. This paper proposes the use of Eliminative Argumentation (EA) to avoid confirmation bias in a SMS. Our approach is an adaptation of an innovative method for safety assurance developed by researchers at Carnegie Mellon University. At the heart of the method, confidence can be increased by identifying potential doubts, and then eliminating these doubts where it is reasonable to do so. A hierarchically structured argument for confidence in the SMS can be explicitly documented using a simple notation that mirrors the structure of the SMS. Following the structure described in Federal Aviation Administration (FAA) Order 8000.369C, the main branches of this argument cover the four components of a SMS, namely the Safety Policy, Safety Risk Management (SRM), Safety Assurance, and Safety Promotion. In turn, each of these main branches are further split into subbranches. For example, one of the sub-branches of the SMR branch of the argument addresses the need to track identified hazards and monitor implemented safety risk controls/ mitigations to ensure that they achieve their intended safety performance targets. To this level, the argument is an instance of a template that can be re-used for other instances of a SMS based on FAA Order 8000.369C. Lower levels of this tree-shaped argument are tailored to the specific details of how the SMS is implemented and maintained. For example, there might be doubts, also known as "defeaters", in the argument at this level that challenge the process used by the organization to decide that particular hazards are adequately controlled. Such defeaters are often expressed in the form of "What if ...?" questions. For example, "what if a decision that an identified hazard is mitigated is made by an unqualified person?". Such defeaters are often eliminated by supplementary details - for example, details about the minimum qualifications of personnel in a particular role. Using appropriate tool support, the structured argument for confidence in the SMS can be linked to Key Performance Indicators (KPI) to measure the effectiveness of the SMS. For example, one such KPI measures how many days on average it takes to analyze and resolve safety issues raised by personnel. If and when this measured value exceeds a defined threshold, it will be flagged as a problem for the SMS. Among other influences on a SMS, this paper will also take account of the impact of relying on Generative AI. In summary, the first contribution of this paper is showing how trust in a SMS can be increased by means of Eliminative Argumentation, especially as a means of avoiding confirmation bias. The second contribution of this paper is showing how KPIs can be used to further increase confidence in a SMS.},
  keywords={Target tracking;Navigation;Generative AI;Surveillance;Key performance indicator;Safety management;Organizations;Safety Management System;Confirmation Bias;FAA;Key Performance Indicators;Generative Artificial Intelligence},
  doi={10.1109/ICNS60906.2024.10550620},
  ISSN={2155-4951},
  month={April},}@ARTICLE{10750789,
  author={Dey, Jaydeep and Anandan, P. and Rajagopal, Sonaa and Mani, Muralikrishnan},
  journal={IEEE Access}, 
  title={Improved Target Detection With YOLOv8 for GAN Augmented Polarimetric Images Using MIRNet Denoising Model}, 
  year={2024},
  volume={12},
  number={},
  pages={166885-166910},
  abstract={Polarized images, which record the polarization characteristics of light, are becoming increasingly important in a variety of applications like remote sensing, medical imaging, and target detection. Their ability to offer additional information beyond traditional intensity-based images makes them valuable in situations where conventional imaging methods are lacking. However, the use of polarized images for tasks such as target detection presents challenges due to the limited availability of datasets, resulting in subpar performance in deep learning algorithms. Traditional methods for improving the quality of polarized images often involve noise reduction techniques, but these approaches may not fully exploit on the potential of deep learning algorithms due to limited dataset access. To get over this restriction and improve the performance of deep learning models on polarised images, new approaches are required. In this study, a new approach is proposed to address the challenges linked with polarized images by harnessing the capabilities of GAN and deep learning models. Specifically, the MIRNet CNN algorithm is utilized to denoise enhanced polarized datasets produced by GANs. By training the deep learning model on these enhanced datasets, the aim is to boost the performance of subsequent tasks like target detection. The study demonstrates the efficacy and efficiency of this novel approach for bettering the polarised image performance of deep learning models, particularly the MIRNet and YOLOv8 models. Through the use of GAN-generated enhanced datasets, there is a notable enhancement in the accuracy of target detection utilizing YOLOv8. This highlights the potential of this approach not only in target detection but also in various other fields that rely on precise object detection and image denoising utilizing polarized images.},
  keywords={Noise reduction;Training;Generative adversarial networks;Deep learning;Accuracy;Synthetic data;Noise measurement;Data models;Data augmentation;Convolutional neural networks;Polarimetry;Signal to noise ratio;Generative adversarial network (GAN);data augmentation;MIRNet;convolutional neural network (CNN);polarimetric images;polarization;denoising;peak signal to noise ratio (PSNR);structural similarity index (SSIM);you only look once (YOLO)},
  doi={10.1109/ACCESS.2024.3496523},
  ISSN={2169-3536},
  month={},}@ARTICLE{10955402,
  author={Zhang, Zeqing and Zhang, Zefei and Jin, Na and Yang, Fanchang and Zhao, Wei},
  journal={IEEE Access}, 
  title={MetaZero: A Novel Meta-Learning Method Suitable for Generalized Zero-Shot Learning}, 
  year={2025},
  volume={13},
  number={},
  pages={76100-76108},
  abstract={Generalized zero-shot learning (GZSL) aims to recognize objects from both seen and unseen classes, when only the labeled examples from seen classes are provided. Most GZSL methods only optimize models based on seen classes but fail to explicitly mimic zero-shot learning settings that transfer knowledge from seen classes to unseen classes at the training time. Meta-learning has been introduced to mitigate this problem, but the models of current meta-learning approaches only learn to face the novel classes rather than learn to face the strong biased problem during the training, which is the main reason for the poor performance of most methods in GZSL. Humans can improve their knowledge with well-designed tests. According to this phenomenon, We propose a novel meta-learning method that is more suitable for GZSL termed MetaZero, aiming to alleviate the strong bias problem in GZSL. Specifically, MetaZero modifies the division of meta train set and meta test set, so that the model can directly face the strong bias problem in the meta test stage. In this way, with the iteration of training, the model can become an expert to solve the strong bias problem. Our extensive experiments manifest that our method achieves the significant gains than the SOTA GZSL methods.},
  keywords={Training;Metalearning;Generators;Generative adversarial networks;Zero shot learning;Visualization;Semantics;Accuracy;Adaptation models;Gold;Image recognition;generalized zero-shot learning;meta learning;adversarial generative network},
  doi={10.1109/ACCESS.2025.3558721},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8469573,
  author={Liu, Yi and Xu, Ying and Li, Shao-bin},
  booktitle={2018 2nd IEEE Advanced Information Management,Communicates,Electronic and Automation Control Conference (IMCEC)}, 
  title={2-D Human Pose Estimation from Images Based on Deep Learning: A Review}, 
  year={2018},
  volume={},
  number={},
  pages={462-465},
  abstract={H150 pose estimation is an important research topic in the field of computer vision and artificial intelligence. This paper focuses on the state-of-art progress of 2-D human pose estimation methods based on deep learning. According to the neural network structure, these methods are classified as single CNN method, Multi-stage CNN method, Multi-branch CNN method, Recurrent Neural Network (RNN) method and Generative Adversarial Networks (GAN) method. We summarize and analyze their attributes and performance. The future development direction is also prospected.},
  keywords={Feature extraction;Pose estimation;Gallium nitride;Generative adversarial networks;Computer vision;Complexity theory;Machine learning;deep learning;human pose estimation;2-D image},
  doi={10.1109/IMCEC.2018.8469573},
  ISSN={},
  month={May},}@ARTICLE{10251073,
  author={Li, Yang and Zhang, Shitu and Li, Yuanzheng and Cao, Jiting and Jia, Shuyue},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={PMU Measurements-Based Short-Term Voltage Stability Assessment of Power Systems via Deep Transfer Learning}, 
  year={2023},
  volume={72},
  number={},
  pages={1-11},
  abstract={Deep learning (DL) has emerged as an effective solution for addressing the challenges of short-term voltage stability assessment (STVSA) in power systems; however, existing DL-based STVSA approaches face limitations in adapting to topological changes, sample labeling, and handling small datasets. To overcome these challenges, this article proposes a novel phasor measurement unit (PMU) measurements-based STVSA method by using deep transfer learning. The method leverages the real-time dynamic information captured by PMUs to create an initial dataset. It employs temporal ensembling for sample labeling and uses least squares generative adversarial networks (LSGANs) for data augmentation (DA), enabling effective DL on small-scale datasets. Additionally, the method enhances adaptability to topological changes by exploring connections between different faults. Experimental results on the IEEE 39-bus test system demonstrate that the proposed method improves model evaluation accuracy by approximately 20% through transfer learning (TL), exhibiting strong adaptability to topological changes. By leveraging the self-attention mechanism of the transformer model, this approach offers significant advantages over shallow learning methods and other DL-based approaches.},
  keywords={Power system stability;Phasor measurement units;Voltage measurement;Transfer learning;Stability criteria;Deep learning;Power measurement;Deep transfer learning;least squares generative adversarial networks (LSGANs);phasor measurement unit (PMU) measurements;power system stability;short-term voltage stability assessment (STVSA);temporal ensembling;transformer},
  doi={10.1109/TIM.2023.3311065},
  ISSN={1557-9662},
  month={},}@INPROCEEDINGS{9401109,
  author={Tang, Jialiang and Liu, Mingjin and Jiang, Ning and Cai, Huan and Yu, Wenxin and Zhou, Jinjia},
  booktitle={2021 IEEE International Symposium on Circuits and Systems (ISCAS)}, 
  title={Data-Free Network Pruning for Model Compression}, 
  year={2021},
  volume={},
  number={},
  pages={1-5},
  abstract={Convolutional neural networks(CNNs) are often over-parameterized and cannot apply to existing resource-limited artificial intelligence(AI) devices. Some methods are proposed to model compress the CNNs, but these methods are data-driven and often unable when lacking data. To solve this problem, in this paper, we propose a data-free model compression and acceleration method based on generative adversarial networks and network pruning(named DFNP), which can train a compact neural network only needs a pre-trained neural network. The DFNP consists of the source network, generator, and target network. First, the generator will generate the pseudo data under the supervise of the source network. Then the target network will get by pruning the source network and use these generated data for training. And the source network will transfer knowledge to the target network to promote the target network to achieve a similar performance of the source network. When the VGGNet- 19 is select as the source network, the target network trained by DFNP contains only 25% parameters and 65% calculations of the source network. Still, it retains 99.4% accuracy on the CIFAR-10 dataset without any real data.},
  keywords={Knowledge engineering;Training;Neural networks;Generative adversarial networks;Generators;Data models;Convolutional neural networks},
  doi={10.1109/ISCAS51556.2021.9401109},
  ISSN={2158-1525},
  month={May},}@INPROCEEDINGS{9860457,
  author={Li, Zheao and Wang, Cheng-Xiang and Huang, Jie and Zhou, Wenqi and Huang, Chen},
  booktitle={2022 IEEE 95th Vehicular Technology Conference: (VTC2022-Spring)}, 
  title={A GAN-LSTM based AI Framework for 6G Wireless Channel Prediction}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={Compared with conventional passive channel modeling, artificial intelligence (AI) based channel models show great advantages in solving real-time prediction problems in wireless communications. In this paper, a generative adversarial network (GAN) and long short-term memory (LSTM) based channel prediction framework is proposed to model indoor wireless channels. By using GAN and LSTM, the model not only enriches the channel data but also achieves the sequence prediction, which can solve the problem of the shortage of training data and prediction channels in the space domain. The prediction performance is evaluated by comparing the root mean square error (RMSE) and mean absolute percentage error (MAPE) of measured data and predicted data. By comparing the statistical properties of the channel measurement data and of the synthetic data, it can be found that the proposed model can predict unknown information in the space domain.},
  keywords={Wireless communication;Vehicular and wireless technologies;Neural networks;Training data;Predictive models;Generative adversarial networks;Data models;AI;GAN;LSTM;channel modeling;channel prediction},
  doi={10.1109/VTC2022-Spring54318.2022.9860457},
  ISSN={2577-2465},
  month={June},}@INPROCEEDINGS{10263628,
  author={Bansal, Kartik and Agarwal, Shubhi and Vyas, Narayan},
  booktitle={2023 International Conference on IoT, Communication and Automation Technology (ICICAT)}, 
  title={Deepfake Detection Using CNN and DCGANS to Drop-Out Fake Multimedia Content: A Hybrid Approach}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The creation of Deep Fakes, which are altered videos, audio, and photographs capable of disseminating false information and fake news and modifying sensitive records, is the result of the rapid advancements in artificial intelligence and machine learning. DeepFakes may also be used for interactive learning and visual effects in entertainment and education. As a result, numerous deep learning models, such as Convolutional Neural Networks (CNN) and Generative Adversarial Networks (GAN), are being used for detection. DeepFakes detection and removal have become essential challenges. Facebook AI's Deepfake Detection Challenge (DFDC) dataset is invaluable for developing and evaluating detection techniques. While it represents serious risks, creating trustworthy detection techniques might lessen their impact and enable investigation of their possible beneficial applications. To ensure the authenticity and dependability of multimedia information in the face of the ongoing DeepFake threat, this paper emphasizes the importance of transfer learning, deep learning, and optimization techniques in building effective detection models. By doing this, we can stop the spread of fake news and information, protect the public's trust, and promote the moral and beneficial application of DeepFake technology across various fields.},
  keywords={Deep learning;Deepfakes;Ethics;Transfer learning;Education;Visual effects;Generative adversarial networks;Transfer Learning;Deep Learning;Convolutional Neural Networks (CNN);Image Classification;ImageNet;Optimization Techniques},
  doi={10.1109/ICICAT57735.2023.10263628},
  ISSN={},
  month={June},}@ARTICLE{10149144,
  author={Gipiškis, Rokas and Chiaro, Diletta and Preziosi, Marco and Prezioso, Edoardo and Piccialli, Francesco},
  journal={IEEE Systems Journal}, 
  title={The Impact of Adversarial Attacks on Interpretable Semantic Segmentation in Cyber–Physical Systems}, 
  year={2023},
  volume={17},
  number={4},
  pages={5327-5334},
  abstract={The widespread adoption of deep learning (DL) models raises concerns about their trustworthiness and reliability. Adversarial attacks are cyber-related attacks that target the DL network's prediction by adding imperceptible perturbations to its input. Their deployment against critical artificial-intelligence-based systems, such as industrial cyber–physical systems (ICPSs), can result in substantial damage. Research on their scope and limitations can provide information that would help with their detection and prevention. In this article, the interconnection of adversarial attacks and interpretable semantic segmentation is investigated for potential applications in the ICPS in order to contribute to the safe use of future intelligent systems. We first explore gradient-based interpretability extensions to semantic segmentation on two industry-related cyber–physical system datasets. Then, two types of attacks on semantic segmentation networks are discussed. First, we apply the dense adversary generation attack on different segmentation outputs and evaluate its influence on the corresponding saliency maps. We then introduce a way to visualize the similarity of attacked saliency maps to the original with respect to the targeted attack's direction. Finally, we extend the application of adversarial attacks on saliency maps to semantic segmentation.},
  keywords={Semantic segmentation;Semantics;Task analysis;Image edge detection;Drones;Perturbation methods;Generative adversarial networks;Adversarial attacks;cyber–physical systems (CPSs);explainable artificial intelligence (XAI);industrial control;interpretability;semantic segmentation},
  doi={10.1109/JSYST.2023.3281079},
  ISSN={1937-9234},
  month={Dec},}@INPROCEEDINGS{10001857,
  author={Hattori, Shun and Aiba, Kizuku and Takahara, Madoka},
  booktitle={2022 Joint 12th International Conference on Soft Computing and Intelligent Systems and 23rd International Symposium on Advanced Intelligent Systems (SCIS&ISIS)}, 
  title={R2-B2: A Metric of Synthesized Image’s Photorealism by Regression Analysis based on Recognized Objects’ Bounding Box}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={In recent years, a lot of researches on AI (Artificial Intelligence) for Image Synthesis and Image Generation have been being conducted actively, and state of the art GANs (Generative Adversarial Networks) for text-to-image have been able to generate precise images with high photorealism for a text-based user query (but also no-good images). However, it is pointed out that the precision of all images generated for a query has been not always enough high. Therefore, for practical usages, they are required to be re-ranked and/or filtered based on some sort of metric(s). This paper proposes a novel metric, R2-B2 (RR-BB), on photorealism, especially “size balance” (i.e., balance between in-image objects’ size), of a manually or automatically synthesized image by Regression analysis based on multiple Recognized objects’ Bounding Box, i.e., the position $(x, y)$ and size (width, height, or area) of objects recognized in the image.},
  keywords={Measurement;Image quality;Photorealism;Image recognition;Image synthesis;Generative adversarial networks;Regression analysis;image evaluation;no-reference image quality assessment;image quality metrics;object recognition;object detection;regression analysis;correlation analysis},
  doi={10.1109/SCISISIS55246.2022.10001857},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9898140,
  author={Jagannathan, Akash and Chandrasekaran, Bharathi and Dutta, Shubham and Patil, Uma Rameshgouda and Eirinaki, Magdalini},
  booktitle={2022 IEEE International Conference On Artificial Intelligence Testing (AITest)}, 
  title={Original Music Generation using Recurrent Neural Networks with Self-Attention}, 
  year={2022},
  volume={},
  number={},
  pages={56-63},
  abstract={A recent trend in deep learning is using state-of-the-art models to generate human art forms. Using such “intelligent” models to generate novel musical compositions is a thriving area of research. The motivation is to use the capacity of deep learning architectures and training techniques to learn musical styles from arbitrary musical corpora automatically and then generate samples from the estimated distribution. We focus on two popular state-of-the-art models used in deep generative learning of music, namely recursive neural networks (RNN) and the self-attention mechanism. We provide a systematic evaluation of state-of-the-art models used in generative deep learning for music but also contribute novel architectures and compare them to the established baselines. The models are trained on piano compositions embedded in MIDI format from Google’s Maestro dataset. A big challenge in such learning tasks is to evaluate the outcome of such learning tasks, since art is very subjective and hard to evaluate quantitatively. Therefore, in addition to the experimental evaluation, we also conduct a blind user study. We conclude that a double-stacked RNN model with a self-attention layer was observed to have the most optimal training time, and the pieces generated by a triple-stacked RNN model with self-attention layers were deemed the most subjectively appealing and authentic.},
  keywords={Training;Recurrent neural networks;Art;Systematics;Pipelines;Neurons;Music;Generative deep learning;music generation;MIDI;MAESTRO;piano-roll;RNN;Self-Attention},
  doi={10.1109/AITest55621.2022.00017},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10111248,
  author={Gorro, Ken and Ilano, Anthony and Ranolo, Elmo and Pineda, Hedeliza and Sintos, Cristine and Gorro, Apple Jane},
  booktitle={2023 International Conference on Business Analytics for Technology and Security (ICBATS)}, 
  title={An experiment on DCGAN-based synthetic samples of flora species for YOLO-based classification}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Image classification has been the prime focus of Computer Vision and Artificial Intelligence. Object detection is very challenging in marine environment which data samples might be limited or the samples are difficult to be processed due to the environment constraint. This study explores the use of Deep Convolutional Generative Adversarial Networks (DCGANs) to generate more samples of flora species. Out of 1000 samples, 500 randomly selected samples were used to train the DCGANs model. A total of 500 samples per class were generated using DCGAN. The two classes are namely seagrass and seaweed. To test the viability of the generated images using DCGAN, a YOLOV3 based model was created to detect seagrass and seaweed. The result shows a 58% accuracy of the YOLOV3 model trained using synthetic samples as compared to 77% accuracy of the YOLOV3 model trained using real samples combined with synthetic samples. YOLOV5 was also evaluated in both samples. The generated samples from DCGAN were also evaluated by the experts of Marine Biology.},
  keywords={Training;Computer vision;Biological system modeling;Object detection;Generative adversarial networks;Complexity theory;Security;Yolo;Deep Learning;Deep Convolutional GAN},
  doi={10.1109/ICBATS57792.2023.10111248},
  ISSN={},
  month={March},}@INPROCEEDINGS{8679269,
  author={Choi, Suh-Yong and Jeong, Hyeok-June and Park, Kyeong-Sik and Ha, Young-Guk},
  booktitle={2019 IEEE International Conference on Big Data and Smart Computing (BigComp)}, 
  title={Efficient Driving Scene Image Creation Using Deep Neural Network}, 
  year={2019},
  volume={},
  number={},
  pages={1-4},
  abstract={The development of artificial intelligence technology shows the possibility of technologies such as autonomous vehicles and A.I robots. Correspondingly, there are many researches and developments for the machine learning. As the evolution of machine learning technology occurs, classification techniques such as image recognition are not as demanding as before. This recognition technique is also important in autonomous vehicle system. For that, we succeeded in training and classifying a few classes (man, car, truck, etc.) in the roadway driving situation using the darkflow which combined the YOLO framework and the tensorflow. In this way, collecting, learning, and recognizing simple objects is relatively easy, but the recognition system for a safe autonomous vehicle system must also be able to recognize certain situations. So we designed the system for training the specific driving conditions on the roadway such as `Car too close', `Under the construction', `People caution' etc. However, it is difficult to gather a lot of specific training data on machine learning. For example, simple forklifts or automobile images on the web can be easily obtained, but data on road construction situation or data on cars just before the crash will be hard to collect. In this paper, we propose a system that can generate a specific situation data using Generative Adversarial Network (GAN).},
  keywords={Generative adversarial networks;Gallium nitride;Roads;Training;Image recognition;Automobiles;Training data;Deep Learning;Situation Generation;GAN;Image Generation},
  doi={10.1109/BIGCOMP.2019.8679269},
  ISSN={2375-9356},
  month={Feb},}@ARTICLE{10497533,
  author={Huang, Lei and Yuan, Zheng and Yan, Huihui and Sheng, Rong and Liu, Linjing and Wang, Fuzhou and Xie, Weidun and Chen, Nanjun and Huang, Fei and Huang, Songfang and Wong, Ka-Chun and Zhang, Yaoyun},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={A Unified Conditional Diffusion Framework for Dual Protein Targets-Based Bioactive Molecule Generation}, 
  year={2024},
  volume={5},
  number={9},
  pages={4595-4606},
  abstract={Advances in deep generative models shed light on de novo molecule generation with desired properties. However, molecule generation targeted for dual protein targets still faces formidable challenges including insufficient protein 3-D structure data requisition for conditioned model training, inflexibility of auto-regressive sampling, and model generalization to unseen targets. Here, this study proposed diffusion model for dual targets-based molecule generation (DiffDTM), a novel unified structure-free deep generative framework based on a diffusion model for dual-target based molecule generation to address the above issues. Specifically, DiffDTM receives representations of protein sequences and molecular graphs pretrained on large-scale datasets as inputs instead of protein and molecular conformations and incorporates an information fusion module to achieve conditional generation in a one-shot manner. We perform comprehensive multiview experiments to demonstrate that DiffDTM can generate druglike, synthesis-accessible, novel, and high-binding affinity molecules targeting specific dual proteins, outperforming the state-of-the-art (SOTA) models in terms of multiple evaluation metrics. Furthermore, DiffDTM could directly generate molecules toward dopamine receptor D2 (DRD2) and 5-hydroxytryptamine receptor 1A (HTR1A) as new antipsychotics. Experimental comparisons highlight the generalizability of DiffDTM to easily adapt to unseen dual targets and generate bioactive molecules, addressing the issues of insufficient active molecule data for model training when new targets are encountered.},
  keywords={Proteins;Biological system modeling;Data models;Transformers;Diffusion models;Drug discovery;Molecular biology;Diffusion model;dual-target;generative model;molecule generation},
  doi={10.1109/TAI.2024.3387402},
  ISSN={2691-4581},
  month={Sep.},}@INPROCEEDINGS{10601854,
  author={Kavipriya, J and Vadivu, G},
  booktitle={2024 International Conference on Advances in Computing, Communication and Applied Informatics (ACCAI)}, 
  title={Exploring Crop Yield Prediction with Remote Sensing Imagery and AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Planning for agriculture, allocating resources, and ensuring food security all depend on the accurate and timely estimate of the crop yield. This paper investigates the use of Machine Learning (ML) and Deep Learning methods (DL) to forecast crop yield using remote sensing images. Multispectral and hyperspectral images from remote sensing provide a useful source of data for tracking crop health and estimating prospective yield. This study scrutinizes the advantage of the abundant spectral and spatial data that remote sensing sensors have collected. Convolutional neural networks (CNNs) and Machine learning are utilized for feature extraction and prediction, leveraging the hierarchical representations acquired from remote sensing data. A dataset of ground-truth yield data and historical satellite photos are used to train the DL and ML algorithms. In order to improve the model’s generalization to various geographic locations and cropping seasons, transfer learning techniques can also be used. Moreover, interpretable deep learning methods and attention mechanisms are investigated to improve the model’s transparency and reveal key elements that influence yield prediction. By giving farmers, decision-makers, and other stakeholders timely and precise information on crop output estimates, the research’s findings have the potential to greatly advance precision agriculture methods. Deep learning methods combined with satellite imagery show approximately $\mathbf{9 0 \%}$ accuracy for scalable and effective agricultural production monitoring, which will ultimately help sustainable farming methods.},
  keywords={Deep learning;Precision agriculture;Satellites;Production;Predictive models;Generative adversarial networks;Data models;Remote sensing;Yield Prediction;Artificial Intelligence;Machine Learning;Deep Learning},
  doi={10.1109/ACCAI61061.2024.10601854},
  ISSN={},
  month={May},}@INPROCEEDINGS{9402809,
  author={Wang, Binbin and Zhang, Yilian and Zhu, Minjie and Chen, Yan},
  booktitle={2020 International Conference on Intelligent Computing, Automation and Systems (ICICAS)}, 
  title={The Security Threat of Adversarial Samples to Deep Learning Networks}, 
  year={2020},
  volume={},
  number={},
  pages={125-129},
  abstract={With the prosperity of artificial intelligence, research on machine learning becomes a hot issue globally. Generative Adversarial Networks expose the huge security risks of machine learning. After the creation, GAN has achieved good performance in image generation, automatic image coloring, and data enhancement. With the improvement of the ability to generate samples against the deep learning network, generating malicious samples against the target learning model to achieve the deceptive discriminator becomes an effective and harmful attacking method. At present, some efficient attack methods have been proposed for different types of learning networks and different types of sample data. This paper mainly discusses the vulnerability of deep learning networks and several attack methods based on adversarial samples.},
  keywords={Training;Deep learning;Semantics;Tools;Generative adversarial networks;Robustness;Security;GAN;deep learning;adversarial samples;white-box;black-box},
  doi={10.1109/ICICAS51530.2020.00033},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10803608,
  author={Wang, Ning and Zhang, Hongyi},
  booktitle={2024 International Conference on Language Technology and Digital Humanities (LTDH)}, 
  title={Integration of AI Generated Content (AIGC) in the Development of Digital Human in the Metaverse}, 
  year={2024},
  volume={},
  number={},
  pages={92-96},
  abstract={This paper discusses the AIGC in digital content creation, interaction experience enhanced, application scenario development path of integration. Driven by AIGC personalized appearance, action expression, speech dialogue content generation, as well as natural language interaction, emotion recognition, intelligent, and so on multimodal interaction can be all-round development and application to digital. The deep integration of AIGC and digital human development is expected to further improve the content productivity and interactive experience of the metaverse, and promote the development of the metaverse industry.},
  keywords={Productivity;Industries;Emotion recognition;Metaverse;Generative AI;Natural languages;Speech recognition;Digital humans;artificial intelligence-generated content;metaverse;digital man;content generation;interactive experience},
  doi={10.1109/LTDH64262.2024.00027},
  ISSN={},
  month={July},}@INPROCEEDINGS{11146169,
  author={Chen, Zongwen and Fan, Dongyang and Zhang, Dongyang and Zhang, Ling},
  booktitle={2024 International Conference on Internet of Things, Robotics and Distributed Computing (ICIRDC)}, 
  title={Research on the Prediction Model of Crystallinity of Natural Rubber Based on Gan-XGBoost Framework}, 
  year={2024},
  volume={},
  number={},
  pages={547-551},
  abstract={The advent of big data era and prominence of artificial intelligence has catalyzed the applications of machine learning algorithms in various domains, including materials science, information technology, control engineering, and biomedicine. This paper explores the combination of machine learning and polymer material science by employing predictive models to ascertain the mechanical properties of natural rubber materials through computational simulations. The proposed solution is grounded in the GAN-XGBoost model framework, which leverages a data augmentation technique founded on Generative Adversarial Networks (GAN) to enhance the initial data set. Additionally, the XGBoost model, which utilizes treestructured algorithms, is implemented to expedite the prediction of crystallinity in these materials. To refine the insights gained, a weighted integration approach utilizing Shapley Additive Explanation (SHAP) analysis is adopted, enabling a nuanced understanding of how variations in phospholipid protein percentage, hydrogen bond strength, and non-hydrogen bond strength influence the crystallinity predictions of natural rubber materials under dynamic conditions. This model effectively integrates the crystallinity prediction algorithm for polymer materials through molecular dynamics simulations with the GAN-based data augmentation algorithm, thereby significantly enhancing the predictive accuracy of the XGBoost model.},
  keywords={Machine learning algorithms;Computational modeling;Machine learning;Predictive models;Generative adversarial networks;Prediction algorithms;Data augmentation;Data models;Rubber;Polymers;machine learning;natural rubber;data augmentation;XGBoost},
  doi={10.1109/ICIRDC65564.2024.00104},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11151891,
  author={Rodrigues, Tiago Koketsu and Songsriboonsit, Norranat and Verma, Shikhar},
  booktitle={2025 IEEE VTS Asia Pacific Wireless Communications Symposium (APWCS)}, 
  title={Weather Attenuation Dataset Generation Method for Prediction-based Control of Non-Terrestrial High-Frequency Wireless Networks}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={High-frequency communications and space/air networks are needed to provide fast transmission rates with ubiquitous connections. The complicating factor, however, is that high frequencies are susceptible to high attenuation caused by adverse weather, such as clouds and rain. Given that weather is highly dynamic but follows predictable patterns, the use of Machine Learning to predict network state and thus proactively control connections is a promising network management method in these scenarios. To train these Machine Learning models, extensive datasets are needed. Unfortunately, existing data have either low time resolution (which does not sufficiently capture the fast changes in weather) or low space resolution (which is biased by focusing on limited locations). To address this, we propose two dataset generation methods that generate high-resolution data, which is still based on real-life measurements. Performance evaluation shows that generative artificial intelligence cannot properly capture the real-life variations in weather, but our proposed heuristics are capable of creating a dataset that follows realistic patterns and that can be used to control space/air wireless networks to improve downtime and throughput when compared to using existing datasets.},
  keywords={Training;Correlation;Wireless networks;Heuristic algorithms;Time series analysis;Machine learning;Attenuation;Generative adversarial networks;Throughput;Meteorology;optical networks;non-terrestrial networks;machine learning;data analysis},
  doi={10.1109/APWCS67981.2025.11151891},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10500084,
  author={},
  booktitle={SoutheastCon 2024}, 
  title={Synthetic Data Creation for ML/AL Model Training}, 
  year={2024},
  volume={},
  number={},
  pages={639-643},
  abstract={Recent years have witnessed an increasing demand for extensive data sets to power various artificial intelligence (AI) methods, including machine learning (ML) and deep learning. Collecting real-world data, however, faces challenges like sensitivity concerns, high costs, and extensive processing times. Consequently, ML/AI models trained on limited data often suffer from implicit bias and reduced performance due to their inability to generalize effectively. Addressing these issues necessitates large, meticulously annotated data sets rich in diverse examples to counteract bias and enhance model performance. Nonetheless, compiling and labeling such vast data sets, potentially consisting of millions of items, is a laborintensive and often exorbitantly costly process. In response to this challenge, the research discussed here explores expanding a deep learning framework to create customizable synthetic data, employing Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs). The proposed VAE framework is designed to digitally generate data as needed, conforming to user-defined specifications. This approach, with its wideranging and generalized capabilities, addresses the gap in customized, synthetic data generation, where previous efforts were confined to specific areas. Our framework leverages the manipulation of latent space distributions in VAEs to produce the required synthetic data. This serves as an augmentation to existing real datasets, significantly broadening the available training data for ML and deep learning applications.},
  keywords={Deep learning;Training;Sensitivity;Costs;Training data;Generative adversarial networks;Data models;Deep Learning;VAE;Synthetic Data},
  doi={10.1109/SoutheastCon52093.2024.10500084},
  ISSN={1558-058X},
  month={March},}@INPROCEEDINGS{10933654,
  author={Peng, Yifeng and Zhang, Haoxi and Li, Fei and Szczerbicki, Edward},
  booktitle={2024 5th International Conference on Computer, Big Data and Artificial Intelligence (ICCBD+AI)}, 
  title={Chromosome Straightening via Disentangled Representations: Exploring Semantic Trajectories in GAN’s Latent Space}, 
  year={2024},
  volume={},
  number={},
  pages={253-259},
  abstract={In the field of chromosome karyotype analysis, performing straightening preprocessing on chromosomes is a key process to increase the accuracy of chromosome identification. Previous studies have typically relied on geometric algorithms; however, during the straightening process, external perturbations caused by geometric factors often result in the distortion or deformation of chromosome banding patterns, leading to the loss of important feature information and the lack of clarity in details. This, in turn, reduces the model’s representation capability and generalization performance. In this paper, we propose a novel disentangled representation learning framework aimed at exploring the semantic disentanglement trajectories within generative models to generate chromosome images with purer straightening semantics. Our framework consists of four main components: the Generator(G), the Semantic Trajectory Explorer(STE), the Disentangled Encoder(DE), and the Classifier(C). The G is responsible for generating chromosome images, the STE explores disentangled semantic trajectories within the latent space of the generative model, the DE maps chromosome images into the disentangled feature space, and the C predicts the chromosome type based on these features. The framework employs a disentanglement loss to force the STE to find disentangled semantic trajectories within the latent space of the G and uses classification loss to ensure that content information remains unchanged along the semantic trajectory, thereby achieving chromosome straightening without altering karyotype features. Based on the experimental results, our method performs well in terms of the Aspect Ratio Change of the bounding box(Bounding Box ARC), Frechet Inception Distance (FID), and Downstream Classification Accuracy (DCA).},
  keywords={Accuracy;Deformation;Perturbation methods;Semantics;Disentangled representation learning;Force;Predictive models;Distortion;Trajectory;Biological cells;Chromosome Straightening;Karyotype Analysis;Disentangled Representation Learning;Generative Models},
  doi={10.1109/ICCBD-AI65562.2024.00049},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10907182,
  author={Swindell, Jonathan E. and Goad, Adam C. and Egbert, Austin and Latham, Casey and Ozalas, Matthew and Howard, Andy and McClearnon, Daren and Baylis, Charles and Marks, Robert J.},
  booktitle={2025 United States National Committee of URSI National Radio Science Meeting (USNC-URSI NRSM)}, 
  title={Multidimensional Load-Pull Extrapolation for Accelerated Computer-Aided Design (CAD) Simulations}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Computer-aided design (CAD) is widely used in the design and optimization of power amplifiers. Often CAD tasks require many simulations and the time required can be a limiting factor. Additionally, there are many difficulties with characterizing the behavior of high-power and high-frequency power amplifier devices. The work presented reduces the time required for CAD simulations and can use data collected from a device in a measurable region to approximate behavior under difficult-to-measure operating conditions. This work improves on the Wasserstein Generative Adversarial Network (WGAN) Load-Pull Extrapolation network trained for 2d load-pull extrapolation (A. Egbert, C. Baylis, and R. J. Marks, “Extrapolation of Load-Pull Data: A Novel Use of GAN Artificial Intelligence Image Completion,” IEEE Transactions on Microwave Theory and Techniques, vol. 70, no. 11, pp. 4849–4856, Nov. 2022) and extends it to support a 3rd dimension, input power. This work can extrapolate as few as 16 simulation queries to 24,176 output powers while predicting the optimal reflection coefficient over changing input power to within a median vector error of 0.1098.},
  keywords={Solid modeling;Extrapolation;Design automation;Computational modeling;Power amplifiers;Generative adversarial networks;Vectors;Time measurement;Reflection coefficient;Load modeling},
  doi={10.23919/USNC-URSINRSM66067.2025.10907182},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10834346,
  author={Hayashi, Victor Takashi and Mohallem Paiva, Henrique},
  booktitle={2024 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}, 
  title={ChatGPT Calls for Self Reflection: Student Perceptions of Evaluation Activities in Video}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={ChatGPT has shown significant adoption for students when answering evaluation activities in undergraduate courses such as Information Systems, Computer Engineering, Software Engineering and Computer Science. When facing this challenge, one possibility for educators is to enable the students to learn while using the tool instead of restricting its usage. In this paper, we describe a case study of evaluation activities in video format as a way to motivate self-reflection in students. This alternative method prevents students from simply copying and pasting textual answers without any reflection. Furthermore, it encourages active participation and improves communication skills and the ability to articulate arguments, which may be lacking when students rely solely on written responses. We present 53 student perceptions regarding these video-based evaluation activities collected during two years, the benefits and drawbacks of the proposed approach, and suggestions for future implementations. According to students perceptions, most of them prefer text and coding evaluation approaches, however these are the ones more prone for ChtGPT ’copy and paste’. The qualitative responses indicate that the main positive aspects are the time flexibility and the additional reflection. The main negative aspects are related to lack of flexibility in communication form, extra work in video editing and additional student anxiety.},
  keywords={Technological innovation;Reviews;Generative AI;Scalability;Anxiety disorders;Chatbots;Reflection;Encoding;Software engineering;Information systems;evaluation;chatgpt;reflection;assessment;artificial intelligence;education},
  doi={10.1109/TALE62452.2024.10834346},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10786739,
  author={Nichols, Robert and Gonzalez-Soler, Lazaro J. and Rathgeb, Christian},
  booktitle={2024 International Conference of the Biometrics Special Interest Group (BIOSIG)}, 
  title={On the Use of Synthetic Hand Images for Biometric Recognition}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Recognition of subjects based on images of their hands does not enjoy the same level of publicity as e.g. face recognition; therefore, scientific studies on this topic are limited. Nevertheless, the importance in forensic scenarios is considerable, where investigators often face the difficult task of identifying a suspect with little more than an image depicting a partial hand, i.e. the palmar or dorsal aspect. However, the large amounts of data needed for robust recognition systems are often unavailable. Recent advancements in the area of generative artificial intelligence have demonstrated impressive capabilities in terms of image fidelity and performance, in turn implying the possibility of substituting or augmenting real datasets with synthetically generated samples. In this paper, we explore generating hand images with latent diffusion models (LDM) conditioned on state-of-the-art hand recognition systems. Our experimental results indicate the possible future viability of generating fully synthetic identity-preserving mated samples. We identify interesting behaviour of the involved algorithms to encourage future work in this area and ultimately facilitate the development of robust, privacy-preserving and unbiased biometric systems.},
  keywords={Image recognition;Generative AI;Face recognition;Forensics;Fingerprint recognition;Diffusion models;Data models;Iris recognition;Synthetic data;Biomedical imaging;Biometrics;Hand recognition;Forensic analysis;Synthetic Image Generation;Deep learning;Diffusion models},
  doi={10.1109/BIOSIG61931.2024.10786739},
  ISSN={1617-5468},
  month={Sep.},}@INPROCEEDINGS{10871136,
  author={Abbasi, Humza Fazal and Abbasi, Merium Fazal and Hamayat, Faizan},
  booktitle={2024 18th International Conference on Open Source Systems and Technologies (ICOSST)}, 
  title={Pix2Pix++: An Enhanced GANs Based Model for Portrait to Pencil Sketch Translation}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The generation of sketches from portraits has been an active area of research for decades due to its applications in various sectors such as entertainment and education. However, due to numerous qualitative factors involved in sketching, programmatically generating sketches from images has been a challenging task. Recent advances in generative artificial intelligence (GAI) seem very promising in solving these challenges. In specific, generative adversarial networks (GANs) like conventional Pix2Pix, were specifically designed for accurate and efficient image-to-image translation tasks. In this research, inspired by GAI and original Pix2Pix, we proposed a GANs-based Pix2Pix++ technique for translating portrait images into sketches. We replaced U-Net with the UNet++ for generator in Pix2Pix++ GAN and trained the proposed model on a self-collected dataset for sketch generation. Furthermore, we evaluated the proposed model's performance both qualitatively and quantitively and performed a comparative analysis with existing techniques. Proposed Pix2Pix++ GAN got MS-SSIM median scores of 84%, PSNR of 21.17, and MSE median score of 495.55. Experimental results showed our proposed technique outperforms the existing techniques in terms of capturing minute details, tonal variations, realistic appearance, and generalization.},
  keywords={Resistance;Analytical models;Translation;Accuracy;Generative AI;Education;Entertainment industry;Generative adversarial networks;Generators;GANs;Pix2Pix++;U-Net++;PatchGAN;portrait;sketch;image-to-image translation},
  doi={10.1109/ICOSST64562.2024.10871136},
  ISSN={2770-8225},
  month={Dec},}@INPROCEEDINGS{10863278,
  author={Ebnou, Haje and Blavette, Anne and Dupriez-Robin, Florian and Roy, Anthony and Bourguet, Salvy},
  booktitle={2024 IEEE PES Innovative Smart Grid Technologies Europe (ISGT EUROPE)}, 
  title={Synthetic Scenario Generation for Microgrid Design: A Methodological Approach Using TimeGAN}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Generating synthetic scenarios for time-series data is crucial for various applications, including predictive modeling, data augmentation, and scenario analysis. In this study, we focus on creating scenarios in purpose of data augmentation for the optimal design of renewable energy systems within microgrids by testing two methods: directly generating photovoltaic production data and generating meteorological data scenarios followed by calculating the production. Our goal is to evaluate how well the TimeGAN artificial intelligence tool performs in generating realistic synthetic scenarios for both approaches. TimeGAN, a type of Generative Adversarial Network (GAN), is known for its ability to capture temporal patterns and maintain data distribution. We use TimeGAN to generate synthetic scenarios for renewable energy production and compare the feasibility and quality of the scenarios produced by each method. Our comparative analysis highlights the benefits and limitations of both approaches, offering valuable insights into scenario generation in energy systems.},
  keywords={Photovoltaic systems;Uncertainty;Wind energy;Europe;Production;Microgrids;Generative adversarial networks;Data augmentation;Data models;Scenario generation;TimeGAN;synthetic scenarios;time-series data;renewable energy;scenario generation;microgrids},
  doi={10.1109/ISGTEUROPE62998.2024.10863278},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9288292,
  author={Yuan, Fangfang and Shang, Yanmin and Liu, Yanbing and Cao, Yanan and Tan, Jianlong},
  booktitle={2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Data Augmentation for Insider Threat Detection with GAN}, 
  year={2020},
  volume={},
  number={},
  pages={632-638},
  abstract={In insider threat detection domain, the datasets are highly imbalanced, where the number of user's normal behavior is higher than that of insider's anomalous behavior. A direct approach to handle the class imbalance problem is using data augmentation on the minority class. Existing data augmentation methods mainly produce synthetic samples according with the linear operation based on samples of the minority class. Hence, these methods just focus on local information which leads to the unitarily of the synthetic samples, resulting in overfitting. To enrich the diversity of the synthetic samples, we propose a deep adversarial insider threat detection (DAITD) framework using the Generative Adversarial Networks (GAN) to approximate the true anomalous behavior distribution. Specifically, we first obtain anomalous user behavior representations from the anomalous behavior data (minority class), and then use the generator of the GAN to model the actual anomalous behavior distribution, use the discriminator of the GAN to distinguish whether the synthetic sample from the generator is real or not. In this way, our method is able to generate high quality synthetic samples that are close to the anomalous user behavior. Experimental results show that the DAITD framework outperforms other comparative inside threat detection algorithms.},
  keywords={Conferences;Training data;Tools;Generative adversarial networks;Generators;Data models;Detection algorithms;insider threat detection;deep learning;GAN;imbalanced data},
  doi={10.1109/ICTAI50040.2020.00102},
  ISSN={2375-0197},
  month={Nov},}@ARTICLE{10429780,
  author={Rao, Bosen and Zhang, Jiale and Wu, Di and Zhu, Chengcheng and Sun, Xiaobing and Chen, Bing},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Privacy Inference Attack and Defense in Centralized and Federated Learning: A Comprehensive Survey}, 
  year={2025},
  volume={6},
  number={2},
  pages={333-353},
  abstract={The emergence of new machine learning methods has led to their widespread application across various domains, significantly advancing the field of artificial intelligence. However, the process of training and inferring machine learning models relies on vast amounts of data, which often include sensitive private information. Consequently, the privacy and security of machine learning have encountered significant challenges. Several studies have demonstrated the vulnerability of machine learning to privacy inference attacks, but they often focus on specific scenarios, leaving a gap in understanding the broader picture. We provide a comprehensive review of privacy attacks in machine learning, focusing on two scenarios: centralized learning and federated learning. This article begins by presenting the architectures of both centralized learning and federated learning, along with their respective application scenarios. It then conducts a comprehensive review and categorization of related inference attacks, providing a detailed analysis of the different stages involved in these attacks. Moreover, the article thoroughly describes and compares the existing defense methods. Finally, the article concludes by highlighting open questions and potential future research directions, aiming to contribute to the ongoing competition between privacy attackers and defenders.},
  keywords={Federated learning;Training;Privacy;Machine learning;Data privacy;Data models;Servers;Centralized and federated learning;machine learning security;privacy defense;privacy inference attack},
  doi={10.1109/TAI.2024.3363670},
  ISSN={2691-4581},
  month={Feb},}@INPROCEEDINGS{10947793,
  author={Sharma, Gajendra and Singh, Vivekta and Krishnamaneni, Ramesh and Murthy, Ashwin Narasimha and Verma, Ashok Kumar and Sen, Souptik},
  booktitle={2024 International Conference on Artificial Intelligence and Emerging Technology (Global AI Summit)}, 
  title={Deep Learning Approaches to Optimizing Dosage and Treatment Schedules in Kidney Disease Management}, 
  year={2024},
  volume={},
  number={},
  pages={452-456},
  abstract={The objective of this research is to investigate the optimal dosage and treatment schedules in kidney disease by means of various deep learning algorithms. Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), Generative Adversarial Networks (GAN), and Deep Reinforcement Learning (DRL) are applied on a dataset containing records of 1258 patients. The results show the overall promising potential of the developed methodologies. The accuracy of CNNs was 0.85, with sensitivity and specificity equal to 0.78 and 0.88, respectively. The Mean Squared Error (MSE) was characterized by low value in the case of RNNs, equal to 0.015. The Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) were also close to zero, a phenomenon indicative of precise prediction of disease trajectories and response to the defined treatment schedules. Finally, LSTM networks showed balanced precision of 0.79 and recall of 0.82; the F1-score was equal to 0.80, indicating that the proper optimization of designed treatment strategies to specific patient conditions was possible. To illustrate, GANs returned a reasonably good Wasserstein distance of 0.035 and Jensen-Shannon Divergence of 0.052. The Fréchet Inception Distance was, however, quite high, amounting to 78.2. In turn, Deep Reinforcement Learning (DRL) algorithms achieved a reward sum of 2350 and 45.6 for the average per episode reward. The exploration rate used in the DRL model was 0.15. Therefore, the dosing regimen was optimized effectively. As a result, the outcomes described above testify to the effectiveness of deep learning-based tools in healthcare and kidney disease.},
  keywords={Schedules;Recurrent neural networks;Medical services;Generative adversarial networks;Deep reinforcement learning;Convolutional neural networks;Optimization;Kidney;Long short term memory;Diseases;kidney disease management;deep learning;dosage optimization;treatment schedules;healthcare optimization},
  doi={10.1109/GlobalAISummit62156.2024.10947793},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9261743,
  author={Ai, Jiangshan and Chen, Sihua and Deng, Peng and Bai, Libing and Tian, Lulu and Zhang, Jie},
  booktitle={2020 International Conference on Sensing, Measurement & Data Analytics in the era of Artificial Intelligence (ICSMD)}, 
  title={CycleGANs for Semi-Supervised Defects Segmentation}, 
  year={2020},
  volume={},
  number={},
  pages={611-616},
  abstract={At present, many vision-based inspection methods are widely using for quality control in different fields. And the deep learning method has made a magnificent breakthrough in a variety of computer vision tasks, mainly through the use of largescale annotated datasets. Utilizing these progress is an option to improve defect segmentation performance. However, in the field of vision-based non-destructive testing (NDT), obtaining large scale annotated datasets is a great challenge. In this paper, a fully convolution neural network (FCN) is supervised trained using a small number of pixel-level annotated data for defect segmentation. Simultaneously, Cycle-Consistent Generative Adversarial Networks (CycleGANs) are used to learn the segmentation in an unsupervised way as a supplement. The requirement of annotated data is then reducing by utilizing many un-annotated data. Experiments on the published GDXray dataset show that the framework based on CycleGANs is effectiveness for defect image segmentation using only a few labelled samples.},
  keywords={Image segmentation;Training;Generators;Gallium nitride;Convolution;Welding;Generative adversarial networks;CycleGANs;Image Segmentation;Nondestructive Testing;Defect Inspection;Semi-supervised Learning},
  doi={10.1109/ICSMD50554.2020.9261743},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10900298,
  author={Li, Quanhong and Li, Xuehui and Liu, Zelei and Qi, Hongxing},
  booktitle={2024 4th International Conference on Artificial Intelligence, Robotics, and Communication (ICAIRC)}, 
  title={pFedCE: Personalized Federated Learning Based on Contribution Evaluation}, 
  year={2024},
  volume={},
  number={},
  pages={262-270},
  abstract={Federated learning (FL) enables collaborative model training across clients without sharing raw data, ensuring privacy while utilizing decentralized data. However, the heterogeneous distribution of data among clients can significantly degrade the performance of the global model. To address this problem, we propose a personalized FL (pFL) framework pFedCE. Unlike traditional FL, pFedCE introduces a Shapley value-based contribution evaluation during model aggregation, adaptively adjusting aggregating weights based on contribution to generate a personalized aggregation model for each client. Since direct access to client data for contribution evaluation would violate principles of FL, we utilize a Generative Adversarial Network (GAN) to generate synthetic data on the server that preserve the statistical properties of client data. We evaluated pFedCE on three benchmark datasets in three types of data distribution. The results show that pFedCE outperforms six other pFL methods.},
  keywords={Training;Adaptation models;Data privacy;Federated learning;Generative adversarial networks;Data models;Servers;Indexes;Robots;Synthetic data;Index Terms—Personalized Federated Learning;Contribution Evaluation;Shapley Value},
  doi={10.1109/ICAIRC64177.2024.10900298},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9643402,
  author={Xiaomao, Zhou and Wei, Wang and Bing, Du},
  booktitle={2021 IEEE 33rd International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={PSG-GAN: Progressive Person Image Generation with Self-Guided Local Focuses}, 
  year={2021},
  volume={},
  number={},
  pages={763-769},
  abstract={This paper proposes PSG-GAN, a novel Generative Adversarial Network for pose-guided person image synthesis, which can progressively generate realistic person images of desired poses together with corresponding semantic segmentation masks. Specifically, PSG-GAN consists of a sequence of Region-Focal Transfer Blocks (RFBs) where each contains two generation pathways: the appearance generation pathway and the semantic generation pathway. The former pathway is responsible for generating the target image by explicitly preserving appearance-related features within certain regions, where local region transformations are considered. The latter pathway is used to generate semantic masks which define the areas for the local transformations to attend to. These two learning pathways work together and reinforce each other to simultaneously generate the target image and semantic masks progressively. Qualitative and quantitative experimental results on two benchmark datasets demonstrate PSG-GAN’s superiority over other approaches in generating realistic person images in pose transfer tasks.},
  keywords={Adaptation models;Image segmentation;Image synthesis;Conferences;Semantics;Benchmark testing;Generative adversarial networks;GAN;pose-guided image generation;segmentation mask},
  doi={10.1109/ICTAI52525.2021.00121},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{11108883,
  author={Pasaribu, Fieter Brain and Dewi, Luh Joni Erawati and Aryanto, Kadek Yota Ernanda and Varnakovida, Pariwate},
  booktitle={2025 IEEE 5th International Conference on Software Engineering and Artificial Intelligence (SEAI)}, 
  title={Effect of Synthetic Data Augmentation on Plant Classification Accuracy Using MobileNetV2, EfficientNet-B0, and ResNet-18}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The classification of agricultural crops such as cassava, corn, rice, and sugarcane is crucial for efficient data collection and decision-making. However, the limited availability of labeled images poses a significant challenge in training deep learning models effectively. This study investigates the effect of synthetic data augmentation using Deep Convolutional Generative Adversarial Networks (DCGAN) and Wasserstein GAN with Gradient Penalty (WGAN-GP) on plant classification accuracy. The original dataset contained only 245 images, which were augmented using GANs to increase data diversity. Three convolutional neural networks—MobileNetV2, EfficientNet-B0, and ResNet-18—were trained on three dataset variations: the original dataset, a combination of original and synthetic images, and a fully synthetic dataset. Experimental results reveal that the use of GAN-generated data, particularly from DCGAN, negatively impacted classification accuracy due to artifacts and inconsistencies in the synthetic images. Despite achieving lower Frechet Inception Distance (FID) scores, DCGAN-generated images introduced distortions that reduced model performance. WGAN-GP produced more visually realistic images but still failed to improve classification accuracy. The highest accuracy of 97.37% was achieved using only the original dataset, while models trained with GAN-augmented datasets experienced performance degradation. These findings emphasize that when the amount of real data is limited, low-quality synthetic images can further degrade model performance rather than improving it. Future research should focus on enhancing the quality of GAN-generated images and exploring hybrid augmentation techniques for small datasets.},
  keywords={Training;Degradation;Accuracy;Noise;Generative adversarial networks;Distortion;Data models;Synthetic data;Software engineering;Image classification;agriculture;augmentation;image classification;DCGAN;synthetic dataset},
  doi={10.1109/SEAI65851.2025.11108883},
  ISSN={},
  month={June},}@INPROCEEDINGS{11035526,
  author={Tao, Liyan and Rao, Hanshu and Zhang, Linyu and Sun, Ruotong and Wang, Shizheng},
  booktitle={2025 IEEE 6th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={GAN-Based Adversarial Attack Against Malware Detection}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Traditional malware detection methods based on signatures or behaviors are increasingly struggling to cope with new types of attacks, prompting a shift towards detection methods based on machine learning and deep learning. Compared to traditional detection mechanisms, machine learning and deep learning-based methods possess stronger feature extraction and generalization capabilities. This paper presents a malware detection model implemented using a Residual Neural Network (ResNet), capable of accurately distinguishing between malicious and benign software. However, detection systems based on machine learning or deep learning have issues with robustness, as malware authors can adjust the features of their malware to evade detection. We implemented an attack method based on Generative Adversarial Networks (GAN), targeting a trained ResNet detector, and used GAN to generate adversarial malware samples. The results demonstrate that this attack strategy can dynamically generate adversarial malware samples while realistically replicating actual attack scenarios.},
  keywords={Deep learning;Seminars;Learning systems;Detectors;Generative adversarial networks;Feature extraction;Malware;Robustness;Information technology;Residual neural networks;Malware detection;GAN;ResNet;Deep learning;Adversarial malware},
  doi={10.1109/AINIT65432.2025.11035526},
  ISSN={},
  month={April},}@INPROCEEDINGS{11035176,
  author={Sun, Siwen and Fei, Lei and Yu, Yang and Song, Changjiang and Xu, Jixiu and Li, Lan},
  booktitle={2025 IEEE 6th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={Ice Classification Technology for Transmission Lines Based on Visual Images}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={In view of the icing problem that may occur on transmission lines in cold weather, traditional manual detection methods are time-consuming and difficult to accurately identify the type of icing. To this end, this paper introduces a transmission line ice classification technology based on visual images. First, an image dataset covering five types of ice coverage was constructed to solve the problem of ice coverage type recognition on transmission lines. Then, combined with the operating environment of the anti-icing and de-icing device, a corresponding control strategy is formulated, and on this basis, an improved UNet network model is introduced. Through ice image feature analysis and Generative Adversarial Network (GAN) optimization model, the classification performance is improved. In the above data conclusions,the proposed method has a significant improvement in classification accuracy, with an average classification accuracy of 92 %. In the image segmentation task, the average value of the intersection over union (IoU) is 0.844 and the Dice coefficient is 0.89, showing high robustness and segmentation accuracy. In addition, the average absolute error (AE) of thickness calculation is 0.3 mm and the relative error (RE) is 5 %, which further verifies the effectiveness and reliability of the method in practical applications. The comprehensive experimental results show that the transmission line ice classification technology based on visual images proposed in this paper can significantly improve the automation and accuracy of ice detection, and provide effective technical support for the safe operation of transmission lines.},
  keywords={Visualization;Image segmentation;Power transmission lines;Accuracy;Image recognition;System performance;Generative adversarial networks;Ice;Robustness;Meteorology;Transmission Line;Ice Detection;Visual Image;UNet Network;GAN Model},
  doi={10.1109/AINIT65432.2025.11035176},
  ISSN={},
  month={April},}@INPROCEEDINGS{10408957,
  author={Liu, Jiayu and Qu, Xiujie and He, Xinyan and Zhu, Qiang},
  booktitle={2023 IEEE 11th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={Design of Face Image Super-Resolution Network Based on Multi-scale Perceptive Inception Dense Block}, 
  year={2023},
  volume={11},
  number={},
  pages={1977-1982},
  abstract={Within the realm of image data manipulation, enhancing resolution and reconstructing facial visuals stand as pivotal methods designed to restore poorly defined images impacted by unidentified deterioration mechanisms. Traditional non-generative adversarial network (non-GAN) models suffer from high-frequency information reconstruction deficiencies when restoring high-frequency information in images. Utilizing the adversarial learning process between generators and discriminators, GANs are capable of synthesizing high-definition imagery enriched with authentic texture and enhanced clarity. However, they have inherent limitations in terms of pixel-level changes, line distortions and detail recovery. In the context of Mixed Residual of Multi-scale Perceptive Inception Dense Block GAN (MRMPIDBGAN), a Multi-scale Perceptive Inception Block (MPIB) is engineered for the robust retrieval of features and multi-scale data from facial images. Based on MPIB, a Mixed Residual of Multi-scale Perceptive Inception Dense Block (MRMPIDB) is further constructed to form the generator, which facilitates better capture and reconstruction of facial image details. Secondly, to more accurately capture the local texture information of the image, the original VGG discriminator in ESRGAN is replaced by a U-Net discriminator, and spectral normalization techniques are applied to improve the stability of the discriminator. Subsequently, an innovative upsampling technique is formulated to optimize efficacy yet minimize computational demands. Further improvements in the model's efficacy are achieved through the replacement of the traditional VGG loss by a metric grounded in perceptual criteria. Experimental results confirm the effectiveness of this algorithm in super-resolution facial image restoration and demonstrate significant advantages in facial image reconstruction, clear texture capture and feature detailing compared to existing methods.},
  keywords={Computational modeling;Superresolution;Stability criteria;Generative adversarial networks;Generators;Image restoration;Image reconstruction;facial image enhancement;GANs;perceptual metrics;hybrid upsampling},
  doi={10.1109/ITAIC58329.2023.10408957},
  ISSN={2693-2865},
  month={Dec},}@INPROCEEDINGS{10710122,
  author={Zhang, Haitao and Dai, Zhongfu and Liu, Honghui and Guan, Rufang and Huang, Yue and Tan, Zhenglin and Luo, Gongfu and Liu, Yuchen},
  booktitle={2024 International Conference on Artificial Intelligence and Power Systems (AIPS)}, 
  title={Few-Sample Wind Power Forecast Using Improved Conditional GAN and Neighborhood Search Crisscross Optimization Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={340-346},
  abstract={To address the issue of low predictive accuracy in wind power forecast (WPF) for newly established wind farm (NEWF) with limited samples, a WPF method is proposed based on an improved conditional generative adversarial network (ICGAN), improved complementary ensemble empirical mode decomposition with adaptive noise (ICEEMDAN), and neighborhood search crisscross algorithm (NSCSO) optimized bidirectional gated recurrent unit network (BiGRU). Firstly, ICGAN is introduced to extract temporal characteristics from wind power data for synthesizing high-quality sample. Subsequently, ICEEMDAN is utilized to decompose the augmented highly volatile series into sub-sequences, reducing prediction complexity. Finally, the NSCSO is employed to improve the dense layer parameters of BiGRU, thereby boosting its predictive capabilities. Results from experiments demonstrate that the proposed model surpasses other hybrid models, significantly improving the accuracy of WPF in NEWF.},
  keywords={Accuracy;Empirical mode decomposition;Adaptive systems;Wind speed;Predictive models;Wind power generation;Prediction algorithms;Generative adversarial networks;Wind forecasting;Optimization;Few-sample wind power forecast;Improved conditional GAN;Improved complementary ensemble empirical mode decomposition with adaptive noise;Neighborhood search crisscross optimization algorithm},
  doi={10.1109/AIPS64124.2024.00075},
  ISSN={},
  month={April},}@INPROCEEDINGS{10987559,
  author={Thomas, Ashwitha C and K, Preethi Salian and P, Prajwal and Nihal and Naik, Kishor S and Mascarenhas, Neil},
  booktitle={2025 International Conference on Artificial Intelligence and Data Engineering (AIDE)}, 
  title={Mitigating Biases in Dermatological Diagnosis through GAN Augmentation and Classification}, 
  year={2025},
  volume={},
  number={},
  pages={245-252},
  abstract={Skin conditions affect individuals of all skin tones, yet biases in dermatological diagnosis disproportionately impact those with darker skin, leading to significant healthcare disparities. This paper proposes a comprehensive solution that integrates advanced data preprocessing, Generative Adverserial Network (GAN) augmentation, and Convolutional Neural Network (CNN) models to mitigate these biases. The initial phase involves meticulous preprocessing of diverse dermatological image datasets, ensuring broad coverage of skin tones. Images are standardized, noise is removed, and critical features are preserved for accurate classification. To address data imbalance, particularly for underrepresented skin tones, a GAN with spectral normalization generates synthetic images of dark skin lesions, enriching the dataset and enhancing model generalization. The preprocessed and augmented dataset is used to train three CNN architectures are ResNet50, NASNetLarge, and InceptionResNetV2, each fine-tuned to optimize performance. Class weights handle imbalances, and an ensemble approach improves classification accuracy, particularly in detecting challenging conditions like melanoma across all skin tones. This combined approach of GAN augmentation and CNN-based classification offers a promising path toward more equitable dermatological diagnostics.},
  keywords={Accuracy;Noise;Medical services;Melanoma;Generative adversarial networks;Skin;Data models;Convolutional neural networks;Lesions;Residual neural networks;dermatological diagnosis;healthcare disparities;preprocessing;GAN augmentation;CNN;synthetic images},
  doi={10.1109/AIDE64228.2025.10987559},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10356447,
  author={Delage, Aurélien and Buffet, Olivier and Dibangoye, Jilles S.},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Global min-max Computation for α-Hölder Games}, 
  year={2023},
  volume={},
  number={},
  pages={518-525},
  abstract={min-max optimization problems recently arose in various settings. From Generative Adversarial Networks (GANs) to aerodynamic optimization through Game Theory, the assumptions on the objective function vary. Motivated by the applications to deep learning and especially GANs, most recent works assume differentiability to design local search algorithms such as Gradient Descend Ascent (GDA). In contrast, this work will only require $\alpha -$Hölder properties to tackle general game-theoretic problems with poor continuity assumptions. Focusing on the example of problems in which max and min optimization variables live in simplices, we provide a simple algorithm, based on Deterministic Optimistic Optimization (DOO), relying on an outer min-optimization using the solutions of an inner max-optimization. The algorithm is shown to converge in finite time to an -global optimum. Experimental validations are given and the time complexity of our algorithm is studied.},
  keywords={Deep learning;Focusing;Games;Linear programming;Generative adversarial networks;Aerodynamics;Game theory;zero-sum games;min-max;game theory;nonlinear optimization;optimization over simplices},
  doi={10.1109/ICTAI59109.2023.00083},
  ISSN={2375-0197},
  month={Nov},}@ARTICLE{10313063,
  author={Zhu, Wentao and Ma, Xiaoxuan and Ro, Dongwoo and Ci, Hai and Zhang, Jinlu and Shi, Jiaxin and Gao, Feng and Tian, Qi and Wang, Yizhou},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Human Motion Generation: A Survey}, 
  year={2024},
  volume={46},
  number={4},
  pages={2430-2449},
  abstract={Human motion generation aims to generate natural human pose sequences and shows immense potential for real-world applications. Substantial progress has been made recently in motion data collection technologies and generation methods, laying the foundation for increasing interest in human motion generation. Most research within this field focuses on generating human motions based on conditional signals, such as text, audio, and scene contexts. While significant advancements have been made in recent years, the task continues to pose challenges due to the intricate nature of human motion and its implicit relationship with conditional signals. In this survey, we present a comprehensive literature review of human motion generation, which, to the best of our knowledge, is the first of its kind in this field. We begin by introducing the background of human motion and generative models, followed by an examination of representative methods for three mainstream sub-tasks: text-conditioned, audio-conditioned, and scene-conditioned human motion generation. Additionally, we provide an overview of common datasets and evaluation metrics. Lastly, we discuss open problems and outline potential future research directions. We hope that this survey could provide the community with a comprehensive glimpse of this rapidly evolving field and inspire novel ideas that address the outstanding challenges.},
  keywords={Three-dimensional displays;Surveys;Shape;Motion capture;Biological system modeling;Electronic mail;Data collection;Human motion;generative model;deep learning;literature survey},
  doi={10.1109/TPAMI.2023.3330935},
  ISSN={1939-3539},
  month={April},}@INPROCEEDINGS{9543264,
  author={Al-Dhabi, Yunes and Zhang, Shuang},
  booktitle={2021 IEEE International Conference on Computer Science, Artificial Intelligence and Electronic Engineering (CSAIEE)}, 
  title={Deepfake Video Detection by Combining Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN)}, 
  year={2021},
  volume={},
  number={},
  pages={236-241},
  abstract={Nowadays, people are facing an emerging problem called deepfake videos. These videos were created using deep learning technology. Some are created just for fun, while others are trying to manipulate your opinions, cause threats to your privacy, reputation, and so on. Sometimes, deepfake videos created using the latest algorithms can be hard to distinguish with the naked eye. That's why we need better algorithms to detect deepfake. The system we are going to present is based on a combination of CNN and RNN, as research shows that using CNN and RNN combined achieve better results. We are going to use a pre-trained CNN model called Resnext50. Using this, we save the time of training the model from scratch. The proposed system uses Resnext pretrained model for Feature Extraction and these extracted features are used to train the Long short-term memory (LSTM). Using CNN and RNN combined, we capture the inter frames as well as intra frames features which will be used to detect if the video is real or fake. We evaluated our method using a large collection of deepfake videos gathered from a variety of distribution sources. We demonstrate how our system may obtain competitive results while utilizing a simplistic architecture.},
  keywords={Training;Privacy;Recurrent neural networks;Computer architecture;Feature extraction;Solids;Convolutional neural networks;Deep learning;Deepfake Detection;convolutional Neural Network (CNN);Recurrent Neural Network (RNN)},
  doi={10.1109/CSAIEE54046.2021.9543264},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8959855,
  author={Kao, Chien-Hao and Chen, Chih-Chieh and Tsai, Yu-Tza},
  booktitle={2019 International Conference on Technologies and Applications of Artiﬁcial Intelligence (TAAI)}, 
  title={Model of Multi-turn Dialogue in Emotional Chatbot}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  abstract={The intent recognition and natural language understanding of multi-turn dialogue is key for the commercialization of chatbots. Chatbots are mainly used for the processing of specific tasks, and can introduce products to customers or solve related problems, thus saving human resources. Text sentiment recognition enables a chatbot to know the user’s emotional state and select the best response, which is important in medical care. In this study, we combined the multi-turn dialogue model and sentiment recognition model to develop a chatbot, that is designed for used in daily conversations rather than for specific tasks. Thus, the chatbot has the ability to provide the robot’s emotions as feedback while talking with a user. Moreover, it can exhibit different emotional reactions based on the content of the user’s conversation.},
  keywords={Chatbot;Training;Generators;Decoding;Emotion recognition;Task analysis;Adaptation models;Chatbot;Multi-turn;Emotional category;Seq2Seq;SeqGAN},
  doi={10.1109/TAAI48200.2019.8959855},
  ISSN={2376-6824},
  month={Nov},}@INPROCEEDINGS{8791686,
  author={Delecourt, Simon and Guo, Li},
  booktitle={2019 IEEE Second International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)}, 
  title={Building a Robust Mobile Payment Fraud Detection System with Adversarial Examples}, 
  year={2019},
  volume={},
  number={},
  pages={103-106},
  abstract={Mobile payment is becoming a major payment method in many countries. However, the rate of payment fraud with mobile is higher than with credit card. One potential reason is that mobile data is easier to be modified than credit card data by fraudsters, which degrades our data-driven fraud detection system. Supervised learning methods are pervasively used in fraud detection. However, these supervised learning methods used in fraud detection have traditionally been developed following the assumption that the environment is benign; there are no adversaries trying to evade fraud detection system. In this paper, we took potential reactions of fraudsters into consideration to build a robust mobile fraud detection system using adversarial examples. Experimental results showed that the performance of our proposed method was improved in both benign and adversarial environments.},
  keywords={Machine learning;Online banking;Training;Robustness;Data models;Credit cards;Supervised learning;fraud-detection,-adversarial-machine-learning;oversampling},
  doi={10.1109/AIKE.2019.00026},
  ISSN={},
  month={June},}@INPROCEEDINGS{9338927,
  author={Ye, Hanmin and Liu, Wenjie and Liu, Yingzhi},
  booktitle={2020 IEEE 9th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={Image Style Transfer Method Based on Improved Style Loss Function}, 
  year={2020},
  volume={9},
  number={},
  pages={410-413},
  abstract={In order to improve the quality of composite image in the process of image style transfer. This paper proposes an image style transfer method based on an improved style loss function: the improved Gram matrix calculates the inner product of the feature map and the spatial transformation map, and then calculates the new style loss function. At the same time, combined with the content loss function, the weighted algebraic sum of the two loss functions is used as the total loss function of the neural network. The gradient descent algorithm is used to iteratively optimize to generate the style-transferred image. Experimental results show that the Peak Signal to Noise Ratio and Structural Similarity values of this method are better than other style transfer algorithms, and the image texture details and spatial arrangement are more complete.},
  keywords={Image quality;Image texture;PSNR;Neural networks;Feature extraction;Distortion;Information technology;image style transfer;gram matrix;neural network;feature extraction},
  doi={10.1109/ITAIC49862.2020.9338927},
  ISSN={2693-2865},
  month={Dec},}@INPROCEEDINGS{10284611,
  author={Ritter, Pattrick and Lucian, Devan and Anderies and Chowanda, Andry},
  booktitle={2023 4th International Conference on Artificial Intelligence and Data Sciences (AiDAS)}, 
  title={Comparative Analysis and Evaluation of CNN Models for Deepfake Detection}, 
  year={2023},
  volume={},
  number={},
  pages={250-255},
  abstract={Deepfake technology has become a significant concern due to its ability to create highly realistic fake videos and images, leading to the potential deception of individuals. Detecting deepfakes has become a critical research area in computer vision and multimedia forensics. This paper presents a comparative analysis of deepfake detection models, focusing on evaluating their accuracy and robustness. Four CNN models, namely ResNet-152, MobilenetV3, Convnext Large, and EffecientNetB7, were implemented and trained using a custom dataset obtained from FaceForensics++. The models were evaluated based on training accuracy, average loss, and testing accuracy. An LSTM layer was also incorporated into each model's architecture to leverage sequential information. The results demonstrate varying performance among the models, with EfficientNet B7 achieving the highest testing accuracy of 75%. The findings of this study provide insights for future research in this critical area.},
  keywords={Training;Deepfakes;Analytical models;Computational modeling;Forensics;Focusing;Streaming media;deepfake detection;CNN models;comparative analysis;accuracy;LSTM layer},
  doi={10.1109/AiDAS60501.2023.10284611},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9459074,
  author={Alzahrani, Yahya and Boufama, Boubakeur},
  booktitle={2021 4th International Conference on Artificial Intelligence and Big Data (ICAIBD)}, 
  title={Deep Learning Approach for Breast Ultrasound Image Segmentation}, 
  year={2021},
  volume={},
  number={},
  pages={437-442},
  abstract={Recent advances in computer-aided diagnosis (CAD) technology have brought about more possibilities to segment and classify breast tumors. In the past decades, breast related diseases have significantly grown among women and have become a leading cause of death worldwide. An effective way to diminish breast cancer is to offer a proper diagnosis in the early stages of the disease by using ultrasound images. Our work proposes a modified U-Net architecture equipped with pre-trained inception residual blocks as an encoder for breast ultrasound (BUS) image segmentation. To enhance the performance, we increased the depth of the network by adapting the inception blocks. Our proposed solution consists of a preprocessing stage, feature extraction based on inception layers and a basic U-Net decoder. We utilized two public datasets named BUSI and UDIAT. This model predicts a mask for regions of interest (ROI) in BUS images by utilizing residual connections to ensure a minimum error rate and to preserve dimensionality. Our results show improved performance over the existing U-Net architecture, as well as the more recent deep adversarial learning and Selective K-U-Net models.},
  keywords={Deep learning;Image segmentation;Solid modeling;Ultrasonic imaging;Design automation;Error analysis;Predictive models;BUS Images;Segmentation and Classification;Neural Networks},
  doi={10.1109/ICAIBD51990.2021.9459074},
  ISSN={},
  month={May},}@INPROCEEDINGS{10168560,
  author={Huang, Baichuan and Zanetti, Renato and Abtahi, Azra and Atienza, David and Aminifar, Amir},
  booktitle={2023 IEEE 5th International Conference on Artificial Intelligence Circuits and Systems (AICAS)}, 
  title={EpilepsyNet: Interpretable Self-Supervised Seizure Detection for Low-Power Wearable Systems}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Epilepsy is one of the most common neurological disorders that is characterized by recurrent and unpredictable seizures. Wearable systems can be used to detect the onset of a seizure and notify family members and emergency units for rescue. The majority of state-of-the-art studies in the epilepsy domain currently explore modern machine learning techniques, e.g., deep neural networks, to accurately detect epileptic seizures. However, training deep learning networks requires a large amount of data and computing resources, which is a major challenge for resource-constrained wearable systems. In this paper, we propose EpilepsyNet, the first interpretable self-supervised network tailored to resource-constrained devices without using any seizure data in its initial offline training. At runtime, however, once a seizure is detected, it can be incorporated into our self-supervised technique to improve seizure detection performance, without the need to retrain our learning model, hence incurring no energy overheads. Our self-supervised approach can reach a detection performance of 79.2%, which is on par with the state-of-the-art fully-supervised deep neural networks trained on seizure data. At the same time, our proposed approach can be deployed in resource-constrained wearable devices, reaching up to 1.3 days of battery life on a single charge.},
  keywords={Performance evaluation;Training;Deep learning;Neurological diseases;Runtime;Wearable computers;Neural networks;epilepsy;real-time seizure detection;self-supervised learning;wearable systems;Internet of Things (IoT)},
  doi={10.1109/AICAS57966.2023.10168560},
  ISSN={2834-9857},
  month={June},}@INPROCEEDINGS{10496974,
  author={Lei, Yue and Qi, Cong},
  booktitle={2023 5th International Workshop on Artificial Intelligence and Education (WAIE)}, 
  title={ChatGPT in Education: Angel or Evil? -A Conceptual Model to Explore Educator's Attitude Change toward ChatGPT}, 
  year={2023},
  volume={},
  number={},
  pages={65-69},
  abstract={ChatGPT as an innovative AI-based language generation chatbot has drawn a large amount of attention from educators and researchers in academia. Though ChatGPT possesses advanced technological functions, users from the educational field hold different opinions and attitudes toward ChatGPT. As using ChatGPT is becoming a non-stoppable trend, most educators and administrators changed their attitude from panic and prohibition to welcoming and embracing. This paper borrowed the concepts of attitude and attitude change from social psychology, and explained the attitude change toward ChatGPT among educators in higher education. Based on the ABC model of attitude and social judgment theory, we developed a conceptual model of attitude and attitude change from T1 to T2. We propose there will be a significant difference between attitude at T1 and that at T2 and explain such a change by using social judgement theory to highlight the significance of stimuli or persuasive messages from universities.},
  keywords={Surveys;Conferences;Education;Psychology;Chatbots;Market research;ChatGPT;attitude change;educator},
  doi={10.1109/WAIE60568.2023.00019},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9181928,
  author={Liu, Yichang and Ma, Wei},
  booktitle={2020 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)}, 
  title={Fusing Edge-information in Image Denoising Based on CNN}, 
  year={2020},
  volume={},
  number={},
  pages={544-548},
  abstract={Due to the good performance, image denoising based on Convolutional Neural Network (CNN) has been widely studied. However, most of existing methods use a single neural network for image denoising. The denoised images occur smooth edges (missing details) at a high noise level. To address this problem, we propose a dual convolutional neural network for image denoising, which is termed as Fusing Edge-information in image Denoising based on CNN (FEDnets). It consists of two parallel network branches, which respectively get the denoised image and edge details in an end-to-end manner. In addition, the edges are fused with the denoised image to get a clearer and more detailed image. Experimental results show that FEDnets can be effectively applied to noise removal tasks and recover clearer images with more edge details and textures features.},
  keywords={Image edge detection;Noise reduction;Training;Image denoising;Noise measurement;Feature extraction;Convolution;Image denoising;Edge extraction;Convolutional neural network(CNN);Fusion;Gaussian noise},
  doi={10.1109/ICAICA50127.2020.9181928},
  ISSN={},
  month={June},}@INPROCEEDINGS{10065069,
  author={Islam Zim, M D Khadimul and Rakhra, Manik and Singh, Dalwinder and Singh, Arun},
  booktitle={2022 4th International Conference on Artificial Intelligence and Speech Technology (AIST)}, 
  title={Noise Reduction and dehazing of Visual Data}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={The problem of haziness is a poorly presented problem that has been broadly contemplated in recent years. Images of dim scenes normally experience low contrast which corrupts the perceivability of the scene. Because of light scattering and absorption by climatic particles, pictures/recordings acquired from video surveillance, traffic checking, galactic imaging, clinical imaging, and remote detecting have poor perceivability. Noise and haze both degraded the overall quality of an image. So, the objective of this paper is to give a review with respect to these issues by reviewing over eleven techniques of image dehazing on different datasets. Through this paper, a thorough study and analysis of unsupervised as well as supervised techniques have been presented.},
  keywords={Visualization;Absorption;Noise reduction;Imaging;Light scattering;Speech enhancement;Video surveillance;Dehazing;supervised;unsupervised;Convolutional Neural Network;Colour attenuation;Image enhancement;Noise reduction},
  doi={10.1109/AIST55798.2022.10065069},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{7090195,
  author={Kurt, Erol and Gör, Halil},
  booktitle={Proceedings of the 2014 6th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)}, 
  title={Electromagnetic design of a new axial flux generator}, 
  year={2014},
  volume={},
  number={},
  pages={39-42},
  abstract={This study presents the electromagnetic design of a new permanent magnet generator. The machine consists of two rotors at both sides and a stator between them. The rotors have 32 rare earth disc magnets in total and the stator has 24 coils. It is a three-phase machine which produces directly sinusoidal output. According to the finite element analysis (FEA), it can produce 340 W at 1000 rpm for the air gap of 5 mm. While some distortions are seen in the waveform at lower rotor speeds such as 100- 200 rpm, the rated values are obtained at 1000 rpm. The simulations prove that the magnetic flux density of 0.6 T can be available in the air gap due to the usage of a core. The machine is easy to maintain and can be converted to a one-phase machine easily after the changes of rotor structures.},
  keywords={Magnetic cores;Stator cores;Rotors;Magnetic flux;Magnetostatics;Generators;generator;permanent magnet;finite element;power},
  doi={10.1109/ECAI.2014.7090195},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{5158988,
  author={Wang, Yuhua and Wang, HongYong and Guan, Aihong and Zhang, Huanguo},
  booktitle={2009 International Joint Conference on Artificial Intelligence}, 
  title={Evolutionary Design of Random Number Generator}, 
  year={2009},
  volume={},
  number={},
  pages={256-259},
  abstract={With simple architecture and faster speed, linear feedback shift register often is selected to produce random number in many applications. However, the random number generated by LFSR cannot meet the demand of unpredictability for secure mechanism. The nonlinearity of genetic algorithm can be used to improve the property of LFSR. We present a novel random number generator by using genetic algorithm to evolve LFSR. This random number generator is convenient for hardware implementation and has longer period and complex architecture. The property of random number generated by it can pass NIST randomness tests and meet the requirement of communication security by test.},
  keywords={Random number generation;Cryptography;Linear feedback shift registers;Genetic algorithms;Random sequences;Communication system security;Polynomials;Hardware;Testing;Vectors;Evolutiona;Random number generato;LFSR;Security},
  doi={10.1109/JCAI.2009.46},
  ISSN={},
  month={April},}@INPROCEEDINGS{10058216,
  author={Lu, Linghui and Wang, Jun and Huang, Weiguo and Shen, Changqing and Shi, Juanjuan and Zhu, Zhongkui},
  booktitle={2022 International Conference on Sensing, Measurement & Data Analytics in the era of Artificial Intelligence (ICSMD)}, 
  title={Dual Adversarial Contrast for Train Bearing Fault Diagnosis under Extremely Low Label Rate}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Fault diagnosis of train bearings is a promising approach to avoid catastrophic disasters and save train maintenance costs. Supervised fault diagnosis model is preferred because the labels of the training dataset are of great use in model training. However, the labeling of a large amount of data requires a lot of manpower and expert knowledge. The dataset in industry generally has a low label rate. Therefore, how to utilize the datasets with low label rates has become a concern. This paper proposes a new semi-supervised fault diagnosis model, which is termed dual adversarial contrast (DAC), to learn discriminative representations of train bearing health states from the dataset with extremely low label rate. Specifically, the DAC performs adversarial contrastive twice to extract features, which are more representative for bearing fault diagnosis. The proposed model is first pre-trained in an unsupervised way, and is then fine-tuned by the labeled data. A train bearing dataset with an extremely low labeling rate, i.e., 1%, is used to validate the proposed model. The results confirmed the advantages of the DAC in both diagnostic accuracy and convergence speed in comparison with the existing contrastive learning models.},
  keywords={Fault diagnosis;Training;Industries;Data analysis;Maintenance engineering;Feature extraction;Data models;Contrastive learning;extremely low label rate;fault diagnosis;semi-supervised model;train bearing},
  doi={10.1109/ICSMD57530.2022.10058216},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10463420,
  author={Ali, Ali Hasan and Muslim Jasim, Hend and Ameen Abduljabbar, Zaid and Nyangaresi, Vincent Omollo and Umran, Samir M. and Ma, Junchao and Honi, Dhafer G.},
  booktitle={2024 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Provably Efficient and Fast Technique for Determining the Size of a Brain Tumor in T1 MRI Images}, 
  year={2024},
  volume={},
  number={},
  pages={608-613},
  abstract={This work proposes an efficient a nd effective technique for determining the size of neoplasms in the brain using image processing. The cerebral hemispheres make up the largest part of the human brain, and abnormal growth of cells within them can lead to the development of neoplasms, or brain tumors. Many tumors are believed to occur for unknown reasons, which highlights the importance of annual check-ups to detect any early signs of a tumor. Image processing is a crucial component of these annual check-ups, as it can identify any changes that may have occurred in the brain since the previous check-up. This work proposes a new method that can segment the tumor through the skull and estimate its size using MRI images. The proposed method involves three steps: first, extracting t he b rain from the skull; second, applying thresholding to identify abnormal cells and segment the neoplasm; and finally, estimating t he size of the neoplasm in a fast manner. To validate the results, a comparison with other techniques such as K-means and C-means is performed. Overall, this proposed method provides a promising approach to detecting and measuring neoplasms in the brain, which could ultimately improve the diagnosis and treatment of these potentially life-threatening conditions.},
  keywords={Image segmentation;Brain;Thresholding (Imaging);Rain;Magnetic resonance imaging;Machine learning;Planning;Brain Tumor;Size estimation;Image processing;Segmentation;Neoplasm},
  doi={10.1109/ICAIIC60209.2024.10463420},
  ISSN={2831-6983},
  month={Feb},}@INPROCEEDINGS{7861084,
  author={Arslan, Sami and Iskender, Ires},
  booktitle={2016 8th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)}, 
  title={Design aspects of a 26500-rpm: 2-kw high-speed permanent magnet synchronous generator for turbomachinery systems}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={Improvements in power electronics technology, coupling technology, high quality iron core material technology and more productive permanent magnet technology in recent years have made electrical drive systems to be more effective with respect to their reduced size, enhanced working speed and increased performance. In this paper it is focused to design highly efficient high-speed permanent magnet synchronous generator of in-runner, surface mounted, 4 poles, 2 kW and 26500 rpm for turbomachinery systems especially for turbocharger which will be used in our micro-CHP project. The criteria of selecting materials, suitable machine type, rotor structures and initial boundary conditions are explained. Electric and magnetic design of the High Speed Permanent Magnet Synchronous Generator (HSPMSG) is conducted analytically in Ansys RMxprt with parametric solutions and analyzed in Ansys Maxwell 2D&3D by finite element method (FEM) with magnetostatic and transient solutions to adjust the detailed machine shape finely and to obtain the best design parameters. The retaining sleeve is also used to provide mechanical integrity and continuity of the HSPMSG and to understand whether it is suitable for working conditions at related speeds or not. This work will also be partake of development of the related designed high speed generator.},
  keywords={Rotors;Permanent magnets;Stator windings;Generators;Stator cores;Magnetic cores;High speed generator;generator design;permanent magnet;turbine engines;turbomachinery systems},
  doi={10.1109/ECAI.2016.7861084},
  ISSN={},
  month={June},}@INPROCEEDINGS{9696023,
  author={Han, Shiwen and Gao, Qiuxin and Wang, Chaoyu and Zou, Jiawei},
  booktitle={2021 2nd International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE)}, 
  title={Animal face classification based on deep learning}, 
  year={2021},
  volume={},
  number={},
  pages={324-330},
  abstract={Using deep learning to automatically identify and classify wildlife can greatly improve the efficiency of wildlife protection strategies. Based on the public data set of Animal Faces-HQ, this essay analyzed methods to classify different types of animals. Then, this essay developed the four means to predict animal species. First two adopts traditional Convolutional neural networks, while later two construct the deep-learning model based on Auto Encoder. Experimental results showed that our four methods is accuracy and effectiveness while the model in which SVM is superimposed on neural network feature extractor performs slightly better. To verify the applicability of our model, this research applied this model in additional test set of data, and it also achieved satisfactory fitting results.},
  keywords={Deep learning;Support vector machines;Image resolution;Wildlife;Neural networks;Feature extraction;Data models;Residual learning;VGG;Auto-encoder;VAE},
  doi={10.1109/ICBASE53849.2021.00067},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10541282,
  author={Jain, Sanyam},
  booktitle={2024 4th International Conference on Applied Artificial Intelligence (ICAPAI)}, 
  title={Adversarial Attack on Yolov5 for Traffic and Road Sign Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper implements and investigates popular adversarial attacks on the YOLOv5 Object Detection algorithm. The paper explores the vulnerability of the YOLOv5 to adversarial attacks in the context of traffic and road sign detection. The paper investigates the impact of different types of attacks, including the Limited-memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS), the Fast Gradient Sign Method (FGSM) attack, the Carlini and Wagner (C&W) attack, the Basic Iterative Method (BIM) attack, the Projected Gradient Descent (PGD) attack, One Pixel Attack, and the Universal Adversarial Perturbations attack on the accuracy of YOLOv5 in detecting traffic and road signs. The results show that YOLOv5 is susceptible to these attacks, with misclassification rates increasing as the magnitude of the perturbations increases. We also explain the results using saliency maps. The findings of this paper have important implications for the safety and reliability of object detection algorithms used in traffic and transportation systems, highlighting the need for more robust and secure models to ensure their effectiveness in real-world applications.},
  keywords={YOLO;Codes;Roads;Perturbation methods;Transportation;Detectors;Adversarial machine learning;Adversarial Attacks;Adversarial Training;Traffic Sign Detection;YOLOv5},
  doi={10.1109/ICAPAI61893.2024.10541282},
  ISSN={},
  month={April},}@INPROCEEDINGS{10467929,
  author={Iwabuchi, Makoto and Nakamura, Akihito},
  booktitle={2024 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)}, 
  title={A Heuristics and Machine Learning Hybrid Approach to Adaptive Cyberattack Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Cybersecurity is more significant now than ever, and the severity of the threat has escalated. One possible countermeasure is the Intrusion Detection and Prevention System (IDPS), which enables the detection of malicious activities in the network based on signature-matching and other detection methods. A signature represents the specific pattern of an attack. However, it occasionally misses malicious traffic or raises false alerts when the detection method is not carefully configured with the latest information. That is, it is susceptible to false positives or false negatives. This paper presents a highly accurate cyberattack detection method with the automatic generation of tailored signatures for a rapid response to emerging threats. We combine heuristics for known attacks and machine learning (ML) techniques to detect unforeseen attack patterns in traffic, i.e. a hybrid method. Rule-based judgment for heuristics and anomaly detection for ML are used, respectively. This study introduces a novel approach by employing machine learning with a packet-to-image conversion technique. We convert network packet data into images and utilize the image data for training and classifying attack patterns. By transforming the problem to anomaly detection in image data, the evaluation results revealed that the method has high accuracy.},
  keywords={Training;Adaptive systems;Intrusion detection;Machine learning;Feature extraction;Real-time systems;Cyberattack;cybersecurity;IDPS;honeypot;machine learning;GAN;LSTM;PNG images},
  doi={10.1109/ACDSA59508.2024.10467929},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{9760580,
  author={Mehta, Charmee and Harniya, Purvi and Kamat, Sagar},
  booktitle={2022 2nd International Conference on Artificial Intelligence and Signal Processing (AISP)}, 
  title={Comprehending and Detecting Vulnerabilities using Adversarial Machine Learning Attacks}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={In today’s world, machine learning is an emerging technology which is being used extensively in different domains. In order to offer effective solutions in the broad area of computer security with the use of machine learning (ML) models, applications which identify and protect against potential adversarial attacks are employed. In the ever-growing field of adversarial machine learning, attackers with different extents of accessibility to a machine learning model can launch a number of attacks to achieve their goals. Concurrently, ML models and algorithms are quite susceptible to various cybersecurity threats. In this paper, an in-depth survey has been carried out on the impact of cybersecurity in machine learning and the adversarial attacks which can be encountered in a ML based system.},
  keywords={Machine learning algorithms;Computational modeling;Signal processing algorithms;Signal processing;Adversarial machine learning;Computer security;adversarial machine learning;threats;cybersecurity;vulnerabilities},
  doi={10.1109/AISP53593.2022.9760580},
  ISSN={2640-5768},
  month={Feb},}@INPROCEEDINGS{10205761,
  author={Junior, Rio and Murti, Ary and Rahmawati, Dien},
  booktitle={2023 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT)}, 
  title={Implementation of Random Forest Classifier for Real-time Earthquake Detection System}, 
  year={2023},
  volume={},
  number={},
  pages={227-231},
  abstract={An earthquake is one disaster that happened unpredictably and in some cases, it harms humanity. There are lots of research that studies earthquake vibrations using machine learning algorithms. However, implementing it in real-time application systems such as early warning systems is quite challenging due to the similarity of earthquake vibrations and non-earthquake vibrations (human activities and noises). Therefore, this study proposed an earthquake detection with Random Forest Classifier to distinguish earthquake and non-earthquake vibrations in a real-time application earthquake detection system. This study shows that Random Forest Classifier in a detection device is capable of classifying non-earthquake vibrations very well while it can classify earthquake vibrations with a success rate of 78.89%.},
  keywords={Vibrations;Humanities;Machine learning algorithms;Earthquakes;Forestry;Real-time systems;Data models;Earthquake;Non-earthquake;Random Forest Classifier;Real-time application;Earthquake detection system},
  doi={10.1109/IAICT59002.2023.10205761},
  ISSN={2834-8249},
  month={July},}@INPROCEEDINGS{9403789,
  author={Sun, Yao and Wang, Dong and Wang, Wei and Xiong, Lei and Yang, Xingyu},
  booktitle={2020 International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE)}, 
  title={Confrontational flight trajectory prediction based on attention mechanism}, 
  year={2020},
  volume={},
  number={},
  pages={211-214},
  abstract={Predicting the flight trajectory of the target fighter as accurately as possible to capture the fleeting time to attack is crucial for close-range air combat, so the research has always been a focus in related fields. Without exception, it is as hard as other prediction problems due to the large degree of freedom of the solution space. All the previous methods only used the time correlation in a single trajectory data to predict and ignored the spatial correlation between the trajectory data of both sides. Therefore, not only the traditional machine learning methods but the current popular deep learning methods have less accurate predictions of trajectories, especially in the case of quick-changing, which greatly limits the practical application of this technology. In this paper, both the time and space correlation of flight trajectories are considered to express the tactical intentions in close-range air combat. Thus, the LSTM trajectory prediction method is proposed based on the combination of confrontational data and attention mechanism. Two or more flight trajectory data are used for learning and training of encoder network parameters, and then the target's trajectory is predicted by a corresponding decoder module. The method also takes the advantage of attention mechanism to strengthen the prediction accuracy. The experimental results show that the accuracy of target trajectory prediction is greatly improved, especially when the trajectory changes quickly, so it is very suitable for practical application.},
  keywords={Training;Deep learning;Correlation;Prediction methods;Feature extraction;Trajectory;Decoding;Trajectory prediction;combat flight;long and short-term memory network;attention mechanism},
  doi={10.1109/ICBASE51474.2020.00052},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9516521,
  author={Li, Weipeng and Ren, Boyuan and Xu, Haoyue and Cao, Shiyuan and Xie, Yuyangsong},
  booktitle={2021 International Symposium on Artificial Intelligence and its Application on Media (ISAIAM)}, 
  title={AutoDance: Music Driven Dance Generation}, 
  year={2021},
  volume={},
  number={},
  pages={55-59},
  abstract={Dance is a popular entertainment. In machine learning, however, dancing to music is really a challenging problem. Lately, researchers use the transformer model in order to solve this question and present an impressive result. In this paper, based on the music and motion data, we tend to use some feature extraction methods to process the training data and later dig the inner feature of data using the above model and then generate auto dance motion. In addition, we present an innovate idea about this problem by adding music emotion into the model.},
  keywords={Adaptation models;Recurrent neural networks;Music;Training data;Entertainment industry;Machine learning;Media;Dance Generation;Music Emotion;Style Transfer},
  doi={10.1109/ISAIAM53259.2021.00018},
  ISSN={},
  month={May},}@INPROCEEDINGS{10574717,
  author={Pandey, Sanjeev and Lekha, J and Kadyan, Sweety},
  booktitle={2024 3rd International Conference on Artificial Intelligence For Internet of Things (AIIoT)}, 
  title={Advancing Road Safety through Driver Drowsiness Detection Using Deep Learning Model}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Driver drowsiness poses a significant threat to public safety, contributing to numerous road accidents and fatalities annually. Drowsy drivers exhibit characteristic changes in facial expressions and behaviors, including eye closure, head nodding, and yawning. These indicators can be detected through various techniques, including image processing, computer vision, and machine learning. This research investigates a promising approach: utilizing a ResNet-101 deep convolutional neural network (CNN) for driver drowsiness detection based on eye, head, and mouth states. The model was trained on a vast dataset of 2.2 million images, covering diverse driving conditions. Despite achieving a 69% accuracy, suggesting real-world potential, computational limitations restricted training to only a quarter of the data. This necessitates further research with larger datasets and increased resources to enhance accuracy and robustness.},
  keywords={Training;Adaptation models;Accuracy;Road accidents;Computational modeling;Road safety;Magnetic heads;Driver drowsiness;deep learning;CNN;ResNet101;image processing;computer vision;facial expressions;head pose;mouth movement},
  doi={10.1109/AIIoT58432.2024.10574717},
  ISSN={},
  month={May},}@INPROCEEDINGS{10760801,
  author={C, Rukumani Khandhan and E, Gothai and G, Arun and R, Bharathi Priya},
  booktitle={2024 2nd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS)}, 
  title={Early Prediction of Chronic Obstructive Pulmonary Disease: A Deep Transfer Learning Approach}, 
  year={2024},
  volume={},
  number={},
  pages={379-387},
  abstract={Chronic Obstructive Pulmonary Disease (COPD) is a prevalent, crippling lung ailment that often progresses undetected until its advanced stages, leading to significant morbidity and mortality. Early prediction and interference are crucial to improving patient outcomes. Here, a novel approach for the early prediction of COPD using deep transfer learning is proposed. Three cutting edge models from deep transfer learning, namely Inception, ResNet, and VGGNet, are trained to extract and classify features from audio recordings of breathing sounds. These models are fine-tuned on a dataset consisting of sounds from both healthy individuals and those with COPD, along with six other lung disorders. The extracted features are used to predict the presence of COPD, enabling early detection and intervention. The outcome of the proposed methodology demonstrates the efficiency of the model’s capability to predict COPD, with the deep transfer learning models achieving high precision in distinguishing COPD patients from non-COPD individuals. This approach shows the potential for cost-effective and early prediction of COPD, facilitating timely interventions and improved management of the disease.},
  keywords={Accuracy;Lungs;Transfer learning;Neural networks;Medical services;Interference;Predictive models;Feature extraction;Chronic obstructive pulmonary disease;History;Deep Transfer Learning;Residual Neural Network (ResNet);Visual Geometry Group Network(VGGNet);COPD(Chronic Obstructive Pulmonary Disease);Long Short-Term memory (LSTM);Convolutional Neural Network (CNN)},
  doi={10.1109/ICSSAS64001.2024.10760801},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9696021,
  author={Yu, Kuai},
  booktitle={2021 2nd International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE)}, 
  title={Deep Learning for Unsupervised Neural Machine Translation}, 
  year={2021},
  volume={},
  number={},
  pages={614-617},
  abstract={With the breakthrough of deep learning techniques, many Natural Language Processing tasks have exploited the techniques to enhance performance. Neural Machine Translation, as a sub-field of NLP, also leverages deep learning methods to enhance performance. There are two main categories of NMT, the first one is supervised, and the other one is unsupervised. Supervised NMT uses labelled data and large parallel corpus for training, while unsupervised NMT only uses independent monolingual corpora for training the model. The latter one gives many conveniences in data collection but poses a great difficulty in engineering the architecture. Thus, in this paper, we give a comprehensive review of deep learning techniques for unsupervised neural machine translation.as illustrated by the portions given in this document.},
  keywords={Deep learning;Training;Computer architecture;Data collection;Data models;Machine translation;Task analysis;natural language processing;machine translation;deep learning;unsupervised learning;adversarial learning},
  doi={10.1109/ICBASE53849.2021.00121},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10141061,
  author={Sravani, Meesala and Purbey, Suniti and Chakradhar, Burada and Kumar Choudhary, Ashutosh},
  booktitle={2023 2nd International Conference on Applied Artificial Intelligence and Computing (ICAAIC)}, 
  title={Design of an Efficient Multidomain Augmented Data Aggregation Model to Solve Heterogeneity Issues for IoT Deployments}, 
  year={2023},
  volume={},
  number={},
  pages={1330-1336},
  abstract={Heterogeneity of data is a common issue in data retrieval in Internet of Things (IoT) Networks, when dealing with data from multiple sensors & sources. To retrieve data from heterogeneous sources, there are several techniques proposed by researchers, which include, Data integration, Data federation, Semantic mapping, Management of Metadata, and efficient Visualization of Data Samples. But most of the existing models that perform these tasks either have limited scalability or showcase lower processing efficiency on the collected data samples. To overcome these issues, this text proposes design of an efficient multidomain augmented data aggregation model to solve heterogeneity issues for IoT deployments. The proposed model initially converts all input data samples into 1D vectors via convolutional flatting operations. These vectors are further converted into multidomain feature sets via a combination of Frequency, Gabor, Entropy, Wavelet and Convolutional analysis. These feature sets assist in identification of differential & spatial data patterns, which can be used for further analysis. To demonstrate efficiency of the proposed model, the collected IoT datasets were given to an Auto Regressive Integrated Moving Average (ARIMA) Model for prediction of temperature and humidity levels. These predicted levels were compared with existing models, and it was observed that the proposed model was able to improve the accuracy of prediction by 8.3%, while improving the precision by 5.9%, and recall by 2.5% under real-time deployment data samples.},
  keywords={Scalability;Semantics;Predictive models;Data aggregation;Wavelet analysis;Data models;Spatial databases;IoT;Heterogeneity;Data;Samples;Sources;Multidomain;Frequency;Gabor;Wavelet;Convolution;Entropy;ARIMA;Predictions},
  doi={10.1109/ICAAIC56838.2023.10141061},
  ISSN={},
  month={May},}@INPROCEEDINGS{10067053,
  author={Kwon, Bokyung and Kim, Youngbin and Lee, Hyukjoon},
  booktitle={2023 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={A Data Augmentation Approach to 28GHz Path Loss Modeling Using CNNs}, 
  year={2023},
  volume={},
  number={},
  pages={825-829},
  abstract={Millimeter waves are easily influenced by the surrounding environment, making it difficult to predict path loss values for 28GHz communication systems. Recently, deep learning approaches have become popular mainly thanks to their superior performance in terms of prediction accuracy, generalizability as well as local adaptability. These deep learning approaches require a sufficient number of training data which often lacks variability with respect to the parameter values of base station configuration if not unavailable at all. This paper proposes to use the data augmentation approach to address these two issues by using a simulator to generate predicted data for the arbitrary values of base station parameters. It is shown that a Convolution Neural Network (CNN) trained with both measurement and augmented data outperforms a vanilla CNN model trained with measurement data only and that it can make accurate predictions for arbitrary base station configurations.},
  keywords={Deep learning;Base stations;Convolution;Communication systems;Neural networks;Millimeter wave technology;Training data;path loss modeling;data augmentation;CNN;5G},
  doi={10.1109/ICAIIC57133.2023.10067053},
  ISSN={2831-6983},
  month={Feb},}@INPROCEEDINGS{9976566,
  author={Liu, Dongming and Liu, Jianchang and Yuan, Peixin and Yu, Feng},
  booktitle={2022 4th International Conference on Industrial Artificial Intelligence (IAI)}, 
  title={A Lightweight Denoising Method Based on Noise2Void for X-ray Pseudo-color Images in X-ray Security Inspection}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={For public security and crime prevention, dualenergy X-ray detection technology has been widely used in the security inspection. Due to the special working environment of the security checker, the generated X-ray pseudo-color images contain a lot of noise. While the image denoising methods based on deep learning have made tremendous progress in the field of image denoising, most existing methods require huge training datasets and clean target images, which limits the application of these methods. In this paper, considering that clean target images are impossible to be obtained for X-ray pseudo-color images, we design a lightweight denoising method based on Noise2Void, which does not require clean target images. Moreover, a lightweight denoising network based on the depthwise separable convolution and U-net is designed to reduce computational consumption while guaranteeing denoising performance, thus ensuring wider applicability and adaptability. The method is evaluated on our real X-ray pseudo-color image dataset with the existing methods and the experimental results demonstrate that our method has better denoising performance and wider applicability.},
  keywords={Training;Convolution;Noise reduction;X-ray detection;Inspection;Safety;Security;dual-energy X-ray detection technology;image denoising;deep learning;depthwise separable convolution},
  doi={10.1109/IAI55780.2022.9976566},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10605439,
  author={Luo, Xin and Huang, Yihao and Miao, Weikai},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Real-World License Plate Image Super-Resolution via Domain-specific Degradation Modeling}, 
  year={2024},
  volume={},
  number={},
  pages={1175-1180},
  abstract={License plate (LP) recognition systems often struggle to accurately recognize images in complex environments. Recent studies have attempted to improve recognition accuracy by utilizing super-resolution (SR) technology. However, these approaches often fall short in terms of generalization performance, as they rarely consider the various degradations present in real-world images. In this paper, we propose to generate realistic degraded LP images by applying a degradation model on a high-resolution LP dataset, which can cover a wide range of the degradation variations of real-world LP images flexibly. The SR model trained with simulated degraded images has better generalization and robustness on real-world LP images. Experimental evaluations conducted on LP recognition benchmark datasets demonstrate that the proposed method not only produces visually superior results but also effectively improves recognition accuracy.},
  keywords={Degradation;Analytical models;Visualization;Image recognition;Accuracy;Superresolution;Robustness;license plate super-resolution;recognition;real-world;degradation model;high-resolution dataset},
  doi={10.1109/CAI59869.2024.00210},
  ISSN={},
  month={June},}@INPROCEEDINGS{10729979,
  author={Zeng, Xiulian},
  booktitle={2024 3rd International Conference on Artificial Intelligence and Computer Information Technology (AICIT)}, 
  title={Unmasking Intruders: An In-Depth Analysis of Anomaly Detection Using the KDD Cup 1999 Dataset}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={With the rapid development of network technologies and increasing number of complex network attacks, traditional cybersecurity approaches do not provide sufficient protection against emerging threats. In the hybrid model proposed for network anomaly detection of this paper, deep learning models like Multilayer Perceptron and Deep Neural Network are combined with classical machine learning classifiers including Decision Trees, Random Forests and Support Vector Machines. The performance of the proposed model is tested with KDD Cup 1999 dataset, which is one pf the most popular benchmark for network anomaly detection. The experiment results show that the hybrid model achieves a higher detection performance than either machine learning or deep learning approach alone. The results demonstrate that the hybrid model fuses advantageous points of diverse models, offering better performance than any other method in anomaly detectionaccuracyand robustness. This study contributes to the development of useful cybersecurity.},
  keywords={Deep learning;Adaptation models;Computational modeling;Telecommunication traffic;Data models;Robustness;Decision trees;Computer security;Anomaly detection;Random forests;anomaly detection;KDD Cup 1999 dataset;cybersecurity;hybrid models;machine learning;deep learning},
  doi={10.1109/AICIT62434.2024.10729979},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11050554,
  author={Rahman, Md Abdur and Francia, Guillermo and Shahriar, Hossain and Ahamed, Sheikh Iqbal},
  booktitle={2025 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Large Language Model can Reduce the Necessity of Using Large Data Samples for Training Models}, 
  year={2025},
  volume={},
  number={},
  pages={988-991},
  abstract={This work introduces an novel approach to improving cybersecurity systems to focus on spam email-based cyberattacks. The proposed technique tackles the challenge of training Machine Learning (ML) models with limited data samples by leveraging Bidirectional Encoder Representations from Transformers (BERT) for contextualized embeddings. Unlike traditional embedding methods, BERT offers a nuanced representation of smaller datasets, enabling more effective ML model training. The methodology will use several pretrained BERT models for generating contextualized embeddings using data samples, and these embeddings will be fed to various ML algorithms for effective training. This approach demonstrates that even with scarce data, BERT embeddings significantly enhance model performance compared to conventional embedding approaches like Word2Vec. The technique proves especially advantageous for insufficient instances of high-quality dataset. The result of this proposed work outperforms traditional techniques to mitigate phishing attacks with few data samples. This work provides a robust accuracy of 99.25% when we use multilingual BERT (M-BERT) to embed dataset.},
  keywords={Training;Support vector machines;Accuracy;Unsolicited e-mail;Bidirectional control;Transformers;Encoding;Data models;Multilingual;Context modeling;Self Attention;Multi-Head Attention;Transformer;Embedding},
  doi={10.1109/CAI64502.2025.00173},
  ISSN={},
  month={May},}
