@INBOOK{10790585,
  author={Adate, Amit and Arya, Dhruv and Shaha, Aditya and Tripathy, B. K.},
  booktitle={Deep Learning: Research and Applications}, 
  title={4 Impact of Deep Neural Learning on Artificial Intelligence Research}, 
  year={2020},
  volume={},
  number={},
  pages={69-84},
  abstract={Deep learning techniques have had a huge impact on artificial intelligence research. They have improved upon the traditional machine learning techniques where human expertise was required for feature engineering. By removing one human factor, they have moved us one step forward in the field of artificial intelligence. They have not entirely removed humans, though. They are required for designing the architectures and cleaning the data. Deep learning techniques have managed to achieve breakthrough results in domains such as speech recognition, machine translation, image recognition, and object detection. This chapter gives a brief overview of various deep learning techniques being used today. Techniques that make deep learning more effective have been described. Some interesting applications have also been covered.},
  keywords={Hidden Markov models;Vectors;Deep learning;Computational modeling;Generators;Decoding;Artificial intelligence;Probability distribution;Training data;Generative adversarial networks},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9783110670929},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10790585},}@INPROCEEDINGS{10685948,
  author={Jung, Hoin and Nascimento, Vinicius C. do and Liu, Hongyang and Wang, Xiaoqian and Koh, Cheng-Kok and Jiao, Dan},
  booktitle={2024 IEEE International Symposium on Antennas and Propagation and INC/USNC‚ÄêURSI Radio Science Meeting (AP-S/INC-USNC-URSI)}, 
  title={Explainable Planar Multiband Antenna Designer with Wasserstein Generative Adversarial Network}, 
  year={2024},
  volume={},
  number={},
  pages={1243-1244},
  abstract={In the antenna design process, predicting return loss via electromagnetic (EM) simulation is crucial for understanding the antenna's behavior. As EM simulation can be time-intensive, its role is often confined to simulating the response, and not extended to proposing alternative designs. To address this, we propose a novel artificial intelligence (AI) framework for antenna design. It comprises a regressor for accurate and fast response prediction, a generative designer for proposing a vast number of new designs that meet users' requirements, and an explainer for analyzing the impact of design parameters. Application of the proposed AI framework to the design of planar multiband antennas has demonstrated its accuracy and capability.},
  keywords={Accuracy;Conferences;Generative adversarial networks;Magnetic losses;Artificial intelligence;Electromagnetics;Antennas},
  doi={10.1109/AP-S/INC-USNC-URSI52054.2024.10685948},
  ISSN={1947-1491},
  month={July},}@INPROCEEDINGS{9390748,
  author={Cao, Minjie and Liu, Zhe and Huang, Xueting and Shen, Zhuoxuan},
  booktitle={2021 IEEE 5th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)}, 
  title={Research for Face Image Super-Resolution Reconstruction Based on Wavelet Transform and SRGAN}, 
  year={2021},
  volume={5},
  number={},
  pages={448-451},
  abstract={Super-resolution face image is the basis of high detection rate in face recognition. In order to meet the requirements of super-resolution image in face recognition, aiming at the problem of texture loss of super-resolution image under high-frequency features, a face image reconstruction method based on wavelet transform and super-resolution generative adversarial network (SRGAN) is proposed to reduce the impact of low-resolution image caused by imaging hardware, network bandwidth and sampling environment on face recognition accuracy. Firstly, the wavelet transform algorithm is used to preprocess the low-resolution face image to extract the detailed texture features of the face image under different frequencies. Then, GAN is used to learn the prior knowledge of wavelet coefficients, and the identity preserving constraint is applied to the output image, and the perceptual loss function of the fusion wavelet coefficients is realized. Finally, the deep learning model based on SRGAN is used to obtain high-resolution face images. Experimental results show that the method can achieve super-resolution restoration of low-resolution face images and meet the requirements of face recognition accuracy.},
  keywords={Face recognition;Superresolution;Reconstruction algorithms;Generative adversarial networks;Feature extraction;Image reconstruction;Wavelet coefficients;super-resolution;wavelet transform;super-resolution generative adversarial network(SRGAN)},
  doi={10.1109/IAEAC50856.2021.9390748},
  ISSN={2689-6621},
  month={March},}@INPROCEEDINGS{10630713,
  author={Sansanee, Hiranchan and Kiattisin, Supaporn},
  booktitle={2024 5th Technology Innovation Management and Engineering Science International Conference (TIMES-iCON)}, 
  title={The Current State of Generative AI Prompt Framework Design for Enhancing Utility in Organizational Decision-Making}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper proposes a novel framework that combines deep learning algorithms with reinforcement learning techniques to optimize decision-making processes in dynamic and complex environments. The framework aims to improve the accuracy, efficiency, and adaptability of AI systems in supporting strategic decision-making for organizations across various industries. Key features of generative AI prompt frameworks include the development of prompt engineering techniques, addressing technological challenges, and applying prompt engineering across various domains like entrepreneurship, art, and science. The AI PROMPT framework provides guidelines for text-to-text prompt engineering. This paper provides prompt engineering techniques and indicators to improve the overall quality and effectiveness of utility in organizational decision-making.},
  keywords={Industries;Deep learning;Heuristic algorithms;Decision making;Entrepreneurship;Reinforcement learning;Organizations;Prompt;AI;Generative AI;Decision making;Open AI;ChatGPT},
  doi={10.1109/TIMES-iCON61890.2024.10630713},
  ISSN={},
  month={June},}@ARTICLE{9247535,
  author={Park, Jeong-Eun and Kim, Goo and Hong, Sungwook},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Green Band Generation for Advanced Baseline Imager Sensor Using Pix2Pix With Advanced Baseline Imager and Advanced Himawari Imager Observations}, 
  year={2021},
  volume={59},
  number={8},
  pages={6415-6423},
  abstract={Green bands in satellite remote sensing play an important role in monitoring water and vegetation information. Due to the lack of observed green band, the Geostationary Operational Environmental Satellite (GOES-16) Advanced Baseline Imager (ABI) sensor uses a synthetic one. This study presents an ABI green band generation method using the Pix2Pix based on conditional generative adversarial networks (CGANs) and convolutional neural network techniques with data observed in the visible range of the GOES-16/ABI sensor. Our model was constructed from the radiance data sets in the red, blue, and green bands of the Advanced Himawari Imager (AHI) onboard Himawari-8/9 satellites from August 27, 2018 to May 1, 2019, and applied to generate a GOES-16 ABI green band using the ABI blue band radiance data. A comparison between the AHI and the Pix2Pix-generated AHI green bands displayed high accuracy, evaluated through bias = 0.120, root mean square error (RMSE) = 0.983 in digital number (DN) units, and correlation coefficient (CC) = 0.999. Furthermore, comparison between the Pix2Pix-generated and synthetic ABI green bands resulted in a good agreement (bias = 1.029 and RMSE = 2.892 in DN units, CC = 0.993). The statistical comparison between the green band, and red or blue band resulted in the exceptional performance of the Pix2Pix-generated ABI green band compared to the synthetic ABI green band. Consequently, our Pix2Pix-based model can be effectively used to generate nonexistent green band of ABI sensor and be applied in a variety of scientific applications requiring green band.},
  keywords={Green products;Satellites;Air pollution;Data models;Training;Vegetation mapping;Indexes;Artificial intelligence (AI);green band;Himawari;Pix2Pix;radiance;satellite remote sensing},
  doi={10.1109/TGRS.2020.3032732},
  ISSN={1558-0644},
  month={Aug},}@INPROCEEDINGS{11146384,
  author={Loevenich, Johannes F. and Lopes, Roberto Rigolin F.},
  booktitle={2025 IEEE 50th Conference on Local Computer Networks (LCN)}, 
  title={Agentic Generative AI for Automation of Cyber Security Attack Chains in Tactical MANETs}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Automating cyberattack simulations is useful for evaluating the cyber resilience of mission-critical infrastructures, such as Tactical Mobile Ad-Hoc Networks (MANETs). Traditional red teaming tools lack adaptability, integration, and scalability, which limits their applicability in dynamic military environments. This paper presents an agentic generative AI system combining Cybersecurity Knowledge Graphs (CSKGs) and Large Language Model (LLM) agents. This system autonomously generates and executes context-aware cyberattack chains. The system analyzes Cyber Threat Intelligence (CTI) data, attack tool documentation, and telemetry data to plan and orchestrate multi-stage attacks using tools such as Metasploit and Sliver within an emulated environment. This approach aligns with the Software-defined Defence (SDD) paradigm by enabling software-driven, mission-adaptive simulation of Advanced Persistent Threats (APTs). We evaluate the agent system in a controlled emulated scenario, demonstrating semi-automation from semantic threat representation to system-level exploitation involving human operators.},
  keywords={Generative AI;Large language models;Scalability;Semantics;Documentation;Ad hoc networks;Cyber threat intelligence;Telemetry;Mobile computing;Cyberattack;Artificial Intelligence;Large Language Models;Automated Penetration Testing;Autonomous Cyber Defence},
  doi={10.1109/LCN65610.2025.11146384},
  ISSN={2832-1421},
  month={Oct},}@INPROCEEDINGS{10306659,
  author={Xiang, Hongbei and Zhao, Yue and Huang, Hao and Miao, Kuo and Dong, Xiaoqiu},
  booktitle={2023 IEEE International Ultrasonics Symposium (IUS)}, 
  title={An Intelligent Ovarian Ultrasound Image Generation Algorithm based on Generative Adversarial Networks}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={A deep learning framework based on generative adversarial networks (GAN) for ovarian ultrasound (US) images synthesis is investigated. This method offers an effective solution for addressing the issue of insufficient and unbalanced data in ovarian disease research. The proposed network, built on the Triple-GAN model, can synthesize a large number of medical ovarian US images which are difficult to distinguish from the real ones. This approach effectively increases the available volume of the ultrasound images of ovarian diseases and facilitates deep learning applications in ovarian ultrasound images. It provides reliable training data replacements. The generated data were validated through professional appraisal, classification method and image metrics. The results demonstrated high credibility and quality. The feasibility of using the generated data in the intelligent classification algorithm of ovarian diseases is verified, which has important practical significance for the research and development of artificial intelligence diagnosis algorithms for various diseases in the future.},
  keywords={Deep learning;Ultrasonic imaging;Image synthesis;Training data;Generative adversarial networks;Classification algorithms;Reliability;ovarian disease;ultrasound images;image generation;generative adversarial network},
  doi={10.1109/IUS51837.2023.10306659},
  ISSN={1948-5727},
  month={Sep.},}@ARTICLE{11005520,
  author={Wang, Yingbo and He, Kun and Qu, Qiang and Du, Xiaogang and Liu, Tongfei and Lei, Tao and Nandi, Asoke K.},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Adaptive Double-Branch Fusion Conditional Diffusion Model for Underwater Image Restoration}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Underwater images suffer from light absorption and scattering, impairs their visibility and applications. Existing underwater image restoration (UIR) methods based on generative models struggle are difficult to adapt to the complex and dynamic underwater environments characterized by illumination interference, low-light conditions, and non-uniform turbidity. To address these issues, we propose Water-CDM, a novel Adaptive Double-Branch Fusion Conditional Diffusion Model for underwater image restoration. Specifically, an adaptive double-branch fusion conditional diffusion model is presented utilizing a U-shaped full-attention network and Guided Multi-Scale Retinex with Brightness Correction (GMSRBC) to restore the challenging regions within underwater images. More precisely, to correct color casts and enhance the sharpness of underwater images, a U-shaped full-attention network incorporating Attention Blocks is designed for noise estimation during the reverse process of the conditional diffusion model. Concurrently, to mitigate overexposure during the enhancement of low-light underwater images under illumination interference, the GMSRBC method, featuring an Adaptive Brightness Correction Module, is proposed to efficiently adjust the brightness of underwater images. Experimental results demonstrate that the proposed Water-CDM significantly improves the quality of underwater images in challenging scenarios. Encouragingly, our proposed Water-CDM yields superior restoration outcomes compared to current state-of-the-art methods on three challenging publicly available datasets. Our codes will be released at: https://github.com/HKandWJJ/Water-CDM.},
  keywords={Image restoration;Diffusion models;Brightness;Adaptation models;Training;Image enhancement;Image color analysis;Feature extraction;Image synthesis;Artificial intelligence;Underwater image restoration;conditional diffusion model;adaptive double-branch fusion;brightness enhancement},
  doi={10.1109/TCSVT.2025.3570372},
  ISSN={1558-2205},
  month={},}@INPROCEEDINGS{10516055,
  author={Zhu, Yuanji},
  booktitle={2024 International Conference on Distributed Computing and Optimization Techniques (ICDCOT)}, 
  title={The Interaction of Big Data and AI Intelligent Technology in Visual Design Systems}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={With the rapid development of big data and artificial intelligence (AI) technologies, their wide application in various fields has become possible. Traditional visual design systems are usually based on static rules and human experience, which are difficult to meet the personalized needs of users, resulting in low universality of design works. This article solves the problems existing in traditional research through in-depth research on the interaction of big data and AI in visual design systems, and promotes the development of more intelligent, personalized and scientific development in the field of visual design. This article takes the Generative Adversarial Network (GAN) algorithm model as the research object, and performs algorithm fusion on its generative fusion model A-VAE (Attention-Variational Autoencoder) based on variational autoencoders and attention mechanisms, and proposes a new fusion model algorithm. Through research, it has been found that the merged algorithm exhibits better image generation performance, accuracy, clarity, and diversity in visual design compared to other algorithms.},
  keywords={Visualization;Machine learning algorithms;Image synthesis;Computational modeling;Training data;Big Data;Generative adversarial networks;AI intelligence;big data processing;GAN algorithm;VAE algorithm;visual design},
  doi={10.1109/ICDCOT61034.2024.10516055},
  ISSN={},
  month={March},}@INBOOK{10950999,
  author={Mueller, John Paul and Massaron, Luca and Diamond, Stephanie},
  booktitle={Artificial Intelligence For Dummies}, 
  title={Crafting Intelligence for AI Data Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={81-95},
  abstract={Summary <p>This chapter discusses how data also contains more than just surface&#x2010;level information. Data analysis and Machine Learning (ML) enable people to push data usage beyond its previous limits to develop smarter artificial intelligence (AI) systems. This chapter introduces data analysis, which serves not as a lesser solution compared to generative or conversational AI but instead forms its very foundation. With the explosion of data availability on digital devices, data assumes new nuances of value and usefulness beyond its initial scope of teaching and transmitting knowledge. ML enables people to perform activities such as forecasting the future, classifying things in a meaningful way, and determining the optimal rational decision in a given context. Unsupervised learning occurs when an algorithm learns from plain examples without any associated response, leaving the algorithm to determine the data patterns on its own. Reinforcement learning is connected to applications for which the algorithm must make decisions, and the decisions bear consequences.</p>},
  keywords={Data analysis;Artificial intelligence;Data visualization;Oils;Internet;Companies;Machine learning algorithms;Transforms;Prediction algorithms;Data models},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394270736},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10950999},}@INPROCEEDINGS{9642841,
  author={Voronov, Vyacheslav I. and Dovgolevsky, Petr A. and Voronova, Lilia I.},
  booktitle={2021 International Conference on Quality Management, Transport and Information Security, Information Technologies (IT&QM&IS)}, 
  title={Creating a Simulation System of Orthopedic Insoles Based on Data from Three-Dimensional Scan of the Feet}, 
  year={2021},
  volume={},
  number={},
  pages={565-569},
  abstract={The article describes a software package for creating a spatial model of orthopedic insoles for patients of specialized orthopedic clinics. Methods of artificial intelligence and methods of processing input data used in the basic algorithm of the software complex are considered in detail. The features of working with various categories of three-dimensional images used for modeling insoles are considered, conclusions about the requirements for the quality and quantity of initial data are given. A series of experiments on modeling insoles based on the clinical data set were carried out and analyzed. The algorithm is based on the generative adversarial network (GAN) of the Pix2Pix architecture, modified by the authors. The software modules that implement the main functions of the software complex are described: the module for loading the initial data, the module for preparing and processing input data, the module for the main modeling kernel, and the module for visualizing the results. A 3D point cloud is used as a display format for input and output files. The goals and objectives for expanding the basic functionality of the software package have been analyzed and formulated.},
  keywords={Point cloud compression;Solid modeling;Three-dimensional displays;Software packages;Software algorithms;Training data;Generative adversarial networks;software package;generative adversarial neural network;GAN;orthopedics;data preprocessing;software architecture;orthopedic insoles},
  doi={10.1109/ITQMIS53292.2021.9642841},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10990518,
  author={Shah, Rohan and Mahato, Manimala},
  booktitle={2025 International Conference on Cognitive Computing in Engineering, Communications, Sciences and Biomedical Health Informatics (IC3ECSBHI)}, 
  title={Integrity in the Age of AI: Detecting Synthetic Text Across Platforms and Purposes}, 
  year={2025},
  volume={},
  number={},
  pages={426-431},
  abstract={The widespread use of artificial intelligence (AI)generated synthetic text in the digital age presents serious threats to the accuracy of content on a variety of platforms. The goal of this review paper is to compile and analyze the variety of studies devoted to recognizing text produced by artificial intelligence. We examine numerous approaches and instruments designed to differentiate texts written by humans and artificial intelligence, assessing their efficiency, constraints, and suitability in diverse settings. Our study covers a broad range of use cases, such as copyright verification, academic integrity, and disinformation detection. This study aims to illustrate the crucial role that detection systems play in ensuring the authenticity of content by discussing important discoveries, technological developments, and continuing issues in the field. We also examine the possible societal effects and ethical issues of implementing such technologies. This review highlights the necessity for ongoing research, development, and interdisciplinary collaboration to improve the detection of synthetic text as AI's capabilities continue to grow. Only then can the integrity of digital material be guaranteed in an increasingly automated environment.},
  keywords={Ethics;Technological innovation;Accuracy;Reviews;Text detection;Intellectual property;Regulation;Real-time systems;Artificial intelligence;Research and development;Ethical Considerations in AI;Synthetic Text Detection;Text Processing;Natural Language Processing;Content Authenticity},
  doi={10.1109/IC3ECSBHI63591.2025.10990518},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9643356,
  author={Wang, Gang and Shi, Haibo and Chen, Yufei},
  booktitle={2021 IEEE 33rd International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Self-Augmentation with Dual-Cycle Constraint for Unsupervised Image-to-Image Generation}, 
  year={2021},
  volume={},
  number={},
  pages={886-890},
  abstract={Unsupervised Image-to-Image generation has obtained many studies recently, where generative adversarial networks (GANs) have developed as an effective model. Cycle consistency or dual learning guides the GAN from aligned image pairs to the unpaired training set and can be applied for many applications based on the image-to-image generation. However, for many tasks, error accumulation, which can be produced in the progress of image reconstruction, affects the realism and quality of the generated images. To eliminate error accumulation and guide the adversarial learning, in this paper, we propose dual-cycle consistent GAN (DucGAN), a novel approach for cross-domain image-to-image generation. The key idea is to introduce dual-cycle learning, which restrains error accumulation. In our method, inter-cycle and extra-cycle are based on the cycle consistency, while the output from intercycle is cast as a new augmented input in extra-cycle. On the one hand, reconstruction loss in extra-cycle can constrain and guide the training. On the other hand, dual-cycle learning is self-augmented. Our extensive experiments on image-to-image generation tasks show that DucGAN is effective and superior to several state-of-the-art GANs.},
  keywords={Training;Conferences;Generative adversarial networks;Adversarial machine learning;Task analysis;Artificial intelligence;Image reconstruction;GAN;image-to-image generation;dual learning;cycle consistency},
  doi={10.1109/ICTAI52525.2021.00142},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{9930233,
  author={Liu, Hong and Ma, Lei},
  booktitle={2022 International Conference on Artificial Intelligence and Computer Information Technology (AICIT)}, 
  title={Infrared Image Generation Algorithm Based on GAN and contrastive learning}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  abstract={For the task of converting dimly lit, low luminance nighttime visible to infrared images, we propose a Contrastive Visible-Infrared Image Translation Network (CVIIT). To better distinguish and translate objects such as pedestrians and vehicles, we introduce an attention module based on class activation map in the generator and discriminator of the Generative Adversarial Network (GAN), which captures richer context information in the images. In addition, we introduce contrastive learning to align the generated images with the visible images in terms of content. Qualitative and quantitative experiments on a publicly available visible-Infrared image pairing dataset (LLVIP) show that the proposed method generates infrared images of significantly higher quality than other state-of-the-art image-to-image translation (I2IT) methods.},
  keywords={Image synthesis;Learning (artificial intelligence);Generative adversarial networks;Generators;Task analysis;Information technology;Visible-Infrared Image Translation;contrastive learning},
  doi={10.1109/AICIT55386.2022.9930233},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10281210,
  author={Guo, Junyan},
  booktitle={2023 4th International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)}, 
  title={Deep Learning-Enhanced Fingerprint Generation and Security Verification in the Context of Siamese Network Matching Models}, 
  year={2023},
  volume={},
  number={},
  pages={293-297},
  abstract={Fingerprint recognition, a widely adopted technology in various domains, confronts significant challenges in both technical and practical realms. Therefore, it is essential to develop an effective algorithm to improve the accuracy of fingerprint recognition. In this study, a novel method is proposed to generate fake fingerprint images by Deep Convolution Generative Adversarial Networks (DCGAN) network, utilizing FVC2002 and FVC2004 as the dataset. Furthermore, a dataset consisting of 6, 000 fingerprint pairs, with the first 3, 000 pairs collected from the same individual and the remaining 3, 000 pairs from different individuals, is employed to train a Siamese Network. Finally, the real fingerprint image and the generated fingerprint image are used as two inputs to the Siamese Network to verify whether any two fingerprint images can be incorrectly matched. Experimental results indicate that DCGAN has an excellent ability to generate fingerprint images, although a small portion of the generated images have defects, which may be caused by the model training the blank part of the images as important features, etc. Additionally, the security verification experiment employing the Siamese Network reveals potential vulnerabilities in the fingerprint recognition system, possibly stemming from the network‚Äôs focus on localized similarities between the two input fingerprint images.},
  keywords={Training;Image recognition;Image matching;Learning (artificial intelligence);Fingerprint recognition;Reliability engineering;Generative adversarial networks;Fingerprint Recognition;DCGAN;Siamese Network;Deep Learning},
  doi={10.1109/ICBAIE59714.2023.10281210},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10574667,
  author={Anushruthika and Justus, J.Jean},
  booktitle={2024 3rd International Conference on Artificial Intelligence For Internet of Things (AIIoT)}, 
  title={Secure Multi-Party Multi-Key Adversarial Cryptography Using GAN}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The realm of cryptography, rooted in neural networks, has experienced advancements following the inception of adversarial cryptography. This approach employs Generative Adversarial Networks (GANs) to construct neural networks capable of autonomously acquiring encryption skills. Our primary focus lies in ensuring the confidentiality of information within a multiagent system, with properties articulated in terms of an adversary. Our approach consists of a neural network named `Alice‚Äô to create a ciphertext from plaintext and multiple keys, for data security. Simultaneously, we introduce several neural networks, collectively called `Bob,‚Äô designed to identify and decrypt the ciphertext back to plaintext. Our system is designed to withstand various threats, including intruders possessing knowledge about the encryption process, and potentially having access to leaked ciphertext or a subset of keys. Our approach addresses the challenges posed by attackers engaging in activities like Chosen-Plaintext and Chosen-Ciphertext Attacks. Our system trains `Alice‚Äô and `Bob‚Äô collaboratively to counteract the impact of both intruders and attackers. Over the training process, Alice and Bob reach a state of equilibrium, enabling them to decrypt ciphers in the presence of intruders. Our implementation reveals that nearly 800 training epochs are necessary for model synchronization. Intruders are left with only random guesses about the plaintext, leading to increased errors. Even CPA and CCA attackers fail to strongly predict a probability of either 0 or 1, yielding probabilities close to 0.5. In contrast, Bob decrypts with minimal errors. Moreover, the study illustrates how increasing the number of keys results in faster learning for Bob.},
  keywords={Training;Ciphers;Neural networks;Buildings;Learning (artificial intelligence);Generative adversarial networks;Encryption},
  doi={10.1109/AIIoT58432.2024.10574667},
  ISSN={},
  month={May},}@INPROCEEDINGS{10281294,
  author={Cheng, Baoping and Wang, He and Wang, Sheng and Chen, Min and Tao, Xiaoming},
  booktitle={2023 4th International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)}, 
  title={Improvement of Packet Loss Concealment for EVS Codec Based on Deep Learning}, 
  year={2023},
  volume={},
  number={},
  pages={309-313},
  abstract={With the advancement of network technology, real-time communication has become an integral part of daily life. However, packet loss presents a significant challenge to the quality of real-time communication. The Enhanced Voice Services (EVS) codec includes an inherent Linear Prediction (LP)-based packet loss concealment system to mitigate the effects of packet loss, but this system exhibits noticeable limitations concerning voice quality and resilience during severe packet loss scenarios. In this paper, we propose an enhancement to the EVS‚Äôs PLC performance using a Generative Adversarial Network (GAN)-based deep learning model. This model employs a generator with an asymmetric causal convolutional network and a multi-resolution discriminator for lost speech reconstruction. Experimental results show that the proposed system outperforms the inherent PLC system of the EVS codec in terms of Perceptual Evaluation of Speech Quality (PESQ), Short Time Object Intelligibility (STOI) and PLCMOS. Additionally, subjective listening tests following the MUSHRA standard further confirmed the improvement in speech quality.},
  keywords={Deep learning;Codecs;Speech coding;Packet loss;Learning (artificial intelligence);Generative adversarial networks;Real-time systems;EVS;Packet Loss Concealment;GAN;Deep Learning},
  doi={10.1109/ICBAIE59714.2023.10281294},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{11021828,
  author={Neeraj and Rahman, Md Mokhlesur and Kabir, Md Lutful and Kabir, Sohag},
  booktitle={2024 27th International Conference on Computer and Information Technology (ICCIT)}, 
  title={Detectability Analysis of AI-generated Research Articles}, 
  year={2024},
  volume={},
  number={},
  pages={1176-1181},
  abstract={The rapid surge of AI-generated content, driven by advanced large language models (LLMs) such as ChatGPT, threatens to undermine academic integrity and redefine the boundaries of plagiarism in scholarly work. This article evaluated the efficacy of five publicly available AI content detection tools in differentiating human-generated content from AI-generated ones. During the assessment, an AI-authored article was analysed using Sapling AI, Turnitin, GPTZero, Copyleaks, and Quillbot tools to assess their effectiveness in detecting AI-generated content. Following the detection reports, the paper was manually revised and resubmitted to the same tools to assess their ability to detect altered AI-authored content. This approach highlighted the susceptibility of these tools to modified texts and emphasised the difficulties in reliably detecting AI-created content. The analysis was conducted using the tools in their default state as black-box systems, without a thorough analysis of their underlying mechanisms or algorithms. Furthermore, the evaluation is confined to a single article on a specific topic, and as such, the performance of the tools assessed cannot be regarded as representative. To gain a comprehensive understanding of the effectiveness of these tools, further research and assessment involving articles from diverse disciplines and a variety of writing styles is essential.},
  keywords={Generative AI;Large language models;Plagiarism;Writing;Chatbots;Reliability;Artificial intelligence;Surges;Information technology;Monitoring;Artificial Intelligence;Generative AI;Large Language Models;AI-authored content;ChatGPT;Academic Integrity},
  doi={10.1109/ICCIT64611.2024.11021828},
  ISSN={2474-9656},
  month={Dec},}@INPROCEEDINGS{11016455,
  author={Heredia, Alfonso Serrano and del Pilar Garc√≠a-Chitiva, Mar√≠a and Camacho-Z√∫√±iga, Claudia and Mirabal, Luis Fernando Mor√°n and V√°zquez-Villegas, Patricia},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Remediation of Mathematics Knowledge in Engineering Students Through an AI-Based Selfstudy Educational Intervention}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={This study addresses the remediation of mathematical knowledge in engineering education, a critical issue as many students lack foundational skills upon entering essential courses. We conducted a quasi-experimental study that compared traditional instruction methods with a self-study strategy across three phases: diagnosing initial knowledge, providing tailored self-study resources to an experimental group, and assessing the effectiveness of the intervention. During the first period of the Fall 2024 semester, an initial diagnostic test on key mathematical topics was administered via CANVAS in a first-year Engineering and Sciences course. The experimental group received CANVAS instructional videos, supplementary documents, and access to the AI tool Jungle for optional self-study. In contrast, the control group had access to voluntary tutoring sessions. Post-intervention, both groups completed a final exam to measure improvements in problemsolving abilities. Additionally, a follow-up survey gathered feedback on self-study materials and Jungle. The analysis shows a positive correlation between Jungle usage and academic improvement. Jungle users initially scored slightly lower, saw greater improvements, and achieved higher post-test and final scores. The experimental group of Jungle users showed a statistically significant score improvement over the control group ($p=0.05$). Qualitative feedback highlights Jungle's effectiveness, feedback, and ease of use, though students suggested enhancing question variety. Results demonstrate the potential of structured self-study interventions to improve mathematical understanding among engineering students. The theoretical implications of this work are that by emphasizing tailored resources, this study aims to contribute effective strategies for bridging knowledge gaps in STEM education, enhancing student retention, and supporting academic success in engineering programs.},
  keywords={Knowledge engineering;Surveys;Technological innovation;Correlation;Generative AI;Learning (artificial intelligence);Mathematics;Engineering students;STEM;Videos;educational innovation;higher education;generative artificial intelligence;STEM},
  doi={10.1109/EDUCON62633.2025.11016455},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{5444,
  author={Irani, E.A. and Long, J.M. and Slagle, J.R.},
  booktitle={Proceedings of the Symposium on the Engineering of Computer-Based Medical}, 
  title={Experimenting with artificial neural networks-artificial intelligence mini-tutorial. 3}, 
  year={1988},
  volume={},
  number={},
  pages={45-46},
  abstract={For pt.1 see ibid., p.33-42; for pt.2 see ibid., p.43-4. To show how neural nets work, experiences in an experiment using them are described. The experiment involves using AI techniques to assist in the discovery of causal relationships between the variables existing in a large clinical trial database. A peripheral vascular disease database was used to acquire a feeling for the complexities involved in developing a distributed encoding scheme and to determine the computational resources required to train a neural net for the type of data used. By testing several models the effects of changes in the encoding scheme and the number of training iterations the system needed to predict the appropriate change needed could be determined. These results were compared to the information available from other analyses of the same data. The generative capabilities of the system were then tested by training it over one sample of cases and applying it to cases it had not encountered before. Some idea of the computational resources needed in terms of time and memory capacity was developed.<>},
  keywords={Tutorial;Artificial neural networks;Encoding;System testing;Artificial intelligence;Clinical trials;Atherosclerosis;Distributed databases;Computer peripherals;Distributed computing},
  doi={10.1109/ECBS.1988.5444},
  ISSN={},
  month={June},}@INPROCEEDINGS{10108101,
  author={Li, Xinze},
  booktitle={2022 2nd International Conference on Big Data, Artificial Intelligence and Risk Management (ICBAR)}, 
  title={Study on Image-to-image Translation Based on Generative Adversarial Networks}, 
  year={2022},
  volume={},
  number={},
  pages={92-97},
  abstract={Image-to-image translation has become an increasingly popular technology across multiple areas such as and computer vision, computer graphics, and image processing. The technology learns the features of existing pictures through neural network algorithms and apply them to the output pictures. For example, a picture can be transferred into an oil painting style, and a scene can be presented in the form of RGB images, gradient fields, edge maps, semantic label maps and so on. This paper provides an overview on current research progress on image-to-image translation based on generative adversarial networks (GANs) approaches, including supervised methods based on conditional GAN and unsupervised methods using Cycle GAN and StarGAN. Their performance is compared and their shortcomings are discussed, respectively. Finally, some possible directions for future research are provided.},
  keywords={Computer vision;Oils;Image processing;Image edge detection;Semantics;Neural networks;Computer graphics;generative adversarial networks;Cycle GAN;StarGAN},
  doi={10.1109/ICBAR58199.2022.00025},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10229250,
  author={Duin, Ann Hill and Pedersen, Isabel and Hall, Jim and Card, Dan and Breuch, Lee-Ann Kastman},
  booktitle={2023 IEEE International Professional Communication Conference (ProComm)}, 
  title={Co-AI Technical Writing: Documentation, Experimentation, User Testing, & Ethical Design}, 
  year={2023},
  volume={},
  number={},
  pages={41-43},
  abstract={OpenAI‚Äôs ChatGPT technology is now in use across academic and professional contexts, and co-writing content with AI is eclipsing older notions of AI assistantship. This panel re-envisions co-AI technical and professional writing amid this transformative AI writing landscape, inviting participants to join in discussion and research on documenting generative AI‚Äôs ability to develop documentation; providing critical examination to deal with issues of explainability, transparency, and user advocacy; introducing co-AI technical writing and usability testing to students; and designing ethical futures through use of ethical algorithmic impact assessment tools and processes.},
  keywords={Ethics;Documentation;Chatbots;Artificial intelligence;Usability;Testing;Artificial Intelligence;ChatGPT;co-AI technical writing;designing ethical futures},
  doi={10.1109/ProComm57838.2023.00006},
  ISSN={2158-1002},
  month={July},}@INPROCEEDINGS{11117931,
  author={Jiang, Yiping and Su, Guanpeng},
  booktitle={2024 7th International Conference on Mechatronics and Computer Technology Engineering (MCTE)}, 
  title={Utilizing GPT and Deep Learning Networks for Image Analysis of Apple News Headlines}, 
  year={2024},
  volume={},
  number={},
  pages={1473-1476},
  abstract={This study explores the fusion of Generative Pretrained Transformers (GPT) and Attention-based Long Short-Term Memory (Attention-based LSTM) models within deep learning networks to analyze concurrent Apple news headlines. The research delves into the collaboration between sophisticated natural language processing techniques, such as GPT, and convolutional or recurrent neural networks, aimed at extracting meaningful features from textual data. Through the meticulous evaluation of performance metrics and comparative analyses, the effectiveness of this integrated approach is firmly established. The findings offer valuable insights for the improvement of multimedia content analysis and recommendation systems on digital news platforms, thus contributing significantly to the evolution of sentiment analysis within the domain of Apple-related news.},
  keywords={Deep learning;Analytical models;Sentiment analysis;Recurrent neural networks;Semantics;Transformers;Feature extraction;Artificial intelligence;Long short term memory;Recommender systems;Generative Pretrained Transformers (GPT);Deep Learning Networks;Attention-based LSTM;Apple news},
  doi={10.1109/MCTE62870.2024.11117931},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10814437,
  author={Chakraborty, Supratim and Chitta, Nithin and Sundaresan, Rajesh},
  booktitle={2024 20th International Conference on Network and Service Management (CNSM)}, 
  title={Demonstration of Automation of Network Configuration Generation using Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={A network service provider (SP) often requires months of planning and testing to launch a new service in the form of a tariff plan. This is because SPs traditionally used operation support systems and business support systems which are large multi-vendor systems with custom implementations that are not easily amenable to launching new digital services such as internet, voice, SMS, IoT. In another detailed work, we have highlighted the challenges and proposed a faster approach to provisioning such services on the network. The method used a deep neural network framework and a large language model to automate the generation of network configurations. In this submission, we propose to demonstrate our solution framework.},
  keywords={Automation;Generative AI;Large language models;Tariffs;Artificial neural networks;Planning;Internet of Things;Testing;Business;Artificial Intelligence;Network Provisioning;Generative AI},
  doi={10.23919/CNSM62983.2024.10814437},
  ISSN={2165-963X},
  month={Oct},}@ARTICLE{10144785,
  author={Huang, Shuo and Sun, Liang and Yousefnezhad, Muhammad and Wang, Meiling and Zhang, Daoqiang},
  journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering}, 
  title={Functional Alignment-Auxiliary Generative Adversarial Network-Based Visual Stimuli Reconstruction via Multi-Subject fMRI}, 
  year={2023},
  volume={31},
  number={},
  pages={2715-2725},
  abstract={Functional Magnetic Resonance Imaging (fMRI) provides more precise spatial and temporal information to reconstruct stimulus images than other technologies that can be used to measure the human brain‚Äôs neural responses. The fMRI scans, however, generally show heterogeneity among different subjects. The majority of the existing methods aim primarily at mining correlations between stimuli and evoked brain activity, disregarding the heterogeneity among subjects. Therefore, this heterogeneity will impair the reliability and applicability of multi-subject decoding results, leading to sub-optimal results. The present paper proposes the functional alignment-auxiliary generative adversarial network (FAA-GAN) as a novel multi-subject approach for visual image reconstruction that employs functional alignment to alleviate the heterogeneity between subjects. Our proposed FAA-GAN includes three key components: 1) a generative adversarial network (GAN) module for reconstructing visual stimuli, which consists of a visual image encoder as the generator that uses a nonlinear network to convert stimuli images into an implicit representation and a discriminator that generates the images comparable to the original images in detail; 2) a multi-subject functional alignment module, which is used to precisely align the individual fMRI response space of each subject in a common space to reduce the heterogeneity among different subjects; and 3) a cross-modal hashing retrieval module used for similarity retrieval of two modalities of data, i.e., the visual images and the evoked brain responses. Experiments on real-world datasets show that our FAA-GAN method does better than other state-of-the-art deep learning-based reconstruction methods with fMRI.},
  keywords={Image reconstruction;Visualization;Functional magnetic resonance imaging;Decoding;Generative adversarial networks;Task analysis;Deep learning;Functional magnetic resonance imaging;visual image reconstruction;multi-subject analysis;functional alignment;generative adversarial network},
  doi={10.1109/TNSRE.2023.3283405},
  ISSN={1558-0210},
  month={},}@INPROCEEDINGS{10779891,
  author={Shirsat, Shweta and Abraham, Siby},
  booktitle={2024 IEEE International Conference on Signal Processing, Informatics, Communication and Energy Systems (SPICES)}, 
  title={Crafting Synthetic Dental Radiographs with Generative Adversarial Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Artificial Intelligence has the potential to revolutionize dental radiology practices. However, training AI models necessitates precise and dependable training data, which can be challenging and costly to acquire. This study aims to generate synthetic or artificially generated data using a generative artificial intelligence technique. Specifically, it investigates synthetic radiography's utility in enhancing the clinical value of panoramic dental radiographs generated by Generative Adversarial Networks (GANs), a generative AI technique. We apply Fr√©chet Inception Distance (FID) to assess the quality of radiographs generated, finding similarities with other high-resolution tasks. Evaluating radiographic clinical realism involves having radiologists differentiate among authentic and synthetic radiographs. Our results reveal that the synthetic dental radiographs are prone to be classified as authentic showing FID as 18.1%o, indicating progress yet there exists room for refinement to achieve true degree of realism.},
  keywords={Training;Generative AI;Training data;Signal processing;Radiology;Generative adversarial networks;SPICE;Dentistry;Diagnostic radiography;Synthetic data;Panoramic Radiographs;Generative adversarial networks;Generator;Discriminator;Dentistry;Synthetic;Authentic},
  doi={10.1109/SPICES62143.2024.10779891},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10535027,
  author={Kim, Carina and Cho, Sungyoon and Park, Yujin and Lee, Luke and Lee, Jin-Kook},
  booktitle={2023 IEEE MIT Undergraduate Research Technology Conference (URTC)}, 
  title={Transforming Architectural Visualizations for Generative xR Renderings using Fine-tuned AI Models}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper explores the transformative potential of extended reality (xR) and generative artificial intelligence (AI) in architecture visualization. For heightened application, the authors mainly focus on generating monoscopic 360 images that are transferable into xR devices. Investigating monoscopic 360 architectural renderings through generative AI powered by few-shot learning methods, the authors adapt different styles while reflecting on real-life streetscapes. This research presents a methodical strategy that incorporates supplementary training through the stages of data collection and preparation, fine-tuning of hyper-parameters, and training processes. The effectiveness of few-shot learning heavily depends on the availability of high-quality training data with consistent representation, emphasizing the importance of the Data Collection and Preparation stage. The authors employ the Low-rank Adaptation (LoRA) approach to facilitate few-shot learning for architectural visualization. The research underscores the considerable impact achievable through the integration of extended reality with Generative AI into the architecture and planning process, presenting a valuable and transformative tool for designing buildings that seamlessly incorporate existing physical settings with prompted aesthetic visualizations.},
  keywords={Training;Solid modeling;Three-dimensional displays;Generative AI;Extended reality;Image synthesis;Training data;machine learning;generative AI;monoscopic 360 virtual reality;mixed reality;image to image generation},
  doi={10.1109/URTC60662.2023.10535027},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9247916,
  author={Luna, Paola Andrea Z√°rate and Sotelo, Jesus Alfonso L√≥pez},
  booktitle={2020 IEEE Colombian Conference on Applications of Computational Intelligence (IEEE ColCACI 2020)}, 
  title={Systematic Literature Review: Artificial Neural Networks Applied in Satellite Images}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={For approximately 50 years, artificial neural networks have been playing a decisive role in the technological advances of the world, however, their application in the treatment of satellite images has not reached the expected potential since researchers have had to face to several problems such as object recognition, classification and semantic segmentation in images of low spatial resolution due to the high costs generated by building an optimal training and testing data set. This article presents the systematic review of large research literature and the most relevant papers presented in the last decade. The main sources chosen for the review were the IEEE digital library, the indexing of the SCOPUS system database and the Science Direct repository, with a total search of 386 articles related to the case study that after applying different filters, Inclusion and exclusion criteria are deepened in detail with 30 of them, finding an ascending scale in the amount of research developed in recent years, demonstrating the great interest and growth of this type of artificial intelligence technique.},
  keywords={Training;Systematics;Satellites;Semantics;Artificial neural networks;Spatial resolution;Testing;artificial neural network;deep learning;convolutional networks;generative model;satellite images},
  doi={10.1109/ColCACI50549.2020.9247916},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10849485,
  author={Alghamdi, Tareq and Vittorini, Tommaso and Spreafico, Marco and Battaglieri, Marco and Sato, Nobuo and Li, Yaohang},
  booktitle={2024 IEEE 36th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Unfolding Particle Detector Acceptance in High Energy Physics with Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={962-968},
  abstract={The ‚Äúacceptance problem‚Äù in high energy physics (HEP) refers to the challenge of accurately modeling detector acceptance to ensure the precision of measurements. This study explores the application of Generative AI to address the acceptance problem in HEP. By training a Generative Adversarial Network (GAN) on simulated detector data (pseudo-data), we demonstrate its capability to learn detector responses and generate synthetic data that closely match measured distributions. A key component of our methodology is a custom generator loss function that incorporates physics-informed principles to improve training. This custom loss function penalizes deviations from the true distribution of event components, ensuring that the generated samples adhere to the underlying physics. Additionally, we trained a binary classifier to distinguish between different topological states (measured and unmeasured events) within the generated Monte Carlo pseudodata, further refining the model's accuracy. Our approach preserves correlations between kinematic variables across multiple dimensions, providing an accurate representation of the underlying physics. Validation with Monte Carlo pseudodata demonstrates the method's ability to recover true distributions even in regions with limited detector sensitivity, establishing a solid foundation for applying our framework to real experimental data. Our results highlight the feasibility and advantages of using generative AI in HEP, paving the way for broader applications in the field.},
  keywords={Training;Monte Carlo methods;High energy physics;Accuracy;Sensitivity;Generative AI;Detectors;Generative adversarial networks;Solids;Synthetic data;Generative AI;Acceptance Problems;High Energy Physics (HEP);Detector Effects},
  doi={10.1109/ICTAI62512.2024.00138},
  ISSN={2375-0197},
  month={Oct},}@INPROCEEDINGS{10008604,
  author={Catak, Ferhat Ozgur and Kuzlu, Murat and Sarp, Salih and Catak, Evren and Cali, Umit},
  booktitle={2022 IEEE Globecom Workshops (GC Wkshps)}, 
  title={Mitigating Attacks on Artificial Intelligence-based Spectrum Sensing for Cellular Network Signals}, 
  year={2022},
  volume={},
  number={},
  pages={1371-1376},
  abstract={Cellular networks (LTE, 5G, and beyond) are dramatically growing with high demand from consumers and more promising than the other wireless networks with advanced telecommunication technologies. The main goal of these networks is to connect billions of devices, systems, and users with high-speed data transmission, high cell capacity, and low latency, as well as to support a wide range of new applications, such as virtual reality, metaverse, telehealth, online education, autonomous and flying vehicles, advanced manufacturing, and many more. To achieve these goals, spectrum sensing has been paid more attention, along with new approaches using artificial intelligence (AI) methods for spectrum management in cellular networks. This paper provides a vulnerability analysis of spectrum sensing approaches using AI-based semantic segmentation models for identifying cellular network signals under adversarial attacks with and without defensive distillation methods. The results showed that mitigation methods can significantly reduce the vulnerabilities of AI-based spectrum sensing models against adversarial attacks.},
  keywords={Cellular networks;Solid modeling;Analytical models;5G mobile communication;Computational modeling;Data models;Sensors;Adversarial machine learning;artificial intelligence;spectrum sensing;cellular networks},
  doi={10.1109/GCWkshps56602.2022.10008604},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10914961,
  author={Shah, Vishal H and Mishra, Abhishek Kumar and Chandra, Nilanshu and Kumar, Shivam and Dash, Prajna Parimita},
  booktitle={2025 3rd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)}, 
  title={Low Resolution Medical Image Enhancement Using Generative Artificial Intelligence}, 
  year={2025},
  volume={},
  number={},
  pages={1813-1818},
  abstract={Accurate diagnosis through medical image data is the base of proper prognosis in healthcare, which requires high-quality medical image. Enhancement of various low-resolution medical images in healthcare needs attention. The research addresses the challenge of generating high-resolution images from low-resolution inputs, a critical difficulty in picture super-resolution. Super-Resolution GAN (SRGAN), which enhances image quality through perceptual loss to produce visually realistic and high-resolution outputs, has been employed. Through experiments and evaluation, we demonstrated the effectiveness of SRGAN compared to other variants of GAN in producing realistic, high-resolution images, showcasing the advancements made in image generation tasks using GANs.},
  keywords={Training;Measurement;Image synthesis;Superresolution;Noise;Medical services;Generative adversarial networks;Internet of Things;Prognostics and health management;Medical diagnostic imaging;Medical Image;Image Denoising;Resolution Enhancement;Generative Adversarial Networks (GANs);CGAN;SRGAN},
  doi={10.1109/IDCIOT64235.2025.10914961},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{11010039,
  author={Li, Haitao and Zheng, Zhe and Cui, Wenpeng and Li, Mingxuan and Guo, Wanpeng and Li, Mingyue and Yang, Qingchen and Chen, Yuzhe},
  booktitle={2025 2nd International Conference on Smart Grid and Artificial Intelligence (SGAI)}, 
  title={Research and Implementation of Intelligent Monitoring System for Power Transmission Line Faults}, 
  year={2025},
  volume={},
  number={},
  pages={1090-1095},
  abstract={Power transmission lines, though widely distributed, remain vulnerable to various hazards. While visual monitoring technologies have significantly reduced manual inspection workloads, conventional monitoring devices still exhibit limitations under nocturnal conditions, particularly regarding in detail preservation. These constraints necessitate further improvements to ensure the secure and stable operation of power systems. This paper presents a Transformer-based and HVI-GLARE Fusion Low-Light Image Enhancement network (THG-LLIE) that integrates HVI color space characteristics with generative latent feature retrieval methodology. Comparative experimental analysis demonstrates that our proposed algorithm achieves superior image enhancement results across both quantitative and qualitative metrics relative to state-of-the-art enhancement approaches. Additionally, we have developed a domestically produced AI chip based on our proprietary architecture, enabling implementation of an intelligent AI-based detection system for power transmission line fault monitoring.},
  keywords={Measurement;Visualization;Power transmission lines;Image color analysis;AI accelerators;Transformers;Propagation losses;Smart grids;Monitoring;Image enhancement;Smart Grid Infrastructure;Artificial Intelligence Algorithms;Low-Light Image Enhancement},
  doi={10.1109/SGAI64825.2025.11010039},
  ISSN={},
  month={March},}@INPROCEEDINGS{10159767,
  author={Poje, Kristijan and Brcic, Mario and Kovaƒç, Mihael and Krle≈æa, Dalibor},
  booktitle={2023 46th MIPRO ICT and Electronics Convention (MIPRO)}, 
  title={Challenges in Collective Intelligence: A Survey}, 
  year={2023},
  volume={},
  number={},
  pages={1033-1038},
  abstract={Collective Intelligence (CI) has been gaining significant attention as an effective method for decision-making and forecasting. Prediction Markets (PMs), as a subset of CI, aim to aggregate participants‚Äô diverse opinions and knowledge to produce more accurate predictions than any individual could make alone. The unique market-based mechanism of PMs incentivizes participants to reveal their information truthfully, leading to a collectively superior prediction. However, CI and PMs have challenges, including manipulation, fallacies, and group polarization. This paper provides an overview of the challenges facing CI and PMs as tools for collective knowledge aggregation and examines the role of machine learning (ML) models as tools for amplification and hybridization in the future development of CI. Furthermore, the importance of continued research in this field is emphasized.},
  keywords={Surveys;Analytical models;Aggregates;Machine learning;Collective intelligence;Reliability;Forecasting;collective intelligence;prediction markets;artificial cognition;challenges},
  doi={10.23919/MIPRO57284.2023.10159767},
  ISSN={2623-8764},
  month={May},}@ARTICLE{10478356,
  author={McCormack, Jon and Samsel, Francesca},
  journal={IEEE Computer Graphics and Applications}, 
  title={Jon McCormack: Art Infused With [Artificial] Intelligence}, 
  year={2024},
  volume={44},
  number={2},
  pages={46-54},
  abstract={We requested an interview with Jon McCormack after we encountered his work when looking for artists doing compelling work at the intersection of art and artificial intelligence (AI).},
  keywords={Art;Artificial intelligence;Interviews},
  doi={10.1109/MCG.2023.3348588},
  ISSN={1558-1756},
  month={March},}@INPROCEEDINGS{11039478,
  author={Howlett, Ethan and Catlett, Joe and Memari, Majid},
  booktitle={2025 Intermountain Engineering, Technology and Computing (IETC)}, 
  title={Intelligent Meal Planning: A Generative LLM-Based Autonomous Agent Application}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={In this paper, we present What‚Äôs for Dinner, an intelligent mobile application that transforms meal planning by integrating advanced Large Language Models (LLMs) with state-of-the-art image analysis and Natural Language Processing (NLP) techniques. Our innovative system accurately identifies food items, maintains a dynamic virtual pantry, and retrieves or generates personalized recipe recommendations complete with detailed instructions. By leveraging an API-driven architecture, the system eliminates the need for local model storage and enables efficient real-time processing. The application couples a precise photo analysis module with a sophisticated recommendation engine, codenamed "Sous-Chef", ensuring scalability and high performance.},
  keywords={Technological innovation;Accuracy;Large language models;Scalability;Transforms;Natural language processing;Autonomous agents;Planning;Time factors;Resource management;Generative AI;Large Language Models (LLMs);Autonomous Agent Systems;Computer Vision;Natural Language Processing (NLP);Deep Learning;Artificial Intelligence (AI);Human-Computer Interaction;Personalized Recommendation Systems;Privacy-Preserving Algorithms},
  doi={10.1109/IETC64455.2025.11039478},
  ISSN={},
  month={May},}@INPROCEEDINGS{10281216,
  author={Teng, Zi and Wang, Huan and Yu, Xiaosheng and Wu, Chengdong},
  booktitle={2023 4th International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)}, 
  title={Degradation Adaption Based Heterogeneous Face Hallucination}, 
  year={2023},
  volume={},
  number={},
  pages={329-332},
  abstract={In real-world long-range surveillance systems, thermal face images captured from a distance suffer from low resolution and noise, posing challenges for thermal-to-visible face image translation. Current methods assume similar resolutions and noise-free conditions between thermal and visible images, limiting their applicability. To address these issues, we propose the Degradation Adaption Network (DANet), which synthesizes high-quality visible images from low-quality thermal images. DANet combines pretrained Generative Adversarial Network (GAN) blocks with a U-shaped deep neural network (DNN) to incorporate faithful facial priors, including geometry, facial textures, and colors. Additionally, an unsupervised degradation representation learning scheme is developed to capture abstract degradation representations of degraded thermal images in a representation space. This approach allows DANet to adapt spatial features based on the degradation representation, striking a balance between fidelity and texture faithfulness using degradation-aware feature fusion (DAFF) blocks. Experimental results demonstrate that DANet outperforms state-of-the-art methods, showing its effectiveness in handling real-world low-quality thermal images across diverse practical applications.},
  keywords={Degradation;Representation learning;Geometry;Image resolution;Image color analysis;Artificial neural networks;Generative adversarial networks;component;Heterogeneous face hallucination;facial priors transformation;generative adversarial network;contrastive learning},
  doi={10.1109/ICBAIE59714.2023.10281216},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9884798,
  author={Guo, Yu-Shi and Li, Heng-Chao and Hu, Wen-Shuai and Wang, Wei-Ye},
  booktitle={IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium}, 
  title={SAR Image Data Augmentation via Residual and Attention-Based Generative Adversarial Network for Ship Detection}, 
  year={2022},
  volume={},
  number={},
  pages={439-442},
  abstract={In recent years, generative adversarial networks (GANs) have been successfully applied to generate the SAR images. However, due to the fact that it is more difficult to generate the images than to distinguish the real or fake, GANs usually suffer from the problems of unstable training and mode collapse. As such, a residual and attention-based generative adversarial network (RAGAN) is proposed for SAR data augmentation. Firstly, the directional bounding box is used as a constraint in the RAGAN to limit the position of ship in the generated SAR image, which can be further set as the annotation of the SAR image for ship detection directly. After that, inspired by the residual and attention learning, a residual and attention block (RABlock) and a transposed RABlock (TRABlock) are designed to improve the generator of the RAGAN, thus preventing the whole model from gradient vanishing and suppressing the effects of speckle noise and background to enhance the quality of the generated SAR images. Experimental results on the HRSID data set demonstrate the effectiveness of our RAGAN model in SAR data augmentation for ship detection.},
  keywords={Training;Annotations;Speckle;Generative adversarial networks;Radar polarimetry;Generators;Data models;Synthetic aperture radar;generative ad-versarial networks;residual learning;attention mechanism;data augmentation;target detection},
  doi={10.1109/IGARSS46834.2022.9884798},
  ISSN={2153-7003},
  month={July},}@BOOK{10949060,
  author={Anderson, Jarrod and Winter, Jeff},
  booktitle={The Chief AI Officer's Handbook: Master AI leadership with strategies to innovate, overcome challenges, and drive business growth},
  year={2025},
  volume={},
  number={},
  pages={},
  abstract={Empower your leadership with this detailed guide for CAIOs and business leaders to drive innovation, address complex challenges, and implement ethical AI strategiesKey FeaturesExplore practical frameworks for effective AI team building and team managementImplement and Optimize AI Agents and Agentic Systems through design and implementation of AI agents.Gain actionable advice for leveraging AI to drive innovation and strategic growthPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionChief Artificial Intelligence Officers (CAIOs) are now imperative for businesses, enabling organizations to achieve strategic goals and unlock transformative opportunities through the power of AI. By building intelligent systems, training models to drive impactful decisions, and creating innovative applications, they empower organizations to thrive in an AI-driven world. Written by Jarrod Anderson, Chief AI Officer at SYRV.AI, this book bridges the gap between visionary leadership and practical execution. This handbook reimagines AI leadership for today‚Äôs fast-paced environment, leveraging predictive, deterministic, generative, and agentic AI to address complex challenges and foster innovation. It provides CAIOs with the strategies to develop transformative AI initiatives, build and lead elite teams, and adopt AI responsibly while maintaining compliance. From shaping impactful solutions to achieving measurable business outcomes, this guide offers a roadmap for making AI your organization‚Äôs competitive edge. By the end of this book, you‚Äôll have the knowledge and tools to excel as a Chief AI Officer, driving innovation, strategic growth, and lasting success for your organization.What you will learnDevelop and execute AI strategy as a CAIO, ensuring ethical complianceMaster agile AI project management from ideation to deploymentApply deterministic and probabilistic AI concepts through case studiesDesign and implement AI agents for autonomous system optimizationCreate human-centered AI systems using proven design principlesEnhance AI security through data privacy and model protection measuresWho this book is forThis book is for chief AI officers, business leaders, AI and data science professionals, IT managers, entrepreneurs, consultants, academic leaders, policymakers, and general business professionals. This diverse audience seeks to understand not only the technical intricacies of AI, but also how to leverage AI to solve real-world business problems, drive innovation, and achieve strategic goals.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781836200840},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10949060},}@INPROCEEDINGS{10778478,
  author={Zunaidah, Asih and Wiharja, Chandra Kurniawan and Wicaksono, Danang Wahyu},
  booktitle={2024 10th International Conference on Education and Technology (ICET)}, 
  title={User Experience with Grammarly's Generative AI: Ethical Implications for Improving Writing Skills}, 
  year={2024},
  volume={},
  number={},
  pages={86-91},
  abstract={The focus of this research is on college students' writing skill improvement with the help of Generative AI offered by Grammarly and their perception after using it, including its ethical concerns. While there is no doubt that in recent years AI tools have gained traction because of the ability to enhance one's written communication, questions have been raised regarding the excessive dependency on such tools and the student's academic integrity. The modeling of User Experience Questionnaire (UEQ) metric was used to complement the qualitative evaluation of opinions of students as users of Grammarly's Generative AI, with the investigation addressing specific dimensions: attractiveness, efficiency, and dependability. It has been established that students are attracted to AI and engaged when using it, though the concern for ethics regarding user control is prominent. This finding shows that ethical use is necessary when integrating AI technology into education to enhance learning without replacing critical analysis and self-learning skills; this extends the ongoing dialogue regarding the use of AI technologies in an education setting by giving precise guidance for educators and policy makers on how to appropriately use AI tools in academic role.},
  keywords={Ethics;Sensitivity;Generative AI;Education;Process control;Writing;User experience;Real-time systems;Guidelines;artificial intelligence;ethical;grammarly;user experience;writing skill},
  doi={10.1109/ICET64717.2024.10778478},
  ISSN={2770-4807},
  month={Oct},}@ARTICLE{10517486,
  author={Wen, Jinbo and Nie, Jiangtian and Kang, Jiawen and Niyato, Dusit and Du, Hongyang and Zhang, Yang and Guizani, Mohsen},
  journal={IEEE Internet of Things Magazine}, 
  title={From Generative AI to Generative Internet of Things: Fundamentals, Framework, and Outlooks}, 
  year={2024},
  volume={7},
  number={3},
  pages={30-37},
  abstract={Generative Artificial Intelligence (GAI) possesses the capabilities of generating realistic data and facilitating advanced decision-making. By integrating GAI into modern Internet of Things (IoT), Generative Internet of Things (GIoT) is emerging and holds immense potential to revolutionize various aspects of society, enabling more efficient and intelligent IoT applications, such as smart surveillance and voice assistants. In this article, we present the concept of GIoT and conduct an exploration of its potential prospects. Specifically, we first overview four GAI techniques and investigate promising GIoT applications. Then, we elaborate on the main challenges in enabling GIoT and propose a general GAI-based secure incentive mechanism framework to address them, in which we adopt Generative Diffusion Models (GDMs) for incentive mechanism designs and apply blockchain technologies for secure GIoT management. Moreover, we conduct a case study on modern Internet of Vehicle traffic monitoring, which utilizes GDMs to generate effective contracts for incentivizing users to contribute sensing data with high quality. Numerical results demonstrate the superiority of the proposed scheme. Finally, we suggest several open directions worth investigating for the future popularity of GIoT.},
  keywords={Generative AI;Surveillance;Ecosystems;Personal voice assistants;Blockchains;Sensors;Numerical models;Internet of Things;Artificial intelligence},
  doi={10.1109/IOTM.001.2300255},
  ISSN={2576-3199},
  month={May},}@INPROCEEDINGS{9395949,
  author={Desai, Shamika and Rajadhyaksha, Atharva and Shetty, Anjali and Gharat, Swapnil},
  booktitle={2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS)}, 
  title={CNN based Counterfeit Indian Currency Recognition Using Generative Adversarial Network}, 
  year={2021},
  volume={},
  number={},
  pages={626-631},
  abstract={In today's world scenario, paper currency is economical in the sense that its face value is greater than intrinsic value. It is also more elastic and stable, paper currency can be counted quickly, it is easy to move and safe to store. These all are the main reasons because of which counterfeit currency recognition is crucial. Fake currency cannot be identified by human vision and due to this recognition of forged currency notes has become crucial problem because counterfeiters are using new and improved methods. The methods currently existing to determine whether the notes are real cannot be accessed by the common people and are also complex hardware based methods. There are no applications or devices available through which fake currencies can be detected and identified easily by common people. The main purpose of the project is to identify Indian paper currency with a new methodical approach using Generative Adversarial Networks(GAN). In this system, the Indian currency note features would be primarily extracted using Convolutional Neural Networks (CNNs).The processed image data are then fed to a Generative Adversarial Network which helps to classify the currency as either real or fake. GAN consists of two main modules - Generator and Discriminator. The Generator generates fake currency images and the Discriminator identifies and labels the real and fake images.},
  keywords={Training;Image recognition;Generative adversarial networks;Feature extraction;Generators;Object recognition;Currencies;Paper currency;CNN;GAN;Generator;Discriminator},
  doi={10.1109/ICAIS50930.2021.9395949},
  ISSN={},
  month={March},}@INPROCEEDINGS{9807703,
  author={Tian, Meng and Zhang, Shuyin and Cai, Yitao and Xu, Chao},
  booktitle={2022 IEEE 2nd International Conference on Computer Communication and Artificial Intelligence (CCAI)}, 
  title={Entropy Based Generative Adversarial Network for PolSAR Image Classification}, 
  year={2022},
  volume={},
  number={},
  pages={132-136},
  abstract={In order to solve the problem that the effect of generator feature learning is not paid enough attention in generative adversarial network(GAN) for Polarimetric synthetic aperture radar(PolSAR) data, a new GAN called Entropy-based Auxiliary Classifier Generative Adversarial Networks (E-ACGAN) was proposed in this paper. The decomposition discrepancy was obtained by calculating the entropy decomposition of the real data and the generated data. Then the decomposition discrepancy is used to measure the similarity between the generated data and the real data. This discrepancy will be introduced into the model as an additional optimization goal of the generator. Therefore, the generator can learn more characteristics of PolSAR data to generate more realistic data. In the step of adversarial learning, the discrimination and classification capabilities of the discriminator are also improved with the generator. The experimental results on the Flevoland2 data set show that the classification accuracy of E-ACGAN is 2.36% higher than that of the original ACGAN and it is also improved to different degrees than other traditional classification methods.},
  keywords={Representation learning;Training;Computational modeling;Conferences;Generative adversarial networks;Generators;Entropy;GAN;image classification;polarimetric synthetic aperture radar (PolSAR);Polarimetric decomposition},
  doi={10.1109/CCAI55564.2022.9807703},
  ISSN={},
  month={May},}@INPROCEEDINGS{9568451,
  author={Hendry and Manongga, Daniel Herman Fredy and Nataliani, Yessica and Wellem, Theophilus},
  booktitle={2021 7th International Conference on Applied System Innovation (ICASI)}, 
  title={Anti-Counterfeit Handwritten Signature via DCGAN with SGPD Network}, 
  year={2021},
  volume={},
  number={},
  pages={79-84},
  abstract={In recent years, the growth of machine learning makes the computer can learn many things by using artificial intelligence. One method that is feared nowadays is the computer's capability to imitate something. This capability is called deep-fake. Deep-fake is the capability of the computer to imitate human characteristics such as voice, images, and video through artificial intelligence. Deep-fake is used to combine put the consisted image and video to another source of images and video using machine learning which is known as a generative adversarial network. With these capabilities, deep-fake is already used to make a counterfeit video, signature, voice signature, and much fake news. This paper is about to combine the capabilities of deep learning and the Generative Adversarial Network (GAN) to deal with detecting the fraud in the handwritten signature. We will focus on several types of ways to sign with the characters. The system will recommend if the hand signature of the user is fake or genuine. This is under the capabilities of GAN to synthesize the signature, it can make the computer automatically generate hand signature by using a machine. Many researchers called this capability is deep-fake. This research aims to learn the hand signature to do fraud detection. We propose an architecture to build the anti-counterfeiting hand signature which is utilized deep learning with a self-growing probabilistic method.},
  keywords={Deep learning;Technological innovation;Generative adversarial networks;Probabilistic logic;Fraud;Fake news;Faces;Deep Learning;Deep-Fake;Generative Adversarial Network;Self-Growing Probabilistic Method},
  doi={10.1109/ICASI52993.2021.9568451},
  ISSN={2768-4156},
  month={Sep.},}@ARTICLE{11134078,
  author={Li, Shaofan and Dai, Mingjun and Jin, Ruofan},
  journal={IEEE Transactions on Network Science and Engineering}, 
  title={FedConsDG: Divergence-Aware Federated Distillation Via Consensus-Diversity Generative Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-17},
  abstract={Federated learning (FL) is an emerging privacy-preserving distributed learning paradigm that enables multiple clients to collaboratively train a shared model by exchanging model parameters instead of raw data. However, data heterogeneity among clients often leads to significant performance degradation. Existing approaches primarily address this challenge by constraining local model updates to align the global model. Nevertheless, they often overlook the fact that direct aggregation of local models into a single global model can inherently introduce severe performance bottlenecks due to client divergence. To address this issue, we propose FedConsDG: Divergence-Aware Federated Distillation via Consensus-Diversity Generative Learning. Instead of simply aggregating local models, our method updates the global model on the server side via knowledge distillation from local models. Specifically, we deploy a generator on the server and propose a Consensus-Diversity Generative Learning, which encourages the generator to generate hard samples by maximizing the prediction variance among local models. These synthesized samples are then used to fine-tune the global model. To further mitigate catastrophic forgetting caused by data heterogeneity, we introduce a divergence-aware exponential moving average (EMA) mechanism to update the parameters of the generator during the distillation stage. Unlike traditional knowledge distillation techniques, the proposed framework eliminates the need for proxy data on the server, thereby offering stronger privacy guarantees. Extensive experiments on multiple heterogeneous datasets demonstrate the effectiveness of the proposed method.},
  keywords={Data models;Generators;Training;Servers;Data privacy;Computational modeling;Distributed databases;Complexity theory;Predictive models;Federated learning;Federated learning;generative artificial intelligence;knowledge distillation;edge intelligence;mobile network},
  doi={10.1109/TNSE.2025.3601224},
  ISSN={2327-4697},
  month={},}@INPROCEEDINGS{10448593,
  author={Jayadharshini, P. and Santhiya, S. and Rakshitaa, J. and Nithika, K. and Kannan, N. and Tharun, P.},
  booktitle={2023 Intelligent Computing and Control for Engineering and Business Systems (ICCEBS)}, 
  title={Advancing COPD Diagnosis through Deep Learning, GANs, and Chest X-Ray Analysis for Precise Detection and Severity}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The rate of mortality within those who have COPD (chronic obstructive pulmonary disease) has risen recently, and itis predicted that it willstayon the risein the years to come. Due to the extensive laboratory testing requiredforconfirmation, standardapproachestakeavery long time to diagnose these medicalconditions. Fortunately, with the development of sophisticated approaches and consideration of the ability to develop powerful techniques forpredictingothercriticaldiseases, itisanticipatedthatthis will helptopreciselyandpromptlydetectchronicdiseases.To aid in the diagnosis of COPD, this project aims to create a clinicaldecisionsupportsystembasedondeeplearning(DL) algorithms. Chest X-rays from 100 patients for COPD diagnosis were selected for examination. Chest X-rays are frequentlyutilisedtofindanomaliesthataidinthedetection of COPD. Many X-ray images are needed to traina classification model; however, radiographic Chest X-rays are still limited in availability. This may hinder the effectivenessoftechniquesforCOPDidentificationthatrely ondeeplearning(DL).Inthis study, thegeneratedChestX- rays using a Generative Adversarial Network (GAN) and Data Augmentation is used to get around these restrictions. Each X-ray that is produced falls into one of the two categories: COPD or normal. Now, the GAN-generated syntheticimageswerecombinedwiththerealimagesandfed into the following CNN architectures ‚Äì VGG16, ResNet, DenseNet, Inception. Amongthesemodels, theoutputfrom the best-performing model is used to identifytheCOPD- affectedpatients. Further, their FEV1 factor range is considered to classify them depending on the seriousness of COPD ‚Äì Mild, Moderate, Severe and Very Severe.},
  keywords={Deep learning;Generative adversarial networks;Chronic obstructive pulmonary disease;Numerical models;X-ray imaging;Medical diagnostic imaging;Testing;Chronic Obstructive Pulmonary Disease (COPD);Deep Neural Learning;GenerativeAdversarial Network (GAN);VGG16;ResNet;DenseNet;Inception;FEV1},
  doi={10.1109/ICCEBS58601.2023.10448593},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10024438,
  author={Mann, Eytan and Dortheimer, Jonathan and Sprecher, Aaron},
  booktitle={2022 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)}, 
  title={Toward a Generative Pipeline for an AR Tour of Contested Heritage Sites}, 
  year={2022},
  volume={},
  number={},
  pages={130-134},
  abstract={This paper envisions a pipeline for automating the generation of augmented reality tours of contested heritage sites while employing a critical approach toward the representation of history. Through the design of a generative pipeline, the paper identifies and discusses the potential and pitfalls associated with extracting spatial features from archival manuscripts and presenting them using an augmented reality application. The paper proposes a number of design approaches that assist in automating the transformation of manuscripts into interactive tours while taking into consideration historical, narrative, and technical challenges.},
  keywords={Visualization;Uncertainty;Pipelines;Production;Immersive experience;Writing;Metadata;augmented reality;historiography;tour;generative;artificial intelligence},
  doi={10.1109/AIVR56993.2022.00026},
  ISSN={2771-7453},
  month={Dec},}@INPROCEEDINGS{10343376,
  author={Khan, Masood M and Dong, Yu and Manesh, Nasrin Afsari},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Authentic Assessment Design for Meeting the Challenges of Generative Artificial Intelligence}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Authentic Assessments are generally seen as alternate to traditional assessments though the scope of an authentic assessment is much larger than that of a traditional assessment. Authentic assessments help students in comprehending the subject matter and, if properly designed, can also ensure student workplace readiness. During the authentic assessment design, five most important aspects are considered and their incorporation is sought. These aspects include; the assessment objectives, the physical context of an assessment, the social context, the outcome of the assessment and the assessment criteria. Emergence of the Generative Artificial Intelligence (GAI) supported applications and the Large Language Model (LLM) tools has posed new challenges to the authentic assessment design. Student access to these new applications and tools has also changed the socio-technological realities of the Learning and Teaching (L&T) practices. Therefore, we need to reimagine both, the L&T practices and the design and execution of authentic assessments. Keeping the prevailing socio-technological context in perspective, this work in progress paper proposes extending the scope of authentic assessments. The aim is to use them for quelling the growing problem of plagiarism as plagiarism can be facilitated by the use of GAI and LLM tools. Instead of considering authentic assessments as merely ‚Äòan alternate to the traditional examination‚Äô or ‚Äòa tool for evaluating student workplace readiness,‚Äô we propose adding ‚ÄòGAI redundancy‚Äô to the scope of authentic assessments. For incorporating GAI redundancy we propose using either the game-based learning environment or a simulation environment. These two environments can be used for generating ‚Äòclose to real life‚Äô problem-solving scenarios while assessing student comprehension and workplace readiness. In order to help practitioners, this paper also presents two examples of authentic assessments that were developed for combating plagiarism vis-√†-vis enhancing student learning and evaluating their workplace readiness. In the first example, we show how to use a game environment and in the second example we demonstrate use of a simulation environment. The two examples also show how course contents can be embedded and how GAI redundancy can be incorporated in authentic assessments. The reported teaching assessment data and student feedback suggest that the proposed authentic assessment design and implementation strategies were able to engage students, help their comprehension and evaluate their workforce readiness.},
  keywords={Mechatronics;Plagiarism;Employment;Redundancy;Education;Learning (artificial intelligence);Games;authentic assessment design;generative artificial intelligence;large language models;plagiarism;student competence;workplace readiness},
  doi={10.1109/FIE58773.2023.10343376},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{11015385,
  author={Tuitt, Tamia-Ashley and Addison, Letetia M. and Hosein, Patrick},
  booktitle={2025 7th International Symposium on Computational and Business Intelligence (ISCBI)}, 
  title={Generative AI and Multi-Agent Systems Approach to Psychometric Evaluation for Human Resource Management and Talent Acquisition}, 
  year={2025},
  volume={},
  number={},
  pages={108-112},
  abstract={Traditional psychometric evaluations often fail to reliably assess candidates due to the reliance on self-reported answers, leading to unsuitable hires and suboptimal organizational outcomes. To address these limitations, we propose a novel psychometric evaluation system that leverages Generative AI and multi-agent systems to create simulated work environments. Candidates engage in real-time, role-specific situational simulations, interacting with autonomous agents acting as virtual colleagues or clients. These dynamic interactions enable objective assessments of cognitive abilities, personality traits, and situational judgment based on authentic reactions rather than tailored responses. The system‚Äôs adaptive design ensures alignment with organizational needs, offering scalable solutions across industries. Evaluation of the system involves testing high-performing and unsuitable employees, with a mathematical model demonstrating its higher accuracy in identifying top candidates compared to traditional methods. This approach represents a transformative advancement in workforce assessments, improving hiring decisions and organizational performance.},
  keywords={Industries;Generative AI;Mathematical models;Autonomous agents;Real-time systems;Reliability;Business intelligence;Human resource management;Multi-agent systems;Testing;Psychometric evaluations;Generative AI;Multiagent systems;Simulated work environment;Autonomous agents;Cognitive abilities;Situational judgment;Personality traits;Mathematical model;Hiring probability},
  doi={10.1109/ISCBI64586.2025.11015385},
  ISSN={2832-4749},
  month={Feb},}@INPROCEEDINGS{10248276,
  author={Beheshti, Amin},
  booktitle={2023 IEEE International Conference on Web Services (ICWS)}, 
  title={Empowering Generative AI with Knowledge Base 4.0: Towards Linking Analytical, Cognitive, and Generative Intelligence}, 
  year={2023},
  volume={},
  number={},
  pages={763-771},
  abstract={Intelligence refers to the ability to acquire and apply knowledge and skills, which comprises three fundamental components, namely knowledge, experience, and creativity. Consequently, there exist three primary Artificial Intelligence (AI) systems, namely Analytical AI, Cognitive AI, and Generative AI. Analytical AI is primarily concerned with comprehending the data and transforming it into contextualized data and knowledge. On the other hand, Cognitive AI is centered on understanding experience and aims to annotate, enrich, and utilize the knowledge, to facilitate decision-making. Lastly, Generative AI delves into the neural mechanisms involved in creative thinking and problem-solving, with a focus on enhancing the process of acquiring and applying knowledge and skills. This paper presents Knowledge Base 4.0 as the backend data for AI engines, which allows for linking knowledge and experience to enable empowering generative AI. The objective is not only to facilitate generating new content (such as text and images) but also to generate new processes when/if needed. We present the architecture of Knowledge Base 4.0 and the design and development of data services that construct and maintain this robust Knowledge Base. Additionally, we provide use cases in various domains, including health, policing, banking, and education.},
  keywords={Automation;Web services;Knowledge based systems;Decision making;Banking;Problem-solving;Engines;Knowledge Base;Generative AI;Crowdsourcing;weak supervision;Business Processes Automation},
  doi={10.1109/ICWS60048.2023.00103},
  ISSN={2836-3868},
  month={July},}@INPROCEEDINGS{10489759,
  author={Klair, Yuvpartap Singh and Agrawal, Kushagra and Kumar, Ayush},
  booktitle={2024 2nd International Conference on Disruptive Technologies (ICDT)}, 
  title={Impact of Generative AI in Diagnosing Diseases in Agriculture}, 
  year={2024},
  volume={},
  number={},
  pages={870-875},
  abstract={In the domain of agriculture, accurate disease diagnosis is crucial for ensuring crop health and maximizing yield. However, the scarcity of diverse and well-annotated datasets poses challenges to developing robust diagnostic models. This research explores the potential of Generative AI to address these limitations and enhance the accuracy of disease diagnosis. To address the issue, this research offers a novel method of data augmentation that applies a cutting-edge generative AI algorithm, namely Generative Adversarial Networks (GANs), to a subset of the ‚ÄúPaddy Doctor‚Äù dataset, which consists of 10,407 photos of paddy crops suffering from various diseases. GANs are employed to generate synthetic images that seamlessly integrate with the original dataset, effectively enhancing its size and diversity. Leveraging the adversarial training process, this method produces realistic images capturing detailed features of diseased crops. Numerous studies demonstrate the effectiveness of this method in enhancing the applicability and accuracy of crop disease classification models. This method proves valuable in addressing data scarcity issues within the agricultural domain.},
  keywords={Training;Generative AI;Crops;Generative adversarial networks;Data augmentation;Agriculture;Medical diagnosis;Generative AI;GANs;Data Augmentation;Paddy Doctor;Agriculture},
  doi={10.1109/ICDT61202.2024.10489759},
  ISSN={},
  month={March},}@INPROCEEDINGS{10096998,
  author={Yang, Linlin and Liu, Hongying and Shang, Fanhua and Liu, Yuanyuan},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Adaptive Non-Local Generative Adversarial Networks for Low-Dose CT Image Denoising}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Low-dose computed tomography (CT) has been widely used in medical diagnosis and treatment. Many deep networks have been proposed for low-dose CT denoising. The local receptive field of the convolution affects the network performance. For different input images, conventional neural networks always adopt a fixed number of channels which limits the performance of deep networks. To address these problems, we propose a channel-adaptive convolution and patch selection (CAPS) module to enhance the feature extraction of our network. CAPS enables our network to adaptively adjust the number of channels according to different inputs. Moreover, the concatenation of patches can expand the receptive field globally, so the shallow layer of our network can extract more global information. To further ensure the clarity of denoised images, we present a new wavelet loss function to the generator of our generative adversarial network. Compared with state-of-the-art methods, our network can obtain superior denoising results.},
  keywords={Visualization;Convolution;Computed tomography;Noise reduction;Neural networks;Feature extraction;Generative adversarial networks;Patch selection;Channel-adaptive convolution;Non-local;GAN;LDCT denoising},
  doi={10.1109/ICASSP49357.2023.10096998},
  ISSN={2379-190X},
  month={June},}@INBOOK{10811680,
  author={Abdalla*, Aly S. and Tang, Bo and Marojevic, Vuk},
  booktitle={Artificial Intelligence for Future Networks}, 
  title={AI at the Physical Layer for Wireless Network Security and Privacy}, 
  year={2025},
  volume={},
  number={},
  pages={341-380},
  abstract={Abstract <p>The chapter aims to provide readers with a comprehensive understanding of AI's role in enhancing the detection, prevention, and mitigation of network threats for safeguarding network&#x2010;sensitive information and ensuring its privacy. It covers various aspects, including threat identification, anomaly detection, physical layer security solutions, and practical implementation considerations. The case study on UAV&#x2010;assisted physical layer security further demonstrates the practicality of AI applied to wireless network security. The chapter also addresses practical challenges, such as scalability and privacy considerations, while providing insights into future trends and research directions to further leverage AI for addressing evolving network security concerns.</p>},
  keywords={Monitoring;Jamming;Communication system security;Sidelink;Protocols;Object recognition;Malware;Artificial intelligence;Wireless networks;Performance evaluation},
  doi={10.1002/9781394227952.ch10},
  ISSN={},
  publisher={IEEE},
  isbn={9781394227945},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10811680},}@INPROCEEDINGS{10963000,
  author={Yin, Cong and Wang, Xiaopeng and Cao, Qiyuan and Liu, Qiang and Yang, Qiang},
  booktitle={2024 5th International Conference on Computers and Artificial Intelligence Technology (CAIT)}, 
  title={Conditional generative model for super-resolution of low-quality color fundus photographs}, 
  year={2024},
  volume={},
  number={},
  pages={172-177},
  abstract={In the clinical diagnosis of eye diseases, color fundus photographs usually have a very large size to distinguish local fundus structure information or conduct combined evaluation with other modalities.However, current deep learning tasks usually require reducing the original images significantly to meet the requirements of graphics card memory during model training. Therefore, we use super-resolution technology to explore how to re-enlarge the small-sized images processed by the model back to the original size for diagnostic analysis. Specifically, it extracts high-frequency components during the enlargement of low-quality images to constrain the training process, which helps maintain the original physiological and pathological information and improve reconstructed image quality. Moreover, a carefully designed image degradation algorithm simulates real low-quality color fundus photographs. Comparison experiments show the model‚Äôs effectiveness in scale x2 and x4 tasks, and image denoising experiments prove its significant inhibitory effect on noise in the reconstruction process.},
  keywords={Training;Degradation;Deep learning;Time-frequency analysis;Image color analysis;Computational modeling;Superresolution;Colored noise;Image reconstruction;Image denoising;Color fundus photographs;Image super-resolution;Image denoising;Deep learning},
  doi={10.1109/CAIT64506.2024.10963000},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11125761,
  author={Abdalla, Aly Sabri and Marojevic, Vuk},
  booktitle={2025 IEEE International Conference on Omni-layer Intelligent Systems (COINS)}, 
  title={The Role of Generative Artificial Intelligence in Testing and Automation of Open RAN Systems: GNG-OTA Framework}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Open Radio Access Networks (O-RAN) empower operators with choice and customization through their disaggregated and interoperable architecture. However, ensuring interoperability in O-RAN presents challenges due to complex testing environments and evolving specifications. This paper addresses these challenges by proposing the Generative AI and Graph Neural Network-based Open RAN Testing and Automation (GNG-OTA) framework. GNG-OTA utilizes state-of-the-art AI techniques including generative AI, natural language processing, and graph neural networks to enable accurate, reliable, efficient, and automatic O-RAN interoperability and performance testing.},
  keywords={Automation;Accuracy;Protocols;Generative AI;Open RAN;Natural language processing;Graph neural networks;Reliability;Interoperability;Testing;O-RAN;testing;automation;AI;interoperability;performance;conformance;GAI;NLP;GNN},
  doi={10.1109/COINS65080.2025.11125761},
  ISSN={2996-5330},
  month={Aug},}@INPROCEEDINGS{9511352,
  author={Suzuki, Muneaki and Kamcya, Yoshitaka and Kutsuna, Takuro and Mitsumoto, Naoki},
  booktitle={2021 17th International Conference on Machine Vision and Applications (MVA)}, 
  title={Understanding the Reason for Misclassification by Generating Counterfactual Images}, 
  year={2021},
  volume={},
  number={},
  pages={1-5},
  abstract={Explainable AI (XAI) methods contribute to understanding the behavior of deep neural networks (DNNs), and have attracted interest recently. For example, in image classification tasks, attribution maps have been used to indicate the pixels of an input image that are important to the output decision. Oftentimes, however, it is difficult to understand the reason for misclassification only from a single attribution map. In this paper, in order to enhance the information related to the reason for misclassification, we propose to generate several counterfactual images using generative adversarial networks (GANs). We empirically show that these counterfactual images and their attribution maps improve the interpretability of misclassified images. Furthermore, we additionally propose to generate transitional images by gradually changing the configurations of a GAN in order to understand clearly which part of the misclassified image cause the misclassification.},
  keywords={Deep learning;Machine vision;Generative adversarial networks;Task analysis;Artificial intelligence;Image classification},
  doi={10.23919/MVA51890.2021.9511352},
  ISSN={},
  month={July},}@ARTICLE{10577141,
  author={Tian, Yuqing and Zhang, Zhaoyang and Yang, Yuzhi and Chen, Zirui and Yang, Zhaohui and Jin, Richeng and Quek, Tony Q. S. and Wong, Kai-Kit},
  journal={IEEE Network}, 
  title={An Edge-Cloud Collaboration Framework for Generative AI Service Provision With Synergetic Big Cloud Model and Small Edge Models}, 
  year={2024},
  volume={38},
  number={5},
  pages={37-46},
  abstract={Generative artificial intelligence (GenAI) offers various services to users through content creation, which is believed to be one of the most important components in future networks. However, training and deploying big artificial intelligence models (BAIMs) introduces substantial computational and communication overhead. This poses a critical challenge to centralized approaches, due to the need of high-performance computing infrastructure and the reliability, secrecy and timeliness issues in long-distance access of cloud services. Therefore, there is an urging need to decentralize the services, partly moving them from the cloud to the edge and establishing native GenAI services to enable private, timely, and personalized experiences. In this paper, we propose a brand-new bottom-up BAIM architecture with synergetic big cloud model and small edge models, and design a distributed training framework and a task-oriented deployment scheme for efficient provision of native GenAI services. The proposed framework can facilitate collaborative intelligence, enhance adaptability, gather edge knowledge and alleviate edge-cloud burden. The effectiveness of the proposed framework is demonstrated through an image generation use case. Finally, we outline fundamental research directions to fully exploit the collaborative potential of edge and cloud for native GenAI and BAIM applications.},
  keywords={Computational modeling;Data models;Training;Adaptation models;Artificial intelligence;Cloud computing;Generative AI;Edge computing;Generative AI;big AI model;edge-cloud collaboration},
  doi={10.1109/MNET.2024.3420755},
  ISSN={1558-156X},
  month={Sep.},}@INPROCEEDINGS{10505362,
  author={Hu, Xinrong and Jin, Yuxin and Liang, Jinxing and Liu, Junping and Luo, Ruiqi and Li, Min and Peng, Tao},
  booktitle={2023 2nd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR)}, 
  title={Diffusion Model for Image Generation - A Survey}, 
  year={2023},
  volume={},
  number={},
  pages={416-424},
  abstract={Diffusion models are a class of generative model that excels in generating high-quality images, making them the state-of-the-art among other generative models. Their impressive image generation capabilities and diverse generation patterns have garnered significant attention. To facilitate the widespread utilization of diffusion models in various domains, this article provides a comprehensive overview of their applications in the field of image generation. Firstly, we introduce the foundational theory of diffusion models and the widely adopted general frameworks. Then, we categorize the applications of diffusion models in the field of image generation into the following areas: unconditional generation, conditional generation, text-to-image translation, image-to-image translation, image super-resolution, image editing, and image inpainting techniques. Furthermore, we thoroughly discuss the limitations of diffusion models in the context of image generation and provide insights into future research and development directions in this field.},
  keywords={Surveys;Human computer interaction;Image synthesis;Superresolution;Robots;Research and development;Generative AI;AIGC;Diffusion Model;image generation;diffusion application},
  doi={10.1109/AIHCIR61661.2023.00073},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10305995,
  author={Saxena, Deepak and Wall, P. J. and Lewis, Dave},
  booktitle={2023 IEEE International Symposium on Technology and Society (ISTAS)}, 
  title={Artificial Intelligence (AI) Ethics: A Critical Realist Emancipatory Approach}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={The importance of any conversation on the ethics of Artificial Intelligence (AI) cannot be overstated as such advanced technologies now influence almost every aspect of our lives. To date, dominant approaches to AI ethics have traditionally focused on the agency of the organisations creating such AI projects (e.g. the Google AI principles), but more recent approaches focus on wider structures and frameworks that may potentially support responsible AI design (e.g. the Ethically Aligned Design framework by IEEE). In this paper, we argue that such frameworks are both incomplete and insufficient as these approaches give primacy to either agency or structure. Moreover, in both approaches, the emancipation of those for whom AI is designed is almost completely ignored. To remove these lacunae, we suggest an emancipatory approach to AI ethics based on the key tenets of the philosophy and ontology of critical realism. The stratified ontology of critical realism suggests that structural conditions may be modified to activate the mechanisms supporting any desired outcome (e.g., bias-free AI). In addition, such an emancipatory approach works towards activating the mechanisms supporting the reflexivity of the stakeholders in any specific AI context. This paper makes an argument for adopting this particular philosophical approach, and we discuss three critical realist-based mechanisms in support of our argument: ethical training of AI professionals, citizen engagement, and freedom of AI information.},
  keywords={Training;Ethics;Philosophical considerations;Oral communication;Ontologies;Internet;Stakeholders;Artificial intelligence;ethics;AI ethics;critical realism;generative mechanisms;reflexivity;citizen engagement},
  doi={10.1109/ISTAS57930.2023.10305995},
  ISSN={2158-3412},
  month={Sep.},}@INPROCEEDINGS{11051726,
  author={Gogineni, Vineeth and Mupparaju, Sowmya},
  booktitle={2025 International Conference on Engineering, Technology & Management (ICETM)}, 
  title={AI-Driven Synthetic Data Generation for Precision Agriculture: Enhancing Decision Support Systems Through Artificial Intelligence}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Precision agriculture represents a paradigm shift in farming practices, utilizing technology to optimize crop management and resource allocation. However, the effectiveness of precision agriculture systems is often limited by insufficient or inadequate data. This paper explores the emerging field of AI-driven synthetic data generation as a solution to address data limitations in precision agriculture. We examine various artificial intelligence techniques for creating realistic, diverse, and balanced datasets that can supplement real-world agricultural data. The paper demonstrates how synthetic data can enhance decision support systems for tasks such as crop monitoring, disease detection, yield prediction, and resource optimization. We also address the technical challenges, ethical considerations, and future research directions in this rapidly evolving field. Our findings suggest that AI-generated synthetic data has significant potential to accelerate innovation in precision agriculture while reducing costs and environmental impacts associated with data collection.},
  keywords={Precision agriculture;Decision support systems;Technological innovation;Ethics;Crops;Optimization;Monitoring;Synthetic data;Farming;Diseases;Artificial intelligence;precision agriculture;synthetic data;generative adversarial networks (GANs);data augmentation;machine learning;agricultural innovation},
  doi={10.1109/ICETM63734.2025.11051726},
  ISSN={},
  month={May},}@ARTICLE{10750354,
  author={Zhong, Ruikang and Mu, Xidong and Jaber, Mona and Liu, Yuanwei},
  journal={IEEE Internet of Things Journal}, 
  title={Enabling Distributed Generative Artificial Intelligence in 6G: Mobile-Edge Generation}, 
  year={2025},
  volume={12},
  number={6},
  pages={6607-6620},
  abstract={Mobile-edge generation (MEG) is an emerging technology that allows the network to meet the challenging traffic load expectations posed by the rise of generative artificial intelligence (GAI). A novel MEG model is proposed for deploying GAI models on edge servers (ESs) and user equipment (UE) to jointly complete text-to-image generation tasks. In the generation task, the ES and UE will cooperatively generate the image according to the text prompt given by the user. To enable the MEG, a pretrained latent diffusion model (LDM) is invoked to generate the latent feature, and an edge-inferencing MEG protocol is employed for data transmission exchange between the ES and the UE. A compression coding technique is proposed for compressing the latent features to produce seeds. Based on the above seed-enabled MEG model, an image quality optimization problem with energy constraint is formulated. The transmitting power of the seed is dynamically optimized by a deep reinforcement learning (DRL) agent over the fading channel. The proposed MEG-enabled text-to-image generation system is evaluated in terms of image quality and transmission overhead. The numerical results indicate that, compared to the conventional centralized generation-and-downloading scheme, the symbol number of the transmission of MEG is materially reduced. In addition, the proposed compression coding approach can improve the quality of generated images under low signal-to-noise ratio (SNR) conditions, and the DRL-enabled dynamic power control further improves the image quality under the energy constraint compared to static transmit power control.},
  keywords={Image edge detection;Computational modeling;Image coding;Image quality;Diffusion models;Load modeling;Encoding;Text to image;Signal to noise ratio;Servers;Deep learning (DL);generative artificial intelligence (GAI);image generation;mobile-edge generation (MEG)},
  doi={10.1109/JIOT.2024.3493611},
  ISSN={2327-4662},
  month={March},}@ARTICLE{9650845,
  author={Li, Tingting and Shi, Yunhui and Sun, Xiaoyan and Wang, Jin and Yin, Baocai},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={PCGAN: Prediction-Compensation Generative Adversarial Network for Meshes}, 
  year={2022},
  volume={32},
  number={7},
  pages={4667-4679},
  abstract={Unlike natural images, the topology similarity among meshes can hardly be handled with classical deep learning because of their irregular structures. Parameterization provides a way to represent meshes in the form of geometry and normal images, which reflects the correlation between neighboring sample locations. Generative Adversarial Networks (GANs) can efficiently generate images without explicitly computing probability densities of the underlying distribution. However, existing GANs such as Coupled Generative Adversarial Network (CoGAN) generally have two drawbacks: (1) Inability to process unnatural images. (2) Insufficient exploration of the inherent relation between normal and the corresponding geometry image. To address these issues, this paper proposes an efficient method named Prediction-Compensation Generative Adversarial Network (PCGAN) to learn a joint distribution of both geometry and normal images, which aims for generating meshes with two GANs. The consistency of two GANs for the geometry and the normal is guaranteed by utilizing a sequence of prediction-compensation pairs. The sequence can estimate the normal image from the geometry image and compensate the geometry from normal progressively. Particularly, the prediction has a closed-form expression, which provides high estimation accuracy and reduces training complexity. Extensive experimental results on facial mesh generation indicate that our PCGAN outperforms CoGAN and other architectures in retaining the geometry of the faces and in generating realistic face meshes with rich facial attributes such as facial expression and morphology. Moreover, quantitative evaluations demonstrate our superior performance compared with the methods mentioned above.},
  keywords={Geometry;Three-dimensional displays;Generative adversarial networks;Mesh generation;Faces;Complexity theory;Training;Generative adversarial networks;mesh;geometry;normal;prediction;compensation},
  doi={10.1109/TCSVT.2021.3135528},
  ISSN={1558-2205},
  month={July},}@INPROCEEDINGS{10230503,
  author={√ñttl, Mathias and Steenpass, Jana and R√ºbner, Matthias and Geppert, Carol I. and Qiu, Jingna and Wilm, Frauke and Hartmann, Arndt and Beckmann, Matthias W. and Fasching, Peter A. and Maier, Andreas and Erber, Ramona and Breininger, Katharina},
  booktitle={2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI)}, 
  title={Improved HER2 Tumor Segmentation with Subtype Balancing Using Deep Generative Networks}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Tumor segmentation in histopathology images is often complicated by its composition of different histological subtypes and class imbalance. Oversampling subtypes with low prevalence features is not a satisfactory solution since it eventually leads to overfitting. We propose to create synthetic images with semantically-conditioned deep generative networks and to combine subtype-balanced synthetic images with the original dataset to achieve better segmentation performance. We show the suitability of Generative Adversarial Networks (GANs) and especially diffusion models to create realistic images based on subtype-conditioning for the use case of HER2-stained histopathology. Additionally, we show the capability of diffusion models to conditionally inpaint HER2 tumor areas with modified subtypes. Combining the original dataset with the same amount of diffusion-generated images increased the tumor Dice score from 0.833 to 0.854 and almost halved the variance between the HER2 subtype recalls. These results create the basis for more reliable automatic HER2 analysis with lower performance variance between individual HER2 subtypes.},
  keywords={Image segmentation;Data privacy;Histopathology;Biological system modeling;Training data;Generative adversarial networks;Data models;Histopathology;HER2;Subtypes;Generative Models;Diffusion Models;Segmentation},
  doi={10.1109/ISBI53787.2023.10230503},
  ISSN={1945-8452},
  month={April},}@ARTICLE{10355933,
  author={Lee, SangEun and Kim, Seoyun and Chu, Yeonju and Choi, JeongWon and Park, Eunil and Woo, Simon S.},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={EAE-GAN: Emotion-Aware Emoji Generative Adversarial Network for Computational Modeling Diverse and Fine-Grained Human Emotions}, 
  year={2024},
  volume={11},
  number={3},
  pages={3862-3872},
  abstract={With the growing ubiquity and broad usage, emojis are widely used as a universal visual language, which complements the intentions and emotions beyond the textual data. Despite the critical role of representing emotion, existing emojis neglect the subtle and complex properties of human emotion in that only countable and finite face emojis exist in a categorical manner. In this article, we propose a novel approach to facial emoji generation, which can control the emotional degree of generated emojis for more complex and detailed usage on online conversations. In other words, we develop a new emotion-aware emoji generative adversarial network, which is capable of generating an emoji that expresses a given emotion distribution. In this way, our approach aims to map fine-grained emotions to expressive emojis. Both quantitative and qualitative evaluation demonstrate that our approach can successfully generate high-quality emoji-like images by representing a wide range of emotions. To the best of our knowledge, this is the first approach to use the deep generative model from the standpoint of the emoji's emotional role, which can further promote more interactive and effective online communication.},
  keywords={Emojis;Generative adversarial networks;Task analysis;Faces;Visualization;Image synthesis;Generators;Computational social systems;emoji generation;emotion modeling;generative adversarial networks},
  doi={10.1109/TCSS.2023.3329434},
  ISSN={2329-924X},
  month={June},}@INPROCEEDINGS{10512880,
  author={Gao, Maosheng and Yu, Juan and Kamel, Salah and Yang, Zhifang},
  booktitle={2023 IEEE 7th Conference on Energy Internet and Energy System Integration (EI2)}, 
  title={An Intelligent Operational Reliability Assessment Approach Considering Sample Imbalance}, 
  year={2023},
  volume={},
  number={},
  pages={4729-4734},
  abstract={Operational reliability assessment is an important approach to evaluate the potential risk in the new power systems. However, the accumulated computation burden from calculating thousands of scenes in operational reliability assessment still challenges the advanced solving algorithm. To address this issue, data-driven approaches using neural networks are proposed. However, existing approaches suffer from imbalanced samples because the possibility of load shedding is extremely low. To this end, this paper proposes an intelligent operational reliability assessment approach considering sample imbalance. Specifically, the imbalanced load-shedding sample extension method is proposed based on the generative adversarial network to deal with the imbalance of the load-shedding samples in the training dataset. Besides, a novel loss function is constructed with a specific focus on the load-shedding buses. This learning strategy helps the neural networks capture the features of the imbalanced shedding loads in different buses. Finally, simulation results in the IEEE 39-bus and 118-bus systems demonstrate that the proposed method can achieve an obvious improvement in evaluation accuracy and facilitate online evaluation.},
  keywords={Training;Simulation;Neural networks;Energy Internet;System integration;Load shedding;Generative adversarial networks;operational reliability assessment;generative adversarial network;sample imbalance;attention learning},
  doi={10.1109/EI259745.2023.10512880},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10563971,
  author={Chaudhary, Ayushi and Sharma, Ashish},
  booktitle={2024 4th International Conference on Innovative Practices in Technology and Management (ICIPTM)}, 
  title={Analysis of Innovative Practices on Steganographic Process with AI Based Algorithms}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents a comprehensive analysis of the innovative practices in steganographic processes enhanced by AI-based algorithms. Steganography, the science of concealing information within other non-secret data, has been significantly transformed by the advent of artificial intelligence. We explore the integration of swarm intelligence algorithms in steganographic techniques, demonstrating their potential to improve the security and imperceptibility of embedded data. The research method encompasses a literature review, empirical analysis, and comparative studies to evaluate the performance of AI-enhanced steganography. Our findings indicate that AI-based methods, including those leveraging swarm intelligence, offer promising advancements in steganography, pushing the boundaries of data security and concealment.},
  keywords={Measurement;Steganography;PSNR;Data security;Bibliographies;Information security;Particle swarm optimization;Steganography;Artificial Intelligence;Swarm Intelligence Algorithms;Data Concealment;Information Security;AI-enhanced Steganographic Techniques},
  doi={10.1109/ICIPTM59628.2024.10563971},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{8022768,
  author={Kataoka, Yuusuke and Matsubara, Takashi and Uehara, Kuniaki},
  booktitle={2017 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)}, 
  title={Automatic manga colorization with color style by generative adversarial nets}, 
  year={2017},
  volume={},
  number={},
  pages={495-499},
  abstract={Many comic books are now published as digital books, which easily provide color contents compared to the physical books. The motivation of automatic colorization of comic books now arises. Previous studies colorize sketches without other clues or with spatial color annotations. They are expected to reduce workloads of comic artists but still require spatial color annotations for desirable colorizations. This study introduces a color style information and combines it with conditional adversarially learned inference. The experimental results demonstrate that the objects are painted with colors depending on the color style information and that the color style information extracted from a color image supports to painting an object with a desirable color.},
  keywords={Image color analysis;Color;Image edge detection;Generators;Linear programming;Training;Data mining},
  doi={10.1109/SNPD.2017.8022768},
  ISSN={},
  month={June},}@INBOOK{9536309,
  author={Soro, Francesca and Favale, Thomas and Giordano, Danilo and Vassio, Luca and Ben Houidi, Zied and Drago, Idilio},
  booktitle={Communication Networks and Service Management in the Era of Artificial Intelligence and Machine Learning}, 
  title={The New Abnormal: Network Anomalies in the AI Era}, 
  year={2021},
  volume={},
  number={},
  pages={261-288},
  abstract={Anomaly detection aims at finding unexpected patterns in data. It has been used in several problems in computer networks, from the detection of port scans and distributed denial&#x2010;of&#x2010;service (DDoS) attacks to the monitoring of time series collected from Internet monitoring systems. Data&#x2010;driven approaches and machine learning have seen widespread application on anomaly detection too, and this trend has been accelerated by the recent developments on Artificial Intelligence (AI) research. This chapter summarizes ongoing recent progresses on anomaly detection research. In particular, we evaluate how developments on AI algorithms bring new possibilities for anomaly detection. We cover new representation learning techniques such as Generative Artificial Networks and Autoencoders, as well as techniques that can be used to improve models learned with machine learning algorithms, such as reinforcement learning. We survey both research works and tools implementing AI algorithms for anomaly detection. We found that the novel algorithms, while successful in other fields, have hardly been applied to networking problems. We conclude the chapter with a case study that illustrates a possible research direction.},
  keywords={Anomaly detection;Taxonomy;IEEE Sections;Tools;Time series analysis;Telemetry;Reinforcement learning},
  doi={10.1002/9781119675525.ch11},
  ISSN={},
  publisher={IEEE},
  isbn={9781119675440},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/9536309},}@INPROCEEDINGS{10685663,
  author={Li, Yishu and Keung, Jacky and Ma, Xiaoxue},
  booktitle={2024 International Symposium on Educational Technology (ISET)}, 
  title={Integrating Generative AI in Software Engineering Education: Practical Strategies}, 
  year={2024},
  volume={},
  number={},
  pages={49-53},
  abstract={The transformative influence of generative artificial intelligence (AI), notably large language models (LLMs), has significantly reshaped the software engineering (SE) landscape, impacting various aspects of software development within industry and academia. The imperative to integrate generative AI into educational programs arises from the necessity to furnish graduates with contemporary methodologies that enhance software quality and streamline development processes. Nevertheless, a research gap exists concerning the systematic integration of established SE education guidelines with specific course contexts to strengthen SE education through incorporating generative AI. In response to this gap, our study presents a vision for integrating generative AI into SE education, with a particular emphasis on practical integration strategies aimed at endowing students with essential competencies tailored for contemporary software development. Aligning our vision with the knowledge domains within SE education, we delineate its application across specific areas such as code generation, auto test case completion, and others. The overall objective of these proposed initiatives is to furnish students in SE with an updated and immersive learning experience, thereby addressing the evolving demands of the field.},
  keywords={Industries;Systematics;Generative AI;Large language models;Software quality;Educational technology;Software engineering;software engineering;education;generative AI;large language models;code generation;auto test case completion},
  doi={10.1109/ISET61814.2024.00019},
  ISSN={2766-2144},
  month={July},}@INPROCEEDINGS{10834337,
  author={Kobayashi, Hisaya and Takagi, Masanori},
  booktitle={2024 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}, 
  title={Learning by Quiz Creation: A Novel Approach Using Interactive Generative AI and Its Experimental Application}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Research has shown that learning through quiz creation, where learners generate their own quizzes, demands a more profound understanding than learning through quiz-solving. Consequently, it is anticipated to yield greater learning outcomes. However, conventional support systems for learning through quiz creation have demonstrated that the learning outcomes vary depending on the process when learners are responsible for creating the quizzes. Additionally, it has been demonstrated that the flexibility of the quiz creation is reduced when the process is streamlined and regulated. To effectively address these issues, we must clarify the quiz creation process to deepen understanding and encourage it in accordance with the process. Moreover, to facilitate the flexible quiz creation and promote a quiz creation process that enhances understanding, we focused on using an interactive generative artificial intelligence (AI). We first analyze the quiz creation process by focusing on three common types: story-based, quiz-based, and solution-based. Additionally, we develop generative AI prompts to facilitate the process. Subsequently, we conducted an experimental application of the generative AI with the designed prompts to university students. The results of the experimental application indicate that the proposed quiz creation process partially contributed to enhancing comprehension through quiz creation, and our approach successfully improved learning outcomes. This study suggests that generative AI can improve learning outcomes by guiding learners to the appropriate process of quiz creation, and that it can help with flexible quiz creation, including the "natural language expression of a quiz setting".},
  keywords={Generative AI;Natural languages;Education;Focusing;Programming profession;Quiz creation;Generative AI;Programming education},
  doi={10.1109/TALE62452.2024.10834337},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8817178,
  author={},
  booktitle={2019 IEEE World Congress on Services (SERVICES)}, 
  title={IEEE SERVICES 2019 Plenary Panels}, 
  year={2019},
  volume={2642-939X},
  number={},
  pages={29-38},
  abstract={Provides an abstract for each of the plenary presentations and may include a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.},
  keywords={},
  doi={10.1109/SERVICES.2019.00012},
  ISSN={2642-939X},
  month={July},}@INPROCEEDINGS{10480503,
  author={Lee, Seo-Hyun and Lee, Young-Eun and Kim, Soowon and Ko, Byung-Kwan and Kim, Jun-Young},
  booktitle={2024 12th International Winter Conference on Brain-Computer Interface (BCI)}, 
  title={Neural Speech Embeddings for Speech Synthesis Based on Deep Generative Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Brain-to-speech technology represents a fusion of interdisciplinary applications encompassing fields of artificial intelligence, brain-computer interfaces, and speech synthesis. Neural representation learning based intention decoding and speech synthesis directly connects the neural activity to the means of human linguistic communication, which may greatly enhance the naturalness of communication. With the current discoveries on representation learning and the development of the speech synthesis technologies, direct translation of brain signals into speech has shown great promise. Especially, the processed input features and neural speech embeddings which are given to the neural network play a significant role in the overall performance when using deep generative models for speech generation from brain signals. In this paper, we introduce the current brain-to-speech technology with the possibility of speech synthesis from brain signals, which may ultimately facilitate innovation in non-verbal communication. Also, we perform comprehensive analysis on the neural features and neural speech embeddings underlying the neurophysiological activation while performing speech, which may play a significant role in the speech synthesis works.},
  keywords={Representation learning;Technological innovation;Neural activity;Linguistics;Brain modeling;Brain-computer interfaces;Decoding;brain-computer interface;deep neural networks;electroencephalogram;generative adversarial network;imagined speech;speech synthesis},
  doi={10.1109/BCI60775.2024.10480503},
  ISSN={2572-7672},
  month={Feb},}@INPROCEEDINGS{10782796,
  author={Latorre, Laura and Petrychenko, Liliana and Beets-Tan, Regina and Kopytova, Taisiya and Silva, Wilson},
  booktitle={2024 46th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}, 
  title={Towards Case-based Interpretability for Medical Federated Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={We explore deep generative models to generate case-based explanations in a medical federated learning setting. Explaining AI model decisions through case-based interpretability is paramount to increasing trust and allowing widespread adoption of AI in clinical practice. However, medical AI training paradigms are shifting towards federated learning settings in order to comply with data protection regulations. In a federated scenario, past data is inaccessible to the current user. Thus, we use a deep generative model to generate synthetic examples that protect privacy and explain decisions. Our proof-of-concept focuses on pleural effusion diagnosis and uses publicly available Chest X-ray data.},
  keywords={Training;Privacy;Federated learning;Biological system modeling;Data protection;Regulation;Artificial intelligence;Medical diagnostic imaging;X-ray imaging},
  doi={10.1109/EMBC53108.2024.10782796},
  ISSN={2694-0604},
  month={July},}@INBOOK{11164685,
  author={Campesato, Oswald},
  booktitle={Large Language Models: An Introduction}, 
  title={Chapter 1: The Generative AI Landscape}, 
  year={2024},
  volume={},
  number={},
  pages={1-54},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9781501520600},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11164685},}@INPROCEEDINGS{9731058,
  author={Meng, Han and Guo, Fangru},
  booktitle={2021 3rd International Conference on Machine Learning, Big Data and Business Intelligence (MLBDBI)}, 
  title={Image Classification and Generation Based on GAN Model}, 
  year={2021},
  volume={},
  number={},
  pages={180-183},
  abstract={The topic of image processing is becoming more and more popular in the field of artificial intelligence, and it can be applied to fields of biology, medicine, video games, art, and etc. In order to have a deeper understanding of how to optimize the image processing, this paper mainly proposed the Generative Adversarial Network (GAN), which is an emerging deep learning model with the ability to continuously improve modeling under the game, and there are already many applications related to image processing, such as video prediction, 3-dimensional object generation, image super-resolution and etc. In this paper, we mainly implement image generation and image classification based on GAN model. In order to indicate the performance of GAN model in image generation in detail, GAN models with linear layers and with convolution layers are trained and compared based on MNIST datasets. Furthermore, we train GAN model with linear layers, and GAN model with convolution layers, Multi-Layer Perceptron (MLP), Convolutional Neural Network (CNN), and Residual Network (ResNet) models in image classification based on the Mixed National Institute of Standards and Technology database (MNIST), and receive the training loss and testing accuracy of these models for different epochs in image classification. The experimental results demonstrated that GAN model with convolution layers performs best in both image generation and image classification.},
  keywords={Training;Convolution;Image synthesis;Games;Predictive models;Generative adversarial networks;Data models;Image generation;GAN model;Image classification;Experimental analysis},
  doi={10.1109/MLBDBI54094.2021.00042},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10213103,
  author={Cheng, Wen and Zhang, ShiBin and Lin, Yusheng},
  booktitle={2023 3rd International Symposium on Computer Technology and Information Science (ISCTIS)}, 
  title={Study on the Adversarial Sample Generation Algorithm Based on Adversarial Quantum Generation Adversarial Network}, 
  year={2023},
  volume={},
  number={},
  pages={238-243},
  abstract={In response to the inefficiency of the existing advGAN method, which requires calculating the differences between the adversarial samples and the normal samples one by one when generating adversarial perturbations, this paper proposes a quantum adversarial sample generation algorithm (QASGA) based on adversarial quantum generative adversarial networks. First, the real samples are encoded into quantum states, then the generator G of QGAN is used to generate adversarial perturbations, which are superimposed with normal samples to obtain adversarial samples. At the same time, the SWAP-TEST method is used to calculate the similarity between all real samples and adversarial samples at once, thereby accelerating adversarial attacks. Experimental results show that the QASGA algorithm proposed in this paper can generate high-fidelity adversarial samples with a one-time similarity calculation on the IRIS dataset, and can reduce the classification accuracy of the BP neural network from 96.67% to 26.67%, verifying the effectiveness of the proposed QASGA algorithm.},
  keywords={Iris;Information science;Quantum computing;Perturbation methods;Neural networks;Quantum state;Generative adversarial networks;component;Quantum Generative Adversarial Network;Adversarial Aamples;Adversarial Generative Adversarial Network;Adversarial Quantum Generative Adversarial Network;Quantum Adversarial Sample Generation Algorithm},
  doi={10.1109/ISCTIS58954.2023.10213103},
  ISSN={},
  month={July},}@ARTICLE{11030612,
  author={Zhang, Qianyun and Shi, Jiting and Zeng, Weihao and Xu, Xinyu and Guan, Zhenyu and Li, Shufeng and Qin, Zhijin},
  journal={IEEE Network}, 
  title={Balancing Security and Efficiency in GAI-Driven Semantic Communication: Challenges, Solutions, and Future Paths}, 
  year={2025},
  volume={39},
  number={5},
  pages={88-96},
  abstract={The convergence of artificial intelligence (AI) and wireless communications has driven the emergence of semantic communication (SC), a paradigm that prioritizes context-aware semantic exchange over traditional bit-level transmission. Although enhancing efficiency and task-specific reliability, this advancing capability is accompanied by significant security challenges that remain underexplored. In this paper, we provide an overview of security challenges in SC systems, with a particular focus on the confidentiality, integrity, and availability of the wireless transmission and generative AI (GAI) models. To defend against risks of model confidentiality compromise and semantic feature leakage, we propose a solution integrating trusted execution environments (TEEs) for secure model inference and adversarial cryptography for the protection of semantics over realistic wireless channels. Test results show it achieves close-to-black-box attack resistance in model stealing effectiveness, and the BLEU scores of eavesdropping attackers are effectively reduced to below 0.1 across various SNR levels. Finally, we discuss potential open issues and solutions for enhancing the SC security, paving the way for future research in this critical area. The proposed framework demonstrates promising results in enhancing both model and data confidentiality, contributing to the development of secure SC systems for 6G networks.},
  keywords={Semantics;Security;Wireless communication;Data models;Training;Communication system security;Accuracy;Feature extraction;Wireless sensor networks;Eavesdropping;Artificial intelligence;Generative AI;Data security;generative artificial intelligence;network security;semantic communications},
  doi={10.1109/MNET.2025.3578783},
  ISSN={1558-156X},
  month={Sep.},}@ARTICLE{10813420,
  author={Shah, Riddhiben Sunitkumar},
  journal={IEEE Potentials}, 
  title={The power of generative artificial intelligence: Revolutionizing cybersecurity, marketing, and creative industries}, 
  year={2024},
  volume={43},
  number={6},
  pages={31-38},
  abstract={This article provides a comprehensive overview of generative artificial intelligence (GenAI) by tracing its evolution from early techniques such as Gaussian mixture models (GMMs) to recent advances like generative adversarial networks (GANs) and transformer-based models. Additionally, it outlines various key generative frameworks like variational autoencoders (VAEs), deep belief networks (DBNs), deep Boltzmann machines (DBMs), and normalizing flows. Additionally, the article analyzes their respective strengths and weaknesses in modeling complex data distributions. Specifically, it discusses how GANs can produce highly realistic outputs but risk mode collapse, while VAEs impose useful structure but can over-smooth details.},
  keywords={Data models;Artificial intelligence;Transformers;Training;Generators;Predictive models;Image reconstruction;Generative adversarial networks;Faces;Creativity},
  doi={10.1109/MPOT.2024.3508073},
  ISSN={1558-1772},
  month={Nov},}@INPROCEEDINGS{10986564,
  author={Kumar, Manoj and Rai, Praveen Kumar and Kumar, Pankaj},
  booktitle={2025 3rd International Conference on Disruptive Technologies (ICDT)}, 
  title={A Novel Approach for Deepfake Video Detection}, 
  year={2025},
  volume={},
  number={},
  pages={218-223},
  abstract={As technology continues to progress, the creation of deepfakes is becoming increasingly simple and accessible. Due to developments in deep learning, artificial intelligence, and face manipulation tools, the quality of average deepfakes is steadily broadening. Deepfake technology represents the forefront of video manipulation, employing sophisticated neural networks such as auto-encoders and Generative Adversarial Networks (GANs) to produce convincingly deceptive facial videos. Replacing the target face with a fake face in video content can be achieved quite easily using face manipulation techniques. Deepfakes can deploy the different type of deep learning algorithm's which can easily manipulate and synthesize the images and videos of a person that humans cannot distinguish from the real one. Caution should be exercised when utilizing this, as it has the potential for misuse. Identifying and detecting the manipulated video content is an essential responsibility that requires resilient methods to detect deepfake videos. There are serious concerns that deepfake technology will become a problem in the future. biometric security may become more vulnerable to malicious use in the coming years, raising concerns about its safety. Information, involving the utilization of facial recognition technology. To address these issues, detecting deepfakes are extremely crucial. Therefore, we attempt to construct a hybrid deepfake detection model which can categorize the manipulated videos and original videos. In this paper we will develop more efficient model to detect whether a video is a real or manipulated video. We will be using Res-Next Conventional Neural Network to extract frame level features and Long Short-Term Memory (LSTM) to differentiate whether a video is fake or real type. There are various available datasets to train and test our model. Our main focus is identifying and detecting deepfake videos with high precision, effectively by using the robust method which can differentiate b/w real and deepfake video with accuracy of more than 94%.},
  keywords={Deep learning;Training;Deepfakes;Accuracy;Face recognition;Neural networks;Feature extraction;Generative adversarial networks;Artificial intelligence;Long short term memory;Deepfake technology;Generative Adversarial Networks (GANs) Long Short-Term Memory (LSTM);face manipulation;Deep learning;Artificial intelligence (AI)},
  doi={10.1109/ICDT63985.2025.10986564},
  ISSN={},
  month={March},}@INBOOK{10952896,
  author={Singh, Shiv},
  booktitle={Marketing with AI For Dummies}, 
  title={Perfecting Prompts for Conversational Interfaces}, 
  year={2025},
  volume={},
  number={},
  pages={197-210},
  abstract={Summary <p>Generative artificial intelligence (AI) and conversational interfaces can help streamline marketing efforts because they use their massive data and language modeling resources to assist marketers with practically every major marketing activity. Chat interfaces &#x2014; such as ChatGPT, Bard, Perplexity AI, and others &#x2014; offer several different formats in which the readers can require the response. The AI can refer to earlier parts of the conversation and even carries short&#x2010;term memory, which makes it even more informed and responsive the more the readers converse with it. The chapter provides seven recommendations that can help the readers limit AI bias via prompt writing: construct balanced prompts, try different prompts, deploy bias detection, be wary of over&#x2010;customization, limit how to use the AI, provide feedback, and share readers' knowledge with others.</p>},
  keywords={Artificial intelligence;Chatbots;Writing;Oral communication;Generative AI;Codes;Large language models;Visualization;Syntactics;Particle swarm optimization},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394237210},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952896},}@ARTICLE{10196455,
  author={Cherqi, Othmane and Moukafih, Youness and Ghogho, Mounir and Benbrahim, Houda},
  journal={IEEE Access}, 
  title={Enhancing Cyber Threat Identification in Open-Source Intelligence Feeds Through an Improved Semi-Supervised Generative Adversarial Learning Approach With Contrastive Learning}, 
  year={2023},
  volume={11},
  number={},
  pages={84440-84452},
  abstract={Responding to the challenge of efficiently leveraging Open-source Threat Intelligence Feeds (OTIFs) to enhance organizational security, this paper presents an innovative approach to automated threat identification using machine learning. Current machine learning models require large volumes of high-quality annotated data, which is a major obstacle given the inherent scarcity of such data in OTIFs. Bridging this research gap, we propose a novel semi-supervised learning strategy that capitalizes on both labeled and unlabeled data to automate threat identification. Our unique contribution is an advanced iteration of the GAN-BERT framework, which incorporates a self-supervised contrastive objective function to fine-tune the BERT language model. Our experiments show that this method outperforms the original BERT and GAN-BERT, achieving a 3-12% F1-score improvement on various OTIFs datasets. Furthermore, we present an efficient method for selecting hard negatives during training, which further enhances our model‚Äôs performance. This innovative approach significantly advances the field of automated threat detection, reducing reliance on human supervision and effectively addressing the issue of limited annotated data. Thus, it offers a robust solution for strengthening security posture through proactive decision making in Cyber Threat Intelligence.},
  keywords={Bit error rate;Cyber threat intelligence;Feeds;Machine learning;Generative adversarial networks;Semisupervised learning;Text categorization;Threat assessment;Open source software;Generative adversarial networks;BERT;contrastive learning;semi-supervised learning;text classification;threat intelligence;open-source threat intelligence feeds},
  doi={10.1109/ACCESS.2023.3299604},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10704261,
  author={Ayubi, Aula and Utama, Nugraha P.},
  booktitle={2024 International Conference on Artificial Intelligence, Blockchain, Cloud Computing, and Data Analytics (ICoABCD)}, 
  title={Enhanced Generation of Gastrointestinal Images for Data Augmentation Using a Modified BlobGAN}, 
  year={2024},
  volume={},
  number={},
  pages={161-166},
  abstract={The advent of artificial intelligence (AI) and deep learning has revolutionized healthcare, particularly in the realm of medical imaging, patient care, and personalized treatments. However, the emergence of deepfake technology, while offering promising opportunities, also presents unique challenges. Generative adversarial networks (GANs) can produce highly realistic synthetic medical images (deepfakes) with potential applications in tasks like segmentation and detection. This study leverages a modified BlobGAN architecture, incorporating a self-attention block, to generate enhanced gastrointestinal images. We trained and validated our model on the Kvasir dataset, a comprehensive repository of endoscopic images. Our modifications aim to address the limitations of current deep learning models by producing synthetic images of exceptional quality that closely resemble real gastrointestinal images. Results demonstrate a lowest Fr√©chet Inception Distance (FID) of 15.552 and a highest Inception Score (IS) of 6.951, indicating the high fidelity of our generated images. By generating synthetic data that mirrors actual medical images, this research contributes to overcoming challenges of limited data availability and privacy concerns in the field of AI for healthcare. Ultimately, our approach has the potential to expand training datasets and improve the performance of automated classification systems.},
  keywords={Deep learning;Training;Deepfakes;Image segmentation;Medical services;Gastrointestinal tract;Mirrors;Artificial intelligence;Biomedical imaging;Synthetic data;Generative Adversarial Networks;BlobGAN;Gastrointestinal Imaging;Synthetic Images;Data Augmentation;Kvasir Dataset;Self-Attention Block},
  doi={10.1109/ICoABCD63526.2024.10704261},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9644063,
  author={Shieh, Chin-Shiuh and Nguyen, Thanh-Tuan and Lin, Wan-Wei and Huang, Yong-Lin and Horng, Mong-Fong and Lee, Tsair-Fwu and Miu, Denis},
  booktitle={2021 6th International Conference on Computational Intelligence and Applications (ICCIA)}, 
  title={Synthesis of Adversarial DDoS Attacks Using Wasserstein Generative Adversarial Networks with Gradient Penalty}, 
  year={2021},
  volume={},
  number={},
  pages={118-122},
  abstract={DDoS (Distributed Denial of Service) has become a pressing and challenging threat to the security and integrity of computer networks and information systems. The detection of DDoS attacks is essential before any mitigation approaches can be taken. AI (Artificial Intelligence) and ML (Machine Learning) have been applied to the detection of DDoS attacks with satisfactory achievement. However, new types of attacks emerge as the technology for DDoS attacks keep evolving. This study investigates the impact of a new sort of DDoS attack ‚Äì adversarial DDoS attack. We synthesize attacking traffic using Wasserstein Generative Adversarial Networks with Gradient Penalty (GPWGAN). Experiment results reveal that the synthesized traffic can penetrate the systems, including Random Forest, k-Nearest Neighbor, and Multi-Layer Perceptron, without being detected. This observation is an alarming and pessimistic wake-up call implying the urgent need for countermeasures to adversarial DDoS attacks.},
  keywords={Radio frequency;Pressing;Denial-of-service attack;Generative adversarial networks;Generators;Computer networks;Security;DDoS;machine learning;generative adversarial network},
  doi={10.1109/ICCIA52886.2021.00030},
  ISSN={},
  month={June},}@INBOOK{10953272,
  author={Singh, Shiv},
  booktitle={Marketing with AI For Dummies}, 
  title={Fine&#x2010;Tuning Content with Localization and Translation}, 
  year={2025},
  volume={},
  number={},
  pages={255-268},
  abstract={Summary <p>Artificial intelligence (AI) can play an important role in making the process of localization and translation more efficient and effective. AI can tailor digital advertising and marketing based on geographic and linguistic data, allowing companies to run localized campaigns that resonate with the target audience. A relatively recent development in the world of generative AI involves the development of multilingual large language models (LLMs). A multilingual LLM is an advanced AI system designed to understand, generate, and process text across multiple languages. Advancements in AI technology enable content creators to produce a variety of localized versions of their work more efficiently and to provide a digital experience that feels deeply personalized. Using AI for quality control in localization and translation can help improve accuracy, efficiency, and consistency in the marketing content and campaigns. This chapter looks at how real&#x2010;time localization and translation solutions work, their benefits, and their applications in marketing.</p>},
  keywords={Translation;Artificial intelligence;Location awareness;Cultural differences;Multilingual;Business;Global communication;Chatbots;Companies;Advertising},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394237210},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10953272},}@INPROCEEDINGS{10974888,
  author={Neha, FNU and Bhati, Deepshikha and Shukla, Deepak Kumar and Amiruzzaman, Md},
  booktitle={2024 34th International Conference on Computer Theory and Applications (ICCTA)}, 
  title={A Tiered GAN Approach for Monet-Style Image Generation}, 
  year={2024},
  volume={},
  number={},
  pages={232-237},
  abstract={Generative Adversarial Networks (GANs) have proven to be a powerful tool in generating artistic images, capable of mimicking the styles of renowned painters, such as Claude Monet. This paper introduces a tiered GAN model to progressively refine image quality through a multi-stage process, enhancing the generated images at each step. The model transforms random noise into detailed artistic representations, addressing common challenges such as instability in training, mode collapse, and output quality. This approach combines downsampling and convolutional techniques, enabling the generation of high-quality Monet-style artwork while optimizing computational efficiency. Experimental results demonstrate the architecture‚Äôs ability to produce foundational artistic structures, though further refinements are necessary for achieving higher levels of realism and fidelity to Monet‚Äôs style. Future work focuses on improving training methodologies and model complexity to bridge the gap between generated and true artistic images. Additionally, the limitations of traditional GANs in artistic generation are analyzed, and strategies to overcome these shortcomings are proposed.},
  keywords={Training;Image quality;Deep learning;Visualization;Image synthesis;Computational modeling;Noise;Transforms;Generative adversarial networks;Computational efficiency;Artificial Intelligence;Deep Learning;Image Processing;Generative Adversarial Networks (GANs);Artistic Image Generation;Visual Interpretation},
  doi={10.1109/ICCTA64612.2024.10974888},
  ISSN={2770-6575},
  month={Dec},}@INPROCEEDINGS{9580137,
  author={Sankar, Rashmi and Singh, Tripty},
  booktitle={2021 12th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Robust Feature Extraction Using Embedded Gan in Image Retrieval Systems for SEMI-Supervised Data}, 
  year={2021},
  volume={},
  number={},
  pages={1-3},
  abstract={A blend of unlabeled data (unsupervised) in large volume, along with a small number of labeled data (supervised), makes a semi-supervised dataset. Content-Based Image Retrieval (CBIR) systems are used to label/model such data. Based on the features extracted, the unsupervised query images get labeled upon the similarity measures with the reference labeled images (one image per class). Due to the insufficient availability of trained data, modeling a CNN to act as a feature extractor will be inefficient. Hence, pre-trained models, trained upon public databases (ImageNet) and have never been fine-tuned on the target dataset, will be used as a feature extractor, which lowers the confidence over the labeling task. The proposed method will put together a Generative Adversarial Network (GAN), with the chosen pre-trained model embedded inside the GAN as a discriminator, that will fine-tune the pre-trained model's weights in accordance with the unlabeled target data. These fine-tuned pre-trained models can then be used to extract features and will help to build a robust CBIR system. Abbreviations - CBIR, Content Based Image Retrieval; GAN, Generative Adversarial Network; CNN, Convolutional Neural Network.},
  keywords={Image retrieval;Learning (artificial intelligence);Feature extraction;Generative adversarial networks;Data models;Data mining;Convolutional neural networks;Artificial intelligence;Feature extraction;Image retrieval;Knowledge based systems;Semisupervised learning},
  doi={10.1109/ICCCNT51525.2021.9580137},
  ISSN={},
  month={July},}@INPROCEEDINGS{10690724,
  author={P, Kumar and K, Rhikshitha and A, Sanjay and S, Samitha},
  booktitle={2024 Second International Conference on Advances in Information Technology (ICAIT)}, 
  title={TNGov-GPT: Pioneering Conversational AI Chat through Tamil Nadu Government Insights and Transformer Innovations}, 
  year={2024},
  volume={1},
  number={},
  pages={1-7},
  abstract={In this study, we introduce an innovative chatbot that utilizes Large Language Models (LLMs) and Generative Artificial Intelligence (AI) techniques. The chatbot undergoes training with a carefully curated dataset extracted from official Indian government websites. This dataset covers a wide array of information, enabling the transformer model to generate responses that are contextually relevant to user queries. Our methodology involves the extraction of data, its preprocessing, and the training of a transformer-based model to handle question-and-answer interactions. The paper explores the nuances of the dataset, highlighting its distinct characteristics and challenges. We delve into the model architecture, providing a detailed understanding of the implemented LLMs and Generative AI. The results from experiments demonstrate the efficacy of the proposed chatbot in delivering precise and informative responses. This study contributes to the evolving field of conversational AI by utilizing publicly accessible government data for training, expanding the potential applications of such models. In the discussion section, we critically analyze the outcomes, addressing both the strengths and limitations of our approach. Comparative insights with existing methodologies serve to validate the effectiveness of the developed chatbot. As a pioneering endeavor, this research not only showcases the capabilities of transformer models in handling government data but also suggests potential avenues for future enhancements and applications in various domains.},
  keywords={Training;Technological innovation;Generative AI;Large language models;Government;Chatbots;Transformers;Data models;Planning;Information technology;Chatbot;Large Language Models;Generative Artificial Intelligence;Transformer;Indian Government;Dataset;Natural Language Processing;Conversational AI},
  doi={10.1109/ICAIT61638.2024.10690724},
  ISSN={},
  month={July},}@INPROCEEDINGS{10411582,
  author={Tomaszewska, Renata},
  booktitle={2023 IEEE International Conference on Data Mining Workshops (ICDMW)}, 
  title={Andragogy Meets ChatGPT in Lifelong Learning: Exploring Opportunities and Challenges}, 
  year={2023},
  volume={},
  number={},
  pages={868-874},
  abstract={This paper delves into the confluence of Lifelong Learning (LLL) and progressive pedagogical methodologies, specifically investigating the integration of Generative Pre-training Transformer - ChatGPT. Examining LLL‚Äôs significance in the digital proficiency context and the evolving educational landscape, the paper highlights the potential benefits of ChatGPT in LLL. Simultaneously, it scrutinizes challenges tied to its assimilation. Envisioning AI‚Äôs central role in LLL, the study underscores ChatGPT‚Äôs transformative potential. Recommendations are offered for responsible ChatGPT integration in LLL. The interplay between lifelong learning and advanced AI-driven tools presents opportunities and responsibilities, necessitating a balanced approach to harnessing ChatGPT‚Äôs potential for enriching lifelong learning.},
  keywords={Education;Neural implants;Chatbots;Transformers;Internet;Artificial intelligence;Robots;andragogy;Artificial Intelligence;AI Pedagogy;ChatGTP;Lifelong Learning},
  doi={10.1109/ICDMW60847.2023.00117},
  ISSN={2375-9259},
  month={Dec},}@INPROCEEDINGS{11041706,
  author={J, Benitha Christinal and A, Betsee Natasha and M, Nivethitha and E, Asmitha and N, Kaviya},
  booktitle={2025 Third International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)}, 
  title={A Modern Generative AI Framework for Alzheimer Detection Leveraging Autoencoders and Softmax Classifier}, 
  year={2025},
  volume={},
  number={},
  pages={271-276},
  abstract={This study proposes a modern generative AI framework for Alzheimer's detection that combines autoencoders with a Softmax classifier. Autoencoders are utilized to extract meaningful and compact features from brain imaging data, enabling efficient dimensionality reduction and noise filtering. The Softmax classifier, built atop the encoded features, ensures accurate disease classification by distinguishing Alzheimer's patients from healthy individuals. The framework leverages advanced neural architectures to improve diagnostic accuracy and computational efficiency. Experimental results demonstrate its potential to enhance early detection, aiding in timely intervention and treatment planning. In this study, the model achieved a classification accuracy of 89%, which is a strong result.},
  keywords={Neuroimaging;Accuracy;Generative AI;Filtering;Autoencoders;Noise;Magnetic resonance;Feature extraction;Planning;Alzheimer's disease;Alzheimer disease;Magnetic Resonance Imaging(MRI);Auto-encoders;Generative Artificial intelligence(Gen-AI);Softmax classifier},
  doi={10.1109/ICAISS61471.2025.11041706},
  ISSN={},
  month={May},}@INPROCEEDINGS{10689846,
  author={Sumathi, G. and Juliet, P. Sudha and Banu, M. Shafiya and Sujitha, S. Daisylin Anbu and S, Yuvaraj and Sujatha, S.},
  booktitle={2024 5th International Conference on Electronics and Sustainable Communication Systems (ICESC)}, 
  title={Molecular Design for Drug Discovery with the Use of Generative Adversarial Networks}, 
  year={2024},
  volume={},
  number={},
  pages={885-890},
  abstract={This research study describes how Generative Adversarial Networks (GANs) are used to improve drug discovery molecular design. The goal is to maximize the discovery of potential drug candidates by making use of GANs' ability to produce a wide variety of chemical structures. The goal is to use better molecular design methods to speed up and improve the medication development process. The purpose of using GANs is to make it easier to build new molecular structures with certain features, such more potency and selectivity. This technology has the potential to bypass the drawbacks of conventional drug discovery techniques and speed up the process of exploring chemical space. It demonstrates that GANs have the potential to revolutionize drug development through computational simulations and validation tests. One potential way to find new treatments and solve medical problems that have so far gone unsolved is to include GANs into molecular design processes. Results from Drug Design Data Resource, Kaggle datasets shows that the molecular formula with id Activity-Based Learning (ABL) minimum value starts with 0.055 and maximum of 10, from the sample of 10 compounds the minimum affinity value is 0.075 and maximum of 3.42. In another data surveyed the drug discovery values show the minimum of the molecular weight is 356.3 and maximum is 471.5.},
  keywords={Drugs;Technological innovation;Design methodology;Refining;Generative adversarial networks;Drug discovery;Space exploration;Compounds;Reliability;Chemicals;Drug Discovery;Molecular Design;Generative Adversarial Networks;Optimization;Therapeutic Innovation},
  doi={10.1109/ICESC60852.2024.10689846},
  ISSN={2996-5357},
  month={Aug},}@INPROCEEDINGS{11158600,
  author={Rajakakarlapudi, Rajeev Varma and Vadisetty, Rahul},
  booktitle={2025 International Conference on Advancements in Smart, Secure and Intelligent Computing (ASSIC)}, 
  title={Generative AI for Adaptive Network Slicing in RedCap 5G Networks}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={Given the imminent introduction of Reduced Capability (RedCap) devices in 5G networks, the computational and communications limitations of these devices note new challenges for network slicing. Adaptive network slicing is required to optimize resource allocation and to maintain quality of service (QoS) across the wide variety of scenarios encountered in RedCap use cases. Finally Generative Artificial Intelligence (GenAI) represents a promising way forward: we use it to predict network conditions, effect automatic slice reconfiguration, and govern flexible resource distribution. In this paper, we look into the handicap of genai models such as generative opposition networks (GANS) and variationally autoencoders (VAEs) assisted network slicing for RedCap enabled 5G networks. Synthetic network traffic patterns can be created by GenAI, allowing it to forecast congestion and adjust slice parameters ahead of time on the basis of what it has learned. A reinforcement learning-driven network model lends itself to real-time decision-making, which will improve spectral efficiency, lowers delays, and will result in optimized power consumption. This paper presents a framework that applies GenAI to handle slice elasticity. If network conditions were changing, be in the future or in the middle of a task, this would ensure the operation of services with minimal interruption. The method was evaluated by simulation and found to be successful in dynamically balancing traffic loads and maintaining QoS levels in RedCap scenarios. Our work demonstrates that adaptive slicing driven by GenAI greatly enhances network efficiency, making 5G RedCap deployments more robust and scalable.},
  keywords={Wireless communication;Wireless sensor networks;Adaptive systems;Generative AI;5G mobile communication;Network slicing;Decision making;Quality of service;Telecommunication traffic;Resource management;Generative AI;Adaptive Network Slicing;RedCap 5G;AI-driven Optimization;Resource Allocation},
  doi={10.1109/ASSIC64892.2025.11158600},
  ISSN={},
  month={May},}@INPROCEEDINGS{10827199,
  author={Zhang, HaiQing},
  booktitle={2024 7th International Conference on Pattern Recognition and Artificial Intelligence (PRAI)}, 
  title={Integrating Multicore SVM With Enhanced Residual Networks for AI Content Recognition}, 
  year={2024},
  volume={},
  number={},
  pages={726-729},
  abstract={This study delves into the intersection of data science and machine learning methodologies, specifically examining the recognition of Artificial Intelligence (AI)-generated papers and images. We curate a comprehensive dataset comprising 200 papers and 855 images, meticulously segregating them into AI-generated and non-AI categories, and transform this raw data into structured formats suitable for rigorous analysis. For text classification, we employ a Multicore Support Vector Machines (SVM) model, optimized through cross-validation and grid search techniques, to accurately distinguish AI-authored papers from human-penned ones. For image classification, we develop an enhanced model that builds upon the strengths of ResNet and DenseNet architectures, achieving high accuracy in discerning AI-generated images. Furthermore, we integrate these two classification systems within a weighted, top-level decision framework, offering a holistic approach to AI content recognition. The proposed methodology and findings offer a novel perspective on AI content detection, with potential applications in copyright protection, academic integrity assessment, and media content monitoring. This research contributes to advancing the state-of-the-art in AI content identification and underscores the importance of robust tools for managing the proliferation of AI-generated content.},
  keywords={Support vector machines;Measurement;Image recognition;Accuracy;Text recognition;Multicore processing;Writing;Mathematical models;Data models;Artificial intelligence;Improved ResNet;AI Thesis Recognition;Decision systems},
  doi={10.1109/PRAI62207.2024.10827199},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10156702,
  author={Laptiev, Oleksandr and Musienko, Andrii and Nakonechnyi, Volodymyr and Sobchuk, Andrii and Gakhov, Sergii and Kopytko, Serhii},
  booktitle={2023 5th International Congress on Human-Computer Interaction, Optimization and Robotic Applications (HORA)}, 
  title={Algorithm for Recognition of Network Traffic Anomalies Based on Artificial Intelligence}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Abnormalities in network traffic can be caused by malfunctioning network equipment, accidental or intentional actions by users, or the actions of attackers. Thus, for reliable data transmission in the information network, it is necessary to take measures to detect anomalies in a timely manner and take measures to eliminate them. Therefore, in order to ensure reliable data transmission in the network, the development of new methods for detecting anomalies is of urgent importance. This work is devoted to the development of an improved algorithm for recognizing network traffic anomalies based on artificial intelligence. On the basis of the conducted analysis and research, an improved algorithm was developed for the most accurate determination of an abnormal state. The principle component analysis algorithm was taken as a basis and a type of Generative adversarial network algorithm, a machine learning algorithm without a teacher, was added to it, namely BIGAN, which uses an encoder in its activity, namely, thanks to its E encoder, it is able to detect anomalies in input and processed data, which made it possible to detect network traffic anomalies with greater accuracy and in less time.},
  keywords={Machine learning algorithms;Telecommunication traffic;Generative adversarial networks;Computer networks;Reliability;Data communication;Artificial intelligence;model;network packets;protocol anomalies;algorithm;machine learning;learning without a teacher},
  doi={10.1109/HORA58378.2023.10156702},
  ISSN={},
  month={June},}@ARTICLE{9508907,
  author={Nguyen, Dinh C. and Ding, Ming and Pathirana, Pubudu N. and Seneviratne, Aruna and Li, Jun and Niyato, Dusit and Poor, H. Vincent},
  journal={IEEE Wireless Communications}, 
  title={Federated Learning for Industrial Internet of Things in Future Industries}, 
  year={2021},
  volume={28},
  number={6},
  pages={192-199},
  abstract={The Industrial Internet of Things (IIoT) offers promising opportunities to revolutionize the operation of industrial systems and become a key enabler of future industries. Recently, artificial intelligence (AI) has been widely utilized for realizing intelligent IIoT applications where AI techniques require centralized data collection and processing. However, this is not always feasible in realistic scenarios due to the high scalability of modern IIoT networks and growing industrial data confidentiality. Federated Learning (FL), as an emerging collaborative AI approach, is particularly attractive for intelligent IIoT networks by coordinating multiple IIoT devices and machines to perform AI training at the network edge while helping protect user privacy and confidential business information. In this article, we provide a detailed overview and discussions of the emerging applications of FL in several key IIoT services and applications. A case study is also provided to demonstrate the feasibility of FL in IIoT. Finally, we highlight a range of interesting open research topics that need to be addressed for the full realization of FL-IIoT in future industries.},
  keywords={Industrial Internet of Things;Artificial intelligence;Servers;Training data;Load modeling;Data models;Collaborative work},
  doi={10.1109/MWC.001.2100102},
  ISSN={1558-0687},
  month={December},}@INPROCEEDINGS{9856380,
  author={Boby, Alden and Brown, Dane and Connan, James and Marais, Marc},
  booktitle={2022 International Conference on Artificial Intelligence, Big Data, Computing and Data Communication Systems (icABCD)}, 
  title={Investigating the Effects of Image Correction Through Affine Transformations on Licence Plate Recognition}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Licence plate recognition has many real-world applications, which fall under security and surveillance. Deep learning for licence plate recognition has been adopted to improve existing image-based processing techniques in recent years. Object detectors are a popular choice for approaching this task. All object detectors are some form of a convolutional neural network. The You Only Look Once framework and Region-Based Convolutional Neural Networks are popular models within this field. A novel architecture called the Warped Planar Object Detector is a recent development by Zou et al. that takes inspiration from YOLO and Spatial Network Transformers. This paper aims to compare the performance of the Warped Planar Object Detector and YOLO on licence plate recognition by training both models with the same data and then directing their output to an Enhanced Super-Resolution Generative Adversarial Network to upscale the output image, then lastly using an Optical Character Recognition engine to classify characters detected from the images.},
  keywords={Surveillance;Image recognition;Superresolution;Detectors;Transformers;Generative adversarial networks;Convolutional neural networks;License plate recognition;object detection;optical character recognition;generative adversarial network;spatial network transformer;super-resolution},
  doi={10.1109/icABCD54961.2022.9856380},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{11050643,
  author={Crossman, Andrew and Plummer, Andrew R. and Sekharudu, Chandra and Warrier, Deepak and Yekrangian, Mohammad},
  booktitle={2025 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-Based Copilot}, 
  year={2025},
  volume={},
  number={},
  pages={1160-1167},
  abstract={We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat models in minutes, relative to the weeks or months a manual process takes. The focus on tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. We establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.},
  keywords={Threat modeling;Generative AI;Prevention and mitigation;System performance;Systems architecture;Information security;Standardization;Manuals;Matrix decomposition;Computer security;Cybersecurity;Threat Modeling;Generative Artificial Intelligence},
  doi={10.1109/CAI64502.2025.00201},
  ISSN={},
  month={May},}@INPROCEEDINGS{10837337,
  author={Sonune, Harsha and Kulkarni, Nilima},
  booktitle={2024 IEEE International Conference on Blockchain and Distributed Systems Security (ICBDS)}, 
  title={Leveraging AI for Enhanced Botnet Detection - A Review of Machine Learning Approach for Cybersecurity}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Botnets represent a substantial threat to cybersecurity, enabling malicious actors to execute large-scale attacks that compromise network integrity and data confidentiality. Current detection methods often fall short in addressing the rapidly evolving strategies employed by botnets. This study has an aim of designing and developing a sophisticated botnet detection system leveraging artificial intelligence (AI) techniques. By integrating machine learning algorithms and advanced data analysis methods, the proposed system seeks to accurately identify and mitigate botnet activities in real-time. The study will evaluate the effectiveness of various AI models in detecting botnet traffic, provide a comparative analysis of their performance, and propose an optimal framework for implementation in cybersecurity infrastructures.},
  keywords={Analytical models;Technological innovation;Machine learning algorithms;Data analysis;Botnet;Prevention and mitigation;Real-time systems;Stakeholders;Computer security;Artificial intelligence;Botnets;cybersecurity;network integrity;data confidentiality;detection methods;AI-driven solutions;machine learning algorithms;data analysis;real-time identification;mitigating botnet activities;AI models;botnet traffic;comparative analysis;implementation framework},
  doi={10.1109/ICBDS61829.2024.10837337},
  ISSN={},
  month={Oct},}@ARTICLE{10475156,
  author={Xue, Xiao and Zhou, Deyu and Yu, Xiangning and Wang, Gang and Li, Juanjuan and Xie, Xia and Cui, Lizhen and Wang, Fei-Yue},
  journal={IEEE/CAA Journal of Automatica Sinica}, 
  title={Computational Experiments for Complex Social Systems: Experiment Design and Generative Explanation}, 
  year={2024},
  volume={11},
  number={4},
  pages={1022-1038},
  abstract={Powered by advanced information technology, more and more complex systems are exhibiting characteristics of the cyber-physical-social systems (CPSS). In this context, computational experiments method has emerged as a novel approach for the design, analysis, management, control, and integration of CPSS, which can realize the causal analysis of complex systems by means of ‚Äúalgorithmization‚Äù of ‚Äúcounterfactuals‚Äù. However, because CPSS involve human and social factors (e.g., autonomy, initiative, and sociality), it is difficult for traditional design of experiment (DOE) methods to achieve the generative explanation of system emergence. To address this challenge, this paper proposes an integrated approach to the design of computational experiments, incorporating three key modules: 1) Descriptive module: Determining the influencing factors and response variables of the system by means of the modeling of an artificial society; 2) Interpretative module: Selecting factorial experimental design solution to identify the relationship between influencing factors and macro phenomena; 3) Predictive module: Building a meta-model that is equivalent to artificial society to explore its operating laws. Finally, a case study of crowd-sourcing platforms is presented to illustrate the application process and effectiveness of the proposed approach, which can reveal the social impact of algorithmic behavior on ‚Äúrider race‚Äù.},
  keywords={Analytical models;Systematics;Computational modeling;Buildings;Predictive models;Data models;Social factors;Agent-based modeling;computational experiments;cyber-physical-social systems (CPSS);generative deduction;generative experiments;meta model},
  doi={10.1109/JAS.2024.124221},
  ISSN={2329-9274},
  month={April},}@INPROCEEDINGS{10404195,
  author={Parida, Shantipriya and Sekhar, Sambit and Panda, Subhadarshi and Jena, Swateek and Parida, Abhijeet and Sahoo, Soumendra Kumar and Dash, Satya Ranjan},
  booktitle={2023 IEEE Silchar Subsection Conference (SILCON)}, 
  title={Olive: An Instruction Following LLaMA Model For Odia Language}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={The AI community is experiencing a profound impact from Large Language Models (LLMs), and the introduction of ChatGPT and GPT-4 is prompting a reconsideration of the potential of artificial general intelligence(AGI). However, most of the LLMs are trained in English and other high-resource languages, resulting in the unavailability of LLM and its related technologies and services for many low-resource languages. In India, where only 10% of the population is proficient in English, the need for LLM models adapted to regional languages becomes crucial.In this paper, we emphasized the need for LLM for the low-resource Odia language by evaluating the available LLM-supporting Odia language. We describe the development process of the instruction-tuning LLM model for Odia. The developed instruction tuning Odia LLM is available freely for research and non-commercial purposes.},
  keywords={Adaptation models;Instruction sets;Chatbots;Data models;Statistics;Tuning;Context modeling;Generative AI;LLM;Fine-Tuning},
  doi={10.1109/SILCON59133.2023.10404195},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10127706,
  author={Rasyad, Farrel and Kongguasa, Hardi Andry and Onggususilo, Nicholas Christandy and Anderies and Kurniawan, Afdhal and Gunawan, Alexander Agung Santoso},
  booktitle={2023 International Conference on Computer Science, Information Technology and Engineering (ICCoSITE)}, 
  title={A Systematic Literature Review of Generative Adversarial Network Potential In AI Artwork}, 
  year={2023},
  volume={},
  number={},
  pages={853-857},
  abstract={Humans have studied calligraphy and calculated programs to foster creativity for years. Image generation technology using artificial intelligence and Generative Adversarial Networks is currently reaching the peak of its performance. While there are newer and newer algorithms to improve the image generation system, the output of the images is still suitable at best and only excels in their category. While it is true that some of the images generated are good enough to be used, it is still unclear whether the capabilities of AI image generation can outperform their creative human counterparts. Therefore, this literature study aims to explore the basics of AI image generation, how they work, and what factors contribute to creating art such as simple pictures. Previous studies from several years ago show that most generated images are not good enough for creative usage because they only replicate traces of their dataset. The most significant factor contributing to this is the algorithm used and how it is used to create new images. In general, the concluded that while current AI-generated images are improving, they are still not creative enough to replace human creativity.},
  keywords={Training;Industries;Systematics;Image synthesis;Computational modeling;Production;Generative adversarial networks;AI;Art;Creativity;GAN;Image},
  doi={10.1109/ICCoSITE57641.2023.10127706},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{9408757,
  author={Wang, Ding and Zhou, Yongbin and Chen, Jianyun and Zhang, Chao},
  booktitle={2021 6th International Conference on Intelligent Computing and Signal Processing (ICSP)}, 
  title={Research on Spectrum Intelligent Recognition Technology Based on an Edge Processing Framework KubeEdge}, 
  year={2021},
  volume={},
  number={},
  pages={847-850},
  abstract={In recent years, artificial intelligence technology has developed rapidly, spectrum recognition presents the characteristics of intelligence. However, with the increase of the amount of radio spectrum data, problems such as the large amount of computation of artificial intelligence algorithm and the shortage of storage and computing resources of spectrum recognition terminal become more and more prominent, resulting in low efficiency of spectrum recognition. Combined with edge computing technology, an spectrum intelligent recognition framework based on edge processing framework KubeEdge is proposed in this paper. The architecture uses KubeEdge framework to co-manage cloud server and edge spectrum recognition node. The training of spectrum intelligent recognition algorithm is realized in the cloud, and the spectrum of input signals is recognized and classified at the edge node, so as to achieve the purpose of cloud and edge collaborative recognition and improve the efficiency of spectrum recognition.},
  keywords={Training;Signal processing algorithms;Collaboration;Computer architecture;Signal processing;Sensors;Servers;Edge computing;KubeEdge;Spectrum recognition;Artificial intelligence},
  doi={10.1109/ICSP51882.2021.9408757},
  ISSN={},
  month={April},}
