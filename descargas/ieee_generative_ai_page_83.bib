@INPROCEEDINGS{10698645,
  author={Oh, Ju-Yeon and Park, Ga-Eun and Cho, Su-Bin and Bae, Seong-Geon},
  booktitle={2024 International Conference on Electrical, Computer and Energy Technologies (ICECET}, 
  title={A Study on Performance Improvement of CartoonGAN through Reflective Object Removal for Comparative Analysis of Content Loss}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Due to the development of generative artificial intelligence and various application possibilities, life can be changed more productively and creatively by supplementing human labor. CartoonGAN can reduce labor and costs through image generation by transferring an artist's cartoon style. In this process, a limitation of the generated image occurs according to the light of the input image. In order to create a more unique artist's style, the reflection of light in the input image must be controlled, and research that maintains detailed information should be conducted. Therefore, in this study, we aim to improve the performance of cartoon image generation by proposing algorithms for improving resolution and controlling the reflection of light.},
  keywords={Image quality;Visualization;Image resolution;Image synthesis;Image color analysis;Generative adversarial networks;Reflection;Colored noise;Usability;Structural shapes;CartoonGAN;BSRGAN;Image Processing;Style Transfer;Computer Vision},
  doi={10.1109/ICECET61485.2024.10698645},
  ISSN={},
  month={July},}@INPROCEEDINGS{9434078,
  author={Ke, Jing and Shen, Yiqing and Lu, Yizhou},
  booktitle={2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)}, 
  title={Style Normalization In Histology With Federated Learning}, 
  year={2021},
  volume={},
  number={},
  pages={953-956},
  abstract={The global cancer burden is on the rise, and Artificial Intelligence (AI) has become increasingly crucial to achieve more objective and efficient diagnosis in digital pathology. Current AI-assisted histopathology analysis methods need to address the following two issues. First, the color variations due to use of different stains need to be tackled such as with stain style transfer technique. Second, in parallel with heterogeneity, datasets from individual clinical institutions are characterized by privacy regulations, and thus need to be addressed such as with robust data-private collaborative training. In this paper, to address the color heterogeneity problem, we propose a novel generative adversarial network with one orchestrating generator and multiple distributed discriminators for stain style transfer. We also incorporate Federated Learning (FL) to further preserve data privacy and security from multiple data centers. We use a large cohort of histopathology datasets as a case study.},
  keywords={Training;Data privacy;Interpolation;Histopathology;Image color analysis;Collaborative work;Regulation;Histopathology;Color Normalization;Generative Adversarial Network;Federated Learning},
  doi={10.1109/ISBI48211.2021.9434078},
  ISSN={1945-8452},
  month={April},}@INPROCEEDINGS{10717261,
  author={Malleswari, G. and Reddy, A. Srinivasa and Raja, R.},
  booktitle={2024 10th International Conference on Advanced Computing and Communication Systems (ICACCS)}, 
  title={Employing Deep Learning Approaches to Detect Deepfake Attributes in Videos}, 
  year={2024},
  volume={1},
  number={},
  pages={929-933},
  abstract={The combination of “fake” and deep learning techniques is known as deepfake technology. Deepfakes are created and detected using deep learning, a form of artificial intelligence. Generative adversarial networks, which are made up of two machine learning models cooperating, are used to create these deepfakes. People may grow less and less inclined to believe content that is genuine as long as deepfake photos and videos keep appearing on social media. Deepfake detection techniques are designed to discriminate between real and fake photos and videos on social media. These techniques rely on training the detection models using datasets that contain both genuine and fraudulent images or videos, highlighting the need for high-quality and diverse data for effective detection. In this research, we initially delve into the realm of deepfake technology and the associated challenges. Subsequently, we identify accessible video datasets. Following that, we employ long short-term memory for learning sequences and utilize convolutional neural networks for classifying eye states. Additionally, we leverage the eye aspect ratio to identify blinking intervals and compute the dimensions of closed and open eyes.},
  keywords={Deep learning;Training;Deepfakes;Social networking (online);Reviews;Neural networks;Hate speech;Production;Sparks;Long short term memory;Deepfake images;Generative adversarial networks;deep learning;machine learning;convolutional neural networks},
  doi={10.1109/ICACCS60874.2024.10717261},
  ISSN={2575-7288},
  month={March},}@INPROCEEDINGS{10183482,
  author={Khan, Leah Pathan and Gupta, Vibhu and Bedi, Srishty and Singhal, Abhishek},
  booktitle={2023 International Conference on Computational Intelligence and Sustainable Engineering Solutions (CISES)}, 
  title={StoryGenAI: An Automatic Genre-Keyword Based Story Generation}, 
  year={2023},
  volume={},
  number={},
  pages={955-960},
  abstract={Story Generation through Deep Learning is a fascinating area of research in Artificial Intelligence that aims to create computer systems that can produce original and compelling narratives and is an interesting concept that has flourished in the domain of Machine Learning applications starting from 2018. Most of the research carried out in this specific area has shown advances in Modelling and efficiency of story generation. However, some of the setbacks in Artificial Story Generation include little to no coherency with human generating pattern, tokens/words limitation, missing plot twists and direction of story. In this paper, we have performed a comparative study on Automatic Story Generation as well as the proposed scheme of this paper has main focus on generating a meaningful story with the help of conditional text generation using keywords upto five hundred words by optimizing hugging face generative pre trained model Version Two catering towards the problem of coherency in the text generated. As a result each sentence is semantically coherent and the first three sentences are indeed related to the title itself. The experimental results show a BLEU score of 0.704 averaging over ten genres.},
  keywords={Deep learning;Computational modeling;Faces;Computational intelligence;Automatic Story Generation;Natural Language Processing;Natural Language Generation;Comparative Study;GPT-2},
  doi={10.1109/CISES58720.2023.10183482},
  ISSN={},
  month={April},}@ARTICLE{9606581,
  author={Li, Xuelong and Zhang, Hongyuan and Zhang, Rui},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Adaptive Graph Auto-Encoder for General Data Clustering}, 
  year={2022},
  volume={44},
  number={12},
  pages={9725-9732},
  abstract={Graph-based clustering plays an important role in the clustering area. Recent studies about graph neural networks (GNN) have achieved impressive success on graph-type data. However, in general clustering tasks, the graph structure of data does not exist such that GNN can not be applied to clustering directly and the strategy to construct a graph is crucial for performance. Therefore, how to extend GNN into general clustering tasks is an attractive problem. In this paper, we propose a graph auto-encoder for general data clustering, AdaGAE, which constructs the graph adaptively according to the generative perspective of graphs. The adaptive process is designed to induce the model to exploit the high-level information behind data and utilize the non-euclidean structure sufficiently. Importantly, we find that the simple update of the graph will result in severe degeneration, which can be concluded as better reconstruction means worse update. We provide rigorous analysis theoretically and empirically. Then we further design a novel mechanism to avoid the collapse. Via extending the generative graph models to general type data, a graph auto-encoder with a novel decoder is devised and the weighted graphs can be also applied to GNN. AdaGAE performs well and stably in different scale and type datasets. Besides, it is insensitive to the initialization of parameters and requires no pretraining.},
  keywords={Neural networks;Convolution;Adaptation models;Decoding;Data models;Task analysis;Clustering methods;General data clustering;graph auto-encoder;scalable methods},
  doi={10.1109/TPAMI.2021.3125687},
  ISSN={1939-3539},
  month={Dec},}@ARTICLE{10577097,
  author={Chai, Haoye and Wang, Huandong and Li, Tong and Wang, Zhaocheng},
  journal={IEEE Network}, 
  title={Generative AI-Driven Digital Twin for Mobile Networks}, 
  year={2024},
  volume={38},
  number={5},
  pages={84-92},
  abstract={The sixth generation mobile network (6G) is evolving to provide ubiquitous connections, multidimensional perception, native intelligence, global coverage, etc., which poses intense demands for network design to tackle the highly dynamic context and diverse service requirements. Digital Twin (DT) is envisioned as an efficient method for designing 6G that migrates the behaviors of physical nodes to the virtual space. However, in the high-dynamic 6G network, there still exist challenges in achieving accuracy and flexibility when constructing DT. In this article, we propose a Generative Artificial Intelligence (GAI)-driven mobile network digital twin paradigm, where the GAI is utilized as a key enabler to generate DT data. Specifically, GAI is capable of implicitly learning the complex distribution of network data, allowing it to sample from the distribution and obtain high-fidelity data. In addition, the construction of DT is closely related to various types of data, such as environmental, user, and service data. GAI can utilize these data as conditions to control the generation process under different scenarios, thereby enhancing flexibility. In practice, we develop a network digital twin prototype system to accurately model the behaviors of mobile network elements ( $i.e$ ., mobile users, base stations, and wireless environments) and to evaluate network performance. Evaluation results demonstrate that the proposed prototype system can generate high-fidelity DT data and provide practical network optimization solutions.},
  keywords={Optimization;6G mobile communication;Digital twins;Wireless communication;Generative AI;Protocols;Optimization models;Ubiquitous computing;Telecommunication network performance;Network digital twin;generative AI;network optimization},
  doi={10.1109/MNET.2024.3420702},
  ISSN={1558-156X},
  month={Sep.},}@INPROCEEDINGS{9045206,
  author={Song, Linghao and Chen, Fan and Chen, Yiran and Li, Hai},
  booktitle={2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC)}, 
  title={Parallelism in Deep Learning Accelerators}, 
  year={2020},
  volume={},
  number={},
  pages={645-650},
  abstract={Deep learning is the core of artificial intelligence and it achieves state-of-the-art in a wide range of applications. The intensity of computation and data in deep learning processing poses significant challenges to the conventional computing platforms. Thus, specialized accelerator architectures are proposed for the acceleration of deep learning. In this paper, we classify the design space of current deep learning accelerators into three levels, (1) processing engine, (2) memory and (3) accelerator, and present a constructive view from a perspective of parallelism in the three levels.},
  keywords={Engines;Parallel processing;Training;Deep learning;Generative adversarial networks;Pipelines;Generators},
  doi={10.1109/ASP-DAC47756.2020.9045206},
  ISSN={2153-697X},
  month={Jan},}@ARTICLE{11045408,
  author={Zhou, Ting-Wei and Zhao, Xi-Le and Wang, Jian-Li and Luo, Yi-Si and Wang, Min and Bai, Xiao-Xuan and Yan, Hong},
  journal={IEEE Transactions on Multimedia}, 
  title={DTR: A Unified Deep Tensor Representation Framework for Multimedia Data Recovery}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={Recently, the transform-based tensor representation has attracted increasing attention in multimedia data (e.g., images and videos) recovery problems, which consists of two indispensable components, i.e., the transform and the characterization. Previously, the development of transform-based tensor representation has focused mainly on the transform perspective. Although several attempts have considered shallow matrix factorization (e.g., singular value decomposition and nonnegative matrix factorization) for characterizing the frontal slices of the transformed tensor (termed the latent tensor), the faithful characterization perspective has been underexplored. To address this issue, we propose a unified Deep Tensor Representation (DTR) framework by synergistically combining the deep latent generative module and the deep transform module. Especially, the deep latent generative module can faithfully generate the latent tensor as compared with shallow matrix factorization. The new DTR framework not only allows us to better understand the classical shallow representations but also leads us to explore new representations. To examine the representation capability of the proposed DTR, we consider the representative multidimensional data recovery task and suggest an unsupervised DTR-based multidimensional data recovery model. Extensive experiments demonstrate that DTR achieves superior performance compared to the state-of-the-art methods from both quantitative and qualitative aspects, especially for fine detail recovery.},
  keywords={Tensors;Transforms;Matrix decomposition;Discrete Fourier transforms;Generators;Data models;Symbols;Streaming media;Singular value decomposition;Noise;Deep tensor representation;deep latent generative module;deep transform module},
  doi={10.1109/TMM.2025.3581777},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{10392649,
  author={Chen, Kexin},
  booktitle={2023 IEEE 6th International Conference on Information Systems and Computer Aided Education (ICISCAE)}, 
  title={Research on Popular Machine Learning Algorithms}, 
  year={2023},
  volume={},
  number={},
  pages={14-21},
  abstract={Artificial Intelligence technologies have been developed rapidly in the past 20 years and have been widely applied in various industries. Machine Learning, as the most important way to achieve artificial intelligence, is evolving at a huge speed. Keeping track of the regular development is quite a difficult work, especially for beginners. In this paper, we are going to briefly discuss about the most popular machine learning algorithms and their variants or improved versions. These algorithms are usually classified as supervised learning or unsupervised learning methods, or other grouping methods based on functionality. Deep Learning is covered because deep learning methods have led to revolutionary progress in computer vision and machine learning. We also talk about the industries that these models can be applied in. This article is intend to provide basic references of these commonly used algorithms in the field for beginners, help them to get a general understanding of the algorithms and the scenarios, and guide to select appropriate algorithm or model to start solving a practical data problem.},
  keywords={Support vector machines;Industries;Logistic regression;Machine learning algorithms;Computational modeling;Clustering algorithms;Classification algorithms;Machine Learning;Algorithm;Deep Learning;Artificial Neural Network},
  doi={10.1109/ICISCAE59047.2023.10392649},
  ISSN={2770-663X},
  month={Sep.},}@ARTICLE{10606337,
  author={Han, Pengchao and Shi, Xingyan and Huang, Jianwei},
  journal={IEEE Journal on Selected Areas in Communications}, 
  title={FedAL: Black-Box Federated Knowledge Distillation Enabled by Adversarial Learning}, 
  year={2024},
  volume={42},
  number={11},
  pages={3064-3077},
  abstract={Knowledge distillation (KD) can enable collaborative learning among distributed clients that have different model architectures and do not share their local data and model parameters with others. Each client updates its local model using the average model output/feature of all client models as the target, known as federated KD. However, existing federated KD methods often do not perform well when clients’ local models are trained with heterogeneous local datasets. In this paper, we propose Federated knowledge distillation enabled by Adversarial Learning (FedAL) to address the data heterogeneity among clients. First, to alleviate the local model output divergence across clients caused by data heterogeneity, the server acts as a discriminator to guide clients’ local model training to achieve consensus model outputs among clients through a min-max game between clients and the discriminator. Moreover, catastrophic forgetting may happen during the clients’ local training and global knowledge transfer due to clients’ heterogeneous local data. Towards this challenge, we design the less-forgetting regularization for both local training and global knowledge transfer to guarantee clients’ ability to transfer/learn knowledge to/from others. Experimental results show that FedAL and its variants achieve higher accuracy than other federated KD baselines.},
  keywords={Data models;Training;Servers;Knowledge transfer;Accuracy;Federated learning;Closed box;Knowledge distillation;black-box model;heterogeneity;adversarial learning;less-forgetting},
  doi={10.1109/JSAC.2024.3431516},
  ISSN={1558-0008},
  month={Nov},}@ARTICLE{10044681,
  author={An, Yongli and Wang, Shaomeng and Zhao, Li and Ji, Zhanlin and Ganchev, Ivan},
  journal={IEEE Access}, 
  title={A Learning-Based End-to-End Wireless Communication System Utilizing a Deep Neural Network Channel Module}, 
  year={2023},
  volume={11},
  number={},
  pages={17441-17453},
  abstract={The existing end-to-end (E2E) wireless communication systems require fewer communication modules and have a simple processing signal flow, compared to conventional wireless communication systems. However, in the absence of a differentiable channel model, it is impossible to train transmitters, used in such systems, which makes impossible achieving optimal system performance. To solve this problem, E2E wireless communication systems, learned with conditional generative adversarial networks (CGANs) for channel modeling, have been proposed recently. Unfortunately, the CGAN training is prone to instability, slow convergence, and inaccurate channel modeling, which affects the system performance. To this end, a learning-based E2E wireless communication system, utilizing a deep neural network (DNN) channel module to model an unknown channel, is proposed in this paper. Simulation results show that the proposed DNN channel modeling has faster convergence, simpler network structure, and can reflect the behavior of real channels more accurately. In addition, the proposed learning-based E2E wireless communication system performs better, in terms of the bit error rate (BER) and block error rate (BLER), than the learning-based E2E wireless communication system, using CGAN as unknown channel, and a traditional communication system, designed based on the prior knowledge of the channel. Compared to these two systems, at high signal-to-noise ratio (SNR) values, the proposed system can achieve a SNR gain of at least 2 dB, in communication scenarios involving frequency-selective multi-path channels.},
  keywords={Wireless communication;Transmitters;Receivers;Channel models;Deep learning;Bit error rate;Encoding;Deep learning;Neural networks;End-to-end wireless communication system;autoencoder;deep learning;deep neural network (DNN)},
  doi={10.1109/ACCESS.2023.3245330},
  ISSN={2169-3536},
  month={},}@ARTICLE{10400952,
  author={Wang, Tianyi and Li, Zian and Liu, Ruixia and Wang, Yinglong and Nie, Liqiang},
  journal={IEEE Transactions on Multimedia}, 
  title={An Efficient Attribute-Preserving Framework for Face Swapping}, 
  year={2024},
  volume={26},
  number={},
  pages={6554-6565},
  abstract={By leveraging deep neural networks, recent face swapping techniques have performed admirably in generating faces that maintain consistent identities. Nevertheless, while these methods accurately transfer source identities, they often struggle to preserve important attributes (such as head poses, expressions, and gaze directions) in the target faces. As a consequence, the current research in this domain has not resulted in satisfactory performance. In this article, we propose an efficient attribute-preserving framework, called AP-Swap, for short, for face swapping. Our approach incorporates two innovative modules designed specifically to preserve critical facial attributes. First, we propose a global residual attribute-preserving encoder (GRAPE), which adaptively extracts globally complete attribute features from target faces. Second, in addition to the regular network streams for the source and target facial images, we introduce a network stream that takes into account the facial landmarks of the target faces. This additional stream enables our landmark-guided feature entanglement module (LFEM), which efficiently preserves fine-grained facial attributes by conducting a landmark-based attribute-preserving (LBAP) operation. Through extensive quantitative and qualitative experiments, we demonstrate the superiority of AP-Swap over other state-of-the-art methods in terms of facial attribute preservation and model efficiency, along with satisfactory identity consistency performance.},
  keywords={Faces;Feature extraction;Face recognition;Pipelines;Facial features;Task analysis;Streams;Face swapping;attribute preservation;facial landmarks;generative adversarial network},
  doi={10.1109/TMM.2024.3354573},
  ISSN={1941-0077},
  month={},}@ARTICLE{10113320,
  author={Ditthapron, Apiwat and Lammert, Adam C. and Agu, Emmanuel O.},
  journal={IEEE Access}, 
  title={ADL-GAN: Data Augmentation to Improve In-the-Wild ADL Recognition Using GANs}, 
  year={2023},
  volume={11},
  number={},
  pages={50671-50688},
  abstract={The types of Activities of Daily Living (ADL) a person performs or avoids, and underlying patterns can provide insights into physical and mental health, making passive ADL recognition from smartphone sensor data important. However, as people perform ADLs unequally in real life, ADL datasets collected in the wild can be extremely imbalanced, which presents a challenge to Machine Learning (ML) ADL classification. Prior solutions to mitigating imbalance, such as oversampling and instance weighting, reduce but do not completely eliminate the problem. We instead propose ADL-GAN, which utilizes translation Generative Adversarial Networks (GANs), to synthesize smartphone motion and audio sensor data to improve ADL classification performance. ADL-GANs augment the minority ADL of subject  $A$  by translating real samples from either 1) other ADLs where subject  $A$  has adequate data in Context-transfer ADL-GAN or 2) other subjects with adequate ADL data in Subject-transfer ADL-GAN. ADL-GANs utilize multi-domain and contrastive loss functions to perform many-to-many translations between ADL classes and subjects, respectively. Subject-transfer ADL-GAN outperformed baselines and improved balanced accuracy (BA) on an in-the-wild ADL dataset by 27.9 %, while context-transfer ADL-GAN performed best on a scripted dataset, improving the BA of baselines by 9.58 %. The augmented samples from ADL-GANs were shown to be more realistic and diverse than conditional GAN.},
  keywords={Generative adversarial networks;Training;Legged locomotion;Generators;Task analysis;Smart phones;Sensors;Data augmentation;Activity of daily living;imbalanced class;GAN;data augmentation;smartphones},
  doi={10.1109/ACCESS.2023.3271409},
  ISSN={2169-3536},
  month={},}@ARTICLE{10646204,
  author={Farea, Ali Hamid and Alhazmi, Omar H. and Samet, Refik and Guzel, Mehmet Serdar},
  journal={IEEE Access}, 
  title={AI-Powered Integrated With Encoding Mechanism Enhancing Privacy, Security, and Performance for IoT Ecosystem}, 
  year={2024},
  volume={12},
  number={},
  pages={121368-121386},
  abstract={The Internet of Things (IoT) ecosystem presents substantial challenges in terms of privacy and security, rendering it an attractive target for malicious actors. In this context, the literature review highlights the ongoing difficulty in addressing privacy and security through a unified mechanism owing to the heterogeneous nature of IoT devices, their dynamic behavior, and the continual advancement of intelligent hacking tools. Hence, encoding techniques have been considered from the perspective of privacy in Artificial Intelligence (AI) models. To overcome these challenges, this study introduces an integrated single mechanism for privacy and security in the IoT. In order to safeguard sensitive data during AI model training, a novel privacy mechanism called Replacement Encoding (RE) is proposed. This mechanism ensures the camouflage of sensitive information while preserving the integrity and utility of trained models. Additionally, this approach provides automated preprocessing, enhancing the performance of AI models. Message packet features were derived, extracted, and analyzed from the CICIoT2023 dataset (PCAP files) using Wireshark. The proposed replacement encoding scheme is integrated with AI classifiers to detect attacks, achieving an accuracy of 88.94% and 86.61% for the Random Forest (RF) and Deep Neural Network (DNN) models, respectively, utilizing 100 features. These results are compared to accuracies of 90.16% and 94.81% for the same models with up to 15 features using genetic algorithm-based correlation features. Finally, the proposed RF mechanism demonstrates its utility across multiple domains, including privacy preservation, automated data preprocessing, and protection of sensitive user data in Generative Pre-Training Transformer (GPT) applications as well as AI models.},
  keywords={Encoding;Artificial intelligence;Security;Internet of Things;Data privacy;Privacy;Data models;AI;encoding;IoT;privacy;optimization;security},
  doi={10.1109/ACCESS.2024.3449630},
  ISSN={2169-3536},
  month={},}@ARTICLE{10942376,
  author={Alafif, Tarik and Jassas, Mohammad and Abdel-Hakim, Alaa E. and Alfattni, Ghada and Althobaiti, Hassan and Ikram, Mohammed and Alharbi, Amirah and Alsharif, Hussam and AlShamrani, Mazin and Alharbi, Ebtisam and Alsubait, Tahani and Alhawsawi, Abdullah and Alsolami, Badr and Khayyat, Khalid},
  journal={IEEE Access}, 
  title={Toward an Integrated Intelligent Framework for Crowd Control and Management (IICCM)}, 
  year={2025},
  volume={13},
  number={},
  pages={58559-58575},
  abstract={Managing large-scale gatherings, such as global festivals, sporting events, and religious congregations, presents substantial challenges in ensuring crowd safety and control. Innovative frameworks are essential to address these complexities effectively. The Integrated Intelligent Crowd Control and Management (IICCM) framework combines cutting-edge technologies, including Computer Vision (CV), Artificial Intelligence (AI), and the Internet of Things (IoT), to enhance participant safety and optimize crowd management. CV enables precise real time identification and tracking, AI analyzes crowd behavior to anticipate risks, and IoT gathers environmental data to improve crowd flow, alleviate congestion, and provide timely assistance. Additionally, the framework facilitates emergency evacuation planning by modeling crowd dynamics and identifying safe, efficient escape routes. Although suitable for diverse events, the Hajj pilgrimage—a uniquely large and dynamic annual gathering—provides a rigorous test case for the IICCM framework. Managing millions of participants from varied cultural and linguistic backgrounds highlights the system’s adaptability and robustness. By effectively addressing Hajj specific challenges, the IICCM framework demonstrates its scalability and applicability to other large-scale events. This research offers valuable insights for decision-makers seeking to implement advanced crowd management technologies.},
  keywords={Internet of Things;Medical services;Estimation;Convolutional neural networks;Cloud computing;Accuracy;Real-time systems;Faces;Streaming media;Scalability;Crowd management;large-scale gatherings;artificial intelligence;computer vision;Internet of Things;emergency evacuation;crowd health;Hajj},
  doi={10.1109/ACCESS.2025.3555154},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10027763,
  author={Duong, Bao and Nguyen, Thin},
  booktitle={2022 IEEE International Conference on Data Mining (ICDM)}, 
  title={Conditional Independence Testing via Latent Representation Learning}, 
  year={2022},
  volume={},
  number={},
  pages={121-130},
  abstract={Detecting conditional independencies plays a key role in several statistical and machine learning tasks, especially in causal discovery algorithms, yet it remains a highly challenging problem due to dimensionality and complex relationships presented in data. In this study, we introduce LCIT (Latent representation based Conditional Independence Test) -a novel method for conditional independence testing based on representation learning. Our main contribution involves a hypothesis testing framework in which to test for the independence between X and Y given Z, we first learn to infer the latent representations of target variables X and Y that contain no information about the conditioning variable Z. The latent variables are then investigated for any significant remaining dependencies, which can be performed using a conventional correlation test. The empirical evaluations show that LCIT outperforms several state-of-the-art baselines consistently under different evaluation metrics, and is able to adapt really well to both non-linear and high-dimensional settings on a diverse collection of synthetic and real data sets.},
  keywords={Representation learning;Measurement;Adaptation models;Machine learning algorithms;Correlation;Data models;Data mining;conditional independence;hypothesis testing;representation learning;generative models;normalizing flows},
  doi={10.1109/ICDM54844.2022.00022},
  ISSN={2374-8486},
  month={Nov},}@INPROCEEDINGS{10661000,
  author={Taqi, Makki and Ram, Pintu Kumar},
  booktitle={2024 5th International Conference on Image Processing and Capsule Networks (ICIPCN)}, 
  title={Synthesizing MRIs From CT Scans Using Deep Learning Techniques: A Comprehensive Review}, 
  year={2024},
  volume={},
  number={},
  pages={189-197},
  abstract={Computed Tomography (CT) and Magnetic Resonance Imaging (MRI) are useful imaging techniques used in clinical practice. While CT scans offer advantages in imaging speed, cost, and patient comfort compared to MRI, MRI provides superior image detail in soft tissue structures. This review investigates the application of deep learning algorithms to address this gap by converting CT scans into MRI representations. Research papers focusing on this conversion process were analyzed. The analysis reveals that supervised learning outperforms unsupervised methods in generating realistic images. However, supervised learning struggles with a lack of paired CT-MRI datasets, hindering its effectiveness. Conversely, unsupervised learning offers a solution by generating synthetic paired datasets that can be used for supervised learning to produce high-quality synthetic MRIs. Finally, this review highlights the need for increased availability of paired datasets to further improve MRI synthesis outcomes.},
  keywords={Deep learning;Training;Systematics;Reviews;Magnetic resonance imaging;Computed tomography;Supervised learning;Computed Tomography (CT);Magnetic Resonance Imaging (MRI);synthesis;Generative Adversarial Networks (GANs);Convolutional Neural Networks (CNNs);deep learning algorithms},
  doi={10.1109/ICIPCN63822.2024.00039},
  ISSN={},
  month={July},}@INPROCEEDINGS{10725408,
  author={Simran, T and Geetha, J},
  booktitle={2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Enhancing Graph Database Interaction through Generative AI-Driven Natural Language Interface for Financial Fraud Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={The rapid evolution of financial services has led to an increase in fraudulent activities, necessitating advanced detection methods. Traditional techniques often struggle with the volume and complexity of financial transactions, leading to inaccuracies and delays. This research addresses the enhancement of graph database interaction through a generative AI-driven natural language interface for more accurate fraud detection. We employ the T5 and LLaMA-2 models, trained on a balanced dataset of financial transactions, to recognize fraud patterns. The $\mathbf{T 5}$ model handles natural language queries, extracting key details such as transaction amounts and account numbers. The LLaMA-2 model generates predictions on the likelihood of transactions being fraudulent. The system then converts these processed queries into Cypher queries for the Neo4j graph database to retrieve relevant transaction data. This approach enables efficient pattern analysis and interactive data exploration. Experimental results demonstrate that our system accurately identifies fraudulent transactions, significantly reducing the time and expertise needed for detection. This approach makes use of Neo4j’s powerful features to increase the efficacy and precision of financial detection systems for fraud.},
  keywords={Databases;Computational modeling;Natural languages;Finance;Predictive models;Feature extraction;Fraud;Pattern recognition;Pattern analysis;Financial services;Financial Fraud Detection;Graph Databases;Generative AI;LLaMA-2 Model;T5 Model;Neo4j;Natural Language Interface},
  doi={10.1109/ICCCNT61001.2024.10725408},
  ISSN={2473-7674},
  month={June},}@INPROCEEDINGS{10698306,
  author={Shruti, Ishika and Kumar, Amol and Seth, Arjun and N, Rajeev Ranjan},
  booktitle={2024 International Conference on Electrical, Computer and Energy Technologies (ICECET}, 
  title={Responsible Generative AI: A Comprehensive Study to Explain LLMs}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={With the emerging significance of Generative Al solutions today in real-world business problems, the adoption of Large Language Models (LLMs) has been observed widely Large Language Models (LLMs), LLMs are a subset of language models trained on extensive text and code datasets, enabling them to generate a lead, perform language translation, create diverse content, provide informative answers, and serve other critical functions. However, LLMs are often seen as black boxes, because it is difficult to understand how they work internally. This is because LLMs are Engineered using complex machine learning and deep learning algorithms, which can be difficult to interpret. This paper provides a comprehensive study of three methodologies that are used to explain LLMs, using a unique solution architecture that gives better results as compared to the conventional methodologies that are used for the same.},
  keywords={Deep learning;Ethics;Electric potential;Machine learning algorithms;Large language models;Decision making;Computer architecture;Organizations;Regulation;Monitoring;LLMs;Explainability;Interpretability;Responsible Generative AI;Compliance Monitoring and Risk Assessment;LIME;SHAP and BertViz},
  doi={10.1109/ICECET61485.2024.10698306},
  ISSN={},
  month={July},}@ARTICLE{10660589,
  author={Shan, Richard},
  journal={Computer}, 
  title={Certifying Generative AI: Retrieval-Augmented Generation Chatbots in High-Stakes Environments}, 
  year={2024},
  volume={57},
  number={9},
  pages={35-44},
  abstract={This article emphasizes the urgent need for certifying RAG GenAI chatbots in mission-critical systems, focused on data integrity and model reliability, with a comprehensive framework of technical, ethical, and operational assessments, which demonstrate its necessity through real-world implementations, advocating for continuous innovation and adaptable regulations.},
  keywords={Technological innovation;Ethics;Generative AI;Data integrity;Computational modeling;Mission critical systems;Chatbots},
  doi={10.1109/MC.2024.3401085},
  ISSN={1558-0814},
  month={Sep.},}@INPROCEEDINGS{11020445,
  author={Sarkar, Swagata and S, Robin and R, Gokulrajan and M, Jitheshvar and Kudiyarasu, Jeshvan},
  booktitle={2025 International Conference on Computing and Communication Technologies (ICCCT)}, 
  title={Generative AI for Personalized Learning Experiences in Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-15},
  abstract={When AI is used in schools, it should help kids to learn more. Individualized learning is an idea that has been around for a while, but you could not use it until not long ago. This research shows easy, cheap, and long-lasting ways to make learning tools. The teacher's learning goals for that class were used to make our tool. This tool can be used with a learning management system already set up at an engineering college. The lesson plans had three styles. For every question, there was more than one short answer and choice. There are three ways to get each lesson. Twenty software engineering students from a well-known European school helped test it in a small way. You can make this tool with a big language model and an application programming interface (API). All the participants participated in their own wish. These things were given to everyone in the class twice. They made a list of the things they used. They also cared about what people saw, thought, and felt, and they cared about these things over time. At school, it was also more important. People paid the most attention to the tests made immediately and looked like quizzes. Because it only looked at twenty kids, the study couldn't say what its results mean for all of them. The activation level for all tests was set to 0.5, and they were all done on the testing dataset.},
  keywords={Deep learning;Measurement;Learning management systems;Generative AI;Education;Market research;Data models;Application programming interfaces;Testing;Software engineering;Education across Lifespan;Input and Content Personalization Process;AI-generated outputs;Data Collection;Metrics},
  doi={10.1109/ICCCT63501.2025.11020445},
  ISSN={2995-3197},
  month={April},}@INBOOK{10880606,
  author={Shukla, Kirti and Kumar, Pramod and Soni, Mukesh and Byeon, Haewon and Pande, Sagar Dhanraj and Keshta, Ismail},
  booktitle={Generative Artificial Intelligence for Biomedical and Smart Health Informatics}, 
  title={GAI and Deep Learning&#x2010;Based Medical Sensor Data Relationship Model for Health Informatics}, 
  year={2025},
  volume={},
  number={},
  pages={375-400},
  abstract={Summary <p>Disease diagnosis is a hot research area in Health Informatics (Healthcare) record data mining and an important step towards achieving generative intelligence (GAI) medical diagnosis. However, health perception data in Healthcare records come from diverse sources, with complex data structures and potential correlations between different types of data over wireless medical sensor networks. There is a challenge in how to integrate heterogeneous data during feature extraction and mining analysis. Only through comprehensive consideration of medical sensing data, personal constitution records, and inter&#x2010;disease relationship data can relevant hidden features be mined to achieve more accurate diagnoses of various disease categories over wireless medical sensor networks. Therefore, based on the fusion of dynamic and static relationships in multisource health perception data, the disease diagnosis model (DSRF) first solves the heterogeneity problem of dynamic medical sensing data and static constitution records through a dynamic&#x2013;static relationships fusion algorithm to explore their correlations. Then, it calculates the correlation matrix of multicategory diseases to extract inter&#x2010;disease dependency relationships. Finally, based on the architecture of gated recurrent unit networks, it integrates various health perception data to accomplish a comprehensive analysis of multisource heterogeneous data. Experimental results on the MIMIC&#x2010;III clinical dataset in the United States demonstrate that compared to mainstream models of the same type, this model can more accurately diagnose multiple disease categories jointly.</p>},
  keywords={Medical diagnosis;Medical diagnostic imaging;Sensors;Hypertension;Bioinformatics;Time series analysis;Pulmonary diseases;Mortality;Diabetes;Data models},
  doi={10.1002/9781394280735.ch19},
  ISSN={},
  publisher={IEEE},
  isbn={9781394280728},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10880606},}@INPROCEEDINGS{9949108,
  author={Duan, Haihan and Wu, Xiao and Cai, Wei},
  booktitle={2022 IEEE 24th International Workshop on Multimedia Signal Processing (MMSP)}, 
  title={Crypto-Dropout: To Create Unique User-Generated Content Using Crypto Information in Metaverse}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={In a blockchain-driven metaverse, user-generated content (UGC) is the core power for building the metaverse, so an easy-to-use UGC editor is imperative. Specifically, using artificial intelligence (AI) to simplify the UGC creation procedure is promising, e.g., generating images from sketches using generative adversarial networks (GANs). However, the simplicity of these UGC creation methods would lead to weak distinctions between the generated UGC, since the users' created drafts may be very similar. In this paper, we propose Crypto-dropout, a specially designed dropout used in the generative neural networks, which could cause pseudo-random disturbance based on the hash value of user information to generate unique results. With a pilot study, the experimental results demonstrate that the participants have different preferences for the generated images when setting Crypto-dropout in the different layers. Accordingly, we implement a practical profile pictures (PFPs) creation prototype. The proposed Crypto-dropout can provide a novel and general insight for creating unique UGC using generative neural networks.},
  keywords={Hash functions;Three-dimensional displays;Metaverse;Neural networks;User-generated content;Prototypes;Signal processing;User-Generated Content;Metaverse;Dropout;Human-centered Computing;Non-fungible Token},
  doi={10.1109/MMSP55362.2022.9949108},
  ISSN={2473-3628},
  month={Sep.},}@ARTICLE{9454486,
  author={Liao, Wentao and Pu, Yuehu},
  journal={IEEE Access}, 
  title={Dose-Conditioned Synthesis of Radiotherapy Dose With Auxiliary Classifier Generative Adversarial Network}, 
  year={2021},
  volume={9},
  number={},
  pages={87972-87981},
  abstract={In recent years, there are more and more researches on automatic radiotherapy planning based on artificial intelligence technology. Most of the work focuses on the dose prediction of radiotherapy planning, that is, the generation of radiation dose distribution image. Because of the small sample nature of radiotherapy planning data, it is difficult to obtain large-scale training data sets. In this paper, we propose a model of Dose-Conditioned Synthesis of Radiotherapy dose by using Auxiliary Classifier Generative Adversarial Network(ACGAN), and a method of customize and synthesis dose distribution images of specific tumor types and beam types is considered. This method can customize and generate dose distribution images of tumor types and beam types. The dose distribution images generated by our model are evaluated by MS-SSIM and PSNR, the results show that the image quality of dose distribution generated by ACGAN model was excellent, which was very close to the real data and shows high diversity, it can be used for data enhancement work of training data sets of dose prediction methods.},
  keywords={Tumors;Generative adversarial networks;Image synthesis;Data mining;Visualization;Task analysis;Radiotherapy IMRT dose distribution autoplanning ACGAN data enhancement},
  doi={10.1109/ACCESS.2021.3089369},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10602253,
  author={Islam, Raisa and Ahmed, Imtiaz},
  booktitle={2024 5th Information Communication Technologies Conference (ICTC)}, 
  title={Gemini-the most powerful LLM: Myth or Truth}, 
  year={2024},
  volume={},
  number={},
  pages={303-308},
  abstract={Gemini models excel in various tasks including image generation and interpretation, video understanding, and solving mathematical problems, among others. The Vertex AI Gemini API and Google AI Gemini API both enable developers to integrate Gemini model functionalities into their applications. This paper offers a concise summary of the Gemini Framework, focusing on its distinctive modalities that distinguish it from current systems. In our research, we explored the details of its architecture, pointing out the innovative strategies employed to improve generative AI capabilities. Furthermore, we conduct a comparative study, assessing Gemini’s performance against other top generative AI models.},
  keywords={Technological innovation;Analytical models;Image synthesis;Generative AI;Focusing;Benchmark testing;Mathematical models;Gemini Framework;Generative AI;Multimodal AI;LLM;OpenAI GPT;input prompt},
  doi={10.1109/ICTC61510.2024.10602253},
  ISSN={},
  month={May},}@ARTICLE{9912424,
  author={Qin, Le and Peng, Fei and Long, Min},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Face Morphing Attack Detection and Localization Based on Feature-Wise Supervision}, 
  year={2022},
  volume={17},
  number={},
  pages={3649-3662},
  abstract={To strengthen the security of face recognition systems to morphing attacks (MAs), many countermeasures were proposed. However, in the existing face morphing attack detection (MAD), the deep networks trained by classical score-level losses are weak in characterizing the intrinsic morphing patterns of different MAs, and they also cannot be directly applied to differential MAD scenarios. To this end, this paper presents a method for detecting and locating face MAs by the use of feature-wise supervision. It constructs the fine-grained classification loss on the basis of different morphing patterns, and designs the similarity-based and distance-based differential losses according to the properties of differential MAD scenarios. The experimental results and analysis show that the fine-grained classification loss can locate the local morphed areas after detecting MAs, while the differential losses are able to improve the generalization ability of MAD methods to unseen MAs, and can enhance the robustness of MAD methods to low-resolution and non-frontal probe face images.},
  keywords={Feature extraction;Face recognition;Faces;Probes;Security;Location awareness;Training;Face recognition;forensics;morphing attack detection;morphing attacks},
  doi={10.1109/TIFS.2022.3212276},
  ISSN={1556-6021},
  month={},}@INPROCEEDINGS{11044008,
  author={Vungarala, Deepak and Nazzal, Mahmoud and Morsali, Mehrdad and Zhang, Chao and Ghosh, Arnob and Khreishah, Abdallah and Angizi, Shaahin},
  booktitle={2025 IEEE International Symposium on Circuits and Systems (ISCAS)}, 
  title={SA-DS: A Dataset for Large Language Model-Driven AI Accelerator Design Generation}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={In the ever-evolving landscape of Deep Neural Networks (DNN) hardware acceleration, unlocking the true potential of systolic array accelerators has long been hindered by the daunting challenges of expertise and time investment. Large Language Models (LLMs) offer a promising solution for automating code generation, which is key to unlocking unprecedented efficiency and performance in various domains, including hardware descriptive code. The generative power of LLMs can enable the effective utilization of preexisting designs and dedicated hardware generators. However, the successful application of LLMs to hardware accelerator design is contingent upon the availability of specialized datasets tailored for this purpose. To bridge this gap, we introduce the Systolic Array-based Accelerator DataSet (SA-DS). SA-DS comprises a diverse collection of spatial array designs following the standardized Berkeley’s Gemmini accelerator generator template, enabling design reuse, adaptation, and customization. SA-DS is intended to spark LLM-centered research on DNN hardware accelerator architecture. We envision that SA-DS provides a framework that will shape the course of DNN hardware acceleration research for generations to come. SA-DS is open-sourced under the permissive MIT license at https://github.com/ACADLab/SA-DS.},
  keywords={Codes;Power demand;Shape;Artificial neural networks;Licenses;Systolic arrays;Generators;Sparks;Prompt engineering;Hardware acceleration;Systolic array design;LLM-powered hardware synthesis;accelerator architecture},
  doi={10.1109/ISCAS56072.2025.11044008},
  ISSN={2158-1525},
  month={May},}@ARTICLE{10990167,
  author={Zhu, Tianwen and Ran, Yongyi and Zhou, Xin and Wen, Yonggang},
  journal={IEEE Communications Surveys & Tutorials}, 
  title={A Survey on Intelligent Predictive Maintenance (IPdM) in the Era of Fully Connected Intelligence}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Predictive Maintenance (PdM) refers to a maintenance paradigm that performs maintenance only after the analytical models predict certain failures or degradations. While traditional PdM has improved maintenance efficiency, its scalability is constrained by network limitations, resource allocation challenges, and the computational demands of AI-driven analytics. With the help of fully connected intelligence, Intelligent Predictive Maintenance (IPdM) overcomes these limitations by leveraging 6G, cloud-edge computing, and AI advancements, enabling a more adaptive and intelligent PdM framework. This survey contributes to the burgeoning IPdM academia from the perspective of communication and networking. Firstly, we explore how communication evolutions and network advancements facilitate IPdM deployment by presenting an integrated cloudedge-device IPdM framework. Under this framework, we analyze the IPdM lifecycle and explore the challenges and solutions within each stage. Particularly, we discuss the novel technical enablers for IPdM in communication an AI. Afterwards, we explore how IPdM helps communication and networking by surveying the applications of IPdM in the regarding fields, such as data centres and sensor networks. Finally, we summarize the crucial future directions for promoting the further applications of IPdM in nextgeneration networking. We believe this work not only contributes to the academic discourse on IPdM but also offers valuable insights for industry professionals navigating the fourth industrial revolution.},
  keywords={Surveys;Artificial intelligence;Maintenance;Accuracy;Predictive maintenance;Data centers;Industries;Costs;Computational modeling;Cloud computing;Intelligent predictive maintenance;fault diagnosis;fault prognosis;edge computing;generative AI},
  doi={10.1109/COMST.2025.3567802},
  ISSN={1553-877X},
  month={},}@ARTICLE{11173627,
  author={Sapkota, Ranjan and Qureshi, Rizwan and Hadi, Muhammad Usman and Hassan, Syed Zohaib and Sadak, Ferhat and Shoman, Maged and Sajjad, Muhammad and Dharejo, Fayaz Ali and Paudel, Achyut and Li, Jiajia and Meng, Zhichao and Shutske, John and Karkee, Manoj},
  journal={IEEE Transactions on Automation Science and Engineering}, 
  title={Multi-Modal LLMs in Agriculture: A Comprehensive Review}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Given the rapid emergence and applications of Multi-Modal Large Language Models (MM-LLMs) across various scientific fields, insights regarding their applicability in agriculture are still only partially explored. This paper conducts an in-depth review of MM-LLMs in agriculture, focusing on understanding how MM-LLMs can be developed and implemented to optimize agricultural processes, increase efficiency, and reduce costs. Recent studies have explored the capabilities of MM-LLMs in agricultural information processing and decision-making. Despite these advancements, significant gaps persist, particularly in addressing domain-specific challenges such as variable data quality and availability, integration with existing agricultural systems, and the creation of robust training datasets that accurately represent complex agricultural environments. Moreover, a comprehensive understanding of the capabilities, challenges, and limitations of MM-LLMs in agricultural information processing and application is still missing. Exploring these areas is crucial to providing the community with a broader perspective and a clearer understanding of MM-LLMs’ applications, establishing a benchmark for the current state and emerging trends in this field. To bridge this gap, this survey reviews the progress of MM-LLMs and their utilization in agriculture, with an additional focus on 11 key research questions (RQs), where 4 RQs are general and 7 RQs are agriculture focused. By addressing these RQs, this review outlines the current opportunities and challenges, limitations, and future roadmap for MM-LLMs in agriculture. The findings indicate that multi-modal MM-LLMs not only simplify complex agricultural challenges but also significantly enhance decision-making and improve the efficiency of agricultural image processing. These advancements position MM-LLMs as an essential tool for the future of farming. For continued research and understanding, an organized and regularly updated list of papers on MM-LLMs is available at https://github.com/JiajiaLi04/Multi-Modal-LLMs-in-Agriculture.},
  keywords={Agriculture;Reviews;Hidden Markov models;Data models;Computational modeling;Farming;Analytical models;Translation;Transformers;Training;Large Language Models (MM-LLMs);Generative Artificial Intelligence;multi-modal MM-LLMs;ChatGPT;Language Processing;Deep Learning;Machine Learning;Computer Vision;Precision Agriculture;Language Models;Transformers;Vision-Language Models;Agricultural Data Analysis},
  doi={10.1109/TASE.2025.3612154},
  ISSN={1558-3783},
  month={},}@ARTICLE{10855556,
  author={Chen, Yuehai and Wang, Qingzhong and Yang, Jing and Chen, Badong and Xiong, Haoyi and Du, Shaoyi},
  journal={IEEE Transactions on Multimedia}, 
  title={CSCC: Cross-Scene Crowd Counting via Learning to Diversify for Domain Generalization}, 
  year={2025},
  volume={27},
  number={},
  pages={3320-3330},
  abstract={It is challenging for crowd counting models to generalize to new scenes due to domain shifts in training and test data. Although domain adaptation approaches have made notable progress in bridging the domain gap, they require target domain data. In this paper, we propose a novel framework for cross-scene crowd counting, which unifies domain generalization and adaptation. For domain generalization, we train a model only using single-domain data and the model can be generalized to any scene with satisfying performance. Regarding domain adaptation, we use both source and target domain data to further improve the performance. We first design a generation network that diversifies the generated samples to cover the unseen target domains as much as possible by minimizing mutual information. This approach simulates training data in various domains, thereby enhancing the model's generalization ability. Then we develop a pixel-wise supervised contrastive loss function that pulls the human heads in the source images and generated images closer to each other and pushes them further away from the background. This loss helps extract a domain-invariant feature representation, thus improving the model's generalization ability. Moreover, if information about the target domain is available, our generalization method can be easily applied as an adaptation method by replacing the mutual information minimization loss with the mutual information maximization loss. This can further improve cross-scene crowd counting performance. The experimental results demonstrate the strong generalizability of our method across different datasets.},
  keywords={Feature extraction;Adaptation models;Data models;Mutual information;Data mining;Training;Head;Training data;Minimization;Deep learning;Cross-sence crowd counting;domain adaptation;domain generalization},
  doi={10.1109/TMM.2025.3535302},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{10751425,
  author={Krishnasamy, Sarawana Kumar L and Lee, Chien-Sing},
  booktitle={2024 International Conference on ICT for Smart Society (ICISS)}, 
  title={AI Chatbots in the Office: Unveiling the Social Impacts on Future Workplace Harmony}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Despite the growing integration of AI chatbots in various industries, their social implications remain underexplored. This research provides an in-depth focus into how Generative AI (GenAI) Chatbots influence workplace dynamics, employee interactions, and the overall harmony of future work environments, from the lens of social sustainability. Through systematic literature review across various sampled case studies from business and technology industries, findings suggest that while AI chatbots contribute to operational efficiency, their impact on social interactions and employee perceptions are complex. Though GenAI chatbots can enhance both productivity and streamline tasks, it potentially creates a sense of detachment among employees. The paper underscores the need for a balanced approach to integrating GenAI chatbots, recommending different modes of transparent communication, employee training, and regular assessments of their social impact. This research contributes to the broader understanding of Generative AI's role in workplace harmony.},
  keywords={Industries;Training;Productivity;Generative AI;Employment;Chatbots;Aerodynamics;Sustainable development;Lenses;Business;Generative AI;Chatbots;AI Social Impacts;Future Workplace Harmony;Collaboration;Change Management},
  doi={10.1109/ICISS62896.2024.10751425},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10773583,
  author={Ozkan, Feyza and Tekin, Hatice Kubra and Keles, Hacer Yalim},
  booktitle={2024 9th International Conference on Computer Science and Engineering (UBMK)}, 
  title={Turkish Sign Language Video Generation from Pose Sequences Using a Conditional GAN Model}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Sign language is a visual gestural language that uses hand shapes, facial expressions, and body movements to convey meaning, and it is essential for communication among individuals with hearing impairments. Sign language users often face challenges in environments where sign language is not readily available. That is primarily because producing sign language requires a real signer, which can be time-consuming and labor-intensive. One potential solution to make more available sign language to its users is the use of artificial intelligence to generate sign language. While there have been global studies exploring AI-generated sign language videos for various sign languages, the research in this field is still evolving and active. Specifically, for Turkish Sign Language (TSL), only a few studies have been conducted. Our study introduces a model that combines pose sequences with reference images of signers to generate authentic sign language videos. Utilizing a conditional generative adver-sarial network (cGAN), the model generates video sequences by particularly focusing on complex finger details, arm positions while preserving the appearance of the reference image. The AUTSL dataset is employed for training and testing our model. Our early results demonstrate our model's capability to produce realistic hand and arm movements while effectively capturing finger details; we got 45.5 with Th e Frechet inception distance (FID), 35.8 with the peak-signal-to-noise ratio (PSNR), and 0.9 with the structural similarity index measure (SSIM).},
  keywords={Training;Sign language;Visualization;Shape;Video sequences;Refining;Focusing;Training data;Linear programming;Videos;Sign Language Production;Conditional Generative Adversarial Networks;Turkish Sign Language},
  doi={10.1109/UBMK63289.2024.10773583},
  ISSN={2521-1641},
  month={Oct},}@INPROCEEDINGS{9182341,
  author={Dungan, Belinda M. and Fernandez, Proceso L.},
  booktitle={2020 International Conference on Communication and Signal Processing (ICCSP)}, 
  title={Next Bar Predictor: An Architecture in Automated Music Generation}, 
  year={2020},
  volume={},
  number={},
  pages={109-113},
  abstract={Music generation has been an active field of research in computer science and is considered as a creative task attempting to imitate human creativity. With the different approaches to generate musical content, recent works have focused on general adversarial networks. One of these is the Midinet, which is considered the baseline model in this study. In this paper, we propose our Next Bar Predictor, a generative model that creates melody one bar at a time using the previous bar as basis to generate aesthetically pleasing melodies. We explore several variants of this by experimenting on different regression and classification models such as Decision Trees (DT), K-Nearest Neighbors (KNN), and Multilayer Perceptron (MLP). The models were trained using the dataset from Theorytab which consists of 460 songs. The outputs of these different variant models were then compared against those from the Midinet, using both machine-based objective scoring mechanism as well as human-based subjective evaluations. The dissimilarity scores obtained by our KNN (0.65) and DT (0.74) models, scored against the melodies in the dataset, are sufficiently high and indicates that both models are generally creative. Furthermore, based on the evaluation by human listeners, the melodies generated by our DT models are more realistic and pleasing than those of the Midinet. Casual listeners also prefer the DT model to be more interesting, although professional listeners think otherwise. Finally, all the variant models, when compared with Midinet, require much less training time and computational power. The proposed Next Bar Predictor is therefore a viable alternative for automated music generation.},
  keywords={Bars;Computational modeling;Predictive models;Decision trees;Multilayer perceptrons;Training;Machine learning;Computer generated music;machine learning;artificial intelligence},
  doi={10.1109/ICCSP48568.2020.9182341},
  ISSN={},
  month={July},}@INPROCEEDINGS{11096443,
  author={Rana, Milankumar},
  booktitle={2025 4th International Conference on Computational Modelling, Simulation and Optimization (ICCMSO)}, 
  title={Quantum-Ai Hybrid Architecture for Intelligent Fault Detection and Auto-Remediation in Distributed Cloud Systems}, 
  year={2025},
  volume={},
  number={},
  pages={443-447},
  abstract={The growing use of distributed cloud-edge computing architectures for high-availability and latency-sensitive applications has created a new class of fault management and system reliability issues. Modern cloud-edge systems are dynamic, varied, and decentralised, making traditional fault detection techniques-which frequently rely on rule-based or thresholddriven mechanisms-unable to keep up. In order to detect, locate, and forecast defects in real time across cloud and edge layers, this study presents a fault detection framework driven by Quantum AI (QAI) that combines deep learning. Hardware-in-the-loop, or HIL, testing is a crucial technique for evaluating the reliability and security of ASS (automotive software systems). However, the traditional data evaluation methods utilised for issue identification and classification using human specialists are unfeasible because of the complicated and massive volume of data generated by the platform of HIL throughout the process of testing. Employing hybrid DL approaches, this study suggests a novel intelligent failure detection and classification (FDC) methodology that may be used during the integration testing phase or the V-cycle phase of development. Moreover, the model structure was developed using a combination of Recurrent Neural Networks (RNN) and Generative Adversarial Networks (GAN). The results have shown that the proposed method outperformed previous stand-alone QDL techniques in detection and classification. Specifically, the proposed structure showed overall accuracies of 99.2% precision, 99.9 % recall, and 99.2% F1-score regarding detection. The experimental results show superiority in average classification accuracy with a rate of 99.1 % with unseen test data.},
  keywords={Training;Cloud computing;Accuracy;Recurrent neural networks;Quantum computing;Fault detection;Computational modeling;Computer architecture;Testing;Edge computing;Fault detection;Cloud system;Deep learning;Quantum computing;Artificial intelligence},
  doi={10.1109/ICCMSO67468.2025.00082},
  ISSN={},
  month={June},}@INPROCEEDINGS{10439099,
  author={Liu, Siqi and Lin, Zeyu and Huang, Yan and Yang, Hongqin and Chen, Jianling},
  booktitle={2023 2nd International Conference on Cloud Computing, Big Data Application and Software Engineering (CBASE)}, 
  title={Applications of deep learning for confocal fluorescence microscopy image quality enhancement using unpaired data}, 
  year={2023},
  volume={},
  number={},
  pages={218-221},
  abstract={The development of deep learning method and open access to ample public datasets have provided an excellent solution for confocal microscopy image translation, which severs as a stepping stone for microscopic imaging and biomedical research. However, in microscopic imaging, most applications of deep learning algorithms are applied in a supervised manner, which hinders the development of deep learning in microscopy owing to the need for large paired images and annotations. Here, we use an improved Cycle Generative Adversarial Network-based unsupervised learning algorithm to achieve confocal microscopy image quality enhancement. Two datasets, the self-collected human prostate cancer cells deblurring dataset and public planaria denoising dataset, are used to train and test in the mentioned model. The results show the model has excellent generalization ability, which can be adapted to different image translation tasks and different types of cell imaging for confocal microscopy.},
  keywords={Deep learning;Semiconductor device modeling;Optical microscopy;Microscopy;Noise reduction;Fluorescence;Task analysis;denoising;deblurring;unsupervised learning;confocal microscopy;artificial intelligence},
  doi={10.1109/CBASE60015.2023.10439099},
  ISSN={},
  month={Nov},}@ARTICLE{10993291,
  author={Annella, Clizia and Raparelli, Edoardo and Vulpiani, Gianfranco and Capozzi, Vincenzo and Adirosi, Elisa and Baldini, Luca and Budillon, Giorgio and Lidori, Raffaele and Montopoli, Mario},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={A Strategy to set up Test Dataset and Evaluation Benchmark for Radar Nowcasting of Precipitation in Italy}, 
  year={2025},
  volume={18},
  number={},
  pages={20240-20261},
  abstract={Prediction of extreme precipitation with high spatial resolution on short time scales (i.e., nowcasting) is still challenging, and data-driven approaches such as artificial intelligence tools are increasingly being used. In this respect, two factors are undoubtedly important: 1) The need of robust databases of temporal and spatial evolution of rain precipitation patterns to train new nowcasting routines, and 2) the establishment of an exhaustive benchmark to evaluate the improvements brought by new prediction algorithms. This article aims to contribute to the two points just mentioned by describing a novel practical-to-use radar data screening method and by analyzing the performance of nine existing radar nowcasting techniques to establish a minimum acceptable performance (MAP) level. The radar dataset used consists of 111 955 frames (1.5 year of data) at 1 × 1 $\text{km}^{2}$ resolution sampled 5 min apart over Italy, a country scarcely investigated so far in terms of radar nowcasting compared to other areas, and that may be considered a climate change hotspot. The results reveal a large variability in the performance of each tested nowcasting method, an aspect often not considered in similar studies but that evidences as the differences among the skills of various nowcasting methods can be systematically masked by the natural variability of each prediction outcome. The seasonal dependence of the nowcasting capacity is also shown and linked to the presence of orographic convective precipitation that occurs in Italy during the summer season. This last point also suggests for the future the need to implement convection-specific nowcasting modules, possibly optimized on local areas to improve the forecasting skills in case of atmospheric instability.},
  keywords={Radar;Rain;Weather forecasting;Meteorology;Atmospheric modeling;Benchmark testing;Meteorological radar;Mathematical models;Generative adversarial networks;Extrapolation;Climate change;Precipitation;Data screening;precipitation;radar nowcasting;weather radar},
  doi={10.1109/JSTARS.2025.3568185},
  ISSN={2151-1535},
  month={},}@ARTICLE{9729515,
  author={Ban, Yutong and Rosman, Guy and Eckhoff, Jennifer A. and Ward, Thomas M. and Hashimoto, Daniel A. and Kondo, Taisei and Iwaki, Hidekazu and Meireles, Ozanan R. and Rus, Daniela},
  journal={IEEE Robotics and Automation Letters}, 
  title={SUPR-GAN: SUrgical PRediction GAN for Event Anticipation in Laparoscopic and Robotic Surgery}, 
  year={2022},
  volume={7},
  number={2},
  pages={5741-5748},
  abstract={Comprehension of surgical workflow is the foundation upon which artificial intelligence (AI) and machine learning (ML) holds the potential to assist intraoperative decision making and risk mitigation. In this work, we move beyond mere identification of past surgical phases, into prediction of future surgical steps and specification of the transitions between them. We use a novel Generative Adversarial Network (GAN) formulation to sample future surgical phases trajectories conditioned on past video frames from laparoscopic cholecystectomy (LC) videos and compare it to state-of-the-art approaches for surgical video analysis and alternative prediction methods. We demonstrate the GAN formulation’s effectiveness through inferring and predicting the progress of LC videos. We quantify the horizon-accuracy trade-off and explored average performance, as well as the performance on the more challenging, and clinically relevant transitions between phases. Furthermore, we conduct a survey, asking 16 surgeons of different specialties and educational levels to qualitative evaluate predicted surgery phases.},
  keywords={Surgery;Predictive models;Generative adversarial networks;Trajectory;Task analysis;Robots;Decoding;Surgical AI;surgery;event prediction;GAN},
  doi={10.1109/LRA.2022.3156856},
  ISSN={2377-3766},
  month={April},}@INPROCEEDINGS{8545049,
  author={Yan, Shiyang and Wu, Fangyu and Smith, Jeremy S. and Lu, Wenjin and Zhang, Bailing},
  booktitle={2018 24th International Conference on Pattern Recognition (ICPR)}, 
  title={Image Captioning using Adversarial Networks and Reinforcement Learning}, 
  year={2018},
  volume={},
  number={},
  pages={248-253},
  abstract={Image captioning is a significant task in artificial intelligence which connects computer vision and natural language processing. With the rapid development of deep learning, the sequence to sequence model with attention, has become one of the main approaches for the task of image captioning. Nevertheless, a significant issue exists in the current framework: the exposure bias problem of Maximum Likelihood Estimation (MLE) in the sequence model. To address this problem, we use generative adversarial networks (GANs) for image captioning, which compensates for the exposure bias problem of MLE and also can generate more realistic captions. GANs, however, cannot be directly applied to a discrete task, like language processing, due to the discontinuity of the data. Hence, we use a reinforcement learning (RL) technique to estimate the gradients for the network. Also, to obtain the intermediate rewards during the process of language generation, a Monte Carlo roll-out sampling method is utilized. Experimental results on the COCO dataset validate the improved effect from each ingredient of the proposed model. The overall effectiveness is also evaluated.},
  keywords={Generators;Gallium nitride;Generative adversarial networks;Monte Carlo methods;Maximum likelihood estimation;Mathematical model;Task analysis},
  doi={10.1109/ICPR.2018.8545049},
  ISSN={1051-4651},
  month={Aug},}@INPROCEEDINGS{9155501,
  author={Yoon, JinYi and Lee, HyungJune},
  booktitle={IEEE INFOCOM 2020 - IEEE Conference on Computer Communications}, 
  title={PUFGAN: Embracing a Self-Adversarial Agent for Building a Defensible Edge Security Architecture}, 
  year={2020},
  volume={},
  number={},
  pages={904-913},
  abstract={In the era of edge computing and Artificial Intelligence (AI), securing billions of edge devices within a network against intelligent attacks is crucial. We propose PUFGAN, an innovative machine learning attack-proof security architecture, by embedding a self-adversarial agent within a device fingerprint- based security primitive, public PUF (PPUF) known for its strong fingerprint-driven cryptography. The self-adversarial agent is implemented using Generative Adversarial Networks (GANs). The agent attempts to self-attack the system based on two GAN variants, vanilla GAN and conditional GAN. By turning the attacking quality through generating realistic secret keys used in the PPUF primitive into system vulnerability, the security architecture is able to monitor its internal vulnerability. If the vulnerability level reaches at a specific value, PUFGAN allows the system to restructure its underlying security primitive via feedback to the PPUF hardware, maintaining security entropy at as high a level as possible. We evaluated PUFGAN on three different machine environments: Google Colab, a desktop PC, and a Raspberry Pi 2, using a real-world PPUF dataset. Extensive experiments demonstrated that even a strong device fingerprint security primitive can become vulnerable, necessitating active restructuring of the current primitive, making the system resilient against extreme attacking environments.},
  keywords={Computer architecture;Cryptography;Hardware;Gallium nitride;Machine learning;Generative adversarial networks},
  doi={10.1109/INFOCOM41043.2020.9155501},
  ISSN={2641-9874},
  month={July},}@INBOOK{11104985,
  author={Nag, Anindya and Hassan, Md. Mehedi and Karim, Asif and Kumar Reddy C, Kishor},
  booktitle={Generative AI in Neurodegenerative Disorders: Innovations, Views, and Obstacles}, 
  title={7 Navigating Autism Spectrum Disorder: A Fusion of Deep Learning and Explainable AI for Enhanced Detection and Classification}, 
  year={2025},
  volume={},
  number={},
  pages={165-184},
  abstract={This book delves into the transformative power of AI in the realm of neurodegenerative diseases, covering topics such as ALS, Huntington's, Parkinson's, and Alzheimer's. Generative AI provides new opportunities for early diagnosis, precise therapy, and individualized rehabilitation, which are crucial as these conditions remain major obstacles for healthcare providers and researchers. Researchers, physicians, AI developers, and healthcare professionals will find this book an invaluable resource for understanding how AI is influencing the development of treatments for neurodegenerative diseases. It describes important obstacles and future directions while providing insights into the newest breakthroughs, thus bridging the gap between technology and practical clinical applications. Anyone involved in neurodegenerative healthcare, from scientists conducting AI-driven medical research to physicians seeking to incorporate AI into patient care or AI professionals investigating new healthcare applications, will find the information and insights they need in this comprehensive book. Predictive analytics, biomarker identification, and drug discovery are being transformed by AI-driven models, such as deep neural networks, generative adversarial networks (GANs), and variational autoencoders (VAEs). This book offers a comprehensive examination of these developments. Robots, wearable sensors, and cognitive therapy platforms are some of the AI-enhanced rehabilitation tools covered, as are AI-integrated cutting-edge technologies like fMRI and MRI, gene-editing methods like CRISPR, and more. In addition to discussing recent technical developments, this book takes a close look at the data privacy, ethics, and regulatory issues that arise when using AI to study neurodegenerative disorders. Issues like algorithmic bias, model explainability, and fair AI-driven healthcare are thoroughly investigated in light of the growing usage of AI models in clinical decision-making, mental health applications, and cognitive rehabilitation.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788743801740},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/11104985},}@INPROCEEDINGS{9725562,
  author={Juzer Gabajiwala, Hamza and Kamlesh Jethwa, Nishant and Joshi, Parth Bimal and Anurag Mishra, Arundhati and Natu, Prachi},
  booktitle={2021 3rd International Conference on Advances in Computing, Communication Control and Networking (ICAC3N)}, 
  title={Comprehensive Review of Various Optimization Algorithms for Image Captioning}, 
  year={2021},
  volume={},
  number={},
  pages={1703-1708},
  abstract={Automatic Image captioning is a prominent and challenging research problem in the field of computer vision and natural language processing with applications ranging in biology, automotive and several other domains. Human brain being a complex organ, is able to constantly identify and establish all the intricate details of a scene in real-time, which a machine fails to imitate. However, with neoteric advances in Artificial Intelligence, image captioning has witnessed significant progress. This paper provides a comprehensive review of the latest advancements in caption generation with an emphasis on encoder-decoder and generative adversarial network frameworks. A comparative analysis is performed on existing approaches and methodologies along with an overview of commonly used datasets and evaluation metrics.},
  keywords={Computer vision;Computer architecture;Biological systems;Generative adversarial networks;Real-time systems;Natural language processing;Distance measurement;Decoder;Deep Learning;Encoder;GANs;Image Captioning},
  doi={10.1109/ICAC3N53548.2021.9725562},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9319045,
  author={Rojtberg, Pavel and Pöllabauer, Thomas and Kuijper, Arjan},
  booktitle={2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)}, 
  title={Style-transfer GANs for bridging the domain gap in synthetic pose estimator training}, 
  year={2020},
  volume={},
  number={},
  pages={188-195},
  abstract={Given the dependency of current CNN architectures on a large training set, the possibility of using synthetic data is alluring as it allows generating a virtually infinite amount of labeled training data. However, producing such data is a nontrivial task as current CNN architectures are sensitive to the domain gap between real and synthetic data.We propose to adopt general-purpose GAN models for pixel-level image translation, allowing to formulate the domain gap itself as a learning problem. The obtained models are then used either during training or inference to bridge the domain gap. Here, we focus on training the single-stage YOLO6D [20] object pose estimator on synthetic CAD geometry only, where not even approximate surface information is available. When employing paired GAN models, we use an edge-based intermediate domain and introduce different mappings to represent the unknown surface properties.Our evaluation shows a considerable improvement in model performance when compared to a model trained with the same degree of domain randomization, while requiring only very little additional effort.},
  keywords={Training;Adaptation models;Gallium nitride;Solid modeling;Pose estimation;Data models;Task analysis},
  doi={10.1109/AIVR50618.2020.00039},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10208531,
  author={Pérez, Juan C. and Alfarra, Motasem and Thabet, Ali and Arbeláez, Pablo and Ghanem, Bernard},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={Towards Characterizing the Semantic Robustness of Face Recognition}, 
  year={2023},
  volume={},
  number={},
  pages={315-325},
  abstract={Deep Neural Networks (DNNs) lack robustness against imperceptible perturbations to their input. Face Recognition Models (FRMs) based on DNNs inherit this vulnerability. We propose a methodology for assessing and characterizing the robustness of FRMs against semantic perturbations to their input. Our methodology causes FRMs to malfunction by designing adversarial attacks that search for identity-preserving modifications to faces. In particular, given a face, our attacks find identity-preserving variants of the face such that an FRM fails to recognize the images belonging to the same identity. We model these identity-preserving semantic modifications via direction- and magnitude-constrained perturbations in the latent space of StyleGAN. We further propose to characterize the semantic robustness of an FRM by statistically describing the perturbations that induce the FRM to malfunction. Finally, we combine our methodology with a certification technique, thus providing (i) theoretical guarantees on the performance of an FRM, and (ii) a formal description of how an FRM may model the notion of face identity.},
  keywords={Computer vision;Image recognition;Face recognition;Perturbation methods;Conferences;Semantics;Artificial neural networks},
  doi={10.1109/CVPRW59228.2023.00037},
  ISSN={2160-7516},
  month={June},}@INPROCEEDINGS{10890511,
  author={Lee, Yongjoon and Kim, Chanwoo},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Wave-U-Mamba: An End-To-End Framework For High-Quality And Efficient Speech Super Resolution}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Speech Super-Resolution (SSR) is a task of enhancing low-resolution speech signals by restoring missing high-frequency components. Conventional approaches typically reconstruct log-mel features, followed by a vocoder that generates high-resolution speech in the waveform domain. However, as mel features lack phase information, this can result in performance degradation during the reconstruction phase. Motivated by recent advances with Selective State Spaces Models (SSMs), we propose a method, referred to as Wave-U-Mamba that directly performs SSR in time domain. In our comparative study, including models such as WSRGlow, NU-Wave 2, and AudioSR, Wave-U-Mamba demonstrates superior performance, achieving the lowest Log-Spectral Distance (LSD) across various low-resolution sampling rates, ranging from 8 to 24 kHz. Additionally, subjective human evaluations, scored using Mean Opinion Score (MOS) reveal that our method produces SSR with natural and human-like quality. Furthermore, Wave-U-Mamba achieves these results while generating high-resolution speech over nine times faster than baseline models on a single A100 GPU, with parameter sizes less than 2% of those in the baseline models.},
  keywords={Training;Computational modeling;Vocoders;Superresolution;Graphics processing units;Computer architecture;Speech enhancement;Generative adversarial networks;Time-domain analysis;Signal resolution;Speech Super-Resolution;U-Net;Mamba;Generative Adversarial Networks},
  doi={10.1109/ICASSP49660.2025.10890511},
  ISSN={2379-190X},
  month={April},}@ARTICLE{10731709,
  author={Liu, Xu and Zhao, Yang and Chi, Kaichen and Zhang, Zhao and Chen, Yanxiang and Jia, Wei},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Toward Individual Tone Preference in Underwater Image Enhancement}, 
  year={2024},
  volume={62},
  number={},
  pages={1-11},
  abstract={Underwater images often suffer from severe color distortion due to the challenging imaging environment. Underwater image enhancement (UIE) techniques have been developed to recover clear images, laying the foundation for various underwater research. However, existing UIE methods tend to produce fixed results without considering individual preferences for different color tones. And there is no dataset with ground truth (GT) in different tones. Therefore, we came up with the possibility of using the currently popular multimodal methods to control the color tone of enhanced images. This article proposes a method for generating underwater enhanced images with cold, warm, and normal tones using multimodal information supervision (MM-UIE). First, we leverage the relationship between text prompts and images to supervise the generation of cold or warm images. In addition, we introduce a 6-D color operator, which not only enhances the tone control of underwater images but also serves as a bridge between different tone images. Finally, we also found that multimodal supervision methods can not only control the color tone of underwater images but also improve the quality of underwater image generation. Experimental results demonstrate the superior performance of our method compared to state-of-the-art (SOTA) techniques. Our codes will be publicly available at https://github.com/perseveranceLX/MM-UIE.},
  keywords={Image color analysis;Image enhancement;Visualization;Image restoration;Geoscience and remote sensing;Training;Visual systems;Supervised learning;Histograms;Generative adversarial networks;6-D color operator;application of the large-scale generative model;multimodal learning;underwater image enhancement (UIE)},
  doi={10.1109/TGRS.2024.3485030},
  ISSN={1558-0644},
  month={},}@BOOK{10882925,
  author={Seyedsalehi, Shirin and Bigdeli, Amin and Arabzadeh, Negar and AlMousawi, Batool and Marshall, Zack and Zihayat, Morteza and Bagheri, Ebrahim},
  booktitle={Understanding and Mitigating Gender Bias in Information Retrieval Systems},
  year={2025},
  volume={},
  number={},
  pages={},
  abstract={Gender bias is a pervasive issue that continues to influence various aspects of society, including the outcomes of information retrieval (IR) systems. As these systems become increasingly integral to accessing and navigating the vast amounts of information available today, the need to understand and mitigate gender bias within them is paramount. This monograph provides a comprehensive examination of the origins, manifestations, and consequences of gender bias in IR systems, as well as the current methodologies employed to address these biases. Theoretical frameworks surrounding gender and its representation in artificial intelligence (AI) systems are explored, particularly focusing on how traditional gender binaries are perpetuated and reinforced through data and algorithmic processes. Metrics and methodologies used to identify and measure gender bias within IR systems are then analyzed, offering a detailed evaluation of existing approaches and their limitations. Subsequent sections address the sources of gender bias, including biased input queries, retrieval methods, and gold standard datasets. Various data-driven and method-level debiasing strategies are presented, including techniques for debiasing neural embeddings and algorithmic approaches aimed at reducing bias in IR system outputs. The monograph concludes with a discussion of the challenges and limitations faced by current debiasing efforts and provides insights into future research directions that could lead to more equitable and inclusive IR systems. This monograph serves as a valuable resource for researchers, practitioners, and students in the fields of information retrieval, artificial intelligence, and data science, providing the knowledge and tools needed to address gender bias and contribute to the development of fair and unbiased information systems.},
  keywords={},
  doi={},
  ISSN={},
  publisher={now},
  isbn={9781638285199},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10882925},}@INPROCEEDINGS{11141009,
  author={Tejasvi, Kurella and Cherla, Srisai Krishna and Kiran Kairamkonda, Uday and Ramesh, G. and Pranathi, Katam and Rama Krishna, N. Siva},
  booktitle={2025 8th International Conference on Computing Methodologies and Communication (ICCMC)}, 
  title={DeepFake Videos Detection using Hybrid Deep Learning Models}, 
  year={2025},
  volume={},
  number={},
  pages={2011-2017},
  abstract={DeepFake videos are artificial media produced through sophisticated artificial intelligence methods, frequently utilizing generative models. In order to solve this issue we came up with solution of identifying the DeepFake videos by combining ResNext and LSTM deep learning architectures. ResNext is employed for capturing facial patterns and extracting spatial features whereas LSTM inspects temporal changes frame sequences to identify manipulation over time and renders a verdict on the video as real/fake. Fake-face videos mislead viewers and speed up the spread of misinformation. Many detectors miss subtle artifacts when faces move fast or lighting shifts. We tackle this issue with a hybrid network that combines ResNeXt-50 for spatial cues with a two-layer LSTM that tracks frame-by-frame changes. The model learns from 19,800 clips drawn from FaceForensics and DFDC after face alignment and 10 Hz frame sampling. Training uses cross-entropy loss, batch size 32, and the Adam optimizer at 1×10⁻⁴. On a held-out DFDC test split the detector reaches 87.2% accuracy, 88.9% precision, and 86.0% recall while processing 22 frames each second. The hybrid stack lifts recall by six points over a ResNeXt-only baseline and keeps memory below 3 GB. These results show that fusing spatial and temporal signals in one compact model curbs the reach of manipulated videos on social platforms.},
  keywords={Training;Deep learning;Deepfakes;Accuracy;Tracking;Detectors;Feature extraction;Convolutional neural networks;Long short term memory;Faces;Deep Learning;Artificial Intelligence;spatial features;temporal frames;Hybrid Model Integration},
  doi={10.1109/ICCMC65190.2025.11141009},
  ISSN={},
  month={July},}@INPROCEEDINGS{9577379,
  author={Shi, Liushuai and Wang, Le and Long, Chengjiang and Zhou, Sanping and Zhou, Mo and Niu, Zhenxing and Hua, Gang},
  booktitle={2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={SGCN:Sparse Graph Convolution Network for Pedestrian Trajectory Prediction}, 
  year={2021},
  volume={},
  number={},
  pages={8990-8999},
  abstract={Pedestrian trajectory prediction is a key technology in autopilot, which remains to be very challenging due to complex interactions between pedestrians. However, previous works based on dense undirected interaction suffer from modeling superfluous interactions and neglect of trajectory motion tendency, and thus inevitably result in a considerable deviance from the reality. To cope with these issues, we present a Sparse Graph Convolution Network (SGCN) for pedestrian trajectory prediction. Specifically, the SGCN explicitly models the sparse directed interaction with a sparse directed spatial graph to capture adaptive interaction pedestrians. Meanwhile, we use a sparse directed temporal graph to model the motion tendency, thus to facilitate the prediction based on the observed direction. Finally, parameters of a bi-Gaussian distribution for trajectory prediction are estimated by fusing the above two sparse graphs. We evaluate our proposed method on the ETH and UCY datasets, and the experimental results show our method outperforms comparative state-of-the-art methods by 9% in Average Displacement Error (ADE) and 13% in Final Displacement Error (FDE). Notably, visualizations indicate that our method can capture adaptive interactions between pedestrians and their effective motion tendencies.},
  keywords={Legged locomotion;Adaptation models;Visualization;Computer vision;Convolution;Predictive models;Trajectory},
  doi={10.1109/CVPR46437.2021.00888},
  ISSN={2575-7075},
  month={June},}@ARTICLE{8708941,
  author={Li, Debang and Wu, Huikai and Zhang, Junge and Huang, Kaiqi},
  journal={IEEE Transactions on Image Processing}, 
  title={Fast A3RL: Aesthetics-Aware Adversarial Reinforcement Learning for Image Cropping}, 
  year={2019},
  volume={28},
  number={10},
  pages={5105-5120},
  abstract={Image cropping aims at improving the quality of images by removing unwanted outer areas, which is widely used in the photography and printing industry. Most of the previous cropping methods that do not need bounding box supervision rely on the sliding window mechanism. The sliding window method results in fixed aspect ratios and limits the shape of the cropping region. Moreover, the sliding window method usually produces lots of candidates on the input image, which is very time-consuming. Motivated by these challenges, we formulate image cropping as a sequential decision-making process and propose a reinforcement learning-based framework to address this problem, namely, Fast Aesthetics-Aware Adversarial Reinforcement Learning (Fast A3RL). Particularly, the proposed method develops an aesthetics-aware reward function that is dedicated for image cropping. Similar to human's decision-making process, we use a comprehensive state representation, including both the current observation and the historical experience. We train the agent using the actor-critic architecture in an end-to-end manner. The adversarial learning process is also applied during the training stage. The proposed method is evaluated on several popular cropping datasets, in which the images are unseen during training. The experiment results show that our method achieves the state-of-the-art performance with much fewer candidate windows and much less time compared with related methods.},
  keywords={Microsoft Windows;Reinforcement learning;Computational efficiency;Training;Image processing;Shape;Decision making;Reinforcement learning;adversarial learning;image cropping},
  doi={10.1109/TIP.2019.2914360},
  ISSN={1941-0042},
  month={Oct},}@ARTICLE{10952376,
  author={Bai, Jie and Fang, Jianwu and Lv, Yisheng and Lv, Chen and Xue, Jianru and Li, Zhengguo},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Gating Syn-to-Real Knowledge for Pedestrian Crossing Prediction in Safe Driving}, 
  year={2025},
  volume={26},
  number={6},
  pages={7509-7522},
  abstract={Pedestrian crossing prediction (PCP) in driving scenes plays a critical role in ensuring the safe decision of intelligent vehicles. Due to the limited observations and annotations of pedestrian crossing behaviors in real situations, recent studies have begun to leverage synthetic data with flexible variation to boost prediction performance, employing domain adaptation frameworks. However, different domain knowledge has distinct cross-domain distribution gaps, which necessitates suitable domain knowledge adaption ways for PCP tasks. In this work, we propose a gated syn-to-real knowledge transfer approach for PCP (Gated-S2R-PCP), which has two aims: 1) designing the suitable domain adaptation ways for different kinds of crossing-domain knowledge, and 2) transferring suitable knowledge for specific situations with gated knowledge fusion. Specifically, we design a framework that contains three domain adaption methods including style transfer, distribution approximation, and knowledge distillation for various information, such as visual, semantic, depth, bounding boxes, etc. A learnable gated unit (LGU) is employed to fuse suitable cross-domain knowledge to boost pedestrian crossing prediction. We construct a new synthetic benchmark S2R-PCP-3181 with 3181 sequences (489,740 frames) which contains the pedestrian bounding boxes, RGB frames, semantic segmentation maps, and depth maps. With the synthetic S2R-PCP-3181, we transfer the knowledge to two real challenging datasets of PIE and JAAD, and superior PCP performance is obtained to the state-of-the-art methods.},
  keywords={Pedestrians;Knowledge transfer;Logic gates;Semantic segmentation;Synthetic data;Adaptation models;Visualization;Three-dimensional displays;Feature extraction;Transformers;Pedestrian crossing prediction;safe driving;domain adaptation;gated network;Timesformer},
  doi={10.1109/TITS.2025.3554767},
  ISSN={1558-0016},
  month={June},}@ARTICLE{11038825,
  author={Zuo, Zuo and Dong, Jiahao and Wu, Yao and Qu, Yanyun and Wu, Zongze},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={PADiff: Reconstruction From Patch to Pixel With Normality-Guided Diffusion Model for Unsupervised Anomaly Localization}, 
  year={2025},
  volume={},
  number={},
  pages={1-14},
  abstract={Anomaly localization (AL) is an indispensable and challenging task in manufacturing. Recently, diffusion models have been widely used to localize anomalies through discrepancies between original and reconstructed representations, which is based on the hypothesis that diffusion models regard anomalies as noise and reconstruct them to normal representations. However, anomalies usually deviate from prior standard Gaussian distribution and diffusion models cannot reconstruct anomaly parts as normal patterns well due to powerful generalization. These issues hinder the application of diffusion models in AL and lead to suboptimal performance. As a remedy, we present a novel framework for AL based on the diffusion model, dubbed PADiff. To enable the diffusion model to reconstruct abnormal regions to normal regions in an anomaly image, we propose to guide the diffusion model in the reconstruction process using its normal counterpart. High-quality guided normal counterpart plays a key role in our method. Therefore, we propose a patch-substitution strategy to obtain a high-quality-guided normal counterpart. Specifically, we first construct a normal patch memory bank using normal training samples. With a normal memory bank, we find potential anomaly patches in testing images and substitute them with most similar normal patches in the memory bank. After substitution, pseudo-normal images are generated to guide the diffusion model. To make our method more data-efficient, we divide an image into patches and propose patch-wise training and reconstruction. As one of our innovations, we propose to encode each patch into positional embedding and add it on time embedding, which introduces patch-level representation and position information in the diffusion model. Extensive experiments are conducted on three commonly used anomaly detection datasets (MVTec-AD, VisA, and BTAD) to showcase the state-of-the-art (SOTA) performance of the proposed PADiff. The source code is publicly available at https://github.com/Jay-zzcoder/padiff},
  keywords={Diffusion models;Image reconstruction;Training;Anomaly detection;Location awareness;Feature extraction;Gaussian noise;Benchmark testing;Standards;Semantics;Anomaly localization (AL);diffusion models;unsupervised learning},
  doi={10.1109/TNNLS.2025.3572438},
  ISSN={2162-2388},
  month={},}@INPROCEEDINGS{8374720,
  author={Mead, Adrian and Lewris, Tyler and Prasanth, Sai and Adams, Stephen and Alonzi, Peter and Beling, Peter},
  booktitle={2018 Systems and Information Engineering Design Symposium (SIEDS)}, 
  title={Detecting fraud in adversarial environments: A reinforcement learning approach}, 
  year={2018},
  volume={},
  number={},
  pages={118-122},
  abstract={Credit card fraud is a costly problem for banks and a major frustration for consumers. As such, static models to detect fraud that rely on supervised training are exposed to the risk of being learned and circumvented. Previous adversarial learning work in fraud prevention showed increased effectiveness over static models that did not account for changing fraudster behavior. We extend this work by utilizing Reinforcement Learning and framing the fraudster and card issuer interaction as a Markov Decision Process (MDP) and performing prediction and control. Our MDP takes on the perspective of an agent (in this case the fraudster with a stolen credit card) who interacts with an environment (merchants and a fraud classifier), by taking actions (transactions), and receiving rewards (relating to whether the transactions were successful/declined). This approach allows us to simulate fraudulent episodes in such a way that techniques like model-free policy iteration can identify an optimal policy for the fraudster. The episode ends when the card is terminated by the credit card company for fraud. We found that, compared to a static classifier, making small changes to our fraud classifier on a regular basis led to a significant decrease in the ability of a fraud agent to learn an optimal policy.},
  keywords={Credit cards;Learning (artificial intelligence);Adaptation models;Training;Companies;Process control;Biological system modeling;Adversarial Learning;Consumer Credit Fraud Detection;Markov Decision Process;Monte Carlo Policy Control;Reinforcement Learning},
  doi={10.1109/SIEDS.2018.8374720},
  ISSN={},
  month={April},}@ARTICLE{9756264,
  author={Thuraisingham, Bhavani},
  journal={IEEE Intelligent Systems}, 
  title={Trustworthy Machine Learning}, 
  year={2022},
  volume={37},
  number={1},
  pages={21-24},
  abstract={Machine learning (ML) techniques have numerous applications in many fields, including healthcare, medicine, finance, marketing, and cyber security. For example, ML techniques are being applied to determine whether to give a loan to a customer or whether the computing system has been attacked. However, the ML techniques themselves may be subject to attacks and may discriminate when determining who should get the loan. Therefore, the ML techniques have to be secure, ensure privacy of the individuals, incorporate fairness and be accurate. Such collection of ML techniques has come to be known as trustworthy machine learning (trustworthy ML). This article describes an architecture to support scalable trustworthy ML and describes the features that have to be incorporated into the ML techniques to ensure that they are trustworthy.},
  keywords={Privacy;Finance;Machine learning;Medical services;Computer architecture;Intelligent systems;Computer crime;Artificial intelligence},
  doi={10.1109/MIS.2022.3152946},
  ISSN={1941-1294},
  month={Jan},}@INPROCEEDINGS{9091371,
  author={Xia, Song and Qiu, Meikang and Jiang, Hao},
  booktitle={2019 IEEE International Conference on Smart Cloud (SmartCloud)}, 
  title={An adversarial reinforcement learning based system for cyber security}, 
  year={2019},
  volume={},
  number={},
  pages={227-230},
  abstract={In this paper, we proposed a reinforcement learning based system for defending the network users from malicious network traffics. By training two reinforcement learning agents: network attack generation agent and network defense agent, and based on the environment of deep neural networks, this system not only aims to outperforme the traditional machine learning algorithm (such as CNNs and LSTM), but also can to detect the adversarial example, which is the one of the biggest challenges for current machine learning based intrusion detection system.},
  keywords={Neural networks;Learning (artificial intelligence);Intrusion detection;Machine learning;Training;Computer security;adversarial reinforcement learning;adversarial samples;intrusion detection system;deep neural network.},
  doi={10.1109/SmartCloud.2019.00046},
  ISSN={},
  month={Dec},}@ARTICLE{9326373,
  author={Yun, Woo-Han and Kim, Taewoo and Lee, Jaeyeon and Kim, Jaehong and Kim, Junmo},
  journal={IEEE Access}, 
  title={Cut-and-Paste Dataset Generation for Balancing Domain Gaps in Object Instance Detection}, 
  year={2021},
  volume={9},
  number={},
  pages={14319-14329},
  abstract={Training an object instance detector where only a few training object images are available is a challenging task. One solution is a cut-and-paste method that generates a training dataset by cutting object areas out of training images and pasting them onto other background images. A detector trained on a dataset generated with a cut-and-paste method suffers from the conventional domain shift problem, which stems from a discrepancy between the source domain (generated training dataset) and the target domain (real test dataset). Though state-of-the-art domain adaptation methods are able to reduce this gap, it is limited because they do not consider the difference of domain gaps of foreground and background. In this study, we present that the conventional domain gap can be divided into two sub-domain gaps for foreground and background. Then, we show that the original cut-and-paste approach suffers from a new domain gap problem, an unbalanced domain gaps, because it has two separate source domains for foreground and background, unlike the conventional domain shift problem. Then, we introduce an advanced cut-and-paste method to balance the unbalanced domain gaps by diversifying the foreground with GAN (generative adversarial network)-generated seed images and simplifying the background using image processing techniques. Experimental results show that our method is effective for balancing domain gaps and improving the accuracy of object instance detection in a cluttered indoor environment using only a few seed images. Furthermore, we show that balancing domain gaps can improve the detection accuracy of state-of-the-art domain adaptation methods.},
  keywords={Training;Object detection;Feature extraction;Three-dimensional displays;Solid modeling;Detectors;Task analysis;Artificial neural networks;image processing;learning (artificial intelligence);object detection},
  doi={10.1109/ACCESS.2021.3051964},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8473310,
  author={Ananthakrishnan, Abhishek and Kanakiva, Vatsal and Ved, Dipen and Sharma, Grishma},
  booktitle={2018 Second International Conference on Inventive Communication and Computational Technologies (ICICCT)}, 
  title={Automated Gait Generation for Simulated Bodies Using Deep Reinforcement Learning}, 
  year={2018},
  volume={},
  number={},
  pages={90-95},
  abstract={A popular problem to solve these days is to propose an algorithm such that a body autonomously learns locomotion. Some of the most efficient and popular contemporary algorithms are Deep Reinforcement Learning algorithms. In this paper, we study three such algorithms from recent times, namely - Deep Deterministic Policy Gradient, Advantage Actor Critic, and Proximal Policy Optimization. We implement and compare the algorithms on the performance metric of average reward per epoch. Given our implementations, we then draw our conclusions on the efficiency of the algorithms proposed and rank the algorithms based on the same.},
  keywords={Learning (artificial intelligence);Optimization;Machine learning;Legged locomotion;Neural networks;Conferences;Reinforcement Learning;Reward Function;Value Function;Policy;Action Space;Observation Space;Actor - Critic;Policy Gradient;Mujoco;PyTorch},
  doi={10.1109/ICICCT.2018.8473310},
  ISSN={},
  month={April},}@INPROCEEDINGS{8683106,
  author={Wang, Yu-An and Huang, Yu-Kai and Lin, Tzu-Chuan and Su, Shang-Yu and Chen, Yun-Nung},
  booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Modeling Melodic Feature Dependency with Modularized Variational Auto-encoder}, 
  year={2019},
  volume={},
  number={},
  pages={191-195},
  abstract={Automatic melody generation has been a long-time aspiration for both AI researchers and musicians. However, learning to generate euphonious melodies has turned out to be highly challenging. This paper introduces 1) a new variant of variational autoencoder (VAE), where the model structure is designed in a modularized manner in order to model polyphonic and dynamic music with domain knowledge, and 2) a hierarchical encoding/decoding strategy, which explicitly models the dependency between melodic features. The proposed framework is capable of generating distinct melodies that sounds natural, and the experiments for evaluating generated music clips show that the proposed model outperforms the baselines in human evaluation.1},
  keywords={Analytical models;Autoencoders;Signal processing;Encoding;Acoustics;Decoding;Multiple signal classification;Speech processing;Artificial intelligence;Music Generation;VAE;Modularization},
  doi={10.1109/ICASSP.2019.8683106},
  ISSN={2379-190X},
  month={May},}@INPROCEEDINGS{9817325,
  author={},
  booktitle={2022 IEEE World AI IoT Congress (AIIoT)}, 
  title={Content}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={Presents the table of contents/splash page of the proceedings record},
  keywords={Machine learning;Data models;Deep learning;Predictive models;Analytical models;Brain modeling;Learning (artificial intelligence)},
  doi={10.1109/AIIoT54504.2022.9817325},
  ISSN={},
  month={June},}@INPROCEEDINGS{10411809,
  author={Zhao, Yi and Li, Yanchun},
  booktitle={2023 IEEE Ninth Multimedia Big Data (BigMM)}, 
  title={SSG-Net: A novel Text-to-Painting AI artwork generator enables illustrating of the step-by-step painting process}, 
  year={2023},
  volume={},
  number={},
  pages={3-10},
  abstract={Endowing AI with the ability of fine-art creation has been a long-standing goal for research community of multimedia. Indeed, recent image generation models have made to the point of shifting human art creation by generating visual image from text description. Although these AI generators are capable of producing end-to-end artworks with remarkable style and quality, they have not been able to imitate human in artistic creation by retrieving its painting process. Therefore, we focused on this challenging task of maximumly patterning human’s art creation by making text-to-painting image generation with fine-grained stroke by stroke predictions. Our proposal (SSG-Net) uses textual description as the input and further produces a quality artwork which not only matches the described scene but also restores the painting process with detailed sequential brushstroke predictions.},
  keywords={Art;Image synthesis;Computational modeling;Predictive models;Proposals;Artificial intelligence;Painting;Image Generation;Image Style;Text-to-Painting;Sequential Brush-strokes Prediction},
  doi={10.1109/BigMM59094.2023.00008},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10326367,
  author={Jin, Hyun-Woo and Kang, Dong-Oh},
  booktitle={2023 IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia)}, 
  title={Versatile-VTON: A Versatile Virtual Try-on Network}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Virtual Try-on Network, an AI technology for virtual clothing try-ons in online stores, offers users an intuitive experience with lucrative commercial potential. Most of VTON researches have focused on single garments, and have limitation in application to trying on various types of clothing. This is an inevitable issue due to limited provision of only top images in the dataset. Although recent datasets used in VTON include various types of clothing images and labels, including tops, bottoms, and dresses, it is not sufficient to give usability of virtual try-on of clothing items other than tops compared to the available data. We introduce Versatile-VTON to give more usability and better quality of VTON. Also, we show the feasibility of the proposed method by presenting quantitative measurements and conducting ablation study experiments.},
  keywords={Legged locomotion;Deformation;Clothing;Usability;Wrapping;Splines (mathematics);Artificial intelligence;Virtual Try-on Network;GAN},
  doi={10.1109/ICCE-Asia59966.2023.10326367},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10820752,
  author={Cao, Phuong},
  booktitle={SC24-W: Workshops of the International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={Jupyter Notebook Attacks Taxonomy: Ransomware, Data Exfiltration, and Security Misconfiguration}, 
  year={2024},
  volume={},
  number={},
  pages={750-754},
  abstract={Open-science collaboration using Jupyter Notebooks may expose expensively trained AI models, high-performance computing resources, and training data to security vulnerabilities, such as unauthorized access, accidental deletion, or misuse. The ubiquitous deployments of Jupyter Notebooks (≈ 11 million public notebooks on Github have transformed collaborative scientific computing by enabling reproducible research. Jupyter is the main HPC’s science gateway interface between AI researchers and supercomputers at academic institutions, such as the National Center for Supercomputing Applications (NCSA), national labs, and the industry. An impactful attack targeting Jupyter could disrupt scientific missions and business operations.This paper describes the network-based attack taxonomy of Jupyter Notebooks, such as ransomware, data exfiltration, security misconfiguration, and resource abuse for cryptocurrency mining. The open nature of Jupyter (direct data access, arbitrary code execution in multiple programming languages kernels) and its vast attack interface (terminal, file browser, untrusted cells) also attract attacks attempting to misuse supercomputing resources and steal state-of-the-art research artifacts. Jupyter uses encrypted datagrams of rapidly evolving WebSocket protocols that challenge even the most state-of-the-art network observability tools, such as Zeek.We envisage even more sophisticated AI-driven attacks can be adapted to target Jupyter, where defenders have limited visibility. In addition, the cryptographic design of Jupyter should be adapted to resist emerging quantum threats. On balance, this is the first paper to systematically describe the threat model against Jupyter Notebooks and lay out the design of auditing Jupyter to have better visibility against such attacks.},
  keywords={Threat modeling;Scientific computing;High performance computing;Taxonomy;Collaboration;Training data;Supercomputers;Ransomware;Artificial intelligence;Software development management;jupyter;notebooks;ransomware;attacks;security;network;quantum;post-quantum;vulnerabilities;cryptography;auditing;provenance},
  doi={10.1109/SCW63240.2024.00106},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9977765,
  author={Hegde, Pradyoth and Sontakke, Swapnil and Kumar, T N Mahesh and Hiretanad, Jeevan Revanappa and Madanbhavi, Ankita and Jayakumar, Parvati and Bhargavi, Kummara and Deepak, K T},
  booktitle={TENCON 2022 - 2022 IEEE Region 10 Conference (TENCON)}, 
  title={Hindi Spoken Conversational System for Healthcare Humanoid}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={As the world is advancing in robotics, humanising the robot is one of the focused areas. In this work, we show-case our Hindi Spoken Conversational System deployed Mitra robot. The Hindi Spoken Conversational system includes speech recoznition, conversational AI and speech synthesis systems.},
  keywords={Synthesizers;Humanoid robots;Medical services;Speech synthesis;Artificial intelligence;IEEE Regions;Automatic speech recognition;Automatic Speech Recognition (ASR);Natural Language Processing (NLP);Text-To-Speech Synthesizer (TTS);Humanoid Spoken conversational system},
  doi={10.1109/TENCON55691.2022.9977765},
  ISSN={2159-3450},
  month={Nov},}@INPROCEEDINGS{10849340,
  author={Sarwar, Md. Nasif and Arman, Md. Shohel and Bhuiyan, Touhid and Rafiq, Fatama Binta},
  booktitle={2025 IEEE 4th International Conference on AI in Cybersecurity (ICAIC)}, 
  title={Optimizing Intrusion Detection with Hybrid Deep Learning Models and Data Balancing Techniques}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The effectiveness of hybrid deep learning models in detecting network intrusions on imbalanced datasets was tested. Conventional IDS often misses rare attacks due to class imbalance. Three models were evaluated: CNN+DNN, Autoencoder+DNN, and DNN+XGBoost, using the CSC IDS 2018 dataset balanced with SMOTE, FSMOTE, and CTGAN techniques. Feature selection was performed using SHAP and correlation studies. The models were evaluated on accuracy, precision, recall, F1-score, and ROC AUC. The Autoencoder+DNN and CNN+DNN models, especially with FSMOTE and SMOTE, showed the best performance. This research highlights the potential of combining advanced feature selection, data balancing, and deep learning techniques to enhance network intrusion detection, offering a robust framework for improved cybersecurity strategies.},
  keywords={Deep learning;Correlation;Accuracy;Autoencoders;Diversity reception;Network intrusion detection;Feature extraction;Data models;Computer security;Artificial intelligence;Network intrusion detection;hybrid deep learning models;imbalanced datasets;CNN+DNN;Autoencoder+DNN;DNN+XGBoost;CSC IDS 2018 dataset;SMOTE;FSMOTE;CTGAN;SHAP;feature selection;data balancing techniques;cybersecurity},
  doi={10.1109/ICAIC63015.2025.10849340},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10889007,
  author={Ma, Kun and Han, Qilong and Yao, Jingzheng and Wu, Changmao and Zhang, Yuntao},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={DDA: Distillation-Driven Acceleration of the Reverse Diffusion Process for Stochastic Multi-Ship Trajectory Prediction}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Modeling stochastic multi-ship trajectories is vital for maritime safety and interaction efficiency. Recent researches show that diffusion models excel in trajectory prediction, surpassing GANs and VAEs in generation quality, diversity and stability. However, their slow sampling speed remains a major limitation, as producing high-quality trajectories typically requires hundreds of denoising steps. We introduce DDA, a novel method that accelerates multi-ship trajectory generation by distilling the reverse diffusion process, progressively reducing sampling steps by half while minimizing quality loss. We use CVAE-based encoder to map multimodal inputs into state embeddings in the latent space, and use distillation diffusion in the latent space to more quickly and better represent multi-ship trajectories. The diffusion model uses Transformer-based core, and we incorporate SO(2) invariance and equivariance to enhance model representation. Validation on real-world AIS datasets shows that the student model retains high-quality trajectory generation while sampling speed is approximately 30 times faster.},
  keywords={Diffusion processes;Stochastic processes;Transformer cores;Signal processing;Diffusion models;Transformers;Stability analysis;Trajectory;Artificial intelligence;Speech processing;Progressive Distillation;AIS;Diffusion Model;VAE;Accelerating Sampling},
  doi={10.1109/ICASSP49660.2025.10889007},
  ISSN={2379-190X},
  month={April},}@ARTICLE{11020732,
  author={Zhu, Yuzhou and Zhang, Xiang and Fu, Zhangjie and Wang, Fan and Wang, Xiulai},
  journal={IEEE Signal Processing Letters}, 
  title={Dual-Branch Texture Enhancement Framework for Steganographic Embedding Cost Learning}, 
  year={2025},
  volume={32},
  number={},
  pages={2619-2623},
  abstract={Cost-based image steganography can significantly enhance its performance through a Reinforcement Learning (RL) framework. However, existing methods still face limitations in the generation of reward signals and the capture of image texture details. To address these challenges, this paper proposes a Dual-Branch Texture Enhancement Reinforcement Learning framework (DBT-RL) for symmetric embedding cost learning. This framework incorporates a Texture Information Enhancement Module (TIEM), enabling the policy network to more effectively focus on complex textured regions. Additionally, DBT-RL integrates multiple steganalysis to construct an ensemble environment network and introduces a novel adaptive update strategy. This strategy dynamically selects the best-performing steganalyzer to provide rewards to the policy network while self-updating weaker steganalyzers, ensuring that the policy network receives precise and dynamically balanced feedback. A large number of experimental results show that DBT-RL achieves high performance in the security of symmetric-cost embedding steganography.},
  keywords={Costs;Steganography;Training;Security;Reinforcement learning;Feature extraction;Error analysis;Data mining;Artificial intelligence;Adaptive systems;Image steganography;reinforcement learning (RL);update strategy;texture enhancement},
  doi={10.1109/LSP.2025.3575597},
  ISSN={1558-2361},
  month={},}@INPROCEEDINGS{10689970,
  author={Vandana and Chaturvedi, Kapil},
  booktitle={2024 5th International Conference on Electronics and Sustainable Communication Systems (ICESC)}, 
  title={Illusion or Reality: Analyzing Sentiments on Deepfakes}, 
  year={2024},
  volume={},
  number={},
  pages={1207-1210},
  abstract={This research study analyses the sentiments of people concerning Deepfakes on social and non-social media channels. The findings have been described after extracting social mentions from Brand24®, an AI social listening tool. The results have been documented through the volume of mentions, discussion contexts, Social and non-social media reach, most active and influential websites, hashtags trending during the month, and lastly, source of extractions. The study's findings depict that Deepfakes is not considered a positive concept as it attracted criticism among people, which is also reflected in social and non-social media platforms. These results shed light on the perception of people about Deepfakes while providing actionable insights for all the stakeholders. The unique aspect of the study is the selection of a topic in the News in recent times for numerous reasons. The findings of the current investigation would provide abundant inferences not only to advertisers and marketers but also to policymakers and society at large. In addition, media houses and academicians would also get significant insights on the concept of Deepfakes to enrich their understanding.},
  keywords={Deepfakes;Video on demand;Social networking (online);Communication systems;Voting;Blogs;Media;Web sites;Stakeholders;Artificial intelligence;Deepfakes;AI;Sentiment analysis;Social mentions;Brand24},
  doi={10.1109/ICESC60852.2024.10689970},
  ISSN={2996-5357},
  month={Aug},}@INPROCEEDINGS{1571426,
  author={Wu, Q. and McGinnity, T.M. and Prasad, G. and Bell, D.},
  booktitle={2005 IEEE International Conference on Systems, Man and Cybernetics}, 
  title={Evolving learning mechanism for a general computing network model}, 
  year={2005},
  volume={2},
  number={},
  pages={1914-1919 Vol. 2},
  abstract={In this paper, an evolving learning mechanism is proposed for general computing network model to make decisions in intelligent systems. The novel mechanism is performed by means of a set of computing cell operations such as self-generation, growth, self-division, and death. Under the mechanism, a computing network grows up to a mature network. A hidden cell in the network is defined as a condition matching-unit in response to a fuzzy sub-superspace in multiple-dimension input superspace. A sense-function is defined to represent connections from a hidden cell to input cells. The range and edge vagueness of the sense-function are determined by evolving learning mechanism when sample instances are presented to the network. This network is able to learn from a very few training instances to make decisions for unseen instances. The benchmark data sets from the UCI machine learning repository are applied to test the network and comparable results are obtained.},
  keywords={Learning systems;Computer networks;Neural networks;Information systems;Artificial intelligence;Intelligent systems;Intelligent networks;Evolution (biology);Intelligent robots;Neurons;Computing network model;evolving learning mechanism;intelligent system;decision-making},
  doi={10.1109/ICSMC.2005.1571426},
  ISSN={1062-922X},
  month={Oct},}@INPROCEEDINGS{9041811,
  author={Gannon, Dennis},
  booktitle={2019 15th International Conference on eScience (eScience)}, 
  title={The Research Assistant and AI in eScience}, 
  year={2019},
  volume={},
  number={},
  pages={458-462},
  abstract={This paper was solicited as a "vision" talk for the 2019 eScience conference. It is based on my assessment of the role AI will have on eScience in the years ahead. While machine learning methods are already being well integrated into computing practice, this paper will look at another area: the role AI will play as an assistant to our daily research work.},
  keywords={Cloud computing;Quantum computing;Neuromorphics;Programming;Robot sensing systems;Probabilistic logic;Supercomputers;Software;Web sites;Artificial intelligence;eScience;machine learning;bots;AI research assistant},
  doi={10.1109/eScience.2019.00059},
  ISSN={},
  month={Sep.},}@ARTICLE{10323272,
  author={Li, Chuanhui and Wang, Dawei},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={Blocky Impedance Inversion of Seismic Data Based on Semi-Supervised Learning Scheme}, 
  year={2024},
  volume={21},
  number={},
  pages={1-5},
  abstract={Semi-supervised learning scheme for seismic inversion uses less labeled data to obtain good inversion results of impedance values by using the forward process of seismic data as constraints. Considering the impedance with a blocky structure is helpful for subsequent interpretation and reservoir characterization, an adaptive edge-preserving smoothing (AEPS) filter was introduced into a closed-loop deep residual network (ResNet) structure. In the training process of the inverse subnet, by constructing a loss function of blocky-structure constraint using the filtered impedance by AEPS filter, the inverse subnet is updated to make the inverted impedance tend to be blocky. Both numerical tests and real data applications demonstrate that the semi-supervised learning scheme combined with AEPS filter can obtain ideal inversion results for impedance.},
  keywords={Impedance;Training;Convolution;Semisupervised learning;Smoothing methods;Data models;Artificial intelligence;Blocky structure;edge-preserving smoothing (EPS);seismic inversion;semi-supervised learning scheme},
  doi={10.1109/LGRS.2023.3334766},
  ISSN={1558-0571},
  month={},}@INBOOK{10952275,
  author={Ammanath, Beena},
  booktitle={Trustworthy AI: A Business Guide for Navigating Trust and Ethics in AI}, 
  title={Privacy}, 
  year={2022},
  volume={},
  number={},
  pages={127-145},
  abstract={Summary <p>The issue of privacy is most visceral when it comes to data about people. There are pressing matters for the nexus between AI, data, and privacy, but perhaps unsurprisingly, ethical questions around technology and privacy are nothing new. Ultimately, the ethical debate over creating and using AI that is respectful of privacy comes down to data control and access such that use of the data does not create harm to the individual. The data may already be pseudonymized and anonymized, but more than that, once an AI system is trained, it is difficult to untrain it. Regardless of laws and regulations, businesses have an interest in protecting consumer data and thinking through how the AI systems they deploy might impact the privacy of individuals. If people are to use AI to its greatest benefit, they need widespread trust, and that requires a focus on privacy.</p>},
  keywords={Artificial intelligence;Privacy;Data privacy;Ethics;Regulation;Monitoring;Government;Data models;Wearable devices;Translation},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781119867968},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10952275},}@INPROCEEDINGS{10991852,
  author={Lu, Huajian and Liang, Daili and Zhang, Yang and Gu, Liru and Yin, Wenxue and Xiao, Yanhui},
  booktitle={2024 IEEE 8th Conference on Energy Internet and Energy System Integration (EI2)}, 
  title={Research on Transformer Fault Diagnosis Method Based on Small Sample Voiceprint Recognition Technology}, 
  year={2024},
  volume={},
  number={},
  pages={5286-5290},
  abstract={As an important equipment in power system, it is very important to ensure the safe and stable operation of power transformer. The diagnosis effect of the fault is significantly affected by the quantity and quality of the fault voiceprint samples. However, the occurrence of transformer faults is a small probability event, the sample of abnormal state of equipment is scarce, and the density of data value is low, which makes it difficult for intelligent diagnosis algorithm to realize the effective diagnosis of transformer operation state under the condition of less data. Therefore, a transformer fault diagnosis method based on small sample voiceprint recognition technology is proposed, which has the advantage of not needing a lot of training data set. Firstly, according to the principle of voiceprint recognition technology, the Mel cepstrum features of transformer operation are extracted. Then, the fault voiceprint of the transformer is compared and classified by the small sample voiceprint recognition method. Finally, the analysis and verification are carried out under the measured data of a transformer factory. Compared with the traditional deep learning algorithm, the results show that the method has higher recognition accuracy, which is of great significance to engineering practice.},
  keywords={Fault diagnosis;Accuracy;Cepstrum;Training data;Speech recognition;Feature extraction;Production facilities;Power transformers;Artificial intelligence;Spectrogram;transformer;fault diagnosis;euclidean distance;small sample},
  doi={10.1109/EI264398.2024.10991852},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10635214,
  author={Shigeyasu, Yuki and Harada, Shota and Yoshizawa, Akihiko and Terada, Kazuhiro and Nakazima, Naoki and Kurata, Mariyo and Abe, Hiroyuki and Ushiku, Tetsuo and Bise, Ryoma},
  booktitle={2024 IEEE International Symposium on Biomedical Imaging (ISBI)}, 
  title={Domain Generalization for Pathological Images Using the Storage Period Information}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper brings attention to a new issue in the development of datasets for AI-based pathological image analysis: the domain shift problem stemming from the storage period until digital scanning. Pathological slides that were sliced and stained in the past may also be scanned to prepare a dataset for AI in addition to the newly stained tissue. However, it leads to changes in their appearance and causes domain shift. We propose a domain generalization method that leverages the storage period as sub-domains. Furthermore, we introduce the ordinal adversarial loss that can perform well for ordinal domain classes. The experiments show the effectiveness of using the storage period as a sub-domain and the ordinal adversarial loss.},
  keywords={Pathology;Image analysis;Hospitals;Shape;Image color analysis;Image storage;Artificial intelligence;Domain generalization;segmentation;WSI;deep learning},
  doi={10.1109/ISBI56570.2024.10635214},
  ISSN={1945-8452},
  month={May},}@INPROCEEDINGS{10751821,
  author={Das, Amrisha and Pal, Shubhangee and Das, Bhagyashree and Kaur, Preeti},
  booktitle={2024 IEEE Region 10 Symposium (TENSYMP)}, 
  title={FakeTweet Busters: A Combination of BERT and Deepfake Detection to Resolve the Spreading of Fake AI Generated News}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The spread of misinformation through social media, particularly fake tweets, poses a significant challenge. This work proposes a novel multimodal approach for detecting fake tweets, combining textual and visual analysis. We leverage the strengths of BERT, a pretrained transformer model, for comprehensive textual analysis, and VGG19, a convolutional neural network, for image feature extraction. Additionally, we incorporate deepfake detection to address manipulated visuals. For tweets containing both text and images, a multi-head self-attention mechanism effectively fuses the textual and visual features extracted by BERT and VGG19, respectively. This combined approach aims to achieve superior accuracy in identifying fake tweets compared to methods solely focused on text or image.},
  keywords={Visualization;Deepfakes;Image resolution;Social networking (online);Fuses;Feature extraction;Transformers;Convolutional neural networks;Artificial intelligence;IEEE Regions;BERT;Deepfake;feature extraction;attention mechanism;SVM;CNN},
  doi={10.1109/TENSYMP61132.2024.10751821},
  ISSN={2642-6102},
  month={Sep.},}@INPROCEEDINGS{10969893,
  author={Somyaji, Aadhish D and Surakasi, Lasya and Puranik, Aditya and Kannan, Devi and Kumar B P, Pradeep and Kumar, Ravi},
  booktitle={2025 International Conference on Computing for Sustainability and Intelligent Future (COMP-SIF)}, 
  title={Melody Mixer: Novel Music Generation by Mixing Styles with Variational Autoencoders}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper introduces a hybrid algorithmic frame-work that merges Long Short-Term Memory (LSTM) networks, Genetic Algorithms (GA), Harmony Search (HS), and Cuckoo Search (CS) for detecting flaws in Computer Numerical Control (CNC) milling automatically. LSTM networks are used for processing time-series data, while GA optimizes hyperparameters to enhance accuracy. Efficient feature extraction and overall optimization search benefit from the use of HS and CS. The hybrid approach addresses challenges in real-time defect detection by surpassing individual models in metrics like accuracy, precision, recall, and mean squared error (MSE). In CNC milling, this minimizes interruptions and enhances production excellence. The study aims to optimize real-time flaw detection in CNC milling by utilizing a combination of LSTM-GA and HS-CS algorithms. The project's goal is to achieve accurate and efficient defect classification by utilizing HS-CS for global search and feature selection, with minimal human involvement and production delay. The goal is to demonstrate how hybrid algorithms improve defect detection efficiency and reduce error rates, leading to precise and automated CNC milling solutions. HS and CS are used to select features and perform a global search, while LSTM is integrated into the model to analyze time-series data, and GA is employed to optimize hyperparameters. Accuracy, precision, recall, F1 score, and MSE are metrics utilized for evaluating performance. The hybrid LSTM-GA and HS-CS model outperformed individual approaches with 97.5% accuracy, 96.3% precision, 94.5% recall, and an F1 score of 0.954, which is equal to its MSE. This combination method is suitable for real-time industrial automation tasks as it enhances fault detection in CNC milling, reducing errors and enhancing precision.},
  keywords={Technological innovation;Accuracy;Music;Milling;Real-time systems;Artificial intelligence;Computer numerical control;Long short term memory;Genetic algorithms;Defect detection;Defect Detection;LSTM-GA;CNC Milling;Genetic Algorithms;HS-CS Time- Series Data Optimization},
  doi={10.1109/COMP-SIF65618.2025.10969893},
  ISSN={},
  month={March},}@INPROCEEDINGS{11020101,
  author={Prathibha, Soma and Shree, B. Sharanya and Narmatha, K.},
  booktitle={2025 International Conference on Computing and Communication Technologies (ICCCT)}, 
  title={Detecting Deepfakes: An Analysis of Modern Approaches}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Deepfakes refer to real-life but entirely fabricated images, videos, or audio generated using advanced AI techniques. The misuse of such technology to spread false information, tarnish reputations, or manipulate audiences presents risks to security, privacy, and public confidence. A real-life case study of a 2018 deepfake video involving a well-known figure in the tech world demonstrated the dangers of misinformation. The manipulated video, falsely portraying him discussing personal control over data, spread widely on social media, raising significant concerns over privacy and trust. This paper reviews the various deepfake detection systems, highlighting the techniques, datasets, and methodologies employed to identify and prevent deepfakes. It also explores the effectiveness, limitations, and future of these detection systems.},
  keywords={Deepfakes;Privacy;Data privacy;Social networking (online);Reviews;Communications technology;Security;Artificial intelligence;Deepfakes;fabricated;manipulate},
  doi={10.1109/ICCCT63501.2025.11020101},
  ISSN={2995-3197},
  month={April},}@INPROCEEDINGS{11089187,
  author={Appavu, Narenthirakumar},
  booktitle={2025 6th International Conference on Recent Advances in Information Technology (RAIT)}, 
  title={Skin Cancer Detection Using A Multi-Scale AI Deep Learning CNN Techniques}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Skin cancer, of which melanoma is the deadliest type, is becoming more common. To stop it from spreading to other areas of the body, early detection is essential. This work reduces the need for medical intervention by introducing an automated method for detecting skin cancer. To detect melanoma lesions, the suggested approach uses transfer learning. The obtained photos are first pre-processed to minimize noise and illumination fluctuations. Image augmentation, a crucial deep learning approach, is used to improve the dataset and increase the training efficiency by producing more training samples. In order to create a Convolutional Neural Network (CNN), transfer learning is then applied by utilizing pre-trained weights using the ImageNet dataset. The network is optimized to detect melanoma and differentiate the item from benign tumors. The three main stages of the methodology focus on examining the image’s center, which is thought to be the location of the suspected lesion. A neural network that is entirely linked is trained using the combined outputs of these stages. On a test dataset, the suggested approach outperformed state-of-the-art methods, attaining an accuracy of 90.09%. This method offers a more precise and trustworthy diagnosis by focusing on the questionable skin area at several stages.},
  keywords={Deep learning;Training;Accuracy;Transfer learning;Melanoma;Data augmentation;Skin;Convolutional neural networks;Lesions;Artificial intelligence;AI Deep learning;Skin cancer;CNN;melanoma;Transfer learning},
  doi={10.1109/RAIT65068.2025.11089187},
  ISSN={2994-287X},
  month={March},}@INPROCEEDINGS{10912535,
  author={Toujani, Imen and Singer, Nicolas and Megdiche, Imen and Alacoque, Xavier},
  booktitle={2024 IEEE/ACS 21st International Conference on Computer Systems and Applications (AICCSA)}, 
  title={Indoor Geolocation Demonstrator: Enhancing Efficiency Through Real-Time Tracking and AI Optimization}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The integration of indoor geolocation technologies within hospital environments presents a significant opportunity to understand circulation patterns, identify congestion areas, and optimize care processes. In this paper, we propose a complete framework of indoor geolocation solutions tailored to hospital settings, aiming to understand circulation patterns, identify congestion areas, and optimize care processes. The framework includes the development and deployment of ESP32-based devices to capture MAC addresses via BLE and WiFi sniffing, and the use of AI models to predict the tracking speed of these addresses. Our results demonstrate improved patient flow management and enhanced care coordination through real-time tracking and data analysis.},
  keywords={Protocols;Tracking;Hospitals;Geology;Refining;Predictive models;Real-time systems;Resource management;Artificial intelligence;Wireless fidelity;indoor geolocation;ESP32;MAC addresses;BLE;WiFi;hospital;patient flow management},
  doi={10.1109/AICCSA63423.2024.10912535},
  ISSN={2161-5330},
  month={Oct},}@INPROCEEDINGS{11133616,
  author={Spantzel, Arnold and Spantzel, Adelheid},
  booktitle={2025 Silicon Valley Cybersecurity Conference (SVCC)}, 
  title={Specialized Language Models for Combating Audio and Video Spam}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The rise in spam calls—both audio and video—poses significant risks to users. Recent studies indicate a dramatic increase in AI-generated voices and deepfake videos designed to deceive and compromise security. AI-driven impersonation attacks account for losses of over $10 billion annually, and nearly 60% of victims are deceived by highly realistic synthetic voices or videos. This paper presents a novel AI-powered framework for real-time spam detection and prevention. Our system combines Natural Language Processing (NLP) and deep learning techniques to analyze conversational content and context, detecting suspicious behaviors such as requests for sensitive information including gift card payments or PIN numbers. These insights trigger runtime alerts that protect users from fraudulent interactions.To further enhance security, we introduce advanced methods for detecting machine-generated content and verifying human liveness. Techniques such as anomaly detection for voice modulation, deepfake video frame analysis, and semantic evaluation of conversational patterns help differentiate authentic human interactions from AI-generated impersonations. Additionally, the system leverages scalable distributed AI models and Specialized Language Models (SLMs) optimized for conversational intent and media integrity analysis. This distributed approach ensures real-time detection with minimal latency, making it suitable for large-scale deployments across diverse communication platforms.This paper elaborates on the system architecture, the role of distributed AI, and the underlying techniques used to enable this solution. Experimental evaluations demonstrate the efficacy of our approach in identifying and mitigating evolving spam threats while maintaining performance at scale.},
  keywords={Deepfakes;Analytical models;Runtime;Prevention and mitigation;Semantics;Systems architecture;Real-time systems;Natural language processing;Pins;Artificial intelligence},
  doi={10.1109/SVCC65277.2025.11133616},
  ISSN={},
  month={June},}@ARTICLE{11088135,
  author={Hu, Mingzhi and Wang, Hongxia},
  journal={IEEE Signal Processing Letters}, 
  title={Directional Adversarial Noise-Based Universal Steganalysis Method for Detecting Adversarial Steganography}, 
  year={2025},
  volume={32},
  number={},
  pages={3002-3006},
  abstract={Adversarial steganography presents a significant challenge in digital media security, leveraging adversarial perturbations to obscure steganographic patterns and evade detection by traditional steganalysis methods. This paper proposes a universal detection method based on Directional Adversarial Noise Search (DANS) to improve the robustness of steganalysis against adversarial steganography. Specifically, an augmentation network is employed to generate adversarial noise distributions, guided by a novel DANS loss function that enables precise optimization of noise distribution. A threshold constraint is further applied to ensure the controllability of the generated noise. By embedding the generated perturbations into both cover and stego images, a robust augmented dataset is constructed to improve detection performance. Experimental results demonstrate that the proposed method improves detection accuracy across various adversarial steganography techniques, achieving up to a 17.14% increase. Moreover, it exhibits superior generalization ability in cross-dataset evaluations, highlighting its effectiveness and robustness in diverse scenarios.},
  keywords={Noise;Training;Steganography;Perturbation methods;Accuracy;Data augmentation;Robustness;Deep learning;Data mining;Artificial intelligence;Steganalysis;adversarial steganography;data augmentation;deep learning},
  doi={10.1109/LSP.2025.3591728},
  ISSN={1558-2361},
  month={},}@INPROCEEDINGS{10809893,
  author={Yu, Qingguang and Liu, Ding and Zhang, Yu and Yao, Xin and Yuan, Leidong and Wang, Long and Ma, Xiyue and Zhao, Haoran},
  booktitle={2024 7th International Conference on Renewable Energy and Power Engineering (REPE)}, 
  title={Research on Online Pictures Recognition of Fault Scenario for Power Supply Reliability Management Based on Improved AI Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={190-194},
  abstract={Data is the foundation of power supply reliability management and is used throughout the reliability management process. However, in the process of data management, manual data supplementation is still dominant, which greatly restricts the efficiency of data transmission, and at the same time there are certain problems with its accuracy and completeness. For this purpose, online reliability management can be utilized to identify and archive pictures or videos of faulty equipment. In this paper, based on YOLOv8, adopted DCNv3 and put forward the novel global attention mechanism to improve the performance, which improves the recognition accuracy, and meets the requirements of online reliability management after dataset testing.},
  keywords={Fault diagnosis;Training;Accuracy;Attention mechanisms;Power supplies;Reliability engineering;Management;Power system reliability;Artificial intelligence;Videos;online pictures recognition;fault scenario;power supply reliability management;AI algorithm},
  doi={10.1109/REPE62578.2024.10809893},
  ISSN={2771-7011},
  month={Sep.},}@INPROCEEDINGS{11008397,
  author={Samofalov, Andrii and Polak, Ladislav},
  booktitle={2025 35th International Conference Radioelektronika (RADIOELEKTRONIKA)}, 
  title={On the Visual Quality of AI and non-AI Images Compressed by Different Autoencoders}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Image compression using deep learning (DL) techniques is an emerging and rapidly evolving field. This approach has the potential to enhance image compression by learning complex patterns and representations from data, enabling higher compression ratios while maintaining high image quality. Unlike conventional compression methods, which rely on predefined algorithms, DL models can adapt and optimize compression based on the specific content of an image. This paper provides a comparison-based study of the two autoencoder models (dense and convolutional), commonly used in DL models for image compression. The comparison is based on objective metrics applied to human-made images from a publicly available database and AI-generated images to evaluate the quality of compressed images. The results obtained show that the autoencoders differ in terms of the visual quality of the reconstructed images.},
  keywords={Measurement;Image quality;Deep learning;Visualization;Adaptation models;Image coding;Databases;Autoencoders;Artificial intelligence;Image reconstruction;image compression;deep learning;autoencoder;AI-generated image;objective metric;image quality},
  doi={10.1109/RADIOELEKTRONIKA65656.2025.11008397},
  ISSN={2767-9969},
  month={May},}@INPROCEEDINGS{11101371,
  author={Ali, Sohrab and Sharma, Sameer Dev},
  booktitle={2025 International Conference on Electronics, AI and Computing (EAIC)}, 
  title={Analyzing and Classifying Mango Leaf Diseases Using Advanced Image Processing and Deep Learning Techniques}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={The performance of several deep learning models for classification tasks is thoroughly assessed in this paper, with an emphasis on contrasting conventional architectures with a suggested hybrid model. DenseNet121, VGG19, ResNet50, InceptionV3, AlexNet, MobileNetV2, and EfficientNetV are among the models that were evaluated using important metrics like accuracy, precision, recall, and F1-score. The most balanced and successful model overall was DenseNet121, which outperformed the baseline models with the maximum accuracy of 95.33% and a perfect recall of 1.00. Additionally, ResNet50 and VGG19 performed well, each obtaining an F1-score of 0.95. With a precision score of 0.96, the suggested hybrid model was the most notable, demonstrating its potent capacity to lower false positives. Nevertheless, its F1-score (0.91) was marginally affected by its somewhat poorer recall (0.88). Even yet, the hybrid model showed that mixing different architectures can result in improved performance and exceeded some standard models in terms of overall accuracy (91.66%). The findings demonstrate that although hybrid approaches can capitalize on complementary assets to attain competitive outcomes, traditional models continue to be formidable competitors. For deep learning model selection and design, this comparison provides insightful information, particularly for applications that need high precision and balanced performance across evaluation measures.},
  keywords={Deep learning;Measurement;Accuracy;Image processing;Computational modeling;Computer architecture;Artificial intelligence;Standards;Residual neural networks;Diseases;Deep Learning;mango leaf diseases;image processing},
  doi={10.1109/EAIC66483.2025.11101371},
  ISSN={},
  month={June},}@INPROCEEDINGS{9419343,
  author={Numan, Nels and Haar, Frank ter and Cesar, Pablo},
  booktitle={2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, 
  title={Generative RGB-D Face Completion for Head-Mounted Display Removal}, 
  year={2021},
  volume={},
  number={},
  pages={109-116},
  abstract={Head-mounted displays (HMDs) are an essential display device for the observation of virtual reality (VR) environments. However, HMDs obstruct external capturing methods from recording the user’s upper face. This severely impacts social VR applications, such as teleconferencing, which commonly rely on external RGB-D sensors to capture a volumetric representation of the user. In this paper, we introduce an HMD removal framework based on generative adversarial networks (GANs), capable of jointly filling in missing color and depth data in RGB-D face images. Our framework includes an RGB-based identity loss function for identity preservation and several components aimed at surface reproduction. Our results demonstrate that our framework is able to remove HMDs from synthetic RGB-D face images while preserving the subject’s identity.},
  keywords={Head-mounted displays;Three-dimensional displays;Image color analysis;Conferences;Resists;Virtual reality;User interfaces;Computing methodologies;Artificial intelligence;Computer vision;Reconstruction;Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Virtual reality},
  doi={10.1109/VRW52623.2021.00028},
  ISSN={},
  month={March},}@ARTICLE{10460339,
  author={Wang, Mengyan and Hu, Yuxuan and Wu, Shiqing and Li, Weihua and Bai, Quan and Yuan, Zihan and Jiang, Chenting},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Nudging Toward Responsible Recommendations: A Graph-Based Approach to Mitigate Belief Filter Bubbles}, 
  year={2025},
  volume={6},
  number={2},
  pages={378-392},
  abstract={Personalized recommendation systems homogenize user preferences, causing an extreme belief imbalance and aggravating user bias. This phenomenon is known as the filter bubble. This article presents the responsible graph-based recommendation (RGRec) system, designed to alleviate the filter bubble effect in personalized recommendation systems. Acting as an intermediate agency between users and existing preference-based recommendation systems, RGRec is composed of three collaborative modules: the multifaceted reasoning-based filter bubbles detection (FBDetect) module, the belief nudging module, and the generative artificial intelligence (GAI)-based recommendation strategy generation module (RecomGen). The FBDetect module identifies users with extreme belief imbalances based on their belief networks, which are represented as heterogeneous graphs. These graphs are then utilized in the Belief Nudging module, where a nudging strategy is employed to adapt prompts for the RecomGen module. Ultimately, the RecomGen module generates contextually rich items for recommendations. Experimental results demonstrate that RGRec can promote diverse content exploration based on user feedback and progressively stimulate interest in topics users initially showed less interest in, encouraging individual exploration.},
  keywords={Recommender systems;Information filters;Filtering algorithms;Artificial intelligence;Behavioral sciences;Filtering theory;Measurement;Belief harmony;filter bubble;nudge theory;responsible recommendation systems},
  doi={10.1109/TAI.2024.3373392},
  ISSN={2691-4581},
  month={Feb},}@INPROCEEDINGS{10800920,
  author={Yang, Zhiyuan and Li, Pei and Wang, Chengwei and Ten, Chee-Wooi},
  booktitle={2024 3rd Asian Conference on Frontiers of Power and Energy (ACFPE)}, 
  title={Scenario-based Emission Simulations Using Time-Series Generative Adversarial Networks}, 
  year={2024},
  volume={},
  number={},
  pages={83-90},
  abstract={Integrating carbon emissions accounting with data analytics in electricity generation is essential for achieving sustainability goals and managing risks, supporting global decarbonization efforts. This paper investigates the spatiotemporal correlation of coupling data using a sampling method with a time-variant generative architecture, producing synthetic time-relevant emissions to address the scarcity and inaccuracy of raw data. The proposed evaluation framework, the Coupling Error Ratio Matrix (CERM), offers an intuitive representation of the coupled flow of power and carbon emission scenarios and provides analytical foundations for learning and training optimizations by identifying aggregated features with specific indicators. The evaluation method is initially validated using the IEEE 118-bus system. Additionally, the scalability and efficiency of the framework are confirmed using the power grid of Hainan province in China and photovoltaic generation outputs.},
  keywords={Couplings;Training;Photovoltaic systems;Scalability;Carbon dioxide;Sampling methods;Power grids;Systems simulation;Spatiotemporal phenomena;Sustainable development;Artificial intelligence;carbon emissions;data engineering;information retrieval;power system simulation},
  doi={10.1109/ACFPE63443.2024.10800920},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11157971,
  author={Zhang, Huiyu and Jie Teo, Bryan Zheng and Hua Goh, Ester Gue and Subramaniyan, Kalyankumar and Lee, Kok Hian},
  booktitle={2025 5th International Conference on Artificial Intelligence and Education (ICAIE)}, 
  title={Exploring Student Engagement and Personalized Learning with a Retrieval-Augmented Generation (RAG) Chatbot}, 
  year={2025},
  volume={},
  number={},
  pages={134-140},
  abstract={Students have become increasingly familiar with ChatGPT, a generative artificial intelligence chatbot that offers users quick access to information, engages them through dynamic question-and-answer interactions and provides feedback on tasks. However, a key challenge with ChatGPT in education is its propensity to hallucinate, which can affect learning outcomes. To address this, the TP AI Assistant, a Retrieval-Augmented Generation (RAG)-based chatbot, was developed to provide a safer and more structured online learning environment. Unlike ChatGPT, which generates broad and diverse responses, the TP AI Assistant focuses on delivering accurate and relevant information aligned with specific learning objectives. This ensures students receive content that aligns with their subject requirements. The TP AI Assistant was rolled out to approximately 600 Year 1 students and 600 Year 2 students from the same academic school at a public polytechnic in Singapore. Before triangulating with student perceptions, it is essential to establish a foundational understanding of their engagement patterns and learning behaviors through factual, unbiased logs. This study thus investigates how students interacted with this RAG-based chatbot and how its structured design supported self-regulated learning (SRL). Additionally, the study examines the strengths and limitations of using the RAG approach for personalizing student learning. Findings will provide insights into how a RAG-based chatbot can enhance learning experiences and better meet students' expectations.},
  keywords={Surveys;Visualization;Accuracy;Scalability;Retrieval augmented generation;Education;Learning (artificial intelligence);Chatbots;Reliability;Investment;chatbot;personalized learning;retrieval-augmented generation (RAG);self-regulated learning},
  doi={10.1109/ICAIE64856.2025.11157971},
  ISSN={},
  month={May},}@INBOOK{10954550,
  author={D&#xfc;ring, Serjoscha and Koenig, Reinhard and Khean, Nariddh and Elshani, Diellza and Galanos, Theodoros and Chronis, Angelos},
  booktitle={Machine Learning and the City: Applications in Architecture and Urban Design}, 
  title={Machine Learning, Artificial Intelligence, and Urban Assemblages}, 
  year={2022},
  volume={},
  number={},
  pages={445-452},
  abstract={<p>Recent advances in generative design, simulation, computational optimisation, and machine learning opened up possibilities in employing data&#x2010;driven workflows to achieve design solutions of unprecedented performance. This chapter showcases generative methods for urban spatial configurations that integrate a number of different simulation engines, along with InFraRed, into one framework. This allows us to quickly explore thousands of urban design alternatives by generating a diverse and informative design and performance data set. Conceptional InFraRed is rooted in the paradigm of cognitive design computing, which emphasises an almost symbiotic relationship between computational methods and human interaction. Performance evaluation methods of urban spaces, either by generating synthetic data or using real&#x2010;world data, becomes more meaningful and interpretable when correlated with design configuration indicators. The InFraRed web platform currently offers a few selected services; however, further services will be included in the near future.</p>},
  keywords={Space exploration;Optimization;Measurement;Engines;Computational modeling;Buildings;Real-time systems;Pedestrians;Key performance indicator;Wind forecasting},
  doi={10.1002/9781119815075.ch32},
  ISSN={},
  publisher={Wiley},
  isbn={9781119749585},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10954550},}@INBOOK{10953005,
  author={Xiao, Perry},
  booktitle={Artificial Intelligence Programming with Python: From Zero to Hero}, 
  title={Machine Learning}, 
  year={2022},
  volume={},
  number={},
  pages={53-116},
  abstract={Summary <p>Machine learning is basically a set of mathematical algorithms developed in the 1980s. Machine learning is an important subset of artificial intelligence, and it is the science that aims to teach computers, or machines, to learn from data and to analyze data automatically, without human intervention. Supervised learning can be used for classification and regression. Support vector machine is the best&#x2010;known supervised learning algorithm. Naive Bayes is another popular supervised learning algorithm, which applies Bayes' theorem with the naive assumption of the probabilities of features for a given dataset. Unsupervised learning is typically used for clustering and association. The most popular semi&#x2010;supervised learning algorithms include self&#x2010;training, generative methods, mixture models, and graph&#x2010;based methods. Reinforcement learning is widely used in robotics, video gaming, and navigation. A random forest is an ensemble learning algorithm that can be used for both classification and regression problems.</p>},
  keywords={Machine learning;Support vector machines;Supervised learning;Machine learning algorithms;Clustering algorithms;Classification algorithms;Artificial intelligence;Unsupervised learning;Libraries;Reinforcement learning},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781119820949},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10953005},}@ARTICLE{8066319,
  author={Long, Yang and Liu, Li and Shen, Fumin and Shao, Ling and Li, Xuelong},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Zero-Shot Learning Using Synthesised Unseen Visual Data with Diffusion Regularisation}, 
  year={2018},
  volume={40},
  number={10},
  pages={2498-2512},
  abstract={Sufficient training examples are the fundamental requirement for most of the learning tasks. However, collecting well-labelled training examples is costly. Inspired by Zero-shot Learning (ZSL) that can make use of visual attributes or natural language semantics as an intermediate level clue to associate low-level features with high-level classes, in a novel extension of this idea, we aim to synthesise training data for novel classes using only semantic attributes. Despite the simplicity of this idea, there are several challenges. First, how to prevent the synthesised data from over-fitting to training classes? Second, how to guarantee the synthesised data is discriminative for ZSL tasks? Third, we observe that only a few dimensions of the learnt features gain high variances whereas most of the remaining dimensions are not informative. Thus, the question is how to make the concentrated information diffuse to most of the dimensions of synthesised data. To address the above issues, we propose a novel embedding algorithm named Unseen Visual Data Synthesis (UVDS) that projects semantic features to the high-dimensional visual feature space. Two main techniques are introduced in our proposed algorithm. (1) We introduce a latent embedding space which aims to reconcile the structural difference between the visual and semantic spaces, meanwhile preserve the local structure. (2) We propose a novel Diffusion Regularisation (DR) that explicitly forces the variances to diffuse over most dimensions of the synthesised data. By an orthogonal rotation (more precisely, an orthogonal transformation), DR can remove the redundant correlated attributes and further alleviate the over-fitting problem. On four benchmark datasets, we demonstrate the benefit of using synthesised unseen data for zero-shot learning. Extensive experimental results suggest that our proposed approach significantly outperforms the state-of-the-art methods.},
  keywords={Semantics;Visualization;Training;Data models;Predictive models;Training data;Zero-shot learning;data synthesis;diffusion regularisation;visual-semantic embedding;object recognition},
  doi={10.1109/TPAMI.2017.2762295},
  ISSN={1939-3539},
  month={Oct},}@ARTICLE{8590804,
  author={Chang, Jianlong and Meng, Gaofeng and Wang, Lingfeng and Xiang, Shiming and Pan, Chunhong},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Deep Self-Evolution Clustering}, 
  year={2020},
  volume={42},
  number={4},
  pages={809-823},
  abstract={Clustering is a crucial but challenging task in pattern analysis and machine learning. Existing methods often ignore the combination between representation learning and clustering. To tackle this problem, we reconsider the clustering task from its definition to develop Deep Self-Evolution Clustering (DSEC) to jointly learn representations and cluster data. For this purpose, the clustering task is recast as a binary pairwise-classification problem to estimate whether pairwise patterns are similar. Specifically, similarities between pairwise patterns are defined by the dot product between indicator features which are generated by a deep neural network (DNN). To learn informative representations for clustering, clustering constraints are imposed on the indicator features to represent specific concepts with specific representations. Since the ground-truth similarities are unavailable in clustering, an alternating iterative algorithm called Self-Evolution Clustering Training (SECT) is presented to select similar and dissimilar pairwise patterns and to train the DNN alternately. Consequently, the indicator features tend to be one-hot vectors and the patterns can be clustered by locating the largest response of the learned indicator features. Extensive experiments strongly evidence that DSEC outperforms current models on twelve popular image, text and audio datasets consistently.},
  keywords={Task analysis;Unsupervised learning;Training;Clustering methods;Pattern analysis;Clustering;deep self-evolution clustering;self-evolution clustering training;deep unsupervised learning},
  doi={10.1109/TPAMI.2018.2889949},
  ISSN={1939-3539},
  month={April},}@INBOOK{10880571,
  author={Gurung&#x2020;, Kusum and Mishra&#x2020;, Saurav K. and Chhetri, Tabsum and Roy, Sneha and Balakrishnan, Anagha and Georrge*, John J.},
  booktitle={Generative Artificial Intelligence for Biomedical and Smart Health Informatics}, 
  title={Recent Knowledge in Drug Design and Development: Automation and Advancement}, 
  year={2025},
  volume={},
  number={},
  pages={153-181},
  abstract={Summary <p>The traditional procedure of drug finding and its progress is arduous and laborious. With the introduction of automation, the process has been streamlined, significantly enhancing efficiency and accelerating drug development. Numerous pharmaceutical companies utilize one of the earliest recognized automation techniques for drug development, high&#x2010;throughput screening, to monitor dozens of molecules for their biological activity. Furthermore, automation has led to a significant impact in medicinal chemistry for designing, synthesizing, and optimizing novel drug compounds, and also numerous algorithms are now used to forecast the features and actions of millions of compounds, i.e., virtually enhancing novel drug discovery. Data integration and analysis play a vital character in automation. With the increasing amount of biological data, appropriate statistical methods are required to predict valid models, and the use of machine learning techniques and artificial intelligence is vital. Automation and advancement have significantly enhanced the drug discovery process, but it has faced several challenges in generating bulk amounts of data. Therefore, understanding the evolving knowledge in drug design and development advancements and automation is crucial. Therefore, this study aims to provide brief knowledge about automation and advancement of the drug discovery process. Successful studies are also discussed, which can help understand how the research communities in drug discovery use the application algorithms.</p>},
  keywords={Drugs;Automation;Predictive models;High-temperature superconductors;Biology;Data models;Chemicals;Libraries;Lead;Drug discovery},
  doi={10.1002/9781394280735.ch9},
  ISSN={},
  publisher={IEEE},
  isbn={9781394280728},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10880571},}@ARTICLE{10962216,
  author={Kim, Yeonjun and Han, Kyung-Hoon and Park, Junsang and Hong, Sungwook},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Nighttime Ground Radar-Like Rainfall Estimation Using Virtual Visible and Near-Infrared and Real Infrared Bands of Advanced Meteorological Imager}, 
  year={2025},
  volume={63},
  number={},
  pages={1-13},
  abstract={Rainfall rate (RR) retrieval methods using visible (VIS), near-infrared (NIR), and infrared (IR) bands from geostationary (GEO) meteorological satellites often achieve higher accuracy compared to methods relying solely on IR bands. These methods, however, face limitations for nighttime applications. This study aims to introduce an artificial intelligence (AI)-based approach for nighttime RR retrieval using actual IR observations and virtual nighttime VIS (0.47, 0.51, and  $0.86~\mu $ m) and NIR (1.37 and  $1.61~\mu $ m) bands data generated through an adversarial data-to-data (D2D) translation method. The study focuses on the Korean Peninsula and employs paired observational datasets from the Advanced Meteorological Imager (AMI) on GEO-KOMPSAT-2A (GK2A) and hybrid surface rainfall (HSR) data from ground weather radars as input and target domains for the D2D model. The study generates virtual D2D-generated (DG) VIS and NIR band data and evaluates DG-RR using only IR bands during nighttime. Results indicate that DG-RR using virtual AMI VIS, NIR, and real AMI IR bands demonstrates superior quantitative and qualitative statistical scores compared to DG-RR based solely on the AMI IR band data. This improvement is observed over traditional algorithm-based GK2A AMI RR and precipitation estimation from remotely sensed information using artificial neural networks (PERSIANNs); thus, this study underscores the potential of using virtual AI-based VIS and NIR band data, resembling actual observations, in RR estimation and various satellite remote sensing applications.},
  keywords={Satellites;Rain;Radar;Artificial intelligence;Sensors;Device-to-device communication;Data models;Spaceborne radar;Estimation;Accuracy;Advanced Meteorological Imager (AMI);data-to-data (D2D) translation;GEO-KOMPSAT-2A (GK2A);nighttime;rainfall estimation (RE);satellite remote sensing;virtual data},
  doi={10.1109/TGRS.2025.3559686},
  ISSN={1558-0644},
  month={},}@ARTICLE{9201109,
  author={Gong, Yu and Shan, Hongming and Teng, Yueyang and Tu, Ning and Li, Ming and Liang, Guodong and Wang, Ge and Wang, Shanshan},
  journal={IEEE Transactions on Radiation and Plasma Medical Sciences}, 
  title={Parameter-Transferred Wasserstein Generative Adversarial Network (PT-WGAN) for Low-Dose PET Image Denoising}, 
  year={2021},
  volume={5},
  number={2},
  pages={213-223},
  abstract={Due to the widespread of positron emission tomography (PET) in clinical practice, the potential risk of PET-associated radiation dose to patients needs to be minimized. However, with the reduction in the radiation dose, the resultant images may suffer from noise and artifacts that compromise diagnostic performance. In this article, we propose a parameter-transferred Wasserstein generative adversarial network (PT-WGAN) for low-dose PET image denoising. The contributions of this article are twofold: 1) a PT-WGAN framework is designed to denoise low-dose PET images without compromising structural details and 2) a task-specific initialization based on transfer learning is developed to train PT-WGAN using trainable parameters transferred from a pretrained model, which significantly improves the training efficiency of PT-WGAN. The experimental results on clinical data show that the proposed network can suppress image noise more effectively while preserving better image fidelity than recently published state-of-the-art methods. We make our code available at https://github.com/90n9-yu/PT-WGAN.},
  keywords={Three-dimensional displays;Two dimensional displays;Convolution;Positron emission tomography;Noise reduction;Deconvolution;Biomedical imaging;Deep learning;image quality;low-dose positron emission tomography (PET);task-specific initialization;transfer learning},
  doi={10.1109/TRPMS.2020.3025071},
  ISSN={2469-7303},
  month={March},}@ARTICLE{10478974,
  author={Peng, Chunlei and Miao, Zimin and Liu, Decheng and Wang, Nannan and Hu, Ruimin and Gao, Xinbo},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Where Deepfakes Gaze at? Spatial–Temporal Gaze Inconsistency Analysis for Video Face Forgery Detection}, 
  year={2024},
  volume={19},
  number={},
  pages={4507-4517},
  abstract={With the continuous development of generative models on face generation, how to distinguish the real and fake face has become an important problem for security. Because of the continuous improvement on the detection accuracy by facial physiological signals, video face forgery detection based on facial physiological signal analysis has received more and more attention, which has become an important research branch in the field of face forgery detection. Currently, most of the research on forgery detection based on physiological signal analysis use biometric features such as blinking patterns, head swings, heart rate signals, and lip movements. However, there hasn’t been much exploration on the usage of gaze features in face forgery detection. Through the analysis of gaze directions in face videos, we have observed differences in the distribution of gaze direction pattern between the real and forged videos. Specifically, real videos tend to have more concentrated gaze distribution within a short period of time, while forged videos have more dispersed gaze distributions. In this paper, we present a novel Deepfake gaze analysis method named DFGaze, to explore spatial-temporal gaze inconsistency for video face forgery detection. Our method uses the gaze analysis model (GAM) to analyze the gaze features of face video frames, and then applies a spatial-temporal feature aggregator to realize authenticity classification based on gaze features. In order to better mine the authenticity clues in the videos, we further use the texture analysis model (TAM) and attribute analysis model (AAM) to improve the representation ability of spatial-temporal feature differences between real and forged faces. Extensive experiments show that our method can achieve state-of-the-art performance with the help of gaze analysis. The source code is available at https://github.com/ziminMIAO/DFGaze.},
  keywords={Forgery;Faces;Feature extraction;Deepfakes;Face recognition;Physiology;Analytical models;Face forgery detection;physiological signals;gaze features;attribute features;texture features},
  doi={10.1109/TIFS.2024.3381823},
  ISSN={1556-6021},
  month={},}@INPROCEEDINGS{9070954,
  author={Chang, Daniel and Chang, David and Pourhomayoun, Mohammad},
  booktitle={2019 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Risk Prediction of Critical Vital Signs for ICU Patients Using Recurrent Neural Network}, 
  year={2019},
  volume={},
  number={},
  pages={1003-1006},
  abstract={Monitoring vital signs for Intensive Care Unit (ICU) patients is an absolute necessity to help assess the general physical health. In this research, we use machine learning to make a classification forecast that uses continuous ICU vital signs measurements to predict whether the vital signs of the next hour would reach the critical value or not. With the early warning, nurses and doctors can prevent emergency situations that may cause organ dysfunction or even death before it is too late. In this study, the data includes vital sign measurements, laboratory test results, procedures, medications collected from over 40,000 patients. After data preprocessing, bias data balancing, feature extraction, and feature selection, we have a clean dataset with informative and discriminating features. Then, various machine learning algorithms including Random Forest, XGBoost, Artificial Neural Networks (ANN), and LSTM were developed to predict critical vital signs of ICU patients 1-hour beforehand. We particularly developed predictive models to predict Heart Rate, Blood Oxygen Level (SpO2), Mean Arterial Pressure (MAP), Respiratory Rate (RR), Systolic Blood Pressure (SBP). The results demonstrated the accuracy of the developed methods.},
  keywords={Monitoring;Medical services;Biomedical monitoring;Recurrent neural networks;Predictive models;Heart rate;Blood pressure;Predictive Analytics;Vital Signs;ICU;Machine Learning},
  doi={10.1109/CSCI49370.2019.00191},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9540120,
  author={Shen, Tianyu and Gou, Chao and Wang, Jiangong and Huang, Jun and He, Yonglan and Xue, Huadan and Jin, Zhengyu and Wang, Fei-Yue},
  booktitle={2021 IEEE 1st International Conference on Digital Twins and Parallel Intelligence (DTPI)}, 
  title={Parallel Medical Imaging: An ACP-Based Approach for Intelligent Medical Image Recognition with Small Samples}, 
  year={2021},
  volume={},
  number={},
  pages={226-229},
  abstract={The deep learning methods trained with large-scale manually annotated datasets have led to significant breakthroughs in medical image community. However, obtaining such datasets remains a challenging work in medical domain. In this paper, we propose an ACP-based approach named parallel medical imaging (PMI) for analyzing and addressing the small sample problem of medical image recognition. Firstly, we present the basic framework and key techniques of PMI, in which the Artificial imaging systems are constructed to effectively augment the “medical small sample”, the Computational experiments are carried out for designing and evaluating the visual models trained with small samples, and the Parallel execution is conducted to achieve closed-loop interaction and optimization in the domain-knowledge guidance. Furthermore, we illustrate a preliminary implementation and application of PMI approach through the case study of mammogram analysis.},
  keywords={Deep learning;Visualization;Image recognition;Annotations;Digital twin;Conferences;Computational modeling;ACP;parallel medical imaging;medical image recognition;small sample;domain knowledge},
  doi={10.1109/DTPI52967.2021.9540120},
  ISSN={},
  month={July},}@ARTICLE{9446061,
  author={Grimmer, Marcel and Ramachandra, Raghavendra and Busch, Christoph},
  journal={IEEE Access}, 
  title={Deep Face Age Progression: A Survey}, 
  year={2021},
  volume={9},
  number={},
  pages={83376-83393},
  abstract={Face Age Progression (FAP) refers to synthesizing face images while simulating ageing effects, thus enabling predicting the future appearance of an individual. The generation of age-progressed face images brings benefits for various applications, ranging from face recognition systems to forensic investigations and digital entertainment. In particular, the recent success achieved with deep generative networks significantly leveraged the quality of age-synthesized face images in terms of visual fidelity, ageing accuracy and identity preservation. However, the high number of contributions in recent years requires systematically structuring new findings and ideas to identify a common taxonomy, accelerate future research and reduce redundancy. Therefore, we present a comparative analysis of recent deep learning based face age progression methods for both adult and child-based face ageing, broken down into three high-level concepts: translation-based, condition-based, and sequence-based FAP. Further, we offer a comprehensive summary of the most common performance evaluation techniques, cross-age datasets, and open challenges to steer future research in the right direction.},
  keywords={Face recognition;Aging;Faces;Skin;Deep learning;Biological system modeling;Robustness;Face age progression;semantic face editing;generative adversarial networks;biometrics},
  doi={10.1109/ACCESS.2021.3085835},
  ISSN={2169-3536},
  month={},}@ARTICLE{10480434,
  author={Gupta, Meenu and Kumar, Rakesh and Abraham, Ajith},
  journal={IEEE Access}, 
  title={Adversarial Network-Based Classification for Alzheimer’s Disease Using Multimodal Brain Images: A Critical Analysis}, 
  year={2024},
  volume={12},
  number={},
  pages={48366-48378},
  abstract={Alzheimer’s disease (AD) is a progressive neurodegenerative disorder that represents a significant and growing public health challenge. This work concisely summarizes AD, encompassing its pathophysiology, risk factors, clinical manifestations, diagnosis, treatment, and ongoing research. The main goal of managing AD is to reduce symptoms while improving the lives of those impacted. This letter has conducted a systematic review to analyze the prediction of AD using the Preferred Reporting Item for Systematic Review and Meta-Analysis (PRISMA) guidelines. The major scientific databases such as Scopus, Web of Science (WoS), and IEEE Xplorer are explored, where 2018–2023 publications are considered. The article selection process is based on keywords like “Alzheimer’s disease,” “Brain Images,” “Deep Learning (DL),” etc. After rigorous analysis, 946 articles were extracted, and 42 were identified for final consideration. Further, several investigations based on the previous work are discussed along with its Proposed Solutions (PS). Finally, a case study on AD detection using the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset and AD Detection Network (ADD-NET) implementation is presented.},
  keywords={Magnetic resonance imaging;Brain modeling;Feature extraction;Training;Computed tomography;Classification algorithms;Analytical models;Alzheimer's disease;Convolutional neural networks;Generative adversarial networks;Positron emission tomography;Biomarkers;Systematics;Alzheimer;brain images;convolutional neural network;generative adversarial network;machine learning;magnetic resonance imaging;positron emission tomography;biomarkers;P-TAU;amyloid beta;systematic review;meta-analysis},
  doi={10.1109/ACCESS.2024.3381956},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10940830,
  author={Singh, Harshpal and Kumar, Rakesh and Gupta, Meenu and Babu Chilluri, Venkata Suresh},
  booktitle={2025 International Conference on Pervasive Computational Technologies (ICPCT)}, 
  title={Detecting Digital Deception: A CNN-RNN hybrid Approach of Deepfake Detection}, 
  year={2025},
  volume={},
  number={},
  pages={667-672},
  abstract={Deepfake technology has forced digital deception to create high demand for detection tools. This paper presents an approach for deepfake video detection using Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) architecture that targets the artifacts present in the output from the generative models including Generative adversarial network (GAN). This approach looks at many strategies in terms of frames, among them for frame comparison, feature extraction based on CNNs, and for the purpose of temporal analysis CNN with long-short-term memory (LSTM) networks. The described model is trained on the set of the genuine vs. forged images and videos and demonstrates quite stable results with respect to digital forging detection. It is discovered that this proposed model achieves higher accuracy than previously used detection approaches in addressing face-swapping and face-reenactment deepfakes. The findings of this research demonstrate that CNN & RNN based deepfake detection is promising for media forensics, as it advances multimedia security and digital media credibility. This proposed method shows an accuracy of 81% in the Deepfake Detection Dataset (DFDS), respectively, with a very reduced number of sample size of ⩽ 100 samples(frames). This promises early detection of fake contents compared to existing modalities.},
  keywords={Deepfakes;Recurrent neural networks;Accuracy;Forensics;Machine learning;Streaming media;Generative adversarial networks;Convolutional neural networks;Security;Long short term memory;Deepfake Detection;Convolutional Neural Network (CNN);Digital Deception;Image Manipulation;Artificial Intelligence (AI);Machine Learning;Multimedia Forensics;Video Analysis;Face Recognition;Image Authentication},
  doi={10.1109/ICPCT64145.2025.10940830},
  ISSN={},
  month={Feb},}@ARTICLE{10965639,
  author={Liu, Yan and Chen, Xi and Lu, Zheng and Wu, Ziyue},
  journal={IEEE Access}, 
  title={Multiscale Structural Information-Based Laplacian Generative Adversarial Network Representation Learning}, 
  year={2025},
  volume={13},
  number={},
  pages={67966-67976},
  abstract={In recent years, network representation learning (NRL) has attracted increasing attention due to its efficiency and effectiveness to analyze network structural data. NRL aims to learn low-dimensional representations of nodes while preserving their structural information, and preserving multiscale structural information of nodes is important for NRL. Deep learning-based algorithms are popular owing to their good performance to learn network representations, but they lack sufficient interpretability as closed boxes. In this study, we propose a novel algorithm called Multiscale structural information-based Laplacian generative adversarial Network Representation Learning (MLNRL). This algorithm consists of two components: 1) multiscale structural information preserving component, where a shift positive pointwise mutual information matrix (SPPMI) is calculated for storing multiscale structural information; 2) Laplacian generative adversarial learning component, where the ideas of Laplacian pyramid and generative adversarial networks are leveraged to generate robust and meaningful representations. We apply our model to three downstream tasks on real-world datasets for evaluation, and the results show that our model outperforms the baselines in almost all cases. Then, we perform an ablation study and verified the necessity of both components. We also investigate the hyperparameter sensitivity to prove the robustness of MLNRL.},
  keywords={Laplace equations;Generative adversarial networks;Matrix decomposition;Representation learning;Mutual information;Generators;Dimensionality reduction;Classification algorithms;Vectors;Sparse matrices;Adversarial learning;Laplacian pyramid;network representation learning;shift positive pointwise mutual information matrix},
  doi={10.1109/ACCESS.2025.3561047},
  ISSN={2169-3536},
  month={},}
