@ARTICLE{10042182,
  author={Teng, Hu and Wang, Cheng and Yang, Qing and Chen, Xue and Li, Rui},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Leveraging Adversarial Augmentation on Imbalance Data for Online Trading Fraud Detection}, 
  year={2024},
  volume={11},
  number={2},
  pages={1602-1614},
  abstract={Nowadays, the emergence of online trading greatly facilitates people’s life. Meanwhile, online trading also brings hidden dangers, such as online fraudulent trading. To solve the issue, researchers have proposed many different detection models. However, in actual business scenarios, fraudulent transactions usually only account for a small portion of normal transactions, resulting in extremely imbalanced data. Besides, the concealment of fraud is reflected in that the fraudsters are imitating the normal transactions of users, posing a huge challenge for fraudulent transaction detection modeling. Inspired by generative adversarial networks (GANs), we propose a GAN-based framework to detect online banking fraud on extremely imbalanced data, called BalanceGAN. A fraud detection model is first pretrained using the data generated by the generator and then the model is fine-tuned using transfer learning on real-world datasets, by using this approach to address data imbalances. Compared with the conventional methods for solving imbalanced data, our BalanceGAN can avoid over-fitting of the model relatively, experiments on two real datasets show that our BalanceGAN has more than 10% performance improvement in Precision and Recall.},
  keywords={Fraud;Data models;Transfer learning;Generators;Biological system modeling;Training data;Generative adversarial networks;Fraud detection;generative adversarial networks (GANs);imbalanced data},
  doi={10.1109/TCSS.2023.3240968},
  ISSN={2329-924X},
  month={April},}@ARTICLE{9940286,
  author={Pan, Qingzhe and Zhao, Zhifu and Xie, Xuemei and Li, Jianan and Cao, Yuhan and Shi, Guangming},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={View-Normalized and Subject-Independent Skeleton Generation for Action Recognition}, 
  year={2023},
  volume={33},
  number={12},
  pages={7398-7412},
  abstract={Skeleton-based action recognition has attracted great interest in computer vision. For this task, a challenging problem concerns the large intraclass variances of skeleton data, which are mainly caused by diverse viewpoints and subjects, and greatly increase the difficulty of modeling actions through a network. To address the above problem, we propose a variance reduction (VaRe) framework for skeleton-based action recognition, which consists of a view-normalization generative adversarial network (VN-GAN), a subject-independent network (SINet) and a classification network. First, the VN-GAN is responsible for reducing view-induced intraclass variances. Specifically, this network, comprising a generator and a discriminator, is aimed at learning a mapping from a diverse-view skeleton distribution to a unified-view skeleton distribution in an unsupervised manner, thereby generating a view-normalized skeleton. Second, taking the view-normalized skeleton as input, the SINet focuses on reducing the influences of the personal habits of subjects on action recognition. To generate SI skeleton data, the SINet automatically adjusts the human pose according to the human kinematic structure under a classification loss constraint. Finally, without the interference of view- and subject-induced variances, the classification network can concentrate more on learning discriminative action features to predict classes. Furthermore, by combining the joint and bone modalities, the proposed framework achieves competitive performance on three benchmarks: NTU RGB+D, NTU-120 RGB+D and Northwestern-UCLA Multiview Action 3D.},
  keywords={Kinematics;Feature extraction;Data models;Spatiotemporal phenomena;Generative adversarial networks;Training;Skeleton-based action recognition;view-normalized;subject-independent;generative adversarial network;human kinematic structure},
  doi={10.1109/TCSVT.2022.3219864},
  ISSN={1558-2205},
  month={Dec},}@ARTICLE{10643547,
  author={Mohamed, Toka A. and Khafgy, Mohamed H. and Elsedawy, Ahmed B. and Ismail, Ahmed S.},
  journal={IEEE Access}, 
  title={A Proposed Model for Distinguishing Between Human-Based and ChatGPT Content in Scientific Articles}, 
  year={2024},
  volume={12},
  number={},
  pages={121251-121260},
  abstract={This study introduces an innovative approach to address the growing challenge of detecting and distinguishing ChatGPT-generated content within scientific articles, particularly in the context of Learning Management Systems (LMS). Leveraging state-of-the-art large language models, including Robustly Optimized BERT Pretraining (RoBERTa), Text-to-Text Transfer Transformer (T5), and Generative Pre-trained Transformers (EleutherAI GPT-Neo-125M), our methodology focuses on the incorporation of the LMS concept into the research framework. To construct a comprehensive dataset representative of the diverse landscape of scientific abstracts, samples of the dataset are gathered from articles produced by human authors and those generated by ChatGPT within the LMS framework. The models (RoBERTa, T5, and EleutherAI GPT-Neo-125M) were subsequently trained on this unique dataset, showcasing their adaptability to the distinct characteristics of both human-generated and AI-generated content within the LMS context. The efficacy of our approach was rigorously evaluated using a range of metrics, resulting in an outstanding accuracy exceeding 99%. This achievement underscores the robustness of our methodology in successfully discerning content generated by ChatGPT within the LMS and that authored by human contributors, thereby advancing the field of content differentiation in scientific discourse.},
  keywords={Chatbots;Data models;Accuracy;Training;Large language models;Transformers;Artificial intelligence;Content management;GPT-3.5;LLM;ChatGPT;T5;RoBERTa;EleutherAI GPT-Neo-125M;AI content;LMS},
  doi={10.1109/ACCESS.2024.3448315},
  ISSN={2169-3536},
  month={},}@ARTICLE{10816449,
  author={Zhao, Wenbo and Jiang, Nana and Liao, Xiaoxin and Zhu, Jubo},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={HVT-cGAN: Hybrid Vision Transformer cGAN for SAR-to-Optical Image Translation}, 
  year={2025},
  volume={63},
  number={},
  pages={1-17},
  abstract={Due to its capability for all-weather, all-time information acquisition, synthetic aperture radar (SAR) plays a vital role in the field of Earth observation. However, the specificity of the radar sensor and the complexity of electromagnetic scattering imaging physics result in SAR images lacking the intuitiveness of optical images, making them unsuitable for interpretation by nonexperts. A common approach to tackle this challenge is to use a conditional generative adversarial network (cGAN) to translate SAR images into optical images, thereby enhancing readability and assisting nonexperts in interpretation while filling the gaps in optical data due to acquisition constraints. Nevertheless, traditional cGAN-based methods are limited by inadequate global semantic information extraction and poor detail preservation, leading to translated images with incoherent texture and color, and blurred edge. To address these issues, we propose a hybrid vision transformer cGAN (HVT-cGAN) for SAR-to-optical image translation (S2OIT). In our proposed HVT-cGAN, the generator utilizes a convolutional stem for patch embedding and encoding. The parallel CNN branch and vision transformer (ViT) branch are employed for the extraction and mapping of local and global information, respectively. Moreover, we propose a novel attention-based feature fusion module, named the convolutional attention fusion module (CAFM), which can adaptively aggregate local and global information from parallel branches by learning both channel-wise and spatial-wise relations. Benefiting from these improvements, our method achieves superior performance in both qualitative and quantitative comparisons with other methods on the SEN1-2 dataset. In addition, the results of multiple ablation experiments validate the effectiveness of the proposed method.},
  keywords={Optical sensors;Optical imaging;Transformers;Generative adversarial networks;Translation;Radar polarimetry;Adaptive optics;Optical interferometry;Computer vision;Training;Generative adversarial network (GAN);hybrid vision transformer (ViT);image translation;synthetic aperture radar (SAR)},
  doi={10.1109/TGRS.2024.3523040},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{10690548,
  author={Rao, N.Venkatesvara and Swaminathan, Subbiah and Kanimozhi, K.V. and Manikandan, S.P. and Seethalakshmi, K.},
  booktitle={2024 Second International Conference on Advances in Information Technology (ICAIT)}, 
  title={Optimizing Resource Utilization in Generative AI Ensembles for Edge Computing}, 
  year={2024},
  volume={1},
  number={},
  pages={1-6},
  abstract={Edge computing in this period makes it difficult to deploy, AI ensemble on resource limited devices together flow the computation complexity and the system performs. The methods state below presents a comprehensive approach to the optimizing envelope of resources in generative AI sheaves for edge computing while characteristic adaptability, privacy and efficiency are minded. With improvement of model compression, hardware acceleration, and model optimization, computational cost can be reduced with high quality generated objects. Privately-oriented algorithms like federated learning and differential privacy provide entity safety of the data in the distributed and collaborative edge environments. Intelligent distribution resources management policies perform such actions instantaneously on-demand and automatically, hence improving performance. The experiments prove that the methodology is worthy to trusted adopting as it facilitates calculational efficiency, generates high quality results and also protects the information of the users. The ongoing evolution and sharing of new technologies including generative AI enhance edge intelligence and stimulate innovative breakthroughs in next generation devices while influencing society.},
  keywords={Performance evaluation;Adaptation models;Quantum computing;Generative AI;Federated learning;Computational modeling;Scalability;Resource management;Optimization;Edge computing;Generative AI;Resource utilization optimization;Edge computing;Compression techniques;Privacy-preserving mechanisms},
  doi={10.1109/ICAIT61638.2024.10690548},
  ISSN={},
  month={July},}@INPROCEEDINGS{10910483,
  author={Beg, Mohd Haider Raza and Mehndiratta, Vandana},
  booktitle={2024 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES)}, 
  title={The Ethics of Generative AI: Analyzing ChatGPT's Impact on Bias, Fairness, Privacy, and Accountability}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Pros and cons of Generative Artificial Intelligence (Intent), Many fields has its own use-case space for GAI. ChatGPT and systems like it give a sophisticated understanding of cognition along with content that is indistinguishable from humans, however these systems raise ethical issues in professional and social contexts. Challenges in the broad adoption of AI technologies including, accountability, fairness, bias and privacy arise as issues. These reforms will be critical as AI systems continue to be both developed and deployed, maintaining the crucial ethical standards and underpinning social trust. In the context of algorithmic biases, potential privacy violations, and an increased amount of risk due to automation in these critical decision areas; this paper provides a commentary regarding ethical concerns using generative AI. In addition, is the necessity of addressing these ethical challenges with tools like AI Ethics Impact Assessments, VADER Sentiment Analysis, TensorFlow's Indicators of Fairness, and continuous conversation.},
  keywords={Ethics;Privacy;Sentiment analysis;Automation;Generative AI;Oral communication;Chatbots;Cognition;Standards;GAI;Ethical Concern;Algorithm biases;bias response},
  doi={10.1109/ICSES63760.2024.10910483},
  ISSN={},
  month={Dec},}@ARTICLE{10508937,
  author={Park, Daeeol and Na, Hyunsik and Choi, Daeseon},
  journal={IEEE Access}, 
  title={Performance Comparison and Visualization of AI-Generated-Image Detection Methods}, 
  year={2024},
  volume={12},
  number={},
  pages={62609-62627},
  abstract={Recent advancements in artificial intelligence (AI) have revolutionized the field of image generation. This has concurrently escalated social problems and concerns related to AI image generation, underscoring the necessity for an effective AI-generated-image detection method. Therefore, numerous methods for detecting AI-generated images have been developed, but there remains a need for research comparing the effectiveness of and visualizing these detection methods. In this study, we classify AI-generated-image detection methods by the image features they use and compare their generalization performance in detecting AI-generated images of different types. We selected five AI-generated-image detection methods for performance evaluation and selected vision transformer as an additional method for comparison. We use two types of training datasets, i.e., ProGAN and latent diffusion; combine existing AI-generated-image test datasets into a diverse test dataset; and divide them into three types of generative models, i.e., generative adversarial network (GAN), diffusion, and transformer, to evaluate the comprehensive performance of the detection methods. We also analyze their detection performance on images with data augmentation, considering scenarios that make it difficult to detect AI-generated images. Grad-CAM and t-SNE are used to visualize the detection area and data distribution of each detection method. As a result, we determine that artifact-feature-based detection performs well on GAN and real images, whereas image-encoder-feature-based detection performs well on diffusion and transformer images. In summary, our research analyzes the comparative detection performance of various AI-generated-image detection methods, identifies their limitations, and suggests directions for further research.},
  keywords={Artificial intelligence;Transformers;Generative adversarial networks;Training;Solid modeling;Generators;Feature extraction;Generative AI;AI-generated-image detection;synthetic-image detection;performance comparison;GAN;diffusion model;transformer;Grad-CAM;t-SNE},
  doi={10.1109/ACCESS.2024.3394250},
  ISSN={2169-3536},
  month={},}@ARTICLE{10433140,
  author={Zhao, Fangzhou and Sun, Yao and Feng, Lei and Zhang, Lan and Zhao, Dezong},
  journal={IEEE Communications Letters}, 
  title={Enhancing Reasoning Ability in Semantic Communication Through Generative AI-Assisted Knowledge Construction}, 
  year={2024},
  volume={28},
  number={4},
  pages={832-836},
  abstract={Semantic communication (SemCom), a pioneering paradigm that places emphasis on conveying the meaning of information, faces challenges in constructing background knowledge to drive precise reasoning of semantic coding models. Fortunately, the recent emergence of Generative Artificial Intelligence (GAI) technology is promising to create high-quality content that can be harnessed to assist knowledge construction in SemCom, enhancing the reasoning ability of semantic coding models. In this letter, we propose a GAI-assisted SemCom framework, named Gen-SC, where sufficient samples for training SemCom transceivers are generated using GAI as per user contextual information. In addition, to guide the GAI model in producing contextually relevant content, a discriminator is incorporated into Gen-SC to measure the disparity between generated samples and actual samples. The simulation results demonstrate that the Gen-SC achieves higher semantic accuracy, especially when the original training samples are insufficient, in contrast to traditional SemCom without knowledge enhancement.},
  keywords={Semantics;Training;Decoding;Mutual information;Knowledge engineering;Encoding;Transceivers;Semantic communication;generative artificial intelligence;background knowledge construction},
  doi={10.1109/LCOMM.2024.3365158},
  ISSN={1558-2558},
  month={April},}@INPROCEEDINGS{11152871,
  author={Fang, Zechuan and Sun, Mengying and Zhang, Yuantao and Wang, Haiming and Xu, Xiaodong},
  booktitle={IEEE INFOCOM 2025 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, 
  title={Generative AI-Driven Cross-Modal Semantic Communication System for Visual Transmission}, 
  year={2025},
  volume={},
  number={},
  pages={1-2},
  abstract={This paper proposes a generative artificial intelligence-driven cross-modal semantic communication framework (GC-SemCom) designed for efficient image transmission. Specifically, at the transmitter, a multi-modal large language model is utilized to extract compact semantic information, i.e. image difference captions between the original image and retrieved background knowledge. This semantic information, expressed in textual instruction, is then transmitted based on joint source-channel codec. At the receiver, the diffusion model, guided by both received semantic information and synchronized background knowledge, iteratively generates the recovered image through the reverse denoising process. Furthermore, the semantic knowledge base provides background knowledge for both transceivers, defined as the semantically similar image retrieved. Experimental results demonstrate that the proposed framework reduces the overall data size to just 0.06% of the original data, while maintaining high-quality transmission even under substantial noise conditions.},
  keywords={Visualization;Transmitters;Simulation;Noise reduction;Noise;Receivers;Semantic communication;Transceivers;Data mining;Synchronization;generative artificial intelligence (GenAI);semantic communication (SemCom);cross-modal transmission},
  doi={10.1109/INFOCOMWKSHPS65812.2025.11152871},
  ISSN={2833-0587},
  month={May},}@INPROCEEDINGS{10448434,
  author={Hu, Jinbin and Sun, Xiaoxue and Bai, Xinhao and Qin, Yanding and Wang, Hongpeng and Han, Jianda},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Subdivision Features-Guided Brain MRI Super-Resolution via Forward and Backward Propagation}, 
  year={2024},
  volume={},
  number={},
  pages={1666-1670},
  abstract={There have been many models designed for super-resolution (SR) tasks. However, the universal model rarely takes into account the potential characteristics of magnetic resonance imaging (MRI). Further, for real-time MRI, SR is a critical technology to improve spatial resolution while maintaining temporal resolution. Trying not to change the existing well-established models, we propose a subdivision feature-guided enhancement module which can be attached to the arbitrary generative networks for the brain MRI SR tasks. The experimental results proved the effectiveness of our designed module.},
  keywords={Backpropagation;Magnetic resonance imaging;Superresolution;Signal processing;Brain modeling;Real-time systems;Acoustics;Subdivision features;brain MRI;super-resolution},
  doi={10.1109/ICASSP48485.2024.10448434},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10086829,
  author={},
  booktitle={2023 15th International Conference on Knowledge and Smart Technology (KST)}, 
  title={Tentative Program}, 
  year={2023},
  volume={},
  number={},
  pages={i-iv},
  abstract={},
  keywords={Computational intelligence;Image recognition;Face recognition;Real-time systems;Emotion recognition;Urban areas;Technological innovation},
  doi={10.1109/KST57286.2023.10086829},
  ISSN={2374-314X},
  month={Feb},}@INBOOK{10614289,
  author={Ojanperä, Tero},
  booktitle={AI Revolution: Mastering AI for Personal and Organizational Growth}, 
  title={4 Productivity Leap &#x2013; Internet to the Power of 2}, 
  year={2024},
  volume={},
  number={},
  pages={83-90},
  abstract={"The AI Revolution" is a practical guide to using new AI tools, such as ChatGPT, DALLE and Midjourney. Learn how to multiply your productivity by guiding or prompting AI in various ways. The book also introduces Microsoft Copilot, Google Bard, and Adobe Photoshop Generative Fill, among other new applications. ChatGPT reached a hundred million users in just two months after its release, faster than any other application before. This marked the advent of the generative AI era. Generative AI models generate text, images, music, videos, and even 3D models in ways previously thought impossible for machines. The book explains in an understandable manner how these AI models work. The book provides examples of how AI increases productivity, which professions are changing or disappearing, and how job markets will evolve in the coming years. With this book, you'll learn to recognize the opportunities and risks AI offers. Understand what this change demands from individuals and companies and what strategic skills are required. The book also covers legal questions caused by generative AI, like copyrights, data protection, and AI regulation. It also ponders societal impacts. AI produces content, thus influencing language, culture, and even worldviews. Therefore, it's crucial to understand by whom and how AI is trained. The AI revolution started by ChatGPT is just the beginning. This handbook is for you if you want to keep up with the rapid development of AI.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770042314},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10614289},}@ARTICLE{9087871,
  author={Chui, Kwok Tai and Liu, Ryan Wen and Zhao, Mingbo and De Pablos, Patricia Ordóñez},
  journal={IEEE Access}, 
  title={Predicting Students’ Performance With School and Family Tutoring Using Generative Adversarial Network-Based Deep Support Vector Machine}, 
  year={2020},
  volume={8},
  number={},
  pages={86745-86752},
  abstract={It has been witnessed that supportive learning has played a crucial role in educational quality enhancement. School and family tutoring offer personalized help and provide positive feedback on students' learning. Predicting students' performance is of much interest which reflects their understanding on the subjects. Particularly it is desired students to manage well in fundamental knowledge in order to build a strong foundation for post-secondary studies and career. In this paper, improved conditional generative adversarial network based deep support vector machine (ICGAN-DSVM) algorithm has been proposed to predict students' performance under supportive learning via school and family tutoring. Owning to the nature of the students' academic dataset is generally low sample size. ICGAN-DSVM offers dual benefits for the nature of low sample size in students' academic dataset in which ICGAN increases the data volume whereas DSVM enhances the prediction accuracy with deep learning architecture. Results with 10-fold cross-validation show that the proposed ICGAN-DSVM yields specificity, sensitivity and area under the receiver operating characteristic curve (AUC) of 0.968, 0.971 and 0.954 respectively. Results also suggest that incorporating both school and family tutoring into the prediction model could further improve the performance compared with only school tutoring and only family tutoring. To show the necessity of ICGAN and DSVM, comparison has been made between ICGAN and traditional conditional generative adversarial network (CGAN). Also, the proposed kernel design via heuristic based multiple kernel learning (MKL) is compared with typical kernels including linear, radial basis function (RBF), polynomial and sigmoid. The prediction of student's performance with and without GAN is presented which is followed by comparison with DSVM and with traditional SVM. The proposed ICGAN-DSVM outperforms related works by 8-29% in terms of performance indicators specificity, sensitivity and AUC.},
  keywords={Support vector machines;Kernel;Education;Deep learning;Predictive models;Gallium nitride;Generative adversarial networks;Generative adversarial network;students’ academic performance;deep support vector machine;supportive learning},
  doi={10.1109/ACCESS.2020.2992869},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11166628,
  author={Almadhoob, Ali and Qarooni, Ahmed and Khadem, Hasan},
  booktitle={2025 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)}, 
  title={Comparing Generative Artificial Intelligence (GenAI) Models’ Capabilities in Solving Cryptographic Problems and Algorithms}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={This study aims to evaluate the capabilities of four large language models (LLMs) that include ChatGPT 4o, Claude 3.5 Sonnet, Copilot, and Gemini 1.5 Flash in different cryptographic tasks and algorithms, mainly solving foundation mathematical problems and classical algorithms in cryptography, while also generating code and performing cryptoanalysis. Using a structured methodology, this study assesses the performance of these models in such tasks. The results of this research vary between models, as some are excelling in simpler tasks (e.g Caesar Cipher), but struggle when it comes to more complex algorithms (e.g AES, DES) and large number factorizations and computations.},
  keywords={Ciphers;Codes;Generative AI;Computational modeling;Large language models;Chatbots;Mathematical models;Data models;Cryptography;Language Models;Mathematical Concepts;Cryptographic Algorithms;Code Generation;Cryptanalysis},
  doi={10.1109/ACDSA65407.2025.11166628},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10488939,
  author={Bajpayi, Pragya and Sharma, Smita and Gaur, Madhu Sharma},
  booktitle={2024 2nd International Conference on Disruptive Technologies (ICDT)}, 
  title={AI Driven IoT Healthcare Devices Security Vulnerability Management}, 
  year={2024},
  volume={},
  number={},
  pages={366-373},
  abstract={In the modern healthcare ecosystem, emerging technologies, Internet of Things(IoT) medical devices playing major role for providing seamless and remote clinical care, disease diagnosis, patient monitoring and many more healthcare services. Wireless, seamless sensor devices and underlying infrastructure creates the IoT ecosystem. An IoT device identification and vital healthcare data collection are the most important where vulnerability management and security is a critical aspect of IoT security Against a number of vulnerabilities, attacks and cyber threats, a proactive approach needs to be builds for Internet of Things medical devices security resilience. In the current fast moving digital transformation, integrating Artificial Intelligence (AI)-driven safety measures into IoT enabled healthcare applications represents a significant advance in building a secure and trustworthy healthcare system. The AI system can identify ordinary patterns of behavior and swiftly recognize any deviations suggestive of a possible security risk or unauthorized access through the continuous analysis of data flows from networked sensor devices. In order to enhance the security of IoT medical devices, we explore security vulnerabilities in IoT enabled healthcare applications and propose an Artificial Intelligence (AI) driven approach for IoT Device level vulnerabilities management life cycle for known and unknown vulnerability detection and protection based on zero tolerance and zero-trust model. The aim of this work is to strengthen the healthcare data vulnerability management strategy through zero-trust based strategy and AI-driven automated IoT devices security vulnerabilities management and risk assessment for an application on managed or unmanaged clinical and diagnosis operational services.},
  keywords={Wireless communication;Wireless sensor networks;Medical devices;Ecosystems;Medical services;Zero Trust;Internet of Things;Artificial Intelligence;Healthcare;Internet of things (IoT);Medical device;Security;Vulnerabilities},
  doi={10.1109/ICDT61202.2024.10488939},
  ISSN={},
  month={March},}@INPROCEEDINGS{10511483,
  author={Kurnianingrum, Dian and Bin Jumri, Isma Addi and Ratnapuri, Chyntia Ika and Karmagatri, Mulyani and Kartawinata, Budi Rustandi},
  booktitle={2024 3rd International Conference for Innovation in Technology (INOCON)}, 
  title={Exploring the Chat GPT's Impact and Prospects for Business Research Purposes}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This research provides a detailed analysis of publications related to the Chat GPT topic using data from the Scopus database. The main purpose of this research is to find research gaps within ChatGPT research, especially in business. This research content is divided into four key areas: publication and citation structure, past research topics, author co-citation analysis, and keyword co-occurrence analysis. The research finds that Chat GPT is actively explored in medicine, social science, computer science, and engineering. Most past research is not directly related to business, but it can support business continuity. The research notes a balanced contribution from authors and identifies "Artificial Intelligence" as a leading keyword. Countries like the United States, China, and India are major contributors. Using Latent Dirichlet Allocation (LDA), the study categorizes previous work into five areas: remote learning, AI-based customer support, Learning Management Systems, academic research roles, and AI data handling. The co-citation analysis shows that authors, specifically Wu J. and Radford A., have significantly impacted the Chat GPT publication. For keyword co-occurrence, "Artificial Intelligence" and "ChatGPT" are keywords that have a strong link. The keywords cluster are divided into technology (red) and human-centric (green) topics.},
  keywords={Computer science;Learning management systems;Distance learning;Databases;Data handling;Social sciences;Chatbots;Chat GPT;Artificial Intelligence;Scopus Database;Publication Structure;Academic Research},
  doi={10.1109/INOCON60754.2024.10511483},
  ISSN={},
  month={March},}@ARTICLE{10296890,
  author={Naz, Huma and Nijhawan, Rahul and Ahuja, Neelu Jyothi and Al-Otaibi, Shaha and Saba, Tanzila and Bahaj, Saeed Ali and Rehman, Amjad},
  journal={IEEE Access}, 
  title={Ensembled Deep Convolutional Generative Adversarial Network for Grading Imbalanced Diabetic Retinopathy Recognition}, 
  year={2023},
  volume={11},
  number={},
  pages={120554-120568},
  abstract={Diabetic Retinopathy (DR) is one of the leading causes of blindness and vision loss worldwide. According to the International Diabetes Federation (IDF), approximately one-third of individuals with diabetes, equivalent to 32.2%, are affected by some form of DR. Due to the uneven data distribution, intra-class variance, and a dearth of ophthalmologists, DR diagnosis is considered challenging. In recent years, Convolutional Neural Networks (CNN) and supervised learning techniques have been potentially useful in computer vision applications. However, unsupervised CNN has received less attention. Moreover, it is more manageable to use synthetic images for model training with the recent advancements in graphics. Therefore, the proposed method combines the actual and augmented views using the Deep Convolutional Generative Adversarial Network (DCGAN) algorithm. The generated views are implemented to balance the minority class in the imbalanced dataset. Furthermore, a novel ensemble convolutional neural network algorithm named Different View Ensemble (DVE) that merges the weighted average prediction of CNN, CNN-i, and CNN+i algorithms has been proposed. The proposed algorithm is evaluated on the DDR and EyePACS datasets, and its performance is compared with K-Means, Fuzzy C-Means (FCM), and Autoencoder-based Deep Embedded Clustering Techniques (DEC). The results demonstrate the superiority of the proposed algorithm, achieving an accuracy rate of 97.4%, specificity of 99.6%, and sensitivity of 92.3%. The promising results underscore the potential impact of this methodology in enhancing the accuracy and reliability of automated diagnostic systems in the field of ophthalmology. Notably, the evaluation considers imbalanced data and a DCGAN-balanced dataset, where the proposed approach exhibits even better performance with balanced classes.},
  keywords={Generative adversarial networks;Prediction algorithms;Convolutional neural networks;Training;Data models;Predictive models;Generators;Diabetic retinopathy;Diabetic retinopathy detection;imbalance data;ensembled GAN;healthcare;health risks},
  doi={10.1109/ACCESS.2023.3327900},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9696138,
  author={Liu, Weichen and Gu, Yuxuan and Zhang, Kenan},
  booktitle={2021 2nd International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE)}, 
  title={Face Generation using DCGAN for Low Computing Resources}, 
  year={2021},
  volume={},
  number={},
  pages={377-382},
  abstract={Image generation is the task of generating brand new images from existing datasets. With the increasing development of the Generative Adversarial Network (GAN), it is now widely used in the field of image generation. Research based on its time cost and the convergence of its training process has been widely concerned. However, existing techniques for network convergence during the training process usually require high computing resources. This paper has used Deep Convolutional Generative Adversarial Network (DCGAN) on the CelebA dataset for experimental evaluation: The number of training epochs and the algorithm’s parameters is adjusted to achieve a balance between the quality of generation results and computing resources used. This is assumed to be convenient for future studies under the condition of limited computing resources. Besides, by adjusting the parameters of the optimization algorithm, the convergence of GAN under the conditions of a specific optimization algorithm is studied.},
  keywords={Training;Costs;Image synthesis;Focusing;Generative adversarial networks;Generators;Task analysis;component;Image generation;DCGAN;Adam;Deep learning},
  doi={10.1109/ICBASE53849.2021.00076},
  ISSN={},
  month={Sep.},}@ARTICLE{11091361,
  author={Chen, Jiheng and Fang, Bo and Dianov, Anton and Xiang, Jiawei},
  journal={IEEE Sensors Journal}, 
  title={Numerical Model-Aided Intelligent Diagnosis Method to Detect Faults in Induction Motors}, 
  year={2025},
  volume={25},
  number={17},
  pages={32194-32208},
  abstract={Faults in induction motors will reduce the operational efficiency and stability of mechanical systems. In recent years, artificial intelligence (AI) models have become an important technology for diagnosing induction motor faults. These AI models can only accurately identify faults when trained on a complete dataset. However, it is difficult to obtain a complete dataset in practical engineering scenarios, which will worsen the performance of AI models. To solve the problem, a numerical model-aided intelligent diagnosis method is proposed. First, a numerical model of the health induction motor is established, and the model is updated using measured health signals. Subsequently, various types of fault mathematical models are injected into the healthy numerical model to obtain simulated fault samples. Finally, the simulated and/or measured signals are used to train the convolutional neural network (CNN). The experimental results show that the model has achieved satisfactory results to construct a relatively complete dataset for engineering applications.},
  keywords={Circuit faults;Stator windings;Rotors;Induction motors;Numerical models;Integrated circuit modeling;Circuits;Artificial intelligence;Motors;Mathematical models;Convolutional neural network (CNN);fault detection;fault sample generation;induction motor;numerical model},
  doi={10.1109/JSEN.2025.3586913},
  ISSN={1558-1748},
  month={Sep.},}@INPROCEEDINGS{11050535,
  author={Islam, Mohammad Rubyet and Sandborn, Peter},
  booktitle={2025 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Multimodal Generative AI for Story Point Estimation}, 
  year={2025},
  volume={},
  number={},
  pages={659-662},
  abstract={This research explores Multimodal Generative AI for Agile story point estimation, integrating text, images, and categorical data with BERT, CNN, and XGBoost to enhance project planning. While effective for simpler estimates, challenges with complex cases due to data imbalance highlight the need for tailored strategies. Findings underscore multimodal AI's impact on Agile decision-making and suggest future improvements in data handling and model robustness.},
  keywords={Automation;Accuracy;Generative AI;Data handling;Decision making;Estimation;Agile project management;Robustness;Data models;Planning;multimodal;NLP;story point estimation;agile framework;fibonacci sequences},
  doi={10.1109/CAI64502.2025.00120},
  ISSN={},
  month={May},}@INPROCEEDINGS{10674524,
  author={Sheu, Jeng-Shin and Ahmad, Aftab and Xu, Shun-Yi},
  booktitle={2024 International Conference on Consumer Electronics - Taiwan (ICCE-Taiwan)}, 
  title={Taiwanese Hokkien in AI: Challenges, Approaches, and Language Modeling}, 
  year={2024},
  volume={},
  number={},
  pages={195-196},
  abstract={In the evolving landscape of artificial intelligence (AI) and natural language processing (NLP), major advancements have been made, particularly with powerful pre-trained language models. However, these models often overlook region-specific languages like Taiwanese Hokkien. This paper addresses the challenges in integrating Taiwanese Hokkien into NLP and proposes solutions. We employ deep neural networks to develop a translation model that unifies diverse Taiwanese Hokkien texts into a standardized script. Leveraging this unified text, we train pre-trained language and generative models tailored for Taiwanese Hokkien. These models are pivotal in facilitating the integration of Taiwanese Hokkien into the AI landscape, enabling exploration of its various aspects in NLP. Our experiments demonstrate the successful acquisition of a universal language representation by the pre-trained language model and the impressive generation of fluent Taiwanese Hokkien text by the generative model.},
  keywords={Pipelines;Artificial neural networks;Writing;Transformers;Natural language processing;Artificial intelligence;Consumer electronics;Taiwanese Hokkien;natural language processing;Transformer architecture;BERT;GPT},
  doi={10.1109/ICCE-Taiwan62264.2024.10674524},
  ISSN={2575-8284},
  month={July},}@ARTICLE{9339895,
  author={Li, Xiaoshuang and Ye, Peijun and Jin, Junchen and Zhu, Fenghua and Wang, Fei-Yue},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Data Augmented Deep Behavioral Cloning for Urban Traffic Control Operations Under a Parallel Learning Framework}, 
  year={2022},
  volume={23},
  number={6},
  pages={5128-5137},
  abstract={It is indispensable for professional traffic signal engineers to perform manual operations of traffic signal control (TSC) to mitigate traffic congestion, especially with complicated scenarios. However, such a task is time-consuming, and the level of congestion mitigation heavily relies on individual expertise in engineering practice. Therefore, it is cost-effective to learn traffic engineers’ knowledge to enhance the problem-solving skills for a large-scale urban traffic network. In this paper, a data augmented deep behavioral cloning (DADBC) method is proposed to imitate the problem-solving skills of traffic engineers. The method is under a conceptual framework, parallel learning (PL) framework, that incorporates machine learning techniques for solving decision-making problems in complex systems. The DADBC method enhances a hybrid demonstration by exploiting a generative adversarial network (GAN) and then uses the deep behavioral cloning (DBC) model to learn traffic engineers’ control schemes. According to the validation results using the real manipulation data from Hangzhou, China, our method can imitate complex human behaviors in intervening traffic signal control operations to improve traffic efficiency in urban areas.},
  keywords={Generative adversarial networks;Gallium nitride;Cloning;Data models;Task analysis;Complex systems;Knowledge engineering;Intelligent traffic signal operations;parallel learning;deep behavioral cloning;generative adversarial networks},
  doi={10.1109/TITS.2020.3048151},
  ISSN={1558-0016},
  month={June},}@ARTICLE{10210519,
  author={Chen, Zhi and Duan, Jiang and Kang, Li and Xu, Hongyan and Chen, Rui and Qiu, Guoping},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Generating Counterfactual Instances for Explainable Class-Imbalance Learning}, 
  year={2024},
  volume={36},
  number={3},
  pages={1130-1144},
  abstract={Existing class imbalance learning paradigms focus on lifting the importance of minority instance, aiming to improve the model in terms of certain evaluation metrics (e.g., AUC and $F_{1}$F1-measure). One drawback of these methods is that they lack enough transparency, hence, cannot be fully trusted in vital domains. To this end, this paper deal with the class imbalance learning task with counterfactual instances. Given an instance and a classifier, a counterfactual is a fake instance which, while having smallest distance to the original instance, is classified as a different class by the classifier. Therefore, the most important features for a classifier can be identified by inspecting the difference between an instance and its counterfactual. To utilize counterfactuals, a novel Explainable Generative Adversarial Network (EXGAN) is proposed. EXGAN has a unique “two generators versus multiple discriminators” architecture where the generators are used to generate effective counterfactuals and discriminators are trained for the class imbalance learning task. In addition to the architecture, an innovative ensemble loss function ensuring each discriminator complementing each other is designed to overcome the class imbalance issue. Extensive experiments prove that the counterfactuals generated by EXGAN can be used to produce effective local explanation and provide significant better class imbalance learning ability than existing competitors.},
  keywords={Generators;Classification algorithms;Task analysis;Standards;Ensemble learning;Costs;Computational modeling;Class imbalance learning;counterfactual;explainable machine learning;explainable generative adversarial network;ensemble learning},
  doi={10.1109/TKDE.2023.3302847},
  ISSN={1558-2191},
  month={March},}@INPROCEEDINGS{10848615,
  author={Galantucci, Stefano and Iannacone, Andrea and Pirlo, Giuseppe and Sarcinella, Lucia and Stamerra, Alessandro},
  booktitle={2025 IEEE 4th International Conference on AI in Cybersecurity (ICAIC)}, 
  title={MAGICIAN: Malware classification Approach through Generation Image using a Conditional and wassersteIn generative Adversarial Network variants}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={One of the main challenges of cybersecurity is the detection and classification of malware to prevent damage to systems by both companies and private users. Identifying the specific type of malware is critical to performing targeted actions. This study proposes a classification approach that generates synthetic images of malware using Conditional Generative Adversarial Networks (cGAN) and Wasserstein Generative Adversarial Networks (WGAN). Using the Malimg dataset, consisting of 25 malware classes, the ResNet50 model shows an overall accuracy of $\mathbf{9 1. 4 \%}$ and an $\mathbf{F 1}$-score of $\mathbf{9 0. 8 \%}$ for synthetic images generated with WGAN. Resizing and resampling were employed as preprocessing strategies to obtain images of size $48 \times 48$; resampling has been shown to be more effective. Thus, the proposed methodology allows malware to be classified quickly and efficiently, and, on the other hand, unbalanced datasets can be enriched to aid classification performance.},
  keywords={Hands;Accuracy;Companies;Generative adversarial networks;Malware;Computer security;Artificial intelligence;Residual neural networks;MalImg;cGAN;WGAN;ResNet50;Malware images;Resizing;Resampling},
  doi={10.1109/ICAIC63015.2025.10848615},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10673889,
  author={Lin, Jia-Xian and Chen, Chun-Ching},
  booktitle={2024 International Conference on Consumer Electronics - Taiwan (ICCE-Taiwan)}, 
  title={Designer-GenAI Co-Creation: Exploring the Potential Impact of Micro-Mobility Tool Design Recommendations on Elderly Mobility and Welfare}, 
  year={2024},
  volume={},
  number={},
  pages={153-154},
  abstract={As age progresses, mobility limitations can hinder the social participation of the elderly, underscoring the importance of enhancing mobility for societal development. This study emphasizes the critical role of mobility in enhancing life satisfaction and facilitating successful aging among the elderly and explores the potential of micro-mobility tools to improve the quality of life and independence. Through workshops that foster collaborative ideation with designers and generative artificial intelligence, we have developed solutions tailored for micro-mobility and offer recommendations for future micro-mobility planning, particularly focusing on the integration of hardware and software details. This research integrates design expertise and artificial intelligence technology, advocating for the continuous innovation of micro-mobility tools to support the active participation of the elderly in society.},
  keywords={Technological innovation;Electric potential;Generative AI;Conferences;Focusing;Software;Hardware;Micro-mobility;generative AI;older people;design recommendations;brainstorming},
  doi={10.1109/ICCE-Taiwan62264.2024.10673889},
  ISSN={2575-8284},
  month={July},}@ARTICLE{10221755,
  author={Wang, Yuntao and Pan, Yanghe and Yan, Miao and Su, Zhou and Luan, Tom H.},
  journal={IEEE Open Journal of the Computer Society}, 
  title={A Survey on ChatGPT: AI–Generated Contents, Challenges, and Solutions}, 
  year={2023},
  volume={4},
  number={},
  pages={280-302},
  abstract={With the widespread use of large artificial intelligence (AI) models such as ChatGPT, AI-generated content (AIGC) has garnered increasing attention and is leading a paradigm shift in content creation and knowledge representation. AIGC uses generative large AI algorithms to assist or replace humans in creating massive, high-quality, and human-like content at a faster pace and lower cost, based on user-provided prompts. Despite the recent significant progress in AIGC, security, privacy, ethical, and legal challenges still need to be addressed. This paper presents an in-depth survey of working principles, security and privacy threats, state-of-the-art solutions, and future challenges of the AIGC paradigm. Specifically, we first explore the enabling technologies, general architecture of AIGC, and discuss its working modes and key characteristics. Then, we investigate the taxonomy of security and privacy threats to AIGC and highlight the ethical and societal implications of GPT and AIGC technologies. Furthermore, we review the state-of-the-art AIGC watermarking approaches for regulatable AIGC paradigms regarding the AIGC model and its produced content. Finally, we identify future challenges and open research directions related to AIGC.},
  keywords={Artificial intelligence;Chatbots;Surveys;Security;Computational modeling;Privacy;Training;AIGC;generative AI;ChatGPT;security;and privacy},
  doi={10.1109/OJCS.2023.3300321},
  ISSN={2644-1268},
  month={},}@INPROCEEDINGS{10942898,
  author={Colombi, Lorenzo and Brina, Matteo and Vespa, Michela and Tabanelli, Filippo and Dahdal, Simon and Bellodi, Elena and Venanzi, Riccardo and Tortonesi, Mauro and Vignoli, Massimiliano and Stefanelli, Cesare},
  booktitle={2024 IEEE 29th International Workshop on Computer Aided Modeling and Design of Communication Links and Networks (CAMAD)}, 
  title={Optimizing Industry 5.0 Machine Learning-Based Applications via Synthetic Data Generation}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Machine Learning (ML) innovations are revolutionizing industrial processes by improving productivity and competitiveness, particularly by creating predictive maintenance applications and Artificial Intelligence (AI) powered services. In the Industry 5.0 paradigm, which strives to reach Zero Defect and Zero Waste Manufacturing, the role of ML is crucial for optimizing these processes. However, developing ML solutions for production-ready industrial settings presents various challenges, such as data scarcity and dataset imbalance, which are further amplified when dealing with tabular data. To overcome such issues we investigate the use of various Deep Generative Models (DGMs) to generate synthetic data that closely mimics real-world conditions. Despite extensive studies of DGMs in the literature, there is still limited knowledge of their practical suitability in Industry 5.0 environments. Our research includes a detailed evaluation of several DGMs, such as Generative Adversarial Networks, Variational Autoencoders, and Diffusion Models, implemented in the gearbox assembly and testing line in the Bonfiglioli EVO plant. Based on our results, the evaluated DGMs demonstrate significant potential in generating high-quality synthetic data, that allows training a high-performance classifier to distinguish faulty gearboxes from well-functioning ones.},
  keywords={Training;Technological innovation;Computational modeling;Autoencoders;Generative adversarial networks;Diffusion models;Data models;Fifth Industrial Revolution;Synthetic data;Testing;Industry 5.0;Machine Learning;Deep Generative Model;Generative Adversarial Network;Diffusion Model;Variational Autoencoder},
  doi={10.1109/CAMAD62243.2024.10942898},
  ISSN={2378-4873},
  month={Oct},}@ARTICLE{10542413,
  author={Yuan, Chengsheng and Cui, Baojie and Zhou, Zhili and Liu, Yuming and Yang, Yimin and Jonathan Wu, Q. M.},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={RTRGAN: Ridge Texture Rendering-Based Generative Adversarial Fingerprint Attack for Portable Consumer Electronics Devices}, 
  year={2024},
  volume={70},
  number={3},
  pages={5471-5482},
  abstract={Deep Fake Fingerprint Detection (DFFD) technique is ubiquitously deployed in automatic fingerprint identification systems (AFIS). Portable consumer electronics devices (PCED), such as smartphones, smart tablets, and PCs, also utilize fingerprint as a authentication method of AFIS. In recent years, the emergence of adversarial examples reveals the vulnerability of DNNs and weakens the credibility of PCED. Existing adversarial examples generally adopt perturbation addition, which lack robustness in the face of defensive measures such as adversarial training. Moreover, the perturbations used to deceive DFFD are easily perceived by human eyes. To address the above challenges, this paper proposes a novel generative adversarial fingerprint attack method for PCED. Firstly, to address the issue of poor robustness against defense strategies, this paper proposes a ridge texture rendering based generative adversarial network (RTRGAN) to perform robust generative adversarial fingerprint attack. Subsequently, to further enhance the visual quality of adversarial fingerprints, the realistic ridge texture is assigned by comparing the feature similarity between real fingerprints and adversarial fingerprints. Finally, this paper designs a joint optimization loss function, including the discriminator loss and the adversarial loss, to balance the attack robustness and visual fidelity. Extensive experiments demonstrate that compared with traditional perturbation-based methods, the proposed scheme significantly improves the attack success rate, has remarkable robustness, and generates more realistic adversarial fingerprints to human perception.},
  keywords={Fingerprint recognition;Perturbation methods;Training;Consumer electronics;Robustness;Task analysis;Optimization;Portable consumer electronics devices;adversarial fingerprints attacks;deep fake fingerprint detection},
  doi={10.1109/TCE.2024.3407713},
  ISSN={1558-4127},
  month={Aug},}@INPROCEEDINGS{8953992,
  author={Mandal, Devraj and Narayan, Sanath and Dwivedi, Sai Kumar and Gupta, Vikram and Ahmed, Shuaib and Khan, Fahad Shahbaz and Shao, Ling},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Out-Of-Distribution Detection for Generalized Zero-Shot Action Recognition}, 
  year={2019},
  volume={},
  number={},
  pages={9977-9985},
  abstract={Generalized zero-shot action recognition is a challenging problem, where the task is to recognize new action categories that are unavailable during the training stage, in addition to the seen action categories. Existing approaches suffer from the inherent bias of the learned classifier towards the seen action categories. As a consequence, unseen category samples are incorrectly classified as belonging to one of the seen action categories. In this paper, we set out to tackle this issue by arguing for a separate treatment of seen and unseen action categories in generalized zero-shot action recognition. We introduce an out-of-distribution detector that determines whether the video features belong to a seen or unseen action category. To train our out-of-distribution detector, video features for unseen action categories are synthesized using generative adversarial networks trained on seen action category features. To the best of our knowledge, we are the first to propose an out-of-distribution detector based GZSL framework for action recognition in videos. Experiments are performed on three action recognition datasets: Olympic Sports, HMDB51 and UCF101. For generalized zero-shot action recognition, our proposed approach outperforms the baseline with absolute gains (in classification accuracy) of 7.0%, 3.4%, and 4.9%, respectively, on these datasets.},
  keywords={Training;Computer vision;Accuracy;Zero shot learning;Detectors;Feature extraction;Generative adversarial networks;Pattern recognition;Videos;Sports;Action Recognition;Recognition: Detection;Categorization;Retrieval},
  doi={10.1109/CVPR.2019.01022},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{10030467,
  author={Sushko, Vadim and Zhang, Dan and Gall, Juergen and Khoreva, Anna},
  booktitle={2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, 
  title={One-Shot Synthesis of Images and Segmentation Masks}, 
  year={2023},
  volume={},
  number={},
  pages={6274-6283},
  abstract={Joint synthesis of images and segmentation masks with generative adversarial networks (GANs) is promising to reduce the effort needed for collecting image data with pixel-wise annotations. However, to learn high-fidelity image-mask synthesis, existing GAN approaches first need a pre-training phase requiring large amounts of image data, which limits their utilization in restricted image domains. In this work, we take a step to reduce this limitation, introducing the task of one-shot image-mask synthesis. We aim to generate diverse images and their segmentation masks given only a single labelled example, and assuming, contrary to previous models, no access to any pre-training data. To this end, inspired by the recent architectural developments of single-image GANs, we introduce our OSMIS model which enables the synthesis of segmentation masks that are precisely aligned to the generated images in the one-shot regime. Besides achieving the high fidelity of generated masks, OSMIS outperforms state-of-the-art single-image GAN models in image synthesis quality and diversity. In addition, despite not using any additional data, OSMIS demonstrates an impressive ability to serve as a source of useful data augmentation for one-shot segmentation applications, providing performance gains that are complementary to standard data augmentation techniques. Code is available at https://github.com/boschresearch/one-shot-synthesis.},
  keywords={Training;Image segmentation;Computer vision;Codes;Image synthesis;Performance gain;Generative adversarial networks;Algorithms: Computational photography;image and video synthesis;Machine learning architectures;formulations;and algorithms (including transfer;low-shot;semi-;self-;and un-supervised learning)},
  doi={10.1109/WACV56688.2023.00622},
  ISSN={2642-9381},
  month={Jan},}@ARTICLE{7948855,
  author={Lee, Jong-Hyouk and Kim, Hyoungshick},
  journal={IEEE Consumer Electronics Magazine}, 
  title={Security and Privacy Challenges in the Internet of Things [Security and Privacy Matters]}, 
  year={2017},
  volume={6},
  number={3},
  pages={134-136},
  abstract={This is the first installment of the new "Security and Privacy Matters" column in IEEE Consumer Electronics Magazine. Security and privacy are always at the heart of everything that happens in the Consumer Electronics (CE) industry. This column aims to provide insight on various aspects of security and privacy in the CE industry.},
  keywords={Computer security;Privacy;Automobiles;Cloud computing;Artificial intelligence;Servers;Wireless communication},
  doi={10.1109/MCE.2017.2685019},
  ISSN={2162-2256},
  month={July},}@INBOOK{10951560,
  author={Sayal, Anu and Jha, Janhvi and Chaithra, N. and Gangodkar, Atharv Rajesh and Shaziya Banu, S.},
  booktitle={Artificial Intelligence and Machine Learning in Drug Design and Development}, 
  title={Revolutionizing Drug Discovery}, 
  year={2024},
  volume={},
  number={},
  pages={189-221},
  abstract={Summary <p>Historically, drug discovery was dominated by relentless scientific experiments and repetitive laboratory procedures. However, with the introduction of computational technologies and multidimensional data, this process has undergone significant transformation. This chapter emphasizes the pivotal role of AI, ML, DL, NLP, and robotics in contemporary drug development. AI, with its evolving intelligence, amplifies decision processes when supported by comprehensive data. The focus remains on the capabilities of ML, DL, and NLP in the pharmaceutical industry&#x2014;from accurate drug interaction predictions to the formulation of specialized treatment methods. Robotics has emerged as a vital tool, streamlining the management and distribution of medications. By leveraging AI methodologies such as random forest, SVM, and others, it is feasible to predict drug outcomes, identify new pharmaceutical benefits, and foresee any adverse side effects. It is notable how AI is the cornerstone for innovations including personalized medications, digital drug analysis, original drug formulation, and data&#x2010;driven predictions. While these technological breakthroughs signify a monumental evolution in drug discovery, there exist challenges like data gaps, unclear models, and ethical considerations. This chapter provides a comprehensive overview of the present drug discovery techniques, outlines prevalent challenges, and suggests potential solutions.</p>},
  keywords={Drugs;Deep learning;Natural language processing;Drug discovery;Random forests;Medical services;Machine learning algorithms;Internet;Hardware;Genetic algorithms},
  doi={10.1002/9781394234196.ch7},
  ISSN={},
  publisher={Wiley},
  isbn={9781394234189},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951560},}@INPROCEEDINGS{8537810,
  author={},
  booktitle={2018 IEEE 4th International Conference on Collaboration and Internet Computing (CIC)}, 
  title={CIC 2018 Tutorials}, 
  year={2018},
  volume={},
  number={},
  pages={25-33},
  abstract={Provides an abstract for each of the tutorial presentations and may include a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.},
  keywords={Cloud computing;Artificial intelligence;Internet of Things;Tutorials;Distributed databases;Safety},
  doi={10.1109/CIC.2018.00-47},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9883242,
  author={Zhang, Huan and Sun, Yingzhi and Liao, Yu and Xu, SiYuan and Yang, Rui and Wang, Shuang and Hou, Biao and Jiao, Licheng},
  booktitle={IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium}, 
  title={A Transformer-Based Cross-Modal Image-Text Retrieval Method using Feature Decoupling and Reconstruction}, 
  year={2022},
  volume={},
  number={},
  pages={1796-1799},
  abstract={With the increasing application of remote sensing technology, the task of cross-modal retrieval of remote sensing images (CMRRS) has gradually attracted widespread attention. Ex-isting methods often completely map the features of different modalities to a shared space and do not decouple between the modal-invariant information and modal-heterogeneous in-formation, which leads to redundant information in feature mapping and usually gets sub-optimal retrieval performance. This paper proposes a Transformer-based CMRRS method using feature decoupling and reconstruction (TBFDR) to solve this problem. TBFDR achieves state-of-the-art performance in remote sensing image-text retrieval task on Sydney-Captions dataset.},
  keywords={Measurement;Reconstruction algorithms;Transformers;Adversarial machine learning;Sensors;Task analysis;Remote sensing;cross-modal retrieval;remote sensing;feature decoupling;adversarial learning;transformer},
  doi={10.1109/IGARSS46834.2022.9883242},
  ISSN={2153-7003},
  month={July},}@INPROCEEDINGS{10222528,
  author={Huang, Yiming and Liu, Guole and Luo, Yaoru and Yang, Ge},
  booktitle={2023 IEEE International Conference on Image Processing (ICIP)}, 
  title={ADFA: Attention-Augmented Differentiable Top-K Feature Adaptation for Unsupervised Medical Anomaly Detection}, 
  year={2023},
  volume={},
  number={},
  pages={206-210},
  abstract={The scarcity of annotated data, particularly for rare diseases, limits the variability of training data and the range of detectable lesions, presenting a significant challenge for supervised anomaly detection in medical imaging. To solve this problem, we propose a novel unsupervised method for medical image anomaly detection: Attention-Augmented Differentiable top-k Feature Adaptation (ADFA). The method utilizes Wide-ResNet50-2 (WR50) network pre-trained on ImageNet to extract initial feature representations. To reduce the channel dimensionality while preserving relevant channel information, we employ an attention-augmented patch descriptor on the extracted features. We then apply differentiable top-k feature adaptation to train the patch descriptor, mapping the extracted feature representations to a new vector space, enabling effective detection of anomalies. Experiments show that ADFA outperforms state-of-the-art (SOTA) methods on multiple challenging medical image datasets, confirming its effectiveness in medical anomaly detection.},
  keywords={Location awareness;Image analysis;Training data;Feature extraction;Lesions;Anomaly detection;Biomedical imaging;anomaly detection;medical image;unsupervised learning;attention mechanism;feature adaptation},
  doi={10.1109/ICIP49359.2023.10222528},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9554533,
  author={Yang, Rui and Gu, Yu and Liao, Yu and Zhang, Huan and Sun, Yingzhi and Wang, Shuang and Hou, Biao and Jiao, Licheng and Zhang, He},
  booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, 
  title={Cross-Modal Feature Fusion Retrieval for Remote Sensing Image-Voice Retrieval}, 
  year={2021},
  volume={},
  number={},
  pages={2855-2858},
  abstract={With the increasing popularity of remote sensing technology applications, some emergency scenarios require rapid retrieval of remote sensing images, such as earthquake rescue, etc. Due to the high efficiency of voice input, researchers have focused on cross-modal remote sensing image-voice retrieval methods. However, these methods have two major drawbacks: speech input lacks discrimination and the intra-modal semantic information is under used. To address these drawbacks, we propose a novel cross-modal feature fusion retrieval model. Our model provides a more optimized cross-modal common feature space than previous models and thus optimizes the retrieval performance. First, our model adds the extra textual keyword information to the audio feature for remote sensing image retrieval. Second, it introduces inter-modality adversarial learning and intra-modality semantic discrimination into the remote sensing image-voice retrieval task. We conducted experiments on two datasets modified from the UCM-Captions dataset and the Remote Sensing Image Caption Dataset. The experimental results show that our model outperforms state-of-the-art models in this task.},
  keywords={Visualization;Semantics;Image retrieval;Earthquakes;Adversarial machine learning;Sensors;Task analysis;cross-modal retrieval;remote sensing;feature fusion;adversarial learning},
  doi={10.1109/IGARSS47720.2021.9554533},
  ISSN={2153-7003},
  month={July},}@ARTICLE{10981777,
  author={Jahanmanesh, Pooyan and Farhadi, Amirfarhad and Zamanifar, Azadeh},
  journal={IEEE Access}, 
  title={Mobility Management With AI}, 
  year={2025},
  volume={13},
  number={},
  pages={83022-83060},
  abstract={Today, considering the complexity of different types of networks worldwide and the variety of different pathways for mobility, researchers are interested in research and analysis in mobility management, one of the critical aspects of network management. Mobility management is used for many cases, such as urban management, location-based services (LBS), collision avoidance and tourism industry improvement. On the other hand, the dramatic advances in artificial intelligence (AI) have attracted much attention to the use of this tool in network management, using which they can quickly predict the following route or destination of users in the network in different scenarios. However, there are many challenges in this field, and ignoring them reduces the accuracy of the models. In this paper, We introduce the methods that researchers have presented and mention the advantages and disadvantages of each. The articles used include reputable journals from 2020 to 2025. Mobility management is done by focusing on four topics human mobility, vehicle, aircraft and ship. After introducing the approaches, we categorized and compared these models with related articles. Then, we showed the important items used in the articles, such as datasets, in the diagram and introduced the most used and famous ones. Also, commonly used metrics were reviewed. We highlight aspects that can help improve the performance of models. By considering these aspects, researchers can introduce more practical models that achieve lower errors using metrics such as Root-mean-square deviation (RMSE).},
  keywords={Artificial intelligence;Predictive models;Hidden Markov models;Data models;Measurement;Marine vehicles;Aircraft;Accuracy;Trajectory;Generative adversarial networks;Mobility management;artificial intelligence;mobility prediction;network management;deep learning;machine learning},
  doi={10.1109/ACCESS.2025.3566337},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10980939,
  author={Gong, Chaohui and Huang, Zisheng and Wu, Zhiying and Zhao, Mingyang and Xu, Fan and Bai, Xuexue and Feng, Ming and Granados, Alejandro and Meng, Gaofeng and Lei, Zhen and Liu, Hongbin},
  booktitle={2025 IEEE 22nd International Symposium on Biomedical Imaging (ISBI)}, 
  title={MR-to-CT Translation Using Frequency-Separated Diffusion Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Diffusion models have shown great potential in generating high-quality images for magnetic resonance (MR)-to-computed tomography (CT) translation. However, existing diffusion models have limitations in preserving skeletal structures, especially for unpaired datasets. The preservation of skeletal structural details is crucial to avoid disease misidentification and to achieve accurate medical diagnosis and treatment planning. In this paper, a frequency-separated diffusion model (FSDM) is proposed to maintain skeletal structural details, whereby a frequency-separated module can effectively separate the frequency components of medical images in the Fourier domain. In the proposed FSDM, a frequency conversion module is incorporated to convert the MR images into frequency-specific outputs. It leverages the frequency-specific information to guide a subsequent diffusion model for MR-to-CT translation. The results on a public brain dataset demonstrate that our method outperforms the state-of-the-art methods in metrics of Structural Similarity Index Measure (SSIM) and Peak Signal-to-Noise Ratio (PSNR). Our experiments show that FSDM can generate high-quality CT images while preserving skeletal structural details. Our code will be publicly available.},
  keywords={Translation;PSNR;Frequency-domain analysis;Computed tomography;Diffusion models;Frequency conversion;Planning;Medical diagnosis;Reliability;Medical diagnostic imaging;MR-to-CT Translation;Frequency separated diffusion model;Patch contrastive alignment},
  doi={10.1109/ISBI60581.2025.10980939},
  ISSN={1945-8452},
  month={April},}@INPROCEEDINGS{9970668,
  author={Zhang, Zhiming and Jin, Lina and Gao, Tianzhu},
  booktitle={2022 International Conference on Cyber-Physical Social Intelligence (ICCSI)}, 
  title={Research on Underwater Image Enhancement Algorithm Based on SRGAN}, 
  year={2022},
  volume={},
  number={},
  pages={374-379},
  abstract={Due to the limitation of the special underwater imaging environment, underwater images usually have problems such as low contrast, blurred texture features, color distortion and so on. Based on the typical problem of underwater images, this paper improves the network structure and loss function on the basis of the original SRGAN network model, and achieves good results. The generative network reduces the convolutional layers and removes the normalization layer (BN layer), reducing resource consumption. The loss function introduces L1 content loss and VGG19 perceptual loss to improve the stability of training. The experimental results show that the improved SRGAN network model effectively solves the color distortion and blurring of underwater images, and has a good enhancement effect on underwater images.},
  keywords={Training;Image quality;Image color analysis;Superresolution;Imaging;Distortion;Stability analysis;deep learning;super resolution generative adversarial(SRGAN);underwater image enhancement},
  doi={10.1109/ICCSI55536.2022.9970668},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10797604,
  author={Sahu, Barnali and Das, Sanjog and Pattnaik, Ayush and Puri, Abhishek and Mohanty, Kasmik},
  booktitle={2024 3rd Odisha International Conference on Electrical Power Engineering, Communication and Computing Technology (ODICON)}, 
  title={Navigating Data Abundance: Generative Conversational AI Agents in Information Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In response to the escalating challenges posed by information overload, particularly in today's data-rich environment, we propose the development of a sophisticated Generative Conversational AI Agent (GCAIA) tailored specifically for information retrieval tasks. This innovative system integrates cutting-edge techniques in natural language processing, machine learning, and generative modeling to provide users with an intuitive platform for accessing, analyzing, and retrieving information across diverse domains. Key features include robust natural language understanding facilitating seamless interaction, efficient retrieval mechanisms enabling quick access to relevant data, contextual adaptation for delivering personalized responses, generative capabilities fostering natural and engaging conversations, multimodal integration supporting various data formats, and utilization of knowledge graphs for enhanced organization and semantic understanding. Through rigorous research, development, and evaluation processes, our goal is to demonstrate the effectiveness, reliability, and scalability of the GCAIA in significantly improving information retrieval processes across diverse domains. Ultimately, our aim is to empower users to navigate the ever-expanding landscape of knowledge and data effectively, thus mitigating the challenges posed by information overload in the digital age.},
  keywords={Power engineering;Conversational artificial intelligence;Navigation;Scalability;Semantics;Organizations;Oral communication;Information retrieval;Natural language processing;Reliability;Generative Conversational AI;Information retrieval;Machine Learning},
  doi={10.1109/ODICON62106.2024.10797604},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10466226,
  author={Verma, Seema and Arora, Vasudha and Perumal, Thinagaran},
  booktitle={2023 International Conference on Advances in Computation, Communication and Information Technology (ICAICCIT)}, 
  title={Art Generation AI Model for Low-End Devices}, 
  year={2023},
  volume={},
  number={},
  pages={30-35},
  abstract={Art is a powerful medium of emotional expression, using elements like color, sound, and form. It reflects the artist's personality and the era they lived in, telling captivating stories. AI has advanced in generating and manipulating high-quality images using text prompts. Generative Adversarial Networks (GANs) revolutionized image generation, leading to various models like Open-Edit, GLIDE, DALL-E, and VQGAN. These models have shown impressive capabilities, producing creative outputs. However, accessibility remains a challenge due to the computational resources required.This work aims to enable art generation on low-end devices, making AI-driven art more accessible. One major challenge identified in the models is the high memory demand during image creation. Here, the chosen method, VQGAN-Clip, allows for image creation and manipulation solely through human-written text prompts. To address the memory constraint, the sliding window method is used in conjunction with VQGAN-Clip. This approach effectively reduces the VRAM requirement from 8 GB to 2 GB for generating images of the same size.},
  keywords={Art;Image synthesis;Image color analysis;Computational modeling;Memory management;Speech recognition;Generative adversarial networks;GAN;Sliding Window;Performance},
  doi={10.1109/ICAICCIT60255.2023.10466226},
  ISSN={},
  month={Nov},}@ARTICLE{11017600,
  author={Yoo, Yongseon and Kim, Seonggyu and Lee, Jong-Min},
  journal={IEEE Access}, 
  title={Comprehensive Style Transfer for Facial Images Using Enhanced Feature Attribution in Generative Adversarial Nets}, 
  year={2025},
  volume={13},
  number={},
  pages={99145-99159},
  abstract={Image-to-image translation is a fundamental task in computer vision that transforms images between domains while preserving essential content. Although adaptive instance normalization (AdaIN) is widely used for style transfer, its reliance on simple statistical measures (mean and variance) may limit its ability to capture complex style characteristics. We propose a novel framework that enhances style transfer by combining AdaIN with Gram matrices, leveraging the complementary strengths of both approaches. Our method introduces two key innovations for enhanced feature attribution: 1) dual Gram matrix-based loss functions (G1 and G2), which operate at different stages of the generation process to capture richer style information by establishing deeper correlations between feature maps, and 2) a balanced training objective that integrates perceptual loss with cycle-consistency loss to maintain content fidelity during style transfer. This comprehensive feature attribution mechanism enables our model to decompose and reassign stylistic elements across domains more precisely. Through ablation studies, we demonstrate that each component of our framework contributes to performance improvements, with the complete model achieving the best results on both the CelebA-HQ and FFHQ datasets. Our comprehensive evaluation, using distribution similarity metrics, classification-based assessments, and visual comparisons, demonstrates that our approach effectively captures and transfers complex style characteristics while preserving content integrity, outperforming state-of-the-art models. Specifically, our model achieves superior Fréchet Inception Distance (FID) scores (19.88 vs. 24.22) and recognition accuracy (0.966 vs. 0.941) compared to StarGAN v2, confirming the performance gains introduced by our enhanced feature attribution strategy.},
  keywords={Translation;Generators;Visualization;Feature extraction;Numerical models;Correlation;Training;Standards;Convolutional neural networks;Transforms;Image-to-image translation;style transfer;gram matrix;generative adversarial networks (GANs);style application;style evaluation},
  doi={10.1109/ACCESS.2025.3574729},
  ISSN={2169-3536},
  month={},}@ARTICLE{10806626,
  author={Pang, Chao and Wang, Yu and Jiang, Yi and Wang, Ruheng and Yao, Xiaojun and Zou, Quan and Zeng, Xiangxiang and Su, Ran and Wei, Leyi},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Multiview Deep Learning-Based Molecule Design and Structural Optimization Accelerates Inhibitor Discover}, 
  year={2025},
  volume={36},
  number={8},
  pages={14022-14036},
  abstract={In this work, we propose MEDICO, a multiview deep generative model for molecule generation, structural optimization, and the SARS-CoV-2 inhibitor discovery. To the best of our knowledge, MEDICO is the first-of-this-kind graph generative model that can generate molecular graphs similar to the structure of targeted molecules, with a multiview representation learning framework to sufficiently and adaptively learn comprehensive structural semantics from targeted molecular topology and geometry. We show that our MEDICO significantly outperforms the state-of-the-art methods in generating valid, novel, and unique molecules under benchmarking comparisons, particularly achieving  $\tilde {8}5 \%$  improvement compared with the state-of-the-art methods in terms of validity. Importantly, we showcase that the multiview deep learning model enables us to generate not only the molecules structurally similar to the targeted molecules but also the molecules with desired chemical properties. Moreover, case study results on targeted molecule generation for the SARS-CoV-2 main protease (Mpro) show that we successfully generate new small molecules with desired drug-like properties for the Mpro by integrating molecular docking into our model as a chemical priori, potentially accelerating the de novo design of COVID-19 drugs. Furthermore, we apply MEDICO to the structural optimization of three well-known Mpro inhibitors (N3, 11a, and GC376) and achieve  $\tilde {8}8 \%$  improvement compared with the origin inhibitors in their binding affinity to Mpro, demonstrating the application value of our model for the development of therapeutics for SARS-CoV-2 infection.},
  keywords={Geometry;Chemicals;Three-dimensional displays;Topology;Drugs;Atoms;Computational modeling;Tensors;Optimization;Inhibitors;Generative model;machine learning;multiview learning},
  doi={10.1109/TNNLS.2024.3506619},
  ISSN={2162-2388},
  month={Aug},}@INPROCEEDINGS{9929762,
  author={Wang, Jiafeng and Liu, Ming and Yin, Xiaokang and Zhao, Yuhao and Liu, Shengli},
  booktitle={2022 IEEE 6th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC )}, 
  title={Semi-supervised Malicious Traffic Detection with Improved Wasserstein Generative Adversarial Network with Gradient Penalty}, 
  year={2022},
  volume={},
  number={},
  pages={1916-1922},
  abstract={With the development of artificial intelligence, malicious traffic detection technology based on deep learning has become mainstream with its powerful detection performance. Most existing deep learning-based detection methods require sufficient labeled data to train classifiers. But much labeled traffic is difficult to obtain in practical applications. To solve this problem, we propose and implement a semi-supervised malicious traffic detection method based on improved Wasserstein Generative Adversarial Network with Gradient Penalized (WGAN-GP), denoted as SEMI-WGAN-GP. First, we construct a pseudo- feature map (PFM) for each stream in the dataset using the time-series properties of consecutive packets in a given stream. Second, we fix the generator and only train the discriminator on a few labeled PFMs, which obtain a discriminator that can distinguish malicious from benign traffic. Finally, the generator and discriminator are trained unsupervisedly in the adversarial setting, which allows the discriminator to improve detection performance by generator-generated PFMs. Experiments on the publicly available UNSW-NB15 dataset demonstrate that SEMI-WGAN-GP can achieve 90.53% accuracy using a few labeled samples (20% of the samples in the dataset are marked), exceeding the 79.92% and 84.94% of fully supervised multilayer perceptron network (MLP) and 2- dimensional convolutional neural network (2DCNN). In addition, SEMI-WGAN-GP also achieves better detection performance than SEMI-DCGAN by generating better samples.},
  keywords={Training;Deep learning;Automation;Neural networks;Multilayer perceptrons;Generative adversarial networks;Generators;traffic detection;semi-supervised learning;generative adversarial networks;malicious traffic},
  doi={10.1109/IAEAC54830.2022.9929762},
  ISSN={2689-6621},
  month={Oct},}@INPROCEEDINGS{10827504,
  author={Nguyen, Tri-Hai and Nguyen, Truong Khang and Quoc Bao, Vo Nguyen and Park, Heejae and Park, Laihyuk},
  booktitle={2024 15th International Conference on Information and Communication Technology Convergence (ICTC)}, 
  title={Generative AI-Powered Aerial Access Networks: Recent Studies and Future Outlook}, 
  year={2024},
  volume={},
  number={},
  pages={529-533},
  abstract={Aerial access networks (AANs), comprising un-manned aerial vehicles (UAV), high-altitude platforms (HAPs), and low-earth orbit (LEO) satellites, are rapidly emerging as a critical component of next-generation communication systems. Their dynamic nature, heterogeneous composition, and vast coverage area pose significant challenges for network management and optimization. Generative artificial intelligence (GenAI), renowned for its ability to generate new content, offers a promising solution to these challenges. In this paper, we explore the applications of GenAI in AANs in recent studies. We also identify key challenges and outline promising research directions.},
  keywords={Satellites;Reviews;Generative AI;Low earth orbit satellites;Orbits;Information and communication technology;Security;Vehicle dynamics;Optimization;Next generation networking;aerial access network;generative AI;recent studies;future outlook},
  doi={10.1109/ICTC62082.2024.10827504},
  ISSN={2162-1241},
  month={Oct},}@ARTICLE{9426423,
  author={Kong, Fanhui and Li, Jianqiang and Jiang, Bin and Wang, Huihui and Song, Houbing},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Integrated Generative Model for Industrial Anomaly Detection via Bidirectional LSTM and Attention Mechanism}, 
  year={2023},
  volume={19},
  number={1},
  pages={541-550},
  abstract={For emerging industrial Internet of Things (IIoT), intelligent anomaly detection is a key step to build smart industry. Especially, explosive time-series data pose enormous challenges to the information mining and processing for modern industry. How to identify and detect the multidimensional industrial time-series anomaly is an important issue. However, most of the existing studies fail to handle with large amounts of unlabeled data, thus generating the undesirable results. In this article, we propose a novel integrated deep generative model, which is built by generative adversarial networks based on bidirectional long short-term memory and attention mechanism (AMBi-GAN). The structure for the generator and the discriminator is the bidirectional long short-term memory with attention mechanism, which can capture time-series dependence. Reconstruction loss and generation loss test the input of sample training space and random latent space. Experimental results show that the detection performance of our proposed AMBi-GAN has the potential to improve the detection accuracy of industrial multidimensional time-series anomaly toward IIoT in the era of artificial intelligence.},
  keywords={Time series analysis;Anomaly detection;Hidden Markov models;Generative adversarial networks;Generators;Training;Data models;Anomaly detection;attention mechanism;bidirectional long short-term memory (LSTM);industrial time series;integrated generative model},
  doi={10.1109/TII.2021.3078192},
  ISSN={1941-0050},
  month={Jan},}@INPROCEEDINGS{10853439,
  author={Huang, David},
  booktitle={2nd International Conference on Mechatronic Automation and Electrical Engineering (ICMAEE 2024)}, 
  title={Using generative artificial intelligence in text generation}, 
  year={2024},
  volume={2024},
  number={},
  pages={264-267},
  abstract={One of the most impactful uses of Artificial Intelligence lies within the domain of text generation. Leveraging discoveries made from Natural Language Processing, Deep Learning, and Large Language Models, text generation has rapidly integrated into modern life. It provides tools that allow anyone on the web to summarize materials, check grammar, and more. To navigate the progress generative text has undergone in the last couple of decades, this work examines a comprehensive review of research that addresses the fundamental components in building an effective model, ranging from the initial developments in algorithmic modules to the advent of neural networks. Then there is a further focuses on the challenges associated with such developments primarily in how the user interacts with the text, the responsiveness of the text, and the grammatical discrepancies between human & machine content. Accordingly, different tools and models are used to varying degrees of success in tackling these issues.},
  keywords={},
  doi={10.1049/icp.2024.4493},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9515223,
  author={Ganepola, Vayangi Vishmi Vishara and Wirasingha, Torin},
  booktitle={2021 IEEE 4th International Conference on Big Data and Artificial Intelligence (BDAI)}, 
  title={Generative Adversarial Networks Using Neural Architecture Search for Semantic Image Segmentation}, 
  year={2021},
  volume={},
  number={},
  pages={236-241},
  abstract={Semantic image segmentation is a crucial task in various fields that use computer-vision based applications. Generative Adversarial Networks (GANs) are attracting widespread interest in the data science community for their prowess in image feature recognition due to their adversarial nature of training. Neural Architecture Search (NAS) is known as the process of obtaining a neural architectural schema that performs the best for a particular task. NAS has been applied in GANs, and it achieved striking success compared to human-designed architectures in conditional and unconditional image generation and GAN-compression. Our research was inspired by the success of NAS applied in GANs. This paper proposes a novel approach for NAS in GANs for semantic image segmentation. After extensive research on related works, the architecture of the Pix2Pix GAN variant was selected for the proposed approach. The architecture of the Pix2Pix GAN consists of a U-Net as the Generator and a PatchGAN classifier as the Discriminator. The NAS component is searched for U-Net architectures using PASCAL VOC 2012 dataset. The NAS component is adapted from using the NAS-Unet research proposed by Weng et al. in 2019. The NAS searched architecture was used as the Generator of the proposed GAN by transferring the searched architecture from the PASCAL VOC 2012 dataset to the Cityscapes dataset. To determine the success of the proposed approach, quantitative analysis was performed with Mean Pixel Accuracy (MPA) and mean Intersection over Union (mIoU) metrics. Several experiments were done on the Cityscape validation set and achieved 81.73 MPA and 71.91 mIoU. The proposed approach outperformed several NAS in semantic segmentation approaches and GANs in semantic segmentation approaches. This study is a preliminary attempt to apply NAS for semantic segmentation using GANs. Further, this research has raised many possible areas in need of further investigation.},
  keywords={Training;Measurement;Image segmentation;Statistical analysis;Image synthesis;Semantics;Computer architecture;semantic segmentation;generative adversarial networks;neural architecture search},
  doi={10.1109/BDAI52447.2021.9515223},
  ISSN={},
  month={July},}@ARTICLE{10570229,
  author={Chen, Ning and Yang, Jie and Cheng, Zhipeng and Fan, Xuwei and Liu, Zhang and Huang, Bangzhen and Zhao, Yifeng and Huang, Lianfen and Du, Xiaojiang and Guizani, Mohsen},
  journal={IEEE Network}, 
  title={GainNet: Coordinates the Odd Couple of Generative AI and 6G Networks}, 
  year={2024},
  volume={38},
  number={5},
  pages={56-65},
  abstract={The rapid expansion of AI-generated content (AIGC) reflects the iteration from assistive AI towards generative AI (GAI). Meanwhile, the 6G networks will also evolve from the Internet-of-Everything to the Internet-of-Intelligence. However, they seem to be an odd couple, due to the contradiction of data and resources. To achieve a better-coordinated interplay between GAI and 6G, the GAI-native Networks (GainNet), a GAI-oriented collaborative cloud-edge-end intelligence framework, is proposed in this article. By deeply integrating GAI with 6G network design, GainNet realizes the positive closed-loop knowledge flow and sustainable-evolution GAI model optimization. On this basis, the GAI-oriented generic Resource Orchestration Mechanism with Integrated Sensing, Communication, and Computing (GaiRomISCC) is proposed to guarantee the efficient operation of GainNet. Two simple case studies demonstrate the effectiveness and robustness of the proposed schemes. Finally, we envision the key challenges and future directions concerning the interplay between GAI models and 6G networks.},
  keywords={6G mobile communication;Computational modeling;Data models;Artificial intelligence;Knowledge engineering;Sensors;Optimization;Cloud computing;Resource management;6G;generative AI;collaborative cloud-edge-end intelligence;resource orchestration;integrated sensing;communication;computing},
  doi={10.1109/MNET.2024.3418671},
  ISSN={1558-156X},
  month={Sep.},}@INPROCEEDINGS{9045713,
  author={Teranishi, Hiroki and Okada, Makoto and Mori, Naoki},
  booktitle={2019 14th International Joint Symposium on Artificial Intelligence and Natural Language Processing (iSAI-NLP)}, 
  title={Hierarchical Attention Model for Acquiring Relationships Among Sentences}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={In this paper, we propose a hierarchical attention model for summarization. Normally, sentences have relations among another sentence and it is important to consider these relations in summarizing. Our proposed model can make each sentence vectors from document composed of multi sentences and get relations among sentences from these vectors by the incorporated operation. As an operation of taking relations, we use self-attention and gated convolutional neural network. It has been reported that these operations can get dependencies among words, and self-attention is particularly powerful. Therefore we adopted these operations expecting the same work in sentences. We conducted an experiment of title generation by using Japanese news articles. We evaluated the performance of our proposed model by Rouge and visualized the relations among sentences.},
  keywords={Heating systems;Attention mechanisms;Data visualization;Logic gates;Vectors;Natural language processing;Convolutional neural networks;Artificial intelligence;nueral network;attention mechanism;generative summarization},
  doi={10.1109/iSAI-NLP48611.2019.9045713},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9724833,
  author={Li, Quanfeng and Hu, Lingxi and Shang, Qiqi and Wang, Yawen and Jiang, Linhua and Long, Wei},
  booktitle={2021 3rd International Conference on Artificial Intelligence and Advanced Manufacture (AIAM)}, 
  title={Research Progress in the Field of Image Completion}, 
  year={2021},
  volume={},
  number={},
  pages={398-402},
  abstract={Image completion technology is a challenging research direction in the field of image restoration. The traditional image completion technology mainly fills the missing areas with missing values based on the information of the unmissed areas of the image. Traditional image completion can well complement images with a small missing area and relatively simple texture structure, but it does not work well for images with large missing areas or complex texture structures. With the continuous development of deep learning, the performance of image restoration has been significantly improved. The image completion method based on deep learning can learn the high-level features of the image, so that the result of the completion is more realistic. This article reviews the image completion technology, introduces the basic principles of typical methods and compares their advantages and disadvantages. Finally, we analyze the future research directions in this field and put forward prospects.},
  keywords={Deep learning;Image restoration;Artificial intelligence;image completion;deep learning;generative adversarial network},
  doi={10.1109/AIAM54119.2021.00086},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9643214,
  author={Qiu, Jingjun and Gao, Yan},
  booktitle={2021 IEEE 33rd International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={User-Guided Image Inpatinting with Transformer}, 
  year={2021},
  volume={},
  number={},
  pages={1099-1104},
  abstract={Deep learning has brought unprecedented progress to image inpainting. Most of the image inpainting methods with guidance mainly use the line as guiding information, which is still a huge challenge for ordinary users. Thus, we propose a novel method for user-guided image inpainting, this method can achieve interactive object extraction in the guided image and add the target object to the original image reasonably. Our model splits this task into three parts: interactive mask extractor, guided feature extractor and inpainting network. The interactive mask extractor can interactively extract the target object from the guided image. Then, we adopt the guided feature extractor to extract the features of the target object, Finally, the inpainting network generates the fine-grained images by fusing the features from the original and guided image. The experimental results prove that our model has a higher inpainting quality than the existing state-of-the-art approaches.},
  keywords={Deep learning;Fuses;Conferences;Learning (artificial intelligence);Feature extraction;Transformers;Data mining;Inpainting;Generative model;Deep learning},
  doi={10.1109/ICTAI52525.2021.00174},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{10277883,
  author={Sun, Jifeng and Zhao, Shuai and Lin, Yibin},
  booktitle={2023 2nd International Conference on Artificial Intelligence and Computer Information Technology (AICIT)}, 
  title={The Super-Resolution Reconstruction Based on Domain Adaptation Model}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={A super-resolution reconstruction method based on domain adaptation model is proposed in this paper. The experimental result on the super-resolution reconstruction shows the effectiveness of the proposed scheme.},
  keywords={Degradation;Adaptation models;Computational modeling;Superresolution;Reconstruction algorithms;Information technology;Artificial intelligence;super-resolution reconstruction;domain adaptation model;degraded generative network;transformer},
  doi={10.1109/AICIT59054.2023.10277883},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11050667,
  author={Fan, Tiffany and Cutforth, Murray and D'Elia, Marta and Cortiella, Alexandre and Doostan, Alireza and Darve, Eric},
  booktitle={2025 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Physically Interpretable Representation and Controlled Generation for Turbulence Data}, 
  year={2025},
  volume={},
  number={},
  pages={1084-1085},
  abstract={Computational Fluid Dynamics (CFD) is central to fluid mechanics, offering precise simulations of fluid behavior through partial differential equations (PDEs). Traditional CFD methods, such as those based on finite difference and finite volume schemes, are resource-consuming, especially for high-fidelity simulations of complex flows. Understanding such datasets presents unique challenges due to their high dimensionality, inherent stochasticity, and limited data availability.},
  keywords={Dimensionality reduction;Solid modeling;Translation;Computational fluid dynamics;Computational modeling;Soft sensors;Partial differential equations;Learning (artificial intelligence);Mathematical models;Finite difference methods;dimension reduction;generative modeling;interpretability;unsupervised learning},
  doi={10.1109/CAI64502.2025.00188},
  ISSN={},
  month={May},}@ARTICLE{9216082,
  author={Xue, Jieting and Guo, Jingtao and Liu, Yi},
  journal={IEEE Access}, 
  title={User-Guided Chinese Painting Completion–A Generative Adversarial Network Approach}, 
  year={2020},
  volume={8},
  number={},
  pages={187431-187440},
  abstract={Image completion models based on deep neural networks have been a research hot spot in computer vision. However, most of the previous methods focus on natural images, such as faces and landscapes. In this paper, we propose a novel image completion model for a special set of artificial ancient Chinese paintings to address this limitation. Specifically, we integrate three complements: the Wasserstein Generative Adversarial Networks (WGAN), Perceptual loss, and Mean Squared Error (MSE) to train the model robustly. We propose a unique generator which can not only pay more attention to complete the details of ancient Chinese paintings but also can provide the synthesized lines to help artists to analyze paintings conveniently. Additionally, we also allow a user to supply a structure hint to guide our model to complete Chinese paintings according to his/her preference. Extensive experiments firmly demonstrate the effectiveness of our approach to complete ancient Chinese paintings and remove abnormal color blocks from them.},
  keywords={Painting;Generative adversarial networks;Generators;Gallium nitride;Decoding;Computational modeling;Neural networks;Deep learning;Generative adversarial network;Image completion},
  doi={10.1109/ACCESS.2020.3029084},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10803329,
  author={Deng, Kainan and Liu, Xiang and Xu, Dongming and Sengupta, Avijit},
  booktitle={2024 IEEE International Conference on Medical Artificial Intelligence (MedAI)}, 
  title={Revolutionizing Digital Health with Generative AI: User Experiences and Healthcare Performance}, 
  year={2024},
  volume={},
  number={},
  pages={366-371},
  abstract={Generative artificial intelligence (GenAl) is revolutionizing digital health by enhancing diagnostic accuracy, predicting health risks, and reducing wait times and costs. This study adopts an inductive approach to analyze user experiences with GenAl through social media comments. We construct a conceptual framework and find that users, including physicians and patients/general users, have varying needs that need to be met using different GenAl types. Our conceptual framework also reveals the interactions among the characteristics of GenAl, users, and users' tasks. This research advances the field of Information Systems by bridging the gap between technology and user behavior in digital health. We also offer insights for future research to explore the influence of GenAl on users' behavior efficiently and how to effectively integrate GenAl tools into their clinical workflows, enhancing patient care and operational efficiency.},
  keywords={Costs;Accuracy;Generative AI;Social networking (online);Electronic healthcare;Medical diagnostic imaging;Information systems;generative AI;healthcare performance;user experiences;generative AI adoption;digital health},
  doi={10.1109/MedAI62885.2024.00055},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9619455,
  author={Guo, Haitao and Tang, Jian and Zhang, Hao and Wang, Dandan},
  booktitle={2021 3rd International Conference on Industrial Artificial Intelligence (IAI)}, 
  title={A method for generating images of abnormal combustion state in MSWI process based on DCGAN}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={This article is to provide qualified images of abnormal combustion state for the research of machine vision in municipal solid waste incineration (MSWI) process. Owing to the scarcity of the images of abnormal combustion state and the high cost of labeling, it is difficult to obtain sufficient images of abnormal combustion state. Aim at the problem, this paper proposes a method for generating images of abnormal combustion state based on a deep convolutional generative adversarial network (DCGAN). First, the real image data of abnormal combustion state is preprocessed. Second, the abnormal combustion state image generation generates false combustion images. Third, the real images and the generated images are fed into the discrimination network. The loss values are used to train the discrimination and generation. Finally, whether to update the parameters of the generation and discrimination network is determined by the error and epoch. The qualified generated abnormal combustion state images are obtained after the epoch setting met. The evaluation result of the generated image quality based on the Fréchet Inception Distance (FID) shows that DCGAN can realize the generation of abnormal combustion state images.},
  keywords={Waste management;Image quality;Waste materials;Image synthesis;Incineration;Machine vision;Generative adversarial networks;Municipal solid waste incineration (MSWI);Abnormal combustion state;Image generation;deep convolutional generative adversarial network (DCGAN)},
  doi={10.1109/IAI53119.2021.9619455},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11167619,
  author={Christian, Michael and Pardede, Ratlan and Dewantara, Yudhiet Fajar and Nan, Guan and Geng, Bi and Irlandra, Frendy},
  booktitle={2025 4th International Conference on Creative Communication and Innovative Technology (ICCIT)}, 
  title={Impact of AI-Generated Tourism Ads on Consumer Intent in Indonesian Market Using PLS-SEM}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={The integration of artificial intelligence (AI) in digital marketing has revolutionized consumer engagement, particularly through AI-generated advertisements. Despite growing applications, the effectiveness of these ads in influencing consumer behavior remains an area of ongoing exploration. This study investigates how AI-generated tourism advertisements affect the intention of Indonesian consumers to visit China. A quantitative experiment with 118 participants was conducted, using a structured questionnaire for data collection. The analysis applied Partial Least Squares Structural Equation Modeling (PLS-SEM) using SmartPLS software to examine the relationships between AI content characteristics and consumer intent. Results indicate that novelty and perceived eeriness of AI-generated advertisements significantly influence consumer travel intentions. Additionally, the synthesis of artificial elements in the ads impacts perceived eeriness, which indirectly affects travel intent. These findings suggest that while AI-generated advertisements can enhance novelty, addressing perceptions of eeriness is crucial for optimizing consumer engagement. This research contributes to the understanding of AI-driven digital marketing and provides valuable insights for tourism marketers aiming to improve the effectiveness of AI-based campaigns, while also supporting the Uncanny Valley theory in marketing applications.},
  keywords={Ethics;Data privacy;Generative AI;Data collection;Motion pictures;Mathematical models;Software;Advertising;Creativity;Guidelines;Artificial Intelligence;AI-Generated Tourism Advertisements;Perceived Eeriness;Intention to Visit},
  doi={10.1109/ICCIT65724.2025.11167619},
  ISSN={},
  month={Aug},}@ARTICLE{10570407,
  author={Kim, Dongseob and Shim, Hyunjung},
  journal={IEEE Access}, 
  title={Locally Conditioned GANs: Self-Supervised Local Patch Representation Learning for Conditional Generation}, 
  year={2024},
  volume={12},
  number={},
  pages={134115-134132},
  abstract={Existing conditional generation models using generative adversarial networks (GANs) suffer from two common limitations: 1) they heavily rely on supervision, or 2) their performance is favorable to the scenario of creating only small changes. This study aims to address both issues by introducing new locally conditioned generative adversarial networks (LCGAN). Inspired by self-supervised representation learning, we devise intuitive learning signals and training tactics to learn the local patch encoding for developing the locally controllable latent space of GANs. Powered by local patch encoding with our novel loss design, the proposed model successfully performs locally conditioned image generation while covering various attributes. Utilizing LCGAN, ordinary users can easily design an image by browsing its patch-level appearance from various patch examples, even including out-of-domain examples. Besides, LCGAN, with latent optimization, offers high-quality results in local editing. Experimental evaluations verify that our model is effective in both conditional generation and local editing in achieving both image quality and fidelity. Our method is the most preferred by 55.78% of user study participants, and it achieved Fréchet inception distance scores of 16.24 and 15.01 on the FFHQ and AFHQ-cat datasets, respectively. Especially, a comprehensive user study supports that: 1) trade-off between quality and fidelity exists in existing methods and 2) our model is the first to alleviate their trade-off relationships, showing the potential in practical image editing applications.},
  keywords={Training;Image synthesis;Generative adversarial networks;Semantics;Vectors;Representation learning;Image reconstruction;Condition monitoring;Generative adversarial network;conditional generation;image composition},
  doi={10.1109/ACCESS.2024.3418884},
  ISSN={2169-3536},
  month={},}@ARTICLE{10916662,
  author={Ha, Sangjun and Sung, Mingyu and Saeed, Faisal and Yun, Sangseok and Kim, Il-Min and Kang, Jae-Mo},
  journal={IEEE Internet of Things Journal}, 
  title={Generative-Diffusion-Model-Based Deep-Learning Framework for Remaining Useful Life Prediction}, 
  year={2025},
  volume={12},
  number={11},
  pages={18431-18434},
  abstract={In this letter, we propose a novel and high-performing deep learning framework for remaining useful life (RUL) prediction, called RUL-Diff, by leveraging a generative diffusion model. It is composed of two modules that are connected in tandem: 1) a feature extractor corresponding to the encoder part of our customized U-Net and 2) a RUL predictor constructed by a multilayer perceptron. We further devise an effective two-stage training methodology for the proposed RUL-Diff, in which the feature extractor is initially pretrained for high-quality feature learning, and then, is retrained jointly with the RUL predictor for accurate RUL prediction. Extensive experimental results on NASA Commercial Modular Aero-Propulsion System Simulation (C-MAPSS) datasets demonstrate the superiority and effectiveness of the proposed scheme.},
  keywords={Feature extraction;Training;Data mining;Representation learning;Network architecture;Internet of Things;Diffusion models;Convolutional neural networks;Time series analysis;Deep learning;Deep learning (DL);generative diffusion model;Internet-of-Things (IoT);remaining useful life (RUL) prediction},
  doi={10.1109/JIOT.2025.3549038},
  ISSN={2327-4662},
  month={June},}@INPROCEEDINGS{10889691,
  author={Chen, Zhiming and Wang, Desen and Fu, Sisi and Wen, Congcong and Lin, Hui and Chen, Bingzhi},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={A2GP-SF: Enhancing Few-shot Class Incremental Learning via Attribute Generative Prompting and Adaptive Sharpness Flattening}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Few-shot Class Incremental Learning (FSCIL) aims to incrementally learn new classes with limited examples while retaining knowledge of previously learned classes. Recent advancements in prompt tuning for large pre-trained models have shown promise in FSCIL. However, current FSCIL methods still suffer from challenges like insufficient plasticity and limited generalization. To tackle these challenges, we propose a novel prompt tuning-based framework named A2GP-SF, which integrates attribute generative prompting (AGP) and adaptive sharpness flattening (ASF). The proposed AGP paradigm dynamically generates attribute-aware prompts for each instance, facilitating better semantics learning and enhancing plasticity. Additionally, the ASF mechanism aims to mitigate overfitting by applying adaptive perturbations to flatten sharpness, with these perturbations adjusted based on gradient norm changes, thereby enhancing the model’s robustness and generalization. Extensive experiments on multiple benchmark datasets consistently demonstrate the superiority of our proposed A2GP-SF framework.},
  keywords={Adaptation models;Incremental learning;Perturbation methods;Semantics;Signal processing;Robustness;Power capacitors;Speech processing;Tuning;Overfitting;FSCIL;Insufficient Plasticity;Limited Generalization;Generative Prompting;Sharpness Flattening},
  doi={10.1109/ICASSP49660.2025.10889691},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10859114,
  author={Hu, Wenyue},
  booktitle={2024 International Conference on Computing, Robotics and System Sciences (ICRSS)}, 
  title={Intelligent Tourism Plan Making System Based on Machine Learning Technology}, 
  year={2024},
  volume={},
  number={},
  pages={140-146},
  abstract={Generative artificial intelligence will conduct in-depth analysis and mining of massive data in the tourism industry to help tourism enterprises and government departments make more accurate and scientific decisions. In order to further improve the user experience of tourist terminals, this study proposes a personalized tourist route generation modeling method based on user interest model. Moreover, after the theoretical research of this method is completed, its application value is analyzed, and the expected design goal is achieved. Therefore, in the future research, this model can be used to solve the route planning problem, and provide users with more personal tourism routes and tourism schemes. Through the experimental results, it can be seen that the route generation result of this model is good, which proves that this model has high application value. In addition, generative artificial intelligence technology imitates human creative thinking to generate a series of data, images, text or audio content that tourists need, thereby effectively improving the user experience.},
  keywords={Technological innovation;Privacy;Generative AI;Service robots;Tourism industry;Government;Machine learning;User experience;Planning;Optimization;machine learning;travel;protocols;intelligence;generate},
  doi={10.1109/ICRSS65752.2024.00032},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10671462,
  author={Zhu, Weihong and Hu, Changhui and Xu, Lintao},
  booktitle={2024 9th International Conference on Signal and Image Processing (ICSIP)}, 
  title={Real-World Blind Face Restoration with Generative Facial Prior and Degradation Simulation}, 
  year={2024},
  volume={},
  number={},
  pages={765-769},
  abstract={Real-world blind face restoration is very hard, since real-world blind face images are with unknown complex multiple degradations. Our previous work [1] proposed a joint image-to-image translation (JI2IT) method for real-world blind traffic monitoring driver face (TMDF) image restoration, whereas JI2IT is unsatisfactory to restore the facial details of real-world blind TMDF images. To tackle above issue, this paper proposes a RestormGAN for real-world image (i.e., TMDF image) restoration which consists of a channel axis attention based Restormer (CAR) encoder and a generative facial prior (i.e., GAN prior). Specifically, we propose to insert a novel channel height and width axes attention (CHWA) module into Restormer module to form CAR module, where CHWA contains the height-axis attention module (HAM) and the width-axis attention module (WAM). The HAM learns a weight for the height-axis of each channel while WAM learns a weight for the width-axis of each channel. Then the dual down-sampling (DDS) module is proposed to ensure the CAR encoder can be efficiently connected with GAN prior. DDS uses bilinear sampling and pixelunshuffle in parallel to generate more representative parameters. Finally, we propose to combine multi-handcraft degradations strategy and pretrained degradation model to construct massive image pairs for the training of RestormGAN. Extensive experiments demonstrate that our RestormGAN achieves state-of-the-art performances for real-world face restoration and superior results in traffic monitoring scenarios.},
  keywords={Degradation;Training;Generators;Image restoration;Automobiles;Faces;Monitoring;real-world blind face restoration;generative facial prior;transformer;traffic monitoring driver face image},
  doi={10.1109/ICSIP61881.2024.10671462},
  ISSN={2642-6471},
  month={July},}@INPROCEEDINGS{11063972,
  author={Ghadekar, Premanand and Paimode, Rupali and Pandav, Soham and Patange, Priyal and Pardeshi, Atharva and Patil, Paras},
  booktitle={2025 3rd International Conference on Communication, Security, and Artificial Intelligence (ICCSAI)}, 
  title={GAN AI for Predictive Threat Detection with Explainable Risk Insights}, 
  year={2025},
  volume={3},
  number={},
  pages={1446-1452},
  abstract={An AI-based approach for predicting and analysis cyber-attacks using a mixture of advanced machine and deep learning techniques. Using a dataset having 40,000 cyber-attacks, we aim to detect attack from its primary symptoms before it affect system, calculating it's impact score, predicting attack and the appropriate response, severity levels, anomaly scores, and detect unauthorized users. We apply preprocessing methods like one-hot encoding, standardization, and feature selection using the Mean Decrease Gini impurity method. Key algorithms implemented include XGBoost, and Generative AI (GEN AI) to simulate potential attack scenarios. Explainable AI method such as SHAP are used to ensure model are transperant and trustworthy. Predicting cyber-attack based on primary symptoms before it affects the system using XGBoost model gives the good accuracy. The results demonstrate that our approach, with XGBoost and synthetic data from GEN AI, achieves a 99.17% accuracy. The use of GAN make model Dynamic improve scalability and use of log loss, Softmax evaluation matrix improves XGBoost performance.},
  keywords={Deep learning;Accuracy;Generative AI;Explainable AI;Predictive models;Prediction algorithms;Threat assessment;Real-time systems;Cyberattack;Synthetic data;Cybersecurity;Generative AI;Explainable AI;XG-Boost;SHAP},
  doi={10.1109/ICCSAI64074.2025.11063972},
  ISSN={},
  month={April},}@INBOOK{10953280,
  author={Marr, Bernard},
  booktitle={Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society}, 
  title={Front Matter}, 
  year={2024},
  volume={},
  number={},
  pages={i-xiv},
  abstract={<p>The prelims comprise: <ul> <li>Half&#x2010;Title Page</li> <li>Title Page</li> <li>Copyright Page</li> <li>Dedication</li> <li>Contents</li> <li>About the Author</li> <li>Introduction</li> </ul> </p>},
  keywords={},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394254255},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10953280},}@INBOOK{10951261,
  author={Marr, Bernard},
  booktitle={Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society}, 
  title={APPENDIX: GENAI TOOLS}, 
  year={2024},
  volume={},
  number={},
  pages={249-270},
  abstract={},
  keywords={},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394254255},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10951261},}@INPROCEEDINGS{9780976,
  author={Su, Liyilei and Fu, Xianjun and Hu, Qingmao},
  booktitle={2021 IEEE 23rd Int Conf on High Performance Computing & Communications; 7th Int Conf on Data Science & Systems; 19th Int Conf on Smart City; 7th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)}, 
  title={A convolutional generative adversarial framework for data augmentation based on a robust optimal transport metric}, 
  year={2021},
  volume={},
  number={},
  pages={1155-1162},
  abstract={Enhancement of the vanilla generative adversarial network (GAN) to preserve data variability in the presence of real world noise is of paramount significance in deep learning. In this study, we proposed a new distance metric of cosine distance in the framework of optimal transport (OT), and presented and validated a convolutional neural network (CNN) based GAN framework. In comparison with state-of-the-art methods based on Graphics Processing Units (GPU), the proposed framework could maintain the data diversity and quality best in terms of inception score (IS), Fréchet inception distance (FID) and enhancing the classification network of bone age, and is robust to noise degradation. The proposed framework is independent of hardware and thus could also be extended to more advanced hardware such as specialized Tensor Processing Units (TPU), and could be a potential built-in component of a general deep learning networks for such applications as image classification, segmentation, registration, and object detection.},
  keywords={Measurement;Deep learning;Tensors;Smart cities;Neural networks;Graphics processing units;Object detection;Data augmentation;Generative adversarial network;Optimal transport;Convolutional neural network;Cosine distance},
  doi={10.1109/HPCC-DSS-SmartCity-DependSys53884.2021.00178},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10505401,
  author={Zhou, Jie and Wang, Yefei and Yuan, Yiyang and Huang, Qing and Zeng, Jinshan},
  booktitle={2023 2nd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR)}, 
  title={Effective Information Guidance for Chinese Font Generation with Skeleton and Channel Expansion}, 
  year={2023},
  volume={},
  number={},
  pages={273-287},
  abstract={The automatic generation of Chinese fonts is an important problem involved in many applications. The predominated methods for the Chinese font generation are based on deep generative models, especially the generative adversarial networks (GANs). However, existing GAN-based methods (say, CycleGAN) for the Chinese font generation usually suffer from the mode collapse issue, mainly due to the lack of effective information guidance. This paper proposes a novel information guidance module called the skeleton guided channel expansion (SGCE) module for the Chinese font generation through integrating the skeleton information into the generator with the channel expansion way, motivated by the observation that the skeleton embodies both local and global structure information of Chinese characters. We conduct extensive experiments to show the effectiveness of the proposed module. Numerical results show that the mode collapse issue suffered by the known CycleGAN can be effectively alleviated by equipping with the proposed SGCE module, and the CycleGAN equipped with SGCE outperforms the state-of-the-art models in terms of four important evaluation metrics and visualization quality. Besides CycleGAN, we also show that the suggested SGCE module can be adapted to other models for Chinese font generation as a plug-and-play module to further improve their performance.},
  keywords={Measurement;Human computer interaction;Adaptation models;Visualization;Generative adversarial networks;Skeleton;Generators;Chinese font generation;skeleton guided channel expansion;generative adversarial networks;mode collapse;skeleton;channel expansion},
  doi={10.1109/AIHCIR61661.2023.00053},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11082971,
  author={Minarno, Agus Eko and Soesanti, Indah and Nugroho, Hanung Adi},
  booktitle={2025 International Conference on Innovation in Artificial Intelligence and Internet of Things (AIIT)}, 
  title={Batik GAN for Generating Motif Synthesis using Multi-Discriminator and Self-Attention}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={This study proposes a novel approach for generating high-quality synthetic batik motifs by enhancing the Batik Generative Adversarial Network (Batik GAN) architecture with multi-discriminator and self-attention mechanisms. The proposed method addresses limitations in conventional GAN, particularly in capturing the intricate patterns, textures, and cultural elements inherent in traditional batik art. The Batik Nitik Sarimbit 120 dataset, comprising 120 images across 60 classes, serves as the foundation for training and evaluation, enriched with augmentation techniques to ensure robust learning. The multi discriminator framework enables comprehensive evaluation of synthetic motifs by focusing on distinct aspects such as global patterns, local details, and traditional elements, providing the generator with diverse and detailed feedback. Simultaneously, the self-attention layer allows the generator to dynamically prioritize critical motif elements, ensuring the preservation of spatial relationships and overall harmony in the patterns. Quantitative evaluation using FID, PSNR, and SSIM metrics demonstrates the superiority of the proposed method over the baseline Batik GAN SL and other tested variations. The proposed method achieved a significant reduction in FID, PSNR, and SSIM score. These results indicate enhanced visual fidelity, structural consistency, and noise reduction in the generated motifs. The findings highlight the effectiveness of integrating multi discriminator and self-attention mechanisms in Batik GAN, enabling the synthesis of realistic and culturally authentic batik motifs. This research contributes to the advancement of generative modeling in preserving and innovating traditional textile arts, with potential applications in digital heritage preservation and creative industries.},
  keywords={Measurement;Training;Visualization;Technological innovation;Art;Focusing;Generative adversarial networks;Generators;Cultural differences;Textiles;Generative Adversarial Networks;Batik GAN;Batik Nitik Sarimbit 120;Multi Discriminator;Self-Attention},
  doi={10.1109/AIIT63112.2025.11082971},
  ISSN={},
  month={May},}@ARTICLE{10081465,
  author={Xu, Jianjin and Zhang, Zhaoxiang and Hu, Xiaolin},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Extracting Semantic Knowledge From GANs With Unsupervised Learning}, 
  year={2023},
  volume={45},
  number={8},
  pages={9654-9668},
  abstract={Recently, unsupervised learning has made impressive progress on various tasks. Despite the dominance of discriminative models, increasing attention is drawn to representations learned by generative models and in particular, Generative Adversarial Networks (GANs). Previous works on the interpretation of GANs reveal that GANs encode semantics in feature maps in a linearly separable form. In this work, we further find that GAN's features can be well clustered with the linear separability assumption. We propose a novel clustering algorithm, named KLiSH, which leverages the linear separability to cluster GAN's features. KLiSH succeeds in extracting fine-grained semantics of GANs trained on datasets of various objects, e.g., car, portrait, animals, and so on. With KLiSH, we can sample images from GANs along with their segmentation masks and synthesize paired image-segmentation datasets. Using the synthesized datasets, we enable two downstream applications. First, we train semantic segmentation networks on these datasets and test them on real images, realizing unsupervised semantic segmentation. Second, we train image-to-image translation networks on the synthesized datasets, enabling semantic-conditional image synthesis without human annotations.},
  keywords={Semantics;Semantic segmentation;Generative adversarial networks;Clustering algorithms;Unsupervised learning;Image synthesis;Annotations;Conditional image synthesis;GAN;semantic segmentation;unsupervised learning},
  doi={10.1109/TPAMI.2023.3262140},
  ISSN={1939-3539},
  month={Aug},}@ARTICLE{9980408,
  author={Värtinen, Susanna and Hämäläinen, Perttu and Guckelsberger, Christian},
  journal={IEEE Transactions on Games}, 
  title={Generating Role-Playing Game Quests With GPT Language Models}, 
  year={2024},
  volume={16},
  number={1},
  pages={127-139},
  abstract={Quests represent an integral part of role-playing games (RPGs). While evocative, narrative-rich quests are still mostly hand-authored, player demands toward more and richer game content, as well as business requirements for continuous player engagement necessitate alternative, procedural quest generation methods. While existing methods produce mostly uninteresting, mechanical quest descriptions, recent advances in AI have brought forth generative language models with promising computational storytelling capabilities. We leverage two of the most successful transformer models, 1) GPT-2 and 2) GPT-3, to procedurally generate RPG video game quest descriptions. We gathered, processed, and openly published a dataset of 978 quests and their descriptions from six RPGs. We fine-tuned GPT-2 on this dataset with a range of optimizations informed by several ministudies. We validated the resulting Quest-GPT-2 model via an online user study involving 349 RPG players. Our results indicate that one in five quest descriptions would be deemed acceptable by a human critic, yet the variation in quality across individual quests is large. We provide recommendations on current applications of Quest-GPT-2. This is complemented by case-studies on GPT-3 to highlight the future potential of state-of-the-art natural language models for quest generation.},
  keywords={Games;Computational modeling;Task analysis;Large language models;Data models;Artificial intelligence;Role playing games;Artificial intelligence;computational storytelling;games;generative models;procedural content generation;quests},
  doi={10.1109/TG.2022.3228480},
  ISSN={2475-1510},
  month={March},}@INPROCEEDINGS{10577853,
  author={Krašna, Marjan and Bratina, Tomaž},
  booktitle={2024 13th Mediterranean Conference on Embedded Computing (MECO)}, 
  title={The use of AI and student population: The change is inevitable}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Generative AI systems have become a permanent fixture, with various authors highlighting their pros and cons. In education, a persistent technological gap often puts teachers at a disadvantage, trailing behind students who are more adept at embracing new technologies. The SETCOM project successfully introduced AI to both students and teachers, particularly focusing on educational study program students destined to become teachers themselves. Despite generational disparities between teachers and students, with younger generations showing more inclination towards ICT and AI, utilization remains sporadic. While students readily embrace AI, subscription-based advanced AI systems see surprising uptake, with around a fifth of students utilizing them. Primarily, students use AI to comprehend unfamiliar concepts, acknowledging its capacity to generate responses but exercising caution by verifying and correcting errors in over half of cases. For teachers, embracing AI becomes crucial to remain relevant in their field, despite potential financial implications. Failure to adapt risks being perceived as outdated by their students across all educational levels. In summary, generative AI systems are entrenched in education, offering both opportunities and challenges. Bridging the technological gap is imperative for teachers, as students increasingly rely on AI for learning support. Embracing AI becomes essential for educators to maintain relevance and effectiveness in teaching, ensuring they do not become obsolete in the eyes of their tech-savvy pupils.},
  keywords={Training;Generative AI;Fixtures;Focusing;Fasteners;Trajectory;Reliability;education;AI;student perspective;influence},
  doi={10.1109/MECO62516.2024.10577853},
  ISSN={2637-9511},
  month={June},}@INPROCEEDINGS{6374126,
  author={Nelson, Mark J. and Burelli, Paolo and Karpouzis, Kostas and Lucas, Simon and Cowling, Peter},
  booktitle={2012 IEEE Conference on Computational Intelligence and Games (CIG)}, 
  title={Tutorials}, 
  year={2012},
  volume={},
  number={},
  pages={F-1-F-2},
  abstract={Provides an abstract for each of the tutorial presentations and a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.},
  keywords={},
  doi={10.1109/CIG.2012.6374126},
  ISSN={2325-4289},
  month={Sep.},}@INPROCEEDINGS{11100261,
  author={Yang, Wen-Xi and Zhao, Tian-Fang},
  booktitle={2025 12th International Conference on Machine Intelligence Theory and Applications (MiTA)}, 
  title={Modeling Cross-Disciplinary Communication in Smart Education via Generative Agent}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={The application of generative agent models in smart education has become a hot topic in artificial intelligence research, with widespread use in fields such as personalized learning recommendations, intelligent question answering, and automated assessment. However, existing researches in smart education face challenges in cross-disciplinary communication, making it difficult to accurately simulate the language styles and thinking patterns of students from different disciplinary backgrounds. This leads to limited semantic transfer ability and weak knowledge integration capabilities, thereby limiting their effectiveness in multidisciplinary contexts. To address this issue, this study introduces the generative agent model driven by large language models (LLMs), based on Qwen-Max, to simulate interactions between humanities and science learners. Six metrics are designed to quantify and evaluate the quality of communication. Experimental results show that cross-disciplinary communication has lower information redundancy and stronger language adaptability compared to intra-disciplinary communication. The memory mechanism is introduced to improve communication coherence and knowledge integration. This research provides empirical support for the application of agents in cross-disciplinary collaboration and offers new directions for the development of smart education systems.},
  keywords={Measurement;Adaptation models;Humanities;Limiting;Redundancy;Semantics;Educational technology;Learning (artificial intelligence);Question answering (information retrieval);Machine intelligence;Generative agent;cross-disciplinary communication;quality evaluation;smart education},
  doi={10.1109/MiTA66017.2025.11100261},
  ISSN={},
  month={May},}@ARTICLE{9241434,
  author={Shen, Yujun and Yang, Ceyuan and Tang, Xiaoou and Zhou, Bolei},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={InterFaceGAN: Interpreting the Disentangled Face Representation Learned by GANs}, 
  year={2022},
  volume={44},
  number={4},
  pages={2004-2018},
  abstract={Although generative adversarial networks (GANs) have made significant progress in face synthesis, there lacks enough understanding of what GANs have learned in the latent representation to map a random code to a photo-realistic image. In this work, we propose a framework called InterFaceGAN to interpret the disentangled face representation learned by the state-of-the-art GAN models and study the properties of the facial semantics encoded in the latent space. We first find that GANs learn various semantics in some linear subspaces of the latent space. After identifying these subspaces, we can realistically manipulate the corresponding facial attributes without retraining the model. We then conduct a detailed study on the correlation between different semantics and manage to better disentangle them via subspace projection, resulting in more precise control of the attribute manipulation. Besides manipulating the gender, age, expression, and presence of eyeglasses, we can even alter the face pose and fix the artifacts accidentally made by GANs. Furthermore, we perform an in-depth face identity analysis and a layer-wise analysis to evaluate the editing results quantitatively. Finally, we apply our approach to real face editing by employing GAN inversion approaches and explicitly training feed-forward models based on the synthetic data established by InterFaceGAN. Extensive experimental results suggest that learning to synthesize faces spontaneously brings a disentangled and controllable face representation.},
  keywords={Semantics;Faces;Gallium nitride;Generative adversarial networks;Generators;Aerospace electronics;Facial features;Generative adversarial network;face editing;interpretability;explainable artificial intelligence;disentanglement},
  doi={10.1109/TPAMI.2020.3034267},
  ISSN={1939-3539},
  month={April},}@ARTICLE{8629024,
  author={Lucas, Alice and López-Tapia, Santiago and Molina, Rafael and Katsaggelos, Aggelos K.},
  journal={IEEE Transactions on Image Processing}, 
  title={Generative Adversarial Networks and Perceptual Losses for Video Super-Resolution}, 
  year={2019},
  volume={28},
  number={7},
  pages={3312-3327},
  abstract={Video super-resolution (VSR) has become one of the most critical problems in video processing. In the deep learning literature, recent works have shown the benefits of using adversarial-based and perceptual losses to improve the performance on various image restoration tasks; however, these have yet to be applied for video super-resolution. In this paper, we propose a generative adversarial network (GAN)-based formulation for VSR. We introduce a new generator network optimized for the VSR problem, named VSRResNet, along with new discriminator architecture to properly guide VSRResNet during the GAN training. We further enhance our VSR GAN formulation with two regularizers, a distance loss in feature-space and pixel-space, to obtain our final VSRResFeatGAN model. We show that pre-training our generator with the mean-squared-error loss only quantitatively surpasses the current state-of-the-art VSR models. Finally, we employ the PercepDist metric to compare the state-of-the-art VSR models. We show that this metric more accurately evaluates the perceptual quality of SR solutions obtained from neural networks, compared with the commonly used PSNR/SSIM metrics. Finally, we show that our proposed model, the VSRResFeatGAN model, outperforms the current state-of-the-art SR models, both quantitatively and qualitatively.},
  keywords={Neural networks;Training;Spatial resolution;Generators;Gallium nitride;Task analysis;Artificial neural networks;video signal processing;image resolution;image generation},
  doi={10.1109/TIP.2019.2895768},
  ISSN={1941-0042},
  month={July},}@ARTICLE{9631286,
  author={Sabuhi, Mikael and Zhou, Ming and Bezemer, Cor-Paul and Musilek, Petr},
  journal={IEEE Access}, 
  title={Applications of Generative Adversarial Networks in Anomaly Detection: A Systematic Literature Review}, 
  year={2021},
  volume={9},
  number={},
  pages={161003-161029},
  abstract={Anomaly detection has become an indispensable tool for modern society, applied in a wide range of applications, from detecting fraudulent transactions to malignant brain tumors. Over time, many anomaly detection techniques have been introduced. However, in general, they all suffer from the same problem: lack of data that represents anomalous behaviour. As anomalous behaviour is usually costly (or dangerous) for a system, it is difficult to gather enough data that represents such behaviour. This, in turn, makes it difficult to develop and evaluate anomaly detection techniques. Recently, generative adversarial networks (GANs) have attracted much attention in anomaly detection research, due to their unique ability to generate new data. In this paper, we present a systematic review of the literature in this area, covering 128 papers. The goal of this review paper is to analyze the relation between anomaly detection techniques and types of GANs, to identify the most common application domains for GAN-assisted and GAN-based anomaly detection, and to assemble information on datasets and performance metrics used to assess them. Our study helps researchers and practitioners to find the most suitable GAN-assisted anomaly detection technique for their application. In addition, we present a research roadmap for future studies in this area. In summary, GANs are used in anomaly detection to address the problem of insufficient amount of data for the anomalous behaviour, either through data augmentation or representation learning. The most commonly used GAN architectures are DCGANs, standard GANs, and cGANs. The primary application domains include medicine, surveillance and intrusion detection.},
  keywords={Anomaly detection;Data models;Systematics;Generative adversarial networks;Generators;Representation learning;Training;Anomaly detection;data augmentation;generative adversarial networks;outlier detection;representation learning},
  doi={10.1109/ACCESS.2021.3131949},
  ISSN={2169-3536},
  month={},}@ARTICLE{10187144,
  author={Dunmore, Aeryn and Jang-Jaccard, Julian and Sabrina, Fariza and Kwak, Jin},
  journal={IEEE Access}, 
  title={A Comprehensive Survey of Generative Adversarial Networks (GANs) in Cybersecurity Intrusion Detection}, 
  year={2023},
  volume={11},
  number={},
  pages={76071-76094},
  abstract={Generative Adversarial Networks (GANs) have seen significant interest since their introduction in 2014. While originally focused primarily on image-based tasks, their capacity for generating new, synthetic data has brought them into many different fields of Machine Learning research. Their use in cybersecurity has grown swiftly, especially in tasks which require training on unbalanced datasets of attack classes. In this paper we examine the use of GANs in Intrusion Detection Systems (IDS) and how they are currently being employed in this area of research. GANs are currently in use for the creation of adversarial examples, editing the semantic information of data, creating polymorphic samples of malware, augmenting data for rare classes, and much more. We have endeavored to create a paper that may act as a primer for cybersecurity specialists and machine learning researchers alike. This paper details what GANs are and how they work, the current types of GAN in use in the area, datasets used in this research, metrics for evaluation, current areas of use in intrusion detection, and when and how they are best used.},
  keywords={Generative adversarial networks;Generators;Training;Surveys;Machine learning;Computer security;Games;Intrusion detection;Data augmentation;Generative adversarial networks (GAN);machine learning;research survey;attack modeling;threat detection;intrusion detection systems;data augmentation;zero-day attacks;adversarial examples},
  doi={10.1109/ACCESS.2023.3296707},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10395092,
  author={A, Jenefa and Ebenezer, V and Isaac, A Joshua and Marshell, Joe and Pradeepa, P. and Naveen, V},
  booktitle={2023 7th International Conference on Electronics, Communication and Aerospace Technology (ICECA)}, 
  title={Adversarial Attacks on Generative AI Anomaly Detection in the Quantum Era}, 
  year={2023},
  volume={},
  number={},
  pages={1833-1840},
  abstract={In the context of the rapidly evolving quantum era, where the capabilities of quantum computing are expanding exponentially, the security and reliability of generative AI anomaly detection systems have come under significant threat from adversarial attacks. This paper delves into the vulnerabilities inherent in existing models in this quantum era and introduces a novel approach aimed at fortifying their resilience. The problem at hand pertains to the susceptibility of conventional generative AI anomaly detection systems to adversarial manipulations, raising critical concerns about their trustworthiness in critical applications. Traditional methods in this domain rely on static models that lack adaptability to defend against quantum-based adversarial attacks, rendering them inadequate for the evolving threat landscape. Our proposed solution combines quantum-resistant algorithms with advanced generative AI techniques to dynamically adapt to emerging attack strategies, resulting in demonstrably enhanced robustness against quantum-based adversarial attacks, as substantiated by our experimental findings. In conclusion, safeguarding generative AI anomaly detection systems against adversarial threats in the quantum era is paramount, and our innovative approach offers a promising avenue for bolstering the security and reliability of these systems in this challenging environment.},
  keywords={Adaptation models;Quantum computing;Generative AI;Computational modeling;Robustness;Security;Anomaly detection;Adversarial Attacks;Generative Artificial Intelligence;Anomaly Detection;Quantum Era;Quantum Computing},
  doi={10.1109/ICECA58529.2023.10395092},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11158675,
  author={Zhang, Shaoying and Wu, Lan},
  booktitle={2025 5th International Conference on Artificial Intelligence and Education (ICAIE)}, 
  title={Research on the AIGC-assisted Instructional Model of Intergrating Computational Thinking in STEM Education}, 
  year={2025},
  volume={},
  number={},
  pages={382-387},
  abstract={Computational thinking (CT) is crucial in the smart era and cultivating students' CT has attracted attention all around the world. Science, Technology, Engineering, and Math-ematics (STEM) education, focusing on the cultivation of higher-order thinking, aids CT development, with group work being the essential part of integrating CT in STEM education. The advent of artificial intelligence in generative content (AIGC) offers new opportunities for improving CT, especially in self-learning and group work. Thus, this study aims to construct an AIGC-assisted instructional design model of integrating CT in STEM education to enhance students' CT learning while providing them with a good experience of group work. Based on that, we developed a course and conducted a two-week quasi-experiment in a senior high school in the South area of China. Data analysis showed that the students were very satisfied with the instructional design model and their CT was significantly improved with the assistance of AIGC in STEM contexts. This study provides some evidence for AIGC-assisted STEM education that supports the development of CT skills and and to provide a reference for AIGC to support teachers in conducting STEM courses.},
  keywords={Ethics;Data analysis;Computational modeling;Education;Focusing;Collaboration;Learning (artificial intelligence);Data models;STEM;Context modeling;artificial intelligence in generative content (AIGC);computational thinking (CT);STEM education;instructional design model},
  doi={10.1109/ICAIE64856.2025.11158675},
  ISSN={},
  month={May},}@ARTICLE{10979306,
  author={Guan, Yuanjun and Liu, Yang and Wang, Jiayi and Wang, Tao and Yi, Qianchuan and Jiang, Wenxin and Gu, Xiaopu and Zhang, Yichen and Zhang, Li and Han, Tianyan and Huang, Binbing and Hu, Lilei},
  journal={IEEE Access}, 
  title={Novel Multi-Scale Attention Generative Adversarial Network for Photovoltaic Solar Cell Defect Inspection Using Electroluminescence Images}, 
  year={2025},
  volume={13},
  number={},
  pages={84409-84423},
  abstract={In the pursuit of promoting green energy, efficient defect inspection in solar cell manufacturing is crucial in enhancing the reliability of solar energy systems. However, traditional deep learning models for automatic defect inspection in photovoltaic (PV) cell electroluminescence (EL) images encounter challenges in industrial settings due to difficulties associated with data acquisition, imbalance, and variability of defects. This paper presents a novel Multi-Scale Attention Generative Adversarial Network (MAGAN), an innovative GAN-based framework specifically designed for data augmentation in the context of solar cell defect detection. When integrated with automated detection techniques, MAGAN markedly improves the accuracy and efficiency of current models. A method for augmenting image datasets of EL was developed to generate a sufficient quantity of images for training machine learning models, addressing sample scarcity and bolstering CNN-based defect classification accuracy. The core of this approach lies in the application of the MCA (Multi-channel Spatial Attention Mechanism) and GLSA (Gate-like Spatial Attention Mechanism) modules, which enhance feature extraction by leveraging channel attention and spatial attention, respectively, thereby reflecting the most recent advancements in attention mechanism technology. The MCA dissects channels into sub-features across various scales, ensuring detailed attention mapping, whereas the GLSA refines spatial cues with a gating mechanism, shedding computational inefficiencies. The effectiveness of this approach is validated by comprehensive experiments against state-of-the-art deep learning models. The experiments demonstrate the exceptional performance of MAGAN, achieving a low FID score of 141.98 and KID score of 0.106 on complex EL images, surpassing previous models and emphasizing data augmentation’s importance in defect detection. With an industry-leading detection accuracy of 87.3%, this study makes a substantial contribution to mitigating data imbalance. This method enhances quality control in solar cell manufacturing. Additionally, it advances defect inspection in the industrial semiconductor sector.},
  keywords={Generative adversarial networks;Photovoltaic cells;Computational modeling;Training;Inspection;Attention mechanisms;Accuracy;Deep learning;Photovoltaic systems;Image synthesis;Attention mechanism;convolution neural network;defect inspection;electroluminescence;generative adversarial network;photovoltaic solar cells},
  doi={10.1109/ACCESS.2025.3565002},
  ISSN={2169-3536},
  month={},}@ARTICLE{9454287,
  author={Wang, Jinghua and Jiang, Jianmin},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Learning Across Tasks for Zero-Shot Domain Adaptation From a Single Source Domain}, 
  year={2022},
  volume={44},
  number={10},
  pages={6264-6279},
  abstract={Domain adaptation techniques learn transferable knowledge from a source domain to a target domain and train models that generalize well in the target domain. Unfortunately, a majority of the existing techniques are only applicable to scenarios that the target-domain data in the task of interest is available for training, yet this is not often true in practice. In general, human beings are experts in generalization across domains. For example, a baby can easily identify the bear from a clipart image after learning this category of animal from the photo images. To reduce the gap between the generalization ability of human and that of machines, we propose a new solution to the challenging zero-shot domain adaptation (ZSDA) problem, where only a single source domain is available and the target domain for the task of interest is not accessible. Inspired by the observation that the knowledge about domain correlation can improve our generalization ability, we explore the correlation between source domain and target domain in an irrelevant knowledge task ($ \mathbb {K}$K-task), where dual-domain samples are available. We denote the task of interest as the question task ($ \mathbb {Q}$Q-task) and synthesize its non-accessible target-domain as such that these two tasks have the shared domain correlation. In order to realize our idea, we introduce a new network structure, i.e., conditional coupled generative adversarial networks (CoCoGAN), by extending the coupled generative adversarial networks (CoGAN) into a conditioning model. With a pair of coupling GANs, our CoCoGAN is able to capture the joint distribution of data samples across two domains and two tasks. For CoCoGAN training in a ZSDA task, we introduce three supervisory signals, i.e., semantic relationship consistency across domains, global representation alignment across tasks, and alignment consistency across domains. Experimental results demonstrate that our method can learn a suitable model for the non-accessible target domain and outperforms the existing state of the arts in both image classification and semantic segmentation.},
  keywords={Task analysis;Correlation;Training;Generative adversarial networks;Animals;Semantics;Adaptation models;Domain adaptation;zero-shot learning;adversarial learning;generative adversarial networks;domain generalization},
  doi={10.1109/TPAMI.2021.3088859},
  ISSN={1939-3539},
  month={Oct},}@INPROCEEDINGS{10936654,
  author={Lee, HyeokSoo and Yang, Minyeol and Jeong, Jongpil},
  booktitle={2025 27th International Conference on Advanced Communications Technology (ICACT)}, 
  title={A Novel Approach to Generative AI-based Optimized Code Generation for Semiconductor Equipment Interfaces}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Generally, standardization defined by the SEMI association is well established and utilized in the semiconductor industry. In particular, most semiconductor equipment supports SECS / GEM communication protocols, and the automation and smart factory construction consist of equipment communication control programs using these standard protocols. We propose to improve development efficiency by automatically generating control program code using generative artificial intelligence technology to develop interface programs that control these semiconductor facilities. In addition, to improve the completeness and utilization of the automatically generated code, this paper presents a method to automatically generate semiconductor equipment control interface codes through generative artificial intelligence based on existing codes and minimize the constraints that may occur due to the hallucination effect, which is a significant weakness of generative artificial intelligence.},
  keywords={Codes;Protocols;Generative AI;Databases;Large language models;Retrieval augmented generation;Electronics industry;Documentation;Standards;Smart manufacturing;Generative AI;Code Generation;LLM (Large Language Model);RAG (Retrieval Augmented Generation);Prompt},
  doi={10.23919/ICACT63878.2025.10936654},
  ISSN={1738-9445},
  month={Feb},}@INPROCEEDINGS{11058678,
  author={Bonilla, Lander and Aguirre-Usandizaga, Jon and Garcia-Perez, Asier and Osa, María José López and Belacortu, Idoia Murua and Diaz-de-Arcaya, J osu and Aroca, Jordi Arjona and Torre-Bastida, Ana Isabel and Milioñ, Raul and Almeida, Aitor},
  booktitle={2025 IEEE International Conference on Smart Computing (SMARTCOMP)}, 
  title={Towards a Framework for Intelligent Sampling: Comprehensive Review of Challenges, AI Techniques, and Tools}, 
  year={2025},
  volume={},
  number={},
  pages={504-509},
  abstract={Intelligent data sampling is an innovative method that enhances conventional data sampling procedures by utilizing machine learning and artificial intelligence approaches. In this manuscript, we deep dive into the scientific and grey literature to find the main challenges faced by data sampling and elaborate on the various AI techniques utilized to mitigate them. We identify key issues such as class imbalance, overfitting, computational inefficiency, and bias, which often hinder traditional sampling methods. Furthermore, we explore AI-driven techniques that have been integrated into the sampling process to address these challenges effectively. As a result, we propose a novel framework for intelligent sampling that incorporates an AI-powered recommender system. This system dynamically selects the most appropriate sampling technique based on the specific characteristics of the data and the needs of the predictive model. By automating and optimizing the selection of sampling methods, our framework aims to enhance model performance, improve resource efficiency, and adapt to diverse real-world applications.},
  keywords={Adaptation models;Reviews;Computational modeling;Active learning;Machine learning;Predictive models;Sampling methods;Generative adversarial networks;Recommender systems;Overfitting;Intelligent Data Sampling;AI techniques;Framework;Challenges;Generative Adversarial Networks;Active Learning},
  doi={10.1109/SMARTCOMP65954.2025.00096},
  ISSN={2693-8340},
  month={June},}@ARTICLE{9376904,
  author={Bai, Cong and Li, Hongkai and Zhang, Jinglin and Huang, Ling and Zhang, Lu},
  journal={IEEE Transactions on Multimedia}, 
  title={Unsupervised Adversarial Instance-Level Image Retrieval}, 
  year={2021},
  volume={23},
  number={},
  pages={2199-2207},
  abstract={With the wide use of visual sensors in the Internet of Things (IoT) in the past decades, huge amounts of images are captured in people's daily lives, which poses challenges to traditional deep-learning-based image retrieval frameworks. Most such frameworks need a large amount of annotated training data, which are expensive. Moreover, machines still lack human intelligence, as illustrated by the fact that they pay less attention to the interesting regions that humans generally focus on when searching for images. Hence, this paper proposes a novel unsupervised framework that focuses on the instance object in the image and integrates human intelligence into the deep-learning-based image retrieval. This framework is called adversarial instance-level image retrieval (AILIR). We incorporate adversarial training and an attention mechanism into this framework that considers human intelligence with artificial intelligence. The generator and discriminator are redesigned to guarantee that the generator retrieves similar images while the discriminator selects unmatched images and creates an adversarial reward for the generator. A minimax game is conducted by the adversarial reward retrieval mechanism until the discriminator is unable to judge whether the image sequence retrieved matches the query. Comparison and ablation experiments on four benchmark datasets prove that the proposed adversarial training framework indeed improves instance retrieval and outperforms the state-of-the-art methods focused on instance retrieval.},
  keywords={Image retrieval;Training;Generators;Generative adversarial networks;Feature extraction;Gallium nitride;Task analysis;Generative adversarial training;human intelligence simulation;instance level image retrieval;unsupervised training},
  doi={10.1109/TMM.2021.3065578},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{10578933,
  author={Frank, Lukas and Herth, Fabian and Stuwe, Paul and Klaiber, Marco and Gerschner, Felix and Theissler, Andreas},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Leveraging GenAI for an Intelligent Tutoring System for R: A Quantitative Evaluation of Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={The tremendous advances in Artificial Intelligence (AI) open new opportunities for education, with Intelligent Tutoring Systems (ITS) powered by Generative Artificial Intelligence (GenAI) proving to be a promising prospect. Because of this, our work explores state-of-the-art (SOTA) ITS approaches with the integration of Large Language Models (LLMs) to improve programming education. We investigate whether and how a GenAI-based ITS can effectively support students in learning R programming skills. We measured the performance of three current pairings of LLMs and user interfaces: GPT-3.5 via ChatGPT, PaLM 2 via Google Bard, and GPT-4 via Bing. Therefore, we evaluated the LLMs on four types of problem settings when learning/teaching programming. Our experimental results show that the use of generative AI, specifically LLMs for R programming, is promising, where GPT-3.5 yielded the most satisfactory results. Furthermore, the advantages and limitations of our approach are addressed and revealed. Finally, open research directions towards explainable AI (XAI) and integrated self-assessment are pointed out.},
  keywords={Generative AI;Explainable AI;Current measurement;Benchmark testing;Chatbots;Internet;Task analysis;Generative AI;AI in Education;Intelligent Tutoring Systems;R Programming;Student Support},
  doi={10.1109/EDUCON60312.2024.10578933},
  ISSN={2165-9567},
  month={May},}@ARTICLE{9366373,
  author={Li, Xiao and Rosman, Guy and Gilitschenski, Igor and Vasile, Cristian-Ioan and DeCastro, Jonathan A. and Karaman, Sertac and Rus, Daniela},
  journal={IEEE Robotics and Automation Letters}, 
  title={Vehicle Trajectory Prediction Using Generative Adversarial Network With Temporal Logic Syntax Tree Features}, 
  year={2021},
  volume={6},
  number={2},
  pages={3459-3466},
  abstract={In this work, we propose a novel approach for integrating rules into traffic agent trajectory prediction. Consideration of rules is important for understanding how people behave-yet, it cannot be assumed that rules are always followed. To address this challenge, we evaluate different approaches of integrating rules as inductive biases into deep learning-based prediction models. We propose a framework based on generative adversarial networks that uses tools from formal methods, namely signal temporal logic and syntax trees. This allows us to leverage information on rule obedience as features in neural networks and improves prediction accuracy without biasing towards lawful behavior. We evaluate our method on a real-world driving dataset and show improvement in performance over off-the-shelf predictors.},
  keywords={Trajectory;Syntactics;Predictive models;Generators;Feature extraction;Robustness;Planning;Autonomous-driving;prediction;temporal logic},
  doi={10.1109/LRA.2021.3062807},
  ISSN={2377-3766},
  month={April},}@INPROCEEDINGS{9261530,
  author={Voronov, V. I. and Dovgolevskiy, P. A.},
  booktitle={2020 International Conference on Engineering Management of Communication and Technology (EMCTECH)}, 
  title={Designing a Subsystem for Creating a Three-dimensional Model of an Orthopedic Insole Based on Data from a Laser 3D Scanning of the Patient's Feet}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={The article discusses the use of artificial intelligence methods for the design of orthopedic structures intended for the therapy and treatment of various pathologies of the human skeleton. The development of a software package for creating a three-dimensional model of an orthopedic insole based on an image of a patient's foot obtained using a specialized 3D scanner is described. The model was built using a modified generative adversarial network (GAN) Pix2Pix. This type of networks is used for the first time to obtain medically significant results in the field of orthopedics. The problems associated with obtaining a dataset suitable for neural network modeling are considered. Methods are described that make it possible to bring this set to a form suitable for training and further use in neural network modeling. A software module-data loader has been designed and implemented, which allows converting a three-dimensional model into a numpy array of a depth map with subsequent use as a training set. For the preprocessing of the original images, the authors used a wide range of methods, including dimensionality reduction, noise suppression (Gaussian filter). The results of neural network modeling of an orthopedic insole are presented. The presence of a three-dimensional model of the insole will allow it to be made on an industrial milling machine or printed on a printer using specialized medical material.},
  keywords={Training;Three-dimensional displays;Solid modeling;Software packages;Generators;Generative adversarial networks;Measurement by laser beam;software package;generative adversarial neural network;GAN;orthopedics;data preprocessing;software architecture;orthopedic insoles},
  doi={10.1109/EMCTECH49634.2020.9261530},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11082009,
  author={Ben Amarat, Samia and Shi, Chaoxia and Wang, Yanqing},
  booktitle={2025 8th International Conference on Artificial Intelligence and Big Data (ICAIBD)}, 
  title={Generative Adversarial Imitation Learning Method Based on TD3-SAC Hybrid Algorithm for Robot Motion Control}, 
  year={2025},
  volume={},
  number={},
  pages={846-852},
  abstract={The dependency on expert demonstrations and the difficulty in surpassing expert performance have been significant limitations in the field of imitation learning. This paper presents a TD3-SAC Hybrid Method that combines the advantages of two advanced RL algorithms, TD3 and SAC, integrating their exploration mechanisms to enhance the exploration capability of Generative Adversarial Imitation Learning (GAIL, an imitation learning method using generative adversarial networks). Furthermore, we designed a closed-loop method for generating expert demonstrations through a learning-based data generation and feedback approach, and proposed a GAIL model training pipeline based on TD3-SAC Hybrid Method, ultimately forming a robust robot motion control method. Through comparative experiments, we demonstrated the effectiveness of the TD3- SAC hybrid method in GAIL. It outperforms baselines such as C-GAIL, GDSG, DAC, and methods combining classical RL algorithms with GAIL, achieving better performance, overcoming the limitations of expert demonstrations and demonstrating a higher probability of outperforming expert demonstrations in MuJoCo simulation environments (46% in HalfCheetah, 35% in LunarLander, 14% in Walker2d, and 21% in Hopper). This method not only retains the advantages of imitation learning but also equips the agent with the necessary exploration mechanisms to overcome the limitations of expert-based learning, particularly in challenging and complex environments.},
  keywords={Robot motion;Training;Navigation;Imitation learning;Pipelines;Noise;Reinforcement learning;Generative adversarial networks;Hybrid power systems;Entropy;GAIL;Reinforcement learning;SAC;TD3},
  doi={10.1109/ICAIBD64986.2025.11082009},
  ISSN={2769-3554},
  month={May},}@INPROCEEDINGS{10933660,
  author={Yan, Dongxia and Cheng, Xien},
  booktitle={2024 5th International Conference on Computer, Big Data and Artificial Intelligence (ICCBD+AI)}, 
  title={Integrating CLIP with Dynamic Memory Generative Adversarial Networks to Enhance Semantic Consistency in Text-to-Image Generation}, 
  year={2024},
  volume={},
  number={},
  pages={466-471},
  abstract={This paper focuses on the challenge of a lack of strong semantic coherence between generated images and their corresponding text descriptions, as well as the low quality of initial image generation and limited detail capture in the Dynamic Memory Generative Adversarial Networks model. To tackle these issues, we propose the DM-CLGAN model, an enhanced variant of DM-GAN. By incorporating the CLIP model, DM-CLGAN achieves improved alignment between textual and image features. Furthermore, it introduces the Text-Image Affine Combination Module and the Convolutional Block Attention Module to optimize image details and enhance the quality of the initially generated images. In the second stage of the model, the dynamic memory network further refines the generated images. We utilized a quantitative assessment of the model's performance on the CUB-200-2011 dataset by employing key metrics such as Inception Score and Fréchet Inception Distance. The results of our study demonstrate that the generation quality exceeds that of other models, as confirmed by manual evaluation methods. Additionally, the model demonstrates exceptional generation capabilities on our custom-built ceramic wine bottle dataset, further validating the adaptability and generative efficacy of the proposed approach.},
  keywords={Measurement;Adaptation models;Image synthesis;Computational modeling;Semantics;Text to image;Production;Generative adversarial networks;Product design;Ceramics;Text-to-image synthesis;DM-GAN;CLIP;DM-CLGAN;ACM},
  doi={10.1109/ICCBD-AI65562.2024.00083},
  ISSN={},
  month={Nov},}@ARTICLE{10638024,
  author={Qiu, Yepeng},
  journal={IEEE Access}, 
  title={The Impact of LLM Hallucinations on Motor Skill Learning: A Case Study in Badminton}, 
  year={2024},
  volume={12},
  number={},
  pages={139669-139682},
  abstract={The rise of Generative Artificial Intelligence, including Large Language Models (LLMs), has enabled users to engage in self-guided learning of sports skills through conversation-based interactions. However, studies have identified a phenomenon known as “hallucination” in which LLMs generate feedback that is inaccurate or non-existent. While this phenomenon has been observed in various domains, including medicine, academia, and news, its existence and implications in the context of physical exercises, particularly motor skill learning, remain unexplored. This study investigates the presence of LLM hallucinations in badminton skill learning and examines their potential impact on learning outcomes. This study aims to investigate whether LLMs hallucinations exist in the motor skill learning of physical exercises and what impact they may have. Eighty university freshmen with no prior badminton experience participated in a 16-week experiment, with 40 students assigned to the Experimental Group (EG) utilizing LLM-based applications (ChatGPT or New Bing) for self-guided learning, and 40 students in the Control Group (CG) learning under the supervision of 12 university sports teachers and 8 experts that specialized in badminton. Evaluation criteria for badminton skills were established, and assessments were conducted at baseline and 16 weeks using independent sample t-tests and paired-sample t-tests. One-way analysis of variance (One-Way ANCOVA) was employed to compare learning outcomes between the two groups. Interviews were conducted to gain insights into the causes of any observed differences in learning efficiency. Both CG and EG groups demonstrated motor skill improvement (clear: p <0.001; smash: p <0.001; footwork: p <0.001). CG exhibited significantly higher scores in long-distance shots and smashes in the post-test. No significant difference was observed in footwork scores between the two groups. High accordance in specific skill points among students in both groups indicated the common usage of prompts. Interviews with EG students revealed hallucinations in the text generated by LLMs, particularly in the context of “forearm internal rotation swing.” LLMs exhibit hallucinations in the context of intricate motor skill learning, such as badminton, where limited corpus data is available. These hallucinations can mislead users and impact learning outcomes. Future research should explore strategies to mitigate LLM hallucinations in physical exercise learning applications.},
  keywords={Artificial intelligence;Sports;Videos;Social networking (online);Fake news;Large language models;Motor coordination;Large language models;hallucination;motor skill learning;badminton skill},
  doi={10.1109/ACCESS.2024.3444783},
  ISSN={2169-3536},
  month={},}@ARTICLE{10716437,
  author={Chen, Qiyu and Luo, Huiyuan and Gao, Han and Lv, Chengkan and Zhang, Zhengtao},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Progressive Boundary Guided Anomaly Synthesis for Industrial Anomaly Detection}, 
  year={2025},
  volume={35},
  number={2},
  pages={1193-1208},
  abstract={Unsupervised anomaly detection methods can identify surface defects in industrial images by leveraging only normal samples for training. Due to the risk of overfitting when learning from a single class, anomaly synthesis strategies are introduced to enhance detection capability by generating artificial anomalies. However, existing strategies heavily rely on anomalous textures from auxiliary datasets. Moreover, their limitations in the coverage and directionality of anomaly synthesis may result in a failure to capture useful information and lead to significant redundancy. To address these issues, we propose a novel Progressive Boundary-guided Anomaly Synthesis (PBAS) strategy, which can directionally synthesize crucial feature-level anomalies without auxiliary textures. It consists of three core components: Approximate Boundary Learning (ABL), Anomaly Feature Synthesis (AFS), and Refined Boundary Optimization (RBO). To make the distribution of normal samples more compact, ABL first learns an approximate decision boundary by center constraint, which improves the center initialization through feature alignment. AFS then directionally synthesizes anomalies with more flexible scales guided by the hypersphere distribution of normal features. Since the boundary is so loose that it may contain real anomalies, RBO refines the decision boundary through the binary classification of artificial anomalies and normal features. Experimental results show that our method achieves state-of-the-art performance and the fastest detection speed on three widely used industrial datasets, including MVTec AD, VisA, and MPDD. The code will be available at: https://github.com/cqylunlun/PBAS.},
  keywords={Image reconstruction;Feature extraction;Anomaly detection;Training;Optimization;Learning (artificial intelligence);Gaussian noise;Vectors;Location awareness;Data models;Anomaly detection;industrial images;anomaly synthesis;progressive boundary guidance},
  doi={10.1109/TCSVT.2024.3479887},
  ISSN={1558-2205},
  month={Feb},}@ARTICLE{10143174,
  author={Fan, Jiayi and Hong, Seul Ki and Lee, Yongkeun},
  journal={IEEE Access}, 
  title={Validity Improvement in MolGAN-Based Molecular Generation}, 
  year={2023},
  volume={11},
  number={},
  pages={58359-58366},
  abstract={Designing molecules that have desired properties is one of the challenging tasks of drug design. Among the many molecular generative models, a generative adversarial network (GAN), is able to generate molecule structures with desirable chemical properties via reinforcement learning. Generating valid molecules is the foremost task of any molecular generative model, since invalid molecules cannot be synthesized. We base our research on a molecular generative adversarial network (MolGAN) architecture to investigate how the validity score is influenced in different scenarios. First, we verify that the Vanilla GAN structure can produce valid molecules in measure, and that the reward network, along with Vanilla GAN, can further increase the validity score in a reinforcement learning manner. Then, the procedure for solely optimizing the validity score is tested, followed by an assessment of validity score maintenance while other chemical properties are being optimized. We found that multiple aspects, including loss functions, hyper parameters, and training sequences, must be carefully considered and optimized to raise the validity score of molecular generation alone or in concurrence with the optimizing of other chemical property scores.},
  keywords={Generative adversarial networks;Generators;Chemicals;Tensors;Training;Drugs;Molecular biology;Drug design;molecular generation;generative adversarial network (GAN);molecular generative adversarial network (MolGAN)},
  doi={10.1109/ACCESS.2023.3282248},
  ISSN={2169-3536},
  month={},}@INBOOK{10614282,
  author={Ojanperä, Tero},
  booktitle={AI Revolution: Mastering AI for Personal and Organizational Growth}, 
  title={AI Revolution: Mastering AI for Personal and Organizational Growth}, 
  year={2024},
  volume={},
  number={},
  pages={i-xxvi},
  abstract={"The AI Revolution" is a practical guide to using new AI tools, such as ChatGPT, DALLE and Midjourney. Learn how to multiply your productivity by guiding or prompting AI in various ways. The book also introduces Microsoft Copilot, Google Bard, and Adobe Photoshop Generative Fill, among other new applications. ChatGPT reached a hundred million users in just two months after its release, faster than any other application before. This marked the advent of the generative AI era. Generative AI models generate text, images, music, videos, and even 3D models in ways previously thought impossible for machines. The book explains in an understandable manner how these AI models work. The book provides examples of how AI increases productivity, which professions are changing or disappearing, and how job markets will evolve in the coming years. With this book, you'll learn to recognize the opportunities and risks AI offers. Understand what this change demands from individuals and companies and what strategic skills are required. The book also covers legal questions caused by generative AI, like copyrights, data protection, and AI regulation. It also ponders societal impacts. AI produces content, thus influencing language, culture, and even worldviews. Therefore, it's crucial to understand by whom and how AI is trained. The AI revolution started by ChatGPT is just the beginning. This handbook is for you if you want to keep up with the rapid development of AI.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770042314},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10614282},}@ARTICLE{10990147,
  author={Rutagemwa, Humphrey and Ghasemi, Amir and Guinand, Paul},
  journal={IEEE Intelligent Systems}, 
  title={Empowering Future Spectrum Management and Regulation With Large Language Models}, 
  year={2025},
  volume={40},
  number={4},
  pages={46-54},
  abstract={Spectrum management and regulation are becoming more complex due to rapid technological advancements, increasing demand for spectrum, and the presence of diverse stakeholders with conflicting interests. In response, governments worldwide are increasingly interested in leveraging advanced technologies, such as artificial intelligence (AI), to enhance efficiency and optimize policy outcomes. This article explores the application of large language models (LLMs), a subset of generative AI, to streamline tasks and improve decision making in spectrum management and regulation. It examines the various roles of LLMs in this field and addresses associated challenges. Through empirical case studies and experimental findings, the article demonstrates how LLMs can profoundly transform spectrum management and regulation practices. The study also offers insights into effectively integrating AI into regulatory frameworks, providing practical lessons and best practices for governmental AI initiatives.},
  keywords={Radio spectrum management;Data mining;Artificial intelligence;Regulation;Licenses;Question answering (information retrieval);Interference;Stakeholders;Large language models},
  doi={10.1109/MIS.2025.3567372},
  ISSN={1941-1294},
  month={July},}@ARTICLE{9847028,
  author={Su, Ke and Su, Hang and Li, Chongxuan and Zhu, Jun and Zhang, Bo},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Probabilistic Neural–Symbolic Models With Inductive Posterior Constraints}, 
  year={2024},
  volume={35},
  number={2},
  pages={2667-2679},
  abstract={Neural–symbolic models provide a powerful tool to tackle complex visual reasoning tasks by combining symbolic program execution for reasoning and deep representation learning for visual recognition. A probabilistic formulation of such models with stochastic latent variables can obtain an interpretable and legible reasoning system with less supervision. However, it is still nontrivial to generate reasonable symbolic structures without the guidance of domain knowledge, since it generally involves an optimization problem with both continuous and discrete variables. Despite the challenges, the interpretability of such symbolic structures provides an interface to regularize their generation by domain knowledge. In this article, we propose to incorporate the available domain knowledge into the learning process of probabilistic neural–symbolic (PNS) models via posterior constraints that directly regularize the structure posterior. In this way, our model is able to identify a middle point where the structure generation process mainly learns from data but also selectively borrows information from domain knowledge. We further present inductive reasoning where the posterior constraints can be automatically reweighted to handle noisy annotations. The experimental results show that our method achieves state-of-the-art performance on major abstract reasoning datasets and enjoys good generalization capability and data efficiency.},
  keywords={Cognition;Task analysis;Computational modeling;Artificial intelligence;Visualization;Probabilistic logic;Annotations;Abstract reasoning;deep learning;neural-symbolic integration;visual reasoning},
  doi={10.1109/TNNLS.2022.3190820},
  ISSN={2162-2388},
  month={Feb},}@ARTICLE{9312402,
  author={Hu, Junjie and Guo, Xiyue and Chen, Junfeng and Liang, Guanqi and Deng, Fuqin and Lam, Tin Lun},
  journal={IEEE Robotics and Automation Letters}, 
  title={A Two-Stage Unsupervised Approach for Low Light Image Enhancement}, 
  year={2021},
  volume={6},
  number={4},
  pages={8363-8370},
  abstract={As vision based perception methods are usually built on the normal light assumption, there will be a serious safety issue when deploying them into low light environments. Recently, deep learning based methods have been proposed to enhance low light images by penalizing the pixel-wise loss of low light and normal light images. However, most of them suffer from the following problems: 1) the need of pairs of low light and normal light images for training, 2) the poor performance for dark images, 3) the amplification of noise. To alleviate these problems, in this letter, we propose a two-stage unsupervised method that decomposes the low light image enhancement into a pre-enhancement and a post-refinement problem. In the first stage, we pre-enhance a low light image with a conventional Retinex based method. In the second stage, we use a refinement network learned with adversarial training for further improvement of the image quality. The experimental results show that our method outperforms previous methods on four benchmark datasets. In addition, we show that our method can significantly improve feature points matching and simultaneous localization and mapping in low light conditions.},
  keywords={Lighting;Image enhancement;Noise reduction;Training;Simultaneous localization and mapping;Robots;Image quality;Low light image enhancement;robot’s perception;SLAM;unsupervised method},
  doi={10.1109/LRA.2020.3048667},
  ISSN={2377-3766},
  month={Oct},}@ARTICLE{10552736,
  author={Wang, Changsheng},
  journal={IEEE Access}, 
  title={Art Innovation or Plagiarism? Chinese Students’ Attitudes Toward AI Painting Technology and Influencing Factors}, 
  year={2024},
  volume={12},
  number={},
  pages={85795-85805},
  abstract={The increasing integration of artificial intelligence (AI) in art, particularly AI painting technology, has captivated significant attention and sparked debate. However, little is understood about the attitudes of Chinese students toward this technology and the factors influencing their perspectives. This study employed a mixed-methods approach to comprehensively appraise Chinese students’ attitudes toward AI painting technology and the reasons behind these viewpoints. Data was collected from five universities and three high schools in China through questionnaire surveys and semi-structured interviews. Quantitative analysis demonstrated clear trends in students’ attitudes toward AI painting technology, with gender, educational level, and background in art and design identified as significant influencing factors. Specifically, students with higher levels of education demonstrated more favorable attitudes toward AI painting technology. This was evidenced by a strong positive correlation coefficient of 0.644 (p<0.01) between educational attainment and positive perceptions of this technology; whereas, a negative correlation with gender (coefficient of −0.263, p<0.01) indicated a difference in attitudes between male and female students, with males displaying more positive views. Specifically, background in art and design did not appear to significantly affect students’ attitudes, as presented by an insignificant correlation coefficient of −0.048 (p>0.05). In addition, regression analysis, with an R2 value of 0.419, suggests that these variables can account for 41.9% of the variance in student attitudes toward AI painting, emphasizing the significant effect of gender and education level on their perspectives. Qualitative findings further indicated that concerns about copyright ethics, job displacement anxieties, personal values and aesthetic viewpoints, and broader social and environmental implications all affected students’ attitudes toward AI painting technology. These findings offer valuable insights into the attitudes toward AI-generated technologies.},
  keywords={Artificial intelligence;Painting;Art;Surveys;Training;Interviews;Collaboration;Educational programs;AI art;AI painting;student attitudes;education and AI;mixed methods research},
  doi={10.1109/ACCESS.2024.3412176},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10585442,
  author={Sas, Martin},
  booktitle={2024 IEEE Gaming, Entertainment, and Media Conference (GEM)}, 
  title={Unleashing Generative Non-Player Characters in Video Games: An AI Act Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={The increased integration of large language models and generative AI in non-player characters (NPCs) is radically transforming the gaming industry. While these new technologies can enhance the immersiveness of the game experience, generative NPCs also introduce substantial risks of damaging misbehaviour. In this paper, we highlight the role of each actor along the supply chain of generative non-player characters (NPCs) and analyse how the forthcoming AI Act might apply vis-à-vis the allocation of responsibilities. Finally, we highlight unacceptable uses of generative NPCs.},
  keywords={Video games;Law;Large language models;Instruments;Supply chains;Media;Regulation;Generative AI;EU AI Act;video game;Non-player character (NPC);Large language models (LLM)},
  doi={10.1109/GEM61861.2024.10585442},
  ISSN={2766-6530},
  month={June},}@ARTICLE{10715728,
  author={Wu, Chunyi and Li, Lin and Zhang, Li and Gao, Chao and Wu, Xingchen and Xiao, Shan},
  journal={IEEE Internet of Things Journal}, 
  title={Efficient GAN-Based Federated Optimization for Vehicular Task Offloading With Mobile Edge Computing in 6G Network}, 
  year={2025},
  volume={12},
  number={3},
  pages={2736-2748},
  abstract={With the rapid development of 6G network technology and intelligent transportation system (ITS), the edge deployment and lightweight of network applications for modern users have gradually become a possibility. In this work, we propose a mobile intelligent vehicular task offloading method efficient mobile edge computing assisted task offloading using generative adversarial network (MEGAN) based on task representation learning and federated optimization for lightweight task recognition and energy consumption optimization of mobile edge computing (MEC) in 5G/6G transportation networks. The extended dataset of tasks is constructed based on generative adversarial network (GAN) to overcome the problems of data model overfitting and sample imbalance. A task preprocessing model between the edge server and the mobile users is established by using the federated deep learning with the knowledge distillation. The task classification accuracy, energy consumption of signal transmission and data computing are the optimization objectives to realize the MEC and lightweight application deployment. Experimental results show that compared with other state-of-the-art vehicular task offloading methods, the MEGAN method has great potential to promote the efficiency and energy consumption optimization of new transportation service processing in the future.},
  keywords={Optimization;Computational modeling;Generative adversarial networks;Big Data;Resource management;Training;Multi-access edge computing;Energy consumption;Servers;Faces;Federated optimization;generative adversarial network (GAN);mobile edge computing (MEC);representation learning;vehicular task offloading},
  doi={10.1109/JIOT.2024.3479285},
  ISSN={2327-4662},
  month={Feb},}
